Hello, Antonio. I'm going to keep talking about FRBs, but I'm going to do more about the classification of FRBs. And this is our work. Oh, I'm a postdoctoral fellow and I'm working with Rado, Derek, Wen, David, and Brian in the collaborative research team. So, yeah, so let's just start from here. So, when we are classifying the FRPs, we have Classifying the FRBs, we have an idea of what we wanted, right? And we worked with the usual classifiers to get there. But we realized that the data is not as simple and we needed to understand what we were doing before trying to actually obtain what we were classifying. I will go fast from here because thanks Amanda. What are radio birds? They are millisecond signals that we don't know where they are coming from. Don't know where they are coming from, but we know that they are extragalactic from outside space. Yay! Very recent, the telescope implemented new ways to find them, and of course, now we have tons of them that are being found generally. The data that we're working with is charm telescope, and just repeating what Amando said: chime is in. Commandos Earth, Charm is in PC, he's static, he's looking at the north sky all the time, and it's a radio telescope and continuously observes between 400 and 800 megahertz. Okay, telescope away. So how many types of FRBs do we know that they exist? So expanding from Amanda. So how do we classify that? So how do we classify them? In the most sensible way possible. So we see them re non-repeating, like they don't just one of us, non-repeaters. We see them repeat, repeaters. That's the most sensible way we found to classify them. Even the subtype of very act uh like a frequency repeat the is a repeater. So just like subclass, but still we don't know. Still, we don't know. So, but what I'm now showing what Amanda mentioned, this is for the time catalog one. So, if we see there are hints that they might be different. So, if we see the structure of the time versus frequency plot of one burst, this is a non-repeater, and you can see that it has like strike. And you see a repeater, it has a wider structure. Wider structure and a different pattern. So, this gives you like an idea that maybe this type of these two classes actually are real and you can trust that they exist. And we go from there, the classification, we go from that pattern now. So, you have different approaches how to work with this. The type of, for example, the regression type that you got, population rates, repeating rates. Got population rates, repeating rates, and you try to explain or feed the population of repeating FRVs or the non-repeating FRPs. Or you can have the classification approach that, oh, you go to the previous time plots, you extract some features, and you try to split these classes or try to identify these two classes. So we are doing the classification. If the title Classification: if the title of the talk didn't give him away, and so the question is: why are we doing this classification? Because we want to identify if with these properties or these features, when we see a new FRBs, we can actually obtain or predict that, oh, this is actually a repeater. So, we might need to pay attention again about this one. That is like, oh, if this is a repeater, maybe we can trust. Peter, maybe we can trust that the PCC is actually correct when you see there, like an extra test. There are different approaches that other people are exploring, like for example, dimensionality reduction, DSNE, UMAP, and you can use these approaches to try to put them together in an embedding. But we found that this is not as good. If you see the non-repeaters are in black, the repeaters. Black, the repeaters are in green and they are mixed together, so it's not very easy to classify that. Even worse, if you select one specific repeater and all the repetitions, red and blue, they are quite far away. So there is more happening in the data than just using it. So there is no clear separation or how to interpret what is happening when you try to do this. To do this. So we went more into the data, try to find what issues do we have, what is happening inside, and we found mainly four issues that we try to deal with. The first one is interpretability, try to understand what we are classifying or what is happening in the data. The other is that the data is heavily imbalanced. One-offs that are like 10 to 1 compared to the repeaters. Server application, yay. Application, yay! I will explain the tab one at the end for the people who have never heard about it. And the non-repeater levels are not always accurate, so they are contaminated. You might have a repeater that actually is one-off, but it's because we haven't seen them repeat yet. So that's also an issue. So, classification, logistic regression. It's the simplest that we can start with. Mathematically, we know how to. With mathematically, we know how to understand very well, explore. So, we went to the registered regression. We use four features that we can extract because I understand it better. What is the special measure? It gives us a distance. We can get the width of the burst, so the time of the width, the time of the burst, the scattering of the signal, and the weight in the frequency of the button width. We grab these four and we apply the logistics. We grab these four and we apply the logistic regression and we obtain nothing. Basically, it says everything is a non-repeater, yay. But this is because, oh, yay, it's imbalance. This is going to happen. When you have that imbalance of the data, depending where you look at, there are different approaches: data augmentation, resampling, weighting. We decided to go for the weighing. I will explain at the end, or I will make sense at the end why. Or, I will make sense at the end why we went to the last one. How do we weight? The common approach will be: okay, we have an imbalance, we put weights that put in 50-50, let's say, like balance the data. But here is our thinking. What if this imbalance is true? What we we actually want to see this imbalance and it exists, so we cannot put them straightforward to a fifty fifty approach. Forward to a 50-50 approach. So, what we do instead is just go and treat it as a rare events problem. For a rare events problem, you have a fraction of the true population, tau, and you have the average of the positives in the data that you observe. You make the weights for 0 and 1, or the positives and the negatives, it's just a fraction of between these two quantities, and you introduce it into the data just as. Into the data, just as the weights. Is it straightforward into the logistic regression, just as a simple factor there at the beginning of the livelihood? Has someone noticed something weird from everything I said? Anyone? No? Tao? Yes, I don't know Tao. How do I use that? Yeah, but you have a rare. Yeah, but you have a relevance problem that I got from political sciences. You have a census and you know the full population and you have an external factor that there is a reason like someone didn't give you back the interview or someone didn't reply. So the fraction of the population that you observe is different and you try to compensate. But we don't have tau. But that's not the problem itself because instead of having Itself because instead of having one classifier, we are just going to create classifiers for each value of tau. So we are just going to try to infer tau from the data. Knowing that, we do exactly that. Now, experiment. So this is just the accuracy of several classifiers as a function of tau. The solid line. The solid line, this blue solid line, is the median, while the shaded blue region is the interquartile range, 25 to 75, for different values of tau. The other has just the minimum and maximum sample from the set k fall cross-validation for each value of tau. And if we see, for example, a And if we see, for example, at 50%, say that you have a fraction of 0.5, it's good enough to say, like, okay, yeah, we could have started from there and we could have obtained something sensible. But if you go just slightly above and you go to 0.6, you get that in the quantitative range, and you already have a perfect classification. Why we care about the repeaters? Again, the repeaters, as Amanda explained, are the ones that we trust. The ones that we trust. Their labels are the most trustable. The non-repeaters, we don't mind if we lose some of them. There might be some repeaters that have the structure of a repeater. So we are just maybe just classifying them correctly instead of misclassifying them. So that's why we go like, oh, yeah, if we go for a tau of 0.6 actually is a better A better fraction. Of course, this is a soft limit, not an actual limit to say, like, oh, yeah, this tau is the correct one. Why? Because there are several biases that we are not accounting for. This is just for the fierce catalog of time. Also, we are only using four features. We should use more than that. And this is just a linear relationship. We are not if there is some nonlinearity, we are not taking into account. Into account. So that's for the imbalance. And what we are actually working on is in the pseudo-replication. How do we introduce the pseudo-replication into the weighing? Pseudo-replication is simple. Basically, is that there is non-IID data in the sample. Explaining, like more concrete, you have the effort resources, right? The effort resources, right? And you have a sample. Non-repeaters, one sample per source. Simple, independent, understandable. You introduce the non-repeaters, the repeaters. That means you have several samples per source. That means that now your data has two level structure. You have the level of the samples and the level of the sources for the repeaters, but not for the non-repeaters. And you have to take into account And you have to take into account now those ones. So you cannot do the classification straightforward because you now have a grouping for the repeaters and you have that information. And this makes sense why data augmentation or resampling is not the best approach because if you have several samples for one repeater, that means that you actually are going to bias towards that repeater because when you Was that repeater because when you resample that one it's going to feel way more than the rest and usual treatments is just made a mixed model where you have the fixed effects that deal with the source level and the random effects deal with the sample level. And yeah, we're going to we're working on how to introduce the mixed model with the waning in the logistic regression to try to obtain a classification that takes into account all of these Into account all of these issues. I'm not going to deal more with this one, only in the future, and I'm just going to wrap up then. That we are working on methodology to classify FRBs as repeaters and non-repeaters, that we want to have some interpretability in the data. We are approaching as a revence problem, and we want to address the structure of the data. And we're working on how to address the Address the seller application into the waiting list square, waiting logistic regression. Yes, thank you. Question. Yes. Go back to your graph with the towel and the