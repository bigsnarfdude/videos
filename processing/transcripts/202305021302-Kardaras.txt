Yeah, thank you very much, Dila. And let me also of course from my side extend my gratitude to the organizers and my relief for being able to do these things all over again after quite some time. Many thanks also for Milan and Ilana, yes, who randomly assigned me the honor to open this workshop and to Air Canada for making sure that I miss the opportunity to go work to be short. And unfortunately I had a lot of quite funny stuff to say and very acute remarks, but they were all contingent on this could be the opening, so I cannot use any of this stuff anymore. Use any of this stuff anymore, so you will get the boring version. Thank Reno also for staying over because I know that you wanted to go to the mountains. So, and apologies for the ones who have seen this very recently. There are developments, but I did not put them in the slides because but I will mention a couple of things at some point. An interrupt me at the Things at some point. And interrupt me at any point you have any questions. Okay, so the whole point here is to talk about portfolio choice, but there will be two things. The most important one will be that I'm not going to see portfolio choice in terms of liquidation at a specific time in the future. So you don't have a fixed liquidation time, but you can choose a stopping time, not to liquidate it. You just will have expected. You just will have expected time constraints. So you want to do it quickly, but you don't have a hard constraint on one hand. The other novelty is that you can solve this problem under also taxation and capital gains. I will explain what I mean by this. It's a fact that could be, you know, seem as theoretical, but makes quite a lot of sense. The good news here is that you can get very explicit solutions in a very general thing. Solutions in the inner very general framework that you cannot in general get for the utility maximization problem in the classical way that you have a fixed liquidation date. You can get very good characterizations, but you do not get closed from expressions. So, let me just start with the market. So, the only thing that I would be assuming more or less is that you have continuous asset price processes, because the thing does not work with junks, what I'm going to say, but otherwise. But otherwise, you just have a semi-martineel model where R is the returns. And I just split it. So R is the returns of the i-th asset, and I split it into the basically excess mean returns. So this is the finite variation process, and these are the local markets that we have. So A is important. What is also important is the covariation process between the recurrence. So CIJ is the covariation process between asset. Covariation process between asset, the returns of asset value and asset chain. Cumulative covariation, so basically. So you can think of a needle model if you want. There's basically just a couple of assumptions that we will make, except for the fact that we have continuous processes. And one important one is that the actually the Actually, the drift lies in the image of the variation metrics. Time is everywhere there, I'm just not putting it so that things look better. Nothing is constant, everything is adapted and so forth. The reason that you want this is that if you don't have it, then basically you can find a direction where you can kill the volatility and just make us what's going on. We can tilt the valuability and just make as much fine as you want. So, there is no point in even looking at such models when you do not have a structure of emissions. This predictable process here will play an important role later. We will see it as a portfolio. Does it have some retigarity? I'm not asking anything now, but I will ask it here. Here. Thank you for this. So, one thing that will be One thing that will be different than in the usual perception that we have with respect to time is that I'm not looking at calendar time, but I'm going to look at something that I call market opportunity time. So we take a clock that moves quickly when there is a lot of opportunities in the market to make money. And you want to make money as fast as possible with respect to this clock. Because the idea is that if you lose the opportunity, then you regret it more. And how this moves is like this. This moves is like this. So, this is the square root of the infinitesimal variation, and this is the drift. So, this is squared sharp ratio in the market. When the sharp ratio is large, there's a lot of opportunity in the market to make money. The clock runs fast. When sharp ratio is low, it runs slowly. That is the end. So, eventually, we will want to make sure that in terms of market time, we do not wait too long. So, this will be. Too long. So, this will be our constraint. And there are some cases where, of course, you have car constraints on when you have to liquidate, other cases where you don't. And this is the second version that I'm just looking at in this presentation. One thing that I want to point out here is that if you look at this norm that is here, basically this is. Okay, this is the normal square that is in there. And of course, if you substitute here one of the dA's, this is mu times dA. And I can do it all over again. And this is just this in mu. So if you see mu as a portfolio that we will do later, then you get that this squared sum up ratio is both the returns and the covariation that we get from this proposal. But you get the only scroll. Alright? Um so as as Tahir mentioned, you have to put some integrability. So throughout this presentation, this G here will have to be finite for every single p. Again, this is an arbitrary assumption. I don't want to get into this, whenever you write any reasonable model, this holds plus the second one, which means if you go all the way to infinity, this will just grow to infinity. These are the only assumptions that we will be working on. Alright, so briefly how we invest. There's no taxes yet. If you have a portfolio, this is fractions of investment, so the relative returns are just written as pi dr. And I'm just expanding them with respect to the finite variation in the marking nu. But remember, the finite variation can be written in terms of DC nu, so this is what the This is what appears here. We start from unit capital because otherwise we can just multiply with the initial capital and everything scales. So you can solve this in terms of log, okay? And when you solve it, you get that it has a drift, which is what we call growth. And the martingale part from here, the growth will be just the drift that you have from here minus a half of the quadratic variation from the persort. Okay, so this is exactly what appears here. It's the drift minus a half. It's the drift minus a half of the quadratic variation. So if you want, you can just try and maximize this point-wise in pi, because this is quadratic in pi. And if you do this, if you differentiate here, you will see that the solution of this maximization is exactly equal to nu, because this is just a quadratic. So this is what we call growth optimal because it maximizes point-wise the growth. So this mu is. This new is argmax of when you take any portfolio, say pointwise. And if you look at what the drift is of the log worth process here, it's this minus a half of the same thing. So it's exactly this G. The drift is exactly this market clock, and the volatility that this thing has, okay, uh is equal to twice G. So this G as a clock uh is controlling both the drift and the volatility of this this process. Volatility of this process. Okay, now up to now there was no taxation. So I'm just going to introduce capital against taxes now in the processes. And this is how it is done. Again, I want to point out that this is a theoretical taxation, but it makes a lot of sense, and I'm hoping that you will agree. So, this will be taxation on capital gains. Be taxation on capital gains. Every time that you exceed the past maximum, you will have to pay part of the gains that you have as tax. That is what is happening. So every time you go to your previous maximum, part of the gains is going to be paid as tax, a fraction of them in your portfolio. So X star here is the running maximum of what you have. CX as a wealth process that you have. This is just heuristics here to see what we are going for. So X star is the past maximum. Is the past maximum? If wealth increases, when you have gains dig C over the maximum, your wealth will increase only with a fraction of this, because the rest you will pay it as tax. So alpha Dixie will be tax, so your wealth will increase by 1 minus alpha Dixie. So what is the tax that you're paying? It's going to be alpha times Dixie, and you can write it as a function of your actual maximum, because that is the extant. Because there is dx star here equal to 1 minus alpha dc. So you can write as beta dx star. So beta times the change in your maximum or this beta is just alpha divided by 1 minus alpha. And I will be carrying this beta instead of the fraction alpha because it makes for better parameterization. So this is a way to write how much is the tax that you're paying in terms of your maximum of your wealth. Every time that we reach a maximum, you have to pay a beta time. We reach a maximum, you have to pay beta times the x star for tax. Which basically means now that we can write down a differential equation for our wealth process. The change in our wealth will be the wealth that we have times pi dr. This was exactly what we had before, if you're using portfolio pi. But now you have to be paying the tax every time that you reach the maximum. So you just pay minus beta times the x star every time that you reach the maximum. All right? So this is this the same thing as paying high watermark fees to the farmer? Lemma. Plasonia 2016. High watermark fees. So this is exactly the same thing. Yes, it's exactly the same thing. Alright? So here is a very nice representation of the solution of this thing given by Paolo and Jan. So this thing can be solved actually, this thing that I wrote down, even though it has the What I wrote down, even though it has the maximum inside, yeah. So here is the SD, okay, and with pi portfolio, beta the level of taxation that you have, you have this SD, so you can solve it in terms of the non-taxed version. So if I call X pi to be the non-taxed version, that we know exactly how to solve that explicitly, then the worth tax is the non-taxed value divided by the maximum of the tax. By the maximum of the taxed, the non-taxed process raised to some power. So, this is an explicit solution for what this is. It's quite amazing. It's also very easy once you know what it is, it's a connormal set, to just figure out that this is the solution, because then you can just use it's formula to verify that this is the solution. Not only that, we have also a representation for what the maximum of this thing is. It's basically putting maximum up here. Is it's basically putting maximum up here. So if you do the calculations, you will see that this is exactly what it is. So we know what the running maximum of the tax process is with respect to the running maximum of the non-taxed. So you have closed form expressions and this is very good for the calculations later. Any questions up to now? Because I want to introduce the problem now. So here is the problem that we're trying to do. So here is the problem that we're trying to solve. So as I mentioned, if you don't have a fixed liquidation date, you can choose it. So now you have two things that you can choose. You can choose a portfolio, you can choose liquidation date. So the maximum is over portfolio SPY and liquidation dates. Now, the liquidation date that you will choose, you will put a constraint in it. You don't want to wait forever. So you want the constraint to be that. So you want the constraint to be that the expected market time, market opportunity time is going to be less or equal than some level gamma. So this will be your constraint. Otherwise you can make as much money as you want. Now what is your functional that you want to maximize here? This is a utility on loss. So this is a low invariant utility. The typical thing that you would use when you use expected utility, for example. Use expected utility, for example. It only depends on the law of the process. So here I'm writing in general as a function on the law, L here law, as in the case of meter, of the terminal of the liquidation value. And I'm writing it in log format because it's just easier for the calculation. So here you can go from log to whatever you want, non-log, it doesn't matter. Because I'm not putting any restrictions on the shape of this utility function here. On the shape of this utility function here. So you can just go from one to the other. There's no convexity, nothing comparable to anything here. Alright, so this is your problem. So u is a function of all probability loss. And I'm only going to consider probability loss on 0, infinity. This means, so the log of x here has to be positive, which means x, remember you started from 1, this means x has to be greater than the initial value that you have. I only want to make money. Have. I only want to make money. I don't want to use anything. At the terminal time, intermediate, of course, you will go down. But you only care about making money here. Now, if you have a fixed time, you cannot usually find such a thing, but if you can choose the time that you will liquidate, even with these constraints, you can do it. You can make sure that you stop somewhere, that you will always have more money than before. Alright, so is this okay for the formulation? So we deviate by not considering fixed date, but expected time constraints for the date. And the problem is to find both the portfolio and the end stopping time that we have here, the blue mass challenges. So I want to do a little bit of analysis that will show you how we should. Show you how we should think about solving this display. Yes. That's kind of a behavioral assumption, right? Is that known assumption, or is it like a bias or that I'm related to other biases, like with red alerts or something like that? So when you say behavioral assumption, you mean that I just choose this constraint? Yes, with that clock, right? That has a flavor of. Yeah, that clock, I cannot really. It's certainly, there is no axiomatic way of saying it. Axiomatic way of saying it. What I mean here is that if you're interested in market opportunities, it makes more sense to use this than calendar dynamic. Because if you take two different markets and one has a lot more opportunities, then clock should be running module. So it is closer to this behavioral thing than actual market from that point. But I want somehow an invariant of the market here in order to solve this problem, as you will see in close call. That's why this is coming. Alright, so let me give a little bit of um uh of analysis so that you can see how should we solve this problem. So remember we need to choose a portfolio and a stopping time. So take any portfolio and any stopping time such that you know that your log, if you just stop here, is strictly positive. Any. And let's call mu to be the law of this log. mu to be the law of this log that you have. So if I integrate x mu, it just gives me expected log. Because this is the law of the law that you have there. Now remember this is the taxed process but we have a closed form expression for the taxed wealth in terms of the non-taxed. So in terms of the non-taxed you can write it as x pi minus well it was divided here by the maximum of the non-taxed. The maximum of the non-text at some power, which was exactly this one there. And now I'm going to make a very simple bound. So instead of x bar, I will put x here. But I have it with a minus, so it makes this bigger. Now, this is log of x pi. Remember, this u maximizes point y is the drift of this thing. I didn't get it. What would we call it x times? What would we call it? X star, just right, X star, greater than X, right? X star is greater or equal than X, but it is a minus sign. And this is why it becomes. So X pi here, if I substitute X nu, I get bigger. And I know that the drift of log of X nu is exactly G, what I have here. So I have this string of inequalities, but I have al already some constraints on this thing. This has to be less or equal than gamma. This thing. This has to be less or equal than gamma. So I know a priori that this thing has to be less or equal than gamma divided by 1 plus beta. So this gives me a constraint on the loss that I can aim for. Now, can I close all these inequalities also is the question. Now, the first inequality will be equality if x star is equal to x. So you stop at the time of maximum of your process. The second inequality would be equality if pi is equal to nu. So if you invest according to the growth optimal. So I need to do two things: invest across to the growth optimal, stop at the maximum of the growth optimum, and make sure that I achieve a law that is very good, yeah, with this constraint that this has to be less or equal than gamma divided by 1 plus P2. So basically, you just split the problem into two parts. There is one static problem. Into two parts. There is one static problem, as I will write, and one dynamic for your choice. So, what is the first step? Completely market-independent. This has nothing to do with the market. You see here what I did, I bounded all of these integrals by gamma divided by 1 plus beta. So I maximize over all probability distributions, C, such that the integrals are less than 0. That the integrals are less or equal than gamma divided by 1 plus beta. So you solve this problem. I'm not going to bother with this because this is just a static problem that you just solve independently of the market. You pick what is the optimum there. You put some assumptions, upper semi-continuity in the weak star topology and so forth. This is a compact set so that you can get your solution if you want. So pick a solution from this. And now the question is, how do you? Now, the question is: How do you realize this solution? So, take any solution from this step. Now, we have to find the stopping time such that two things have to happen: at the time that I stop, I am at the maximum, and that at that time, I have exactly this distribution that I need to do. So, this is the problem that I want to focus on, and this is embedding that you have here. But it's embedding not of a usual type because Of a usual type because the process that you have to embed the law is not a local marking yield. It's not a Bronien motion, it also has a singular part. So you have to basically figure out how to realize this time clause. So it is essentially also this property. So given, of course, that you can solve this. Given of course that you can solve this, the solution to the second always exists. For example, if you are if you allow extra randomization, you can always do this. So what do I mean by this? You want to target this new, you throw a random number generator that gives you something independent of the market that has distribution new, and you start running this process until it hits that random number. This will be a time of maximum, it will realize this way. Will realize this moment. Now, these solutions, apart from the fact that they have to use extra randomization, they're typically not optimal in what you want to do. Of course, we have not decided what we mean by optimality, but I'm writing down here, make sure that this tau that you find, because this is not a unique way of picking it, but it will be somehow optimally realized in you. And I will explain what I mean by optimal later on. But I can tell you already what the situation is. Already, what the situation is. You are solving here a problem where you just want to liquidate at some time in the future, okay, but for external reasons, you might be forced to liquidate earlier. And if you have to liquidate earlier, you have to make sure that the losses, the possible losses you may incur, they're not going to be very, very much. So what I will be worried about is not only to realize this, but also to make sure that the losses that I might have Make sure that the losses that I might have are not that, but if I have to liquidate earlier, that is the idea. Because the solution to this thing is not unique in general. So I will show you a solution that has this optimality property of making sure that the losses that you have are minimal. So I'm not going to, in the interest of time, I'm not going to go through the analysis. If there is time in the end, I can Is time in the end, I can do it. But when you have to solve embedding problems, there are different ways of going about it. There is potential theory with type of processes, and there is excursion theoretic arguments. There are also Martin-Yield arguments. So we like Martin-Yills, at least I like Martin-Yills a lot. I can understand them much better. So the key is to somehow find is to somehow find a rich enough collection of martingales that will allow you to solve the problem in every case. And, well, so this is the key lemma that allows everything to work. And again, from some point of view, this is again like Poland Buset. Because if you see it, okay, so let me read what it says. This is the process that we want to stop, the log, let's call it L, the maximum. Let's call it L. The maximum is L star. You want to stop when L is equal to L star. I is the losses that you have on the way. This is minus the minimum that you have in the log scale. So this is the total losses that you have, then the maximum losses that you had out of that point. And there is a collection of martingales that actually connects these three processes. L, its maximum and its minimum. What you have here. And it is exactly this. And it is exactly this thing here. This is an indicator that your losses are less or equal than a level Y. So Y appears here in L star, I appears here in L, and you can show that this thing here is a marking name. Now let me remind you, this thing also has this taxation, so it has the singular part. This is what makes this thing appear here as well. Again, if you see this, if you try to do it with it's formula as three lines, you just stop it at the first time that you will hit Y, you use it's formula as. That you will hit y. You use it as formula here, and you stop it at the first time that the minimum will hit y, and then you can see that this is a mark. But this took me a month to figure out that this is the right collection of marking yellow to use for the problem, basically here. Anyway, I just wanted to mention that this is the thing here. So let me show you what the result is. This is this part that forces you to take continuous processes, one of the parts. One of the parts. Yeah. I mean, you said that the problem is that you do not want to overshoot, you don't want to undershoot. There is a lot of stuff that's called. Okay. So let me show you the one solution and in what sense this is optimal. So as I said, from step one of the problem, you're getting a mu that you actually want to That you actually want to somehow realize with your process. So you have this distribution in zero infinity, and you will define some non-decreasing function that depends on mu. The definition is here. So with argument y that appears here, you're just trying to figure out what is the maximal z such that this integral here is less or equal than this side that we have here. Is less or equal than this side that we have here. You see, this stuff that appear here, they're very much related to this lemma that I showed you earlier, these exponentials that you had before. So you solve this equation for each y that you have here. You can show that this is an increase in function of y we have here. And then you define this topic time, which is you wait until the first time your low wealth hits a moving Hits a moving boundary. Now, the moving boundary is you take your losses, your maximal losses up to date, and you apply the function f. Now, the maximal losses is increasing, f is increasing, so this is an increase in stochastic barrier, and you're waiting for the first time that you will hit this increase in stochastic barrier. So, in particular, you will be at a time of maximum when this happens. But F mu here is selected in FÎ½ here is selected in such a way so that at this time, L, of course, is equal to L star, because as I said, this is an increase in stochastic boundary, but it actually has the correct distribution that we want, which is here. So, this is work solution. Why is this good? If you take any other stopping time, any other stopping time that you know realizes this new. So that if you stop at that point, Yeah, so that if you stop at that point, your distribution will be new. Then, if you look at the maximum losses that this has up to the liquidation time, okay, this is I of tau is the maximum losses that you have up to the liquidation time with some stopping time that realizes nu. I tau nu is the same thing up to the liquidation time of what I claim to be optimal. So these losses here. So these losses here will be st stochastically smaller than anything else that you can do. So this stochastically down new stochastically minimizes the total losses that you can have up to the liquidation time over all other stopping times that you can have. So it has this optimality property. And again, this is very important because you might have to liquidate earlier. So you don't want to have a lot of losses if you happen to liquidate earlier. That is the whole point. That is the the whole purpose of this statement. Alright, okay. So, um well since I have a little bit of time, let me explain to you how you come up with the idea of using this specific F that I had there. So, let me explain here. So, you want to target some distribution mu here. And you make an answer for a candidate of stopping. So you wanted to stop at the first time that L is equal to some function of i t. This is reasonable because you want to control the losses. So this is why you want to write it like this. And you know that f has to be increasing. But how do you calculate what f is? Is the question here? How do you come up with the formula for f? So again, if f is is increasing, then L will be equal to L star at top. L will be equal to L star at tau, which is great because you want to stop at the time of maximum. Now, what about F? Now, remember the lemma that we had, which actually gives us, let me go back a little bit, it gives us this collection of martingales here. For any y, this is this thing here as a martingale. Now, at the stopping time that we're interested, L star is equal to L. So you can combine these two terms with L that you have. That you have all right, all right. So, this is what you do: you combine these two terms into this one here. So, this is a marking gale, this is the initial value, and that is what you get here. So, from optional sampling, this is a bounded marking, so this is what you get. Now, you are being a little bit bold, and you're saying, imagine that f is strictly increasing and continuous. So, if i is less or equal to y and I apply f from both sides, And I apply f from both sides, then f of i has to be less or equal than f of y and vice versa. Again, here, this is not entirely true always, but if you have strictly increasing and continuous function f, then this is okay. So this holds if and only if this holds. But now this part here only depends on L tau. This is the only randomness. And you want this to have a distribution of mu. So you write down the integral of what this has to be. integral of what this has to be. And then you have this equality, and you want to solve for f of y. And that's how you define f of y here. Now your f might not be one-to-one and so forth, so you will have to work a lot more with making sure that you can accommodate for jumps that the CDF might have and so forth. But that is the idea. Okay, so that is how you come up with the optimal one. Of course, then you have to make sure that this is also Sure, that this is also make sure that this has minimal losses on the way. And for this, you have to use some kind of variant of Neyman-Wilson lemma to be able to prove it. But I'm not going to go through this. I'm happy to stop here if you have any questions. So, what I wanted to say is, I will go back to the thank you note: what I wanted to say is that this approach is Is it has the pros that actually gives you closed form expressions and it's very simple to use. It just completely splits the problem. So you solve a problem that has nothing to do with the market. You get the target distribution and then you go to the market and you know that you have to use the fastest way of growing and you can choose what the stopping time is so that you can actually realize the distribution that Actually, realize the distribution that you want. So, from that point of view, it's very simple to implement. The drawbacks is that you must allow yourself this flexibility of not having to liquidate at a specific time. So, if you don't have any hard constraints on when you should have to liquidate, but you are willing to wait a little bit, but not do it at ridiculously long times, then this would be something that Then this would be something that we might want to consider. That's all. Thank you very much. So we have time for questions. So at the beginning you didn't take when you take A and you take C, you can just parameter when process, why you make that C minus one and a half, you make Minus one half, you make things much a bit complicated than it's supposed to be. Just like the characteristic, you know. So, A and C should give you one process that controls both of them, and then that's it. Then your G becomes like lambda C lambda transpose C lambda D all processes. Right, so I find it easier to present it this way. Yeah, which is the reason that's Yeah, what is the reason? That's why uh because this one looks like a bit more not like an easy computer just how how people are used to to write things I think this this this kind of thing. I just I like it better this way, so I think that's that's the honest answer to this. Can you change the constraint you're putting on the time? Like, I don't put the expectation. No, no, no, I don't, I don't. But what you can do is, I mean, the the easiest way that that you can do this is that so you have a you have a functional that is on the that is here. That is here, right? So you can just take a concave representation in terms of, you know, a dual concave representation for this and try to solve it like this. I mean, this would be the easiest way to do it. But I don't have anything in mind because this part does not have anything to do with stochastics, right? I mean, this is just an analytical problem. And I don't have any specific use that. Of course, you can put specific examples to. Uh specific examples to to do it. Um I I I'm to be honest, I'm more interested in the in the heating problem, but uh yeah, you're right. I mean some examples should be should be there. But it doesn't have anything to do with the market or the other thing. So something would be total tax collection by the government as a function of the parameters. So for example it's like a gamma or something that the regulator could control and you tell them that you need Uh can you tell them like you know you want to make it bigger or smaller so that you increase the taxes? So what this I mean the solution because you're stopping at the maximum what it also doesn't just minimize but gamma cannot be put by a regulator. I'm not entirely sure that this is because this is a concern of the investor, right? So I'm not entirely sure whether you can do that. What I can tell you that you can do is that you can play with the taxation. Okay, so this is something that I did not mention. Maybe this is something that I'm... Okay. So here I'm taking this to be constant, this alpha, but you can take it to be a function of x star, which is progressive. Which is progressive taxation. The analysis will carry through, some of the formulas become quite more complicated. You still have closed-home expressions and so forth, right? But what you can do is that you can look at the progressive taxation that you have and see the effect that it has on the optimal maximization problem. And from there, you can think of how to set progressive taxation in terms of how people will behave. That is the way that I can see it, because I'm not the time. I I I can see because I'm not entirely sure how you can force a cell regulator gamma to be very small if you're just an investor that wants to invest and has their their own environment constraints. Is it clear that the optimal tau is finite, almost surely? Yes. The reason is not clear, but you have this constraint here, right? And g at infinity is equal to infinity by assumption. So if it was not finite, almost sure. So, if it was not finite almost surely, this expectation would be infinite. I'm assuming that g at infinity is equal to infinity. Okay, and the problem is set for tau's which are finite from the beginning, almost truly finite? Yeah, well you have this constraint too. So, set for tau's which are almost truly finite. Yeah, you should write it here that this only makes sense when this tau is otherwise, yeah, when this tau is finite, because it comes as a consequence of the constraint. A consequence of the constraint. But you are right that it should also be put here somehow. I can only define this one talent finitely. All right, without no more questions, let us request that again. So, our next speaker is Jacob Rodriguez from ETH and is going to tell us about ESDs and reflective PSDs. Thank you, Devon. Thanks also to the organizers and for the opportunity to give my first talk here in Pears. It's also the first time I've been in Canada and it's, yeah, I'm just amazed by this place, it's super nice here. And as the title suggests, I want to show you two well-post-net results, one related Well, both net results, one related to BSDs and the other one related to reflected BSDs, where both of them are driven by Martin Hills that can jump. Of course, ESCs have been used as tools in pricing problems in finance, in general successive control problems, in optimal stopping problems, and also recently in principal agent problems with Carla Hesn. Problems with Corbola has it. But I would say the main motivation to study the BSTs in the generality that I will present is that we want to eventually tackle stochastic control problems where we control the the triplet of a semi-marketing of X. So the drift, the volatility.