Last speaker for today is Al Garber, who will talk about promotion by representations of quivers. Yeah, thank you, Jim. It's good to be here in Banff. Nathan, Jim, Jessica, Tom, thank you for putting on this conference and thanks for giving me the chance to be here. First time. So, what I want to talk to you about is promotion. So, I'm people, so I want to talk about this piece. People, so I want to talk about this piecewise linear promotion in this talk that Jessica mentioned. That'll be my emphasis. And also, the emphasis will be sort of on the algebraic part of guest dynamical algebraic combinatorics. So, I want to say a little bit about representations of quivers. This is joint work with Becky Petrius and Hugh Thomas. Saw Hugh, I think Becky might be teaching right now. I think Becky might be teaching right now. Yeah, so let's get started. So, the posets I'm interested in are called minuscule post-ets, and I know Jessica said this word at least once. And these come up in Lee Theory. I'll just say to get a minuscule postet, you want to start with a simply laced tinken diagram and a minuscule vertex of that simply laced. Vertex of that simply lace thinking diagram. And then from that data, you get a postet, and you can talk about piecewise linear promotion on that. So in type A, every vertex will be minuscule. So the minuscule vertices of these diagrams will be the ones that are in red. Type A, every vertex is minuscule. In type D, the degree one vertices are minuscule. And then in And then in type E6 and E7, some of the degree one vertices are minuscule. No minuscule vertices of E8. That's why it's not here. Okay. That's the initial data. So in type A, the minuscule postets you get are products of two chains, which have already been discussed quite a bit. And the length of those two chains depends on which. Two chains depends on which minuscule vertex you pick. So, this one here would be an A4 example. You choose not an end vertex to be your minuscule vertex. In type D, there's two infinite families. There's this one, which is a diamond consisting of just four elements, and then two equal length chains extending from the top and bottom. That diamond, the length of those chains depends on. On what n is. So you have dn, depending on what n is, that determines the length of these equal length chains. And this family corresponds to picking the far away degree one vertex for your meniscal vertex. And if you pick one of the other meniscal vertices in DN, you get these triangular postsets. Okay. And And so let's see. Something is dinging on my computer. So what I want to look at is reverse plane partitions on these postets. So a reverse plane partition is an order reversing map on a postet going to the non-negative integers, and usually there will be some large. And usually, there will be some largest possible value, called capital N. So here's an example of a minuscule poset or of a reverse plane partition up here. The numbers are where the elements of the poset go under this map row, and the numbers go down as you go up in the poset. Reverse plane partitions. And all right. And so on the page right now, going up in the post-et means going up in the page, but that will change for the rest of the talk. From now on, going up in the post-it will mean going right, turning your head to the right on the screen while looking at the screen. So let's do that. Jessica already mentioned piecewise linear toggling. So we all know it, but I'll just say it again. Why not? So what I want to do is I want to start with. To do is, I want to start with a reverse plane partition like this one, and I want to pick an element. Let's pick this five that's in the box. And to toggle this reverse plane partition at that element, I'm going to say, I mean, this formula here, okay, you can think of this formula as you say, five has to be. You say five has to be in between five, has to be at least five, and it can be at most capital N, where capital N is some largest entry of a reverse plane partition that we're considering. And then between those extreme possible values, you reflect five within that interval. That's what this piecewise linear formula is saying. So when we toggle at this five, it becomes a three. It becomes a three, or sorry, it becomes an n. So it goes from one end of this interval in which it can vary to the other end of it. And then we want to toggle at three. Here's another example. Well, this has to be at least one, and it can be at most four. So it's one less than four, so now it's going to be. Than four, so now it's going to be one more than one. That's what toggling is going to do here. Toggling. So promotion is made out of a bunch of toggles. Let's just see what I mean. Okay, so here's the same reverse plane partition that was on the previous slide. This one here, I mean. So promotion on this. On this will be a sequence of toggles where I toggle, I'll say rows of this postet, but I should maybe be saying columns of this postet for whatever reason. So what I want to do is I first toggle everything that's in this blue row. That's what this blue T3 means. Somehow, this is the third row. And then after that, I want to toggle everything in the I want to toggle everything in the fourth row. That's what T4 means. And then after that, I want to toggle everything in the orange row. That's the second row, apparently. And then lastly, I want to toggle everything in the red row, the first row. And so, what's happening? I mean, when I, as I do this, so. This, so let's see. Going from here to here, performing all these operations, that's one iteration of promotion. And as I start doing all these toggles, I start introducing all these symbols into the reverse plane partitions that are n minus something. Okay, and so we get to this to this one here, the first. One here, the first result of the first application of promotion, and then there's a bunch of n minus ones, and then we get over here applying promotion again, even more n minus ones, and then we do it again, and some of these n minus ones start to go away, so on and so forth. We get back to where we started. And I mean, so stuff has already been mentioned, but this isn't a pathological example. Example, this promotion operator always has a finite order. And I guess I'll state this theorem here. Promotion on reverse plane partitions in the product of two chains has order A plus B. So this was proved by Dari Greenberg and Tom Roby. And then a new proof appeared later, Greg Musicker and Tom Roby. Dari and Tom, they also. Dari and Tom, they also, my understanding, my recollection is they prove this in other cases, case by case, but not E7. Anyway, that's my understanding. But so they prove this for this piecewise linear promotion by proving by proving By proving a periodicity statement for a birational version of promotion and then tropicalizing to get this piecewise linear result. So what we do is we have a uniform proof in all these stinking types that have a minuscule vertex, but it uses some representation theory. Okay, so what's going on? So this example that we So, this example that we saw so far was this reverse plane partition. I'm just going to keep using this. This is really an A4 example. And really, I'm going to be thinking of it as coming from not only A4, but this orientation of A4 that I'll say is a quiver, in other words, a directed graph. In my mind, those are synonyms, but I'll say the word quiver. Quiver. And so what we show is if you have a reverse plane partition on one of these minuscule postets, you can turn it. Okay, so there's a question from Tom. I mean, so Tom was asking, why is it in that order? Well, somehow this order comes from the orientation of this quiver. That's an important part of what order to toggle in. Like what order to toggle in. So I don't know, maybe I can say more about that later. Oliver is adding more. Isn't it left or right? If you just turn your head correctly, I mean, in my mind, it's yeah, it's left or right. Okay, well, anyway, so if you have a reverse plane partition, it can be turned into. Partition, it can be turned into a representation of the quiver associated with the reverse plane partition. And so there that is, it is a diagram of vector spaces assigned to each vertex of the quiver, and then linear maps, these things, assigned to each arrow that go between the corresponding vector spaces. So, um, Okay, that's equiver representation. Rather than having a dimension, this has a dimension vector. It's another bit of notation. The dimension vector is just what you get by reading the dimensions at each vertex. So in this one, you get 3, 5, 8, 5. Also, I haven't. Oh, yeah, this is K is a field. K is some, I guess, algebraically closed field. I guess algebraically closed field. Yeah, so it's okay as a field. All right, so a lot of questions. No, the field does not have to be characteristic zero. Emily, maybe I can answer your question later. I'm not. Yeah, in general, if you could text me questions rather than the speaker, then I'll choose which ones should be saved for later. Okay. All right. So I'm going to slightly repeat myself. The point of this theorem is saying: start with the Dinkin quiver, start with the minuscule vertex of that Dinkin quiver, and then look at all representations of that quiver. Representations of that quiver that have the property that when you decompose them into decomposable representations, every indecomposable is supported at your minuscule vertex. So that sort of assumes some baseline knowledge of quiver representations, but there are other ways to decompose them. And that decomposition is unique. And so you just make sure every indecompose will sum into support at your minuscule vertex. When you do that, you choose any reverse plane partition. choose any reverse plane partition it it's uniquely identified with such a representation of this quiver um and so i i should say a lot more but uh somehow this map is given by if you have such a representation you look at a generic nilpotent endomorphism of this quiver and that is a sequence of linear transformations one at each Of linear transformations, one at each vertex, going from the vector space at that vertex to itself. And then you look at the Jordan form of that, and you get a sequence of Jordan blocks at each vertex. And somehow you can stuff all those numbers indicating the number of Jordan blocks, the sizes of Jordan blocks into your postet. And they all fit together and it makes a reverse plane partition. And it's And it's, I mean, it's miraculous in my estimation. So, but what I want to get to promotion, and I don't know if it's even possible. So, let's try. So, what's going to happen is there's another quiver that comes from a quiver. It's called the Auslanderiten quiver. And so, it is a quiver whose vertices, so these are the vertices. Whose vertices, so these are the vertices, the vertices are isomorphism classes of indecomposable representations of the quiver you started with. So in type A, these will be sequences of length three and of some zeros and then a contiguous sequence of ones and then possibly some more zeros. So, I mean, so that's what the dimension vectors of indicomposible representations in type A look like. In type A, look like. And then the arrows of the Elzender Rayton quiver, these are the solid arrows only. They are the so-called irreducible morphisms. And I won't define what those are, but that's them. And when you have an Alzheimer's-Rayton quiver, there's this map, this functor tau, called the Alzheimer-Rayton translation that it's homologically defined. I won't define it, but it moves. But it moves the indecomposables, sends indecomposables to indecomposables approximately. Some of them it sends to zero. These ones that are all the way here on the left. But this is what the L Center writing quiver looks like if you have the quiver three goes to two goes to one. Okay. And but this isn't, there's slightly more that we have to say. So there's a So, there's a bigger Alzheimer-Reiten quiver that this one from the previous page sits in. It is the Alzenderite and quiver of a category called the root category. So I kind of just have to make this a black box, but so the objects of this root category are indicposable representations, and then I'll just say there are things that look like this: it's indicomposable representations. Like this, it's indecomposable representations with this bracket one next to them. This bracket one. If this is a shift in a certain derived category, the derived category representations of Q, but whatever, we can just think of it as a formal object for now. For every indices representation of Q, there's another object in this category that's that same dimension vector, that same representation, just with this bracket one next to it. Just with this bracket one next to it. And what happens is, you look at this picture, and I have this triangle here, and then over here I have this triangle that's inverted, and they're sort of like glued together. Well, not glued together. They're sort of connected by all these arrows. And now tau acts cyclically on this thing. So you think about it, this is really a cylinder, and tau is just sort of rotating around the cylinder. Rotating around the cylinder. What is the point? So we said the promotion is supposed to be some kind of cyclic action, supposed to be a periodic action. So what we're going to show is that Tahoe is really promotion. And so the periodicity of promotion will be a consequence of periodicity tau. Okay, so what's happening? So I'll read. What's happening? So I'll restate what I said. If you have a Dinkin quiver, you can construct this root category whose objects are dimension vectors and dimension vectors shifted by one. And if you apply tau to something in here, h times where h is the coxeter number of the associated root system or the associated Coxeter group, then you've gone from yourself. You've gone from yourself back to yourself, and this is like the minimal power of tau that will do this for every object. Coxstar number is the order of a Coxer element. In type A, that just, one way to say that is just, it's the number of vertices of Q plus one. So So hopefully the tau and so hopefully tau and promotion are like compatible in some way. So we're almost done. So we have this reverse plane partition that we had before here. And actually the representation that goes with that, I'm going to say it looks like this. And these exponents are these superscripts on these dimension vectors are supposed to be a multiplicity. On these dimension vectors, are supposed to be multiplicities. So, this is a module, this thing here. So, these are the representations that are all supported at vertex 3. Okay, here's something that's missing. So, this example is 4 goes to 3, and then 2 goes to 3, and 1 goes to 2. And I'm choosing 3 to be the minuscule vertex. So, I should have that the corresponding representation. That the corresponding representation has all its sum ends supported in vertex 3. So whereas I can toggle the reverse plane partition, the corresponding thing to do is to apply this so-called reflection functor to the representation. And so I toggle the blue entries on the upper level. Trees on the upper level. And down here, I'm going to apply well, I apply the reflection functor to every representation, and it will change these representations in some way. I'm applying it to everyone. And in this example, I mean, without really defining this reflection functor, in type A, you can say this is supposed to be the reflection functor that goes with vertex 3. That's what this little three means. And so you look at the dimension vector and you. At the dimension vector, and you say, I want to apply the reflection functor here. There's a one in vertex three. If I can turn that into a zero and still get a valid dimension vector of an indecomposable representation, then I do that. Otherwise, I don't do anything. And that's one way to calculate the effect on dimension vectors in type A anyway. And there's a caveat if I apply this. And there's a caveat if I apply this reflection functor here to the representation that has only a 1 at vertex 3, then I introduce this shift symbol next to it. Anyway, so as I apply these reflection functors, I introduce more representations that have this shift thing, and the things that have The things that have the shift thing correspond to entries in the reverse plane partition that have a capital N. The corresponding entry in the reverse plane partition is capital N minus something. And that's that turns out to be what always happens for various reasons. But okay. So what happens that, yeah, if I Yeah. If I start with a representation and then apply rho to it, which is the thing that extracts the reverse plane partition, and then I toggle, that is the same as performing a reflection functor at vertex i, and then extracting the corresponding reverse plane partition. And then we make use of this theorem. It's quite. You know, it's uh, it's quite general, actually. Um, uh, it goes back to Gabrielle in 1980, and it's saying that if you have one of these objects of our root category, but this theorem holds more generally, and you apply tau to it, you can calculate tau by doing all these reflection functors in a suitable order. So, for us, that's this left to right order, um, and then we combine. And then we combine this theorem and this lemma. And what happens? Well, we say start with x, apply tau. That's the same as apply tau and then extract the reverse plane partition. That's the same as doing all the reflection functors and then applying and then extracting the reverse plane partition. But from our theorem, you just change all these two toggles. Extract the first thing partition then changes all the toggles, but that's the same as promotion. And so we use, therefore, this periodicity of tau to get this periodicity of promotion. So that'll seem pretty fast, but that's what I want to say. So hope to have some more interesting discussions during the session later. But yeah, that's it. Later, but yeah, that's it. Thanks a lot. Great. Well, let's thank Alex. We had a question from Emily Gunawan. She wants to know why do the left and right pictures of the root category look like? What do the on slide nine? On slide nine? Let me see. Um Right, so what do they look like? I'm not sure I understand. Oh, I meant the other parts that were like dot dot dot. Oh, I mean, this is, I mean, so if I were to continue this picture, I would get exactly this here. I would just be continuing. I'm like already wrapping around. This example is small enough that if I were to continue this picture, I draw an arrow from here, and then I'm already back here to this one or to this one. So it's basically the whole picture. So you just have two copies. There's just two copies. I mean, in general, that's what happens. Like you, because the objects are of the form. The objects are of the form an indecomposable or an indecomposable shifted by one, and that's it. I think there's just yeah and Sam and Hugh have some comments in the chat. Okay, let's take a look. Um Sam is right, it is a quotient of the bounded derived category. I guess I didn't really. I didn't really say that, but yes. Yeah. Are there any other questions or comments for Alex? I have a question. So in my talk, I talked about this bijection between these rectangular reverse plane partitions back to semi-standard tableau of rectangular shape. And I was just wondering if your representation I'm wondering if your representation theory here plays nicely at all with cash-downlistic theory or the algebra that Rhodes used to prove the cyclic setting. I mean, yeah, I'm not sure. I mean, I'm going to say, yeah, I don't know. Yeah, I don't know. I'm not sure. Hugh says not that he's aware of either. It's just kind of, I don't know, I guess kind of just different representation theory. Any other questions? Let's thank Alex again. Thank you. And do stick around for the breakout rooms. I don't know if Linda's still here, but you can choose your breakout room and if you have trouble. But you can choose your breakout room and if you have trouble.