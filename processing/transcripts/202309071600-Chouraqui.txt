First of all, I would like to thank the organizers for the invitation to give this talk. And it's my first time in Mexico, and I'm really happy to have the opportunity to be here. So, in this talk, I want to present a conjecture that is very much not known, we can say. It is called the Ertog-Shannheim conjecture from the 70s around, and in fact, it is very. Around and in fact, it is very easy to state. So, I will state it already. Okay, so in fact, if we have, I will draw it more than state it. Okay, if you have a group G and G is the Design union of several cosets of subgroups, okay, so we have H1 alpha one, H2, alpha two, and so on. And here you have HS alpha S, and we have this subgroup. S and we have these subgroups are of finite index, and we have the following. Okay, we decide to order the subgroups in the following order. The D are the indices. Okay, so the Herzog Schoenheim conjecture says that necessarily DS appears at least twice. Or in fact, not necessar, I mean, not necessarily the largest index. Not necessarily the largest index, but one of the indices necessarily appears at least twice, and it seems to be the largest in general, if it is true. Okay, so this is the Herschel-Schoenheim conjecture, very easy to state. Now, the common approach to this conjecture is to prove it for finite groups. And Juval Guinosa from the University of Haifa, he introduced me to this conjecture, and we tried some time to try to solve it for finite groups. Try to solve it for finite groups, but I'm not a finite group theorist, so very soon I get bored about it. And then once I met Luis Paris from the University of Dijon, and we talked about it, and he suggested me, why not working on free groups? Because if it is true on free groups, then it will be true for all the groups. So, and he suggested to me to try covering spaces, higher drust, and so on. So, after that, And so on. So, after that, I can say that I was not bored anymore, and I really tried to solve it. Now, the aim of my talk is to present, is not so much to advertise my own results because I'm not so satisfied for myself, but it's more to present the approach and two sub-approaches that gave some partial results. And mostly, I hope that people will have suggestions, ideas, maybe. Suggestions, ideas, maybe it will lead to a break through. Okay, so let's begin. So, a cosette partition of G, I will give all the definition. So, you cannot accuse me that I won't give something. Okay, so we have G, a group, we have subgroups of G, H1 to HS, so finite indices. Okay, okay, so a coset partition is simply to say that G is the disjoint union of all the Union of all these cosettes. Okay, it is also called the covering of the group by Dijon cosets. So the cosette partition has multiplicity if one of the indices appears at least twice. Okay, there is a conjecture of Erdos from 90, from the 50, which says the following. It says that if we have that instead of G, we have Z, and we have here these joint cosets. And we have here disjoint cosets of subgroups of Z. So we have arithmetic progression. So if Z is the disjoint union of arithmetic progression of this kind, then the largest index, ds, appears at least twice. Very soon after he stated this conjecture Erdos, it was proved. It's not clear exactly who proved it. It seems two groups of persons, Rado and Davenport, independently. Independently, and Minsky and Neumann, I think, independently, something like that, but they did not publish it. And in fact, it was published in a paper of Erdos in Hungarian. And I will go back to the proof in a few minutes. You will see that it's a very easy proof, in fact. So it was proved. Yeah, those are the names. And there is also a recent proof by Yuval Guinosar, this one, using group representations. Also, a one-page proof, very nice. Which prove very nice. Okay, so these are the results that were proved furthermore: that not only that ds, the Larchette's index appears at least twice, but it appears at least p times, where p, the smallest prime, divided ga ds. Each index that does not divide another index appears also at least twice. And each index, sorry, I missed, each index divides another index. Index divides another index. So if it does not properly divide any other, it appears at least twice. So in fact, the Ersk-Schannheim conjecture is an extension of the Erdos conjecture for any G. Okay, so it says take any group. So is the question that Erdos posed for Z true also for any group. So this is the Erdos, this Erzog Schannheim conjecture. It is now all the proof that appear. All the proofs that appear are for finite groups and very algebraic proof. Okay, so the pedara-midal groups, this is a sublass of the finite solvable groups. This was proved in a series of papers by the three persons in the 80s. And it also known, it is a result of Leomar Golis and Offir Schnabel. That is, it's true for all groups of order less than this number. And also, if you take And also, if you take coset partitions and you have special conditions on the subgroups, normality, and things like that, then there are also some results. Okay, so now I will give a very fast crash course on covering spaces. I believe that most of the people know all this definition. So, I will go very fast on that. So, we have exotopological space, we have its covering space above, and we have a map which And we have a map, which is an open continuous surjection. And for each point at the bottom, we have a fiber above the pre-image. Okay, the fiber, each fiber has the same size. And okay, this is a multiplicity. Okay, there's our standard definition. So the standard example that appears in all the student books, this is the books this is the the the the infinite sheeted covering okay of z by of the cycle by r okay now some more data okay so if we have such a covering so we have an induced homomorphism from the fundamental group of the above onto the onto the group at the bottom and it is an ejection so it is a subgroups the group So, it is a subgroup. The group at the bottom acts transitively on each fiber. And the size of each fiber is exactly the index of this subgroup. And if we change the base point of the fundamental group, we obtain a conjugate subgroup. Okay, so let's see. In my talk, there will be a lot of examples. So, many times I will tell you to skip what is right. skip the what the what is right written but just to look at the example because i think it's more clear in this way okay so for example if we take we have the two the two rows the bouquet of two petals this one f2 and we have a covering above okay so we have here a three-sheeted covering space of x okay now we have that if we take the fundamental group with this base point Uh, with this base point, so we look at the subgroup generating generated by all the minimal loops based at this point. So, we have the following, ah, here it works. We have the following, I must, I'm not okay. Now I succeed. Okay, so we have the following subgroup of the free group, it is of index three, okay, because we have three. Three, okay, because we have three vertices. And if we change the base point, we take x1 instead of x0, so we look, we have a conjugate conjugate subgroup. And also, if we take, we change the base point, we have still another conjugate subgroup. Okay, so let's see more examples. So here again, we have this one, which is This one, which is a subgroup of index four. Okay, and again, we read all the loops, the minimal loops based at X0, and we got this subgroup. Okay, another example. So notice that they look very much the same, but if you notice, it may be small a little bit, but if you see here there is AB and here there is AA. And here there is AA. I'm not good at the pointing, but okay. So if you look at the left and the right, they almost look the same, but they are not the same. Okay, so in fact, combinatorially, you can obtain all the covering graphs when you run around all the possibilities to denote the ages. Okay, so what is important for us is the following. us is the following. If we have a subgroup of the three groups, then we can attach to him a covering space in the same way that we have done. Okay, this is the relation between the rank of the subgroup and the index, depending on the rank of the free group in which it lies. And we have that the covering is regular if in fact you see that the graph is very regular in some sense. Regular in some sense. So, here, for example, this vertex and this vertex locally don't look the same, but here, okay, they look exactly the same. So, this is, in fact, means that if the covering is regular, at any point you see exactly the same loops, so the same subgroup, because this is normal. Okay, now, okay, so this is this was a very fast introduction to covering spaces graphs. So, now given This graph. So now, given a subgroup of finite index, I look at its covering graph. And now I want to look at this graph as a Schreyer-Caused graph. Okay, that means that if, for example, I was interested in the subgroup with a base point X0, so now this is my subgroup K. Instead of X0, I have K. And I denote all the cosets according to the label, to the path relating them. Okay, so we can see that this graph as a graph, yes, it is a strongly connected oriented graph, which means that from every point to every point, you have an oriented pass, labeled pass, and at each vertex it is regular, it's in degree equal or degree two, the number of generators of the free group. Okay, so let's see some more examples. Okay, so now if I have this Schreier graph. Have this Schreier graph. Okay, this is a graph. I can assign to it a transition matrix. Okay, so in this transition matrix, I say, okay, from K to itself, I have no path or no edge. From K to K1, I have one edge. And then that's it. I have from K to K B the fourth one. Okay, this is the K, K1, A, K B, K B in the same order as the vertices. So in fact, it says from It says from vertex to vertex what is the number of ages, oriented ages that connect them. Okay, so this matrix is a non-negative irreducible matrix, irreducible matrix. It is because the graph is strongly connected. Okay, so now we arrive to the definition of the period of a matrix or a graph, if you can define by both ways. So if we look at the graph, So, if we look at the graph, in fact, this is the period H is the GCD of all the lengths of the loops based at any point because our graph is irreducible, is strongly connected. Okay, so at any point I can look at all the loops and I take the G C D of all the lenses. Okay, or the first definition using the matrix. So, for example, in this example, as For example, in this example, as we can easily see, the period of the matrix is 2, and we can see it also here in the powers of the transition matrix. Now, just to recall, when we have a transition matrix of this way, for example, if I'm looking here at this place, let's see 2, 3, for example, okay, this means that there are exactly two paths of lens, two connecting two, two, three. 2 to 3 on the on the on the oriented 2 to 3. Okay, and the same here. Here we have the number of paths connecting, for example, 3 to 2. Okay, there are four. Okay, this is another example. This example just wants to show that here the period is simply equal to the index. equal to the index, it is equal to four. Okay, so we have here in the following, in the next in the previous example, we have a matrix for four, of order four to of order four. And it's period wax two. Here we have a matrix of order four and its period E4. That means that we have no real way to guess the period. Okay, so now some elements of Are now some elements of the Perron Frobenus theory. So, if we have the Perron-Frebian theorem, it has two versions: one for positive matrices, that means only positive elements in the matrix, or non-negative irreducible matrices. Okay, so here in my case, the matrices are non-negative irreducible, so I will state only the part for this part of the theorem. So, if we have such a matrix, we have. So, if we have such a matrix, we have the period greater equal than one. So, in fact, the theorem states that there exists a simple eigenvalue, a simple and real eigenvalue, which is called the PF eigenvalue. Okay, and this is in fact the maximal one. Okay, so it gives also the radius of the spectral radius of the matrix. Now, if the period is greater than one, then we have Greater than one, then we have a set of simple eigenvalues of A given. Notice that here we have at the fraction, we have H in the denominator. And also the matrix has a right angle eigenvector and a left eigenvector whose components are all positive. And here we have two statements that are very important in our context. Okay, if the matrix is aperiodic. If the matrix is aperiodic, means period one, then we have that, in fact, we can say that the proportion, some proportions here goes to this limit goes to p. And if the period is one, then we have another range of proportions that goes to this matrix. Very soon it will sound more clearer. Okay, so there's some elements of the parent-Frebionist theory. The parent-Frebiolines theory. So we want now to apply them to a Schreier graph. Okay, so what about our case, which interests us? So we have a Schreier graph of subgroup H of index N. We have its Schreyer graph. Okay, the parent probium is eigenvalue is equal to N. It's easy to see because the sum of each rows and each column is exactly equal to n. The right and the left eigenvectors are Left eigenvectors are 1, 1, 1, 1. And if we want to normalize, we divide by 1, 1, 1, 2d. And here, so here, notice the red one, if the period is greater than 1, then we have a set of simple eigenvalues. So n is the peron-Freubenus eigenvalue. And here we have the H at the bottom. And the matrix P in our case, it will be equal to. case it will be equal to a matrix with all the entries equal to one to the D because of VR V L are this way. So it means that, notice the following, it means that if it is a periodic, we have in fact a kind of proportion of the proportion of paths of landscape divided by all the number of paths of landscape equal to one to the d and here. One to the D, and here it is only an average and not the proportion itself. Okay, so let's do some summing of what we have seen. We have a subgroup of finite index in Fn. Okay, we look at its covering space, we look at it at a Schreier graph, and we have with accompanied with it, we have a transition matrix, we have Have a transition matrix, we have a period, these are the data associated to it, and we have all these elements of the perimphrobionous theory that we know that there is n the perimphrobion eigenvalue and if the period is greater and so on. Now, we can look also at this graph as an automaton. Okay, so we begin with again with the covering and next, instead of looking at it as a simple, as just a graph, we can look at it in parallel as an automaton. It in parallel as an automaton. Now it now replaces one, the approach does not replace the other. We need to keep, I mean, open minds and to look at it in all the ways possible. So it looks the same. But now if you have an automaton, we can talk about the language accepted by this automaton. Okay, so now we have to be careful because I have not written it so precisely here. If we take this to be the star, This to be the start and the end state of our determinant automaton. Notice that it is what is called a b-deterministic complete automaton. I mean, the best possible, the simplest one, we can say, the most beautiful one, I can say. Okay, so if I take this as a star, and the end state, now I say that the language is equal to all the words in the subgroup G. Now we have to be careful. Now we have to be careful because when we talk about a Schreyer graph, implicit there are always the reverse arrows denoted when we have here A, we have also A minus one here. And we know that it is implicit and it appears in the Schreier graph or in the covering. But when we talk about an automaton, we need to be very careful because an automaton, what you see is what you get. So if you see A, you have only A. So if I want to get all the elements. All the elements in G, I need to take into account to add all also all the reverse arrows. But I won't do that because, in fact, I'm interested in the positive words, I mean words that don't have a minus at the power, that belong to this coset. Okay, so here it's not written the most precisely, but recall that we need to take into account that. And if we take this as the start and the end. Take this as a start and the end. So we have the conjugates a group of G. And if we change, sorry, if we change, if we take this as the start and this at the end, so in fact, it reads all the elements that belong to this cosette. Okay, and also, or either the positive ones or all depending on the arrows. Now, to such an automaton, we can associate a transit. We can associate a transition monoid usually, but in our case, when the automaton is with all these properties, it is a group, and it's also a group of the symmetry group. And in fact, we take A, we look at the, I mean, the permutation that A generates and B, and this is the group generated by the permutation phi A, phi B. Okay, so in this case, it is equal to S3. So we have all that. So we have all these ways to look at our Schreier graph. Okay, so let's see some examples. Okay, so we have the Schreier automaton. Okay, again, depending on if we take only the positive or the negative. Now, when we have such an automaton, we can also define what is called the generating function of an automaton. Of an automata. Okay, so in fact, it is defined by the following. Okay, it went too fast, but no matter. Okay, it is defined by the following. We have all the paths of lands K from I to J. Okay, so this is the number of should be here, number of paths from landscape from I to J multiplied by ZK, and we run over all the possibilities. And in fact, there is the following. And there is the following formula in any book of combinatorics, it appears. Okay, so this is an easier way to compute it. And we have from the elements of parent-Frobenius theory that we had before, we had that this set is a set of simple poles of the generating function. Okay, now if you remember, it was L root of unity of H. Of h. But now we have that i minus a. So this set is the set of poles or the set of zero of the denominator here. So the set of poles of this generating function. Okay, so now I want to go to the to to the you know what let's make a summary again. Okay, all this theory, all this background was. this theory all this background was to have the following data we have we have a free group we have a coset partition we look at the sorry we look at the subgroups of finite index each one comes with all his own luggage shreya graph shreyer automaton transition matrix generating function all this data that we have seen is this set of pulse of generating function now imagine the situation Now imagine the situation. Each one was all of them were completely strangers a time ago. And then we put them together. It means that their transition metric generating function were as they were. Now we put them together in the coset partition and now they need to mandate together. So in fact, it seems that there should be some correlation between them that was there initially. So in fact, what So, in fact, how I see the Erz-Soch-Schoenheim conjecture, it says that necessarily there was the connection was the repetition of the index. Okay, now I could obtain some things, but it's not the repetition of the index. Now, I want to go to the proof of the Erdos conjecture, which is a very simple one. Okay, so if we have a cosette partition. We have a cosette partition of Z, okay, so we have the same browing as before: D1Z plus R1 and so on. We are going to count all the positive numbers in Z and we are going to compute their generating functions. That means, okay, for example, in Z, if we look at all the positive numbers, so we have zero, we have one. Number. So we have zero, we have one, two, and so on. And so that means that we are exactly one positive number of lens zero, lens one, lens two. It means that, in fact, the generating function looks like that. This is the generating function. For z, when you look at 2 as 1 plus 1, so it's nice 2, 3, 1 plus 1 plus 1. So in the in the radio. In the reduced or coverage of in the unit ball, this is this is the equal to that. Now, for example, we give an example with 2Z, for example. If I counting all the positive numbers into Z, so I have 0, 2, 4, and so on. So I will have one number. I will have Z to the 2, one number, always one number in Z. It's not. Is one number in z, it's not okay. So it will be z 2k and it will be 1 1 minus z 2. And if I'm looking at the cos edge 2z plus 1, all the odd numbers, so I will have 1, 3, 5, and so on. So I will have here 1z plus 1z3. I take z outside. I take z outside, outside, sorry, so I will have this generating function. So we can see that the rule is, if I'm looking at dz plus r, its generating function looks like that. Okay, so this is the idea in the proof of the Erdash context. We are counting all the numbers, so all the positive numbers. So, all the positive numbers that are in Z is equal to all the positive numbers that are in all the cosets in the Dijon union. So, it is true also for the generating functions. So, we have here the generating function of Z, and we have here the sum of the generating functions of all this coset in this way. Okay, so we have, okay, I was too fast here. So, we have a sum of things like that. Now, what are the poles here? Now, what are the poles here? For example, if Ed is equal to 4, so here we have E to root of unity of order 4, or let's say 5, for example, 5 root of unity of order 5 as a pole here. Now, if we take Z and we make it turn to this root of unity, where ds is the largest index, yes, then we will have that the right-hand side goes to infinity. But what about the right hand side? Infinity, but what about the right the left-hand side? It goes to a number, so you necessarily have some other generating function that is eliminating, cancelling the other one so that it goes to something finite. So, this is the idea. Very, very elegant. I mean, Erdos itself says it's a kind of from the book proof because it's very simple. It's a kind you take, you take your root of unity, you have a pole in the Root of unity, you have a pole in the right-hand side, but not a pole in the left-hand side. So it had to appear twice at least. So I'm trying to do the same thing, but unfortunately, F2 or the other three groups are not so easy to handle as the Z group, as a cyclic group. So I'm also doing the same. I'm going to count the number of positive words in FN. And I will say the same thing. And I will say the same thing as in the proof of the Erdos. The number of positive words is here is equal to the number appearing in each coset because it is a Dijon union. And in particular, we have the same thing with the generating functions. But here we have the generating function in Fn for the positive words. We have n to the k, okay, and to n to the power k positive word. To the power k positive word, and we have this function. The point is here that if you recall, then when we look at the Schreier coset automaton, Scheyer graph, and so on, the poles are not given respectively to the index, but to the period. So, here, if I take Z, I make it tense to that, but here I have the maximal period, then I have a repetition, but not of the. And I have a repetition, but not of the index of the maximal period. Okay, so from this, I could obtain, okay, don't bother to read what is written here. Here, this is the context, okay, with all the data that is accompanied to a cosette partition and the subgroups. So, in fact, I can recover that there is a repetition of the period, of the maximal period. And if there is a period which does not Period which does not properly divide another one, then also it appears twice. Now, this permits to recover the result for Z, because I can describe also a subgroup of Z in this way, as an automaton, a Schreier graph, Schreyer automaton, doesn't matter how we call it, there is only one generator, one. But here, as you can see, for any DZ, the period is exactly equal to the index. So here we can have the repetition of the So, here we can have the repetition of the index. But if you recall, there are examples in Fn, but the period is certainly not equal to the index. So, it's not enough. There is a case. Okay, I just give an example. Okay, those examples are a little bit artificial because it's a very small cosette partition, but it's just to have an overview ID. Okay, so for example, I take my subgroup H with transition matrix this one. Transition matrix this one, and then I'm generating function this one. I take this coset partition, so this will appear twice with two cosets: K A B and K. I have made an error here. I need to take KA and KB. No, and KAB. Sorry. It should be KA and KAB. Okay, so these are the generating functions. So, this is the generating functions, and here, okay, the theorem one theorem one gives it's not we don't need theorem one, but it's just to illustrate, okay, so there is a repetition of the maximal period. Now, I can add a condition that if the maximal period is equal to one of the maximal indices, then I will have a repetition of the index, but it's not. Of the index, but it's not necessary, it's not necessarily the case every time. So, this is just a condition that ensures that. So, for example, just a little small example again. Okay, so again, we have this age and we have generating function. And here we have a Schreier graph with period 4. And here, if we take Z tending to this root of unity of the maximal period, which is also the maximal index here, then I will have a repetition of the. Then I will have a repetition of the index, and because of the repetition of the period. So, in fact, for Z it works because the period is always equal to the index, but in Fn, where there are a lot, a lot, a lot, a lot of subgroups of finite index, so this is not necessarily the case. Okay, so Okay, this was the first sub-approach using the Perron Frobenius theory. In fact, it shows that there is a repetition of the index of the period, sorry, and sometimes also it leads to a repetition of the index. There is another approach, but I will go, I will give mostly the idea. I don't know how much time we will have to finish it. But the idea is the following. As I said before, we have at the beginning. We had at the beginning S subgroups of fine antidex with their cosets, and they had their own life. Suddenly, we decided to put all of them together. Okay. And we want to see how why should they manage together to make a decent union of all the free groups? It's a kind of strange. So, the idea is the following. Okay, so I just want to give the idea. Okay, so I just want to give the idea, even if after that, there are many technicalities. So forget about that, just the idea. Okay, so I have all this cosets, the subgroups. So I will take N to be the intersection of all the normal cores of the subgroups. Okay, so this is a normal subgroup in L F N. Subgroup in Fn and what is important that it is inside each HI. So I'm looking at the normal subgroup that is inside every subgroup that I have. Now, you agree that what's happening here has to be in correlation with what appears in the Shire graph. I mean, what appears in the Schreier graph of this one needs to be in correlation with the Schreier graphs of all the. The Schreier graphs of all the subgroups, all the different subgroups. So, the idea is the following: I'm taking a word W in Fn. Okay, now it has some behavior in each of the Shire graphs, in each of the subgroups. And this behavior has to be related to the behavior here. So, the idea is the following: I'm trying to understand how this correlates. And I will have some partial results also. Some partial result, also a repetition of something, but this something again is not the index, but something else. Okay, so this is mostly the idea to try to look how they should manage together all these circles. Okay, so let's begin. There are some technicalities. Don't read everything just to understand the drawing. I think it's the better. So for example, I have XK, the Schreier graph for K. Okay, and I take the word W. Okay, and I take the word w equal ab a minus one. I defined, okay, I define this order. What does it mean? In fact, let's do it with a b. Okay, let's do it a b a minus. Okay, a b a minus one. And if I come back, a b a minus one, that means that the order of this w at zero is two, okay, because kind of order, natural, minimal, natural number that makes him come back. Natural number that makes him come back. Okay, if I'm looking at, for example, at three, so I do A, B, A, sorry, A, B, no, at two, I'm doing A, B, A, B, A minus one. So after one step, I have come back. Okay, it's kind of order, like the non-order of an element in a group, but here it's a kind, how many, what is the minimal natural number such that The minimal natural number such that w to this power come back to here to zero. So, for example, for zero, a b a minus one, a b a minus one, two steps I have come back. And this is the set of vertices visited. So now I, instead of the of the regular Schreier graph, in fact I draw a new graph and in this new graph, in fact, I label it with W. I label it with W. So, for example, in our case, if W is ABA minus 1, so we have that K is related to K AB. And this one, in one step, it comes back. If we take AB, then AB, it makes four AB, AB, AB, AB. The order is four, and there are four vertices. So we have a kind of lens four elements. Okay, so let's see, for example, so I'm trying to, there are several graphs that I defined in the way to obtain a graphical representation of the coset partition. So if this is the normal core of K, okay, and I have W equal AB, for example, so in the normal core here, when I'm looking at AB, so I have two disjoint loops of lance four of this way, label W, in the normal core. Okay? The normal code, okay? Okay, don't read all that. I will explain in words. Okay, so I have n and I have k. I have my word w. Now, n is contained in k. Now, for example, the subgroup K is the disjoint union of two cosets, N and N B, and I put them just above it. And K A B is the disjoint union of these two cosets of N, and so on. Now, in N, I have. So on. Now, in N, I have the following two disjoint loops of lens 4 labeled by W. And in K, I have the following. And I see the image here one above the other as it should be. Okay, so now I do it as, in fact, just one subgroup and the normal core. Okay, so another. Okay, so this is the same example as before. Now, for example, n is also contained in H. The normal core of K is also contained in H because K is contained in H. So now I'm looking, I have H at the bottom, okay, with these two cosets, and I have N is contained inside, and now we have in H we have four cosets of N, and here four cosets of N. And if here we had just the lands two loop. The lens two loop labeled by W. Here we have already two design loops of lens four, and I see, in fact, this inside this, this inside this. Okay, yeah, directly to the example. Now, the purpose is, as I have said, to have. Have said to have a picture, okay. Just I will recall. I have my normal core, the intersection of all the normal cores, and I'm looking at the graph of n above the graph of each of the subsets, of the subgroups. Now, I want to look at the cosette partition. Okay, for example, I have this following partition H1, H2AB, H3A with H1 the H and H2, H3 the K. And H2H3 to the K. Now, I want to see all the pictures together. Okay, so what I have, I have my eight cosettes of N. Okay, I know that I have two disjoint label loops of flannels four, labeled by W, relating the cosets of N in this way. Now, instead of color here, I have changed, instead of color, I have put forms. Color, I put forms. So these are the four cosets that belong to H. If you recall, this was in the previous previews. Here, this was here. Okay, these are the four cosets that belong to H. And here, those are the cosets that belong to K A B and K A. So I want to put all the picture together. And not to deal with all the cosets of H and all the cosets of K, but just the one coset that belongs. The one coset that belongs to the coset partition. So these are the four cosets of N that belong to H. I'm going to put them in this way as if I had here H. These are the coup cosets that belong to KAB and as if the KAB was here and this to KA. So now I see in fact a pigraphical representation of the coset partition with this W. With this W, how it behaves. Now, there are some technical points here. I don't want to get into these numbers too much. I will just say the following. When I have such a loop, I prove, in fact, it's not a hard lemma, but it's a very critical lemma here. That in fact, when I have such a loop with all these numbers, okay, I can build for Okay, I can build for from it a cosette partition of Z, and the indices in this coset partition are exactly this number, these orders. When I denote A star i W, I mean A star i is the order when I look at the specific coset that appears in the cosette partition. Okay, so I have a coset partition of Z. Cosette partition of Z with subgroups of indices, these numbers, and I can take the residue so that it fits. So it is a technical lemma, not hard to prove, but important here. So each time I have this kind of loop, I have, in fact, a coset partition as it. And then instead of proving the Erdos conjecture as before, I'm using the Erdos conjecture. And I say, okay, so there is a repetition of this number, of the maximum. Of this number, of the maximal number. Okay, so if here this is the maximal order of w, there is a repetition. So again, there is a repetition of some number, but not the index. If I assume some things that this number is large enough, then there will be a repetition of the index, but not always. So the theorem says the following: again, what is written above, this is the context. Written above, this is the context. Okay, so if I have now, I'm not choosing a W this time. I say if there exists some word W in the free group, which has this kind of order in the Schreier graph equal to the maximal index, then, okay, I will have a repetition, and then there is a repetition of the index. And in fact, instead of going through all the words. Going through all the words in the free group because it's a kind of a lot of words, I can look only on the transition group. If you recall, the transition group, which is a subgroup of the symmetry group. So if there exists a DS cycle in the transition groups, and this is easy to check because it's a finite one, then this is a translation of this thing in terms. Of this thing in terms of the transition groups instead of looking at all the words. And in fact, I can give a list of conditions, and it's very combinatorial and it's funny because this was the first time in my life that used the Pygon principle so many times. But it was a kind of, you really, Pygon. When I learnt it, I say, what's that? It's a stupid thing, but no, it's not so stupid. Sometimes it can be that. That's a shooting sometimes in combinatorial things of this kind it works. So there is a list of conditions, but this let's not cover all the cases. Okay, so now I'm converging to the end. Okay, so some remarks and questions. So I just want to make a summary. So the idea is to have a cosette partition, to look at the Schreier graph as the Schreier coset graph or Schreier automatic. Triacoset graph or triat automaton, all these data relating. And in fact, to try to understand why they should manage to live so well together and to make a cosette partition when each one has its own, has had its online life just before. So now what I have obtained, the partial results that I have obtained, is that I can show that there is a repetition of the largest period and the repetition. Period and the repetition of the largest order of some W. And if it's big enough, it gives the repetition of the index. So as we can notice, the repetition of the index, it occurs whether when the period is large enough or whether there is a long enough cycle in the transition group of the largest index subgroup. So, so in this case, I can say, I don't know how it is precise mathematically to say such a thing, but we can say that the HS conjecture is satisfied asymptotically, okay, with such a probability, because there is a known result of Dixon that says that if you take any random pair of elements in Sd, okay, Sd, if for us it's because of the G index, so I probably. Index. So at probability is three to the three fourths, it generates S D as D goes to infinity. So in our case, for example, when we take any two permutations from the A B, the Phi A Phi B, so if D is large enough, there is a lot of chance that it generates S D. So there will be a long cycle. And also, if it is cyclic, there will be a long cycle. So it seems that there are many. So it seems that there are many chances that it works. Now, there is a point that here I want to suggest, to point. It's the following. If now I consider a shrieal graph and it is aperiodic, the period is not big enough, it is even one. So we have this result from the parent-Frobenius theory, which From the Perron Frobenius theory, which says the following. Now, when you look at that, in fact, it says the following. It says that the proportion, okay, imagine that you have here at some point, at some place, the proportion of positive words accepted by my automaton, because here it is, it is the number of all the positive words in FN. And here, this is the number accepted by my automaton. So the proportion of positive words accepted by Words accepted by automaton, it turns to one to the index. So, in fact, it means that you have the following. It is written in the next. So, if we have a partition with all of them are periodic, so my theorems cannot apply because I need period greater than one. I need more the first theorem, the first approach. So, on one hand, I have that the sum of all these fractions is. These fractions is always equal to one because of the coset partition on one hand. On the second hand, I have that the sum of proportions of positive words tends to one to the d and their sum need to be equal to one. So it's a kind of, you understand why, what bothers me? I mean, I have, write it a second. I mean, we have that necessarily this order. Really, this always occurs. This has to occur. Now, the proportions, it tends to one to d the one. So, for example, if I have, okay, it can be plus minus. Okay, this is the proportions or the proportion of positive. Or the proportion of positive words accepted by the first automaton and so on. At each lens, at each k, at each lens, k large enough, okay, you need to have equal to one. Now, why if this occurs, why these numbers should concede so that they cancel what to the other. You understand? There is something not clear here. Why should it happen like that? So, this is the case that I did not. This is the case that I did not work on because it's a little bit, as you see, it's a little bit hard to make examples of coset partitions, of large enough coset partition. So I think that one of the problems here is to understand if all the Schreier graphs are aperiodic and we have this kind of thing that should occur. And if there is a conterexample, if there is, I'm not sure. So maybe it occurs there. That's the. It occurs there. That's the idea. Okay, so if you have ideas, if you have suggestions, if you have some breakthrough, I would be happy to hear. That's it. Thank you, Pauli. So the talk, we yeah, we already have a question. So you need it. It's all for the good. I don't remember, but uh maybe, maybe, maybe maybe, maybe, maybe, yes, maybe, maybe. Okay, thanks. So when you look at the, you mean the proof in the first approach relied on looking at this counting generating functions of the positive elements lying in the coss and then looking at the poles. So, what happens if you count not just the positive elements? You made a remark to this effect. I can continue. Okay, so there is a paper of Grady Gorchuk with Armand de Bignan and maybe someone else where they are counting reduced words. And they build an automaton that counts reduced words. So I was in touch with Armand at some point, but their automata is very complicated. It's much more complicated. That's true. It's much more complicated. But maybe. And also, what I was interested in. But and also what I was interested that I need to see somewhere the index appearing because I can see that it will repeat itself. So he told me that, I mean, you cannot see from the automata where the index appears. There is also another approach that Tomas Delzon from don't remember which Renoble maybe? Tomas Delzon. Okay, so he suggested to me there is an To me, there is another paper of Tatiana Nanibeda and Grigor Chuk, an old paper on rational generating functions. And there, instead of looking at the number of elements of lance, blah blah blah, they are looking on the elements in a group, no, sorry, in a ring, in a ring. So it is a kind of generating function where the elements, the coefficients are not taken in Z. It's taken in Z, but in N, but in a ring. So I have tried, but I did not know exactly how to what to do with his ID. But I mean, this is the logical question to ask what if it won't look just positive, but something else, maybe it will lead to something, but I don't know how to go on with that. Thank you. Okay, anyway. So, what's not clear to me is how does this depend on the generating set of the free group? So, what if it changed the generating set? Can it happen that the periods change? This is a question that I have thought about it when I work on the second approach, because this was a chrono corno it was first, the to the to the second one. Uh yes, things may change if we change the set of generators. If we change the set of generators, indeed, I have not. I now you remind me that I have then thought about something about that, but because especially I think that maybe also the transition group may change if we change the generators. But I have not gone through this idea, but maybe it should be done. Any other questions? If not here, then I can ask. If not here, then I can ask one question, maybe. So you didn't say this, but it's clear from the talk, maybe that there is no known counterexample to this objection, right? So it's okay, good. No, it's funny because it sounds so easy. I mean, it makes me should be worked, but something should be worked. From said, I mean, you try to generalize it to nilpotent groups, maybe. Maybe it's easier, I don't know. The question for nilpotent groups, maybe it's Important groups, maybe it's uh this. I did not try to adapt my method for what they thought. I know that it is a natural question to try to reprove the infinite nilpotent groups. I mean, torsion-free nilpotent groups. That is torsion-free nilpotent, so maybe other torsion-free nilpotent, no? Because I mean, I think in the end cosets in nilpotent groups, I think you understand quite well. You mean the result of bare? The the result do you mean the result of Berger no no no I mean I mean do you try do you could could be a suggestion to another tr um uh type of group to try to to solve the conjecture in so so they so so they proved it for a class of the some class of the of the solvable groups but finite you said yes but if you I mean if the if the conjecture was proof for all the finite groups it was proved also for the all the groups you can you can make some You can you can make some questions. And maybe if you go back to the Dixon slide, so you said that you mentioned this theorem of Dixon, but I mean, there okay, so it's not so precise comment, right? I mean, yes, but the point is that do you know that the so the point what you said it would be true if once you take the set of all subgroups, uh, this is kind of uniformly distributed inside this, right? So this is true, this is true that if you take a periodic uh graphs. A periodic curves, so in fact, the distribution is a kind of uniform amongst all the cosets. Amongst all the cosettes, okay, I didn't expect that. Okay, and now there is a point that I did not point here, but you can act on the coset partition, and then you get another cosette partition, and then it's funny, funny for me, I think. But I mean, the numbers need to fit once again. It's strange, I don't know. Okay, then if there are no further questions, we're supposed to thank Fabian again.