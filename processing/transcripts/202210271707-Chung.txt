So in this talk I'm going to talk about some multi-scale methods. So this is the outline of my talk. So first I will give some overview of multi-scale methods. And then I will talk about this numerical backscaling for non-linear multi-scale problems. And then next I will talk about learning of cost scale computational models. Models. Finally, some conclusions. First, so this is the type of problems that we consider. For example, we consider PDE models that contain physical parameters. And these physical parameters typically contain multiple scales and high contrast regions. And of course, if you apply And of course, if you apply a classical numerical scheme, you will need very fine computational grid. So this means that the computation is very expensive. So that's why we would like to design some cost-scale models in order to speed up the simulations. Okay, so in our simulations, we will start. Simulations: We will start with a call script. So, this typically means that the size of the core script does not need to be solved scales and contrasts. So, for example, in this domain, so we see that we have a lot of features. And then on the right-hand side, we can just place a cost grid. And you also see that the grid size does not need to resolve all the Does not need to resolve all the small details in the domain. And then, based on this call script, we will construct a suitable computational model to solve the DDE. And as you will see, this computational model is based on some type of local simulations. So, and also let me point out that this call speech size is typically fixed and it is basically chosen according to computational concerns. For example, you may want to specify how much computational savings you want to achieve in the beginning when you take a course with science. So let me first start with some more classical ideas. So this is upscaling. So here we have a domain, and you also see that there is a cost grid in this domain. And then typically what we can do is that for each cost element here, we solve two local problems. And in this case, we consider this elliptic. This elliptic PDE in this domain, and then we solve two local problems with two different boundary conditions. And then using these two local solutions, phi1 and phi2, we can find this effective property, k star. And this k star is used in the simulation in the whole. In the simulation, in the whole computational domain, based on this cost-creep. And I thought there were a lot of research in this direction. And then a related idea is multi-continual model. So the main idea is that we may need multiple effective media properties for some applications. So typically, So typically, say for example, in this, and this is my example, for example, we need two effective mediums, K1 and K2, for this type of applications. And for example, this K1 corresponds to the effective medium properties for fractures, and K2 corresponds to the medium properties for the matrix. The matrix, and then they are coupled together based on this type of model. And then in our research, we will basically represent heterogenetics by basis functions. And of course, there are many other multi-scale methods that one can use for applications. And here we look For applications. And here we look at this specific type of methods. And here we say that upscaling models can be constructed by local multi-scale basis functions. And these basis functions are solutions of some local problems. And this is the basic idea of multi-scale finite element method. And so typically you see that. And so typically, you see that for each local region, we solve a local GDE, and then we obtain some basis. And these bases contain some final scale features. And then we use these basis functions. And then we can approximate the final scale model by a corresponding cost-scale model. And then we can obtain more efficiency. More efficient simulations based on this cost-scale model. And what we do is that we would like to have some type of extensions. And typically, so we know that one basis function per cost element is not enough. And we would like to see how do we systematically add more basis functions. And in this process, it In this process, it is important to systematically identify channels and also how to localize long channelized features. And we decide this generalized multi-scale finite element method for this purpose. So, here this is the basic idea of this multi-scale method that we Multi-scale method that we use. And this is a design based on linear elliptic PDEs. So, first, step one, we will identify local degrees of freedom. So, basically, for each cost element, we would like to know what are the unknowns that we want to solve. And this is typically done by solving some local special problems. Some local special problems. So, as you see in this figure on the right-hand side, so for each cost element, we identify some local unknowns. And so, these costs are the local unknowns. And then, next, we will compute some local multiscale basis functions. And these are solutions of local problems on some over sample domains. Over sample domains. So as you can see in this figure, so for each cost element, we define an over-sample region like this, and then we solve some local problems here in order to get the multi-scale basis. And you'll see that why we have to do this, because the local basis will connect all the degrees of freedoms within this over-sample region. Region. And then we also have a localized theory to determine the size of this of a sample region, which means that the size of this region will be determined by this theory. And this is also important because for problems where you have some long channelized features, you see that the See that the solution along these channels are all related. And it's usually difficult to localize these features. And then this theory says that we can actually solve the local problem in some oversample region without actually the solution here also capture most of the important information and the influence outside this. Influence outside this over-sample region is small. And then we also have error bound for this elliptic linear case. And so this figure on the left-hand side shows this feature. So you see that this is the over-sample region. And you see that these local bases are concentrated in some localized region. Region. So, the overall steps are the following. So, we did some offline computations and then used the solutions from offline computations to find the multi-scale model. And once we have this model, we can solve the problem for many input sources in order to get the answer. Okay, so that was some overview of multi-scale methods. So next I will talk about the problems that we consider. So in particular, we would like to consider this non-linear multi-scale problem. And this G here is a non-linear multi-scale operator. And U is the solution. And for nonlinear And for nonlinear problem, we will not use the idea of basis functions because it's not suitable for this case. And instead of multi-scale basis functions, we will use the idea of local non-linear maps as I will define next. So, our method basically consists of three major steps. So, number one, we will first identify suitable Will first identify suitable microscopic variables that we need to solve. And then, number two, this is the local nonlinear map. So, basically, instead of using the idea of basis functions, we solve local problem in this sense. Basically, these are local so basically we see that we try to map the local background. Local macroscopic variables to a downscale function phi. And this downscale function phi satisfies the given PDE. And this mu is a suitable source term. And then after that, we have this step three. We will use the downscale function to find. To find the final cost grid model. So, this is step one. So, we will have to specify some cost scale variables. And this is one simple choice. So, one example of cost scale variables are the average of the solutions on continuum. So, for example, this is one. So for example, uh this is one uh cost element, and then we can see that we can divide this into three continuum. Okay, and then uh succeeds is k1, k2, k3. And then the variables are denoted by this notation. So capital U n is the steps, n is the nth time step. And then here i means this is the variable for the i cost element, and j means this. element and j means this is the jth continuum within the cost element i. So this is my cost scale variables and they're actually the mean value of the solution within the continuum. And then our goal is to find a cost scale equation for these variables and this equation typically has a form like this. So you see that we apply This. So you see that we update the cost scale variables in time according to this equation. And this G bar corresponds to an average operator. And this G bar will give an approximation of the original multi-scale operator G. And then this capital L here could be N or M plus 1, depends on whether we use an explicit scheme or an implicit scheme. Scheme or an implicit scheme in time. So, next, once we have specified the cost scale variables, we construct the local downscaling functions. And this is needed in order to find this average operator g bar. And this is the definition. So, we let C be a set of cost scale values. And this C will be the And this C will be the U in my scheme. And given these macroscopic values, we solve the local problem defined in the oversample region here. So you see that this red element here is one of the cost element, and then this is the green region is the oversample region. And we solve this local problem in this over sample region. And this G is the again this. And this G is the, again, this original operator G. And then we find the solution n so that n satisfies this equation. And also this solution n subject to this constraint. So you see that this is, so it means that the affect of this capital N on each of the continuum must be equal to the given microscopic values. Okay. called scopic values. And then typically we solve this local problem using a final computational match. So anyway, so this capital N is a final scale function. And then next we can use this local downscaling function to get the final cost read model. And first we will define this global As we will define this global downscaling function, capital F, you see that this is basically a combination of all the local downscaling functions, n, and then this is multiplied by a suitable partition of unity functions, chi. And then to get the cost scale model, we approximate the solution u by this function f. And you see that this function f depends only on the cost free variables. Variables. Okay? So we do this approximation. And then we take the PDE and multiply this by suitable test function. And we get this variational form. And you see that in this equation, the only unknowns are the values u bar. And of course, there are many choices that you can take these test functions. And then we can also do this. And then we could also do this time discretization. So here let me give an example. So here we consider this two-phase flow problem. S is the saturation, and U is the velocity, P is the pressure, and kappa is some heterogeneous medium. And then we can basically typically, we can also And then we can basically typically we can also write this system in this form that we consider. And then the unknown U will be both the saturation and the pressure P. And then this operator capital G has two components. And you can basically base on these two equations. So next, in order to solve the, I mean, in order to The I mean, in order to find the downscaling function, we solve some local problems. And here, in this specific example, all we need is we'll compute the downscaling function restricted on a cosmic edge. Because this will be this because this value will be used in the cosmic simulations. Cosmic simulations. So that's why for each cosmic edge, we will consider some type of oversampling region like this. And then within this oversample region, we will solve these local solutions. And you see that, so basically we just take the, say for example, for this pressure equation, we discretize this. We discretize this pressure equation on this over-sample region, and then we obtain these two equations. And then we also see that we also have to specify this constraint. Basically, actually we will solve three functions: NP, U, and NS. For example, this NP is the downscaling function corresponds to pressure. This NS. Pressure and this NS corresponds to the downscaling function for saturation. So, anyway, so we take this system and then we discretize this in this oversample region. And then you also see that we have to specify this constraint. And again, this says that the average of this downscaling function on each of the continuum must be equal to Must be equal to the cost scale variable that are given in the beginning. So example here we are given the cost scale variables and then we will construct this local downscaling function. And then for the saturation equation, this is similar. So we discretize this equation and then we require the downscaling function to satisfy this type of Satisfy these type of constraints. And then next, once we have those downscaling functions, then we discretize the original system by using a finite volume scheme. For example, if we take the pressure equation and then we integrate this on some cost element, so we obtain this type of equations. So you see that. Equations. So you see that, so in this equation, we only see the cost pressure unknowns. And you also see that we have this coefficient t that depends on the local downscaling functions. Then we can also do this for the saturation equation. So we take this equation and then we integrate this on a cost element. And then you see that we will have some. That we will have some flux terms. And this flux term basically depends on those downscaling functions. And those downscaling functions depend on these cost-grid values. So basically the conclusion is that in order to have a scheme like this, we only have to know the flux on the costly edges. Edges. And these factors are non-linear functions of the cos-scale saturations and cost-scale pressures. And so this is one simple example to show this type of idea can help to improve the performance of the simulations. So here we take a medium like this and Medium like this, and this yellow means a high contrast region. And then we consider two types of schemes. So the first one is based on the idea that I just mentioned, and the second one is based on just a classical finite volume scheme on the same cost width. And you see that so the our idea here actually can can can improve the the How much more expensive is it T V checks? It is more expensive because we have to solve a lot of local non-linear problems and also for each time step we also need to solve this local non-linear problem. It is more expensive than a typical finite remote. A typical finite volume scheme. But that's why we have this next slide. So, as you can see, that the goal here is to compute this cost-scale equation, which relates all the cost-scale variables. As you can see, that this our nonlinear upscaling ideas give a stencil for this scheme, and all we need to do is to compute the unknown coefficients. the unknown coefficients in this model. As I just mentioned, this is expensive because you will have to solve a lot of local non-linear problems. And also for each time step you will also have to solve all these local non-linear problems. But the good thing is that in this scheme all we need to know is the flux of the downscale functions on the boundary Scale functions on the boundary of cost elements. So that's why we would like to design a way to speed up this process. Here we make use of some ideas for machine learning. And we would like to build a map that can compute this solution fast. So the training data here can be obtained from either numerical simulations or Numerical simulations or measurement if there exist measurements. And also, we do not have to use a fully connected network because we know how the local unknowns are connected. So, that's why a localized network here is needed. So, this is the basic training concept, and this is the idea. And this is the idea. So basically, for each local over-sample region, we can collect some so we can perform some local simulations to get training data. So basically the input of this level will be the local heterogeneous medium and also the local mean values of the solutions. And then given this. Solos. And then given this input, we first go through a couple of CNN layers, and after that, we will do a couple of standard feed forward local network. And then the output of this network is the values of the downscaling functions on cosmic patches. So example number one. So we consider this. One, so we consider this unsaturated flow problem in fracture process media. And here we so again the purpose is to construct a model like this, and then p bar are the cost-specific mean values. And then the unknowns in this cost-speed equation are these capital T that we need. That we need. So basically, we will perform a lot of simulations on over sample region in order to get the training data. So here in the training, so the training data will be obtained by snapshots. And then the network basically output these transmissibilities that we need. And then the input are the local And then the input are the local uh averages of the solutions and also the permeability fields. And then we take uh we use this type of loss function. So x is the input, y is the corresponding output, and then we just use this simple L2 type loss functions. And then on the right-hand side here, we see, so this is the medium that we consider. And on the right-hand side, we have some training. On the right-hand side, we have some training results. And that basically we will. So, this so basically, we have to consider multiple networks in order to capture different mechanisms. For example, MM means the matrix coupling and FEA is fractured to fracture coupling. And we see that the performance seems good in this case. Good in this case. And we also have this priority plot to compare the predicted value and the actual value. And you see that in most cases, the predicted value and the actual value are close enough to each other. But you also see that in some cases, we can make a wrong prediction. There are a few cases here. And then in this example, too, we look at this. And in this example, too, we look at this couple flow and transport problem. And this is the medium that we consider. And on the right-hand side here, we look at both the training error and testing error. And we observe reasonable performance. And then in these few figures, we look at the output of the fluxes. Of the fluxes. So here, this black line here corresponds to the solution coming from the fine-grid simulations. And the green line is the prediction from our method. And the red line is the flux that are computed by classical finite volume method. So you see that the green line and the black line are matched. And then you see that the red line here is kind of different from the other two lines. Different from the other two lines. And again, it shows that the predicted flux is accurate enough for these simulations. And then so here I present some of the snapshot of the computer solution. And this is the sexuation and the top row. So these are the reference solutions at three different time steps. And then this is the upscale solutions. And then the error is about 7% at the final. About 7% at the final time. And also in this simulation, the cost-scale model has about 2,000 unknowns. And high-scale model has about 15,000 unknowns. Okay, so finally the conclusion. So we decide concrete model based on multi-scale ideas. And then we consider some type of non-linear problem. And we see that we have to make use the idea of double. We have to make use of the idea of downscale functions instead of multi-scale bases. And then we obtain this non-linear upscaling for non-linear multi-scale problems. And you also see that in order to compute this computational model, we need a lot of computations. And here we propose to use some machine learning ideas in order to speed up this process. Order to speed up this process. I'd like to thank you for your attention. Thank you very much, Eric. Maybe I have time for some questions. So if you change resolution, you have to retrain the entire thing. Yeah, the answer is yes. So we kind of have to fix some of the configurations in the behavior. So, if you change the call speed, we need to recompute the train. Let's say that you train something and then you look at the resolution and everything is reasonable, and then some scientists tell you that you need to reduce the error by 100%. So, how are you going to do it? So, one way is to repeat the process. It's one way. The other way is that we can also make use of. We can also make use of these simulator solutions as the condition. And then we use that for fine-scale simulations to get a fine-scale solution. That could be one way. But if you have to do this cost-scale model again, then we probably have to do the training idea. Uh if not, please gentlemen if he marked all the time.