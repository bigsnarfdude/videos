To focus on the period of Folk's career, which was working on the entropy theory, the equilibrium states theory. And I want to start with, I guess, the period a little bit before I knew Todd. And then I'll talk about how Todd and I started working together. But the context is that robustness questions beyond Beyond uniform hyperbolicity have a very long tradition. So, robustness, stability, these kinds of questions, these go back to the rigs of modern dynamics, food dynamics, so particularly championed by the snail stool and also the Brazilian stool. So, these questions have been around for a long time. So these questions have been around for a long time and I want to focus on a couple of papers of POD which really develops analogies of this in thermodynamic organism. So the two papers I want to focus on is there's a paper by Uzi Fisher. Fisher, Sanburino, Egg San Barino, and Vasquez. And that was published in ETBS in 2012. I think the alphabet preprint was a few years earlier. And there was a related paper by Boozy Fisher, JMD, 2013. So let me So, let me just give you a bit of background about this. And actually, Keith set me up nicely for this. So, if we have a dichomorphism on the manifold and it's transitive, so again, we're interested in properties which are stable when you give the dynamics a push. So, the definition of robust transitivity, I think we can probably imagine what it might say. Imagine what it might say if you haven't seen this before. This says there exists an open neighborhood U of the diffeomorphism F. So this is a neighborhood. I guess maybe topologies and stuff can be varied, but I'm going to write it as a neighborhood in the space of just C1 diffeomorphisms such that each Such that each G in U stays transitive. So we're transitive, we give it a C1 push, and we're still transitive. So examples of this, well, transitive and also dipiomorphisms satisfy this property by structural stability. Then the moral. Then the more assorted examples or where we enter the beyond world. And that gives me a good chance to mention, of course, one of the many things Pog did is we had a major involvement in the Beyond Uniform Hyperpublicity Network, sometimes organizing the conferences himself, but there was a big one in Britain Young 2016. Yeah. So So mania ecomorphisms, which I will try and give you an idea soon how we define. So these were defined as robustly transitive examples, and these are partially hyperbolic and not an OSOP. I'm going to define this soon, and then the next level of And then the next level of difficulty R is the Bonassi-Vianna diffeomorphisms. And these are, these have a dominated splitting. And they are definitely not partially metabolic, but they still have this robust transitivity property. Okay, so let me give you a definition which I think I'll attribute to Luzy and Bischer. So I'm not quite sure of the publication history, so I think that the first time this definition appeared in print is this paper, but it looks like there's an earlier preprint with just Boosey and Fisher's names on it. Just Boozy and Fisher's names on it. It looks like that grew into this work. I'm not quite sure what the backstory was, but on the archive, it's just Boosey and Fisher. And the definition is analogous to this. A system is intrinsically stable. Well, same set as this. Well, same setup as this. So if there exists an open neighborhood u of f so for and again, this is in the space of C1 difficomorphisms. So for all G in the neighborhood, G has a unique measure of maximal entropy U subscript G. U subscript G and furthermore so the system equipped with the measure of maximal entropy for G is isomorphic to the original one. In what seems? Just measure theoretic isomorphism. So I wrote all the words, but you know, a slogan is clear. We just they've actually We just they've asked me the question of when is uniqueness of the measure of maximal entropy robust in smooth dynamics. So you have a system with a unique MME, you give it a C1 kick, do you still have a unique measure of maximal entropy? And of course, they're very inspired by what went before over here, that this history in questions of robust transitivity. Robust transitivity. And it might be that Todd was the authors, maybe Todd who had those connections with the South American soul studying this. Maybe. I don't know. Anyway. So let me tell you what the theorems are, and then I'll try to explain these examples. Explain these examples. Okay, so the theorem, so from first paper, so Goosey Fisher, San Barino squares 2012. The Magnier diffeomorphisms are intrinsically stable. Intrinsically stable. And then the next paper, using pressure 13, but the messy VM videos intrinsically stable. And one thing I really like about both these papers is. Really like about both these papers is there's some really nice conceptual definitions in there, such as that one, which maybe haven't been explored as much as they deserve, but it's nice to be able to get some attention. There's another concept in here, which I'll come to in a minute, which is what they actually prove, and then this becomes a corollary. There's another aspect of this paper, which again people nicely, and they're intrinsically stable, even though Even though the neighborhood u will contain an X G with positive failing triple. I'll try and say something about what that means in a minute, but this is a connection with another of lines of research, the symbolic extensions. Symbolic extensions and all of that business. So, having positive tail entropy is a way of saying not asymptotically entropy expansive. So, tail entropy is a number which measures how much entropy is going to appear at smaller and smaller scales. So, this quantity vanishing is exactly the definition of asymptotic entropy expansivity. That is the condition that gives you symbolic extension. That gives you symbolic extensions. So, you know, you might think, okay, great, but there really are some pretty serious dragons lurking in the set U, and they still get influenced by this. I think I can say more about that. Okay, so let me define these two clusters of examples. Well, maybe not defined, but at least tell you roughly what they are. Okay, so let's start with Magnier. So it's a construction, and we start with just a little slip. Just a nice toral automorphism of the tree torus. And we're going to assume that the eigenvalues of the matrix defining the automorphism, we have a lambda one, which is rotational one, lambda two, and a lambda three. So we have one expanding direction, two contracting directions. Let's do this visually. Let's do this visually. So we've got three directions. This can be my U. Well, both these are S, but I'm going to make a distinction. I'm going to put two arrows there, but that's meant to be going with Lambda 3, which is the really strong contraction. And that's going with Lambda 2. With lambda two. So we could think of both these directions together as the stable, or formally you can think of this as partially hyperbolic. So this direction, the lambda two direction, we can think of this as a weak stable direction, or we can also think of it as a central direction. We can just declare it to be a central direction. This is a kind of trivial example of partial hyperbolicity. Now, Manning's construction is to start. Construction is to start with this. And what you do is you turb this map, turb this very nice linear thing in the neighborhood of a single fixed point. So, starting with this, and we're going to do a pitchfork by vacation. And this is just going to be done in a And this is just going to be done in a small ball around zero. So it's a C0 small perturbation map. C1 is going to be absolutely huge perturbation. And what we do is we just look at this direction and kind of pull it apart. And instead of contracting, we're going to create two new periodic points. Sorry, two new fixed points. Points. So this was the original one. We're messing with the strong stable and the strong unstable as little as we can. And now this direction, we actually change the derivative from being a little bit below one to just a little bit above one. So we actually push out there and then we start decreasing it again. It becomes one at some point, I guess. At some point, I guess, and then we're going back in again. So, we've got two new fixed points here. So, now we're going the wrong way. So, away from this neighborhood, we're still as nice as you can possibly be. And this is done carefully so that everything's still integrable. We still have, well, it's still smooth. Yeah, we still have, we've got still got these distinguished directions. Yeah, we've got still got these distinguished directions, and we make sure that everything's still integrable, so on and so forth. But now we genuinely have something whose splitting is into three directions, and we really have a central direction corresponding to and then we're considering maps G in the neighborhood of this. About Natty Bianna, it's quite similar. We start with a four-dimensional torque automorphism. We'll make all the eigenvalues real and distinct. Two expanding ones, two contracting ones. We take two fixed points one and P2 and around P1, well, okay, let's label this with a star around P Around P1, do what we just did over there in the lambda two direction. And around P2, so that pulled just in neighborhood of P1, we pulled the expansion, the weak expansion, just a little bit of contraction. Then we do the opposite around the other one, around this other point somewhere. Around this other point, somewhere completely different in the space, we pull the weak contraction, the lambda three, into a little bit of expansion. The lambda three direction. So this is lambda three is contraction, but we're messing with that, doing something like this to create a little bit of expansion. They also perturb to give a little twist, but to make the derivative so after. So, apti-perturb, they also give it a little twist, make sure we have complex eigenvalues of the derivative at these new fixed points. And the reason they do that is because that's an obstruction to anything splitting further. And what we get is FBV, Genesis Viana, with a splitting. Genativiana with the splitting into a center stable and the center unstable. And it's a dominated splitting and giving it this little twist prevents that from having any chance of splitting any further. The Bonatti-Vian examples are quite fiendish, particularly if you're thinking about perturbative type things. Just because having more dimensions allows us to do nasty things. So let me just say something like this. G C1 close to a Bonanza Vienna thing, we may have horseshoes. We can have a sequence of horseshoes, small and smaller in size, but all having positive entropy. Positive entropy, maybe that's part of the definition of horseshoe, having positive entropy accumulating to fixed points. So this is meant to be a four-dimensional torus. This is meant to be the point, the place where we messed everything up. And if you give this a C1 kick, it is quite possible we have all these horseshoes. Each one of these is positive entropy measures. Dementiary measures. We can bound that away from zero. It gets smaller and smaller and smaller and smaller until they limit onto this thing. That's bad. That's really, really bad. So expansivity is failing as dramatically as it possibly could. This rules out the symbolic extension. Well, this is exactly what rules out the symbolic extension. So being able to model something. To model something by a finite alphabet, you know, you're essentially discretizing the space, which is essentially in some sense saying that there's some scale where you can just fix things and see everything. Having more and more entropy coming up on arbitrarily small scales is really exactly what prevents that from happening. And that's what would make size Mr. Lindbergh stated earlier. Okay. Okay, so this isn't asymptotically age expansive. The entropy map isn't upper semi-continuous. Yeah. So let me say something about how they dealt with this situation. They being told and your own. Yeah. So, this other notion that they introduce, I think, in the second paper, the JMD paper, which I alluded to earlier, is entropic stability. Hopefully, I do justice to this definition. I've had to simplify it a little. I may have oversimplified. We'll see. So, the definition says something like the following. Something like the following. So, a system F is entropically stable if the gene F there exists subsets M prime and M prime prime of M and a Borel isomorphism sign from the multiple times. Psi from m prime to m prime prime. See what this means in a minute. The number h, which is less than the topological entropy, so if mu is ergodic, so if mu is ergodic with respect to f, With respect to F and it has entropy bigger than this threshold H. Also say if it's a product for G, again with entropy bigger than H then the measure of M prime is one measure of M so that is to say oh and And right, and I missed the important thing, blah, blah, blah. It's just a variable isomorphism. So the important thing, the maps, you know, it's the normal conjugacy definition on here. These things can be vectors. So we have a conjugacy just on this subset M prime. So let me try and decipher this. So what they're saying is, you know, instead of having this. Is, you know, instead of having this in a more conventional setting, two maps which are close, you know, you have your structural stability, gives you something like this, and size, a very nice map. Structural stability, they're saying we're going to ask that on a subset that we don't know much about, we can do this measurably, and any measure with large enough entropy. With large enough entropy, it sees this. So it says nothing about the low entropy measures. We just forget about them. But anything large entropy, we have a nice, and this induces a measure theoretic isomorphism for anything with large entropy. So my understanding of their logic is this is what they actually prove. And this gives you a one-to-one correspondence preserving entropy between high entropy measures for F and high entropy measures for G. You can thus come. For G, you can thus conclude that if F has a unique measure of maximal entropy, you just step over to G, same thing, because all the measures that matter for high entropy, same entropies, still unique nose. I think this is a very nice concept which could really be explored more. Okay, so that's what I wanted to say about Um Lucy Fisher. So now let me talk about how I started working with Todd and the work we did after this. So I have three papers with Todd. It's very sad that there won't be any more. Sad that there won't be any more. Um, let me tell you how that came about. Um, so Todd had, so we probably met in, I don't know, I'm gonna say 2011. I was definitely at Penn State at the time, so probably 2011. We might have met, we probably met before, but the first time we really talked, yeah, we'd certainly met before that, but the first time we really tried to talk, man. But the first time we really tried to talk math, it was the Maryland conference, Maryland Dynamics Conference. Well, in fact, I was still at Pennsylvania, so that's in April, so it could have been 2012. Maybe it was 2012, actually. Anyway, so at that point, Vaughan and I had been working on uniqueness of equilibrium states. Well, we started off doing the uniqueness of measures of maximal entropy for beta shifts. Uh, beta shifts, so it was all symbolic at that point, um, and Bourne and I were continuing to work in this direction. And I think at that point, we'd written our second paper, which was doing equilibrium states, but it was still all symbolic. Um, and I was probably giving talks about that, and so was Bourne. Um, at that time, I mean, we knew that we could get out of symbolic world, obviously, um, but at that time, I But at that time, we have another project on the go just to do it for a topological dynamical system. And at that time, we thought we would get more examples and we would do more things. But at that point, it was just, well, we have something symbolic. Let's write it non-symbolic. That was probably where our ambitions were at that point. So that's as far as we were with that. So we didn't have any application to smooth dynamics. We didn't have. Smooth dynamics, we didn't have, well, we really didn't have a theorem that was useful beyond the symbolic case at that point. But Todd, I guess, had heard me speaking about it or Vaughn speaking about it. And he said, hey, you know, I've got an idea. We should talk. I was like, okay. And he suggested we have lunch and talk about an idea he had. I said, okay. We went to a We went to a restaurant in College Park, which was really not very nice. It was not the first, not the last mediocre restaurants I've been to with Todd. We went to many. So actually, I just figured out where this place was. I know we all know Maryland well. I googled it. I thought I would recognize it. I think it was R.J. Bentley's. I think it was R.J. Bentley's. It has a three and a half star rating on Google. I think that's quite generous. Anyway, we had, I guess we ate burgers, but they weren't very good. But we had a really interesting conversation. And Todd said, hey, I've been studying these examples, there's these partially hyperbolic things. And I just got a feeling that the stuff that you're doing, we really want to do equilibrium states. We can't do that now. Our techniques just don't do that. Techniques just don't do that. I mean, I think everyone can see this isn't going to cut it, but equilibrium states. So, hey, I feel like your stuff might apply there. I said, okay. And he drew the kind of pictures that I just drew on the board. And I went, okay. And at that time, I certainly couldn't explain why this was an important example or give the kind of presentation I just gave about the context, but I just kind of went with it and went, okay, cost. And went, okay, Cole knows about smooth dynamics, so let's see where this goes. And that was how we started collaborating. And I think this speaks to the themes that came up in the professional development talk on Tuesday, just about talking to people, being open, going to events, sharing ideas, making connections with people. Pod was really a master of that. A master of that, and he's one of the best in the community. I think that explains how he has all these, what did we say, 24 collaborations? Don't know explain like, yeah, all these different themes of his research. And he was really, really good at that. And in this case, he really, really had an insight about how the techniques that Vaughan and I were developing could be used, which was ahead of where Vaughan and I were at that time. At that time. So we started doing this. So Fotkod's idea was to build an equilibrium states theory for these classes using the ideas that Vaughn and I had been developing. And we were really not very far along in our developments of this when he realized this. When he realized this. Okay. Peter, how much time do you want at the end? I don't need very much. Okay, so just keep tool. All right. Again, this probably wouldn't be possible to say what I want to say, except we've been well set up by talks earlier in the conference. So, really, the Mannier case was where we figured out how to do this in smooth dynamics. And we didn't have the terminology at the time, but the way we study the Mania case is using what Ben introduced as a lambda decomposition. And the idea is that lambda should be non-negative. It's a non-negative function which somehow measures if it's positive, that should be corresponding to having some nice but uniform estimates. And they're very accepting. You can do this in different ways. But the prototype here is we're doing this, this Manier example is a torus and it's really the nicest thing in the world, except for in the neighborhood of the fixed point, which I'll put on zero here, we messed it up in a horrific way. A horrific way. So, the way you can measure if you're good or not is literally just where you are, the location, right? So, if I, okay, so if this bad goal is B, keep calling it P to be consistent, I guess I'll make the radius be rho, then our function lambda is just going to be the characteristic function of the whole torus with this little ball around. This little ball running on me around here dropped out. So, what's this measuring then? Well, you know, every time lambda outputs are one, that means we're in the good path of the space. We've got every nice estimate you could possibly hope for. And every time Lambda outputs are zero, we've hit the stuff that we really have problems with. And somehow, as we saw, there's some quite delicate structuring here. Quite delicate structure in here, um, but somehow our idea is to be rather naive and just say that, well, we're going to try as far as we can to just ignore that and use what's good over here. And the way we're going to get away with ignoring this is by saying that this is small in some sense, and the sense of smallness is in terms of entropy or pressure. So, we use this to do a land decomposition. With lambda decomposition, I'll draw the picture that Ben drew. So we're chopping up an arbitrary piece of orbit. So we've got a point in a time. And what we do is use this function. Oh, and we have some threshold eta. And we just chop off at the last time the average of this along the orbits is the. Among the orbits is less than eta. And we chop off from the end for the maximal time, again, so that the average among the orbit of this is eta. And then a simple argument gives you that in the middle here, everyone has an average at least eta, and also this way. So, what this is giving us in this context. Are giving us in this context is along the middle of the orbit, um, you know, we have a definite proportion of time, and we're thinking of picking eta really small for the pressure estimates. But along the middle, we're getting a definite proportion of time. It might be a small proportion, but it's a definite proportion of time away from the bad neighborhood. And of course, over here, at the beginning and the end, too, particularly when this number's chosen small, this is a piece of orbit at the beginning spends most of time in this band bank ball. This band back ball, the eighter. So that's what we do. And then the idea is with this definite proportion of good time, we can do stuff over here. And then the idea is this stuff that we can't do much with, because it's spending most of its time here. We hope that the pressure estimates is very close to somehow the pressure or entropy of things that spend all their life in this ball. And yeah, that's exactly how it goes. So, let me state a theorem so this is. So this is this is Bourne, God, and myself. And I'll do it for Manier. So let G be in a neighborhood called F M and we'll be able to tell you. And we're going to take a follow-up continuous function. I've got two parameters around. I'm going to give up writing complete sentences in the interest of time. So I've got rho, which is the size of the neighborhood where we did something bad. And I've got a R, which we haven't met yet. But this is a logarithm of the maximum expansion in the sense. Expansion in the center. So we took the weak contraction, we pulled it through one and just to the other side, but we keep it small and we take the log of that number. So this is something small and positive. I can write it like this. So if this a function hr which goes to zero as r goes to zero, which is the same as this expansion decreasing to one. Expansion decreasing to one, and then we have some formula. I don't know if I should really be writing this, but I will, anyway. So, one minus r supremum of the function just in this mad ball. So, that's part of the pressure estimate. And then there's another function. I wrote H to invoke entropy type stuff. But it gets small as R gets gets small. So, this term is somehow estimating the pressure of what. Is somehow estimating the pressure of what lives in the ball all the time, or something like that. As long as that pressure is smaller than the whole space, then there exists a unique moving state. And we apply this, if pi is a fixed holder function, if we allow ourselves to mess with the map afterwards, if we choose r and row small enough, we can always switch this. We can always switch this hypothesis on. So, in other words, there is a Mannier example. So, given the fixed holder, there is a Mannier example so that you get the unique equilibrium state. This also applies to SRB measures. That too. We did the similar analysis with the Bonati Gianna. That was hard. I don't see. Hard. I don't say that to show off. It was so hard. I'm still somewhat traumatized. It wasn't hard in a good way. It was just, oh, it was just unpleasant. So all I say about the Vanessa-Vianna case is it's similar methods, but we also need a term to do with tail entropy. So somehow we have to deal with those nasty horseshoes I was telling you about, but somehow the nasty horseshoes have to live in here and their entropy is constrained. And their entropy is constrained by what R is and what, yeah, probably R is the number that Matt is there. So but after Bianca, there was another technical issue which I can't really get into, but that forced us to work at fixed scale. In this case, we could do specification at all scales. This is what you expect. But we wanted Bonati Viana too. And then we figured out that we couldn't prove specification. Figured out that we couldn't prove specification of small scales. This fall in the Vanati-Vianna case is just too nasty. It just messed everything up. And we were stuck for a while. And then another concept that came out of Fuzzy and Fisher, I don't think it made it into the final paper, but they had some concept called uniformly overflowing or something like this. And all that really is, is the observation that, okay, this can be really bad, but even if your estimates are all But even if your estimates are all the wrong way, and so on and so forth, the worst thing that can happen is if you want to be pulled in, but you're being pushed out, something like this, the worst thing that can happen is you get pushed out just outside this ball, and that's as bad as it can get, because once you're outside, all the nice estimates happen. So we did the very underhanded trick of just doing everything at a scale bigger than this. So we always had points out here, wherever we were. Always have points out here, wherever we were. Okay, there was a cost to doing such a cheap trick. It made everything extremely painful, and we had to do everything coarse and at a fixed scale. And yeah, I mean, this is what it is. You can look at the paper and you'll see what I'm talking about. Okay, so let me wrap up. So this was this project. This project, and this was this partially hyperbolic-dominated splitting setting, was really where we figured out how to use the specification approach in smooth dynamics. And the work that we've done since really points back to this. We have to figure out how to work with core scales to do Fanatic Vienna. And a lot of work has come out of this. And a lot of work has come out of this since. So, work that's come, I won't do details anymore, but BCFT we heard about earlier in the week. So, geodesic flow and non-positive curvature. So, actually, in some ways, easier than stuff that's on the board right now. We had some other challenges, but in other ways, things were nicer. And the theorem we had there was that, of course, T is, sorry, F is again Fischer. F is again pitcher. You know, we have the pressure on the singular set is less than the pressure on the whole space, then there exists a unique equilibrium state. There's no way we would have known how to do that if we hadn't have done this work before. And of course, we had a key because we needed someone who really understood geometry. And we spent a few weeks together, over three years at AIM in California, the four of us. I mean, I'm sure. Ah, okay, great. So that came out of that. And then also the course approach that we had to develop for Benatti Biana. I mean, after that, I said, never again. Why are we doing this? But I was wrong. Feigenhega, Nipa, and War really put that horsebrook somewhere where it actually, you know, you can really say, yeah, okay. They applied this in no conjugate points. And they had a unique MME. And let me also mention recent work, which I regret we were unable to hear. Um, I regret we were unable to hear about this this week. Uh, we invited a couple of the authors, but we can make it. Uh, so the classical Lorenzo tractor, this is very recently being studied from the thermodynamic dynamic point of view by and sectional hyperbolic things more generally by Pacifico Yang and Yang. Really beautiful, recent work. Again, using specification stuff, all this course stuff, and there seem to be several other challenges that I really want to talk to these authors to find out. To talk to these authors to find out what they are and how they got past them. My point being that this approach still seems fruitful, and really, all of this stuff really came at its roots from Todd saying, hey, I've got an idea. There's these examples I know about. I think the stuff you're talking about might work here. Let's go to a dive bar in College Park and eat a burger and talk about it. So it was really Todd, without Todd's insight, I really don't know how much. Site, I really don't know how much of this would have been done. It would certainly have looked very different, and who knows when or how it would have been done. And I think really, I mean, Todd really had a special ability to get people together. He was part of some great mathematics, part of creating a lot of new mathematics. 26 co-authors really says a lot. He was really a blue in the community, someone who could connect a lot of things. Always friendly, smiling, upbeat. Yeah, I'm sure we. Up these, yeah. I'm sure we all miss them. I said we do. So I think the idea is that I'm going to finish with the paper that hasn't been written yet, because I'm supposed to be writing it, and Todd is no longer around to help me do it. Can I focus on the we have the middle point? We have the middle point. So, this is an application of the scheme that was described, was it the first or the second day in Ben Cole's lecture and that Ben has just been talking about? So, it's a sort of extension of what was done in the BCFT paper. So, I would Will give as little details I can get away with. There are three authors. One of them is B. If we all know it's Fisher. The third author is McEnroe. She was a graduate student at Northwestern who has now finished her PhD. PhD. She is not related to the famous tennis players. So we just dealt with finding a unique measure of maximal entropy. And this was for a geodesic flow. And it was a geodesic flow for a rather specific type of surface. And this type of surface was created for a rather specific purpose. Rather specific purpose. There was a question back in the 1980s. We everyone knew about surfaces with negative curvature, and they had ergodic geodesic flow. And that was great. But then you looked at the sphere, or even the torus, and you did not have a metric with negative curve feature, and you did not know a metric that had ergodic geodesic flag on. Eggotic geodesic flow, people wanted one. So essentially, what they did was to come up with a sphere with negative curvature. And so here's a picture of it. This is meant to be a pair of pants. Normally, when I talk about this, I make somewhat careful attributions to all the people who thought of this, but in the interest of time, But in the interest of time, I'll skip that today. Hopefully, people whom I'm not mentioning won't mind too much. But in the simplest scheme of this, this is just the hyperbolic pair of pants that we all know and love. And then you just bang a hemisphere on each end. And you think about, you can think about geodesic matter, and you pretty quickly realize that you've got an ergodic geodesic black water. Got it. Geodesic block because when your geodesic goes into one of these hemispheres, you know exactly what it does and how it comes back out, and you can understand it. So that was great. But then people said, well, but yeah, but there's that discontinuity of the curvature. And people who really knew things said, yeah, there's this famous picture of a billion in the stadium. The stadium. And there, the discontinuity of the curvature of the boundary is essential. It was thought for a while that this might be a phenomenon of discontinuous curvature. But in fact, it was realised that you could smooth this picture out in the obvious way. So in particular, Victor Donet wrote his PhD thesis analysing the behaviour of The behavior of the smoothed version of this. So, the way you smooth it is you look at one of these ends. So, you replace, you take some neighbourhood like that, and the whole picture that you draw in that neighbourhood can be thought of as a surface of revolution in R3. The surface of revolution has, it looks something like that. Something like that. This boundary curve is a closed geodesic. The curvature out here is negative. It's positive there. It's helpful if the curvature increases as you go upwards. And it's helpful to keep the rotational symmetry a little bit outside the actual desk. This thing seems to be technically. This thing seems to be technically known as a cap. So you have these caps and you have negative curvature outside the caps. And so it was shown by Donner that you get ergoidic geodesic flow for a surface like that. You can do the same thing for a torus. And there are some tricks to extend this. You do something analogous in dimensions three. Not yet in dimension four, but never mind. Mentioned four, but never mind. So we looked at these things and wanted to do the same kind of thing that was done in the BCFT paper and find a unique measure of maximal entropy. I think if we put the work into it, you could also deal with at least some potentials and get unique equilibrium states, but let's stick with MME for the moment. So we wanted to do this. So we wanted to follow the kind of scheme that's been described by Bear. Scheme that's been described by Ben and also sketched by Dan here. There's a bad part of the world, which is the cap, and it's helpful to make a little neighbourhood of the cap and exclude that as well. So maybe I'll go back to this picture. We have these, we have some wood region out here, and so we have a lambda decomposition. The idea is. Show. The idea is it's good to spend a reasonable amount of time out here, and it's bad to spend too much time in the danger zone and the caps. So we go through the usual scheme. Then you have to verify various things. So we happily did that. And one of the things you have to verify is expansivity. And in the BCFT paper, expansivity was Expensivity was easy. That was one of the parts that really was not behind. So we were capable of going along. And then we started, we got to point where you had to write down something about expensivity. And we realized, oops, this thing is not expensive at all. And if you think about it, since I've got about negative one minute, I'll just say that if you start thinking, you realize that for any Thinking, you realize that for any measure of the nature that you want your measure of maximal entropy to be, almost every orbit will fail to be expansive. So this was a bit of a shock. They got us worried, but we were able to fix it. And the problems come up at the boundaries of the cap. So for the boundary of the cap, there are two wards, but you can go this way. Orbits because you can go this way or you can go that way. And so, if you move into the units of tangent variables, you have a picture of you have your orbit going along, which is the boundary of the cap, and then you have something transverse tablet. And we want to change the things here to make The things here to make expansivity easier. And so, what you do is you take this orbit and you just sort of blow it up. So, transverse to the orbit, you remove the point in the middle and kind of change the geometry of that cross-section. So there's a whole layout and you do that kind of thing. And so that fixes expense. And so that fixes expansivity for you. And then you have to go back to the other things and be a bit more careful than you were before. And it seems to work. So that was going for Odd. And I still have to, I've got writing to. And so that fits into the progression of things that Dan was talking about. So that's where I want to. Talking about. So that's where I want to finish. But let me just say one more thing: which I think everyone who knew Todd will agree with, that he was about the nicest guy you could ever wish to meet. And yeah, we all miss him a lot.