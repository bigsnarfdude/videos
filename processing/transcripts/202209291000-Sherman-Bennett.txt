Morning. Melissa Sherman-Bennon is joining us from MIT, and she's going to be telling us about cluster structure on type A braid varieties from 3D playback rest. Thanks, Melissa. Thanks, Tim, for reading out my entire title, which is quite long. Yeah, so thanks to the organizers for this opportunity to speak. This work is very inspired by a conjecture of Leclerc of Bernard. Of Leclerc of Bernard on Richardson varieties. And so it's a real delight to be able to talk about it to this audience. Yeah, so as Tim said, I'll be focusing on type A braid varieties, which are a natural generalization of Richardson's and type A. I'll give a cluster structure on these varieties from a particular kind of combinatorial source, which we are calling 3D playback graphs. Like Lara, if you don't like. Laura, if you don't like this part of my title and have suggestions for some alternate, please tell me afterwards. So they're pictures that look like this, or I guess really the 3D playbook graphs, pictures that look like this. Okay, so that part is joint work with Pasha Golashan, Thomas Lamb, and David Speyer. It's not on the archive yet, but it will be very shortly. And then I will also briefly mention a related project, which is joint work of myself and Christina Seryenko, where we resolve a conjecture of Bernard on. Conjecture of Bernard on cluster structures for type A Richardsons. I won't really say any details about that, but if you want to know more, talk to me afterwards. Okay, so let's get going. So before I tell you what these braid varieties are, just a little bit of background about flags. So this is a type A talk. So my G is always SLN. B is going to be the subgroup of upper triangular matrices. And as usual, I identify the quotient G mod B with the complete flag. quotient g mod b with the complete flag variety. So just to be very concrete, if I have some coset, so g times b in this quotient, the way I'm going to identify it with a complete flag is, well, I take the leftmost column of my matrix G, that the span of that will be the first vector space in my flag. Then the leftmost two columns of G will give me the dimension two subspace in my flag, et cetera. Subspace in my flag, et cetera. Okay, so the braid varieties will be defined by some relative position conditions. So, very roughly, the relative position of two flags, it's kind of a rough measurement of how far apart they are, how different they are. So, let me define it. So, if you have two flags F and F prime, I say that they're SI related or in relative position SI, if F and F prime differ exactly in the ith subspace. If you want to think about this in terms of cosets instead, so pick some coset representatives, G and G prime for F and F prime. This condition is saying that G inverse G prime is in B S I B. Okay, so you can think about it both ways. And this coset description makes it easy to say what F and F prime being W related should mean. Well, it just means if I take coset representation, If I take coset representatives again, then G inverse G prime should be in BWB instead. W is a permutation. Okay, if you don't like thinking about cosets and only like thinking about flags, there's another way to think about being W related, which is as follows. So F and F prime are W related, if and only if, for every choice of reduced word for your permutation W, so S I S I L. One da da sil. There's a sequence of flags that interpolates between f and f prime, and kind of at each step in this sequence, the subspace you're changing is dictated by the reduced word you picked. So I want to find this interpolating sequence where to move from f to f1, I change the i1 subspace, and then to move from f1 to f2, I change the i2th subspace, et cetera. And it turns out if such a sequence exists, it's actually unique. This is from some properties of. This is from some properties of Tim just made a face at me, but I promise it's true. Yeah, so some properties of this relative position make that true. Okay. Oh, and I guess I should say also, please stop me if I'm going too fast or if you don't understand something. Otherwise, I'll just motor through. Okay. So now, what are type A braid varieties? So they're indexed by a pair. The first thing in this pair is a word, which I'll call beta underline. A word, which I'll call beta underline, which is just some word in the simple transpositions, not necessarily reduced. The second thing in this pair is a permutation u such that my word has a reduced expression for u as a subword somewhere in there. Okay, so given this information, the braid variety x beta u is, well, okay, so I like to think about points in the braid variety as walks in the flag variety. In the flag variety, and the steps. Okay, so these walks are always going to start at the standard flag at B. And then the steps in this walk, their directions will be dictated by the letters of the word you picked. So I'm going to have walks that start at B, and then the first step in my walk, I take a step in direction SI1, second step I take in direction SI2, et cetera, until I get to some final flag in my walk, FL plus one. And there's now a restriction on FL plus one that comes from the On FL plus one, that comes from the permutation U. The final flag, so the place where your walk ends, it needs to be in position W not U with respect to the anti-standard flag. This feels like a very weird condition, like feels like there are more natural ways to use the permutation U to put a constraint on this final flag, but for historical reasons, this is the one I'm going to pick. Okay, and these were studied by a number of people under many different names, but People under many different names, but one of them was Mellet, another Kasalz, Gorski, Gorski, and Simon Tal, and I think many others. I think everyone uses different conventions than what I've presented to you today. So good luck if you want to read other people's papers on them. Okay, so is that definition clear? Okay, so why are these called braid varieties? I have not yet, there's no braid yet in the picture. So the reason for that is that if you take That if you take your word, so beta underline, and you apply braid moves to it, so you swap commuting transpositions, or you do the other braid move on three transpositions, then it turns out your braid variety won't change. So instead of indexing the braid varieties with these words and simple transpositions, I can actually index them by elements of the positive braid monoid. So that's what I'll do. And the positive braid monoid. What I'll do. And the positive braid monoid, if you're not familiar, it's just exactly like the symmetric group, but you do not say that the simple transpositions are self-inverse. Okay, and what else can I say about this variety? Well, it's smooth, it's irreducible, it's affine, and we know its dimension. The dimension is just the length of beta minus the length of u. Okay, and if you are not sure yet that you care about these varieties, let me give you some examples. These varieties. Let me give you some examples to maybe convince you that you should care. So, first, the first example of a braid variety is if you choose your word, beta underline, to be reduced, like it's just a reduced expression for some v in the symmetric group, this braid variety, it well becomes much simpler. So if your work If your word is reduced, then having this string of flags between B and your last flag, all it means is that B and F L minus are V related. So, and in fact, actually all of these intermediate flags are uniquely determined by F L plus one. So, when the word is reduced, you may as well only remember your final flag. And so, the braid variety X V U is actually just isomorphic to a Is actually just isomorphic to a sub-variety of the flag variety. So you don't have to think about walks anymore, you just think about flags. And what sub-variety is it? Well, it's exactly those flags F that are V related to the standard flag and W not U related to the anti-standard flag. And if you think about this some more, or if you have already know about Richardson's, then you can see this has another description. So this sub-variety of the flag variety has another description. It's just Description: It's just the intersection of the Schubert cell for V and the opposite Schubert cell for U inside of the flag variety. So it's an open Richardson variety. And these are always, so open Richardsons are always indexed by two permutations, and these are the two permutations that you need. Okay, so braid varieties generalize these open Richardsons. There's an even more special case where if your permutation V is a special permutation and it has Is a special permutation and it has only one descent, then this braid variety is isomorphic to an open positroid variety of Knuts and Lamenspire. So they introduced these varieties very heavily influenced by work of Posnikop on positroid cells. So yeah, so maybe if you've heard of these before, then and you like these, then maybe you should also like braid varieties. One of their generalizations. Okay, and then in another special case, And then, in another special case, so that's when my permutation U is the identity, we recover the type A double-bot Samuelson cells of Shen and Wang, which Fan Chin talked about a bit in his talk. Okay, so those are my varieties. Why might you suspect that they have a cluster structure? That is, their coordinate rings are cluster algebras. Well, a really good reason to suspect this is because it's been conjectured. Been conjectured. So, in the type ADE Richardson case, Bernard conjectured that these coordinate rings, coordinate rings of Richardsons, should be cluster algebras. But actually, he did even better. He constructed some seeds for Richardsons and conjectured that the cluster algebra with that initial seed, I should say my frozen are inverted, is equal to the coordinate ring of the approach. To the coordinate ring of the appropriate Richardson variety. His techniques were cluster categorical. And so, as you may know, though he constructed seeds, it can be actually kind of difficult to write down the quivers in particular. It's kind of straightforward to get the cluster variables, but the quiver for the seed is computing it requires knowing a lot about morphisms between modules in some category, and it's hard to know that much. So, maybe the, oh, I should say. Maybe the, oh, I should say Bernard proved that this inclusion always holds. So the real obstacle is this inclusion. And maybe the biggest obstacle to proving the unknown inclusion is that it's actually pretty hard to compute these quivers. Okay, so since Leclerc's conjecture, there's been kind of bits and pieces of progress. So first, Galachian and Lamb showed that this conjecture is true in the special case of positroid varieties. So that's those, those are. So that's those, those are kind of special type A Richardsons. And one nice piece of their work is they sort of nail down exactly what the quivers look like. So the quivers for these seeds actually come from Posnikov's Playbic graphs. And they were sort of inspired by work that I did with Christina Serienko and Lauren Williams. Okay, so that was one bit of progress towards this conjecture. Other bits of progress include Progress includes work of Menard, who in his thesis constructed some other seeds for type ADE Richardsons. Not totally clear how his seeds relate to Leclerc's. And then Cow and Keller later showed that the upper cluster algebra using Menard's seed as an initial seed is equal to the coordinate ring. So, okay, it's got an upper cluster algebra structure. Not clear how this relates to this, but fine. And then in a different direction, okay, so I should say. A different direction, okay. So, I should say Menard's work is also sort of cluster categorical, very representation theoretic. In a very different kind of strategy, Gracie Ingermansen in her thesis constructed yet another different kind of seed, not clear how it relates to any of the other ones. And she, her seeds were only for type A Richardson, so the ones I actually gave you the definition of. And she showed that, again, if you take the upper cluster algebra using her seed as the initial seed, you Using her seed as the initial seed, you get the coordinate ring of the Richardson. Okay, so there's all these little bits and pieces. Mostly we've gotten upper cluster algebra structures, not like actually just cluster algebra structures, and not really clear how many of these different constructions should relate to each other. Okay, and then so that was all in the Richardson situation. But really, braid varieties are, I mean, they're a generalization of Richardson's, but they feel really close to them. And so, Them. And so Casal's, Gorski, Gorski, and Cimental made the conjecture that, okay, well, you know, we think Richardsons have a cluster structure. Well, we also think that braid varieties have a cluster structure. But their conjecture, they don't say anything about what a seed might be, just that there should be some seed. Okay. So that's some, a lot of possibly somewhat confusing history. And now I will tell you about hopefully not confusing results. So in this This joint work with Galachian, Lam and Speyer, we show that the Casal's Gorski-Gorski-Simental conjecture is true. So we produce a cluster algebra, which is equal to the coordinate ring of the braid variety. And we also show it's locally acyclic. So A is equal to U here. Okay, so how do we construct this cluster algebra? Well, so you're focused on a particular braid. So you're focused on a particular braid variety, x beta u, and you pick any word, so any positive braid word for beta that you want, beta underline. And from this word, we create a bicolored graph, which is naturally embedded in three space and is not planar. So we're calling these 3D playbit graphs because in some cases they are actually one of Posnikov's playbit graphs, but in general, they are not planar. They are not planar, but it seems stupid to get rid of the like PLA and Playbic, which is the thing that stands for planar. So, anyway, if you have a better, any better names than 3D playbook graph, please tell me. It's kind of a, yeah, well, anyway. So, we produce these graphs embedded in three-space. They're bicolored. And then from these graphs, we obtain a seed. And all of the seeds we obtain from these positive braid words for beta, they're all mutation equivalent. And we actually also produce some more seeds from these 3D playbraids. Produce some more seeds from these 3D playbit graphs that come from a slightly more complicated source than positive braid words for beta. Okay, so we have, so I guess, so we confirm that the coordinate rings of these braid varieties are cluster algebra, cluster algebras. And moreover, we also have kind of a nice combinatorial source for seeds. So I can draw you a picture and tell you how to get a seed from it. And it's very explicit. Oh, and I should also say. It. Oh, and I should also say: okay, so I should say two things. First, this theorem is just in type A, but we have general type work in progress. And I should also say there is related work by another group of mathematicians, Kasalz, Gorsky, Gorski, Leschen, and Simmons Hall. Jose is going to talk about this related work later this afternoon, so stay tuned. So they give a quite different construction of a cluster algebra structure on this coordinate ring. Okay, and then, okay, so that's. Okay, and then, okay, so that's the result for braid varieties. And so you might think, okay, well, that's great. Richardsons are a special case of braids. So now we have a cluster structure on Richardsons. But maybe you're a stickler and you want to know, no, Leclerc gave a construction very early on. And I want to know, does that construction give a cluster algebra structure? And the answer in this joint work with Christina Sarijenko is yes, it does. And so So the quiver of Leclerc's seeds can also be read off of one of these 3D playbit graphs. So we also have a kind of a combinatorial source for these quivers that we were very stuck on computing for a long time. I will say it's sort of, if you want to be a stickler, this cluster structure is not the same one as this cluster structure. We think. We think they're related by a twist map recently introduced by Galoshan and Lamb in the case of Richardson variety. And lamb in the case of Richardson varieties. And I, yeah, like I said, I really won't talk about this at all. But if you're interested, just ask me, Peter. Yeah. I wanted to ask about the quantum variables of this cluster. Are they all inverted? Yes. Yes. They're always inverted. And I think that you cannot say anything sensible about, like, I don't think this statement holds if you want to close this variety. Want to close this variety and then not invert frozens here. I think that that is not a thing you can do. Yeah, so this is like very special too. We want to be dealing with these kind of these varieties are affine. Yeah, I don't want to think about any partial compactifications of them. I want to think about those in particular. And then I, yeah, I also really want to think about inverted frozens in all of my cluster algebras. Okay. Okay. So, any questions so far? Okay, so any questions so far? Any other questions? I should say. All right, great. So let me tell you about this cluster structure. Okay, and I'm going to do kind of a funny thing, which is I'm going to start by defining the cluster tori without telling you what the cluster variables are. So I'll tell you the place where my cluster variables will be non-vanishing. And then after that, I will tell you what the cluster variables are. And then, after that, I will tell you what the cluster variables are. And then at the very end, I'll tell you about the quiver. Okay, so the first thing I'm going to do is I just want to produce a bunch of tori in this braid variety. Okay, so just a reminder, right, this is what the braid variety looks like. And I'll get one torus for each positive braid word beta underline for my braid beta. And actually, okay, some of these tori will be the same. These tori will be the same, but some of them will differ by a mutation or by some sequence of mutations. And I'll be able to kind of tell you which one. Okay, so how will I describe these tori? Well, it's sort of maybe it's suggested in the way that I've presented the braid variety to you. So when I gave you the definition of the braid variety, I specified the relative position of the anti-standard flag with the final flag. So a very natural way to describe a subset of this variety is to say, oh, well, I'm now going to prescribe. Oh, well, I'm now going to prescribe the relative positions of F minus with all of the intermediate flags in my walk. And that's exactly how I'll tell you about these tori. Okay, and one combinatorial notion I need before proceeding is the Demoger product of a permutation V and SI, so V star SI. This is just the max in the Brucha order of VSI and V. So the Demoger product of V in a simple transposition is either. Of v in a simple transposition is either going, it's going to kind of bring you up in the Bruchop order if possible, and do nothing if it's impossible. Okay, so I've picked a word for my braid beta. The corresponding torus is, well, all of those walks, so all those points in the braid variety, where if I start kind of at the end of the walk and go backwards, End of the walk and go backwards at each step, I greedily increase my distance from the anti-standard flag. Okay, so what does that mean? Okay, so I'm starting at fl plus one. I know what the relative position to F minus is. If I take a step backwards, I've changed the I L subspace. And it's not too hard to see that the only possibility for the relative position of F L and F minus is, well, it's either whatever the relative position here was. Either whatever the relative position here was, or it's this relative position times SIL on the right. And the greedy condition is telling me I'm going to choose the bigger of those two options, i.e. I am exactly going to choose the Demager product of W and SIL. And then I'm just going to continue in this way. So at each step, there's not a lot of freedom in what the next relative position can be. It's either this permutation or this permutation times whatever simple transposition was here. And I'm always going to take the. Transposition was here, and I'm always going to take the bigger of those two. Okay, so let me do a little example. Okay, so here is one of these tori in my braid variety. So this is the word dictating the steps, and this is the permutation controlling the ending relative positions. Okay, so if I'm in this torus, okay, so the rule was when I So, the rule was when I take a step backwards, I have to greedily increase distance. So, this, the distance, the permutation labeling this edge is either the identity or it's the identity times S1. Which one is bigger? S1. So, I put an S1 there. At the next step, I either have S1 or S1 times S1, whichever is bigger. S1 is bigger. Then Then at the next step, I've either got S1 or S1S2. S1S2 is bigger. That's right. That's right. Yeah, yeah, yeah. So all of my relative positions are given by elements of Fn. Yeah, but this word is in the brain group. Thank you. Yeah, okay. So let me just fill out the rest of this. So then at the next step, we can. This so then at the next step, we can again increase, and then at the final step, um, this is already w naught, so definitely I'm going to continue to have a relative position w naught all the way to the left. Okay, so I'll just put w naught there. Okay, so that's my torus, or at least the subset I'm claiming to use is a torus. Oh, I should also say we call these deodar tori because they're very inspired by the deodar stratification of Richardson varieties, which is classical. Okay, so. Okay, so maybe it might not be immediately obvious to you that this is a torus. So, just to give a little bit of definitions, a little bit of intuition, let's think about one little triangle in this torus. And it turns out, okay, so they're kind of two different sorts of triangles. In one of them, these two permutations are equal. These two permutations are equal. And in the other kind of triangle, these two permutations are different. And these are actually like we want to pay attention to this difference because it turns out if these two permutations are different, once you know this flag, this flag is uniquely determined. So when these two permutations are different, there is no choice in the next step in your walk. This is again some fact about relative position. But when these two permutations are But when these two permutations are the same, if you know this flag, there are C star worth of choices for this flag. So that's why it's a torus, because sometimes as you're doing this walk, you have no choices, and sometimes you have C stars worth of choices. Okay, so I want to know the dimension of this torus. So I'm also going to keep track of when I had choices and when I had no choices. And I'm also going to give some names to this. So if the two permutations are the same, that's when I had choices. I'm going to call kind of the index. Kind of the index here, C, a solid crossing. It's solid because it's dependable. I'm going to depend on it to tell me things about this variety. And if these two permutations are, oh, I have a typo. Both of these things are. That should be a not equals. Oh, no, I have misread my inflation. Okay, sorry. This is correct. If these two permutations are different, then I had no choices and I'm going to call that index C hollow because I should ignore it. And I'll always color the hollow thing. And I'll always color the hollow things with blue so we know to ignore them. So, in this example, in my first step, or I'm going to work back to front, I guess. So, here I have two different permutations. So, that means that this is a hollow thing that I should kind of ignore. Here I have the same permutation, so I should, this is a solid crossing. Here I have two different ones, so this is hollow. And then in the next step, I also have two different ones. Two different ones. So this is hollow, and then the final crossing is solid. Okay, so it's actually much easier than I have said to know what the hollow crossings are. If you think about it a little, they just give the right most reduced expression for the permutation U. So just look, given the braid word and your permutation u, you know already what the hollow crossing should be. And so you can see that here. So my u was w naught, and this, these blue things give. This these blue things give the rightmost sub-expression for w naught in my breakword. Okay, and using that, you just know that you have length of b minus length of u many solid crossings. That's the dimension of our variety. And well, that's how many cluster variables I want in each seed. So I'm going to use those solid crossings to index my cluster variables. Okay. And now that I've given you the cluster Tori, I can sort of slowly. That I've given you the cluster tori, I can sort of slowly work up to actually telling you what the cluster variables are. Any questions so far? Okay. So to define the cluster variables, I need to think about the complement of this torus in the braid variety. So if I take the complement, I get a union of irreducible codimension one sub-varieties. Dimension one sub-varieties, which I'll denote by VC. They're indexed by those solid crossings C. They're called deodar hypersurfaces, and they're actually pretty easy to describe, or at least an open dense subset of them is pretty easy to describe. So this VC is just the closure of all walks where I started at the end. And as I went, so as I go this way, I'm still going to do the greedy thing of like. Still going to do the greedy thing of like greedily increasing my distance to F minus up until I hit crossing C. And at C, I make a mistake. I do the non-greedy thing. And then after that, I continue to do the greedy thing. And that is, so that's the kind of most of this Deodar hypersurface. So just for example, so here is my torus again that we already thought about. I'm interested in the Deodar hypersurface indexed by crossing four. So that's this one. It's a solid crossing. Solid crossing. And so, what I do is: okay, so what are the points in here, or at least most of the points in here? Well, I still compute this distance in a greedy way. But now for this triangle, I don't take the demajeur product of this permutation. This one, instead I take the other thing that was the min of v s i and s and v. So instead of increasing the distance to f minus i, decrease it. So that means that. I decrease it. And so that means that in the Deodar hypersurface, this edge is labeled with just the identity. And then after that, I continue to do this greedily increasing the distance things. So here I see S2, and here I see S2, S1, S2, S1, S2. So those are my hypersurfaces. And my cluster variables are basically exactly the functions. Exactly, the functions which cut out these hypersurfaces. So the cluster variable xc, c as a solid crossing, is just the torus character which vanishes to order one on the hypersurface VC and order zero on all of the other ones. That's it. And okay, so I should warn you, this is kind of a lie. This doesn't really work for frozens. So if you think hard about it. If you think hard about it, I haven't told you what the frozen variables are, but I can tell you that this definition just will not work for all solid crossings. Because sometimes if you choose to make a mistake in your greedy walk, you can't get back up to W naught at the end. And that was an important property of my braid variety that at the end, I really needed to start with V. And so this is impossible. V. And so this is impossible sometimes. And so, in that situation, you need to define the hypersurfaces inside of a bigger space. Those solid crossings will correspond to frozen variables, but it's all kind of okay. It all works basically the same way. Yeah, so I'm lying a little bit to you, but the basic idea is correct. Okay, so those are my cluster variables. And you might be, I don't know, depending on how accommodatory. I don't know. Depending on how combinatorial you are, you might not be that happy with this definition of cluster variables. Like maybe you want some really concrete polynomials on your space, and you can just say, like, these polynomials are the cluster variables, and this you have to kind of do some work. I actually can't really give you, yeah, it would, I would not be able to produce immediately the polynomial cutting out one of these deodar hypersurfaces. So another thing you can do is there are some Taurus characters that are really easy to get your hands on. That are really easy to get your hands on called chamber minors. And you can also alternatively define these cluster variables as certain Laurent monomials in the chamber minors. So that's another thing you could do. Okay, so those are the cluster variables. And now what about the quiver? Okay, so this is the part that is going to generalize the Playbook graph story, if you happen to know that. Know that. So, what we do is we take our positive braid word and I will turn this positive braid word into a bicolored graph with n marked points. And it won't be planar, but I'll draw it in the plane in a particular way. And then each solid crossing in my braid word, I'll turn it into a relative cycle in my graph. Okay, and in the Playbit case, Okay, and in the playbit case, so kind of in this positrid variety playbit case, my graph would be planar and my cycles would just be faces. But in this more, in this greater generality, it's a non-planar graph and the cycles will kind of spread throughout the graph. And then, okay, so now I've got a graph with some cycles on it, and I want to somehow, I don't know, pair these cycles in a reasonable way to obtain numbers, which will give me arrows between cluster variables. And so the way I get Variables. And so the way I get that is I upgrade my bicolored graph into a surface. And then my cycles are just cycles on an oriented surface. And I can just take their assigned intersection numbers. And that will give me the number of arrows. This is sort of a la gantra of Kenyan. Okay, so that was the overview. Let me tell you actually how to do these things. Oh, a question. I think someone else will have to click on it for me. Ah, no, I can click on it myself. To click on it for ah, no, I can click on it myself. Ah, okay. So, um, I am tricking you. I guess so. All of my mutable cluster variables will be honest cycles, and my the frozen ones will be cycle, you know, relative cycles. So, they'll have they'll be paths that end on the marked points. Um, and so I only ever care about intersections of um Intersections of a cycle with a cycle or a cycle and a relative cycle. So never two relative cycles together. Yeah, because I don't care about arrows between frozens. Okay, oh, and to actually answer your question, Roger, I think we do keep the marked points on the boundary even when we go all the way over here to the surface. Okay. Okay. Okay, let's see. Will this just go away? Probably. Okay, so now, so let me give you the common autorics of this part. Okay, so here's, I'll just do it by example. So here is my braid word. Here's my permutation u, which is just w naught, and then I've highlighted the hollow crossings as usual. Okay, so to turn this braid word into a graph, it's really simple. It's really simple. All I do is I draw the wiring diagram of this braid word. Or, well, really, I want to draw the braid diagram. So instead of having the wires just lie on top of each other in the plane, I think about this kind of living in three space, and I let this strand cross over the falling strand in all of my crossings. Okay, so here's the Bray diagram. I've again colored the hollow crossings, and then I just take each solid crossing. Take each solid crossing and I replace it with a little bridge like this. Okay, and then I also am going to add marked points on the left end points of all of the wires. Okay, that's it. So this is my 3D playbit graph. We also get ones that look more complicated than this if this doesn't seem exciting to you. And I guess the other thing I should say is we have these trailing wires over here, but it actually doesn't matter. We could just delete. Doesn't matter, we could just delete all of this wire up until it hits the first vertex. So that doesn't matter for any of our constructions. Okay, so here's our graph. So that part was not too bad. And now I want to, for each of my solid crossings, give a cycle in this graph. And the easiest way to do this is to actually give a disk for each of my solid crossings, and then my cycle will be the boundary of that disk. Okay, my disk. Disk. Okay, my disk is going to be bounded by the edges of my graph, but I want to emphasize I'm not actually going to glue this disk in. That's not how I get a surface. I'm just using the disk to get the cycle. Okay, so how does this disc work? So the disk indexed by solid crossing C, it's going to begin at the bridge labeled C, and then it will kind of proceed along the two edges of the graph kind of emanating to the left from that bridge. And then it will That bridge. And then it will propagate moving right to left according to these rules. Okay, and these are best just seen in illustration. So let me just use some examples. Okay, so maybe first let's think about D7. So here's crossing 7 over here. And then my disk is just going to go along these edges of the graph until I hit bridge 6. And then I'm in this situation in this picture. In this picture, so my disk actually just ends. Okay, so my cycle in this situation is just this face. Oh, and I guess I should say I'm always going to orient the cycle kind of so it goes up along the bridge that it started. Okay, so that one was boring. Let's do a more interesting one. So maybe starting at six now, so the D6. So now, okay, so my disc. Okay, so my disc is going to go along. It goes underneath crossing five because the disc is attached to the strand that goes below in that crossing. And then I hit the bridge four, and now I am in this situation. And so my disc sort of continues underneath that bridge. Okay, and then three looks exactly, the bridge three looks exactly the same. Okay, and so now, and then at crossing two. Okay, and so now, and then at crossing two, it kind of goes like this. And now, okay, and so we see this is a relative disk, I guess. So I get a relative cycle. And so the relative cycle is oriented like this. Okay, and you just do that for all of them, and you'll get some collection. I don't know if I want to. Yeah, so maybe I'll just say in this particular example, this cycle, the cycle for four is also. Cycle, the cycle for four is also uninteresting, it's just a face. The cycle for one is also kind of uninteresting. The cycle for three goes like that, okay? And okay, so I should maybe say if you don't like oriented surfaces, you could actually stop here where you just have a bunch of cycles in the graph, and you can do a combinatorial computation, which will tell you what the number of arrows between xc and xd should be just looking at the cycles. X D should be just looking at the cycles C C and C D. But maybe you like oriented, maybe you like oriented surfaces, so I will also tell you how to do it there. Okay, so to upgrade my bicolored graph to a surface, I'm going to do something which is already well known in the literature. So I'm going to take my bicolored graph and just turn it into a ribbon graph. And then the surface is just the surface naturally associated to the ribbon graph. Okay, so if you're an expert, that made sense. If you're not. So, if you're an expert, that made sense. If you're not, it didn't. So, concretely, what I'm going to do is I'm going to take each or in a little neighborhood around each black vertex, I'm going to replace the black vertex with this configuration of ribbons with the edges oriented as indicated, the boundary oriented as indicated. And then around each white vertex, I'm going to replace that neighborhood with this configuration of ribbons. Okay, and the point here is this is an oriented surface. point here is this is an oriented surface and so the yellow stuff is supposed to be the underside of my surface um okay and then once i so i did that replacement here and then i just connect the ribbons along the edges of g so i kind of go like this and i won't fill in all of these because i think it will be boring to watch me draw but uh i think you guys But I think you guys probably get the idea. So this ribbon will pass underneath the other one, et cetera. Okay, and then to compute the number of arrows from XC to XD in my quiver, I'm just going to compute the intersection number of the cycle CC and CD in this surface that I got. And I'm not going to walk through that computation. I think I always get confused about conventions, but it's perfectly well defined and maybe not too hard if you're the kind of person who likes surfaces. kind of person who likes services. Okay, yeah, so that's how you get the quiver out. I have a little bit of extra time, so I actually want to tell you another way you can get the quiver, which I find very interesting. It's probably not too hard to show. It's not too hard to show that they're equivalent, but it feels like a very different way of thinking about things. So, okay, so to construct this quiver in a slightly different way, I still want to get my Still want to get my bicolored graph and my disks and cycles, but then I'm not going to do the surface, I'm going to do something else. And the kind of idea of this is you want to pretend like you really wish that G were a planar graph. And so you're just going to pretend as hard as you can that it's planar. I have fixed a drawing in the plane of this graph that I like the best. And so you can, I mean, you know, it's in the plane. Okay. Can I think about this just in the plane, not going to three dimensions? And so in And so, in the if it were planar, what we would do is we would put a vertex or a variable in each face, and then to get the quiver, we just take the dual quiver. And so, I want to try to play the same game here, but it's a bit more complicated. So instead of putting a variable in each face, I'm going to put a cluster monomial in each face. So, which, okay, so in which faces should I put the variable xc? Well, in all of the faces, In all of the faces that are contained in my disk that I drew. And by face here, I just mean connected component of the complement of like this particular drawing of G in the plane. Okay, so we had, remember that the disk for seven just covered this face. So that's the only place that I put an X7. But the disk for six went all the way over here. And so I put an X6 in all of those faces that that disk covers. Of those faces that that disk covers. Okay, and then again, really wishing that this were planer, I'm just going to draw the dual quiver of this drawing by putting this configuration of arrows around each bridge and crossing. These are half arrows, so you should add up the contributions of the half arrows in order to see how many arrows you actually have pointing between different faces. Okay, and so then after you do that, you end up with a picture. You end up with a picture like this. So, this is a quiver that isn't really the one you want. Its vertices are labeled by cluster monomials, and there are too many of them. So how do you turn this into the quiver you do want? Well, each arrow in the quiver you don't want between a face containing XC and XD contributes an arrow in the quiver you do want between XC and XD. And then at the end, you'll get all kinds of two cycles and maybe. Get all kinds of two cycles and maybe even some loops, and you need to cancel them. And then that gives you the quiver you do want. So, just for example, maybe I'm so let's let's look at this arrow in the quiver I don't want. It points, so it goes from a face containing X4 to a face containing X6. So that means I should draw an arrow like this in the quiver I do want. But then there is also an arrow from a face containing X6 to a face containing X4. So I also draw. Four, so I also draw. Oops, I also draw an arrow the other way, and in the end, they cancel. So, this is another way to get the same quiver. You just delete those. Yeah. Yeah. No. In general, you just get, yeah, yeah. In this example, there are lots of frozen variables, but in general, the Are lots of frozen variables, but in general, the cluster monomials will consist of, yeah, some mutable, some frozens, no inverses of frozens, of course, but yeah, the monomials can be quite complicated. Yeah, one thing that's somewhat surprising. Oh, wait, do I want to? Okay, no, never mind. I don't want to say that. Okay, so that was all I wanted to say about this. Okay, so now, so that was all. So now, so that was all the new stuff I wanted to tell you. Let me just summarize what I've said so far. So I defined these braid varieties, and then the result I told you about is that the coordinate ring of this braid variety is equal to a cluster algebra, a locally acyclic cluster algebra, though I didn't tell you why. And then kind of separately, using a little bit of this, I also mentioned you can show that the coordinate ring of a Richardson. Can show that the coordinate ring of a Richardson has a cluster structure given by Leclerc's seeds. Okay, so moving back to the braid variety, what kind of cluster structure is this? Well, the cluster tori, the special ones I talked about, are deodar tori, just defined by some greedy procedure. The cluster variables are functions which vanish on these deodar hypersurfaces, the complement of the in the complement of the torus. Deodar hypersurfaces are defined by making There, our hypersurfaces are defined by making one mistake in this greedy procedure. And then to get the quiver, I well, I showed you a couple different ways, but one way to do it is to go from your particular braid word to a surface and your cluster variables to cycles and then compute intersection numbers. And I'll just end by saying there's also some applications of this work to knot theory. So, combining our results and some work of Galoshian and Lamb, you can show that if I take a braid variety and I consider the number of FQ points. The number of FQ points of that braid variety, you actually get the Homphley polynomial of a certain link, and I guess I should say a certain specialization of the Homphley polynomial. And there's also an expectation that the cohomology of these braid varieties should give you information about some other link invariants. I think that's still pretty conjectural. Yeah, so thanks so much for listening. Thanks so much for that wonderful talk, Melissa. So let's open up the Zoom room to questions now. So if you can just unmute yourself and ask your question if you're on Zoom. Yeah, something from Roger. Yeah, sorry, I can speak instead. Yeah, sorry if I missed that, but is there any sense sort of more conceptual that? Of more conceptual that the geometry of this deodorant hyper surface gives you to deduce that if you mutate a cluster variable once, this special cluster torus character, you actually get a regular function over the whole variety? So for certain mutations, yes, the mutations that take you from one of these special seeds to another one of these special seeds. But so these are like the analog of the square face mutations for playbit graphs. For playbit graphs. So, those ones that's easy to understand. For the other ones, actually, the way that we deal with this issue is by induction. It's really easy to induct on braid varieties. You just sort of chop off the end of your word. And so, yeah, I don't, the only explanation I know for why most of the once mutated cluster variables are regular is because of induction. So, these other hyper surfaces, sorry, follow-up. You can understand well that one teacher. Understand well that uh want to chop off the last crossing, like how the pre the new the other hypersurfaces relate to the previous one, like all the inclusions and things like that. So, um, I guess I was uh you can just understand the braid varieties, like the relationship between those two braid varieties. I have not thought about the relationship between the other hypersurfaces, though that's probably also not too hard. Um, yeah, so the answer to your question, I think, is mostly no, except No, except in some very special mutations when you're just, yeah, except in some very special mutations. Thanks. Sorry, I have another related question. So you mentioned the mutations of this initial class seed. Well, this gives you some other plebigger graph as well, or where it go to somewhere else. Where to go to somewhere else? Okay, sorry, can you say that one more time? Yeah, so you start with some plebio graph like this, and you get some particular seed, right? And then you can do mutations at that seed. So I was wondering what will the mutated seed be? Will you get some other Playback graph? Yeah, so most of the time, no. I mean, just like the normal Playback graph setting, if you try to mutate at a six-valent. Um, at a six-valent vertex or you know, a hexagonal face, then you won't get another plebit graph. We still suffer from that issue. So, um, you can still, if you do a mutation at a very small cycle, like this, then you get another 3D playbit graph. But if you try to do a mutation at a bigger cycle, then you don't. But the point is, so I haven't told you about the full power of these 3D playbit graphs. We actually get more of them that don't just look like this. And so the point is by kind of in By kind of enlarging the class of graphs we can get a hold of, we actually kind of obtain enough mutations that we understand to be able to do some more powerful things. Like, for example, I think we have a green to red sequence, or at least a reddening sequence, that stays entirely within the world of the seeds we describe, which is like not the case for usual Playbit graphs. I see. Thank you. Yeah. Any other questions from our virtual participants? Okay, so let's open up the room to questions then. Yeah, just regarding the last sentence of your talk, what is the, I mean, is there a conjecture regarding the cohomology of these varieties? And do you expect to be able to recover the full homphy polynomial? Yeah, so, okay, so what I know is in the Richardson setting, which is work of Galashian and Lamb, so what they show is that the cohomology of Richardson varieties recovers maybe like two, maybe like the top graded piece of the Kovanov-Razonsky homology for a particular link. But I think there's basically no hope to recover the full thing. And so it's sort of Thing. And so it's sort of the same situation with the Homphley polynomial. We get like the top A degree term, something like that. But I don't know, I don't think there's any natural way to get the rest of it. Like it's not clear how to put A in in order to get more than just like the top A degree piece. So I am So I am not sure. I do know, okay. Yeah, I feel like I should just refer you to the paper of Goloshian and Lamb so I don't misstate exactly what they do. But yeah, I think, well, yeah, if you have ideas in that direction, I'd be interested to hear them. We'll just hand it to you. So thank you for your very nice talk. Nice talk. Just to clarify the combinatorics, could you tell us what are the simplifications when you are in the positroid case? So, what kind of difficulty disappears? Yeah. Yes, that is a great question. Thank you. So, basically, in the positroid case, what's going to happen is when I draw, okay, so I draw the braid diagram as usual, and then I go to this graph. And what happens is as long as I have a graph, And what happens is, as long as I delete all of these right tails, I'll actually just get a planar graph in the end. And what that means is that in these propagation rules, as soon as you like, I won't see any of these fancy propagations because the non-planar parts of my graph were where the disks had an opportunity to kind of slip below other strands. Other strands. And so all of these fancy propagation rules kind of like they only happen if you had a chance for the disk to slip under some strands. And so all of my disks will just bound a single face of my planar graph. And that's it. So in that situation, my cluster variables will just correspond to these really straightforward cycles. And yeah, you can just compute the quiver using the usual dual quiver. Usual dual quiver rule kind of thing, yeah. You mean that the hollow not exists in this, yes, that's correct. So you do get some hollow crossings, um, but once you like delete the tails, the right tails of the wires, um, then they kind of it gets rid of all of the hollow crossings. Yes, that's right. So that one would just kind of disappear. Um, but in this example, two would not disappear, but in the positroid case, you wouldn't see anything. But in the positride case, you wouldn't see anything like that. Oh, yeah, maybe I should. Okay. Okay, you didn't say much about the proofs. And so as you mentioned in the beginning, the difficult part is to prove that you don't have only a sub-algebra inside the coordinate ring, which is cluster algebra, but these are equal. These are equal, so how do you do that, or just yeah? So, um, we use like it's very important to us that we have local acyclicity. So we basically, I guess, use the trick of showing the cluster algebra is contained in the coordinate ring and the coordinate ring is contained in the upper cluster algebra. And then, because we know local acyclicity, those two things on the ends are equal, and so everything is equal to the coordinate ring. Is equal to the coordinate ring. Yeah, basically. So what we do, yeah, these quivers are, yeah, so we prove that we can always do some mutations that rotate the braid word. Maybe, and maybe you need to, I don't know, maybe you need to conjugate by W naught at some point, but you can kind of do a rotation of the braid word. Rotation of the braid word, and that can be done via a sequence of mutations. And what this lets you do is it lets you produce a sink in your quiver, kind of all the way to the left. And then using the occurrence of that sink and induction, you can show local acyclicity, but kind of one of the standard, like, oh, your cluster algebra should be covered by either localizing at the sink or localizing at all the neighbors of the sink. So, yeah, it's a fairly standard argument once you know that. Fairly standard argument once you know that you can kind of rotate the braid via mutations. Yeah, I don't know. This is a little bit maybe going in a different direction. But so, if I understand you well, you have this pair beta and u, and you associate the surface to it. So, is can you say what surface it is? Is there a formula for the G? Surface, it is? Is there a formula for the genus in terms of beta and u? What happens if you vary u within the same beta? Do you, what happens to the surface? This kind of question? Yeah, this is okay. This is a good question, and I am not that well equipped to answer it. So the link in the background is not just the closure of the braid beta. Instead, it's like, well, maybe there's a couple of different things you can do. Like, well, maybe there's a couple of different things you can do, but one thing you can do is you can take the braid beta, and then after it, you put a negative braid lift of u, and then you close. And I think the surface we get is rather closely related to the ciphered surface of that link, but is maybe not exactly it. I think you have to do some fussing. Like there's some natural local operation you can do to get from one to the other. And that's as much of your question as I can answer. And that's as much of your question as I can answer, but it's a very good question. That's right. Yeah, and that is the relevant link for the applications to not theory. Okay, and there's was that a okay. Sir, it was just fixing her hair. Are there any other questions? Okay, so let's thank Melissa again then. And so we have an hour break now, an hour coffee break, and then we'll get started again with Lauren Williams after that.