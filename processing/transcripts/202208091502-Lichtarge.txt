Variation like a derivative. If you interpret the algorithm as a derivative, it leads to an equation. And from this equation, you can compute the variant impact, which has a lot of good applications. So one of the observations is that you get this decaying exponential distribution of the variant impact, which looks like a Boltzmann distribution. And I interpreted that through the years as being statistical mechanics. Through the years, as being statistical mechanics in the real Bolshevik distribution. But I really didn't know whether it was or not. So I tried to figure out how to test whether it's really statistical mechanics or just a happy coincidence. And I decided that maybe I should try whether equipartition applies to my model in biology, which is completely separate from anything that put into the model. And I'll show you that, in fact, equipartition does inform the biology, suggesting that the statistical mechanical model is true. Mechanical model is true. So, the starting point is this evolutionary trace algorithm, which I developed over 20 years ago to identify protein functional sites so that you could do protein engineering and understand how proteins work. So, basically, the algorithm does mutational scanning in silicone. So, in a wet lab, you do a mutation, you do an assay, you identify a functional position and functional sites. In the dry lab, we look at sequence variation. Lab, we look at sequence variations and you couple them to evolutionary divergence as opposed to an assay. And if you do that, you get correlations between changes in sequence and changes in clades during phylogeny in phylogenetic trees. And I have lots of slides to show you that. It's like lots of work. But basically, this is a very simple algorithm, and it allows us to predict binding sites, to redesign functions using structure. Using structures to predict protein function and also to design protein peptides inhibitors. So basically, it's a simple algorithm with many applications and the question is, are there greater forces at play? So the next step is to introduce maybe some formalization of this algorithm. And the main problem that I usually work on is the genotype, phenotype. And it's the genotype-phenotype problem. So that means, given a sequence, are you going to be healthy or not? This is important because then if you're new, of course, as Chris was mentioning, you can engineer, you can cure people, but it's very, very hard. And why is that? And the reason is because the way that sequence encodes fitness is extremely roundabout. Extremely roundabout. It involves a number of hierarchy of nested network structures, each with cryptic emergent properties and described at every level of resolution by specialized mathematics that don't really feed well into each other. So that knowledge is split apart as opposed to being integrated. So the question is, what are we to do in order to describe the entire biological system as a Entire biological system as one thing. So the next step is to devise equations, but you can't devise equations if you don't have computable, relevant variables that describe biology. Not variables that describe physics, variables that describe like life, death, things like that. So we shift representation and we And we get rid of everything that's in between the genotype and the phenotype, and we say that there's a mapping, a function that maps the genotype to the phenotype. So this is really great, because this function f hides all the details. It defines the fitness landscape. The only problem is, of course, is that it's unknown. So now we need to solve f. We solve f very simply using calculus. You take the derivative of f. You take the derivative of F, which is a model for the impact of mutations, right? Because this is a small change in the genome. That's a mutation. So this is the impact of a mutation on fitness. This is the variant impact. That's the derivative of the function. And then you integrate. Okay, so you differentiate and you integrate. So what have we done? Well, we've gone from something that's very detailed yet essentially in tracking. Yet essentially intractable, right? To something that's completely abstract. But now you only need to solve three things, and that's it. You need to understand how you take the gradient of the fitness function, how you compute the size of a mutation, and you need to figure out how to integrate. And integrating is really easy. It's just summing things, right? So basically you've got to figure this this out. Do you need a business landscape to be smooth enough? Let me go back to that. Otherwise, like a spider whose web is destroyed, I'm going to have to start again. Anyway, so what do these mean? This is the landscape that you were just talking about. So every genome has a position in the fitness landscape. And when you have a mutation, the genome moves. So every mutation is a displacement in the fitness landscape. If it goes in the wrong direction, you die. So there's pushback. Die. So there's pushback from the fitness landscape. But if the mutation is okay, then it survives. So the landscape constrains mutation as if by force. But now you need to also understand what fitness truly means. So here's a young woman doing parkour. Here's some strapping young lads telling the earth. And here's the polar bear lonely on this yellow iceberg. On this little iceberg. Not fit, highly fit. Fitness is essentially the ability to do the work necessary for reproduction. So fitness is the ability to do the work. Fitness is the energy, the reproductive energy you can bring to your own life. So it's essentially energy. So that's interesting because then the fitness landscape is really a set of energy contours, right? And in physics, Right? And in physics, of course, we know very well how to deal with energy fields and potential fields. And it also means that the gradient of the fitness landscape is essentially an evolutionary force, just like the gradient of the gravitational potential is the gravitational force. It also means that if you have a mutation and you move in the fitness landscape, then you perform work given by the usual equation for work. Usual equation for work, which is force times distance. And there may be also energetic constraints on the type of mutations you can do, because in a person or in a population, we really are facing a swarm of mutations. And that mutational swarm, you might think, has statistical mechanical constraints. And you might expect that the distribution of mutations. The distribution of mutations in your population would obey perhaps Maxwell-Boltzmann distributions. So you would predict that there's exponentially fewer mutations in your cells or in the population with higher and higher energy. So basically, that's it. And what we only need to do now is to compute the gradient of the fitness landscape and the size of a displacement. So the size of a displacement is So the size of a displacement is intuitively super easy, right? Because that's a mutation, and everything I'm going to tell you from now on is a for coding variance for proteins. So here's the set of amino acids, and you know very well that some of the amino acids have very close biophysical similarities, but some amino acids are extremely different biophysically. So the mutation from alanine to valine is fairly frequent, a mutation from glycine to lysine. From glycine to lysine in a multiple sequence alignment is quite rare. So basically, you can guess that the size of the mutation from one amino acid to the next is given to you by those substitution log odds matrices. So that's how we can. Glossum. Yeah, exactly like Glossone. So we can measure pretty easily the size of the mutational mode. The really hard part, maybe, is to get the gradient of the fit. Get a gradient to the fitness landscape when you don't even know what the fitness landscape is. So, this is the fitness landscape, and this is your isopotential contours. The gradient is obviously in one dimension. It's the change in fitness for a certain moon in the landscape. And so, it is the change in fitness between this plate and that plate given. Than that clade, given a change in amino acid. But now you can actually read that plot from the evolutionary tree. So basically, if there is a move that occurs, let's say, between a chimp and a matat, whatever those are, that's going to be a small move. The gradient is going to be small. Gradient is going to be small, but if that position varies between an animal and a plant, that's a big change. So the gradient is going to be large. And of course, if it is between a eukaryote and a prokaryote, then that position undergoes a huge gradient change. So that's the correlation between variations in sequence and variations during evolution, which is exactly the evolutionary trace algorithm I've given you before. Given you before. So basically, this is almost 15 years of work to try to go from an algorithm that computes the evolutionary importance of positions and the functional size of a protein to realizing, oh my god, this is actually the gradient of the fitness landscape. Now, if you have that, then we should be able to compute absolutely everything. So it's based on a set of assumptions, which may or may not be true, and the only question May not be true, and the only question then is whether those predictions, which are testable, end up being true against experiments. So because I'm very, very short on time, I'm just going to breeze through because this is only about 10% of my talk. So let me show you the equation for variant impact, small changing genome, and mutation. Small change in genome, a mutation, the gradient of the fitness landscape, the sensitivity of the fitness, times the change, is equal to the prediction of the impact of the mutation. So there are challenges, just like the CASP competition. There's a KG competition to predict the impact of mutations by a set of predictors, and then there's independent assessors which Assessors, which are the only ones who know the experimental results. And basically, the thing is that we're not necessarily the best method, but we are consistently amongst the top methods. And the other methods tend to do good in one challenge, but then do poorly in the other. We are consistently at the top, and there's the newest results. And our method is the red one. And we do well in objective challenges. It's like winning the task competition. This is winning the The TAS competition, this is winning the KG competition. And we do well because if you look at the prediction of the impact of the mutation versus the experimental measurement over a large number of mutations, the correlation is obviously not too bad. This is true in a eukaryotic protein, this is true in a viral protein, and this is true in a bacterial protein. Now, some patients, unfortunately, have mutations in genes. Have mutations in genes that directly cause disease, like cystic fibrosis. And it turns out, of course, that our ability to predict the impact of mutation correlates directly with the severity of the cystic fibrosis based on the mutation in the CFTR gene. There's another genetic disease, Mendelian genetic disease, same thing. We can even look at p53. You might imagine that the worse your mutation is in p53, the higher your mortality rate will be. Let's say we've had an Rate would be, let's say we've had a neck cancer. This is exactly what's shown here in this collaboration with MD Understood, where we were able to identify a threshold in a set of training patients, and we found that in a different set of patients, people with P53 mutations above that threshold actually had worse clinical cores. Now, the thing is that we can apply this equation for mutations not just on one mutation, I can apply it to all of you, all of your mutations. And if I do that, And if I do that, this is the distribution that I get in 200 units. I can also do it in macaques, I can also do it in flies. And what you will observe is that basically, no matter what, it's a beautiful exponential decay, pretty much like a Boltzmann distribution. Now, those are mutations that are taken from you, like wild type, essentially, but I can also look at variants that have been identified in diseases. In diseases. And then, if I look at the distribution of variants identified in diseases, they don't decay exponentially. The ones which are pathogenic actually have a completely different distribution. So what happens is that essentially, and you can actually use that to separate benign from pathogenic mutations. This is with an equation that applies across evolution with no training. If you try to specialize the equation just to humans, Just to humans, you do a little bit better in terms of your predictions. So, this suggests two simple rules: that two simple rules: that background mutations, populations at equilibrium, follow a Boltzmann distribution of the EA score, but that trait-specific mutations from populations under selection, which are not in equilibrium, obey non-Boltzmann distributions. So, basically, what I've shown is that we can compute. Is that we can compute mutational work and variant impact, and we do as well as anybody out there. The distribution of mutations in populations follows a Boltzmann distribution. And now the question is, can we ask the difference between Boltzmann and non-Boltzmann distribution to identify genes that drive special traits, including, for example, complex traits like cancer. So the idea is that we can take mutations in p53 in Mutations in P53 in a cancer population and get their distribution. And this is a distribution of P53 mutation, the EA score, in patients with cancer. And this is totally not a decaying exponential. So that suggests that p53 obviously is linked to cancer. It's also true with other tumor suppressors. It's also true with oncogenes, where those distributions which are not peak in the middle are also non-boltian. Are also non-bozeman. So, in this way, we can identify genes that drive cancer using this EA score over a population and compared to other methods by different scores. We tend to do quite well. And we recover a number of genes that are known to drive cancer, but also a number of new genes. And the genes that we predict are oncogenes. And we can apply this, sorry, not only to genes, but we can apply this to. Genes, but we can apply this to groups of genes to identify pathways in which the set of mutations, not in one gene, but across the genes from that pathway, has a non-political distribution. So anyway, we can compare this to experimental data from the Broad Institute or with our collaborators. And basically, the things we predict to be oncogenes seem to be oncogenes, things we predict to be tumor suppressors in these two cases seem to be tumor suppressors. So it looks like. Much suppressors. So it looks like this Boltzmann versus non-Boltzmann works in a context of cancer. But maybe cancer is really special, right? So what about other diseases? So we still did another, this is a specialized cancer, breast cancer in the germline, 25 genes that may drive breast cancer in the germline of women. So that means when you're born, maybe you have a greater propensity to develop breast cancer. Develop breast cancer. So, again, we identify very nice genes that cluster together and they involve pathways that are linked to cancer. We can do that with autism. Identify a set of genes that are linked to autism. Those genes, it turns out, are linked to neurodevelopment pathways, which is no surprise. And the mutational burden that we compute with EA score in those genes correlates with the patient IQ. With the patient IQ. So, this is an example where the burden, the functional burden computed with EA, correlates with an outcome of the disease. We can do that not only in eukaryotes, we can do that in prokaryotes. So this is our analysis of directed evolutionary data in our lab, 25 genes of drive, antibiotic resistance, and all the non-drivers are at the top. Now, you can take the CS core and not only analyze it statistically, you can put it into machine learning. Machine learning. So you can put it with machine learning. So you can look at one gene at a time, all genes at once, genes in a protein-protein interaction networks, or genes over functional units and functional pathogens. So for example, we did that in Alzheimer's disease. We identified a set of genes that are dysregulated in post-mortem analysis of Alzheimer's disease brains. The genes are have pathway pathways outlined, but those genes are enriched for no information. Enriched for no information. And in wet lab work, when we took those genes in a fly model of AD, they modified the neurological phenotype of the flies, which were engineered to have technological phenotype based on amyloid. And those are genes that were not known to take part in Alzheimer's disease. The really important thing is that as we reduce the number of patients, we probe. We probe. The quality of our predictions stays remarkably high compared, for example, to GWAS. So, for example, there's a tenfold difference in quality at this point between about 250 patients, 2,500 patients. So, we can apply this technique to many, many, many, many fewer patients than GWAS and still identify the genes that drive disease and identify genes that drive risk in women and genes that drive risk in men. Drive risk in men separately because we don't need to group them. They have the power to analyze them separately. And we identify slightly different pathways in men and women linked to Alzheimer's. We can also play games because we don't need that many patients. So we can take all the patients with APOE4 that are old and really healthy, even though they carry ApoE4, which predisposes them to Alzheimer, and compare them to patients with ApoE2, which should be protected from Alzheimer, and yet still shines of. And yet, show signs of dementia. So, we take those extreme paradoxical phenotypes, compare them against each other, and we can identify genes that are modifiers of APOE. And those genes actually predict differences between APOE2 carriers who will be sick and APOE2 who will be healthy. And these patients, or those patients, were never part of our study. And still, we're able to separate them from the paradoxical patients. We can identify Patients. We can identify those genes in your part of pathways that are druggable. All the lozenges here are druggable. So we can repeat this again in other diseases, multiple sclerosis, Parkinson's, diabetes. None of this is published. But basically, we can identify and separate risk in the cases and in the controls. And this is the AUC in diabetes. Unfortunately, I'm not a penologist. This is where we're. This is where we do the worst. But in multiple sclerosis, we actually do quite well. So these data basically suggest that even though those assumptions, you may or may not agree with those assumptions, the bottom line, maybe we're just lucky. It works out that we can compute learning impact. The distributions and populations follow Boltzmann in equilibrium, non-Boltzmann if you're out of equilibrium, and this allows us to recover genes. Genes. So again, this shows that this difference between Boltzmann and non-Boltzmann is fundamental to identify the genes that drive the disease, that drive you away from the equilibrium point in the fitness landscape. But I was a little unclear, personally, about whether this Boltzmann, non-Boltzmann difference, which sounds like really great, is true. I mean, basically, I have a decaying exponential. And if I just do statistics and I know nothing. And if I just do statistics and I know nothing about physics, I have a decaying exponential, and then the other genes that don't have a decaying exponential, boom, there's a difference, and that's it. So you don't need to invoke statistical mechanics. So the question is, is this really Boltzmann non-Boltzmann or is it just like a happy coincidence that ultimately is really just fraught? So how do you do that? How do you figure it out? So I really actually thought about that for a long time. Thought about that for a long time and hit upon the fact that statistical mechanics predicts it has to be in a system that fills statistical mechanics, there's a partition of energy between all the degrees of freedom. So every single degree of freedom has the same amount of energy. So that's it. So now you can say, okay, what do you do with it? So the next step is to say, okay, what are the degrees of freedom? So the next step is to say, okay, what are the degrees of freedom in a biological system? And I decided they were probably the genes. Every gene evolves differently. So basically, you normalize the genes by their length, because some genes are big, some genes are small. You normalize it by its length, and you basically say, assuming that all the genes are independent of each other, which is wrong, but assuming they're all independent of each other, I'm going to ask their distribution of energy, that the energy of each gene be the same, normalized by lens. So that's the prediction. So that's the prediction. And that's the observation. That's the energy of every single gene. It's a distribution. It's not at all constant. It's not the same, right? So it's a big problem. I've just said that if equipartition applies, every single gene should have a value of 130. So, how do I recover from that? Well, I'm going to say for this gene whose value is 130, is 390, I'm going to. I'm going to postulate that it has a mass. It has a mass that is one-third. And the gene that would be there is going to have a mass above one. So every single gene is going to be associated with a weight. And when you multiply the sum of energy in that gene, by that weight, you're going to get they're all going to be a one-third. So this defines, this prescribes exactly how to compute mu. Exactly, how to compute μ, which I will call the mutational weight and mutational energy. And then, if you do that, you realize that everybody has a much tighter distribution of energy. It means that your energy and my energy is essentially very, very close to each other. So this was before mu and after mu, much tighter distribution of energy. The fit to the Boltzmann distribution is much better. Well, somewhat better. It was pretty good. Better, well, somewhat better. It was pretty good here, but it's even better after we introduce new. And then, if you look at the similarity of those distributions amongst ourselves, then actually we're again also a little bit tighter. So your distribution of mutation and my distribution of mutation is very, very, very similar. More similar than before. So what are the genes? What is new really in reality? What is new really in reality? So we can look at the genes that have very high scores in new, the top score in new genes. And in protein-protein interaction network, they network with each other. Their betweenness is very large. So it turns out that the most important genes cluster with each other. Now, I didn't know that a priori, right? I just postulated there's this mass, and I found the mass for every gene, and all the genes which have high mass. And all the genes which have high mass basically are pathways, they link to each other and they underlie extraordinary important biological pathways. And that's true not only in humans, but that's also true in e-commerce. The genes in humans that are diseases tend to have, that are linked to diseases, have higher mu scores. And the genes that are haploid insufficient, that are dominant, tend to have higher mu scores. Tend to have higher immune scores. If you knock out the genes that in humans are predicted to be the most important in mouse embryo, most of them die, right? Or the others have neurological phenotypes. So those genes are really, really important for development. And in E. coli, those genes turn out to be essential as well. So in the interest of time, I'll just say that there are large scale tests for a gene essentiality. Tests for a gene essentiality in E. coli. And this is, if you just, this is how well we're confused about which is which. Yes, if you just look at gene importance use frequency, you get a pretty good correlation. But if you look at gene importance with equipartition, you get a better correlation to the experimental data. So it's not that this is bad, this is not bad, this is just fine. But this is better. So mu is informative. Informative. So we can even do better. So far, I've only taken a species, I've looked at the new distributions, I've looked at the top new genes and bottom new genes. But we can also do something finer. We can take in a species individuals with a trait and individuals without that trait. And we can compute the mu score with a trait, without the trait, sorry, with the trait, without the trait, and see whether there are And see whether there are some new scores that are highly different when you have the trait, when you don't have the trait. And in this way, we can directly identify genes that we believe would be linked to Alzheimer. So we overlap with known genes that are linked to Alzheimer. More important, the genes we identify are very, very closely connected in networks to Alzheimer genes. This is a diffusion of those genes. The genes we identify networks. The genes we identify network with each other almost significantly. If you take really the top ones, they're very, very significant. This is the Q, this equal to 0.1 limit. And they network with each other in such a way as to delineate pathways in gene set enrichment analysis that are highly linked to Alzheimer's neurodevelopment. So those genes, this is the network, we've put them together here with the GWAS genes. Together here with the GWAS genes. So we have the genes that we identify plus the GWAS genes put all together. They network incredibly well and they identify clusters that are directly linked to Alzheimer, but also clusters that are linked to carbon metabolism. And in yellow, you can't see that very well. Those in yellow have only two or fewer publications in the literature linking them to Alzheimer. So the genes in yellow are essentially. Genes in yellow are essentially unproven or new. So this is two out of five are in carbon metabolism and are new. Insulin secretion, two out of four are new. Glucagon, two out of four are new. Glycerolipid metabolism, two out of four are new. Endosome, so housekeeping in the cell, four out of seven are new. Immunoregulatory, two out of four are new. Two out of four are new. And the best of all, if we have the genes that we believe are linked to Alzheimer's, then I can look in a subject, sequence them, and see what mutations they carry in those genes, and decide whether their mutational burden might predispose them or not to Alzheimer in the same way that before for autism, a higher mutational burden was associated with lower IQ. And if we do that, we can use this. We can use this with machine learning and basically separate cases from controls. And if you do it just with genes identified by GWAS, your separation is not too bad. Your AUC are remote, the curve is 0.67. But now we jump to 0.71. In the top 10% of the patients you predict, our precision jumps from 0.83 to 0.89. So we can predict a subset of patients in the population. A subset of patients in the population that are very, very high risk of developing Alzheimer's. So these data show that egipartition, which dictates how we compute mu, actually helps us identify genes that discriminate between having a complex disease and being positive. So we can identify the drivers of it. I just don't want to go over that again. I just covered it. Now, Now, mu. Mu was always in our equations. Mu was always in our equation. This is the derivative of the fitness function, and it's basically df by d gamma. But you apply the chain rule, it's really df by dB, the sensitivity of the fitness of the protein, times the sensitivity of the protein to the amino acid change. This is really the evolution trace, and this is mu. I knew that term, but I didn't know how to compute it. But I didn't know how to compute it. So when I published it, I arbitrarily put it to one, so it went away. But now with equipartition, that term, which was before undeterminate, now becomes fully determined. So in summary, I've gone from an algorithm to a derivative to an equation. And the equation shows that our mutations follow statistical mechanics. Equipartition seems to apply. And this is Seems to apply, and this is testably predicted and true. So, in math, what I've shown is essentially the fundamental theorem of calculus applies to mathematical objects, which I don't find trivial. The integration is more like a Lebesgue integral. And then in physics, basically, we can map the fitness landscape, species of Reibolts and law, drivers of special. Drivers of special field types are non-bulls and the love equipartition of R's. So all this work was done by my hard-working colleague to home and good. Thanks. So we have time for a couple of questions. Yes. Oh, let me ask you, i in in your analysis, uh can you identify what is the Is can you identify what is the position, what is momentum kind of analogy? Because I want to actually very, very nice. So, so I was saying that here's units. It's physics, right? So, we need units. So, I believe, no, I'm not sure. This is between us. So, the MH3 action, the fitness is the energy of the system, the energy for production. The MG for reproduction. So F is equal to MA. So M is mu, the inertial mass of the gene. So if the gene is essential, it's not going to be mutated. So it means that it's mutated, you die. So you don't have a record of the gene being mutated because you die. So the gene is essential, it means its mass is enormous. It doesn't mutate. And that gives it a high mass. A gene drives a phenotype, it will mutate a lot. Phenotype, it will mutate a lot to that phenotype. So that gene looks very fleet on its feet and it has very low mass. It changes quite a bit. So that leaves the mutation, which is a displacement in the fitness landscape. So this is a distance. So clearly, Et has to be an acceleration, because this has to be a force. So this is mass. So this is acceleration. So that's a So that's as far as it will go to mention. The reason why I ask is because I wonder if we can phase space with a position-like and momentum-like qualities, then there's a chance maybe you can even prove the totally. Totally, I'd be super happy to go along that path. Yeah, absolutely. Completely agree. I've been reading every night my landowner onlices. Trying to figure it out. Yeah. Okay, sorry, I had to go through I had to go through. I know a lot of you had questions, and maybe Peter. So we talked the other day about DUS. Yes, variance of unknown significance. Yes. You showed a slide multiple times where we took an eye in about the decade. Yes. Sure. So basically, those are all. Yeah, yeah, those are all categories given by others. Sorry, can you say again what we need? Sorry, can you say again what we mean? That kind of thing. Variants of unknown significance. The big problem in human genetics right now is classifying variants. So veny and pathogenic overlap considerably in with your EA. They do. They do. So you haven't solved the problem. Well. When you sequence the genome in five minutes, hold on, hold on. Hold on. You're giving me one particular bit of data, and you're saying. Particular bit of data, and you're saying that particular bit of data is not perfect. I totally agree, that little bit of data is not perfect. I can predict who's going to get Alzheimer better than anybody else in the world. So some things do work. So it's not absolute. You don't have to be perfect to be right. So that's too much of. So this is our ability with this overlap to separate. To separate benign pathogenic as defined by other people clinically. So that's competitive with the best in the world right now. Okay, despite that overlap. All I can say. It's not good enough for most clinicians, I can say. Well. They prefer better discrimination. Right, right, right. But if you can tell people at birth that they have a significant risk of developing disease. A significant risk of developing this disease or that disease that might lead to changes in behavior or this is p53. 90% of all human cancers of mutations. P53C of a really large data set. Well, with P53, we can decide who's going to have a worse cancer outcome and who's going to have a better cancer outcome. Well, and that's the question: what about the mutations in the middle, which are found in both? With the scores. With the scores, but hold on, hold on, hold on. Mutations are not independent of each other. So if you're in the middle, if you have middling mutations, then yes, I'm sorry, the genetic context is going to have an impact on how well you do. You can't escape that. There's an uncertainty principle. You can't tell me that, oh, well, you can't define P and Q perfectly, so it doesn't work. No, that's the nature of the beast. There is an uncertainty linked to the epistasis. So the Epistasis mature robots. I'm sure we're running a couple of minutes behind, so maybe we'll be able to continue the discussion. Hello everybody, my name is Francesco and today I'm going to talk about drawing information as in thermodynamics and in particular in chemical processing when they are described by deterministic reactions. This is the work I've done with Emmanuel de Penny. With Emmanuel Pinocchio and Suminian Esposito. And Siminanesposito at the University of Luxembourg. But before moving to the main topic of the talk, I would like to briefly recap some of the long history thermodynamics and information share so that I can be more or less sure we are on the same page. So as most of you probably already know, thermodynamics was developed in the 19th century to characterize the interconversion of energy in macroscopic steel. Conversion of energy in macroscopic schematics, which operate between equilibrium states. So it was formulated as an equilibrium theory and it is based on two laws. The first law is an energy balance.