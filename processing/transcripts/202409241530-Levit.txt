And the idea of Hilbert-Schmidt stability is that something that's almost a representation into unitary matrices is close to actual representation. And one way to formalize this is that for every sequence of maps into unitary groups sequence of maps into unitary groups. Unitary groups. So I'm using the local definition, not the uniform definition, such that the distance, and I'm using, I will always be using the normalized Flopers-Schmidt metric of this distance of these groups. I will not define that in this conference. So the distance here tends to zero. And this is in the local sense. And this is in the local sense, for each uh pair of elements it can happen with a different rate. Uh then uh there should exist a sequence of uh uh representations. I need not say the important thing. Here you just have any sequence of maps, and here you have honest representations, and the distance between uh the two should tend to zero. Should tend to zero. So that's the definition. And once again, I'm using this normalized Hilbert-Schmidt distance since I want to be talking about Hilbert-Schmidt stability. And actually, that's just one way to give the definition. There are several other ways. For instance, you can be talking about if your group is finitely presented, you can be talking in terms of generators and related. And relators. You want some matrices which almost satisfy the relations to be close to ones where the relations are satisfied. So you can think of the relations as certain equations. I will not restate the definition in that way, but I will just show you how it looks for the Heisenberg group. So the equations would be just the relations. The relations would be two matrices. The matrix says they are commutated with C by third matrix, and the third matrix is supposed to commute to the first two. So you can think of this as a system of equations for matrices, and since it also happens to be the defining relations for Heisenberg, discrete Heisenberg group. So looking at these equations translates to Hilbert-Schmidt stability for Heisenberg group. Okay, so that's the starting. Okay, so that's the starting point. However, in fact, I will not be using this definition almost at all, because the main point of this talk is to translate the question to the realm of characters. And I think maybe that will also be part of the team Kevix talk. And the idea is that I'm going to rely on this very nice and beautiful criterion of adding and shummer. Right, this criterion uses characters, and Cyril introduced them in his survey talk, but it's been yesterday, so I'll just very quickly remind you that a trace on your group is some function to complex numbers, which is a conjugation invariant. So it's like a class function. It's positive definite. It's positive definite and usually we normalize it at the identity to take the value plant. So that's the definition and this is from a group theoretical perspective. I define how it looks like from the point of view of the group. And these guys, they can be sometimes called complex combinations of other guys. And we also want to talk about characters of G. Of G, which would be in decomposable sorry, in decomposable traces. So whenever you have a trace and it cannot be further decomposed. And of course, the way this relates to the main themes of this workshop passes through von Neumann algebras, and I'm sure most of you know about that. But there is the Thomas correspondence. Thomas correspondence. In fact, these objects I think were introduced by Thomas, I think, in the 60s or 70s. And the idea is that whenever you have a representation of your group into the group of unitaries of some von Neumann algebra, such that the image generates the von Neumann algebra, and you have some faithful normal trace in your von Neumann algebra, then you can just take Then you can just take uh you can just compose the trace with the representation and you get a trace on the group in this crypto radical sense. And the correspondent says that this is the only way to get group characters and in this way, well, you get traces and characters correspond to the situation where the von Reumann algebra is indeed a factor. So that's like a way to see it from the von Reumann algebra point of view. Point of view. But just some very basic examples that show you the way that this generalizes representation theory and characters of finite groups, like we're doing, I guess, in undergraduate studies. So for instance, if G is abelian, then it's quite easy to see that every character is going to be multiplicative. So the space of characters is just going to be the Pointrigadian dual, right? Are in dual, right? And by Boffner's theorem, we know that every trace, every positive definite function, is going to correspond to some probability measure on the Reigning Dival. So we actually have this from using the Hochner's transform to go from probability measures to positive definite functions. So this works for Boolean groups. Okay. And this is one example. Another example I want to give. And another example I want to give is whenever you have just a finite dimensional unitary representation, you can take the normalized trace and this would be what I refer to as a finite dimensional trace on the group. So these are like at least two sources of characters for your group, either coming from the It's Abbeyonization or coming from traces of finite-dimensional representations. And now I'm going to erase this distribution and it will not come up. And it will only come up through characters theory. So, what is the Hadwin-Schulman criterion? It tells you that it only works for amenable groups, unfortunately. And it says the following: so, this is the Hadwin-Schulman criterion. Hadwin and Schulman tells you that he is amenable. It's going to be the following are going to be equivalent. So G is going to be Gilbert Smith stable, same letters. So that I'm not confused by that. And the interesting part is that every character for this group is a limit of finite dimensional ones. Finite dimensional ones. And by limit, I mean in the pointwise convergence topology. So it's a pointwise limit of finite dimensional ones. There is a bit of ambiguity. What exactly do I mean by finite-dimensional trace? Because you can either take this as a definition, or you can think about the von Neumann algebra here being finite-dimensional, and you get slightly different notions, but it's not going to matter which one I use. One I use the theorem is correct. I mean, you can use both for the theorem, and you can also use traces instead of characters here. You're likely to be fine. Right. So, what is the goal for this talk? Basically, the goal is going to be study various families of amenable groups. We're going to do hopefully metabilian and nilpotent, maybe some other groups called citric groups, and prove some of them are ill-buttoned. And prove some of them are Hilbert Schmidt stable or trying to understand when they are Hilbert Schmidt stable through this condition. And you see, there are like three parts to this. One is you definitely want to classify characters. Since if you want to approximate a character, you better know what are the characters to begin with. And then you're able to approximate any given Any given character. That would be the second step of the strategy, and the last step would be to reduce stability. And this is going to be well to do in several examples, right? And usually the hardest part I mean, well, we'll see there sometimes there are challenges with number one, sometimes there are challenges with number two. Just number two. And I want to connect this to also the serial survey. So, what is at least for me part of the motivation for doing this? Maybe Hilbert Schmidt's stability is just an excuse. You know, there are studying characters. I think there were maybe historically two different communities. There is Toma and the people who studied Seniil Poten groups. Same important groups like there was Keniov and Kerry and Moran and Bershik, and there were other people like PECA and the people who followed that who came from the direction of higher-ranked crisis. And each of these communities had developed its own tools and methods. And the idea here is to test the methods on several amenable groups and develop new tools to study characters. And hope maybe some of these tools will eventually be useful in character return. Be useful in character rigidity for going back to higher rental races, etc. So, at least part of the motivation was just to develop a set of tools. And that's why I want to show you some of the details for the proofs, so that you can sort of see which tools are handy in this thing. So, let's just start. And the first case is going to be when G is a billion, and that was of course covered, have been shown in the original paper. I have written Shulman original paper, and this is very easy since basically there is almost nothing to check. And what's safe generated a Billion, then every character, we know what the characters are, so we just said that the space of characters is a contriigan dual. So you just need to see that every character of this group is only made of ones with finite set. The limit of ones with finite, say, finite dimensional. Well, you don't even need to do that. Of course, it's one-dimensional. So you just finish off by this DRM. So that's like how powerful this Hadwin-Schulman criterion is. You get that abelian groups are rich groups stable free from that criterion. So what would be the next thing? So what Itamarinai did was to consider metabelian groups. So these are just solvable groups of the right length 2, the ones where double commutator vanishes. Let me give you some examples in case you're not so used to working with these groups. So we have groups like basically you can take K computing matrices in GLNK in GLND and let these matrices. So you just pick K. So you just pick computing matrices in GLDZ, a group of automorphisms in Z to D, and you get this group. So one thing I learned from this conference so far is that we call this a cross ZK cross CD, I would say it's a semi-direct product. Okay, then we get Bunstead solitude group. So, this is complex solidarity 1n. And you have lamp lighters, of course, just reef products and lamp lighters. So, these are all metabilium groups. And so, and just to convince you, I mean, I was not used to this before working on this project, but just to convince you how complicated this world is, you can basically take any finitely generated module over this. Over this group ring, and so just take an ideal. I mean, it's very easy to get lots of different such modules, and for each one, you would get a metabilian group. So, there's really a lot of complicated metabilian groups, and say Baumster spent a significant part of his career studying these groups. And then, what do we do? I would Do. I would like to state our theorem, but before that, I need to tell you two things about characters. One is very easy, so one is just the kernel of a character. So for a character, you just define its kernel to be just all the book elements, where it takes one. Well, a trace or a character, of course, is in general not a homomorphism, but nevertheless, it's very easy to see. But nevertheless, it's very easy to say that this is going to be a normal subgroup. So we have kernels. You can always factor a trace through the kernel. So that's one thing. Another thing we want to talk about is induction. So this is one of these handy tools that we have with characters. So we all know that from representation theory, right? And what you can do basically in usual representation theory for finite groups you can do here as well. You can do here as well, but you need some condition. So, here is the condition that we use. So, Canius pioneered this, maybe. I'm not so sure, but he definitely used this a lot. So, you have a subgroup and you have a trace on your uh subgroup and you want to induce it to the big group. So, you there is no way I mean, I I don't know how to do it in general. Know how to do it in general, but you can do it under the following assumption that phi is almost gene variant. What would that mean? So that means that if we take the group of all elements which are the normalizer of H and also the way it acts on the trace, there is an obvious action on traces, so you want it to be preserved. Preserved. Basically, if instead of plugging being an element of middle age, you're plugging its conjugate by G, you want that to be preserved. And you want this to be a finite index in G. So under this assumption, right, so I hope the assumption is clear, under this assumption you can easily induce from H to G just by averaging, sort of. So then you can, under this assumption, So then you can, under this assumption, you can find the induction of the character from H to G simply by averaging over the cosets. Let's call this group G3. So you average over the cosets. And then what you do is back by G. And this till here is the trivial extension. So you extend by zeros. So this way you get a 20. You get a trace on G, and I've induced my trace from H to G. So it works in this world of characters for infinite groups as well, and there are some additional assumptions. Now I can tell you what our theorem says for the Tabelian groups. So let G be a litabelian group, what it says, and V be a bit of a. What it says, and Phoebe some trace. So, well, it says that we can find the group which is going to be sitting between the right subgroup and G itself. I will give you some examples to see why you need to take this group H. But basically, what you do, you take this H, just think about these examples and you see what H can possibly be. And C. And phi, so first of all, the kernel of phi is contained in the derived subgroup of H, and phi is induced from the abelianization of this subgroup. So, what it's actually saying is that every character of the abelian group is induced from some abelian subgroup. Some abelian subquotients. And this is very useful because you can sort of try to see what are the possible ages. And also, whenever you know a character is induced from an abelian subgroup, you can apply Boffner's theorem to that. So what you can do, you get a probability measure, you get a gene variant probability measure. On this abundanization. So, of course, on the P2O. So, you get a G-action by automorphisms on this compact group. And you can also go the other way. You can start with a probability measure and you get a character. So, this is a description of characters in terms of basically in my abstract I mentioned topological dynamics, and this is where it comes up. Is where it comes up. So, for instance, also Beka and his work uses similar ideas of using probability measures in this way. Right, so that sort of checks part one of the strategy of classifying characters. And now I want to know whether I can approximate this. And this is where it gets more interesting. So, I want to make a definition which is purely topological dynamics. So, say you're So, say your group is acting on a compact space by homomorphisms. For us, this compact space is always going to be a compact abelian group. And we say this action has dense periodic measures. So, that happens if every gene variant probability measure. Gene variant probability measure. So that's going to be u is going to be a gene variant probability measure. I want it to be a good star limit of, you know, just some uniform measures on finite georgs. So we're going to be looking at this section and looking for finite georgs. At this action, and looking for finite g orbits, and you want to know whether any gene variant probability measure can be approximated in the weak star sense, like finite optics. And it turns out that this characterizes stability. So you get that this group G is average mix. Is Hilbert Schmidt stable if and only if every for every such possible H the action of G on the conflagrine dual has dense periodic measures and I am not going to prove it but I think it should sound quite reasonable because after all you know to even have any chance of approximating this Any chance of approximating this character, you better be able to approximate its restriction to this subquotient. And to be able to do that, you probably better continuity of the Botler's transform, you better be able to find such a sequence of probability measures. So I think this is quite believable. I'm not going to prove it in detail. And then basically the question becomes which actions like this have this dense periodic Have this dense periodic measures property, and this brings us really into dynamics. And here are just some examples. So, Bernoulli actions always have this. So, if G is just some compact set, compact space, we have sort of the Bernoulli action of G on this product space, and it's not so hard to see that this has advanced periodic measures. This is not very hard, and because of Not very hard, and because of this, we get Kilbert-mean stability for all the groups where sort of the dual to the modules that you get there are sort of the milligrams. So you get a lamp light, this will give you the lamp lighter and brief products, and also the balance solitar, where the topological dynamics is conjugated to the granuli shift, hence, there is a phiatic solenoid there. There. Right. What about any torus automorphism? So here we had to sort of dig into the literature. It depends on the properties of the automorphism. And it sort of goes back to dynamics people doing the did in the 70s, such as Boeing, Rufus Boeing, people of that time. That in these topics, that if the torus automorphism is erglotic, then it has dense periodic measures. If it's unipotent, then for sure it has dense periodic measures, but somehow it's not that easy of a question. And what we don't know, so this would give you a group like this, assuming the actions by an ergodic, given by an ergodic torus auromorphism, one without any. Morphism, one without any root of unity eigenvalues. What we don't really know is the case where you have some computing matrices, at least two of them. So for this, we basically don't know dense periodic measures. And I think probably not have time much time to talk about this, but this is related to a famous open problem in this type of dynamics, which is the higher end. Of dynamics, which is the higher-end natural rigidity conjecture of Patok and other people who worked on this. So basically this conjecture says that if this action is minimal, then every invariant measure is the hard measure, in which case it certainly has dense pervaded measure as the system. So if we knew this So if we knew this conjecture, I mean if people knew this conjecture, then it would imply that these type of groups are converted with stable, but this is sort of beyond reach for now. And I can talk a bit more about this. This is also related to the Furstenberg times two times three problem, which is also a special subcase of this problem. But I think I should move on. But I think I should move on. Any questions about this metabilian discussion? Okay, or you can ask me in the end. I want to be able to say a few more things. I mean, the point here is that we were surprised to find this link with topological dynamics. And in the end, to prove these groups out here, but should be stable, you need to tackle some hard problems. Stable, you need to tackle some hard problems in dynamics, which we know how to do in some cases, but not in all cases. So that's why we, the bottom line is that we know some metabelian groups are coverage mid-stable, but not definitely not all groups of this type. So this is a question mark. Okay, now let me talk a bit about milpotent groups. So, for Nilpotenton groups, this is one of the classes of groups that people have classically studied. So, for instance, we have Howe's theorem, and it says that Eg is probably finitely generated new potent. Possibly, he also assumed torsion-free, but we don't mean torsion-free. And phi is a character, then his theorem says that every character His theorem says that every character, well, the character might as well be trivial, so for sure you need to take its kernel into account. But up to modding out by the kernel, you can see that it's always going to be induced from the FC center of the group. So I've told you what induction means. So the character is going to be induced from the FC center, but for this to be true, you need to model it by the character. True, you need to model it by the kernel. So you model out by the kernel, and then you get this induction. I wanted to show you how to approximate this character, but I think I will skip that for the lack of time. But let me just tell you that such characters can be approximated. Can be approximated using the residual finiteness. So basically all nilpotent groups and even virtual nilpotent groups are in the infilbert stable. And what caused us the most, what was the most difficult class of groups for us in the work were the virtually polycyclic. Virtually polycyclic ones. So, what is this class? Those are virtually solvable groups. It's slightly an odd class, but it is quite natural because it's equivalent to say that the group is, I guess, virtually solvable and notarian. So, every subgroup is finitely generated. Group is finitely generated. And maybe another definition which I like even better is because of this alternative. This is going to be every amenable subgroup of GLNZ. So this is the class of groups, the virtual equalistic groups. And we wanted to apply the strategy of first classifying characters and then trying to approximate them. And for this, there were no, I think, like you were not. This there were no, I think, like you or noticed results in the literature prior to our work. And here is the characterization we obtained. It's going to generalize what I just said here for Newport 2 groups, but it's more involved. We sort of struggled to find the best way to formulate this, but we couldn't improve on what I'm about to say. So before I say this, I need to define. This, I need to define, reuse the notion of a virtual feeding subgroup. So, you know, a feeding subgroup is the maximal normal neopotent group. This is going to be the maximal normal virtual new potent group because in a subgroup, because basically in classifying characters here, we use what we know about these groups. So there's the virtual. So there's the virtual feeding subgroup, and our theorem says that if G is virtual cyclic, then first the role where G should in general pass to a finite index subgroup. But there is a finite index subgroup such that phi is induced. From the FC center of this virtual fitting subgroup for this finite indox subgroup. So this is maybe not as satisfying, but we couldn't really, I think we had a way to see that it really need all of these, this is a finite index something. So in the end, all the characters here All the characters here sort of come from the only place they can, which is the FC Center or the virtual fitting subgroups. They sort of come from this dilt of that part of your group. Okay, and once again, I don't have time to show you the details, but maybe I wanted. So maybe I'm not going to be able to keep up the promise of showing you the tools that go into this. But we can talk about that later. I will just say that here in the end, stability questions also reduce to knowing this N's periodic measures property for some family of torus automorphisms. I mean, which ones? Well, if you give Which ones? Well, if you give me your polycyclic group, I will have to analyze this. And basically, these are the ones that show up here. This will be the ones that you need to consider. So that's why we, once again, don't really know, we can't say that all virtual equal cyclic groups are individual virtually stable. But what we can say is that as a family, if this smaller family of all Of all ZK cross Zd. So these are both polycyclic and fabelian. So what we can say, maybe it's not as satisfying, that as a family, this entire family is stable if and only if all virtual equalistic components are because. Because the reason for this is that in both cases the Hildrest Mid stability reduces to sort of the same topological dynamics question. So you just need to think about these if you want to prove all virtually polycyclic groups that are stable. And let me move on to the last topic. Maybe before that, just give you at least one positive. Before that, just give you at least one positive example. So, we wanted to have at least one example where we can do something in the paper, and that's where we take O to be, O K to be a ring of integers in the number field k and I want the the rank of the units Of the units to be one. Since this is just one, you don't have any computing torus automorphisms. That's the thing. Just have one of them. And then the group of upper triangular matrices over this ring is going to be called a chip stable. Because if you basically run through this entire proof and you analyze the types of systems that show up, Types of systems that show up, they will all have sort of a rank one behavior. You will never have two computing matrices inside this guy, so we are fine. Because of the, say, yeah. Okay, so this is stable. So now, the last topic, and I feel like I'm not doing very good justice to my co-authors because I will not be able to touch upon it. Some of the ideas in our work, especially the second work of Falearn. But okay, so now I'm going to talk about the diagonal products. So I'm basically changing gears. If you have lost me, you can come back now. So this is going to be just some group theory. It's a beautiful construction, and Tiony used her as well as her work about. as well as her work about speeds of random blocks. So I'm just going to remind you or or tell you about this if you have not seen this before. It's very nice. Right, so you need to first work with some finitely generated group. So let G be a finitely generated group and I want it to be a left group. Left I want it to admit a left approximation. I wanted to admit a left approximation, so I'll define what that is. So, I'll see. So, left approximation is a sequence of maps, let's call them θns, into some family of finite groups. So, I have my family Gn of finite groups. And I have maps, just set the radical maps from my group G into those groups GN. And I wanted to. Gn and I wanted to, well, what you normally say, you want to find any finite piece of the multiplication table of J inside those groups. That means that for every G and H, these maps are multiplicative for all n sufficiently large, depending on G and H. So this is for all n sufficiently large. Sufficiently large, and also these maps are injective. Well, for these maps are injective, again, for all and sufficiently large. So that would be a left approximation, weaker than residual finiteness, I suppose. A very interesting notion. And for some technical reasons, in our work, we assume these groups are simple, pairwise anisomorphic. Isomorphic and maybe some more technical conditions, but you will mostly be working with the alternating groups, which are going to define. So what I want to do now is to define the, some people use this notation, the diagonal product. And how do you do that? So you define it to be a subgroup of the direct product. Of course, the direct product is compact, but not. Product is well compact but not countable, then the avalanche product is going to be countable. And I'm going to tell you what it is by specifying the generators. So it's a group generated, the group to the subgroup of the direct product generated by these times, generated by like tuples where you just plug in S each generator. S, each generator. So I had my finitely many generators S for my group, and I just consider that as an infinite vector, and so I get the right product by applying the map stella to each coordinate, and I take this subgroup generated by that. So this is the diagonal product, and uh it's it's a very nice construction. It takes some it's a bit uh takes some time to get used to. Time to get used to. One of its interesting properties, at least given the assumptions that we have, is the tail map. So the tail map goes like, it goes from the diagonal product into the group, the left group we started with. And there is this short exact sequence where the kernel is going to be the direct sum. So it turns out that the direct sum That the direct sum sits inside the diagonal product and it's a kernel of this nice tail map. I'm going to use T for the tail map. It's not a very hard exercise to see that you have this thing here. I think it's going to be much better to just give you an example, which was the motivating example for our work. These are the classical books of B. H. Newman. So people have. So, people have mentioned two generator groups today. So, what are these groups? B.H. Newman used this to construct an uncountable family of parvoids non-esomorphic to generated amino groups. So, in his groups, I don't think he used this language, but his groups are the above products. By the way, I did not say, but it follows from here that if G is a minimal, If G is amenable, then the Lyrono product is amenable. And I also did not say that I'm abusing notation because this notation here, it really depends not only on the, it really in an essential way, not only depends on the sequence of groups, it also depends on these maps data and we can construct, you can cook out different diagonal products. And this is also something that we're doing this work, or other people do as well. So, what is the BH Neumann example? Again, in a slightly different language. You need to start with some, you better start with some finitely generated amenable group. So, we want to work with the finitely supported alternative permutations. That one is not finitely generated, so we just add this group, which acts by an infinite shift. So, that's the group, it's amenable. So that's the group. It's amino, of course, finitely generated. And in fact, let's pick a pair of generators. So the first one is just an infinite shift running on this C here. And the other one would be a guy where you don't have any shift, but you apply some free cycle because you want it to be the alternating group. And now I need to specify the I need to specify the I need to specify the theta n's. So I'm going to be using the alternating groups operating from minus n to n. So this is an odd cardinality set. And I need to tell you what are the theta n's. So theta n takes sigma to the full cycle and then it takes tau to just You just do the tau just does the same thing. And you can check this is indeed a rough approximation. It takes some time. Maybe it's not as easy to do in just a few minutes, but here is how I imagine this group. The pH Neumann respective group is then going to be the algorithm product of these guys. And basically, the way to imagine this is that you have this shape, this cone here. This shape, this cone here, and it turns from minus n to plus n. And at the limit, you have a copy of Z, sort of limits onto Z. And you have these permutations, they act in the same way. So starting from some finite part, finite time, it sort of acts by some given permutation, say pi. But here you can have some garbage. But here you can have some garbage. So that's how we should think of these groups. I hope that gives you some intuition. And the tail map will just read off this permutation that's being applied at infinity. And this is what I call the garbage, is the kernel here. Just finitely many permutations, where you can do whatever you want to finitely many coordinates. So these are the B.H. Schneumann groups. What he did in his work was to show that, well, if you Well, if you just use some of the coordinates, you don't use all alternating groups, you just do it along the sub-sequence, then you get capital-wise non-esomorphic groups. That's how we call his theorem. Yeah. And what do we do with those? So we follow the same strategy I introduced in the beginning of the talk. So, first, we classify characters of diagonal products. Products. So we have a classification theorem, which goes as follows. So we can say that the characters... So we were quite surprised when we discovered this, because normally characters, it's not going to respect quotients or subgroups in a very nice way, but here it sort of turns out to work out well. You can think of this as sort of a Sort of a fibered space over the space of characters of the direct sum, which is by the way just a product of the character perspective character spaces with the character space of the group you started with. So that's your left group that you sort of used as a seed for this thing. And we choose a pair of characters. So it's not quite the direct product of the two. So just compare. Product of the two. So just compare this to the download. I have the quotient and I have this kernel. So this is the two guys in this formula, but they need to be compatible in some way that I'm not going to be able to define right now. And it's quite tricky, this notion of compatibility. But you can think of this as a sort of a fiber space over the space of characters of this product. So we have a character classification. So we have a character classification up to this quite tricky notion of compatibility, which okay. And then as a consequence of this, we know that if, together with the Hadwin-Shulman theorem, we know that if G is amenable and to a bridge bit stable, then this is like a This is like an inheritance type thing. It passes to the diagonal product. The diagonal product is still, well, it's amailable, as I said, and it's also much made stable. And this corollary is sort of quite easy from the classification. I don't have time to explain it, but you just approximate, once you know, it sort of splits in this way, just approximate both corresponding. Both uh both coordinates. Uh, and I only have just a very few minutes, so I want to say that I prepared to show you ideas of proofs, but I skipped all of that part, unfortunately. But you see, we have not achieved our goal was to show that the VH-Neumann groups are. VH Neumann groups are Hilbert-Schmidt-stable because Alex Trobotsky asked us if there are uncountably many Hilbert-Schmidt-stable groups. So this was a candidate. And maybe you expect that it follows, I'm about to say that it follows from this corollary, but that it's not. Because this group here is not co-reactionally stable, it's not even residually finite. And of course, every finitely generated amino group, if If it's Hilbert-Schmidt stable, then it's also residually finite. So we cannot just apply this corollary directly as is, but with some extra work, we were able to show that these pH Neumann groups are convergent stable. And since there are countably many of those, you get a countable family of amenable Hilbert stable groups. It actually also works with groups like it also works with groups like groups like It groups it it works with groups like uh like so, where you're over a finite field. So I'm not going to be able to explain this proof. Let me just say that to go to handle these groups, we had to rely on character bounds that people such as uh Larsen and Shaleb have developed for these groups. Developed for these groups. For instance, so we actually had to rely on character bounds for these finite groups, finite simple groups. So maybe I'll just tell you like what is the character bound that goes into proving that this group is over should be stable. We need to know that then I'll stop. You need to know that if sigma m is a sequence of permutations and phi m And phi n is a sequence of characters in just your common sense, in the usual sense, in the finite group sense. And these characters are non-trivial. So the things we had to, like something that we had to use was if you know that the supports of these permutations are quite large, so permutations with large support. With large support. I'll just finish this and then I'll stop. So if you have a sequence of permutations with largest support, then any sequence of non-trivial characters is going to tend to zero. So that's like a character bound from the theory of character bounds for finite simple groups. That's part of the things we had to use to get all the instability. To use to get how much instability here and now stop. Thank you. Any questions or remarks for Ian? I was kind of confused how correct stuff is to settle off and sell both the diagonal because let's say G1 equals G2 and SITA1 equals SITA2. Yeah, you're right. This is not true in general. This is not true in general, but I had some extra assumptions. For instance, I assume the groups are simple, or whatever isomorphic. So this short exact sequence is not exactly true, complete general. I see. For these groups, the assumptions are quite wild. Just basically pureways an isomorphic simple groups, and at the end, you don't want them to be homomorphic groups. Any other Can I ask just because I don't always work with a or very rarely have worked with LEF groups but if you're working in the immutable setting what's a good example to bear in mind of something that is LEF but not RF? Should be able to answer on this, but yeah, yeah, yeah. I mean, I would assume that we have an example up on the board, but I guess that's not. Okay, with some help from the audience, yes, we have this group, which has a normal and residually finite subgroup, but actually this is a left approximation for it. Okay, so let's uh thank Maria again. So thank you.