That there's some people probably some people will be joining as we roll. So let's give it a minute or two, then I'll briefly introduce the panelists and we kick it off.  Okay. All right. Let's see if everybody is here. Yeah, Jared is here too. Great. All right. Welcome. Welcome, everybody, back. So I'm very happy to have all of you here, of course, but especially I'm excited about the panelists because I think I, for one, would learn a lot. So we're happy to have Professor Seth Lloyd, Professor Vladimir Corpit, and Corpit and Dr. Jared McLean. So, Seth is a professor of physics and mechanical engineering at MIT, and he's been a contributor to all aspects of quantum computing from the early days. Many of the foundational results go back to him. Vladimir Korpin, of course, is a world expert in quantum many body systems, more recently working on algorithms, also done very nice. Also done very nice work in mathematics. And Jared, last but not least, he's at the Jared does very interesting work at the interface of AI and quantum computing. He's at the Google AI research and did his PhD at Harvard. And I really like his papers and presentations. There's a clarity to them. And so I think he would be also a great person to have on this panel. Great person to have on this panel. So maybe, actually, maybe I give you guys a chance if there's anything you want to add about yourselves. Maybe we can go one by one if you want to say something more that's introductory. And if not, it's also okay. We can just, you know, jump into certain questions. You can tell us maybe what you're excited about right now, or what aspect of the conference you might find exciting, or whatever else you want to say. Then I'll ask some basic questions. Then I'll ask some basic questions, and we'll have plenty of space and time for QA. So, Seth, do you want to add anything, say anything? Please unmute. This is a really great conference, and of all the conferences that I've attended over the last year or so, I would say this is the one that is most relevant to. The one that is most relevant to what we can do with near-term quantum computers. And addressing the effects of noise, compensating for effects of noise, looking at random circuits, which are easy, relatively easy circuits to build, though maybe not without noise. And yeah, so I think it's a very, and the questions raised by it are really great. I don't actually have an answer to the question of, you know, what's the Of what's the kick-ass application of random circuits for quantum computing in the near term? Of course, there beautiful applications to things like tomography and stuff, and the sort of thing that Olos was talking about to evaluating properties of the partition function, et cetera. But I think it would be very wonderful to come up with a, you know, a very useful application of quantum computing to some real problem like the kind in AI that Jared and I work on. And I work on that where you could apply these methods and get some near-term big win for the field. So, anybody who has it who can tell us what that is, that would be great. Right. Thanks a lot. Thank you. Vladimir, do you want to say a few words? Thank you for letting me speak. So, among other things, I also work on entanglement in spin chain and this This entanglement, the entropy of block of spins, which I mean in XXX Heisberg anti-Ferromarket, it scales logarithmically with the size of the block. I was excited by the model which Ramis with Peter Schwartz discovered. Some people call it Shormavasa model, other people call it Smotzkin model. Actually, the ground state of the model can be described by random work on the upper half plane of the square ledges. Half-plane of the square ledges, which is like Motzkin walk or Dick walk. And I don't know, that's exciting for me. I would rather stop here. Thank you, Vladimir. That's great that you brought that up. Since we have a lot of time, if there is any interest in, you know, hardness of chemistry, for example, or hardness of physical simulation, you'd be the perfect man to comment. So thank you. Jared, do you want to unmute? Sure, yeah. So I. Sure, yeah. So I don't want to ramble on for too long because this might get into some of the question topics maybe you're interested in, but I'll just pile on by saying how interested I am in the topic area of the workshop in part because I work at Google and we have these 50 to 100 qubit devices. And it's actually a bigger question than a lot of people might think. How do you even do a stable computation on one of these that gets you a result? On one of these, that gets you a result. And I think we've realized, you know, somewhat recently that we're hitting this wall with entirely unitary operations because things just depolarize so quickly. And so we have this wonderful machinery of error correction, but it's got quite a bit of baggage attached to it in the sense of what you have to do. And the core ingredient that really makes things stable is very fancy entropy reduction. And so it becomes a question in my mind if that's. It becomes a question in my mind: if that's sufficient, what's necessary? And I think the kinds of work that's being discussed in this workshop is something that can help us get to that question. How do we do a stable, interesting computation that isn't using the full machinery of just quantum error correction again? So I'm excited to hear all of the talks and all of the discussion here. So, awesome, wonderful. So, you really went ahead and spearheaded the discussion. I was going in that direction and. Going in that direction, and uh, instead of a few words about yourself, you kicked it off, which is great. So, um, yeah, we've come to realize that you know, random circuits seem to have, you know, like the power of quantum supremacy, for example. Like, we know that random circuits are the type of circuits you use to prove the exponential separation, although we don't quite have proof of quantum supremacy yet, but they seem to be the most promising. So, they seem powerful. On the other hand, with uh, I mean, in some of With, I mean, in some of my earlier works, but I'm sure all of you also, it's become clear that using dissipative systems and couplings, you can force the result of the quantum computation into certain set of states, ergodic states, or whatever. So you can kind of design and engineer the output by, you know, dissipation. And like you heard in the last talk, also the ideas of Ideas of coupling the system to a bath and transferring, so coupling different thermal states, you can cool down or do entropy reduction like Jared was just saying. So there seems to be various potentials for using dissipation and also randomness, either together or separately to do meaningful stuff. And it is timely to give this field, this Field this mentality, serious thought because of obvious reasons that we don't have quantum error correction and we have systems that are intrinsically noisy. So perhaps we can, you know, what would be great is if we could actually utilize unmodulated noise, noise or randomness or dissipation that we cannot account for, like environmental effects, if we could actually utilize them. And also, there's this possibility of engineering dissipation. There were some Dissipation. There were some earlier papers, for example, using engineered dissipation, you could do all sorts of things, like preparing frustration free ground states or doing universal quantum computation, what have you. So the first question I wanted to ask, so it is a general broad theme. And again, if any question I asked, like there is no, you don't feel like you have an answer to, they can totally skip it. It's not that, you know, there's no, it's just free discussion. Free discussion, and there will be plenty of questions, I'm sure. So, can you? It would be great if each one of you, in the same order, tell us a little bit about what you think, like reflecting on the past before we move into the future of what we could do with dissipation and randomness. Like in your own work, have you come across ideas or like in reading papers that you found interesting that we can kind of get everybody can get some kind of an understanding of. Get some kind of an understanding of in what places or in what context such mentality of using dissipation and randomness proved to be helpful for quantum technologies or quantum computation, or more broadly. Like recently, there are these discussions about black holes and holography, et cetera, which also use randomness. The SYK model is a very random model. But the hope is to keep it closer to quantum computation and near-term quantum computing. But if the situation becomes desperate, we can always talk about black holes. Sprint, we can always talk about black holes. All right. All right. Seth, do you want to? I'm sure you have a lot to say. Well, it's funny you should say if it gets later, we can talk about black holes because in my own experience, so during my PhD thesis, I wrote a paper, which never got published, called Black Holes Are Like Black Bodies. And it was this paper that basically said if you take a Har Random Said, if you take a har random pure state, that the any small subsystem of this harrandom pure state will be in an almost purely mixed state. Or if you have a constraint on the energy of the overall state, it will be in something very close to a Gibbs, Boltzmann-Gibbs state. And then I kind of got stuck like talking about how you could, how a black hole might thermalize because, you know, it's. Because it takes a very, very, very long time using things like von Neumann-Berkhoff-Kupman-Nergodic theorem for things to thermalize. It goes as one over time takes one over the smallest energy gaps in the spectrum. And so it was this, for me, this the introduction of these pseudo-randomizing techniques and all these lovely results from people like Aram Harrow about how shallow circuits can produce approximately. Circuits can produce approximate K designs and hence give you this. They're good enough for giving you this kind of entanglement and thermal states of small parts of the system, despite not giving you a hard random state. That's been very exciting for me. And I actually don't, though, I don't, I'm a slight skeptic on the kind of recent claims about Black. Recent claims about black holes and thermalization because the models that are given are really very aspirational, let's say, since we don't actually know what goes on in a black hole. But I'm happy to believe that it's something like a pseudo-random circuit. Yeah, the other place that I think is, this is work I'm doing right now with Alyosha Hama and his group. Very interesting distinctions between. Very interesting distinctions between random circuits, which are very good at creating pseudo-har random states, and then Clifford circuits, which are simulatable classically, though if you start to introduce a little bit of non-Cliffordness in the circuit, then they very rapidly become hard to simulate. And I'd just like to make a very true. Yeah, yeah. Yeah, I mean, it's right. Alyosha has and his folks have some. has and his folks have some nice things where you know you insert one non-Clifford, you insert one T gate in a big Clifford circuit, and all of a sudden it becomes almost impossible to figure out what happened. Any other comments to this very quickly, Seth? So actually we could recently prove that if you have a circuit that's near, just near Clifford, all these hardness results about sampling will carry through just the same. So you don't have to have a completely random circuit. We can talk about it more. We can talk about it more. It's very good, good. Let's come by my office since we're actually, you know, we're in the same together. So, I agree completely with what you're saying. Like, exact Clifford, you know, is in P because of the Gothess McNeil. But as soon as you have a little bit, I mean, you're just in a very, very, very close neighborhood of a Clifford. It could even be an identity circuit, trivial circuit. If you're just in a close neighborhood of it, all these hardness results kick in. Oh, that's really interesting because the experimental point I'd like to raise. The experimental point I'd like to raise, really kind of as a question for people like Jared, who have been working with big systems, is there's a kind of a funny feature that, you know, since most of the actual errors in the kind of irreducible errors in a quantum computer, like in a two-qubit superconducting gate, are actually not necessarily decoherent. So of course, that's important. But slight over-rotations and slight under-rotations of the qubits, the kind of coherent but systematic, unknown coherent errors. Coherent errors. And if you actually try to simulate a Clifford circuit, this is a real problem, right? Because the Clifford gates are a measure zero subspace of all the gates. And if you're doing a pi rotation or a pi over two rotation, but it's actually pi over two plus epsilon rotation, which is what always happens, then this kind of non-cliffordness can infect your circuit. So maybe, and so I'd be very interested in the question of, you know, when if you're doing The question of, you know, when if you're doing kind of trying to do Clifford operations, but you're getting extra non-Cliffordness in your circuit, when does this kind of your exact Clifford group theoretical calculations break down? Sounds like Ramas, you and I need to talk. Sounds great to me, always. Great, Seth. Should we, are you finished with your remarks? Should I move? remarks should i yeah i want to hear i want to hear i want to hear what other people have to say and i also want to yeah we'll of course come back to you yeah thank you so much this was very nice vladimir would you like to uh say a few words yes a couple of words i was i mean in the previous life i was mathematician so i was interested in random matrices and random matrices was discovered in nuclear physics by eugene wigner wigner in 1955 and then it has And then it has a lot of applications to description of the spectrum in nuclear physics, and also independently there is another independent application to solid state, noise in solid state. More recently, interesting application to me is in quantum optics to boson sampling. Actually, people claim that transformation, including random unitary matrices, are crucial for demonstrating the advantage of quantum version. Of quantum versus classical computation. Random matrices has also application to high-energy physics. I mean, we're talking about black hole. Black holes are officially enrolled as high-energy physics. So, random medicine is also important for application of chiral Dirac operator in quantum thermodynamics, two-dimensional gravity. I mean, I'm also excited about mathematics. I mean, I was in. Mathematics. I mean, I was interested in the number theory, I wrote a couple of papers, and the fact that the zeros of Riemann zeta can be distribution of zeros on this vertical curve, like imaginary part of Z equal to one half, can be described by a random ensemble. That's the result of Dyson and Montgomery is really exciting to me. And I don't know, maybe I should stop here. Random matrices. Yeah, yeah, there is no. Yeah, yeah. There is no, I agree with you. There is no argument with utility. I mean, the beauty, also utility of random matrix theory, mathematics and application, and more generally, randomness in theoretical computer science. There is this beautiful lecture by Avi Wiggerson, who's Abel Prize lecture, which is about randomness and pseudo-randomness, where he talks about all sorts of applications randomness has, practical applications. My personal, sorry for interruption, apologies. My personal. Sorry for interruption, I apologize. My personal involvement was like taker and the metrics to try to try to calculate the probability of formation of a large gap in the spectrum. That's what I've done. But sorry, Ramis, I apologize. Yes, yes. No, no, please. Yeah, yeah. So Vladimir has done, I mean, the core pin determinants and also his amazing work on exactly solvable models, like the reference book for integrable models, beta and zots, et cetera, is work of Vladimir Korpen. You know, Vladimir Korpen. So it is, yes, I agree. Like, there's plenty of interest for it. Can I make one short remark before I quit coming? You do, yes. There is several publication models, and since you mentioned complete integrability, so other word for complete integrability is betanzas. Betanzatz is the eigenfunction of this xxx model, which was mentioned in the previous lecture. So there are a bunch of lectures, bunch of work. Lectures, a bunch of work in the archive: how to input the better and such wave function into the quantum computer in the QISKIDs. And there is like exciting. It's not random, but still about quantum computing. Sorry for interrupting. That's the end of my remark. No, no, we have plenty of time. I'm glad that you make these remarks. Okay. All right, great. Thank you so much. Jared, would you want to say a few words? Yeah, maybe. Yeah, maybe I'll make my remarks in the form of a story of a kind of failed experimental exploration of mine that invoked some dissipation and some randomness. So, you know, if we're talking about how we might want to implement some of the first dissipated circuits that are kind of stable, that aren't just quantum error correction, you might try to be leaning on your intuition from error correction. So there's, if you ask what the So, there's, if you ask what the easiest to correct codes are, these kind of fall in this category of self-correcting codes, which are codes that you just put them in some thermal environment and they kind of repair their own errors. And so even if you don't care about self-correction, this is some proxy of like how much sophistication you need to remove entropy from a system. And like above this, there are locally correctable things. So things with cellular automata decoders that work well. This is connected to, say, That work well. This is connected to, say, single shot stuff. And then above this is more complex things where you need to aggregate global information to really remove entropy effectively, like a minimum weight, perfect matching decoder. So we say, okay, let's start with the easiest thing, self-correction. And quickly you learn that most people don't believe that self-correction matches like a 2D grid, but you're still, you want to do an easy experiment first. So there's 2D classical self-correction. You're like, if I can't self-correct a classical code, even with dissipation on my device. Even with dissipation on my device, probably can't do quantum either. So you set up your like 2D icing ferromagnet, you do something like a digital simulation, say, of a self-correcting code, and hope the noise from the environment kicks you back into the right subspace. In fact, I think someone told me at some point, Seth might have written a paper about this, but despite my furious Googling, I couldn't find the reference work and it was just a numerical experiment. Anyway, so if he remembers this, I'd be happy to hear from him. But to make a long story short, To hear from him, but to make a long story short, you just digitally implement a self-correcting code. It turns out that, like a classical, you know, ferromagnet, there's some temperature below which it's stable. And depolarizing noise in a quantum circuit actually looks like a tiny coupling to an infinite temperature bath, and it kind of ruins you and you don't get it. And you're like, okay, well, next step, I'm going to couple it to a bunch of qubits I can reset and keep resetting them like a cold bath. Can I out-compete the noise? Will it like work out? Compete the noise, will it like work out? It turns out the form of couplings that we use, we didn't really do a numerical experiment to see if there was a threshold, but nothing we could actually reach could cool it fast enough, even with interlaced qubits all being reset, to really have a measurable self-correction property on the real chip. And so that's kind of maybe now you might ask, well, how does this connect to randomness? Well, if you write down like a classical icing model that's self-correcting, all of the gates commute. And so you could. The gates commute. And so you could just choose time steps which happen to be, say, pulsing the stabilizers on and off randomly, which starts to look like some kind of Xeno experiment, like things that Sergio worked on in the past, that random evolution is like measurement. And you can attempt that as well. But the secret is like the noise in the background is your non-commuting element that you can't see. So there is some element in which you have to have trotter steps, even in a commuting Hamiltonian, to realize self-correction. So this has been a long story. So, this has been a long story to say that maybe a first step in stabilizing a quantum computation, if you want to do it, not error correction, is to stabilize a classical one on a quantum device. And the most, the simplest thing you can try doesn't immediately work. That's not to say there's a trick that can make it work, but that's my story of a failed experiment. It's very awesome. So, it's actually interesting you say this. You know, like usually, when you want to saturate the parameters in Saturate the parameters in error correction, like classically, you know, the Gilbert Veshamoff bounds, or even in communication. Usually, the way you saturate them is you assume you have random codes. Like the generic things just do the job. But somehow finding like single examples can be very hard and like doing it in application are very hard. In this particular case, do you happen to know if what you're saying has been done for? Maybe you answered this already, for classical codes, even? Classical codes, even to use randomization to stabilize them. I think you said no. I don't actually know. I mean, part of the problem is the classical literature doesn't have as much on faulty gates as, say, we do. They often assume that like operations are noiseless and communication is noisy. And we have to kind of deal with both. I mean, that's, I think it would provide a nice foundation if results there were easier to get for what we would expect in the quantum case, but we don't have. In the quantum case, but we don't have as much to lean on there that I've seen. It might exist and I might not have seen it. Very cool. Very cool. Yeah, I mean, it's always been an interesting puzzle. Maybe somebody can give some intuition for it, for why, you know, you can prove so easily using random stuff, you know, awesomeness of the underlying code or what have you, but somehow it's so hard to just nail down a single example you can prove anything about. But I think Seth has something to say. I'm looking agitated. So I'm actually writing, doing agitated so i'm actually writing doing a uh for the santa fe institute i'm doing uh an annotated version uh with introduction of shannon's um a mathematical theory of communication and he says something really rather great about this you know because he he introduces these random codes and he says he says they're um look we can prove that almost all codes work really well but we can't find any individual ones and then he says something which actually since it was 19 Which actually, since it was 1947, I guess, he really presages the introduction of algorithmic information and scrambling. He says, probably the difficulty here is that it's difficult to set up small classical procedures or circuits that construct things that are truly random. Interesting. Very interesting. Can I comment on it? I'm not sure which paper. I also not clear what paper I wrote that you're referring to either. To either. But there is, I mean, this is a really interesting question, and particularly for you folks at Google and other people who are trying to build quantum computers, is that fault tolerance with threshold theorems, the noise models are really not very accurate because there's all these coherent errors and correlated errors and things like that. And of course, one goes in and uses correlations in time to do things like spin echoes to filter out noise that's highly. Throughout noise that's highly correlated over long periods of time. But I wonder if there's waiting for us a kind of continuous time error correction model. All these codes, Paulo Zonardien paper from a while ago from showing that basically all quantum error correcting codes, including topological ones, operate by mapping your quantum information into a noiseless subsystem. They act on symmetries, right? They induce an effect. Symmetries, right? They induce an effective symmetry. And then the noise acts on the complementary subsystem. Your quantum information is protected, and then you map it back in kind of a discrete fashion. So there have been a few, I think, failed attempts at this, but it would be very interesting to see if one could actually, you know, work out some kind of continuous time Limblad operator-based self-correction of the form that you're talking about. And maybe you're going to talk about that actually tomorrow. Talk about that actually tomorrow. So I don't know if I'll talk about that, but if people want me to. Very interesting. And Vladimir, how about you? Like have you come across randomness in the context of I'll take Fifth Amendment, you know. You take Fifth Amendment on this one. Well, you already hear. Well, you already talked about how you're fascinated by random matrix theory and its application. So I guess you have answered it. Let's see, there is a question in the chat. I work in the applied quantum machine learning area. I have a question about the uniqueness of the probability distribution generated by a quantum circuit. Are they just extensions of classical distributions, or should we expect really different families of distributions? Families of distributions. Anyone working in this area? I think we all are to some extent working in this area. Yeah, so I asked the question because, you know, we often talk about Nicole Barber, right? Yes, Nicole Barberis. And I work at IonQ and specifically in kind of the classical machine learning realm and quantum machine learning. quantum machine learning and so we often ask you know we often tell our clients and we're working we say that um uh you know the wave functions you can think of them actually as a probability distribution but they're complex and we have negative values and so it's a generalization of a probability distribution and i was trained as a statistician and then got into the machine learning field and i've always been very interested in the statistics Very interested in the statistical and probabilistic nature of quantum computing. And so I've been looking to see if, you know, so my question is, do you as experts expect to have new families of distributions? For example, in the classical realm, we have the exponential family, right? And then you have a whole series of distributions that fall into that exponential family. Do you expect the same kind of Do you expect the same kind of thing in these unique distributions that we get from a quantum circuit? Or is that not even a meaningful question? So your question is, do we generate certain distributions that we don't have names for, but are nevertheless interesting? Yes. Exactly. And are there hints that there are families of distributions out there? So, I guess one thing one could say is every time you run a quantum circuit with any specific gates, you do generate a distribution on the outputs that, depending on the choice of gates, it could be some distribution, whatever it may be, and may not fall into any particular class. But if you do have random circuits, then depending on the type of local gates, you know, like for example, the quantum supremacy, you expect the Porter-Thomas distribution. Distribution. But I guess I'm not the one who's supposed to be talking much. So maybe somebody else can say, yeah, if you have random circuits, they may reproduce famous distributions and they may not, I believe. But I'll leave it to other more well-informed people to comment. I don't think you're less well-informed than the rest of us here. So good to see you, Nicole. That's a great question. And I mean, of course, if you have random circuits, like even shallow depth random. Circuits, like even shallow-depth random circuits, exhibit these pseudo-random states, which are quasi-har and characteristic. And then they have this feature that the individual parts look very mixed. They exhibit quantum supremacy or advantage. There are some things that's useful for them. What would of course be great, and I just certainly don't know the answer to this, and if anybody does, it would be wonderful to hear it: whether these kinds of relatively small quantum circuits can create. Circuits can create probability distributions, which in some way match up stuff in the real and classical world in a way where it's hard to produce them without a large classical computer. So it's really the non-random circuits that would be are interesting here. And that's like some sense a real question about quantum machine learning, right? Is it, you know, with, can we do quantum machine learning with relatively small scale devices like Relatively small-scale devices like INQ's beautiful systems, or Google's beautiful systems, or IBM's beautiful systems. And then that's the $64,000 question: whether we can come up with non-random quantum circuits that somehow match features of classical data that are very hard to do otherwise. Because there's plenty of things that are hard to learn, types of data that are hard to learn on a classical computer. Yeah. So I don't know. Yeah. And then we would, and then from there, we would, you know, I don't know, I can think of, you know, how we have parameterized families of circuits or of distributions. So it might be that we discover that one distribution that matches this type of data, and then we can tweak that and use it for other use cases. So that's exactly where I was headed. Thank you, Seth. Can I give? I'm just going to toss this out there, but, and I don't know. But and I don't know if this would work at all. I mean, one thing that this is not about quantum supremacy, it's really the fact that in quantum states, you know, you have more entanglement gives you more correlation than you're allowed to have classically. And so there's been a bunch of nice work recently about using quantum Bayesian networks. So if you take a Bayesian network and you do it in a coherent quantum fashion, then the different parts of your circuit. The different parts of your circuit can have a higher degree of correlation than you can have classically. And it might be that you can capture causal features, which is what Bayesian networks are supposed to do, better using quantum circuits than classical circuits. Ah, interesting. Okay. I don't know, but I mean, it's possible. Yeah, yeah, with quantum Bayesian networks. Okay. All right. Thank you. Yeah. Maybe I'll mention from a related, but not exactly the same. Related, but not exactly the same point of view. There was this paper. You know, I guess anytime you ask about a difference between the classical and quantum probability distribution, there has to be inherent in there some kind of restriction on the quantum circuit. Like if I use low depth random, you know, does this correspond to needing a lot of power to do this classically? Because if you just had arbitrary power on either side, you could always reproduce it. And along these lines, one of the Reproduce it. And along these lines, one of the simplest setups I know of that shows a separation is a paper that Sergei Bravi is on, where he talks about rather than probabilities like functions where you get a separation between constant and log depth by leaning on non-locality in the graph state. But actually, if you go to the conclusions of that paper, they leave as open questions what this means for classical and quantum probability distributions. Because often when you use non-local games as your Games as your crutch for kind of showing a separation, sometimes those can kind of be exceptional from the point of view that only at these specific measure zero points do you see a difference and everywhere else like classical kind of works fine. And so he leaves it as an open question and even suggests a proof technique of how one might show the difference using like entropy-based bounds. But to my knowledge, no one's actually gone into the conclusion and then completed that. So it's like one avenue is perhaps looking at functional differences. Perhaps looking at functional differences, but that on its own might not tell you about the whole probability distribution. So that's kind of an interesting anecdote. Yeah, yeah. And that's an interesting hint that maybe, you know, entropy measurements would shed some light on that. Yeah. Thank you. Anyway, and also, you know, for the for Jeff and for Samis, you know, thank you very much. I think this is a great one. I think this is a great when I saw the advertisement on LinkedIn, I was like, yes, I'm going to go to that. So I think it's a great focus area within quantum computing, just the probability discussion. Thank you so much. About the question about probability distributions, which so I don't really know what comes out of quantum circuits, but I think it's useful to have, like, if you think about the classical families of probability distribution. If you think about the classical families of probability distributions, say you know, exponential or Gaussian, they all sort of have they come out of sort of different scenarios, right? Gaussian distributions come out of the central limit theorem and they're universal for that. And exponentials come from sort of waiting process, you know, right, you know, waiting times independent, independently, you know, Poisson process, you know, as exponential times. And it is certainly the case when you sort of, you know, you start looking at the development of probability theory that new Probability theory that new, you know, very new structures do lead to new distribution families. So, the thing that came to mind when people were talking is the random matrix families and the Tracy-Woodham distribution that describes the eigenvalues at the edge, which prior to its sort of people exploring its properties in the 90s was not an identified sort of family of distributions, but now it is something that exists. And I think, you know, in that sense, And I think, you know, in that sense, right, of course, from a mathematical standpoint, these are all just probability distributions and they're all just probability measures and there are many such things, you know. But from the standpoint of having a parameterized family, I think one, of course, if you develop some new structure, it's not unreasonable to think that there are going to be new families that emerge from that after the sort of dust settles and you look at it. Oh, interesting. Yeah. Good. If I may comment on your comment, Jeff, what's special about all of these distributions, like Gauss and the random matrix distributions, is that they themselves define universality classes because there's a stability of these distributions with respect to some operation. And I'm not sure whether I see this here. Whether I see this here, whether there are universal distributions in that sense, that there's a stability result. That's that's yeah, I agree. Yeah, um, yeah, that's a good point. Well, some of the hard, I mean, we can say some things, like some of the hardness results hold for neighborhoods of circuits. So there is some. So, there is some stability with respect to imperfect implementation of local unitaries. But most of the distributions we understand and we try to cast the answers to come from the classical world, like for the Thomas distribution or what have you. Because it's hard to access the direct, you know, like every time we make a measurement, we get a string. It's hard to access the probability distribution. It's hard to access the probability distribution directly to explore the space of possibilities. So it goes to Nicole's point, actually. You started a very good discussion, Nicole. Thank you. I mean, of course, you know, there are lots of well-known quantum distributions for things like eigenvalues of eigenvalues of different kinds of Hamiltonians, of course, dating back to Vinger-Dyson distribution. And then these things are known about their stability. Things are known about their stability there. And actually, lots of good questions about that. For example, there's an open question that my former student, Bill Kaminski, and I are working on for quantum annealing, which is, you know, in quantum annealing, you have an initial Hamiltonian, which is just all x's, and it's got a Gaussian distribution of eigenvalues. And then you have a final distribution, which is some like, you know, random-looking Ising model. That's got a Gaussian distribution of eigenvalues from the central limit. Gaussian distribution of eigenvalues from the central limit theorem. And then the question is: does the distribution remain Gaussian throughout, right? So even at the minimum gap? Because if it does, then actually you always have the number of eigenvalues that are within a constant factor. For example, the temperature of the minimum energy is actually constant. It actually doesn't even depend on the size of the system, which would explain why quantum annealing works well. Why quantum annealing works well, but those are things that are hard questions about random matrix theory. So, well, thank you, everyone. I need to drop at the top of the hour for a work meeting, but I just love this and thank you very much for the answers. Sure, we're all an email away. Yep. Thank you, Nicole. All right, so there's another question on the All right, so there's another question on the chat that I have to answer too. But so I guess my next question is: well, first of all, like you're welcome to ask questions from each other as well. I think there's a question from Mario in the chat. Oh, is that right? If you go before Sergio's comment. Oh, great, great. Thank you so much. Yeah, there's been a, it's hard for me to multitask. So maybe, so Mario Sagetti asks, thank you, Mario, for the question. In complexity theory, we call randomness. In complexity theory, we call randomness a resource. So, in complexity theory, we call randomness a resource. While in quantum computation, randomness is a curse. It actually rhymes. Whether it is a curse or it is a resource, does it depend on the quantity of noise, the type of noise, the way that we cannot control it, or that because in quantum computing, unlike in classical, we have not learned yet how to explain. We have not learned yet how to exploit randomness to our advantage. That's a great question. So I have a personal thought with respect to this question, which people are free to disagree with. But one of the reasons it's been so hard to introduce and use controlled randomness, at least within the context, Controlled randomness, at least within the context of traditional unitary algorithms, is that unlike a lot of algorithms, say if you were doing just classical simulated annealing or gradient descent, you introduce like a controlled amount of randomness, like a bit flip or something like that. But then in consequent steps, you quickly lose that as you descend like an energy landscape. So many states go to one state. And so you're able to introduce a controlled amount of randomness that doesn't affect you that much. Doesn't affect you that much. When your circuits are entirely unitary, as soon as you introduce a little bit of controlled randomness, it never goes away. Orthogonal states have to be mapped to orthogonal states. If the rest of your algorithm is entirely unitary, a single amount of randomness will always take you to a different answer. And so this makes it exceptionally hard within that mindset of algorithm design to tolerate any amount of noise. Whereas a lot of classical algorithms, say in machine learning, stochastic gradient. In machine learning, stochastic gradient descent, simulated annealing, noises helpful, even or just part of the game. And so that's something to think about. Wouldn't that kind of point that open quantum systems should help, where you skip the unitarity. Yeah, so I would tend to agree that open either. Tend to agree that open either open quantum systems or design of algorithms within a non-unitary mindset is helpful. And I think the tension right now is that people are hesitant to throw in any amount of open system because keeping the same mindset as, say, random quantum circuits or computational problems there, there's a feeling that maximizing entanglement and maximizing unitarity is the closest path to classical hardness, and we want to maximize along that. Hardness, and we want to maximize along that trajectory. But the risk is you go too far and you enter this regime of over-entangled and super-sensitivity to noise. And there has to be maybe some Goldilocks regime in the middle where you're attached to a bath, the system is still entangled enough to be hard, but it's not so entangled as to be exponentially sensitive to noise. And like, I don't know exactly how to shape that regime, I guess. Is it clear that this regime exists? Regime exists? I would say that maybe error correction is a constructive example of a contrived version of this. Whether it exists in a pure algorithmic framework without just pumping entropy out, I'm not sure, but I think it's an interesting question. That is, that's- Oh, sorry. Oh, no, in the spirit of like brainstorming for this, I wonder. Storming for this. I wonder if it's possible to, if you introduce noise into a system which you know how to correct, that you could mitigate the effects of noise that you don't know how to correct. That is like your good noise drives out bad. And I'll also add something, Seth, because it's just following what Jeff and Jared were saying. And that's a great follow-up question because that actually goes into the future of what we could do with randomness and dissipation. So there is this limit where you think if you make things very classical, it becomes easy. Like you make it very non-unitary or what have you, it becomes very easy. But some of the numerical studies recently have shown that even for constant depth circuits, if you make certain truncations, say, and you make the local gates non-unitary. And you make the local gates non-unitary, the output always turns out to be hard, even when the unitary circuit is easy. Even when you expect that the unitary circuit is easy, some of the non-unitarity kind of pushes you in a harder regime. And, you know, unlike what you might expect that, you know, okay, I just chop things off, I introduce some random, unaccounted non-unitarity, and maybe things will start acting more classical. But, you know, it's surprising that some. But you know, it's surprising that sometimes actually it's the other way around. Things turn out to be harder. Like when you try to do your tensor contractions, get a particular precision, you realize that the time it takes is just like exponentially more than it would have been if everything was unitary. Anyway, so that's just a side comment I wanted to add. So there is a, there is a, Jeff, you asked me, are you sure there's such a regime? It seems like a pretty rich regime. Now, whether, you know, whether you're asking exists or not, I don't know. Yeah, no, I mean, it's just the worry. I mean, it's just the worry that I, right, that you want to introduce some openness to sort of stabilize things, but not so much that everything turns classical, right? Which presumably, if you do too much, if there's too much decoherence, then it's back to just classical physics, basically. So. Yeah. So, Steph, you're muted. I wanted to go back to you right now, please. I wanted to go back to you right now, please. So, there are examples where introducing noise into the system can help, right? So, there's this paper that Lorenzo Viola and I wrote a long time ago that shows, you know, it's a pretty simple result. It says if you introduce random unitary transformations and they're selected from a particular group, right, then you automatically stabilize the states which lie in the commutant of and operators which lie in the commutant of that group. Operators which lie in the commutent of that group. And this, in fact, if some of your errors can be reduced, and sometimes some of your errors can be reduced in this way. It's like, you know, it's a induced, you induce a decoherence-free subspace or a noiseless subsystem. So, can you summarize the result again? You said you introduced. Result again, you said you introduce. Maybe, maybe I won't try to say it. Can you say, yeah, yeah. If you, if you, if you just suppose that you have a quad of system, right, and then and then you just add, you have a group of transformations that you can apply, and you just apply random elements of that group then to your quantum state, right? Then yeah, that's right. So that then this is a filter and it induces because you're inducing random noise in. It induces because you're inducing random noise in this group, then the dynamics which is which is it filters out dynamics that doesn't commute with the group, whereas quantum information that's stored in the noiseless subsystems, which are in the commutant of the group, is just left alone. Interesting. Very interesting. Is this something that you think of using for sort of globally conserved quantities, or are these transformations something that should be more local? I mean, like, that's a far more technical question that I probably should be asking right now, but I was thinking there's sort of two options, right? You could have sort of some conserved charge for your whole system in some group that's, or there's some sort of like local gauge symmetry that you're trying to. To rotate things with, yeah, that's a good question. I don't know. I mean, if you do things locally, right, then stuff that's elsewhere commutes with that, right? Right. That you don't necessarily doesn't necessarily protect the stuff that's that's elsewhere. Yeah, that's that, but this actually, you're right. So, in fact, this global, yeah, if you have some kind of global charge symmetry or something like that, and you can somehow And you can somehow enforce something of that sort, then that could be helpful because then you introduce when you have a global symmetry, you can introduce these super selection rules in the system. And then presumably noise that tries to violate the super selection rules will be filtered out to some degree. I don't know. I'm just making it up here. Cool idea. There's something in the chat. Thank you, Mario. I think Mario said Eli. And you know, yeah, Mario, thank you so much. It's just Yeah. Yes, if, yeah, Vladimir, you wanted to say something? No. Actually, we're going to come to you because there are some people on the call who would be very interested in your thoughts about ground state simulation of physical matter and hardness for that. I just want to make sure that we run out of the like, I don't want to break the conversation, but what we're talking about right now. So, what we're talking about right now is pretty interesting, and I want people to have time to ask questions and stuff. But I very much look forward to the entanglement content of space chains, etc. Does anybody else? Yeah, please. I mean, are we making closing remarks for the discussion or you want me to talk more about the ground state simulation? I'd like to wait a little bit. I understand. So, I wanted to make remarks about the previous question, which was maybe the second question about different probability distributions. So, when we was running our modified quantum search on different hardware, I mean superconducting qubits and iron and ion traps, ion traps. I clearly had the impression that the noise distribution. That the noise distribution, the probability distribution of noise of arrows are different for these physical devices. So it will be difficult, interesting to make a prescription that some specific noise distribution for superconducting and some other noise distribution for ion traps, because that was my impression that they're really difficult. I mean, that's not the answer, that's a question, but anyway, that's what I wanted to say. With this, what I wanted to say. The type of noise you encountered in different architectures was tremendously different. It depends on the physics of these devices because supercontact is a macroscopical thing. I can buy Josephson junction from a company for a dollar and I can grab it with my fingers, right? On the other hand, iron trap is just really macroscopical, like one iron seven. I mean, this is really, truly microscopical. And the physical difference leads to the different probability distribution of the noise. Maybe this should be studied in more detail. That's, I mean, open question, open question. To me. Well, actually, I think, no, this is an interesting question. I think Jeff suggested a question along these earlier. Yeah. So, yeah. So, Jeff asked me, you know, maybe a question I could ask is: how do we model noise? But I think this is a pretty general question from the different directions. So, I think noise, you know, by training, I'm physicists. So, I'm afraid that the model of noise will depend on the physics of the hardware. That's what I'm saying. Of the hardware. That's what I'm trying to pronunciate. Yeah. Well, that's certainly true, right? And it, I mean, for instance, you know, superconducting qubits famously exhibit a combination of one over F noise, which at a certain, one over F noise at low frequencies, which then gets taken over by ohmic noise at higher frequencies. So and so it's quite colored noise. And it's actually a It's actually: if you're trying to simulate an open quantum system on a quantum computer, then if you're lucky, the noise on your quantum computer will end up being noise that might be realistic noise for your quantum system. But of course, that assumes you get lucky. I wonder if there's a way for doing quantum simulation. If you suppose that we have a quantum computer that has a specific kind of noise, I wonder that's, you know. I wonder that's not very device dependent. I wonder if there's a way to say we can also do a quantum simulation while kind of massaging the device-dependent noise to turn it into the kind of noise that we actually want to have in our system. Let me ask you, is there other universality classes for different noises? Noises. I mean, there is this stochastic independent noise model that you can apply to every qubit independently. But I think you're asking for something. What I'm driving to is, is there kind of, can you put the different noises into different classes? Yeah, I mean, well, I mean, Yeah, I mean, well, I mean, it says, as Vladimir was saying, that different systems have different kinds of noise, like, you know, this one over F noise, which for superconducting qubits, which is a ubiquitous thing, you can never quite get rid of it. And then, you know, when you're in quantum optical devices and operating with single photons, then you have things like shock noise, or when you create continuous variable EPR pairs, you have higher photon numbers which leak into things. Photon numbers which leak into things. So, in each individual kind of system, you can try to characterize the additional kinds of noise, which may be quite common for that particular type of device. Maybe I'll just add on to what Seth and Simone are asking and talking about, which is to say that there are different classes of noise, and then there's the second question of: say, And then there's the second question of: say, you're doing an open quantum system simulation, and what is your capability to map the natural noise of your device to, say, the behavior of the bath? And this has always been a question that's been on our mind for physical systems we're interested in. And you can kind of look at an example where this sort of works out, which is, you know, quantum annealers have many flaws, but one of their strengths is they're a more direct physical implementation of the thing. Implementation of the thing that you're looking for. So, noise is closer to what you might expect noise in a system to look like, in the sense that when they fail, they fail in like a local ground or local eigenstate of this Hamiltonian and might reduce to classical annealing, but it's not like the gate model where when you fail, it's typically total randomization after you do many gates. And there's a question of if within a gate model rather than an analog model, you can sort of orient the noise towards. You can sort of orient the noise towards your preferred direction such that it matches something you have in the model. And I don't know of any direct results ruling this out, but there's kind of tangential results that suggest it might be difficult in this field of what's called bias-preserving gates, because people figured out that if you could very much structure the noise that's happening in your system, error correcting codes and decoders can take advantage of that and perform much, much better. The only problem is once you start doing The only problem is once you start doing typical gates, you know, you're rotating the state and axes of the qubit states rather than the device itself. And so as you have one type of noise, you change to the other axis to do an operation and it tends to spread your noise throughout the system over all the axes. And so it becomes this art form to create what are called bias preserving gates. And there are kind of proofs that you can't do it with qubits, but you can maybe do it with Qdits. And this is related to Amazon's kind of cat Q. Related to Amazon's kind of cat qubit effort and an attempt to have like bias preservation, so kind of keeping the axes of your simulation, even in a gate model, close to the axes of noise that you have. But it's kind of a non-trivial operation, and I think sort of an open question how generally one can perform these acrobatics. Very interesting. Can I have the follow-up? Can I ask a follow-up question on this? Please, yeah. I'm wondering, how much do we actually know what kind of noise is in various machines or how much it is just our guess? I mean, for example, remember about annealing, a long time ago I read the paper of Zurich that they were like running a very simple integrable computation where you can compute what is the non-adiabatic, what should be the non-adiabic. What should be done on adiabatic amplitude. And then they were like trying to guess what noise would explain the result, which is not the same. And I don't think there was any conclusion. I don't think they could figure out any noise that would produce the result. So, how much do we actually know what is the noise or just are guessing what is the noise? Interesting. That's an interesting question. I guess, yeah. I mean, of course, the people who are building quantum computers work very hard on characterizing the single qubit decoherence times. And indeed, for working with superconducting qubits for the last, I know it's like 23 or four years or something like that. You know, you know, your superconducting qubit is heading into a good place where it's not dominated by one of ref noise if T2 For the qubit is twice T1 for the qubit. That means your qubit is interacting in a kind of very pure way with its environment, and you can model the noise in a thermal fashion. In other places, you don't know what's going on. And one of the main issues in making very good two-qubit gates is that when, in order to make a two-qubit gate, you know, the qubits on their own, you try to keep them in this kind of sweet spot where they have the absolute minimum amount of noise and decoherence. But in order to do the two-qubit gate, Coherence. But in order to do the two qubit gates, you have to move them away from that sweet spot and then back again. And consequently, the noise gets quite complicated when that's there. And people do a lot of effort to try to do, you know, process tomography for just a two-qubit gate. And then when you have more than two qubits and you have problems like crosstalk, which is, you know, actually, we're now on our, on our, maybe our third generation of like 50 to 100 qubit quantum computers. And I gather the early ones were really plagued by crosstalk and Plagued by crosstalk, and um, I won't ask Jared to give away Google secrets about this, but so yeah, it's a it's a tough problem, and you know, you try to understand as much as you can, but there's always extra junk out there. You don't know what it is, yeah, it is impressive that the Google Circuit, when you look at the noise, it really aligns with single-qubit gate type of noise, and it doesn't seem to have many body effects. If you look at the original supremacy paper, there is a very Supremacy paper. There is a very nice question related to what was just discussed by Mario Seghetti again. So, talking about, so the question reads: talking about different classes of noise, where is non-Markovian noise on the ladder of deadliness? I think he means in terms of like being able to deal with it, or like that it would kill our quantum computation. Is my impression correct that this is a type? correct that this is a type type of noise about um type about we're the most helpless the surf is laughing so you want to yeah yeah sorry sorry no that's very funny that i i i i i i hope that all of us are very low down on the ladder of deadliness right now so um uh well i mean there's a sense right you know in in I mean, there's a sense, right? You know, in one of the issues about non-Markovian noise, temporally correlated noise and spatially correlated noise, all these robustness and robust quantum computing theorems fail to deal with that kind of noise. However, in the case of correlated noise, temporally correlated noise, if the noise has a very long temporal correlation, like in, for instance, one over F noise, then One over F noise, then you know you can just do a rapid spin echo, and that will filter out the noise that's correlated over long periods of time. It kind of becomes a high pass filter. But of course, what you say is when you actually have really kind of like, you know, non-Markovian noise where the system is exchanging quantum coherence with its environment and that. Quantum coherence with its environment, and that is coming back to like whack the system again. You can't model it with a LIDBAD operator in an easy way, then that's difficult to deal with. We don't really have great techniques for dealing with that. I don't know how deadly it is. Anyway, I'm not going to climb up that ladder. That's not my intention. Yeah, I'll just maybe add on that, yeah, characterizing whole ship noise is, of course, quite difficult, and even if we could. Difficult. And even if we could, one is probably, for the purposes of building a device, most interested in characterizations that lead to, say, causal models to something you could change on a chip. And often, if you do some kind of randomized tomography and you find there's an in-qubit error, you might not know if you can do anything about that. And so we kind of focus on these more physics-ish models of things that allow us to make reasonable changes in the device itself. And then just to be able to do that. Itself. And then, just to be a little bit of a contrarian, I'll channel Austin Fowler for a minute. Just something I never thought I'd say. But if you ask him, he'll tell you that actually, for the purposes of a quantum error correction, the exact origin of noise is somewhat immaterial to you. What matters is the density of overall errors. And by virtue of the fact that in each round that you measure, you kind of decorrelate and randomize any of the Of decorrelate and randomize any of the coherent error buildup, and you can take care of even long tails of non-Markovian errors so long as that tail isn't heavily weighted beyond the distance of the code in the time-like direction. So, you don't really care where they came from so long as the density of errors is much, much lower than your decoder can handle. And from that point of view, we offload a lot to like our abstract frame of where the qubits are at, and small errors, their origin become. Small errors, their origin become a little bit less important within the frame of error correction. And I think a lot of people, when they hear that, they're like, no, that can't be true. And there's still debates going on. You can do numerical simulations that show even heavy weighted tails error correction still working. And so, you know, it's kind of a subject of debate, but I thought I'd stir the pot by throwing that opinion out there. Very cool. Thanks, Jerry. All right, maybe I can ask you guys if you would again you can pass, but if you would to speculate how How I can speculate anything useful for near-time quantum computing, but especially like as a way of sticking with the theme to use dissipation or randomness. And you don't have to justify your speculation too much because that's when it becomes difficult to speculate too much. Then, you know, you're like, how am I going to back it up? But if you have some gut feeling about how and in what ways it could And in what ways it could lead to breakthroughs, be it in error correction or algorithms or error mitigation, which is something we didn't formally talk about. But for example, one thing in Olis's talk that you saw towards the end, you can adjust these random parameters and mitigate errors. So there is a dissipation, there is randomness, and you can adjust it to get distributions we cannot account for. But nevertheless, despite being random and not Gaussian, you know, you can mitigate errors. And not Gaussian, you know, you can mitigate errors quite effectively. So it begs the question: you know, I have my speculations, but it would be great if you guys would also speculate in what ways might dissipation or randomness, even far-fetched, you know, help us realize the dream of quantum computation or doing very meaningful things with it. I have no idea. I have no idea what the, I don't know. It would be great. I mean, of course, like, you know, again, these random methods are common for things like tomography. Also, they're useful for things like classical shadows. And what was your most recent paper on this? Anyway, never mind. But they, they, but the, I would just raise it as a question. I mean, actually, I think the whole field. A question. I mean, actually, I think the whole field is in a very interesting point right now because, I mean, now a significant amount of investment is going in to the private sector to build quantum computers, and folks are working very hard to build error-corrected quantum computers. On the other hand, fault tolerance is like 15 years away, plus or minus never. And I just pulling out a number out of my hat. I guess actually, it can't be minus never. Never. Log of 15 years away, plus or minus never. And so I think that there's a real question, like, right, can we solve some societally useful problem in the near term, like in the next five years, with the devices we have, noisy as they are, and actually have quantum computers be the go-to method for solving a particular kind of problem. So, you know. A particular kind of problem, so you know, now someone from Airbus, you know, people Airbus and Boeing say, Okay, this here's this fluid flow problem. I'm just making something up here. Uh, that now is going to be solved using quantum computers. So, I will say that I think the kind of questions, and I said this at the beginning, I'll say it again, the kinds of questions that are being asked here, you know, how do we deal with noise in, you know, pre-fault tolerance? Can we use it in a constructive way? I would say that if the answer to this question is going to be, If the answer to this question is going to be yes, that is, we can fund some kind of near-term useful use of quantum computers, it will because we've figured out good ways to handle and use noise. So actually, can I have a, I've been just taking a poll at COVID recently. Who here thinks that, so the question is, who here thinks that there's a good chance that we're going to come up with some near-term, you know, in the next five years, useful use. In the next five years, useful use of quantum computers, where you know, now quantum computers are going to be doing this particular thing for society. And how many people think we're going to have to wait for error correction? So, who here thinks in the next five years we might have a good change with a useful use of clone? I think the previous talk showed that you have it. Also, can I say something? I mean, simulation is good. I mean, for quantum chemistry, people have to solve Schrodinger equation with five atoms like Equation with five atoms like famous benzole molecules. I think there might be progress in this, which has direct application to pharmacy and some medication. Oh, yeah, you're right. Sorry, I should say clearly, quantum computer, it's very likely that quantum computers are going to have useful use for simulating exactly the kinds of systems that you work on, Vladimir. So let's exclude outside of quantum systems, some of these society at large, not just for pointy-headed geeks like us. For pointy-headed geeks like us, so I'm so thank you, thank you. So, who here thinks that outside of quantum simulation there's going to be a useful use for quantum computers in the next five years? Who thinks that? Actually, I think it's likely. I'm willing to. I mean, I like my quantum search, so I think it will work out. So, I raise my hand. Yeah, good. Okay, well, what are people's opinions here? Like, raise your hand. If you're raise your hand. Raise your hand. You're not there. There's something. I have no idea category. Oh, no, no, you're not allowed to do that. You can't. Yeah, we're in this speculative realm. Like, you know, you can always flip a coin and that's okay. It's going to... It's speed one half. It's going to self-average. No zero states. Arrow up, arrow down. You can be in a quantum superposition of either one. It's okay. Raise your hand if you think answer is yes in the next five years. Answer is yes in the next five years. Maybe I can also even forget. And then if you, right, I'm raising my hand for that. Who else thinks that? Yeah, okay. I mean, people will just either not raise their hand for either if they don't think so. So they can abstain. All right. So, yeah. Okay. Who thinks we're going to have to wait for fault tolerance? I'm going to raise my, right? Because I'm just going to use the fact that I don't know to. That I don't know to, and that I'm a mathematician to be the sour puss and say. Good, good, good. No, stop being a sour puss. I would say, I don't know whether you will have to wait for our correction, but five years is short if you look at the past, how many five-year periods there already have been. Made it short on purpose. Okay. Five years is way beyond your average venture capitalist's time span, attention span. Span to attention span. Right, but whether quantum computation will take that into account, I don't know. Yeah, and I also don't think that it's an exclusive or because it's not like it's either for tolerance or so I'm slightly conservative, I would say, about that. I mean, so there is one thing if. So there so there is one thing if if it works somewhat nicely and and there is another thing if it's commercially uh justifiable. Like let's say for like a $10 million quantum computer to solve maybe something a little faster. So so it's also the commercial justifiability. That's another There are commercial companies which do quantum information, like information transfer protection, right? Those are commercially available. Like BB84, those are commercial. Well, can I add? So it's, you know, we're very hung up on simulation and runtime on simulation. But as a matter of fact, there are certain things you can do in the cryptography. You can do in the cryptography space that you can provably do quantum mechanically and you cannot do classically. Like, for example, recently there was a paper about certified erasure. So, if you're familiar with Snapchat, you know, you can send a message to somebody on Snapchat and, you know, they have, when they open it, within five seconds, the message disappears, right? Now, classically, nothing prevents Snapchat from making a copy of the message you sent, although make a copy. Although, make a copy of the message you sent, although it gets erased for the receiver. Now, however, quantum mechanically, there is a new paper showing that you can indeed send a quantum information and certify its erasure. That is like you can actually certify, you say, okay, I'm going to send this within like two minutes. It's going to erase and it will be erased. I mean, it cannot be copied or cannot be stored or what have you. So, I feel like quantum cryptography and certain aspects of theoretical computer science do not get as much attention. Theoretical computer science do not get as much attention as they should. We are really hung up on simulation, you know, and the scaling, the runtime scaling for simulating matter or what have you. So there's certain, so in terms of applications, that's something useful. I mean, it's possible that it comes from areas a little bit tangential or a little bit more computer science-y. So, Olis, you have something to say? I have a kind of stupid idea. I have a kind of stupid idea which fits the basically the topic of this conference and basically this panel discussion. What about can we actually use the fact that we cannot keep state a quantum state for a long time? So we can send some quantum state which decohere inevitably, and now we know that nobody can actually keep it and code information that way that it disappears just because of Just because of quantum decoherence. So, in that case, decoherence actually helps us a lot. So, encoding information in a way it's inevitably disappears in some commercial use cases. You mean to use it to actually erase information? Yeah, I mean, when code information in quantum state, we want to ensure that this information will not be available. Not be available after some time. I don't know, maybe it's usable. So we encoded in a way some quantum correlations in the system such that these correlations will die. And we know that only person with quantum computer can be access to this information only in very, very limited time, like in leveraging this in some tasks. And we know that a person cannot copy. I mean, yeah. Thank you so much. It's fantastic. Thank you so much. Mario, you wanted to say something? I'm sorry if I'm putting us by complicated. Well, actually, I don't know what we mean on information because I would like to call classical information information and quantum information pre-information. So when I have some classical information and I encode it as a quantum information, then I can just always convert. Can just always convert it back to classical and then I can keep it forever. So, well, unless, yeah, so, but I don't exactly know what your kind of tricky device would be, maybe. Yeah, I agree. Also, destroying information isn't that hard, but like destroying it in a way that at least somebody can make use of it is much harder. Like, you can't just let the second Like, you can't just let the second law take over and lose all information. Make sure that it isn't copied and it's erased. But what I'm puzzled, Pai, in all of that discussion is that we need, I think, and this is what Mario was saying, we need classical information, right? And so once the end user converts it to classical information, you've got the screenshot problem, right? If it's on their computer screen, they can reproduce it. They just need to take a screenshot. They just need to take a screenshot, right? And we can't interact with it until it's classical and on the screen. Yeah, but we can encode more information than I don't know. This erasure problem that you're bringing up, Olaz, this was to some extent addressed, right, by this new result, which is interesting. You can actually send information and make sure it gets. Actually, send information and make sure it gets erased. It's called certified erasure. You might want to look into it by Anne Broadbent and colleagues. But there's a lot more in what you're saying, of course, which is interesting, but some aspect of it has been answered. I'm just brainstorming. I don't know. It's great. No, it's great. The fact that nobody can store now some complex quantum state forever can be used. It can be used in security purposes. I mean, this now cloning theorem has some ways around it, so it's impossible to copy qubit exactly. But if I want to copy that approximately, there are ways to copy, I mean, quantum state with like maybe love. Quantum state up with like maybe lousy approximation, but might be enough for enough information into this approximate quota. Yeah, it's not emphasized enough. That's a very good point. So I pause because in case somebody is thinking about asking a question. I'm thinking about asking a question. Or making a statement. Or make a statement. Oh, sounds like. You should feel free. It looks like we've lost two out of three panelists, right? Yes, yes. Vladimir actually is, we're holding on to Vladimir because it's a topic of discussion that he can ride on for hours if he wanted to. He doesn't have to. I mean, maybe just to weird. I mean, maybe just we're about to adjourn. So Skype, maybe I just want to Skype, just to make some kind of advertisement of our Steningbrook. I work in Steningbrook. So we have a physicist. His name is Igor Leyner. I think I misspelled in the spell check, of course, corrected incorrectly. Corrected incorrectly. So, um, he wrote those nice. I think he work for one of the companies doing quantum computation right now. So, he wrote this nice paper, the code in qubit, how to input beta and zat. So, uh, this is about integral models, about this conservation laws. Super conservation laws are supersedation rules, which was brought up recently. There was discussion. And then, also in Spain, there is another physicist, his name is German Sierra. Physicists, his name is German Sierra. So he wrote another Qiskit program: How to input algebraic betanzas. Algebraic betazas, this is some kind of a compact way to write betanza wave function. I mean, Hans Bertha in 1929 wrote some form of the eigenfunction of this xxx anti-ferromagnet, which appears in the OLS lecture and many others. But then this wave function looks horrible, like the n-factorial square. Like the n-factorial square terms, and then one can apply these ideas of matrix product states to Bethanzat's wave function and write it much more compact way. Then it's called algebraic Bertansatz. And then that one also can be inputted into quantum computer. And the Qiskit program was written by German Sierra. So sorry for advertisements. That's anyway. Interesting. So, Vladimir, there's this question of like. Bladder, there's this question of like, is the ground state of relevant quantum matter in P or not? So, let me just say a couple of words to tell you what I mean. You know, there's like, you can, of course, have QMA complete type of Hamiltonians, or you can make very contrived Hamiltonians whose ground states are heavily entangled, and matrix product states, or tensor product states, or tensor networks would choke on them. Now, you and I have worked on certain spin chains. Worked on certain spin chains. And when I go to talks given by people who work on classical simulation of quantum manybody systems, often the message, the underlying tone, what they want to convey is that everything relevant, and they use different words like generic or physical, everything relevant that you would care to study that might be part of nature that you care to study should. The characteristic should obey an area law, or should be, they won't say it directly like this, but that you know you would you would think is in p, so it's in polynomial time. You can use some tensor networks, etc. Now, we have counter examples to this, of course. Now, I was wondering if you could, if you like, if you would be willing to say a few words about to what extent you believe such a claim or what kind of arguments you have about physicality of such models. Models, um, um, what you might call generic or robust, yeah. I want to how the question should even be formed, you know, like how do you debate with such people? So, that would be, you know, something you could help us. I will answer as a politician, meaning that you ask a question, I answer another question. Um, and then I also spoke to a lot of solid state people. Um, I mean, specifically, I discussed this spin chains, Movas Shorts. Movas short spin chain, also they call it sometimes Motskin spin chain, which has exponentially large entanglement entropy and meaning that a high level of quantum fluctuation. Me, myself, I also work on this and then Short Movas spin chain handle spins with integer spin and our generalization we call it Fredkin spin chain. They describe half integer spin chain. Integer spin chain. Fred can pay attention to the third letter, which is the first vowel, which is E. There are several people with similar sounding name, but they keep on this third letter, which is first vowel, which is E in my case. I mean, okay. And then those spin chains, I also, like Ramiz did, lectured about these spin chains in some APS. Some APS meetings, March meetings, the solid state section. I also was attacked by the same question, like Ramis was that this is not generic, and then some small noise will kill all these nice properties, and it's unessential for physics. I have a philosophical reservation. Philosophical reservation, come back to my previous remarks. So I worked for a long time on integrable models which has infinitely many conservation laws, like for example XXX spin model. Like, for example, XXX spin one-half Heisenberg anti-ferromagnet, which was solved by Hans Ber. I talk about this a lot. So, those integrable spin chains, they're called completely integrable, exactly solvable, infinitely many conservation laws, they're unstable also, meaning that there is many, many, infinitely small perturbation which can easily kill integrability and kill all of these conservation laws very easy mathematically. On the other hand, On the other hand, in the real devices, they were built. This extract X pin chain specifically was built in optical lenses. So it exists as physical reality, disregarding these arguments. Of course, in solid states, another important model in solid states is strongly correlated electrons. Strongly correlated electrons was experimentally implemented even for one dimensional case, one space dimension, one space dimensional model, which mathematically described this strongly correlated. Describe this strongly correlated electrons as Hubbard model, which is completely integrable, has infinitely many conservation laws, and still exists as a physical model. As for high-energy physics, in high-energy physics, I work in Stenbrook, close by, there is BNL Brook, having national lab, they're building new electron icon collider. So, the main pro one of the important processes which they will measure when it will be built probably. When it will be built, probably in 10 years from now, it's called deep elastic scattering. Deep and elastic scattering can be compared to an X-ray of a baryon, of the proton, of the neutron. And then there is quantum thermodynamics which describe it. Quantum thermodynamics means that I have to sum up some Feynman diagrams. And it was done. And the essential parts of the decay of this virtual photon into quarter-anti-quar the virtual A virtual photon decay into quarks are like quark pair which interacts with the constituent quarks by exchanging gluons. And the gluons interact between themselves. So the interaction described by the integrable spin chain. So this is like real physical experiment described by integrable spin chain, which kind of disregards this argument. So Ramis, I believe your model will be built in a real device, or maybe there is a quantum circuit for that. Circuit for that. So maybe yours. Maybe I'm talking too long, so I just want to. Or maybe yours will be built. No, no, that's actually great. This last example you gave is really answers the question I was going to ask, and that is, you know, sure, you can engineer them with a lot of hardship in lab and, you know, perhaps even realize them, but is there any hope to see them in any realistic compound or any realistic situation? And the high-energy physics example you just gave was a pretty good argument. Was a pretty good argument. Also, I want to add a little bit to the arguments. This electron aisle collider in BNL probably will be built in 10 years. I probably will be dead by that time. But nevertheless, in northern Germany, there is DAISY COLIDER. And the part of this was HERA, HERA H-E-R-A. This is a collider decommissioned by now, but the data remains and they were numerically analyzed. And they were numerically analyzed so far using classical computers, and then the data seems to agree with that integrable model. Well, within arrow range, and I mean, it's not ideal coincidence, but it looks like this integrable spin chain in deep and elastic scattering works. I mean, there are hints from here that the experiment was done a long time ago, and the collider was decommissioned, but the data remains. Anyway, that's my That remains anyway. That's my remark on your remark. That's amazing. I didn't know about this. That's that's amazing. I have a publication recently with in Stonybrook. We have a man making a lot of advertisement of Stonybrook. In Stonybrook, we have a prominent nuclear physicist. His first name is Dmitry. The last name is Kharzeev. So it's spelled in English with K-H, Kharzaev, Kharzev, then K-H-A-R-E-Z-E-V. And then we have a publication about this deep. And then we have a publication about this deep and elastic scattering and the modeling with this integrable model. This is the real physics. It just can be will be measured in high energies. So it just overcome all of this vague, lousy arguments which was put forward against your speech. That's the end of my speech. I mean, I don't want to talk forever. I mean, people will be bored. That's great. Yeah, I'm sorry, for a second my uh my internet jumped, but yeah, so I look forward to your uh I look forward to this paper. Definitely. And yeah, I mean, if you send me a I will, I will. When you have it, it'd be great. Of course. Maybe not everybody interesting, so I will send you a personal email, okay? Sure, yeah, and uh, Vladimir, do you know? Yeah, and Vladimir, do you know? Are there like cases open for debate? So, ground states of real compounds for which we are not sure? I mean, not that you can certify that they're hard, but you suspect the quantum correlations. Usually, the story is that if it's 1D and it's critical, it must be one plus one CFT. And you have logarithmic correction to the entanglement entropy. And therefore, since it works in 1D, Therefore, since it works in 1D in any dimension, it works similarly. You know, you go to higher dimension, you do some IR cutoff, and you still get an area law with the maximum violation of log L. But you know, it just becomes much more speculative as you go up. Like, there is no proof or anything. But do you actually? Yeah. I want to reply in my political style again. So, just, you know, when I was younger, when I was undergraduate student, I was trained as a nuclear physicist. So, let me tell you something about entanglement. About entanglement entropy scaling. So, of course, area law for the gap full models in one dimension was proved. Okay, so we believe that. Now, if CFT, confirm field theory, if we do not have gap, gapless, CFT gives logarithmic scaling of the entropy with the size of the block. So we also understand. But I somehow due to some reasons I want to concentrate on scaling of entropy. To concentrate on scaling of entropy, so in your model, Ramis Movassa, Short model, the entropy scale is the square root of the size of the bulk, which is exponentially larger, super great. I mean, then there's Q deformation of this Motzkin spin chain, which I mean, Klich, Israel Klitsch, made it show deformation, then entropy linear. Linear seems that this is like, it's case like thermal, this is like second law of thermodynamics. Thermal, this is like the second law of thermodynamics. It scales like thermal fluctuation. So it seems that nothing can be faster than that. Not true. One should learn nuclear physics. In nuclear physics, there is a model of the baron, which is called Fireball, Feibel, Ball of Fire, and Hagidorn, the person who wrote... When I was undergraduate, this was like extremely popular. The entropy scales exponentially with respect to... Scales exponentially with respect to the size, okay? So the R is not even 1D. Well, it's not possible. It's not dimensions. This is like exponential with the number of particles, nevertheless. Entropy, well, yes, that's correct. That's correct. Entropy with exponential with number of particles. I mean, there is Wikipedia article about Hagorn model of firewalls, so maybe I should attract this attention because Maybe I should attract this attention because somehow it went far away. So people who do quantum computation doesn't care much about nuclear physics, but in nuclear physics people know this, fireball and this. Well, anyway, this was the first part of my statement. The second, which is completely independent of the first one, is that for generic, come back to one dimension. Forget Hagedor. One-dimensional spin chain. So, I mean, Spin chain. So, I mean, if I have a generic Hamiltonian, then of course it's not integrable. So, I mean, my expertise goes down the drain. So, then I start reading papers of Ramiz Mavas or Bruno Naftihalle. But my general feeling that the ground state will be in the NP class, not in P. So I might be wrong, but I'm afraid that it's not in P. So I mean, I don't have proof of that. That I mean, I don't have proof of that, but so somehow I suspect. And the third is maybe I talk too much, so maybe we should adjourn the meeting, so we shall have tomorrow another day tomorrow, right? Yes. I mean, the Schmidt rank is exponentially large. And we even know the Schmidt numbers do not decay so quickly to just chop them off. I mean, for Haggy Dora, partition function doesn't exist because everything diverges. I mean, actually, like, would you? Actually, like, would you please spell it? I'm trying hugging. So, you know what? Let me let me. Okay, so I'm going to Wikipedia and then hug it. Hug it on temperature. So, uh, control C, I just put in I found it, so I put it here, yeah. Right, and then Ctrl V. This is how you done temperature. This is Hagidon temperature. Haggid on temperature. Okay, so anyway, maybe some other people want to say something. Yeah, please, please wait. And I'm sorry, maybe I should have been more conscious. Anybody has a question or a comment for Vladimir? I mean, it's a great opportunity. He's the man of. We can really query Vladimir about like speeches, entanglement, and all sorts of things. Unique access. Thank you. Very interesting. He was like a very prominent nuclear physicist. And this fireball, when I was undergraduate student, was really important. So it's not a universal model of a baryon, but some features of baryons, of hadrons, are captured well in this model. And so, wait, so the take-home messages. So, wait, so the take-home message is that the thermal entropy grows exponentially? Yes, yes. Okay, so you're saying since the thermal entropy, you know, thermal and uh, I mean, of course, it's different from actual time entropy, but they have the same mathematical structure. Such a thing might happen, like, for example, in a field theory or. Right, but of course, Hagydorn was an educated person. He understood that baryon is quantum, so he was not trying to write a classical model. This is a quantum model, and of course, he understood Quantum model, and of course, he understood it's quantum from dynamics, quantum. I mean, sure, sure. It's definitely not classical. Yes, all right, right. So maybe we should thank our moderator, Professor Adjourn. Yeah, I can. This is very interesting to me. If any, I mean, if, by the way, if you're sick of us and you want to let me out, you're totally fine. It turns into monologue. I'm talking. Can maybe somebody else. I'm talking and maybe somebody else should say something. Oh, no, I don't think anybody's shy. We'll just like jump into this. I would like to address the question to like that. So you are talking about this like highly like so when we build like a useful quantum system or quantum computer which can like solve some ground state. So that would be the ground state. So that would be the ground state of like a highly theoretical system first, like like quarks or so modeling quarks or whatever. So it would not be like a new medication for COVID or something, right? So it would be something highly theoretical. Is this your I mean I don't know. I mean, I'm sorry, I have to disagree. I mean, Tesla went away regrettably. I mean, well, let me answer again in this, you know, political snakey way. So, first of all, I believe that the fastest results which will come out of existing. So, our conference about NISC devices and NISC devices getting larger, larger, and larger. So, I do believe that the first useful results which will come out of this NISC Results which will come out of these NISC devices will be simulation. So these devices will be used to represent the solution of some Schrödinger equation. For example, this benzol molecular, this five atoms moving, and there is Schrödinger equation for this, which is difficult to solve classically, but quantum mechanics on the computer is already quantum, so maybe to solve it. If it does, then it will give some new medication, not necessarily. Give some new medication, not necessarily COVID, but some medication, because independently of this essential efforts from the biochemistry, from the biochemistry companies which make medication to solve this damn equation, the Schrödinger equation with many body, they do want to solve it very much. And they they get stuck because it's exponentially slow. But I mean, my belief that the first useful results will be simulations solving this Schrodinger equation from any particle. Schrading equation from any particle. This is the first thing. I do want to move to the second part of my question because with the second thing. So the second part. Interesting question, at least. That's my opinion. I even was under the impression that Cesloyd would have agreed to me, but of course I can talk to him. Okay, second question. Second question, spin chains. So right now, what people who do quantum objects, what they do, I mean, is I mean, they built these toy models, the famous models of mathematical physics. 1929, Heisenberg wrote this XXX spin chain, which is very useful, has multiple applications to high energy physics and solid states. And then Hans Bertha, three years later, 1932, wrote the wave function. And I discussed this wave function many, many times. So this spin chain was built in optical latences, so it exists. So it exists. So the short answer to your question, Mario, is yes. But what I was trying to say, that's a piece of information which I didn't give up yet. So when I started working on the model by Ramis Shor spin chain, we got our own kind of generalization of this model to half integer spin. So the simplest is this Fretkin model. Simplest is this Fredkin model. We already discussed the pronunciation of this Fredkin. Fredkin-Hamiltonian is just Fredkin Gate. You know, Fredkin Gate is the Hamiltonian for our model, which is half-integer version of a Schor-Movas model. So I think maybe it will be possible to build. I mean, we already have Fredkin Gates. So just, of course, I need several copies and then the nearest neighbors, the triplets of nearest neighbors interacting by Fredkin Gates. But I think Fredkin Gates is part of the. Fredkin Gates is part of the software and hardware, anyway. So, if we have to build it, maybe we shall build this Fredkin spin chain, which is Hamiltoni made out of this Fredkin gate. So, I think there's some chance to build some version of Shore Mavas in the nearest future. That will be my hope. Anyway, of course, this is partially simulation, speculation, and I don't have proof of that. So, Mario, all I want to say: all my comments, which I have. All my comments, which I have to say on your comment. Thank you very much. Of course. Thank you, Mario, for the question. Thanks, Vladimir, for the nice answer. Also, one comment is like using trapped atoms and ions might be one of the best architecture for spin chain type of emulations. On a superconducting qubit, it might be a little bit harder, but like, for example, Ising spin chain is very naturally modeled on these. Modeled on these trapped ions and atoms. Right. Yes, you're right. I forgot the name. I mean, like, I'm 72 years old. So I forgot the name. In southern Germany, in Munich, there is a very famous experimentalist in quantum optics. I forgot. Immanuel Bloss. What? Blossch? Bloss. Emmanuel Bloss. And he was the one who built XXXZ. XXXXXZ. XXXXXZ spin chains. And once again, Ramis, this is just to rebuff your attackers because it's completely integral, has infinitely many conservation laws, which easily, mathematically on the piece of paper can be easily killed by adding almost arbitrarily, infinitely small perturbation, but it exists in reality, manual block. Do you think there are compounds we might run into naturally, not engineered or built? Not engineered or built, but like condenser systems for which, yes, okay. So I'm from Long Island, if you remember. So I work on Stonesbrook, but one hour drive to the Easter is BNL, Brookhaven National Lab. And there is, it's like big national lab. Okay, and there is, among other things, among many, many sub-organizations inside, one of them called Institute for Theoretical Condensed Matter. Institute for Theoretical Condensed Matter. Instead, Institute for Theoretical Condensed Matter. And there is a physicist. First name is Alexei, the last name is Tzvelik. Alexei Tsvelek. And he wrote many, many papers, like I'll say, devote his life to the question which you ask. So in solid state, there is many different crystalline structures, okay? Some of them are almost one-dimensional. But for example, this is strontium oxide. This is strontium oxide high-temperature superconductors. Superconducting current goes along two-dimensional planes, but above these planes, there are chains. And the chains, electrons hop along this chain, and this is like one-dimensional model. Hubbard model works. So there is a collection of, I mean, he, Sivelek, Alexei Tevelec, he wrote a couple of books. Actually, he's a great writer. So he wrote several books about this or. About this occurrence of completely integrable models in highly anisotropic crystalline structures in real nature. So, in real nature, there's somewhat exotic examples, but they can be fished out. And then there are people who actually devote the whole scientific life for doing that. So, the short is yes. Oh, wow, oh wow, cool. So, these are certain excitations on top of a chains of excitation on top of. So, there are chains of exhibition on top of a superconducting slab of material? Yes, yes. Of course, in optical lattices, there is. Well, I already spoke about this in high energy. So, Mario, speaking, Mario, there was some more. I wanted yet another remark about your statement. So, in quantum homodynamics, of course, there is a highly respectable branch of high energy. Respectable branch of high energy physics, which is called the lattice gauge. Okay, so lettuce gauge, of course, puts some quarks on the lattice and I mean gluons on the lattice, young Mills fields on the lattice. I mean, it's very successful, but they actually have a problem with the lattice gauge. People who write out for lattice gauge, the time, time evolution works nice in Euclidean time when the time is imaginary. Leading time when the time is imaginary, which is not always good because sometimes we are interested in real-time evolution, like entanglement entropy, for example. In our days, like the modern science interested in real-time evolution. And real-time evolution, maybe quantum computers are necessary to describe the real-time evolution. So what I'm trying to say is that quarks and gluons on the letters are And gluons on the letters are important, but remember what I said. So there is people. I mean, I was at the younger age, I was a student of Gribov, Vladimir Gribov, and cooperated with Lipatov. So the work was the following. So deep inelastic scattering, the electron try to scatter on the hadron, on the baryon. So electron emit virtual photon. And then we forget about this electron. Photon and then we forget about this area. Virtual photon of very, very, very high energy. So, meaning that the size of this virtual photon is much smaller than the size of the proton, of the neutron. So, this virtual photon come inside of the baryon and then decay into quark-anti-quark pair. And then, this quark-anti-quark pair starts interacting with anstital quarks. What I'm saying to you, this was clarified because of the following: people analyze which Analyze which Feynman diagrams are most important, are leading in the limit when the energy of this electron, of this photon, is very, very large, limit going to infinity. And then Gripov had this idea about leather-like diagrams. So leather-like diagrams come in the following. So this quark anti-quark pair, which appeared out of the decay of the virtual photon, they interact with the constituent uh quarks of the hadron. Of the hadron. And this interaction is via exchange of the gluons, which is quants of Young-Mills field. And here the ladder-like diagrams dominate. And then there is one-dimensional spin chain which describes these ladder-like diagrams. And this is, we call it lattice non-linear Schrödinger. There's some equation which actually has something to do with Lieb-Lininger model. Lie-Lininger model is a completely integrable continuous model, but I can discretize the space. I can discretize the space in some intelligent way, keeping integrability. Then I got this lattice non-linear Schrödinger. Latest non-linear Schrödinger is what it's equivalent to, it's lattice non-linear Schrödinger, also equivalent, can be rewritten as a spin chain. This spin chain is like XXX Heisenberg spin chain, but the spin is different. So Heisenberg wrote his spin chain with a spin one half, and the one which is good for deep and elastic scattering has negative spin. It's spin minus one. This is Lattice non-linear. Minus one. This is Lattice non-linear Schrödinger, which is equivalent to Heisenberg's spin chain with spin minus one. And this is one-dimensional spin chain. And if we can put this, simulate this somehow in the quantum computer, it's easier than to put the whole quantum thermodynamic four-dimensional on the latest. But this one-dimensional spin change, it's already described the heart of this deep and elastic scattering. So I'm kind of optimistic that this is give a rise. So what I'm trying to say. Give a rise. So, what I'm trying to say is that our approach should be hybrid. So, to quantum thermodynamics, we should first use some analytical result which helps us to reduce the whole process to one-dimensional spin chain. And then, spin chain, maybe we can build on the quantum computer. So, that's the end of my lengthy remarks. Very cool. Very cool. Thank you, everybody. But then you are saying that basically, so these are like what particles. like what what uh particle theorists are interested like yes yes yes like like knowing this behavior of of quarks and and uh knowing these details about quantum chromodynamics does not even affect like our ability of like building atomic weapons or anything like that. No, this is a dynamic weapon. So it's not even like like it's basically just it affects our It affects our understanding of the understanding of quantum chromodynamics. Quantum chromodynamics by itself is not exactly solvable. So, some parts done analytically, some experimental, some factorization hypothesis in quantum chromodynamic meaning, there is some paths which we can calculate at least perturbatively. There are some other paths which we have to measure experimentally. So, we'll be progress in this direction. So, understanding. So, this is just understanding of the structure of quantum formulation. Theoretical understandings. There's no Political understandings. There is no atomic weapon involved. Yeah, yes. According to my knowledge, according to my knowledge, I am only responsible for what I know and what I say. And so that's what Seth says, that so probably the results will satisfy us nerds, but not necessarily like we'll go out of our circles or no, but nevertheless, I mean, speaking of cameras, Of cameras, so yes, no, I was like, maybe, maybe it was now. Don't forget quantum cryptography. Quantum cryptography, of course, doesn't compute anything, there is no computation, but safe transfer of the information protection, I mean, so already exists commercially. So, people who want to hide the information with the transfer, already can use quantum effects. So, this is commercially available in Europe, but Gissen in Switzerland has his own company. And I'm sure in France there is something. I'm sure in France there is something, and of course, in the US, actually in Boston, there is so PBL. I talk too much, so maybe some real. I know, by the way, you actually have a question. Sergio, do you want to ask it? So Sergio Burks has a question, or if not, I can't read you. Okay, there you are. Please? Yeah, I mean, I don't know if I really follow Vladimir's explanation, but what I understood is this was a problem that you could map to a 1D spin chain with one minus one. Spin chain with one space, one time, right? Spin chain space is discrete, and there is continuous time still, yeah. So if I don't understand why DMRG doesn't work, then to simulate this problem, you know, because DMRG tends to work really well in one DMG. Well, I can give you the legal answers. So, first of all, I never said DMRG doesn't work, okay? That's a legal answer. And second, I think it works sometimes actually. Actually, the renormalization group is useful. Well, you know, since it looks like our conversation drifted into the direction of high-energy physics, so quantum thermodynamics is important, but one of the important features of quantum thermodynamics is asymptotic freedom, which can be described by the normalization group. And then there is one-dimensional spin chain, which is one space, one time dimension, which is called Gross-Nevere spin chain, which also has asymptotical freedom. On the other hand, it's exactly solvable. On the other hand, it's exactly solvable, not by Beta and Zatz, but the Young-Baxter equation. So I don't know, I think it can go hand into hand. I think Beta and Zatz and Young-Baxter and all of this algebraic solvability does not contradict a normalization group. They just can go together and cooperate. So I think the reason Sergio is asking this question is that, like, do we have any examples that are physical and encounter in nature on which DMRG would choke a non- DMRG would choke and not work well. It's true that you get spin chain effectively in this high energy model, but and then there is, of course, our models for which DMRG doesn't work, like Motzkin spin chain, a Fred can spin chain. But you know, you don't encounter, you don't encounter them naturally in nature, at least not that we know. But you know, I think part of the difficulty, Sergio, is that like studying the entanglement entropy of these models is not easy. And one needs to analytically show that entanglement entropy is high and it's very difficult to do. And it's very difficult to do, and it's not been seriously studied. It's a very recent thing that people actually seriously study the entanglement entropy of models. And you know, we took a chromological view towards this to show how much entangling entropy you could have in a spin chain to guide that search. But others, go ahead. Yeah, I have some kind of stupid remark, it's more about the literature. I forgot the name exists. Again, I forget the name. I forget the naming again. There is some person who recently wrote a paper, and the paper is hydrodynamic description of Shormovas model. I mean, it's the title, it's on the archive, I forget the name of the person, but I mean, in the title, it's hydrodynamic of Motskin model. I think the title is hydrodynamic of Motskin model. Hydrodynamic is kind of can be considered as a generalization of conformal field theory. So it's not conformal, but Theory, so it's not conformable about hydrodynamics. I don't know, I didn't look into this paper from the point of view of DMRG, but it's like a paper a couple of months ago. So maybe DMRG can be that hydrodynamic can be reinterpreted as DMRG. So interrupting, Ramis. I apologize for interruption. This is fine. Maybe it's this paper. I'm not sure. Yeah, but that brings up a very good point. So there is a topic that we haven't covered, which is. Yes, that's a paper. That's a paper. Yes, that's a paper. That's a paper. That like solving differential equations might be also something that quantum can do, like certain differential equations. Well, for example, Schrödinger equation, right? Like or hydrodynamical kind of. Well, of course, Schrodinger equation, but that's, you know. There's some numerical name of Schrodinger equation, like Storm Louville equation or something. You can just hide that. This is Schrodinger. You can't. Just hide that this is Schrödinger. You can there is some mathematical name for that. Sorry, sorry, interrupting. That's great. Yeah, we have some quantum algorithms for solving differential equations. Yeah. Also, let me say some more remarks. So in Germany, the capital of Germany is evidently Berlin, and there is a technical university in Berlin. And there are a couple of people working on there. Working on their well, basically, Bobenko is one of them, Bobenko, and there are Suries, and also some Hoffman, Hoffman, Hoffman working with that. So, what they're doing, they're working on my non-linear Schrödinger. So, non-linear Schrödinger equation, this is the same, non-linear Schrödinger in the continuous case has like five different names. I call it quantum non-linear Schrödinger equation, also can be called Bose-Gas. Also, can be called Bose-Gas with delta interaction, can be called Lieb-Liniger equation in quantum optics. They call it Gutzwill. They have some other name which I forgot also. So my contribution was discretization of space discretization. In my discrete version, time is still continuous. Space is discrete. Amazingly enough, this is good, this works nicely for quantum thermodynamics, which you already discussed. But in Germany, the But in Germany, they also discretize time. So these three people whose name I mentioned consider discrete discrete, non-linear, which is discrete in space and in time. So it's still integrable, it's still integrable. So it might be good for computers when I put this in the computer. I mean, when I put differential equation in the computer, I want to discretize everything. And these guys in Berlin, they discretize non-mini-sharing in such an intelligent way that after. An intelligent way is that after complete discretization, space and time discret is still integrable. So, I don't know, maybe we should pay attention to this. Very interesting. Yeah, thanks. I mean, it's great that you're bringing these things up. I don't think anybody knows all these different facets that connect to spin chains and integrable models like you do. I really don't think there's anybody who does. It's really great that you say. Maybe to close up on mystification, for complete mystification and application. Complete mystification and application. So, okay. Um, I mean, this differential equation I can solve. I mean, I don't some differential equations don't even have time, right? There's some differential equation which is purely space dependent, right? And there's some of them completely integrable. There are some names, cadence of Pitwell-Schwilly equation, but there is some differential equation without time. So, one can start discrete. So, one can start discretizing those, keeping integrity. That's what people do in technical university in Berlin. And after