Thank you, Elizabeth. Oh, hello. So, we're going to be kind of sort of now going from advanced calculus to basic math back again. So, we're going to be simplifying things in terms of math a lot, but talking about more purposefulness and how we design problems, what type of selections we do, and also talk about the methodology a little bit and try to understand what's going on behind the scenes. If we didn't have any data. Behind the scenes, if we didn't have any data, any numbers, and just was looking at a core problem. So, those are kind of what we're gonna do today. Although the name is like optimization under uncertainty, mostly going to be talking about two-stage stochastic programs, like they are the most commonly used method. And I think that's one text. I hope this is like kind of for you to take a step back when you face a problem. Back when you face a problem, and as we saw in the think project introductions yesterday, you can have like really technical, complex, and fancy, and nice problems, but you don't know what you're using it for, and you don't have really a purpose, and you don't know the use case, then it will still be a good exercise and you'll still improve your skills. But kind of selling that out will be a little bit of limited. So, as like a business school representative here, we generally are very Generally, are very interested in how to also sell our work and problems, but it is the same for everybody, right? It's getting very competitive, academic context, and PhD programs, and everybody in like the publications are also getting harder and harder. So, if you have that edge of trying to really convince the editorial clean review team that you are doing something important, you'll have a bigger, much better chance. Because now everybody thinks like, I mean, we believe that you know the math, right? So we don't think that you're going to fail on that side. Think that you're kind of failed on that aspect, but more so the relevance and positioning. So, I want to talk about those a little bit as I know everybody is very kind of skilled at Matt already, and maybe probably more than I. So, let's kind of talk about how we purposefully design problems. So, when you're looking at an optimization problem and we know the basic anatomy of it, you're going to have an objective. So, in the beginning, maybe you need to think about your own objective. So, what do you want to do? Publish a paper. So, what do you want to do? Publish a paper? Why are you doing this? I mean, you can try to satisfy your mathematical curiosity, which is very good, or write a fancy algorithm, which they're all very fruitful efforts. But the biggest impact will be if you kind of manage to solve an important or relevant problem. So, generally, it's kind of advice to rather than trying to fit and in this kind of summer school, our idea is like learning skills and experimenting. Skills and experimenting. So, this is not for the projects, of course, but in a bigger context, your thesis or your work, you're going through things. Don't fit, you know, data to your don't fit your problem like to the data that you have a fancy data set and don't try to make up a problem to use that. Rather, first define your problem as a relevant, like important problem, figure that out, and then find data to solve that problem if it's needed. So, in terms of the So, in terms of the micro-grid applications, and I'm going to be keeping the focus a little bit about Canada's north, since he had all those lectures by Joshua about the remote communities and location-wise, it's also relevant to us. And it's part of my research is looking into what researchers are doing with remote communities data and for those locations, and really how it's perceived by the communities themselves, and generally by policymakers. Generally, by policymakers, and is it really kind of useful or working? So, if you look at the problems generally, it's in the electricity grid optimization, especially when you're not connected to the grid for areas that don't have that backup grid connection. And we were thinking of different objectives. Emissions is the one we've talked a lot about and here in this course as well. I mean, climate change is important. We want to have sustainable futures. Futures, so clean energy is, of course, important. Then we also have to think about maybe the certain context and dynamics of the problem: how are we going to utilize the assets that we own? Reliability is going to be a big concern. You're talking about context when you don't have a grid connection. So, if there is no electricity, if you have an outage, it means there is no backup and you're going to be in a blackout, probably a very cold temperature. So, I have to think about that reliability aspect, the comfort level. Aspect, the comfort level. I mean, is the heating, indoor heating, all of those? Can you sustain a comfortable level for occupants? And then, of course, your profits, risk of doing business, that could be many, many objectives. But it's going to be very important again to be purposeful here. Let's talk about emissions. Again, we're pointing out like a lot of the projects that are being done, a lot of the research projects that are being designed, and even, you know. Being designed, and even public projects advertise themselves or target the emissions reduction when they're building something in Canada's north. But if you take all of those remote communities that Joshua talked about as well, all of them combine them all together, their entire diesel consumption, electricity for heating, everything, their emissions are going to be like this from Environment Canada. All of them became net zero, but you're going to. Became net zero, what you're going to achieve from a Canadian emissions reduction perspective is like 0.2 percent of Canada's entire emissions. So, really, is this the best way to get an emissions impact, really using those people, those communities? And specifically, there's the kind of understanding with especially indigenous populations that they are the most vulnerable to impacts of climate change, but we are also wanting or asking them to carry the flag. Carry the flag in leading this change, but whereas they're only kind of contributing, they're only 2% to the emissions. So maybe emissions is not the best objective. I mean, you can design a kind of a mini grid, microgrid that's going to remove the air diesel emissions, but that's not really what they're most worried about. So you're not going to be able to sell that research project. Maybe you'll be able to publish it somewhere, maybe not in a very tough journal. Again, the relevance aspect you're going to be losing out on. Going to be losing that on, and then the communities will probably not implement it because they won't have much use case for it. If you do go talk to those people, and I was in Yukon for actually doing that, kind of things from last year, that's the photo I took. So they named their streets diesel smoke. It's kind of very customary to have diesel smoke there, but they're not really worried about the smoke itself, right? So if you talk to people there, it's not like we want clean energy because we cannot breathe. Because we cannot breathe, we don't have clean air, it's mostly going to be on the affordability side of things. So, electricity there is too expensive, reliability is a big concern. If you don't have continuous deliveries of fuel, diesel fuel in the winter, you can just be cut off. And then, you know, we'll talk about different objectives, but definitely it's not going to be emissions. So, this topics also like remote communities, indigenous communities, Canada, we have all this. We have all this sustainability push with every field, and then like ADI initiatives are very popular. So, there's been like increase in projects that are kind of looking into making sustainable solutions for remote Canadian communities. So, I'm going to give you examples of these now and sort of where you can go wrong. And these are published papers. And I'm not saying they're like not bad research or anything. You can find in the notes section of the slides, which papers I kind of took. Slides which papers I kind of took the sinfo from, but there can be a mismatch between what you're kind of proposing if you're only focused on your project, on your problem, and really kind of lose out on the big scope of things, then what you end up with might be kind of a little bit infeasible or not reasonable that much. So this is from an academic paper that's kind of looking at a clean energy solution for this community, Sanikila. So that community, if you look at their day timing, they just surpassed 13,000 people. But the time this research was conducted, it had around 800 people in terms of population. So it's a small, small community. And then the research kind of sets out to find a microgrid project that concerns the availability and affordability of supply and mixes different. And mixes different renewable energy sources. And then, what they suggest that the solution is this hybrid system based on solar, wind, hydrogen, natural gas that's supported by fuel cells. And the cost minimization perspective, but from a total cost point of view, it's like about almost 4 million capital investment required, although it's the minimum cost. And the maintenance, ongoing maintenance, is going to be about $6 million. So imagine a community of 800 people. Community of 800 people, pretty much they are mostly occupied, anyways. Like you cannot find people to do other stuff there. So there's a human capital issue as well. So, how are you going to raise this much money for maintenance and kind of find the people to operate the system that looks like, you know, so many generators, field cells together, only for 800 people, right? How come maintenance costs is higher than the capital? So you can look at the paper for the details. I don't remember. I don't remember the details now, but there's the link or the reference there, so you can explain it, I think, more in the there. So, there's one more study. I'm going to give an example. There are so many of these. We have a paper about this actually. I linked my website in the beginning, so you can look at it from there, kind of showcase this type of problems that are not really solving something very useful. So, with this research, we have actually in our focus three communities. So, we combine them. Three communities, so we combine them. It's a good solution. I mean, combining things economies of scale always makes sense, so we like that. And the suggested solution is more reasonable now. It's not like this kind of 10 different type of generators together, just going from diesel to biomass, which actually is generally well received by communities because they are used to operating their diesel generators. So, just like switching out to fuel with biofuel doesn't really change how they do things, not too many. Things, not too many new learning processes, not new things to maintain new extra material infrastructure. So it's actually a feasible solution from that point of view. But these communities are north of the three line, so there's so not resource or kind of biological material to do the biogas in a kind of circular system locally is possible. So as a solution, the authors suggest the community import wood to the region using the waterways. To the region using the waterways, but that is where the kind of solution fails because you're essentially replacing a diesel dependency, which again, emissions is not the point of kind of conflict for these communities, but the sovereignty aspect, being mandatory to depend to outside resources, being able to not generate your own resources within the location. So those are the concerns. So you're just like switching one for the other. Switching one for the other, really not helping that, plus they really don't like to use their waterways to transport, like you know, those kind of big vessels which disturb local animals and everything. So, again, this is not going to be a feasible solution, even though it's very good designed and everything. On paper, it's good as a mathematical exercise. It's really nice, but implementation-wise, it's going to miss the ball. Other aspects are thinking about feasibility. Thinking about visibility, so we're talking about Canada's remote regions. I mean, we have three northern territories there, one of them is Nunavut. You can google this yourself, replicate this. You'll find there are no roads to Nunavut. So the problems there, what you see is there will be an outage. One of the power plants will go down in the middle of the winter, and you cannot get there. There is no grid to connect to. You cannot take. You cannot take no maintenance, cannot take people immediately in a spur of the moment. So they're stuck there in the cold minus 40, 50 degrees. Or when there are no roads, how are you going to take items there? Either you fly planes, which is really expensive, or during summer months where the waterways are not frozen, you can take barges, put all the supplies there and store it on location. But sometimes they are delayed, so they don't have fuel over there, no supplies. So the idea is finding solutions. So, the idea is finding solutions for this community. At least it's not about eliminating diesel. The problem with diesel in that case is not having a viable, continuous supply chain for diesel. So, the idea is finding a solution that's going to be more reliable than what exists. So, that's going to be the objective that's going to make most sense for that region. And think about more roads. You have to take things by plane. I mean, ship, you have more options, but those waterways are not like really large, you're not going. Are not like really large, you know, going to where the communities are. We know how big wind turbines are. That's the wind turbine blade. How do you take it there? Maybe once for the initial operations, you can, but imagine the life horizon. I mean, that has a life cycle, that equipment. Even solar panels are not really small. So imagine that's kind of big community that your needs. You're going to have a lot of equipment, lots of kilograms that need to be transported there also in an ongoing manner. There also in an ongoing manner. So, all of those are going to make kind of your problem invisible if you're not careful about those aspects. So, just finishing off that introduction there. So, what is relevant? So, you need to figure out what is needed, what is wanted, and what is feasible. Talking to people, reading a lot of news reports, keeping track of the media, all of those are very important. So, definitely know your context first and first do the problem. And first, do the problem. Don't take the data and say, okay, this is a very good data. Let me come up with a hypothetical community and have this optimal microgrid, which is good again as an exercise, but not for implementation or publication purposes. We can do more useful things, so know your context. For Canada's remote specifically, affordable and reliable solutions are going to be our priority. This communities or stakeholders' priority. And they actually also. And they actually also want or prefer event-side solutions more than supply-side. So, everybody that's doing a project over there is thinking of clean energy, just replace, take the diesel out, put clean energy, and really not thinking about retrofitting the houses, building more energy efficiency, demand response so you can have more reliability through a flattened load at times. So, all of those are actually making more sense in that region, both from an economic point of view. From an economic point of view, housing safety, and that they're also interested in general of kind of the safety aspect from a holistic point of view. So, when you're designing, you know, a renewable system, it's important to think about a little bit of the future, if the community is going to grow, if they also want to make use of like, you know, greenhouses and you can maybe use this energy system to sustain growing food in there or new businesses will show up, hopefully, as there's more electricity over there. As there's more electricity over there, hospitals, schools. So you need to think about that expanding community and sustaining those systems as well. And since this is not a grid-connected region, when thinking about cost alternatives and trade-offs, generally suggested to look at not just money to purchase the fuel or the raw material, but think about the bigger scope of the entire supply chain, really, what is avoided cost. Again, you have to think about transport. Again, you have to think about transporting everything there, the surcharge of the material, and eventually the health impacts from environmental, you know, negative effects over the long horizon as well. So even though it's not the primary motivation, of course, that is cleanness is still a motivation. But just the point is more of your context. So that is kind of the intro that I wanted to start with, to at least make you think a little bit more. Just make you think a little bit more about your problems and see if there are points of mismatch in your designs. That some of the solutions or suggestions may not be really feasible in a bigger context to take a step back. So maybe I hope this is helpful to think about those aspects. So just to remind you, in the exercise session, we're going to be building or solving a problem in Mathematica. So if you don't And Mathematica, so if you don't have that in your computers until the exercise session now, just go and download it. So if you go to the website, there's a trial version that you should be able to access quickly. And even if you're not, you can track what I'm doing here and have the code later too. But many of you will probably also have access to the full version through your institution or university. I put the link for the University of Calgary software distribution. I know a lot of you are from PFC, but just From your C, but just check your own schools and yeah. So, any questions so far? Anybody? I have a question from the last slide. Yes. What do you mean that event soil is more important than sectors? Yes, so imagine like the community element on tan diesel generators. So everybody that's looking to improve certain objectives there, but the reliability, even reducing emissions. Reducing emissions, if you look at the literature, you won't find anybody discussing demand, like no energy efficiency, demand response goals in their package of hybrid system designs or solutions they develop there. It's only going to be like, I take five, six, seven out of these diesel generators and put clean energy in place of it in a battery. But if you can manage to reduce your demand or make it so that houses don't lose that much heat, right? So they are more energy efficient and everything, the demand goes down tremendously and the Demand goes down tremendously, and the benefits of it is way more than actually like trying to just send stuff, but it's clean, but it's still excessive and you know, unneeded. So, it's better to try to minimize the load and make it so the variation is actually as minimum as possible. So, the variation has the most drastic or negative impacts to planning and making sure the system is sustained without the lack of. So, if you can find solutions to reduce that variation, those would be, yeah. Variations, those would be really useful. Any other okay, so now we're going back to math basics. I said taking from advanced calculus and putting it to math linear programming ANOVA. So just a kind of an introduction. I don't know how everybody's background is in near programming and general optimization. So I wanted to remind you the basics. Remind you the basics. So we talk about duality. Everybody knows duality? Okay. Anyone who doesn't know what you're talking about? Good. Okay. So let's say we are trying to solve an optimization problem, has the general structure. So it's a very canonical or standard form to represent an optimization problem. I put kind of an expanded version of these vectors and matrices below. And matrices below to really see what we mean there. So, this could be, I mean, we're maximizing something. So, imagine a firm, maybe you're selling different types of goods that are represented by X and they each have a price. Or you can be thinking of like type of an abstract problem, trying to maximize the value you gather within a limited, say, capacity. Your bag has a capacity, and let's say each of the items you pick has a weight. So, those kilograms have to be less than your capacity. Than you know your capacity, say you have m bags in this case, so you can like the traditional format for an optimization problem. You have an objective, it's generally maximize or minimize. You want to have more of something or as like little as possible. So that's the goal. And now we put our constraints and kind of decision variable here is my x, which is non-negative. So I checked it to be non-negative. This is the kind of easiest optimization problem as everything is linear here. Everything is linear here. I don't have any negative terms, and these are called change variables. So, tomorrow we'll talk a little bit more about integer programming. You can have non-linear problems, and as you add more complexity, of course, it gets harder and harder to solve. Linear programming can quickly solve it. I mean, we have methods by hand too, like Simplex that we kind of learned in undergrad. I think it's just ChatGPT probably just does it in seconds now if you hear your problem. Your problem, so possibly you don't even need it. Uh, but this is when yesterday people were talking about park aslema. I'm not gonna take it from there, but essentially there is like this concept of duality is we can bond our problems in the linear case and in nicely behaved problems. Actually, the solutions for the primal and dual problems will be equal to each other. But the idea for the dual originally comes from kind of depending on whether. Kind of depending on whether it's a maximization or minimization problem, you can use the deal to have an upper or a lower bond to your kernel problem and get some information about your solutions. So if you have like strong duality, solving one of these is enough and the solutions are equal. With weak duality, we can bond them and also we can make judgments. Like if one of these is unbounded, we can decide the other is infeasible, vice versa. So without Vice versa. So, without even knowing the solution, this kind of helps us build on the problem thing. So, how do we take a deal? It's kind of, if you also practice about it, let's do it once because in the exercise, we're going to be taking deals of a more complex problem with also uncertainty and a two-stage. So, let's kind of do a very simple exercise just to show you how we go from one to the other. Okay, let's go from a minute. Okay, let's go from a minimization problem actually. And it's like I had an example here that I can make up new data too if we want, but just let's use this. Let's say I have this problem. I want to maximize or minimize actually in this case, maybe I want to carry the little amount of weights or so another objective or minimize the cost of doing something. And then I will have certain constraints. Again, there are going to be linear equations. Constraints, again, they're going to be linear equations. And for minimization problems, your constraints will be in the form of greater than or equal to for the standard form. So let's say I have some constraints. And I'm just putting in numbers now, but I will take out the numbers for the rest of the course, so just so you can conceptualize. But the whole point of this. The whole point of the lecture over two days is like, I mean, maybe that integer programming, but the idea is thinking about the problem without the data. So just make it basic, but see if there is need there, even if you take the most simple assumptions, if you can pick out anything interesting from that. So if this was my, like, say, original problem, what we do to write the deal of that is we assign a deal or shadow variables. These correspond to generally. These correspond to generally we use lambda, there it was y, I think a new variable. With the change of variables, we associate these kind of shadow prices or deal variables with each constraint. So if you have like more here, I had like three X's and three lambdas, doesn't have to be if I have more constraints, I can have more S sine because of that. And then, so let's see. So the coefficient matrix here, so I'm gonna write. So I'm going to write this if I wrote this in the form of Ax less than or equal to B, you would have 4, 2, 1, 1, 1, 0, and 0, 1, 1. So we transpose that and we go to the deal and we change this objective. So this is a minimization. We are now writing a maximization. And then on the objective, we are using. The objective, we are using now these new variables and the constraints next to each other. So, the b's, the original kind of right-hand side of the constraints, go to the objective function. So, I'm going to have like five, lambda two, plus four, lambda three as my objective, and then the constraints are going to be so we will flip this, transpose this, uh, so I'll have like four. So I'll have like four lambda ones and a single lambda two and zero lambda threes. And that is going to be now less than or equal to and c is this is here the original kind of uh coefficients there. But that's how we translate it. We can write the rest. So this is going to be two. Four and then so if you solve these problems and anybody wants to feed it into GPT, you'll see the solutions are the same. Yes, yes, yes, is it number one plus yeah, okay, yes, fine things happen. And then the numbers are greater than equal to zero as well in this equivalency. Oh, yeah. Yeah. So then now it's still like not easy to solve, but it's a very simple problem. If I use less variables, we could even like solve both equations and find a solution. In the linear case, you're going to find out this is equal. But where this kind of theory is coming from to show you, imagine I had all these equations here. All these equations here. Imagine I multiply them, let's say, like with X's and right side. So all those constraints on the left-hand side. So think about making them, you know, as like multiply these with these numbers. Let's say I have this and then the first constraint a11 x1, all of that. Say what next stand and then I can say this is less than or equal to b one times y lambda one and then do the same for the others all of them and now you have the nth one m ones so let's say you multiply these uh mth one and M1 and then add them together. You're eventually going to have this left-hand side less than or equal to these added together. And then if you group them in another way, take the x's out in parentheses. So you have in x, parentheses, these lambda sequences, x to the other sequence, all of that. Reorder them. You're going to end up with this kind of those terms. Kind of those terms, x's, but now a lambdas added together is less than the side. And then we can actually find the lambdas to satisfy this equation such that these are like greater than or equal to the c axis for these constraints that fall next to the x's. We can make sure that they are all of them are less than c. If you can find a solution like that, then we know that. Like that, then we know that kind of deals with the bond to this other problem. And if one solution exists, the kind of gap between them closes and they become equal in the linear case. And so that's kind of how it helps us. Now, this is very basic duality. So if we know the deal, and that's kind of how far we are going to build up to in the exercise session, sometimes you can avoid actually solving, solving the problem, and that helps to characterize. And that helps to characterize the optimal solution without really going into the Noma solution or the details of it. But we don't always have to use this for linear programs. You can use this, even convex is not masks, non-linear settings, any type of an optimization function. I can have this F to be any structure, same with my constraints. It gets harder and harder to solve, but it's possible. And then we can have. And then we can have both equality and inequality constraints. And actually, that could be also converted to a steel, which we call the Lagrangian deal in this case. I think, like, I don't want to see a digital mean and everything, but you can write the Lagrangian function with the objective and then again assign these multipliers to your constraints. And sort of they are like penalties of if you're not satisfying that constraint, you're kind of penalizing this function. kind of penalizing this function by how much you're not satisfying that. So if the solution is going towards the optimal for minimization, it's going to try to minimize those penalties and find a solution that doesn't really have none. So in the kind of standard form problem, so that you and then it still becomes, I think I can be more complex about it. Can be more complex about it. Somewhere here just search like Aglij Duality, Duality on Wikipedia, like kind of tells you all the details about this. It's very well known theories now. So if you So if you think about your original problem, let's say that L X lambda, and maybe I can even make it simpler. So imagine my problem only had the inequality constraints. So this was that. And let's say it's subject to these inequality constraints. So if you write your diagram. Your Lagrange function. I know over these constraints you have your orange multipliers. So when you think about the original problem, we are actually trying to find if you think of the kind of deal of this. And this is kind of the minimum. So, you maybe sometimes see this as income as well, where we're pushing the problem. But we're gonna try to find the kind of the X that makes this minimum kind of solve it as the kind of two-stage problem. And this part is the dual function that we have there, the G and kind of the. And kind of the if you switch over, sorry, if you switch over this, that's the part is the deal, minimum max over this side is the deal. And then if you kind of take the other maximum outside, they give the same solution as well. This becomes your field problem that you solve for that field function. If you have like those equality constraints, you can add that next to this one. So, yeah, I think it sources as form of the implementation. I think it shows this as form of the impending as well. So, if your solution is from visible domain of the problem, and now you can write the deal. And depending on how nicely behaved your function is, how convex it is, the constraints and everything, it could be strong and the gap delta gap could be like non-existent, or you might have a delta gap. But this is the kind of quantitative delta theory, and from there, we There, we don't know which is the chicken, which is the egg. This was the order I learned about this, but then we kind of build up to Kirish-fun-Tucker conditions or KKT conditions, which really helps us characterize the optimal solution to optimization problem. So if I have, n doesn't have to be linear, at least the constraint is the linear structure here, but we don't really know that you have to have like some regularity conditions. Have to have like some regularity conditions, and you need to check those, of course. But it's not very strict, so it kind of allows a lot of functional possibilities for your constraints and the objectives. If you have a standard form canonical format problem, optimization problem, and you write its Lagrangian function, you can check certain conditions that will help you characterize an optimal solution to that. An optimal solution to that specific problem. So, what x is solved as at the minimum? Doesn't have to be a single optimal, it can be more than one. But there are two sets of conditions, necessary and sufficient. So, for any solution to be an optimal solution, there are some conditions that are necessary that it has to satisfy. If it's a minimization problem, then you take the first order condition of your Lagrange in terms of the X's, then it has to be zero. Then it has to be zero on the right-hand side. So it's again, we can think about any function that the derivative is zero is the point where it's minimized or maximized. It's the same idea, but we're looking at the bigger large range optimal function there. And then, of course, has to satisfy the constraints of the original problem. That's our core feasibility. From the dual of it, we also have the deal feasibility. I didn't erase it, but the deal variables for this minimization problem in the structure. Problem in the structure, they have to be larger than zero. If it's a maximization, you can still write them like this, but then you like, yeah, use minus for the penalties, so you subdirect them. And then there's something called complementary slackness. So that is where kind of we force the optimal solution to minimize those penalties is your thinking about this inequality. So it's normally depending on whether you're in the interior above. Depending on whether you're not the interior of boundary solutions, either exactly zero or it's strictly less than zero. So if it's strictly less than zero, then you're forcing because it would, there is going to be a value. So if it's kind of strictly less than zero, there is, if you kind of look at the value of it and put your optimal solution here, there is going to be a penalty associated with that. So if the So if the dual variable is also non-zero and that's non-zero, you're kind of minimizing a problem and adding a positive thing next to that. So you don't want to do that. So we're forcing one of them to be zero. So either it's a boundary solution or it's in the interior, but then the deal is going to be zero or the shadow price associated with it is going to be zero. So if we just check these conditions. Just a comment. So it essentially means that that constraint is not valid. That constraint is not binding, not binding, or if it's binding, then your deal is free. Like it can also bind, but if it's exactly binding or it's a corner solution, then your deal variable can be strictly larger than zero. Yes, so when it's zero, it essentially means it's not binding. Yes, when it's zero, it's in the interior, yes. It's not bin. So this is the necessary, so it has to set aside. So if any of these is violated, that's not an optimal solution. That's not an optimal solution. So we can kind of find our at least candidate solutions from just checking these conditions, right? Ignoring the problem, not trying to solve these could be again complex equations, just characterize our conditions. And actually, we're going to do that and feed it into mathematical even. So we don't have to do that. And the problems can help us take these derivatives and even figure out solutions, programs. And you know, kind of the thing about Mathematica is first like Mathematically is first like you can make a lot of mistakes when you're taking derivatives with hand, and then it's hard to see and catch it. But having a software do the same for you kind of lets you see if you have a mistake there and it can like really plot nice regions where certain conditions are like, you know, let's say you want to find out values where this objective is larger than certain level or look for solutions that satisfy a different criteria. So you can just plot your. Criteria. So you can just plot your nice regions for parameters and everything that actually satisfy your objectives. And you can build up to even like numerical optimization problems from, so it's not only for theory, you can also use it for numerical calculations. It's very powerful. But we will stay on the theory side. So this is the necessary condition. These are necessary, but satisfying these doesn't mean it's still an optimal solution. It has to satisfy these, but for practice. Satisfied, but for that to be characterized as an actual optimal solution, we have also the kind of sufficient conditions. If those hold, that is sufficient, and those will be related to the second derivative. So if it's just a simple LP, I mean, see, they're going to be linear, so they're going to be equal to zero. So this is V, it's not a strict equality there. It's equal to zero is fine. If the second derivative is zero, you're good. But it's otherwise going to require. But it's otherwise going to require the concavity or convexity, or you look at the Hessian if it's a larger matrix to have that second-order condition satisfied. So essentially, if you take the red electrical twice for this minimization problem, we are having like this analogous of convexity here. So you need to have kind of have a vector, non-zero vector that you can write that satisfies that condition and then you can. And then you can safely say this is an optimal solution if your X also satisfies that. That's the JKT. Any questions? Yes. I was just wondering how effective are these optimization methods in terms of generating In terms of generating the optimal solutions for remote type problems, what type of problems? Sorry? Problems involving supplying supplies to remote communities, whether it be electricity or like how effective are these optimization methods? So I don't know what you mean by effective, but this is how you get the optimal exact solution, right? So this is the way of finding your Way of finding your analytical solution, but this is again not a numerical method. So you're going to be very limited in your power of being able to close form, characterize, and develop an analytical solution for an optimization problem without numerical methods. Again, there's nothing numerical here. We are doing a spear math, finding the function that fits the functional solution. So, in that case, if you have like start getting a little bit You have like start getting a little bit complex in the objectives in the constraints, you're not going to be able to solve it. So, there won't be closed-form solutions. I mean, if you could start going to four degree, 50 degree polynomials and stuff, you're going to start having either too many solutions or not finding exact solutions. So, in those cases, we go for numerical solutions. We use the actual data and do numerical optimization. Then you can have like a lot of things and do a lot of things. But, first of all, to understand kind of First of all, to understand kind of trade-offs in a problem, it makes sense to go a smaller version where you can characterize analytically and see if there are good insights even in that version. I would possibly add that, Kevin, KKT by itself is as effective as it gets, right? All the numerical machineries develop around solving KKT conditions, really. Yeah, so any serious method would derive this KKT and then, you know, solve it one by one. KKT and then you know solve it one way or the other. Either through some numerical homotopy market or what have you, but this is this is the only tool, really, except for if you're willing to use like ant colonies and whatever. Yeah, I mean we can have those like kind of maybe Neptune methods or step functions. You could just go for KK. Yeah, numerically solve them. You solve them in the analytical and numerically, but this is what you really solve. Yeah, true. Again, that's the way to solve the problems, yeah. Solve the problems, yeah. But analytically, you're going to be limited. I mean, analytically, the problems you can solve analytically is a very smaller set of problems in the wider scheme of things, I guess. So, there is also a lot of research done on finding better algorithms and better numerical methods that let you solve a certain type of a problem more efficiently faster. So, that's definitely a very valid research stream as well. And then your relevance is not as important to the poseomorphism. Important to the more of a theoretical contribution, right? And they are in general, right? These methods and numerical, they're super effective. I mean, people solve generous problems in reality. Yeah, and like many softwares do have packages already built inside them, so you don't need to like rewrite those algorithms or rerun the wheel. So like R, even like Mathematica, MATLAB, like even pre-ones, now pre-month, they will have packages inside to do those. Inside to do those approximations. Yeah. As I maybe comment, like this is the KKT is guaranteed to provide us with a local optimum, right? Like a local minimum. So stationary point doesn't mean it's local. So you can be. Yeah, but if it's stationary, then the relatives must vanish at that point. It can also be like a midpoint or a corner solution. You can also. Or a corner solution, you can also characterize corner solutions from here, uh, and they might not be maximizing or minimizing. Or, like, if it's a very nice to behave problem, yes. But then, again, as you said, like there could be kind of several points, even. Yeah, I guess if you look at a very small area, it's gonna be a local stationary point in that very small small interval. So, under suitable regularity. So, under suitable regularity conditions, like convexity, right? Convexity, you know, like that. Then it's local. But even if you look, if you try to solve like mixed integer problems, then you'll be solving a gazillion of these things locally, right, and doing some branching and so on. But it's like this is always under the rule, right? Again, yeah, there is no, these are all continuous variables, so it's so simple in that sense that we have here in a just the entire dot. Just the entire domain, but if we are looking for integer solutions or binary variables, it gets more and more complex. Yes. Yes, so true. I mean, you can use in different, so there is like semi-definite program. So, there is like semi-definite programming to write. Oh, you cannot see? Yeah. Okay, so maybe I can open. So, usually, you can have non-convex formulation of your optimization problems with energy and planning, but to solve them, you have to convexify or relax them to be solvable is the comment we received. So, yes, that's true. You either need to maybe relax. We will talk about more integer programming tomorrow. So, thank you, Thea, for that comment. You may need to relax them or find methods like, you know, when. Fine methods like you know, like with quadratic problems, we can convert them to solvable versions, like rewriting those constraints in a different format. So there's again semi-definite programming, which is like looser than convexity or concavity, the strongest, but still has those like regularity conditions. And if you go to like KKT. KKT or similar things in Wikipedia go around there, you can see like different regularity conditions as well that are not as strong as KKT, but like give you still some type of beat duality or a bound to the solution if like more, I guess, less strong assumptions are satisfied. So goals do exist. But ideally, yes, if you have a convex minimization problem or concave. minimization problem or concave maximization, that's you're in the good case and you can solve it. So let's go to the context wise is thinking of these optimization problems and the microgrid planning was my title, but any type of capacity planning over a longer horizon, think of the general Think of the general like microdata planning problem. It's you have a first stage in a way before stage where you do your capacity messengers. You need to build the generators, you need to have your system. And then while you're doing that, you yet do not know what's going to happen after you build these and you start the operation. So there is a whole bunch of uncertainties in between that we yet do not know about. Maybe the demand is uncertain. I mean, you build a solar panel, you don't know how much sun is. Panel, you don't know how much sun is going to be there. You have some ideas and maybe distributions. If you're lucky, sometimes you don't even have them. And you might also have like random shocks that are not really well behaved, well-defined. Certain cases, you cannot even foresee them. Like COVID, we say it's like Blexivon event. It's a shock that affected supply chains. Nobody planned for it. We couldn't have. So you cannot plan for every contingency. I mean, technically, a meteor could hit Earth right now as well. There is a probability for that. Now, as well, there is a probability for that. But when we are building or planning like microgrids, we don't think of every possibility of what could happen in terms of risk, just only the most relevant ones and uncertainties there. And then the second stage, after you build things, you would have the chance to observe the realization of some of those uncertain variables in between. And then, in the second stage, say the operational period, in the context of a microgrid, that's where you're like day-to-day. That's where your like day-to-day dispatch happens. There is a daily demand, and then you have to turn these generators on, satisfy that demand. Maybe one of them breaks down, you have to do maintenance, so it's those more in operational decision-making, which is going to be like smaller chunks. So maybe every day is a repeated problem, every minute, every hour. So you can bring it down to a smaller time period that's repeated. So, how long these are gonna be? The context, I mean, we're gonna keep again, not gonna have. We're gonna keep again, not gonna have any numbers. I'm gonna call this like a period of large t. So it's not gonna matter here, but when you're solving actual problems, you have to make this reasonable. So if your capacity investment decisions, say different types of generators, they will have different life cycles. So you need to make sure you account your costs to look at a similar horizon. So if you think of just the one year problem, normally it's maybe 20 years lifetime for a solar panel. But if you're trying to make it comparable, maybe you're Comparable, maybe you're like comparing one year of each wind turbine, solar panel, and everything. Then you have to make sure your costs are accounted for and reduced to that portion of time. So it's apples and apples, not apples and oranges. But essentially, it's the structure of a general, you know, two-stage problem with uncertainty, which we call two-stage stochastic programs or SPs, like linear programmers, LP. So you can have stochastic integer programming, SIP. Cast integer programming SIP, which is going to be even harder. And we have been using this methodology a lot. Some of these are really like good journals and kind of seminal papers in my area. So Management Science is a very good top journal in business and VGR is very good and so on. And if you go to these, they're all going to be, if you're interested, like two-stage stochastic decision-making problem in different contexts. So we're going to talk a little bit about this one to see. Bit about this one to see a technique that will later build on in the exercise session. But it's like manufacturing capacity decisions, even competing in the power market size as generators. Stage one, you might be submitting your bids, your supply functions to a central pool where you still don't know how things are going to realize. And stage two, like every 15 minutes, every hour, the market clears. So it's going to be the same structure or this is the kind of thing. This is the kind of day-to-day markets without the competition. With competition, I put the examples, and there are many more applications. And within the business journals, it's different a little bit. The operations management or research and engineering and the business schools, pretty much like different in the sense that in the business school, we are not really concerned with solving a particular application or one particular problem, but trying to do this more high-level analytical policy suggestion. Analytical policy suggestions so it characterizes a solution without the numbers in general. So we can make recommendations. And like if you increase the price of a certain thing, your solution will behave in a certain manner or go in a different direction. So the problems or the models are not going to be very complex. So even if like the best journals, you go to one of these papers, you'll see them solving the same thing. So when I first started business school, coming from an engineering background, I was like, are these people doing like Are these people doing like you know something sketchy because their models are really simple and it's like at most quadratic programs and we know how to solve them? So, where is the contribution in this paper? I had a hard time really understanding where the contribution is coming from. It like gets over time. It's not about solving the model. It's we're trying to solve it so we can make a judgment or recommendation about the solution, about the context. So, we model is a toy that we use here just to get kind of those directional insights. Get kind of those directional insights, that's why your contextual details become even more important. So, if you're doing something in a manufacturing setting and pretty much use a very similar, I mean solvable to space stochastic programs against a small set. So, if I want to solve this, functions are going to be looking similar, some quadratic penalty, they're going to not be too much different, but the context is different. So, you should have elements that are particular to your context that brings something interesting in that. So, if you have the exact Interesting in that. So, if you have the exact same paper as manufacturing people, but just change the variables, like you know, we did in some of our coding projects in undergrad, like you take the code from an upper year and change the variables and submit it again. So if you do that, it won't hold. So, you need to have a contextual thing that makes it particularly relevant to your problem, right? Why did you use that model and what is the idea there? So, we'll see some examples, but you can use like again any more applications that are like. There, like this is a bike allocation. I think for those rental bikes, you're allocating them to stations back to charge. You can have like a multi-stage. You can so first stage have an allocation, then you see the flows, and then you need to rebalance in the second stage. It doesn't have to be two-stage. Generally, we use two-stage, but there's also multi-multi-stage, so more steps, and then you can build onto more like dynamic programming if there are like dependencies between. If there are like dependencies between the time periods when you're going forward, we sometimes also call these problems with recourse because in the beginning, again, you come up with an expected solution based on an expected objective, and then you have a chance usually to recourse in the operation stage to make up for any deficiency because you didn't have the exact data, your solutions are not exactly. Your solutions are not exact as well. So you can tweak it in the second stage by paying for it, of course, through a recourse. So we also call them problems with recourse. So this is how to generally like show again standard form if I want to use that format. I can write a two-stage program. Let's say this is a minimization of like a passing. The minimization of like capacity investment costs. So, C is, let's say, your investment cost of generators. Next is how much maybe you're building. And then that is your first stage. There is an uncertainty that the side is representing. And then you, second stage problem, this Q solved is the solution, ultimate solution to the second stage program. There, in the second stage, you know what you are. State, you know what your random variables are, you have more information about that, but you don't actually know what you selected as the optimal axis. So, you solve this problem conditional on the x's, assuming you already know them. So, what if you knew the x, if you treated it as not a variable, but just a parameter, how would you solve the second problem? Then you solve it in terms of x, and then we start with that solution here. So then it will be in terms of So, then it will be in terms of a function of x and then also the uncertainty. So, when you take its expectation, now this is only in terms of the entire problem becomes a single variable program in the first phase. And you know how to solve it using the KKT connection. So that's the idea and how we treat these problems. So, this is more in a continuous setting, but as we talked about, either polynomial solutions we might need to express. We might need to expertise. Second stage program might be looking too complex to actually solve or take its expectation in that form. So, for the numerical solutions, you might need to do the discretization. Or if you like these multiple periods models, like individually, again, you still want to keep them, all of them, like from one to however many you have, 3000 hours, but I really cannot write that as like kind of that. That kind of that summation. But if you can disclose it very nicely, then actually you can write even the kind of stochastic program as a deterministic equivalence, like think of a full enumeration in a way like a scenario tree. So that helps us in driving solutions. Just a clarification: so QXC is the minimum of that. Yes, it's the minimum. So it's for the y star of that. Y star of that problem, if we plug that into objective function, and x is acting as a parameter, yes, and c is the random variable, and that is acting as a parameter. And solution will depend on x and c. Yes, and you're taking the expected exactly. I'm kind of removing the x c through an expectation, taking it out, and then it's we have a term left in terms of x on. Have a term left in terms of x only. So, we will, in the exercise session, we're gonna first build a simple problem in the context we're looking at, try to do like a very basic one and solve it with kind of different uncertainties, maybe for the demand and everything. So, we're gonna use Mathematica for that. But before that, I actually want to go over this. To go over this paper. So it's not the electricity context, but this is one of the earliest ones that actually derived a way or developed a way of characterization in the association programs that we kind of go back to and refer to. And it's actually related to, and we'll kind of go over it now, but related to writing your duality in a way. So rather than solving. Duality in a way. So, rather than solving this problem in this manner, we can have some advantages if we wrote the deal of it in the first place. And then we are going to see in the program that by writing the deal, we're going to have equations that behave similarly in terms of the C or the random variable in that problem. So we can reduce one in a way, like degree of freedom and Of freedom and gain and advantage. So there's a link to the, like if you click that, you should be able to get to the PDF if you want to look. And I have it here and I'll write the basics of the problem here. And like the context really doesn't matter for us because once we write it in the Us because once we write it in the standard form, it could be anything, it could be a healthcare problem, it could be a bike allocation, it could be manufacturing. It's like as long as it's of course relevant contextually and it holds, like a certain penalty function might not be relevant to a healthcare setting. So then it won't be appropriate to use. But it's kind of just a linear form or a metrics form program that you don't have to even know what it's about after you have. Even know what it's about after you have the canonical form. So, in this paper, we have again a manufacturing company that's trying to build products. So, they're trying to build a total of n different products and going into there, they have to use n different resources. So, each product might be like this, say, resources one through n. Maybe product one uses like some of one, a little bit of this resource, and then. Of this resource, and then the second one could be using like all of them in certain quantities. So they have like different needs for these set of resources, each of these products, and the company wants to build this like kind of portfolio of products there. And let's say they make money out of selling these. So they'll have this in format of a maximization problem. And each of these, like, say, can be sold at a like price by each of the goods that they are building. So if you write this in. So, if you write this in a vector form, and you'll see this in the papers, like third page, I think, this program. So, this is a, and now my x's are for period t. Again, I'm using this for multiple periods. And then let's say each of them is a vector of size n. So, each of them represents the n goods I produce at time t. I produce at time t. That's what I'm trying to decide. And then I'll have the price times the X's as my revenue. Each of them I'll be selling the same is up to the, of course, demand. I mean, these are all vectors. So if there's no demand for something, you won't get, of course, the money for it. And then also, it doesn't make sense to maybe produce a lot more. I mean, if you had like Like a constraint for inventory, you're able to store this. So, if you have a battery, let's say, in an optimization problem regarding a microgrid, then you might want to think of the solution and how the terms relate to each other. So, we don't have to fully satisfy the map, right? With each period? Right now, no, but if you want to maximize your revenue, you're going to end up fully satisfying because it's not going to be optimal, right? If there is more you can sell, it means you can improve your objective function value. Improve your objective function value, then essentially you're going to max it out. But yeah, so this constraints are not for the optimal solution. Constraints you write for any feasible solution for this problem. So as long as you have like, because you cannot sell more than the demand, as long as you sell less than the demand, it's feasible. The company might be able to do better, but let's say like they had no workforce, they couldn't achieve the optimal solution, they did something suboptimal. They did something suboptimal, it would still be feasible within these constraints and in this problem. And then we also have these kind of resource requirements as a constraint, like each of these is going to be using a certain number of the resources. So if I remember the metrics format, like A1M times however much I'm using from that resource, plus if I can write them in the matrix format, I can write this as. Format, I can write this as a capacity constraint as well. So this is for the demand, this is for the capacity, and this is maximization. And mostly for the grid problems, we look at post-minimization generally. So it just would be flipped with larger than or equal to constraints. But this is all another kind of x's are greater than or equal to zero, of course. So this is a product mix problem. Product mix problem, but this is the second stage of this, right? So, think of this problem. This is already once you know how much capacity you have of each resource, and then you should have gifted capacities to do that, which happened in the first stage. So, we're just now looking at the second stage part of this problem, the kind of Q that we're trying to solve. So, when we optimize this, find the X star and submit it into the objective function, you are essentially. Objective function, you're essentially going to get your q, the second stage value. So, this is very traditional problem that's been solved so many times before, especially if it's in the linear format. So, there's like really nothing too tricky here, only the fact that like these are in a way random. So, and in the constraint side of things, so right now, as it stands, if demand is random and in the constraints, it's very hard to get. It's very hard to get the optimal solution out of this in this format unless we figure out a way to move that to the objective so we can deal with that variable and take it out. So that's why the reality helps us. So now if we take the deal of this problem, actually we can save a lot of headache and kind of go to a really nice solution that fits in the first phase. So that's what this paper, I guess, first recognizes in the manufacturing setting as a theoretical contribution. Theoretical contribution, and then we depend on that a lot with certain assumptions, of course. So, as you have more correlations, so here these are not time-dependent, right? Like the A's, they could be time-dependent. So, that makes the problem more complex and maybe not separable as easily. But if it behaves nicely, not too many dependencies, so dynamic issues, then we can use this method. So, again, this is the second stage. So again, this is the second stage. So let's say I have a solution to this. And they use when you have the optimal and plug it in and let's say have the value, like instead of the Q, they use pi in this paper. So pi is the profit function of when we solve this in terms of going to be the capacity. Going to be the capacities here. So that's what in the first stage we decided. And also the demand. And actually, this could be T as well. So we can write that as a function of both the demand and capacity. So how we do that is we're going to take the dual and plug that in there. So here in the rest of the problem, we're also talking about actually. Problem they're also talking about actually still pre-writing it, but so see here the demand, yeah. PT is the CS. Yeah, and the first stage I have, and I'm gonna go to the paper because they build a more complex problem, but in the first stage, obviously, it's the maximum, it's still profits, but you're selecting the case now in the stage. How much capacity am I building for these resources? Resources which you want to get it. Well, let's go to the paper. Yeah, so this is where I took what I copied over there. So again, they kind of explain this here. They call the A a technology matrix, and ij element is how much of a resource I is required to build the product J. So J goes one to N and I go one to M there. So this is like standard terminology, we call cater to the capacitor vector. Call K to the capacitor vector as we discussed. And then the maximal profit function is they define it as this pi, where this x is kind of the optimal vector or solution to the second stage. So we don't, again, necessarily have to have only one optimal solution, but if you have multiple optimal solutions, they will all give the same objective function value as they are both like optimal. They have to achieve the best together. So it doesn't matter, then your pi is going to be eventually the same. Than your pi is going to be eventually the same, even with different x's. Any questions so far? What is the problem for K T here? So we're going to come there. I think they haven't kind of showed that in there. So the first stage is this expected little pi as your objective function that you're trying to maximize. Yeah, this is the kind of expectation of today. Don't have writing any. Expectation of so they don't have writing any additional besides there was a penalty that they're discussing. But didn't have to be in terms of T minus one. Yeah, so that is now kind of what they talk about here is if you want to check, as you said, resource levels in terms of what happened in the previous period as we build onto the other periods. So there is this kind of adjustment. there is this kind of adjustment cost or that's allow at the recourse each period in a way if you feel like you're under capacity you can add more to a resource so you can have the cost of adjusting your capacity levels up or even down they let that to be a bit negative so you can disinvest in certain resources maybe some of these not required anymore or build more you can do More or build more, you can do that in between. So allow that kind of a refort to add both positive and negative to each element. So from one period to the other, you can add or subtract from a resource and depending on it, have to pay something. And they are left free to be like positive, negative. So, the second thing is, which we haven't mentioned in the presentation, is there is also, depending on how long your time horizon is, you might need to have a discount factor as money value like depreciates over the time. So it's not going to be the same. And depending on how much you value future versus now, the discount factor is going to change. But usually, in the first stage, you will have like when you're maybe. Like when you're maybe summing over the T periods, your expected solutions for, let's say, the second stages, you will multiply it with some discount factor usually in the form of exponential decay generally, or that could be different ways to model it. This is the most common way to solve it, but you can have that discount and even could be like zero. You don't care about maybe certain periods too far into the future. Periods too far into the future, you can change your caring horizon as well. I assume less now there is no discount and these periods are at the same time happening. And so I'm kind of going to ignore at least in the exercise the discount factor. So let's go to this one example actually one I think to talk about. Talk about okay, so let's focus on this example: two products, three resources. So that's where we'll build this thing up. So imagine the ends or the X's. I have like just two products, and I have three resources that Resources that I can use. They gave the A here. Okay, so this is your technology metrics. So each, so product one uses each of these three resources. And yes. Yes, in these levels, and this is already product too. Yes. Okay. So ignore the details. I'm just seeing if they were important, but and you don't wanna for their context is important. And if you want to understand the context, just do try to see why they use the gamma and why it makes sense. Why they use the gamma and why it makes sense in this context. So, those are those relevant details that come up, but we are not talking about manufacturing and we will go to the electricity context. So, I don't want to spend a lot of time in the details of it, but just like assume this is it. This is your technology matrix now. So, what we want to do is if you write the constraints and expand that in terms of the different types of kind of Types of kind of resources you use, you must also satisfy certain reasonable feasibility constraints. Like you shouldn't, we imagine these. So they characterize these again, it's a context size. There is like parts you build and there is the testing and assembly. So you need to have like a larger capacity for you know assembly than like each of the individual components, etc. So it has to Components, etc. So it has to make sense. So there are certain constraints that we write. And then the again, first stage or very start to solution problem is look at the second stage contingent on, let's say, assume I know the demand vector and I want to write the optimal strategy of the third, I can look at the partitions of the demand space. So that's actually the values. Actually, about 80. So, your demand is, let's say, uncertain and ranges from can be negative, so zero, and let's say maybe is it unbounded here? Yes, so depending on your selection of case in the first stage, you're going to fall in a certain region. So, you might have like ample capacity here. So, there's a demand value such that the demand The demand, whatever is in the future, times your resource requirements is feasible within capacity constraints. So that's a possibility. But you might have selected like zero of our capacities in the first stage. So at this point, we don't know what we did in the first stage. So we're going to be ready for every possibility. We not necessarily assume it would be optimal. So you might also be in places where, you know, let's say low demand levels and necessary. Let's say low demand levels, and let's say you select the K to be here. Imagine you have a single variable. So then I have like two regions in this case. If I have a simple problem, two regions. So I can be in a place where demand is less than or equal to my capacity. And I can be in a place where the realization of demand is larger than my capacity. So what this paper says or characterizes, and they do that for actually four different five different regions here. Five different regions here. So, the three resources and the constraints they have, it translates to five regions, so it's more complex. But if you focus your attention on just these partition regions, they will have kind of a very identical structure in terms of their duals and Lagrange variables. So the problems dual in this area is consistent, and problems dual in this area is consistent within itself. Consistent within itself. So that is how we write actually kind of the after we characterize the shadow prices and shadow variables, and we'll do this like one by one on the exercise together, you can write your second stage objective in terms of that large range multiplier. So this is your B lambda, if you imagine. And then for every partition, say like for the first partition of the second one, third. First partition of demand, second one, third one, and kind of fourth one here. In their case, if we wrote R's, it's going to be two. So there's going to be a summation of two things in my problem. And this format is going to be consistent within that region of the demand. So all of the shadow variables, there values, will be same here. So then I can write that lambda that is within given that d is less than or equal to k times the probability that this. Times the probability that this happens. And I can add the second domain, like second partition there. And if I have more, I can keep doing this. So this is where the kind of the shadow variables given that the event was larger than K. And then I can here write the probability of this other event happening. And this would be equal to the expected value of this pi. If I take its expectation, the expectation. The expectation of that is going to be equal to the expectation of that one. So that's what this paper shows eventually and proves. And I don't think we have much time to go over the details of that proof, but please read that. And if you're interested, of course. And then just plug that in the first page and solve our problem. So this is really simplified. I couldn't find something with two variables. This was the kind of simplest. Puzzle kind of simpless, but you can actually see the partitions here. Okay, so I have the two products, I think. One of them is here, the other is here, and there's a like a capacities problem for assembly. And we have to leave descriptions now, I forgot, but essentially you can have these kind of five regions with the demand realization. So you might be like here, I think one of them is like you don't have enough capacity for one of the resources. Capacity for one of the resources, and then you have to go to the corner solution for that because there is not enough capacity, so you can't produce as much. So, the solution that goes to whatever, however much capacity you have for that resource, but the other ones are feasible. So, the zero is that both of them are feasible. So, it's the interior, you have capacity available for both resources. So, any solution in here will have the same kind of shadow prices if you want to kind of move. And if you want to kind of move your object value, there are other partitions here too. So I think this is where that assembly starts to be the constraint that we are kind of hitting that corner. And then this is for the other resource. Essentially, I have like three capacity constraints here. And depending on that, I can be either in the interior or these four regions. This is an analog of the omega one or the other. Of the omega one for the other resource, and omega three is like he lines too much in terms of every type of resource you have. So you've got the nearest corners that you can physically produce. Yes, and then each of these domains or regions have the same set of shadow prices, so we can easily characterize the second stage objective. We're out of time. Yes. So now I'm going to stop there. So now I'm going to stop there and we will do this exercise together for a smaller, simpler problem in the exercise session.