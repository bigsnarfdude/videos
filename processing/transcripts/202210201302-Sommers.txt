You know, but you're not going to start exactly on time, so you can take additional device that we're not going to be around. Yeah, right. So, I'm not saying I can say it doesn't play. I think we'll be very pretty, but you don't want to be able to do it. Okay, I think that we should get started soon. Yeah, thank you. Okay, quickly before I introduce Eric, I mean, okay, making me use my teacher voice, which is a projection. I wanted to go over the schedule because there was some confusion and some changes to this afternoon. And some changes to this afternoon's schedule that, if you had looked at it a few days ago, may not know. So, let me just, I think Latino briefly talked about this this morning, but I just wrote it on the board to even further clarify. So, like, right now is Eric's talk. On the schedule after his talk is actually an open discussion, which is scheduled to take place in this room. And the topic is on arbitrarily type Hessenberg varieties and the dot action and the setting. Then we have a half-hour coffee. Then we have a half-hour coffee break. There's time for a group discussion, and then we'll also be hosting a virtual discussion for students. So those take place at the same time. It was similar to Tuesday afternoon. And then actually, this is an additional thing we add to schedule. This is a casual open discussion again back in this room. If you're interested on affine springer fibers and the connections to Hessenberg varieties and chromatic quasi-symmetric functions, which Eric has sort of graciously agreed to start. Graciously agreed to start off at least with the other eric, yeah. Two erics. I mean, in my head, I can clearly see the K versus the C, but it doesn't transmit in language. So just to let you know, this is the outline. It is a very full afternoon. I'm not going to take attendance, so if you need a little bit of a break, please give yourself a break. I promise no one is going to be chasing you down, wagging their finger. At least me. I guess I. At least me. I guess I can't vouch for the other organizers. Okay, but without further ado, Eric Summers is going to tell us about Hessenberg varieties and related objects in general in Taipei. Thank you, Martha, for the introduction. And to you and the other organizers for organizing such a great conference. And also, thank you for the joint work on which this has been. Three thanks. So, yeah, really, really sorry. So, yeah, really, really sorry we're going to have to leave Taipei. But I think that's okay. I'll try to do my best. So we can think of arbitrary root systems, finite in finite spaces. And so you have your root system, your positive roots, your simple roots. Reflections generate the vile group, also generate by simple reflections. Reflections. Everything lives in an ambient space, which is n minus 1, so I can keep the n for gln sln, where we usually like to work when we work in type A. So our favorite object, I think, at this conference, or one of its many equivalent things, are the DIC paths. If I write it like this, I can think of it as a If I write it like this, I can think of it as living in a matrix, five by five. And if I just look at the dots, so this has already come up in earlier talks, I want to say Jennifer Morse. If you take the dots above and you look at the coordinates of the boxes, and you take the difference, what is it, the row minus the column, then you can just think of that as a root in the root system. In the root system. So it's a root space. If you're in the matrix itself, it's a root space for the Lie algebra, which is just the n by n matrices. Okay, so what happens when you take a dick path and you do this? You get an upper motor ideal. So we heard that already, so I think we know what that is. And then you're familiar with the famous fact that the DIC pass or the Catalan number here. So, our first foray into other types is to take the set of all upper order ideals in whatever corresponding root system we're interested in. And then we have a nice analog of the Catalan number result due to Cellini and Poppy in all types. And that is that the set that we're interested in has a formula that uses some nice numbers from the root system, the rank. From the root system, the rank, R, the Coxeter number, and then the fundamental degrees from the invariants of the Weyl group. And H is actually the top invariant, the largest fundamental degree. And W is also the product of the fundamental degree. So you can even get rid of W in that formula. So maybe you should remind what's Sage in the A. What's Sage? H in the A. Oh, oh, oh, yeah, I think, yeah, so I think. Oh, oh, yeah, I think actually, yeah, so thank you, thank you. It's written there. Yeah, so H, so the fundamental degrees would be 2 through n plus, I switched to N. Supposed to be, I kind of went back and forth, but yeah, so if I'm in AN, then H is N plus 1. Okay, so it's actually the N that I had before. So I didn't change that. So anyhow, it's 2 up to that number. 2 up to that number. And if you multiply that, then you would get, well, you'd get n plus 1 factorial with my poor notation here. So anyway, you can work out just that you get the same number. I will talk about EA twice. So here's the first time, just to show you that it's not an outrageous number, 25,000 roughly. So if you want to attack the dot action and type E8, you've only got 25,000 cases. You've only got 25,000 cases to work. All right, now let's upgrade to the Lie algebra or the group. So we're talking, depending on, it doesn't really matter much for this talk, GLN, SLN, the Lie algebras, the matrices. Yeah, so it's not really, I think I changed later, it's not other types, it's all types inclusive. So type A comes with more. So type A comes with more goodies, which is, I think, why it works well. But anything you can do in type I mean, anything you can do in the other types, you can also do in type A, and maybe that can be helpful too. All right, so we have the upper triangular, strictly upper triangular, or sorry, upper triangular and the diagonal. And you can do that on the group level, the Lie algebra level, or the group level. And then you have the strictly upper triangular, which is the nil radical. Which is the nil radical. All right, now if you start with a dick path, you can, so we could, in the previous slide, you can pass to the upper order ideal, but you can also concretely take the matrices where those dots are not, everything else is zero, and those dots can be arbitrary. So that will actually be a vector subspace, seven-dimensional. Subspace, seven-dimensional here, and because of this, the way it's set up, it's stable under the action of the Borel, which is pushing everything higher. That's the upper-order ideal piece. So you might want to actually have the subspace, not just the set of roots. And I didn't want to get into the font issue. I'm going to mix up the two things, so you have to be able to go backward. This doesn't come up that much. It's mostly going to be this one. So those are sometimes also called ad no-potent ideals in the piece. Called ad nilpotent ideals in the paper by, for example, Shellini and Poppy. So you can pass from the DIC path to one of these adenil potent ideals, or you can take the transpose of the DIC path, and you can do what most of the talks that mention this did, which is to take the stuff now above it, and that's the Hessenberg space. The Hessenberg space is going to contain the full Borel, the upper triangulars, and in particular it's all. Triangulars, and in particular, it's also going to have to contain H. So it basically has every element, up to conjugation, every element in the matrices is in this space, so I can see why it has some advantages. You have to be nilpotent if you're in the ad-nilpotent ideals. So there's only a finite number of conjugacy classes of matrices that intersect that. So that is also why that has an advantage, because there's less sort of to deal with. Sort of to deal with. So you can go back and forth between these two. It's just, if you want to be, if you don't have your dick path, of course you can combinatorially say how to go back and forth, but it's under the killing form. It's actually the orthogonal space in the Lie algebra. And now, so there is more stuff going on in type A. I mean, you can take all the roots which are not in the upper order ideal and connect them, connect the row with the column. Connect the row with the column. So that's just the roots below the diagonal back in the I case. But then the games that you play in type A, like these two games, I don't know if you don't want to call them games, two things that you can do, there aren't really direct analogs as far as I know, and I know people are trying to do that. But I guess all the related, many of the related objects do exist in all types. So for example, The Moscow's Dodd action, the monodromy action of Braznian Chow, and so on. So that's there's nothing good, that's why type A is better, because you have this other thing that you can do or things that you can do. All right, so let's get started. Why, one thing that makes other types more difficult, besides the fact that maybe they don't have some of the concrete gadgets. So in type A, these three things are all the same. So in type A, these three things are all the same, and we've been in some of the lectures we've been exploiting that. If you have a partition, partitions parametrize the two important things. They parametrize the no-potent conjugacy classes, and they also parametrize the irreducible representations. But then there is this formal way actually to go between the two on the top, and that's the Springer correspondence, which I'm not going to talk about too much, but to each nil-potent-constant class, you can. Class, you can, well, I guess we've talked about you can construct the Springer fiber, which is a Hessenberg variety, and then SN acts on that. And in the top degree, you'll find the irreducible representation. So Springer correspondence exists. So all those things exist in other types. I don't know what to say here. You have your vile group and you have its irreducible representations. You have nilpoten-congency classes. Nilpotent cogency classes, you have the group acting on the Lie algebra, and you take the nilpotent orbits. So you have that. And you do have a parameterizing set, at least for the nilpotent orbits. So maybe I'll start down there. So there's something called the Jacobs and Morozov theorem. If you have a nilpotent element in your simple Lie algebra, all our stuff is simple here, simple Lie group, simple algebraic group simple. Then you can embed it in an SL2 triple. So you can get a homomorphism from SL. So you can get a homomorphism from SL2, which hits E. And the interesting thing is it gives you this semi-simple element. You ask where does the diagonal 1 minus 1 go, and that's H. So each nil potent element gives you a semi-simple element. And things are well defined up to conjugacy. So if I conjugate my E, I conjugate my H. Now you have a semi-simple element. You can put it in your carton, and you can just evaluate all the And you can just evaluate all the simple roots on it. So if I take the nil potent for partition 2,2 and GL4, then when I do that process, I end up with this way to dink and diagram. So the first simple root has value 0 on H. I think I wrote it down here. These are the values of the simple roots on H. And that characterizes the nilpotent orbit. So each nilpotent orbit comes with a unique Comes with a unique weighted Dinkin diagram with positive coefficients, non-negative coefficients on it. And in fact, those coefficients have to be 0, 1, or 2 from SL2 theory. So I give you another example here. So they don't have to all be 0, 2. You can get 1s as well. So for the 2, 1, 1, we get 1, 0. Okay, so you have a parameterizing set that comes up a lot for the nilcon orth. But the problem is there's more irreducible representations. There's more irreducible representations in other types than nilpotent orbits. And what was figured out is that you need this extra piece of information, basically coming from the fundamental group of the orbit. And then it's more complicated than that. Not all of those representations of the fundamental group of the orbit. Not all of those even show up. So there's kind of like two L's. But once you restrict to the ones that need to be there, then there is a spring requirement. That needs to be there, then there is a Springer correspondent. So there's a way to go from a Vile group representation, irreducible representation of the Vile group to a nilpotent orbit, but it also comes with this extra data of this representation of the fundamental group of the orbit. Taking the general point of view, but if you specify one specific W or ME for A and we know for a. And we know for other specific families, we might know explicitly more of the story. Yeah, you mean to actually explicitly work out this correspondence? Yeah, for safe. BN or something. Yes, absolutely, absolutely. You can work out this correspondence inside BN, take up a pair of partitions, and then you can say exactly where. I mean, I just, you know, like the Atlas data, like the VATLAS data is online, and they And they, like for small rank cases, there's a lot of examples there. So, if you were just looking to get started with some examples, it was very first once that information does. Well, my point was not that I don't know, but my point was that if you have, you restrict to a specific family, the picture is more complete. Yes, I guess my point was that, you know, maybe you don't know and you want to know some examples, there's like a really great resource. Examples, there's like a really great resource for that online. In fact, Eric and I cite it in our papers because we've worked at those tables to help us with our plan. There's some special, so now that we know that no potent orbits, we probably want them around as part of this triangle that exists in Taipei, and we want these ideals around. One thing to know is that each ideal, I mean, each nil-potent word can be a, we can. I mean, each nil potent orbit can be, we can go from a nil potent orbit to a specific ideal, which I'll call the Dinkin ideal. So if you take that semi-simple element and you grade your roots by the value of each root is given alpha h. So that's going to be an integer because we have an SL2 representation. And then you consider all the roots where h is at least 2. Then because of the 0, 1, 2 thing that I said, this actually has to live in the null. This actually has to live in the null radical. So it has to, only positive roots, in other words, can be involved. And it also has to be closed under the action of adding a simple root and staying in there. So each new equivalent order comes with this ideal called the Duncan ideal. And so let me just show you what that is for these two examples. So what you could end up with is a parabolic thing where you A parabolic thing where you touch the diagonal. So that's if you were on the dick path scene, I can actually write in real time, not so well. If every corner touches the diagonal, then that's like the parabolic case, so that can happen. But it doesn't have to happen. So this box is too high up there. And what's going on here is that we can actually go from ideals to nilpotent orbits. So to each eye, there's a unique nil potent orbit. There's a unique nil-potent orbit, O sub I, so that when you intersect with I, it's dense in I. I mean, there's only finitely many orbits, so you're going to chop it up, but the point is there's a unique one, basically because I is irreducible, that has largest intersection. Okay, so that gets us a map from the set of ad-nilpotent ideals to n. So usually we use n for the nilpotent cone, and then maybe an O. And then maybe an O for nil potent orbit. So that's a finite set on the right there. And we just go from, we just take an add nilpotent ideal and go to O, go to OI, so associate an OI to it. And the point is that if you take the Dinkin ideal for E, you get the G orbit through E, which in particular means the map is surjective. So every nil potent orbit arises. Why is it going to arise multiple times? And then I usually like to stick in this result here. It's not so well known, but if you, I just want to say that there is something really combinatorial here, a combinatorial root system here, that the partial order by inclusion of upper order ideals tells you exactly the partial order on nilpotent orbits. So orbits are ordered by inclusion and the closure of another one. The closure of another one. And then an i is just strictly by inclusion. And the partial order on no ponoris is calculated completely from the one on i as soon as you know how to compute OI, the associated orbit. So it's clear that if an ideal is contained in another, then the largest orbit is contained in the largest orbit, the closure of the largest orbit of the other. But the point is that Is that the harder part? Is that if you have two orbits that are related, you can actually find ideals that give those orbits and one is included in the other. So it's really fun to work that out. It's basically how Mizuno and others first calculated the partial order on the nilpotent orbits in E8 and E7. So there are other ways to do it now, but that's one way. Let me see. One way to find universes algorithm or which one? To find OI or to find I1 and I2. There is an, yeah, so there's a, I guess, an algorithm to do it. But normally, once I have this theorem, then I'm mostly interested in which orbits, the OI for each ideal, and then I just use the partial ordering on Ordering on the adenal potent ideals, to then you can produce the partial wording that way. But if you did want that, you could actually chase that around too, without having to produce all the adenal potent ideals. Anyhow, the ordering in GL4, this just came out too big, the ordering in GL4, here are the 14 dick paths, the 14 subspaces. It's a linear ordering, so it's a little boring, I should know, but basically, here are the five. Should know, but basically, here are the five. So, you want the rank one matrices. So, you're basically just asking, hey, what's the largest, not just rank, but what's the largest Jordan form I can get in there? So the rank ones are going to correspond to 2, 1, 1. And then here is the 2, 2 stuff. And then, you know, then this is the only one that will intersect the regular notebook. The regular nil potent, and then you have the five other ones for 3, 1. And you can just see, yeah, that's linearly ordered. So you have 4, 1. So I guess it's reversed the way I've got it here. And the triple. Okay? Just an example. I think you can go to C3 and then it's not linear. How do you know those 5R? How do I know those 5R? Those five are. How do I know those five are related? I'm. Experience. What's that? Experience, right? Well, well, well, I was trying to just do like the rank to say that it's rank one, so the only possibility is two, one, one. But so I'm going to talk about the modular law in a moment, and that can be used to show that they're all related. I didn't actually think to include that, so if there's time, let me come back and mention that. So you can actually. And mention that. So you can actually. So I'll talk about the geometric modular law, which is related to the modular law of GPA K and of Runi-Grow. And if you use that philosophy, then that actually gives you a systematic way to show all these equivalents. And then I have a paper with my graduate student, Molly Fenn, where we show that it exactly generates these equivalence classes. But I didn't actually have that. Classes. And I didn't actually have that here. So let's see if it comes up more naturally when I get to the geometric modular law. All right, so now, so this actually did come up, Jennifer Morse's talk, she built this vector bundle from the ad nilpotent ideal or the DIC path. This is the vector bundle there. And then I guess it was tensored eventually with a line bundle. So you take this vector bundle, you can take any B representation and And build such a vector bundle. It's a vector bundle over the flag variety. And the point is, for this particular kind of vector bundle, I can just project, I can let G act on this, the first coordinate act on the second coordinate. And now, because everything is nilpotent, I end up in the nilpotent cone. This map has nice properties. It's proper. It's G-equivariant. This object is a vector bundle. It's smooth. And then, from the definition that I already gave, the image is not in general surjective. It's rarely surjective, except for one ideal. It won't be surjective. So you'll miss the regular orbit if you're not the full nil radical. So there's some orbit, and it's the same orbit that I defined before. It's the closure of that orbit. So it'll contain that orbit and everything lower in this partial order that we just talked about. Definitely feel free to ask. Questions? Other questions? All right, so now we're getting back to where we need to be. So we have a Hesseberg variety. So this Hessenberg variety hasn't been defined yet, but it's the same as the one that was defined by Laura on the first day, except now I'm using the ideals instead of the Hessenberg spaces. So I'm doing the same thing. This map wasn't there, it's just the This map wasn't there. It's just the fiber over an element in this map. It has the same definition. You're looking at points in the flag variety so that when you act, well with the inverse, you act on E, you're constrained to come back into the add no potent ideal. So I'll adopt the convention of the conference for the notion. Notation. Tell them how to write. There's a lot of characters. It's a lot of characters. So that will be the same object where the, it's really the same definition, everything you saw before in type A with the flabberg, except the only difference is that you have to replace your hustle workspace H with one of these ideals. Alright, so now I want to describe for these varieties some work with Martha and a student of Patrick Brosnan. Ken. Ken Shui. Shui. Shui. Ken Shui. And it's really based on Based on the ideas go back to a paper of D. Conshini-Luc Broschesi. Now, before I do that, I have two remarks. So again, the image isn't surjective. So if you're not in the image, then your Hessenberg variety is empty. And then you have this cool fact, which is one advantage, I think, to these, is that if you're not going to be able to do this To these is that if you are in the, if E is chosen from the biggest orbit in the closure, then the variety is smooth. So you get that for free. Now what happens if you go to a smaller pointer here? It's been a while since I lectured on Zoom. If you go to a smaller element or orbit in the closure of OI, that doesn't have to be smooth. That doesn't have to be smooth. And what you can do is you can imitate this paper, I'll just call it DLP, and you can partition up your variety into a set of smooth varieties which are no longer projective. So what they turn out to be, and there's some indexing set by the Weyl group, they turn out to be vector bundles over smooth projective varieties. So I'll give you an example in a Varieties. So I'll give you an example in a second. Now, what are these W's? So I kind of hide the definition, I didn't want to get into it too much, but basically they're minimal cosmic representatives for a parabolic, so like a young subroot, and then there's a further condition. You can calculate what those are, and I'll show you what it is in a second. Basically, you break it up into these vector bundles. The vector bundles are smooth over these littler objects. And it turns out, so one way to And it turns out, so one way to say it is that these littler objects, so we really got to figure out these. Because the cohomology of this is just going to be, the complexly supported collomology of that is just going to be the cohomology of the smaller thing just shifted. So, but it turns out that those are actually just smaller, those are just other, those are just a subset of the things we're trying to calculate. But they're very particular, so they only. So they only come from this case where E is an O sub J. So they're smooth. So that's the smooth case when you're in the largest orbit. Moreover, they're constrained to be in this G greater than or equal to 2 space that we had before. So if you start with a nil code E and you have this SL2 triple and you find this subspace, then only it's not necessarily a small number, it's a much smaller, it's a smaller number. It's a smaller number of ideals that you have to worry about, and, but more than that, you only have to consider E in the dense order. Okay, so, and then what's the condition? How do I get from W to this object? You take W inverse of your upper order ideal, or your ideal, you intersect it with the G2 space where H acts by 2. You just tack on this higher. You just tack on this higher thing, and that will be the J. So if you get such a so the w's that we need are the ones that we get a j, like up here. And so again, sort of set it, but the gi is where h is acting by eigenvalue i. That's always an integer. Can you say what it is? If it's just the flag variety. So with the flag variety, so this is why there's some. We're sorry, this is just G minus. For sorry, it's just G mod B. G mod B, yeah. So then it's just W as the identity, and the smooth variety is just the flag variety. So that's kind of a weird thing. So you'll have, these will often be like little baby products of baby flag varieties, and in that case, it's just the flag variety. So we kind of declare that we know the flag variety, or the GMOD P case, and that's kind of, those are examples of these HES EJs. Hess EJS. If I intersect the Hessenberg with each of those smaller things in the flag variety case, I'll get the intersection, this intersection. I'm not sure about that. I'm not sure I understand. Like if I just take this decomposition just for G mod B, I just intersect those slices with the Hessenberg variety, and then getting those slices. No, I don't know. No, no. It is different. It is different, because the GMOD B case itself is just this one thing. Yeah, so the Hessenberg, so you're varying the Hessenberg space or the ideal space, and you're varying the nilpotent. And then you only need to calculate when the nilpotent is tightly connected to the Hessenberg space in this one way. I had some more details, but I think it's better. I'll just be sort of high-level. What this decomposition gives you, though, is a way to compute the cohomology of your general Hessenberg space. In this case, I'm in the ideal setting. And once you know these smaller ones, these smaller smooth ones. So there's some shift because of the vector. There's some shift because of the vector bundle. The shift is by the dimension of the fiber of the vector bundle, which is also just something that comes from W. And then you have to compute these other things, and then you can add it up. So the upshot is that the computation of the cohomology of the nilpotent ideal Hessenberg variety reduces to computing this set of file group elements. This set of file group elements and these smaller smooth varieties. So I'm going to kind of omit how that might be done and just tell you one corollary, which is really important in all that we're doing. So there's no odd cohomology in any of these ideal Hesseberg varieties. Now, most of them, we already know, say, from Martha's work and Juliana's work, most of these are paved by affine, but in type E8, actually we don't know, even for the springer fiber, whether it's paved by affine. The springer fiber, whether it's paved by affine. We do know that there's no odd cohomology, so we do, but just to confirm that we get even in E8, we get the vanishing of the odd collomology. And basically, it relies on work of DLP. Alright, so finally an example. So just if you do that 2,2 case, and now I'm going to actually do the Springer fiber, just because it's maybe a little bit more familiar. Maybe a little bit more familiar. So I've inserted N for I, so it's the null radical. Going to get the Springer fiber. So it's three P1s, and they touch like this. It looks just like the Dinker diagram. And then what does this method tell you to do? It tells you that there are actually three J's that arise in this computation and their corresponding smooth varieties. Varieties, we get P1 itself, we get a point, and we get a point. And there are three Vile group elements that show up. So it happens to, it's not usually the same. Usually there's way more Vile group elements than there are J's, but here it's exactly the same. And so what's going on when we do our decomposition? The decomposition into those Y's is actually this. So we pull apart the two P1s. We've lost a point from them because they stay with the center P1. What happens to take a? P1, what happens to take a point out of P1? It's just C. That's a vector bundle over this point. And the other one is a vector bundle over that point. And so that allows you to add up the cohomology as 1 plus 3Q. That's the cohomology. The Poincaré polynomial, well, it's really 3q squared, but everything's an even degree. We'll probably just be forgetting about the even degree like that. So that's the Poincaré polynomial. In E8, just to give you the most interesting, I think the most interesting example in E8 often is for this particular null potential orbit, E887. And it's the one with the most local systems from earlier in the talk. In that case, the size of the bile group set is 4,480, which is not so crazy. 480, which is not so crazy. The vial group is enormous. You cannot store the, on my laptop, I cannot store the vial group of E8, but I can definitely locate these 4,480 elements. There's a systematic way to locate them. They come in seven flavors. That's not really important. But the point is that the J's that we consider is 501 J's. You have to make this computation of the 501 test EJs, and then you're good to go. One thing that we know. One thing that we know is that the number of yw's is always the dimension of an irreducible. And so that's nice. There's 4480 is the dimension of a particular irreducible of the VAL group of E8 that sits at the top of the Springer fiber for this element. So it's kind of fun to go back to the Springer case even. So this is basically just kind of already in decontinuing Lustic Perchese. Already in decontinualistic Rorsches, but it's fun to write down so far. Okay, so if we carry out this method, so what's the point? The point is we can maybe start to compute things in other types. It's probably not very legible. These are the Poincaré polynomials of these Hessenberg ideals with a slightly different, with my old notation, or our old notation. So these are, there's 20 idea, the W Catalan number is 20. Here are the 20. I'll try to zoom in a little bit. I'll probably slip. That's better. That's better. So on the bottom, you'll find the Springer varieties from the regular Springer varieties, just a point. Over zero, it's the whole flag variety. Yeah, so actually, over zero, it's always just the full flag variety. What's the asterisks? So the asterisks are the J's. The J's. So that if you want to know the J's from this, you come to the largest, the diagonal has the colomology that you have to compute independently. So basically, you compute. Independently. So basically, you compute the diagonal and then you can compute everything below the diagonal. Although, of course, this kind of comes for free. So they don't have to be smooth. You can see that it's smooth along the diagonal. It's a product of Q numbers, which at least shows it smooth. But it doesn't have to be lowered down. Although a lot of them are, I don't know. Or a lot of them seem like they're rationally smooth. I don't know. The other comment is: there is. The other comment is there is this extra, so for the nil potent orbits in type B, you have to have an even number of even partitions. But we do have to take into consideration these local systems, so they're broken apart. So there's more data than just the nil potent orbits, which I was talking about in the Springer correspondence. That data, one what do you think? Can you read it? I'm sure. Let me know if you want to focus in on any particular ones. So, anyhow, so they're grouped by the bars are where they all have the same nilpotent orbit, OI, associated to them. And the second column is the roots, the minimal roots, the anti-chain for the upper order ideal. I think I've asked this sort of thing before of you, but just so I mean types B and C are different, even though the value is the same. Yeah. Did that actually represent feature? Yeah, yeah, like this table would be different, right? Right, I really should have. I meant to like clean up the C3 so we could see C3 next to it. But even, but the thing is, actually, B3 and C3 have different number of nilpotent orbits. So we would need to go to like two slides. We would need to go to like two slides later where we actually go to the dot action and then actually make sure that that is different. So, definitely, this will be different because there's different like parametrizing things. Something like that. Right, so I mentioned here, I don't know if this is the crowd for it, but the extra piece of data is coming from, there is something group theoretic. I said it was the fundamental group of the orbit, but it is group theoretic. But it is group theoretic. It's the centralizer of E, mod its identity components, a finite group. They're very simple finite groups. It's S5 was the one that came up in the E8 example. And in classical types, it's just a product of S2s. So it's elementary abelian. So that gives some hope. If you're interested in the other types, you're going from the trivial group to elementary abelian groups. They're not crazy groups. Okay, so anyhow, I Okay, so anyhow, I was showing those isotopic components in that table. It's not essential, really, for the rest of the talk, though. Okay, so let's get to the geometric module long time. A decent amount. So I was having Matthew's talk. I think that was yesterday. Feels like I've been here a long time. But not long enough. I'd like to stay a little longer, if I can. So he exactly wrote down: so, first of all, let me just say. So, first of all, let me just say, I write it later, but there was a Zoom talk early in the pandemic. Alejandro Moraz organized it. I forget, was it Antonio that spoke or your collaborator? I forget. Antonio spoke and I went and I like, oh my gosh, this is the same thing, we're a similar thing that we're doing. So emailed Martha. She jumped on. After the fact. After the fact. But anyhow, so we're highly motivated by that talk and that paper. And those papers. Paper, those papers. So, but we want to give a definition of all types. So, it turns out it's really in this DiConcini, it's really in the DiConcini-Lusti-Brochesi paper, what a modular triple is. And actually, if you want to trace it back further to these papers of Mizzono, where he's calculating the partial order, he's doing something similar. It's a ginormous paper, but the first few pages are. Pages are totally accessible. He has upper-order ideals in there and he's manipulating them and deciding when they have the same built-in order. So, anyhow, a triple. What is a triple? So, in type A, Matthew wrote it down. It's just you have a Hessenberg, was it a Hessenberg function? Is that what you call it? The H vector, the H, little H. You have a series of those, and the dimensions differ by one as you go from the first to the second and the second to the third. As you go from the first to the second and the second to the third, so that's one condition. And the other condition, you have to find, I'll say it like this: you have to find a simple reflection in your vile group that preserves the outer two and that does not preserve the middle one. So you just act by the roots. You can go to the upper order and deal. You act by the roots. You act by this simple reflection on the roots. And you have to preserve that or not. So that's a modular triple. So that's a modular triple. And so the first example is in GL3, where you have something going from smallest to largest in this notation. It's this modular triple. So obviously the nth is zero. It's invariant. This is invariant under S2. If you take the symbol reflection S2, you'll just flip alpha 1 and alpha 1 plus. Alpha 1 and alpha 1 plus alpha 2. And then sadly, you want, well, good, for us, you won't preserve this because it wants to go to alpha 1. So in this case, I should have written that down. The simple reflection that we're talking about is S alpha 2. Okay, so once you have a modular triple, then we have this result that Martha and I showed in this context about the Poincaré polynomials of these Hessenberg varieties. So the middle. So the middle Essenberg variety for the middle ideal gets a q plus 1, and the smallest one is here, and the largest one, or no the other way, this is the largest one in this case, and then you get a q times the smallest one. So they're related in this nice way, whenever you have the modular triple. So this is what you're calling a geometric. Geometric, I don't know. Is that good? Is that good notation? So it's basically, we're motivated by the modular law. And the proof is more geometric, is geometric. Is more geometric? Is geometric. And the proof is geometric. Although I would say, if I understand Matu's result, it probably holds in all types. So it would also could be translated into an exact proof up here. And then I believe there's some researchers online who also, maybe at least in type A, gave another proof. Yeah, I think there was a recent preprint that gave a different geometric proof of this. Can you say the names of the. Okay, well, we'll say it. Okay, well we'll say it. We're sorry to the, I think they're listening on the lines. Lee, I mean, that's not distinct enough, but is it Don Lee? And his advisor. And their advisor. Okay, so that's the result. So that's actually fun. And just in one minute, the proof sketch, it's kind of similar to what's happening in the DLP paper. You have a P1 bundle over the middle one, it's a blow-up. Middle one is a blow-up of the big one over the small one. And then you analyze the cohomology of both sides. In the general case, you have to know that there's no odd cohomology anywhere. So that is important. That's why I emphasize that. So what's a non-trivial example of other types? So there's 10 examples in B3. There's 10 modular triples in B3. I don't have them all off the top of my head, but 16, 15, and 14 are, I don't think there's time. I was just going to show. I don't think there's time. I was just going to show you that you can see how they're. We can look at the table later. Maybe in the discussion, if that's interesting. So again, I sort of already said this, how we were motivated by this earlier work and motivated, and it's similar to what Mathieu did yesterday. I want to say that there is something in the Abru Ni Gro work, and I think Mathieu said it, but I want to emphasize it that one. But I want to emphasize it that once you know any of these objects in the parabolic case, which is the case in your dick path, every corner touches the diagonal, then their method shows that you can compute it anywhere. And that's, I think, in Alejandro Morales' group and his discussion, he has software that produces that. So any of the objects. So if you were to know the Poincaré polynomials at the parabolic, you know. At the parabolic, you know it everywhere. And so, in this case, the dot action or the Stanley-Stembridge basis, you know it there, you can compute it anywhere. That's a very, very fun result that I like a lot. So, so the wider differences, maybe this is off the topic, but the wider differences have any gene matter meaning then? That's not in my real house. Good question. Yeah, let's talk about that. Let's talk about that later. We have an open discussion right after this. All right. Alright, so how are we doing here? Looking on Taipei. We're almost done. We have coffee right now. You want to take a break for coffee? Sorry, sorry. Oh, I read the chart. Holy water. Sorry. Sorry. You can see my valuable time. So, anyhow, you can do exactly the same thing. Yeah, you can do exactly the same thing for the Hessenberg space case that we talked. I briefly said how to get from one to the other. You can decompose into the same thing with Y sub W. You have the module law. Although we need to maybe write those details down more carefully. They're not in the paper. The issue in that case is that the size of the vile group set is way, way, way bigger. Way way bigger. I don't think I can do the E8 case. So I can do the entire E8 case. In principle, I can do any E8 case that you want, any nil potent and any ideal space. But I think you would need the size of the vagrants too big. I think Juliana, I think she has, I've heard from a graduate student of Club Alejandro's that there's a way in type A, though, so it's a different way, similar. Way similar, basically intersecting with the Schubert cells, and then there's a common combinatorial objects that you can use to parametrize. So it's not impossible, but this method would not maybe be so advantageous for that setting. Okay, so now we have, we're ready to just plow through the rest. We have our ideal, nilpotent ideals, spaces. We'll take the Poincaré polynomial. Probably getting rid of like Q goes to Q to the one-half, so we get rid of the. To the one-half, so we get rid of the, we just don't have to worry about the odds versus the evens. We can do the Hessenberg-nilpotent ideals, and then we can do the regular semi-simples. Again, it has to be H because the I case doesn't see that. And so we have three things that we can consider. Here are the three objects. We have the last one as the dot action or the monodromy action of browsing chow. Dot action is Fosco. And now there's three games we can play. So we can do the natural projection. So I talked about the top one and the bottom one. We would just do the same thing, but we would get the holding out. We would always be surjective in this case. This case is always surjective. There's this intermediate one that we don't understand so well, but it does appear in the parabolic case in Borho-McPherson. You could take your Hessenberg space and say, I don't really want anything that's not nil-proposed. Really, I want anything that's not nilpotent, do that, and then you would project to the nilpotent cone and it would be surjective there. So that one doesn't have a complete answer, but it should be studied more as an expected answer. All right, now I really apologize. So we'll just use a little bit of converse sheaves, intersection cohomology, decomposition theorem. So, anyhow, there's some So, anyhow, there's a machine, let's say. And this didn't come up when we were proving sure positivity, but hey, it's another machine. So, you can take your vector bundle, take the constant sheaf on it. You have to shift it by its dimension. That will be a perverse sheaf. And then you can do this thing where you push it down to the nil potent cone. And then there's a big theorem that says it breaks apart. It has to be perverse. So it breaks apart. Perverse, so it breaks apart. There's a natural basis, the intersection cohomology she's, and then those appear, and they appear in some shifted degrees. And yeah, you do that. And the point is, you get a grade of vector space, so you get something with positive coefficients when you kind of take its Poincaré polynomial. And so those are beautiful objects. All right, so I'm not going to dwell too much because it's a machine, but one thing that Martha and I did was we showed that. That only the local systems that come from the Springer correspondence show up on the right. And that's good because that means that we're really just talking about the vile group representations. There's nothing extra to mess it up. So we can go back to parametrizing everything by vile group representations if you want. So I think that's good. So I said, I kind of said it again. Alright, now let's just get to. Again. Alright, now let's just get to stuff just skipping over all those words. Let's introduce a polynomial which encodes this graded vector space that came out of this machine. So we'll have for each representation of the while group and each ad nil potent ideal, we get this is a polynomial. And it's related to the Poincaré polynomial of the new. Of the nilpotent ideal variety, again with this extra character coming from this component group, something called proper base change. So if you know one, I guess the only thing we need to take away from this, if you know these Plancker polynomials, you know these FI's. And there's some matrix that comes from the intersection, local intersection colonology, which in type A are the Costca-Fouls polynomials. So it's probably a known, so I guess it must be known. I guess it must be known maybe from Brows and Chow or other places that you can transition between these two, not sure, these two bases. So this is like the F and the P, two sets of polynomials, indexed by the same thing, indexed by irreducible representation. There's some shift in Q. This fancy theory tells you that the F is palindromic. I don't remember if it tells you automatically that it's pale. I kind of remember if it tells you automatically that it's unimodular or if we need to put in more stuff for that. So maybe we can talk about that after. But anyhow, let me just show you what it is in V3. By the way, all these tables are in the paper. Everything I'm saying is really in the paper. So now what we have is we have everything is unimodular here and palindromic. And this is the key table that we're all really interested in. Table that we're all really interested in, as I'll say in a second. So as we look across, we're basically getting the dot action, maybe up to sine as we look across. And up top now, I have the irreducible representations of B3, which are given by pairs of partitions where things turn to three, while the parts turn to three. Okay, so it's the same 20 ideals here. Alright, so you could do the same thing. Um with the Hessenberg space um you can push this thing forward and use the decomposition theorem. And then in this setting, Patrick had conjectured that indeed only stuff from the Springer correspondence will arise. That's what we've got here. And then the other thing that we get is that the graded thing looks Is that the graded thing, those graded vector space, really are the same? So this F polynomial will appear all three times. So we have this transformation against the same Costco-Fouls transformation there. Now we have to change, we have to tensor with sine. And then back to the dot action, monodromy action case, you have exactly the same F appearing if you want the phi isotivic component. Phi isotivic component, it's phi tensor sign with this F. So once you know the F in any one of the three cases, you know it in all the cases. And so that's why I suggest using, you can use this method. The module law will save you some time. And the ideal setting is nice. Any questions? All right, so I'll just do the last object that was in my abstract. Don't want to follow my places here. My places here, which is the LLT side. I think this was one of the things I thought was actually. So, Tim was the first to show me this paper for Chasey four or five years ago. I thought it was really cool. People have referenced it a couple times. This is the Torret case that's been mentioned. So, in general type, if you look in Mathieu's work, he gives the idea, and he actually mentioned it, picture him mentioning it yesterday with the two arrows, depending on your base rank. With the two arrows, depending on your base ring. You can get the LLT side, you can get the actual representation. Mortha wrote this carefully down in our paper. So you know that there really is a representation, but I think it's really cool how you get it if you don't want to GKM it. Is that a thing? If you want to GKM it. If you have the dot action representation, then there's a nice transformation to get the representation, the W. So these are both W representations. So these are both W representations by doing this. You take the co-invariance and you tensor with the dot action. Okay, so that's a W representation. And then, it turns out, because you know that you're actually going to end up with a representation, you can actually divide by the Poincaré polynomial of G mod B. So kind of like the co-invariance where you forget the W action. I feel like I've seen Mark Heyman do things like this. And I always thought they were really cool. But anyhow, Prochesi does it. But anyhow, Prochesi does it in the Tori case. And so I'll just finish by showing you the calculation for the Prochesi case in GL3. So we know that the dot action is four trivials in dimensions 0 and 2, and then a reflection in the middle. And then you tensor with the coinvariance, which is a graded version of the regular representation. Boom, just do it out. Whoa, it's all that. But you can divide. Whoa, what's all that? But you can divide by, you can factor out the Poincaré polynomial, and there is your LLT representation. And you have to, this also tells you it has to be regular. Because if you tensor anything with regular, you have to get regular. Or a sum of regulars, maybe. So anyhow, you end up with the LLT. Oh, so Protiti does it like going the other way, I guess, right? Because he's trying to find. Yes, yes, that's true. Yes, yes, that's true. Right, right, right. He actually went the other way. That's right. So he gives an elementary way to construct the right-hand side and then he gets the dot action. Yeah, okay. Anyhow, I like that. So I've got one minute. I don't want to go take my extra five. But one thing that I do think is intriguing, try to sell people on it. In this Costca Fuchs K that showed up, I don't know if people can picture it on the right, there was this K. It's the Costca Fuchs. Picture on the right, there was this K, it's the Costco for the polynomial. If you want to compute then in arbitrary type, this is the information, this is the only information you really need. You need to take, to know how to decompose the tensor product of two irreducible representations of the Vau group. And then you need to know where they sit in the coinvariance. It's called the fake degrees. So that's the input for that matrix, which wasn't really talked about in general type. But that's also only, that's only what... But that's also only what you need here because you're grabbing something over here and censoring it with something over here, and then you're basically doing that same thing. So I think it's kind of interesting that there might be, it's really this thing is a fundamental object that is important. That's all. Thank you. Eric. Can you go back to the first set of data? The Poincaré polynomials? Yeah. So is this the limit of what you can compute with the IFB, or is there a Q? It's not. So it's what we have already done. We can compute more. We can compute more. So, the issue is not. So, the vile group elements that show up, that's totally cool. We can go up to like probably rank 11, 12. That's not an issue. But to actually compute the smaller smooth varieties that went into it is a little bit tricky. I don't have anything. In type A, it's systematic because you basically can basically the module law all over again. So we have to think about that a little bit. But you want more data, is what you're saying. The reason why I mentioned it is because I recognize something. Mention it is because I recognize someone who is great on all this. Oh, cool. In what setting? Other varieties and type A. Oh, okay. Oh, interesting. I don't know if that could be a low-dimensional loop. Oh, I say, I swear to man. That's what I wanted to find. Okay, that would be interesting. So, like, in particular, what do you use? Like, the 13563 shows up as the ones that are all very quilted. I'll like that. Ah, so this is a springer fiber. This is springer fiber. That's a springer fiber. The bottom row is finger fiber. The bottom row is about one three five or three. That's also a spring or five. Those are all true. The one on the spring or five. Okay. Yeah. Okay. No, I mean, I don't know. Type eight. Patrick has a question. No, Mary. Okay, yeah. Okay. No, the second to last. Okay, that is interesting though. Because what I'm looking at. I mean, doesn't that can't you use that? I mean, doesn't that? Can't you exactly define LLT? Oh, if that is what you're going to say, LLT in general. Yeah, this is how we should define LLT. Yeah, we could define LLT like that. Can't we just agree? But it agrees with what Matthew was doing yesterday. I guess that's the point. Yeah, yeah, so Gronelsky and Haman defined it a totally different way, but maybe it's equivalent. So there is like a definition. I think Jim showed me in the paper of Heyman-Grinowski. In the paper of Amy Dronowski, that we have been mentioned many times. Oh, okay. That there is a definition of an LLT polynomial for an arbitrary reductive group. Yeah. Okay. I mean, we have this other generalization that is like a very natural generalization of LLT to other types. I don't know if the two alignment. Okay, okay. Basic open question that would be very interesting. But this is open. But this this is only good. You would be like the generalization of unicellular. Yeah, sorry, sorry, unicellular. Yeah, sorry, I've Heyman and Brannon's be defined for every kind of skew shapes. Okay. Yeah, this can be sort of a unicellular. So I have a question here. You have a picoomology range that you're censoring, and you're portioning up by polynomial. I know, I know, I know, sorry. So I guess I want to take the Poincaré, whatever. I want to take the Poincaré, whatever, the Frobenius, whatever thing of the top. I've got a representation on the top that's graded by Q. And then I noticed that every coefficient of any irreducible is divisible by the thing on the bottom. Triple, maybe then for life easy. What you should do is you should shift that to the other side. Yes. Think of it as the trivial representation of those things. Yeah, yeah, that's actually how it is done. In Prochesian, right there. In Prochesian and then our paper Dobian once a And then our paper debut on the ones. But I like the way it's like, because it's kind of, it also shows you that when you go Q to one, what happens? Well, actually, that's not, yeah, I think. Yeah, Q is one, then it should be the same. That's the same thing. Yeah, same thing. Yeah, but that's not right. You can't let Q go one. Something about Q goes to one makes it works out. Ah, Q goes to one means. Q goes to one is what I don't know who I was asking you. Who I was asking you says that it's actually the same ungrade, I mean, same grading. What do I say? The Poincaré polynomials of both sides are the same. That it's like 1, 4, 1. Well, in the emission later in case you get the regular representation. Well, no, that's not. You get the regular representation from one explanation because you're tensoring with regular. But then this fact that the somebody help me with the fact that the Poincaré polynomial of this agrees. The Poincaré polynomial of this agrees with the LLT grading. When you evaluate the character at the identity. When you evaluate the character at the identity. Meaning here, like I got, I got my answer here was here's the dot action. If you take the sum of the dimensions, yeah, take the sum of the dimensions, that's what I should say. Then you get 1, 4, 1. And then the answer here is also the sum of the dimensions is 1, 4, 1. Dimensions is 1, 4, 1. I think the LLT side is really cool because if I tell you that it has to be 1, 4, 1 and it has to be the regular representation, the only choice you have is to switch the sine and the 1. And actually, it's always going to be 1 in degree 0 from the definition. So it's totally defined. So I don't know. I think it's highly nice constraint to put on the problem. It's fine. Sure. It's minecraft also. Hmm? Inside the side. I think John has thought about this a lot. I think lots of people in this room have thought about this a lot. Oh, okay. Inside Vegas. Inside Venezuela. All right. Any other questions? All right, let's take a look. I mean, maybe we'll take like a five-minute break. There's an open discussion basically keeping it all. Um basically uh came in along the lines of these things, um, uh other types of not actually. Oh yeah, they also