Okay, so we have two talks this afternoon. We start with Jose. We talk about robust probabilistic bounds on the number of real signals. Please. So the first question is we will try I will try kind of answer three questions. Stop. So, let me start here. So, question one of three hot sleepers. System shave. Second question will be. In order to answer this, what we say is how the properties Of the clear heat set related conditioning. Question three How long time agree? So, question one, okay, we are in a quantum random multi-variant geometry, so it makes sense to ask this question. In order to answer this question, we do this through a certain relationship that there will be between the properties of the real, of the real zero set, and the conditioning of the real polynomial system. Conditioning of the real polynomial system. And then this thing will come for a very specific kind of approximation of the polynomial system by low-degree polynomials. So, before continuing, let me put some couple of definitions that you should have fresh in your mind. Geometric Geometric functionality functionality analysis. So let's put it up here random variable and then we will say it's Gaussian. If the probability colon t is bounded by an exponential of t squared, some constant t squared, or equivalently. This is bounded by some universal constant, or constant of four, and the half of this. Okay, this will be the one, and then the second one I will say use anti-concentrated if The probability of being R, the probability is small than epsilon, P is small. The sensor is of Gaussian, this means that the tails of the random variable go to zero fast, and this tang just means that you don't have too much of a random variable probabilistically at any point. Probabilistically at any point on the real line. Main examples of this are the Gaussian, the uniform in minus 1, 1, and essentially any reasonable random variable will tend to satisfy these things. Okay, so just keep in mind these two things. So just keep in mind these two things. So whenever you hear that the random materials are sub Gaussian and anti-concentrated, you can just think about what's the name? You can just think that they are either normal or uniform between minus one and one. So whatever, whatever one you prefer. Okay. Now let me put the two models where we will be working. Two models where we will be working? So, maybe question. It's funny that in this condition we have two constants, we have C and K value. Yeah, this is a universal constant. This is a universal constant. I see okay. Yeah, C U appears the uh mess around with us. Let me get Let me get number one. I will refer to this as sincho, which means could be task. Excuse me, this is the That's basically and we have our favorite support systems. Then we will have some polynomial system, F1, Fn. Here we will have FI alphabet. Okay, so we have we feature support, support for the first system, second system, third system, and we write this, and then the assumption is that the alpha will be independent with sub Gaussian concentrated. So, important cases that we can consider here. We can just take all these to be normals. We can take all these to be uniforms between minus 1 and 1. But also, one of the things that we can do, beyond the normals, centered at zero or uniform, centered at zero, we can center the variables wherever we like. So, these models, I don't need expectations to be actually any. To be actually anything particular. Also, here one can do it slightly more general, and we can also consider random integers for each one of the coefficients with a certain measure of uniformity. But since explaining that will take probably more time than explaining the rest, let's just put it under the rack and let's focus on the continuous case. Okay, so this will be model one. This will be model one. Now, we remember this right here model two, and this will be dobro, which is in the Slavic language that means good, etc. And I think in Turkish meaning honest. Dobra, tobra. There is also Greek. There is also a Greek. Okay, so in this case, we use the beta bigger. We pick a homogeneous system in m plus one variables, because here we will be working on a projective real space. And fi will be homogeneous of degree di. Okay, what's the condition here? Here it's not that the I have. Here it's not that the condition is such that for all x belonging at the middle of the sphere, because this is equal to the weight of the sphere the f i x are independent super Gaussian And the concept. Okay, in particular, this is enough to assume that the Fi alpha here I have to do divided by corresponding By corresponding scene, independent, super shaped, and anti-concentrated. So here we have the ESS polynomials, and this condition is the condition that you can find precisely in an article by By Rgur, Paubris, and Rochas, where they do the probabilistic analysis of the condition numbers. Okay, again here we also include the smooted case. So that's good for us. So now, let me state the theorem here into versions. Okay, so version one, the expectation Expectation is the number of zero set. May I ask this question? So I'm wondering, you said in particular, why is that? I mean, you require at each point. This is a particular case. It's in particular. But this is, for instance, the implication of the other case. Okay, I was confused. Surely. Okay. Okay, so I'll put this plus and then we put here an L so here I'm taking the L moment and then I take, once I take the L moment, I take the L root of the L moment and this thing will be called N and let me put this is here on the right. This is here on top to the right and then that log to n d l n. So this d so when I write a capital D, this is the maximum of the degrees. So the the V zero polynomial in L. Polynomial in n the zero will be the number vertices minus vertices after that it's polynomial poly so this is a polynomial in n to the n longer than to the 2n of the maximum degree and then we have this ln that tells us all things about then Then, whatever familiar with this kind of bounds, this is a given to saying that the probability of what's the restriction on L? There is no restriction. L is arbitrary model of integer links. Populated the number of zeros of this guy here. So I take the n root of the number of zeros of n-dimensional system, real or equal to t is less or equal exponential of minus t divided by boolean log square battery. So, this is just a way of saying that this is sub-exponential. As you can say, this is all exponential. The consequence of this is if this t is large, essentially we have that we have exponentially many the probability that you have expo uh degree many uh zeros here, degree many around d to the n or some power of d to the n. Or some power of d to the n is exponentially smaller in capital D. So this so the maximum of the degrees. So essentially this tells us that real polynomial systems with many zeros, with many real zeros are red, are exponentially red. No, not that one. Just for that, okay. We have to remove it on it. Right. And then for this model, we have similar. And now it will be mutation of F. Now we take the number of zeros of this in the connected real space. Now under L and half to M of D to the N and L to the N. So again, we have a bound in all the moments and particularly this is also equal to the probability that the number of zeros of this car is here. And root is less than equal to an exponential minus t divided by square root of z on the n of t. So in particular, in the KSS model, the probability that a system has the so many zeros. As the so many zeros is exponentially small in the degree. So these are the two main probabilistic results. Then, in a certain way, I think some of I think some of them are. I mean, this I think is quite of nil. This is kind of null when you take all the degrees the same, you take Causalan polynomials of the same degree, then you have this theorem by Pasai, Armentano and Valmal in Le√≥n, where they saw that this quantity, not this quantity, but you have the one over n, behaves as a normal as the degree goes to infinity. Degree goes to infinity, you have a central limit theorem. This is what we saw. Also, the results that these ones are rare, you have the papers by Diata and Lerario, and then I always forget the second name, Redin, Keneslaw, and Lerario. So they have a similar result in terms of having exponentially small. The advantage of these results is that they hold under general probabilistic assumptions, in the sense we are all. In the sense we are only assuming that these are sub-Gaussian and T-concentrated and independent. Here we even have more general assumptions. And also, here we can also solve this kind of bounds when these guys are random integers. And also, this holds when our variables are not centered. So it covers a lot of cases at the same time. Of course, this means that this bound will not be, let's say, tied for a lot of cases. Of cases. Now, if something covers a lot of cases at the same time, it means that in some cases we are probably overbound. Okay, so how we do this? So, in order to do this, we now go to the second question. And then the condition number enters into play. Let me put here model one. Here on the one two. We do that a little longer. But okay, in the sensor case, we will have a condition number. And we'll just define this for the unit cube. Then the way that you will define this for the whole positive ones is by inverting variables in the corresponding vertices of the support. So let's just do this. So let's just do this. Here we have this weird quantity. Here we have some norm. The one norm. I will not enter which norm is this. And I will have the inverse inverse of the alcohol here. Ltd. This will just be the Just be the diagonal matrix with the one, the n in the diagonal. And then this, okay. Anything, there is I don't care. There is a question here by Antonio Le Lario. It's okay to ask, but you can read it. You cannot read properly. But if the main results say in the same conclusion as the seven yata with pass. Of the serum with the altar with all modularity? Yes. Because you cannot do it so for zeros. Yes, in the zero-dimensional case. You also have this for more general sets. You have it for more general zero sets, but in the zero-dimensional case, okay. Understanding this thing is kind of hard. You spend a lot of time trying to understand how this thing behaves, etc. Other one learns at some moment. Is that the best way to understand this thing here? There are these things here. This thing is screaming and variety. So, this is the set of polynomial systems that have a singular zero in the cube i. So, essentially, this thing is proportional to the comic distance. I think this proof was originally used to Malachovic from the stories that Felipe tells of under the kirting, of the inner workings of under the One of the inner workings of the machinery of a paper. Okay, we have this. Of course, once you have this, you can do all kinds of condition-based analysis only of this distance. If you put the distance, you put it in a reformulation to translate this L1 distance to an L2 distance, and then you have this result by initially by Burgess, Cooker, and Armentano, and then by Armentano, and then by the radio numbers. But you can bound this kind of chronic condition numbers. But now, important thing here: let's not go rails. Do we need to call them up? Yeah. No, but then there is the paper I have. Gerardio, I'm assuming that they generalize. I know. In this case. Okay. Okay. Let me not the wrong formula. So then the number of real zeros in this interval is just bounded by all the n to the n up to n. And then here you get this condition. And this is the rich. And this is the reason that we get, what's the name, more robust conditions, because analyzing the condition number is a lot easier than analyzing the number of 00. So we take this, and then we use analyze the condition number, and then it happens that the logarithm of the condition number is extremely well behaved. We can bound all the moments of the logarithm. What is I? Unit q. Q of minus 1, 1. Yeah, unit q. And this is a determination. Yeah, yeah. And this is a deterministic geometry. There's nothing. And the sigma is the intersection of sigma is the discriminant variety. The sected with the cube. Yeah. Well, the cube node, the discriminant variety of the cube, so real polynomial systems that have a zero in the cube. Yeah. Okay, and then singularly here. We have this condition number, which okay. We can write this as bi norm. I will not enter which norm is this. It's another norm f square minus dx f identity minus s x transpose delta let me put this in the yeah square zero n square this is uh least singular value This is precisely equal to what you want it to be equal. This is the distance in the diagonal. Here this is here, we really have the discriminant variety without any local restriction. So, yeah, this is the condition number we need a little bit to Hooker Greek, Malachovitan the Seva, and then this is the formula they proved in the part two. Okay, so again, there's a paper by Raffali which has been had it first. Yeah, but all in the hyper souffling. Um okay, and then we go. Okay, and then we go and here formula properly. My formula is slightly different, but kind of the same. Now instead of having the logarithm and the polyn, we have this common term. Now we'll put all these things here. Now we draw all these things here and block of two of the condition number to the n. Again, a deterministic formula. Important conclusion of these two formulas is that a real polynomial system with many zeros is ill-conditioned. In other words, if you have many zeros, this seems, for example, is d to them. This i will be an exponential of d to the n. If this guy is d to the n, then the condition number will be an exponential of the square root of d to the n. So essentially, polynomial system, real polynomial systems with many zeros are ill-posed. So the more zeros you have, the more careful you have to be, numerically speaking, because this is the distance to the discriminant variety, so if that thing is. Discriminant variety, so if that thing is B, the inverse of that, then the distance to the discriminant is small. So if you do a small numerical error, this means that you move to a different chamber of the discriminant, and then you are solving a real polynomial system with a different number of real zeros, and that's problematic. If you wanted to solve a system with many zeros, and you end up a system with half the numbers of zeros, that might have implications, applications. Applications. Of course, this is, you know, this is more structured in the sense. This holds for arbitrary supports. Here, okay. We move in the dense case. I guess this is reminiscent that we wrote the spoken sympathy, we all did. A lot of real zeros are small variation messes it up. Yeah. And I think this is in a certain way justify a lot of the intuitions that a lot of people in numerics say when they say solving polynomials. Solving polynomial systems with respect to monomial basis is imposed or is unstable, etc. The thing is because many times, sometimes they consider systems with many zeros, then these are doomed to be unstable, and then it happens that you can mess it up easily. Okay, so the question is: how do we get this? So, since time is a finite resource, I will erase this part and I will focus. Erase this part and I will focus on how we get this formula. Because this formula is in some way constructive. So this term you can really write it in a more precise way, which is the constructive There is an explicit cover by oxygen of IN only depending on D. N. It's an important thing. This thing does not depend on the polynomial system. On the polynomial system that we are analyzing. And by explicit mean, we can really build it. So this will be this guy. Then here. Essentially, it's like rectangles. Essentially, it's like rectangles that if you go in a direction, you approach one of the edges, it becomes sorted in that direction. In the middle, you have a big square, and then you move a little bit up, and you have a rectangle where the vertical thing is smaller. Okay. Size, da, da, da. Of size. So some constant times the lower etiquette of z. Okay? Such that for every F on B here, there is a polynomial for something here, Taylor approximation. Of degree bounded to both by log D to N log L power to F such that the number of series Of zeros of F is bounded by the number of zeros of this real-pointed system in the box or even outside. Let me just put the full name to my theme. Put it here, so that the router. Uh, what else do I want to write now? Um I want to write now. Such that every for every zero of the original system, there exists a zero of this approximation, I want to say. Sorry, yeah, I want to say such that Newton starting at my approximation converges quadratically to the zero. So in other words, I construct discover, I find a way of bounding the condition number. In the condition number, so that I can know how much approximation I need. Just by solving a lot of low-degree polynomials, I can solve my original polynomial system, and then in order to get the roots, original zeros, I only have to apply Newton and the zeros that I found in the lower-dimensional systems. Okay, so how we do this? So here Here is to say this is the main difference with the what's the name with the original approach by Lenario, Diata, Fineslau and Bradin. Because while they are using global spherical harmonics to get the low-degree approximation, here we are not getting global approximations, we're getting a lot of local approximations in a cover. Approximations in a cover, and then in each one of these pieces of the cover, we're getting a low-degree approximation. And this is extremely low-degree approximation. And also, a nice thing of this approximation is that this is just doing the Taylor approximation. So, we are not really doing taking the polynomial, find the center point of the box, write the Taylor series, and scale it appropriately. It appropriately. Okay. So let me finish a little bit how it works a little bit. So otherwise it looks a little bit like magic. So we have the alpha theory. So in an attack of originality, they decided to call different parameters. They decided to call different parameters alpha, beta, gamma. Alpha is this, beta fx and beta is, beta is this, the inverse of the Jacobian are this. Equivalently, this is Newton step. And then this is just the singularity coefficient that is training here k 1 over k minus 1. So these are all the parameters. And then here we have the alpha theorem. I mean that's not so weird, that's because you're taking it. I mean, that's not sober, that's because you're taking a Taylor search at the trigger. It's usually less than a radius conversion of other drugs. Yeah, I mean, it's related to that, but it's not exactly. Yeah, it's pretty good. He said. See, the main difference is that in the radius you will take the lean soup, here you are taking the soup. That's the main difference. And then the therapist told us that if we are below some critical value, then Low salt value, then this guy is quadratically. For all those that don't know or are not familiar with quadratically, this just means that for every iteration you get the double amount of decimal places. So you multiply your precision by two. Okay. Then to finish, so there is this truncation serum for calling me its own. And then this truncation theorem just starts okay. Get some, but one gets some key. Get some volume function here and some number some point in user favorite n-dimensional wall with respect to the norm that we are working on. Then we define this weird quantity P of f x of delta. of delta so three moon plus k becoming one that delta plus one amp again this is pretty similar to the radius of convergence as permanent say but notice that the higher derivatives are centered at zero and that there is a two to the k this is the hard part to bound because this in a certain way is a measure of how Of how fast does the Teigeno series converge? That thing is bounded. Then we have that the Taylor series converts pretty fast because we have a 2 to the k that we can take out. And then this 2 to the k means that we can truncate it pretty early. By truncate, My truncate is moving the k equal to 0 up to delta and then fault notation. Then the nice thing of the theorem is that it tells us that. Is that it tells us that if the degree sufficiently large, we mean that delta minus the logarithm of this is greater or equal of the logarithm of this. Then the alpha of the communication delta text is bounded He's found it. And this is one of the directions. It's the standard divided by one minus two to the minus theta theta plus two. Okay, beta plus two squared plus three. Okay, so let's look at this a little. So this is only telling us that if something is a nice zero in the sense of the smell for f, then it's a nice zero in the sense of the smell for the truncation. We can also get the other way around, but the other way around, the formula is slightly uglier to write. So then I write this formula. By balancing here, as balances that I The nice thing here is that this as well as this large. And then the nice thing is that depending on the random model and depending on the condition number, we can extract this out in a way that with the cover, we force this thing to go sufficiently fast to zero. So we really force this thing to be bounded by choosing the cover. In the case of the unit cube, it's covered with rectangles, gives us something, what was it? What was it? It is something like max. Like it really forces this to the stand, I think, like a constant, and then we can take it out. And then in the case of the name, in the case of the Kosla and Smail model, here we can take out some kind of square root of D, and this is where we get the square root of D. And this is why we get the square root of it. And this is essentially what is going on in the hack. There is like, for now, what we have written, I think, is like five pages of expand the Taylor series, manipulate it around, move it around, do this, do another bound, write another Taylor series, do another bound, combine, and then you take a lot of these formulas. We have this also for the Kantorovitz theory. So instead of using gamma, we can use the K of Kantorowitz, which is slightly nicer. Kantrovitz, which is slightly nicer. And then, an interesting observation is that this points probably to some more general theory because this comes from a certain way the geometry of the spaces that we are working with. So, in the unit cube, it happens that this model of condition number was the nice one when you arrive. For the Kauslan, you get that it was other geometry that one that is nice. And then it's finally that you can apply the same arguments in the component. You can apply the same arguments in the complex case, but in the complex case, the same arguments seem not to give you a contradiction between the number of zeros and the condition number, because the thing that multiplies the logarithm of the condition number is the su bound, or the corresponding bound that you have to have in the complex case. So it looks like in the real setting, the cover in a certain way covers the whole thing. Covers the whole thing and is sufficiently small because there is not enough space to put it, and this really forces the number of zeros to respond. I think with this note, I will end the doc. Thank you, Jose. First question? 