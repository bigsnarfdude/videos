Right, we begin the last session of the workshop. The speaker is Josuetonelli Cueto. He is a PhD student or posto, posto, at Johns Hopkins University. And he's going to talk about lazy quotient metrics. And thank you for being flexible, Jen. Very much. Don't worry. Okay. Okay, so this is a talk about ongoing work with Austin Mixon and his PC student, Brandy Busse from Ohio State, and of course, Solead Villar, which I think a few people here know her. Okay, so before starting with the talk, a small warning. So this is ongoing work. Ongoing work. So, this means that we will have an answer questions and traverse paths and thought directions. So, essentially, feel free to make question, comments, impressions. So, any feedback is welcome. I mean, this is more like a talk to get your feedback than to actually present groundbreaking results, more like small things that we have been considering. So, let me start with a motivating example. Motivating example. We have this kind of text where each word has been permuted a little bit. However, if you try hard enough, you will be able to read. This is not the usual version of the text with Cambridge. So this is usually the version of, I think this is a paragraph from Don Quixote translated to English. I thought it was basketball. No. Too many C's. Too many C's. Thank you. But okay, so this is one of the things you can permute and you're going to still understand the text. And then the motivating example too is like you take a number, you rotate it a little bit, maybe the person was not very careful, he was not so careful. But then if you rotate too much, then the six becomes a nine. And of course, you end up this kind of thing. And of course, you end up this kind of thing. But it's like there are some transformations that if they are small, you will still be able to recover what you want. But if they are too big, then you get certain form of ambiguity on what you will get. So you want to do small symmetries or approximate symmetries, but you don't want to do full symmetries. So the idea is, okay, how can we formalize this in order to use it? Okay, so the first idea is. Okay, so the first idea is a small transformations do not change the object, but too many might make it recognizable. So the usual way in which this goes in the, well, before continuing, so the setting will be G is a group, X D, a metric space, and G is acting on these biosometries. Why biosometries? Because this is the simplest case in which everything is nice. Which everything is nice. Maybe at some future, we probably need to consider when it does not act by its own metrics, but then things become a little bit more complicated. So the usual Portion metric, and here notice that metric is between well, so notice that metric has this apostrophes because it is not a metric, it's a pseudometric. Yes, you take the two things and then you. Is you take the two things and then you take the infinite. So I look at all possible elements in the orbit of x and take the one that is nearest to y, and that's it. Notice I only need to minimize some one because the action is by symmetries. So I don't need to minimize the two at the same time. And this works pretty well as a metric. So the way in which we turn this into a metric that is maybe more amenable to the idea of Maybe more amenable to the idea of we don't want to do too much work when we move x. This is essentially what we want to do. Then we introduce what we call lazy quotient metric. It is we want to get something that is near y, but not to, that is not very costful to move. So we introduce this kind of monstrous expression. Here we can see that now on top of the distance of gx to y, we have this kind of Why we have this kind of regularizing term where we have this nu of g and some parameter lambda. And this nu of g is a group norm. So this just means that nu of one is zero, that the nu of g and g inverse is the same, and that we have the triangle inequality. This is equivalent to saying that we have a left invariant metric on the group, and then new year. And then will just be the distance of g to the identity. That's how this will translate in metric terms. And this term is used here to penalize large transformations. If my group is far away from the identity, I'm moving too much. I don't want to do that. So I penalize it by adding a term that penalizes it. Okay, so now here we have two examples: one more theoretical, one more. One more theoretical, one more practical. But before passing to it, this is the Laisy quotient metric. Then, when we make lambda go to zero, we recover the quotient metric, because essentially this term here vanishes, so I can take larger and larger and larger root transformations. And when lambda goes to infinity, we recover the original metric because as lambda becomes larger and larger, then okay, the more lights. Then, okay, the more lazy I become, and then the most lazy that I can be, means that the only work that I will do to move an element is the identity element, essentially doing nothing. In a certain way, this is kind of a metric that interpolates between the quotient metric and the regional metric. It's important to note that this guy is a metric. So, this is actually not a pseudometric, but an actual metric. Okay, so theoretical example. So, theoretical example, this is more of a toy example. We are trying to compute this for maybe more interesting actions, that is, O n in Rn. Now, here we have two points, X and Y. If we want to compute the quotient metric, what we will do is we will move one of the points around the circle of the origin, and then we will find the one that is nearest. And then, a very simple computation shows us that if we take the Computation shows us that if we take the quotient, we have C infinity. And so the quotient metric is just the distance between the norms. So two elements are this. And of course, here we see that this is a pseudometric because if x and y have the same norm, then their quotient metric distance is zero, even though they might be different vectors. So now we add or turn. This is the geodesic distance on SOD. SOM. So, this is the geodesic distance to the identity. So, one way of seeing this is you express your element G as an exponential of a matrix, then it will be the exponential of an anti-symmetric matrix, and then you look at the Frobenius norm of that anti-symmetric matrix. Then you choose the smallest of all the anti-symmetric matrices that give you that element. Okay, so then the proposition that we have in this case. So, then the proposition that we have in this case is that this guy is actually Riemannian. So, that's good for us. And then we're able to compute the Riemannian metric. So, recall that the Riemannian metric is just a way of computing inner product between vectors. And this is given at each point x of Rn, and it will be a different inner product for each point. And what we have is that this is just the usual inner product of Rn, and then there is this correct. R n and then there is this correction term where I'm doing the orthogonal projection onto the orthogonal hyperplane to x, orthogonal projection, and then some kind, some normalization of this thing. Maybe to get a little bit of an idea of what is this term, I mean, one can look at it and see that in a certain way we are making, we are contracting it in the direction orthogonal to x, in the direction where the group is acting. In the direction where the group is acting. So, if we look at this and we make lambda go to zero, then we get essentially a pseudo-Riemannian tensor that essentially forgets everything that is not in the direction of the orthogonal loop. So, essentially, this only sees the movement orthogonal to the orbits. And if we do lambda to infinity, then we recover the usual Euclidean product. The usual Euclidean product. Again, we see that this is something in between the two metrics, and it's kind of an interpolation. But okay, then we go and we decided to use the most overused data set of data science, MNIST handwriting digit. Now we will do horizontal shifts. Why horizontal shifts? Because this was the one for which the thing worked. And then one of the things that made were And one of the things that maybe we're trying to look is more interesting practical cases where maybe we can test this kind of formalism against. But okay, what we are doing is we have a digit in MNIST and then we are allowed to cyclically permute, muve, cyclically move each one of the rows independently. So each row of pixels I allow to move it independently. To move it independently, so this is such that it can be pretty dramatic. So, here I have a one, and I move a little bit the rows, and then suddenly I end up with a five. It's kind of in this setting where if I do too much of a transformation, that's bad, because then suddenly numbers that shouldn't be the same become the same. In our theme, we will do a 10-nearest neighborhood classifier. So, this is just the scene that That we did. Well, we did. Randli did. And okay, we put in the setting, X will be used as R to the 2828. Then we will have the group G will just be the set over 78. This is each one of the sieves of each one of the rows. Then we have 28 of them. And then the way that we act is use we add the corresponding. We add the corresponding translation to the column index, and that's it. And then the metric that we use here is kind of an L2 aggregate of the most obvious metric that you can use in each one of these cyclic groups, which is taking the representative with minimum absolute value. That will be the norm in a cyclic group. And okay, let's see a little bit how this works. So here we have the original digit, target. The original digit, target digit. So we want to move x into y. Then we look at the definition, and since this is a finite group, we know that there will exist some g lambda that will achieve this equality. And then for several lambdas, okay, we look how is this guy. If lambda is infinity, we just recover the regional metric. So then G lambda will be the identity, and this is the regional digit where we start. And if we allow lambda. And if we allow lambda equal to zero, that's the quotient metric, then we can actually reach our target. And then we can see how in the middle we get kind of more similar to the target as this goes. This is one case that, okay, not very interesting. It's a one a little bit tilted, another one a little bit tilted to the left. And now we do this with a one and a five. And then again, you can see planned increases. My translate gets nearer and nearer and nearer until it gets to where we. Until it gets to where we want to go. Notice that this thing is not exactly the target. No, it's a little bit more sparse, but it's pretty similar to it. Okay, so then we apply the classifier and then we look this is just by looking for it yeah so there is an evolution. Yeah. So there is an evolution. Yeah. Yeah. It's not. This is what's, I mean, this is more like, again, this is like a toy practical case to see, okay, we are doing something that might give some gain somewhere, that maybe might give bigger gains somewhere else. But it's not something that, okay, we did the classifier, we apply, we did it for several lambdas. The good news is that we saw that, okay, if you do the quotient metric, the accuracy starts at 0.2. Starts at 0.66. Then, as you increase lambda, then the classifier accuracy starts increasing. And then we see that there is a moment where it starts going down. Is the accuracy evaluated on clean, at least? Yeah. Clean. But then I think this was... Something seems odd. I thought that the accuracy of nearest neighbors on clean MNIST you Clean MNIST using the Euclidean distance between the images was already 95 probably. I think this is maybe a good question. Okay, so then maybe, or maybe it's that because this is the nearest neighbors, right? So it's not. I mean, in the 2000s, there were tons of nearest neighbors papers on classifying any. Neighbors' papers on classifying MNIs with different metrics. Like, probably the shape context paper from Belongi probably has the standard as a baseline. Maybe I'm remembering the names wrong. Certainly, the shape context got 99 points something, but that was with a very special fancy metric comparing the linear. But there was, as a baseline, the example with just Euclidean distance. Maybe I'm wrong. I remember. Maybe I'm wrong. I remember that it was higher. Maybe, maybe. Yeah, that's the other question. What is K? What do you mean by K? Number of New York. 10. But yeah, we will check on that to make sure. But yeah, I mean, the important thing here was use that, I mean, at least the idea that, okay, this might be something useful. This might be something useful, is that in a certain way, the maximum accuracy is achieved at an intermediate value of lambda. This was kind of the idea. Even though I have to say that, okay, at the middle value, but it's not like if you go to lambda infinity, you are losing a lot. I mean, that will be seventy eight, seventy six. But okay. We are uh I mean, we are hoping to maybe find a context in which this is more Context in which this is more natural and this works more than this, you know. This is a case to make it work and to see, okay, is there at least a case where this might give you some gain? Looks like there is, but then we will need to think a little bit on a more practical case where this really you can take advantage of this. From an experimental perspective, maybe this is not the best opinions because. And so the translation of the group isn't the one that is going to make it easy. And so that's why. Okay, maybe I will check that with maybe do some augmentation of the set to make to see if it changes the interaction. Okay, so we will try that. Okay. Okay, now we go to the second idea. This was not really our idea. It was done by Vieti, Venturi, and Bruna in a paper of 2021. We call it aberrates lazily the output. The usual way that you do operates, Primos operator, you take a function, you put the group inside, you take expectation with respect to the hard measure. You are assuming that the group has a hard probability measure. Some people might like to write an integral, and in favor of. Write an integral and in favor of writing expectations whenever they can. But okay, so we have this. Now we say, okay, maybe you have a group, you are a little bit lazy, you look at the hard probability measure and you say, I don't want to compute the whole hard probability measure. Maybe your group is discrete and it's too large. Then you don't want to do a very large, so then one does this so-called lazy averaging. So you choose some probability distribution on your group. On your group under some idea. And then you take the expectation not with respect to the hard probability measure, but with respect to other probability measures. Now the question that we were asking is, can we choose this guy so that this guy turns this function into quasi invariant? So we have a function that we suspect it will behave nice with respect to certain quasi invariance. Then we want to choose the probability distribution in the group that makes this like. The group that makes this like a nice averaging, but still be in a certain sense cheap. So, again, we decided to continue overusing the most overused theme. So, we did some augmentation by rotating several different kinds of rotations of the theme. The best case is always the six and nine. The thing is the ones that are easier to confuse. So, if you rotate too much the six. Rotate too much the six, that looks like a nine. If you rotate two degrees or thirty degrees, it'll be fine. So we choose some discrete distribution of degrees. I mean, I think this is more like zero plus two plus four, six. Now at some moment we jump it to 10, 15, 20. No, this is not an experiment that with a lot of thought. We just put something that roughly samples the space of angles. The space of angles. And then we use gradient extent with the log loss to learn this. And nothing fancy. And then we, this was the thing that kind of we learned, that is like, this is zero. Of course, you don't do nothing, that will be pretty good. And then we saw that, okay, doing some rotations might improve this. And the way in which this happens is: okay, we have the F that is the classifier. F that is the classifier, I have 0.28. Now, when we apply this lazy averaging, we get 0.187. So, this improves a lot, but this is more related to how lock laws deals with things that are not on the support. Improving the support makes a lot, and then we get some improvement in accuracy. Although, here I will say again that the same issue we are having. Like, this is not. Is not 0.9516 to 0.9532, it's still not a rate improvement. It shows that it might have potential, but we still need to play on how probably to optimize this eta and how maybe to compute it in a better way to see if we are able to manage to get a more radical improvement. Then, maybe to finish, a small theoretical result on this guy, remind that you have. On this guy, remind that you are given an ellipsis function. Okay, this is ellipsis, maybe it is not invariant. Now we apply our lazy averaging, and then we want to see how invariant is this guy. So we take an element of the group, we evaluate our lazy averaging function here, and then we subtract the thing. So this is kind of a saying, okay, we are looking how invariant is this guy. Is this guy, and then we got this kind of a weird result where kind of transport plans appears and so on. So the L goes outside, and then we get the infimun overall transport plans by between eta and a translate of our distribution eta. And then the cost function is just given by the distance. So, this kind of shows that this kind of turns this in some form because all this thing here is kind of a kind of a basel stance between eta and the eta. So it's kind of saying that if you want this to become, you know, roughly, let's say roughly constant. Constant for certain values of g, then you need that eta, the g translate of eta, is roughly the same as eta. This is kind of what is behind this inequality. But this is a direction that we still have to explore more, maybe to see how one can take advantage of this thing. Like I want maybe some translations or certain transformations to don't perturb the input. Maybe I don't want the whole hard provocation. Want the whole hard probability measure because that will kill and will over-identify things or it will kill too much information about the function. Then, maybe one should try to play a bus sustained distance between eta and yet and then trying to see if one can optimize over this kind of weird not this kind of set and then see how to implement this. So, this is the lazy averaging. So, now instead of using the hard probability measure, we are using eta. And now, here we're evaluating this at gx and at x. So, that is to see how invariant is this with respect to this particular element g. So, h1 and h2. So H1 and H2 is a couple of elements of the group sample according to pi, and pi is a transport plan between eta and g eta, where g eta is a translate of the distribution eta. All this is roughly the Busserstein distance with cos the distance between eta and its translate with respect to E. It's kind of showing that if eta is near in the Wasserstein. Is mirroring the Wasserstein distance with cost distance to its translate, then this guy will be roughly the same with respect to this transformation. What do you mean each one and each two are not unique? Like in the distance. Yeah. What happens if I uh have a left time nothing because this is acts by isometries. So therefore when you're stuck stage one and what why that that fact does not affect the meaning of I don't understand why that doesn't affect the question of whether this product is what it is. Well, it doesn't affect in the sense that this is just like the definition of Basselstein's distance between eta and its translate. So then you might restrict yourself to certain family of distributions of candidates. Then you might want some, say, some subset of your group that doesn't alter too much your family. That doesn't alter too much your functions. And then you will try to make to minimize this in some way. This is, I think, the idea behind this. I mean, we still have to explore this a little bit more because I could turn it up to D0 in the entire orbit. My question is whether the cluster time system has any problem with that. I repeat the last thing. Ah, Gx and Gx, you mean? Ah, you mean that if this and this are equal? Yeah, but this is this is the thing. You are translating this. Unless this eta is the, let's say, I mean, if this eta will be the trivial distribution that you take the identity with always, then it will be, here you will have the identity, but here you will have g. So then. Have G. So then these two guys will be different because one is applied to one element and one is applied to a different element. So, in general, these two are sufficiently different so that this guy, it might happen that this guy is zero, but this guy being zero for a particular G actually helps us because it means that, okay, for that particular G, I don't need to worry for this distribution. So, that's, I think, is more a feature that if this Bassersten thing is equal to zero. Basserstein thing is equal to zero, that helps us more because it means that O actually is invariant with respect to this particular element G, instead of being used O roughly invariant. So a little bit of conclusions. So this D lambda and this lazy quotient metric and lazy averaging are kind of attempts at approximate symmetries, small symmetries. Approximate symmetries, a small symmetries, or however you want to call it. This depends on how you think about what's the name? Symmetry as a property of the object, then you will say approximate symmetry. You think of symmetry as a group transformation, then you will say a small symmetry. Then we have some initial examples of results that show some promise. They are not the best results in the world, but there is some promise on them. The world, but there is some promise on them. And now, the big question that we have is: we can find can we find new settings where to test, let's say, these two formal notions, like to really see how they work or how useful they are actually or not. And of course, here we mean by settings, we mean both theoretical and practical settings, where we might apply this. So this is the current thing which we are like intensely working now. Intensely working now. So, thanks a lot for your attention. Thank you. That was a really good talk. So, I have one question, which was: can you explain again what was the setup of the second experiment? Ah, you mean the one with the rotation of the You mean the one with the rotation of the numbers? Yeah. So here we rotate numbers and we want to learn the distribution. Learn the distribution. Yeah. So we pick one distribution of angles. This is a discrete distribution of angles. And then we do gradient descent on the log loss. And then this is what we get. That's the set. So the last. So the lock, we do the log clause and then So the log we do the log clause and then we do gradient descent to the probability weights of this distribution in order to find the optimal but optimal in what sense minimizing the lock loss of the classifier that we have so we pick a classifier and then we see yeah um the the second thing I have is a comment as we go back to the second last slide. To the second last slide, second last slide. You mean this or the previous one? Yep, this one. Seems like there should be another theorem here, which is if you take eta to be a normalized restriction of R measure to a neighborhood of the identity, then there should be some other neighborhood of the identity so that for all g in that neighborhood, So that for all G in that neighborhood, this Baselstein thing is zero. We have examples with that, with the cyclic group, where we pick a neighborhood and we get, I think you don't necessarily get zero all the time, but it's very much because if because when you take a neighborhood, there is a moment. When you take a neighborhood, there is a moment if you move it a little bit, it will be a part where they don't agree. Like this is the. But not if eta is normalized R measure on some neighborhood of the identity of zero also. Yeah, this is what I say. When you do it in the thing, you get that it does not become zero, but it becomes the neighborhood that you take to translate, you really see it in the thing, it's related to the. Theme is related to the neighborhood itself appears in the theme. The radius of the neighborhood, you can see that it appears in the upper bound to this guy. So you will not necessarily get zero because there is some place where they not overlap, and then there you have a positive difference. So this guy will be positive there for that for any element in that small neighborhood different from the identity. I have one other thing which I bit weird. The metric you're using in the Waterstein definition is a metric on X. You're comparing probability distributions on G. Yeah. Is there an obvious translation in between? Because I would have thought if you're comparing probability distributions on G using Basserstein metric, you really want to be using a metric on G. That is what the Nicholas. That is what initially I was thinking too, but then in a certain way, I mean, there is one that this is what appears. So that's what we have to handle with. And then whenever you try to do any kind of relating the metric in E with the metric in the thin of the action, then at one moment one realizes that it's just better to handle the induced Bassersten distance by the action itself. Because in the end, you have a space. End, you have a space and you have an action, so then it doesn't make sense to oh, yes, okay. So, the idea would be if you fixed x, you get a metric on g. Yeah, so then you want yeah, so the action is there, like this is not something we can thank you. So, can you go back to your histogram of the distribution? So it's looks, I mean, it's centered around zero. And presumably, that's kind of what you want because you want it to be somewhat biased towards zero. Yeah. Right. So why learn it necessarily as opposed to just, because it seems like there's a lot of, like, I mean, you're updating essentially however many parameters in Ada here. Parameters in ADA here, and there's like, I don't know if there's any guarantees about that or anything. But if you just start with some distribution that has a nice kind of zero bias of some kind, like it's got a mean of zero or something like that. Here you can do that. I mean, maybe not just mean of zero, but something stronger than that, right? You can just think of distributions, uniform distributions, but in general, you want it to be a mean of the identity operator. And yeah. Right. Yeah. You come up with just like you just sets. Like, you just set some distribution and see how you perform using some distribution, then you can just parameterize that. So, you could, for example, consider beta or something, or like semicircle with some height or something like that. Yeah, you're saying that choosing maybe a better parametrization of the family of distributions. Yeah, yeah, essentially. And then you just optimize that single parameter as opposed to however many parameters you have. Yeah, that could be probably a better idea than. I mean, here also one issue is that since this was in. One issue is that since this was in MNIST, then one has to be careful of how to implement the rotations because it's you know have an image with 28 by 28 pixels, then it's not like it's not obvious how you do the rotation of it, but you need to at least have some implementation of it. So, this is kind of an artificial intell example. All right, thank you very much. Thanks a lot.