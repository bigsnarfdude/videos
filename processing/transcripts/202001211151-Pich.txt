So we know that uh proving complexity of overbounds is hard. In fact, it's so hard that uh it's useful to study metamathematics of lower bounds, which might guide us away from methods that cannot work and even inspire new approaches. Today I'll speak about metamathematics of proof complexity, but Complexity, but I should really start with circuit complexity, which inspired our results. In circuit complexity, we've seen a period of rapid development of new overbound methods in Deities, but it's also quite fair to say that this development stopped in Deities as well. In fact, by now we have several barrier results that partially explain why this happened. And in case of non-uniform CITIP models, the most significant Circular models. The most significant bio result is the bio of natural proofs by Rasboro and Rudic. What Rasboro and Rudic realized is that all existing circular bounds for explicit Boolean functions are very constructive in the sense that they give us efficient algorithms efficiently recognizing with high probability whether a given Boolean function is hard. But if you had such an algorithm for recognizing hard Boolean functions for a strong circuit model, then this would break standard hardness assumptions. So this term is a very important thing. Assumptions. So, this turned out to be very influential, but it's also kind of ad hoc. Natural proofs are not really proofs in the formal sense of mathematical logic. Nevertheless, they can be used to obtain unprovability results for logical theories, and this was done already by Rasborough in the 90s. Rasborough showed that you can't separate P and N P in certain weak theories unless Trump so the ungenerators don't. Unless true so the ungenerators do not exist. And this result can be reformulated in the language of propositional logic, where it says that propositional tautologies expressing circular bounds do not have short proofs in automatizable proof systems under the same assumptions. And I would like to be more specific about the definition of these propositional formulas because we will use them. So I will denote by TTFS a propositional formula which is S, a propositional formula which is tautology, if and only if uh the Poolean function f doesn't have sieve bits of size S. And the Poole function f with n inputs here is represented by 2TN many bits incording its truth table. Now this propositional formula TTFS has polynomial many variables in the size of the SIP and the total size of the formula is exponential The total size of the formula is exponentially none. Do you really need automatizable or weakly automatizable? It's sufficient to work with weakly on automatizable systems. This still works. So this propositional formula, TTFS through table tautologies, have been studied quite extensively. Now we have so Quite extensively. Now we already have several lower bound methods how to prove their hardness for weak proof systems. And in fact, these are one of the main candidate hard tautologies for strong propositional proof systems. So we would like to understand better whether it is very likely whether we can prove actually their hardness for strong proof systems. And we would like to employ this kind of framework to reason about hardness of proof complexity or ground zone. Lower bounds on. So we know that proving proof complexity lower bounds tends to be harder than proving circular bounds. With a major example of this phenomena being the fact that we still don't know how to prove S0P frag lower bounds, but somewhat paradoxically, the proof complexity lower bounds hasn't received, or mathematics of proof complexity over bounds hasn't received so much attention. Still, there are some results in proof complexity that tell us something about In a proof complexity, that tells something about the hardness of proof complexity or bounds, and I would like to briefly review them. So, first of all, if you go back to the notion of simulation between proof systems, it's easy to see that if you have two proof systems, P and Q, two natural proof systems, then the proof system P cannot prove a lower bound for a proof system Q unless P simulates Q. And by proving a lower bound for a proof system Q here, I mean proving efficiently a propositional formula which is the Formula which is denoted LBQS phi which is tautology if and only if there is no proof of size s in the proof system q of some formula phi. This is a formula which has polynomially many variables in s, where s size of the of the proof and also the size of the formula is polynomial in s So, for example, if you are reasoning inside an extended Frege system, then you can't prove lower bounds for set theory unless extended Frege simulates set theory. Another important barrier falls from the correspondence between preserved theories and propositional proof systems. It is shown, for example, that the theory P V cannot prove super polynomial extended regular bounds. Extended regular bounds. And this is a significant result because the theory PV is actually very strong, it can formalize a lot of complexity theory, and in particular it can formalize, for example, a resolution logo bound for Pidgeon principle. And in the work of Palantoni, Pitasti, and Urkuhar, they gave a constructive proof of constant efferent bounds, which they claim at least to be formalizable in the theory PV as well. A more recent type of uh bioresult follows from witnessing theorems. So the ankle check, for example, showed that the theory PV can't separate NP and co-NP under standard hardness assumptions. And this might look weaker than the previous result about the unprobability of extended regular bounds, but the thing is here that this separation of NP and co-NP here is formalized differently so that the Formalized differently so that the number of assignments of the heart tautology is feasible from the perspective of the theory. Or using more technical terms, 2 to the n is the length of some number. So this means that for the theory P V, it's much easier to reason about this formalization than about the formalization of extended regular bounds, which I mentioned previously. And there are also various results reducing proof of the requirements. Various results reducing proof complexity overbounds to other problems in complexity theory, which I recognize as hard. For example, Groscho and P test show that if IPS is not pre-bounded, then VP is different from VNP. And there are similar results for standard proof systems as well. If extended reg is not pre-bounded, then, like Igo said, the separation of PN and P is consistent with the theory as well too. So these are essentially all results about hardness of proof complex lower bounds I'm aware of. Of proof complex lower bounds, I'm aware of, but with Rubber, we wanted to understand if there is a version of natural proofs in proof complexity. And in order to explain our results, I should be slightly more specific about the notion of standard natural proofs. So B natural proof useful against a circle class D. It's a set of Boolean functions which is which are represented by vector tables. The truth tables. So these functions are represented by the truth triangles. The set is recognizable by an efficient circuit from the circuit class B. So this property is called constructivity. Then another property of the set is that it's large and finally it's also useful, meaning that it doesn't contain Boolean functions which are in the circuit class D. And as I mentioned earlier, Rasburg and Richard showed that if strong cell ungenerated does exist, there are no people naturally There are no people natural proofs against Pipoli. And Prudich extended this implication to show that, by showing that if the so-called super bits exist, then there are no even ampinatural proofs against Pipoli. And super bit here, so there are no generators safe against non-deterministic circuits. But in order to make this definition meaningful, we need to be slightly more careful, because non-deterministic circuits can actually easily recognize elements inside of a range of generators, so we need to Inside of the range of generators, so we need to modify the definition so that it forces these non-atragic circuits to recognize elements outside of the range of the generator. So, we can now define our version of natural proof-complexity lower bounds. I already mentioned these formulas T D and L B, which express circular bounds and proof complexity lower bounds. And we will say that the propositional proof system Q defines a Q-natural property useful against propositional proof system P. If for a big fraction of Guillain functions, the proof system Q proves that the truth-table tautologies expressing hardness of these functions are hard for the proof system P. So again, a Q-natural property useful against the proof system P is the assumption that the proof system Q Proof system Q proves the harness of many truth-table tautologies for the proof system P. So, why is this a reasonable definition of natural proof in proof complexity? If you compare it to stand-up natural proofs, then the first thing you notice is that we replace the notion of constructivity by the notion of probability. Instead of having a circuit, Circuit which recognizes hard-boolean functions, we have a proof system which recognizes hard topologies. So we also change the notion of largeness. Instead of recognizing hard functions, we are recognizing hard tautologies. But what does it mean to recognize many hard tautologies? Unfortunately, there is no There is no distribution on tautologies, so we need to choose some. And in this case, we decided to work with the truth-table tautologies. They induce a natural distribution on propositional formulas. If you pick a random Boolean function f, then you will get a random truth-table formula, which is going to be tautology with high probability. And in fact, it's also going to be hard for all propositional proof systems if you assume the extent of super bits. However, we can also consider different uh distributions on tautologies and uh for example see some results about random free CNFs as well. Another thing which uh might be worth mentioning here is that if your goal is to generate hard tautologies for strong propositional proof systems, then uh it's easy to see that. It's easy to see that these hypertatologies can't be generated deterministically in polynomial time because such tautologies are efficiently recognizable in some pro systems. So in this sense, better to focus on random tautologies in this case, in this scenario, and this might add another reason why this kind of natural proof is really reasonable is a really reasonable definition. So the first question you might ask is uh whether the existing proof complexity lower bounds are natural. And if you are able to formalize for example lower bounds for resolution inside some big theory like PV, then this is something that is reasonable to expect that we are able to do such a thing. Then we will find out that, for example, resolution of Then we will find out that for example resolution logs for truth table tautologies are extended frequencies. The travel we focused more on negative results and the first thing which we realized is that if you assume the extents of super bits then for every propositional proof system which is sufficiently strong, one of these two things must hold. Either it is hard for the proof system P to prove any circuit lower bound for any Boolean function. Prove any circuit lower bound for any Boolean function f, or there is no proof system Q which would define a Q natural property useful against the proof system P. So this means that under reasonable Hagen's assumption, then any sufficiently strong proof system is either incapable of proving strong circuit lower bounds or it is hard to prove lower bounds against the proof system in this sense. sense. And the proof is an adaptation of the lower bound method of Rasborough in the setting of proving hardness of true table topologies. So we proceed by contradiction. If we assume that we have some proof system P which proves some circular bound for sample in function L and we assume also that there is a q natural property, this all gets to this proof system, then we want to break super bits. Now Now, by Rudig's theorem, we know that it's sufficient to prove to construct any pinatural property is useful against p-pover. And we can construct such a property in the following way. So, you just take a set of all Boolean functions for which the proof system Q, which defines natural property, can prove that these truthable tautologies defining hardness of FX or G are hard for the proof system P. Then directly from definition you will get that this constructive and large. Largeness false from the fact that Q defines a natural property against the proof system. But what requires some argument is to show that this notion that this set is useful. So if the proof system P proves hardness of this Boolean function f, then you can actually show that it proves that either f or g is hard or g is hard for any Boolean function g. And then And then this means that if G is easy, then the proof system P proves that X of G is hard, which means that the proof system Q counts that X of G is hard. Now, using theorem 1, you can derive an unconditional lower bound saying that the existence of superbase doesn't admit. The existence of superbs doesn't admit feasible proofs in a certain sense. So, what I mean by this, I will say that the existence of super bits admits feasible proofs if for every non-uniform propositional proof system P, that's a propositional proof system in which verifying correctness of proofs can be done by non-uniform circuits. For every such propositional proof system P, there is another proof system Q which proves for a big fraction of Luan functions that For a big fraction of win functions that uh the fact that they are hard is hard to prove in the proof system P. So this means that uh for any proof system P potentially defining an NP natural property useful against P poly and breaking super bits, there is a proof system Q which refutes this fact, which refutes that which proves that P is really not and P natural. Which proves that P is really not an P natural property, useful as people. You only need like one or two of the order random fraction. Peasibility just means that you need for either case or not. No, you need to refute the fact that uh P is a natural property. And P would be a natural property if it would prove hardness only of one over two to the n manipulant functions. But now we want to refute the f this fact, so we need component obvious. Component always it's not sensitive result but uh it doesn't imply that N P is not co N P because propositional formulas which are proved to be hard are actually not necessarily tautologies. And this is Tautologies. And this is how the proof proceeds. If you assume that there are n pinatural properties useful against Pipoly, then of course you can't prove that there are no natural proofs useful against Pipoly. But if there are n-pinatural sorry, if there are no if there are n pinatural proofs useful against Pipoly, then you can't prove that uh that there are that uh they are not there. That they are not there. And if there are no NPHL proofs against the poly, then of course there are hard boolean functions. There is actually a proof system which proves hardness of some Boolean function. And then you can adapt the proof of theorem 1 to show that there are no Q natural proofs against P, which implies, which means that no proof system proves hardness of this L B formulas for 1 over 2 to the only many Boolean functions, but this is stronger than what we. Functions, but this is stronger than what we have shown it. So, this implies as well that the existence of superbiz doesn't admit feasible proofs. Why is it, can you repeat, why is it called super beats? Uh it's uh generalization of soder on generators and I actually don't know what is the motivation behind this name, but uh it's supposed to be a generator sa uh safe against non-terify six circuits, stronger than the terracing circuits. What is the non-determinism? Oh, uh here actually you don't need to think about this definition of supervision because actually it would be more accurate to call this the impossibility to prove the non-existence of anti-natural proofs against pipoly because the way I defined it just says that for every potential ampinatural proof against pipoly, there is a proof system q which refutes this possibility that this proof system p This persistent period actually defines our potential proving as people. So STRAP2 is unconditional, but when you compare it to natural proofs in circuit complexity, the disadvantage is that it doesn't really work for specific proof systems such as extended Frege. It says that there is some uniform proof system for which proving system for which proving overbounds is hard, but we do not know if extended Frege is such a system. And this is also the main drawback of the first theorem, which says that if your proof system is sufficiently strong, then you can't prove lower bounds against this proof system. But we do not know if Extent Rega is such a system. Now as I mentioned earlier, we can prove similar things about other distributions of topologies. For example, if you look at the random three scenarios, then uh you can formulate a version of non-deterministic Feiger's hypothesis, which says that uh for every non-informal proposition proof system R there is a if you take a random Fristian F it's going to be unsatisfiable, but um It's going to be unsatisfiable, but uh moreover, it's going to be also hard to prove its unsatisfiability in this proof system. And you can similarly define this and similarly define the notion of feasibly proving uh the non-deterministic Faggers hypothesis by saying that for every non-uniform propositional proof system P, there is another proof system Q, which proves for a big fraction of 3CNS phi that this. Of three CNFs find that these uh three CNRs are not provable in the spruce system P. That it's hard to prove their hardness in the proof system P. Now with this definition we can also prove that uh the extent of feasible the of feasible proofs of non-translic Feigen's hypothesis is not possible because It's not possible because if you assume the extent of super bits, and the proof of similar strategy, but you need to use the notion of colloggal complexity in this context and some properties of colloggal complexity. Finally, the last result which I would like to mention is that we can actually show that the existence of superbase doesn't admit, doesn't Superbase doesn't admit, doesn't have feasible proofs in certain theories of boundary. This is also an unconditional statement and interestingly it has the same meaning as this theorem 2 which says that there is no feasible proof of the existence of super beats. But the proof is completely different, is based on Vita Sync theorems. So what we are proving is that the P theory P V can't prove the existence of super bits. Of super bits and the proof extends the method of Jankreich, which solves the unconditional unprovability, the conditional unprobability of the separation of NP and co-nP. And some questions. So as I mentioned, we would like to see if you can prove hardness of proof complexity load bounds for specific proof systems such as extended fragile. Extended Fagger. Another question is if you can prove unconditional hardness of Fager's hypothesis, because right now we have you can prove it only conditionally under the assumption of the existence of super bits. But you do show it for EF. I don't remember the quantifier. The notion of feasible probability of uh show it for every existence of super bits, but this is not provable. Existence of super bits, but this is not provable. But the question is: if such a statement is also probable because of non-atricified hypothesis. EF here means the proof system for which you prove the lower bound and the proof system that proves the proof system whatsoever. Yes, which Yeah, so the first question is whether we can do it for extended fragment, and the second question is whether it there is whether well the second question was about removing this assumption from TLD. Another interesting thing it might uh which uh ask is whether we can obtain similar harness results for other families of prime and topology. Results for other families of running tautologies. Maybe there is a more general result which is not really dependent on what kind of tautologies you take, whether it's true table or running tree skills. Next, our methods which we used for proving these results were non-constructive. So the question is if we can find more applications of non-constructive methods in proof complexity. And finally, of course, we would like to understand better meta-authorities of Orban. Like to understand the thermometer analytics of overbounds and the connections between group complexity and simple complexity over bounds. And just like Igor, I would also like to invite you to the Czech Republic to attend our workshops, which we organize in September, and you are all very welcome to participate. So thank you very much for your attention. Thank you very much for your attention. Any questions before we have to ask? Yes? So you have one formulation where you have either or a question, either if superbs if super beats exist the same thing as the two beams. there's something have then two so the first is actually circuit complexity hardness and the second is the lower bound on proof complexity hardness but then you have another theorem too which only have proof complexity hardness yes so I don't I this actually means that biases so you don't exist either or you actually have uh under this is consequent of this uh first statement but uh Of this first statement, but the advantage of this one is that these are almost identical statements, but the similar structure of the arguments. Here it's you say either the circuit complexity lower bound or there is this actual circuit complexity lower bound holds this uh twisting itself, right? Or what my question is whether to understand this theory or to To understand this theorem too. Indeed, if indeed this is only saying that if this demi uh super or demi bits exist, super bits, then indeed you don't have uh you have some lower bound some uh limitation of complexity lower bounds. So the assumption is just saying that random true tail totalities are hard of every propositional proof system. That's what the assumption says. So the assumptions itself uh uh kind of it's actually a proof of extreme assumption. If these totalities are indeed harder, then it's hard to prove that they are. Bit harder than far too hard. That's super bits. So are you saying that the assumption of super bits already is about the true point? Yes, strengthening of. Oh, because NP is different from current P is weaker statements. Oh, I suppose. Okay. There are no other questions. Let's thank Jan again.   