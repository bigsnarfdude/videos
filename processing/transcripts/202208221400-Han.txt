Okay, so thank you for coming. I'll be talking about some extensions to real-world data settings and multiple surrogate markers. So the goal is to extend the typical setting of a single surrogate marker in a randomized control trial, of which there are plenty of methods. I've listed a few references, primarily from the PTE framework. But the question I want to ask are twofold. Ask are twofold. First, what if we want to consider observational data settings? So, this could be EHR data, claims data. It might even be cross-trial comparisons, like where you take the treatment arm of one trial and the treatment arm of another trial, and you want to make a comparison by breaking the randomization by pulling just the treatment arms from two trials. We might also want to consider multiple surrogate markers. There are some papers, model-based methods, as well as more. Based methods as well as more robust approaches for how to ultimately combine these approaches. I think Dennis will probably talk about that on a later day of the conference. So yeah, this is the setting. So why care about this? Explosive growth in healthcare data offers promise for identifying surrogates using this type of data. The 21st Century Cures Act really spurred a lot of interest from both clinicians and regulators to use data from EHRs. Use data from EHRs to then design more targeted and less costly trials, and specifically using observational studies to do so. For example, in the COVID-19 pandemic, we saw that EHRs were used heavily in consortium like the 4CE consortium, where essentially multiple hospitals or sites agree to come together under a common data model to study the same disease together. So these were. Together. So these were used to assess different vaccines and treatment regimens at least at breakneck speed compared to what previously would have been done using clinical trial data. But directly using certain types of surrogate markers can be problematic. So in the settings where you might not have clinical surrogates, you might want to use predicted outcomes from, say, your favorite machine learning model or some algorithm-derived outcome. Or some algorithm-derived outcome. These algorithms can sometimes be quite simple. They're like clinician scores that they calculate for different diseases. And there have been examples of really nice papers in top medical journals which use regularly collected EHR data to predict things like post-operative hospital mortality. But other studies have shown that directly using those predicted outcomes can result in poor post-prediction inference. So So, I think there are two main reasons why we might want to determine the strength of these surrogate markers or potential surrogate markers. First, to inform whether they can be used in future studies, a point that we've hammered in the morning session. But second, also because many methods require that surrogate marker to meet certain assumptions to be relatively strong. For example, Mark van der Laum talked about his surrogate needing to actually be under some transformation. Actually, be under some transformation to be the same as if he had used the true outcome. So, I'm going to first talk about the setting of real-world data, and then later I'll touch a little bit more short, a little bit less time on the multiple surrogate marker setting. So, for the real world data setting, our first goal is to identify an optimal transformation of the surrogate. And it's optimal in the sense that it optimally predicts the true outcome. And I'll show you what that means in the following slides. Means in the following slides. For estimation, we propose both IPW and W robust methods to estimate both the optimal transformation function as well as the downstream proportion of treatment effect explained measure. In doing so, we propose fitting flexible semi-non-parametric models for the relationship between the true outcome and the surrogate conditional on your covariates, as well as the propensity score model for the treatment conditional on your covariates. Conditional on your covariates. And I wanted to illustrate the utility of this method in two different types of real-world data settings. The first is using electronic health records collected from MGB to assess how well an algorithm-derived outcome does for comparing two biologic therapies for inflammatory bowel disease. So there are some really nice anti-TNF treatments for inflammatory bowel disease. I wanted to compare if they do really well. If they do really well. And then, also importantly, a cross-trial comparison of two different biologic therapies for ulcerative colitis, which I've been told is a type of IBD. This one is really interesting. There was a New England Journal article which compared vedilizumab against adelimumab for ulcerative colitis. And the problem there is though that And the problem there is, though, that oftentimes when you have two pharmaceutical companies, one proposes a new drug, another one proposes a different one. They both run placebo-controlled trials. And so they don't want to compare their new therapies head to head. And so can we develop a method to assess surrogacy in the setting where one might be interested in comparing those two new therapies head to head? The notation and setting are standard primary outcome Y, surrogate S, a binary treatment A. Surrogate S, a binary treatment A. We work under the potential outcome framework for both the true outcome and the surrogate. And in reality, we only get to observe one of the pair of Y1S1 and Y0S0 for an individual. And we assume that we have IID data for N individuals. Our target is this treatment effect delta, which is the difference between the mean potential outcomes mu1 and mu0 under treatment and control. Mu0 under treatment and control. Here it's integrated over the density of the covariates. And then throughout, I'm going to assume without loss of generality that this is a non-negative quantity. And just recall, remember that in real world data settings, the treatment is not randomly assigned. And so we say that it may depend on covariates X. And we'll develop methods under this framework. So the goal. So, the goal is to first find an optimal function of the surrogates such that this optimal function g of s can be used in place of y, so in its stead, to then quantify treatment effects on the true outcome. And we'll translate the problem into a prediction framework and aim to identify the optimal transformation function that minimizes this mean squared error loss function, which is the, as the name suggests. As the name suggests, the square of the mean of the difference between the treatment effects on the true outcomes and these transformed optimally transformed surrogates. So Wong et al. in a Biometrica paper in 2020 showed that under this working independence assumption that the pairs Y1, S1 are independent of Y0, S0, that we can translate this, sorry, we can translate this oracle loss function and the loss function and the oracle transformation function into an optimal transformation function g opt of s, which as you can see is the summation of the conditional mean of the outcome conditioning on the surrogate equaling little s plus some some shift shift by lambda times calligraphic p naught of s. So p A of So P A of S is just the probability that you receive treatment little A, conditioning on observing surrogate little S. So, and then lambda is lambda is not a tuning parameter. Lambda has an analytical form given here. And let me just comment briefly on this lambda. I think it's on the next slide. So, lambda, you can see, is the difference between your conditional mean outcome, conditional uncertainty. mean outcome conditional on surrogates and treatments in both the control group and the treatment group. And so when these are actually the same, lambda equals to zero. And then our optimal transformation function is simply equal to the conditional mean outcome conditional and surrogate. So for big values of lambda, the shift from this will be larger. So it's kind of an interesting way to compare m of s versus this. M of s versus this optimal transformation function. So let me comment just briefly on this working independence assumption of y1, s1 independent of y0, s0. Admittedly, it is unlikely to hold in practice. We make this as a working independence assumption to derive the optimal transformation function, go from the equate the oracle g to the optimal g, but it's not required for to interpret the proposed. To interpret the proposed PTE measure or nor for validity of inference. And I will say that the SUN et al. Biometrica paper has a very nice section where they look at different, they break this independence assumption. They look at different correlation structures for the counterfactuals, and they show that as long as the correlation is not terribly strong, then the optimal transformation you get is very close to the ORCL transformation. Very close to the ORCOL transformation. So, indeed, intuitively, the optimal transformation of the surrogate approximates Y optimally in terms of minimizing the mean squared error. So we would be able to infer the treatment effect on Y based on the treatment effect on the G of S. And so that's what we do. Instead of being able to get delta, we use the best approximation possible based on the surrogate alone, delta G. And as to get the. And as to get the proportion of treatment effect explained, we take the ratio of delta G over delta. So that's a natural definition. Leila, I believe, has a paper where they have different types of PTE measures. Here we use this particular definition. And Xuan in 2020 showed that under weak assumptions, two relatively weak assumptions, we can ensure that the PTE is bounded between zero and one, as we would hope to do so with the proportion, and that we can also And that we can also avoid the surrogate paradox, right? So that delta is always at least as large as delta G. And I believe Tyler will probably talk about, he might talk about the surrogate paradox in the next talk. I'm not sure. So yeah, because he'll talk about it, I won't discuss it here. So right, so for identifiability, we would require the standard causal inference assumptions. Causal inference assumptions. In real-world data, like I said, treatment is not randomly assigned to patients. So, to estimate this optimal transformation, we cannot actually directly estimate each of the constituent components, the conditional mean, lambda, calligraphic P, which remember is just the ratio of the density for under treatment divided by the density under treatment and control. And so, what we'll do instead first is consider inverse probability weighted estimators. Reverse probability weighted estimators for the constituent components, and then we'll develop some doubly robust estimators for the optimal transformation. So to construct IPW estimators, we can use kernel smoothing versions here of both conditional mean as well as the conditional density functions given here. If we have, say, instead of continuous surrogates, if you have discrete surrogates, we can replace these kernels with indicator functions that With indicator functions that say s i equals to little s. And with an appropriate under-smoothing of the bandwidth, we can obtain plug-in estimators for the different constituent components M, calligraphic P, and lambda, respectively. And subsequently estimates the optimal transformation functions using plug-in versions, as well as for the delta G, that is the Delta G, that is the estimated treatment effect on the transformed, optimally transformed surrogate, as well as for the actual treatment effect on the true outcome, and take the ratio to get the estimated proportion of treatment effect explained by the optimal late transformed surrogate. For inference, so for inference, we show that this PTE converges in distribution to E converges in distribution to a normal. The form is quite complex. And so instead of using, say, an influence function-based approach for variance estimation, we simply use a perturbation resampling approach. So this is a type of bootstrapping, bootstrapping. So we generate, say, and we generate from an IID, let's say, distributed non-negative random variables from some known distribution that has mean one and variance one, say the unit exponential distribution. One, say the unit exponential distribution, we generate a lot of v's, and each time we observe i, a patient i's data, we perturb that observation by vi. And once we have perturbed, we get these perturbed counterparts for the optimal transformation, the estimated PTE, as well as the causal effects we see. And say we can generate a large number, say 500 realization. A large number, say 500 realizations for v, to obtain 500 realizations for each of these perturbed parts. And then we can do our usual variance and confidence intervals based on empirical quantiles of these realizations. So that's great, but if you misspecify your treatment model, then you will have a biased estimate. So, can we do a little bit Estimate. So, can we do a little bit better to construct, say, doubly robust estimators? So, it's well known that for any counterfactual random variable, we can construct an augmented inverse probability weighted estimator for its mean in the usual AIPW way. But deriving an AIPW estimator for this proportion of treatment effect explained is more involved because the optimal transformation function itself in The formulation function itself involves conditional mean functions of y given S, YA given SA, as well as the density functions for the potential surrogates. Okay, so the strategy goes, we'll first try to develop doubly robust estimators for the optimal transformation function, and then we'll develop a doubly robust estimator for the actual PTE measure. So this is This is the optimal transformation function recall, and we will propose doubly robust estimators for the M A of S and F A of S in the following way. So you can see immediately that this is not so clean because we have psi AM and Psi AF in this calligraphic capital M, right? And so, and then when we look at the conditional density, look at the conditional density we also have a psi af here so what are psi am and psi af well they are the um they are psi am right is the expectation of the mean potential outcome true outcome conditioned on the mean potential surrogate sorry this potential surrogate and the covariates that should be x and then psi af is this conditional density of this potential surrogate Potential surrogate. So, the challenge now, in order to actually construct the W robust estimator for the optimal transformation function, is that we need to get W robust estimators for M and F, which allows us to get calligraphic P. And in order to get WS estimators for both of those parts, we need to somehow estimate well psi A. well psi AM and psi AF. So the goal now is how do we, or the question is now, how do we estimate psi m, psi f in a reasonable way? So that's the question. First, we show that if you can estimate these reasonably well, then the so this is looking at the doubly robustness. So here's the propensity score model, which will converge, the maximum over X will converge to zero in probability. converge to zero in probability or for the conditional out true outcome model conditioning on the surrogates and your covariates x this converges to zero in probability looking at this supremum over both the covariates and the surrogates so so that's our double robustness property and so okay that was a bit of a tangent let's go back to the estimation so how do we actually estimate uh y conditional s x and a well the simplest way may be to assume Well, the simplest way may be to assume that we have this conditional normal distribution with a constant variance. And then for the treatment model, that the mean of the treatment is related to the, sorry, for the outcome model, it's related, the mean of the outcome model is related to treatment and coverts in an additive fashion. But in observational studies, we know, right, that the true form of these models is typically not going to be so simple. So if you were to go for an MLE approach, you would like. were to go for an MLE approach, you would likely have a biased estimate, and the amount of the bias would depend on how misspecified your model was. On the other side, someone might come to us and say, well, I want to propose a non-parametric estimator. And for that non-parametric estimator, if we went down that route, the convergence rate would depend on our smoothness and also the dimension of the regression function. So this would converge more slowly with less smoothness and more covariates due to a cursive dimensionality. So the question is, can we take Dimensionality. So, the question is: Can we take a middle ground here? And that's what we do. We specify the semi-non-parametric estimation strategy for the conditional density, as well as for the conditional mean function. And then we obtain plug-in estimators and then follow through with the other components. So, I won't go into the details here, but that's generally how we do this. We do this. Simulation strategies here are a little ugly, so let me just go to the results. Under misspecified outcome models in the top row and misspecified treatment models in the bottom row, we see that for our estimation strategy of the optimal transformation function g, I'm showing you that the bias over different values of our surrogate s is quite small. The empirical standard error, which is the standard deviation of the point estimates over many simulations, is very close to Many simulations is very close to the average of our estimated standard error. So our perturbation resampling seems to be doing well. And the coverage probabilities across S, although we have some below nominal coverage on the edges of the surrogate where we don't have many observations, remember we have some kernel smoothing happening here, is relatively good. And here I'm showing a comparison of the bias, the empirical standard average of the estimated standard and coverage for different Estimated standard area and coverage for different methods: Friedman methods, one of Leila's methods, one of Xuan's methods that doesn't account for covariates, and then different specification scenarios of our models under the IPW and the WROBUS. And the conclusion is that as long as one of our models are correctly specified, our WROBUS method has good coverage and so. And a small bias. Okay. So I think, in lieu of going into the two applications, I want to briefly talk about the multiple surrogate setting. So I'll just say that, let me just cover this quickly. So for the cross-trial comparison, we wanted to look at the surrogacy of a non-response likelihood score at six months for the number of narrative mentions of pain at one year. So the clinicians were really actually interested in this outcome and they said, well, Interested in this outcome. And they said, well, could we look at some likelihood of not responding to some therapy half the time? And using our estimator, we obtained a PT estimate of 0.72 with this confidence interval, suggesting that this is a strong surrogate for pain at one year. If we were to use the estimator of long, which doesn't take into account the confounding, their estimate gives a relatively weaker PTE. PTE. So that's that result. And then for the EHR, I think I might have actually mislabeled this. This should actually be the cross trial. The other one was the EHR. For the head-to-head trials, we break randomization. So these were two trials, one for Infliximab, one for Galimumab, and we want to actually compare these two. And we see that using, we used a partial Mayo score. We used a partial Mayo score at six weeks, okay, for a full Mayo score at 54 weeks. And the partial Mayo score does not include this invasive procedure. I forget if it's a colonoscopy or something else, but it does not. So this can be done quite quickly and non-invasively at six weeks. And we wanted to see if this had good predictive performance for this 54-week full Mayo score, which is actually used in the clinic. And we saw that the PTE using our doubly robust estimate. Using our doubly robust estimator was very strong. And again, if you don't account for confounding, you get a qualitatively different answer. And here I'm just showing you the estimate of the optimal transformation function across the surrogate for these two different applications. So here, a continuous surrogate and then a discrete surrogate here. Okay, so that's the real world data. That's the real world data example, and actually, in fact, Dennis will talk about the multiple surrogate and real-world data, I think, together later. So, let me just talk about multiple surrogates briefly. So, there are many examples here. I list two. For prostate cancer, we might think of prostate-specific antigen, the gleesin score, the number of circulating tumor cells as all potential surrogates for actual prostate cancer. Actual prostate cancer. In diabetes prevention trials, fasting plasma glucose, HBA1C, and early incidence of diabetes are all pretty commonly used. And the question so then is, can you identify and evaluate surrogacy of some combination of these multiple surrogates such that using them together, you can do better than had you just used one of these alone? So if you did it marginally versus jointly, can you do better? So I just want to return to the So, I just want to return to the Wang et al. framework here. So, recall this optimal transformation function. So, Wong showed that when S is univariate, you can make inference about the optimal transformation in PTE non-parametrically. But this is not feasible for multidimensional S. So what are some strategies one could undertake? Well, you might be able to approximate the optimal transformation by imposing some assumptions on your data, distributional assumptions, or you could restrict, say, Or you could restrict, say, the search space for G to some smaller functional space. So these are all two, both paths forward you could take, but neither of these paths alone would be robust to a misspecification of models, the parametric procedure or for the restriction. So the solution that I'll talk about is a two-step robust calibrated model fusion approach. And so this work basically says that first we want to derive, say, two estimates of the optimal transformation function. The first imposes the parametric assumption on MA and calligraphic PA. And the second says instead, let me be more flexible. So I want to directly minimize the mean squared error loss that I gave you earlier, but restricting the possible search space for G to just alpha trans. g to just alpha transpose psi, where psi is some pre-specified basis expansion of the surrogates and alpha is some unknown parameter. And so we derive these two model-based estimates for G and under model regularity conditions, we have that both of these converge in distribution to mean zero Gaussian process. Okay. And the final in step two. And the final, in step two, to optimally calibrate or combine these two model-based estimations of the functions, we have some weight omega for these two, omega and one minus omega, and then some calibration function calligraphic g. And these are estimated in a fashion that we can optimize the proportion of treatment effect of this combined composite score. Score. So if omega was known, then the calibration function here is just the optimal transformation function, where the difference is that here, these m of s and lambda and calligraphic p of zero, they use calligraphic s, which is itself some combination, convex combination, or just some combination of the two model-based. Combination of the two model-based transformations of the surrogate. So that's when omega is given. And of course, we actually have to estimate this optimal weight, call it omega bar, and we'll do so to maximize the proportion of treatment effect explained. And so I don't have time for the details, but in the paper, the calibration function can be estimated non-parametrically, and also inference can be done. And also, inference can be done using the same resampling approach. And so, here I just give a brief example for type 2 diabetes, where we look at how well this combined approach does compared to three individual markers, HBA1C, glucose, and an indicator for survival time being greater than 0.5. And then the true outcome is taken either at time. true outcome is taken either at time one, two, three, or four. And you can see that the calibrated model fusion estimate of the non-parametric estimate of the PTE is actually much higher than if you use any of these individual markers alone. So indeed you gain more information by optimally combining these multiple surrogates. Okay, so for future work, I think both examples I gave here were focused on a single study setting where you had access to individual level data. If you wanted to extend this to the multi-study setting, you could use some approach like described by Geert and Mark earlier, or potentially a different way forward is to consider some federated learning strategies that would allow for only sharing of summary level information. Only sharing of summary-level information and algorithms that preserve patient privacy in the calculation of different measures like the PTD. So I'll stop there. Thank you. Thank you, Larry. I am going to move on to the next talk, just given our time, but we do. Our time, but we do have a big, a larger discussion after this. So we should, we'll have more, we'll have some time to ask Larry questions. I got at least one comment that the camera