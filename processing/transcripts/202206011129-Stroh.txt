ARDS research done in collaboration with a bunch of other people. It's not my work and my ideas alone. So I just want to give a shout out to everybody that we've worked with and probably some other people in the background that Dave's talked to about this. So the clinical setting and problem here is ARDS, which is acute respiratory distress syndrome. This is an incompletely understood pathway to respiratory failure. It involves fluid buildup in the lung. It involves fluid buildup in the lung that can prevent the lung from opening completely. That can cause low oxygenation and some other downstream problems. It occurs in about 8 to 10 percent of ICU patients. Lots of them require mechanical ventilation support to survive. ARDS is found in about 3% of all ICU patient mortalities. So there's a really important reason to be looking at. You know, a really important reason to be looking at this. So, the fact that people with ARDS need or require mechanical ventilation increases their risk of ventilator-induced lung injury. So, I think Brad's going to talk a lot more about this. Okay, he has. Okay, so I'm not going to talk about it a whole lot then. So, but the basic idea is that there needs to be a way to minimize. To minimize ventilator-induced lung injury through appropriate ventilation schemes, but that probably requires some patient and injury-specific settings. Those we don't really know, and there's not really a way to discern what they are. The real consequence is that mismatch between the ventilator settings and the sort of patient capacity or Sort of patient capacity or expectation causes ventilator dissynchrony. So I'm going to abbreviate that VD. Brad has probably also talked about that a bunch. It's hypothesized to relate to ventilator-induced lung injury and therefore to worsening ARDS and poorer outcomes. So the clinical decision points here, just to provide context for this problem, I'm certainly not going to address these, involve things like what kinds of patients should be paralyzed to limit. Should be parallelized to limit the desynchronous behavior. When you paralyze them, parallelization comes with its own set of risks and downstream problems. The other more sort of informatics-minded questions are that it's really difficult to quantify the contribution of desynchronous behavior to VILI and ARDS, and it's not clear how ventilator desynchrony should be. Later, dissynchrony should be quantified in terms of severity. So that's sort of the introduction slide. Looking at it more in a systematic perspective, the system has two components. One is the human lung, and the other is the ventilator. So one of those is a piece of an anatomical organ. Is an anatomical organ, and the other is an engineered sort of artificial system. So combining them together is not a physiological system per se. So the ventilator here is providing the forcing. Sometimes the patient's diaphragm movement and some other things are also contributing to the forcing. But the lungs are really acting as an internal compliant boundary. And so the The pressure and volume dynamics, which is really sort of the mechanical way to represent this system, those dynamics arise from really small-scale structures like a fraction of a billion alveoli spread between two lungs. The observation process, however, takes place outside the patient body, or like in, you know, between the respirator or the ventilator rather and the person's lungs. So it represents kind of So it represents kind of the integral or the net sum or the bulk effect of all of those processes together, not separately the lungs, not separately the ventilator, and certainly not with any kind of spatial resolution of the lungs. So models can't really assume any kind of long heterogeneity, even though we know that that is essentially something that's lying at the base of the problem. On the other hand, we have really high resolution waveforms. Really high-resolution waveforms, and the nice thing is that pulmonologists and people in the respiratory world can look at the waveforms and be able to identify what type of ventilator disynchrony is going on, especially if they have esophageal pressure, so that they can quantify the patient effort at a breath level. So, looking at the waveforms are really important, and what we're trying to do is harness some of that information that people Some of that information that people know when they look at a waveform and know that that is a certain type of desynchronous behavior and know possibly what the mismatch between the lung and ventilator is based on that. So the observations again that we have to work with are pressure and volume at the airway. I'm adding flow in here, although I don't talk about flow. It's really like the derivative of the volume. We also don't have esophageal pressure for a lot of patients, so I've kind of For a lot of patients. So I've kind of left that out. So, really, what we're working with are pressure and volume and then the ventilator settings. So, the existing models don't really account for the ventilator side. They're more models of the lung. And they're not really, at least in my opinion, they're not forward kind of dynamical models. They take sort of knowledge at present time of pressure or volume and translate it. Volume and translate it parametrically into current knowledge of pressure or volume. So there's no time-forward forecast in these systems. And that makes it a little bit different from what I was expecting when I started working on this problem and people were talking about this being an ODE model. So really, it's a macrophysiological problem, but it's a model, but it's really built for inference, that you take pressure and volume information. And volume information and optimize parameters on the basis of that in order to get parametric representation. So in order to estimate all of the various behaviors and waveform complexity that we see in desynchronous breasts, you need either a lot of parameters or a lot of model complexity. That makes things difficult to infer and identify. So, for example, here's So, for example, here's a model from Brad's lab, which is super awesome and replicates some really interesting small-scale dynamics and things like that, which is really important. But in terms of trying to infer this, I did not try it personally, but it has state-dependent parameters. So, coming from a data assimilation background, when I think about trying to infer state. to infer state dependent parameters by optimizing or by optimizing parameters in order to match the state. It feels like a very complex problem that I would not want to be dealing with, but it still doesn't involve the model component. So these are good and really important models for understanding physiology, but we're trying to migrate things toward an informatics environment where we're taking the healthcare process, namely the ventilator. Healthcare process, namely the ventilator, into account along with the lungs and patient interaction. So, four basic problems here. One is stiffness. So, I'm putting that in quotation marks. It's probably familiar to people that work in numerics, but this is really the fact that second scale or breath scale events and insults that take place within the lung within a breath can propagate through time and accumulate over time scales of hours or days to cause injuries. Hours or days to cause injuries. So that's an important part of this problem that we're trying to capture. Another one is the sort of trade-off between complexity and inferability, that if you have a high-fidelity physiological model or one with high complexity or a large number of parameters, it's going to be difficult to infer accurately or stably or efficiently some combination thereof. Some combination thereof. There's also a question of modelability: that the system that we want to represent includes a non-physiological component. And this is one of those things that drove me nuts when I was starting on this, because I think, like Brad and like Bruce mentioned during their talks, like I'm also something of a hard mechanistic thinker. And it occurred to me actually in writing kind of a synopsis of Deepak Agarwal. Of Deepak Agarwal's paper that Brad talked about yesterday, that you don't really need the hard kind of physiological representation simply because this problem isn't limited to a physiological context. And then the last bit of it that I'll mention is the interpretability. So this is, you know, the model has non-physiological components. There are some other parameters that you're trying to make the model super complex. Some of those parameters may escape the physiological. May escape the physiological domain and therefore not be easily interpretable to people who would want to use them for some purpose other than research like pulmonologists. So there's the translatability issue in there too. So we developed a really, really simple, like dumbly simple model, which is, I guess, what this talk is about in some way. And that is essentially a first order linear ODE from Order linear ODE from your basic introductory freshman differential equations class that has some kind of parametric forcing in the form of a piecewise linear square wave whose amplitudes are defined by parameters. So through this filter or this, yeah, it's essentially a filter process, this ODE, comes out with a variety of different waveforms that are associated with the, you know. With the representation of the parametric forcing you gave it. So it's really simple, it's easy to identify. The problem is that it has only a limited amount of parameter identifiability, and those parameters are not necessarily physiological. Those parameters, the parameters are interpretable in the sense that they correspond to parts of a waveform that a trained pulmonologist could look at and identify them as corresponding parts of a waveform. Corresponding parts of a waveform or their influence on the corresponding parts of a waveform. So we traded in all of the physiology in order to get something that represented neither the lungs nor the ventilator process, but really is capturing the entire sort of system in tandem by essentially not capturing any of it, by representing it in a convenient way that we could translate to a more informatics minded environment. So, the way that we were looking at this, and I'll sort of sound it out here a little bit, is that this is in the context of knowledge-informed inferential modeling. That what we're doing is we're taking individual patient information. I hold the control button down here, individual patient information, feeding it into a model, optimizing it on the basis of some external data or an External data or an alternate data stream, and then coming up with some personalized parameters. So it looks a lot like data assimilation without the external data arrow coming in here. The problem of interpretability is really putting it through what is the context of the model definitions. How did you define the model definitions? So, unlike machine learning, here, the Like machine learning, here, the definitions are defined a priori in the model, but they're not tied to any kind of understanding of processes underlying the model. So we really are relying on expert knowledge and the background parameter definitions in order to be able to interpret them in some meaningful way. So this is somewhere between data assimilation and machine learning, the way that we're thinking about it, where instead of Thinking about it, where instead of this block, which would be sort of mechanistic process resolution in a normal sort of physics-based data assimilation model, and we're replacing it with a more kind of arbitrary model that represents some form of expert knowledge that is being used to define the model and interpret the parameters. So, to actually implement this, we used an asynchronous ensemble common filter. So, this is the same thing as a windowed ensemble common smoother. It has a bunch of names. But it basically treats a window of observations as a vectorized operation and then finds an optimal representation within the ensemble span for the For either minimum variance or mode of the posterior distribution. So it's probably not interesting to this group. So I'll just kind of move on past that and say that when we applied this method, or choosing this method, what we were really after was some speed and some flexibility because some of the waveforms have really short-term parameters in them, which presents Term parameters in them, which presents a particular kind of sparsity problem. In that there might only be occasional breasts that have this weird feature that take place in very short time that we would want to capture. So that was one of the considerations for choosing this that turns out not to be important to this example, but we're trying to keep it in there for future use. So continuous time. A couple minutes left there, Jake. Yep. So 1.5 seconds. Uh, so 1.5 second intervals, uh, sorry, yeah, one and a quarter second uh moving window estimates. We get it to match continuous data in real time really nicely. When we look at it in 40-breadth sequences, what we get out are distributions in this blue curve here for the parameters corresponding associated inferred from that data. And we're defining something called a characterization to be the model. The characterization to be the models applied to that parameter summary, or like for the mean, for example, reproduces a red curve shown here that's a static representation of the data within that window. So what we can, I just got a warning on my screen that says my audio might be performing. You're good. You're good, but not a lot. You're good. You're good, but not a lot like two minutes or something. Yeah, okay. So, anyway, static characterizations here beat the single compartment model in the desynchronous cases. So, the blue ones are our model, the red ones are the dumbest single compartment model, but with a pretty high resolution parameter estimation in comparison to the static characterization here. So, where we're headed with this is. So, where we're headed with this is trying to look at long-term behavior within the patient system. So, looking at, for example, 24 hours worth of lung ventilator system descriptors that are composed of statistical summaries in 90-second windows, along with the vent settings associated with them, fed into a phenotyping pipeline that Dave's PhD student, Yan Rong Wang, has developed during her PhD studies here. We're able to Studies here. We're able to identify that the model is, both the model is describing, the inference is describing, and then the clustering algorithm is able to discern particular breath types, a bunch of which correspond to disynchronous breath types. So we see this kind of structure emerge a lot. In relation to the ventilator settings, we can see that there are a lot of ventilator settings. A lot of changes that occur as a result of ventilator settings. The ones that we're most interested in are in this window, which are changes in breath types that don't correspond to ventilator setting changes. Because what that means is that the changes are attributable to some changes in the patient, either because of posture or other applied therapies, not necessarily the lungs, but it gives us a foothold on identifying when these changes happen, why they happen. When these changes happen, why they happen, and other things found here correspond to changes in the ventilator settings that were not included in our statistical summary that we used in the cluster analysis, like pressure support. So there are regularities that occur in the patient evolution. This is just one example, but we see commonalities among many patients. So there's still a lot to improve here. There's a lot of confounding and other moving parts. And other moving parts that we're still trying to navigate our way through. But the thing I wanted to kind of get across is that we're getting a lot of mileage out of using a knowledge-informed framework in a non-physiological inferential setting that's sort of a hybrid between model and data-driven methods. So we're applying a model and we're also optimizing it to data, even though there's no underlying theory involved here, but there is an underlying understanding that we're assuming. That we're assuming of the waveform generating process. And there's a post-inference machine learning going on with this. So that's where I'll stop for the sake of time. And thank you much. Thank you. Any questions? I'll just make a comment by setting up. I'm super excited to feed in like 10 million mouse breaths that I have stored in MATLAB structures into this thing, where we have precise control over injury state, ventilation pattern, and we do a huge leap of like different peeps, different ventilation patterns. I think I'm excited to see how this works in parsing out the difference between. In parsing out the difference between lung condition and the ventilator settings themselves, because it's like somebody who's interested in the physiology, deconvolving those two factors is important to do. You can see how it was built with a translational I because it's trying to deconfound the healthcare process pieces. 