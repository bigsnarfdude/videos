I am very glad to see you all here. I hope I can meet you soon in Oaxaca. The talk that I'm going to give is related to a series of projects that I've been working on for the past three years with Jeff Kalkowski. We developed a framework for studying eigenfunction. For studying eigenfunction concentration. And we have been applying this to studying different problems. So, what I'm going to do is, I'm going to just start explaining what the motivation and the setup is. And hopefully, you'll just interrupt me whenever you want so that I can explain where I'm at. Okay, so here we are. The setup for us is going to be that of a compact Riemannian manifold. A compact Riemannian manifold. We are going to assume it's smooth and that it has no boundary. And throughout the talk, the dimension of the manifold is going to be little n. This is going to matter because I'm going to be writing bounds all the time. So you should remember that that's the letter that I used to know the dimension. Now, acting on the manifold, because the manifold is compact, you have the Laplace operator that has discrete spectrum. Its eigenfunctions, I'm going to denote them by I'm going to denote them by phi lambda, and the eigenvalues are going to be lambda squared here. So, what's going to happen is that throughout the talk, I'm going to be referring to lambda as the frequency of the eigenfunctions now. This is a discrete sequence of eigenvalues accumulating at infinity. Because we are going to be talking about concentration properties of the eigenfunctions, I'm going to normalize the problem and we are going to ask for the total. Problem, and we are going to ask for the total L to mass of the eigenfunctions to be one. And what this means is that then you can think of the modulus square of the eigenfunctions at a point as the probability density for finding the quantum part, a quantum particle of energy lambda squared, the eigenvalue of lambda, at the point x. And the reason why I say this is because now I have this plot that I usually show in my first live with which I'll try to convey. With which I'll try to convince you that sometimes you can see how eigenfunctions respond to the dynamics of the geodesic flow on your manifold. So, here what you have on the left is a disk and a cardioid. And in red, what you have is the trajectory, the billiard trajectory of a particle that you just kicked in with some initial velocity and it started bouncing around. And then these four plots, these are the density plots, the plots of the absolute values. The plots of the absolute values for four eigenfunctions. The eigenvalues here are growing in this direction. And basically, what happens is that black means the eigenfunction is concentrated here, white means the eigenfunction is near zero. So you can see, for example, in this first line that corresponds to the disk that the probability for finding your quantum particle near the center is close to zero, which mimics what happens with the class. What happens with the classical particle that avoids touching the center of the disc? Similarly, here for the cardioid, this is quite chaotic and it's reflected by these eigenfunctions. As the eigenvalue gets larger and larger, it looks like this is getting evenly grayish, which means that finding the quantity for finding your quantum particle somewhere here is just given by the area of the region that you're looking at. It doesn't really matter the shape. Looking at, it doesn't really matter the shape. And so basically, what we are going to try to do throughout the entire talk is to try to understand how, if you fix a point x on your manifold, how the value of the function at the point x responds to it, and how you can use any information on this to get results about LP norms and by laws. So, I'm going to start actually giving the motivation. Really, giving the motivation for the talk. And the first thing is just to present you with the results that we know on point-wise bounds. So there is this universal point-wise bound that's due to Lehntan, Nebuchadneutz, and many more actually. In its fullest generality, the one that I'm writing here, it's due to Hornwander. And what it says is that if you want to understand what's the maximum value that a function can take at a point, then there is a uniform. point, then there is a uniform constant. This big O has a uniform constant on it, that so that the value of the function at the point is bounded above by that constant times lambda to vn minus one over two. So here is the first time where n appears, the dimension of the manifold. So basically this gives you a bound for how big the eigenfunction can be at any point on the manifold. And this bound is saturated on the round sphere. The round sphere is very symmetric. sphere is very symmetric and this helps the eigenfunctions collide at a point and create a huge value. So this is the density plot for what's called sonal harmonics on the sphere. The height of this peak is like lambda to the n minus 1 over 2. So sonal harmonics, they saturate this upper bound. I'm going to be referring to this as the universally upper bound or hormonal upper bound. And the idea is to try to improve on is to try to improve on this bound and not just improve it in for all of m, but basically like how is it that one can impose conditions on the point x to get quantitative improvements on what the value of the function at the point x is going to do depending only on geodesics that run through the point x. Like we wanted to avoid to put blanket assumptions on the geometry of the manifold like negative curvature or no conjugate points and we wanted to try to understand And we wanted to try to understand really like how much information you need on a point to control the value of the function at the point. Now, so this is an L infinity bound. It holds on all of m and more general, you can look at a refinement of this problem and look at L P norms. Then you have SOGS upper bounds that say that the L P norm of an eigenfunction that's gonna be controlled by well, what you had before, but now corrected by minus n over p. Now corrected by minus n over p. This is as long as you are studying LP norms for p above this number, which is called the critical exponent. Basically, you can see that you can recover this result from that one by setting p equals to infinity. And this upper round and LP norms is also saturated for all this p on the round sphere. We will see later why. But the last point in this slide The last point in this slide that we are going to be discussing is how to also try to get improvements on bylaws out of these techniques that we developed. So the bylaw, I'm going to just only talk about counting eigenvalues, even though what we do can be applied to understanding point-wise by laws. But here, we are going to restrict ourselves to fixing a lambda and looking at the number of eigenvalues smaller than lambda. This grows like Smaller than lambda, this grows like lambda to the n plus an error term. This error term, Paul proved first that it was like little low, like the time, little low of lambda to the n first, and then it got improved. And the idea is for this talk to just get quantitative improvements on this error term, this error term, this error term, all under assumptions that should be as local as possible, depending on where it is that you're understanding, trying to. On where is it that you're understanding, trying to understand your problem? Okay, so here we go. The first thing that I'm gonna do is to explain what the structure of the talk is gonna look like. So in the next slide, I'm gonna explain how to decompose eigenfunctions into superposition of what we call geodesic beams. I'm gonna introduce geodesic beams and try to explain how to think of eigenfunctions in terms of this. Then we are gonna talk about how to control. We are going to talk about how to control the value of an eigenfunction at a point using these beams. Then we are going to talk about how to apply these results to improving point-wise bounds on the values of the eigenfunctions, then to improving LP norms, and finally to improving bio loss. Now, what I should say at this point, in case Laplace and functions are your favorite object. Your favorite object is that everything that we do applies to not just eigenfunctions, but quasi-modes of elliptic self-adjoint operators. So if that's pseudo-differential operators. So everything that I'm going to say actually can be applied in a much more general scheme. It's just that I'm using the Laplacian because I can talk about geodesic. Laplacian, because I can talk about geodesic flare. Otherwise, every time that I say geodesic flow, you should substitute that by characteristic flare, and everything just holds. Okay, so first order of business, trying to understand what I mean by thinking of an eigenfunction as a superposition of beams. And here is the first picture that I have for you. Basically, what we are going to do is we are going to fix a point. We are going to do is we are going to fix a point and we are going to look at all the directions emanating from that point. And what we are going to do is to cover the set of directions using what we call to cover it by poles. So like if this is your point X, here is the point X. This is a zoom picture. And here you have the set of unit directions at the point X. And what you do is the sphere, you are going to cover it with bolts. You are going to cover it with balls of radius r lambda. So, r lambda is going to be a function of lambda. You can think of it as lambda to the minus a half, cannot be quite there, but almost. And then what you're going to do is the set of all directions, emanating from x, you cover it with poles of radius r lambda. And then what you're going to do is to turn on the geodesic flow and propagate these balls for a finite period of time. And that's not generate a tube for each ball. You propagate. Each ball you propiate it under the geodesic flow, and then you generate a tube of fixed length whose head is the ball that you are working with. So, these tubes are quite narrow. As lambda gets large, the tubes are getting thinner and thinner. They concentrate along the geodesic. And what we are going to do is to micro-localize our AM functions to each of these tubes. So, this is how the construction goes. This is the same picture that I was just showing you, only smaller. New only smaller. What we are going to do is we fix the point x and we are going to decompose our function. And this is only a local decomposition near the point x into what we call geodesic beams. So each of these objects is what we call a beam, a geodesic beam. And the way in which we are building them is, again, we have this point, all the directions through the point, and then we cover it with tubes now. Each of these tubes Each of these DJ is going to have a beam associated to it. So, the way in which this beam is built is simply you micro-localize a cutoff function that's localized to your tube. You quantize it, you get this micro-local cutoff. And then the way in which you are actually building this is so that they behave like approximate solutions to your eigenvalue problem. Make solutions to your eigenvalue problem. And this is quite important for us. So basically, what we want is: well, this phi lambda was a solution for this problem. What we want is for each of the pieces to behave approximately like a solution. So basically, at the level of these two operators, what you want is for these two operators to commute. At the level of principal symbols, this simply means that the cutoff function needs to. The cutoff function needs to be invariant under the geodesic flare. This is why our cutoff functions are supported in tubes and our tubes are localized along geodesics. In principle, you could build just any family of tubes, but we do need the tubes to be centered around geodesics so that exactly this property holds for us. And so that you just have an idea of how each of these beams will look like, if you only grab one, it's going to look grab one it's gonna look like this so this is your direction or this is your direction if you want and one beam is gonna look like this is the plot the density plot for your function along the beam so this is the direction in which you're moving on the round sphere for example this is what's called the highest weight spherical harmonic and the height on the sphere of this along this tier is like lambda to the one Along this tier is like lambda to the one-quarter. The width of the band is exactly R of lambda, which on the sphere is lambda to the one-half actually, minus a half. It's exactly that. The sphere is quite particular, so there are like things actually can be pushed all the way up to a limit. And this is what happens if you only put, if your function, if your eigenfunction is only one beam through a point, this is how it would look like. So for the picture on the sphere, is you have the equator. The sphere is you have the equator that's your closed geodesic, and then it's concentrated along the equator. And everywhere else outside the equator, the eigenfunction is very, very small. And if you put more than one beam, say you had two beams going through the point, then it would look like this. Then the two beams would cohere at the center and then your function would start creating a peak. If you're wondering, for example, Wondering, for example, what was happening for the sonal harmonics, the ones that were peaking at the north and south pole and saturating the universal round. Then what happens in that setup is that you have to be able to fit through the point as many ims as possible, as you possibly can, while still keeping them orthogonal to each other. So, basically, what happens here if you are trying to recreate the behavior of a sonal harmonic on the sphere is. Behavior of a son of harmonic on the sphere is that you have to start adding beams through the point. You quickly realize that the maximum number of beams that you can fit, because you're covering the set of all directions with balls of radius lambda to the minus a half, is like lambda to the one half of them. And then once you put all these beams through the point, you are going to generate a huge peak. This is the peak that was drawn here at the very beginning on this for the Here at the very beginning on this portional harmonic, this peak has height, lambda 2n minus 1 over 2. And this is how you go about saturating the bound if you're thinking of your eigenfunction as a superposition of beams. Basically, what happens is that if you're going to saturate the sup upper bound, the universal upper bound, then your function is going to look like it will have a positive measure set of directions in which your function can be decomposed into beams that are going to field all those directions, and then those are going to. And then those are going to cohere at the point to give you the maximum growth. But you can think of also like working with these beams: like, if your function is only concentrated in this sector of angles, then you can just arrange your beams to be placed in that direction, and you can put as many as them as you can to create different heights for your beam. So, like for your eigenfunction. So, really, like, think of this decomposition as a very flexible one, but it's giving you the flexibility. But it's giving you the flexibility at the same time of being able to then look forward in time and try to understand what happens with what the value of the function at each of the tubes were. So basically what we are going to be doing is to try to control the value of the function at the point x by understanding how each of these beams behave. So at the point x, we are putting At the point X, we are putting a tube. We are micro-localizing the function to a tube. We are generating what we call one of these geodesic beams. And then you turn on the geodesic flow and you're going to try to see how this tube is going to evolve under the geodesic flow. And we are going to control the value of the function at the point x in terms of what happens with the L to mass of the eigenfunction on this tube and whether this tube for the geodesic flow is going to be solid. Flow is going to be self-looping or not. That's what's going to end up mattering. Okay, so what I'm going to do in the next slide is to explain exactly how to control this value using the beams. So here we go. This picture is the same as before, but now I have two colors: I have green and orange. Orange will mean bad. So bad simply means a tube that's going to reach. means a tube that's going to return to itself in in finite time or like in time less than what you're interested for this talk we are going to be running the time up to log lambda so a bad tube is a tube that comes back to itself in time less than log lambda these tubes that i colored in green are good tubes in the sense that this entire family once you turn on the geodesic flow it doesn't come back to itself Come back to itself. It's what we call non-self-looping. So the first result that we have is the following. Suppose you have a point X on your manifold, and now you can look at the set of tubes emanating from X, and you can split them into two groups, what you're going to call the bad tubes and the good tubes. So, what good is what it means is that your family of green tubes is good, provided it's non-self-looping for time. concept looping for time log lambda. If you have this setup, then what we can do is to control the value of the function phi lambda at the point x, and actually in a neighborhood of the point x, this ball of radius r lambda around x. By this quantity here, so let's parse this together. Here you have a constant times lambda to the n minus 1 over 2. This is exactly what appears in the universal bound of corn. Appears in the universal bound of core manner. This term, it's a weight that we are adding now in the hopes that it will contribute with something meaningful from which we are going to get the quantitative improvement. So I'm going to parse for you what this piece says. So basically what we have here is the number of bad tubes to the power of a half, the number of good tubes to the power of a half. The good tubes come with this improvement. They are divided by log lambda to the one half. Are divided by log lambda to one-half. And here in front, we have the radius of the chips. So basically, remember what we had was: this is your point x, this is a set of all directions, and you're working with these walls of radius r lambda. So you're working here in the co-sphere fiber at x. This is space of dimension n minus one. So the volume of the, so what happens here is if you look. So, what happens here is if you look at the volume of a single tube, the length of the tube is fixed. So, then the volume of a single tube is going to be r to the n minus one. And this is the square root of the volume of a single tube, what I'm circling here. So, basically, what you're doing when you're multiplying these two terms together is to write the volume of the set of the bad directions to the power of one half. That's how you can. That's how you can think of that product. And at the same time, if you multiply the radius times the number of good tubes, then you get the volume of the set of good directions to a power of one half, but with the low atmic improvement. So the idea is for you to check if you are trying to get an improvement on the universal bound, you look at the point x and you ask yourself, can I split the family of twos going through this point into Going through this point into two sets, good tubes and bad tubes, in such a way that the set of bad directions is smaller than the volume of the set of good directions, but divided by log lambda. Can I do this splitting in such a way that the set of tubes that are returning, the bad ones, have very small volume? If the geometry of the problem that you're looking at allows you to do that, then you're going to get this lower rhythmic improvement. Improvement. That's how one goes about using a result like this. And what I want to do now is to explain where this comes from before I explain different situations in which one can do this splitting. So the reason why this works is an estimate that holds under no assumptions. You just need eigenfunctions. Actually, you only need Poissy modes for your elliptic self-adjoint operator. Operator. And what happens is that you can control the value of the eigenfunctions at the point x by, well, here you have the same constant that the universal band had, the same radius to the power of n minus 1 over 2. But now instead of putting numbers of good tubes and bad tubes, you just have the sum of the L2 masses of each of your beams. So you are localizing your eigenfunction to a tube. That's your geodesic beam. And now you measure its L2 mass there. Maps there. So basically, the reason why an estimate of this shape holds, and basically, what's happening is that one has this extra radius here that's giving you the improvement, is the following. So I'm going to try to explain the idea in three bullet points. So this idea comes from work from Koch, Tottario and Sworsky on LP semi-classical estimates. Piece and classical estimates. So, what they did was to realize the following: you're looking at your beam, I'm writing it as beam here, and you have your tube that's concentrated along a geodesic. Now, call the normal direction to your geodesic CÎ½, new for normal. Okay, so this is in phase-phase. You're looking at the set of directions that are perpendicular to your geodesic. That are perpendicular to your geodesic. And then what happens is because the head of this tube is like of size R of lambda, then your beam, when you take it Fourier transform, the support is going to be inside this tube that you're working with. And that means that in the support of your beam, the frequencies are going to have their normal components be smaller in size than this radius R lambda that you're working with. Working with. What this allows you to do then is if you differentiate in the normal directions to your geodesic, you're going to get R of lambda improvements. So basically, when you differentiate alpha times in the normal direction, you get radius R lambda to the power of alpha as an improvement on the L2 norm. And then what you can do is, once you have control on the derivatives, you can use them. You can use them using a Sovolev estimate to get control on the n infinity norm. So basically, you're getting this improvement here, which is the one that appears in front of the sum for each of these beams. Now, the question is, how is it that then one goes from this sum to counting good and bad tubes? And in this step, what we are using is Egore's theorem. So Egore's theorem. Theorem. So Agorem's theorem is doing the following. Again, this is a proof of a picture. It says that, well, it doesn't say this. This is always true. If you grab just your piece of the function, the beam, its L to mass is going to be controlled by the total L to mass. What the Gorab's theorem tells you is that if you look at your beam and now you propagate it under the flow once, you now have this tube that has twice its length. You're here. You're here. And what the Gorham's theorem tells you is that the mass of this new tube is going to be twice the original mass that you had, as long as this tube didn't come back to intersect itself. So Wegor's theorem tells you that if you're looking at the mass of this combined tube, now this is going to be twice the original one. But you know that the mass of the combined tube is controlled by the total L to mass. So you get this bound here. And of course, what you can do is you can propagate this argument as long as This argument as long as your Q doesn't come back to intersect itself. And if your assumption is that your Qs are non-self-looping for a time log lambda, then you can carry this argument for log lambda times and get a log lambda improvement here. So each of these pieces here, each of these L2 norms of your beams, are going to be controlled by the total L2 mass divided by log lambda. So that's why for the good tubes, you have the total L2 mass divided by log lambda. The total L2 mass divided by log lambda, you get that quantitative improvement, but only for the good piece because those ones are the ones that don't come back to self-intersect. For those ones, are the ones that you really know that you can get this improvement. For the bad ones, the ones that do look back and self-intersect, we cannot do anything and we just use Cauchy shorts. So you just put the number of tiers. So this is really what's behind the scene. Actually, the Actually, the result that we have is more refined than this. You can work with several families of tubes where good and bad are defined for different times, not just for log lambda. And then you have like this, you can set a sequence of times and look for each time which tubes are non-self-looping for that given time and so on. And you can have a more refined control of what's happening with your tube. Fine control of what's happening with your tubes. This is the easier version. And now, or perhaps this is a good time to say that if you're working on a space where you can apply a Gore's theorem for times that are longer than log lambda, if you can keep control of what happens with the masses of your tubes and get an improvement for polynomial times, then you can get polynomial improvements on this mouse. It's just that in its fullest. That in its fullest generality, Egor's theorem works up to error-first time, which is lowarhythmic in Lambda. This is why all the improvements that I'm going to show you are lowarhythmic. Okay, so now I can start explaining how to apply this result to getting improvements on L-infinity bounds, LP norms, and biology. So, those are the next three slides. So, for So for pointwise bounds, we had this result by Formanda that says that the infinity norm was controlled by lambda to be n minus 1 over 2. Now there have been lots of improvements on this bound due to Safari, Sol, Selditz, Toth, Galkowski. These are improvements that go from a big O to a little O. So it's not a quantitative improvement and really quantitative was what we were looking after when we Was what we were looking after when we started with this decomposition. So, in terms of quantitative improvements, the result that's out there is due to the R from 77. And it says that if you put a blanket assumption on the geometry of your entire manifold, you ask for it to have no conjugate points, then you can get a logarithmic improvement on the L infinity norm of your eigenfunction. And this is quite a strong. This is quite a strong assumption, asking for no conjoined points, and we wanted to step away from it and like weaken it. So, let me explain briefly what this implies. So, having no conjugate points, it implies that no matter which pair of points you choose in every direction, geodesics are spreading apart. So, like, if you have a pair of points that's joined by a geodesic and you want to consider a variation of a geodesic in some given direction, then geodesics. Direction. Then geodesics that are going to be variations of your original one in that direction are going to start at this point x, but they are going to split apart from y once you get all the way up to y. So here what's thrown is the Jacobi field along the geodesic, satisfying this equation. This is the Jacobi equation. And basically what's happening here is that your Jacobi field at the point X is forced to have the value zero. If you have no If you have no conjugate points, what this means is that no matter which GLSA gamma you choose and no matter which variation of it you choose, so no matter which initial velocity you give for this Jacobi field, then the Jacobi field, once you get all the way up to y, it's not going to be zero. So this vector field, this field along the curve, is going to have a component there that's going to be making your new geodesic spread apart from the original one. So that's what. Gina one. So that's what having the conjugate points means. It means that no matter which curve points you choose on your manifold in every direction, you're gonna your variations of your geodesics that joins these two points are gonna be spreading apart. In the opposite case, you have the sphere, the sphere that was saturating our bound. What happens basically here is that you have a point X and Have a point x, and on the sphere, every point is so it's conjugate to itself, and it's conjugate in the worst possible way. So, if you if you connect X with a geodesic to itself, then any variation of this geodesic is going to give you a new geodesic that's going to come back and wrap around and close at the point x. So, basically, if you force a Jacobi field to vanish at the point x, then after you come back, And then, after you come back with the Jacobi field along the curve, it's always going to vanish again at time, after time, whatever, to apply once you return. So upon return, this y is the same as x, and it's also going to vanish. So in every variation of a geodesic that joins the point x with itself, it's going to give you a new geodesic that closes. This is what's called maximally self-conjuate. So it's quite the opposite of x. Quite the opposite of having no conjugate points. But in the middle of these two pictures, you have a lot of room. You may have two points that are joined to each other. And yeah, it may be that most geodesics are going to collapse. But it may be that you have just one direction in which geodesics are spreading apart. And it turns out that that's enough to get this logarithmic improvement. So that's the condition that we are going to be working with. That we are going to be working with, we are going to say, okay, if you're a point and after time t, you return to a ball of radius e to the minus constant times t near the point, center around the point. So if you look like your geodesic is going to close at the point, or at least it's going to close if you are only looking with an exponential lens. Then what you need to make sure Then, what you need to make sure is that when you're returning to the point X inside this tiny exponential ball, your Jacobi field cannot vanish. So, basically, what that means is that there has to, if you come back to return to the point, there has to be a direction in which geodesics are spreading apart. If you can guarantee that this is happening, then what we prove is that you can get the logarithmic improvement for the L infinity norm. For the LUFINIT norm in a ball of radius r lambda that's going to zero centered at the point x that you were interested in. So basically what happens is that we can get an improvement of this form, but without asking for an assumption on the global geometry of the manifold, we just need to fix the point x and look at what happens with geoesics that are going to join the point x with itself. And what we need to ask is that there has to be always a direction in which geosynchronics are going to be spraying apart to get this logarithmic improvement. And what happens is that once you have a result like this, you can now start thinking, okay, perhaps I can improve LP bounds because after all L P bounds, you get them as interpolation of L infinity bounds and L P critical bounds, at least for the high. At least for the high exponents. So that's the next slide for us. We are going to basically use this result to improve LP norms. I'm not going to show you how it's done, but for LP norms, you have this result of salt that only holds above the critical exponent with this shape. And Hassel and Daisy in 2015 got a lower. 15, they got a logarithmic improvement on it. So they got square root of log lambda to improve the L P norm, asking that the manifold had to have non-positive curvature. What we were able to do was to weaken this assumption and to ask instead for the following. So suppose you are interested on the LP norm inside a set U that satisfies the following. So you have That satisfies the following. So you have your surface or your manifold, and you're interested only in the LP norm inside this set U here. So what you're going to do then is to look at all the points x, y in here, and you're going to ask that the point x shouldn't be maximally conjugate uniformly to the point y. So what that means is exactly what was in the previous statement in the previous slide, only with x different from y. So basically you're asking that. So basically, you're asking that if X and Y are joined by a geodesic, there has to be one direction in which variations of geodesics are going to be spreading apart. If you have that assumption, then we can control the LP norm inside this set here only, and we can get a logarithmic improvement. So this assumption, for example, holds when the manifold has non-positive. Holds when the manifold has non-positive curvature, but it allows for positive curvature, it allows for conjugate points. It's just that they cannot be of the worst kind, basically. And it's also more general in the sense that it's not an L P normal of the entire manifold. It could be, but it's not. Like you can really just look at what happens with your subset U. And if you understand what happens with geodesics, that join the point at any two points. Join the point any two points X and Y inside your set they can, of course, leave the set. You need to keep track of what happens with the geodesics when they leave the set. But if you control this geodesics, then you have this L P north bound on the set U only. And perhaps things that are quite interesting from this work is that in the proof of this is hidden that basically Hidden dot. Basically, if you are going to achieve this LP bound, if you're going to saturate it, it can be only saturated at finitely many points. So basically, if you fix an epsilon, then there exists a finite number of points that depends on epsilon, at which the value of the function at the point x is going to be bigger than your bound. And not only this, but also And not only this, but also what we can say is not only that there will be finitely many points, but we can actually understand exactly how the function looks like at these points. So how these eigenfunctions will look at the points where the LP norms are being saturated is exactly like the sonal harmonic divided by square root log lambda. So when I say this, when I say that the function looks like this sonal harmonic, what I mean is like if you think of it. If you think of it in terms of the decomposition into beams, the sonar harmonic was the one that had all the directions filled by geodesic beams. So you had this positive set of measures, positive measures here, sorry, a set of positive measures of directions through the point X on which the function was localized. And then what happens with the sonal harmonic. And then, what happens with the sonal harmonic is that it's uniformly spread in all directions. Well, if you are going to saturate the L P norm, you have to have the same shape. You have to be concentrated in all the directions, or at least in a positive measure set. And the way in which you're going to be supported in each of the tubes is the same way as the sonar harmonic does. I will not say much more than that here. If you're interested, you can go check the theorem in our paper. The theorem in our paper, but just have that picture that if you are saturating the L P norm, then you are only saturating it at finitely many points. And at those points, you really look like a sonal harmonic. So you really looked like the eigenfunctions that were peaking at the north and south wall on the sphere. Okay, and now the last topic was how to get improvements for biolog. Get improvements for bile laws. For bile laws, we were counting the number of frequencies smaller than some fixed number, lambda. And they grow like lambda to the end plus an error term. And the aim is to try to improve this error term. Now, the general result is lambda to the n minus one. So the number of eigenvalues that grow at most like lambda is like lambda to the n grows like lambda. The n grows like lambda. Sorry, the number of eigenvalues that are whose frequencies are bounded by lambda grows like lambda to the n. Now, the error term in general is known to be like pig O of lambda to the n minus 1. This is for a compact, smooth Riemannian manifold. There is a result by Deutschermat and Gilamin that says, well, this can actually be improved to a little lower bound if your manifold is aperioic. This results. This result also holds when you have a boundary that's due to E-b. We do know, I should have said this a second ago, but we know that this bound is saturated. It's saturated on the sphere, it's saturated on solving manifolds. So you do need an extra assumption if you want to improve it. If the manifold is aperiodic in the sense that the set of directions that give you close geodesics has measure zero, Close geodesics has measure zero, then you can improve it to a little low bound. That's Deutscherman and Gillimin. Recently, Josevich and Weiman proved that if you're working on a product manifold, and what I mean by that is that M is like M1 cross M2 with the product metric, a non-trivial product. Then they prove that a product manifold is aperiodic in this sense. Periodic in this sense. So the measure of the set of directions that generate closed geodesics is zero. And so then they could apply the Eustermat and Gillimin's result to get that this error term in the eigenvalue counting function is going to be like little low of lambda to m minus one. In terms of quantitative improvements, there is the result by Verard that says that if your money That says that if your manifold has no contrary points, then you can get a log-lambda improvement there. And basically, what we were able to do was to use the geodesic techniques that we've been developing, not for the setup that I showed you, but actually for instead of understanding how the values of a function at a point behave, more like understanding how the average. Understanding how the averages of a function along a sub-manifold behave. We use that to think of a bio law as an average of a spectral projector over a sub-manifold. The sub-manifold is a diagonal in McRosan. And doing that, we were able to prove, for example, that if you're working on a manifold that's a non-trivial product, then you can actually get a logarithmic improvement for Improvement for the remainder term under no extra assumptions. Basically, what's happening here is that if your manifold is a non-trivial product, it's more than just being a periodic what you have. And what happens really is the following, which is a slightly more general result. You can get the logarithmic improvement on the bio law if you ask for the following. If you ask for the following, so you're looking at the set of directions that are close to being periodic. So you're looking up to, think of r as a number that's going to zero. And now look at those directions such that four times that are smaller than log of r inverse, they come at most are close to in periodic. So you don't just look at the periodic trajectories, you look at the ones that are. You look at the ones that are close to being periodic for times that are smaller than lower rhythm of one over r. If you look at all those trajectories, all those directions that give you trajectories that are near periodic, and you measure the volume. And this volume is controlled by one over log of R inverse, then you Then you can get this upper bound on the remainder term for the bio law. And basically, what happens is that a product manifold satisfies this condition. And a manifold without conjugate points also satisfies that condition. But many more manifolds also satisfy that condition. So, like, this bound that we are getting is much more general than what was had before. And I should also mention that it's not just a bound for the Not just a bound for the eigenvalue counting function, it's a bound that we prove for the pointwise biolog. So, if you're interested in what happens when you are working with points x and y and looking at spectral projectors at x, y, the results that we have apply to that setup. Okay, that's it. That's the end of the talk. Thank you very much. Thank you very much, Arisa. Yes. Does anyone have any questions? Very short. Chaisa. Yeah. What if you don't have a product with something like a product, like say a fiber button? Any hope of any improvement there? If you had one, can you say? A fiber button. So like a twisted product. Oh, yes, yeah. Yeah, I think so. Yeah, actually, so we do we do have examples where you twist the metric on the manifold. Like we are not thinking of it as a bundle, but yes. And I'm pretty sure what you're saying, yes, can also yeah. Yeah. So like a Riemannian submersion or something? Yes. So be beyond that, if I can So beyond that, if I can, if instead of a fiber bundle, what you have is a foliation and then some metric adapted to the foliation and to the orthogonal to the foliation. Same thing, probably. So this is how you should think of it. If you have any mechanism that's hinting you at the following, if you have a closed trajectory, you can consider variations of that geodesic that's gonna end up generating things that are spreading apart. Generating things that are spreading apart. If you think that that can be done in your setup, then there is a good chance that you can get this lower admitting primat. When you have a maximally non-self-conjugate direction, I mean points, yeah, point, then, so there is one direction where you start out with a Jacobi field that will not end up as being. End up as being zero once you come back, right? And so this is going to be happening also in a neighborhood of the point of the direction. So that by itself is a set of positive measure. That's how you use it, yeah. But then so that affects only the constant that appears in front, not the log lambda, it's still there. I mean, it's just a constant that gets messed up. Messed up in which sense? Messed up in which sense? That the constant becomes bigger, the smaller the volume of the set of directions that are not self-conjugate. You have this C and then lambda and then the square root of log lambda in the denominator. Yeah, so okay. So the C that the Cs that I'm writing here are completely independent. Are completely independent on the points. They are really uniform in whichever set that you're looking at. I meant in the O of lambda to the n minus one over two and so on. I mean. Yeah, but they like every constant that I wrote throughout the entire slide presentation, they are uniform in the neighborhood. So these are neighborhoods that were shrinking around the point, but the constant was uniform in that neighborhood. Uniform in that neighborhood. So you fix the point x, you have a radius that's going to zero, and in that wall that's shrinking to zero, the constant that you choose is uniform for every point on that wall. But you're right. I mean, what you're using is that if you have one direction in which geoes are spraying apart, then you use that direction to build your family of good tubes that's gonna be in volume much larger than the ones that do return. Larger than the ones that do return. Okay. Anyone else have a question? Okay, so what about singularities, let's say, you know, boundaries? How hard is that? Some of us used to work on these things. Yeah, and I work with Jeff on these problems, and he sort of likes boundaries. He sort of likes boundaries. I think what's happening right now is that we are just working out the easier case of no boundary and try to understand what's the full extent to which we can improve, yeah, apply these results too. But yeah, I fear we are moving to boundaries. Well, I mean, the transversal part of the boundary shouldn't be fundamentally different when the rays are simply refracted. It shouldn't be. And I guess the usual arguments are that the tangent rays have relative. Arguments are that the tangent rays have relatively low measures, so you might be able to get some fairly cheap results. Yes, yes, but there are very few results about even how to control the spectral projectors and near the boundary. Because they're not, you know, they're not understood at all. I mean yeah, so understanding near glancing, which we which is what we would try to I guess. Try to like there is some serious technical math that needs to there are indeed there are indeed. Um, yeah, okay. Well, thank you again for a wonderful talk. If if no one has any questions, we'll resume at