Inviting Stubanti, this is my first visit in Canada and even in the Western Hemisphere, so I'm very excited. And I contribute to some research on open quantum systems, but now just recently I am very focused on my other field of interest about entanglement detection. So I decided to say something about this. So about optimization. So, about optimization of environment weaknesses. So, Marco told me to be to start from the beginning, so it will be very basic introduction. So, let us start from various inequalities, yes. Very inequalities, yes, and this is inequality involving classical random variables, yes, and inequalities hold under assumption, yes, of Yes, of comparability space, yes, from physics would say local in variable space, yes. But yes, it appears to be violated for quantum observables. And you know, let's start from the most famous, yes, for C HSH equality. Yes? So here. Here. A1, A2, B1, B2, they are dichotomic observables. Yes, they have spectrum plus minus 1. Yes, this is not yet the spectrum, yes, possible values, yes, because they were in a classical case, yes. And you know, it is, all of you, I think, know it from the course that it is, you know, you can easily prove it that that it should hold. Yes? That it should hold, yes? Hold, and then we see that this is the example. If we choose such an observables, you know, each of these observables is dichotomic, yes, spectrum of sigma x, spectrum of sigma z is plus minus 1 of B one and B two as well. Yes, and then if we take a L pure state, yes, given by such a state vector, yes, we obtain expected value. Yes, we got an expected value 2 square root of 2, yes. So this is surprising, yes, but here we do assumption, yes, maybe sometimes not conscious assumption, yes, of that there exists a primity space, there exists a hidden variables. And there is a lot of philosophical implications, yes. Yes, this is uh uh local realism. Realism and so on, yes. So then inequality, of course, won't be violated on separable states. Yes, so this also we can show in a similar way that we show that it is satisfied for classical random variables. Yes, and we show, yes, so this is Alena Speck last Nobel Prize about it. Yes, we show by. Show violation, yes, in a so-called bell experiment, yes. We have a source, yes. Source have a state law, yes, because you know, to do any measurement, any expected value, we have to we rather we do not rather say about state of a quantum system, but rather state of the source, yes, because we assume that each copy is. Each copy will have the same state, each new copy. And, you know, we have two laboratories specially separated. Yes, here we can choose one of two observables to be measured. Yes, each observable has spectrum plus minus one. Here the same, yes. And we do it yes in this way. We choose one or two randomly on both sides, yes. Randomly on both sides, yes. After all, yes, we see what we obtained. We sorted, yes, that let's say A1B2, yes, that we multiply, we calculate expected value, yes, and then we calculate this expression, yes, and then we can obtain something bigger than true. And this shows us non-classical. Shows us non-classical behavior. Yes? And now you see, we can rewrite this CH essentially quality in this way. Yes, you get less or equal than 2, but this is expected value of 2 times identity. Yes, and now, and of course, this is true for a separable state, but we know that there exists a state that is not true. Yes, this is not true. So any choice of observables. Any choice of observables, yes, give us observables. This is true for any choice of such observables. Yes, so yes, in this way we always obtain, we always obtain observables positive on separable states, but sometimes, yes, when we can obtain violation, yes, this observable is not positive on entangled states, yes. Entangled states, yes, and we call such an observable entangled weakness. This is an observation which is positive on all separable states, but it is not positive in general. Yes? And so it detects if we observe that expected value, yes, or this observability is negative. Yes, we have detected entanglement in a state row. Okay, yes, and for any state row, And for any state raw, yes, there exists a witness detecting it. So this is a simple consequence of Harden-Manner's separation theorem. Yes, so we have a convex set of separable states, and tangled state. It is always a convex set. So we can, so there exists a linear functional, yes, separating, such that one set, yes, this one point set, lies in this area, yes, and separable states lies in this area. Yes, and of course, This area. Yes, and of course, any functional can be realized in this way, so for any row that exists, weakness detect. How concrete is this existence? Is it just an existence theorem kind of? Or is there a method of constructing the W? Ah, so okay, there is not a meth we have no hypothetization of endangered weaknesses, yes, and this is uh so that's why uh antagonistic is still a challenging problem. Still a challenging problem. So if raw comes from, if we know about entanglement of raw from, let's say, as a parameter criterion, yes, we are able to construct entanglement weakness. Yes, so we can translate it to observables AIBI, yes, and construct experimental technique. But we have no except, let's say, two qubits, yes, like this, yes, but for higher-dimensional systems. This, yes, but for higher-dimensional systems, yes, or more particles systems, we have no characterization of entanglement weaknesses. So, bare inequality we can treat as a factory of entanglement weaknesses. Yes, we put them observables, yes, and what we obtain is an entanglement weakness. Yes? But, okay, it is important there are weaknesses not originating in any berry inequality, because it was shown in our labor. Because it was shown, you know, maybe 20 years before already that there exist entangled states, yes, which admit a local variable model. This is interesting. Okay, so this common choice, yes, it is choosing this observables, and then CHS inequality produces such an entanglement weakness. This is exactly. Weakness. This is exactly entangled weakness. It's produced, and this entanglement weakness detects entanglement of Bell pure Bell state. Yes, and now due to Choi Markovsky's amorphism, and I'm going to witness the choi-matrix of a positive but not completely positive map. Yes, so we have a lot of positive maps, just in Anheld, let's say. Just in Anheld, let's say, let's say COP. Okay, so this is Chernikovsky's analogism. And okay, and now how it's time to say something about optimality of weaknesses. So this weakness is not optimal. Yes? So now without giving a proper definition. Okay. So let us put him closer to the set of separable states, yes? To the set of separable states, yes? Oh, this is better, but it's still not optimal. So we can do it like this. Yes, this one detects more than this. And this one is optimal. Yes, because if you would like to correct them more, okay, so we will gain something here, but we lose something here. Yes, so this one is uh optimal because uh it cannot detect more states be uh uh without losing something. Uh without losing something. So it's kind of fast. Yes. And optimally it would be local or yeah, because you will show the boundary of the proxy as a straight line. Maybe it could be curved and it could be only local. Okay, if it is, you know, if it is, let's say, here, because it's high-dimensional, yes, a set of this is the set. Uh density, this is a set of density operators, yes. So uh but n let us use uh let us use uh lower dimensional analogues that let it be just set without any facet, yes, like a circle. Yes, so then all a tangent is optimal. It's not a local property, yes, because It's not a local property, yes, because it is here. We have a definition, yes. So optimal, yes, if no other witness detects more states, yes. So it is defined, you know, in terms of all possible entangled states to be detected, yes? So it's not a local definition. Yes, so it is optimal, yes, in geometric words if it is tangent, yes, if it's coincides with. Yes, if it coincides with a phase set of maximal dimension, yes? Face of the convex set. Yes, like here, yes, like here, that here it touches, here it touches in one point, but we see that this one point is a point of a phase. So we can yet make it more optimal. I'm currently because it's it will always be a plane. Yes, yes. And the boundary of the simple state has no reason to be yes, yes. So we can characterize the boundary of density matrices, yes, it's yet quite simple, but characterize boundary of set of separable states. It's not a simple thing, yes, so we have not. So, we have no full characterization, I think, even for the two cookies to describe the spatial structure. Yes? Yes, so this is just, you know, if no other witness detects more states, yes, in sense of inclusion, yes, not in sense of a not in sense, let's say, of a measure, yes, of the volume of the set, yes, but in sense of the inclusion. Okay, and equivalently, yes, this is a Yes, this is an important result that it is optimal, yes, when we cannot subtract a semi-positive definite observable, yes, and still have a witness. So this is an equivalent definition. Okay, so let us take our witness from the example. What we can see. First, we can do this thing that we See. First, we can do this thing that we have something on diagonal. Yes? Of course, here we have to calculate something, yes, but we can show that if we will subtract this value, yes, it is still a weakness. And then we can see that here there is yet one more positive, yet one more observable here, yes, to be subtracted. And so we do it. And this is. And this is already optimal. And on this stage, you have to just believe me. So you can just take, you know, alpha beta, yes, pure separable state, yes, and check that this is for at the choice of alpha beta. This is good. But yet you have to believe in, but I will show you that this is this is optimal. Yes, and the dots are zeros, right? Dots are zeros, so this is a very good way to. So, this is a very good way to represent zeros. So, it is still quite readable. And you see that, of course, we have something like this, and it gives us nothing, yes? Because this is observable on a specially separated system. So, of course, we have to decompose it. Yes, we have to decompose it to local tester products, yes, and then we will do it, you know, in a four settings in a Bell experiment. In a Bell experiment. Also things in a Bell experiment. So always we have to decompose it in this way. Okay, so let's go further. Yes? And so important definition. We define a stimulus subspace. We know that this expression has to be non-negative. But now we were interested for which pure states, yes, for which state vectors it is exactly zero. Yes, and then we check. Yes, and then we check what subspace such a vectors span. And now we obtain this is a spanning criterion, then if this is the whole Hilbert space, then W is optimal. Yes, and this is, you know, if you see the literature about, you know, new entanglement weaknesses for technique entanglement, this is the common way for proving optimite. But this is only a sufficient condition, it's not necessary. I will show you. And okay, let's go back to our example. Yes, so we do this thing, yes. This is zero. So you can write it in terms of vector entries, yes, and you obtain this thing. And you see that beta one has to be minus alpha one, beta two has to be alpha two. So this is a simple calculation, yes. A simple calculation, yes, and then so you put it here and you obtain such a vector. What is vector span? So, here it is here it is simple. So, normally it's harder to prove, yes, the spanning, but here, what is the dimension of spanning subspace? So, okay, we do numerics, yes, tossing, but then you have to provide the proof. So, we have to think a little bit, yes, how to justify our numerical result. But here, it is simple because this, you know. That, but here it is simple because this, you know, these polynomials are just independent, so of course they span everything. So, this is simple there. We have four independent polynomials here, yes, on each entry, so we are happy this is we already have an optimal weakness. So, we started from weakness, yes, coming from brain equality, we optimize it. Yes, so okay, and okay, let's say that it is. And, okay, let's say that it is not optimal. Okay, maybe I have written here a wrong word, so it is not spanning. So now, yes, observe W supported on the orthogonal complement of the subspace. Now we're candidates to be subtracted from W and to optimize W. Yes, because subtracting positive observable, yes, we optimize the witness, like in the previous example. Yes, so now we can restrict our candidate. We can restrict our candidates. Yes, candidates have to be supported on the orthogonal document of the spanning subspace. Okay, so here let us take an example. So this is a witness coming from the famous choin map, yes, in this for two kutrids. Two kutrids, yes. And it has seven-dimensional spanning space, but this is optimal. So it is no result from the late seventies that is even a From the late 70s, that is even an extremal positive map. Personal witnesses maps we can use just can exchange because duty is important to this. Same objects. Yes, okay, and so let us go to further to cook quart and cook quart. Yes, and let us take such a witness, so like a similar to Troy. Just a generalization. Yes, just a generalization. Now it has three-dimensional spanning space and it's not optimal. We can show this is not optimal, but this is its optimization. Yes, so we subtract two projectors. Yes, still it is not spanning, but it is already optimal. Yes, so this is quite this is a family of examples, and it's quite fair that we still can prove of. We still can prove optimality without spanning. Yes, and in general, yes, this example is like this. Yes, so here we have, you know what this means, yes, 2, 1, 1, 0. And then by cyclics, 0, 2, 1, 1, and so on, yes? So here we, in next diagonal blocks, yes, we do cyclic permutation. And here this is a generalization, yes, and then still it has n squared minus n plus one-dimensional spanning space, yes, but it is optimal if and only if, yes, they are relatively prime. Yes, okay, so interesting results, yes. But why do we do it? Yes, so of course, proving these things is very nice, is because there are hard things, yes, and any proof is any proof, any theory is just. Any theory is challenging and any result, we are happy with this. Yes, but now let's go to motivation. Yes, so okay, first I have to let us take, yes, we have a space of D1 square, space of Hermitian observables, yes, in one subsystem and space of Hermitian observables in the second subsystem. And let us choose here a orthonormal basis. Orthonormal basis. Yes, I guess. Nice. And okay, and let me do one assumption that you know first element of basis is no normalize again. Normalization factor yet here and here. So of course the rest are traceless. Yes? And then let us calculate the expected values of such observables. Yes? This is slogan. Here we measure something, here we measure something, we will experiment. Something we will experiment. Yes, and then such a matrix, yes, we compose a matrix of this number Cij. And this matrix is called correlation tensor. Matrix tensor, yes, of course. Tensor, because we can choose another basis with fixed basis in correlation matrix, let's say. No, correlation matrix means something other. Let us call it correlation tensor. Okay. Yes, and we have rely on the criterion. Yes, if rho is separable, then trace norm. Then trace norm of correction tensor is less or equal one. Okay, so with this non-linear criterion, yes, we take a density matrix, yes, we take density matrix, and we calculate this is yes, linear transformation here, because of the composition of a basis, in a basis, but then this is just, but then we calculate a matrix norm, yes, so this is non-linear, but yes, let us proceed. Let us proceed. This is a trace norm, yes, we can express, yes, that is its minimum over all isometries, yes, and Hilbert-Schmidt inner product with all possible isometries, we minimize it, yes, and this is exactly the exactly the criterion. Can I ask you the question? No, maximization. Maximize H flow. Okay. Yes? I'll ask you a question. Does this have anything to do with the PPT criterion or something? No, PPT criterion is another criterion and finding relation between them is hard. So even there is a hypothesis that if C two cubic times something, yes, that Reiman criterion cannot detect uh uh T P T states. TPT states, yes. But it's hard to prove it, yes, because they are of completely different origins, yes. But okay, TPT criterion is another very important criterion. But for PPT we have we know to what diet weaknesses is related. Yes, so this is so-called decomposable weaknesses. But here, let me proceed. Yes, so this is no minimum but maximum here, so sorry about this. Here, so sorry about this. Yes, Hibeschmit inner product, so this is this. And okay, so let us use definition of 0, yes. So this is this, and this is less than 1, but 1, this is trace of rho, and we can put everything to one trace, yes? And this is like this, yes, so it should be, and here I have minimum. Be and here I have minimum, so sorry about this. Yes, it is greater equal than one. Greater than equal than zero, yes, because I had one. This one I put to this side. Yes? So you see, it means that this criterion is equivalent to family of witnesses. Yes, what is here in this parenthesis? It is exactly an antagonist witness. Antagonist witnesses constructed from bases of operators. Basis of operators, permission operators, and elements of isometry matrix. Okay. So, entanglement criterion is equivalent to family of weaknesses parametrized by isometries. They are another criterion based on correlation tensor, but let us focus focus on this. So we know this characterization. Yes, we have uh like a non generic criterion. Non-dynamic criterion, a shape, but the shape can be characterized by tangent hyperplase. So, yes, so this is yes, for any you know shape, no cutting, maybe not exactly, but cutting the set of separable states, yes, we can characterize by tangent hyperplace. So, for any such criterion, there exists a family of family of weaknesses realizing, of course, yes, but uh to sh show them To sh show them so it's not so trivial. Yes, but let us say these witnesses, yes, we know that they are that generically they are non-optimal. Now they see if we will have any general method for optimizing these weaknesses. Maybe subtracting only something, not optimizing to obtain optimal weaknesses, but even subtract something positive from all of them, yes, but Them, yes, but not from unique ones, yes, but have a general construction, yes. And then we can go back, yes, doing this minimization. Yes, we obtain a stronger criterion than a Lehman criterion. Yes, so our goal is to improve existing criteria, yes, based on correlation tensor, yes, by improving optimal improvement. Optimal, improving antagonist weaknesses which are related to a given criterion. So that's all. Thank you for your attention. Thank you. Use this kind of approach to to try to define because you have a family of capital sort of define a measure yes so this is let's say that this expected value yes of witness which is negative yes we can take let's say this with plus and okay, but first we have to have a proper uh proper normalization of witness, yes, because Normalization of witness, yes, because witness is just a zero or non-zero. If you multiply by a scalar, there's still a witness, or by positive scalar. Yes, so we have to fix that. But it seems that such a naive measures, yes, using just like a Hilbert-Schmidt distance, a young distance, yes, they do not behave well under LOCC, yes? Yes, so we have counterexamples. Have counterexamples so that it is not a good measure, yes? You know, for some reason that you have a witness which is optimal. So it's given that it's optimal. Is it easy to reconstruct the face on which it lies? Okay, if I know that this is optimal, yes, because then I have this. Then I have this alphas, yes, when there are zeros, yes, and they span this phase. Yes, I have this pure pure states, yes, and they should span this phase. Are there any remote questions? Very interesting. I've learned a lot. Very interesting. I've learned a lot about entanglement witnesses. Is there a connection to non-Markovianity and open systems I'm missing? I think I can sort of see probably some connections, but I'm wondering whether there's. Better connection, not, but I think about, you know, we have better inequalities and then we have Ledger GAT, yes, inequalities, yes. So I think from LedgerGAT, we can construct. From Legendcat, we can uh construct, yes, somehow, witness, but with for different yeah well actually when we have uh a completely positive well it's not exactly uh that thing, but when we have completely positive maps of CPA visible maps, you can also consider an entangled state between two parties and then monitor the tangle tanglement entanglement measures between the two parties. And then, if the dynamics is immediately visible, the tangle will decrease monocronically. I don't know if perhaps I don't know if perhaps something similar can be implemented via witnesses, I don't know, but that could be a connection here. I don't have connectivity, but another connection. You could also implement temporal and tangible methodicism that is a signature of genuinely quality memory. And then to proceed with it could be a idea. Okay, is there a final question? Or do we finish on the bell? No questions? Let's take a nervy again. 