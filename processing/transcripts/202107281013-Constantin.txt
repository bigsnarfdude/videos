So, let me introduce our next speaker. Peter Constantine is a John von Neumann professor at Princeton University. And Peter is an eminent expert in fluid mechanics and more generally in applied mathematics. So, thank you for accepting our invitation. For accepting our invitation to speak here. And welcome. All right. Thank you so much for the invitation to speak here. It looks like a great meeting, and I'm very happy to be able to talk here. I am also very happy to be a speaker in the Two Constantine morning. So I think that's great fun. So I will talk about the Nord Planck. I will talk about the Norst Planck and Avi-Stokes system, some results. So, let me start with a preamble. And so, the Nerst-Planck equations, uncoupled with fluids or coupled with fluids with Navier-Stoked type or variants, have a long history. Nerst was a student of Planck and these things originally had to do with the behavior near flat boundaries. Near flat boundaries has truly wide applications from electrochemistry to dialysis, to desalinization of water, to computing the charge across cell boundaries in blood flow, and to batteries, and also without fluids in the case. Without fluids in the case of semiconductors. So it's a huge area, and now nano devices as well. So the steady states without fluid motion are governed. So there is no velocity zero. They are governed by a semi-linear elliptic equation called the Poisson-Boltzmann equation. And that also has a long history. And there are specific studies going back to Joe Keller. Specific studies going back to Joe Keller in the 50s and Abner Friedman and Tintarev and others, who were specifically talking about the Poisson-Boltzmann. And then the semi-linear elliptic equations, you don't need me to tell you the list of eminent experts that worked on them and the Gelfand blow problem. So there are lots of interesting things that are related. There will be exponential nonlinearities in this one, but there will be benign. There is no blow. So for So, for the time evolution of fluids, I'm not going to mention really exhaustive history, but there are important results by Biller and Dolbo. These equations also have a different name, Debye-Huckel model, and without fluids. And also the results by Choi, who also introduced good new ideas there. I'll mention more without fluids in a second. Without fruits in a second. In bounded domains, the boundary conditions matter. So the two Navier-Stokes Nerse Plancks equations, with something, you'll see the boundary conditions a lot. Blocking for ions, meaning the ions cannot cross the boundaries. And a robin boundary condition for potential, for the electrical potential. There results in 2D by a group from Darmstadt, both Fischer and Sahl. And in 3D, there are weak solutions. And in 3D, there are weak solutions, earlier results by Jerome in the whole domain and with boundaries, Jerome Sacco, and Fisher and Sahl, also weak solutions. Many more studies, and including many numerical studies. As you know, it's electrochemistry, this engineering stuff. So there are lots of them. Some of them motivated our work. So the salient points are this is a semi-linear parabolic system. So even without fluids and without boundary, including the Boundary, including the results by Biller and Dolbo. In 3D, the general global smooth solution problem is open. And the reason is, of course, there's no fluid. There is no, not because of the 3D Navi-Stokes problem, but rather because of the nonlinearity in the equations and what you get for free. So as you know, in semi-linear parabolic problems can blow up, like the semilinar heat equation blows up. Semilinear heat equation blows up, or even with fluids, you can have the Keller-Siegel problem blow up. And you can have situations like the Navier-Stokes equations in which you do have some form of dissipation, but on the face of it, or maybe not only on the face of it, it is not enough to arrest a blow-up. So here there will be also a weak dissipation, and then you'll see what are the kind of And then you'll see what are the kind of results we can do. But I'm repeating, even without fluids in 3D, the thing is still open if you are looking at a general problem, even if there are no boundaries, even you take it periodically. The main scientific issues, however, have to do with boundaries because this actually originally the whole D-by screening mechanism has to do with screening of charges at the boundary. So there are in the certain boundary conditions experimental. Experimental, physical, and matching asymptotics arguments of undisputed instabilities, important instabilities, lateral instabilities, motion, non-Boltzmann, Poisson-Boltzmann states. And another scientific issue of great importance: there are several small parameters, if you want. There is the viscosity small, but there is the d-by length. The d by length. And the compared to the viscosity, in some sense, this is not the smallest parameter in the problem. And the smallest parameter in the problem is the d by length. The limit of vanishing d by length leads to some contradictory models that they don't make sense. And it's a very interesting one. And in particular, what leaves beyond the boundaries The boundaries, you should be able to check that the system is in electrical neutrality. And that's an open problem, an interesting problem that we're going to discuss. So in this talk, I'm going to, we've been working on this problem for three, four years now with Mihail Ignatova and our students. And I'm going to talk about an older result from 2018 because of the structure of the equation. Because of the structure of the equation, I want to explain and revisit it. So that's a global stability for in 2D with large initial data, arbitrary large initial data, and in quite general configurations, but with boundary conditions, which are the ones that ensure stability, which are blocking boundary conditions, I'll explain them, or what we call uniformly selective boundary conditions. You will see them too. Then we're going to talk. Then we're going to talk about a recent result on nonlinear stability in 3D. So, nonlinear stability in 3D is not, there were some results by Ryham and others. So, it shouldn't be surprising that if you are near some steady states in a parabolic problem, you should be able, in particular, if there are no issues with boundary conditions, you should be able to go to equilibrium. So, nevertheless, this is a new result in the stable case because. Case because we take advantage of the structure and the condition for stability is, let's say, satisfactory with very little requirements. It's only an energy. So, and then for large data, we can prove global irregularity in some cases. So, unconditionally, if we couple with Stokes equations and if we couple with Navier-Stokes equations, conditional on Conditional on the usual situation, Navier Stocks. This coupling doesn't help Navier stocks, so the Navier stocks by itself shouldn't blow up. So we can do this in two cases or two types of cases, two species, so let's say Anions and Catians, Cations, two species with arbitrary diffusivities, or many species, but then they have to have the same diffusivities. But then they have to have the same diffusivity. So we also can prove recently, and I'll talk about it in the cases where you might not be stable, the existence of non-Boltzmann steady states. So steady states in which there is non-zero velocity and there is no Boltzmann state. And then finally, I'll discuss recent. Finally, I'll discuss recent work on interior electron neutrality, which is the subject that I mentioned before: the fact that in the bulk you should see neutrality. This is in the cases both 2D and 3D where you have stability. So in 2D, we know globally the stability, by which I mean no matter from what initial data you will end up in a Boltzmann state. And in 3D, we know from small perturbations in some. From small perturbations in some sense of Boltzmann states that you end up in Boltzmann states. In these cases, now you take the limit of zero d by length and you get interior vanishing of the electrical charge. So we'll discuss all these results. Now, next slide is busy and want to explain it. Slow down, you'll see it repeated. Repeated, so bear with me. No, so the Nerse Planck equations are equations for concentrations Ci. These are a priori the average number of certain ions per unit volume, and they obey conservation laws. So the fluxes are called Gi, small Ji, sorry, small Ji, and they are formed with the various With the various mechanisms. So there is a component that has to do with transport by the fluid. So U is fluid velocity. We'll talk about that later. There is heat diffusion, molecular diffusion with a constant diffusivity capital DI. And then there is transport by a potential, electrical potential psi. So these are all So these are all constants here. E is electrical charge. EI are valences. I'll come back to those. The valances are numbers. They don't need to be integers in our calculations, but normally they're integers. But they are not necessarily positive. And we have to have both positive and negative valances in order to have neutrality. So essentially here, there are n of these, and important that n is larger than 2 in general, but think of it as being 2. Think of it as being two. Then, if you have salt, you have ions positive and negative. The two Zi's are equal in that case in absolute value. One is plus one, one is minus one. So we'll come back to that. Easel elementary charge, Boltzmann constant, absolute temperature. And you have now the potential. This is a mean field equation in which the electrical potential responds to the charge density. Response to the charge density, rho, and the charge density is contained obtained as a sum of the concentrations at the point multiplied by their valences and elementary charge. So this system by itself, if you give yourself a velocity or you can turn it off, modular boundary conditions that we are going to discuss next, is the Nerse Planck system. So if you couple this system with a velocity equation, couple the system with a velocity equation, in our case, we couple with the Nabier-Stokes equation, then the coupling is done through electrical forces. So electrical forces are the product between the electrical field and the charge density. And the electrical field, there is no, in this talk and in this arena, magnetic forces are the, so this is the Lorentz force in the absence of a magnetic field. So there is no time. So there is no time-dependent magnetic potential here. So throughout the talk and throughout actually original Nerse Planck, but you can restore it and it's an interesting problem by itself. So this force, we'll talk more about it. So divergence zero for the velocity. We're going to keep on repeating this equation, simplify a little bit. So the boundary conditions are for the potential are Dirty Lebanon. Are Dirty boundary conditions are given voltages at the boundary. So the boundaries typically you can think the simplest one, you can think in 2D an annulus. You have more than one boundary. It's not simply connected. And you need to have that in order to have interesting effects. And the boundary conditions for the velocity are no slip at the boundaries. And the boundary conditions, important And the boundary conditions, the important boundary conditions are not for the ionic concentrations. So the blocking boundary conditions are no flux boundary conditions. So if you go back, the flux is all this thing. So suppose for a second that U is zero on the boundary, as we have with Navier-Stokes, then the no flux is essentially a Neumann boundary conditions, homogeneous Neumann boundary condition for a combined quantity called the electrochemical. Electrochemical potential, you'll see that again. But it's the Neumann, the normal component of this guy, which is a gradient of C and the gradient of psi, together. So that's the blocking boundary condition. And its meaning is that the total concentration of the i species is constant in time. The integral of Ci, if you look at the equation, the integral of Ci will be constant in time because n dot gi is zero. n dot g i is zero. The boundary conditions, the boundary has many components maybe and many pieces. Think of in particular for semiconductors, this is really the most important part is that the boundary is extremely complicated. But in general, nano devices as well, the boundary, the engineering of the boundary is very important. So there are several components of the boundary and several species. And several species. The boundary conditions are not by geometry, they are by species. So, different parts of the boundary play different roles for different species. So, you always think species by species, you see what does the boundary do for me? In this particular case, for all the species, a blocking one says all the boundaries, there is no flux through the boundary. Selective boundary conditions. Selective boundary conditions, which are the conditions under which you can have instability, are essentially like Dirichlet boundary conditions for the electric chemical potential. So they are more complicated, so bear with me. Some concentrations are given on some parts of the boundary. So this is now I by I. So there is a piece of, for let's say that I'm talking about potassium. There is a piece of the boundary in which the concentration of potassium is given. Which the concentration of potassium is given is given by gamma i, and the rest is blocking for potassium. The flux of potassium doesn't go through the rest. And so I have m of these guys, and then the rest are blocked. Okay, so selective boundary conditions are extremely important, and these are the ones that can produce effects, desired effects or undesired effects. And you can design the pieces so you can. Can design the pieces so you can have a L-shaped device in which SI is one of the legs, and you can having this Dirichlet boundary condition itself, it's a modeling issue. It's really not that you can place ions there. It's you connect it to other reservoirs so the ions are essentially kept steady on that piece of the boundary. So it's a really complicated system. As you saw, it is also in kind of like a In kind of like a bulk system by introducing the interactions only to a potential. So these are the boundary conditions. We're going to simplify a little bit, but not much, the constants. So we're going to normalize the potential by the electric charge and Boltzmann constant and absolute temperature and call that phi. And the resulting At phi. And resulting to this, we also will have the charge density to be some Zi Ci. However, we keep the Zi's. And the reason for that, it's just graphical because then all the equations for the concentrations look the same, except that sometimes these are pluses and sometimes there are minuses because of the ZI's. Okay? So there is some consistency in writing. So the bad news is for people. So, the bad news is for people who like maximum principles and things of that sort, this is a true system which can pattern and the Turing patterns different because the DIs cannot be equal. So, for instance, this most common electrolytes, you have two guys with equal post-valences, sodium chloride, but their diffusivity is. But their diffusivities are different. The ratio in water at normal temperature is three to two. So you cannot really honestly take them all equal. The equation for the Poisson-Boltzmann equation becomes epsilon La plus phi is rho or minus rho, the way I wrote it. And the Navier-Stokes equations, they have a coupling that has to do with the Boltzmann constant and temperature. Constant and temperature. So epsilon is proportional to the square of the d by length. And so these are normalizing factors, typical concentration and sum of valences. And there is the d by length square that if you want, this is defining the d by length square. And the boundary conditions can be written after we divide. After we divide, we have this function w that is the potential on the boundary. It's a given function of space. Velocity is zero on the boundary or the boundaries. And the blocking boundary conditions, because the velocity is zero, they look like so. So this is really, again, the GI flux dot n is zero. So it looks here, this quantity will appear several times below. This is called the electron. times below this is called the electrochemical potential log ci plus zi phi so it's neumann typically the concentrations are non-zero on the boundary but the the normal derivative of the electrochemical potential can be zero and that's the blocking boundary condition so no flux boundary condition notice that that mixes boundary conditions for the concentrations and the potential so requiring a combination to be zero that means Requiring a combination to be zero, that means they are related. Okay? The selective boundary conditions, like before, they are kind of Neumann boundary conditions for part of the boundary for the flux and Dirichlet boundary conditions on the other parts and the rest block. So we have another type of regular boundary conditions which we call uniformly selective and those require the Require the chemical potential on the boundary, so log gamma i plus zi w to be a constant in space for all the boundary. And these are going to confir stability. And the general selective, as I said, can be arbitrary functions gamma i and w on the boundary. So let me stop here and explain. By the way, you can ask me questions. I am really. I am really happy to hear interruptions and all that. So let's for a second simplify a little bit the picture so that you understand when I say general selective or when I say uniform selective, what do I mean? So let's imagine now that I have only two species and I have only two boundaries, let's say an annulus in the plane. And let's say one of the species is blocking. So the normal flux rate is zero. Flux rate, it's zero, so I don't have any problems. And let's imagine that on the other, I have two boundaries. The other species has constant gamma and the potential is constant. So let's say one of the boundaries, the cation has concentration one and the potential is two. And on the other boundary, the concentration is, let's say, three and the potential is zero. And the potential is zero. And this is not a uniform selective boundary because situation, because S corresponding, let's call this quantity S1 corresponds to the first C1 is the entire boundary. And the function is two constants on the boundary. It's one constant on, let's say, the inner annulus and the outer. And the outer circle is a different constant, e to the zero times one, the other one is e to the two times three or something. They are not a constant on the boundary. And because of that, this is a selective situation, but it's not a uniform selective situation. So requiring this chemical potential to be constant on the boundary, which is a Dirichlet boundary condition for the chemical potential that is constant on the boundary, is very special. Okay? But of course, Okay, but of course, if you have everybody be, let's say, zero and gamma is a constant, or if w is zero and gamma is a constant, then it's satisfied. Boltzmann states. The Boltzmann states are related to the Poisson-Boltzmann equation. So you have a non-linear equation in which you take exponentials with the valances here and with constants zi. So see the concentration in steady state looks. concentration in steady state looks like the exponential e to the minus zi phi star same phi star divided by constant zi capital zi and the constants are constant but they they do may depend and i'll give you examples they may depend on the potential uh through some integral so they are may depend non-locally on phi star but they are constant in space and time and uh then you And then you solve this semi-linear elliptic equation with boundary conditions W. And in all the situations that we are discussing, this will have smooth and unique solutions. So the simplest case when these guys are constant, constant, and then you have a convex problem. So it's going to be very nice with a nice energy and all that. That's not really the difficulty to solve this one unless you want explicit answers. Unless you want explicit answers. So the ZIs for they're more complicated for blocking because, as you know, for blocking, the total concentrations need to be constant in time. So the integral of Ci is a constant in time. So if I take some initial data and I can compute the integral, I get some numbers. And the elliptic equation that I need to solve has those numbers entering the definition. Entering the definition of the Zi's. So the Zi's are some constants times the integral of e to the minus Zi. This is the valence. So capital Z little Z, okay? So for, for instance, valence one, this is e to the minus five star divided by some number. And you can think of it as being some, you can normalize this if you prefer, and then multiply by another number. But essentially, Multiply by another number, but essentially, the equation therefore is really non-local. Because if you remember, the equation had this form with the sum. These are little ZI's, they're just constants, plus minus one, let's say. And here you have a normalization that is non-local. In the case of selective, uniform selective, this will require this product to be constant or the log of it to be constant, and therefore you have actually. And therefore, you have actually a very simplest Poisson Euler Poisson-Boltzmann equation in which these are really constant. Don't depend on the solution. And then if you have mixed system, then part of them are depending on the solution and part of them are given. We'll return towards the end of the talk. If I have time, I'll return to these equations and discuss them a little bit. And discuss them a little bit. All right. So the result that I mentioned in 2D, the result with Mihaela from 2018, is the following. You can have arbitrary balances, arbitrary number of species, any positive but non-zero d by length, arbitrary diffusivities. And then with arbitrary initial data that are nice and smooth. Data that are nice and smooth, positive, of course, because you are doing concentrations, some regularity that you don't need to worry about. Then you have global existence from arbitrary large initial data and convergence to steady states, which are Boltzmann states. So the velocity will go to zero and the Boltzmann states. So there, the proof is a little complicated because the convergence. A little complicated because the convergence to Boltzmann states is done at the end with decay and identification of the limit. So, there are, I'm not going to describe the proof, I'm going to talk only about the relative energy decay, because that is a structural element of the equations that's really both cool and important. So, the proof goes through first that relative energy we call now Now, and then local existence and a priori bounds, and then identification of the limit. We're not going to go through those steps at all, but I'm going to discuss the local energy. So, the relative energy is a sum of what in mathematicians call relative entropies and a H minus. So, this is the Kullback-Leibler divergence in statistics. And the relative H minus. And the relative H minus one charge density. So they look like this. This is the Ci star and phi star are elements in a Boltzmann, Poisson-Boltzmann solution. So you have a solution of the Poisson-Boltzmann equation. You take one with the corresponding boundary conditions to the equation. And the rho star is the corresponding charge density. And then you form. You form the relative entropy relative to the Ci star and the H minus one. You see that because Laplace of the difference is the difference of the rows, you have the difference of the charge densities here and the epsilon is there, the same epsilon. So it's H minus one of the charge density. So the main thing that I want to discuss a little bit is the decay of this relative. The decay of this relative energy coupled with an obvious Stokes decay. So, if you add the kinetic and properly normalized kinetic energy of the fluid and this relative energy, then it will decay in time and the decay is formed with some positive things that I'm going to describe. So, the way we row the energy is non-negative, it vanishes only at the Boltzmann state, relative to that Boltzmann state. Relative to that Boltzmann state and zero velocity. The dissipation, of course, also vanishes only at the Boltzmann state. And the decay of energy implies that any time the independent solution of the system has to be a Boltzmann state, this is a consequence of the boundary conditions. And the result is true in 3D as well, in 2D and 3D. So let's explain a little bit. So the ZIs are, as I said, they were fixed by the boundary conditions. If you have units Boundary conditions, if you have uniform blocking, if you have uniform selective, then they are given by the uniform selective requirement that this is a constant. So now I'm going to slow down a little bit to explain this because it's a very important object. So we have the electrochemical potential, which as I said is the log of the concentration and valence times the potential. It's a combined quantity. And then the Nernst Planck equation. And then the Nerse Planck equation reads like diffusivity times the divergence of the product between the resident Ci and the gradient of electrochemical potential. And if you take the variational derivative of the relative energy, you get the log of the ratio and the difference of potentials. If you look what that means, it is really because the Really, because the electrochemical potential of the Boltzmann state is a constant. That's by definition what if you take the log of this. So the sum between log Ci star and Zi times phi star is by definition the log of it's a constant because it's the normalizing constant, constant in space. Therefore, its gradient is zero. So because its gradient is zero, here you see CI. Gradient is zero here, you see Ci gradient mu i is the same as Ci gradient of mu i minus mu i star. And this is the variational. So you have this structure that the time the transport of the C i concentration is proportional to divergence of the gradient in the C i variable of this energy. Now, this is a very familiar structure to those who it is familiar to in the case of one eye. In the case of one eye. And that is the same structure that does the famous results by Felix Otto and Kinderler and I'm blocking the names, of showing that Fokker-Planck is a gradient system for the Wasser sign. For the Wasserstein. So it's a structure, a very natural structure, a dissipative also in Poros medium equation if you have one probability distribution. And this then is essentially the relative entropy. But we have a system. And this nevertheless holds like this. It's very nice. And then if you want to look at its time evolution, you have to take a material derivative this time. So if I have. This time. So, if I have a material derivative of the energy density, relative energy density, which is this object, you compute it by chain rule. So you differentiate with respect to the entries here. So the variational derivative with respect to concentrations times the material derivative of the concentrations, which gives you a very nice structure that we discussed before. And then there is variational derivative with respect to the With respect to the steady concentrations times the material derivative of the steady concentrations. And here comes the difference between having a fluid and not having a fluid. If you have time-independent objects here, the time derivative of these guys is zero. But if you have a fluid, the material derivative is not zero. And that means simply that you will get an error term. You will get an error term here that has to do with the fact that there is a velocity, non-zero velocity. It turns out that the other error term has a structure. So the structure is that it is the dot product of the transporting velocity with the electrical force. And that, in my mind, is a derivation of the electrical force. So there is not other thing that you put here in order to couple to fluids. I'm going to repeat that. To coupled with fluids. I'm going to repeat that in a second. And there is another term, R, and very remarkably, the other term has mean zero. And the computation that the other term has mean zero uses only time independence of the steady states and the fact that the potential in the equation and the potential of the steady state have the same Dirichlet boundary conditions. It has nothing to do with the boundary conditions for the CIs. The CI's it's only about the potential boundary conditions, and it works for any other boundary condition for CI. So, the fact that this integral goes to zero has only to do with the fact that you can integrate by parts in this equation, having the, you see here, products. So this means the following thing: if you take Nerse Planck equations with this correct boundary conditions and put them in a passive flow that you design. Massive flow that you design, they'll be unstable. Stability will come only if you couple it and force the flow with the force F. Okay, so this is why I'm saying it's the derivation of the force back on the flow. If you want stability, you deduce that the flow has to be forced by F. So let's see that. So if you take the equations and now you integrate, so you take, now we compute. integrate, so you take, now we computed just the material derivative. Now you integrate in space, you get, because of the calculation before, the integral of r is zero. So you end up with this guy integrated and this guy integrated. So f dot u with minus, where f is the forcing that will be suffered by the fluid. And because the structure of the equation, The structure of the equation. The structure allows you to integrate by parts in this term. So now the boundary conditions for C appear. So first of all, in order to get rid of this guy, I need to couple with a forced fluid in which the forces, work of the forces, cancels the work of the forces here. So I'm coupling with Navier-Stokes. I could couple with anything that obeys this force. That obeys this force. Doesn't have to have dissipation. I don't really use that dissipation at this point, but it has to have this force. So you can force Euler if you want, as long as the velocity is forced by F. You can ballistically force, but you have to force this. Well, because of this, you need to have a nice positive energy that is forced by this guy. You'll see actually later that I do that. So they cancel, and then this integral. And then this integral becomes the integral of a divergence times the same object. So here is the equation, and then I have boundary terms. And guess what? The boundary terms are exactly those boundary terms for boundary conditions that are stable are the ones in which this is zero. And if you have other boundary conditions, this whole thing holds and you're going to have driving by the boundary. So remember that variational derivative of the Derivative of the relative energy is the difference in electrochemical potentials. So either their normal derivative is zero or they themselves can be adjusted to be zero on the boundary, then you're okay. So normal derivative being zero means blocking boundary conditions. Them themselves being zero are what we call uniform selective boundary conditions. So in either case, this red term disappears and you have stability. So I'm going to go. So, I'm going to go now away from this area, but I think that this is a very, very important structure. And it is, in some sense, this structure that dominates the whole nonlinear system. All right, I'm going to go now for the 3D. So the stability for small data in 3D is done assuming only relative energy is small and the relative L2 small. Relative L2 small, the boundary conditions should be the good boundary conditions. So this is blocking or uniformly selective. Okay, so then it's 3D and globally stable, meaning that you are going to zero. So here is an idea of the proof very quickly. If you take the evolution, this is an L2 kind of thing. So you take the evolution of the sum of L2s, you get a nonlinear term and a forcing quote. And a forcing point, quote unquote, is not also non-linear. And damping, damping coming from the various dissipations. So the main point is that for small data, these guys are benign because this is dominating them. So the question is, what's the so-called forcing? So forcing has two pieces. It's an energy velocity piece and the concentration piece. The velocity, let's talk about it later. The concentration piece is, again, the relative. Piece is again the relative energy, which we know is decaying, so it will be controlled by initial data because we are in blocking or uniform selective conditions. And then there is a relative L1 squared. And then we are lucky. Okay, L1 squared is controlled by the so-called generalized Chisar Kullback inequality. She's our good Hungarian guy, so all these things are simple to pronounce. And so this. And so this object here is essentially L1 squared for small. And this one is the relative entropy. So that means that this term here, the quadratic L1, is controlled also by the initial energy by constant. So at the end of the day, you have the contribution of the concentrations is controlled. Now the velocity, you are having an obvious Stokes driven. So why do I have the velocity small? Well, in steady states, the velocity is. In steady states, the velocity is driven by the difference of the electrical forces, and the electric force in steady state is a gradient because this is a function of phi, phi star. So this is the gradient of some complicated function of phi star is a gradient. Therefore, the projection of gradients of that thing is small dynamic. Starts out small and you control it small dynamically. And that's the proof. And that's the proof. So, in the end, you need only energy and L2. And of course, for Navier-Stokes, the initial answer is small. For large data, we were considering, let's say, Dirichlet boundary conditions, which are selective, arbitrary. And then in general, you don't have dynamically, you don't go to Boltzmann states. And actually, we're going to show that steady states are not Boltzmann. Are not Boltzmann and instabilities are observed numerically. So let's consider this where you put boundary conditions arbitrary and ask yourself whether or not you have solutions for all time. So this is the same system, but we're doing 3D large data. So here is a theorem that says that if you have two species, it's a not harder result, and you do all the data in both two and three. Data in both 2 and 3D. Now, you know, in even 3D and Abby Solx, you have steady solutions and arbitrary forcing. So if a certain integral condition is satisfied that we can verify, then the steady state cannot be Boltzmann. So it's a very simple argument. The proof of existence is done via degree theory, and it uses some ideas that we're going to do for dynamics as well. The vector field here is tangent to the boundary, it's normal. To the boundary is normal cross gradient. So it's tangent to the boundary. So if you give yourself, and this term here is actually the concentration, charge density concentration on the boundary. So the charge density concentration on the boundary should not be zero. Otherwise, you don't know, but you don't have this condition. And you need some variation in space of the potential on the boundary. So this condition can be satisfied if the charge density is not. If the charge density is not zero and the potential varies on the boundary. And in that case, you are guaranteed that the steady state is not Boltzmann. However, it could be that there are no Boltzmann states even if these conditions are not satisfied. But we guarantee in this case that there is non-Boltzmann steady state. And the dynamic consequences of this in the perturbation field. Consequences of this in the perturbation theory around this are open. So there could be that the steady states are, I mean, the dynamics are not steady, but the Boltzmann state lose stability and there are some cycles that numerically people observe vortices near the boundary. So we haven't done anything with that. So now for 3D global existence, let's see how I might for time. For 3D global existence, we have We have global exists unconditional in two situations. And first, we do a result that allows you to extend the solution and then prove that you have that condition. So for nurse plant composed with stokes, so there is no problem with a fluid part or with anything that doesn't blow up. That doesn't blow up. All you need is the relative, no, the charge density in L2 in space to the power 4 in time to be integrable. And then you can extend the solution. And for Navier-Stokes, you add, I added here one of my favorite conditions, which is fourth power of the L2 norm of the gradient of velocity. The gradient of velocity. So, if you assume those, this is a sufficient condition for regularity for an abiestode by itself, and this previous one together, finite, imply that you can extend local solutions beyond that. So, and moreover, you have quantitative bounds. I don't want to, but they are double exponential. So, you have quantitative bounds even in the case of the coupling. Coupling with Stokes is double exponential in this quantity B. So the theorems are that in two species, not two, but two species, then you can prove global existence unconditionally with arbitrary data, Dirichlet data. And in particular, with different diffusivities. If you want n species, unfortunately, the way we know right now how to prove, you need the diffusivities to be equal. And then you can have arbitrary main species and again, arbitrary data, you get global existence. And if it's Navier Stokes, you need Navier-Stokes not to blow up. You assume that. But if you are coupling with Stokes, which is actually very physical, this is most of the Physical, this is most of the applications have lower Reynolds numbers, then you don't need any assumption. So I will present a little bit the ideas of the proof. May I ask when do I have to stop? We started a little bit later, so five minutes would be. Okay, I can squeeze in five minutes, maybe some ideas. Minutes, maybe some ideas. So, um, the main point here, uh, thank you. The main point here is that we're gonna use another energy to cancel the Navier-Stokes force. So, we're gonna consider a simpler energy, which is just the potential part in the previous case. So, it's a rho times Laplace inverse of rho. And the reason for that. And the reason for that is that this other energy produces growth, but you see the producing growth, there is the required force that this is what I need. I need to cancel this guy with minus in Abiya Stokes. So I'm producing this growth and I have errors. And the main thing here is that the non-linear pieces of the errors are of the type U times rho or C. Type U times rho or C times rho and no other terms. And you will see that we can deal with this, but not with the others. So, in that case, and the other piece we're going to deal with will be you take an extension of the boundary conditions, and then you look at the equation for the difference between Ci and some extension of the boundary conditions. And that looks like the Nairs-Planck equation. The Nairs-Planck equation: this is not like a force, but it's not really a force, it's an affine quantity that depends on u and on phi, but linearly, as you see, only u. These are extensions, these are known functions. And then you look at the usual L2 evolution of these guys, and the main point is that in the case of two species, the cubic term that comes out has a sign, and if you compute. And if you compute what's the cubic term, you have only two species, the difference and sum. And then, if you refer, these are not quite the C's, but you refer to the C's, and you get that use the fact that the C's are positive, and their sum is larger than the modulus of the difference. And therefore, you get a cubic term here, rho, rho, rho, modulus. So, rho squared times modulus rho. And this cubic term is saving life. Is saving life. So then you have a dissipation here of this L2 kind of energy plus a cubic term. So I'm not going to belabor that. And 3D, you do something similar. I want to quickly say something about the electroneutrality and stop. So for any number of species, you get this cubic term, and then you can deal with what it does. So let me show you just the electroneutrality result. You have You have essentially showing that in the four situations with all blocking conditions, so this is the blocking case, this is the selective case. In all these situations, the limit as epsilon goes to zero of the supremum of the charge density in any compact is zero. So these are all four of them. Here is a mixed case in which you Here is a mixed case in which you have one blocking and one selective, and this is the other blocking and selective. Their all conclusions are that inside the domain, fix where you are in the domain, let epsilon go to zero, the charge density is zero. And as a consequence of that, oh, here is the idea of the proof, but it's so complicated I don't have time to explain it. Essentially, it is several steps. One of them is to identify the limit of in the Of in the Boltzmann state, and then be a little lucky that that determines that the Boltzmann state the charge density goes to zero in L1, then upgrade to L2 and then use the remarkable fact that it's always subharmonic, so to get L infinity inside. So, and the result is that in time, because of the stability, you are going to go in this order. You take time first to infinity and then epsilon to zero, and you are going to. And then epsilon to zero, and you're going to go to inside to equilibrium. So you get the same result in this ordered limit, first time to infinity, then epsilon go to zero, the charge density goes to zero. So lots of open questions. Let me just finish. So this, I'm done, and you can read the conclusions. I'm happy to answer questions. All right. Thank you. Thank you.