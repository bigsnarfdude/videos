And now, for the real thing that you're here to hear, we're very happy to welcome Akshay Bhakwani, who will be giving our last lecture of the day. Thanks, everyone. It's great to be back in Canada after five years, and I'm glad to see some familiar faces. So, what we'll be talking about today is somewhat new territory for me also. So, I must thank Haviba for guiding me. Must thank Haviba for guiding me and Tim for making some useful suggestions. Okay, so let's just dive right in. So we'll be, everyone knows the prime number theorem. What we want to do is we want to look for primes in short intervals. So I'm trying to look for primes in the interval of the form x to x plus x raised to theta, okay, for some theta less than one. theta less than one. And so if you want to do this, you will be taking this pi x plus x to the theta minus pi x. And what you're expecting is that all the editor terms somehow cancel out and become small. And what you want is that you should just get the difference of the two main terms here. If you look at this difference, you can see that this is actually asymptotic to x raised to theta by log x. So our expectation is something like this. So, our expectation is something like this. Okay, and we want to find theta so that this happens. This is an asymptotic for primes in the short interval x to x plus theta. Yeah, x plus x raised to theta. Okay, so question is how small can we make theta so that this happens? Theta between 0 and 1. Theta equal to 1 is, of course, there. So, what will happen if we do this? What will happen if we do this? One consequence is that you can look at gaps between the primes. So, Pn plus 1 minus Pn, you can show that this will be bounded of the order of Pn raised to theta. Here Pn denotes the nth prime. Okay, so the first person to give, as far as I know, the first person to prove the existence of such a theta less than one was Hoch Heisel. So he gave this value of theta, which is just short of one. Which is just short of one. And then there were further improvements. Heelbron gave 249 by 250, and Chudakov gave 3/4 around 3-4th. This is all before Ingham. And today we are going to talk about Ingham's result. Of course, since then, there have been improvements on this theta. I think the best is due to Heath Brown right now, 7 by 12, if I'm not wrong. Okay, so today we want to prove Ingham's result and we'll try to. Want to prove Ingham's result and we'll try to go through the steps of this proof. And it ties in some of the stuff that we have already seen in Olivier's lecture. So, what is the result? The result that he showed is that if you have this estimate for zeta, that is zeta of half plus it is bounded below t raised to c for some c positive, if you can do this, then you can get, he explicitly tells us what is the range of. He explicitly tells us what is the range of theta in terms of this C. So he gives us theta between 4C plus 1 by 4C plus 2 and 1. Okay. All right. Now, what C's do we know? Just putting stuff, the numbers that we have. C equal to 1 fourth is the classical one. So this for him improved the previous results. He already got a two-third with just this. The Hardy Littlewood so-called The Huddy-Littlewood so-called that he calls it the Huddy-Littlewood value C equal to one-sixth will give you theta to be five around five-eighth. And I believe that we have an explicit, you know, the zeta half plus it result is explicit with this value of C. So one can use that and get more explicit results here also. So theta equal to 5 eighth around 5 eighth is what you will get. If you had the best thing possible, that is the Lindelof hypothesis. possible that is the Lindelof hypot the Lindelof hypothesis. You could put any value of C equal to epsilon epsilon positive. This would give you the dream that is theta to be half plus some epsilon. Okay. And this is comparable to Kramer's result on Riemann hypothesis that your gaps between your primes will become less than square root. Okay, so what does theta, what does this theta have to do with stuff about This theta have to do with stuff about the Riemann theta that we have learned so far? So we can connect it to zeros of this theta. And our two most familiar hypotheses right now, based on everything that we have been studying, are regarding the zero-free region for Riemann zeta and the zero density result. So let's consider these two hypotheses. The zero-free region hypothesis is telling us that zeta has no zeros in a That zeta has no zeros in a region slightly to the right of left, you can carve out this region for t sufficiently large. You can take out this log log t by log part. Okay, so here I'm keeping a as some parameter. Then we also have what is called a zero density result, which we have seen now multiple times. So what we are doing, we are counting zeros of your Riemann zeta function, which have a real part to the right of your sigma, some sigma. part to the right of your sigma some sigma and imaginary part up to height t so zeros in a rectangle of height t and you want i mean we have seen this form of the zero density result you have some parameter b here times one minus sigma in the exponent and you have some power of log t. Okay, now here in Ingham's work, we are looking for such a result uniformly between half and one, sigma between half and one. Between half and one, sigma between half and one. And B and capital B, I'm taking as some parameters here. So what he showed is that if you have such a hypothesis, zero free, I'm calling as ZF, zero density, I'm calling as Zd. Then if you have these two, in terms of these parameters, you can build this range of theta. And he tells you that you will get an asymptotic for short intervals of this x to x plus. Of this x to x plus x raised to theta form for theta, any theta in this range. Okay, so you can see this B is coming up here, this A is coming from the zero free region, and this capital B coming from the log here. In practice, I mean, for his purpose, in the zero-free region hypothesis, one can, we know results where you, I mean, you can take A to be arbitrarily. I mean, you can take A to be arbitrarily large. So, this part will actually become go to zero if you take A going to infinity. And what will really matter is this B, this exponent B. So, if you want to improve this kind of, if you want to improve this range of theta, you need to also reduce your exponent B in this zero density result. So, first, let's try to see how we can prove this lemma. Okay, so we'll try to do that. Okay, so we'll try to do that. So the proof starts with an explicit, the explicit one-mongol formula connecting this psi, the summary function of one-mongol to zeros of Riemann zeta. It's a truncated form. We are taking zeros. These are non-trivial zeros of Riemann zeta going up to height t, imaginary part up to height t. And there is this error term also having this t in it. Also, having this t in it. This is uniform for t going up to x. And we are interested in short intervals. So let's just try to just see what we get when we just take psi of x plus h minus psi of x. So I'm just writing exactly what we get here without any simplification. So this is what you'll get. Now let's just try to simplify this a little bit. So if we think of this second term, so actually what is our goal right now? Actually, what is our goal right now? Our goal is to show that we want to get that asymptotic, right? So, we want to show that this left side is asymptotic to H. I want to show this is negligible and that this error term is also negligible. If you do this, then you can prove the same kind of asymptotic with pi here instead of psi. So, let's look at the second term. We are looking at x plus h raised to rho minus x raised to rho by rho. to rho by rho let's just write this as an integral so we will get u raised to rho minus 1 du going from x to x plus h i'm interested in bounding this so let's start looking at absolute values and this is below x to x plus h when you take the absolute value inside you will get the real part of rho which is beta so i'll get u raised to beta minus one du du but beta is going the range of this real part is between 0 and 1 so this exponent is non is negative okay so we can just do a simple estimation here i'm just going to write this as um since it's negative the x term will matter rather than the x plus h so i will get x raised to beta minus 1 and the length of the integral is h okay so this is what we have Let's just put this in here into the second term. You are going to sum this, and we just divide through by h everywhere. So I'll get a one here, and then I'll just simplify. So we'll get this formula. So we have this x to the beta minus ones summed up here, and you have this error term. Now, your goal, as I said, is to show that you get asymptotic to one. Okay. And actually, you want to do this. And actually, you want to do this with h being x to the theta with theta in this range. Okay, that's what your main lemma was. I mean, that's what we want to show. T is, we can still have some freedom with the t. So, first thing is, we have not as yet used any hypothesis. So, let's try to connect this to our hypothesis. How can we connect any of these terms to what we have? So, if you see here, you are this. If you see here, you are this term is actually like this: you are summing over zeros with height up to t. So, it looks like you should be able to connect this with this quantity that was a zero density function. So, what we do is actually you can do that by writing this sum as a Stilj integral. So, let's just motivate that. How do we just do that? Um, this thing you can think of as if I just If I just take beta out, so I'm taking beta between 0 and 1, okay, and we have x raised to beta minus 1. Now, what are we doing inside? We are summing over rows with real part rho being beta and imaginary part of rho being below t in absolute value. And this is what you have. So, this part is essentially coming from this. Is essentially coming from this function, except that we are not on the right of, well, we want exactly equal to beta, the real part. So you can, well, you can write it as a Steel J integral now, or you can think about it a little more and just write this as, well, how is that coming from that function? You will think of this as n beta t minus just to the right of beta if you go. You want to take this limit. You want to take this limit kind of as epsilon goes to zero. I'm just writing, this is not rigorous. This is just to motivate what is our next step. So this will give you some, this will give you zeros in that rectangle with real part being beta. And this you can just think of as, so let me just put approximate signs. This is what we are just viewing it as. And this is the incremental difference in this function. difference in this function. So I want to say this is my d sigma n sigma t well at sigma equal to beta and with a minus sign because this function is a decreasing function. Okay. So now you can write now you get how to write this sum as a Steel J integral. If you do that we'll just move to the next slide. You will get Move to the next slide, you will get this thing. Okay, I should have, maybe I should write something. Uh, here there is an absolute value. If you remove that, I want to say between 0 and t instead of the absolute value of because of symmetry, I can put a 2 here. Okay, so because of that, there's a factor of 2. And if you write it as a Steelj integral, there's a minus sign, there's a 2, and it's an integral from instead of sum beta from 0 to 1, you are taking. Of some beta from 0 to 1, you are taking an integral, and this is what you have. Okay, we write it like this so that we can apply integration by parts and then get something. So, let's do that. So, let's do integration by parts. I'm just going to write down what we get. Yeah, so we will get minus two. So we will get minus two x raised to sigma minus one n sigma t evaluated between zero and one plus two integral zero to one n sigma t x raised to sigma minus one. I'm differentiating x raised to sigma minus one so I will get a log x yes this is correct. Yeah. This is correct, yeah. Okay, so this is what we get when we integrate by parts. And if you just look at this, this is simply if you put sigma to be one, it will give you a zero because this function, there are no zeros to the right of one. So I will just pick up two x inverse of n zero t. All right. This is what we have so far. So this is all we have obtained for the second term in that in this explicit formula, right? That in this explicit formula, right here, we plug this all in, and what we get is: yeah, for the second term, we have obtained this expression right now. Now, we want to estimate this and we want to say that this is negligible. I want it to be little of one, so that the main term is one. Okay, so for this N0T, we use. So for this N0T, we use the known so-called. Do you have a question? Do you look up at the previous slide? Yes. So the upper end of the integral, why is that not actually just the zero tree we generate instead? Why is it? Yeah, we'll do that. Which this one? Yeah. Yeah, we'll do that now. But shouldn't there be a term already after doing partial summation because n of sigma is going down to zero and then changes because there's like a different like Because there's like a different, like a derivative, like it's not differentiable there. Like the integral has to be broken up into those two pieces. Yeah, so actually, this part, you're talking about this stuff that we did here. This part is kind of heuristic. Actually, one can prove this in a rigorous way without getting into this kind of motivation. I just gave this to give an intuition into that, why it looks like that. That but um yeah, you can get the you mean to say this part, yeah, we can do it without that, yeah. Oh, so what I mean to say is I just think the upper bounds, like at least to me, it seems like it should end at the zero-free region, not at one, but maybe endures forgetting something about merging summation, but it's actually making this valid, so it's fine. Yeah, we can ignore it. I see that it's going to come up in the next one, it's going to come up, yeah, maybe one should put it now. To come up, yeah, maybe one should put it now. Then, I don't know, okay. All right, so now what we'll do is we'll use the estimate for um n0 t that will be known, the known t log t. And so we do not need to take this integral all the way up to one because we know this zero-free region hypothesis. So, you can instead go up to something lesser than one. So, we're going to go up to one minus eta t t this. t t this uh eta being log log t by log t that's up to where we have the um that's where the zero free region starts so if we do that what we get is um yeah so uniformly uh in this region we are getting um this estimate t log t by x and this integral all that we have done is just change this one to one minus eta t Minus eta t um okay and we just have an estimate for the first one now. We'll use the next hypothesis that we have which is the zero density hypothesis. So you know you know an estimate for this n sigma t, which we'll plug in there. So we'll just put that in. If you use this hypothesis and just plug that in, this is what we get. Okay. Yeah. So Yeah. So far, so good. Now, what we do is, if you actually one should work backwards and try to optimize this, like what do you need to take, choose T as, okay, in terms of X. If you do that, you will see that you end up taking T to be some power of X, where alpha is less than one. Okay, so we just plug that in and try to. That in and try to then see what is that range of alpha that we get. If we do that, let me just see what happens. Okay, first term is straightforward. You will just get x raised to alpha minus 1 log x. And for the second term, what's happening is, yeah, you're just plugging it in and kind of integrating. So this part remains as it is. It's just brought out of the whole thing. Let's let you just integrate the rest of it. If you integrate the rest of it, you will get. If you integrate the rest of it, you will get x raised to alpha times b minus 1, that is this power, and you have this 1 minus alpha, and you have a log x, which will go after integrating. Okay, so you will just get this exponent between these limits, 0 and 1 minus eta of x raised to alpha now instead of t. And you just do your subbing in. You will, this term actually will not matter because if you see here. matter because if you see here this is now negative so this is a um yeah this is a power saving you have here x raised to some negative power which will not be important i mean we can drop that and whatever you get here will curse if you put things together you'll get some power of log so log x raised to minus delta is what you'll get where delta looks like this now it involves uh these parameters that we started with there is a b here uh there is alpha There is alpha here, there is small b here, and yeah, yeah, I think the a also comes up because of this, because of this eta. Okay, so you will get this expression for delta. And if you want to get your asymptotic, you want delta to be negative. So to sorry, you want delta to be positive. So if you to do that, you take alpha between alpha less than, yeah, this. Are less than this quantity. All right. So we do this. This takes care of the second term and then we move on to the third term in the error term. So this second term is fine. It's negligible. Now you come to the third term. As discussed, you have taken t raised to t being x to the alpha. Alpha can right now it can be any number which gives you that delta to be positive. So we have this range. To be positive, so we have this range for alpha right now. And you are interested in h being x to the theta. So, all I want to do is just ensure that whatever is the power I get here, that's negative. The exponent here is negative. Then I'll be good. So, yeah, just we just put that in here. This is x raised to 1 minus theta minus alpha. And you have some power of, you have log x square. You want this to be negative, which means you want theta. Which means you want theta to be bigger than one minus alpha. If you do this, then you get this asymptotic that you were looking for. And because you are allowing alpha to go for any value in this range, that's why theta also can take any value in this range. Okay, so for any theta in this range, you are getting this asymptotic. That was what we wanted to prove. From this, you can try to. Um, from this, you can try to see that this is happening. You are getting an asymptotic for primes in this interval. Okay, this is a straightforward exercise. All right, so this proves this lemma. And what we want to do next is improve the value of B. So, recall the zero density hypothesis: b is the exponent of t that you have here. Okay. So, what are the previously known values? We have p to the 4 sigma by Hoherssel. We have Titchmarsh's result. And what Ingham gives is the following. So, let's look at that. Yeah, so again, what we are doing is we are saying that if zeta half plus it is of the order t raised to c for some c positive, then you can, he gives an exponent for this b. Exponent for this b um, yeah, he gives a value for this b in terms of c. Basically, you are getting he gets b being uh 2 plus 4 c. Okay, so that is what we have here. And yeah, there is a log t raised to 5 in there. If we have this, we'll see how to prove this, but if we have this, what can we get for the theta? So if you go back here. So, if you go back here, this was our lemma. In this lemma, you have these parameters. So, just plug them in. A goes to infinity. So, this term will drop out. You will be left with 1 minus 1 by b. And b is 4c plus 2 as per Ingram's result. If you prove that, if you just plug in that, you will get theta between 4c plus 1 by 4c plus 2. Okay, so the smaller your c is, the value this left side is approaching half. This left side is approaching half. Okay, this is what he gets. So we'll now try to see how to get this zero density result that Ingham proved. So let's look at, so this is theorem two, that this is the main result that we want to look at. And let's look at how, what is the strategy of the proof first? I mean, the cure for a year of the meeting was not an end of the time. Meeting was not sugar copper or something. So, this was known at his time with this what he this was known. Yeah, because he is using this. Oh, okay, yes, It's fine. Okay, okay. Is that one by little? This type of key is okay. All right. So, what's the strategy of the proof? Well, Proof. Well, we are going to there are going to be some common ideas here from Olivier's lecture. So, this is again, we are he's modifying the zeta function. And you could see that what he's using actually, let me write the modified function will be actually of this form: one minus. minus zeta is okay let me just write zeta times mx minus one so uh in olivier's lecture we saw that you can take this raise to 2k he just takes k equal to 1 so this is what we have okay mx here is the um is zeta inverse truncated so you have you are looking at mu n by n raised to s n going up By n raised to s, n going up to x. So, this function in here, that's what we are calling fx for now because we just want to keep a record of some properties that we are going to use. But this will be your modified function that we will use to detect zeros. So, in terms of what we have studied, you can say that the zero detection method here that he used was the logarithmic method. Okay, the very first one that we studied. So, what do we want to know about fx? Yeah, just if you keep look at the coefficients, so what we have here is, I'm just going to really quickly write it down. Yeah, if you the coefficient that you will get is d dividing n mu d. adding n mu d d going up to x okay and then you have this minus one so we'll write for okay this is for real part s greater than one so we'll write these coefficients as axn and if you just look at this what you are seeing if from from this itself a1 is zero and because you And because you are subtracting the one here, and ax of n will also be zero for any n between one and x, okay, because you're going over all the divisors here and you will get a convolution. So, the fundamental property of the Mobius will give you zero. So, basically, the coefficients only survive after x. So, we have this Dirichlet series with n bigger than x, ax n by n to. Bigger than x, ax n by n to the s, and this is the formula for the for the coefficients. All right, and one more thing we should just keep in mind is that the coefficients in absolute value are bounded by the divisor function. This is what we'll this we'll use. When your real part is two, then um, you can just bound this and you can see that fx square is bounded by this convergent sum. Tail of a Sum tail of a absolutely convergent sum, actually. So yeah, it is just becoming smaller as x goes to infinity. Well, I've written one by x here, but it's of the order, I mean, it's smaller than log x squared by x squared, right? So yeah, we'll just be using something like this. For x sufficiently large, this becomes of the below some constant times one by x. So these are some things about fx, but what's the main, what's the idea? But what's the main, what's the idea of proving this theorem? So, like we were saying, the modified function is going to be 1 minus zeta mx minus 1 raised to 2. Or well, in general, it was supposed to be 2k. And this will look like zeta times g for some g okay, some function g. Some function g. When you take k to be 1, like in this case, this g that you get will be of this form. It will just look like mx times 2 minus zeta mx. And what's happening? The key thing is that whenever zeta is 0, h is also 0. So you are picking up maybe more than the zeros of zeta, but you are definitely picking up those zeros. So we are interested in this one, but we'll upper bound it by. This one, but we'll upper bound it by nh. So we'll look at this quantity now. And we will use a result of now we want to detect zeros of this h. Okay, so we will use a result of little wood. So this was also mentioned in Olivier's lecture. This relates an integral of this zero density function nh to integrals involving arguments of h. Involving arguments of H and log of absolute value of H. So here you have this formula. So it's not hard to prove this. It uses only the Cauchy residue theorem. I have kept this in the learning activities. You can try it, but there's also a proof in Olivier's notes. So if you want, you can also look at that. So we get this. And the argument here is Argument here is okay. Let me maybe draw the rectangle. We are looking at such a rectangle: some alpha between some alpha beta and alpha plus it, beta plus it. So we are looking at zeros inside this rectangle. And when I say this nh sigma t, it basically is touching everything to the right of some sigma. Okay, an argument here is defined as at beta, your h is actually a real function. So you're keeping argument zero here. And then you vary continuously along this line. And wherever you want to go, you can go along this path. Okay. So this is the path you will take for the argument. The argument. Okay. So, yeah, so this is the result. And so, why do we use this? We want to bound this nh. We want to get some upper bound. And we have something in terms of argument and log. Well, let's keep aside the argument part right now. And let's just look at log of mod H. So if you do that, what you see is that this log of mod H from the way it's constructed. log of modest from the way it's constructed so let me write down h h is supposed to be one minus f square okay so from the way it's constructed this is actually bounded by fx square so those integrals which were appearing with the with the log of absolute value of h can be bounded by second moments of your function fx so you will get if you look here you have these two terms You have these two terms. Both of them will be bounded by the second moment: one at one at alpha and other at beta. Okay, so that's what we have here. And what happens typically is that we take in this rectangle, the beta that we take is beyond one. So on this side, you will be able to use so beta bigger than one, and we will be using the Dirichlet series to just work with this moment. Moment. On the other hand, this alpha is somewhere between half and one for us right now. And we don't have a clear result on this side. So we need to prove something else. And that I've stated as a claim. Okay. So Ingam proves this, that the second moment between half and one, you can give a bound of this form uniformly. Again, this C is what is appearing from this hypothesis. This is theta of half plus it has to be bounded by some t raised to c. If you do that, you get an upper bound for second moment uniformly between half and one. Okay, so we use this. So for now, we'll assume this. We'll come back to this. So this is the strategy of the proof. Basically, you're upper bounding the function you're interested in by function which counts zeros of h. And for zeros of h, you use Littlewood's formula. That brings you to. Formula that brings you to integrals involving log H, which can be then bounded above by these second moments. Okay. So now let's get into this, the proof of this theorem. So we have defined H like this. It's 1 minus FX square. It is zeta times some G. What we are going to do is we are going to take alpha between any, it could be anything between half and 1, and beta we fix. Half and one, and beta we fix as two. Okay. And now just yeah, instead of going from zero to t, let's just go from t1 to t2. Yeah. So this is t2. This is t1. So this is well, we are on two, two plus i t one and alpha plus i t one. Okay. I t1. Okay, so this is this is the kind of rectangle we are taking. And the way we are doing this is basically we want to avoid those. Yeah, we want to just go little high enough. So we are taking t1 between 3 and 4 in such a way that, and t2 also between t and t plus 1, roughly it's like t. But I just want that this function doesn't have any zeros on this. Doesn't have any zeros on this segments right now. So, over here and here, H doesn't have any zeros. You just pick those kind of horizontal lines, roughly up to some four and t here. And now you try to apply Littlewood's theorem. So, what we are looking for is, well, whatever you had in the previous slide, the statement, we just applied for T2 and T1 and just subtract it, you will get this quantity, this expression. Okay, so your counting number of zeros. Okay, so you're counting the number of zeros of h in this rectangle in this given rectangle to the right of some sigma that is here, and you will get an integral involving argument and log as expected. Let's just separate these two because we want to look at log first, and then we'll go come to the arguments. So, this let me call as first term is I1 and second term is I2. So, let's look at I2. Let's look at I2. So, for I2, as we discussed, we are going to use this fx square as the bound so that we are pulled into second moments. For the right side, it's always easier, right? So, this 2 plus it is fine. If you do that, you have, okay, you had two moments to deal with. One is at alpha. We keep that as it is. Another is at 2 plus it. For the 2 plus it, let us just go back to what we have. Let us just go back to what we have observed. So, if you look at f of x 2 plus it square, this is because of the way the coefficients were chosen, it is divisor function upon 2 n square and going from 1 to infinity, the whole square. We had this bound, and this we said that it's less than 1 by less than less than 1 by x. We just put this in. We'll just put this in so that oh, yeah, yeah, otherwise, this won't work. Yeah, from n going from x to infinity, that's why you get this, um, you get some savings. Yeah, so you just put this in for the second moment, and this part you are just picking up t by x. We're not being too careful here because this is going to be negligible. Okay, so you'll just get t by x. Okay, so you'll just get t by x here for the first moment. You are using that claim which we have not yet proved. So that uniform result. So this here, we are using claim yet to be proved. Okay, that is key here. Okay, so this actually takes care of this integral involving law. Now let's move to the argument. So, how do we bound these? The argument. So, how do we bound these terms involving argument? First thing is, let's just look at the argument: argument at some sigma plus i tj. So, if you, okay, let's come back to that statement. Yeah, we are in, we are asking for argument of points of this form, actually. This is some sigma. I'm interested in argument at sigma plus i t1 and sigma plus i t2. sigma plus i t2. So only on these two horizontal lines we are looking at the argument for the purpose of this integral. So let's come back here. Yeah. So this claim says that you can actually bound this by something which counts when h is purely imaginary. So let's just see why this is the case. I'll just draw the rectangle. Okay. So this is my t1 and this ordinate is t2. So I am having alpha plus t2 so i am having alpha plus it1 beta plus i t1 and down here somewhere is beta okay and we are interested in some sigma plus i t2 i'm for instance let me just take this point so you're interested in what is the argument here and What is the argument here? And what we know is that argument at beta for h is zero. So, what will happen is you're going to vary continuously along this line and then reach here. Along the way, your argument is going to increase. So, how it, what we can do is we can try to pinpoint all the points where H is purely imaginary. Whenever H is purely imaginary. Whenever h is purely imaginary, you have an argument increase of at least pi. Okay, so at these points, your argument is going to increase by, well, increase or decrease, whatever, but it's going to increase by pi, going to change by pi at most. And if you just keep all these points, this is what you have. Okay, so this is what this claim says, basically, that MJ, so you will get Mj. mj so you will get mj plus one where times pi where mj is the number of points at which you hit purely imaginary values on these two seg on the union of these two segments that is from um beta is actually two so let me just maybe write that i don't need to work with this okay so on the Okay, so on the segment 2 to 2 plus i t2, and then from here to here, whenever it's purely imaginary, those points I calibrate, and then I just say that argument is bounded by number of such points. But you can do something more. What you can say is, actually, in this picture, I don't need to have these points. Okay. These points, I mean, there are no such points. So our next claim is that. So, our next claim is that. So, what we are saying here is now I've changed mj. mj is now number of points at which h is at which h is purely imaginary on just the horizontal segment. Don't have to worry about the vertical segment. So, here, if I take this out, let's just copy it to the next one. So, what we are saying is you can forget about these ones. These ones just worry about these horizontal ones. So, why is that? That is not too hard to see. If you are talking about on this sigma equal to two line, let's look at real part of this function h. Okay, so this will be real. H is supposed to be 1 minus fx square. So, I'll get this. So, I'll get this, and if you write down the coefficients using the fact that they are bounded by the divisor function, you will get one minus summation dn. Again, we have the same series, n bigger than x squared. Okay. This is just by the way we have constructed fx. So, again, this is decaying as x goes to infinity. So, I can just make it. To infinity, so I can just make it less than half, let's say. So, for example, I can say this is bigger than half for all x sufficiently large. That means real part of h on this line is always away from zero. So, it's never purely imaginary on this line. So, we can forget all about the points that we were trying to catch on this line. We only need to look at the horizontal points, horizontal line. Okay. Okay, so yeah, now what do we do with the horizontal points? These are all these points at which h is purely imaginary, or you can say real part of h is zero. So instead of looking at that, we can write. So I'm looking at all points on basically let's just overestimate and on that whole full horizontal segment, we are looking at points at which. Are looking at points at which real part of h is zero. This is the same as saying it's they are zeros of a certain function. So, this, yeah, you just take the add up the conjugates, half of that. That function, you are basically catching zeros of that function on the horizontal axis. That is, that number of such zeros will be mg. Okay, so this is the number of zeros of this function 8j. In this, well. In this, well, you can go even further and increase that area. You can look at a disk around 2. Since you are kind of at most between half and 2, I can take a radius of 3 by 2. Okay. And look at the number of zeros in here. And now we have formulas to pick up the number, to count this, the number of zeros, and we'll use this application of Jensen's formula. So I've just stated. Jensen's formula. So I've just stated that here. So if fx, fz is analytic on an open disk and you have a bound on the boundary of that disk, then you can count the number of zeros in a smaller disk. Okay. So that will be at most this quantity. Log of this bound upon f value at the center and divided by log of this bigger radius upon the smaller radius. Okay, so what we're going to do is for us, this R is going to be 3 by 2. This Z naught is going to be 2. That's what we are interested in, this disk. And it's analytic in a bigger region. So I can just take, it doesn't actually matter what I choose here, but I can take capital R to be slightly bigger. So 3.5 by 2 I can take. If you just put all this in, you will get something in terms of this m. And if you look at the m value, this is okay, let me write here. M is going to be at most. Yeah, actually, let's look at this one. This one is going to be f of 2, which will be, so h j of 2 is real and it will be bigger than or equal to half. Okay. Bigger than or equal to half, okay, as we just showed. So you can just you don't have to worry about this denominator for the top one. You will get max of everything with sigma bigger than half. And you can let t go up to capital T and look at maximum value of H, which eventually boils down to the maximum value of the small h. That's because it's just a combination here, and I'm putting a big O. So I'm going to get H. So, I'm going to get H. Okay. So, this is the form that if you just apply this, you'll get. And these numbers really don't matter because we are looking at little O. So, what we'll do finally is we'll get number of, this should be mg. This number that we are counting, the number of those red points on that segment will be bounded by log of whatever is the max of h. Whatever is the max of h on this in this region. Okay. But recall that h is actually 1 minus fx squared and fx was supposed to be zeta mx minus 1. So everything boils down to bounding zeta and mx, which are known things, and you can use whatever information we have in this strip. If you do that, you will get some. That you will get some, you will get basically polynomial growth of t and x. So you will get log t plus x. Okay. So we are using some known bounds here and then getting this upper bound. Basically, what we are getting is that the argument part will not contribute much as compared to the log part of the integral. So when we just plug in whatever we have here, it's just a logarithmic group. So here, this is bounded by Um    Hi, do you hear us now? People answering. I don't see. Yes, yes. Okay, thank you. Camera's not on now. Oh, camera's not on. Is that open up? I can't see both. Yes. That's a good one. Maybe. Okay, so what we said, just for the people, maybe the past minute. So, MJ is bounded by, you can use, we use this application of Jensen's formula and we bounded the number of zeros on this number of zeros of this function. If you put this all together and you use whatever bounds, finally it comes out in terms of a bound for h. Of a bound for h. Since h is in terms of these known functions zeta and mx, we have bounds in this region which we use here, and you will just get a log of t plus x. Okay, so this is what we have essentially for the integrals involving the argument, and I just put everything together and we still have a log of t plus x. All right, we put everything back, the integral involving The integral involving this zero density function for h is now bounded by three terms, two of which are coming from the moments, which are actually were coming back from integrals involving log H. And one of them is coming from this last one is coming from the integrals involving argument. Okay, so this is as far as we got. And if you just look at this region and the terms you have, it's only the And the terms you have, it's only the first one which dominates. So you can absorb this t by x into this, and you can also absorb log t plus x into this in this region. Okay, so finally you can check this. You will be only left with this first term that you have. So this gives an upper bound for this integral, but we are interested in the zero density. Zero density. I mean, I'm interested in counting the zeros for zeta. So I will bound, I will, this integral itself was an upper bound for when you count the zeros of zeta between t1 and t2 again. Let's say I don't want to, I'm now, you know, you'll get that factor of log that was talked about earlier. So from alpha to two, instead I'm going from alpha to alpha plus some delta, which where delta is less than one. Actually, you will be choosing delta to be one by log t. One by log t. That's what is going to happen. So you will get that this integral is an upper bound for 1 by log t times your counting function for zeta. And instead of t1, t2, you can again go back to t because whatever you have missed out here are, you know, just that bottom region and you can absorb this. And you can absorb this into your constants here. Okay. All right. So we have, yeah, since T1 was growing like one and T2 was growing like T, we can get this. So now we just have obtained an upper bound for what we are interested in. We just have divide through by delta and that will give us what we want. So let's just do this. We are interested in this. Are interested in this? I'm going to call as sigma now and just rewrite the thing. So, n number of zeros to the right of sigma up to height t will be bounded by this quantity. We have a delta here coming in. And you're going to take delta. I mean, you can try to work out what is the best possible choice, and you will get delta to be 1 by log t. And t you will take as x. Okay, if you just put that in. Okay, if you just put that in, yeah, you will get such a bound where t is x actually. So, yeah. This gives you a bound since this was sigma was alpha plus delta and alpha starts at half. Alpha could start at half. So you have got something in this region. But that's just a little bit to the right of half. It's actually half plus one by log t. But that small gap is fine. We just use the known bound there, and that is smaller than what we have observed. And that is smaller than what we have obtained in the. Okay. So, in this missing region, we are just using this t log t that nicely is smaller than this. Okay. So, this completes the proof of the zero density estimate, which was obtained by N1. Modulo one claim that we didn't prove. So, let's just look at that. So, recall this. This is one of the key things here. One of the key things here. If you have zeta of half plus id bounded by some t raised to c, then you can get this kind of upper bound for the second moment uniformly between half and one. Okay, so ideas here are sort of have been discussed. What we do or what he does is he tries to get the second moment to the right of one. So you have one plus some delta. Okay, that you can try to get by exploiting the Dirichlet. Try to get by exploiting the Dirichlet series that you have. To the on the half line, also, he tries to get the second moment that is the second calculation. But on the half line, we don't have any information. That is where we are using this piece of information that we are assuming. Okay. Because I guess I should keep writing down the definition of fx. Fx is zeta times this juncated sum of mobile, this series in. Sum of movies, this series involving movies minus one. So on the half-line, we will use, we can get something about MX, but we don't know anything about Zeta. So we use this piece there. So these are two bounds that he gets for right of second moment to the right of one and at half. And in between, he uses a convexity result. But he uses a convexity result due to that's due to Thadi himself, that's Ingam and Polya. So we will state that. So, we will state that, but first, let's just try to see. So, these parts, more details are put in the learning activities, but we will just try to get an idea of what's happening with this bound, with this moment and this moment. Okay. So, let's just look at first the easier one. That's to the right of one. Let's look at this moment. Here you are using the Dirichlet series. If you recall, we had written Okay, we had written fx as summation ax n by n to the s for real part s greater than one. So just plug that in and try to work simplify. I mean, you will get you will get this directly. And this m by n raised to it, if you try to bound this in absolute value. In absolute value, you are integrating something, you will get a factor of log m by n that is going to come up in the in the denominator. Okay, you get a factor of log m by n in the denominator, so there will be a log, I'm just calling m by n as lambda, but if you use some inequalities, you can change it to two terms, which is what one of them is will give you something like this, and the other one will give you this. So, this you will be working out in the learning activity. out in the learning activity. And you will get, so you will get these two series. And so here log m by n has disappeared. But this one you can use your usual estimates and get something. And for this one you can use some known bounds due to Ingham himself. So this is a different paper. But you can also do it from scratch. But it would be easier maybe if you use this one. Okay. So you can use this one and try to bound this series where n and This series where n and m are bigger than x, and you have this log n by n in the denominator. Okay. So if you work this all out, you will get this bound for the first for the second moment at 1 plus delta. Delta is between 0 and 1. Let's look at the second moment at half. If you look at the second moment at half, there is nothing to help you in terms of a series. You in terms of a series, but what we can do is since we are looking at fx is zeta mx minus one, for this piece we will use the growth that we have the zeta half plus it. But we can so using that and piecing things together, it will boil down to taking the second moment of mx. Okay, if you take the second moment of mx, you are going to get a now here you can use your Now, here you can use your series because this is a finite sum. So, here you use your series. You do the same thing essentially that was done on the previous slide. You will be integrating something. If you take absolute values, you are going to be getting a log in the denominator. For that log, you break it into two parts like this. And you will get this first term and the second. And then you can do some estimations and you will get t plus x log x. So these this. log x so these this is an intermediate step you'll get so this also you can try in the in the learning activities so this second moment you get this bound and assuming zeta half plus it is uh yeah you you put this information together with that to get finally something like this this t raised to 2c times t plus x times log x as the bound for the second moment at half now as i said we need to use a convexity As I said, we need to use a convexity result. So now you have a bound for second moment to the right of one and at half. So we use a convexity result. This result that I'm stating is by Hardy, Ingham and Polya. And you can see that there are a bunch of conditions here which were not there in the newer convexity results stated by Olivia, which is by Gabriel. So Ingham used this one and this is a convexity. This is a convexity result for integrals. So, what you have is you have f satisfying some conditions. I think the most important one is this one. I mean, this needs to happen that this p-th moment of f, when you're taking from minus infinity to infinity, this integral, it should converge when x is alpha and when x is beta. This is not happening if I use what I already have. The moment that you're looking at, it is not going to converge. So, you need to. It is not going to converge, so you need to put some factors in there which scale down the growth so that this happens. Okay, and if you can do this, then whatever integral you are working with, well, this is a loose statement that log jx is convex. This is just, you can think of it like this. Whatever you know about a convex function, that's what log log jx is going to behave like. That means jx is going to satisfy this part. Okay, so this is uh. So, this is J of Px plus Qy, and here you can put there'll be a P here and a Q here, similar to the form that we have seen in all of this lecture. Okay, here, what is the J that you use? So you will take again something similar. Let me write. Basically, you can't take F as it is. You need to, first of all, you need to kill the pole. So you will have S minus 1. And you need to also kill the growth of Fx because those. f x because otherwise this won't converge so what we do is we put an s cosine to oh sorry s by 2 tau here um where tau is bigger than 3 by pi and you take j to be the following j sigma will be integral minus infinity to infinity phi of phi of sigma plus i t squared dt okay so this integral j will satisfy uh sorry this function phi will satisfy these hypothesis that you're looking for and then you will have convexity for this integral j which is uh well almost fx except for these factors but one For these factors, but once you get an upper bound for this, you can kind of relate the growth of J to the growth of the second moment that you're looking for, because you just have to deal with these factors, which are growing like some exponential in the denominator. Okay. So if you take care of that and you relate the growth of these two, you will get the upper bound for F for the second moment of F that we are looking for. So you do that. And yeah, this also. Uh, yeah, this also has. I mean, we can do it in more detail in the learning activity. Okay, so this would basically take care of this theorem where you are getting a bound for the second moment uniformly between half and one. Now, let's just look at some applications. So, when you're getting these primes between in short intervals, it has an application to primes between consecutive large powers. Consecutive large powers. So, this takes us back to Legendre's conjecture that between any two consecutive squares, there is a prime. This is unresolved still, even under Riemann hypothesis. So, we can ask instead an easier question. So, we can ask whether there is a, well, I'm saying easier now, but is there a prime between every pair of consecutive cubes? Okay. And this is easier because this. is easier because this interval between two consecutive cubes if you take it will already contain the and it will contain two consecutive squares inside there so it will contain this interval involving two consecutive squares if you're going to take y to be x to the three dot okay something like that or just take the integer closest to this so so this is easier than the than legend legendo's conjecture and in general you can And in general, you can see that if you are looking for primes between consecutive nth powers, then it will imply the existence of primes between consecutive m plus one powers because the gap is increasing. And if you prove it for n powers, it will happen for all powers after that. So what do we really need in order to do this? If you want to obtain a prime between mth power of, I mean, n raised to m and n plus m m plus 1 raised to m. m plus one raised to m for all sufficiently large m. So you need to show yeah so you need to show that there is a prime in a certain interval. What is that interval we are looking at? Suppose I'm calling this as x. Okay. So we are looking at the interval x. So I'm writing x to be n raised to m. So n plus 1 raised to m will be x raised to 1 by m. plus one raised to m which is basically i'm looking at this interval x raised to uh i'll get x plus m times x raised to i'm just using binomial theorem here plus higher terms and then finally we have m x raised to 1 by m plus 1. Okay, so you are looking for primes in this interval, actually. But since x is large enough, in But since x is large enough, in practice, what happens is you can neglect these higher, sorry, these lower order terms. And it's enough to find a prime between in every interval of this form. Okay, if you want to show existence of primes between consecutive m powers, we need to find a prime between every interval of this form for all x sufficiently large. Okay, so if we want to do cubes, let's say, so I just plug in m equal to. So I just plug in m equal to 3 here. So I'm interested in finding an prime between x and x plus 3 times x raised to 2 thirds. Okay, that's what we get. So you are interested if you want to do it for cubes. I want between consecutive cubes, n cube and n plus 1 cube. This is what we want to get. For all sufficiently large x, I want this quantity to be positive. So if you just actually you do get this from. So, if you just actually, you do get this from Ingham's result. Why is that? If you take C to be, as we saw, you can take C to be 1/6, that gives you theta to be 5/8ths. Okay. This interval contains this thing already, because 5 eighths is bigger than 2 thirds. So, it contains this interval of length x to the 2/3, roughly. So, this gives you primes between consecutive cubes for all sufficiently large cubes. Ingham's result is given. Large cubes, Ingham's result is giving you that there are primes between consecutive cubes. Now, how large you can make this everywhere I'm saying n sufficiently large, x sufficiently large, but you can actually start quantifying like how large do you want that n and x to be. So these are explicit results which one can try. And we have some results due to so Dudek proved that you can go between, you have a prank between Can go between, you have a branch between consecutive cubes for all n bigger than e raised to e raised to 33.3. Okay, that's how far you have to go. And he also showed, so another thing is, suppose you don't want to go this far and you want it for all integers, then you should try to raise this power so that the gaps are bigger. Okay, so he showed that there is at least one prime between mth powers, consecutive mth powers, for all integers. mth powers for all integers provided your m is this large so it's well all m after this will also work m is 5 into 10 raised to 9. this was uh improved very recently uh this is new work due to michaela so she showed that uh there is a prime between consecutive uh cubes for n bigger than e raised to e raised to 32.537 okay and this power here has been reduced substantially Here has been reduced substantially, so you can show that between 148 consecutive powers, there is always a plan. Okay, yeah, so these are some of the recent results. Okay, I'll start with this.