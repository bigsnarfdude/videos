So I'm going to talk a bit a bit about some of my recent studies and I would first start. So here it is great that I can skip the introduction of the quantum Tyrodal algebra relations and generators and the properties. This is fantastic. I hope that I will have a This is fantastic. I hope that I will have a bit more time to talk about the actual thing. So, the talk is going to be a little bit physics-inspired, but I'm going to make some rigorous statements. So it's not going to be hand-waving, pure hand-waving, but I would like to start with a somewhat Somewhat general picture of what I'm trying to do. Let me start with a prototypical example of the action of the quantum toroidal algebra of type GL1 on the key theory of instanton modulus spaces. Right, so. Right, so I have a sum of instant on over instant on numbers, and here I have eventually the Hilbert scheme of points on C2. I'm writing this a bit schematically, but so this is the prototypical example that this sum of k theories is a Fokk space, a Fokk representation. Representation of this algebra. And here Q and T correspond to the equivalent parameters of the equivalent K-theory. And here F also contains this Q and T parameters in principle. It is labeled by these parameters. Now, what kind of generalization we may be looking at? So one can generalize both levels here, or like both sides. Levels here, or like both sides of this. So either algebra, which is going to be generalized, or the spaces, representation spaces on which it acts are going to be generalized, and somehow somehow different types of representations are mixed up together and played with. So here, the next thing one can consider. The next thing one can consider is, of course, the quantum toroidal algebra of other types, of other Lie algebras for other G's. And a bit more generally, there should be quantum toroidal algebras corresponding to toric diagrams drawn on a plane. Drawn on a plane. I'm drawing an example of it. This type of a diagram, the combinatorial type of this diagram, should encode the data, the commutation relations of an algebra. In particular, this algebra will correspond to a single vertex which is C3. So there is a possibility to generalize to other quantum toroidal algebras. On this side, one can keep the algebra the same, but consider more general representations. So here if we have this section on the Fox space, we know that there are spaces, Fox representations of different, for example, of different Of different slopes, so-called slopes. And playing with different representations like this, one eventually obtains intertwiners R matrices for different representations. The pioneering example of an intertwiner of this kind is the The Psi AFS, which was discovered by Avata-san, Feginsan, and Sharaishi-san some time ago, which is related, well, its matrix element is equal to a refined topological vertex. And this is an extremely nice connection. And this is an extremely nice connection from which one learns that if one draws a particular network of intertwiners and glues them together, eventually everything is consistent. One obtains a partition function of a refined topological vertex, of sorry, refined partition function of a Tori Calabiyu threefold. Let me here emphasize that refined topological vertex leads us to Vertex leads us to the toric Calabiao threefolds, and this Tauric Calabiao threefold has a priori nothing to do with this Tauric Calabiao threefold, of which the diagram parametrizes the algebra. These are two different things. There is a relation, but I'm not going to talk about it. Well, and there are and there are. Well, and there are some, one can consider more intertwiners, more representations. I'm going to be a bit more specific in what follows. There are matrices, of course, they permute tensor products of representations. There are also some nice formulas obtained by some people who are in the audience. And naturally, one can, of course, do both simultaneously in principle. One can do. One can do generalization to other G's, consider representations of it on more fancy spaces. There are going to be similar fork representations, for example, and consider intertwiners of these representations. It's going to be very technical, but you can do it. Now, there is a separate story which was also mentioned during one of the talks, and this is the Talks. And this is the story of, well, how to call this BPS or like Quiver W algebras algebras. So this will sit separately from this two a priori. Quiver W algebras, BPS. Algebras, BPS algebras and also this spiked instantons, etc. So, quiver W algebras, for example, they naturally depend on a quiver queue. Uh queue and uh they contain again a priori, they contain they are more general than quantum toored algebras because a particular example of a quiver that can lead us to this action on the folk representation of this quantum toridology or button principle. We can consider more general queries. More general quivers, and there are more, for example, there are more equivalent parameters in this setting, in this quiverW algebras, and also, for example, in this spiked instantons. So, the spiked instantons can be viewed as a generalization of this space. Space. So, this space, the Hilbert scheme, is really the modular space of U1 instantons on C2. So, this is modular space of U1 instantons and for spiked instantons, as we Instant tones, as we have heard in Nashita's talk, that here we have instant tons on C4. So a kind of instant ones on C4, but more generally on subspaces thereof. Thereof. And on C4, naturally, there are more equivalent parameters. There is natural equivalent action on the C4 involving four parameters. I have no idea. This is the terminal, the folded spiked instant tons, folded instant tons, and crossed instant tons. You have to accept some terminology. I don't know. I don't have a better name. Maybe, maybe. So you are talking about this type of picture. Like there is a framing, more framing nodes, like this, and this is. This and this is like a spike. Okay, okay. For C3? Here, if I put C3 here. Ah, here. This is C3. This is we return circle back to our standard example. QueryW algebra is a different beast. So here you see they are separated. And beast. So here you see they are separated by impermeable membrane. So a priori, this downstairs level is not connected to this level. Can I reproduce this thing from a quiver? Quiver W algebra there is a definition. Equivalent W algebra, there is a definition by Kimmur and Peston. This is what I mean basically. I don't completely understand the question. So we have you ask what if the quiver the quiver is what? The quiver is the it's just a one-wheel floor without the quiver. Without these guys. Mm-hmm. Yes. This is going to be a W algebra of affine A0. No, it's a so W of A0 hat. This is not W1 plus infinity, it's a different beast, and we are going to touch upon this in this talk. Thank you for the question. On this in this talk. Thank you for the question. Sort of anticipate what I'm going to talk about a little bit. I will not explain what it is. I don't completely understand it still, but I will have some thoughts. Okay, so yes. The idea of my talk is to make some connection between two levels. Between this level, try to work a little bit with intertwiners here. bit with intertwiners here and try to obtain some of this to try to go to this higher dimension while staying in the very basic framework of this algebra so I don't modify the algebra I keep the algebra the same but I do something some combinations of intertwiners In order to go to higher dimensions here, to try to understand what are this, possibly what are the spiked instantons, what are the quiver W algebras in particular of this affine type. Because for finite type, at least for finite A n type, one can draw some connection here. But for a fine type, there are more deformation parameters, as I said. Parameters, as I said. So there are more equivalent or deformation parameters. And how to deal with it is a priori, not evident, because the algebra here just contains two. While here there is Q, T and also an extra parameter mu, which is sometimes called the adjoint mass, which is not present here. But we'll see that we can somehow Somehow, cook up this parameter from playing with intertwiners. And in order to play with intertwiners, I'm going to define some of them, some objects. Like some are mattresses, some intertwiners, which I'm going, which I will need in my pictures, which I'm going to draw next. So I'm going to I'm going to introduce first some R matrices. And sorry, so maybe first I introduce what is going to be the mnemonic for different representations of this algebra. So I'm going to have representations corresponding to brains. And let me once and for all introduce the notation A for this algebra brains of type to be string theory And in mathematical terms, it's just going to be mnemonic, which will allow me to draw pictures instead of writing intertwiners as formulas, I will draw pictures, okay? So the string theory contains 10 it is It is defined on a 10-dimensional space. What is this 10-dimensional space? It is going to contain three dimensions like this. Sorry, six dimensions like this, three complex dimensions, okay? Sorry. Then it will contain. Then it will contain a pair of real dimensions like this and a separate pair of real dimensions like that. Now here I'm going to write out the brains and representations simultaneously. Okay, so what are the representations? We already had this F. Already had this F, the focus representation, and that will correspond to five brains which span some directions here. Here, by this, I mean that the brain completely spans the two real dimensions corresponding to this complex dimension. And I can put a point here, or I can simply write now. Write nothing, and this means that the corresponding brain sits at the origin of the corresponding direction or at the point in general. So the picture for the five brain and the corresponding F is going to be like this. You see, I've made a choice here that I span CQ and CT inverse, but I don't span this direction. Hence, I need... This direction. Hence, I need to introduce the labels of my representation here. And I've also made a choice that it spans this Rx here and doesn't spend Ry here. So I need to somehow keep track of this. This will correspond to the slope of the representation. So the slope of this representation is going to be 1,000. I will write it out here. Also, this F contains a spectral parameter U. Spectral parameter u, as some of you probably know very well. And this u will correspond to the position of this brain in our y direction. So this u is the position in Ry. Okay? Now I have two more types of brains. And naturally, here you can already guess what happens. Here, you can already guess what happens when I change the slope. Of course, I need to change the direction which I span here. And also, if I change these indices, I naturally have two more choices which I don't write out, but of course I can spend CQ and CTT over Q and skip this one. There are three choices. Now, there is the so-called vector representation. Vector representation which corresponds to D3 brains. I'm not going to stop much on the physics again. For me, this picture in this talk is going to be simply a mnemonic for drawing diagrams. It's a little bit like Feynman diagrams, but you know, any diagram is like a Feynman diagram, almost. And here, And here I have I also have to choose a direction which I span, but since it's two less dimensions compared to the five brain, I need to choose only one C here. And I also, due to the reasons which I'm not going to talk about, physical reasons, it's going to be a point in this. Going to be a point in this Rx and Ry direction. This is again a little bit complicated, but I'm just going to state this as a fact. So here I need to introduce a label which keeps track of which direction I span, but only one label. It's either Q, T inverse, or T over Q. The different representations. And these representations can be thought of as representations, of course, on the space. Of as a representation, so of course on the space of functions on Laurent polynomials in X or Laurent series in X. Here I don't want to emphasize what is going to happen, but it's a representation by different separators. It is also a well-known representation. It is also a well-known representation. And now the final one is, of course, the so-called Mach-Machan representation. It corresponds to seven brains which span the whole C3 here and And here one also needs to draw it like this, but I include them mostly for generality. I'm not going to use this. I'm going to use this too. Okay, so this representation is going to be invariant under the exchange of q, t inverse t and t over q is just going to be an Over Q is just going to be an automorphism inside the representation. As for this VQ, VQ is also invariant under SL2Z. So here X SL2Z, the SL2Z automorphism of this algebra, of the algebra A. So here is the mnemonic, here is the picture which. The mnemonic here is the picture which includes in itself the representations and the automorphism of the algebra. Now, what are going to be my building blocks? So my building blocks will be intertwiners and R matrices. Let me start with an intertwiner. With an intertwiner. So I'm drawing the R squared XY plane here. Oh, maybe I okay, maybe I start with R metrics better. So, an R matrix is an operator like this, where here I have F10 and here I have F01. They can be of different types. Essentially, there are two possibilities. This F can be, let this F be of some type, say QT. Be of some type, say QT, then this other F can either be of the same type or of a type which shares one dimension with it. So this is either like this or it is of this form. Okay? There are two possibilities. And this I'm going to write as two different R matrices. So this one I will call RHW and again, so this name comes from physics from Hanani Witten. The corresponding brain like brain setup means something physically, but I don't really want to. Don't really want to go into details here. And if I have FQT T FQT here, then this is going to be our conifold. And again, so why it is conifold? This is this is too much. This is too much of a detail for this current talk. I can explain it, but I won't need it. So these two are explicitly computable. I mean, by this I mean I can find every matrix element. Find every matrix element of the SAR matrices. Basically, all building blocks which I'm going to use today are explicitly computable. Yes? Here, yes. Again, in the current talk, yes, they are going to be. Yes, they're going to be like this. Yes, yes, you can do it. Some of them are harder than others, but some of them you can compute. This is the question, like you can consider you can consider different things. There are two levels to this question. First is like the surface one is something explicitly computable, and the second. Explicitly computable, and the second one is that there are metrics might not be defined for every pair of representations. But here it seems to be okay. Yes? The labels are different. Here it is Qt over Q, and here it is Qt. Sorry? Here 0110, 011. Like this. So let me maybe introduce some color coding. Maybe I can to distinguish two pictures. Let me draw this FQ. Sorry. Wrong. I'm sorry. Made things worse rather than better. Let me. Let me draw this FQT as white lines while I draw FQT over Q as orange lines. Now I think it's better. Okay. And then I have our matrices also between Fox spaces and vector representations. So this is going to be, say, one prime. These are also. These are also R matrices, but these are between Fox spaces and like FQQT. And here I'm going to have a vector space. There are different choices, but again, essentially, there are two possibilities. Either this V Either this V has this spectral parameter which is distinct from both of these two, or they share one dimension. So if it is distinct from these two, the R matrix is particularly simple. This contains only the sum of two vertex operators, really. Let me write out it explicitly. These are also explicit expressions, and I do have them. Explicit expressions, and I do have them. If I have time and end, and anybody is interested in getting explicit expressions, I do have them, but they will fill out half of the blackboard. Well, this one will fill only a fraction of a blackboard. So, here I have a supp so this is an operator which acts from the tensor product of a folk space and a vector space. So, it's going to be an Going to be an operator in the Fox space which also acts on the functions of some variable x, like here. There were functions of x. So it turns out that the expression looks like this. There is v plus of x t over q x dx over 2. So this is a shift operator which shifts the argument. A parator which shifts the argument of f by t over q square root plus, so there is some u here, u t over q v minus of x t over q minus x dx over 2. So everything as is as promised. Here I have summed I have an operator acting on functions of x. Then I have something depending on x, and here v plus and v minus are vertex operators vertex operators acting on f and they see that point x, this point x is. At point x, this point x is the variable in the function on which I act. So this is functions of x. And here, so this is the expression, the closed form expression for the R matrix between Vt over Q and F Qt. Now I still have one more possibility. One more possibility, which I'm not going to write out explicitly, but it exists. The possibility when, so now I need some color coding again. Which one is better? I don't know. I hope the green is visible. So, this is V. I have to choose one of the indices here, and I choose VQ. Of course, Vt is a Vq. Of course, Vt is obtained by the symmetry of the algebra. So I have it's also an explicit expression, but an infinite sum. Sum of shift operators tensor V. V of x, some v v v i of x, by which I mean vertex operators, certain vertex operators. And the final piece of construction, I think I didn't forget anything, is going to be the intertwining operator like this. So here. So, here, okay, okay, okay, okay. I think I again made things worse rather than better by introducing the color coding in the wrong place. So, let this guy be green, okay? I'm sorry, and let this guy be white in the paper. I used In the paper, I used three different colors, but on the blackboard here, I'm as you can see, even with two colors, I'm too bad. Like this. So here is going to be VQ and FQT. So this VQ is again, it's corresponds to some functions of X, and this is simply a And this is simply so this is phi of X a vertex operator operator on F. As you can see, I have quite a lot of Lego bricks, a lot of building blocks, and I can draw many, many things. Many, many things. In particular, with the sarmatrices, I can draw a lot of things on a plane and I can study them, and I did study them. But in this talks, in this talk, I'm going to introduce something called a spiraling ring. Hence, I'm going to draw a very strange looking thing. And before drawing it, I want to motivate it a little bit. A little bit. Yes, of course. For the Hanani-Witten case, you mean this and this? No, and for a good reason. Because geometrically, if you have a five-brain like this, and you have an orange five-brain, let me try to draw it here. An orange five-brain is going to Orange five brain is going to span this, this, and this. Okay, now what I'm drawing is this plane, but there is an extra plane here, and in order for these two guys to merge, well, they need to have common dimensions also along the C, C3. It is possible if I have two wide. It is possible if I have two wide brains, two brains like this, this can happen, and this will lead precisely to a picture like this, which is the famous refined topological vertex. They can merge precisely because you can forget about these dimensions, they are common for them. For them. Well, here they can merge, the vertical and horizontal can merge and produce the diagonal one. While this white and orange lines, they cannot merge. But they can cross. Here it is like kiss and goal. They cannot spend any time together. But they can cross. Okay? Sorry? Sorry? No, there is one, one representation with either Qt or Qt over Q or the third one. But if you consider a tensor product of these two guys, the central charge would not match the central charges of these representations. There are two central charges of this. So the central, this contains, it has non-trivial second central charge. It has non-trivial second central charge. This contains non-trivial first central charge, but they are incommensurate. So when you merge them, you obtain something which is not, no folk representation can have. Okay, we can discuss it later, I think, but I believe that there is no such thing for orange and white brain. Orange and white brain. Okay. So, motivation for spiral for a spiral one can consider integrals of motion. So, the expression, the common expression in integrable systems for integrals of motion is a partial trace of an R matrix, right? So, we had it in Yevgeny's talk. There was a trace of some P times D times R one times the R matrix. times the R matrix. And here there was one times some W. W was the representation sitting on one of the legs of this R matrix. Of course, I can still do this for my R matrices. It's not going to be tremendously interesting, but I can do it. Now, what I would like to consider, so this will correspond to the This will correspond to the picture like this where here these two spaces are identified. I take a trace. Sorry, and here I would like to draw this P to the D as a block like this. So this just introduces, this just counts the grading along this vertical Fox space. But if I want to take a trace of something of something more interesting, usually again, there is some physical motivation for considering such intertwiners, like when people consider adjoint gauge theories with extra adjoint matter. One usually One usually wants to consider a different trace, so more general trace, which I'm going to draw. Now, instead of writing, I'm slowly switching to just drawing things. Okay, so I want to consider, for example, something like this, where I have two refined. Refined topological vertices corresponding to the intertwiners, and I identify these two spaces. What's the difference between these two pictures? Well, there is one essential difference, that here, this Fox space and this Fox pace, they have different evaluation parameters. So this is F of W and this is F of C. And this is f of some mu times w, where mu is a naturally a parameter of this system. Mu corresponds to this. Basically, in this picture, mu corresponds to the distance here between these two lines. And I still have my p parameter. My p parameter, I'm not going to draw it anymore in what follows. I'm going to draw a peak. Going to draw pictures like this, where P is going to be simply this distance between the, if you wish, the circumference of this circle on which I compactify my picture. So now these pictures are going to be drawn on a cylinder. So these are pictures on a On a cylinder, now I'm always confused. Is there one L or two L's? I'm sorry. Anyway, I hope it's understandable. Now I'm going to draw pictures on the cylinder. And now I have choices. I can consider this picture with mu equal to one. To one, then I more or less return to this picture schematically, and I don't have an extra parameter mu. Or I can consider a parameter mu, but then what I'm taking trace of, so this is a, let me try to write out what this is. This is a trace again over the first representation. So this W here is F zero one. F01 and here it is also F 01 but now I have instead of the R matrix I have psi psi star the intertwiner and the dual intertwiner psi AFS Psi AFS dual and here I need to introduce an extra shift use an extra shift μ to the d orthogonal. This is the second grading of the quantum toroidal algebra. In a certain sense, this picture is more natural because I employ both gradings. But again, so I don't want to consider the to say that it is the most general thing one can consider, but it is uncertain. Consider, but it is in a certain sense natural that I have some operators like this, of which I would want to take a trace, but the vertical lines here don't completely align, they don't match. So I need to introduce the shift mu. Okay, the price to pay is that this is not an R matrix. Not, it's an intertwiner, but not an R matrix. And I want to play a little bit with our matrices. And for reasons which I'm not going to explain, sometimes I would want to consider a picture with extra R matrices on the top. Again, from integrable systems perspective, it is natural to consider some type of a picture and Some type of a picture and add some R matrices, then commute with these R matrices or with transfer matrices and see what happens. It leads to some nice relations usually. But here, I cannot introduce an R matrix on top of this picture, which means on what does it mean on top? I cannot combine these two operators. They are operators on the horizontal Fox space, but But I cannot combine them because I have different shifts here. I mean, like operators on FoxPlace, I can combine them, but they would not mean anything in terms of my algebra, because the shifts here and here are different by this mu. Now, what happens if I, well, stupidly still want to combine this operator with an R matrix? If I want to insert an R matrix here, why do I want to do such a Why do I want to do such a thing is a good question, but yes. No, this does not satisfy Youngbach's equation. This part does not satisfy Youngbach's equation. Satisfies Youngbacher equation with an extra, what we call caseycle, or it does not satisfy Young Baxter. Does not satisfy Young Bux unless mu is T over Q, the square root of T over Q. So this is most definitely not in our matrix, but what I care about is what if I have some picture like this and I want to put near it some picture like this. Oh, this is a This. Oh, this is, of course, in algebra this wouldn't make sense, but I still want to try. What if I have a crossing like this, an R matrix like this, and then I have some spectral parameter W here, then it is going to be W, well, shifted by some Q over T. Sorry. Well, let's keep it like this. Let's keep it like this. The problem is that if here I have some y spectral parameter, it's going to be muy. So it means that my cylinder, it identifies representations with y on top with representations with the mu y here downstairs. And if I still want to put our metrics. If I still want to put our matrix here, I don't have a shift inside. So, what happens is my identification is not going to be with this fox space, but I need to introduce an extra fox space. There is no way around it. And I will have to introduce extra folkspace here like this. Like this, and it's going to continue in both ways, like this, etc. You squared W. So, I'm going to get something awful. I'm going to get this type of an This type of an infinite spiral. So, my Fox space is going to spiral around. And here I'm not going to write a formula because it's easier to draw a picture. What it corresponds to. So it looks like just a crazy thing, a crazy expression, but it turns out that it is nice and it makes some sense. I'm going to give two Two applications of this. Okay? Or maybe three. The first application of this, so first of all, this is a nice picture in terms of the intertwiners of the algebra. So the shifts here are consistent. I can write this as the following picture. The following picture like I have an infinite sequence of these Fox spaces and then here I put one and the same operator P to the D μ to the D orthogonal And after that, I can take the trace, and it's going to be alright. So, here, how do I draw a trace like this? So, this makes sense as an operator, except it's an infinite tensor product of Fox spaces. So, there might be some problems, but we'll see that it works. And what are the applications? The first application I'm going to consider is to key theoretic vertex counting sheaves on C three. So this vertex was introduced by Was introduced by, I think, Nikrasov and the Kuinkov some time ago. But, and it is an uplift of refined topological vertex. So, refined topological vertex is a limit of it. So, refined is its limit. Is its limit. So, by itself, the question is interesting. I have a refined topological vertex here directly as an intertwiner of my algebra, but what is the meaning of this uplift? This uplift contains extra parameters. A priori, no algebraic meaning is given as any intertwiner or whatever. But we'll see that the curious observation is that a certain That a certain spiraling operator reproduces this. Sorry, so I need orange brain here. So I introduce the following picture and I'm going to comment on it in a moment. In a moment. So here is the picture. And as usual, I say that this is identified with that, this is identified with that, etc. Now, what happens? This is an infinite sum over intermediate states in the Fox space. So this is a sum over an infinite number of Young diagrams. Of Young diagrams. So I say here sits lambda 0, lambda 1, lambda 2, etc., lambda minus 1, lambda minus 2, etc. And I have to sum over all of them. And to every term corresponds an operator still acting on this horizontal Fox space. Okay? Now I do the simplest possible thing. I put vacuo here. I introduce a vacuum. Vacua here. I introduce a vacuum matrix element of this spiral. And notice here I have slightly modified, here I have modified R matrices. Here I have R matrices. And here I have R inverse matrices. So this is R, this is R inverse. Now the theorem is: if I consider this thing, this is going to be the sum over pi plane partitions. plane partitions plane partitions of certain coefficients C pi which are going to depend on Q T mu my parameter mu the shift and on P but the dependence on P is going to be very simple so the dependence on P is written out Dependence on p is written out like this. This is the total number of boxes in the diagram pi, and these are some rational coefficients. So these are some rational function which can be found explicitly and it coincides with the weights of the k-theoretic vertex function. And there is an identification of the parameters qt and mu. Q T and μ with three equivalent parameters here: T1, T2, and T3. I'm not going to write it out, but you'll have three independent parameters here. Now, recall that we had Q, T inverse, and T over Q, which the product was one. So, here mu is independent of Q and T. So, we have three independent parameters, as we do in this case. Parameters, as we do in this k-theoretic vertex, and it matches. Now, a short remark is that one can consider also asymptotics, pi with asymptotics, so pi with asymptotics can also be considered. Because lambda satisfies certain selection rules, because this R has most of its matrix elements between lambda, say lambda 0 and lambda 1. So lambda 1 sits here, but it also sits here because these two are identified. Oh, I'm sorry. I think it's the wrong way. Anyway, it's lambda minus 1 here, okay? So between lambda 0 and lambda. So between lambda 0 and lambda minus 1, the matrix element of this R matrix, most of them vanish. Those which do not vanish are those satisfying lambda 0, lambda 1, lambda 2, etc. And the same and vice versa, where this sign is called interlacing condition. And interlacing condition is exactly the condition satisfied by the slices of a three-dimensional Young diagram. If some of you considered refined topological vertex computation, you know that I will draw a very small picture here. I'm sorry. That if you have a 3D Young diagram like this, and you slice it diagonally with some plate. With some planes. In every plane, you obtain lambda, lambda 0, etc., lambda n, and in this side 2. So they will satisfy precisely this condition. So this sum over an infinite number of Young diagrams boils down to the sum over plane partitions, and moreover, the coefficients are correct along q direction. Yes. Yeah. I have tried to draw it like this, you see? So diagonally, diagonally, like this. So my planes, they span one of the vertical axis in this picture, which corresponds to the Q parameter, and they are diagonal in the two remaining parts. Okay? Now my time is almost up. Is always almost up. How much time do I have? I'm sorry. Three minutes? Perfect. So let me erase this. And I introduce my second application. And by the way, so I have currently, I can say that I. Currently, I can say that I have almost no idea why the applications work, but they do work. And it is curious to see what this dictionary brings us. So, application number two is the so-called Shiraishi functions. Functions, also known as non-stationary. Elliptic Rogenard's Snyder wave functions. So these are some explicit functions which depend on a set of two sets of variables, x and y, and they also depend on a bunch of parameters, q, t, mu, and p. Okay? And they have very nice properties. Very nice properties under exchange of X and Y and mu and P. Let me just stop at this. And they are some natural generalization of trigonometric Reginald's wave functions. But then again, so their algebraic meaning is not completely clear. They are defined in terms of certain affine set of screenings, but this affine set of screenings by itself. By itself, it's not clear why one should consider exactly this one and why one should consider the product which is considered. Now, the final drawing is going to be a picture corresponding to the wave function here. And by x, I mean x1, etc., xn. So I have this parameter n, the number of particles in this. Particles in the system. So I'm drawing n Fox spaces here and I'm drawing n vector spaces like this. So here, every crossing of a vector space and the Fox space is an R matrix, every junction is an intertwiner here, like this. So, this is FQT, this is VQ, and they have spectral parameters. So, the spectral parameters here are Y1, okay, YI, PI over N, P to the power Y over N, and here there are spectral parameters 2, or the variables in the function on which the vector representation acts, and this is going to be x r. And it's going to be xi mui over n. But it doesn't end here because I have to consider the spiral like this so they get shifted by mu and the circumference is p and this should continue to infinity. Continue to infinity, like circling around and circling around. And then I put vacuum everywhere here. And the theorem is that this is equal to F. Now, I have no time to explain why all the properties follow, but they follow. They follow the non-trivial symmetry properties of this. The duality has nice duality properties properties which follow from star where star is this equality. Okay, sorry for Okay, sorry for running our time. Thank you very much.