The introduction. Thanks for the chance for me to speak here. Right, so I hope everybody sees that all right, if and hears me alright too. So if not, then now is the time to object. Okay, so exactly. So what we're going to be talking about is some recent work that I did together with Evaud Vanderberg, Slatkuminev, Abanov Kandala, and myself. And it's probably going to be relative looking at the program more of a physicsy talk at the moment. More of a physicsy talk at the moment, but it sort of fits to the line of noise and near-term quantum processors and so forth, which I think might still be nonetheless a pretty good fit. And so on a high level, so what is it that we do? There's something called error mitigation, which is basically you accept defeats and declare that you are not able to do error correction right now, but still would like to do something with noisy devices. And then you have to put in some. And then you have to put in some thought into how you could possibly get something meaningful out of noisy devices in lieu of not having error correction. So, of course, there's way more limitations and a lot more restrictions, but you get away with a lot less. So, that's roughly the setting of that talk. And I'm going to present one particular kind of error mitigation technique. So, let me go into that. So, what's the entire setting in which we're working? So, we're looking at algorithms. So, we're looking at algorithms, quote unquote, for near-term devices. So, we know those devices decohere, they run for some coherence time, then T1, T2, whichever noise model you have, turns everything into mush, and you end up with a classical probabilistic mixture where nothing quantum is sort of left. And so, people knew that right from the 90s on, that that's the fate of all things quantum unless you go and error correct them. And so, here's one simple thing you could do: is so basically you. One simple thing you could do is so basically you could chastise your experimentalists and tell them just build it better, build it better, build it better, and progressively make better devices and progressively have more coherence. And then you say, well, all computations I want to do, I'm going to do something simple. I'm just going to look at the coherence time that I have available on that device. And I'm just going to go that long. And then in the end, I'm going to do something really simple. And I'm just going to measure some expectation value. So all that I care about is basically I'll let the circuit run and the end measure some expectation value. Okay, that's the setting. Expectation value. Okay, that's the setting in which our quote-unquote algorithms are supposed to work. Now, the question is: is there anything interesting in that setting you could do? And yes, so there's been a couple of heuristics that have been proposed. So there are certain near-time algorithms where people essentially just proposed using a quantum computer as a factory for trial states. So you can do ritz minimization, something that's been known as VQE. You could try to look at some shallow depths, time dynamics, measure something in the end. Measure something in the end, and you get access to interesting physics stuff, like you get magnetizations, binding energies, and so forth. There are certain other things, sort of more in the learning, in the statistical setting, where you could try to use the quantum computer to estimate kernel functions, and those end up being expectation values as well. So, there is plenty of things one could try to do, and so forth. And so, we have in 2017 for a very, very tiny experiment. Very tiny experiment. That's essentially the experiment that motivated the work. I mean, it's kind of very simple. So it's just four qubits a depth to a circuit. And you would wonder, well, could I use that to compute the ground state of a four qubit map molecule? Right? And you do that, and you see the curve should be that solid curve at the bottom. And what the quantum computer produces, or the quantum device produces, essentially, are those dots that lie over that curve. That lies over that curve. And that's clearly not ideal. So it's actually quite bad. And the only insight you have basically is: so, where does that come from? Well, if you do a classical simulation and look at including all the noise model and so forth, you can exactly predict where those things ended up. And it's, of course, due to decoherence that it ended up being there. So if you look at that expectation value, what happens is now, so you're now in this restricted setting. And so how does decoherence sort of manifest? Does decoherence sort of manifest itself? So, formally, you can say, Well, decoherence introduces some form of a bias. It basically goes and turns some pure state into a mixed state that you would like to prepare. And that mixed state has an expectation value that deviates from the pure state expectation value. And so you produce something that's wrong. And so now, if you're sort of very naive like myself, you could sit there and ask, well, why? I did everything according to plan. I stopped the calculation before decoherence time. The calculation before decoherence time hit and so forth, and before the decoherence time was over, and it should have been still kind of good, right? And so, that is, of course, a very, very, very naive picture to have. Of course, it doesn't work that way that up until the declarance time, everything is hunky-dory, and from there on down, it immediately gets really bad. It starts to get pretty bad right from the beginning, and you have immediately an exponential decay. So, what error mitigation tries to do is sort of to make it look as To make it look as if you were in that naive picture. So, up to some coherence time, what you would like to do is to basically get correct expectation values up to the coherence time that your device is given. And then you don't care about going beyond that coherence time of the device anymore. So that's the entire setting. You have to come up with some trick to basically make that bias go better within the coherence window. And so that's essentially something we set out to do in 2017. So there's now To do in 2017. So there's now, of course, many follow-up error mitigation ideas and so forth. So those were the earliest two. And so we had some two ideas, and the goal was essentially just, okay, give me such a device with a limited number of coherence time. All I want to do is at the end of the computation, guarantee you that I've fixed the expectation value of my computation. Okay, that's my entire setup of this thing. Okay, so I already accepted defeat in the regardless. I'm not going to be able to extend the computation. This, I'm not going to be able to extend the computation beyond the coherence time. That's what error correction is for. I'm not going to be able to have correct states actually. So, my states are not going to be fine that I produce doing this. I'm just going to look for good expectation values on some states and so forth. And I won't be able to sample. I'm not going to get the right statistics of the device either. I just want correct expectation values after all that game. Right? And so, you could wonder: so, what are two ways to do this? Those are the ones we proposed. And so, we have Kristen, a quick question. Question: So, correct expectations for certain operators or for all operators? Ideally, for all operators. So, but this is a good question because some of those methods actually we drive some error bounds and so forth, especially for method one that guarantees, well, if you go this far for those kinds of operators, then this far, then it works for all operators. But it's actually, if you do experiments, you see that the method actually empirically works. You see, that method actually empirically works a lot better than that error bound would suggest for particular kinds of operators, i.e., in the first method for very local operators. They are then, then, if your operators are like low weights, then the method tends to work better than for high-weight operators, unsurprisingly. Presumably, if you could do all operators, the states have to be the same. Like, there shouldn't be any coherence if you want to get really no error. No, exactly, but I'm not doing this on a single-shot basis. I'll explain in a second. I only care about the expectation values. So, you can do like you can. So, you can do like, you can do tomography and then mitigate on the tomography thing. It doesn't mean that the state that you prepared is a good state. It just means that your expectation values and tomography that you get out of the device have been improved by some tricks. And I'll go through that. So, one trick, so we have two tricks. One is basically zero noise extrapolation. Basic idea, that's the one we've been doing so far experimentally quite a lot. What's the basic idea? Well, if you're sort of having some early stage numerics background and so forth. Stage, numerics, background, and so forth, you may be familiar with something that's called Richardson extrapolation. So, given that your expectation value, you treat your expectation value as a function of the coupling to the bath. And so you can show that that is, of course, an analytic function in that bath coupling, meaning you get to Taylor expand that thing. And once you can Taylor expand that thing, you can basically do Richards extrapolation, which is in the polynomial extrapolation, which basically goes and cancels order by order by order at that noise strength. That noise strength. Meaning, in that thing, you need to have the ability to basically tune that noise strength. And there are some tricks you can play this by stretching dynamics and so other things that you evaluate the same expectation mail at different noise strength. Then you look at a linear combination that basically cancels the first n plus one orders in the expansion, obtaining error bounds from basically standard Richardson extrapolation. And that works in practice. Up until the error bound, everything of course works because math. From the interesting thing. Math. The interesting thing is, if you go beyond that and you look at local observables, then it does apparently better than what you would have expected it to do. But that's not the method I'm going to be talking about. The method I would like to talk about is probabilistic error cancellation. That's the second method, which is experimentally a lot more challenging to implement than the first one. The first one already was pretty difficult, but you had to think about a lot of other things to make this feasible, right? And to get that. And to get that going. Okay, so what is the basic idea? Suppose in probabilistic error, the setup is the following: probabilistic error cancellation. Suppose you have someone gives you your circuit up to coherence time, whatever it is, and writes down a set of ideal gates. And you come to the realization, the only thing that you can implement are a bunch of noisy gates. So the naive first attempt, which is the one the way we presented in the paper, is you look at this and you come to the conclusion: well, what I can do, though, is I have a bunch of operators. What I can do though is I have a bunch of operators I can do now in all the places where I want to do gates, I can do complete gate set tomography, which means I'm going to measure a lot of different maps, TCP maps, and so forth, and I can actually measure sufficiently many so that they form essentially basis. So if I take all Clifford operations plus state prep for Clifford states, they form a basis. And I'm just going to go and measure their noisy version. So they're epsilon perturbed away from their ideal action. Then what I could do. ideal action, then what I could do is I can expand, because there are basis, linearly expand every clean operation or the full circuit, if you like, in terms of that basis. And so that is just a linear combination, but now you can sort of cheat a little and do the same thing that people have done for decades in quantum Monte Carlo and say, well, I'm just going to promote that to a quasi probability distribution by slapping the sign into the observable that I want to measure in the end, making renormalizing coefficients and then resampling that. Coefficients and then resampling that. Okay? And then allow you to sample over different instances of noisy circuits and basically go and produce a correct expectation value. So what's the nice thing about this? Christina, I want to ask you a quick question before you go forward. So these coefficients, do you find them by sampling gate by gate? I mean, this U presumably is a global unitary. And then a product of local unitaries, but yes, in principle, you would have to sit. But yes, in principle, you would have to sit down and go through every gate individually. So how do you build C of alpha from the gates? How do you build C of alpha from the gates? Oh, yeah. Basically, once you've perfectly assumed, I mean, this is the theory setting, right? So once you've perfectly assumed that you've measured your entire thing, then you just do a local linear, solve a linear equation that basically tells you on two qubits, this is how large you assume your gates to be. Assume your gates to be. And that basically gives you all the C of alphas in theory. Right? So, because I don't understand. O'1 into that basis. Yeah, I understand. But like the O's are presumably not given to you a priori. There's just some operators that are epsilon away from the true unitary. Right, right. Those experimentalists have to sit down and measure very, very carefully. I see. So, per instance, they can do a certain, I see, so they can do a bunch of measurements and give you like right on. And give you, like, write on paper what those O's would be, these non-unitary O's or close to unitary O's. But then that would be per given instant. Then you could probably say, I still don't understand. I mean, every time you do it, you get a different O, right? No, you get a map. So that's the same. You assume Markovianity here, right? So assume your noise model is Markovian and you just learn the noisy processes that you implement. So O-alpha is an operator. So, O alpha is an operator, isn't it? Yes, it's a TCP map. Yeah. Right. So, tomography on that TCP map. So, you look at a noisy version of, say, a of you want to do a C0 gate, but you do look at a noisy version of a CZ, for instance, because it's a different Clifford operation, right? But you do that for multiple operations on that thing. And then you have a complete basis written down on paper, and then you go and you decompose your C0. Then you go and you decompose your C naught into that noisy basis. And then you go and you basically resample those different noisy operations that you get to implement in practice. But I mean, maybe this is a simple misunderstanding I have. I feel like every time you want to run the experiment, you know, initialize and run, you would have a slightly different basis. No. That's a statement on average. I mean, you produce a noisy operation on average, sure. But like period. Right? On average, sure. Right, you only care about, you only care about the expectation value. That's the point. Uh-huh. So you're gonna, I see. So yeah, there's a step there, but I can't think about it to make sure that the output expectation can be obtained from the expectation of these. Correct. So what happens is that this sort of this circuit, which is a product of individual ones, is the one you want to apply. And that gives you, and you compute the expectation value of that, by linearity of expectation value. Value of that by linearity of expectation value. If I can't decompose u into the basis, a basic element, I can basically write that as a linear combination of noisy expectation values. Right? Maybe. I don't know. You'll see it. So, I mean, we'll do that. So, we actually do it in practice because we don't do that. We do a modification, which becomes a little simpler, I think. So, this is the case. No, no, no. This is a perfect thing. I just wanted to clarify. So, you pick your basis. The basis is fixed. You pick your basis. The basis is fixed, right? Right. The basis is fixed, Ramis. It's just a method. Oh, no, but you fix the basis. You don't learn the basis by doing experiments. But yes, you fix a basis that you learn. You learn the coefficients for it. You have a complete set of different unitary gates. Right? So I know cleanly I would want to have this set of, say, Clifford operations. So I have, I don't know, 200. So I have, I don't know, 200 something on my two qubit gates, right? And then I'm going to measure those noisy operations, because they're not going to be exactly CZs. And then once I've chosen, I've measured those CZs, say a CZ, CX, Hadamard, take your favorite pick of Cliffords. And then I basically, under the promise that you can show that, okay, there's some epsilon noise on this, there's a perturbation bound, they still form a basis. Now I've learned exactly. Basis. Now I've learned exactly what that basis looks on my device. And now I go, I decompose a clean operation. Yeah, no, that's that's clear. So, O's, uh, and you're not necessarily assuming O's are unitary or imperfect implementation of a unitary that remains unitary. They could be non-unitary, right? They're all non-unitary in the end. Okay, good, good. All right, they're because they're clarified. Okay, last last question: what's what's Question. Why do I have to put this sine, sine of alpha in? Because it's a priori, it's a linear combination over C alphas. Let's go a slide back. The only thing I'm sort of, I only have is basically, oh, these are a bunch of, you can show they're a bunch of real coefficients. Oh, I see. So they're not positive or negative. They don't form a probability distribution. But what I'd like to do is I would like to have a probability distribution there, because what I would like to do is. There, because what I would like to do is I would like to go and average over multiple realizations of noisy circuits. But wait, if you're allowing sort of arbitrary linear combinations, then a sign won't help you to render this a probability distribution. You also have a normalization issue. That's gamma, correct. That gamma is actually very important. Why? So the nice thing is that this thing on average completely removes all noise. thing on average completely removes all noise because you on average implement the perfect estimator which has the exact noise-free mean. Cruxes though, as with many of those things, you basically incur a sampling overhead which is given to you by the normalization. So if you have a sampling overhead that for every say for every individual operation that you do, you pay the price of one plus say order epsilon because you're Say order epsilon because you're epsilon away from the ideal operation. You can show that that's possible and so forth. And now, what happens if you do L operations? You have to pay the price 1 plus C epsilon to the 2L. So you have an exponentially growing sampling overhead in implementing that estimator, right? So you know that the mean is absolutely correct in terms of the bias. However, now the expense, the way that noise shows up here is basically in this increased sampling overhead, which is an Sampling overhead, which is an exponential increase of the sampling overhead. However, an exponential increase bar a sort of a small basis, one plus epsilon roughly. Okay, so nothing's for free. So, but as long as you say, well, if I go sort of order my operations of sort of L over epsilon, I'm still kind of good, right? So, I could treat this as a constant. So, I get to do sort of one over epsilon many, I get to do one over epsilon order one over. Get to do one over epsilon order, one over epsilon many operations, which is sort of consistent with that picture that I mentioned earlier. Well, there's a finite time, you won't be able to go beyond that time because if you go beyond that time, you have an exponential increase. Okay, to make it a bit more concrete, let's take like an extremely naive toy example. Suppose everything is clean, so let's make it even simpler. Maybe it becomes a bit clearer than about the bases as well. It's basically right, you're given a circuit, and I promise. You're given a circuit, and I promise you, the only point you shall be struck by noise is on the second qubit after the second gate, and it's exactly going to be depolarizing gate on a single qubit with noise strength epsilon. So how would you go and fix this? So the first thing you would do is, okay, look at this map. So one plus epsilon is perturbed away from the identity. So I'm just going to do something stupid. I'm just going to invert it. I want to imply the inverse map. So now everybody should scream. That is not a physical operation. Of course, it isn't. Of course, it isn't. But what you could do is you can look at this inverse map and promote it to quasi-probability distribution. There's a normalization factor, I have different p's. And now, if you look at that inverse map, which happens to be the inverse of a Pauli map, it's sort of, oh yeah, there's this normalization factor in front of it. There's a bunch of probabilities. And the way I implement that is with probability P1, I don't do anything, multiply whatever sample output I get with gamma. With probability P2, I'm just going to apply an X gate there, and so forth. And so forth. And that on average is going to produce the correct inverse. It's going to cancel what the noise did, and I'm going to have a pristine operation. So that's, of course, very, very naive, but just to explain what's going on. Okay? Okay. So now, what are real world challenges? So things, stuff doesn't look like that, right? So what typically happens is I have some gates, but in the meantime of those gates, I basically go and have idle errors, right? So even if I don't touch my gates, So, even if I don't touch my qubit, it just decoheres. So, it has to decohere in some sense as well. So, then the question is: do I slap that onto the next set of gates and so forth? But then, if I do the tomography, do I have to always wait exactly at the point of the circuit? So, it's really not practical. The other thing is, which is way worse, actually, is all these gates, I drew them naively on two qubits. What happens in practice is they have complete crosstalk errors, meaning you ring up a two-qubit gate and all the adjacent. qubit gates and all the adjacent qubits, they're part of your interaction essentially, because you have some leakage into those other qubits. So what happens if you start bringing up two gates next to each other, they start influencing each other and they become a mess. So actually you have to learn the entire noise model over the full entire chip. And in principle, if you go and tell an experimentalist they have to do full gate set tomography, even on two qubits, they run out screaming. So all these things really don't work. So what is it that we need? Okay, so what is it that we need? Well, the first step is we need some kind of very simple, very, very simple and very faithful noise model that is actually able to correlate those captured errors, has a very compact representation, you can efficiently learn it, and it's something called that spam robust. Because in the process of learning, you introduce a lot of other types of errors as well. So you have state preparation errors, measurement errors, and so forth that influence whatever you think your actual operation is. And is there a way to basically learn those operations spam robots? Learn those operations spam robust. But then going back to the naive picture, so that has to be now a noise model that's basically crossed the full chip. And now I have to go and invert it. And so if you want to go and invert that, you're inverting a 4n by 4n matrix naively, which is not very efficient and defeats the entire purpose of doing that. So you have to basically, based on the simple structure of that noise model, you basically have to be able to have some efficient version to To have some efficient version to sample the inverse, right? Those are all the problems, and that's what we're trying to address here. Okay, so how do you make that a little bit more practical? So, first of all, you look at sort of your standard circuits. So, your standard circuits should be cucked up out of, okay, there's layers of single qubit gates, which could be identities, and then there's layers of two qubit gates, which are U1, U2, U3, UL. And one assumption we have to make is that basically, oh, the noise that single qubit gates have. The noise that single qubit gates have, they're sort of independent of the type of single qubit gate that you apply, which is reasonably fair considering that Z parts, the experimental state, they're always sort of done in software, which means they have to do some basis change in the actual program and the evaluation. So that's fine. So yes, it's a fair assumption to basically assume they have the same noise. Then the next assumption is now you have these complicated, large two-qubit gates, which are the most expensive ones. And what you can do is you can basically slap that noise. What you can do is you can basically slap that noise from the single qubit ones into that larger layer of two qubit gates, and they're messy, right? They have crosstalk, they have idling errors, they have a lot of stuff, and they're really noisy, and they go across, say, this entire layer goes across the full device, right? So that's still a bit unwieldy, but now we can sort of do a trick that people have done since, well, since the 90s, actually. So Charlie was actually the first one to have done that. I should have put that in there, and that's called polytwirling. So what's the idea of polytwirling? Really simple, you insert before and after. Insert before and after the full gate layer. Noisy gate layer conjugate pairs of Paulis, they're conjugate by that layer. You assume that layer, by the way, is Clifford. So let's for now assume they're just C naughts at the moment. And then you have these conjugate pairs. And then what you could do now is you can randomly insert them and average over them. So whenever for every sample you get a new instance of the same circuit with a new set of Pauli spread out, you can basically absorb them into those single qubit operations. them into those single qubit operations and trivially you can basically write every noisy operation as a lambda one twiddle whatever it is that's the noise part times a clean gate by just whatever lambda one twiddle is by conjugating with the inverse right applying the inverse right so basically i think that basically answers my question like u two tilde is like a lambda two tilde plus two blue rectangles right correct and these are clean gates at the moment right Gates at the moment. Right. No, but this is, I mean, the question you had earlier, it's a different setting we're in right now. Right? No, I know. I know. We're really trying to understand we're trying to invert. So right now I'm even not trying to find a full basis. That was the basic idea. Now I'm just going to want to imply the inverse of lambda one. Yeah, so this has nothing to do with my previous question. So here, every one of these rectangles on top, say U2 tilde, is now replaced by a lambda two tilde plus a bunch of. Tilde plus two blue rectangles, which are clean ideal gate. Correct. And that's naive. You can rewrite it as you please that way. I mean, that happens. But then what I do now is basically you conjugate that. And so this is the same as doing this, because that's how you define them. You conjugate them. And then if you average over all those Paulis, what you do effectively is you generate a two design, right? Or and they basically go. And they basically go and they twirl the entire channel out. What you're promised is then that the resulting channel is of a particular form. So if you average over multiple channel uses, it's essentially just a pinching, if you want to. It's essentially a pinching of the super operator. But you do a pinching of the super operator so it's diagonal in the Pauli basis. That's what you do with this averaging procedure. And so that makes it something called, which is called a Pauli noise model. One of which, like, the simplest example is deep. One of which, like the simplest example, is depolarizing noise. That's like a completely flat Pauli noise model. But after this twirling and after this average operation, you're now promised: okay, the noise model that I have is just a classical mixture of Paulis that I apply. Right? And so you already, so looking at that, you sort of already immediately know what the some stuff. So one thing is, okay, it's just random Paulis that I insert. That's all that that noise model has. They can be correlated random Paulis, fine. But they're just random Paulis that are going to happen here. But they're just random Paulis that are going to happen here. The next thing what you're going to observe is you know that, okay, these things have sort of you already know what the eigenbasis is of those maps. The eigenbasis are just Paulis. And you have some real eigenvalue going from 0 to 1, between 0 and 1, a real positive eigenvalue between 0 and 1, and so forth. And the experimentalists like to call those the fidelities, okay? So, which means you now have the eigen decompositions. Which means you now have the eigen decomposition. So, in theory, you could go and compute the inverse by basically inverting all your all the fidelities that you somehow compute or learn or whatever, and then taking the symplectic Fourier transform that gives you all those coefficients in front of all those C alphas. So now you could basically renormalize them and so forth, but that still is not in the realm of feasible, right? Why? Well, because it's 4 to the n minus 1 different fidelities. Fidelities, and then you have to compute the Fourier transformer over that, so that's expensive, right? But at least you can write down formally: okay, this is the inverse. So now, now we get to the next part of the noise model. So now we know at least, okay, we're promised it's a Pauli noise model across every layer. This is the structure of the circuit. And what we want to do is we want to apply the inverse of that circuit effectively, okay? Fine. So if we do that, we have to cook up some model, right? And it's Right, and that model may be correct, that model may be wrong, but what we want is we want to have some form of a very sparse model, right? So, for to act on that device, right? And so what we do is basically, so we know it's a Pauli channel, I'm just going to assume it's going to be Lindbladian that is of Pauli form, right? So, my cross-operator, my Lindblad operators, they're just going to be a bunch of Paulis, and there's going to be some positive or non-negative coefficients in front of those Paulis. And in principle, you could. Those Paulis. And in principle, you could have all four to the n minus one Paulis sitting there. But what you can do now is you can impose a sparsity structure that is sort of physics motivated, right? So it's very unlikely that you're going to see an interaction sort of between all that is mediated by all qubits at the same time as the interaction term. So you typically assume, oh, there's some locality of the interaction, there's some locality in terms of the noise that's going on. And you basically make those assumptions. Basically, make those assumptions. And so you truncate, for instance, the weight of the Paulis. Say, suppose you only look at weight K or say weight 4 Paulis, and you include all the Paulis in the Landladian noise model up to that weight. So all the singles, they're fine, they decay. Then you can have adjacent two-qubit interactions. You can have like non-local two-qubit interaction that would push it up to n squared roughly. You could have n to the four, whichever it is. And now you have a polynomial set of numbers that determines that noise model. Right? And so there's another nice feature. Right, and so there's another nice feature. Oh, god, there's still a typo in there. Okay, never mind. Um, so there's another nice feature. If you look at those, in terms of operate, in those Pauli individual summons in the Pauli land body, they commute. Right? So you know, if I look at the exponential, it's just going to be a product of individual Pauli channels. So the row should be outside of the brackets. That's kind of wrong. Sorry. So it's basically the product over all the k element k. I have a row. So omega k, I apply the identity with. I apply the identity with 1 minus omega k. I apply a pk Pauli to this entire thing, right? And that's the noise channel, and all of those individual probabilities, which are like a binary outcome, they're given to you in terms of those WK. So it's a very, very simply structured model. And I can efficiently, by the way, sample that model by itself as well by just tossing a bunch of coins. Okay? Fine. So that's the model we're just going to go with. And now the question is, is that a legitimate model? Question is: Is that a legitimate model? Can you worry about that and so forth? Can you learn it and so forth? And the nice thing is: so, let's start with generalists. So, it's pretty neat to have a Pauli channel. This is why the experimentalists care so much about those fidelities, because you can learn all those individual fidelities from the exponential decays by applying the channel multiple times. And the nice thing is you get multiplicative error approximations to those fidelities doing that by iterating, looking at the decay, and fitting a decay. Iterating, looking at the decay, and fitting a decay line. And you get a multiplicative error approximation to this entire thing. And in particular, it turns out that the spade preparation and the measurement errors, they factor out. And so there actually you learn those decay lines of the fidelity sort of spam-free. The only crux is we don't get to apply that noise channel by itself, right? Because it's a noise channel that only comes in conjunction with the actual gate that you want to apply. So, however, if you look at However, if you look at certain Clifford, noisy Clifford operations that have the ability that they square to the identity, you could basically say, well, at least this way, I'm just going to apply it twice, I'm going to get back to where I want it to be, but I'm going to learn now the product of those fidelities. And you sit down, you realize, okay, that's not enough because I'm only going to learn certain products. But then you can play around with this a bit and you could say, well, at least I get single qubit operations for free and basically can go and basically learn all those single qubit operations by inserting more and more. Single qubit operations by inserting more and more single qubit operations into that circuit, randomize and choose different realizations of those and find different products. And you realize, okay, that's cool. I get a lot more. I'm still missing two. And it turns out, so there's two things you can do. Either you go and you make a symmetry assumption and assume that a CZ gate has the same error model than a CX gate, which effectively amounts to that symmetry assumption, or you basically bite the bullet and do a The bullet and do a spam-dependent approximation that you're going to have, and are really, really careful about the spam errors and look at certain other ways of dealing with them, which is also what we've done. So, we've done both of those things in experiment, okay? Both of them proposed, we do them, okay? Fine. Now you have a set of those fidelities. And since the model is so neat and nice and simple, what you could do is you can actually now try to say, well, I give you a list of those fidelities. List of those fidelities, given with that list of fidelities that you have, let me compute them for you with the model. And you see, oh, it's just the exponential of a set of those lambda k's, which are exactly the lambda k's that contribute by anti-commuting to that one fidelity that we want to measure corresponding to the, say, for Pauli, PA, the fidelity is basically all the lambda k's where the pK Pauli anti-commutes with the A Pauli, right? So there's a very simple. A poly, right? So there's a very simple structural relationship between the f's and the lambdas, and you can express that essentially as if you take the log of those fidelities, it's just a 0, 1 matrix, so it's a linear system of equations. And you can take a lot of them. So if you take sufficiently, if you measure sufficiently many of those, you can ensure that you were going to have a full rank matrix, binary matrix M, sort of that recovery matrix. And you can also go beyond that and measure more. You can also go beyond that and measure more. And the recovery procedure is then something called positive least squares that you can do. So, the only constraint you impose for that very, very simple noise model is the fact that all those coefficients be non-negative. And then you do your least squares optimization subject to that constraint. And that is, for instance, I mean, all of those things I show, by the way, they're all experimental data. Maybe I should say that. So that's some recovery on 4Q. So that's some recovery on four qubits they could have done. So there's two CNOT gates, those two gray boxes, and that's the recovery on those four qubits. Fine. Now you've recovered your noise model. So you could wonder, like, how well did you do? Right? So the first test is now you basically go, you learned your Lambda case, and you wanted to learn, you check your model. And since it's only four qubits, you can really go and measure a lot of fidelities for those four qubits. And you can wonder, like, how well does And you could wonder: like, how well does my model, after having learned it, actually predict the model that if I were to measure it directly? Right? So, how well does my sparse model predict the actual physical fidelities that I could have measured? So, the eigenvalues of that noise channel. And so, this is that experimental plot, basically, where you see, well, blue one corresponds to directly measured fidelities, whereas the green one corresponds to the sparse recovery of those fidelities. And then there's some neat little error bars around that. And you can also sit down. And you can also sit down and try to prove error bounds on those. So, assuming that this noise model is true, you can roughly give error bounds in terms of what your expenses, sampling cost is of learning each of those fidelities relative to that rank of the matrix that you've recovered, and how many of those fidelities you try to recover, depth of the circuit, and so forth. So, that gives you a multiplicative error bound between. Bound between the correct fidelity and the inverse of the fidelity that which we'll effectively be needing. Okay, so and also you can also basically derive a bound on what the true gamma is relative to the one that you're going to be working with. Okay, so that's fine. Although that one is not that much interesting. So you have that roughly that learning bound for that sparse recovery model. Okay, fine. Now that we've done that, we've done that for four qubits. Let's try to go bigger. Go bigger, right? So, you could, you know, if we start to restrict this entire thing and we're going to say, well, I all that I care about are effectively single qubit and nearest neighbor two qubits according to the chip topology. Does this do well? Right? And so we set that out, we did that, and the nice thing is the entire thing scales sort of linearly in the number of qubits for you to recover that. To do the sparse recovery takes linear time in the number of qubits, because this is how many terms you have. So, like, you could per link, you could count. Per per link you could count per per yeah, per link you could count roughly order 15 Pauli pairs, right? So and it scales with the number of links. So fine. A nice thing is also there's you only need to actually the number of different basis settings, which Pauli basis you work in remains constant. So you can cover that essentially for arbitrary size. So we did that and so that's sort of some experimental result to find. Okay, now does that does that tell you anything that that that um that that say that say the physicists what that they care about right so there's some some nice thing that you can look at so does that what what that model tells you captures actually very interesting aspects of the um of the noise right so suppose you have um uh you look at this thing for say an experiment for seven qubits right so you have like two c naughts that act on one four and ten twelve and then you have some idling qubits that don't do anything in the meantime and they they defade anything in the meantime and they they defase and they decohere and indeed if you start measuring that um that um that noise model you see in the single qubits sort of 0 7 and 15 there's a strong lambda z component so it's the z Pauli in your in your in your in your Pauli a noise model that has has a pretty significant contribution and the capable experimentalists on our team they identified oh this is dephasing noise due to coupling to the to the adjacent qubits and so forth and their system Adjacent qubits and so forth. And there's a trick that they always do use and do, and that's essentially dynamical decoupling, which is basically a control-theoretic trick where you start pulsing and canceling, sending echo pulses that basically cancel those interactions out. And the nice thing is you could now learn the same layer with dynamical coupling, decoupling applied. You can already see, oh, yes, naively, that naive picture that you had about that Z Pauli being responsible for that is actually true. And that Z Pauli error basically is massively reduced due to. Basically, it is massively reduced due to dynamical decoupling. So, that noise model seems to actually really capture the chip pretty well. Okay, so now that we've learned the noise model, we actually want it for the main point of the talk to mitigate with it. Okay, so what we have to do is we have to compute the inverse of that noise model. Since they're, of course, trivially products, then, of course, you just indivert every factor individually, and the only two points where they differ is effectively in that. Is effectively in that minus sign that you get here, so it's not a physical map anymore, and that normalization factor gamma. So now you have computed immediately what the inverse is, and the sampling overhead, that gamma is just the exponential of the sum over all the lambda k's that you measured, two times the sum over the lambda k's that you've measured. That gives you essentially the sampling overhead that you're going to have to pay. Okay, and the next nice thing is because it's so simple, that noise model, it immediately tells you how to sample the end. It immediately tells you how to sample the inverse, right? So, for k-Pauli terms, you basically toss a coin from k equals one to order k, right? Record how many minus signs, like how many Paulis that are not identity you've applied, go through that entire list, multiply that entire list out to a single Pauli, compute the parity, report gamma, and insert that random final Pauli in the place of where the inverse should have gone, and then you average over those instances. Right, and if you do that, you multiply. Right, and if you do that, you multiply the output by minus one times gamma, whatever sample you got from the measurement that you wanted to have done, and that average should, in order, gamma squared, like yeah, gamma squared divided by, say, epsilon squared, many samples converge to the exact correct noise-free expectation value. Okay, so far, so good. Any questions at that point? Nope? Okay, now I'll carry on. Okay, so what you can do now is basically: okay, we're in this setting. Any circuit can be basically phrased in that context. You have the map, you have the inverse map, you have the unitary in front of it. And you can then in the end guarantee by how much you basically deviate from the exact expectation value with your statistic that you've just proposed over multiple samples over the circuit. So there's one trivial triangle inequality. There's one trivial triangle inequality involved, which is basically how wrong you measure the noise model relative to what the true noise model is. And that is a C L tau epsilon. So that grows also exponentially with the number of layers that you have in your circuit. But the base C epsilon tau you can make as small as you like by being more and more careful in your measurement. And then you have the exponential growth in that gamma factor, which is like the product of all those individual gammas. And so it's an exponential of So, it's an exponential of a set of really small numbers, right? And that's roughly what's behind that entire bound. So, now you have a guarantee. So, I have to measure this well versus I have to take this many samples in the end, and you produce a correct error-free expectation value. Okay, so let's do this for some simple thing in practice and see whether that actually works. So, what you can do, what we did is we just did an easing model, 1D easing chain of going up to what is it, 10, 12 qubits or something, and a given depth. And what you do is you have those alternating chains, basically, odd even within that depth of a certain number of charter steps. It's a pretty coarse one because we don't really care about the trotter error because we just want to compare exact circuit versus noisy circuit and see what it does. And see what it does. So let's do this for four qubits first. So in the experiments, you look at sort of the dynamical curve that you trace out under the easing evolution, sort of in the equator section, or, well, I don't know what that's the equator, of your bloch sphere. And you basically follow that trajectory. And this is what the ideal trajectory should look like. If you do a lot of cleanup operations that the experimentalists like to do, so you already do the Pauli twirling, you already do dynamical decoupling and so forth. You fix readout errors by some. Forth, you fix readout errors by some readout error mitigation scheme and so forth. This is roughly the curve you end up with, right? So, and this is, I don't know how many steps we did: one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen trotter steps. So, 15 times two layers is 30 layers. So, if you count, it's a depth, in this case, it's a depth 30 circuit on four qubits. Okay, fine. But you see then, okay, yes, decoherence does something to the curve. It basically Does something to the curve, it basically pushes it to be closer to becoming the maximum mixed state. Or having like single-qubit mixed marginals, that's probably the right statement. What we're looking at is sort of the average magnetization across the device. Okay, now if you go and apply this error mitigation method, you essentially go and within the variance, so those shaded regions, they're recovered from. They're recovered from bootstrapping and so forth, within variance. You recover actually the exact curve as you would have expected it to be. So there are some other metrics you can look at, error-mitigated versus non-error-mitigated curves in terms of the relative error that you occur about that single qubit expectation value, and so on. But the interesting one is basically if you look at higher weight observables. Observables. So the premise was basically that that method bar that exponential, weekly exponential sampling overhead, allows you to basically produce correct and exact expectation values. And so what we do is now let's look at 10 qubits and look at something that is very noise sensitive. So it's basically a very high weight parity function. We know high weight parity functions are very, very noise sensitive, even like just classical bit flip noise and so forth. Let's see how they fare. And so what we do is we do a treader. Right, and so what we do is we do a trotter evolution on 10 qubits depth 7, so that's a depth 14 circuit, so 10 qubits depth 14, so still pretty manageable. On one end, you compute what you would expect the classical evolution of that parity thing to do, a parity function to do under the transverse field easing evolution. And then the experimentalists go and measure, and so for the first step where nothing has happened, things are still fine. Where nothing has happened, things are still fine, and so forth. But you can see that the signal dies off really, really significantly, pretty fast. So at the end, you're close to something that's pretty much flat. See, the error at the bottom, the residual increases, and so forth. However, if you apply the error mitigation method and apply readout error mitigation and so forth, you actually go and recover the exact signal from that, right? Bar the exponential sampling overhead. So I think that's it. I don't know how I'm doing on it. That's it. I don't know how I'm doing on time, but yeah. Great, you're doing very well on time. All right, any questions? Oops. No questions. All right, well then. Thank you, Kristen. So it actually brings us to the end of the conference. And I'm supposed to give some closing remarks. So let's thank Kristen for his talk. You can react, I can clap for you. Thanks. And I mean, so thank you all very much for having taken part. Especially, I want to thank the organizers, especially Jeff Shanker. Simone, thanks for being here, despite all your big time difference that we've had. And Cecilia couldn't make it. And Cecilia couldn't make it. And since Simone was very excited about closing remarks, I did a bit of preparation to come up with some closing remarks. So it was a very exciting week for me, at least. I hope it was for some of you as well. I learned a lot. So we explored, you know, probability and quantum information and two themes that emerged were randomness and dissipation and the potentials they offer. So with randomness, quantum complexity. Do you guys see my screen? I hope you do, right? Okay, good. I hope you do, right? Okay, good. Yes, I do see. Yes. Thank you. Thank you. Wonderful. So, with randomness, we saw that it touches quantum complexity. Powerful circuits seem to be random. The cryptographic applications. And there's an inherent robustness in terms of when you want to implement a gate, if it's from a random ensemble. And we learned a lot about dissipation and its applications, like to error mitigation, usefulness, fixed points, like forcing certain dynamical maps to give you the tape line. Certain dynamical maps to give you the type of answers you like, preparing ground states and quantum algorithms, for example, Wilson's talk, as well as Vladimir's talk. So, there are certain questions that jump out, and I think they have a future in the next few years. I personally would love to pursue them more and with you, perhaps with you, and I hope you are interested. So, you know, can we buy task one of error correction and push error mitigation and dissipation techniques to do useful tasks without realizing full possible? Useful tasks without realizing full fault tolerance. Other near-term quantum algorithms, besides the two we heard. So there was one by Vladimir Koropin and one that was a joint work with Olis Schenko that Olis talked about. But I suspect there will be other interesting things we can do. And generally using quantum dissipation for technologies, perhaps by designing the dissipation or even better, unwanted dissipation that we encounter when we do quantum processing. So we have just scratched the surface, but some topics that did. But some topics that did come up during this conference were erodicity, open quantum systems, quantum algorithms, spin chains, generic quantum quantum circuits, K design, Markov chains, and classical quality. So if you went to the very first talk by Mario Segedi, he told us how, you know, certain like random quantum circuits and other techniques that might come from quantum motivate a very beautiful classical probability. Classical probability theory questions. Localization that India talked about, quantum circuit complexity that Nick talked about, NISC algorithms, transport that Marius talked about, chemistry and quantum channels that Jared McLean and Priyuhaimuri talked about. So there's like a lot of interconnected ideas that come together when you think about randomness and dissipation. So this was a lot of fun for me. And I want to thank you all. And this was a lot of fun. We should thank. And this was a lot of fun. We should thank first for hosting this. Unfortunately, we couldn't be in time, but it was nevertheless a great meeting. So we are 10 minutes early for finishing. Whoever wants to make a comment, say anything. I want to make a comment. It was a good conference. I learned a lot. It was highly educational. I'm really grateful to the organizing committee and to Professor Mavaso. Thank you. That's very nice of you. That's very nice, Avi. Thank you so much, Blademer. I mean, your participation was very valuable too. We learned a lot from you. Okay. Okay. Thank you all. Have a wonderful weekend. And again, thanks, everybody. I really enjoyed this. Hopefully, we can do it again. Thank you very much from Simone and Jeff. It was another person, I thought. It was another person, I thought. Yeah, she has another conference right now, she's organizing another conference, so she couldn't be here, unfortunately. Um, but she wanted to be here. Um, but you know, she has she had committed to something else, so we're just lucky to have her on the list of organizers despite her busy schedule. That's heavy multitasking, organizing two conferences at the same time. Yeah, that's right, that's right, that's right. Yeah, it was wonderful. Thank you. Thank you so much, Bruno. It was great seeing you. Thank you so much, Bruno. It was great seeing you. Bye-bye. Bye. Simone, I delivered the closing remarks.