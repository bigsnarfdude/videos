Thank you very much for kind introduction and also I thank the organizers to be here for the this wonderful city, Hansu. So this is the third part of the lectures, first given by Jiang Kritov on Monday and then on Tuesday it was given by Chen Ning Gu and then I continue. So I give slightly more So I give slightly more specific title, but this is application of what Chenin talked on Tuesday. So he talked about the convergence rate of the diffusion coefficient, which is written in terms of some variational formula and some a kind of Dirichlet form, but on the infinitely many. Infinitely many particle systems case. Then he discussed the convergence rate from the finite volume. And it plays a very important role in my talk, actually. We can give so we consider non-gradient and so in his ca he said the uh exclusion process with uh speed change, but uh I I call it this a Kawasaki dynamics, which which is A Kawasaki dynamics, which is essentially the same in the next slide. So, this is a joint work with Chen Lin and also Han Wan, as he said. And then also PD part, I work with Hyunjun Park. He was a student at KAIST, but he is now in Tokyo. And then I also discuss a fluctuation problem that is derivation of the stochastic PDs. I'm working with Claudio Randim in Impact. With Claudio Randim in IMPA and also Sundasses Raman and Arizona for that part. So let me start. So my motivation comes from physics literatures. And actually I discuss sometimes with Kawasaki, who was a Japanese physicist. And he discussed the so-called dynamic Uh the so-called uh dynamic phase uh transition or phase separation. And uh uh we understand it uh from the microscopic interacting particle systems. Uh it is actually very simple in our case. It's a random hooks on the lattice uh as uh Chen Jin discussed. Uh but in our case we put uh some uh also the creation and annihilation effect. Uh in his case he considered just uh uh He considered just uh a conservative system. It's a particle number was conserved, but uh I add some effect of the creation and adherence. And then uh we observe uh autonomous separation into uh dense and phase uh sparse phases. We consider uh some very specific creation and ancillation rates. Then uh we can realize the situation that uh uh then Dense and sparse phases are stable. So this is just a picture, just an image. So we have a dense phase for the interacting particle system which are moving and also sparse phases and it is separated by some interface. It is not so clear at the microscopic level, but if we move to the macroscopic level, we observe very sharp interface. And the problem is to find out And the problem is to find out the time evolution of the gamma gamma t, which I call the interface. And so we first discuss the Loblarge number, that is the derivation of such kind of interface motion, and actually we can derive the unisotropic curvature flow at the microscope level. And if we so we actually consider the non-gradient model. Gradient model. So, as Chen Lin discussed, and also I think I commented a little bit after his talk, there was Vardan's argument. But his argument is only good for showing the qualitative homogenization. That's just converging to this kind of motion. However, as changing this. However, as Cheng Jin discussed, we can also derive the quantitative hydrodynamic limits. That we can give a convergence rate for this low-rise numbers. That is, I think, quite new for the non-gradient case. Okay, so there is a simulation, so please start. That's a very simple video, but it is made by all. It is made by Otobe, who is my colleague in Japan, Shinshu University. So please click it. I hope you can get some image from the video. So we consider on the lattice and the lattice sides, one side is two hundred, the other side also two hundred. And the blue blue part uh the there are particles at the blue part and the yellow part no particles. So Yellow part, no particles. So we we consider under the uh exclusion rule, therefore only one particle can occupy each side. And uh maybe in the middle some vacant side after sorry, maybe this one, maybe here, vacant side, this uh after after annihilation of the particles, but anyway, uh starting from sharp interface uh the boundary becomes uh vague and vague at the Boundary becomes vague and vague at a microscopic level. But we consider a huge and should be very huge. Then we will find some sharp interface in the limit. Maybe you can start again, please. Okay, thank you. So the blue part is occupied by particles at the time zero, and then of course the particle uh just making random walk and some some place it disappears and uh some place it uh uh just created. Place it just created, therefore, you see something like this. But we see, we will observe very wide, very big regions, therefore, in the limit. Oh, thank you very much. So, maybe, ah, okay. So, okay. Please go back. Then, okay. Then I will discuss. So, this is a robot number. Therefore, we have. We have a very very sharp. So get uh so this is random system because uh essentially it is random works, but interacting random works. So uh but uh limit gamma t so uh is uh uh deterministic motion. So actually I didn't say but uh there is a den uh density threshold. Uh so uh the dense uh the dense area the average density is say low plus and uh the spin. low plus and the sparse area, avalid density is something like rho minus, then in between you have a density threshold row star. And if the region that the particle density is bigger than rho star at the time zero, then immediately it goes to this situation. And if it is below, then it immediately goes to this sparse region. Then afterward we observe this gamma T. But gamma t is the But uh gamma t is deterministic, therefore it is a low-large number. Then the next problem is to discuss the fluctuation of the interface. So this part I work with Claudio Randim and also Sundases Raman. And in this part, at the moment we discuss in a very simple situation. And the interfa we assume the interface is just a flat flat surface or the Surface or the essentially we discuss two decays or the one decays, then the interface is a single point. Then at the low large number level, this is just a flat surface. So we consider very simple situation. Then we don't see the fluctuation. To see the fluctuation, we have to stretch, stretch the to the normal direction. So interface is originally very, very small fluctuation. Generally, very, very small fluctuations like this. But if you stretch to the normal direction, you can observe some fructations. Then we can derive the some at the moment we can derive the linear stochastic PDs, but I have some conjecture to derive nonlinear stochastic PDs also. But we don't reach to that level at the moment. So in the first section, I In the first section, I introduce a model which is called the global classic dynamics and the scaling. Scaling was already discussed by Ben yesterday. Also, in the second section, we studied the quantitative hydrodynamic limit and the derivation of the interface motion. This is a localized number part. And then finally, we will discuss the fluctuation of the interface. Uh the main part is uh to prove the uh Boltzmann-Gibbs principle. Boltzmann-Gibbs principle. I want to explain shortly for this what does it mean. At the moment, we can derive only the linear stochastic PD, therefore it corresponds to the central Linux theorem. Okay. So the Grauber Causal Dynamics was introduced first by Grauber already in 1963. So he introduced the Grauber dynamics. He introduced global dynamics as a time-dependent model associated with the easing model. But in his case, there is no conserved quantities. But shortly after, Kawasaki introduced, maybe three years after, so he introduced some conservative dynamics corresponding to the easing model. So this is a time-dependent easing model. Okay, so we consider this mixed Consider these mixing to these effects the particle systems. Global Carson Dynamics is originally a dynamical easing model. However, easing model case, we usually consider plus one and minus one, but you can switch to zero instead of minus one, and we interpolate, just interpolate. So we consider on the lattice, but for simplicity, The lattice, but for simplicity, we consider under the periodic boundary condition. So we call T D N that is discrete lattice, but side language is capital N and we consider in the D-dimensional case identifying with the boundaries. Then x from this lattice point, so we denote by eta x equals 0. we denote by eta x equals 0 or 1. The eta x equals 0 means there is no particle at x. The eta x equals 1 means there is a particle at x. So we consider under the exclusion exclusion rule. So this is hardcore interaction. Therefore only one particle, at most one particle can occupy each site. Then discuss a zero range process. Then you can allow to to put You can allow to put several particles, but here I only consider under the exclusion rule. This is actually this random walk part is conserved, the particle number, and it corresponds to the Kawasaki part. And uh creation and annihilation uh part correspond to the global. Global are just uh uh considered uh sometimes uh plus one spin Sometimes uh plus one spin flips to minus one spin and also minus one sometimes flip up to to plus one. But uh in our case uh zero flips to one means uh uh a particle is created at a point x and one to zero means a particle is annihilated at a point x. So uh we just interpret in that way. So we we just we we think uh we consider the same dynamics but uh just interpretation. It's Just interpretation, it's the viewpoint of the particle systems. Okay, then Chen Lin already explained C X by eta. This is the jump rate or the jump speed. So if C so we we so to d to define the dynamics, maybe it is better to write down the generator, but uh I I just write uh jump rate, C X Y. The jump rate, CXY, eta. And also Ben also explained about this, how you can associate corresponding dynamics. So anyway, if C is large, then the particle moves much faster. If C is small, then the particle moves slower. So th it is controlled by this uh jump rate. And it depends on the uh configuration eta so A configuration eta. So uh eta was uh this one. So e uh so we call uh uh zero one to the power uh TDN. This is uh called uh configuration space. So this covers all possibility of the uh particle arrangement. Then uh uh the element of this one is called eta. Okay, then then uh C actually depends on Then uh C actually depends on the eta. So this gives the interaction not only the exclusion rule but also so the jump rate depends on the eta means uh uh it is affected by the other configurations. But eventually we assume it is a finite range and also translation invariant. But anyway, there is an interaction among the particles that is designed in this jump rate. And the jump or the And the jump or the maybe exchange between the X and Y, so that that was also explained by Chandlin, is happens only in the neighboring side, only in the neighboring side. The particle may jump only to the neighboring side, not to the far away point. And also, as Chen Din explained, we assumed so-called detailed balance condition with respect to the Bernoulli measures. Bernoulli measures. Bernoulli measure is just a product measure independent if the site is default. But it is parameterized by the particle density law. So the invariant measure or the reversive measure is not unique in this because we have a conservation law. So it is not unique. That is quite important to discuss the hydrodynamic limit. So it is parameterized in in this system by the macroscopic density law. Macroscopic density row. In our case, so maybe we can generalize maybe to the Gibbs measure, but at the moment we consider very simple situation that the invariant measures, just a product measure. And the main point, one of the main point is we consider the current. Current is just jump rate from x to y minus y to x. And we consider in the symmetric case, this is Symmetric case, this implies the symmetricity. Therefore, the average of this quantity under this measure is zero, always zero. However, later we introduce some time change. Then if this satisfies the gradient condition, which is written in this way, maybe also Chandin explained already, then it's a bit easier to discuss. However, if C. Discuss. However, if C, in general, C never have this form, this is a very special case for this particular system. But we don't assume anyway. In this talk, we don't assume this is not of this form, but in general form. That makes the problem much harder. And okay, so without assuming. So then for the grava part, the grava part, we have a flip late CX. We have a flip plate, C x eta. This is a flip plate at point x. Flip plate means eta x flips to 1 minus eta x. That means if eta x equals 0, then this is 1. Or if eta x equals 1, then this is 0. So this one just governs the rate of the creation or annihilation of the particles. So sorry. Sorry, the particle system is determined by this jump rate and also this one. And as I said, we actually designed this flip plate in a specific way, maybe I will explain later, to favor two levels of the particle densities, rho plus and rho minus, which is called the sparse and dense phase. But we have to choose this frequency. Have to choose this flip late in a specific way to realize this situation. Then we can discuss the phase separation phenomena. And also, maybe I will explain later what does it mean. Two phases have the same degree of the stability. It is called a balanced case. Maybe. So anyway, I will impose some conditions for this flip late data. Then we Then we introduce the scaling from microscopic to macroscopic. So by these two rates, we can define the actually it is a finite volume. We consider on the finite volume. Therefore, ether, the configuration space is just finite set. Therefore, this is a continuous time Markov chain. A very simple object is essentially. Then we Then uh uh we introduce uh time change for the cover circuit part by putting n square. We speed up uh by putting n square for the this is the usual diffusive scaling or the parabolic scaling for the cosic part. On the other hand, we also speed up uh the the global part by putting k, but k depends on n. So uh also uh depending on uh n is the uh space size of the k. Space size of our lattice. Then depending on n, also k, k is a function of n, therefore, also k, depending on n, it goes to infinity actually. But it is much slower than n square. So n square moves much, so the random walk path moves much, much faster. Then much slower we move the creation and annihilation effect. Then we consider the macroscopic We consider the macroscopic empirical mass distribution defined in this way. This appeared already in the, I think, a bench talk and also a change in stock. So we introduce a time change in this way and also spatial change scaling in space. Space size is scaled down by putting 1 over n here. So originally it is very huge. However, we just scale down. We just scale down by dividing by n to the macroscopic size. That is given here. And also originally the particle had a mass 1 microscopically, so 0 over 1. The whole particle had a mass 1 microscopically, but we divide it by n to the d. Therefore the particle uh mass becomes very small. But the totally it should kept at the macroscopic level. At the macroscopic level. So the goal is to to study the limit of this uh macroscopic empirical mass distribution in what happens uh when n goes to infinity. Then okay the main result is this one. The main result for the hydrodynamic limit is this one. And uh uh the particles autonomously make phase separation. I I didn't say any condition for C C X. Say any condition for C C X, but under proper choice for that CX. We have this situation, and by this scaling from microscopic to macroscopic, we observe an isotropic curvature flow. So we have this macroscopic empirical mass distribution determined from the particle system. Then I I will explain w what is this one in the next page. what is this one in the next page. But uh uh it converges to the uh this is actually the uh step functions separated by this interface gamma t and it takes value rho plus or rho minus. And then in this sense, weak sense, we we multiply the test function, which which is a C infinity and this bracket means the integral by this measure, and also integral of this one. integral of this one and this converges to this one converges to this one in probability but we have a convergence rate convergence rate means that usually we can prove this goes to zero that that is a convergence in probability for for every epsilon positive and this converges to zero means uh just a convergence in probability but uh we can give the convergence rate so there exists some So there exists some kappa positive and some constant C, then this probability is governed by this one. So it converges in this way. And up to time t, and t is maybe explained in the next page. So in this way, we can show that macroscopic. There is a phase separation and phase separation. And the phase separating interface moves according to the isotropic curvature flow. Actually, we assume some entropy, so initial distribution, we need some condition that is maybe a bit technical, but maybe we need some conditions. But anyway, and also we have to K K N is the the time change. uh the the uh the time change for the uh Grava part, uh which is uh uh should co goes to infinity, but it should be uh the order of the log n. So di to derive this bound, uh actually I need uh what changing proved so the convergence rate for the uh the diffusion coefficient. Then uh uh we can realize this one also. So Okay, so uh I want to explain what what is uh this limit, uh g xi gamma t in the next page. So this uh as I said this is uh uh just a step function. Say the uh there is a phase separation curve or the in the 2D case or the surface hypersurface in the D D dimensional case. It is separated by this uh hypersurface. Say inside takes the value of the rho plus and outside it is rho minus. And the evolution of the gamma t is given by this equation. So v is the normal velocity of the gamma t from row minus side to row plus side. So v is just the velocity, h how gamma, the speed of the gamma t from the row minus side to low plow plus side. The rho minus side to Lapla side. And it is given by minus trace of the mu of n is unit normal vector to the gamma t to this direction and given in this way. And the mu n is determined from the Kawasaki and Global flip rate and the exchange rate. We we have an explicit formula for for mu. For mu. So maybe I make a comment that n is so if you if you introduce assigned distance function from gamma t, so this is actually so maybe I want to give a comment that if mu is uh just uh identity matrix times some constant, then th this is nothing but the mean cover flow. H however, it it is more complicated. However, it it is more complicated. So why di uh di in this case uh this one is a ma mean curvature flow? Because uh if you consider the distance fun so if you uh on the gamma t distance function is zero and uh inside rho plus maybe distance function is positive, at outside it is a negative. Then uh if you consider the gradient of the distance function then it gives uh uh it gives a uh unit normal vector on gamma t. And therefore this one, this one is given as a Hessian of the distance function. Then the eigenvalue of the Hessian gives us just a curvature. And therefore if you take a trace, so in this case this is simply just a diagonal matrix, therefore you have a sum of the carbon. you have a sum of the curvatures for the uh uh d minus one curvature one curvature is zero should be zero to the uh however uh otherwise so if the trace you take a trace then you have a uh just a mean curvature however we have uh some extra effect coming from in fact uh a non-gradient effect therefore this is uh uh this is uh anisotropic um unisotropic uh motion by mi uh motion and by curvature. And uh from the gradient case we only get uh this type of the uh coefficient mu. However for from the non-gradient case we get uh much more general uh result. Okay and also uh I didn't explain anything about the balanced condition but uh unbalanced case unbalanced means Unbalance case, unbalance means maybe rho plus is much stronger effect than rho minus. Then gamma t just expands to outside. In that case, we can derive some constant. So gamma t moves to the con with a constant speed to outside. That is Hoyen's principle. This was also discussed, but this was discussed only for the gradient case. And also growing. Also, uh growing interface pro maybe uh I want to also I don't succeed yet, but uh maybe uh this case is related to the derivation of the uh KBZ equation in the if we can succeed to derive something non-linear in the fluctuation part. But uh at the moment I I don't I don't succeed quite well. Okay, so then how yes KP's equation case. So maybe I will touch maybe at the last point, but at the moment I don't have any result, any rigorous result. Can you tell me about the assumption on those rates functions, CXY and CX? C X Y is okay, so C X Y is maybe C C X I don't know. Maybe C C X I don't say anything, but uh for C C X Y I assume the detailed balance condition. This is this doesn't depend on the C eta X and eta Y, then Bernoulli measure becomes the invariant measures. So we assume this one. Yes, sorry, so maybe finite range and so in the bottom I wrote and also for C X I So and also for CX I have to assume. So that that that is important but I don't say anything at the moment. Maybe in the next page I think. Ah okay so the proof for the proof so I want to touch the proof of this result. So then the proof is separated into two parts. So first we approximate this one by the solution of the certain nonlinear PDF. Solution of the certain nonlinear P D. Then afterward, we take so nonlinear P D still have some diverging factor. Then we want to study what happens for this nonlinear P D. Then that is a P D problem. Okay, so the proof is separated into two parts. The first part is just this defined from the particle system, can be approximated by the solution of this. The solution of this nonlinear PD. But it still contains some diverging factor K here. So this part is coming from Kawasaki, random work part. And this is coming from the global part. And yeah, Chandin wrote in this way. So what Chandin discussed is without the causal case. Therefore, k was zero. Sorry. But in our case, we put all In our case, we put also the creation and anniversation. In effect, therefore, you have another term which is coming. So, this still contains some diverging factor. Therefore, rho also, rho is a solution of this P V, nonlinear P V. This is a kind of the nonlinear Alan-Kahn equation because the nonlinearity is not not only this one, but also the diffusion, diffusion term. It contains some nonlinearity. It contains some nonlinearity. And the gradient case has been discussed. Sorry, maybe the variables denoted by V, because for the microscopic point is denoted by X, therefore it may be strange, but the macroscopic spatial variable is denoted by D. Okay, then as Ben discussed, in the gradient case, In the gradient case, I think he wrote something like this. So he derived this kind of equation. And from the say zero range process, this is a this is a diver uh okay, so the gradient case. But the non-gradient case, it's a it has a divergence form, but not not like this one. So this this can Not like this one. So th this can be written. Actually sin since th this is the Laplacian, this is uh just if you write maybe d as say b i. And first you take a derivative and rho d d i. So so you you just separate in the two derivatives, then you have this form. Therefore So d i, sorry, so d i j. So in this case, the gradient case, this is just a diagonal matrix, diagonal matrix. And however, of course, d rho is a diagonal matrix in the gradient case. In fact, starting from the digitalities, starting from the microscopic particle system, you have a time. System, you have a time change n square. Then the one n can be anyway killed by using the summation by parts, by acting to the some test functions. Therefore, you have this one. This one is free also for that one. However, the gradient case, you have another, actually you have another very good summation by parts. Uh summation by parts. Therefore, you you can come to to this level. And the two n's, n square can be anyway killed by the summation by parts. But uh non-gradient case it is not true. Therefore it it's much much harder. You have to kill another n. This is slightly for experts, sorry, but maybe that that is the reason why uh it's more difficult. But uh some time change effect. Okay, anyway, anyway. Okay, anyway, anyway, DIJ, so it it is called it is discussed by Chen Din already. And also this one is essentially determined from the Kawasaki part. And this is just the equilibrium average, ensemble average of the grava part. And in the next page, I will give the recall you the formula, especially for D. And And so, in the first part, this is probabilistic, and as Chen Din discussed, we use relative entropy method, and then we can show that this is approximated by this one, but with a convergence rate also. That is also new. So, therefore, it is a quantitative hydrodynamic limit. Okay, so in the next page, maybe I can recall what. Maybe I can recall what Chen Lin discussed. So the diffusion coefficient is given by so-called Green-Kubo formula, and it is also sometimes called the Einstein relation. And this one is defined by some variational formula, and this is essentially the Dirich reform associated with our dynamics. Then this is a variational formula, and actually I will discuss some. Okay, I will discuss some physical meaning of F maybe in the next page. But anyway, it is a variational formula on the infinite particle systems. Therefore, this is in a sense infinite-dimensional variational formula. Then what Chen Lin discussed is uh you you take uh F is supported by the some fi finite region, then uh what what is the convergence rate? Then the w what is the convergence rate? Uh if you restrict this one in the finite finite region, then uh w what is the convergence rate? So of course the th this is taken for the whole space. Then uh that that that is the convergence rate is quite actually now uh quite quite important and it is crucial to discuss this uh quantitative hydrogen and climate. Okay, so that that was discussed by Chen Lin and uh it was quite well uh Quite well associated with this problem, actually. Then this gives some conditions for the Grauba part. Grauba part, so we have a microscopic system, then hydrodynamic limits tells it is to move to the macroscopic picture. We have a creation. We have a creation rate and the anhydration rate. So, how the density changes? We have an equation for the density change. Therefore, the density change coming from the global part is microscopically the creation rate. Just if you create, then the density increases. And if it is annihilated, it density decrease. Then the point is we have to take an ensemble of it is called ensemble. ensemble average. So we have a long time behavior and also a very wide area. Therefore it is averaged out by it is called the local erodicity. So we can replace this quite messy microscopic function by the macroscopic. So th this F is a macroscopic function. So F is a macroscopic function, so it depends on only the density. But this is quite uh uh microscopic, so uh messy messy function. However, you can replace by the this ensemble average. So sorry, I didn't write any that. So this bracket means the expectation or the average under the bernou measure with the density row. So we can replace by the uh ergodicity of the system by this one. Then we assume I did. We assume, I didn't tell, but for the grabber part, we assume this F had this shape, and this row, there are three zeros, three zeros for F. So F is a function defined between zero and one because a row takes a value from zero and one. Then it has three zeros, and rho minus and rho plus in this situation. This means rho minus and rho plus. rho minus and rho plus are stable points for this function f. And also balance means this row the integral of the f between rho minus and rho plus vanishes. This means row minus and rho plus have the same strings. This is well studied in the PD group. But especially when the DIJ is just the that PIJ is just that part is a Laplacian case, it's quite well studied in the PD case, PD people. Okay, so we assume we construct C C X in this way. So maybe this I hope answer your question. So we have to create C C X eta which satisfies these conditions. Okay. Then we can prove this is approximated by this one in this way. So first we approximate this one, then afterward we study the limit of this location. So for this part I heavily use the paper with Chenlin and Wan and the convergence rate. And the convergence rate of the diffusion coefficient plays an important role to prove this, especially for this one. And also to derive this condition and this convergence rate. This Chengdin's contribution is I appreciate very much. Okay. Then okay, the uh actually maybe I don't have much time, therefore Don't have much time therefore. As Chengin said, we use a relative entropy method, but not so. We compare the DR system that is called the FT eta and the local equilibrium that is called the PSIT. But the point is we have to consider the second order approximation of the local equilibrium. So this corresponds to the correctors in the homogenized Collectors in the homogenization theory. So you you for in the homogenization theory you usually construct the collector. Now for gradient model uh you don't need to consider the second order approximation but uh for the non-gradient case it is useful to consider uh the second order approximations. Essentially this should co go to zero, but this gives a good cancellation. And also this f is a the same f. Is the same F which appeared in the Barison formula for the diffusion coefficient. And once you can show this goes to zero, this is the entropy per volume goes to zero, then by using the entropy inequality and the large deviation type estimate, we can prove. Maybe Chenlin already touched, or maybe Ben also maybe touched already. S something something similar. And then Something similar. And then to prove the we have to prove this entropy per volume goes to zero. To prove that, we need several steps, say the child estimate, to control this one. So this the derivative diverges because it contains k times f. So we need some estimate for this. And also local ergodicity, that is a replacement of the some function by its. Of the sum function by its ensemble average, this is important steps. And we need some convergence rate. Also, convergence rate should be shown for this step. And also, we have to replace some, as I said, the non-gradient term gives us some diverging term. Therefore, we have to replace it by the gradient term. That that is originally go goes back to Bharadan. But To Varadan. But Varadan actually proved the characterization of the closed form. It's much complicated. But we can skip, in a sense, we can skip this step now. But of course, instead, we have to prove something. But anyway, Chen Lin proved also some estimate for this. So this is the convergence rate for the diffusion. This is the convergence rate for the diffusion coefficient. So convergence rate was shown by this. And also the Chenling gave some minimizer restricted to the volume N. Then the minimizer should satisfy this one. Then for this, he used some mixing time estimate for the random OK, actually. But anyway, so. But anyway, so I appreciate very much he and also Han Wan derived this kind of estimate and it is quite well applied to this problem. Okay, so I think he explained these steps. Then, maybe I have only five minutes. So maybe PD part also we have to prove the discompositive Have to prove the disconvergent this one, especially the Prussian term is non-linear. Therefore, I worked with Park with postdoc in Tokyo. He was originally in Kaiser. So, anyway, combining two steps, the proof is completed. Then, the problem is to discuss the fluctuation of the interface. So, we proved the lobalized number. Then, the next step is to do the number of the number of the number Lobolized number. Then the next step is to to to show uh how the uh interface fluctuates. In fact, at the moment we so th this part is a joint joint, so just we are preparing. The paper is not completed yet, but I'm working with Claudia Landima and also Sundases Raman. And we consider a very simple situation at the moment. So, Carsac part is simple. Simple means the jump rate is just constant. Then, in this case, the Then in this case, uh diffusion coefficient just uh uh uh j just uh uh identity matrix. Therefore, uh PDE uh I wrote a PD3, but uh the leading term is just Laplacian. And then we also consider the stationary profile case. Stationary profile case means uh uh this is uh a parabolic equation, but uh we just uh uh consider the uh the solution of the elliptic equation, but on the torus. but on the torus. And we assume in a sense it is a j just one direction, the solution of the to the one direction. Actually I learned from Dr. Du he was discussing some conjecture. But we are on the on the tollers, not on the whole space. But it is natural to assume it is just one direction if dimension is smaller than or Is smaller than or equal to 8. He said such kind of conjecture. So we are considering in that situation, actually. Since we have a k that's some scaling parameter, it should be stretched. So u0 is a so-called, without k, without k, it is a one-dimensional standing wave solution. It is called a standing wave solution which connects from the rho minus to rho plus. And then this one is really. And then uh this one is realized in a sense. Of course we consider on the tallest th this is on the whole line. So it it's slightly different, but uh uh we just uh uh consider to the one direction B1. Then this is this should satisfy something like this equation. Then uh we consider the stretching we should uh consider stretching to the this uh going back to the this interface problem to we have to consider the stretching to the normal. Have to consider the stretching to the normal direction. And then maybe, okay, so maybe. Then we need to stretch. So originally, the interface fluctuation is very small in the low large number level. So you don't see. Therefore, you have to stretch to the normal direction. This way, then you can observe some fluctuation. So we have to uh introduce uh scaling in such a way that we have already In such a way that we have originally this one, then we consider to the normal direction and also tangential direction. For the tangential direction, we don't touch, but for the normal direction, we stretch. Therefore, we divide by square root k. Then, and also we introduce the CLT scaling, and also we need this scaling also for the noise. For the noise to survive. So, we want to derive something fluctuating. Therefore, to the noise to survive, we need this scaling also. Then, we can discuss what is the limit of this object. Okay. Then, as usual, we want to compute the time evolution of this one. That is just called the Dinkins formula or Ito's formula for this. Ito's formula for this uh particle system. Then since uh leading Kawasaki part is a Laplacian, essentially we have this by stretching uh to the normal direction we have a k, but for tangential direction we don't have. And then uh from the grabber part we have uh some something uh more complex uh formulas. Then the uh we have a fractures term that is a martingale term. Uh we we can compute the quadratic variation of the martingale term. Quadratic validation of the marketing term. Then acting some test function, we have this. So this is just a simple computation. Then the scaling was chosen in such a way that this stays order one. Martinier term stays order one. Then, okay, then we have two noises, the space-time Gaussian white noise, to the normal direction, tangential direction, and also. Direction, tangential direction, and also from the Graber part, we have another space-time Gaussian white noise from the Kawasaki and also Graber path. Then roughly, we have and also the main point is that we have to prove the so-called Boltzmann-Gibbs principle. Sorry, maybe I should stop. And then the the point is that this uh again we replace this one by the ensemble average and then we we make a tail expansion. And then we we make a tail expansion. Then uh we we have something. Then the to prove this one is uh uh main task. But uh it it is shown with uh Landiman Sunda Sesraman. If k is smaller than this one, then but uh so I I keep the second order term but uh at the moment only only the linear term. So we don't reach to this this stage but uh only linear term. Then, yeah, okay, so maybe I should. From then. Yeah, okay, so maybe I should. We can derive some stochastic PV for the interlimit, like this one, and this describes some fluctuation of the interface. And I have some conjecture. Also, if we may have some nonlinear one, but we don't reach to this step at the moment.