Happy birthday. I hope everyone had a wonderful day yesterday exploring the area. We're going to start today's first talk with Lena Podina, who is a PhD candidate at the University of Waterloo in the computer science department. And she's going to be talking about universal physics informed neural nets and their applications. Thank you, Lina. Awesome. Thank you. Thank you for the introduction and thank you for the invitation. Imitation. I'm Lena. Yep. This is the topic of my talk. So I'm going to be talking about two papers. The first one is sort of the one where we kind of introduce and do the preliminary experiments on universal pins. And then the second one is the one where we apply this to learn the drug action of chemotherapy products. Yep, so this is about the first paper. This is The first paper, this is a collaboration between Brian Eastman and my supervisor, Mohamed Khan. I'll start off with some introductions, some motivation, get into the implementation details, and then talk about some examples of which we have. So just a bit of intro. Our lab does generally the mechanistic modeling of disease, but more recently we've had a focus in machine learning and also we focus in oncology as well. One of our As well. One of our aims is to integrate data-driven modeling with conventional, sort of, more differential equation-based approaches. The sort of motivation for this is that if you integrate, as you've already heard in John's talk yesterday, if you integrate sort of data-driven techniques and conventional, sort of more differential equation-based approaches, you could reduce the manual building of assumptions. So instead of sort of thinking about the assumptions that you want to build into your model. Want to build into your model, maybe you could learn them. The UPIN approach is pretty general, and here I'll focus on more so biomedical applications. So I'll start with a motivating example for the type of problem that we want to solve. So apoptosis, as I'm sure many of you are familiar with, is programmed cell death caused by a regulatory network. And some of the key proteins are p53 and AK2. P53 and AKT, which promote apoptosis and inhibit apoptosis, respectively. So, one way to model this would be through this kind of system of differential equations, but the issue is that you could kind of model this on different levels of granularity. So, you could add more or fewer details, or add more proteins that kind of help also these main proteins. These main proteins. So you could essentially add more details. So, our question is whether we can use machine learning to identify some of these underlying mechanisms of action. As you already saw in John's talk, we have kind of a spectrum between white box models and black box models, where white box models are deterministic equations and maybe more sort of equations where models where you build in all of your physiological knowledge and all. Physiological knowledge and all your assumptions. Gray box models balance sort of data-driven approaches, purely data-driven approaches such as machine learning, and white box models where you know exactly what's happening. So here we're kind of where we want to reach sort of a middle ground where we kind of have the best of both worlds in the sense that we have sort of the integrated knowledge from the Knowledge from the sort of knowledge, the background knowledge that we have about the problem, but then we also sort of use data-driven methods to figure out what's going on. This is also part of a broader sort of movement, such as to kind of bridge the gap between quantitative systems pharmacology and machine learning. And in this case, some of the problems that you might want to work on are parameter inference, inference of models. Parameter inference, inference of model structure, and dimension reduction. So, this is a second motivating example on tumor growth modeling. So, here we're talking about a glioglastomultiform, which is an aggressive form of brain cancer. And one way to model that is using this partial differential equation. The issue is that DNR can be used to predict tumor growth, but actually, they're quite different. Actually, they're quite difficult to measure, and they are sort of specific parameters that the patients would have. And every patient might have a different set of these two parameters. So we could fit this. In fact, one of my colleagues, Cameron Meany, produced estimates of diffusivity and growth per patient using just two MRI images. So, physics and for neural networks, which is what he used for this, are very For this, they are very powerful in the sense that you would only need two images to do this. However, one sort of drawback that they have is that they do require the entire differential equation to be fully specified. Yep. Do you want us to ask questions now, May? Sure, go ahead. So, how do you know those estimates? Um, if they can predict some holdout data well. Some holdout data well. You could say that they're correct in that case, but I think in terms of the ground truth information, you wouldn't know. So you don't know. How well do they predict it? I think they predict them quite well. I think he had a holdout set and then he managed to predict the holdout set. Yeah. Yeah, so essentially traditional pins, such as the kind that Cameron used, in fact, he was using In fact, he was using discrete pins rather than continuous pins. But both kinds of physics and form neural networks suffer from a bit of this problem that they require the entire differential equation to be fully specified. So that means if you don't know part of your differential equation or if you've misspecified it and you think that there's a specific component there, but actually it isn't, it's something else. In that case, the output that you get might be not. That you get might be not useful. So, we'd like to find the hidden structure of the model using machine learning. This has been done before in a different work on universal differential equations and neural ODs, which I'm sure a lot of you are familiar with. And in this case, the idea is that you're able to take these hidden terms, which in this case we're going to say is minus beta xy and minus delta xy. xy and minus delta xy in the Law Ka-Volterra model. And you can replace them with neural networks and then train them and then be able to get a representation of this hidden term using the neural network. The problem is we found that this approach is not particularly robust to noise in the data. So if your data looks more so like this, where you have a lot of noise and it is quite a bit of data. It is quite a bit of data, but it's fairly noisy, then the hidden term that you learn will actually not correspond to the true hidden term at all. So it's still a very powerful approach, and especially because you only need to sort of have one loss function here with the mean squared error. But essentially, we found it doesn't perform super well in cases of noisy theta. This is a bit of a problem because biological data is often. Biological data is often sparse and noisy. We found that if you try to do the same kind of thing, so the same, you try to obtain the same type of representation of the hidden term, but using a different framework instead, you use physics-informed neural networks, then you can get the same kind of solution. So you'll still get a representation of the hidden term, but it will be a lot more noise-robust. So here we have the same noisy data, but Here we have the same noisy data, but we get a much better representation. So, a benefit is that we have a better fit to the data, and additionally, we could potentially discover the biological interaction from the data. I want to make a small aside about symbolic regression. Symbolic regression is essentially a way to fit a model to data where the space of the models that you're searching. The space of the models that you're searching actually is not sort of parametrized the way that a neural network would be, but you're searching specific functions. So, for example, sine, cosine, exponential, log, things like that. And your final result is basically a combination of a whole bunch of different functions. So, the idea is that you want to find a closed-form solution for the function that you have. The other thing that symbolic regression algorithms tend to want Regression algorithms tend to want to do is to trade off complexity and goodness of fit. So, if, for example, you have some data and such as here and the data is fairly noisy, it's going to try not to overfit it. So, that's usually something that's part of symbolic regression algorithms. So, AI-Feynman is one of the state-of-the-art symbolic regression algorithms, and sort of in some of our applications, we will be using that one too. Is we will be using that one to show some sort of downstream applications of finding the hidden term. Yeah, so the idea is that you can discover physical relationships between quantities. So we'll talk about standard pins first, and then I'll talk about UPIS since it's really not that big of a difference. And that said, as far as I understand it, biology and form neural networks from before are also very similar to UPIs. So here we're So here we're kind of starting with pins and then going to UVINs. But I would say some of the here we're focusing a lot on the model discovery aspect. So for PINs, we are assuming that we have data from a differential equation, possibly a partial differential equation or ordinary differential equation, and we fit a neural network to the solution of this differential equation. So rather than using a solver, So rather than using a solver, you have a neural network which provides the solution. We're going to call this the surrogate solution because it's not exactly potentially the solution, but it is approximating it. Optionally, with the pin method, you can fit parameters within the differential equation as well. So that is possible to do. The way that you do this is you treat them as weights within the neural network, and then you can optimize them. Neural network, and then you can optimize them sort of using the same optimizer that you would train the surrogate solution. So the loss function, which you've already seen, kind of looks like two components. We have the data loss and we have the pin loss. The data loss ensures that the surrogate solution matches the data that you have. And then the pin loss ensures that the differential equation constraint here, which here Strength here, which here we want the left-hand side equal to zero. Basically, that it's satisfied. That's kind of what we want. I also want to note that you don't need always data to get a pin to work. You can also, in some situations, train it using no data at all, but of course, data helps because it helps you anchor your solution at specific points. So, what we're basically going to assume is that. Going to assume is that for the UPIN situation, is that this known term can be split into several terms. So we have a known component and we also have an unknown component. In this case, we're saying that they're added together. They don't have to be and for sort of further experiments that you'll see. So, for further experiments that you'll see, they will be added mostly. Will be added mostly, but it doesn't have to be the case. So, this part is known, you exactly know the closed form. This part, you're like, I'm not sure, I'm gonna fit that. Yeah, so just a comparison, they can do much of the same stuff. You have the data, get the differential equation solution, and fit parameters. And you can still do this in a UPEN framework, but you can also model unknown terms, and additionally, you can enforce or learn boundary conditions if you have. or learn boundary conditions if you have those. So here, just kind of again, really similar loss function. We've got the data loss, does the same thing. We have the boundary loss and we have the pin loss. PIN loss also does the same thing. And this is actually how the neural networks can get trained because in the data loss, the neural networks that represent the hidden term, they're not actually in there, but they are in the pin loss. So here, if you wanted to, you could try. Here, if you wanted to, you could, well, I'm sure you want to. You want to train the neural network using backpropagation, and since the neural network is in this loss, you can move up. You can also learn or enforce part of the boundary condition. So here are some of the examples that we tried UPINs on. We're going to learn, again, same lock-kind-Polterra model. We're going to learn the red terms, so minus beta xy. So, minus beta xy and gamma xy, replace them with neural networks and use this data here to train. So, what we see is that even for 10 data points and for a lot of what we call collocation points, we can get a really good identification of a hidden term. So, here the top table is the mean squared error between the true hidden term and the learned hidden term. And this is for noiseless data. And this is for noiseless data, and then the second table here is for noisy data. And the collocation points are basically the points at which the differential equation constraint gets enforced. So even if you only have 10 data points for this situation, you can still kind of, as long as you enforce the differential equation constraint, in as many points as you can, then you can still get 10 to the minus 6 or 10 to the minus 4 in terms of the spirit error. Minus four in terms of means greater. This you've seen already. I showed it earlier to kind of show the gist of what we're doing. And this is the UDE performance. Again, the hidden term is maybe not learn in the best way. This is mostly due to noise in the data. And then on the right here, we have sparse data. So it performs a lot better, but still perhaps not as well as it could be. Using UPINs, we can again We can again sort of learn the hidden terms in cases of noisy data, in cases of sparse data, and we do significantly better than using UDEs. Comparing against sort of more specifically to sparse data in cases of sparse data and in cases of noisy data, here lower is better because that's the mean squared error for the hidden term. For pins, we sort of managed to do maybe a We sort of managed to do maybe about an order of magnitude better than Yui's. Another thing that we did, which sort of going back to the little aside on symbolic regression, is that we tried to learn the coefficients for these terms. So if you recall, these were basically multiplicative and they had a coefficient on them. And what we did was we took this hidden This hidden term representation using the neural network kind of gives us a mapping from the inputs to the outputs. And then we take that as data and we give it to symbolic regression to see if the symbolic regression algorithm can correctly find the form so that it's a coefficient c times x times y in both of these cases, and then also see if it can get this coefficient correct. So in this case, kind of understanding. In this case, kind of understandably, because if the data from pins is sort of a little bit more high quality, then we can find this coefficient more often when we use UPINs rather than when we use VPNs. Are you assuming you know the parameters of the known part? You know them or not? So they are alpha and algelta? Yes. Yes, those we fix. We also tried this on Berger's equation, and we only have training data at two different times, t equals 0 and t equals 0.5, and it's quite noisy. And again, sort of treating this term as the hidden term and this one as the known term, we can get good sort of mean squared error on the solution and also on the hidden term. So that was kind of an overview of. So that was kind of an overview of UPINS. And then in this paper with my two supervisors, we went a little bit in more depth in terms of applications to chemotherapy and cancer modeling. So there's two different applications here that I'm going to talk about. We have synthetic data, an application on synthetic data, and also an application on in-mutra data. So in both cases, we, well, In both cases, we well, in the first case, we want to identify the drug action, and in the second case, we want to identify time-dependent sort of proliferation rates. So, this is again kind of not exactly a drug action, but it's going to be different based on the dosage of chemotherapy that cells are receiving. So, the model for the synthetic data experiments looks like this. We have some logistic growth, so there's a system of two ordinary differential equations. Of two ordinary differential equations. We have logistic growth, and then we have a cell kill term, which depends on the concentration of the chemotherapeutic and also on this drug action. The concentration of the chemotherapeutic we assume is kind of placed and then it decays. So the initial condition is that we place the concentration at, I think, one and then it sort of decays over time. G of n, we're going to. G of N, we're going to say, is one of LawKill, Norton Simon, or Emacs sort of drug actions. And we want to be able to identify the type of the drug action from the cell count and the drug concentration. So more specifically, the data looks like this. We have the data as the concentration of the drug and of the cell count over time measured at regular intervals. It may or may not be noisy. And then, as you can see here, we have. And then, as you can see here, we have no chemotherapeutic. We add it, it decays, but then the cells die as well. So, our approach has been to model first the concentration with a neural network, and then we're going to fit this term here as one thing in the UPIN framework. So, it is possible to fit these two separately. So, for example, have this to be a neural network. Example, have this to be a neural network and this to be a neural network, and it should still work because we have data for the chemotherapeutic. But in this case, it actually yielded better results to fit it as one term and then simply divide by C to get G. So, yeah. So, in terms of some results, this is for noiseless data. For each of these cases, Log Hill, Norton-Simon, and Emacs, type of drug actions, we're able to identify the We're able to identify the G of N term. And this is the term after we've already divided by the chemotherapy concentration. We can also do this for noisy data in these cases. So, yeah. We also looked at different ways to collect data. So this is kind of a summary of some of the results. This is kind of a summary of some of the results. Here in the columns, we have the drug action, but then the type of data could be either noisy or not noisy. The first two columns are not noisy. The second ones are noisy. And we kind of experimented with a way to collect the data where if the cells are dying really quickly, such as here, then what if we collect the data sort of more often? Can we get a better result in that case? Because here, if you can see, there were. There's these sections where there's not very much data for high values of n because they die off really quickly. And we do get better results, which is kind of interesting, but also you wouldn't necessarily a priori know how fast they were about to die off, but if you had some idea, you could measure more frequently. So, in general, we do get better results for that. For that. The other thing we're able to do is to estimate beta, and beta is over here, the growth rate. We're able to estimate beta from the untreated data using a standard pin. And in that case, we're using the cells as they grow before treatment. And then use that estimate to fit the drug action. So instead of just sort of assuming it, we can learn that part as well. So now I'm moving on to. So, now moving on to the second example. Here we're interested in applying UPINS to in vitro data, and here we're taking data from McKenna from 2017, and they basically collected time series data of, again, cell count over time. And yeah, so we want to use UPINs to learn time-dependent terms within this equation. The data looks like The data looks like this. It's essentially, as I mentioned, time series data. And the doxorubicin was applied to a cell line of cells for either 6, 12, or 24 hours. And after that, the chemotherapeutic was removed. And this was done at nine different concentrations. So after the drug was removed, basically the cells grow. And presumably, if you give more chemotherapeutic and then you remove it, then the cells would... And then you remove it, then the cells would sort of take longer to grow back. So, the model that they used is the following: We have the number of tumor cells, we have a proliferation rate, we also have a death rate, which is dependent on the dosage and the time. And so, yeah, so over time, but then also the dosage is how much, how many nanomolar you're giving to the cells. We have theta. We have theta, which is the dose-dependent carrying capacity. And we kind of, again, assuming that it's lower for higher dosages. And what they did was that this death rate here, they modeled it using either equation 5A or 5B. And in fact, in the final model, they used a linear combination of these two equations. In this case, the death rate is constant for all time. It does depend on dosage, but it's constant over time. And in this case, it's actually not. And in this case, it's actually not. So, our goal is to learn KD with a UPED, basically. That's what we like to do. So, I want to talk about the different ways that you could approach this. So, in this case, when the underlying equation isn't known, you could learn the net proliferation rate sort of directly from data. However, you could still not assume very much Very much prior knowledge. And for example, here you could just say, okay, it's exponential growth, and then everything else we're going to offload to the neural network. Another way you could do it is you could assume the logistic growth and then learn a neural network for sort of the rest of the component. So, in the first case, you would basically be replacing these two terms with a neural network and then learning this one. Sorry, yeah, learning these two terms and then Learning these two terms, and then this would be the surrogate solution. And then the other way that you could do this is you could replace this with a neural network, and this theta you will assume, but you can normalize it per dosage. I suppose there might also be a way to not normalize it, but we did this just to sort of keep everything on the same scale. Yeah, so first we looked at some synthetic data just to make sure that it would work. Data just to make sure that it would work for sort of cells and numbers that are on the same scale. And here we simulated some data from equation 5A and then learned F, so not assuming very much, not assuming logistic growth. Again, we get pretty good identification here. We did this for equation 5B as well. So again, still simulated data, but we're only using equation 5B. We still get pretty good identification here. And then And then we use the other approach where we assume logistic growth, but then we learn everything else. And here we get something kind of interesting happening where we get good identification up to maybe 0.6, but then afterwards it sort of falls off. So the reason for that, it seems, is because when n is actually really close to 1 here, the neural network is a Network is kind of not identifiable because if n is really close to 1, then this term is quite small. This is close to 1. And then the derivatives is also fairly flat. So it's close to 0. So it doesn't maybe as such matter what g is, and it's going to, and sort of any value for g would kind of yield a good fit here. So that's kind of what's happening. And this is interesting. kind of what's happening. And this is this is interesting because I think before running this experiment I hadn't realized that the function could be only identifiable for part of the trajectory, which is kind of cool. So now we looked at sort of real data. So this is only some of the, this is just one of the experiments that I ran. Here we have some data and it's kind of again normalized. Again, normalized, but this time it's from the six hours of exposure and 312 nanomolar. And when we learn this curve here, we get something that looks kind of like this in terms of shape, so that's quite reassuring. We don't have a ground truth to compare to, though. We also do the same thing using G, so now we have an extra assumption that we are working with logistic growth. And in this case, we're And in this case, what's kind of interesting is that it's flat in the beginning, and then it kind of goes up. So if it were exactly equation 5A, then this would just be sort of flat the whole time. And maybe here it would drop off because of some identifiability issues. But it would be flat. And if it were 5B only, then the curve would look a little more like this. So this is kind of interesting because it's not a linear combination of either 5A or 5B, but it's more like we have. 5B, but it's more like we have 5A in the beginning and then we have 5B later. So we don't have a good idea of what this means biologically, but definitely sort of worth investigating for later. Yeah, so in summary, this method is able to, in addition to other similar applications such as with biology-informed neural networks, we're able to accurately identify hidden terms in the case where you want to do model. In the case where you want to do model discovery, you can apply it pretty much anywhere. We've got differential equations, you can apply it on partial differential equations as well, and you can link it with symbolic regression algorithms such as AI Fein1. So some future work I'm thinking about is some better integration with symbolic regression, such as if you could do sort of more of a feedback loop between symbolic regression and the viewpin. View pin and then some work on function identifiability such as such as what we saw before. And I've also been working on uncertainty quantification pins and Q pins more generally. Thank you. These are some questions. Do we have any questions? Yes? So really, really great talk. At the end, when you fit with data and you showed When you fit with data and you showed kind of the recovered form, did you try to do any symbolic regression on that? And what kind of functions seem to fit? And I know that maybe you cut it off where you think things did not identify, but did you look at that? No, we didn't. That's a good point. I think we could. And maybe we could see something kind of interesting. Like, I think if it was simple and then it found that, I think it would be kind of an evidence, like some evidence for, like, oh, maybe you should actually model it this way. So that's a good point. I had not thought. That's a good point. I had not thought about this, but it's definitely, I think it's something to look at, yeah. Yep. Thank you. Very interesting talk. So, you didn't mention anything about the networks that you're using. And I would like to know a bit like, you know, how large are those networks? Do you always use the same one for all the problems? Do you somehow adapt them to the problem? Yeah, so for the PDE, it was okay, so for the ODEs, it was like about It was like about, I think, 64 hidden units and maybe like 10 layers. So maybe, maybe kind of large, but then also not as large as, I don't know, Transformers, right? So definitely like maybe about eight layers and then around 64 hidden units for those. And it was larger for the PDE. It was maybe 128 hidden units. These are all fully connected networks. The activation was 10H, and we used. And we used Atom as an optimizer for maybe a few thousand iterations, like 2,000 to 5,000 iterations, and then we moved to the LBFGS optimizer. Yep. So I have two connected questions. If you go back to your conclusion, you have this statement that accurately identified in terms. Well, Heiko had this question the other day about. Well Hyper had this question the other day about what happens if you have chosen another growth form of a tumour. And yeah, how do you I mean you found some that works, haven't you? Or can you say that you have a list of functions where the one you chose was the best one and how superior is it to the next one in the list compared to the noise and the things? Sorry, I'm not sure I quite So, the question is: when you use machine learning to identify a trip where you have a huge catalogue of possible ones, you might get one out that is the best one. But how much better is it compared to the second best one? And would you trust that ordering? I see, I see. Okay. So the way that we're setting this up with the UPINs, like no symbolic regression, is that we hope that if you've minimized the loss enough, then in Loss enough, then in that case, that should be the actual hidden term. So suppose if the differential equation loss is very, very close to zero, the data loss is also very low, so it matches the data very well. That should be the exact hidden term, barring any identifiability issues. So we're not maybe as such choosing functions from a list, but But because neural networks can sort of approximate functions really well, we're basically saying, you know, as long as the surrogate solution matches and as long as we've trained it really well, we should be able to get the actual hypnot, given that it is identifiable. However, for symbolic regression, so where you're kind of looking at different functions and maybe you've got sine and cosine and things like that. And things like that. I think that's kind of a universal problem for them, I think, because the very best function might fit really well, but then it overfits a little bit. So the next best one is maybe significantly simpler. And then I think at this point, the modeler should probably intervene and try to figure out which functions they think are better for the model. Yeah, so related to that question, you said something about we need to sample at time this or that and that, and then we get a good read. Or that, and that, and then we get a good bit, which is better than the next one. It's not, my question is: doesn't it depend on where you are in your phase space, which is kind of determined from your original hidden model? So there's like this feedback loop between the two that you cannot just say, I need to sample at this and this time, but it depends on where I start, what my true differential equation is, and if so, like, do you have any kind of workarounds? Like, what would be your recommendation for somebody else? Would you say ten times five or three? You should say ten times five or three, or like what would you like? Yeah, no, I think it's a really good question, and I'm not sure I have a good answer, but I think because sort of the way that the way that I approached this was, you know, we kind of know that the cells are going to die off the, you know, and maybe arguably we don't always know this, but in this case, we're saying, well, they're going to die off the quickest in the beginning, so that's where we should sample. But I agree that in general, you wouldn't know this. And I think it really becomes more of a sampling problem. Like a sampling problem, and given that you don't really know what's coming next, right? You kind of sampling and then you don't necessarily know what's going to happen later in the different equations. So I think that's maybe a totally separate problem, but also really important. So about this last point of the future work, the integration of symbolic regression. So nobody is dying to steps, right? So nobody is dying two steps, right? So are you thinking here and try to do this at once somehow? Or I've seen a paper that they try to do it at once in a sort of iterative way, so they jump from one problem to another one. Yeah, I think, yeah, that's kind of what I was thinking. It would be great if you could send me this paper, because I think it would be cool to look at. But yeah, that's kind of what I was thinking because I thought maybe, you know, in some cases, such as You know, in some cases, such as this one, like it learns something, and then here it kind of maybe loses the plot and gives some other result, which kind of still works with the prediction, but maybe isn't exactly right. Then I thought maybe if the symbolic progression, you could actually say, oh, you've made the model too complicated. You should reel it in. And maybe just keep this flat, right? So something like that. But yeah, that's let me know. Okay, last question. Okay, last question. Yeah, very beautiful. Thank you so much. When you showed your data on the accredit and there was barely a difference in the error. Must have jumped before using this area. So I trended sleeve. If you see between one to five, you gain five orders of magnitude, and then you barely. And of course, if the next question cases a dynamics that we see, I person for five time points would not be it. Um sorry, who? So so you're a network. Yeah, yeah, yeah. Um Yeah, yeah, yeah. Yeah, I agree. I think most of the success is due to, again, the high number of collocation points where we want to enforce a differential equation. I think it might be worth investigating what happens for 2 and 3 and how quickly it kind of goes. But yeah, I would say it's also maybe not super, I guess, not always, not super super. Not always, not super surprising in the sense that even pins could solve an equation just from the initial condition and enforcing the differential equation. But I agree. I think it is remarkable in this case. I mean, I can enforce differential eight computing function data usually well. No, I mean, I think it's, yeah, it might be worth looking into. Something else that I think would be interesting is like novel points. Would be interesting is like not all points are going to be worth the same because, right, like, because if there's nothing happening, if it's kind of a boring section, and if you have lots of data there, it's like, okay, great. But maybe you should have been collecting somewhere where it wasn't much. So, yeah, I think there's definitely some extensions where we're looking more so at like, where should the data be and how do we make it know a priority? Where do we come from that data? I think we've just decided that you should become a part of the UPIN's UDE school. Okay, cool. Thank you so much, Lee. And before I turn off the microphone, thank you for anyone.