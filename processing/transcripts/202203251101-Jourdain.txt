From École de Pont of Paris Tech, and he's going to talk about the approximation of Martinier Kaplan's in the wiki-aptive topology. So, please start. So, thank you for the introduction, and thanks to the organizers for the invitation to this nice workshop. What I'm going to present is a joint work with Matthias Beigelberg, William Margheriti, and Goodman Palmer. So, I'm interested in I'm interested in the Martangel optimal transport problem, and I will first recall its financial interpretation. When we consider an exotic option with payoff, which is a function of the prices of T assets at time T1 and at time T2, the payoff function is assumed to be measurable, and we assume that the Rix. We assume that the risk-neutral distributions of the assets at time T1 and at time T two are known from the market prices of liquid options, which is reasonable in dimension one and which is more discussable in higher dimension. If we assume zero interest rates, then the price of the exotic Is the price of the exotic option should belong to these boons where we have the Martangal optimal transport value function for first marginal mu, second marginal new, and cost function C, which is simply the infimum over all mark angle couplings between mu and u of the integral of the cost function against the marked angle couplings. couplings. So I will denote by pi m of mu nu the set of martangal couplings, which is a subset of the set pi of mu nu of all couplings. And those couplings, of course, are characterized by the fact that the first marginal is mu and the second marginal is new. And for martengal couplings, we have this decomposition M of dx dy as the first marginal. x dy as the first marginal times this notation mx of dy, which is the conditional distribution of the second coordinate given that the first is equal to x. And we ask that the integral of y with respect to mx of dy should be equal to x mu almost everywhere. Okay, this problem was introduced by Goldberg, Henri Laborder and By Goldberg, Henri Labordère and Penkner in discrete time. And also, there is a continuous time version by Gallichon, Rélabordère, and Tuzi. And since there have been many contributions, some of people in the audience. And when new and new are finally supported, as Pietro Sorpares told before today, the Martangel optimal transport problem. The Martangel optimal transport problem boils down to linear programming, which can be solved by, for instance, interior points algorithm or simplex algorithm. And an important question in this perspective is the stability of Martengel optimal transport value function. Is this value function continuous in the marginals? So it's important for Important for numerical purposes to be able to compute the limiting value function by discretizing the measures. But it's also very important in practice because mu and new are extrapolated from the market data, and the list that we can ask for robust bonus. Robust bonds is that they don't depend badly on these market data in the end. Okay, so I will now explain the approximation of marked angle couplings on the line that we obtain in the weak adaptive topology. So I will first recall the Vasarstein distance, W rho. W rho of mu is simply the infimum over all couplings between mu and mu of the integral of distance between two points to the rho. And we take this integral to the power one of the rho. This matricizes the topology of weak convergence plus convergence of a moment of order rho, so for any point. Point X naught in the space Rd. In dimension one, it's given by the common autonomous coupling, that is, we obtain this by the common inverse transform sampling method with a single uniform random variable on zero one. Variable on 0, 1. So this is the integral of the Rof power of the difference of the contract functions of mu and u. Okay. And as we saw in Goodmoon Palmer's talk on Monday, this is not well suited to take into account the flow of information with respect. And of information with respect to time. And that's why we are going to work with the adapted Vasorchein distance, which matricizes the adaptive topology that he mentioned during his talk. So for two couplings between mu and mu and pi prime between mu prime and mu prime, the adapted Visor shine distance between pi and Between pi and pi prime will be the infimum of all couplings between the first marginals mu and mu prime of the integral of the distance between the initial points plus the Western distance, usual Westernstein distance between the conditional laws of the second coordinates pi x and pi prime x prime. x and pi prime x prime and you integrate against the the coupling guide between mu and new mu prime okay so when we have sequences of marginals which are converging to mu and mu in weisserstein distance In Waserstein distance, it is well known that for any coupling between μ and μ, it's possible to approximate this coupling by couplings between μn and μn in Westerstein distance with some quantified error. So the Westernstein distance to the row between pi and pi n will be smaller than the Will be smaller than the sun of the search line distance to the row for the marginals. Okay, and the first question that we can ask is, is it possible to obtain such an approximation in the stronger adapted Western distance? And the answer is positive. In general, dimension, we obtain that it's possible to We obtain that it's possible to approximate pi by couplings between mu n and mu n, but in a non-quantitative fashion. In dimension one, using copulas, it's possible to do better and under the condition that in fact the germs of the cumulative distributions functions of mu. Functions of are included in those of the cumulative distribution function of limiting first marginal mu, then it's possible to recover the rate that we had for the usual Wasserstein distance in terms of adapted Wasserstein distance. So now I have So now I will be interested in the case when mu is smaller than mu in the convex order and pi is a Martangel coupling. And in that case, from the convergence of adapted Veserfrain distance to zero, it's possible to see that in fact the pi n. The pi n are almost martangal couplings. In fact, if we are interested in the lack of martangality, that is the integral of the difference between X and the integral of Y with respect to the contradictional distribution of second coordinate given X. given x to the rho then we can use some coupling between mu and mu in fact we can introduce minus x prime plus x prime and force minus x prime plus x prime and since pi is some marked angle coupling in fact x prime can x prime can be interpreted as the integral of y prime with respect to p x prime of dy prime. So now the difference of expectation, it's well known that it's bounded from above by the W1 distance. So in the end, we obtained that the lack of mart angularity is bonded. Is bonded from above by a positive constant times the adapted Visorchein distance to the row, which goes to zero. So we are in a good position, in fact, to obtain a sequence of Martangal couplings converging to the original one pi in adaptation. One pi in adaptive asorction distance. And in fact, it's possible to do so, but only in dimension one. Okay, so I suppose that mu and mu have finite moments of order rho, with mu is smaller than u in the convex order, that mu n is smaller than u n in the convex order, and the sequence mu n. The sequence is converging to in W rho, mu n to mu in W rho, then for any martangle coupling between mu and mu, it's possible to find a sequence of mart angle couplings between mu n and mu n these times, which converges to the given martangle coupling m in adaptive. In adapted by the train distance as n goes to infinity. So if we have almost Martangal couplings from the previous results, it's not so easy to restore the global Martangal constraint. We need a construction, we have several subsets that I cannot explain in details. So, what I'm now going to discuss is the consequences in terms of stability of weak Martangle optimal transport problems. Well, let us first start with the stability of the Martangle optimal transport on the real line. I am in the same framework as before with a cost function which is constinuous and which satisfies some growth which is related to the index row of integrability of all measures. And back of Veraguas and Pamer and independently Viesel established Independently, Wiesel established that the value function of the Martanguel optimal transport with marginal mu n mu n converges as n goes to infinity to the value function for the limited marginal mu nu. Well, in dimension greater than two, there is this very nice counter example. This very nice counter example by Martin Brikorov and Nicolas Villet that was mentioned earlier today. So it's very simple. When you take mu to be one Al, the direct mass at one zero plus the direct mass at two zero, that is the uniform probability on the red points. Red points and for some angle theta between zero and two pi nu theta to be the image of mu by the Markovian kernel, which consists to add cos theta symteta with priority one half and to withdraw cos theta symteta with priority one half. So we end up with the uniform laws on the Laws on the blue points. On the picture, we have theta equal pi over 4 and theta equal to pi over 6. Okay, so mu is the uniform law on the red points, mu is the uniform law on the blue points, and when the angle is non-zero, then this is in fact the only Only Martangel couplings, mu of dx, p theta of dx, x dy. And for the cost function, which is simply the distance between the points, this means that the value function will be equal to one. Now for theta equal to zero, all the points are on the first axis with Two of the blue points which coincide with the red points, and it's possible to construct other martangle couplings, in particular some couplings which permit mass to stay at the same place. And for the coupling that I wrote here, which has probably one-fourth the possibility to stay. The possibility to stay at the point one zero and one fourth the probability to stay at the point two zero, one obtains that the integral of the cost is two over three, which is smaller than strictly smaller than one. And this proves that the value function is not continuous in the marginals. Marginals, of course, because nu theta is converges to nu naught as theta is going to zero, of course. And moreover, this counter example also shows that our result of approximation of Martangel couplings is not valid in dimension two or higher. Okay. Okay, so in dimension one, we can recover the stability results obtained by Veraguasson-Palmer and by Wiesel, and also deal with more general problems, which are the weak Martangal optimal transport problems. So let us start with non-Martangal version. Non-martangal version, which was introduced by Gausland, Roberton, Senson, and Thétali. So we define the weak optimal transport problem as the infimum overall coupling pi between mu and u, the integral of the cost of the position x and of the X and of the conditional distribution pi X of the second coordinate given the first one and we integrate this against the first marginal. So the cost function capital C is some is defined on the set E times the set of priority measure on F. Okay, when mu on. Okay, when μ and U are priority measures on two polished spaces, E and F. Okay, so if E and F are both R D and mu is smaller than mu in the convex order, then it's possible to define the weak Martangal optimal transport problem, which consists simply in the minimization of Minimization over all Mart angle couplings in place of all couplings. And an example of application of such weak martinial optimal transport problems is given by the SUR application price of the VIX feature, which, according to Guillaume, Menego, and Newts is is given by minus the square root of of minus two over the difference of times of the first some integral of the logarithm against the conditional distribution of a second margin of okay so of course this generalizes Of course, this generalizes the classical optimal transport or Martengel optimal transport problems, which are obtained for a choice of cost capital C linear in the major components, which is given by the integral of small C against the measure component P. So, concerning this weak Martangal optimal transport problem, if we take some cost function over Rd times the set of priority measures over Rd, the finite moment of order rho, which is convex in the measure argument, lower semi-continuous. Lower semicontinuums, which satisfies some growth constraints, again related to this index row. Then we obtain existence on uniqueness. So for mu smaller value in the convex order, there exists a couple. A coupling, a Martangle coupling M star, which minimizes the problem. And for uniqueness, we need a strict convexity in the second argument of the cost function. And we have lower summary continuity of the value function. So for mu n, mu n in convex under unconverging to mu. And converging to mu and nu respectively in W rho, then we obtain that the value function at mu nu is smaller than the int of the value functions at mu n u n. And last, if we can prove that the value function converges, which is not for free, then the accumulation points of optimizing Optimizers at level L are minimizers at the limiting level for W mod of mu nu. And when C is moreover strictly convex, then the optimal couplings converge even in adapted Waserstein distance. Okay, so let us let's So, let me just explain some elements of proof. The difficulty, of course, is to obtain relative compactness for adapted Vasarstrain distance. This is not easy at all. But in fact, it's possible to throw our sequence of couplings. Couplings between μ and μ into a larger space, which is the space of priority measures on Rd times the priority measures on Rd, simply by taking eta of dx times the d direct mass at the conditional distribution of a second coordinate of dp. Coordinate of dp and then relative compactness is for free. But what becomes more difficult is that in the limit, we don't have guarantee that the direct conditional distribution of p given x is preserved. Okay? And that's the reason why. And that's the reason why we assume convexity of the cost function in its second variable. This permits, in fact, to say that the integral of the cost with respect to capital P of dx d par dp, in fact, when we decompose as When we decompose as usual with mu of dx and the conditional distribution of p given x, then by convexity in the second argument, we see that it's greater than the integral of c of x and the mean, in fact, and this is the way The way that one can recover the direct conditional distribution in the end. And the last result is that in dimension one, when we suppose that the cost function capital C is continuous, then we have stability. Then we have stability. In fact, the value function converge. And we also have the convergence of the optimizer that was stated in the previous results. And moreover, convergence in adapted Weiser Schein distance when the cost function is strictly convex in the measure argument. In the measure argument, so that there is a single optimizer. Okay, and how can we obtain the fact that upper subicontinuity of the value function also holds? This is the place where we use our approximation of Martangal couplings. Martangal couplings, in fact. So we take M star to be a minimizer of W mode for the limiting marginals mu and U. And we are able to approximate this by Martangel couplings between mu n and mu n, which converge in adapted Vasor Shine distance. But convergence in adapted Vasor Schneid distance is equivalent. Strain distance is equivalent to convergence in usual Vasov strain distance on the large space of probability measures over R times priority measure over R. So J is as before this embedding. And so we have that the value function for mu n mu n is smaller than the The value function corresponding to the Martangal coupling in the approximating sequence Mn. And this is the same as the integral over the enlarged space of C of X pi P times the the J of M N. J of Mn and we have all we need to ensure that this converges to the integral against J of M star. So we obtain that we have upper semi-continuity for the value function. And that's the end of my talk. Thank you for your attention. End of my talk. Thank you for your attention. Yeah, thanks a lot for this nice talk. Are there any questions, comments? Thank you, Benjamin, for your talk. I have one small, a bit vague question. Namely, we can see these problems that. We can see these problems that happen in dimension higher than two when we are dealing with martingal transfer, these instabilities and so on. Do you have a hunch for what should be imposed additionally to the marginal sequences that could rule out the problems that we see? I had no clear answer, but in another work with Gilles Pages, what we did is to use primal quantization of mu and dual quantization of mu. Okay. And then for this particular approximation, we We have a convergence of the value functions. Okay? So this is somehow restrictive because to make dual quantization possible, we need the measure to have bonded support. Still, this gives at least some numerical applications. A numerical approximation which is feasible in higher dimension. Thank you. I had a question as well. Yes, go ahead. Sorry, it's loops. If I use my computer, so I have to do this quickly. Menjamo, so in even in dimension one, So, even in dimension one, do you have any idea of the dependence of the convergence on the number of time steps? On the number of time steps? Yes, so in your last bits, you just had two steps, but at the beginning, you had the mu, right? You have many, I think you had several time steps. So, when in when you had about When you had adapted, I think in my talk, I had only two steps. So the convergence results are just for two steps. Yes, yes. The convergence is also just for two steps. And you expect it to hold it for three steps, et cetera, for more steps in adapted Wasserstein in the same way? Or do you think your methods will go through? Or is that? Will go through, or is that um, it's not obvious, at least it's not obvious, but we can uh deduce for several steps. Thank you. Okay, so there's do not seem to be any further. So, there do not seem to be any further questions. So, let's thank Benjamin for this nice talk again. And we'll switch to the last talk of this workshop, which will be in person.