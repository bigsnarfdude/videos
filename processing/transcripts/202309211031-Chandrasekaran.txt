Approximating model of K-partition via principal partition sequence. This is based on joint work with my advicee, Wei Hang Wa. She finished her PhD and joined the industry. Let me begin by introducing the terms in the title, submodular functions. So a function is submodular if for every pair of subsets A and B, the sum of the function values on A and B is at least the sum of the function values on The sum of the function values on intersectional union. And so modularity can equivalently be expressed by this notion of diminishing marginal returns. And it arises frequent spleen commuter optimization. Some well-known examples of submodular functions include the graph, hypergraph type function, matroid rank function, and coverage function. I think for this audience, I don't have to I think for this audience, I don't have to emphasize all of this. I suppose most of you are familiar with these functions. The main problem of interest to this work is submodular k partition. Here we are given a submodular function over a finite ground set V. We will assume non-negativity. We are going to approximate, so we are going to assume non-negativity here. And the function is given through an evaluation oracle. Through an evaluation oracle. Given a set, the oracle will tell you the function value of that set. This is the standard input model. And for most special cases of submodular functions, this oracle can be implemented to run in polynomial time. So this is a reasonable model. And we are also given a positive integer k. The goal is to find a partition of the ground set into k non-empty parts. Non-empty parts in order to minimize the sum of the function values of the parts. And the non-emptiness will be the only constraint that we will enforce in this problem. And such a partition, a partition of the ground set into k non-empty parts, we will call it as a k partition. And that's where the name comes from. We would like to find a k partition of the ground set to minimize the sum of the function values of the. To minimize the sum of the function values of the parts, and this function is going to be submodular. That's the setting. Right. Submodular k partition, you can cast several partitioning problems as special cases of submodular k partition. In particular, think about the special case where the submodular function of interest is the graph cut function. And if this case 2, then This case 2, then this is simply global min cut in the graph. So it generalizes global min cut in graphs and submodular non-trivial minimization. You can cast several problems as special cases, several partitioning problems as special cases of submodular k partition. But global min cut and submodular non-trivial minimization, these are polynomial time-solvable mainly because k is 2. Here we will Here we will be interested in the case of k being part of input. So, k could depend on the size of the round set. In this case, the problem becomes n p hal. And one can get order k approximation for this problem. And even th this is non-trivial. Even getting order k approximation is non-trivial. But this k seems too large. Order k approximation seems too large. Seems too large. So, the question we start asking is: can we get better approximations for broad families of submodular functions? We look at three broad families here. Firstly, we look at symmetric submodular functions. A function is symmetric if for every subset A, the function value on A is equal to the function value on the complement of A. And it's easy to see that the graph cut function is symmetric. The second family that we consider is monotone submodular functions. Function is monotone if for every pair of subsets A and B, the function value on A is at most the function value on B if A is a subset of B. Right, and it's easy to see that matroid rank functions and coverage functions are monotone. So these well-known examples fall into these categories. We consider third. We consider a third subfamily which generalizes symmetric submodular and monotonous submodular, namely posimodular submodular functions. A function is posimodular if for every pair of subsets A and B, the sum of the function values on A and B is at least the sum of the function values on A minus B and B minus A. And it should be easy to see that monotone functions are possible model because f of a minus b is at most f of a. Because f of A minus B is at most f of A, F of B minus A is at most F of B. So, monoton functions are in fact posimodular. It's not difficult to also show that symmetry and submodularity also implies possimodularity. Symmetric submodular functions are also possimodular and submodular. In fact, I don't know of any other functions, natural functions, which are possimodular, submodular. Are posimodular, submodular, apart from these two families and their positive linear combinations. Maybe there is no other function, or maybe there is, I don't know. So I have not encountered this, but it seems like a clean generalization of both these families. That's why we ended up here. I thought there's a clean generalization. Right. So those are the three families we will see. Cost modeler, submodular, K-partition. Poisson modular submodular K partition, symmetric submodular K partition, and monotone submodular K partition. Those are the three problems of interest for this talk. Special cases, it's helpful to understand special cases of submodular functions which fall under these categories. For example, if the submodular function of interest is the cut function of a graph, then the corresponding problem of an explicitly given graph, then the corresponding problem is known as graph K-cut. Known as graph K-cut, and this is one of the well-studied special cases of submodulant K-burdition. This is typically taught in approx courses and so on. Right, so we will come back to this. If the submodular function of interest is the cut function of a hypergraph, then you end up with hypergraph k partition, not so well studied. If the submodular function of interest is the coverage function, Coverage function. So you can think of coverage function, you can view it via hypergraphs. So if it is a coverage function, then you end up with coverage k partition. And in fact, coverage k partition where the input is in fact an explicitly given graph, even this has not been studied, which was somewhat strange. Yeah, that's a special case of Meritons of Model K-partition, and then you can also look at You can also look at the rank function of matroids as the submodular function of interest. And a special case of that would be this matrix k-partitioning problem, where you're given a matrix and an integer k, you would like to partition the rows of the matrix into k non-empty parts to minimize the sum of the dimensions of the subspaces spanned by these parts. This seems like a linear algebra problem, but I don't know of any tools from linear algebra that will help you. From linear algebra, that will help you out. This is better cast, or at least solved through the submodular connection. Right, so these are all some special cases that fall into these categories. And in fact, all problems at the bottom level are NP-hard. So, all these are NP-hard. So, let's talk about the approximation status. Right, so we wanted. Right, so we want to talk about approximation status of these three families of submodular functions. I will also use a column for the well-studied special case, namely when you do hypergraph partitioning, you're referring to the version where a hyper edge plays the number of sets that it in the partition that it cuts, right? So when I think of hypergraph k-partition, the sum K partition, the submodel function is the cut function of the hypergram. Right, right. So if you want to think about it, a hyper edge could cross several parts. And you pay for all for all the hydrogen. Yeah, it pays as many as. There's another model where you pay only one independently of the number of sets. But that that's not ca captured by this model. That is not captured by model or submod that's a special case of submodular k-partition. So that's uh Modular k partition. So that's a separate special case. And that is even that is generalization of graph K cut. And that has strong inapproximately the cells also. Yeah, that doesn't fall under that. But there are two other hypergraph partitioning problems. This hypergraph K partition, where you're interested in the cut function, that's a special case of this. And if you're interested in the coverage function of the hypergraction, And if you're interested in the coverage function of the hypergraph, then that's a special case of model also modeling. And yeah, there is one more version that I'm not going to talk about. Right, so all these problems are hard. Let's go to the approximation status. I'm going to use this first column for GraphK-cut. This is the well-studied special case. In fact, there are several techniques known which all achieve a two approximation for Graph K-cut. Approximation for graph K cut. Don't worry about all these techniques, but you can get to approximation. This is known. And under the small set expansion hypothesis, this 2 is the best achievable. You cannot get better than 2 minus epsilon. Right, let's go to symmetrics of model K partition, which generalizes graph K partition. K-cut. The symmetrics of model k-partition generalizes graph k-cut. Turns out some of these techniques have been generalized and they give a 2 approximation for symmetrics of model k partition. Note that this 2 is much better than k. For general sub-model k partition, we are only getting k approximation. So now we are getting 2 here. And is this 2 tight? Turns out this 2 is tight assuming polynomial number of function evaluations. Function evaluations. Recall the input model, the sub-model function is given through the evaluation oracle. If we are allowed to make only a polynomial number of function evaluations, then you cannot get better than through approximation. What is what? No graph in the easy problem. There is no graph in the problem, but every symmetrics of model function admits a Gomorrhythm tree. Model function admits a Gomorrhy2 tree, and you can use that the same thing that you would do for GraphKut, you can do the same, and it gives a two-approximation if you know Gumeri Hood trees. But I'm not going to talk about Gumeri Hood trees here. Right, so we have the type factor for symmetrics of model K partition. Let's go to monotone. One of these techniques has been generalized and shown that it has been. And shown that it achieves a two-approximation. But if you only care for a two-approximation, there is a much simpler algorithm. For monotones of modular functions, you just look at k minus 1 singletons, you order the elements based on the function value, function value of singletons, and you pick the cheapest k minus 1 singletons and throw the remaining into the last part. This is already a close approximation. There is a very simple algorithm. Is a very simple algorithm, so you don't have to do 3D splitting. If you only want to, you can do this. Lower bound, assuming polynomial number of function evaluations, you cannot get better than 4 third. There is this gap between 2 and 4 third, upper and lower bounds. Posse modeler, submodeler, k-partition, turns out nobody has studied this. We were the first ones to see it as a generalization of symmetric. Generalization of symmetric and monoton. So, we arrived at this because we thought 2 should be the right answer for both, and it should be the right answer for posse model, submodel, kth addition as well. So, that was the conjecture that I gave to the student. I'll tell you a bit more about this. So, we said, okay, let's first see the greedy splitting. Since that has generalized for these two, can you generalize it to that? And we were in, so this Zaun Nagamul Chevara. This Zao Nagamul Chibaraki did not look at possible modular submodular functions, but we were able to adapt their analysis, whatever the lemmas they had, and see that it implies a three approximation for possible modular submodules partition. And so my conjecture was this, and of course, yeah, the lower bound is also two because it generalizes these two, so the best lower bound will be four. And my conjecture was this four-thirds should go up to two, and this three should. To 2, and this 3 should come down to 2. And there should be a lot of structure to nature and problems. So that was the initial conjecture. So, anyway, so this was the status. And we see this gap between lower and upper bounds for monotone and possible modules of K-partition. In fact, even for those special cases, coverage K-partition and matroid K-partition, 2 was the best known. And as you can see, 2 is very simple algorithm. simple algorithm. Right, so this is the status. You can get two here, two there, and two here, and three there. Right, so in this work we decided to focus on this principal partition sequence based algorithm. I'll tell you what principal partition sequence is, even if you don't care about submodel K partition and all these problems, I think it's a nice structural statement about submodel. Nice structural statement about submodular functions, and it's good to know. Right, so this technique was introduced by Narayan and Rav and Phatkar in the 90s. Got it? Yeah. So this three is still the best? No, we will get to it. So yeah, this principal partition sequence, this was this algorithm for submodular K-partition was introduced by Narayan and Rao. Was introduced by Narayanan, Rao, and Padkar. And for some reason, this paper and its results are not well known in the Aprox literature. And its results have been rediscovered a couple of times since 96. Firstly, their results for Graph K-cut, they already showed that it's a two-approximation. And much later, Ravi and Sinha, they reproved the same thing. Thing. A lot of you may be aware of this Ravi Sinha paper. Turns out it's in fact a rediscovery. And then a couple of years ago, or last year, there was another paper that rediscovered the results of NRP for some hypergraph partitioning problems. Anyway, so it was a rediscovery, and I did mention this to Ravi around 2019 before the pandemic. I mentioned this to Ravi, and he graciously. And he graciously said you should write a short note mentioning that it is a rediscovery. But I felt it would be silly to write a short note saying something is a rediscovery, so I didn't do anything about it. And then I also mentioned this to Chandra. And Chandra said, okay, maybe we can ask this question: what is the approximation factor of this algorithm for symmetrix of modular k-partition? And so that's And so that's that we quickly realized it's two factors. So we were able to quickly see this. And that only recovers old results. So again, still not interested in writing a note. And then we put it aside and student, I said at least put it in your thesis to the student. And at that point, while writing the thesis, we decided to ask these two questions: monotone submodular K partition and possibular submodular K partition. And then we were able to analyze the approximation factor and show that it achieves the lower bound. So it achieves the best factor for both monotone submodular K partition and possibular submodular K partition. Right, so that's the story. So now we get 4/3 here and 2 there. And in fact, this gives better results even for coverage K-partition and Matroid K. For coverage k-partition and matroid k-partition, which were not known before. And then, yeah, this ended up being a paper. Right, so let me now tell you about the principal partition sequence. What is principal partition sequence? So recall we have a submodular function. We are going to create, we are going to define a new function. There is a function, a univariate function g of lambda. Of lambda, it's the minimum over all partitions of the ground set of the sum of the function values of the parts minus lambda times the number of parts. Lambda is the variable now. It's the minimum over all such partitions of this quantity. Now, how does this function g look like? You can try plotting it as a function of lambda and you will quickly realize that this is in fact a Quickly realize that this is in fact a piecewise continuous function. So you don't need submodularity or anything. Any set function f, you realize, okay, this is a linear function of lambda. You are taking a minimum of a collection of linear functions. So this is a piecewise linear function and you will have at most ground set minus one great one. Pi is a k partition or just a partition? Pi is any partition. Pi, yeah, there is no restriction here. Right, so you click quickly realize this. Right, so you you click quickly realize this. Now let's care about the partitions which achieve the minimum between these breakpoints. Let's call these pi 1 to pi r plus 1. Now turns out if the function f that you start off with is submodular, then you can say more about these breakpoint partitions. Turns out the leftmost partition pi 1 is the ground set. It consists of only one part, the entire ground set. Of only one part, the entire ground set. The rightmost partition breaks it into singletons. Consists of B parts. V is the size of the number of elements in the ground set. So you break it into singletons. What can you say about the intermediate partitions between these breakpoints which achieve the minimum in G? So there is the partition which achieves the minimum and it's going to be the same between two adjacent breakpoints. And is there some connection between the Is there some connection between the subsequent and the previous one? Turns out the subsequent partition refines exactly one part of the previous partition. Pi 1 is already one part, pi 2 will refine that part. That will be the second partition. Pi 3 will refine exactly one part of pi 2. And pi 4 will refine exactly one part of pi 3 and so on. This gives us a sequence of partitions where every A sequence of partitions where every partition is a refinement of exactly one part of the previous partition. And this sequence is called the principal partition sequence of submodular functions. This theorem was shown by Narayanan in 91. And you can also find this sequence in polynomial time using polynomial number of function evaluations. This is This was shown by Narayana, and this is also mentioned as a passing remark in Fuji Shige's book. But beyond that, there is not much literature on this. Narayanan has a few papers on this using this, but that's about it. Right, so based on this sequence, principal partition sequence, Narayanan showed a lattice structure associated with the principal partitions, but for our purpose, we will But for our purpose, we will think of it as a sequence. Right, so once you have the sequence, here is the algorithm proposed by Narayan and Raman Putkar for submodular k partition. They said compute the sequence. Now, if you see that one of the partitions in the sequence has exactly k parts, then you return them. And it's not hard to see, this will be an optimum. You don't have to worry about approximation. This is in fact an optimum. So one of the parts. Is in fact an optimum. So if one of the partitions in the sequence has exactly k parts, then return it and it's the optimal thing to do with that. Otherwise, so let me do this with an example. So suppose this is the principal partition sequence and suppose k is 6. You realize that, okay, this has 4 parts, that has 7 parts, 1, 2, 3, 4, 5, 6, 7. So after that, every subsequent partition refines it further. So you will only get more. Refines it further, so you will only get more parts. So you are going to get a six-partition by suitably refining pi 2. And how do you refine this? Well, you look at all parts which are not refined by pi 3, they are all going to be parts of the partition that you return. So you get 3 parts. If you need 6, you get 3 parts. Now you look at the part which is refined by pi 3 and you order these parts based on function values. And you pick the cheapest two parts. Cheapest two parts. You'll get five parts, and then you throw the remaining into the last part, that's your sixth part. That's the algorithm. And that's what I've stated here. And this is the algorithm. And then, yeah, let me quickly flash the analysis of this algorithm for monotone submodular K-partition. This is the new. This is the new result, so I want to tell you the last question. If they were exactly a part of K, that's true for any sub-bounder function, no symmetry, nothing required. It will be the optimum for yeah, you don't need non-negativity also. So, this is like the Lagrangian relaxation. This is the Lagrangian relaxation. So, this quantity is of interest for other reasons also. But yeah. But the key thing is that this refinement happens. Is this refinement happens because it is a submodular function. Otherwise, the statement is not true in general for arbitrary components. Right, so analysis, as I said, the easy case is if you have a partition with exactly k parts in the sequence, then you are optimum. Otherwise, you look at the case where you don't have a partition with exactly k parts, then you will have. Exactly k parts, then you will have two adjacent partitions in the sequence which straddle k in the number of parts. You look at that and you see you show these two lower bounds. So pi i minus 1 is refined to get your k partition and pi i also refines this pi i minus 1. And one can show these two lower bounds and these two upper bounds. I won't exactly go into the details here. So we just followed the nose and just said okay these. Followed the nose and just said, okay, these are the lower bounds, these are some upper bounds. So let's see what is the factor it gives. We said, okay, the best lower bound is the minimum of these two. And sorry, the best upper bound is the minimum of these two. And the best lower bound is the max of those two. Now compare the min to the max, and a bit of algebra immediately told us it's four-third. And that was the complete analysis. We ended up with the four-third factor. This is not something that we. This is not something that we set out to prove. This was just something that we just follow the nose and take some natural upper and lower bounds and things work up. So if instead of the sort of the best parts, like if you choose random, like skinning random previous picture but you sort of chose uh randomly two parts and the rest does it still go? Yeah, it's still in expectation also it goes through, so it's the same. Right, I won't go into the details, but each of these is fairly simple. The first lower bound is just application of submodularity, three lines. Second one is submodularity, four lines. This is submodularity, three lines, and this is Modularity, three lines, and this is no submodularity, just monotonousity and the greedy choice of the DIs. This is where you use this. Each one is about three lines. I won't go into all those. How big are your lines? That's it. That's your proof. Not as big as yours. You were trying to optimize for that. Of course, yeah. The paper, the line. Of course, yeah, the paper, the lines are much longer. This is after we wrote the paper, I realized this can be done. It's all as simple as this. Right, so that's the status. So we are able to get the best factor for monotone submodular k-partition and possibular submodular k-partition. The analysis is for symmetric and possible modular for almost the same. You just use the same lower bounds, stare at the upper bounds. Stare at the upper bounds a little bit, use symmetry or post-modularity, adjust it, and you get the true factor. Yeah, so let me emphasize the open questions here. So we said for monotone submodular k partition, we can get a 4 third approximation. In particular, that gives 4 thirds for these two problems: coverage K partition and matrix K partition. Coverage K partition, you're given a, you can think of You're given a and think of graph. Think of the graph. You're given a graph and integer k, you would like to partition the ground set into k non-empty parts to minimize the sum of the coverage values of the k parts. You can get 4 third, but we don't know if this is the best possible. What's the inapproximability of this? And matrix K partition. This seems like a linear algebra problem. And we can get 4 third. We know that both are n. 4/3, we know that both are NP-hard, that's all we know. Lower bounds, we don't know anything further. And so it would be nice to see if 4-3rd is tight for these special cases, or can we go below 4-third? Alright, thank you very much. Any questions? Is it the general submarine? Is there a lot of questions? For general submodular functions, you can get a k approximation. What's lower bound? Lower bound is what is known from these special cases. Q is the best. So, what goes wrong? Did you try it? Oh, so that particular algorithm, we also got an example where it's not even k approximation, it could be as big as n. Is there still an inspiration? No, because the example is should not fall into these three categories. Should not fall into these three categories. So it's a contrived example. And it's not even a k approximation. So it's not the best one for general submodel or k projection. Does four-thirds lower bound apply to Matroid? No. So this four-thirds does, it's clever hiding of something. So this is information theoretic lower bound. Unlike our usual. So these are clever hiding of information, optimal things. Information, optimal things fortunately. Yeah, that's why I'm asking this question. It's not the focus on the talk, but then the key is like constant or a key is parameter, like what is the case fixed constant, then the story is very different and I've spent a lot of time on this. We don't know the so for mo no, even this I don't know. Uh yeah, for k equals ten, is there a polytime algorithm? I don't know. Yeah, for up to k equals four, we have polytime out of it. Then yeah, up to k equal to special cases on the last slide, do you know if the principal origin sequence has any additional special in this case? Do they have it? No, I didn't think about it. Possibly, I don't know. 