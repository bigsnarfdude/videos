And evolution of natural selection from an information-centric perspective. And today I'm going to talk about, I mean, this is a problem we've really been struggling with and not made all that much headway on, but I think the closest we've come to getting anywhere is in his most recent paper. This is work from a graduate student of mine, Ryan McGee, and former graduate student now at Washington University as a postdoc in collaboration with Libya Coster Litz-Ben Kerr and Artem Kaznachi. And so, you know, you can picture that if you want to see the. So, you know, you can take a picture of that if you want to see the preprint and on the bioRxive and so on. If we think about the sort of tremendous diversity of biological form, think about the exquisite fit of biological organisms to their environments, to their niches, to their life histories, and all of that. You realize there's got to be a tremendous amount of information that goes into building a phenotype. And that, of course, you know. And of course, you know, that information is encoded to some degree, or we can argue about exactly what that means. And philosophers do when they goaded me into arguing with them about it. But that information is encoded in the genotype. And then we can ask, well, where does that information come from? And before Darwin, it was divine creation. And then Darwin gives us a mechanism. And so a lot of that information, especially the adaptive parts of it, are coming from natural selection. From natural selection. And so, in particular, oh, and this is this guy, this is from yesterday. This guy was up in Grassy Lakes, way up on a cliffside in a cave. That's his nest there. But in any case, organisms need to, I like this because it feels like someone said this is that they say that they say he's more mountain than owl. And so, organisms need. So, organisms need to match their phenotypes to their environments, they need to match them to their niches, their life histories, etc. And natural selection is providing, taking that information, encoding that into genomes. And so we can think about, you know, for example, a mouse that has to sort of decide about what kind of phenotype does it want to produce. Decide, well, this is the developmental decision making. And perhaps it's going to find itself in a light-colored environment, perhaps it's going to find itself in a Perhaps it's going to find itself in a dark-colored environment, and hopefully, it's got some information in the genome that tells it what to do. And you can kind of think about what the process of getting that information into the genome would look like. You know, you'd have a bunch of mice in a light-colored environment. In fact, people have done exactly these experiments with live owl predators and things like this. You have a bunch of mice that are in an environment like this. Maybe you have sort of equal allele frequencies or equal phenotype frequencies to start with. Frequencies to start with. And then, you know, sort of along comes a hawk and picks off one of the dark mice. The allele frequencies start to change, and more hawks come along, and the allele frequencies change more, and you get more hawks. And this process kind of continues. And what we end up with is a change in allele frequencies and a pile, so to speak, of dead mice. And these are really the core consequences, the core kind of quantities I want to talk about today is this change in allele. About today, is this change in allele frequencies as it reflects the incorporation of information about the environment into the genomes of the population and the size of this pile of dead mice? So after this has gone on for a while, of course, this mouse sort of wakes up into the world, gets this message from mom in the genome. The environment is light, so grow like firm, or rather, maybe a little bit more precisely, given that it inherited a lot. Given that it inherited a life for all, its likely life for has been favored in the past, and so it's likely to be beneficial now. And so, this is why Michael Lachman and I say that every bit of adaptive information in your genome was paid for in the blood of your ancestors' children. It doesn't get any more metal than that, right? So, it's literally, you know, every bit of adaptive information in your genome is because there was some other bit of information that was switched a different way, and one of your other ancestors. A different way, and one of your other ancestors' other children, and that was wrong. And here it was. So, yeah, so great. We're population geneticists, mathematical biologists. So, can we quantify this? And I think so. This is what I've been trying to figure out and do for many years. Let's talk about, and again, this is, you know, this slide is a paper and so on. But, you know, adaptive information. When I'm thinking about adaptive information, adaptive genetic information, I'm thinking about the inherited material that reduces an organism. That reduces an organism's uncertainty about its current environment so that its expected fitness is bigger than it would be by chance alone. And one way I might like to think about this would be sort of imagine the state of the environment as a random variable. The environment could be one way, could be another way, could have been one way, could have been another way, could be one place, could be another. And think of the genome as another random variable. There's a distribution of genomes, actual and counterfactual. And so you sort of wake up in the world. One morning, you're newly fertilized zygote or something, and you're in some environment, that's a random variable, and you've got some genome, that's another random variable. And the mutual information, the natural selection, builds up over time as the mutual information between the genome and the environment, which is the entropy of the environment minus the entropy of the environment conditional on the genome. We can measure how much of that entropy. We can measure how much of that information has been put in there by looking at how much allele frequencies have changed due to selection. So these are just basic identities in information theory. This mutual information term is equal to the Kolbeck-Leibler divergence between the joint probability distribution of gene and environment versus the product of the marginal, sort of if they were independent, which in sort of a basic model where you start out without any correlation is equal to the joint probability distribution. The joint probability distribution now, the KL divergence between the joint probability distribution now after selection has acted for a long time and the joint probability distribution before selection started doing anything. So what kind of happens is, you know, you have this, you have a range of different types, natural selection starts to act, allele frequencies change, and we can look at that, how much they've changed by this divergence. This gives us some sort of information measure, and so it's not a problem. And so it's not a proper distance, but it's a divergence. We can think about, you know, if we have different phenotypes, you might evolve by some arc along here. And at any given time, we can look at, well, how far has the population traveled? Sort of total distance that it might need to travel to get to the optimal phenotype would be, you know, this kind of a divergence. In fact, these things, there's actually sort of a potential information, and this thing moves up a gradient to the Moves up a gradient to the potential information surface, and so on and so forth. That's again another talk. Instead, let's step back to say 70 years ago. We've got Haldane and Kimura thinking about this pile of dead mice. How big does it have to be to do things, right? And so they're able to write down some of the kind of mathematics of load, and in particular, And in particular, you know, they're trying to understand what selective deaths look like. And Jamira introduces the notion of selective load and the basic idea, or substitution load, and the basic idea with that was if you think of this now we're switching from mice to bacteria, but you know, imagine you've got some blue bacteria and red bacteria, and the environment turns out to be propitious for red bacteria. So the red ones grow nicely, the blue ones don't. Red ones grow nicely, the blue ones don't grow as well as they could, and after some period of time, we have you know a set of blue ones that could have been but aren't because they didn't have the right phenotype, the red ones that are, and then we're looking at the difference between the fitness of the optimal type or the growth rate of the optimal type and the growth rate of these other sub-optimal types. And then we sum that across all the different types according to the type frequencies. According to the type frequencies, look at that, integrate that out over time, and that gives us a measure of all the types, all the populace. How much growth could there have been that there wasn't? So again, this is sort of the fitness of the optimal type. This is the average fitness in the population. This time integral gives us the substitution load. And people sometimes complain about talking about costs of natural selection or loads or things like that. But I think Joe Felsenstein used to say, But I think Joe Felsenstein says, What do you mean, the cost of natural selection? Natural selection is a benefit, it's not a cost. And Joe says, Well, no, it's appropriate to speak of the cost of selection because it comes from the fact that selection is less efficient, slower than divine intervention. It would be better if God could just do that, and then you'd all be the optimal type, but he doesn't for whatever reason. And so, there's a cost of doing it the heart, right? So, where are So, where are we so far? So, we've got this notion of information gain that I've talked about, which is this KL divergence in wheel frequencies. We've got a concept of substitution load, and we want to think about how these relate to one another. And the first thing is that Kumura shows in his 61 paper that as time gets large, these are equal. So, as time gets large, information gains. Gets large, information gain equals the substitution load, converges to the substitution load, which is remarkable because these are very different kinds of quantities. Turns out, if you use Timura's model, you can prove, and we do, that not only do they equal each other, that as t goes to infinity, but the load is a strict upper bound, or it's an upper bound on the information as well. And then a little aside, right, so. Little aside, right? So, what's that? What are the meaningful units? These are substitution load, so information gains. I mean, this is part of what's amazing about it, right? So, a substitution load is like a fold, it's like a fold, substitutional load is like a fold loss in potential growth. And so, information gain is measuring fold changes in information. So, fold or bits, essentially, are the units. Are the units. So, a little aside, right? So, Kimura is thinking about the sort of substitution load problem, and this is what it's called into: well, there are all these different boci. And so, you know, you got substitution load here and substitution load there, and there, and there, and there, and there, and there, there, and there. And, oh, the load is too damn high, right? And so, substitution load becomes so large, no species can tolerate it. I know. Substitution, there isn't substitution. Substitution, there isn't substitution above it, most of the loci because they're neutral. This is the genesis of the neutral theory. So, yeah, so this is sort of all based on this theoretical model of a thought experiment, if you will, that Jamara does. And it was only possible to be a thought experiment when Jamira wrote the paper, but now we can move past that with sort of current lab technology, and we can actually do this thought experiment in practice in the lab. Experiment in practice in the lab. So we did it. We started out with a bunch of different strains of bacteria. These are different variants of the RPOB locus with different fitnesses and basic growth medium. We label them with fluorescent labels. We grow them up in stationary phase for sort of away from stationary phase, grow them up in exponential growth for 36 hours. So hopefully constant growth conditions. And then you can sort of see the changing allele frequency. You can sort of see the changing allele frequencies just in the stacks of points that we have afterwards. We can look by measuring the frequencies of the different strains, we can measure this sort of this divergence term, look at how much information has gone into the population. So these are these information measures. By measuring the growth rates of the various straits, we can measure the population growth rate, the type Population growth rate, the type growth rates of the optimal types, all of that. We can get measures of this substitution load, and then we put those together to get this picture like we're talking about. What happens to substitution load, what happens to the amount of information acquired. And this is what we find. So, typical trace, you see sort of one type replacing the other, and then we see something like this, and that's not. And that's not good because these are supposed to converge and this one's always supposed to be smaller. So what went wrong? Right? And so is Trimura wrong? What happened? So then we kind of look carefully at the data and we notice, aha, there's one piece of Trimura's model that is not matched in our experiment. Even in our most tightly controlled lab conditions, we can't keep the fitnesses constant. So there's some fitness fluctuation over time. Fluctuation over time in that system. So we go back to the drawing board, and here's the sort of illustration of fitnesses variant. We go back to the drawing board. Chimera has this model where fitnesses are completely constant. Now we just adjust that and create what we call mismatch mode, where we allow fitnesses to vary over time. Redo all the mathematics, and we can come up with another version of Chimera's basic formula. Basic formula. The same inequalities hold, same convergence holds. We re-plot this using our mismatch load, and now we get these beautiful curves like this. And these beautiful curves, in fact, show up, you know, for all of the experiments, we do different strains competing against each other, starting at different starting frequencies, and so on. And over and over, we see this relationship where the amount of information going into the population converges from below to the From below to the substitution level. Okay, that's the basic experiment, the basic finding. I'm just going to kind of tease where this goes next because I want to talk about loss and regret. And I want to talk about loss and regret not out of sort of midlife issues, but rather out of computational learning theory issues. So loss is the payoff cost of a population playing where Of a population playing or a player playing a strategy that's not perfectly tuned to the current state of the environment. Regret is the cost of having to learn that strategy. So, you know, if you have an environment that's stochastic, you may, even playing the best possible strategy, you'll still suffer some loss because you'll get unlucky. But it may take you a while to even get to that best possible strategy. Regret is the part where you're like, well, damn it, I should have been able to just jump there by defining dimension, but I couldn't. So we have these concepts of loss and regret and computation. Concepts of loss and regret in computational learning theory. And by thinking about regret, we can extend very broadly our results about substitutional load from very simple models like the one I showed to more complicated ones that do all kinds of cool things and look at much more complicated environments. So what we could show in general is that the load of an evolving population is always bounded above by the load of the best, the loss of the best population, best type in the population. Best type in the population, plus this information gain. So this is your, this is a, this is a, this is a, so low and low bounded by this, plus, so this is a, this is a loss term, this is a regret term, right? And we can look at different situations. So we can say, you know, stochastic environments, different individuals in the same population end up with different environmental conditions. And so you have different environments, different phenotypes, different phenotypes are best for different environments, but each one each Different environments, but each individual gets a random draw. Of these three types, the best one turns out to be this one. There is continual loss because this isn't best for everybody. It would be nice to assign each person to each individual to the proper environment, but you can't. But this is the best you can do. So, what you see is you see this cumulative loss increasing, but if you look at regret, the amount of information, this COVID-like divergence term, Term behaves just like we saw in this case of fixed environments. We can look at cycling environments. They're a little bit more complicated, but you can kind of work out math for these kinds of things. We can do games. We can do frequency-dependent fitnesses. So you have a rock, paper, scissors kinds of situation, and now you have a weird thing where the information gain kind of fluctuates like this, but converges to the regret term. And so we can do all these kinds of things. This is sort of more. And so we can do all these kinds of things. This is sort of more of a teaser for the paper than the actual paper. Prove a bunch of theorems. The information gain converges to the regret, no matter what model we use. We can show that the information gain is bounded above by what we call empirical regret, which is a slightly more complicated thing. It's a measure of regret not taken to anything that could possibly have happened, not in the computer science worst case scenario, but it's ex-post-metal. Case scenario, but it's an ex post measure of regret given what actually did happen in the sort of particular sequence of environments. And then finally, and then I'll open it up for questions, we can show that among learning algorithms, natural selection is never far from optimal in the sense of minimizing regret. For certain kinds of environments, there'll be more responsive algorithms, fall with a leader-type algorithm. Algorithms follow the leader-type algorithms that will do somewhat better. For other kinds of environments, you'll want less responsive environments, but we can sort of put bounds on how bad natural selection is. And the bottom line is it's not very bad. It's actually very, very good. So with that, yeah, that's the talk. You can read the paper, which actually has all of these theorems and proofs and kind of a big experimental section and way too much kind of computational learning theory for my taste. Computational learning theory for my taste. But that's just Brian and Arkham are excellent at that. So thank you very much for listening. Couple of questions, please. Yeah, Joanna. So consider a case of not just generation to generation and the model that you have, but multiple like this pages. Okay. And then taking. And then tighten this with play approach. So one alley all is better at one history stage, one allele is better at the other. You could also think of fluctuating selection, like seasonally adapting flies or whatever. Some are better at winter, some are better at summer. The cost of selection in terms of your platform dead mice increases in an unbounded pattern. That's right, that's loss. Okay. Okay, so that doesn't go, that's not going to converge to your information. No, that doesn't. It's regret that converges to information. Yeah, okay. So, yeah, because I think the history of this field is troubled by confusing load with, which Kimira did, with cost. That's right. So, I think the separation between loss and regret solves that. Yeah, so I think, I mean, I think what we're doing. Yeah, so I think what you're doing has very little to do with cost. It's sort of about more like this, it's about clarification of different modes. It's just coming out of this general line of thinking. I'm not claiming to have solved the cost of natural selection problem per se. I'm claiming to have found a way to apply computational learning theory to think clearly about the selective consequences of putting information in genomes. Is the discrepancy between the load and the information content that a selective death leads not only to the absence of that individual but all of its descendants, so it takes a while for information to catch up? Or do you have another intuition? I don't have a good intuition for that, Sally. I wish I did. It's kind of stupid that I don't. But maybe thinking about it. I need to figure that out. That's an excellent question. I should just say, oh, it's this, right? Right. I think it has to do with the curvature of the way these things are measured, but I don't have a sharper intuition than that. Do we have time for that? Let's just get going. Thanks, Prov. Okay, thank you. So next,