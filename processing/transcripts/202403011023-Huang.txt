Thanks to the organizers for putting together this wonderful workshop. So, today I'm excited to tell you about a new group of the priest formula for spherical spectroscopy. This is joint work with Mart Salki, Lizzer. So, um this talk will be about mean field spend losses. Will be about mean field spin losses, which are random polynomials with Gaussian coefficients. And usually we take the domain to either be the Boolean cube or the sphere of radius. So one well-known and easy-to-state example is the SK model. This is a random quadratic over the cube defined as follows. You write down all n squared monomials of degree 2, put an independent Gaussian in front of each one, and I Independent Gaussian in front of each one, and that. So that's the model, and maybe one of the most basic things you might want to know about it is what's the maximum value with high probability in some suitable scale limit. This is called the ground state energy. And it's already quite a difficult problem because of the randomness of these coefficients. So these pi k's determine whether you want the spin sigma i and sigma k to agree or disagree. To agree or disagree. But you can often run into situations like this, where maybe this pair of spins wants to agree, this pair wants to agree, this pair wants to agree, but then that pair wants to disagree. So a priori, it's sort of unclear what the optimal sigma should look like or what the maximum ought to be. Another example of a spin glass, which Chris already talked about, is the p-spin model, where you do the same sort of thing but over degree p. But over degree p instead of g. So you write down all n to the p monomials of degree p, put a Gaussian in front of each one, and add them up. And this factor in front is for normalization. So the SK model corresponds to p equals 2. And even more generally, even more generally, you can take linear Even more generally, you can take linear combinations of these piecemeal models to get what's called a mixed piece of model. So, this is specified by a sequence of scalars, beta p, that tells you how much every degree is participating. And this is, as I said, studied over either the cube or the sphere, and these are called the easing or spherical mixed easing models. For the rest of this talk, we'll package this sequence of scalars beta p into this graphic psi, which is To this parameter psi, which formally is a generating function, but just think of it as specifying the model in some way. And these spin glass models are closely related to other problems studied in this community. So it is way smaller. Because otherwise, the clicking will trade out a problem by clicking is the size of the case. Maybe let's try that one. Yeah. So one example is the Tensor PCA problem. Is the tensor PCA problem that Chris just discussed. Another that David talked about earlier this week is random constraint satisfaction problems like random max cut or max set. So if you take these problems in the large constraint density limit, appropriately recenter and rescale, you get exactly the unmixed views of the whole. They also show up naturally as posteriors in various high-dimensional Bayesian reference tasks. So, in STEM class theory, one of the central things that's studied is the free energy, which you can think of as a sort of softmax version of the ground state. So, this is defined through a partition function, which is this integral over the sphere, or analogous to the sum over the cube, of this e to the sum inverse temperature times the Hamiltonian. This inverse temperature parameter beta controls how close. Parameter beta controls how close this off max will be to a real max. When beta goes to infinity, this becomes the real max. And free energy is just the rescaled logarithm of this. And the main question we'll care about is if we fix all the parameters and send the system size to infinity, then what's the limit value of this reaction? Right, so a word on this inverse temperature beta. So let's remember that this Hamiltonian. Beta, so let's remember that this Hamiltonian H already had some scalars built in, so we might as well absorb beta into H. And from now on, we'll think of this as the partition function. A closely related object is this Gibbs measure. This is a random measure supported on the sphere where every point sigma is weighted by e to the Hamiltonian at that point. So we'll also be interested in the limiting behavior of this Gibbs measure. For example, if you take two samples, If you take two samples, call it replicas from this Gibbs measure, what's the law of their normalized inner product, which is called the overlap? This model originated in the statistical physics literature, and physicists have come up with many beautiful predictions about this model, many of which have by now been proven. So I want to share with you this beautiful picture. So these predictions come in terms of an order. Predictions come in terms of an order parameter, which is a probability measure on the unit interval. This can be a discrete measure, a continuous measure, or any combination. And we'll always identify a measure with its CDF, which is some essentially arbitrary increase in function from the unit interval to itself. And the order parameter to have in mind here is the overlap of the function. So this is, again, this limiting law of this overlap of two replications. Law of this overlap of two replicas. And there's two predictions both packaged in the Parisi formula. So the first is that the limiting free energy is the minimum of a certain Parisi functional, which I won't write down. But this Parisi functional takes us input a probability measure like we discussed and this size specifying the model like we discussed. So this is some measure value. Is some measure-valued optimization problem, and the prediction is the minimum is the Linux reaction. The other prediction is that the minimizer is exactly this overlap distribution zeta star. Yet another prediction is about the limiting geometry of the Gibbs measures. This is called ultratricity, and it roughly says that the limiting Gibbs measures. Limiting Gibbs measures live on the leaves of a tree. More precisely, the Gibbs measure is a convex combination of pure states equipped with a hierarchical kind of clustering structure. So to explain what this all means, let's look at this picture on the left. Then each of these blue clouds is a pure state. Think of this as meaning some. Of this, as meaning some well-concentrated measure that's localized to some region of the sphere, or analogously to the Q. Then these pure states come in clusters. So these three pure states are in one cluster, these are in another, these are in a month. You can also have a more complicated structure like clusters of clusters, third-order clusters, and so on. And here's what clustering will mean formally. Will mean formally. We can identify every pure state with its barycenter, some point in R to be M. We can identify every cluster with the barycenter of all the pure states underneath it. And so on and forth. So this gives you some collection of points in R to be n, which you can think of as a tree in the natural way by drawing these like parent-to-child line segments. And ultimately means that all of these line segments. Means that all of these line segments are approximately pairwise orthogonal. So this tree has a sort of orthogonal branching structure. And because of that, we can kind of represent this tree schematically like this picture on the right. So the vertical axis here represents radius. All of these pure states will live at some radius, and then their parents will live at some smaller radius, and so on all the way up. This is radius in the sphere. In the sphere. Yeah. Okay. The queue here does not have anything to do with overlap. Yes. Yes. Yeah. So maybe a word on... Yes. Yeah, maybe a word on why this is called ultrotricity. So if we consider any two leaves of this tree, sigma u here, sigma v here, then if you squint Then, if you squint at this orthogonally branching structure for a second, you'll notice that the inner product of these two leaves is basically the depth of these common ancestors of U and P because all these steps are orthogonal. And this sort of means that this inner product will induce. This inner product will induce a tree-like similarity structure on the leaves. And that's why this is called ultra-cursion. And in particular, the overlap of these two points is the radius squared of whatever their leads combined system is. So to bring all this back to the overlap distribution, let's consider any two samples from this given. Any two samples from this Gibbs measure. So, one possibility is they're from the same pure state. Then, their inner product will be roughly the radius of whatever that pure state center was squared. Another possibility is they're from neighboring pure states, in which case their inner product will be the radius of whatever that parent cluster was, square root, and so on. So, the set of possible overlaps of two samples from the Gibbs measure should be precisely the set of squared radii of points where this tree has hoods. So for this to make sense, this tree will branch at precisely the radii in the support of, or radius squared, in the support of this Parisian metric. So that's how all this connects together. So that's how all this connects together. And maybe another way to say that is this zeta star, which we remember is the minimizer to the Parisi functional, it has some support on the unit interval, and this support is a sort of specification for this tree. It's telling you exactly what radii this tree is supposed to represent. And perhaps just one more note on this, it's possible for this zeta star to have a continuous support. And this corresponds to a sort of continuous. And this corresponds to a sort of continuous branching of the limit, which goes by the name of full run 700. Okay, so sorry if I'm just like being slow, but the... I mean, if you have continuous support, does that not mean that if I sample two points independently on a rest, the overlap is going to be zero or the super measure of the Of the pairs of points that are descendant from the same node should be really small. I think there's a sort of order of limits being happening here. So maybe at Finite, I can think of this brick as happening at some speed that's growing, but not learning. So, this is what happens in the general. So this is what happens in the general case when you have a mixture, but say if you just get like tensor themselves, like then is it a finite tree or is it still an um it will in general oh I said for for a pure um spherical piece then uh there'll be it'll be a finite tree. It's a finite piece. I guess now's a good time for mushrooms. More questions. Yeah, so that is kind of the very beautiful predictor painted by physics. And by now, most of these predictions have been rigorously shown. So I'll just give a brief history of the rigorous results. And these hold for both the easing and spherical mix of these intervals. So basically, all the settings that we've talked about so far. First, Guera showed that. First, Guerra showed that the Parisi formula is an upper bound on the free energy. This uses an interpolation argument, where he says, let's interpolate from this spin glass, which is some complicated Gaussian process, to a much simpler Gaussian process. And along this path, the free energy will only go up. So you get it up and down. Then Talibrand proved that this is tight and thereby proves the priest formula. So his proof is essentially analytic. So his proof is essentially analytic and works by sort of self-bounding the error from where it's on the bound. Later on, Panchenko proved that the limiting Gibbs measures are in fact ultrametric. And this gives a new proof of the Parisi formula based on sort of induction on the number of spins. So the way this works is you ask things like: if you have a system of 10 spins and you add 100 more spins, how much does the free energy increase? And if you understand this, then you can kind of read off a lot. This will boil down to understanding the Gibbs measures at a very fine-grained level, because if you can do that, then you can sort of read off, if I add in 100 more spins, how much of the energy will increase. And this ultrametricity conjecture gives you the control needed to do that. In more recent progress, Jaganov, Subag, and Chatterchen-Slowman showed various forms. Showed various forms of approximate qualitricity at finite n. And also, Jacqueline Tabasco showed that for spherical models, this Parisi measure is always just a finite combination of atomic and continuous pieces. So you don't ever have this infinite complexity, and you don't ever have some weird measure theory happening. And this will be useful later on. Our main result is. Our main result is a new proof of the lower bound in the Prize formula for spherical models. So, this is not a new result, but we've reproved this result using a new approach that sheds light on different aspects of this problem, and which we hope will be useful in the future for models where some of these questions are still open. Our approach at its heart is geometric. So, we will directly construct an ultrametric tree. Construct an ultrametric tree of pure states in R to the N that looks like what the Paris on size predicts. So, more precisely, we start with this zeta star that minimizes the Paris football. It's a sum measure. Its support is supposed to be where this tree is branching. And then we will cook up a tree matching that specification, where all the pure states have the free energy predicted by Paris. Predicted by current. The way we do so is by breaking down this zeta star into smaller and easy-to-understand pieces. So, roughly speaking, every discrete piece and every continuous piece. And we show that if we can understand how to build this tree for these basic pieces, then there will be a way to kind of stack them together to get a tree for an arbitrarily complicated crazy measure. So, in this toy example, I've drawn a CDF. Toy example, I've drawn a CDF of some zeta star where the boundary is three discrete components with boundary at radius one-third and two-thirds. And this corresponds to this tree on the right, where the bottommost piece is this depth one tree rooted at the origin with children at radius one-third. So this is the tree corresponding to this piece. And then at each of these child nodes, we make that the root of a tree. Make that the root of a tree with Children at radius two-thirds, corresponding to this purple piece. And then the pure states live at radius two-thirds. So before stating the result formally, let's just briefly remind ourselves the setting we're in. We're working with the spherical mixed piecemeal model. So this is described by this sequence of parameters beta packaged into this. Packaged into this generating function psi. We're working over the spheres of the free energy this integral. Here's our result. Let's consider any sequence of radii in the support of the Parisian tree, where the biggest radius, Qd, is maximum of the support. So this is the radius that the pure states are supposed to live at. So I gave an example here. So, I gave an example here. Here's a CDF of some example zeta star drawn sideways. So, its support is zero, and then this increasing interval. And we picked some q0, q1, and q2 in this support where q2 is the maximum. Our result says, let's let k be any constant area. Then, there exists an ultrametric constellation. An ultrametric constellation of points indexed by a K area tree. So this picture over here, where this is ultrametric, meaning that all of the points live at the correct radius, and all of these line segments are parallelized orthogonal. And around each leaf. So around each leaf, you can draw a band. So maybe Maybe this point here is the leaf, then you can draw a thin orthogonal band around it where this integral over just this band already has the free energy predicted by the Priest formula. So, just given one of these bands witnesses the lower bound in the Paris formula, and we construct a whole tree of them. Um is this uh like okay is this implied by the previous lower god, but you don't know how to construct these the set of uh I mean the tree? Or is it like it something new that wouldn't have been applied to the previous low-down? So I guess Pemchenko's result also says that this Michael's result also says that this tree exists. We show how to construct it. Okay, so you have like an algorithmic proof of this? I wouldn't call it algorithmic because some steps of this are like some steps of this construction are by a second moment method. I see. Yeah, but it's like by a combination of algorithm plus second moment method. And Tego's proposal says that a single band will form this tripolar band? I think so, but I'm not sure. Okay, I guess in the rest of this talk, I just want to give you some ideas from the proof. So one idea already alluded to earlier is a decomposition of the model into little or easy to understand pieces. So let me first tell you what it means to decompose one model into two little models. Model into two little boys. Let's remember that our model is a random polynomial on this sphere of radius 3n. Well, we can pick any number r between 0 and 1. I'll tell you how to pick it later. And let's draw two spheres. The first sphere will be this purple sphere of radius root rn centered at the origin. And for the second, we first pick a non-random point on this purple sphere, and then draw the orthogonal band to it living in the big. Band to it living in the big sphere. So this is some sphere of codimensional. And now we think about the restriction of this spin glass Hamiltonian, this random polynomial, onto each of these spheres. So each of these restrictions is a spin glass, or is a Gaussian process on some sphere, and that makes it a spin glass in its own right. And we just say that this main spin glass decomposes into these two. Spin glass decomposes into these two little spin glasses. And of course, we can iterate this operation. So we can then decompose this orange sphere further into smaller spheres. And by doing this, we can kind of slice at any sequence of radii we want. And we'll pick the radii to slice at depending on this sigma star, so that this will inform what we got. So by the sequence of radii, you mean like in every lower code dimension you're going to. In every lower code dimension, you're going to choose different radius or so we'll slice at a superset of these Q's where we wanted to build a tree at. So basically we slice at every Q, and we slice every time Zeta star either has a new atom or switches from discrete to continuous or back. So each of these kind of transition points in the CDF. And this And this will decompose this big model into several little models belonging to one of four types. The first type here is the, we call this the topologically trivial type. This is where zeta star is zero. The second type is the replica symmetric type, or the pure state type, where zeta star equals one. The third type is the one RSB type, where it's flat and not equal to zero or one. And not equal to 0 or 1. And the last type is the full RSV type, where it's increasing. So there could be at most one topologically trivial piece, which has to be at the beginning. And there will be one relevant symmetric piece at the end. But in the middle, you can have an arbitrary number of these pieces. But there will always be a finitely many number of pieces because of this junketh and the basketball result that I control. So, the reason this decomposition is useful is that it gives a lower bound on the free energy. So, it turns out that the free energy of the main model is always lower bounded by the sum of the ground state energies of the first D model, so all but the last one, and the free energy of the last one. To see why, maybe let's consider this two-model decomposition. Model decomposition again. We said that this black point is a non-random point, but let's suppose for a second that this were the maximizer on the purple sphere. Then, roughly speaking, the free energy of this orange band will be its typical value, but shifted up by whatever energy this pump had. So, you get this inequality for two models. And by iterating this, you get this kind of inequality for arbitrarily many. Get this kind of inequality for arbitrarily many models. Okay, I am being a bit imprecise here. So these models are not literally independent. If you know that the center of the orange band is the maximizer on the purple band, then its law isn't exactly the original law shifted up by something. But at the level of free energy, this turns out to be okay due to a uniform concentration of Eli and Simoke. So somehow this all works. And this also gives a strategy for constructing a pure state. So maybe let's consider a model whose overlap distribution is three pieces. Then when we try to construct, so the following strategy will locate a pure state. We first look at the radius one-third sphere, find a maximizer of that. Find a maximizer of that, and then look around in the orthological band that goes out to radius two-thirds. Find a maximizer of that, and then this will be a pure state tree. And furthermore, this strategy also lets you build a tree. So if you can find k orthogonal maximizers like each of the E guys, then by doing the same sort of thing, you gotta treat this one. But, okay. But, okay, back to this. The reason this works is that this inequality turns out to be tight. So, if you kind of plug in the right answer for each of these terms, which is given by the Parisi formula, then you get an equality. And I want to maybe emphasize that this is not anything magic. So, the reason this happens is if each of these terms is some variational problem. And if you look at And if you look at the minimizer of that term, it turns out to be the, you know, just zeta star restricted to the corresponding interval, then kind of reparametrizable. So both sides of this equation are really solving the same calculus problem, but the right-hand side was doing so in several places. But this gives us a strategy for, it gives us a pathway for showing this lower bound, because it means that. Showing this lower bound, because it means that if we can show each of these terms is lower bounded by the corresponding term here, then just adding up, we get the previous lower bound. So we've now reduced our task from showing this for all models to just showing it for these fundamental models. And this is what we'll do. So, I guess more precisely, we want to show the free energy lower bound for RS models and the ground state energy lower bound for the remaining models. Ground state energy lower bound for the remaining poles. And out of these four types, two are already understood. So, in the topologically trivial case, this was done by Efeodurov. And the story here is that in these models, these models typically have just one local max and minim on the whole sphere. And the energy of the max can be characterized through the catspheres. In the full RSB case, the story is that the ground state energy. The story is that the ground state energy is witnessed by an algorithm, this very beautiful algorithm by Subat, which picked off a whole line of work on algorithmic limits of optimizing spin pulses. So now our task is just to understand the free energy of replica symmetric models and the ground state energy of one RSV models. And this is what we'll do. So we achieve this by a truncated second moment method. By a truncated second moment method. And I'll explain this for the RS models. So the one RSB case will be kind of the more complicated, but in spirit, a similar version of this. So if you write out what the Parisian lower bound says for replica symmetric models, it amounts to showing that the partition function is typically on the same exponential scale as its expectation. So the natural way to try to show this is by So, the natural way to try to show this is by a second moment method. So, if the second moment of C is typically the first moment squared, then the moral. But it turns out that this is not always the case, because sometimes the second moment ends up being dominated by pairs with overlap, like a half. And we will fix this through a new truncated second moment method. So, we say that a point is taken. We say that a point is typical if these two spherical caps of points that are not almost orthogonal to this point sigma accounts for a small fraction of this partition function. And we show that we can do the second moment method on this truncation and it will give the right answer. So this truncation makes the truncated second moment makes the truncated second moment equal to the ordinary first moment squared kind of automatically. So the main content of the proof is to show that the truncation didn't really hurt the first moment. And the way we do this is by understanding what the dominant contribution to the first moment looks like. So the dominant contribution will come from points all with some around some certain energy. And we show that, okay, well. Show that, okay. Well, first, so conditional on sigma having this energy, this Hamiltonian will basically be a spin glass with a planted spike in the direction of this point. And this is something we know how to analyze. So in each of these non-equator orthogonal bands, 2 sigma, the free energy can be upper bounded using this, whereas upper bound to the president won. And this shows. And this shows that if sigma has this energy, then with high probability it is typical. And therefore, this truncation didn't really hurt the first moment. So then putting everything together, this truncated second moment method gives you the free energy for all RS models and a similar truncated second moment, but now uncredible things. So this will again go. So, this will again go through the Katz-Rex formula. It gives you the ground state energy of all NRSB models, and in fact, also shows that you get this K-orthogonal maximizer that I talked about here. And therefore, when you stack these trees together, you can build this tree witnessing the pre-C lower bound for no matter what Zeta star you started out with. I'll end with a question. With a question. So, this tree witnesses the free energy of overbound, which means it accounts for at least a e to the minus little o n fraction of the structure. Can we ask for something stronger? Can we construct such a tree that also exhausts a one minus little o n fraction of the kiss measure tree? That's all I have. Thank you. Okay, thanks first. That was a fantastic discussion question. Sorry, go ahead. Since this is sort of a self-reducibility thing of like, you know, at each point, as you say, the sphere around it is another spin glass. In Subag's bound, why doesn't the entropy of the intermediate things matter? Why is the free energy just the sum of the ground state energies plus the free energy glass? State energies plus the free energy of the last thing, as opposed to like the sum of the free energies all the way through. Is there an easy explanation? And if not, I'll ask you some questions. Yeah, ma ma maybe ask that one. Okay, great. Okay. So, I'm curious if you wanted to make this truly algorithm. With the use of just like existence by a psychonomic? I mean, is there like, does this suggest a pathway towards that? I don't think so, because these second-moment, like, okay, the second-moment steps are kind of it's it's not algorithmic and um we sort of have lower balance um for algorithms at a different energy yeah good point yeah yeah so idea of your hardness though. Yeah, so the picture here is like in these kind of second moment pieces, you have these like many kind of orthogonal maximizers, but it's hard to find any of them because like for each of them, think it's like a tensor PCA instance, but you don't even get this like. Yeah, I see. Get this like. Yeah, I see. So, so for the context, I guess, to set this up, you could say, well, we pressed this for the algorithmic threshold for essentially the same model, right? So, here you're asking for sort of the existence threshold. So, in the matrix case, you can do this, and that's sort of how the, like Ahmed and Andrea's work works to go down to the ground state by taking the sequence of orthogonal steps. Yeah, so the in the matrix case, you're kind of in the 4RSP type of model, so it's all work. But also you can find these maximizers, because that is just a spectral thing or something. Thanks so much for coming. It's been super fun to meet you. Thanks for awesome meeting you guys. So next time.