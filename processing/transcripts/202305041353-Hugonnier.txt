Continuous time of self-protection. Thank you, Jaksha, and thank you, all the organizers, for the invitation, and to everybody for this amazing conference. So today I'm going to present a joint work with Nabi, who is in this room, and his student, Sarah Bon Salem, who now moved to the industry and is working in an insurance company. So this work is of insurance and it's motivated by a a paper from the seventies. A paper from the 70s by Erlich and Becker, in which they say that there are two main actions that people can take in order to reduce their exposure to risk. So the first one is what they call self-protection. And these are actions that reduce the probability of people having a loss or an accident. And the second one is called self-insurance. And this action reduces the size of an accident when it happens. Size of an accident when it happens. So, to give some examples, for instance, in health insurance, if you try to exercise yourself and to try to be fit, this would be self-insurance because it is known that some diseases hit you less hard if you are fit than if you are not. And self-protection could be if you know that. If you know that in your family there is the gene of a cancer disease, then some people can take prevention surgeries. So they remove some organ from their body and what they're doing is to reduce the probability of actually getting the cancer. And the main two uh conclusions from this work is that uh market insurance and self-insurance are economically substitutes. Are economically substituted, and market insurance and self-protection are complex. So, in a previous work with Navila and Sara, we studied a static model for both self-insurance and self-protection. And now, what we want to do is to set a simple model in continuous time for the self-protection problem, which is much difficult than self-insurance. Probably I'm going to Probably I'm going to explain later why. Okay, so this is our model. So we have an insurance seller and an insurance buyer, and they are going to sign a contract for a time period. The idea is that the buyer is going to choose a proportion alpha between 0 and 1, which is going to be the fraction of the losses that are going to be covered by the seller. And for that, he's going to pay a premium that we denote pi of. That we denote pi of alpha. So the accidents for us are going to be modeled through a comparison process. So you have this random variable set ID and the idea is that the prevention effort that the variable is going to do is to control the intensity of this Poisson process, M. And by doing so, this prevention effort is costly, so the Is costly, so the buyer has to pay some cost function. Okay, and nowadays it is becoming more common the idea that in insurance contracts you should reward the good clients. So we have this feature in which at the end of the contract there is going to be a reimbursement for the buyer, which is this random variable chi alpha. Chi alpha, depending on how many accidents happened during the life of the contract. And the idea, of course, is that the reinforcement is never going to be higher than what was originally failed at the beginning. So we have this FT measurable random variable which is bounded. Ah and and the filtration is uh generated by process J. Okay? So what the buyer wants to do. No, no. Okay. But yeah. It doesn't change things very much. So what the buyer wants to do is to maximize his wealth at the end of the contract. So there is going to be an initial wealth, the reimbursement that he receives minus the premium that is paid. And this is the fraction of the losses that is not covered. So 1 minus alpha times the losses. And he's also paying. And he's also paying the cost of their actions, of the prevention efforts. So, this is a picture of interaction. So, the insurance seller is giving coverage alpha and is also giving a reimbursement at the end. And the buyer is paying the premium and is doing some effort to reduce the accidents. So, we are going to focus only on the problem of the buyer. So, we are going to solve this problem in which So we are going to solve this problem in which the buyer wants to choose optimally what is the fraction that he wants to declare and what is the optimal prevention effort. So let me give you some examples of this reimbursement that we are introducing in the contract. Of course if you consider contracts which have no reimbursement, this is just taking the random variable chi equal to Taking the random value of G equal to zero. And then, if you want to do things more interesting in the reinsurance market, this is reinsurance means that the buyer is already an insurer to another person. So, it is pretty common to, when you share the losses in reinsurance, the reinsurer at the end is going to pay back some fraction of the earnings that we made. So, in this case, we have a random variable with this form. We have a random variable with this form. So P is the proportion of the earnings that are given back, and this is the profit made by the insurer. Now here we have a random variable which depends only on the terminal time of the process J, but you can also find more sophisticated examples. For instance, again, in the real insurance market, we have the e-commerce contracts in which basically In which basically there is a random variable R, which is going to be the reinsurance. So here there is that you order all the losses, you rank the losses and you are going to cover only the highest one, but compare against the L highest loss. So if this contract, when you put what is called an out-ring bonus, it means that if there is no reinsurance at all, There is no reinforce at all. If this random variable r is equal to zero, then you still get something back. Okay, and this is going to be a deterministic value that here we call t of r. Okay, so now mathematically, what is the problem of the insurance buyer? So, as I said, he wants to optimize over some real numbers alpha and some space of optimization. A space of optimal prevention efforts that we assume here we only put integrability conditions in order to have everything well defined. So, what we're going to do is to split this optimization in two. First, if we fix some value for this number alpha, then we can write this problem for a given level of coverage and we end up with a stochastic control problem for. Control kroner for the bike. This is something that we know how to handle. So I'm going to show you first what happens when there is no reimbursement, because this is one of the main conclusions of our work. So we have the simple case in which this random variable is equal to zero. And this is simple because in this case the problem In this case, the problem of the prevention effort becomes more poignant. So, as usual, you can write the dynamic version of the problem. So, you define this value function d alpha and you can write the problem as maximizing the utility, this is exponential utility, of the terminal value of this control process. Okay. And then we all know that you can write. We all know that we can write the PVE associated to this problem. In this case, the Hamilton-Jacobi-Reynold equation is a PIDE because of the jumps, right? So you have this form here. I didn't say, but this function G is the CDF of the losses, of the random variable set, and you have natural listing up here. Okay? So fortunately So uh fortunately for us, uh in this setting uh we can solve explicitly this P E. Uh so we tried with some exponential functions and it worked. So we have this explicit solution which is also smooth. Okay so we have this form with this term which contains the optimization in the effort variable. So then we So, then we can use the classical verification results in stochastic control, and we can say that the value of the problem with fixed coverage, what we're looking for, is just the smooth solution to the PVE evaluated at the initial conditions. Okay? So, what is important from here is that you can also say that the optimal prevention effort is going to be given by the optimization that we have up here. And if you look carefully, you can see that Look carefully, you can see that this is not time-dependent. So, what happens in the absence of reimbursement is that the optimal prevention effort is going to be constant. And this means that now, from the point of view of the seller, there is no way to give incentives to have a dynamical effort. And this can be pretty bad because there are some examples in which actually. Some examples in which actually what is going to happen is that this tar is just zero and the value of insurance is never going to do anything to reduce the risk. Okay? And then of course the same that I say applies not only when t is equal to zero, but also if the reimbursement is independent of the process j, then we have the same situation. Situation. So, here, just to show you an example, very simple. Suppose that the company Poisson is just a Poisson, so all the losses are equal to one. Suppose that we have a linear control of the intensity, so the agent can reduce the intensity up to some minimum value, the minimum epsilon, so he cannot make it zero. And suppose that the agent has a linear cost. So, here this problem is going to have a blank-bank solution. A plan-bank solution. So, depending on what is the value of the cost compared to the coverage, the optimal prevention effort of the agent is going to be either zero or one minus of sine. So, here basically what happens is that since the agent is, the value sorry, is choosing the value of alpha, if the value gets a sufficiently high alpha, then we are going to be in this first case. To be in this first case, and then he doesn't need to do any prevention effort at all on doing all the contract. So, from the point of view of the seller, this is not very good. So, now we move to the general case in which we have this random reimbursement that is going to give the appropriate incentives to the buyer. Okay, so here now the Here, now the full problem of the buyer is what is written here. And for the ones that are familiar with contract theory and the principal agent problem, you can notice that this is very similar to the problem of the agent, to the usual problem of an agent. Okay, so you are receiving some random payment at the end of the contract, you are paying some cost of your actions, and here maybe the new is that you also have. And here, maybe the new is that you also are losing or you are carrying some cost coming from the state process, but nonetheless you can still use the main ideas, the dynamic programming approach that was developed by Jacksia Dilan Amiser, and you can prove that the value of this problem you can identify it with the solution to a DSD. So in this case, we have exponential utility of YC. exponential utility of y0 alpha and where y alpha and h alpha are the solution to this BSD chunks. Okay, so this is pretty standard, this is the generator of the BSD and here you have the optimization in the F or variable which is going to give you also what is the potential F. Okay, so if you define So if you define what is called the optimizer function in this generator, so if you call the point that attains the infimum here, if you call it h star of h, then we can also deduce from the dynamic programming approach that the prevention effort of the buyer is going to be this function E star applied to the second component of the solution to the previous PSD. Okay, so now that we know how to find the prevention effort for any given level of coverage, we move to the full problem in which the buyer also has to choose optimally what is the proportion of the losses that he wants to be covered against. So, here this is just, if you look at this problem, this is just an optimization in R and over R. In R and over a compact interval, so you need very mild assumptions, for instance, for the premium pi. You need it to be just lower than equal in 20 in order to hope for a solution to this problem. Here, I also say that the premium is not decreasing, but this is like a modeling assumption because it is very natural to think that if you want to receive more coverage, then you have to pay more. Okay? But then But then, since we have some kind of continuity on the premium, to have a solution to this problem, we just need to make sure that there is also some continuity on the value we alpha, which is a stability resource for PSPs. So what we do is to assume that this reinforcement, these random variables, are linear continuous in L2, which, by the way, Which, by the way, is a very reasonable assumption because all the examples that I gave you of reimbursement satisfy this condition. So we are not losing much generality. So then when the terminal conditions of the BSDs are lit cheat, we can prove also that in our case our generation of the BSDs is equally cheap. So then we can prove that this mapping We can prove that this mapping that goes from alpha to the initial value of the solution y alpha is continuous. And then you are optimizing a lower semi-continuous function over a compact set. You know that there exists an optimal intrans curve alpha star which attains the value of the flow. And then just to conclude, if we go back Just to conclude, uh if we go back to the previous uh example in which you have uh Poisson dossiers, the linear control and the intensity and linear cost. There is a very common type of the premiums that we have this form. This is called the safety loading premiums, in which you are basically what you charge for the insurance is the expectation of the The expectation of the loss times this term one plus theta. So this number theta is what determines the price of the insurance and this is called a safety load in fact. So in this case if we look at this particular type of premiums we can also solve explicitly what is going to be the optimal coverage for the agent. And in this case what is important from this expression compared to From this expression, compared to the usual results in the literature, is that we can see some complementarity between the value of the premium and the optimal choice of the insurance, because this is a decreasing function of theta. And then also something which is not very common is that in this model you can obtain intermediate choices. I mean values of alpha that are strictly between 0 and 1, because in most of the models, Because in most of the models, you either get full insurance or no insurance at all. So I think I went fast, but thank you. Here the price is given, the pie is given. So there is no pipe risk or increase. The price of the reimbursement is given. So, in terms of the point of view of the seller, if you want alpha, you pay by alpha. No, no, no, this is interesting because this is just the here. So, this is the usual picture of this eval agent, but we are doing only the agent, right? If you want to now look at what would be the Now, look at what would be the optimal choice of the premium under reimbursement. Then you can again do the dynamic programming approach by D La Jack Cha Missa. So you can write, I guess, to write the reimbursement as the terminal value of the continuation you did divide. But then you have this kind of constraints, this one, so you will be facing what is called a So you will be facing a what is called a stochastic target problem. So the value, the continuation value of the buyer cannot be anything, it has to belong to this set. So again, it can be done, but it's much more complicated than we have diagnosed. Thank you, Microsoft. 