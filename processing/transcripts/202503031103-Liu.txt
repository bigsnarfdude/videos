And ongoing work with Daimy and Sheen on data-driven matching for mutation and heterogeneous demand and supply. And unfortunately, we are going back to the bipartisan team. So in this work, we can see the generic bipartisan models with demand nodes on one side and supply nodes on the other side. I will use J to index my demand nodes and K to index my supply nodes. What's the difference here is that agents are Here is that agents arrive at this node according to some continuous time renewal processes with arrival rate them at the so it's not like a discrete time model, this is a continuous time model with a general renewal arrival processes. Upon arrivals, these agents will wait at their respective node waiting to get matched. If it is in right half then, you can think of the left-hand side as modeling passengers at different locations requesting a drive and waiting to get matched. Requesting a drive and waiting to be matched with a driver. And the right-hand side of the figure would be modeling drivers becoming idle at different locations and waiting to get matched with a peasant. But more generally, the node here is not restricted to some physical locations. It actually refers to a type of worker or a type of customers. And how to define that type will be tailored to some city applications. And VJK here is the matching value I get if I match a type J agent with a type K agent. After being matched, both agents will leave the system immediately. So you can think of it as a queuing system with instances surface. I'm also going to pin light waiting because and most of the time we do not want to wait. So CW here is the holding cost incurred per unit time for each type W agent waiting in the system. Each type W agent within the system. Moreover, we assume that agents are inpatients in the sense that each agent has a patient's time, random patience time, drawn from this general distribution, patient time distribution. So we allow it to be general, and you need to have a density, and it's CDF is strictly increased, and that's all. Aligning with relationship, I'm going to call it the renaging distribution. This is because if agents wait longer than their pay. If agents wait longer than their patient's time, they will be matched without being matched. So, given the heterogeneous matching values, holding cost, and customer abandonment, there is a natural trade-off between making matches quickly versus waiting to enable better matches. And the focus of our work is to develop a matching policy that can make this trade-off optimal. So, here by matching policy, I mean a policy. By matching policy, I mean a policy that determines when and who to match over time. Is everything clear about the setup? So we are not the first one to consider a matching model with renegotians. I'm showing you here some of the work here. But this work assumes that the renegotian distribution is known. And what we are going to do in this paper is a matching model with unknown parameters. Specifically, the arrival rates lambdas and the re-enagging distribution g's are unknown to us. Our objective is to find a matching policy M to maximize this long-range average objective that consists of the total matching values I get minus the potential polling cost. So, in here, the function MJPT here is the cumulative number of matches between type. Number of matches between type J agents and type K agents over the time interval 0 to 5 T. Yes? Is the Renanging distribution dependent on the waiting time at Q length or is it independent for each? It's independent. So the relation distribution is high specific, but it is IID joint for each each of the arrival agents. So this MJPT function is determined by the matching policy that I choose. Determined by the matching policy that I choose. And the function QWS here, this is the QN function that tracks the number of type W agents waiting in the system at time s. So by taking an integration over the time interval and multiplied by the waiting cost, I'm having the cumulative waiting cost hit my seminars. This is my objective. And if we look at, oh yes, because we have Yes, because we have these unknown parameters, we will assume offline data. Basically, we will have IID samples on the inter-arrival times and the renaging times. And we will let have lambda and have G be empirical estimates of the arrival rates and the relaging distributions. For other talk, I will try to use the orange color to highlight things that is either unknown or estimated from data. If you look at other work, they consider If you look at other work they consider learning in the matching models, their focus is primarily on learning matching values or types. There's either no renaming or degenerate renaming. And we are the first work to consider learning the renegotiating distributions in a matching system. And this learning problem is not easy because we did not assume a personal arrival and we did not assume an exponential patience time. So for the states, So, for the state's system state to be Markovian, we need to track the time elapsed since the last arrival of each class. We also need to track the potential waiting times of each class, which determine the abandonment process. A very complicated space implies that there's no known optimal policy, and we cannot fully explore using dynamic programming. So, learning an optimal policy appears difficult. Our focus is to learn. Our focus is to learn a fully optimal policy. For this purpose, I'm going to ignore the stochastic and discrete nature of arrival. And let's pretend we have ground-true knowledge on the arrival rates and relation times for this moment. This will allow us to write out this ground-true fluid meshing problem, which uses ground-true knowledge on the arrival lambdas and the remaining CDF, which is embedded in. JCDF, which is embedded in the QLN function here, and I'm going to talk about that later. So the decision variable of this optimization problem is the next string rate MJK. This is the instantaneous, yes. Just to help me before you go through the math rate, like what is the fluid system supposed to look like? Because here you have these departures matching. I'm not sure what this is. So you can think of this arrivals, they're just like flowing into the system. Flowing into the system at a rate of lambda. So, which Q is going to which Q of Q is going to be non-empty in the total? Basically, if you do not match everything from a specific type, then the Q line will be non-empty. Yes, yes. I'm going to talk about that. Okay, so my deserial variable is MJK here. This is the instantaneous rate at which I match type J agent with type K agent. This process here ensures that I cannot match more. Ensure that I cannot match more demand and supply than in summer. For example, if you look at the first constraint here, if I take a sum over O J with MJK, I'm having the total rate at which I'm matching type K H. And this total rate cannot be greater than the arrival rate, which is lambda K. And a key ingredient in this optimization problem is the Q length function Q here. So it is dependent on the machinery and it approximates the On the machine rate, and it approximates the steady staining QLAF. So, I'm giving you the mathematical expressions here. I'm not going to go into too much details of that, but there is theoretical underpinning showing that these QLAN functions will arise as a formal temperature limit of the fully scale QLAN. So, provide you some integration and go back to your question. This is the QLAM functions when the relational diffusion is differential. So, we can see that QLAM. So we can see that Q lambda equals to lambda over theta, where 1 over theta is the mean patient's time. Multiplied by this quantity, this is the fraction of type J demand that I'm left unmatched. So if I match everything, I will have 0 here, so the Q ln is 0. If I do not match, I match nothing, then this continuum will be 1, and the Q length will be just lambda over theta, which aligns with. Lambda over theta, which aligns with the little slope, because one over theta is the mutation sign, and lambda is the arrival. However, the dependence here is not always linear. If the Rienasian distribution is uniform, then we will have this quadratic dependence. And for some distribution, there is no closed-form expression for this kilogram. I'm trying to situate your model. So you have Golden cost and you have Renaigans. Yeah. And you have some Q. Yeah. And you have some cues that will not be fully matched. Is there some grounding application? Because I'm thinking that: hey, if I'm never going to match this person, not like half of this queue is going to go unmatched, why make them wait and cause a holding cost and then wait for them to resign. Just tell them not to join and wait for them. The issue is that we so in the ideal world we would like to match everyone, right? And the issue is that if the if the arrival here is imbalanced in some sense. Is imbalance in some sense. We have supply arrival and demand supply. In order to serve the demand, you need to have the supply. And QLAF will build up in that case. So here, you can think of the I am making a trade-off of having a specific type of agent to wait. Which type of agent I want it to have a longer wait time in the system. But at the same time, the QLAT is also helping you to make valuable matches. To make valuable matches. Because if you wait a little bit for the QNAM to build up, you can determine the most valuable mesh. And that would be the fundamental trade-off in this automatic. You're talking about data-driven estimation. Is there like one application I can keep in mind? Where can I use your method? You can think of a case where, like the route hiding platform, where we do not have the underlying one-traw arrival rates every natural distribution. You just observe this over data on them. In ride-hailing, I can tell the customer that there are no cars available, so I will not make them wait until they limit. Yeah, if that's possible. But your model, you're not letting, you're not a luxury entry, is not a lever for the platform, only matching it with the computer. We are not considering that level. We are letting customers to choose their behavior based on their own patients' time distribution. So, prior work has shown that we can construct a discrete rule policy that bases on an optimal solution to this optimizer problem. Yes, just to Yash's question, wouldn't you always add a dummy thing somewhere with value zero to say that whenever you want to discard something, it gets matched to the dummy? Uh what do you mean by discard something? Here I'm we are not controlling the behavior of the man at arrival. Their abandonment is due to their own patient stuff. That's not a decision That's not a decision. Yes, please. Is the main goal learning the parameters or is the main go goal finding a good policy? Finding a good policy. So basically we will start with a set of historical data and we will transform it to an implementable machine policy. And we are going to establish performance guarantees on that policy based on the amount of data we have. Of data we have. To Jasha's point, if you knew the parameters and you had, because you've learned them and you had found your policy, at that point it would be easy to tell some demand not to show up, right? Because you know, sort of, hey, I have that much of my lambda k left that I'm not matching anyway, so I can tell a tenth of my. I can tell a tenth of my Lambda K customers don't join. I realize that's not in your model. Yeah, no, but that's not. You're talking about admission control, I think. And that's possible to be added into the model, but we are not considering. Okay, that's one. Thanks. Yeah, so as Daniel said, if we have one true knowledge on the parameters, then this prior has shown that we can construct a distributed revenue policy that basically it will asymptotically Basically, it will asymptotically achieve the optimal machine rate prescribed by this optimization model as the arrival increase to infinity, and it can be shown that this force is asymptotically optimal. So I would like to put a few remarks here. First, this optimization problem can be highly nonlinear because of the QNAN function here. If I let m start to denote an optimal solution to this problem, it will depend on the entire relation distributions. Because if you look at the expression for QNAN function here, it uses the CDF. It uses the CDF of the distribution and also the quantile functions. And the issue is that we do not have quantum knowledge on the arrival rays and related distribution. So we will look at a data tree function version of it. Basically, I will replace everything, the arrival rays, lambda, the re-energy CDFG and the re-energy quantum function G inverse by the embryo estimate. So everything in orange here is estimated from data. Here is estimate defined. If we take this approach, there are several important research questions that we need to answer. First, how well does this problem approximate the one-two-matching problem as functions of sample source? Second, because this optimization problem looks quite complex given the data-driven queue function here, how can we solve this problem? In fact, we can only solve it approximately and we will quantify the approximation. The last question. The last question is: how to develop a matching policy based on an optimal solution to this problem and what performance guarantee can be expected? And for the interest of time, I won't have time to go into the third question here and then focus on the formula truth. So let's look at the first question. How well does this data-trip problem approximate the Brown True problem? So before going into the theory, I want to show you some numerical results. So here I'm considering a very simple network. Considering a very simple network with two demand nodes and one supply node. For simplicity, let's assume that the arrival rates lambda are unknown. So the only unknown thing is the renatching distribution G. I have already specified values for the arrival rates, for the holding of C and for the matching values V. And I'm going to try different distributions of these relation distributions. So if I specify the distribution So if I specify the distribution, I should be able to solve the quantum measure problem, which has access to the ground truth relation distribution to obtain my optimal solution M star. The data-driven problem won't know the ground truth relation distribution, but it will have access to like samples that is ideally generated from the distribution. And based on those samples, I'm going to solve it and get m hat. So m hat would be a data. hat. So m hat would be a data-driven approximation of my optimal solution m star. And I'm going to measure the approximation accuracy of the data-driven matching problem by this relative optimal value gap. So here f is the objective function of the ground true meshing problem. Make sense? So in this plot here, I'm showing you the relative optimal value gap. And x-axis here, I'm having the sample size of the rematching time samples. And the different lines here correspond to different menaging distributions. I'm trying uniform distributions and weightable distributions with different shape parameters. We can see that a weightable distribution with a shape of 0.15 have a very large automo get when the symbol size is large. To get more insight, I'm also plotting the relative mean estimation error here. So this is the So basically, we use the data to estimate the mean patient's time. You see that the wave group 0.15 also have a very large mean estimation error. So you may expect that the larger estimation error in the mean value lead to the larger estimation error in the optimal leader this larger optimal curve. But this is not always the case. I'm here I'm I would zoom in this part of the figure This power of the figure and this power of the figure. We see that the Weibo distribution with a shape parameter of 4 and 8 have a smaller mean estimation error. However, they will have a larger optimal value. And we are going to develop theory that can explain this behavior. So, this leads us to developing statistical guarantees on the data driven problem. For that purpose, I need to make a few assumptions. Furthermore, I need to make a few assumptions on the underlying arrival processes and Renaging processes. I assume that the inter-arrival distributions are sub-existential. I assume that the Renaging distribution has a finite 2 plus P moment and it has a rate function that is bounded away from zero. I also assume that there exists a function rho that controls the tau behavior of the relation time test. With this assumption, I can prove something about the optimal web. Prove something about the optimal value gap. So, because the data sheet formation problem uses empirical estimate of the arrival rate, the renational CPF, and the renational quantile function, it is expected that this optimal matter gap should depend on estimation errors on those quantities. To formalize that, I will define some events here. The quantity in the first graphic here, this is the estimation error in a rivalry. Because if we estimate the arrival, If we estimate the arrival rate accurately enough, then this thing should be close to zero. And the thing in the second bracket here is the estimation error in CDF. It is actually the L1 plus the sun distance between my empirical CDF and the voluntary CDF. And the last point here is the estimation error in the corner functions. It is actually the uniform error because I'm taking a supreme over all x in the 0 to 1. So my theorem says that the problem. So my theorem says that the probability of my optimal wild gap exceeding a threshold epsilon will be controlled by the probability that this event happening. When you collect data, do you like what is the process that you observe? What I'm referring to is the renetching distribution. Like for the arrival rates, you just observe arrivals over time and then you And then you can guess what the you can estimate, the rate at which people are working. For the re-natching distribution, that's a function of your matching behavior, right? So here we are assuming SX to offline data, there's IID generated from them. In practice, it could be a full exploration. Algorithm variable to non-metric everything. So basically, this freedom told us that the probability of this large optimal value gap event happening will be controlled by the probability of these bad events happening. These bad events are related to the estimation errors in the arrival ray, CDF, and quantum functions exist in a certain threshold. But this theorem does not tell us how those probably change with the sequence. So we have a second-power theorem that says for a given threshold epsilon, there exceed positive. Threshold absolute, there exceed positive constants A and B, independent my sample size on the interval times and remaging times, such that the probability of the first bad event happening related to large estimation error in the arrival rate is exponential decay. This is not a very surprising result given the sub-exponential assumption we have made. We also have the probability of the second bad event happening related to the estimation error of in the CBF. Of in the CBF to be exponential decaying inverse sample scales. And this comes from conservation inequality of the Wazi-style distance. And our innovation comes from the last part here. We are able to derive a finite semi-bound for the uniform moderated quantum functions, errors. We show that this probability of large error in this thing will be controlled by three functions. The first two functions will be asynchronous. The first two functions will be asymptotically exponential decaying, and the last function will depend on density behavior of the Renaissance distribution. We believe this finite symbol value is normal, and it could be generalized to a broader class of function f that is integrable, bounded, and non-negative. For the purpose of our theorem, we only need f to be the complementary CCDF, CCDF of the relation distribution, which clearly satisfies this assumption. And if we look at the literature, And if we look at the literature, there's work that study the large sample behavior of the uniform error in quantile functions. There is also a lot of study in data-driven new spenders that study the point-wise error of quantile estimation. There is also finite symbol bound for the uniform error, but only restrict to the standard zero, one distribution. And our bound provide the first finite symbol bound for the uniform error of Homeland functions for a general class of fabrics. For a general class of families. And we're going to show that this bound will be tied for distribution with bounded support at positive destiny. Let's come back to what we have observed previously. We saw that the wave distribution with shape parameter 4 and A have a smaller mean error, but it has a larger optimal value error. And here I'm plotting the quantile error of different distributions. We can see that those two distributions actually has a larger quantile error. Has a larger quantile error. So that will explain the larger optimal value gap. And the paper will also show that our financial amount is able to explain the behavior of the quantile error shown in this figure T. Okay, so that's about our first research questions on statistical guarantees on the data transformation problem. Let's switch gear to how to solve this problem. Because to propose a policy, we need to obtain an optimal solution to this optimization problem. To this optimization problem. So, we will make two observations here. The first observation here is that the empirical corner functions can only take value in the relation time samples. This is, by our definition, how we define these empirical corner functions. And the aggregable CD F here would be a step functions that jump upwards at each of the sample. With these two observations, we can prove that the data-driven QLN functions can take. Quantum functions can only take values in this set, and this set can be constructed from historical. With this observation, we can formulate a mixed integer non-linear program to the data generation problem. This problem is non-linear because we have this strict inequality. And this strict inequality comes from the fact that when we define the anti-quantile function, we have this left open and right-closed inequality. And this strict inequality makes it And this strict inequality makes it more solvable by standard solvers. We propose to approximate the strict inequality by a weak version, but we will increase the right-hand side by bar of kappa. So if you think of kappa as something that's positive and it's small. And we use mhat kappa to denote an optimal solution to this MILP. And this MILP can be solved by sender solver. We show that for all sufficient. We show that for all sufficiently small values of kappa, the MIRP approximation gap can be controlled by two components. The first component is proportional to the buffer copper, and the second component is the maximum spacing of order statistic, which will converge to zero almost shortly under general regular conditions on the Renation distributions. So, with this theorem and the statistical guarantees we establish, we can propose a We can propose a matching policy that is asymptotically optimal with high probability. And for the interest of time, I won't go into detail of that. Let me sum up the work. We study a matching problem in which the inter-arrival time and relation distributions are unknown and must be learned. The very complicated space implies that learning and exactly optimal policies appear in this book, so we propose a framework that can. We propose a framework that combines Foulouter model approximation with statistical learning to formulate a data-driven Fouloui matching problem. We provide statistical guarantees to this problem by developing finite single bounds that involve the full renatural CDF and coordinate functions. We show that this problem can be approximately solved by MILP and we quantify the approximation. In the paper, we show that a discrete imposing based on an optimal solution to this problem. Based on an optimal solution to this problem, is epsilon is totally obtained with high probability. And we actually just finished our first draft of this paper. And if you are interested in seeing that, please feel free to reach out to us and we will make sure to add you to the distribution list. We have time for a couple of questions. Notice that the optimization problem, even when you have a uniform distribution, so the actually is you maximize a commax function, right? You mean the Guangzhou, yes. So do you have any understanding about like this? If you are talking about the Guangzhou problem, when the Hedgehog rate of the Riemannian distribution is strictly increasing or decreasing, we can prove that the Q-line function would be strictly concave or convex. In that case, it would be. Concave or convex. In that case, you would either have a convex optimizer problem or a problem whose optimum solution would be an extreme one of the fees for which. So it seems that you had access to the empirical distribution of the view data distribution. So, in practice, you could imagine the situation where the queues were all quite small. Then, if everyone gets served, they won't be negative, so you won't get data about the table. Open X, you won't get data about the table, the relegate distribution. That's a very good question. So, in here, I'm hiding the fact that we are having access to IID samples, or IID revenue samples. And in practice, that would have to be collab in a situation where you do not provide service to anything. That you just let those abandonment to occur naturally, so that you get a unbiased sample point. The opposite could happen, that you just don't need that data because You just don't need that data because that doesn't happen. Well, you know, if you see what I mean, so it's not clear if you need it in order to come up with a robust policy system grow so you can get the data and then optimize it. Yeah, but here I'm thinking about a small explosion period. So we definitely don't want a system to run a long time without control. Alternative might be resumed to a parametric format. Might be resumed to a parametric form, and then you can use the small sample data tip and get estimates on the data. Yeah, probably. Okay. Just very quickly, just make sure I understand, when you talk about turning some solution to your data-driven fluid optimization into some sort of policy, is this some sort of fluid policy or fractional policy or something? So, basically, it would be a discrete real policy that matches only a discrete time quadrant. Time point. Between two discrete review time points, you will let the Q lamp to build. And then at the point, you will match according to the optimal solution that is provided for by the optimal solution. Okay, let us take the speaker again.