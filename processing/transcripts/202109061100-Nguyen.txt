The title of his talk is Shoquet Integrals, Capacitary Inequalities, and the Hard Deletable Maximal Function. Okay, please. Could you start recording? Yes, thanks. I started already. Thank you for the introduction, Iga. I would like to thank the organizers. For the invitation. Today I will tell you about my joint work with Ken Oi about our work on chopper and zeros, capacitor inequalities, and the Holly Littlewood maximal function. Sorry, I missed one work here. So this workshop is about non- So, this workshop is about nonlinear potential theoretic methods in partial differential equation. Unfortunately, for my talk today, I don't tell you much about, I mean, they're not much of nothing about a bachelor differential equation. My main focus will be about potential theory. And luckily, it's truly the non-linear potential theory, the non-linear one. All right. All right. Let me start with the well-known fact about the Harley Littlewood maximum function, which I denote by M. And given a function f, the Harley Little function applied to F at a point X is just the supremum of the average of F over a point. Over a ball centered at the ball X of radius R, and the superior is taken with respect to the radius R here. And it is well known that this operator is bounded on L P whenever P is bigger than one and is of put type one one in the K when P equals one. This is with respect to Lebesgue measure. However, in this talk, we are not concerned with Lebesgue measure. We are not concerned with Lebesgue measure, which is an additive measure. My purpose here is to talk about capacity, mainly the super lab capacities. All right. Before I discuss about sober capacity, let me go over a little bit on a similar notion, the so-called house dock content, okay? Also known as house dock capacity. Of capacity, so given a number d, a real number d between zero and n, and is the dimension of the ambient space. Okay, so we are working on our n. Given a D between zero and n, then we can define the so-called the house dot content of dimension G denoted by S D infinity and follow. So given any set, any set E in S D infinity. S D infinity of the set E is defined by this infimum. Well, you just take any covering of E by Q Q J and then you take the sum of the length of Qj raised to the power G and then you take the infinite product. And of course, this house drop content is smaller. Content is smaller than the so-called house dot measure. Okay, and however, they have the same moon set. They have the same moon set. And in the K when D equals N, then if you give it definition, then you get exactly the so-called outer Lebesgue measure. Okay, but we will always talk about the K when D is strictly less than N. And if we require in the covering here, if we require. In the covering here, if we require the qqj's to be diadic qs, then we get the so-called diadic house of content, which I denote by S d infinity with a tilde. And it is well known that the dyadic one and the regular ones are equivalent. When you have the house dot content, then you can define the so-called chakra integral. The so-called Chucker integral associated to this Hauruk content. Given any non-negative function phi on n, then you unify the basically like L1 norm with respect to this outer content by this one-dimensional integral. It's very similar to like Lebesgue measure. You look at the upper level set at the high T, and then you compute the house drop content of that set, and then you integrate. That set, and then you integrate along t here from zero to infinity along h here. Okay, this is well defined provided that the exceptional set of the phi is of zero d dimensional house that measure or how the content. And of course, you can extend the definition for L P norm or with L P norm in a similar fashion. So if you want to compute the L P norm with the LP normal with respect to this health of content, you just calculate the chop integral of F to the P and then you rate it about one of P, and you can define similarly for the weak LP norm with respect to this heart of content. All right. And it started in, I mean, the story I want to tell you started in 1986. So at that time, Adams, the That time, Adams, David Adam, who just passed away, you know, a month and a half ago, he obtained the following vowel for the maximum function with respect to the house subject. So he got the bow that the maximum function evaluated from A1 to A1, strong type. Okay, this is strong type, not weak type, with respect to the house of content. And his group somehow gives a very strong result. Use a very strong result of Pfefferman's style and style about the S1 and B modularity. So he used S1B modularity to obtain this kind of estimate. And of course, by interpolation, one can also get this bound for all P between 1 and infinity. And later, in 1998, Aurbit and Vadera extended this bound further. This bound further, uh, they obtain that the p here, the p here can go down to uh d over n. Remember that d is less than n. Okay, so this p could be smaller than one. This p could be smaller than one. And at the end point d over n, they get the wig tie bound. Okay, and so I the So, the idea of the proof is that you also give Carolin Lemma, like you try to prove the Wu Taiwan one for a highly much more functional with respect to the back method. So, but however, it's not that simple because if you use Cali Nemo, you have to use it in a clever way. And there are two ingredients in the proof that eventually work out for them. The first one is that the A1 norm, okay, the A1 norm. One norm with respect to the house drop content is a normal spice. It's not clear, but actually, this follows from the fact that the house drop, the regular house drop content and the dyadic one are equivalent, and the dyadic one is strongly subaditive. Okay, this is a result due to Robert Feckerman in the 70s. And by strong subaditivity, here I mean that if you take the hound of You take the house drop content of the union and you add to the house dot content of the intersection, then this is controlled by the sum of the housed content of the set. This is not true in general for the regular house of content, but it's true for the diademic one. And this actually, this property is equivalent to the fact that the A1 space associated to this dietary halt of content is a norm space. Okay, and therefore, Okay, and therefore, um, the L1 norm, uh, the L1 spec with respect to the level housed content is normable. Okay, so that is one important ingredient in the group, and another one is that because you know, house of content is not entity, so you have to be careful and they yield the following property. So, if you have a sequence of QJ, a sequence of the choice of the Q, and then you want to control. And then you want to control the sum, the sum of on each, I mean, restricted to it, q j here. You cannot simply just take the union here. I mean, they did so, but you cannot simply put the technology union here. You can do that as long as you have the back-to-man condition for the qqj. So you need the condition that the sum for given any dynamic q given any qp. Given any QP, if the sum of the length of QJ rate to the D, and then just like the sum over QJ over in chat, the other QP, then this is going to go by L B to the D. Of course, if D equals N, this is always true, but if D is on, it's not true in general. Okay. And so to get this, to get this power, you need this kind of connection, and then they have to come up with a special kind of current. A special kind of current lemma should have like a d row to property, and eventually they get this weak type. Okay, I want to mention this here because I will deal with capacity later. And actually, in our group, we cannot do something like this. We cannot, you know, cover for capacity. One cannot do that. Okay, so our group is completely different. And actually, for what I present later, Present later also require a new inequality. All right, so now let me go to the main object of today soberly capacities. So consider now the homo sober x space, okay, w dot alpha s n. So s is a number bigger than one alpha. Than one alpha is a number between zero and n uh then uh w dot alpha s can be characterized as the space of read potential of function m in m s okay so you can characterize w dot alpha s as a set of all function g where g is represented by a potential i alpha f where f is a function in ms and um And ms, and the notation i alpha f here is this integral, it's just uh the risk potential order alpha. Okay, it's just the risk potential order alpha. And then we define the so-called risk capacity by this infimum. For any set K, the capacity of a set K is just the infimum of the S norm of F raised about S. And then you Then you minimize overall F such that the lift potential of F is bigger than one on the set K that you want to calculate the capacity. And of course, because of this relation here, you see that this capacity is associated to the homogeneous toplex space. All right. And when you have the capacity, you can also refine the chopper integral and Chopka integral and uh and chopka space associated with capacity as in the case of house of content and so on. So you just replace the house of content by capacity when you try to introduce the LQ spaces with respect to the capacity or with LQ spacing with respect to the capacity. Okay, so let me not go over that again. And so before I continue, let me mention that in Um, in general, you cannot, you know, if you get some result for the house of content, you can never get it for the you cannot do for the capacity. Uh, you have one set of estimates here. You can control the capacity by the Lebesgue measure rate of some power here. This follows from select inequality. There is another interesting formula here. You can control the capacity from above by the house drop content exactly. stop content exactly of dimension n minus alpha s and on the side on the and then you can control from below by the house of content of this dimension but you have to ask you have to require that your epsilon um to be bigger than strictly bigger than uh zero so if epsilon is zero it jumps over here okay it becomes a different inequality but if your if your epsilon is uh strictly bigger than zero then you can only find a constant uh Fire constant dependent on epsilon should not be true. And if this equals n, I mean n minus alpha n multiplied by one of epsilon equals n, then you get back to this low bar. Okay. All right. But however, if you get something for the house of content, you cannot get it for, you cannot really dedue anything for the capacity. Okay, so the main question. Okay, so the main question of my talk is that so given alpha s between, I mean alpha alpha and s, we are the product of alpha and s between zero and n, for what q do we have this about for the maximum function? Okay, so we want to find the right q so that this is q okay for all m in this uh lq norm with respect to this capacity and uh it is easy to see that if q is in field. It is easy to see that if q is infinity, this inequality this inequality is trivial. Okay, so if you get it for some q, then you can always interpolate, okay, and uh form the equalities here. So, the capacity of a ball is just the radius of a ball rate of the power n minus s. So, you see that it you expect that so this is pretty much like the housed up dimension here. So, you expect that the q. That the q the q should be bigger than n minus alpha h over n. And if you look at this, if you look at this, here you expect that it's going to be n minus alpha h over n. Okay, that's one thing. Moreover, at the end point q zero equals n minus alpha s over m, we expect that we have the weak time bar. Okay, so this is what we're trying to prove. Okay, so this is what we're trying to prove, and uh, so in fact, you see that in this case, and the statement is exactly what I just mentioned, okay? So we have those, we have a strong type bound in the K when Q is bigger than n minus alpha SON. And at the end point, we have the weak type bound. All right. So I will discuss about this the proof of this. Bit of this of low inequality, but I would also mention some other results. So, the first thing that is very important to us is that we really need to know that L1 with respect to the capacity is a normal space. Okay, we need to know that this is a normal space. So, In the case when alpha here, I mean, this is the order of the derivative, when alpha is between 0 and 1, and when S e 2, okay, when S e 2, and alpha between 0 and 1, then one with respect to the capacity, it indicates a norm space. It's a norm space in this case. And this is a classical result. You can find in the book of Lenco, follow. Land corp follow this follow the so-called strong maximum principle. Okay, but it's true only for some range of alpha and only in the case in the linear case, alpha s equal to now for for the for alpha equals one and s bigger than one, any s bigger than one, then actually l1 with respect to capacity here is normable. It's normal. Is normable. It's normal because the capacity in this case is equivalent to the so-called S capacity. Okay, the S capacity and the S capacity is known to be strongly sub additive and therefore it's normable. And so in this case, we also have normability. Now, so for us, because we want to do it for all alpha and for all S, so we really need to have these kinds of normability. This kind of normability. And in fact, we proved earlier that A1 with respect to this capacity for any alpha is normable. And the idea of the proof is that you can show that given a function g, and norm of g with its capacity is equivalent to another functional, okay? Equivalent to another functional. Okay, equivalent to another functional. And this functional is defined like this. You take the infimum of all function f in L S. Sorry, the infimum of the L S norm of F raised to the power S. And F is any function in L S. And the potential of F is bigger than Gu raised to the power one of S. So Gu is an even function. And then you look at this set, and then you minimize it. Set and then you minimize it. It turns out that this, you know, weird looking infinity actually equivalent to the A1 norm of U with respect to the capacity. Okay? And of course, the second thing you need to do is you need to verify that this function known is some editing. It simplifies the triangle inequality. And in fact, this kind of triangle inequality for this was done in an earlier work of Calton and Eagle in the 90s. And I just want to mention that the equivalence here, to prove that this is equivalent to this, I have to give the so-called capacity stronger inequality. Capacity stronger inequality originally obtained by Mazia and subsequently attended by Adams, Daupel, and Hansen. Okay, so I will focus more on this capacitor strong inequality in a moment. All right, so the measure capacity strong inequality is static as follows. Given any function f in L S. any function f in ls then uh i alpha f the potential of f okay of order alpha here is actually in the ls uh space with respect to the capacitor okay this so this is what we call master capacity stomach inequality and um in the 90s there there is another there is a problem proposed by adams he proposed that He proposed that, so instead of looking at the, if you look at a non-linear quantity like this, okay? So if you look at a non-linear quantity like this, so f to the s and then multiply by i alpha f raised to the power q minus s. Then this form below actually by the LQ norm of the potential of L. And here LQ is which And here LQ is with respect to the capacity. Okay? So Aram believed that something like this is true, and he proved this in the K when alpha is an integer. Okay? He proved in the K when alpha an integer and Q is between 1 and S plus N over N minus alpha. And recently, we were able to handle this inequality in the spectral plane. You can say that this is. Okay, you can say that this is your input case q equals one for all alpha, so we can do it for q equals one and for all alpha for all alpha, right? And somehow our approach uses the Han-Mannach theorem, okay? With your Han-Banach theorem, apply to the space, the condition of the space C CN with respect to the A1, A1 norm, with respect to the capacity. To the capacity sheet, and because we do Hanbana theorem, so we use the energy, so we really need to know that this one is a ones with respect to capacity here is a normal spike. Otherwise, we cannot apply the Hammer here. Okay, so that's why I try to emphasize the importance of the normability at the beginning. Okay, so recently I was able to handle the case when Q is strictly bigger than one. Okay, so only Okay, so on the other hand, this is for all alpha between zero and n. On the other hand, it's not clear to me how to do it in the case when q is less than one. Okay, it's not clear to me. I don't know how to do it in the case where q is less than one. Okay, so this case remains open. All right, so now let me go back to the proof of this main theorem here. All right, so I will first give you a So, I will first give you a linear drop, okay? And because it's a sort of linear root, so it doesn't cover the full redshift. It only covers the case when Q is bigger than N minus alpha over N, not N minus alpha over N, without the S in here. So, Q still can be less than one, but it's not a full range. So, let me tell you how. The idea is to use the idea is to give this Into you this gap inequality in the KQ equals one. Okay, so bound for a maximum function in the K even Q is bigger than M minus alpha over N. So because we was able to settle the problem in the K Q equals one, with that we can show that actually the L1 norm of function G with respect to the capacity E. Of function G with respect to the capacity E also equivalent to another function law. Okay, and this time the functional is like this so you minimize over this non-linear expression. Okay, it's a non-linear expression. Okay, but this time you don't raise any power here. So I alpha f is bigger than or equal to u. Remember that before you put the f to the s and then you have to raise to the power one of s here. So the gamma functional. So, the gamma function loan. For the gamma function loan, you have to raise to the power one over s, but here it's a nice one, f to the s. But this time, for a beta function loan, you don't raise any power here, but then you have this some sort of nonlinear quantities here. All right, and with this, you can easily show that you can easily show the maximum function power in the K1Q bigger than n minutes. K when q bigger than n minus alpha over n because because if you if your q is in this range this quantity is this one right so basically if you want to you show if you if you if you write one over q here then you then in in that case you can show that i of a f greater than power one over q is actually an a1 weight and therefore uh you can replace i mean the like right the this The this one by the maximal function of q, and therefore you get this part, okay. And it's just basically, I said it's some sort of linear approach, so you don't really get the full range, okay, okay. But it's the first result that we can go down to below one for this for this bar, all right. Now, uh, for the rest of the talk, I will discuss the proof. I will discuss the proof of the Wig Tie and Wood bound. Okay, this is the one because so the main theorem here is this one, but if you can prove the Wig Tie bound here, you can interpolate and get everything, right? So I will discuss this one. All right. Okay, and this time I will give truly non-linear potential theory. So this is the part that we want to get, okay, the wicked bar. Get okay, the width type bound, and the q0 here is this number, which is strictly less than one. And we will need some facts from non-linear potential theory. Before I continue, let me mention that there is a related work due to Igor in the 80s where he proved not exactly the same kind of inequality, but he proved something like this. Okay, so if you have a function f and If you have a function f and f satisfy this kind of condition, if this is finite, then the maximum function of f also satisfies a similar condition. But this is only for q strictly bigger than one. You cannot do it for q equal to one or less than one. All right. And so let me go into the proof. And first, let me go over a little bit of non-linear tensor theory. Are non-inable tensor theory. So the capacity of a set of a compact set K, recall that it is given by this intimate, right? You minimize over the L S norm of F greater than S for function F such that the potential of F is bigger than or equal to one on the set K. It turns out that this incimum has an echemo. So the echemo function that minimizes that real idea. That minimize, that real idea about infimum is called the capacitive function for k. And the kimono is given by the potential of a measure of mu sub k raised to the power s prime minus one. So s prime is square over s minus one, the Honda conjugate component. Nu k here is a measure, a non-negative measure supported on a set k. Okay, so the chemo function f. The Kimo function F here is given by a potential of a non-negative measure called the capacitor measure for the set K. And the measure mu sub k is supported on the set K. And you have a power at prime minus one. In the K, when at equal two, it's just a linear one. You don't have any power here. I mean, the power, the power will be just one. The so-called master having only the potential, the potential of. Potential is the potential of the function f. And if you write down, it's going to be this one. And usually, this is denoted by V alpha s of the measure mu sub k. And this is called the capacity potential for a set K. And this look, yeah, it's normally one, but in the K when S equals two, then the Maser Havid potential will become just the. Potential will become just the Newtonian potential here, I, 2 alpha of the major mu. And one have we have the following extreme properties. Okay, of course, this is well known. The capacity of the set K is exactly the total mass of the measure K, our measure of mu mu sub k. And because yeah, it's going to be equal to the s prime norm of I of. S pr norm of I alpha mu k raised the power s p and so on. And if you fully need, you can write this down like this. So you can you can express the capacity in terms of the measure here. And on the set k, the potential is bigger than equal to one, positive everywhere. And it on the support of this of the major mu k is going to be polished by one. Another important property is that you have the Important property is that you have the so-called dual definition of the capacity. In fact, the capacity is also equivalent to this supremum. So you set the supremum over all the total mass of a major mu, supported on a set cake, and you require that the non-linear, the mass having potential is doubled by one on a support mu. On a support view. And in the 80s, using the so-called works inequality, one can show that you can replay this Mazar Harvey potential by the so-called work potential, which is in general, this is smaller than this one. What we still can get the same equivalent capacity. And the work potential, W alpha S of a major mu is given by this. By this, okay, all right. In the case s equals two, you get linear potential. And the work potential that I mentioned is this inequality. And this is significant only when your s is near one. But because if s is bigger than two minus alpha n, the master having potential and the work potential are equivalent, you don't really need to give the work potential at all. All right. So, the importance of the work potential here is that if you take the work potential of any major mu, okay, of a non-zero major mu, you raise the power delta. As long as your delta is in this range, so delta is less than s minus one times n over n minus alpha, then this function. function is always an a1 weight okay meaning that the maximum function of this is control by its itself everywhere all right but for us we we we need to give the end point so this is true only in the k when delta is strictly less than this one now in the k when delta is delta zero where delta zero is exactly this end point then we have something very close to the a1 weight A1 weight, uh, is but instead of using the maximal function, and you have you use some sort of wig ties maximal function. You can say something like that. Well, the idea is that you look at the integral of this over, I mean, you look at the weak L delta zero of this function over the ball center at the point X operators R, and then you take the average product, and then you take the super. And then you take a super, this you can go by this for any okay. So it's very close to A1, but you don't use the weak tie here instead of strong target. Okay? And this is with respect to the back measure, of course. All right. And now let me complete the proof. Okay. It takes a few more minutes to finish. So we want to prove this. Okay. We want to prove this. Okay, we want to prove this, and the q0 is this number. Remember that q0 is strictly less than one. The first step is that you can reduce this to the case when f is just the characteristic function of a set k. Why is that? Because even a function f, you can always track your f like this. But you have to be able to put them together at the end, right? Now, to put them together at the end, you need to give a very important fact, which is binomial. fact which is binomial binomial trial okay that the the mq0 i mean the weak mq0 with respect to the capacity here is q0 normal or locally q0 convex okay in the sense that if you take a sum i mean any sum here m is any in any positive integer you take the sum of of f sub k here and then you you measure this in the weak mq0 norm here this is controlled by a constant mode This is controlled by a constant multiple of the sum like this. So you can bring it inside, but you have some power, q0 here. Okay, and the q0 is exactly the one we need. If you use something like Aucky Draw Lovic theorem for Osynom space, the power is going to be different and it's not good for upper work. And in fact, this is kind of surprising because it's not true. Okay, this is not true in the K when Q0. not true in the case when q0 equals one okay it's true because q0 here is less than one and if q0 is one it doesn't work and this curve results were proved by um nigel counter in the 80s okay and uh but he proved for measure but the idea carried out for for capacity as well but we need to know that the air ones with respect to the capacity is Respect to the capacitor is normal. Okay. I don't know how to do it without knowing that this one is normal. Okay. So that is the first step. So you can actually, you can assume that your F is the characteristic function of a set. Okay. And the second step is that you pass from the maximum function of the characteristic function of a set to the work potential of the equation. So, of the equimo measure here of the capacitor measure for the set K. So, mu k here is the capacitor measure for the set K. So, how do you do that? Well, so you want to control this by this somehow, right? So, you look at the average of the calculus function over both. And we could see a calculus function. So, L1 norm is the same at which L1 norm. At which L1 norm for a candidate one norm is the same as the weak and one norm. Okay, so so you can write like this, and now remember that if mu is the capacity major, then the work potential of that is bigger than one on a set K. So you can switch from the character function on a set K to the work potential of the extreme major. Raise to any power you like. So in particular, I2 delta zero to be exactly this ritual. Exactly, this ritual power, okay, and um, and because as I mentioned, that for this work potential, we have this some sort of A1 control, so you can switch from this average here into the value of the potential at the 4x here. Okay, so from here, you see that the maximum function is controlled by the work potential. By the work potential of the Ximo major greater some power, and then finally, from here, you know, potential theory will come into play, and then you can control the weak, the weak LQ norm, this one, by the capacity, okay, and by the total mass, and the total mass is exactly the capacity, okay? So, you done. So, I just want to mention that. Want to mention that the argument here also works for you know inhomogeneous solar space WÎ± S. So we have to use in this case we have to yield a so-called basal capacity. We have to use the peso capacity. So instead of working with the drift potential, you work with the peso potential. And also in that case, the maximal function here should be replaced by the so-called local maximal function. The so-called local maximum function. It defines it defines similarly, but you have to restrict the radius in the range from zero to one. Okay. And with that, I finished my talk today. Thank you very much for your attention. Thank you very much, Fuk, for your very interesting talk. Are there any questions? Are there any questions or comments? Any questions? Okay, I have a question. Could you tell us if there is an analog of this for, say, other kernels, I mean, more general kernels, say, radially decreasing kernels? Say radially decreasing kernels with a weak maximum principle, or it is more specific. Yes, yes, yes. You can get something like this. Yes, yes. But well for I think so. I think so. I think my Keno, he had something like this too. He had something like this. I think he tried to get something like this. Right. Okay. And another question. This inequality that was proved by David Adams for integers. Yeah. Yeah. Is it stronger than the strong capacity? Than the strong capacity inequality. No, no. So you see, if Q equals S, you get back to the MASA batch inequality, right? Yeah. So yeah, the K Q equals one is one. It is a spectral case here. So we can say equals one, and if you, if you, you can find where to interpolate, you can get from one to q, but then from q. But then for cubicle than S, you can also, if you give the so-called independent bipartisan model that you have, you can also get it for cubic good and S. But for Q less than one, I don't know how to do it. Yes, yes, I see that. And also, this expression that you have on the right-hand side of your inequality is kind of reminiscent of what appeared in some old papers. Appeared in some old papers by Barras and Pierre in the context of nonlinear PDEs. Yes, but they work only for integer. They work for them. It was only for integers. No, no, no. They had an abstract version, actually, for any potential. I didn't know that, but uh I I look at their paper. It's uh it's all always for for the integer. Well, that was in the paper of uh Paper Michel Pierre Barrow. Oh, you may not. Yes, yes. But that was in the spirit of your paper with Nigel, right? So it's applicable in some sense. I think I give that idea for the KQ equals one, but for general Q, I don't know how to do it. Yeah. Thank you very much. Mr. Chairman, can I ask a question? Sure. Can I ask a question? Sure, okay. So, thank you for the very nice talk. So, you also mentioned the characterization of capacity in terms of the visc potential. And I mean, we know if you replace the vispotential by the fractional maximal function, you get the Hausdorff content. I wonder, given all these inequalities that you are proving, so would there be any situations where Be any situations where, if you replace the LP norms by some corresponding Lorentz norms, Lp1, whether you would then be able to prove equivalence of the corresponding capacities defined using Reese potential with the ones defined using the fractional maximum function. Fractional maximal function. Yes, I mean, I'm asking because I try. I'm asking because I tried that myself. I mean, and I was told by Jan Mali a long time ago that it was wrong, but I didn't explore all possibilities. So I wonder whether you have any insight. So you replace, I mean, so, okay, so I can tell you, so if you take instead of the V potential, you take the fractional maximal function, you get the Hausdorff content. Function, you get the Hausdorff content of the cross-bounding dimension. If you replace the LP norm by the Lorentz norm, you get some Nitrusov capacities. I mean, some capacities that we was interested in when he discussed Glassoff spaces for P equal to one and Q less than one. And so that just followed from the definition. But I wonder whether there would be some kind of some possible equivalent. Some possible equivalence in some of these limiting cases if you replace the back spaces by Lorentz spaces. So, in other words, can you equivalent define in terms of the fractional maximum function? So, that's my question. I mean, maybe it's uh yeah, I'm sorry, there are just 30 seconds to answer your question. I just want to mention that I'm not really well, I cannot say much about that. Well, I cannot say much about that, but I just want to mention that when you have control for the maximum function, you can prove some sort of superlap embedding. Like given an F, which is in that LQ with respect to the capacitance, then the potential, like the read potential of that function is going to be in another LQ star, where it's some really cool Q star and with respect to the set capacity. So you have, you can give, when you have a maximum function. Use when you have a maximal function bound, you can give a superhead inequality and you can control the maximum legitimate potential by the maximal function, and then you can obtain some sort of superlevel embedding. But in your case, it's not clear to me. Okay, I mean, I might send you an email. So, because I thought a bit about this at some point, but yeah, okay. Thank you very much for the question and your reply, Fuk. Okay, now it is. White hook. Okay, now it is time to start our next.