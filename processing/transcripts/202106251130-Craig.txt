I think that's it the background is no the background is no in fact I decided to shamelessly copy Yunnan and have a background of Vanth behind me Santa Barbara if you've never visited there it's stunning place it could equally be a background anyway so this Katie is going to talk about a blob method for degenerate diffusion and applications to sampling and tooled neural networks go ahead Katie so thank you very much for that introduction and I'd also like to again thank the organizers Also, like to again thank the organizers for putting on this wonderful workshop. I think, as the complications from COVID are still slightly unwinding here, I haven't been able to join synchronously as much as I want. And for that reason, I'm really grateful to the extra efforts that the organizers and the beer staff have been going to to post many of the videos after the session. So, thank you very much. That is a big benefit to me in the current circumstance. So, hopefully, looking towards optimism to the future with improved circumstances. Future with improved circumstances in that regard. So, today, as it was already said, I'll be talking about a blob method for diffusion and applications to sampling and two-layer neural networks. And the subject of my talk today is based on two joint works: the first with Jose Antonio Carrillo, who's now at Oxford, and Francesco Patakini. And the second with Karthik Alempasuthi at UCLA, Matt Haberland at Cal Poly, and Matt Haberland at Cal Poly and Olga Taranova, who's now at Michigan State. So, my plan for today's talk is to begin by motivating the problem that I wanted to consider, which is basically to develop a new method for either could be used for either sampling probability measures on one hand or robot control algorithms on the other hand. So it turns out that these two problems can be somewhat put into the same mathematical framework in both. The same mathematical framework. In both cases, you have a desired target distribution and you want to approximate it by Dirac masses, a sum of Dirac masses. From the sampling perspective, the Dirac masses, the locations of those masses represent the samples you're trying to draw. And then from a robot control perspective, that represents actually the physical locations of your robots that you want to distribute themselves according to some desired target distribution. So, you know, one situation you can imagine is you have. Can imagine is you have weather balloons that are helping give internet service in a rural area, and you want the weather balloons to configure their locations so as to kind of optimize the internet signal. So my goal in kind of considering both this application in sampling of probability measures, or on the other hand, this robot control problem is to develop Was to develop a PDE-principled method for doing this. In that sense, in spirit, it grows very much out of kind of the classical sort of Langevin dynamics based on the Fokker-Planck equation. But the PD that I'm going to consider is actually not a diffusion equation like the Fokker-Planck equation, but a degenerate diffusion equation. It's a weighted porous medium equation, which I'll describe in a few slides. So that PDE turns out to have a Voss. So, that PDE turns out to have a Vosserstein gradient flow structure, something that we've already heard about in this conference. So, I'll give you a little bit of background on what that means for that PDE to have a Vosserstein gradient flow structure and also some related Vosserstein gradient flows. And so our approach is to take this sort of PDE'd principled way of flowing towards a desired target distribution and use that to develop an algorithm that can be used in practice. Develop an algorithm that can be used in practice, a fully spatially discrete algorithm. And so, to go from the spatially continuum world of PDEs to the spatially discrete world of a system of ODEs that could be used in a numerical algorithm, we link those two using a numerical particle method. So I'll tell you a little bit about numerical particle methods and why, in a sense, they're sort of closely linked to this Bosser-Sein gradient structure. Unfortunately, the case in which these are Unfortunately, the case in which these are most beautifully connected is when you have a kind of global Lipschitz estimate on the velocity field in your Vosserstein gradient flow, which tragically for our degenerate diffusion PDE, we completely lack. So we have to instead combine our particle method with the regularization to develop what I'll call a blob method for these diffusive PDEs. And this helps us achieve our goal of developing a new PDE-principled algorithm for either the SAM. Algorithm for either the sampling or robot control tasks. And then I'll close with some numerical illustrations of our method. And please do feel free to jump in at any point with questions. I should theoretically be able to write on my slides, though, as all of my students from this year of remote teaching will know, I'm horrible at looking in the chat. So please just jump in if there's anything that would be useful to discuss. I will alert you if something pops up. I will alert you if something pops up in the chat. Thank you very much. Okay, so like I said, let me begin with some motivation for the problem. So in both the case of a sampling algorithm in statistics or a kind of a robot control algorithm for the robots to complete a coverage task, just for the robots to cover some desired distribution. We start with some. We start with some desired target distribution, rho bar, which you know, up to normalization, I'll say, is a probability measure on Rd. In sampling, the question we're trying to ask is how can we choose in samples in d-dimensional Euclidean space so that at least with high probability, they accurately represent this desired target distribution. And in the robot coverage task, the question is: how can we program robots to move? How can we program robots to move so that they distribute their locations according to this desired target distribution? But a key difference here is in the robot coverage task, we really want a deterministic algorithm. We don't want to have to sort of drive the weather balloons around several times and then have to average over those results to get a reasonable guess. Whereas in sampling, that's totally fine. This is something that's typically done numerically. It's no problem if you have to run your algorithm 100 times and average over it to get the best results. Get the best results. And so, in both of these cases, our essential goal is we want to approximate the desired target distribution by an empirical measure. And for simplicity in today's talk, I'm always going to assume that the Dirac masses are equally weighted, but everything that I will say today also works for unequal weights and the Dirac masses. So, it's well known that PDEs can inspire new ways to construct this type of. To construct this type of empirical measure. So, to describe this, I'm now going to put additional assumptions on my desired target distribution, which is that rho bar is going to be log concave, or in other words, it's given by the exponential of negative v, where v is a convex function. Okay, so in this kind of nice setting, maybe the most classical connection between PD Classical connection between PDEs and sampling algorithms comes from the Fokker-Planck equation in Langevin dynamics. So, at the top of the slide, here I have the Fokker-Planck equation. At first, I wrote it in a kind of weird way. Here, it makes it look like it's almost a non-linear PDE in rho. But if you can see, if you just expand out this side, it becomes the familiar Fokker-Planck equation. We have the time derivative of rho is just given by Laplacian of rho. Of rho. And then we have our continuity equation term where the velocity field is just given by the gradient of the logarithm of the target density you seek to approximate. So the Fokker-Planck equation is a great PDE from the perspective of sampling algorithms because solutions of this PDE flow towards the desired target distribution very quickly. Higher target distribution very quickly. One of the ways to measure that is to say that the Kolbach-Liebler divergence between the initial data of your PDE and the desired target distribution times this exponential factor, where, for example, if V is Lambda convex, the Hessian of V is bounded below by Lambda, we get that parameter lambda here. Parameter lambda here. And so we can see that this is something that's as time t goes to infinity, this is going to be decreasing exponentially quickly in time. And this provides an upper bound for the distance between the solution of our PDE at times t and the desired target distribution. So this is saying that the difference between these two things, as measured by the Kolbach leader divergence, is getting small exponentially quickly in time. So, okay, so this is saying that solutions of the PDE are going towards the desired target distribution quickly. And so, this is a natural approach if you want to flow towards that target distribution. So, now if you want to turn this into kind of a spatially discrete algorithm that can be used in practice, you can approximate this continuum PDE using a particle method. In this case, I just wrote a stochastic particle method. Stochastic particle method. So, this is exactly sort of Langevin dynamics. We have the Brownian motion to capture the heat term, and we have the kind of drift term to capture the continuity equation term. And sure enough, you can show that if you evolve the locations of your particles according to these stochastic dynamics, as the number of your particles increase, this converges to a solution of the continuum Locker-Planck equation. Of the continuum Pocker-Planck equation. And then you know that as time goes to infinity, since the solution of that Pocker-Planck equation gets very close to your target distribution, as you run this algorithm for large n and for large time, this will give you a way to approximate the desired target distribution. Okay, so this is maybe the most classical connection between PDEs and sampling algorithm. You get a PDE that goes towards the Get a PDE that goes towards the target distribution you want, and then you discretize it with a particle method. In this case, a stochastic particle method. So, the PDE that I'm going to propose today is a slightly different PDE. Instead of this diffusion equation, I'm going to propose that we consider a degenerate diffusion equation. And if you just look at this form of each equation, they look pretty similar. Basically, all I did to go down here is I got rid of the logarithm. And at first glance, you might. And at first glance, you might think that that would be great. You know, logarithm, it's got some singularity origin. Surely by getting rid of it, the PDE gets nicer. Unfortunately, in this case, the PDE does not really get nicer. I'm not going to expand the right-hand side like I did up here for general rho bar because it gets a little messy. But in the specific case, that row bar is identically equal to one. If I expand the right-hand side here, I get exactly the porous medium equation. So this is a degenerate. So, this is a degenerate diffusion equation. Solutions of this equation have lower regularity than a nice diffusion equation like the Fokker-Planck equation. And so, in many ways, it's not quite as nice of a PDE. But it shares one important property with the Fokker-Planck equation, which is that solutions of this equation still approach the desired target distribution exponentially. Distribution exponentially quickly when measured in Kolbach-Leibler divergence. So that shows that this PD isn't really, it's not a crazy choice if you're trying to flow towards rho bar. So the goal of today's talk is going to be to explain how we can develop a particle method for this PDE to develop a fully spatially discrete algorithm for approximating these kinds of. These kinds of desired target distributions. Now, at this point, it would be very natural to object and to say, Katie, we already have a great diffusion equation that has a wonderful particle method. Why on earth do you want to come up with, work with this much worse diffusion equation and come up with a new particle method? Can't we just go with what we already have? So, I'd like to give you a few items of motivation. Items of motivation for why you might be interested in what at first glance is a much worse PDE. Okay, so the first reasons I would like to give come from the sampling literature. First, Stein variational gradient descent is a sampling method that's attracted a lot of interest in recent years. And in the sampling literature, they've identified this type of degenerate diffusion PDE as a good toy model for understanding the dynamics of style. Model for understanding the dynamics of Stein variational gradient descent. So, from that literature, there's interest in the dynamics of this PDE and in particle approximations of it. Another motivation for studying this type of PDE that comes from the sampling literature is it turns out that solutions of this equation, I'll say this precisely in a slide or two when I talk about the Walserstein gradient flow structure, but solutions of this equation turn out to dissipate. Turn out to dissipate the chi-squared divergence between the solution and the desired target distribution as quickly as possible with respect to the Vassar sign structure. So, you know, kind of if you had some sort of kind of modeling assumption where it made sense to be dissipating the chi-squared divergence instead of dissipating the Kohlbach-Leibler divergence as quickly as possible, as the Fokker-Planck equation does, then this PD might start to seem a little. PDE might start to seem a little bit more natural. Other reasons you might be interested in studying this is if you're just kind of a PDE person at heart, as I am, these types of PDEs arise in a variety of models and physics and biology and models of porous media and biological swarming. So, by developing a particle method for this PDE, this will give us a numerical method for understanding these kinds of phenomena. From the perspective of robots, From the perspective of a robot coverage task, this is a really good choice of PDE, much better than the Fokker-Planck equation, because what I'm going to develop today is actually going to be a deterministic particle method for approximating solutions of this PDE. You know, while the stochastic particle method appears not a problem for the sampling application, when you're trying to develop a robot coverage algorithm, you would really like a deterministic particle method with convergence guarantees. And strangely enough, these types of deterministic particle methods, it's much easier to develop them for degenerate diffusion equations, much more difficult to develop them for the classical diffusion PDE. And then lastly, the last motivation I would like to give for why this isn't a crazy PDE to study in this context is that it turns out the dynamics that I will introduce, this particle method for approximating solutions of this PDE, correspond exactly to Correspond exactly to the dynamics that would arise if you are training a neural network with a single hidden layer in a radial basis function activation function. So, understanding the extent to which this particle method converges this PDE will shed light at the same time on the continuum limit for this toy model of training a neural network. Okay, so I hope now that you are not so opposed to studying this much worse PDE and seeing how. And seeing how a particle method can be developed in order to use it in sort of sampling or robot coverage algorithms. Okay, so now that I've given the motivation, I'll describe a little bit about the Voserstein gradient flow structure of these PDEs and how we use them to develop our algorithm. So we've already heard about Vasserstein gradient flows once in this conference, so I'll just sort of briefly Just sort of briefly recall the main idea. A Wasserstein gradient flow describes the evolution of a probability measure, ρ of t. So it's a probability measure evolving in time, where the time derivative of that probability measure is given by negative the gradient with respect to the Vosser sign structure of some energy. And basically, what this equation is telling you is that the probability measure is evolving in the direction. Measure is evolving in the direction of steepest descent of this energy with respect to the Wasserstein structure, or equivalently, that it's trying to dissipate that energy as quickly as possible kind of in the Wasserstein geometry. So turns out all of the equations that I've PDEs that I've mentioned so far in today's talk are examples of Wasserstein gradient flows. So here we have the Fokker-Planck equation. This is the Wasserstein gradient flow. This is the Vosser sign gradient flow of the Kolblak-Lebler divergence. So, solutions of this equation dissipate the Kolblak-Lebler divergence as quickly as possible with respect to the Vosser sign structure. In that sense, we would know automatically that the Kolblak-Leibler divergence is always decreasing along solutions of this PDE. And it's just the extra interesting piece that it, in fact, decreases exponentially quickly whenever the desired target distribution is strongly log concave. Distribution is strongly log concave, that is the interesting part. You will always know that a gradient flow will cause the energy to decrease. The key is just trying to figure out how quickly is it decreasing. So this is the first equation that we looked at. The equation that I'm going to be advocating that we study today is this degenerate diffusion equation, which is a Wasserstein gradient flow of the chi-squared divergence. So, as I already mentioned, you might be interested in this PDE if you. Be interested in this PDE if you were in some kind of a sampling context where dissipating the chi-square divergence as quickly as possible was natural. Katie, wouldn't in the in that chi-square case, wouldn't the numerator have some kind of difference square? Because usual chi-square is like, you know, you look into the difference of the two counts, square it, and then divide by the divide by the. Let's see. So if we had. see so if we had i i think maybe it's it's up to a constant um if we expand the square if we expand the square the rest doesn't matter yeah and and and that i'm i and a key thing here is that i'm assuming all of these equations that i'm looking at are you know conserve mass so that i can um rho is always a probability measure um so i can kind of uh you know integrate that out against the constant but your abs so uh this is a So, this is a very good point, which is that, you know, of course, these, since we're doing gradient flows of these energies, apparently am being a little sloppy with my constants, but because we're just going to be taking the gradient of it, the constants will not affect the dynamics of the PDE. But yeah, thank you for pointing that out. I should probably clean that up the next time I give this talk. So, these are the two PDEs that we've seen so far. Two other PDEs that I would like to mention because they will turn out to play a role in the algorithm that we develop. One is an aggregation and drift equation. This is a PDE that arises, especially a lot in models of biological swarming. This is a Vosserstein gradient flow of the interaction energy and external potential energy. And then more recently, there's been a lot of interest in looking at the Vosserstein. In looking at the Wasserstein gradient flow of this kind of quadratic loss energy that arises in training dynamics of two-layer neural networks. So, here is just one kind of very simple case of this energy where we have the quadratic loss. We're trying to approximate a function f naught. We have an activation function capital Phi. Rho are the weights of the parameters, and nu is our data distribution. Parameters and is our data distribution. And so, you know, there's a variety of choices of activation function that show up in different contexts. For example, the Relu activation function or a radial basis function activation function. So in the special case where we're looking at the quadratic loss, I can expand this out and I end up with something that doesn't look so different from the energy that I had above for the aggregation equation and drift. Aggregation equation and drift. A key difference, though, is that this kernel really depends separately on x and y. But it turns out that in the special case of a radial basis function activation function, this simplifies even more. And this term of the energy becomes the integral of the convolution of the radial basis function with rho squared integrated against the data distribution d nu. And so I'd like you to keep this energy in the back of your mind because it turns out that this energy is going to. Of your mind, because it turns out that this energy is going to appear again in a few slides once we start developing our particle method for the degenerate diffusion. And that is what links our particle method to the kind of Vosser-Strain gradient flow of this energy, which is a continuum model of training dynamics of two-layer neural networks. Sorry, Katie, is there some reason that you chose to focus on this particular exponent in the porous medium equation, 2, instead of a general exponent, M? An M? Oh, thank you for asking that question. In fact, right now, for simplicity, I'm talking about two. In previous work, we considered rho bar identically one and general M. But I guess the to the reason that I'm focusing on the case two, in this case, while I'm getting junk calls on my phone, is that we're able to get the strongest result on the Able to get the strongest result on the convergence of our particle method in this case. But we do have results for general M, but only for a uniform target distribution at this time. And I also see that there's a question in the chat. What are typical choice from LaVon or Becky and what are typical choices or assumptions on kernels K? This kernel K in the aggregation and drift context. In this case, you can see you see lots of ones. For example, Ones. For example, in biological swarming, it's common to see kernels that have attractive and repulsive components at different length scales. And in fact, these exponents can even have a singularity. I guess if I'm going to be so lots of or Lots of, or I'd say the theory is nicest if we have if we assume that this sort of interaction potential is you know maybe C2 or something like that. But things still can be said even for attractive repulsive interaction kernels, even with singularities of the origin. You could think of this as almost like a toy model, obviously with a much better, not as bad as singularity, but a toy model for like a Leonard Jones type potential. Toy model for like a Leonard Jones type potential. Thank you. Okay, so how does the structure of Vosserstein gradient flows impact our goal, which is design this kind of sampling algorithm, robot coverage algorithm? It turns out that Vosserstein gradient flows have a really behave really nicely with respect to particle message discretizations. So let me tell you why that is the case. Why is that the case? So, as here, I listed the three PDEs from the previous slide that I wrote out. And something you will notice in common of all these PDEs is that all of these PDEs are examples of continuity equations. And where, you know, for any Wasserstein gradient flow, it will always be a continuity equation where the velocity in that equation is given by the energy according to this formula. It's just the first variation of the energy. You take the gradient, and then we're doing a gradient flow going. And then we're doing a gradient flow going down in the direction of C, this is a descent of the energy. So we have a minus sign out front. So because all Vaser sign gradient flows are, okay, you know, this is a bit formal because, you know, depending on what energy you have in mind, you need to, you know, make sense of the appropriate regularity so that the symbol makes sense. But it's certainly true that all of Oserstein gradient flows are given by solutions of continuity. Given by solutions of continuity equations. And particle methods are a natural choice for any continuity equation. So, what do I mean by a particle method? And why does the Vosso sign gradient flow structure help me even more with particle methods than a generic continuity equation would? So, if I have a generic continuity equation, I'm going to assume that the continuity equation satisfies a very, very nice regularity. A very, very nice regularity assumption, which is that it has a uniformly continuous velocity field. And here, what I mean by uniformly is uniformly in row. So we'll discuss what happens when this assumption breaks down in a moment. But for now, let's just assume that the velocity field is really nice. If I want to approximate a solution of this PDE, it's an initial value problem. My first step in doing a particle method. To do in doing a particle method, I take the initial data and I approximate it by a sum of Dirac masses. And then what I'm going to do is I'm going to take the locations of those Dirac masses and I'm going to evolve them according to this system of ODEs, where this velocity here is exactly the same velocity that appeared in the original equation, but now instead of evaluating it some sort of, you know, potentially continuum. Actually, continuum density rho, I'm evaluating it at this empirical measure, rho n. Sorry, I'm a bit confused about the notation because in the fluid mechanical sense, the velocity is applied to particles, not to measures. So, what do you exactly mean by the velocity of the measure? Yeah, so that's a great. So, let me give maybe a specific example. So, let's consider the aggregate. So let's consider the aggregation equation that I mentioned on the previous slide. Oh, I should have got up in a sign. Okay, so in this case, my velocity is given by grad k convolved with rho. And so, for example, in this specific case, if I it would my velocity evaluating that at this empirical measure rho n is now just Does that clarify things? Yeah, I think my notation is a little weird at this slide. Okay, so okay, so this is so I approximate my initial condition. I approximate my initial condition by a sum of direct masses. I evolve my sum of direct masses according to this system of ODEs, where the velocity is the same as coming from the original PDE. What's nice about this is that it turns out that you can write this equivalently in two ways. You can either say I'm evolving the locations of my Dirac masses according to the system of ODEs, or that turns out to be equivalent to saying that this empirical measure is a weak solution of the same continuity. Weak solution of the same continuity equation that you started off with. But the key difference here is that it's an empirical measure on a finite number of particles, whereas up here, this could have been a continuum measure, row, or kind of a general measure of both sort of continuum and singular parts. But by so, what's so great about the fact that you can, about this particle method framework where the Where the OD, the evolution of your discretization agrees with the same structure of PDE as you're originally trying to approximate, is that now we're allowed to use the stability theory for the original PDE in estimating how close our numerical approximation is to the original equation. Because essentially, all we've done is perturb. All we've done is perturb the initial data. We've gone from this initial data row naught to a discretization of it. And so, as long as we have some information, for example, about the velocity, in this case, if it's uniformly continuous, we can say that perturbing the initial data causes our empirical approximation to be, we can say it's within this distance of the original solution of the original PDE. Of course, this estimate. Of course, this estimate deteriorates over time, but it's good enough on bounded time intervals to say that as n goes to infinity, this empirical approximation will converge to a solution of the original PDE in the Wasserstein metric. So just to, whoa, because the way I wrote on top of it. Okay, what you would be able to see here if I hadn't written in that exact spot is that particle methods lift solutions of Methods lift solutions of ODEs into the same PDE framework. And that's useful because the Vosserstein gradient flow structure gives us good tools for proving that V rho is uniformly Lipschitz, in particular, has a Lipschitz bound uniform in the row that you pick. And so that helps us get these sorts of estimates by which we can then prove that the particle method approximation converges to a solution of our original PDE. Converges to a solution of our original PDE. Okay, so this is the general particle method recipe. This works really for any continuity equation, but it's especially favorable for a Vosterstein gradient flow where you might have nice tools for getting these Lipschitz estimates. But the key question that you should be asking is, what about when you don't have these nice uniformly Lipschitz estimates? Because it turns out that if you go back to the PDEs I've mentioned, both of the first PDEs we have, we've these uniformly These uniform Lipschitz estimates on the velocity dramatically fail. But it turns out that this equation that I kind of casually mentioned before as arising in models of biological swarming does have these types of Lipschitz estimates as long as we have bounds on the interaction kernel and the drift potential on their Hessians. Okay, so what are we, what is the... So, what is going on here? We want to come up with a particle method for this degenerate diffusion equation so that we can use that in these sampling algorithms and these robot coverage algorithms. But the normal way of doing a particle method doesn't work because the velocity and the continuity equation here is not uniformly Lipschitz. So, what is our strategy? We want to somehow make this degenerate diffusion equation more like this aggregation equation, and we're going to do that by regularization. By regularization. And in fact, the type of regularization we consider in spirit derives from these approaches used in vortex-blob methods in fluid mechanics for developing particle methods for the Euler and Navier-Stokes equations. Okay, so let me tell you exactly what regularization we consider and how that allows us to develop this deterministic particle method for a diffusive equation. So at the top, I have the degenerate diffusion equation that Degenerate diffusion equation that we seek to approximate. So the Walserstein gradient flow of this energy. And beneath it, I have our approximation. And so here's the idea behind our approximation. If we take a, like, for example, a Gaussian mollifier, phi epsilon here, and if epsilon is very small, phi epsilon convolved with rho, morally speaking, will be very close. Rho, morally speaking, will be very close to rho. So that this energy is, you know, in some sense that we make precise, approximating that energy. And so the hope would be that if you look at the Wasserstein gradient flow of this regularized energy, which turns out to have this form, looks a little weird because of all these convolutions, that solutions of this PDE, as epsilon goes to zero, would approximate solutions to the top PDE. Okay, fine. This seems like it's. Fine. This seems like it's plausible, it could work. But what is the benefit we get of introducing this kind of weird regularization via convolution, which gives us a slightly unusual looking PDE? So the key benefit is that the velocity field here in this PDE turns out to be uniformly Lipschitz in rho, though it, of course, that Lipschitz constant does depend on epsilon. So as epsilon goes to zero, this Lipschitz constant deteriorates. Um, this Lipschitz constant deteriorates, but that's fine. At least for finite epsilon, it's uniformly Lipschitz. So, for finite epsilon, we can apply our particle method recipe, turn that crank, and we get a great particle method for approximating solutions of this PDE. We know that as long as epsilon is positive, as n goes to infinity, the empirical approximation that we get by the particle method will converge to a solution of this PDE. To a solution of this PDE. So the key question remains: our goal wasn't to approximate this PDE, it's to approximate this PDE. So now, what happens as we send, okay, I'll mention that in a second, what happens as we send into infinity and epsilon to zero? So that we're removing the regularization as we are increasing the number of particles. The hope would be that we approximate a solution of this original equation we are interested in, the degenerate diffusion equation. Generate diffusion equation. So, I have two remarks here, and this is just connecting what we've done to these toy models of two-layer neural networks. So, this energy here should remind you of this energy I mentioned earlier in the talk. This first part here, this is exactly the energy arising in models of two-layer neural networks with a radial basis function activation function. In that case, there is also an additional drift potential. I haven't been writing the additional drift potential. I haven't been writing the additional drift potential here in my talk, but all of my results continue to go through all these results with an addition of a drift potential. I'm just dropping it off for notational simplicity. So in this way, you can see that the dynamics, the particle method we're doing here, which our goal, you know, in sending into infinity and epsilon to zero is approximating this degenerate diffusion equation, the dynamics of this particle method is exactly the same as. Particle method is exactly the same as the dynamics of this toy model for training neural networks. So the limit we're looking at, where we're looking at the number of particles goes to infinity and epsilon goes to zero, this will also shed light on the limit of these toy models for neural networks in the over-parametrized regime. The number of neurons goes to infinity, and when the variance of the radial basis function goes to zero at the same time. So let me say exactly what our convergence result is. We indeed are able to prove that this particle method converges to a solution of the PDE as the number of particles goes to infinity and as the regularization is removed. Since I'm running short on time, I will just briefly say that there have been several interesting previous works looking at the exact same method, but all in the case of uniform target. Uniform target distribution. So ours was the first in allowing for a target distribution that didn't necessarily have to be uniform. In general, it could be just anything that's log concave. So what we were able to show is that given a log concave target distribution, as long as you have some, so this result is talking about how the particle method converges to a solution at the degenerate diffusion PDE. Solution of the degenerate diffusion PDE. So you take whatever the initial data is you had in mind for your initial degenerate diffusion PDE. You want to approximate that by a sum of Dirac masses and then evolve the Dirac masses according to the particle method. And the key question is, how do you have to increase the number of Dirac masses, increase your spatial discretization, and with respect to removing the regularization that we introduced? What we have is something that is sufficient, but Have something that is sufficient, but I expect is far from necessary. I bet something, uh, we don't know how to do something better, but it does not seem like this is optimal. What we're saying is that as epsilon gets smaller, you have to drastically increase the number of Dirac masses you're using in your approximation of the initial data. So, in particular, the Vosserstein distance between your Dirac mass approximation and the initial data has to be little low of this sort of Has to be little O of this sort of exponential, depending on epsilon. Okay, so I expect, as I said, this is basically saying that in has to go to infinity very quickly as epsilon goes to zero. This is sufficient, but I expect that what we observe numerically is that slower values of n also work. So under these assumptions, we're able to prove that our particle method converges to a solution of our PDE. PDE, and that this works on all bounded time intervals. And so now this gives us the piece of what we want because we know that as you advance time, solutions of the PDE approximate the desired target distribution. So now we can say we take our particle method, we do it for a large, a large, in a small epsilon in a large time, and this gives us an approximation of the desired target distribution. So, I think I have already discussed the connections with these applications. This gives us a method for sampling. It gives us a deterministic particle method useful in robot coverage algorithms. And it sheds light on the continuum limit of these toy models of two-layer neural networks in the connection between those and solutions of this degenerate diffusion PDE. So, I'll close with just a few numerical. So, I'll close with just a few numerical examples. So, here, what I'm illustrating is we have three choices of desired target distribution. Here it's a uniform target distribution. Here it's a log concave. And then here, this is just like a piecewise constant target distribution. So the dotted purple lines show the desired target distribution. In this case, we were considering 100 particles, 100 direct masses in our approximation. What we show on What we show on the bottom is the initial locations of the Dirac masses. So, in this case, we are distributing the Dirac masses uniformly between negative 0.5 and 0.5. And then we choose epsilon in this way. And then we evolve the Dirac masses according to this particle method. So here, the purple trajectories are the paths of the particles. And then at the top here, what you see are What you see are the kernel density estimates at each of these times of the particles. And so we see, sure enough, at time zero, the kernel density estimate just gives us something that's uniform between negative 0.5 and 0.5. That makes sense because we are just initializing the particles uniformly between negative 0.5 and 0.5. And then we see that the kernel density estimate converges to the desired target distribution as time evolves. Distribution as time evolves. Okay, so here are some illustrated numerical solutions. Something that's really nice is we, I told you that a major motivation for considering this degenerate diffusion equation was that, at least at the continuum level, we know it dissipates the Kohlbach-Leibler divergence to the desired target distribution exponentially quickly. And what's great is we observe that exponential decay of the Kohlbach-Leibler divergence also at the level of our discrete scheme. So our discrete scheme is not. Discrete scheme. So our discrete scheme is not breaking that. We can also look at the rate of convergence in the number of robots. I'm thinking about this application in mind. I can be robots or particles, whichever application you have in mind. The rate of convergence in the number of particles to the desired target distribution. We observe sort of first order convergence in the L1 norm. And similarly, we can also. And similarly, we can also analyze the rate of convergence, not to the asymptotic target distribution, but to the solution of the PDE to fixed time. And again, we observe something about first-order convergence to a solution to the degenerate diffusion PDE. There's several directions for future work. One is loosening the requirements on the desired target distribution even further. Target distribution even further. Interestingly, the main obstacle here is getting well-posedness of the Wasserstein gradient flow. Our argument for sending n to infinity and epsilon to zero does not use any log concavity of rho bar. But it was a lot harder than I expected to get the Wasserstein gradient flow well posed for general rho bar. And so, you know, we have some ideas here, but I can, this is that's going to be a follow-up work. Another thing I Another thing I've mentioned, I'm sure, you know, really we have nothing quantitative in terms of the rate of convergence depending on n and epsilon. It would be very interesting to say something along those lines. We know from how vortex blob methods are used in fluid mechanics that picking a smart choice of your radial basis function can lead to faster rates of convergence. In this case, I was always just using a Gaussian, the most naive choice. Choice. But it would be interesting to look at other more optimal choices of radial basis function. And then lastly, our method is sort of inherently order n squared. The motion of each particle depends on the motion of all the other particles. But there's been some interesting recent work on the random batch method, sort of inspired by stochastic gradient descent, where the hope is that by kind of instead of saying that every particle, the motion of every particle depends on all of the other. The motion of every particle depends on all of the other particles. It could you choose batches of the other particles at each time step and for the particle to see. This would certainly break down the dynamics at intermediate times. It would no longer correspond to the degenerate diffusion PDE at intermediate times, but there's hope that it could still get the right asymptotic profile, which, you know, in both the sampling and robot coverage algorithms, that's your goal. You don't care if you're, I mean, well, maybe you care. If you're, I mean, well, maybe you care a little bit if you're how fast, you know, the Kolbakovular divergence is decreasing or something like that. But if you could do it with much lower computational cost and still get the right asymptotic profile, you might be happy in some circumstances. Okay, so thank you very much. All right, thank you, Katie. Let's thank Katie for a wonderful talk. All right, okay, now the floor is open for questions. The floor is open for questions. If you have questions, please speak up and ask her directly. I have a question, actually. So, if we go back to these examples of the equations that you had, like here, for instance, right? So, also one motivation for like regularizing using a convolution. Like a regularizing using a convolution, is that this velocity field is a local quantity in density, right? And so if you want to estimate the density along a trajectory, you cannot do that unless you use some kind of integration like a Jacobi formula or something like that, right? So when you do this phi epsilon convolution, essentially the velocity field becomes like an expectation, and that's why you can do the And that's why you can do the particle method, right? So, but you could still do the same with the logarithmic kernel, right? So you could approximate the log rho term by the log of convolution. Is that interesting at all or would it give I spent some time trying to do that and I would love it if that would work. So the the the idea is well, couldn't you do something uh Do something like this in order to be able to come up with a deterministic particle method for a heat equation. I would love to be able to do that. I tried and I've not been able to figure it out. But yeah, I can do it for, so this relates back to also Robert's question of, you know, we really have this sort of family of energies. Okay, I'm just going to. Of energies. Okay, I'm just going to focus on Rhobar identically one for a moment. We have this family of energies. And in previous work, what we did was we were able to make this develop a particle method and get some convergence results for all m greater than or equal to 2. Our best results, our strongest results are when M. Our strongest results are when m equals 2. When m is strictly greater than 2, we have to sort of impose some additional assumptions on a priori estimates for solutions of this equation, which we are unable to justify. The only thing we can say as sort of in the case that M approaches one is we're able to show, we're able to prove. were able to show we're able to prove a gamma convergence of this uh um of this energy to the unregularized energy but not a gamma convergence of the gradient flows um so that was we um yeah so i i have been unable to do that but it seems i would it was it would be great if someone could do that um though i would say i guess you know