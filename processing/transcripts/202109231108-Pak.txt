Thank you so much, and thank you all organizers for having me here. And if I'm going to start thinking slowly and a little loopy, it's because I'm on the giant jet lag coming from Moscow the other day. So I'm going to talk about random linear extensions of possess, which one should think as some very unusual way of thinking of random extensions. Usual way of thinking of restricted permutations. So I can see some of you, if you don't understand something I'm saying, just let me know. Otherwise, I'll try to proceed. And everything I'm going to say is joined with Sui Hong and Greta. Sui Hong is my postdoc at SLA and Greta is at USC. Okay, so here is the plan for today. So, here is the plan for today. I'm going to do something a little unusual in contrast with what Svanta was saying. And thank you, Svante, for mentioning me. I am going to prove something. At least I'm going to sketch something, something very simple. And somehow it's going to be related to the rest of the talk. You'll have to wait for that. So I'm going to talk about linear extensions, then first introduce the subject. Then first introduce the subject, then I'm gonna discuss sorting probability, then I'll tell you about Poisson inequality, and then I'll come back and tell you how it's related to some inequalities for random walk. So I hope nobody has any questions yet, and then I'll proceed. Please excuse my low-tech slides. This is and let me know if you can see them. So I'm going to talk about mini extension. So, I'm going to talk about mini extensions of post sets. And the way to think about a posset is we have a ground set X and the partial order, which is this wiggle over there. And I'm going to, a linear extension is a map from the ground set to numbers from 1 to n, which has to be a bijection and order preserving. That is, if x is less than y in the partial order, then f of x has to be less than f of y. That's sort of the main definition for the day. Is everyone okay with that? Yes? Do this if you're okay, and do that if you're not. Okay, some of you figured out those of you who are yes, very good. Reactions are great. Okay, so by curvy E of P we denote the set of linear extensions, and little E of P is the number of linear extensions of a positive, and the And that's going to be our main subject for today. So, the simplest example one can imagine is a partial order without any relations whatsoever, in which case all permutations will work and the number of linear extensions is unfactorial, as you can imagine. So that was simple enough. Here is another post-set, which is sort of small post-set on four elements: A, B, C, D. Four elements A, B, C, D. The way I'm thinking of a poset is I'm sort of thinking of the smallest element on the top and which sort of increase down. Apologies for purists who think posits should grow from bottom up. So that's a poset on four elements, and there are exactly three linear extensions of that poset. One is the smallest element should always go on top, and then you have a choice whether the element. Whether the element here could be two, three, or four, and that's all the choice you got. Everyone comfortable with that? Yeah? Okay, good. I can see some thumbs up. And so here is a somewhat larger example, generalizing example I just gave you. So suppose you have some kind of rooted tree on an invertis. Rooted tree on n vertices, then there is actually a formula for the number of linear extensions. And again, the way to think about it: this is a labeling of a tree which starts at one at the root and increases downwards. And this is a product formula, but one should understand the reason. Where is this product formula coming from? Now, let me explain this PO facts: that the size of a branch below the element. So you take n factorial, the top. You take n factorial, the total number of permutations, and you divide by the product of the branch sizes. And the reason why that is true is because when you look at the posset, in order for something to be a linear extension, for every branch, this element x should be the smallest element in that branch. That's why you have one over b of x. Now, that's not a proof. In order to prove that, you need to show. In order to prove that, you need to show that if you take two different elements, then these events are independent, that this smallest element, this element is smallest in both this branch and that branch. And that's almost trivial. So that's so example one is really an exercise. Can I move on? Yes? So this should be compared with example two, which is my main subject. So suppose your Subject. So suppose your posit is a young diagram, and the way I'm thinking of Young diagram is a set of squares which is ordered from left to right and from top to bottom. So that top-left most element is the smallest element in the posset. And then there is also a formula. I can see there is a shot. Okay. So then there is again very similar formula, number of Very similar formula. Number of linear extensions in this case, this is called number of standard linear extensions, are called standard Kang tab laws. Number of linear extensions in this case is equal to n factorial divided by the product of Hook numbers, where Hook numbers, the way to think about it, if this is an element x, then hook numbers go down and to the right. And there is one attempt to prove that result in the same way as result number one. The first result is proved, and that's impossible to do it that way. Possible to do it that way. These events are completely not independent, and yet this formula exists. So that shows how complicated this issue can be. And finally, one of my favorite and the easiest example of a posset is a Catalan poset. So that's just a Young diagram, which is 2 by n, in which case the number of linear extensions, which is the same as the number of standard Young tables, is a cut. Kablos is a Catalan number, and I'm sure you all have seen how to prove that. I'm not gonna tell you in minions time again. Can I move on to the next slide? Okay. And so now that we're done with the definitions, let me tell you about what is the sorting probability. The sorting probability is given by this long formula. Let's try to understand. formal let's try to understand i'm going to look for all pairs of elements uh so that probability uh elements so that the probability linear extension on the first is uh less than the second minus the opposite is as small as possible so we want to find two elements so that the so that uh so that uh they divide basically the set of all linear extends Basically, the set of all linear extensions into two roughly equal parts. You see what I mean? So, if they were exactly equal, this minimum would be zero. They would be exactly the same number on the left and on the right. And I'm phrasing in terms of probability. And so, this whole subject is motivated by this strange-looking conjecture, which has a stranger name until you realize what that is. Name until you realize what that means. So the name is one sort to sort conjecture. And it says that one can, let me use this definition, one can find two elements in the possibility so that that probability is between one third and two thirds. Okay? And in the notation of these deltas, this is saying that this delta is less or equal to one third, which is the difference between one third and two thirds. You don't have a complete order. Yes, yes. Uh, yes, yes. If it's not, uh, uh, I should write it somewhere. Uh, is not a change. Thank you. Thank you, Peter. Sorry, Igor, I've missed something. So I haven't understood what this probability measure is. We choose can uniform measure on Linux functions. Okay. So we look at a random Linux. At a random linear extension, and we ask what is the probability this linear extension on element x is bigger than element y. And we want to make sure, and we want that probability to be between one-third and two-thirds. That's what this formula is saying. Sorry, so I must misunderstand. But if x and y are comparable in the linear order, yes, but so this. Yes, so but so uh this uh so if if it's a if it's a chain it's a complete order then there's no such element yeah but I mean the point is that if they're comparable then this difference is always one but you should take the minimum so you should choose a pair that's not comparable. Correct. Okay. So and it's worth pointing out that if your post that is a three element post that like that then this probability there are exactly This probability, there are exactly three linear extensions. It's the same example as I showed you before, essentially, and the probability is exactly one-third, so you cannot really improve over that one-third. Everyone clear about the definitions? Yeah? Okay, well, your last chance. So if you look at Wikipedia or Google. Wikipedia or Google, this is one of the most popular problems in the whole kind of recreational mathematical community. And obviously, there's been a lot of work done on that. One key paper that I want to single out is this paper by Nathalinia, who showed that one sort of sort of conjecture is actually true for posets of width two. It is not known for posits of width three. Posts of width three for process of height two. It's actually also been shown by this group. But this really uses essentially Komlusch's paper about sorting genuization of pigeonhole principle. And somehow many other papers are essentially redoing approach bilineal. Approach bilinear, which is very commuter and elegant, and I'm not going to tell it to you for the sake of time. And I'll just move on. So that's the state of art. Now, what is sort of the point? The point is many years ago, it's actually in some sense, if you don't particularly care about a constant, this conjecture had been resolved by Jeff Kahn and Mike Sachs, who showed. Jeff Kahn and Mike Sachs, who showed that this delta is bounded not by one-third but by five-elevenths, which is equivalent to saying that the probability that two elements that one is bigger than the other is between 311 and 811. And that's a little weaker than one-third and two-thirds, but good enough for computer science purposes. So, somewhat later, Canon Kim showed that. Canon Kim showed that one can use this approach to get an algorithm which does sorting with a partial information in essentially entropy bound number of comparison. So if you started with a, if you have a partial information about the numbers that you have, you can completely solve the numbers by picking the right element x and y and comparing them. So this theorem is saying there exists elements that you can choose. There exists elements that you can choose, and the second theorem is telling you how to do in polynomial time. But that's a completely different story. So this is the best bound as far as I know for the one-third to third conjecture. This delta is bounded by one of the square root of five, and since 95 has been 25 years, obviously, it hasn't been improved at all. But somehow, Linio's result is a little confusing in the sense that the real conjecture, in my opinion, is this conjecture by Canon Sachs, who was saying that if the width of the pulsar goes to infinity, then this sortic probability goes to zero. Essentially, if it goes to infinity, then lots and lots of elements which are not comparable, and you should be able to. And you should be able to find some of these elements so that the probability is close enough on them. And everyone good with this? Yeah? Okay. So what did we do? I'm not going to tell you much about the proof at all. What we did is we showed the Did is we showed a large number of results around the case when you have a young diagram of skew shape. If you remember a couple of slides before, one sort-to-sort conjecture actually has been established by elementary means. In that case, what we did is we said, suppose actually there is some epsilon delta so that both the smaller part wait sorry. Wait, sorry, the parts and the largest part are different by at least epsilon n. So somehow we have big diagrams which is sort of growing. Then this sorting probability is going to zero rather rapidly. It's big of one of the square root of n. And here, the number of columns is fixed. So we're actually working in this scenario for a posset of fixed widths. And that's the proof. I hope my co-authors forgive me. The proof is horrendously complicated. It goes on and on and on for pages, sort of the way Solanta was describing a lot of work and probability. In this case, essentially, we're taking one element which is sort of in the middle of the first row and looking at various And looking at various points in the second row and checking which one of them will work in order to have a very small sorting probability. And we show by really involved asymptotic analysis that one can do it to have sorting probability one over square root of n. And so let me sort of describe the essence of what we do. The way to think about it is. The way to think about it is to look at the projection onto the first row and the second row. What is the number going to be in this black point and in one of these red points? Turns out that the way one should think about, if you ignore all other rows, one should think about some kind of pass similar to the Catalan pass above diagonal. And the probability becomes, roughly speaking, Becomes, roughly speaking, the probability that this path goes above the red point or below the red point. So if you're looking at different red points on this line, and you're basically saying there is no sharp concentration on this probability in any particular point. If your diagram is wide enough, then somewhere it's going to go just... It's going to go just very slowly from below one half to above one half. And at the point when it just goes from below one half to above one half, that's what gives us our sorting probability. That's how the proof goes. And essential ingredient is this Narus-Hukman's formula, which comes from enumerative algebraic geometry and Schubert calculus. I'm not going to tell you anything about that. Not going to tell you anything about that. But this is the formula that we knew from my previous work with Greta and Alejandro Morales. Okay, so I'm not going to ask if you understood any of that. I'll just move on. And the reason is there is a simple case where one can actually do a lot of calculation. And that's the case of that Katuan post that I mentioned before. And in this case, there are no constraints. You are literally looking at the path from. You're looking at the paths from low left corner to upright in this triangle shape. So, all these grid paths about diagonal. And you're asking, does there exist a black point like that here? So that a probability that the path is above that red point minus the probability that below red point is very small. That's literally what the sorting probability question is. You see what I mean? You see what I mean? Yeah. And what we proved is in this particular case, you can just calculate everything to death. Everything is some kind of binomial coefficients, and it's still some effort, but one can show that the sorting probability is big of one over n to the five-fourths, so substantially better than one over square root of n. And we believe it's actually, this is actually tight. This is actually tight. This 5-4 is the correct number. And this is the place where I overwhelm you with graphs. So, this is the first graph, is an illustration for the first theorem. So, we take this, we just calculated what happens for n up to 1000 and looked at the sortic probability multiplied by n to the 5 fourths. And you can see that the constant applied by this big notation is roughly 2. So it's basically not basically not much more than two over n to the five fourths. However, if you look down, you can see that this sorting probability can be really, really small sometimes. So the right way to scale it is to look at the log base n of the sorting probability. And now and now some picture emerges. We still believe that this five-fourths is tight, but you can see some occasional spikes going way, way below. Very, very below. So it's a little unclear. Five-fourths is about here, 1.25. So it's a little unclear if that's actually the true limit, but you can see that it appears quite a bit often. So we believe it is. But that's all we know. Can I move on? So, does this have been a roughly exponential distribution, the values on the left? Left so if you look at n to the five fourths delta of pn, does this empirically have roughly exponential distribution? This is a polynomial. When n grows, it grows like one over n to the five-fourths. I don't think there is anything exponential here, but we cannot get a lower bound at all. Okay, well, later. Okay, so um So I forgot what time did I start the talk, but there are lots of inequalities about random about lim extensions. That why don't I show you the whole slide? So I'm talking about well let's go back. So let's standards and equality okay so standards inequality So, Stanley's inequality is saying that we're looking at random lean extension and the values that it takes on one particular element x. And so we're looking at what is the probability, in this case, I'm doing the counting version. What is the probability is that random lean extension has number k at the element x. And turns out that there is a surprising, very surprising log concavity that you see. Rising log concavity that you see in this case, and that log concavity extends to many other results. This is Kan Sachs' theorem. Okay, thank you, Omer. And what we are so this can sac theorem, so that's a key connection to the sorting probability, essentially. probability essentially Jeff Kahneman Sachs used this result this log concavity to obtain the 511 part so they used the result that is saying the following suppose you have two distinct elements X and Y and by a K denote the number of lean extensions so that the difference is on X minus Y is exactly K. So that's So that's this formula over there. And turns out that now numbers A of K are look concave. Can Sachs theorem generalize the standard because you can just take one of the elements to be the artificially added minimal elements on the process, in which case you get the original standard result. And in fairness, the proof is about the same, uses exactly the same Alexandra Famphen bulb technology. And one wonderful conjecture that I want to mention is about sort of correlation version of the CanSach inequality. So what happens when you have FKL? So the number of limit extensions. So we have now three elements, X, Y, and Z. And the difference on the first two is K, and the difference on the second and third is L. And then turns out that there is a conjugate. There is a conjectural remarkable inequality that I wrote here, which is, you know, for some time I thought it's going to be false, but now I don't know. So I tried very hard to disprove it and I failed to disprove it, which is saying really nothing. But the bright Felsner and Trotter actually proved it in a special case, K and L equal to one. So those are very old classes. Uh, very old, uh, I would say, classical inequalities for numbers of linear extensions. And I'll repeat this cross-product conjecture here. I'm just generalizing it by instead of having plus one and k plus one and l plus one, I'm putting k plus i and l plus j. And we believe that a slightly stronger inequality might be true. And we tried. And we try. So, one thing that one needs to understand is that this inequality, if that's true, that's just remarkable. It really has superpowers. So, what we showed is that it implies Can Sachs inequality. It implies something I'm not going to explain, the inequality by Gram, Yao, and Yao. And it, but more interestingly, it implies XYZ inequality. And that's just if the only thing you learn from. If the only thing you learn from this talk is the X-Y inequality, my job is well done. So let me try to explain it. Time to wake up. So, this is inequality proved by Larry Schapp, and it's saying that what the probability that a random linear extension on one element is smaller than on the other. So, you fix two distinct incomparable elements, X, Y, and Z. So, that probability only increases if you condition that f of X is. That f of x is smaller than f of z on a completely different z. So when you're adding something, this is sort of like monotonicity argument. I don't know how else to describe it. So somehow this extra conditioning is pushing the value at x a little smaller, which makes it a little easier to satisfy f of x less than f of y. That's how I would put it. How I would put it. And so it was several years until Larry Shep proved that it was conjectured earlier, and that was considered to breakthrough. And what we just observed in essentially half a page is that this generalized cross-product conjecture implies this easily by soft argument. What we can do is we can prove the generalized cross-product conjecture for all possesses of widths 2. Of widths too. That is something we can do. Another thing we can do is we can actually prove a Q analog of that result for well, let me kind of explain where it comes from. Essentially, when you have a postet of width two, that post kind of looks that way. So we have two chains, C1 and C2. And you're looking. And C2. And you're looking, and you have some other partial order which goes from top to bottom. Just like in the case of sorting probability, the way to think about linear extensions of this poset is to look at some region gamma corresponding to this possibility, which the picture is not exactly monotone, but this is some kind of latest. Are this some kind of latest path from lower left corner to upper right corner? And now, and now you're looking at the random path from lower left corner to upper right corner, and that's your linear extension. And that's what we do. We analyze those paths. So, in order to understand. So in order to understand what is this Q analog, one should think of the area below the red path. That's how we obtain our Q analog. That's what Q really means in this case. And we prove sort of Q version of the cross-product conjecture in this case, where Q version is this product of polynomials with. And this is a product of polynomials which depend on q, and less or equal in this case is coefficient wise. So we're saying that power coefficients in q on the left-hand side are less or equal than coefficients of q on the right-hand side in this product. Can I move on? Any questions so far? No? So I wanna, before getting to the last part of the talk, Getting to the last part of the talk, I want to mention some of our more recent results. So, this is related to equality condition. And I want to this is there is last year there was this kind of remarkable brute force paper by Schenfeld and Handel, completely geometric. It's all about Alexander Stanfield inequality. And they showed that, remember, in So, Stanley inequality is saying that AK squared is greater or equal to AK minus 1 times AK plus 1. So, there is a lot of concavity for these numbers AK. Now, what they're saying is that equality is rare. In a sense that in order to have an equality, everything really should be equal. So, the way to think about So, the way to think about it is that the graph sort of goes up, there's a plateau, and there's going down. So, for the, this is sort of like probably for the graph of AK. So, this is K and this is A of K. I hope you see what I mean. Okay, so the low concavity is rather rare in this case and Case and what we do is we obtain we obtain a Q analog of that result for posits of WITS2. And hopefully soon enough we or our competition from Princeton and MIT will prove equality condition for Kan Saxon equality. We can just do it for process of withstood. But we were telling the exact conjecture of what it should be, and the conjecture is saying basically. What it should be, and the conjecture is saying basically the same thing. The only way for the constraints and equality to be inequality is to have everything to be. Okay, so now is another time to wake up. I'm going to move to the random walks. And you all ready? Yes? Yeah. Okay. So, and it's going to be different font. And what one should do is just look at the What one should do is just look at the picture. So, here is the region. Here is the region gamma. I'm gonna start a random walk at a point O, somewhere on the left vertical boundary of the region. So the random walk starts and sort of goes around, goes around until what can happen to that random walk? Well, walking in a simply connected domain, which is constrained by vertical by By top and bottom boundary, which are sort of monotone from left to right. And what can happen is that when the wall can hit the right boundary or it can hit any other some other boundary. Now, if it hits any of these boundaries, vertical boundary on the left or the top boundary on the bottom boundary, then the volt dies. If it hits, If it hits the boundary on the right, we're going to record it. That's going to be a success. And we're going to denote by PK the probability that it hits at level K. Okay? So what we're looking at is the exit probability of the random walk through this vertical interval beta. Everyone clear what I'm doing? Yeah. Maybe not. Yes? The people who are silent should do this who are not on video. Okay. So, and now what we're saying is that for all regions, for all regions who have this low concavity result, do you see what I mean? Now, that is a really strange and possibly surprising result in a sense that you would expect that to be easy to prove for some particular regions, but not for general regions. And in fact, we can allow different probability, different transition probability for the random walk as long as it's vertically invariant and one can do diagonal steps. One can do diagonal steps, one can do all kinds of wonderful stuff, and the theorem remains true. That's why this is theorem one because we have several. Is the statement clear? There is a question. Vertical position on the right side for a successful walk. I don't know what it means. What is k in my picture? K is the height of point X. And we're conditioning on not exiting until we hit beta, essentially. Is that right? Yes, that's correct. So we're looking at only random votes which leave the regions through beta. Now, that may seem surprising, and even more surprising is what does that have to do with anything before, but the truth be told, Uh, truth be told, uh, for a very particular region which looks like a region between these two latest paths, that is exactly the same result, and you are allowed to go only up and to the right. So you only have, you cannot backtrack at all. That is the same result as one of our results for the positive width 2. Let me not explain that, but that's the connection. Essentially, what we did is we found the combinatorial because we had a combinatorial proof for those regions. Proof for those regions, we start looking for a combinatorial proof which generalizes and turns out that there is one. And that's what I can show you. Is the theorem clear? Yes? Any other questions about the theorem? Are the paths the green paths are the monotone or green paths have to be monotone? Otherwise, that's just not true. So, you are not allowed to have some kind of region which looks like that. That is not allowed. So, they just have to be a function? Yeah, it is I mean, it's not agreed. So, s uh so the the the uh eight plus and eight minuses go up and to the right or down, but they're just not never allowed to go left. But they're just not never allowed to go left. In the limited function, but okay, good. So that's our theorem. And now I can tell you a little bit about our proof. So we prove a stronger result. And what we do is essentially we say, well, this inequality one should be interpreting as an injection of the right-hand side into the left-hand side. The right hand side into the left hand side. This both sides count some number of pairs of paths. And we're gonna take these pairs of paths and do something to them, switch something, just like in Linstr√∂m's Vinot principle, we're gonna do something to this pair of pests to make other pairs of pests. Is the strategy clear? Yeah. Now, and Now, and I'm reading the question. Wait, exit probability typo. Okay. So this is so this. So what I'm doing here is I'm slightly generalizing by having a starting point. So literally. Point. So literally, those means. So before we had one starting point at O. If you look at the previous picture here, we had paths starting at O. And now I want them for illustration purposes to start on A and B. And it actually generalizes to different starting points. And they can either go slightly further away from each other or slightly closer away to each other. Okay? So this result comes. So, this result comes from this injection when you have T prime equal to D prime and A equal to B. That's how the embedding goes. But now I'm just going to tell you, you have, suppose you have this green path and this red path. What do you do in order to make this path go instead of C and D into C prime and D prime? I'm going to do something to those paths. Okay? And And the way to do it is the following. I'm going to take my bottom boundary and I'm going to lift the top. I'm going to lift the top by what? By basically this distance over there. Actually, no, no, no, by this distance between C and D. So So you get some kind of path which goes through somewhere through the region. And I'm going to define a point E. The proof is slightly invoked, but I'm just going to show you the steps of the proof. I'm going to define the point E to be the last point of intersection of my green pass and this lifted boundary. That's how I define point E. Point E. Similarly, what I'm going to do is I'm going to lift the red path so that instead of going to point D, it's now going to point C prime. So you get this kind of brownish pass over there. And I'm going to, this path can go outside. It's not like the original red pass, which was constrained to the region. But now I'm going to find the last point. Last point on the path, which is going to be the intersection with the boundary. So I'm going to define a point F. Then I'm going to define a point G as follows. So now I need both points E and F and my original green path is going from E to C and my lifted red path is going from F down to C prime. Down to C prime. I'm going to define the last point of intersection G. All of those pieces are important. And now this is part three again. Now, when I'm looking at this point G and what I see is there are two ways to get one way to get using original green path to get to C and using this brownish path to get from G to C. Brownish path to get from G to C prime. So that's what we switch. So instead of going to C, I'm now going to C prime. And similarly on the bottom, I just push the whole picture in the other direction. If you notice, this path from G to C prime actually was a lifted part of something. So we pushed G down to get to G prime, and from G prime, we used to go to. And from G prime, we used to go to D. And now along this path from G to C, we're going from G prime to D prime. Sorry, this was fast, I know. But that's the proof. That's how the proof would go. So essentially, everything else is bookkeeping. So what we do is we have somehow the right order of things to define which points are. Are obtained up to which points, what's inside, what's outside, and the rest is bookkeeping in a sense that you have to show that you can undo this. Okay, that it's truly an injection whenever it works. And the reason somehow why the whole thing works is because of planarity. Somehow, the path from E to C and F to C prime have to intersect because both paths are different. Because both paths are inside this region gamma that we consider. So it shouldn't have holes of any kind. And that's why you need monotonicity for the boundary. And that's it. My time is done. Thank you all. Thank you very much indeed, Igor. Questions or comments? Svanta. Ah, Svanta is just copping. Sorry, I thought that was a hand being raised, but it's just applause. Oh, I have no question. So, just to be clear: so, you say that if the top and bottom are more general shapes, then this actual. General shapes, then this actually fails. Not just the proof fails, but actually the claim. The claim fails. So how many? I didn't prove that the claim fails. I convinced myself that the claim failed. We didn't put it in the paper. Stas, you've got your hand up. We can't hear you. Can you hear me better now? Yes. Yeah. So I just asking about the random walk. Is it with six possible steps or with possible steps? Because simple random walk is usually up, down, left, right. In the picture, it's the way the theorem is stated here is up, down, left, right. Here is up, down, left, right. But I'm telling you that we have also theorem four or something, which tells you that you can go one over six. Okay, thank you. Yeah, so both, so that's also true. There is a question in the chat. Does the sorting probability have something to do with limit shape of young tableaus? Yes. I can explain it. I can explain it, I suppose. Ben, you're with us? Okay, yes. Okay, so the idea is the idea is the following. Essentially, the limit limits the same thing. The limit shapes of Young tableaus are some kind of curves, level curves. So if you have a really large Young diagram and you can look at random Young tableaus, then with high probability, numbers less or equal than some kind of alpha times M are going to occupy a Young diagram, which is in various ways. Various ways can be shown to be close to a certain curve. Yeah, I was thinking of your Catalan picture, and you just mentioned in passing that you were saying that this point is above or below this other red point. And that seems to me about the upper contour. Let me tell you in this young diagram picture, because that's very clean somehow. What we're saying is that if you take two points on a level curve, then with equal probability, then the probability. With equal probability, then the probability that one is going to be bigger than the other should be roughly one-half, because those are the points which are incomparable up to alpha times n. But we are not able to use any of this technology to actually prove anything about sorting probability. So our bound over there comes from a completely different Comes from a completely different tool. Well, I don't know, but completely different. In my paper with Alejandro Morales and Martin Tassie, we use the same tool to prove a version of this result about limit curves. But I think that's pushing the subject a little further away. Okay. Okay, thank you. Gail, you've got your hand up. Yes, I think I missed the punchline of the last proof. So, how The last proof. So, how does the inequality follow from the injectivity of the map? Oh, yeah. So, we need to prove the in order to prove the negative we're constructing an explicit injection between pairs of paths counted by the right-hand side and pairs of paths counted by the left-hand side. And then I generalize that and I take giant pains to actually show. I take giant pains to actually show that this is an injection. And by giant pains, I mean a couple of pages. Thank you. I mean, in fairness, this is, I mean, I've heard and I've seen people in probability writing short papers. This is my first short paper on probability. It's under 10 pages, which is surprising for a paper on probability. That's because the argument is completely communatorial. I was wondering related to that proof. I was confused about what A and B are. I thought the paths started at the origin. Don't they start at the same point? Remember, this is what I said. So origin, if origin is the same as A and the same as B. So essentially, I'm proving a stronger result and I'm making them different for illustration purposes as well, because otherwise it's. Purposes as well, because otherwise it's hard to figure out what I'm talking about. So I prove a strong result than whatever you see over there. So in fact, we have more of these inequalities, but it's really much nicer to draw this picture over there. And another thing is C prime equal to D prime. d prime and and another thing is c c prime equal to d d prime equal to one so so that inequality this inequality over there is a special case of those three and we tried we tried to see if there is any kind of general argument in kinetic In kineto probability from which this would be trivial corollary, and we couldn't find anything. It's really a novel type of injection, kineto argument. So Igo, you've got these results for various different families of postsets. I was wondering if, in some sense, you take a typical postet, or so, say, for example, you do the following thing. You start with a uniformly random permutation, you have no information about it. Mutation, you have no information about it. And maybe you just ask n questions at random. You take n pairs and you ask: is A bigger than B? Is C bigger than D? And then you have some information. That's some post that. Can you say something about... Yes, I'll get it. So Graham Brightwell wrote in the 80s or 90s a long survey about random postets and posted from different... There's no one model of random postets. One can sort of look at random post-like. At random poset, like uniform distributional poset, or you can have other models. So, a typical model would be to put them in line and put basically inequalities which go from left to right, sort of emulate random graphs that way. And then almost all these conjectures become trivial in all of these models. For example, if you take a unit, it's a theorem by Kleitman and By Kleitman and Rothschild back in the 70s, that a random posit has height 3 with high probability. And in fact, it sort of looks that way. You kind of have random graphs between levels and they know exactly what's going on. Since we have this result for positive with two, sorry. Sorry, for posets of height two, it's not really that much of a stretch to prove that it's true for random positions and somebody did it. Okay. And there is more to the story for other models, there are other results, no. So you really want to prove this for all postets, not somehow random. And we don't, we prove them for post-sets that. Prove them for post-set of uh it's sort of one of those things when you prove stuff about things that you know that you know how to deal with. In my other hat of algebraic comatorics, I deal a lot of with algebraic kinetorics, and that's what I do. But you might be able to get so okay, so one third or whatever is easy, but you might be able to get some results like one over root n again or some actual order of country. They do, okay. Yeah. Yeah. So Komlosh is especially interesting. So he basically says that if you have a kind of positive height two, when both parts are bounded away from a constant, when minimum of the two goes to infinity, then delta goes to zero, and he has bounds on how that works. So, so I recommend Comlash paper, which is just three pages. Fantastic. Okay, thank you very much. Any more questions or comments before we round off for today? I can remark that. Go for it, Peter. Yeah, I agree with Igor's statement that the question of whether these sorting probability you call it. The sorting probability you call it goes to zero as width, or perhaps something else increases is more interesting. And one of the reasons is that Brightwell showed even before it was proved that the right answer, in some sense, really is one over the square root of five, because if you extend two infinite posets, you can get the other bound for that answer as well. So, in some sense, the one Answer as well. So, in some sense, the one-thirds, two-thirds business is an end effect. It's just something that creeps in as a result of the finiteness of the order. And we don't really seem to have the tools to prove it, therefore. By the way, did you know, Igor, that the XYZ conjecture almost became the XYG conjecture? No. I don't know what that means. I don't know what that means. Yeah, the conjecture was first made by Rival and Sands, actually named by me. And I was the one who communicated it to Larry Schepp, who proved it using the FKG inequality. So Larry Schepp sent me a copy of the proofs of his paper on which he had marked, dear typesetter, beautiful job. I could find no error. Beautiful job. I could find no errors at all. And I didn't actually see any errors at all. But when my colleague Dwight Duffis looked over my shoulder from about 20 yards away, he saw that the title said XYG conjecture in 24-point bold-face blocked things that you could read from one end of a football field to the other. But you know, you get proofs. Who reads the title, right? I called up Larry and he was able to call Switzerland. Was able to call Switzerland and change the title like just in time before the paper appeared. Just a historical