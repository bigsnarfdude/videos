I mean I've been there for almost thirty years so it's easy to remember the information. So how do I so you will see something about homogenization? No, this is salary. Well, I sent it by email, but I don't see it here, so I don't know. Yeah, this is what Marco asked me to do. So, you get an extra minute, yes, to be this. I don't think I can get on 107. Yeah. I had a different title that says the pointer? This is the pointer. Fine, can we say that's the one we use? This is the same thing. So I think that's a good question. Okay, so we will see about automationization with no local test procedures. Okay, thank you very much. Okay, thank you very much. I'm very happy to be here. I'll try to be a bit light. Everybody is tired, the last talk. And just let me say that I will be transversal to the majority of the talks. So there will be no diffusion in my talk. There will be some non-locality and the most disc structure. So the point I will try to make is that. The point I will try to make is that the problem I will discuss is really discussed at the level of the static analysis because the difficulty is already very high in that case. So maybe there is room for diffusion, but I mean, we'll see there is already very involved. I don't know which one is the right. So, this is a very short series of pictures to say the motivation for my analysis. The motivation is the study of plastic behavior of metals. And this is really a rough way of saying that metals are crystals, they behave differently at different scales. The reason for the plastic behavior. The plastic behavior is related with the presence of crystal defects, and these crystal defects appear at different scales, they interact, they accumulate, they create structures, these structures are important for the effective behavior, for the evolution, and so on and so forth. So, this is more or less the type of motivation I have in mind. And so, let me briefly tell you what are these defects. So, I mean, this is a So I mean this is a I don't know whether this one's I was hoping the opposite is a kind of very basic cartoon of what is a defect in a crystal structure okay or at least the defect I will have in mind in describing the In mind, in describing the model, and I think it's useful to see the discrete situation because you understand why there is a defect, but then I will switch immediately to a continuum approach. So the idea is that, so you see here you have say cubic distribution of atoms, and in this region, there is something which is round. So essentially, you have an extra plane of atoms that ends with a line of atoms that have. Line of atoms that have wrong neighbors, in a sense. So they don't really see a perfect crystal around them. And this has topological defect as well as vortices in the Gisborne-Landahl theory, for instance. So if you take a cut of this and you take a two-dimensional picture, this is very similar to what happens when you have a vortex in crystals, in superconductors. So the way you detect this. So, the way you detect this topological defect is drawing a circuit around this defect and comparing this circuit with a perfect crystal. So, I mean, if you look at the crystal here, this is a kind of sort of small deformation of a perfect crystal, and this is true locally everywhere around it. You go around this defect, you do the same in the perfect crystal, and you have an extra step. And the extra step is really somehow the signature of the presence of this defect. Of the presence of this defect. And if you want to say that in somehow in continuum variables, you will have a field which is not globally a gradient, and the circulation is given by this gap. And the gap is related with the crystal structure. So the gap belongs to a given set of admissible vectors, say zeta 2, okay, in a two-dimensional situation, or zeta three in a full three-dimensional setting. So this is just to remember that. So this is just to remember that there is a vector, which will be the kind of multiplicity of my effect, and this vector must belong to a lattice. So now switch to the continuum picture. The continuum picture really goes back to the beginning of last century, Volterra description of this defect. So the idea is that the reason why you have this extra plane of atoms is because there was a shift in your body, like here, you cut. Body, like here, you cut a plane, a slip plane of your domain, you slip by a given vector, just a part of it, and possibly a vector that restores the crystal structure almost everywhere, like it happens here, apart from this line, red line, that has, I mean, the problem of having a misfit around it. Okay, so this is the defect we are talking about, and these are called dislocations. In this specific case, these are edge dislocations. Are edge dislocation. This is the case in which your slip is orthogonal to this line that's separating different slips on this plate. Okay. So let's look at it in a closer way. So there are several models that describe this type of objects. Many of them are very much related with the theory of Giesburg-Landau. Kiesburlandau. So vortices in two dimensions, of filaments in three dimensions. The one I'm talking about, this, as far as I know, is really kind of characteristic of this interpretation of crystal defects in metals. And this due to Nabarro empires is an old model. And I mean the the one I will describe is a general more more rec recent generalization, but essentially it's the the client. But essentially, it's the quite classical approach. So, the idea is that you restrict your kinematic to the only slip on a given plane, like the picture of Ala Volterra that I was describing before. So, you have, in principle, a deformation U of your three-dimensional body, which is a vector-valued map, and so you associate to that inelastic energy, so a quadratic form that depends. Quadratic form that depends only on the esimetric part of the gradient if you look at the NRS models, but I mean, this is somehow partially important. So, you have an elastic energy of the bulk, and then you assume that this function can have a discontinuity on a given plane. This will be interpreted like the slip on that plane. Okay, and so the jump on this plane, which I call sigma, is a sign. Call sigma is assigned. Okay. And now you associate to this quantity here an energy which is made of two contributions. One is the bulk elastic energy that I have here, and another one which somehow should tell you something about the fact that when you sleep by multiple of the of in of Of integers, so if you want by somehow by vectors which belong to zeta 2, you restore the lamp, so you don't pay energy, okay? Otherwise, you pay some energy because you deviate from the, so you create a misfit. And then there is a one over epsilon coefficient here, which is reminiscent of the fact that you have a lactis spacing, a lactis structure, so a discrete model. Structure, so a discrete model, a microscopic model. So, and then you cannot see it here, but there is a list of authors which have been working on that. I don't even know whether that okay, no, there's no need to watch essentially this mod, this is the original original model, and I'm This is the original model on ambarobias, and this is a generalization to this 3DE to DE setting given by Tukozlowski, Kutini, and Dartis. So let me give you a very informal way of understanding why you have this model. So, and this is really going back to a very old way of describing the Way of describing the behavior of the interaction of particles in crystals, some of the supposed Franklin-Kontorova model and some other more recent generalizations. So let me stick on a two-dimensional model. So say I have a cross-sector, so I take a cross-sectional parallel to the screen of the picture, the screen picture that we have seen before. And now I describe my And now I describe my deformation with a discrete variable which goes from omega intersection zeta 2, so this set of atoms to R. It's R because it's just horizontal. So I'm assuming that you only have horizontal deformation. And so the model somehow is telling the following thing. If I compare two out of Following thing. If I compare two atoms in the horizontal lines, so two neighbors, or horizontal neighbors, I pay the square of the distance and somehow a gradient. So I'm assuming that I have small deformation in the horizontal. But I'm allowing large deformation, large leaps, which means I'm allowing large deformation vertically. But I don't want to pay if I move by integers, because if I move by integers, I restore the lattice. Move by integers, I restore the lattice. So, what I really want to see is the elastic distortion in the default configuration. And so, this is somehow modeled by this quantity that projects the slips in vertical on integers. Okay, something like that. And then you sum over all the atoms. And now, so the idea is that, oops, yeah. Yeah, that essentially, if you now assume that this ellipse is only on one single plane, like I was doing with the Nabarlopias, so not only in not in all possible horizontal lines, but just one, then I isolate the interaction around this plane. So I count all the interaction outside if you want the plane, and I'm assuming that outside you only. I'm assuming that outside you only have small deformation, so a sort of a gradient here. And then you stick with the neighbor of this horizontal line in which you look at the vertical interactions. And this is somehow really something like, oh, sorry, there is a square missing here. This is really the distance of the jump from integers. And the word over epsilon is really the difference in scales. So this is a bulk thing. So you come then. thing so you you count the number of atoms here and you count the number of atoms here the difference is scaling is this one over epsilon so it's just the fact that this is a bulk thing and this is a surface term okay it's a bit informal but at least to justify the the structure so let me now so essentially sorry now essentially I really have the number of wires I have something which is elastic plus one over epsilon the distance from uh to a multi well potential. To a multi-wheel potential. In this sense, it's a phase field model. Okay, so let me now try to say what would be the analysis of a model like that. So I have an energy, which is a gradient square on a two-dimensional domain here, but it would be three-dimensional, plus a surface term with a penalization. Okay, this was studied. This was studied in a very nice paper by Alberti Bushensi-Bachet, where they consider, well, they consider a Canillier-type model for phase transition at the boundary. And so they have like a gradient term plus a multi-well potential with wells that live at the That live at the boundary of the domain, so the variable here is V, and this is the trace of V at the boundary. And with the blow-up argument, so moving from the variable trace of V to the variable U, which is defined at the boundary, with the black argument, they rewrite this energy in terms of a one-dimensional model in which this gradient here. Which this gradient here becomes this H1 alpha semi-norm. Okay? So it's a phase transition model with a regularizing term, finally a type. Instead of the gradient, you have this non-local interaction with the H1F. And the H1F really comes from the fact that here you are looking at the variable at the boundary, it's a trace energy. So we are doing the same thing. Same thing, and so the number of piers was that. So, like an energy, elastic energy, and plus the multiple potential. So, let me write it here so we have it. So, the Mavaroch energy in terms of the variable u, which is now defined on a two-dimensional, so u is defined on a two-dimensional domain. So it's this double integral on sigma. Then there is a kernel. So it's a quadratic form in terms of this. In terms of these differences, plus one other silon is multi-wheel potential. So this is essentially the trace version, if you add some boundary condition, some boundary condition on the latter on a lateral infinite cylinder of this integral, say, something like that. Say something like that. So, this is the equivalent of the bulk elastic energy. Okay, and this K is a matrix, is a two by two matrix, which has exactly the behavior of the kernel of the H1 half node. It's anisotropic, in principle. In fact, it will be anisotropic. In fact, it would be anisotropic, and so this is a quadratic form with this curve. And this is the model I want to discuss. So, let me just give you a little bit of heuristics of what should be the behavior of this energy. So, so I I'm thinking of approximating a configuration which should should jump from zero to the vector E one, for instance, okay? E1, for instance. Okay, so remember my domain now is the slip plane, and I'm looking in my variable is the slip along this plane. So this U, which is a vector zip. So suppose that now I want to approximate the interface, so the energy of the phase transition between zero and E1. And so this computer, so somehow this potential. Somehow this potential here wants the transition to be on a set, a small set of order epsilon. So I do it somehow regular. So I go from zero to one, somehow linear, whatever. And I compute the non-local energy. So the non-local energy somehow has a kernel like that. And then you realize that the leading order term of this non-local interaction, in which you have the interaction between The interaction between A and B, A and the layer, the layer and B, and so on and so forth. The only relevant part is the interaction between these two plateaus. Okay, this is the leading order term. You integrate it and you get a logarithmic behavior. Okay, so the idea is that if you escape this energy by the logarithm, you would see some finite energy for the interface. The interface. And this has been done in several situations. We started with Stefan Müller in 2006 for the Scalar case. And so I'll try to describe you the general two-dimensional vector value case that we did with Conti and Müller in 2011. And so the idea is that, so when you do a rescaling by log epsilon, you end up with a line. Epsilon, you end up with the line tension energy. So you pay a finite energy which is proportional possibly to the length of the interface between two different phases. Okay, and so this is the first result and which I was mentioning, and it is in terms of gamma convergence. So I was told that I should recall what gamma convergence is, so let's be six. So, I mean. So, I mean, already Alice mentioned it. So, this is somehow a way of describing asymptotic behavior of minimum problems associated with some energies. And so the idea is that if you want to prove gamma convergence, so if you want to prove that, say, a functional f epsilon. So, in this case, f epsilon bar of iron will be one over log epsilon energy I was adding before, so the escape energy. So, if you want to prove that this converges to some F0, you have to prove two things: an upper bound, a lower bound, say, a lower bound, which is simply saying that if you look at all That if you look at all possible configurations that in some topology that you need to choose for virtual limited configuration, then your limiting energy should always be below the limit for f epsilon of epsilon. So you look at all possible configurations that approach, for instance, a sharp interface, all possible ways of approximating it, and then you should your energy have to see. Your energy zero should associate the least energy that you obtain with these approximations. Okay, and then the upper bound means that this is optimal, so that you can find the sequence that really achieves the values if you want. Okay? And then there is a second important step is a compactness statement which allows to sell you. Which allows to tell you what Alex was mentioning: that if you look at minimum problems with this energy, you have convergence of minimum to the minimum problem of S0 and convergence of minimizers. In a sense, we'll tell you in terms of models that this limiting model is a good approximation for the approximating models and possibly the evolution. So, the result here is then the following: you rescale the energy, you have a first statement, which is a convergence statement, which is saying that up to translation, your sequences with bounded energy, with an energy that is logarithmically bounded, converge L1 to BV functions with values in zeta 2. So, imagine a picture like that: a partition of the domain with different slips. And then the gamma convergence is to an energy, and this is zero, which is the line tension. So it's an energy on the jump set of U with an energy density that depends on the jumps along the interface on the normal at the interface integrated on the jumps. Okay, just for second. Just for the sake of simplicity, now assume that the kernel is homogeneous, anisotropic, but homogeneous. Actually, this is the case of the asymptotic behavior at zero. So this function psi is determined, completely determined via the kernel K and a relaxation procedure, which means the following situation. So first Define a density psi zero, which is really defined in terms of this kernel gamma. So it's the integration along fibers which are orthogonal to the normal u that you are considering of this quadratic form with the gamma here. So this say zero actually gives you Actually, it gives you the right energy when you do the heuristic computation that we have doing before. So, you essentially take something that goes from zero to B with a layer of order epsilon, and you can do that simply modifying the step function with the kernel scale epsilon. You compute the energy corresponding, and you get exactly the right side zero. Okay, so this. Zero. Okay, so this converges to sine zero of B. Okay, but this is not the right gamma limit. For the scalar case, this is the gamma limit. For the scalar case, so if you assume that here you just have scalar function and you are distant from zeta, that is the right gamma limit. And these are the optimal sequences. So the optimal sequences are really okay in just modifying. Sequence I really okay just modifying the profile. Okay, and instead, in the vector-valued case, you need to relax. Okay, don't look too much at the picture, at the formulas, just the pictures. So, the idea is that in order to achieve a straight interface, you cannot really take a straight configuration and modify it, but you need to construct a sort of microstructure. So, that you have locally optimized, so you optimize. Optimism, so you optimize your energy at scale one, then you rescale your profile, and this gives you the optimal scaling, the optimal energy. Okay, so I forget. I mean, it's not really important to really understand this relaxation procedure, but the idea is that in the limit, a straight interface is not obtained by modifying the straight step function. It's obtained by modifying a more complicated structure that is a microstructure. That is a microstructure. Okay? You mean that the microstructure will be influencing what is the result, but you can choose different microstructures? Say it again? You can choose different microstructures or it depends on the choice of microstructure. No, no, it's not dependent on the choice of microstructure. The microstructure depends on the limiting configuration. So if you have one, so for instance, I don't know. So this is a. I don't know. So, this is a if you want to approximate the configuration zero E1 plus E2, you need to produce a construction like that in order to optimize the energy. Okay, it's like convexification. So, okay, so suppose you have a non-lower semi-continuous energy, non-convex energy, in some regions of your domain, you need to convexify the energy density and the macro structure. G density and the macro structure you need to convexify depends on the configuration you are looking at. Right? It's sort of convexification. And I was wondering about how much do you want to know about the cell structure? You don't know much. Like, I mean, in here there is a specific example in which you can construct some some configuration, but in general I like it for quasi-convexification. I mean, it's an implicit formula. So I mean, it's an implicit formula, so in some cases, you can find some ideas of how to construct the microstructure, but it is not in general true. Okay. So this is my first somehow summary of the multi-scale feature. So I have shown in a sort of justification of why you have the number of viruses. So, the number of values is more or less a discrete model, okay? So, you have a discrete model, discrete in the sense that this is the discrete signature, which is this one. Then, from your discrete model, you go to say mesoscopic model in which you have single dislocation, which are lines, and this somehow. And these somehow are related with this relaxation that I'm showing here. And so you end up with a model which is a model, a line tension model with an effective line tension energy density, which is this one. And here, the jumps are quantized because they belong to zeta two. Okay, so this is okay. But actually, this is not the case. But actually, this is not the case. I mean, in plasticity, you don't see jumps which are quantized because actually the jumps are at the order of the lattice spacing, are very small. So the idea that when you have a plastic slip, you have sort of a continuous leap, which at the microscopic model is a superposition of very small slips, like in this picture. So you, in principle, have a continuum distribution of plastic slip, and then you can think that these. And then you can think that this continuum distribution is a superposition of many small effects of small order. So, the next step is to understand what happens if you rescale these jumps. So, if you rescale this u. So, you allow u to be in sigma zeta 2 now. So, the jumps are ordered sigma. Then you rescale properly your energy density here, and then you lose. Here, and then you look at again at the gamma limit as sigma goes to zero. And this new result produces an energy which is now defined. So actually, sorry, this omega here is what I was calling sigma over there. So it's a two-dimensional domain. So now it's defined in all BV functions. This was defined only on BV functions with very. Was defined only of the V function with values in zeta 2. And then, so this is an integral integrated with respect to the total variation of du, and so can be diffused in this plane, it can be concentrated on lines, can be concentrated on counter sectors, so the structure here, with an energy density G, which is again due to the sort of relaxation, so a sort of microstructure. Sort of microstructure procedure. And so I'm not saying, don't want to say anything about the proof, but just to make it clear why you have another microstructure. So now suppose that you want to approximate a diffuse slip which is affine. So a rank one matrix, B times nu times X. So you do it like this line, you do it with jumps. Line, you do it with jumps uniformly distributed, which means you do it with straight lines, so straight interfaces, okay, oriented with mu with multiplicity sigma b at the distance sigma. Okay, so if you do that, your energy here, or that energy, will give you the resection function of psi, so this limit here. Okay, okay, so this. Okay, so this is essentially the energy you want to associate to this specific configuration. Now you want to associate energy to all possible configurations. Now is the convexification. You take an energy density, which is the psi infinity for all rank-1 matrices and plus infinity otherwise, and you convexify it. Okay? And so to all two by two matrices, you associate an energy. matrices you associate an energy density which is the convexification of this energy and the interesting thing is that in in explicit examples you can show that this convexification produces non-trivial microstructures so instead of approximating the difference of these two one random matrices with a checkerboard so in which you put uh constant and jumps by sigma in two in the two directions uh every time you cross an interface. Across an interface. So, this configuration will have an energy which is larger than this energy. Okay, so in a sense, you have a farther microstructure at a larger scale. Remember that already these lines are coordinated with the microstructure. Okay. How much time do I have? Ten minutes. 10 minutes yes uh okay so 11 wow okay so okay but this somehow was not particularly convinced in a sense because I was first sending the lattice space to zero and then I said no but but then the Burgess vector actually should be small which should be of the order of the lattice space so I introduce another scale sigma so let me see if I can do this So let me see if I can do this directly. So if I can start with a different scaling from the Navarro virus and go directly to this continuum distribution of slips. So the idea is that I would like to scale these Navarro virus in order to allow for many lines because the logarithmic scaling here, this is the energy per unit length. So if I divide by the logarithm, I immediately select It might immediately select configurations with the finite length. And so the idea is that you want to scale by a number that converts tends to infinity in order to let the length of the total length to go to infinity. And this somehow was a picture to try to explain why this number should be given by logarithm of epsilon. And so this, so I don't know if I have room to make this picture over there, but. So the idea is that each line costs logarithma and I allowed for n epsilon lines somehow with the scaling. And then instead the long range cost n epsilon squared. So imagine of having many lines. I said at the beginning that if you take the non-local interaction between two neighboring interaction between two neighboring plateaus, this gives you a logarithmic. And the logarithmic depends on the fact that somehow the interface of this distance. So you have a singular kernel, so it's not integrable, but you skip an epsilon neighborhood of the discontinuity. Okay, but now you let interact all the others, so you keep the full energy, and the interaction of each one with all the others in order or the one instead. order one instead. So you count all of them is order n epsilon squared. Okay. So say that you have n epsilon lines. Okay. And so this means that the regime in which you will see both contributions is the critical regimes of n epsilon equal to log epsilon. And this is actually also used in the Gisburg and Dau contest. So also in the results by San Diego. By Sandies and Fatih, in which they study the regime which has infinitely many vortices, the right scaling to see this is exactly that. So it's the scaling of the energy with log epsilon squared. Okay, so this is what we do. And the result, so it's a recent result again with Conte and Mueller. So we take the number of virus energy, we scale it by lower. Bias energy, we scale it by log epsilon squared, and in the gamma limit, we first have a compactness result with the scales vary scaled variable in H1 alpha weaker to functions that belongs to B V intersection H1 alpha and in the limit you see both contributions. The one that we obtained via homogenization starting from the line tension energy, so the one we described before with the fake sigma variable. The fake sigma variable and the elastic valential interaction, both terms, which is somehow very close to what you would use in elastoplasticity, a kind of model which accounts for the elastic distortion of the plastic slip along the blade. I think I'm almost done because I don't think I will have time to tell you anything about the proof, even if I want to stress one thing. Even if I want to stress one single point. So, the idea is that the model is anisotropic and vector-valued for good reasons, because it represents a situation in which these few ingredients are essential. Let me stress that the anisotropy of the kernel over there does not depend on the fact that we choose an elastic energy which is i which is anoscropic. It it depends on the anisotropy due to the lack to the crystal structure. So, the crystal structure behind it. So, it's really essential. And for these reasons, it's not possible to use the rearrangement techniques that were used by Alberti Bouchet and Sépéchet, for instance. No rearrangement does not work. So, you cannot reduce to a straight interface configuration one-dimensional using this idea. And then the singular kernel makes very hard the work because the sharpening. Of the work because the sharp interface are not admissible because B V functions are not admissible, and we need to BH1F. And so, in general, the Navarro Pius energy does not control the line tension. So, you need to work a lot to do that. And then, another problem is that there is no intrinsic scale. So, this critical H1 alpha regime gives you a logarithmic behavior. So, there's no automatically scaling like for Giesberland Dao. Scaling like for Giesberland DAO that produces an optimal profile problem to use. And then, as I said, there are several steps of relaxation and microstructure that makes the life very difficult. So these two slides are kind of messy, so don't look at it. Just to say, there are three ingredients, one which I like to sell, but I will not have the time to convince you that this is a nice. See that this is a nice idea, but this is, I think, the most important idea of the paper. You decompose your singular kernel with the sum of dyadic kernels which are regular, so truncation of the original kernel. And then you rewrite your energy as a sum of energy with regular kernels. And once you have this, somehow you now allow at each scale, you allow for. Scale you allow for sharp interface. So, if you have a B V function, you can compute the energy of this B V function with jumps. And if you look at the function which has a jump, essentially this kernel play the role of a sort of modification here. So, you really compute the line tension. So, you using this kernel, you have to reduce with some messy projection. Messy projection averaging projection and so on procedure to BB functions. And once you have BB function, you somehow are able to compare each of these configurations with the line tension. And there you apply the microstructure. So I'm aware of the fact that this is too messy to be understood, but just to remember some pictures. And so I also have a take home message. I also have a take-home message. And the take-home message somehow is to say that this problem is pretty involved as non-locality, which is related with the fact that you are looking at the trace problem for good reasons. The criticality of the singularity makes the scale of the problem not easy. And the anisotropy is really related with the application. Is really related with the application. So, and all these ingredients make the problem non-one-dimensional, produce microstructure. And I mean, the key idea that I want to stress is this decomposition of diadic kernels. And with this, I think I stop in advance and thank you. Questions? Thanks a lot. Yeah, the next group have several questions, but I will explain. You developed this very nice new methodology for estimating the singular potential, and this was a lot of time to something that is not like about layers, but some other kind of models. Some other kind of? Well, actually, so the other dissolution models, as far as you know, don't have this restriction that all the plastic slip is on one plane, you end up with the full three-dimensional model. So you don't have the singular kernel anymore. It's a problem because, I mean, here you really have all this machinery of BV to deal with this phase transition. With this phase transition model. So it's massive, but at least you have a good variable to work with. We have done problems in 3D, but in the full 3D, the analysis is very complicated. So for instance, we don't have a complete result. So we have many restrictions in order to get the asymptotics and so on. So I don't see exit from the kingdom of a phase field model. I don't know how to use it. I was hoping more on other applications. Applications not related with dislocations. Let me introduce some problem. So, you decompose your singularity into pieces, dyadic pieces. This looks like this typical Roman truncation mode. It's like truncation. Yeah, it's a truncation. Yeah. Uh but um you mentioned something about the fact that uh you were thinking about introducing the time or like um no I was not thinking I was just suggesting problems I mean there are some problems some results so I know that Tim Prindler Thomas are working on it but with many restrictions because I mean this microstructure thing is not is really difficult. Thing is not really difficult to take into account in evolution. Okay, thank you very much. Now we have to do a little bit about genes.