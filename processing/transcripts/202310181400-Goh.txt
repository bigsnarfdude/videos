First of all, some of you might have heard pieces of this talk before, but every time I give this talk, I learn something new and then I incorporate it into the next talk. So hopefully you will learn something new from this. Let me start with the basic definitions here. We're interested in the pigeonhole principle, the finite pigeonhole principle, as a problem. Okay, so what I mean is that we will have instances which are functions from m to n. Which are functions from m to n, where m is a fixed integer greater than n, also fixed. And then the solution would just be a witness that it's not injected, right? So we need to find any pair ij distinct so that fi is equals to fj. Another problem that is of interest in this talk is quite simple. It's the identity function on a fixed domain k. So in this case, the instances are just elements of the domain, and the solution is just. Domain and the solution is just the same thing. It's identity, right? So that's a very simple problem, but you'll see that there are surprisingly complicated questions involving these problems on the screen. Okay, and then so what are we going to do with these problems? We are going to compare them up to the following notion of reducibility. So this is strong viral reducibility. Let me just remind you what it is. So if we have two problems, P and Q, If we have two problems, P and Q, right, we say that P is strongly by rock-reduce value Q if you have some forward function of P and P with the following properties. So first of all, Phi is going to take in instances of P. Be so particular about that here. So this P is going to transform, right, an instance of P into an instance of Q. Q. And then going backwards, right, this C is going to take any solution to V of P and it has to produce a solution to P itself. So the intuition here is that if P is reducible to Q, then P is at least as easy to solve as Q. No, sorry, the other way around, right? And that means that if we have some way of solving Q, then we have a computable way to transform that into a way of solving P, right? What are we doing? That into a way of solving p, right? What do we do? We're given some instance of p, we apply the forward functional to get an instance of q, and then we kind of magically get a solution to that, and then we use the backwards functional to solve the original instance. Okay, so this is the notion of strong biological reducibility. And so, technically, these functionals, right, in the definition, they have to be computable. But for the first half of the talk, it's not actually going to matter because we'll be dealing with discrete objects. We'll be dealing with discrete objects, so everything's automatically computable in that setting. But in the second half of the talk, it will become relevant. In the second half of the talk, we'll also look at what is known as viral reproducibility. So this is perhaps the more commonly studied notion, where the only difference here is that the backward functional now has a backward control can be including. Control it into the original instance T as well as this acute signature. And with those two bits of information, you can then set it all up. So, of course, we have a strong priority. And in general, the converse is not true. All right, so that's the way we're comparing these problems. And now let's talk about some basic facts. So, first of all, identity problems form a strict hierarchy. The fact that these reductions are strict, actually, that's the pigeonhole principle. Also, these pigeonhole principle problems, if you fix the codomain, so you fix the N, right, and then you vary the domain, which is the M, then these actually form a non-increasing hierarchy, a weakly decreasing hierarchy. And so I'm not claiming strictness here. So, I'm not claiming strictness here, and in fact, we will prove some partial results about the strictness, but we don't actually know that the entire thing is strict. Yeah. Okay, so why did I bring up the identity problem? Well, that's because of the following observation. So, it turns out that if you look at the pigeonhole principle, but you know, for functions from n plus one to n, that's actually equivalent to identity for n plus one choose two. And how does the proof look like? Well, And how does the proof look like? Well, I will just say it verbally here, right? So, to reduce the left problem to the right problem, what we do is, well, the solution set of the problem on the left is all of the pairs of numbers from n plus one, right? Distinct numbers. So, that's where the n plus one choose to not trust. And to reduce the right problem to the left problem, well, what matters is that for Well, what matters is that for any pair ij, right, from n plus one, you can come up with a function from n plus one to n so that the unique solution to that function is ij itself. So you can basically encode the ij into the instance, and then you can uniquely recover what ij is. Okay, so that's just a brief sketch, but you know, so this tells us that, okay, so identity seems to be somehow related to these. It raises the natural question of, you know, what other relationships are there between these? What other relationships are there between these two kinds of problems? And just a quick kind of useful combinatorial characterization. So, identity K is strongly biologically reducible to M to N, if and only if you can find K many functions from M to N such that they have no pairwise common solution. Okay, so that's how you can think of these reductions from identity. From identity, we're just trying to find these functions with no pairwise common solution. And once they have no pairwise common solution, right, then you can sort of uniquely decode, like given a solution to one of these, you can decode which function it is a solution of. So that's why the no pairwise comment comes into play. Okay, so later we will give other characterizations. So in the special case where m is n squared, and or more generally, m is a multiple of n. Is a multiple of n for you know where the multiple is still less than or equals n, we'll have further results about this. So these will relate to classical finite combinatorial objects. All right, so first thing, kind of just to limit the scope of our consideration, first of all, it's easy to see that identity two actually reduces to n squared, doesn't go to n. And the reason is, let me just show the proof here, right? Is let me just show the proof here, right? So, what we do is we just think of n squared as a grid, n by n grid, and then we can have a partition of this into like the columns. And that's actually a function, right, from n squared to n, where everything in the first column maps to one, everything in the second column maps to two, and so on. Um, and then also you can have a different partition, right, where you partition with horizontal lines. And the point is that if you have two different like uh squares in this grid, they cannot be both in the same grid. They cannot be both in the same row and in the same column at the same time. So that's the condition we need to actually get a reduction here. So the reduction is simple. Then the non-reduction, well, you actually apply pigeonhole principle twice. The idea is, okay, if you have a function from n plus one to n, right, if you chop up n plus one into n pieces, at least one of the pieces must be large. It must have at least n plus one numbers. And then you think about, okay, what about if you What about if you further chop that n plus one set, that set of n plus one into n piece first? Then at least one piece must have size at least two. And that tells you that actually any two functions from n plus one to n, sorry, from n squared plus one to n must have a common solution. And so you cannot have a reduction. So, okay, it's okay if you didn't really follow the proof, right? But the point here is that there's no point in thinking of n, which is strictly greater than n by. Of n, which is strictly greater than n plus one, strictly greater than n squared from now on, right? Because the identity two, which is the weakest possible identity, doesn't even reduce to that. So now, you know, for the rest of the talk, we'll focus on what happens at n squared as well as what happens below. We'll see that, you know, there are some interesting connections here. So n squared, let's look at m equals to n squared now. This turns out to be closely connected to Latin squares. Connected to Latin squares. So, what is a Latin square, right? On screen, I have, if you look at the first square, that's a four by four Latin square, right? Where in each column, you have one, two, three, four, but no repeats. In each row, you have one, two, three, four, but no repeats. The square in the middle, right, that's also a Latin square, okay? And what's interesting here is that these two squares are orthogonal in the following sense. So, if we sort of superimpose the two squares, which is the third square, right? Which is the third square, right? You see that if you take any two entries in the third square, they cannot be the same. And that's what it means for these two Latin squares to be orthogonal. And if you think about it closely, then this actually gives us a reduction from identity 4 to 16 doesn't go into 4. So the 2 comes from the two Latin squares, which are orthogonal. And then you sort of get 2 for 3 by taking the column. Sort of get two for free by taking the columns and the rows as I described in the previous slide. Okay, so again, I'm moving a little fast here because I want to kind of get to the recursion theory. Right now, this is all finite combinatorics, right? There's no recursion theory yet. But yeah, so what I said just now generalizes to get the following theorem. Identity k plus 2 reduces to n squared, doesn't go into n if and only if there exist k mutually orthogonal Latin squares. K mutually orthogonal Latin squares of order n. And what's interesting here is that the maximum k for which this is true, that is a long-standing open problem. So people have been studying this since the time of Euler, and this is unknown for many values of n. And here's a special case, which is also quite famous. That's why I thought I'd mention it. So if you specialize to the case where k plus 2. Where k plus 2 is n plus 1. So that's actually the highest possible k. That's an upper bound that you can easily prove. So even that special case, that is also wide open. So in finite combinatorics, you can think of these n minus 1 mutually orthogonal left-hand squares as what we call an air fine plane. So this is the projective plane, finite projective plane, but you remove the Plane, finite projective plane, but you remove the points at infinity. That's that's the so-called affine thing. And so, such an object, right? Um, we don't know for many values of n, we don't know if there exists such an object of order n. We know it exists for prime powers, and we know that you know for certain numbers it doesn't. But for example, for n equals to 12, we don't know if it exists or not. So, this was a big surprise to us, right? Because we were kind of looking at this problem. We were kind of looking at these problems and we were thinking, oh, yeah, this will just be a fun exercise, you know. And then it turned out to be equivalent to these open problems, which, yeah, that was interesting. Okay, so I'll now turn my attention to a different range of values. So just now we talked about m equals to n squared. Now let's talk about n less than or equals to 2n. I just want to mention this because this is the most tractable case. In this case, we can actually prove a bunch of We can actually prove a bunch of reductions without running into open problems in combinatorics. So, first of all, let's look at m equals to 2n itself. And that has to do with perfect matchings. So, let's think about what perfect matchings have to do here. If you have two n vertices, and you think about a perfect matching on these vertices, so that's a set of n edges, right? Which are such that no two edges are adjacent, right? It right um that gives you a function right from 2n to n. So that's why this is relevant. And so, indeed, by looking at this graph decomposition, so we take a complete graph on two n vertices, we decompose it into perfect matchings, that's a classical fact, and that gives us 2n minus 1 functions from 2n to n with no common solution, and therefore we get this reduction. Okay, so in the picture, you can see an example of a decomposition of K8 into perfect matchings given by the colors. Okay, and then so this is what m equals to 2n itself, right? But for m less than or equals to 2n, you can get further results of a similar form by looking at other decompositions. So there's these almost perfect matchings, there's Hamiltonian cycles. So you can do a bunch of things like this to get reductions. Reductions. But I won't go into details here. All right, so this slide is meant to show that, okay, there are some cases where it's tractable, right? But we saw that for m equals to n squared, it's like wide open. We don't know what's possible. Also, now on to kind of multiples of n. So this is another case where we have some equivalence with some combinator object, and that's also in general open. Uh, in general, open. So, this is what are known as resolvable, balanced, incomplete block designs. Okay, so I don't actually want to go through the definition. So, basically, the special case, if you want to think of this, decomposition into perfect matching. Okay, that's actually a special case of this. But in general, right, we don't know if such things exist, okay? And we can prove, so first of all, just a kind of observation. Just a kind of observation based on the definition. If such a thing exists, right, then you can get a certain reduction. Okay, that's kind of the easy part. But what's interesting is we can prove the converse as well. In other words, we can show that if there is such a reduction, then such a combinatorial object must exist. And I'll just say a bit about the technique here. This is done using the counting lemma that you see on the slide. Okay, so what is this counting lemma? Okay, so what is this counting lemma about? I'll just explain the idea. So consider a function from qn to n, right? This is the setting where m goes to qn. So we're interested in such functions. Such functions must have at least a certain number of solutions. Okay, and that's naively the, this is the case where, I mean, not naively, but literally, the minimum number of solutions is attained when the function is very balanced, right? It's taking Qn and just chopping it. Taking Qn and just chopping it up into n many pieces of size Q. So that balanced situation is the one where you can minimize the number of solutions. So, and you can prove that formally, right, using a complexity argument. And so, with that, then we can actually do some counting. And so, that's this lemma is the key tool that you use to prove the theorem. Basically, it says that, okay, if you have a reduction, right, then just numerically, All of these remember reduction is equivalent to the existence of certain functions with no common solution, right? So, if a bunch of functions have no common solution, just numerically, because of the numbers here, it's each of those functions is forced to have the minimum number. And once they have the minimum number, then you know exactly how they look like, right? And so you can extract this combinatorial object from the reduction. Okay, so just again, very vague, but the point here is that we have this nice equivalence, and this equivalence actually generalizes the corollary on affine planes. So if you take the extreme case q equals to n, so then the right-hand side just becomes identity n plus one reduces to n squared, doesn't go into n. So that's the, and then the left-hand side just becomes an f. And then the left-hand side just becomes an F. So, this is a generalization. And let me again point back to the case where we have perfect matchings. If you take q equals to 2, then this equivalence is just trivial in the sense that both sides are known to be true. Because we know that we can decompose in a perfect matching, so we do have the reduction. Okay, so this is the kind of the oh, right. So, sorry, it's not the end of the. Oh, right. So, sorry, it's not the end of the finite combinatorics part. So, a bit more applications of the counting lemma here. Basically, we can get separations from the counting lemma as well, just by basically by cardinality reasons. So, for example, we can use this counting lemma to prove the following separation. We have 2n plus 1 doesn't go into n is strictly below 2n doesn't go into n. So, that is an example. Remember, on the Remember on the first slide, right? I showed you that, okay, you have this decreasing hierarchy, right? And this is well, this is the second example we see where it's actually strict. The first example we saw was the division between n squared and n squared plus one. Now is the division between 2n and 2n plus 1. So these are kind of dividing lines, right, in the strength of these problems. Also, another one. We also have a dividing line at have a dividing line at between n plus one and n plus two uh but let it actually let me point out here that the uh here that's assuming n is at least three so for n equals to two this is a kind of an edge case we actually do have an equivalence between uh two of these problems so three doesn't go into two is equivalent to four doesn't go into two yeah but otherwise you know that that never never happens for all bigger n. Okay, so I think I have a bit of a summary slide here of the first. Okay, I don't. Okay, so the summary is the following, right? We have these problems involving the finite pigeonhole principle, and we have shown at least a shrinkness at some levels of the decreasing hierarchy. What I'm going to do for the rest of the talk, and I'll go a bit slower now, is to bring in the recursion theory. So, so far, everything is finite combined to show you at the end. And I'm going to show you at the end how we can use recursion theory to actually get more separation in this hierarchy. And okay, like I'm not saying that those results cannot be proved by combinatorics, but it's sort of the proof was very natural from the point of view of recursion theory. So I think that's also valuable. All right. So what is this second part about? So we're going to consider now the jump of the problem. Okay, and I'll define that. The problem, okay, and I'll define that in a minute. But first, some motivation for the actually, this motivation was our original motivation for this whole project. Okay, so in reverse math, we have this equivalence between the infinite pigeonhole principle and the statement saying that for all n, there is no sigma 0, 2 definable injection from n plus 1 to n. So this relates, right? The infinite pigeonhole principle and the finite pigeonhole principle, right? And the finite regional principle, right, is an equivalence. Furthermore, so in this work by Bellinger, Chong, Wang, Wong, and Yang, they showed that if you take, if you instead look at injections from 2n to n, instead of n plus 1 to n, then you actually get a strictly weaker statement in terms of reverse map. Okay, so, right, because like n plus 1 to n, you know, saying that there's no interjection. To n, you know, saying that there's no interaction from n plus one to n is the strongest possible thing, but if you increase the domain, right, you actually can get a weaker statement. And let me also point out that, you know, they didn't just do this for fun, right? Their motivation was actually to study a certain period of wheat Koenig's lemma. And they showed that actually this statement about to end to end that actually characterizes the first order theory of some second order state. So I think. Second-order state. So, I think this motivates the study of such kinds of statements here. So, our original motivation was that, okay, maybe we can look at this from the perspective of viral reducibility instead of reverse network. You can see what happens. So, how does that motivate now the subsequent work? Well, here we're talking about sigma 02 definable injections. So, in some sense, we don't have the injection directly, we just have some. We don't have the injection directly, we just have some sort of indirect access to it. And how does that manifest when we talk about problems? Well, that's where we're going to talk about the jump, where if you have a problem P, the jump of P is another problem where instead of being given the P instance directly, you're given a limit approximation to it. So this is like sigma zero to the final subject. And then the solutions are just the same. So the solutions are just. Are just the same. So the solutions are just the key solutions to the limit key instance in a given. Okay, so some basic facts about this jump. I mean, what we're going to do is we will lift our results from the first half of the talk to this setting, right? We don't want to redo everything again. So we're going to do some lifting. And so these are some tools that are very good for lifting. Our first example. So what is the jump of identity? So we're just given. Identity. So we're just given a sequence of numbers, right, less than k, which converges to some number less than k, right? And then so this is more well known as the limit problem for k. You are given a sequence which converges to some number less than k find the number, find the limit. Okay, so some basic facts about the jump here. The first one is that if you have a strong viral Is that if you have a strong viral reduction between problems, that will lift to a strong viral reduction between the jumps. Okay, so all of the reductions we proved in the first half of the talk, those will just lift to the jumps of the corresponding problems. And what's even better is that we have some kind of converse to this. Okay, so we don't have a literal converse, but if we're willing to talk about continuous reducibility instead of computable, Reducibility instead of computable, okay, then we do have a converse. So, what does that mean? So, first of all, continuous strong viral reducibility is defined in the same way as strong viral, but the functionals can be continuous instead of computable. So, of course, if you have a strong Virgo reduction, then you also have a continuous strong Virgo reduction, but not the other way around in general. But here, what we have is if P is not continuous. If P is not continuously strong by rock reducible to Q, then P jump is also not continuously strong by ordinary Q jump. And so this will be useful when we are trying to lift the non-reductions that we've given. So the first proposition helps us lift our reductions. The second theorem will help us lift the non-reductions to this jump setting. Jump setting. Okay, so this is the lifting. And I chose to trace it as this theorem here, where we have a bunch of things being equivalent. The first point is saying that the limit problem, right, remember that's the jump of identity, right? Is viral reducible to the jump of the pigeonhole principle. So remember, viral production. Okay, I'll talk about it more in the next slide. Okay, I'll talk about it more in the next slide. So maybe ignore point number one for now. Point number two is saying that the limit problem is strong, firework, reducible. Number three is about continuous, strong firearm reducible. And four and five are the results on the sort of the bottom level, right? The one without the jumps, where we have a continuous strong bio reduction and a strong firearm reduction, respectively. So why are these equivalent? Let's talk through some of them. So one implies two, we'll discuss on the next slide. So, one implies two, we'll discuss on the next slide. Three implies four, so that is the theorem on the previous slide. Four implies five, so that is saying that, well, right, if you have a continuous strong biological reduction from identity to pigeonhole, then you automatically have a strong biological reduction. Well, I mean, in this discrete setting, right, anything that's continuous is just computer work, right? So, so you Computer work, right? So you get that for free. And then five implies two. Well, that's the fact that the strong bioc reductions lift through the gels. So that's the proposition on the previous slide. Okay, so in this equivalence, right, the only thing, like two implies one is trivially true, right, by definition. So the only thing left to explain is one implies two. And that I will do on the next slide. Do on the next slide. Okay, so how can we, right? You know, how can we upgrade? Right, if you have a virux reduction, how can we upgrade it to a strong viral reduction? This is using tools from previous work with Damir as well as other people. So, first, a quick definition. So, maybe I don't want to talk through all of this, but basically, we have this property of problems that Problems that essentially says that you can fudge with the instance in a finite way, and that doesn't really change much. So we're saying that, okay, if you fudge with the instance in a finite way, and you know you have a bound, right, for which, after which there's no change, okay, given that you can uniformly compute, given the solution for the original instance, you can uniformly compute the solution for the Can uniformly compute the solution for the fudged instance. Okay, so some examples for this kind of phenomenon. Ramsey's theorem is something like that. So if I give you a homogeneous set, if I give you a coloring, and if I give you a homogeneous set for the coloring, and then I say, well, I'm going to just change finitely many places in the coloring, and I'm going to tell you where I made the changes. Like, you know, I give you a bound, right, for where I made the changes. Then, well, you can just say, okay, I take the homogeneous set, just chop. Say, okay, I take the homogeneous set, just chop it off, like remove everything below the bound, right? And then you have a homogeneous set for the new coloring. So, Randy's theorem is like that, cohesive principle is like that. If you know about this, you know. But for us, what's relevant is that the limit problem is like that, right? If you have a sequence which converges to a limit, right, and you change finally many things, well, actually, the limit doesn't even change. So, the limit problems are finitely tolerant in a trivial sense. Sets okay, so that's uh that's a nice property, and this nice property enables the following uh result. So, this lemma here is saying that you can upgrade a BIROC reduction to a strong VIROC reduction, provided you have the following assumptions. So, these problems P and Q, their solutions are all in a fixed finite set. And if you modify a P instance, you still get a P instance always, and furthermore, P is finitely possible. And furthermore, P is finally tolerant. So these are all true, right? For P being the limit problem, and Q is the jump of the pigeonhole. So, and the proof of dilemma is not very hard. It's like the kind of a cohen forcing argument. Like you say, okay, we're going to, if we can force that you do something wrong, then we'll do it. And if we cannot, that means that we actually have what we want. So, yeah, this is the technical tool, right, which lets us upgrade a viral production to a strong viral reduction. And so, this completes the proof of the equivalence on the previous slide. Okay, so now we're going to start looking at the sorry, so just coming back to this theorem, right? So, what does this say, right? So, this tells us that all of the reductions and non-reductions we proved in the first half of the talk did as lift. The talk later spent, yeah. But you know, what else can we say? Right? We're not done yet, and the reason is because we can actually say more, okay, in this junk setting. The kind of slogan here is that, and this was the slogan in the original paper, which defined a jump. If you have two problems, right, and which are different, you know, not equivalent, and you study their jumps, okay, intuitively the jump sort of amplifies the difference between the two. Amplifies the difference between the two original problems. And so, if you have two problems which are maybe not so easy to separate, well, maybe their jumps will be easier to separate. Okay, and we will see an example of that. But first, an example of some improvement of a result we already have. So, identity two, right? Remember, I said that identity two doesn't reduce to n squared plus one to n. So, so taking the jump of both sides, right, we get this lin two doesn't reduce to n squared. Lin2 doesn't reduce to n squared plus 1 to n, jump. But we can actually improve that. Okay, so I won't define this problem here. So this is a restriction of the choice problem. But the point is that this is a problem which is strictly weaker than LIN2. And it's significantly weaker, like you know, not even close. And then in this setting, we can show that actually this weaker problem doesn't reduce to this n squared plus one. To this n squared plus one, then we're going to jump. Okay, so this proposition here is a strengthening of the result on the first line. So it's a shrengening of something we did in the first half of the talk. And I'll skip the crook here because I didn't define what all our unique choice is. So the proof is not going to make sense. But my point is that, yeah, so we can actually strengthen some results that we have that will. That were obtained by lifting the jump, lifting to the jump. Another situation where we can get a nicer result is the following. So again, we have some problem here, which is all our co-unique choice. Again, it's some restriction of choice, but in a different way. So this we can prove the following proposition. Okay, so this problem, ACC, whatever it is, it reduces to n. It reduces to n to the k plus 1, doesn't go into n, jump, but it doesn't reduce to the problem below, right below it. And the point here is that now we have a separation between n to the k plus 1 and n to the k plus 1 plus 1. These two, we know that they are separate now, up to viral reducibility. Okay, and that actually gives us. And that actually gives us, right, we can now push that result back to the bottom level. Just now we were taking results at the bottom level and lifting it up, right? But now, by the same machinery, because we have a separation between n to the l plus one and n to the l, right, so this is a Virac separation between their jumps, right? But by the machinery we set up, we can push that down to the bottom level to get a strong Virac separation between the original. Between the original properties. And this separation at the bottom, well, we didn't prove in the first half of the talk. And if you ask me to prove it directly, I don't see a nice way to do it. So this is one situation where by actually working with the jumps and working with recursion theory, we can actually prove this final result at the bottom, which is basically finite combinatorics. Basically, finite component products. Okay, let's see. How much time do I have left? Okay, quite maybe quite a lot of time. But yeah, I also don't mind to end a bit early. But okay, so now at the end of this talk, I want to talk about some other kind of reduction that we have, which is technically the most complicated. It and it's kind of a yeah, well, we don't know how to generalize it, but at least we have this uh special case. So let's see. Okay, the slide isn't moving. Not moving. Okay, yeah, we can move it completely. Thank you. Okay, all right, so. Okay, all right. So, yeah, I actually had a comment here. So, these two non-reductions, right, that were on the previous two slides, one might wonder: okay, I mean, sure, like you proved this result, but maybe actually you could have proved it at the bottom level and then lifted it up, right? But actually, you can't, all right? So, so it's not possible to prove something of the bottom statement and lift it up. The reason is because Is because if you look at any problem of the form p jump, okay, that is below these two problems, they're all or unique choice or all or co-unique choice. Actually, they must be computable. Okay, so there's no non-trivial jump that is below these guys. And therefore, we couldn't actually have found some key, proved the result, and then lifted it. So that's not possible. Not possible. And in fact, so if you know what LPO is, right? So actually, LPO itself doesn't bound any non-computable junk either. I don't know if this is a well-known observation, but either way, the proof is not very, very long. So yeah, this is again some kind of justification for doing the stuff that we just did, right? It's like we couldn't actually have done it if we stayed in a bottom level, right? But by moving up, we managed to get these guys. Okay, so the final. Okay, so the final thing: this is an ad hoc reduction. So now I actually have to tell you what choice is in order to make sense of this. Basically, what we showed before, it shows that choice for two elements reduces to this eight doesn't go into two. And now in this theorem, we improve the choice on two elements to choice on three elements. And okay, like this, I don't expect this result to mean anything to you. But the proof is actually, you know, it's quite technical. Technical and it's very combinatorial as well. So, I think from my point of view, this is one situation where we have some demand for some combinatorics thing to exist. And I would hope that maybe combinatorics people have a device for showing such things exist, but I don't know. Okay, let's see. So, first of all, what is choice on three elements or in general? Okay, the point is. Elements or in general. The point is, the instance is a subset of three, like a proper subset of three. Sorry, not a proper subset of three. It's a non-empty subset of three. And the way the instance is given to you is by an enumeration of the complement of the subset. And then your job is to produce an element of the non-empty subset. Anyway, so how can we sort of represent this? Anyway, so how can we sort of represent this? Well, like at each point, right, we have some enumeration of the complement of the set. And so at each point, we have the following information. Maybe the enumeration has not given us anything. So that would be the empty set here. Or maybe one number has entered the complement. So that's the A, right? So A could be 0, 1, or 2. Or maybe two elements have entered the complement. So A entered first, and then followed by B. First, and then followed by B. Okay, and let me point out that we are keeping track of the order here. This is going to be important. And these are the only possibilities, right? Because we cannot enumerate all three numbers, otherwise it wouldn't be a choice any longer. Okay, so this is the kind of schematic of the proof. I'll try to explain what's going on. So the tree on the left is kind of a flow chart description. A flowchart describing what could happen with the enumeration. At the beginning of time, the enumeration hasn't given us anything. So we are starting at the top of the tree. And then maybe the enumeration is going to give us some number, either one, two, or three. Okay, so sorry, I'm counting from one here, not from zero. And then finally, after that, right, maybe the enumeration might give us an additional number. Okay, so for example, if it's given us one, then maybe after that it will give us two, then you'll get one, two. One, two. Okay, so the thing on the left is like a, yeah, it's just how the enumeration works. The thing on the top right, that is the forward functional that witnesses this reduction. Okay, and basically corresponding to each possible state of the enumeration, we will produce some function from eight to two. Okay, so those things in brackets, right, those are meant to signify a function from eight to two. 8 to 2. And basically, because at each stage of the enumeration, we have to output like a guess, right, for what we think the final instance should be. And then as the enumeration stabilizes, our output will also stabilize to give us a function from 8 to 2. Remember, we're looking at jumps, right? So these are all like limit approximations. Okay, so what is the tension here, right? What are the combinatorial properties needed? Combinatorial properties needed. Basically, we need to design these functions from a to two in a way so that we can actually figure out a valid solution for the original instance. So, okay, I'll just run you through an example of what the backward functional should do. So, top right is the forward functional, and the bottom is an example of the backwards. So, let's say we have this backwards functional, which is given one, seven. One comma seven. Okay, in other words, we know that one comma seven is a solution to whatever limit, you know, whatever the choice problem. No, sorry, whatever the F is. So suppose we're given that. Well, we cannot, from this, we cannot uniquely recover the F, okay, because there are multiple F so that one, seven is the solution of A. The solution of it. In particular, there are five, right? At least on the slide. Okay, well, but you know, that's okay because we still have access to the original instance P, right? We have this enumeration, which we will now use to figure out actually a valid solution. So what can we do? Let's see what are the possibilities here. So we have F12, F21, F2, F32, F31. All of those things. All of those things, what they have in common, is that at least one thing is enumerated, right? Because F and T is not among those things, right? So we know that at least one number is enumerated, which is great because that means we can wait for the first number to be enumerated. And this is guaranteed to terminate. So let's wait for the first number to appear. Okay, well, a few cases, right? So maybe it's one or maybe it's two. That's an easy case because if the first number is one, Because, right, if the first number is one or two, that means that the reality is that we're either working with F12, F21, or F2. It cannot be F32 or F31, because if it's F32 or F31, then 3 must appear first. So we know either it's 1, 2, 2, 1, or 2. Well, regardless of which one it is, 3 is going to be a valid solution because 3 is not enumerated in those situations. On the other hand, well, if the first number is three, right, if the first number that's enumerated is three, well, then, okay, we're not done yet because it could be F32 or F31. And so we can't just answer one or two, right? Because we might, if we make an answer, maybe the enumeration will prove us wrong. But that's okay, because again, we know that a second number is going to appear now, right? And so we just wait for that number to appear, and then we can give the correct answer. So this is kind of. So, this is kind of, you know, this is how the backward functional works. And I just did this for one possible pair, right? You have to, the whole proof will have, you have to do it for, you know, eight choose two, many pairs, like 28 pairs. So for all the 28 pairs, you have to do something like this. But it's possible by the way we set things down. So, yeah, this reduction, well, I mean, just to come up with this forward functional, right, was not so easy. Not so easy. And we would like to know a way of doing this in general. You can sort of abstract this into some combinatorial problem with certain restrictions. And yeah. Okay, that's all I have. Thank you for your attention.