Okay. So it's very sad not to have Akima with us in Oaxaca, but it's very nice to have her online for this talk. So I'm happy to introduce Akima Besai from Florida International University, and she will discuss synchronization of stochastic models. Thank you very much. And I am also very sorry that I Also, very sorry that I was not able to join you, and you're having fun and eating a lot of very nice food, right? Okay, so thank you very much for this kind invitation. I have enjoyed all the talks so far in the morning. This is a little bit new topic for me, for my research, which is not really related to. Which is not really related to fluid, fluid, fluid dynamics in general. So, this is a joint work with Maria Garrido that passed away two years ago, Verena Kopp, and Bjorn Schmalfus. And there are some also results with Verena Verena Kopp, who is finishing her PhD in Vienna. No, no, positive binary. No, no, it positively. Okay, so let me okay, maybe it's better to use this. So, synchronization. Let me start with synchronization. Just to give you an idea what synchronization is, it was first like observed by Christian Huggins. That was, you know, in that. That was, you know, that slow-moving pendulums then synchronized together. Okay, so let me give you a simple case of an ODE, deterministic ODE in R. If you take two ODEs, the first one where U is the solution, V is the solution for the second one, kappa is just a positive coefficient. Coefficient and f is a function that has nice properties. Initial condition u0 v0 in r and f is global ellipses. This means that you have global solutions. Then, if you take the difference between the two, then you get the following difference. And if you use the fact that F is Lipschitz, the Lipschitz condition of the F. Condition of the F, then you get an inequality of the following type. And using Brombalemma, you end up with a difference. The difference between Ut minus Vt will converge to zero and T goes to infinity exponentially if you assume that this kappa is bigger than this L, the constant of the Lipschitz constant. Now, if Now, if you take particular examples, f, for example, sine 2x minus 0.4x plus 1, this, and you start, you know, this is, you start looking at the solution of this ODE, simple ODE, this is what you see. But then if you simulate the solution, you know, for the for kappa equal to zero, this is what you see. Equal to zero, this is what you see for the first one and the second one, the system. If you take kappa bigger and bigger, you see that they synchronize earlier. Okay, and you see you take 0.5, you take five, they synchronize right away, actually. Okay, okay, so the so what we can see is that. What we can see is that when we know that the limit of ut minus Vt when t goes to infinity for kappa large enough, this is zero. Now, how do we describe the coupling, the long-time behavior of the couple UT VT? So, one guess, in fact, a reasonable guess is that if you take the system and you take the difference. And you take the difference being this zero, the equation that is of interest, the limiting equation, would be the following equation, d over dtwt equal to f of w t. And the long time behavior of the coupled uv will be the long time behavior of ww, you know, the coupled ww. Okay, of course, here we are. Okay, of course, here we are. I am interested in stochastic SDEs and stochastic SPDEs. So this means that I would like to add a random influence to the system. So here I have to introduce you to random dynamical systems in general. And what is a random dynamical system? I will go and define it for you. So first we define a metric dynamical system, which is a quadruple omega f p t. quadruple omega fp theta where omega fp is a probability space theta is a map that satisfies the flow property theta zero is recalled the the identity and theta of t plus tau is equal to theta t composition with theta tau and it is this theta is measurable with respect to this the product of this sigma algebras and it preserves the measure p so p is The measure p. So p is invariant for theta t now really the example that we use is the winner. So omega is the winner space, T0R with values in a Banach space X. P is the winner measure, and theta is the winnership. So theta t of omega s is omega t plus. Of omega s is omega t plus s minus omega t. Okay, and this way we use all the nice properties of the winner space. So this we call this omega f p theta t a metric dynamical system on a banach on a separable banach space x. And then we define a random dynamical system. Sorry, yes, the dynamical system phi. Dynamic system phi as being on this metric dynamic system X as the following map phi such that it has these two properties. In zero, it's just the identity and it has this cosycle property in general. So now just to give you an idea, because they go hand in hand. They go hand in hand, you know, the teta ti, the shift, and the flow, the random dynamical system, they have these very nice properties that you see in this cosycle property. Okay, so this is just a picture of that. Now, this is also another picture of that. So, now what are the objects of interest in random dynamical six in the random dynamic? Random dynamical systems in the random dynamical systems, these are random attractors. So, what is a random attractor in general? Random attractor, in order for us to define it, we have to define random sets. First, we define tempered random variables that are random variables that have sub-exponential growth, and then the tempered random. Then the tempered random set is defined as just in the following sense, x of omega. So it's a set, it's a set of points such that they have, you know, they are all temporary. Okay. And then the random attractor, which is a random set, is a random pullback attractor. It is always pullback, but forward invariant. The definition is that it is a random attack. The definition is that it is a random set which is not empty, compact, it is forward with phi, and it is pullback attracting the second property. These are the three properties that gives you a random attractor in general. So the forward invariance can be seen as follows. If you take a point in the random set A of omega, Set A of omega, if you go forward with T1, then phi T1 of omega of A of omega is equal to A of theta T1 of omega. Okay? And the pullback attracting is that if you take T is, you know, T1 or T2 bigger than T1, meaning that minus T2 is smaller than minus T1. So if you somehow you zoom in. You somehow you zoom in and you get into, you know, you go backward, and when you take t, this t to be to go to plus infinity, you will end up in this random set, this attractor. Okay? So how do we prove there are there is a long huge theory about this. How do we find a pullback attract? Pullback attractors, usually it is enough to find an absorbing, a pullback absorbing set, and then which is attracted, which is compact. Then you have the theory, and it is proven that then the omega limit of this absorbing set is going to be your attractor. Okay, this is the main theory. And this is just another picture that. Is just another picture that shows you that it is pullback, absorbing, but forward in that. Okay, this absorbing ball. And then we take the omega limit of this absorbing pole to be our attractor. Okay, let me get to the our model. We have, I'm going to work on two models today, but the first one is a lattice model, stochastic lattice. Stochastic lattice system of equations. I'm going to take this system to be in L2 cross L2. And of the following system, you know, two equations. A is a bounded operator. Kappa is just a constant that is positive. The coupling is between, this is the coupling, kappa uk minus vk, kappa vk minus uk. F and g are two functions that G are two functions that are globally lickshate with a linear growth. W1 and W2 are two-sided linear process with chase-class covariance operating. I take it really to be very general, but really an example, and we worked with this example actually even with fractional Brownian motion in the past, is the discrete Laplace operator. But we are able even to use more More general operators here. Okay, so this is our equation. And this equation we would like now to describe the behavior of this system of two equations when kappa goes to infinity, when the coupling is large. Of course, it would have been better to do it when T goes to infinity and kappa fixed, but we were not able. Fix, but we were not able to do it in the case of an additive knowledge. And I will show you the results here. So, how do we describe the behavior of the limit when kappa goes to infinity? In fact, when kappa goes to infinity, we are going to describe a synchronization behavior. Okay, so the idea is that when kappa goes to infinity, I call the solution as a u infinity v infinity and. And we will define the following new equation, which is the average between the two. So this equation uk duk u kappa plus v kappa over 2 plus a plus lambda, the sum. And now I have the average one half of f of u k u kappa plus g of v kappa plus the average of w1 and w2, numerical average. Okay, so then the equation that we are interested in is this equation, sorry, this equation here, W, which is solution of the average equation, and we call it W. And the result that we prove, in fact, in 2022, it was Was published. So for every kappa positive or equal to zero, the equation one or the system of two equations has a unique global pathwise solution and it generates a random dynamical system. The random dynamical system has a pullback attractor, A kappa, and we have two results. We have trajectory, we have synchronization. We have synchronizations in terms of trajectories. This means that the U and the V have the same behavior. So if you take the difference, U kappa T minus V kappa T, the norm, converges to zero when kappa converges to infinite for every t fix. This is a behavior asymptotic in kappa, the coupling. The second behavior The second behavior that we have is that we have it in terms of attractors. This is synchronization of trajectories and it's almost sure convergence pathwise. The second result is the we describe it in terms of attractors. So the family A kappa, which is the attractor of the system for the solution U kappa B kappa. The solution u kappa u kappa b kappa. So this family is upper semi-continuous when kappa goes to infinity, meaning that the distance between A kappa omega and A omega, this converges to zero when kappa goes to infinity. And the A omega is a diagonal. This is the diagonal. The A of omega is the step ZZ in L2 cross L2, where each Z is in A infinity. Each z is in A infinity and A infinity is the random pullback attractor of the averaged equation. Okay, so this is synchronization in terms of attractor and it's pathwise. In particular, what we have is that this, as we defined it, is when kappa is larger and larger, we have the convergence. We have the convergence to this diagonal A. Okay? Now, special case, as I said before, it is more interesting to do things for not an infinite coupling, but the finite coupling. And when t goes to infinity, this can hold if we take omega 1 and omega 2. So the noise in the first equation. So, the noise in the first equation and the noise in the second equation to be the same. Then we prove that the trajectory synchronizes when t goes to infinity and when kappa is fixed. So, in particular, the difference u kappa t minus v kappa t converges to zero for t goes to infinity almost surely, but for kappa fix. This is like a byproduct of our hour okay uh i would like to uh i would like to maybe to show you just an idea about the proof the proof is uh pretty straightforward a little bit technical but the idea is that we use transformation the idea is that we would like to go to the difference between the two and the sum between the two and uh you you you use a transformation to transform the system To transform the system, you end up with a system in X and Y, X kappa and Y kappa. And then this is still, these are two stochastic equations with an additive noise. And then we use the usual, the transformation into a random equation using the DOS-Tussman transformation using Ornstan-Unenbeck processes. And in all of this, the technicality is to use the ergodic properties or the stationary. Properties or the stationarity of this Orl-Starunbeck processes. And this is how we prove things. Quickly now, I would like to jump into this was the lattice equation, additive noise. So the synchronization tells you that it synchronizes to an average random equation in the limit. In the limit. Okay. Now, what happens when we have a multiplicative noise, which is interesting? So, progress, project in progress. And this is with the Verena COP. And actually, it's almost done. We just have to write down the introduction. So, in this particular case, we started actually with a graph. This is like equations on graphs, a finite graph. Finite graph. But so let me do it for two. The simple thesis to show it for two. You have U1 and U2 are solutions of some PDEs. These are really S PDEs. You have here kappa U1 minus U2. This is our coupling between the two. A is really like the Laplace operator. And sigma, here you see that it is a multiplicative. Here you see that it is a multiplicative noise, and they are coupled through the equations through a drift and they are also through the diffusion. They are coupled in both cases. F is really, we are going to take it to be in particular, we are going to take it to be like the really reaction diffusion, so polynomial, the polynomial growth. I'm not going to write down all the details, but it's really reaction diffusion equation. So more generally, we did it. More generally, we did it for two, but in general, you can take n equations, n reaction diffusion equation on this graph of n vertices. On each vertex, you have an SPDE, our reaction diffusion equation. And here we define the matrix L D and the matrix L S. This matrix N by N matrix L S L D, this is what contains the couple. This is what contains the coupling. Sigma here is just a constant which is positive. W omega omega j here is a Brownian motion with a trace class that will give you all the existence of solution. Okay, so here I will just show you the results at least. This is an SPDE, you know, it's an SPDE on graphs, and our results show a synchronization for. Show a synchronization for fixed kappa when t goes to infinity to some deterministic behavior. And the deterministic behavior in the limit, the synchronization, is that it goes to this deterministic equation, which is a reaction diffusion equation, but deterministic. Okay? And more in particular, so let me just show you maybe the assumptions that we have. I didn't want to write everything, this lambda. Everything, this lambda one is the eigenvalue, the first eigenvalue of the Laplace operator. The sigma square is the sigma square that you have in front of the noise. N is the n, the number of the rank of the matrix. Trace of Q is related to the Brownian motion, the covariance. Ls is the matrix L S, so this is a norm, and L D is the L D is a coefficient which is related to the matrix L D. It's just to give you an idea that there is a balance between all these coefficients. So I don't have time to go into all these details, but this is under these conditions. We can prove three results. First, we have synchronization in mean square. So the difference between, so each equation, they have the same behavior. UJT minus UKT, the expected value. The expected value of the L2 norm square converges to zero when t goes to infinity exponentially. So, synchronization in mean square. The second, we have synchronization again in mean squared, but this W is the solution of the deterministic equation. So, you have UK, so it synchronizes through W is the weak solution of the deterministic equation. Of the deterministic equation. So again, synchronization in its square. Lastly, we have the following synchronization, which is synchronization in terms of attractors, but in probability. So the distance between the solution of the STDE, the H1, UJT, and the attractor of the deterministic equation that it has one segment. That it has once a dissipative system. So the distance of this, the distance between the two converges to zero when t goes to infinity, but in probability. And A, as I said, is the attractor for the deterministic equation. So this is a nice result that shows you that there is a behavior from a stochastic system to a deterministic system. I will finish here with all this result. Finish here with all these results are these results are actually two results in the third and the fourth. This is what we about the first paper. For the last one, it's in progress. And I wanted just to mention that a lot of results have been done for master slave sanctuarization by Igor Schwieshov and Bjorn Schmanfus for SPDEs. For SPDEs, but all everything is in for additive noise and for actually SPDEs. Lastly, I would like to mention the paper of Landoly, Guess and Schuzzo, where they have also synchronization by noise, but it's more about stabilization by noise. It's another concept, but it's kind of similar. Of similar. And I think I will stop here because I am out of time. Thank you, Achima. Are there questions? Questions? Yes, so here again, you're looking at the and well, infinite-dimensional. Well, infinite dimensional system, right? And so I was wondering if the this operator A it induces a little bit of yeah, so it induces a little bit of damping. Is it helping you to get synchronization? Yeah, I mean, keep in mind that here, of course, A, this is a dissipative system. This is a dissipative system, but what makes it what the central makes it what the the synchronization is that you have this kappa the coupling and also this sigma you know they are coupled on both sides but keep keep in mind that you have also the non-linearity f that is non-linear non-linear here okay but but i mean you you could get this with the same kind of um method could you get something uh with no a Probably, but then you don't have, but then you have to have, you know, the coefficient have to be really, you have to take other assumptions. Yes, because there is, in order for you to have like a synchronization, keep in mind that actually, no, it's not true because the synchronization tells you that the cup, the the in the long term, The in the long term, the equations don't become coupled anymore. So the coupling will forget each other. So if you don't have the A, what happens? I don't know. I don't know, actually. I don't know. Okay. All right. Are there more questions? I was just wondering if you could return to the earlier slide and elaborate on the original equation. I think it's like in one dimension or something like that. You mean this model? Yes, yeah, this is the one. Yeah, maybe you could just explain what, or I guess I could just read it. So here, here, actually, I mean, Actually, I mean, we like to write it in a very general setting, but this is really like a lattice. So the first, I mean, the result, you can think about this equation as a system of equations, you know, ui here. You can take ui, because here u is just, how do you say? It's a sequence. These are ODEs. These are ODEs. It's a system of ODEs. And this A is nothing else than, you can take it as being a discrete Laplace operator, but you can take more general than that. We have even more general than this. And so it is really a bounded operator. And in order for you to do calculations, you need to add this lambda. In order for you to. This lambda, in order for you to find attractors, etc. It's not in when you have bounded operators, it's good, but it's not good for other things. Is this your question? Yes, yes, that's perfect. Thank you. Thank you for explaining that to me. Yeah. And F and G, by the way, F and G are just, you know, they are very You know, they are very general functions. The only assumptions that we have is that they are global ellipses. We were not able to do anything with non-global ellipsis functions. Impossible. All right. More questions? Well, if not, thanks, Sakima again. I think Parisha had a question, but it's okay. And Paul, I was wondering if you could do Nevi's talks on it, like because it's kind of similar to fluid equations. Do you see that as a possibility? No, so let me just answer about, you know, like the reason for which I wanted to do something for like Navier Stokes or the reason for which we didn't do is that in applications, In applications, what does it mean, Navis talks for synchronization? So while, you know, while diffusion equation, lattice, like particles, it's... Yeah, it might not make sense physically. Yeah, in applications, I don't see what it means. So this is the only reason. Thanks. All right. Okay. Thank you. Okay, thank you, Akima Girin. We'll try to move to the last talk.