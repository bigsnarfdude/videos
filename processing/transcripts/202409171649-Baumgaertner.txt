Myself, a computational philosopher. By that I mean I tend to use computer models, especially agent-based models, to try to amplify or better understand sort of philosophical questions, particularly those about rationality and bounded rationality. And the best part of my job is that I get to hang out with people who are way smarter than me in all sorts of ways. So I get to hang out with a psychologist when I have questions about empirical questions that, like, there's no studies out there. Let's do one. And so then he helps me figure out that. And I get to hang out with. Figure out that. Then I get to hang out with math modelers to be like, what would the population level dynamics look like if we had these ideas in terms of like aggregating maps to the population level? So, a lot of what I was hoping to say to convince you of has actually already been said. I'm just going to carve this out in a slightly different way to see if this distinction helps with thinking about some of the topics that we've talked about. So, there's a model, a sort of oversimplified model that works perfectly fine depending on the kinds of things that you. Perfectly fine depending on the kinds of things that you're interested in doing, but we should be aware of what those trade-offs are when we use this kind of oversimplified model. That one is something like this: when you have two people, someone has like the orange belief and someone has something like the purple and magenta belief, you might think, oh, the disagreement in those beliefs somehow is a difference in the data that these patients are looking at. And so, what we need to do to get some kind of agreement, whether it's to convince someone about the effects of vaccination or whatever it might be, you need to give them the information, right? There's a deficit information. Give them the information, right? There's a deficit in information, or there's a deficit in knowledge, or there's a deficit in the scientific comprehension of that. I'm going to push back against that simplified model. We should at least know what those trade-offs are. The first thing I'm going to try to push back is to think about evidentiary standards and realize that those are actually much more heterogeneous than I think we sometimes give credit to. They can depend on context, domain, social conventions. So we've already talked a little bit about risk perceptions being different in different kinds of groups. Different in different kinds of groups, right? So I won't spend that much time talking about the first one. The second one, deference to experts, I'm going to say, also is actually subject to different kinds of standards of evidence, and that's maybe a little bit more surprising. So to make that case, there's going to be two concepts that I want to introduce you to, and Megan actually mentioned this in her talk as well. She called it a second-order evidence. I'm going to call it higher order. It's just like taxidami in the third, fourth, and fifth order I want to throw at it. But it's this distinction that I want to talk about today. To talk about today. So, here's an example of first-order evidence. You get a two-by-two table where you have, say, a control group and you have some kind of intervention. You're looking at some kind of outcome. Someone has a rash, right? You do not give them a new skin cream. You see how many people had the rash get better, or how many had the rash get worse. And in this kind of two by two table, you might look at this, and if you're somewhat naive, you might look at all the people. Look at all the people who had their rash get better and used the new skin cream. I should use the new skin cream. Another way you might, of course, when they expect us, like, oh, okay, let's look at the people whose rash got better. More of the people who use the new skin cream had their rash got better compared to those who did not use their new skin cream. Use the new skin cream. But here's one more. Who used the new skin cream? Compare those whose rash got better and whose got rash got worse. Use the new skin cream. Or else use a new skin curve. But if you've done any kind of very basic reasoning about this, what matters is compare this ratio to that ratio. This is 3 to 1, this is 5 to 1. If you're making a bet, don't use a stink cream. Probably runs in the center. And sure enough, we know that people's ability to reason about those kinds of questions correlates with what's called numeracy. So numeracy is actually not necessarily a huge amount of Numeracy is actually not necessarily a huge amount of education in any kind of like statistics. It's the basic capacity to just suppress your instinct answer and be like, you know what, I'm going to slow this down and just think about through this problem a little bit more carefully. And if those of you who know about the sort of motivated reasoning literature, right, you've got system one, system two background here that sort of helps explain this. And this is done from Emil Graham. Okay, here's a little harder overcase. Motivated by a real example of someone who motivated by a real example of someone who was homebrewing, who had three thermometers, that gave three different readings. 62, 65, and 72. What would you infer is the temperature of the water? And no, you don't have time to get another thermometer. You're already brewing. It's taking hours. You just, you've got to figure out: do I keep heating the water or do I stop? Well, if you're in this range, you're using information. You're using information about the distribution to tell you something about the reliability of that thing out there. This is a piece of first-order evidence, but you're kind of discounting the reliability of it. It's an outlier. More likely to be an outlier compared to these two because they're closer together. You're using distribution information to make assessments about the reliability of the data points. So we're using this higher order reasoning. Whereas if you're in this range, if you're like, no, the information. Range, if you're like, no, the inference that I'm going to make is that the water temperature is above 65, what you're doing is saying, okay, that 72 still matters. Maybe not as much as the others, right, but you're not discounting as much as if you're in this ring factor. The point I want you to recognize that even in this really simple example with thermometers, there's not a single correct inference to make when sources differ in their reports. In their reports. All the other cases I think that we can think about are going to be significantly more complicated than this kind of case. Why does that matter? Well, there's this kind of interface between first-order evidence and higher-order evidence. So I'm going to do a little activity for us. Touch a piece of metal. And for those of you in the room, I check to make this work. Honestly, touch the piece of metal on the bottom of your chair. The legs of your chair. There should be some metal. Just touch it. Metal, touch it. And now touch a piece of wood or plastic. Just fine. Do they feel the same or different? They look different. If you're anything like me, they feel different. Are they the same temperature? But you're saying yes? But she's saying yes. Like if you say yes, you must somehow be either suppressing or recontextualizing or discounting the first order evidence you're getting from your senses with some kind of theoretical considerations. Now that might come from reasoning about thermal equilibrium. It's going to be like, look, the ambient air has been the same. I know that hot things tend to cool down. I know cool things tend to heat up. When they're in the same room, they have to meet at some kind of point. The chairs and all these materials seem like The chairs and all these materials seem like they've been around here long enough. They should be in some kind of thermal equilibrium. They've got to be the same temperature. Too much like so bad senses. I've got to discount you. Right? Or you might just like trust. Be like, well, I've done this exercise before. I had someone take a thermometer and show me that their effects on temperature. But be careful. If you use an infrared thermometer and your metal is really shiny, it has an emissivity rate and your infrared thermometer thermometer might actually agree in line with what your senses are. So it matters a little bit what the Bit about the rubber. Okay, this interface between first order and higher order evidence, I think, gives us a much, much more nuanced picture. Will you let me know when I have three minutes left? Okay. Why? So in a lot of studies that get done in terms of misinformation or trying to correct information, what you do is you take the control or sort of intervention sort of information, change it to something else that could politically motivate. Politically motivated or religiously motivated. So, cities that did ban carrying concealed handguns versus cities that did not ban carrying handguns. And then you can take these data points, increase in crime versus decrease in crime. You leave the numbers exactly the same. Nothing but the numbers change. And there are a lot of findings like Serge Robert. This is a stylized version of Kahan, where if the heuristic answer is incorrect. Incorrect. The answer is kind of convenient for what your worldview is. You just kind of keep going with the heuristics. The question we ask is, is ideology really the cause of that? Or is it somehow just a reflection of something else that's going on? Might be some kind of background knowledge, the priors, and people have thought about these sorts of things that's correlated with the ideology. Is it potentially some higher-order evidence about the information sources? Do they even believe what we're saying? Do we even believe what we're saying, knowing that we're academics? And in particular, the one I'm going to say a little bit about today is on evidence-gathering behaviors. So, this is some ongoing work that I've been doing with Florian Justwan, where what we do is we present individuals not with pieces of information, but with opportunities to get information. So they have to click to figure out what information they could get. And we do this in the case of like asking certain Case of asking certain questions about like, is this efficacious, whether it's a vaccine or whether it's some other policy or whatever. And so in this case, we were doing this for cash bail reform. And the first four pieces of information we give them, number of cities that have implemented the reform, saw increases in crime, they're just the four points in the 2x2 table. But they don't see that. They have to click on that. We just say, would you like to see the number of To say, would you like to see the number of cities in so-and-so? We don't tell them the number until they click on that. And then we also give them four other options. We varied this now in some ongoing studies where we have things like Democrats, what they say, Republicans, what they say, Center for American Progress, what they say, or whether the NRA says that. So that's how we're trying to think about this. Like, how do people decide to go about the evidence that they need to make a decision? So here's just looking at some descriptive information. These folks, we call them categorical categorizers, they're like the folks that looked at like that top left corner of the 2x2 table and are like, wow, look at that number. So they just looked at one number and then made a call on whether they think this is advocation. This group, they never looked at any of the first order evidence. They just defer. What do the Democrats tell me? Or so on. Or so on. The full cognizers made sure that they selected all four of those questions that would give you the full 2x2 table. And then the partials would only look at either like a column or row. They wouldn't have a complete hit. Three minutes? Then we divide them up into the different deference groups as well. So in this row, those are the folks who didn't bother looking at information about what others say. They just use that first order. About what others say, they just use that first-order evidence to make their own call. We look at individuals, what we call an out-group deference. So, those are like if I'm a self-identified Democrat, I looked at only what the Republicans said. Maybe the answer is always just the opposite of what they say. We had in-group deference, so you sought information with a group that you then also self-identified with. I know there's mixed deference. People are like, I'm going to see what the Republicans say, I'm going to see what the Democrats say. Saying I see what the Democrats say. And the thing that I really think is really interesting is this: people look like they're using a lot of sources of information to make a call on whether something is efficacious or not. I don't have much that I can share or say about the results of this yet, but this is just telling me that matters. I need to start doing some more investigation on that. So, I don't really need to say that. So, I don't really need to say that. Here's the more complicated picture I want us to sort of think about. You've got the first-order evidence, but you also have these higher-order considerations that helps contextualize all of that. So, what is soft and tempting to do is like, that person's irrational. Because why? We gave them the data, and they just didn't come to the same conclusion. And we've seen lots of talks now talking about how that's way more complicated than you think. So, this is just one way of also thinking about how to carve out that difference. Carve out that difference. By thinking about those relationships with respect to trust, social context, right? Think about that as a higher-order evidence that we shouldn't be treating the same as the sort of first-order evidence that we have treated. Okay, I'll say. Thank you.