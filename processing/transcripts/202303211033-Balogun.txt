I'm a professor of Wench at the University of Toronto. So I'd like to be sharing some of the things I've been looking at over the last year that I've been there. So I've been talking about assessing wildfire emissions of carbon monoxide using foliar info spotlight. And thank you to the two speakers that came before me. They gave me a lot of background. So I won't be going to the technical aspect of it, but I'll just be showing some of the results that we have so far. Now I'd also like to recognize my co authors as well. My co-authors as well. So, we've heard so much today about CO and how important it is. We know that the total area burn in Canada has been increasing over the last 50 years, and it's definitely due to some of the changes in climate, both in terms of higher temperatures as well as changes in precipitation patterns. I'm going to expect that that would increase in the future. So, there's a lot of concern about wildfires and the same way the climate. And the same way the climate affects these wildfires, they also in turn will affect the climate. And we know that these emissions from these fires again will also impact the air quality. And that's something that is very, very important for us to study. Apart from that as well, they're going to also impact the borough forest carbon balance. And we know that these fires, you know, they help eat renewing the forest, also determines the age of trees in the forest as well. So all of these things will definitely be important going forward. Definitely important going forward. And if you can see this graph here, you can see that trend of increase in the area bond in Canada. So it's very, very important for us to study these fires. And we know that carbon monoxide is an ideal tracer for this biomass bonus. Apart from producing the CO from forest fires, we also have them being produced from fossil fuel combustion and as well as the oxidation of methane and the non-methane volatile organic compounds. So, for our study, we focused on using two satellite observations. One is EAC and the second one is MOPI. I'm sure most of us are familiar with some of these satellite observations. So, the EASIS is on board METOP satellites, and it's compared to the MOPIT, for example, you can see that it measures only in the thermal infrared region, unlike the MOPIT that measures both in the infrared and the Tamil infrared. Both New Year infrared and Tamil infrared. It's a polar orbit with an equatorial crossing of about 9:30 a.m. and it has about 14 orbits per day. And because of its very, very large swap of about 2,200 kilometers, it's able to provide us with daily coverage, which is very, very useful. And the special footprint is about 22 kilometers at that year. For the MOPID, it's flying on the terrace space. Flying on the Terra spacecraft and it measures both in the near-infrared and thermo-infrared, like I mentioned earlier. On it's also in polar orbit and it repeats every three days. So, I want to just keep that in mind in terms of the differences in the repeat days for both ERC and MOPI. And the equator crossing is about 10:30 a.m. And the footprint is about 22. Special footprint is about 22 kilometers. So, we use the geoscan model, and I, you know, I said John's already talked about. And I know Professor Jones already talked a little bit about that. And we run this model using the form of forward model version 13 as well. So we updated this version 35J to be consistent with the forward model. And the model is run at a horizontal resolution of 4x5 with 47 particle levels. And we use the GEOS-5 meteorological estimated meteorological fields from Geos5. Now it's very important to know there's the Now it's very important to so there's the original model, Josh model, which you call the base model, but we are using the updated version, which provides us with better match with the full chemistry. So for example, the source of CO from the oxidation of non-volatile organic compounds is no longer specified as a 2D source. So in the original model, all the CO from that is produced from these Nucleoses are assumed to be produced instantaneously at the surface. Instantaneously at the surface. But we know that's not accurate. But in this new updated version, we now have it in 3D. So it's archived from the fault model, and then we use that for the agent run. So now we can actually, unlike the previous base model, where there is wrong yield as well as wrong location of those emissions, so there's usually an overestimation of CO at the surface compared to upper levels in the atmosphere. But now we're able to account for that by using this 3D. Account for that by using these 3D surface sources. The methane source and OH fields are also specified from the forward model as well. And the OH fields are now consistent with all of the chemical sources specified in the seal. So overall, this version of the model is much better than the previous one. And it's better able to match the full chemistry around it. So for the four-diver assimilation setup, which we already talked about, so what we Which he already talked about. So, what we did was to so we again were looking at two different observations: one from MOPID and the other from ERC. So, we got the CO columns from MOPID and the partial columns from EAC and we used that to estimate the CO emissions. Now, we used a window of about four months, so we're mostly interested in the August forest fires in 2017 and 2018, but we used a window of June to September to quantify these emissions of these fires in Western Canada. So, the first thing. Western Canada. So, the first thing we did was to use the weak constraint separately for MOPI and YACI to optimize the state of CO in the atmosphere. So, after doing the weak constraint for the variable, then we did the strong constraint to estimate the actual emissions. And following the previous studies, we focused initially on monthly scaling factor because most studies in the past have also done the same thing. And we also were concerned about. And we also were concerned about we would not have enough information on the final temporary resolution to constrain the models. And we used the GFAS inventory as a prior. So let's go into the results. I'll talk first about the August 2017 Canadian wildfires and then the August 2018 wildfires. So this shows the COR columns for August 2018. So, this shows the CO columns for August 2017. So, this is the base model regarding the assimilation. Then, this is the ASEA assimilation and the mopping assimilation. I don't know if you can see anything on the back there. So, this is for the mean CO total column. And so, this the bottom panel shows the difference between the base and the different satellite. So, obviously, this is zero, and then you can see this base. So, for this one, for example, you can see for ERC, we have this negative Negative value. Yeah, so it for the assay scaling down the emissions compared to what it were scaling up the emissions in the Northwest Territories where we had fires. So that was very, very interesting for us to see exactly what is going on. I'm going to show you some other results to actually see how we can better understand what is going on here. So the second slide is very similar to the first one, really. There's not much difference, but this is just at the surface. So this is the main surface CO concentration. You can still see, you know, You can still see the major difference between MOPID and ARC in terms of the CO estimates. If we go to August 2018, again, same panels, you see here that you can still see that negative value here. So Yassi again is scaling down the emissions, especially in VC. So for August 2018, the fires mostly, as you can see, went from the VC area. See, from the VC area compared to MOPI, where you have much higher emissions. And this again is similar to the first slide. This is just showing the surface CO concentrations. So we're interested in looking at the scale factors, you know, for amorphous static. Know for a morphid. So, this is the scale factors, the monthly scale factors, you remember, for the MOPI, and this is for ERC. And as you can see, you know, not so much different if you look at it very, very closely. But you see that, you know, in VC, for example, where I said we had to spires, you can see this is actually blue, so it's much closer to zero compared to this value for MOVIP. So, definitely, regionally, there's very, very different. Like, if you look at the states, in the United States, for example, somewhere around the agency, the YSCRT has. Somewhere around here, I can see that Yassi actually has is scaling up the emissions compared to MOPIC. So perhaps my due to that might be due to the fact that Yassi is able to is more sensitive to long-range transport from those areas. But overall, they're quite similar, but there are some large regional differences. So again, this is for the monthly scaling factors. Now, so what we tried to do was to calculate the total emissions of CO. The total emissions of CO for Korean North America for 2017 and 2018, and that's why we begin to see some interesting results. So, this is for 2017 emissions. This is in teragrams of CO per month. So, these are the priors. So, obviously, they're much smaller in June, July, and September. We're most interested in August. So, these are the priors of 12.8. And for Morphe is 38.0, and for ERC it's 13.1. So, very, very huge emissions for MORPI. Emissions for MOPI for 2017. And for 2018, it's also very similar. They're very, very small, obviously, for June, July, and September, but in August, it's 8.3 for priors, 15.1 for market assimilation, and then it's 10.0. So the difference is not as much as in August, but it's still, you know, almost a factor of two. So we're really interested in seeing what exactly is going on and which one is, you know, I mean, yes, it's very much closer to the You can the base run. So obviously one of the best ways to look at this is to compare them to independent observations. So we looked at the TCON observation from East Shout Lake and compared the two results with that. So if you look at this, I don't think you can see it very well from the back. I know you can see very well from the back. So, the red are the TCON XCO, and the orange one is the base run, the virus, and then the blue is the AC, and green is MOCID. And you can see here, you can see that overall the MOCID emissions are much higher than the blue, which is the AC. Overall, there is a reasonable agreement between the assimilated results and the TCAN measurements. The TCAN measurements. So, overall, we're happy to see the results, though there are still lots of differences that you can see that sometimes MOPIT is definitely overestimating the emissions. And if you look at the regression plots, for example, you see this is the base base. This is the soft year is about 0.39. Much better year is 0.93. So, definitely the assimilation is doing a good job in terms of trying to improve the results. And for MOPID is about 0.87. So, overall for this year, 2017. This year, 2017, at this track length, the results were overall reasonable. But it still begs the question: if you look at the table that I showed, initially, the differences were much, you know, were really large. But yeah, it shows that they are both showing reasonable results. But obviously, we have to remember the fact that this is only for just one station, right, this track link. So perhaps it's going to be different if we look at other sites across Canada. Another. So, this is where things got a little bit funny. So, this is August 2018. And if you want to compare this to the previous result, this is not as encouraging, obviously, as the previous one. So, the agreement is very, very poor. As you can see, this is different measurements, and the model results do not capture those peaks at all. Almost on every day, they are under. On every day, they are underestimating the CO emissions at each short lake for both of the models. But overall, it seems that the Morphe inversion of CO is in better agreement than the Yassi measurements. So if you look at this, this is the base model 0.22. The RC is even worse than that, but the slope is 0.19 and the MOPIT is 0.35. The R is 0.57. So overall, it seems to be MOPID that is. Be MOPIDA is able to capture this a little bit better, but overall, the results are not good. Again, just remember that this is for the monthly scaling factors that we have used. So, definitely, what we started looking at was that perhaps if we improve the temporal resolution of the scaling factors, perhaps we'll be able to get more accurate results. And because these fires, they're very episodic, right? So, the fact that we're using monthly scaling factors, you know. Fact that we're using monthly scaling factors, you know, definitely might have been a problem. So, this just shows the scaling factors for MOPI for the week one, week two, week three, week four. So, instead of having one scaling factors, we had one scaling factor, we had four of them. And as you can see, you don't really see a lot of difference for the first two weeks, but in the third and the fourth week, you can see that the emissions are a little bit much different. So, the next one is for ERC, and you can see again very, very high ERC scaling. You see scaling up the emissions, especially at BC as well as in the eastern part of the United States. So the scale factors also vary from week to week. So now we apply those scale factors, those weekly scaling factors, to the same results to see if there's any improvement in our results. And the first thing that you notice is that the morphed emissions are much more higher than in the previous slide. And you can see that before there were You can see that before the web, much, much, much lower than the previous one that we used just monthly scaling factors. But still, there's still some days, obviously, where you can see that the model is not capturing those things that we see there. And the changes in ERC are not as substantial, which is surprising because this is weekly scaling factors. And ERC repeat is, we have daily coverage for ERC. So you'd have expected us to see. You know, us to see you know, a better performance of the assay, but I'm obedient every three to four days, and there's still some improvements. So, you can see here it's a 0.41 slope, which is higher than the previous run that we did, and the R-square is also improved. But for ARC, we don't really see a lot of difference or a lot of change in the results. So, what we did then is to even make it much more finer. So, we tried to use four-day scaling factor, and this is where you begin to see ERC, you know. And this is where you begin to see ERC showing us a better result. So if you compare that on this left-hand side here, this is the weekly scaling factors, and this is the four-day scaling factors. So here, obviously, the base remains the same. So this is about 0.22. You are seeing 0.22 here where it increases to 0.38 for the four-day task claim factors. And this is the R value at 0.51 and increases to 0.67. So we can see a lot of improvement in Yassie when it Improvement in Yassie when it comes to the four days. And again, it shows us that it's good to perhaps use final scales, scaling factors for these emissions, again, because they are very inspirated. There's a slight improvement also in MOPID, but not as much as ERC. And also you can see that the blue dots are much higher than it was in the previous study. So this is encouraging in terms of just seeing how the model is able to respond to these changes. So overall, in terms of our conclusions, So, overall, in terms of our conclusions, because of this wildfire has been episodic, confined the emissions with scaling factors of course, temporal scale and spatial scale is challenging, which is what we see from changing from monthly scaling factors to the weekly and to the for the scaling factors. Now, ideally, you know, it would be better for us to use daily scaling factors, but we are not, we don't know for now if the observations have enough information to constrain the model at that time. To constrain the model at that temporal scale. And this is where we are hoping that Tropomy will be able to help us with this because it has a final special scale. And it also provides global coverage every day. So biases in the observations due to error source from the fires could also contribute to some of the differences we're seeing. So we have somebody in our group, Eva, that also has been looking at the different satellite observations: Morpe, ISI, and Tropome, and she has. Um tropomy, and uh she has found that the uh the sensitivity of these uh satellites is quite different when you have uh very, very high air results, particularly when you have uh strong fires. So, that's definitely something that we are also thinking about. The inversions will be sensitive to the altitude at which the model injects the fire emissions and at the different vertical sensitivity. So, currently now just game is set up to run. So, we so we get the injection height. So, we get the injection heights from GFAS, and they specify the mean altitude of maximum injection, which is the MAMI. So, right now, GFAS, the model just assumes that all of the emissions are distributed uniformly from the surface up to the MAMI level. But we know that that might not be accurate, especially when we have very, very strong fires. So, that's definitely something that we're looking at to see if we can change some of those injection heights, perhaps scale them. Perhaps you know, scale them up instead of distributing everything uniformly at the surface, and then just see how. And some members of the group have looked at it for 2017 fires and they saw some differences, but it's definitely something that will be the next step. So the first thing in terms of our future work is to assimilate the triple ME CO data and compare them to the ones we have and hopefully run them at the final resolution and maybe even get a time scale for the scaling factors and also to play with those. Factors and also to play with those GFAS injection heights that I talked about, because again, the different measurements would respond differently to this. And finally, and hopefully, is to use a nested model because obviously we understand that using this 4x5, it's not a little bit too coarse. So it might be much more helpful if we run the model at the final resolution, perhaps the 2 degree by 2.5 degree, and hopefully able to resolve some of these questions. able to resolve some of these questions that we have. So thank you very much for listening to my talk. Are there any questions for Welca? Thank you for the nice talk. I'm wondering about the background state. Does it explicitly include fire emissions of Canada? Yes, yes. So we used the the GFAS as the priors. As the priors. Okay, sorry. I just missed that. And I heard that, like, if you have extreme events like forest fires, you can run into problems if your background covariance is not, like, your uncertainty is not big enough in your assimilation algorithm. So you can't basically correct these large dis discrepancies between the observations that are seen in fires and radio background, which is far off. Did you observe problems like that? Chromes like that, or did you take a look what the background variances were in the fire locations? I don't really remember. I know we specify like the volume, like to vary the because like it depends on how much we specify for the errors. If it's very, very high, then the model is able to adjust itself to that. I don't know. We didn't really look at it from the perspective of the state, but we didn't describe it. That's something we should probably look at, but we just made a little bit of money. Thank you. Yes? I guess more of a comment about scaling factors and GFAS. At least with QFED, which is similar to GFAS in the bioreadiator power products, they miss a lot of biomass burning in the oil forests. Because, just like aerosols affect the Aussie and Moppet, if you have aerosol loading FRPs, Aerosol loading FRPs, we're going to miss that fire. So using a scaling factor, I think you're going to, you know, you're going to miss all of those fires that were missed in the first place. You you have two two types of errors, right? Probably the emissions factors aren't well tuned, but but you also have the fact that there's just fires that we know these things are missing. That we know these things are messy. That's a good point. So, a lot of point inherited this from another postdoc, and in that analysis, we actually look at the GFED versus GFAS, and GFED misses the fire particularly. And so we really couldn't even use GFED for the analysis. GFAST actually has the fire in the right location. The intensity might be probably off. But it really, when you run the board model with GFAS, We've done the Ford model with GFAS. If you compare the simulation with independent data, we actually see the signature of that fire showing up in time where you need it. Is that with the 4S GFED product or 4 before the small fires were added? So, and I, you know, there's rumors that GFED5 will have even more. So last year comments are going to be nice. Oh, do you know how the uh release pipe is calculated or retrieved from Java? No. The only thing we have is, so we have the mummy height and the model just assumes that all of the emissions are released uniformly from the surface to that height. And change the height in terms of like you know, just seeing how the model works. In terms of like, you know, just seeing how the model performs, but in terms of how it's calculated, I'm I'm not really sure. Which is special. Well, I yeah, I think most of the satellite observation only give you the radiation power. They don't give you injection height because injection height is supposed to like people have their own choice to calculate algorithms. Yeah, but if you take GFAS, then you make a choice of uh Of Kaiser who developed this and done the good bridge and its stability. And as far as I know, I know Netsby on this once used for heat fires, but it's another issue. But high-radiative power plus stability of the atmosphere. Yeah, actually, we have twice three different formulas for the injection. I don't believe that each one is performing better than the other and you have to consider all those things. I think in Jackie High most of the time when people model the welfare, they do their recognition rather than directly taken from the semi-authoritarian. Yeah, that would be nice. We are, so one thing that I think decided not to mention was that we are thinking of looking Mentioned was that we are thinking of looking at using the Canadian Group of Environment Canada has this fire model that actually simulates injection. Also, use of method by Solo Freitas. Yeah, actually right now we are trying to build a quasi operational forecast system and we try to probably like freeze the platform you are performing will be the best. Yes, sorry. Just a sign I noticed on slide eleven Yeah, so you can kind of see the effects about mountains tracking the Alps through southern South America, following the Rockies up or in the E of the Rockies to the west of them, up through the western side. You can then see the snowy mountains, smoky mountains, sorry, out east, just in view of them, and then you can see the effects of the Alps. Alps. So I'm just wondering, you know, that seems to be near to mountain regions, high altitudes. So down sloping or upsloping a trend on there are a lot of fires and lightning. I mean, there's forests and lightning in the mountains, so there could be. Yeah. So one one possibility, which is I think what I want to link to, is that the two instruments have different vertical sensitivities, right? So how the signal is lifted into the free troposphere, and then that transport signature will be picked up differently. It could be that where you have strong topographic features, you're getting this lifting, and these satellites are picking that up differently. Differently. So, for South America, it could be that we just don't have enough information to get a decent constraint on all of South America. And so, what you're seeing is transport from the eastern part at the field and so on, that's probably getting vector out over the southern Atlantic, whereas in the northern part, that signal is probably going over the Pacific. Seeing that, but in the uh the honesty's picking it up so like He's picking it up, so like you're tracking the mountains, that's what I was noticing. So it's a great option. It is pretty coarse resolution, though. No questions online. Is there any last question in the room? Let's thank the welcome again. The next speaker will be.