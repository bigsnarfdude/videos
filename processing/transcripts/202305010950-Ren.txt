So today I will talk about this particular problem of uniform in time propagation of chaos results for particular multi-line diffusion called unified alpha mechanics, which I will introduce. It's a joint work with my two PhD students, Shen Fan and Wazung Bo. So let's first motivate our program while we study this midfield on dynamics. We study this mid-field neural dynamics. So, the whole story started from the training of neural networks. So, nowadays, neural networks is already an indispensable tool for all the scientific or technology demand. So, well, our study focused on the simplest architecture, the two-layer, or you can say one-hidden-layer neural network, because you are seeing mass metrics, better defined. So, a two-layer neural network is nothing but a parametric edition of a function. But a parametrization of a function in this form. It's a linear combination of activation function of linear combination of data. So the so-called universal representation theorem ensures that any continuous function defined on a compact point can be approximated by this kind of paradigm tradition of new layer new layers. But in order to find those optimal parameters, you face this kind of non-convex optimization problem. It's non-convex due to Problem is no convex due to the fact that the activation function is no convex. So the objectivity function here is no convex. And it's often over-parametrized, meaning that the number of parameter n can be very large, larger than the number of data sometimes. So it's a difficult optimization problem to analyze, so we need a new point of view. Here is the Point of view. Here it is the observation. So, in fact, we can have this trick divide n and pass n on the parameter C. And now the output of real network here looks like an empirical sum in probability. So, now we lift the problem, we think, oh, now let's rewrite the problem. Instead of considering optimization, we probably define a real space, we define this optimized mean-field optimization problem with respect to probability measures. So, now we choose n, which is the Choose n, which is the law of the random variable triple CAB. So by this reformulation, we find that an convex optimization. The objective functional f here is a convex functional of probability measures. So now we are considering a convex mean field optimization problem. Now the objective is to analyze this kind of mean field optimization problem. So in the previous study, In the previous study with Kaitong Wu and Rikash and Devil in Scotland, we studied this entropy regularized version of neutral optimization problem. We add a temperature times entropy to the objective function. One notes that entropy is strictly convex, so it's still a convex include the optimization problem. So first theorem tells you that entropy is a legal regulatory. Is a legal regulator in the sense that when you make the temperature go to zero, then the minimum of the legalized problem converges to the minimum of the initial problem. So it's a legal legalizer. Then we can use the notion of a linear direct filter to think about the first order condition for this optimization problem. So first we find this kind of a first order condition. First, we find this kind of a first-order inequality. It's just an order log of the real space. So for convex functional, so the difference increment of the functionality is bigger than the improvement of the tangent one. And then this inequality immediately gives you the sufficient and necessary condition for m star to be the minimizer. In fact, if integral here, inequality is equal to zero. inequality is equal to zero, then since m and m prime are both probability measure, the right hand side is zero, and this is true for every m prime, which means m is the minimizer. So this gives you the sufficient condition and also necessary for m star to be the minimizer of this energy function. So f plus entropy we call it energy function. Well we give a name To give a name, so we call the sum of these two terms the linear derivative of the energy function f sigma. That's just a notation, because the energy function itself is in fact not differential. Okay, and well, here is a remark. So if you know the literature of Minfield gaps, then you know that the thing you have to define out of a constant in the first order condition here, it's also equal to. Here, uh it's also equal to a constant. Find out to a constant. So if you don't like the constant, you can further uh take a gradient in x and define the so-called intrinsic derivative and the sufficient condition. First of all, the condition here will become the intrinsic direct of the energy function equal to zero on the minimization star. Okay, so this is just a current relation for the minimizer. The current relation for the minimizer of the mid-field optimization problem, then further we need to know how to approximate it, how to find it. So again, we start from this force-of-developer equation in the previous slide. And now we want to connect this first-order equation to diffusion. So the little trick is: okay, we write Bruce and the lobby by its definition. And then take a divergence in front. Take a divergence in front, and then we figure out: well, in fact, this means m star is the stationary solution to the following focal point equation. And if we use our notation of the intrinsic value of the energy function, then the Folk Planck equation can be rewritten in a compact way, like this, which we'll use today. So, well, in this room, everybody. Well, in this room, everybody knows that once you know that this is the station solution to the focal plot equation, then it means it's in market measure to the corresponding diffusion process. And the corresponding diffusion process is written as follow, and we call it the mean-field Launchman dynamics. Why we call it mean-fueled Launchman? Because first the it's a machine level for diffusion and depending on the marginal law of the diffusion. And also uh we see the drift that is in fact in the form of directed gradient. So Of directed gradient, so it's in the same text of non-dominant, so it's a natural extension of non-dromatics. We call it mean-fueled non-kinnetics. So the first, so so okay, so now we know that the minimizer of our mean field optimization problem is the invariant measure of the mean field not one of x. Now we expect to prove. Now we expect to prove that the marginal row of the medium large magnetics converged to its marginal method. But to do that, the first important observation is so-called energy dissipation. In fact, if you input MT, the marginal row to the energy function, you figure out if the energy will decrease all the time. And you can in fact compute this uh uh time directive of the energy. So now uh I give you uh formal proof at the supersymples. Proof by the supersymposity. So we are looking at the dynamic evolution of energy. So using the definition of linear directive, you can immediately write this equation. And then for DTMT, you use the Fokker-Planck equation. And Folk-Planck equation using our compact form uh of uh writing is like this. We now apply an Foucault uh integral by part, we get what we want. Part, we get what we want. And what do we want? It's the so-called energy distribution. And this energy distribution gives you a nice intuition of inconvergence. Why? Because it tells you energy always decreases until the red turn equal to zero. And the red turn equal to zero, if and only if n is the ng is the minimum, it's the first order condition. So it tells you that the mean view lambda will make the kinetic will make the Well, the dynamic will make the energy decrease until it hits the minimum. So, following this intuition, we can make a reverse proof using so-called Lasado's invariance principle and prove that indeed the marginal law of the mid-field long-running batteries converge in the sense of watch time distance to the minimizer of the desired mid-field optimization product. And following our work, And following our work, there are other other researchers, they prove the, well, with a little bit more adoption, they can prove the exponential convergence and got the convergence quantity. So the idea of this proof is just a logo with unified and the convexity of the of fi L of F. So, um, well, now to go to the topic of this talk. So, in reality, well, in the training of neural networks, now we know that the mean field launch line, its marginal logo converged to the optimizer of the mean field optimization motivated by the training of neural network. But now, how to achieve in practice. In practice. So, in practice, we can, of course, not simulate a marking razor for diffusion directory, right? Because it's an infinite-dimensional object. What we can understand it, so you're true. This is kind of an alternative to what everybody does with answers to atoms, or stochastic gradient methods. Want to do it in front of the or? Or see here, in fact. Yes, and no. In practice, Um well in practice everybody is a breathing design. Okay, breathing design or stop. Uh it's the same thing. Okay, just uh uh relaxation. So yes, it's it has a follow-up. So uh the difference here is is just the brown motion. Okay, if you forget about brown motion, it's a great decent. And now to make the story a regular C in mathematics we need to add the bright motion. Sigma times ground. Sigma is the temperature Sigma times run. Sigma is the temperature was just normally chosen to be small. But you need it to exist, otherwise it will not converge to the placebo. It will be stuck at the local minimum. Okay, so come back to our topic of particle system, okay. So we cannot uh simulate MFL, the medium learner dynamics, directly, we simulate the uh finite particle system, okay. The particle system. So this is the marginal sort of diffusion. Now the particle system corresponding to it is written this way. So you replace the marginal distribution by the empirical distribution of the particle system at time t. And well now let's recall what's the classical propagation Kelsey estimate. It tells you d is a certain distance. You can just think it's a Washington distance. The distance between the particles The distance between the particle system and the mean field system will be dominated or controlled by a constant times the distance between these two systems at the time zero. Okay, that's why we call it a propagation of chaos. Propagate the error of the of the particle system and the view system along the time. But unfortunately, in the classical estimate, the constant here will depend on T. The constant here will depend on t and it depends in this fashion exponential of ct due to the round one inequality. The constant constant of groundwater inequality. And in particular, you can see that the error will be very big if t is big. And in our story, let's recall, we have proved that for the middle system, the module wall will converge to the mid-miter and start. Minimizer and star. So at the end, we want to sample minimizer and star, right? So in other words, we want to sample mt, but with very big t. Okay? In reality, what we will sample is m n t, the particle system. Okay, the particle system. Which means we need the propagation chaos result, the error control to hold true for big T, for very big T. For big T, for very big T, or at least big T. Well, ideally, it should be uniform in time. Ideally, it should be uniform in time. So, this makes classical results not so useful in our context. Because we want to sample NT the Marine law for beta. And of course, there are study of uniform time proposition of test for macroscopic diffusions. Marking velocity diffusions, but with very few exceptions, all those existing results will depend on the so-called small mean field dependence condition of the gene. Well, more simply speaking, they ask the Lipschitz constant with respect to the marginal law should be small. In other words, it's just a perturbation result of the norming field result. Result. More participation. But since we want to apply the result to the neural network, and there's no reason that this refuel dependence will be small, so we have to go a step further. That's what we do. I will not go to detail, but some general idea. So to prove that, the uniform impact propagation tells without a small amphibious dependence. Small Ni field to mass. Well, we introduce this n-particle mean field, sorry, n-particle energy function. And well, in particular, we realize that the normal gradient of this function here, if we empirical uh measure, it's equal to the the the the the the intrinsic error applied Nutrins get applied to it. And well now we figure out if we use this kind of energy and the corresponding classical non-transdynamics will be written this way because of this observation. Because in the classical non-trans dynamics, the drift is just the gradient of the potential. And we identify that this Lantrine dynamics is indeed our part. Is indeed our particle system. It's the same thing. So the particle system of the mean fuel Launchman dynamics, in fact, the classical Launchman dynamics with respect to this energy function. And now with this observation using the result we have already proved, like the energy distribution, we can show this important lemma. It tells you that tells you that the energy the energy of the n-particle system decrease uh converge uh uniformly quickly up to uh error. Error is the size of 1 over n. All the constant c depends on the dimension of x t is 0. No, it depends on the dimension. C then does not depend on the dimension. C depends on the regulator of F, the if she's constant bound of diagrams. Okay, so well I will not talk about the proof, but basically all the tools we need is the so-called component-wise logical inequality and the convexity of f. So if f is not convex, you cannot expect this kind of result. The key structural conditions Key structural conditions. Okay, um well, uh here is a numerical test for this lemma. Okay, so you see that well we are training a neural network to learn this uh two-dimensional sinus function. Okay, and then uh here is the train uh is uh is uh here is the value of the energy uh along the train. Okay, then you see the On the train. Okay, then you see the log of the log error. Log error. Then you see that the log of the energy function. Then you see that you have an exponential convergence with the same rate for different number of particles until a certain moment. Until the moment that the particles, the energy of the particle system enter a box of the size of one. Box in the side of the size of one of n. Okay, for example, for n small thing, you see it stop at a higher level, for n uh bigger thing stop at the lower level. But before that, it's a beautiful coverage. Beautiful in n. So this is important lemma. It helps you to prove propagation of chaos uniform in time. Because first, this error dominates the relative entropy between the particle system. uh entropy between the particle system marginal and the uh optimiz the tensor of the n tensor of the uh optimizer probability meter. And then if we want to prove the uniform time propagation Kelsey in Washington 2, then well the so-called propagation KLS result is to compare these two measures, the part single minus and the end tensor of the and the n texture of the field uh marginals. And then uh immediately using uh triangular sir triangular inequality, you have this kind of thing. You compare both to the end tensor of the minimizer. Okay, and then uh uh using the result I showed in the previous slide, this guy is dominated by entropy thanks to the telegram, the two inequalities. And and uh and now the And now both releasing entropy here is dominated by this kind of error. And this tells you the propagation of chaos for big time T. If time is big, then this term is very small. So it's dominated by a C over N. And then you compi uh combine the short time propagation chaos and the the long time propagation chaos together. You will take the minimum between this guy and the the the classical one. So The classical, the partial constant. So, this gives you the propagation chaos a uniform time. This is in practice point of view, this is a useful result. And then, to please mathematician, we prove some more technical results, which is very challenging to prove, but I will not talk about in this talk. So, we proved the LP convergence of the minor law of the material launch 1, and also using this result, we And also using this result we'll prove the uniform in time for real health in the sense of uh relative entry. So here it's a much true. But for relative energy we don't do more channel. But we will prove it. So uh that's all. Thank you for the attention. Quite the simulated uneating that they used to do. This is the simple thing, I think. But you're doing need the room. I don't know whether there are subtle differences or it's similar things or. It's the similar thing. Here we didn't treat simulated union. Simulated union, you to let the signal go to zero. Yeah, but even before that, it's metropolis algorithm and all that. They're all related. Yes, yes, yes, that's true. It's it's like because Metacol is the Like because metapolis testing is exactly algebraic testing. You write down the continuous version of metapolicy and it's algebraic. And they also argue that method policy testing only works for a low dimension. Because for high dimension, the rejection rate work is too high. So it does not work. But with launch line, you can have so-called only adjusted launch line assembly, then it will work even for high dimensions. Higher question. Real training, why did they not use it in this computation? I'm sure they know. Some people know, but I think it's many academics to use it. But in well, why in industry very few people use it, but since there's few, but very few, there are people who want to push for it, but it does not work so well. Push point, but it does not work so well because in practice you use the deeper neural network. Here it's just a tooling. And for deeper neural networks, well, with some magic of tuning, you know, sometimes it always ends up in good results. So they don't think it's necessary. But who knows? Can I ask uh clarifying this question? So in the case where f is linear, just you take out of some function u you want to minimize u? You want to minimize U. So, in that case, there is only one minimizer because the first-order condition is only one minimizer because F is convex. Yeah, when F is convex, already at some point you assume that there is only one in mind. And so, coming back to the constant C, you assume that the gradient of U is the kit and it depends only. Yeah, it depends only only depends on this uh lipstick constant, right? It's independent of uh dimension. Uh which is the table? Somewhere in your uh in your behavior. Yeah, here, here. So assume that f is only the integral of some function ultimate m. So it's a linear Yeah. So it's a linear. That is linear. So it's only linear. Because then you don't need a propagation of chaos, right? No, no, no. I just get. And if that's a linear, you don't need a propagation of chaos because you have a Langevin dynamic, which is and then uh you are talking about convergence rate. Then convergence rate uh is given by the logs of lift inequality. Sub-level inequality. The rate is depend on the constant of the lowest of left inequality. And this is on the condition on the structure of the single.