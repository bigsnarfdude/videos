And then I will interrupt the speaker to ask those questions. Okay. Everything looking okay? Looks good here. Great. So yes, thank you, Peter. Thank you, Andrew. Thank you for the invitation and soldiering on with holding this workshop, which I've enjoyed so far. Those of you who were here with us today would know that I wasn't afraid of. Would know that I wasn't afraid of interrupting people during their talks, so I hope people will return the favour to me today. Yes, so I'm planning on sorry, I've got a thing in the way, there we go, talking about non-equilibrium thermodynamics of catalytic information processing. So, really, the talk is going to break down into three parts. The first is me saying The first is me saying what I mean by this and why I think it's a really important type of process. The second is to say why these systems are somehow complex and hard to design and build. And the third is to actually touch on a few experiments we're actually doing in the lab on how we're trying to meet this challenge of engineering catalytic information processing systems. Catalytic information processing systems. So slides moving forward. Okay, so actually, very helpfully for me, the first day was essentially about catalytic information processing systems, although they weren't called that. But as introduced by Udo, there are cell surface receptors that detect molecules in their environment. Molecules in their environment. And there are catalytic systems that read out the state of those receptors and pass a signal on to the interior of the cell. Can you see my cursor, by the way? No? Yes, the little white arrow? Yes. I don't know if there's a way to make it better, but okay, let's work with that for now. Okay, so. Okay, so what happens in a canonical example is that receptors that are anchored to the surface of a cell up here become activated by some process in the exterior. And when they're activated, they can act as catalysts to catalyze the conversion of downstream enzymes from an inactive to an active state. From an inactive to an active state. And those activated enzymes then go on to catalyze enzymes further downstream and so on all the way potentially to transcription factor regulation or whatever response the cell needs to have to the external signal. So if we really want to abstract what these things are doing, we can What these things are doing, we can talk about them effectively copying the state of the receptor into a readout molecule. So, this purple Y is a receptor molecule. It can bind to a ligand with a rate that's proportional to the concentration, which was very important in Sarah's talk. And the ligand can unbind to switch back to the other state. So, we could call this state zero when there's nothing bound, and state one when you have got a ligand. One when you have got a ligand bound. What the readout molecule does is when it's when the receptor is in the inactive state or state zero, it can tend to catalyze the conversion of the readout from an active state, state one, to an inactive state. So typically, some kind of dephosphorylation mechanism, the readout molecule can be converted from one state to another. State to another. When instead the receptor is bound to a ligand, the readout molecule can be converted from state zero to state one by the catalytic action of the receptor. And therefore, if most of the receptors are in this state, if they're mostly bound to a ligand, most of the readouts are going to end up in state one. And if most of the receptors are in state zero, most of the readouts are going to end up in state zero. So here I've talked about specific. So, here I've talked about specifically a bifunctional receptor that acts as a catalyst in one state to push the system in one direction, and a different catalyst in another state to push the system in another direction. That's an idealization of how the system behaves, but broadly speaking, I don't think this story would be too unfamiliar to real molecular biologists. Fundamentally, the important point here to note is: I'm calling this thing a catalyst. I'm calling this thing a catalyst. Why am I calling it a catalyst? Well, the state of the readout is being changed by these reactions, which are facilitated by the receptor, but the state of the receptor itself is not changing in the process. The receptor is accelerating reactions without being consumed, and that's why I'm calling it a catalyst. Now, those are the most obvious examples of catalytic information processing, but they're not the only ones. And in fact, they're probably not the most. The only ones, and in fact, they're probably not the most important ones. And I would argue that the polymer copying mechanisms that underlie the central dogma of molecular biology are also catalytic information processing. So, what am I referring to here? Well, I'm referring to DNA templates, DNA double strand being replicated into two double strands. I'm talking about DNA being transcribed into RNA, and then the RNA. Into RNA, and then the RNA strand being translated into proteins. And the fundamental point here is that there's a specific sequence in the template DNA, famous ATGC base pairs. That sequence is preserved in the daughter DNA when replication occurs, and it's also preserved in the RNA, which is transcribed from DNA. And that sequence is also used to determine the sequence of In the sequence of amino acids in a protein, although not all of the information is preserved, there's kind of a compression of information at this stage. Now, why am I calling this catalytic information processing? Well, at a very fundamental level, the templates themselves act as catalysts. In the absence of a DNA strand coding for a protein, you have a very, very slow, I would we can approximate it as infinite. We can approximate it as an infinitely slow rate at which RNA, mRNA for that protein is produced, and an infinitely slow rate at which that protein is produced. You need the template there for the reaction, for the production of the mRNA to happen. Furthermore, at the end of the process, the template is recovered. The DNA that is used to make DNA that is used to make the mRNA isn't destroyed by the process of making the mRNA, we get it back, and so it's contributing to the reaction, it's accelerating the reaction, but it's not being consumed. So, at a very fundamental level, it's a catalyst. So, I've identified these two important classes of information processing systems in biology and said that they're catalytic. Why is it Why is it important that they're catalytic? Well, the reason I believe is that if something acts catalytically, it means that the effect that it has on the downstream product can persist for a long period of time after the two are no longer bound to each other. So, in the particular example of the receptor that is catalyzing the conversion of a downstream readout, The receptor when it's not bound to the ligand catalyzes the readout being turned off. That readout then diffuses away in the off state and it stays in the off state. It doesn't need to stay bound to the receptor for it to be kept in the off state. Finally, yes? We have a question from the audience. I hope I'm reading this correctly. If it's really a catalyst, it should enhance the backward rate. It should enhance the backward rate, which is RNA degrading as well, right? That's the question. Yes, it does, but it's driven so hard forwards that you never see that happening. The RNA degradation, I mean, this, I'm going to get into the thermodynamics of these things in a moment, but the RNA template, in principle, if you were able to wind down the nucleotides. Nucleotides triphosphate concentration. In principle, the template could come back to the product should be able to come back to the template and be disassembled there. Now, that's not what happens in a cell. What a cell does is it has the reaction to produce the reaction to produce the mRNA, which is being strongly pumped. Which is being strongly pumped with free energy supply, basically. So it overwhelmingly goes forwards. You never see it go backwards. And then they also have the degradation of the RNA via another pathway, which again is driven with free energy. And so you never see that one going backwards either. But in principle, if you turn the knobs of these free energetic driving towards zero, you would see these processes. You would see these processes going backwards and forwards via the catalyst. And to some extent, that's what I want to do in my experiments that I'll get to later is really actually reach these limits where you could do that. Does that answer the question? The answer sounded good to me. I don't see a response from the question asker. Yeah. He says, yes, thanks. Great. Okay. So, okay. So what I'm saying is that the So what I'm saying is that the catalytic action allows the product and the substrate to go their separate ways, the product and the catalyst to go their separate ways after the interaction, but retain the change that was made. Now, this you don't get in the other model of signaling, signal transduction in molecular systems, which is sort of allosteric binding. Is sort of allosteric binding. So if I imagined my X here, which can switch between two states, is my downstream molecule. And my upstream molecule is this green protein, say. And when the green protein binds to the orange one, it tends to favor converting it into this circular state rather than the square state. This would work, right? This would transmit information. This is the sort of equilibrium information transmission. Equilibrium information transmission mechanism that Udo was talking about in his talk. And when, and cells do indeed use this. However, as soon as the green upstream protein unbinds from the downstream one, lets it go again, it will then immediately convert back to its unbound state. It turns out that you can do. Unbound state. It turns out that you can do the analysis. And in order for, if you wanted the downstream protein to remember the influence of the upstream one from the past, you'd necessarily be violating the second law of thermodynamics. You'd be creating time asymmetries without an input of fuel, and that's a violation of the second law. So you don't get this ability to persistently modify. persistently modify your downstream products unless you're unless you're acting catalytically and consuming fuel. Okay, so why is this catalytic action particularly useful? And what we've hinted at is that indeed there's a cost to it, which is that you need to consume a supply of free energy to signal in that way. So it better have some important uses. Well, given that the product Given that the product can detach from the catalyst and they can go off and have an independent existence from each other, what that means is that one upstream molecule can activate two downstream ones, or three or four, or indeed an arbitrarily large number. So what that gives you in these signaling cascades that I talked about at the start is the potential for extremely strong signal amplification. A single input species can actually Input species can activate a whole host of downstream ones. And on a similar level, there's no reason why the two downstream things that you need to interact with have to be the same. They could be different from each other. And that gives you the option of splitting your signal without corrupting it, essentially. My collaborator, Peter Rine, argued very eloquently that another important use Another important use of this persistent modification mechanism is that it allows you to do a time integration. So, the classic Burg-Purcell story that was touched upon on the first day is that a single receptor which goes from being unbound or bound to a ligand molecule, at any one time it gives you an incredibly noisy reading of what's the concentration of the ligand in the outside world. Of the ligand in the outside world. However, if you're able to average that signal over time, you get a much more accurate guess at what the concentration is. But in order to average, you need to remember the past. You need some kind of memory that records what the state was historically. And that's exactly what you get with these catalytic modification schemes because the upstream The upstream receptor can catalytically set a memory, and then that memory holds that state in principle for a long period of time, even as the catalyst is flipping around between the bound and the unbound states. And hopefully, it's reasonably clear that you can't do this mechanism with this equilibrium binding mechanism. Finally, another thing it allows you to do is if your If your mechanism for activating the downstream substrate is to transiently interact with it, turn it on, and then diffuse away and not interact with it again. That means that the effect of the downstream substrate on you is quite small. In electrical engineering, it's very useful if we're able to make assumptions about modularities of circuits. About modularities of circuits. If we can design one part of a circuit and another part of a circuit, an upstream and a downstream part, plug them together and have as little as possible feedback from the downstream subject to the upstream one. Once you start getting this feedback or retroactivity, it becomes really, really hard to rationally design circuits that work the way you want them to. You lose this ability to think modularly. Modularly. And this catalytic activation, because you can activate the downstream module and then you only need to be interacting with it transiently, it gives you the opportunity to really reduce this back action from the thing you're interacting with. You don't spend your time bound to it, sequestered for long periods of time, and therefore the retroactivity is small and your modularity is potentially quite high. So there's lots. Potentially quite high. So there's lots of uses for catalytic action in signaling. What about the other example I gave, which were these sort of polymer copying mechanisms that I talked about in the central dogma? Just a moment, Thomas. We have a question from the audience. Yeah. Is it true that integration of the signal will happen only when the catalysis is coupled to free energy dissipation? If the catalyst Dissipation. If the catalyst only changes rates of the downstream reaction, say phosphorylation, would the downstream molecule be able to integrate? So you can, a catalyst can only, so if I go back to this picture here, so the only thing a catalyst can do, as was pointed out, is accelerate both forwards and backwards processes in the reaction. Processing the reaction. The way these phosphatase kinase networks work is that the phosphorylation pathway is a phosphate group is taken from ATP and added to the downstream protein. And what the kinase does is accelerate both doing that forwards and doing that backwards, right? So both adding a phosphate from ATP. Adding a phosphate from ATP to your readout and removing that phosphate and giving it back to ATP. However, that's not the only way to switch between those two activation states. The other way to switch between those two activation states is just to release the phosphate into solution or get it directly from solution. So the phosphatase accelerates the interchange of phosphate with solution and the Solution and the kinase accelerates the interchange of phosphate with ATP. And both of those processes, one of those processes is downstream in one direction, and one of them is downstream in the other direction, because when you go around in a full cycle, you've hydrolyzed an ATP, which is incredibly favorable free energetically speaking. So, the presence of the kinase, what it does for you is it really ramps up both. Both of these reactions, both the forwards and backwards reactions associated with taking an ATP, a phosphate from ATP and giving it to your downstream readout. But because one of those reactions is miles faster than the other, that's effectively all you see. Similarly, the phosphatase accelerates both the giving phosphate back to solution. Giving phosphate back to solution and binding phosphate from solution. But because binding phosphate from solution is so much less favourable than giving it back to solution, you only really see the phosphatase dephosphorylating. So you get these cycles and you get the ability to turn on or turn off, but you only get that because these two processes are actually microscopically different from each other. And in going around a circle, Going round a circle back to the start, you've burnt one molecule of ATP. Is that roughly answering the question? He says, got it, yes. Brilliant. Okay, so that's how it works for a signaling cascade. How does it work? Why is it important for templating? So in a human cell, there are about 10. In a human cell, there are about 10 to the four distinct proteins with completely different structures and completely different sequences of amino acids making up those structures. Those 10 to the four proteins are made from 20 amino acids, 20 distinct types of amino acids that are just effectively floating around free in solution. So if you hoped to mix 20 unique types of components in a pool, Types of components in a pool, and then get 10 to the four specific things assembling out of them without anything else, with no other junk. That would be like putting a load of Lego bricks in a washing machine and hoping to get a model of London out at the end. There just isn't enough information in 20 building blocks to give you precisely 10 to the four different assembled products. And indeed, Products. And indeed, that sort of question of how many distinct products are available from a given set of building blocks is something that's been studied by Stanislaus-Leiba and his group. There's a reference down there to it. So basically, you couldn't make proteins just from the amino acids. It would be impossible. Of course, biology doesn't do that. It uses this central dogma that I talked about before. Dogma that I talked about before to template the sequence of amino acids using RNA and eventually the DNA sequence. So the RNA in this context is really just an intermediary messenger. There's a sequence in the DNA template that is used to direct the assembly of the protein of the amino acids into the right sequence. And when you've done that, there is then enough information that they can. Enough information that they can fold into the structure that you need because you've already chosen the reactants, the component, and the order in which they appear in this. So templating is used to make proteins from DNA. This won't be surprising anyone, but somehow I think it's often undersold that these things must act catalytically. For a start, it's no use if your protein stays stuck to your polynucleotide, it needs to detach and go. Nucleotide, it needs to detach and go off and have an independent existence and do whatever the protein is supposed to do. But arguably, more deeply, if you can't reuse the templates having made your protein, if and remember in this case, RNA is just really an intermediary messenger, and we could imagine that we were making the protein directly from the DNA. If you couldn't reuse the DNA sequence to make another copy of the protein, then every Of the protein, then every time you wanted a new protein, you'd have to make a new DNA from scratch. And that's actually harder than making the protein because you've only got four ingredients for your DNA and it needs to be three times as long. So you'd have actually made the problem worse if the DNA wasn't acting as a catalyst. So fundamentally, without templates acting as catalysts, you can't solve. Can't solve the problem of biological complexity. So I would argue that this is the most important class of process in living systems. And I think to some extent, people haven't really thought about it very much from this perspective. But when you do, you get some really interesting things coming out. Okay, so hopefully I've convinced people that. People that some processes in living systems are catalytic, and it's important that they are. So, now I'm going to talk about why catalytic systems are really hard to design and build. So, the whole point of the processes I described to you before, both the templated production of polymers and the signaling architectures, is that Is that what you're trying to do is correlate the state of one set of molecules with the state of another set of molecules? So, in the case of the signaling, you're trying to correlate the state of the receptor with the, or the state of the readout with that of the receptor. In the case of the templated copying, you're trying to correlate the state of templates, which I've represented as three-side templates in this case, red, blue, red, with the state of Red with the state of a load of products, daughter polymers, which in this case are also red, blue, red. And when I say correlate, what I mean is that in principle, I could have red, blue, red, and then produce loads of other red, blue, reds. But if instead my templates are blue, blue, red, I produce blue, blue, red. So in principle, the template sequence could be anything, and I need to be able to produce any. To produce any daughter polymers as a consequence. So the sequences, there's some distribution of these copy sequences, but they're strongly correlated with the distribution of templates that are present in the system. So what does this actually mean thermodynamically? Well, to do that, we need to go a bit more formal, and I'm going to be leveraging a lot of what Udo and Massimiliano said over the last two days. Said over the last two days. So, as Udo described, I'm going to be working at the macrostate level, which I've kind of been doing informally already, which is that I'm kind of going to be describing things like polymers as blue, blue, red or red, blue, red, which might correspond to AAT or TAT as a sequence in a polynucleotide. Now, for a given set of Set of for a given sequence, there are multiple possible microscopic configurations, which I'd call microstates. But what I'm doing is I'm lumping all of those microstates into one macrostate or another, which is this sequence or that sequence. So, in general, the system will be in some distribution of microscopic configurations. Distribution of microscopic configurations, PY. So it's a probability distribution of microscopic configurations. And in general, that won't be equal to the equilibrium distribution, which is just given by the Boltzmann distribution here. However, what I am going to assume, and again, Udo covered this in his talk, is that these macrostates are well defined in the sense that there's a separation of time scales, so the system equilibrates effectively within the Effectively within the microstates of one macrostate, but doesn't equilibrate between the macrostates. So, formally speaking, what I'm saying is that given that I'm in a macrostate M, the Y states are distributed according to the Boltzmann distribution, but I can't guarantee that two microstates corresponding to different macrostates are in equilibrium. What this means is that the probability distribution of the macrostates is the key quantity, and that tells Is the key quantity, and that tells me whether I'm in equilibrium and how far away I am. Okay, so in general, the distribution over macrostates, i.e., what's the probability I'm in blue-blue-red rather than red-blue-red or any other sequence, in general, that won't be equal to the equilibrium distribution. And the equilibrium distribution is again just given by a Boltzmann factor. But here, instead of the energy as a function of the coordinate, you've got The coordinate, you've got the macrostate free energy, which is just the combination of the energy within that macrostate, the typical energy within that macrostate. So are the configurations of blue, blue, red, are they low in energy or not? And if they are, G is low and that makes you very common in equilibrium. But also a contribution from the entropy. So effectively, how many microscopic configurations are there? Microscopic configurations are there within the macroscopic one, blue, blue, red. If there are a lot of microscopic configurations, that gives a positive contribution to the entropy. And that makes it positive contribution to the entropy of the macrostate, which makes the free energy lower and again makes it more common in equilibrium. So you've got the average energy and the number of states, basically. Of states, basically. And again, I don't think this should surprise anybody too much who's familiar with biochemistry. Okay, so perhaps slightly taking a step further is to say, I now want to not just talk about the free energy of a given macrostate, I want to talk about the free energy of the whole distribution over macrostate. So I want to say what is the average energy. What is the average energy of the system given the probability of being in state blue, blue, red, state red, blue, red, et cetera, minus temperature times the entropy. So how uncertain, how many states am I occupying? Now, the average energy is just given by taking the probability that I'm in a macroscopic configuration and multiplying by the energy of that macroscopic configuration, nothing special. But the entropy. But the entropy splits into two terms. One of them is the entropy arising from the average entropy of the microstates. So it's basically saying if I'm in macrostates which have a lot of microscopic freedom, then I have a lot of entropy in my system. I have a lot of uncertainty. But there's another more interesting term, which is this one here, this third term. This one here, this third term, and that is the entropy that arises from uncertainty over which macroscopic configuration I'm in. So, this first term is the term that corresponds to how much microscopic wiggle do I have given that I'm in blue, blue, red. And this second term corresponds to how certain am I that I'm in blue, blue, red rather than blue, red, blue, red, blue, blue, etc. So this second one is really. So, this second one is really the informational thing that we're interested in. It tells us how much information is there in the sequences that are present in the system. So, we can rewrite this as what I typically call a chemical free energy. So, how much chemical free energy is there in the system? And this is what you'd be very used to from biology in terms of talking about the chemical free energy of a bond. Chemical free energy of a bond. Chemical free energy of a bond favoured by low energies, disfavored by the fact that the microscopic configurations are restricted because the things are stuck together. This is just the normal chemical-free energy. The second term, this is the entropy due to the uncertainty over macrostates. And this is basically it's small when you're very certain about the macroscopic configuration you're in. The macroscopic configuration you're in, and it's large if you're very unsettled. So, why is this generalized free energy useful? Well, it turns out that, and again, this was touched on by Massimiliano, is that if you're only in contact with a thermal reservoir, i.e. if you're not being pumped, if you're not being continuously supplied with fuel, your free energy, your generalized free energy, can only decrease with time. This is the second law of third dynamics. This is the second law of thermodynamics in this context. So, what that means is that generalized free energy is minimized by the equilibrium distribution over macrostates. So, that equilibrium distribution could be fairly flat. So, if all of the chemical free energies of all of these different macroscopic configurations are roughly similar, then Then the system will say, okay, all of these are pretty much equally favorable and will spread as much probability as possible over the different states. You'll end up with a fairly flat probability distribution. However, if one of them, say this one, has a much lower chemical free energy than all the others, the system will tend to occupy that configuration. So basically, you can pay for a low entropy. Pay for a low entropy with a low chemical free energy. And again, that probably, hopefully, that doesn't surprise people too much. But the slight difference here is that we're talking about this sort of informational entropy, which is related to which macroscopic configuration you're in. And the actual microscopic entropy associated with the individual degrees of freedom has kind of been all swallowed up into this chemical energy. Been all swallowed up into this chemical for energy path. All right, so in catalytic copying, we create correlations between inputs and outputs. So this means that the entropy is low. There's low uncertainty in the state, because we can have states that look like this, or we can have states that look like that, but we can't have states, or we tend not to have states, where the product sequences aren't tightly related to the template sequences. To the template sequences. So we've got a low entropy. However, there's no direct physical interaction between the templates and the copies. As I said before, they're catalytic. At the end of the process, the copy have got to detach. They've got to go off and have their own existence. That's not only what actually happens in the cell, but it's actually fundamental to how these processes need to work. Okay, so there can't be a direct physical interaction. Be a direct physical interaction. And if there is no direct physical interaction, what that means is that the chemical free energy can't be more favorable in this state than in that state, systematically, because there is no interaction between this template and this product. And therefore, there's no reason why the correct sequence that you want needs to be favored in equilibrium. So the conclusion. So, the conclusion, and this is really the one thing to remember from my talk, is that these catalytic information processing systems, they produce states that are really far from equilibrium. And when I say really far from equilibrium, I mean at the macro state level, about as far from equilibrium as you could possibly imagine. The RNA, the production of an RNA sequence from its DNA. Sequence from its DNA, let's say it's, I don't know, 100 bases long, which is a short piece of RNA. Typically speaking, that sequence will be produced in a cell with pretty high accuracy, order 100% of the sequences are correct. And so they've managed to pick one sequence from four to the power 100. Power 100, and there's no reason why that one sequence is actually any more energetically favorable than any of the others from that distribution. So that is stunningly far from equilibrium. And my argument is that you really can't think about the properties of these processes without taking that into account. And I would make the case that in the past, people have tended to study these systems and ignore that fact. And that And that's why I'd argue we're in a position where we can't actually build catalytic information processing systems, as we'll explore in a second. Okay, so ordinarily, I would now dive very deeply into the thermodynamics of non-equilibrium correlations in molecular systems and also get into a load of fights about the interpretation of Maxwell's demon and Szilard's engine. And Szilard's engine. But today I want to focus a bit more on the sort of like the practicalities of what I've just said rather than the fundamental physics. But here are a load of references which I've shared the slides, so hopefully everyone can see them if they need to. I'd like to highlight Rory, who I think is in the audience today, and Jenny, two of my students who did a lot of this work. Okay, so. So, in recent years, we've got really good at engineering self-assembling molecular systems. And my background is in DNA nanotechnology. And in DNA nanotechnology, what you can do is you say, I want to build a structure of a given shape. You sit down either with a pen and paper or a CAD tool like CAD Nano. You draw your shape. You work out a load of sequences of DNA strands. Of DNA strands that are complementary in such a way that they'll tend to form that shape in equilibrium. You mix them up in a pot and you cool it down and the shape comes out at the end for you, exactly as you want it. And people have been able to assemble remarkably complicated things in this way. I don't know how, hopefully these structures here, these are real electron microscopy. Microscopy images of assembled structures, right? These aren't pictures. So they're able to assemble, this is a picture, this is the assembled structure. So self-assembly, really impressive, particularly with DNA, because we can specify, we know so well that A will stick to T and G will stick to C, we can specify the assembled structure with such precision. Harder with proteins, but David Baker's group in recent years. But David Baker's group in recent years have been making progress in that direction and have assembled some pretty complex structures through rationally designed protein self-assembly. And it should be noted that although typically to get the best yield, people tend to do a temperature ramp so that you go through the exact assembly point at the right time. If you're careful enough, you can also assemble complex structures at constant temperature. So you really can. Constant temperature. So you really can put a load of ingredients in a pot and watch them assemble into one of these complex structures. And these structures arguably resemble the complexity and size of the things that cells can assemble in equilibrium as well. So sort of virus capsids and things like that. We can basically make things that are as complicated as that, if not more complicated. So we're really good at self-assembly, but A self-assembly, but there are very few synthetic catalytic information processing systems coming out of the same research. And I would, you might ask why, especially if you believe my argument of the first half of this talk, that actually catalytic information processing is the really fundamental thing that biology does that enables it to be interesting. And my answer is they're hard to engineer because you need Engineer because you need strong selectively attractive interactions for the things to act as catalysts and act as catalysts for the right sequence. So you want to template the assembly of the right RNA, not the wrong RNA. But then these strong selectively attractive interactions, you need to disrupt them later on. And that's the practical statement that the eventual product needs to be out of equilibrium. And that just makes it so much harder than. It's so much harder than being able to mix things together and let them fall to an equilibrium. So, and this problem is worst for polymerization. So, if you want to make one of these polymer copies, like in RNA or DNA templating. So, what happens, let's say, and you could do this very easily with DNA nanotechnology, you could create a monomer template that is complementary to some other monomers in. Some other monomers in solution, and they stick to the template. And because they're stuck to the template, they're close to their neighbors, they bind to their neighbors, they polymerize, and they form a ladder here, where the daughter has the same sequence as the template. And this, loads of people have done this. This is quite easy. It's effectively self-assembly. But at this point, the daughter polymer is cooperatively stuck to the template. The template. There are six bonds here, and you only gain one entropic degree of freedom when you detach from the template. So it really is stuck very strongly. And this tendency of the copies to stick to the template is called product inhibition in the trade. And basically, people haven't really come up with chemical ways to get around the problem. Instead, they'll use things like heat cycling to break these interactions. Break these interactions. Okay, so it's now 45 minutes. Do I have 10 minutes more? I mean, we've kind of stopped for a couple of questions. Is that okay? That's fine with me. We're scheduled to have a half an hour open discussion, but I mean, we can certainly continue into that. So please go ahead. Yeah, okay, great. And please do continue to ask. So first of all, I want to briefly mention some work. Briefly, mention some work by a former PhD student, Abhishek Despande, who's now in Wisconsin, who asked a very simple question about: okay, if I want to build a catalyst, how do I design a catalyst so that this product inhibition effectively is minimized? And here's a very simple model of a catalyst. You've got the catalyst and the substrate, they bind, the substrate gets converted into the product, and then it gets released. Into the product, and then it gets released. And all of these steps, in principle, are reversible because we want to be able to do the thermodynamics. Okay, so he said, question is, given an overall free energy budget, i.e. an overall change in free energy from going from this state to that state, and reactions that are diffusion controlled, so the binding, these two binding reactions, they're diffusion controlled, so they have a fixed rate, rate constant anyway. Break constant, anyway. How can I design my catalyst in the sense of changing the energies of the intermediate substrate and product bound states? How can I change them to be optimal so that the catalyst has a high flux, i.e., converts as many substrates into products as possible, whilst minimizing the amount of time that I spend in these intervals. Of time that I spend in these intermediate sequestered states. So, how do I get as catalytic as possible in some sense? Okay, and we apply thermodynamic constraints, so the overall free energy change is set, and we talk about moving these intermediate states up and down, the substrate bound and the product round. And we apply the rule that the forwards and the backwards transitions are related by the Transitions are related by the first talks we saw this week. So this system, if you've got isolated enzymes, you can analyze each enzyme as a three-state system, which can either be substrate-bound, product bound, or free. And the transitions, here's a diffusion-limited binding of the substrate and release of the substrate, and that's related. Release of the substrate, and that's related by the chemical free energy of the bond. The only subtlety we have is that the conversion between the product and the substrate, you need to make some statement about some maximal rate there. If you allow one of these reactions, this substrate to product conversion to be infinitely fast, then you get pathological answers, which just says make your enzyme infinitely fast. But if you say that there's some fundamental If you say that there's some fundamental limit, either the forwards reaction or the backwards reaction goes at that speed limit, and the other one is slowed down according to this delta G rule, then you can ask sensible questions. And so, what you can do is you can solve this system, it's pretty simple, and you can analyze the flux, i.e., the net tendency, the net. The net tendency, the net current for the system to go around a cycle like this, E, E, S, E, P, back to E, and the sequestration in terms of first passage times of the processes. And what you can, in fact, show is that if you do this and you want to minimize sequestration, i.e., the amount of time you spend in either this state or this state, rather than free, if you want to. Rather than free, if you want to minimize sequestration, what you end up doing, sorry, I'm just going to take a drink, what you end up doing is moving towards this line of solutions, which are a fixed offset between the energy of the product bound state and the energy of the substrate bound state. Amos, we have a question from the audience. Go on. The question is: can you please explain? The question is, can you please explain again how E is at the two different delta G levels at right and left of the reaction coordinate diagram? Okay, yes. So there's something implicit in this figure, which is that at the end of this process, there's one more product and one fewer substrate in the universe. And there's a free energy change associated with that, which is some intrinsic free energy change delta. Some intrinsic free energy change delta mu plus a log of concentration ratio substrate to product. So really, yeah, this would be like n substrates and m products, and this would be n minus one substrates and m plus one products. And this implicitly having something pushing you around a cycle is kind of exactly what we had with the ATP at the start. Is that okay? Sounds good to me. Yep, the questioner says good. Good. Okay. So, so what happens is that your sorry, just sorry, just to quickly interrupt again, another question just popped up. This is more of a statement, which is the figure should start with E plus S and end at E plus P. Yes. We, from the perspective of our system, we are treating it a bit like Massimiliano was with just saying what's the state of the enzyme. And the state of the enzyme is E in that configuration. But yeah, I mean, there are different formalisms that you could use. Agreed. Sounds good. This isn't the most unambiguous presentation of the figure. Of the figure. Okay, so yes. So, what happens if you target a certain flux, you say, okay, I need to achieve a certain flux with this, and that's what this psi is. Don't need to worry too much, but if I'm targeting a certain flux, then I reach some point on this line. All of my solutions are on this line, which is a constant offset between the energy of the product bound straight and the energy of the substrate bound state. Bound state and the energy of the substrate bound state. And the offset between those states is exactly this intrinsic free energy difference between the substrate and the product. So there are lots of things you can delve into about this result and exactly how we get to it. It's quite interesting. But the real physics that's coming out of here is saying the optimal strategy is to take this intrinsic free energy change that you get from converting your substrate into the product. Converting your substrate into the product, and use it to pay to make the product-bound state less stably bound than the substrate is. So what that means is that you can quickly unbind your product once you've had the reaction. But the really nice thing that comes out of this admittedly very simple model is that it's exactly the overall The overall intrinsic free energy drive that you should be using to do that. If you want to design an optimal enzyme that minimizes sequestration. So what I'd like to do in the final part of my talk is talk about trying to use that insight to design a synthetic system for propagating information via catalytic assembly on a template. Catalytic assembly on a template. And so this is Javi's work, and it's recently appeared on BioRxive. Although I noticed that I actually cut off the citation there, but yeah, it's on BioRxive. And there's a reaction again, my background is DNA nanotechnology. And so this is based on DNA nanotechnology. And in DNA nanotechnology, if you want to design a dynamic system where things are evolving over time, you use a Over time, you use a type of reaction called toehold-mediated strand displacement. So you start off with a duplex labeled T and N, target and incumbent. And the target has an overhanging toehold of bases, which typically is about six bases long. And then you have an invader that's complementary to the whole of the target, and it combines to the toe hold, competes with the incumbent. With the incumbent for binding to the target, and then basically pull the target off the incumbent. And by embedding this toehog mediated strand displacement reaction in more complicated contexts, you can actually build sort of Turing-complete complicated reaction networks. I'm not going to go into the details here, but that's the essence. The important point here is that what you have is recognition-based process, right? Recognition-based process, right? You have the toe hold is providing the recognition for you, a bit like the way a template provides the recognition for the assembly of these polymers in the molecular dogma, the central dogma of molecular biology. But in this case, at the end of the press, the toe hold is here, and if I Is here, and the final bound domains are next to them. So they're behaving very cooperatively. So fundamentally, the recognition domain is going to be used up by this process. You're never going to be able to use toehold mediated strand displacement to perform a recognition interaction where that recognition interaction subsequently breaks. And if you remember, I was arguing that that's really what made copy. Really, what made copying of polymers and so on hard is that you need to have a recognition interaction that later on in the process breaks so that you recover your product at the end of the process. Now, what Havi is working on is an alternative scheme called handhold-mediated strand displacement. And the idea here is that primarily reactions are instead driven by a handhold in the incumbent, which is reckoned. The incumbent, which is recognized by the invader. The invader binds to that handhold and then starts competing with the incumbent for binding to the target. So what's happening here, this is our product formation step. This is going from substrate to product. And what's happening is the formation of the product is involving us ripping the toe hole, the thing we want to bind to, off the incumbent, off the... The off the incumbent, off the template. So, the formation reaction, the polymerization reaction, if you will, we're using the free energy of the process to weaken our binding with the template, which is exactly the insight that we got from Abhishek's work. We should divert the free energy, the downhill free energy of the reaction into weakening our binding to the substrate. To the substrate, not so the template. Okay, and so Javi has monitored the pro, he's been able to study a whole range of system designs varying the toe hold length, hand hold length, etc. And what he's been able to do, you can basically monitor the formation of these products in solution. And that's what I've plotted here. So this is just one. I've plotted here. So, this is just one particular system at different concentrations, and he's able to model them very precisely. So, we feel we have a very good idea about what's going on. And what he's been able to show is that as he makes his handhold longer for a given length of small toe hold here, he makes his reaction much, much faster. So, this is the ratio of the half-life for an invading strand with a handhold compared to one. With a handhold compared to one that doesn't have a handhold. So he's able to make the handhold, he's able to make the reaction four orders of magnitude faster than if he didn't have a handhold at all for short lengths of these turbons. So he's able to accelerate the reaction. He's able to demonstrate that the formation of this blue-green complex is faster. What we also need to do is demonstrate that actually this recognition. Actually, this recognition interaction can be transitory, can break after the product is formed. And yes, let's just look at the top one of these two figures. He has another fluorescent reporting device, which this time will only react if it sees a target and an invader complex that is free in solution rather than bound still bound to the incumbent. And what he's able to show is that if his handhold was really long, Is that if his handhold was really long, 20 nucleotides, this reporter wasn't triggered because the thing never detaches, the handhold is too strong, the recognition interaction is too strong. However, the shorter recognition interactions, he sees release of the product. So he's able to use the handhold to template the formation of the product, but then the handhold breaks and the product is released and is able to have an independent existence from the Existence from the incumbent endpoint. So the final thing he did was then to say, okay, can I use that to generate a non-equilibrium ensemble of complexes? So he started out with all three invaders. So all three of these strands, or three different types of these strands, all with a different handhold, and reporters for each of those strands. And he put in And he put in templates for one handhold, or another handhold, or another one, and he was able to see essentially perfect formation of the desired complex. And what I want to emphasize about these results is that the duplex that's forming in the end is equal stability, whether it's the first type of invader, the second type of invader, or the third type. They're not distinguished by their chemical free energy. Free energy, they're equally stable, they're just driven by this transitory templating interaction. So we really have taken like the first step towards generating a non-equilibrium ensemble of outputs, which as I argued before is at the very basic level what the copying of a polymer is doing in biology. Okay, so that's basically it. Where we'd like to go next is to really Next, is to really use this reaction to build a genuinely catalytic system for dimerization. So, here we kind of did the second half of the process, but we didn't do the initial recognition of the first half of the dimer. And then we'd like to go on to longer templates. So, can we really build things that copy information in a sequence of length three, four, five, six, and so on? And then there's a whole host of other interesting questions we can ask. Other interesting questions we can ask. Okay, so thanks to all of you for listening. Thanks to people in my group at Imperial, Peter Rine and his group, Nick Jones, Guy Bart, Andrew and their groups. Thank you. Thank you very much, Thomas, for a very stimulating, interesting talk. We have approximately, by the schedule, we have approximately 15 minutes for questions, but what's after that is just a break. That is just a break, so we can keep questions open for 20-25 minutes or so. With that, I'll sit here and moderate lightly, but I think the practice in other talks has been to simply allow people to ask questions without my intervention. So please feel free to unmute and ask your question. And ask your question. I see two questions just came up on the screen. Perhaps Christina can go first. Yes. Just start up my video. Yes. While you're getting ready, Christina, let me just say, if you would prefer, if anyone would prefer me to ask the question on your behalf, just type it in the chat window and ask. It in the chat window and ask and make a statement to that effect. Yeah, no problem. So, I'm just wondering for the model DNA system that you were showing at the end, what the equivalent of the VADA is for the biological system of RNA synthesis in transcription. Okay, so yes, it's a very important question. So, effectively, if I go back to if we go. If we go, if I go back to here, yeah, this will do. So we are using whole strands of DNA to stand for one information-bearing unit. So 10 to 20 nucleotides is our one information-bearing unit, as opposed to one nucleotide or three in the case of translation, but for transcription, one. Translation, but for transcription, one nucleotide. So the invader would be interpreted as the next nucleotide that's being added to the process. And what we want to do eventually is build something that looks a bit like when you have RNA polymerase, right, going along a chain, we want to do it without an RNA polymerase. But what you have is you have the DNA duplex, right? Is you have the DNA duplex, right? And then you have a growing single strand of RNA coming off it, which is only attached essentially by its leading edge to the template, right? Yeah, yeah, that's correct, yeah. Yeah, and so what we want to do is recreate that sort of thing, but each single strand coming in is the equivalent of one nucleotide. And when the new single strand binds, it rips the one behind it off the template, and the whole thing takes a step forward. So you can see that you. Takes a step forward. So you can see that you grow a longer and longer tail as the leading edge moves forward. Yeah, okay. Yeah, that makes sense now. Just out of curiosity, is there a reason that you went for modeling it like a whole entire piece of DNA as opposed to like shorter sequences or even single nucleotides? So the reason we're using DNA is because we're able to rationally engineer interactions with DNA. So With DNA. So we're able, I'm able to, and I am not any good at chemistry, right? I am able to design things to interact with one thing and then interact slightly more strongly with another thing and then grab something else in a way that I just can't do. And I don't think even really good chemists can do with much smaller molecules. So obviously nature has found a way to do that through a lot of trial and A lot of trial and error basically, but what working at the level of whole strands enables us to do is to rational design of these things. Yeah, okay. But yeah, the fact that it happens to be the genetic thing in cells is, I wouldn't quite say coincidence, but it's not what we're using it for. We're just using it as a selectively sticky molecule. So if you were able to give me another So, if you were able to give me another selectively sticky molecule, I'd be very happy. And what I'd want to do eventually is when we've really understood the constraints under which these systems operate, is go to some good organic chemists and say, okay, this is what I need some molecules to do. Can you find some that will do that for me? But it's easier to tinker and find out what you need. And find out what you need at the level where at the using whole DNA strands. Yeah, sure, makes sense. Maybe one last question, and then I'll leave the floor to someone else. And that's about the kinetic proofreading. Whether you already have any ideas on how to implement this with the strand displacement strategy that you are using. Yes, so Rakesh, who's actually, I think, on this call, that's his project at the moment. And so the essential idea. The essential idea is you can see my, you can see the talk, right? Yeah, I can see the talk is. Yeah, yeah. So the essential idea is that when the invader binds, that it opens up a region that was previously hidden. So this invader would initially actually be bound to a blocking strand and it opens up a little toe hold at the end. opens up a little toe hold at the end and then that is that gives the opportunity for a kind of like a proofreading molecule that's hanging around in solution to come in and and and and and rip it back off again um in a way that is dependent on how strongly it is initially bound to the template right so that gives you like rod rate yeah yeah um and so yeah the key point is does that enable you to get discrimination both at the initial binding Both at the initial binding stage, which we should be able to do fairly easily, but also getting the discrimination at that second stage that is sensitive to how strongly the thing is bound to the template. That's one of these key tinkering things that you have the opportunity to do with DNA nanotech. Yeah, no, sounds like a really cool project. Thanks. I have a question that's been sent to me privately, and I've been asked to ask it. The question is. The question is: Does sequestration give a strategy for binding the RNA of a pathogen, such as, say, a virus? Well, in the sense of would you use sequestration during the RNAs acting as a catalyst? I guess what you could do is design. Is design if you were able to, for example, screw up the translation process of some viral RNA so that it didn't got stuck, basically. Maybe that would stop so many of your RNA getting reproduced. I mean, certainly binding to your RNA strand and then dugging something. And then and then and then dubbing something to it is a strategy that um that uh I mean that's how CRISPR works, right? Think so so it's just just using binding to to trigger some kind of downstream process that that renders the invading sequence harmless is a common strategy. The question of could you screw up Could you screw up the templated copying that the RNA is trying to do so that it gets stuck? I don't know if anything does that. I mean, it sounds like a more complicated way to try and do the same thing. Don't know if that answers your question. Hey. Really nice talk. This is David Savak. So, your idea about this challenge of catalysis being that you don't want to be stuck to Analysis being that you don't want to be stuck to your product at the end of the day. I mean, I was thinking in terms of, I don't know, sort of classic enzymology, you think about selectively binding the transition state rather than the product itself. And so is that, is that, how does that relate to the point you're making here? And are there like special challenges for these template-mediated polymerization reactions that you want to? Yes, I mean, somehow in the discussion that I was given, we kind of assumed a certain thing about. kind of assumed a certain thing about we kind of assumed that the transition state was down to detailed chemistry and was was kind of fixed and all you could tune was the the size of the wells on the other side um but fundamentally if you if you you have to go through the product is bound to the enzyme step and if you make it really really unstable a you really really don't A, you really, really don't want to bind to the product, then you're never going to get to that state in the first place. You make it too far uphill to go forwards. It will just stay in the initial state. And if you make it too far downhill, then the product stays stuck to you, and that's product inhibition. And the answer that Abhishek got out was somehow quantifying exactly the fact that there's a sweet spot in the middle of votes. The fact that there's a sweet spot in the middle of focus. But yeah, like in all cases, if you can make your transition state lower, you make your job easier. But even no matter how low your transition state is, that question of how strongly do you want to stay bound to the product is still relevant. Yeah, and maybe a relationship. Yeah, I had maybe a related question. So where did you use this theoretical knowledge in this practical experiment? It's just this central idea, which is the way that this mechanism works is that one, like you can think of, if you, if you can you see my cursor at the moment? I could, yes, I still. Yes. So this, although we haven't quite got there, like Although we haven't quite got there like this, you could imagine that this is the initial state of an enzyme that wants to bind to two substrates, join them together and release them, right? Which is in fact exactly what aminoacyl tRNA synthases do. I think that's the correct word. So another incredibly important process in biology, right? But so what the interpretation of Abhishek's work is. Interpretation of Abhishek's work is: it says that this step, what you want, you want to use the joining together step, you want to weaken the interaction with the template. And that's exactly what happens, right? Because it grabs the blue one and then pulls it off. Now, a more traditional approach in DNA nanotechnology would be to have the green and the blue thing stuck next to each other, and then they bind to each other, but not in a way that the blue thing. Not in a way that the blue thing gets ripped off the template. And that is the fundamental novelty of our approach, is that the polymerization, the dimerization reaction weakens the interaction with the template. And that was the theoretical insight from Abhishek's paper that's been carried over. Does that answer your question? Yeah, yeah, yeah, yeah. Thanks. Are there any other questions? Hearing none, thank you once again, Thomas, for an outstanding and very interesting talk. Thanks for the questions. Yeah, very great discussion, too. So I was very pleased with that. Pleased with that. Our next, so right now we actually have a scheduled break until the scheduled break will be until 9:30.