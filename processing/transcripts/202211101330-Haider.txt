Metagenomic microbial communities. I'm happy to welcome our first speaker, Diana Hayter from Dalhousie University, about quality thresholds and mock microbial community. So please take it away, Diana. Yes. Hi. Let me just move my screen. All right. Perfect. So hi, everyone. First of all, thank you for inviting me to talk. I didn't realize this in my life. I didn't realize there was a microbiome section, so that's quite interesting. I'm a PhD student in the Department of Biology at Dalhousie University, and today I'll talk about how selecting different quality thresholds for amplicon sequencing largely impacts the interpretation of various measurements such as taxonomy and relative abundances of mock microbial communities. So, you'll notice that my focus is a little bit earlier in the process than many of the very Earlier in the process than many of the various talks you've heard so far, I'm more interested in investigating the robustness, reproducibility, parameter sensitivity of the various workflows that generate some of the data that some of you are going to use after for modeling and analysis. So I'm not so much in that part, but more in the pipeline part. So more a little bit further, a little bit before. Sorry. So I'll start off by making honest, by talking about the microbiome association with various The microbiome association with various health outcomes. On this plot, what we're seeing on the y-axis is the cumulative PubMed entries on the x-axis, the year, and the different lines represent different phenotypes. And what basically we're able to observe on this plot is that from the last 20 years, the number of publications with the query microbiome and any of these different phenotypes has increased a lot, allowing researchers to establish a pretty clear link between the microbiome and health. And what's making Microbiome in health. And what's making this a bit more interesting is that we're not only linking the microbiome with these different health phenotypes, but more specifically, researchers have been able to identify specific microorganisms that are going to influence these different phenotypes throughout the body. And amongst these, we have the modulations of different metabolic outcomes that are caused by microbes. We have android diseases that are caused, for example, by C. diff or different strains of E. coli. They can Different strains of E. coli that are going to be associated with different phenotypes, and also various chronic conditions like colorectal cancer, which has been linked to different strains of porphyromonas and IBD inflammatory bowel disease that also has been linked to specific gut microorganisms. So, we have this link of microbiome to health, but more specifically, specific microorganisms to different phenotype health outcomes. Health outcomes. And even if, so if we go a bit more in details, we have microorganisms, but we also have capable of identifying phenotype association with strain-specific microbes. So if we look at this figure E right here, we're seeing that we have this phylogenetic tree of species. But if we look at one specific species and look at the phylogeny of the strains within this clade of species, we're able to see that. Clade of species, we're able to see that different strains are going to generate different phenotypes in different individuals. And furthermore, each of these different phenotypes are also going to be differentially impacting the outcome in health and individuals, depending on whether or not they're present, or also depending on the species abundance. So, we can see how important it can be to identify which species are present and how important it can be to go down. Presence and how important it can be to go down to the strain level, and also how it's important to understand what are the abundances of the different strains that are present in a microbiome. And what's also great is that we have had different, we've developed methods using high throughput and often culture independent techniques. So, omics techniques to try to understand that better. And amongst those techniques, there's a bunch that exist and are readily used. That exists and are readily used to identify different strains and microbiome communities. So, we have amplicon sequencing, metagenomics, metatranscriptomics, proteomics, and all of these great omics methods that have been talked about a little bit earlier. And my focus is going to be on the use of amplicon sequencing, which is selecting a specific marker gene of interest for studying a microbial community. And we'll try to understand how we can get near-strain identification for specific microbial communities. Specific microbial communities using amplicon sequencing. Great. So if I think about microbiome analysis, I'm going to go step by step, trying to go step by step into understanding how we analyze the microbiome and what specifically is a question of interest in my case. So let's suppose we have a microbiome we're interested in. We're going to collect a sample from this environment, extract the DNA from it, proceed with amplification of a specific region of interest. Of a specific region of interest. Once we got our region of interest, we're going to sequence it. And once we got our sequences back, that's when we dive into all the bioinformatics analysis. So clustering our reads into taxonomic or functional clusters and then diving into the diversity to understand who's present and in which abundances. But unfortunately, what we do know is that microbiome analysis is biased. So at each of these steps, there are different aspects of the step that can induce. Of the step that can induce biases in the study, and one main aspect that my research is interested in is understanding what these biases are and how can we quantify them. So, better understanding them to quantify them and then correct for them once we know what these biases are. So, for example, if we think of the DNA extraction step, we can get biases introduced depending on the different cells in the microbiome. So, how easily are the cells going to be lyzed, and what is going to be the DNA yield from each of these cells? Going to be the DNA yield from each of these cells that are in your sample. At the amplification step, you get primer bias. So, depending on which primer you're going to use, you will have different taxon that are going to be differentially represented in your final community. And also, depending on the gene that you're using, so here I just use 6NS as an example, but depending on which gene you're using, the copy number is also going to be impacting what representation you get of diversity. And finally, the bioinformatic step, which is what I'm interested in. The bioinformatics step, which is what I'm interested in, you get a lot of biases depending on how your reads are filtered, which methods you're using. So, we've discussed about methods before, so we know how difficult it is to figure out algorithmic method amongst all the methods that exist. And also, how are you going to normalize the reads that you have? So one thing to keep in mind also is that if we have a poor data set, so we start with a sequencing data set that is poor and we're not filtering it properly. Poor, and we're not filtering it properly, and we can have the best perfect model ever, but we're still going to get poor predictions if we're not able to filter our data set properly. So, um, I think that's why it's pretty important to try to understand where our data comes from, what are the biases that are introduced in our data, and how can we make better use of our data to give better predictions. So, the outline of the talk today, I'll talk about if there's really a problem in microbiome studies, what are approaches to tackle the bioinformatics. Tackle the bifurmatic biases. Some of the observations we're making in terms of taxonomy and in terms of relative abundances for our abundant in rare taxa present in our communities and some insights for future work. So, first of all, is there really a problem? So, let's assume that we have a community of a micro. A community of a microbiome of known communities. So, a mock community is a community that is artificially made in a lab from which we know the composition. And usually, those are used for benchmarking. So, you want to want to use that because you know what you're expecting. Therefore, you're able to play around with your parameters and your steps to understand how they're going to impact your final results. So, let's assume we start with a mock community of known composition, which would be composed of these three taxa, the green one, the orange one, and the blue one, and even proportion. One and the blue one, and even proportions. Let's assume we go through all the steps that I was talking earlier. We extract them, amplify, sequence, go through the bioinformatics step. And what we're seeing in the end is that usually what we're getting is a really distorted view of the actual community. So unfortunately, we see that some of the groups are going to be overrepresented, other ones are underrepresented. And this is often what is going to happen. So the goal here is to try to understand what is happening in those steps and what can we change. And what can we change to better have a better representation of our microbiome? The step that I'm specifically interested in, because I could go on and on forever about all of these steps, but it's the step right after the sequencing and before the bioinformatics stuff. So basically, when you get your sequences back from the sequencer, there's a filtering step where you want to remove the low-quality nucleotides, keep the high-quality nucleotide, and try to keep the longest read possible so that. To keep the longest read possible so that you have the most information for the next steps, such as taxonomic identification. So, if we use, in our case, the primers we're using for the PCR amplification step are going to amplify both 16S and 18S ribosomal RNA genes, which are conserved genes that are going to allow us to discover most of the prokaryotic and most of the eukaryotic diversity. And because they are paired primers, once we sequence, we get both forward and We sequence, we get both forward and reverse reads, and when you have paired and reads, the goal is to merge them together to get one single end read. But usually, when you sequence them, what you the result you get back is a plot like that, where you see that on the x-axis, you have a nucleotide position, on the y-axis, you have a quality score, and what you're able to see is that towards the end of your read, the quality starts to drop. And this is where, as a user or as someone that is interested in this. Someone that is interested in this data, you have to make a decision. You have to trim some of these bases off because you can't trust them. So, you would set a threshold, a minimum threshold of quality, where you remove all the bases that are below this quality threshold to only keep high-quality nucleotides. But you can see how this is sort of a trade-off, and there's no golden standard because you want to keep the longest read possible while minimizing the errors. So, one thing to keep in mind, though. One thing to keep in mind though is that there are major differences between how 16S, so prokaryotes and eukaryote reads are going to be joined when you have paired end reads. When you have prokaryotic reads, the region of interest that is going to be amplified using the primers we used in our mock community is the V4, V5 region, which is small enough to have an overlapping region, which allows us in the bioinformatic pipeline to merge our reads together to get reconstruct the single fan read right there. Single van read right there. But in the eukaryotic community, the V4 region, which is the region targeted by our primer, is too large. Therefore, there's no overlapping region between our forward and our reverse reads. What happens is that instead of merging them, we're going to concatenate them. So putting one there, the other one there, and just filling the inside with ends. And you'll see that this is going to impact some of the results you'll see later. This basically means that if you have prokaryotic results, if they fail to merge, Results, if they fail to merge, the program just discards those reads because it assumes that they're too much of low quality or too short to do anything with them. Whereas for the eukaryotes, because you're concatenating them, there's no way you can reject any reads. Everything is always going to be kept throughout the analysis because you're just cutting them and then kind of stitching them one to another. So there's no way you're discarding any read at this filtering step. So that's one thing to keep in mind for the differences between the prokaryotic and eukaryotic reads. So, we're not the only people that have been interested in looking at how different steps impacts, sorry, microbiome analysis. So there has been a bunch of papers where they use mock communities to try to understand how different steps throughout the bioinformatic pipeline are going to impact the microbiome. And all of these have different suggestions on how we can make things better and how we can try. Things better, and how we can try to sort of find a golden standard and make our research more reproducible and comparable between different labs. So, more specifically, the step we're interested in, the quality trimming, has also got some interest from other groups that have had a kind of different focus than us. Our focus is more to understand the impact on taxonomy and relative abundances observed, whereas these other papers are more trying to find More trying to find developing programs to try to keep the maximum length in your read, but removing lower quality nucleotides. So, we kind of have a different approach to this problem. So, what is our approach? Basically, what we did is we used a mock community that was generated using ocean samples. Basically, from this mock community, we've used the universal primal I talked about earlier that can recover both prokaryotic and eukaryotic. Cover both prokaryotic and eukaryotic diversity. And from these results, what we did is we've generated all possible combinations of trim and length for both the 16S and the 18S. So they're analyzed separately. And by generating all of those results, what we're getting every time is an observation table where each column represents a different sample and each row is a different OTU or ASV or any cluster of reads that you've put together. Any cluster of reads that you've put together, and basically, from all of these observation tables, we've generated taxonomic information, phylogenetic information, and looked at the relative abundances and made comparisons between them to try and understand how different trimming impacts our data. So what are we observing? I'm going to share some of the results we've got from this so far. So the first thing we can look at is the average read quality of the retained reads. So as I told you earlier, we're trimming the reads and then we're To earlier, we're trimming the reads and then we're keeping a read, merging it, and then clustering it so that we can get clusters of reads for downstream diversity analyses. So, here what we're looking at on this plot on the x-axis, we have the read length, so the length of the read that is kept. On the y-axis, we have the average quality of the retained read. In blue, we have 16S in or prokaryotes, sorry. In orange, we have 18s or eukaryotes. The dotted lines are the reverse reads, the full. Reverse reads, the full lines are the forward reads. What we're observing just quickly, like that, is that prokaryote seems to have a higher quality in comparisons to eukaryotic reads, and also that forward reads have generally in comparison to reverse reads, a higher quality. Another thing we can notice is as we are keeping longer reads, as you can see here, it seems like when your reads are longer than 250, the average quality of your reads seems to be going down a lot more. So we're going to see what. Down a lot more. So, we're going to see what is the impact on the different parameters we are analyzing in our research. So, the first thing we can look at is the number of reads retained. So, on the upper plot right here, we have the prokaryotes and here we have the eukaryotic results. So, what we're seeing in these heat maps, on the x-axis, we have the reverse read length. On the y-axis, we have the forward read length. And what's the color basically represents the percentage of read length length length. Basically, it represents the percentage of reads that is retained after the filtering step. So, after we've trimmed, what percentage of our initial input reads are going to be kept? If we get a very dark red color, you're close to 100%, meaning that you're keeping most of your reads, whereas if you're close to zero, you're discarding most of your reads. What we're noticing for prokaryotes is that there is this sort of, maybe I'll change colors. It seems like there is this cluster here in the middle that. The middle that has kept a lot of reads, and as you move further from this cluster, it seems like you're keeping less and less reads. Whereas for eukaryote, it seems like we are seeing something quite a bit different. We have this L shape where if you keep long forward reads, very short reverse reads, and vice versa, you keep a lot of your reads, but everything else in the middle seems to be keeping less than 50% of the initial input that you have. So, some questions that can So, some questions that can arise at this step is: Does it mean you keep more reads that you have better results? Is that the goal here? So, is that what you're trying to do? Basically, what we wanted to do first is try to understand how do these community compare in terms of taxonomy only. So, if we look at the taxonomic similarity of an observed community at any combination of trimming line against the expected community, we've used taxonomic. We've used taxonomic trees to compare how similar they are one to another. The reason why we use taxonomic trees is that we can evaluate the similarity at different taxonomic ranks. And also, this is only going to be looking at presence-absence data. So, this is actually taken from a paper published in 2007 by Backross et al., where they use this to measure the similarity between two vegetation falls. But we've adopted this to tax. But we've adopted this to taxonomic trees for microbial communities where the similarities between two an observed and an expected table will be calculated as the number of shared nodes over the total number of nodes. So if you have a lot of nodes shared, you share a lot of taxonomic similarity. If you don't have, if you don't share a lot of nodes, then you're very far in terms of taxonomy to the expected community. So what it looks like. So, what it looks like, if we first look at the prokaryotic community, we see that this sort of triangle that we had here of kept read doesn't seem to be corresponding to the highest score for similar taxonomic similarities. So, here this scale goes to zero to one. So, that's our taxonomic similarity score. If you have a score of zero, it means that you're very far from the expected community. If you have a score of one, Community. If you have a score of one, you're very close to the expected community. And once again, our x-axis is the reverse read length, the y-axis is the forward read length. And what we're able to observe here is that it seems that this sort of cluster here in the middle doesn't correspond to the highest core, but instead it seems to be everything around the cluster here that corresponds to fewer reads kept in comparison to the input, but these seems to have better scores in comparison. Seems to have better scores in comparison to this little cluster that keeps most reads. So, this suggests that perhaps if you're keeping most of your reads, maybe you're trying to keep the reads that are of too low of a quality, where you would be generating false positives, for example. And if we're looking at our eukaryotic community, we're seeing something that's quite similar, but not exactly. We're seeing here that the bottom left corner of very small reeds has a very, as very far. Has a very is very far from the expected community, and it seems like the good scores are where we keep a relatively longer forward read length, relatively shorter reverse read length, where we're able to reconstruct the community that's taxonomically similar to what we are expecting. So if we just dive a little bit more into this eukaryotic one, just to have a better idea of what it means exactly when we talk about they're closely related or not. So I was just, I just wanted to show you the Not. So I was, I just want to show you the best table, for example, for our eukaryotic community looks like something like this. It has 15 out of the 16 types I expected identified, but it generated seven false positives. But the reason why the score is pretty high is because those false positives are very closely related to the expected groups. As an example, I've put this little table here where you can see the taxonomy in red of the false positive and in green of the true. False positive and in green of the true positives. The true positive is only identified down to the genus level, which is what we would be expecting. But this false positive goes down to the species level and identified this ASV or sorry, this sequence cluster as this species, but actually it wasn't it. And what you can notice is that the confidence level usually goes down for the false positives. If we look at the bottom left corner of Left corner of our heat map, we can see that everything is pretty poor. There are nothing, none of the expected texts are identified. We're getting only false positives in there, and everything is just identified down to the domain level because the reads are so short, so we're not able to identify anything. What if now that we've looked at taxonomy, we try to move our focus a little bit into relative abundances? On both of these plots, on the left side, we have eukaryotes, on the right side, we have prokaryotes. On our x-axis, Side, we have prokaryons on our x-axis. We have the expected relative proportion. Oh, I think that's something I forgot to mention. I don't actually have an even community. My mock community has some groups that are abundant, some groups that are rare. We try to mock a real community where you have just a few groups that are going to be abundant and the rest is rare. So, what we're seeing on the y-axis is you observe relative abundances. So, anything that would fall perfectly on the line means that it's relative abundance. So, then the abundance. So, then the abundance of these groups is perfectly matching what we're expecting. But what we're observing is that some groups are overrepresented and some others fall below the diagonal and are underrepresented. Another thing we can see in this plot is the size of it and the color of it. If it's a very small dot and it is dark in color, it means that this taxa wasn't recovered in a lot of tables. And what I mean by that, if I go back one slide before, all of these are all the One slide before, all of these are all the results we are generated. So, if you have a dark color, it means that you're not present in a lot of tables. So, you're only appearing in some instances. Whereas if you have a very light color and a dark circle, you appear in a lot of results. So, what we're seeing is that there doesn't really seem to be a trend where very rare ones are going to be under, where very rare ones are less detected than others, because you can see that here, this dot seems. See that here, this dot seems lighter than this dot, meaning that this one is more this cranomadida species is more abundant but is going to be recovered less often than some of these rarer taxa. So what seems to be observed in these plots is that regarding of your initial, regardless of your initial true abundance in the community, you are still going to different taxes are still going to be differentially observed in the final community. So it doesn't seem to be. Final community. So it doesn't seem to be dependent on your initial true abundance in the natural microbial community. So another thing we've looked at is precision and recall. So for both 16S and 18S. So first of all, if we look at precision, the question we're trying to answer is how much of the observed taxa were expected. So basically, we're calculating the number of true positives divided by true positive plus the false positive. So all of the observation. What we're seeing is that for prokaryotes here, We're seeing is that for prokaryotes here at the upper plot on the y-axis, we have the precision on the x-axis, we have the forward read length, and on this bottom one, we have the reverse read length on the x-axis. We're seeing that the precision is pretty high, meaning that most of our observations are true observations. And if we look at the recall, which tells us the number of true positives over the number of true positives and false negatives, basically we're trying to understand how much of the expected diagnostic. Understand how much of the expected taxa, so out of the 16 taxa we were expecting, how many of them are actually recovered? And what we're seeing is that once again, it seems to be fairly high for the majority of the results for both forward and reverse reads. But it seems that here we have this trend where if you keep too much of a low read or sorry, a smaller read length, you're losing some of the true positives that you would expect, and you're also losing some precision. The trends we are observing in procarats. Observing in prokaryotes are fairly similar in eukaryotes too for both precision and recall. It just seems, as I talked earlier about, that the spread of the results for eukaryotes are way larger because we're getting more results in the eukaryotic community due to the nature of the rejoining. And what we're also noticing is that if you keep too much of your read, so if you're trying to keep too much information, but that information is poor information, you're again going to start losing precision both. Precision, both your score is going to go down for both precision and recall. I'm going to skip this just because of time. So, in summary, what we're seeing overall is that the 16S result seems to have less variation due to how the reads are joined. So, merging instead of concatenating in comparison to the 18S. Also, what we're observing is that taxa are going to be differentially recalled, regardless of what their true initial abundance is. And this is telling us our. And this is telling us or suggesting that it's most likely due to other factors. So, other factors that I've talked about in the initial slide about the different biases that are introduced. And one great thing, though, to keep in mind from this is that most taxes are recovered correctly. So even though the relative abundances can be tricky to work with because a lot of taxes over underrepresented, most tax are going to be recovered. So we just have to be careful about conclusions we make in terms of relative abundance. Make in terms of relative abundances of observed taxa. So, some future work could be very interesting is exploring how other parameters determine bias and correct for them. Also, using this type of analysis, but on some real data set, and also we've developed a plugin for QIIME 2, which is a program that is used widely for analysis of microbiomes to allow users to compare their results if they're interested in doing something similar, maybe on a smaller scale. So they can just import their data and look. So, they can just import their data and look at how different taxons are appearing or disappearing in different parameters. So, I just want to thank both of my lab, the Biko lab in the Department of Computer Science at Dalhousie University, and Julie LaRoche's lab in the Department of Biology at Dalhousie University. And I'm open to take any questions if anyone has any questions. Great. Thanks so much, Diana. This is applause. Thank you. Some clapping. Not sure how good the mic is. Thanks so much. And I think you made up a bit of time. We started a bit late. So we can take a question or two and I think still stay more or less on time. I don't know if there are questions in the room, Sam. Hi, Diana. Thank you. It was a great talk. How? I just wanted to, I might have missed this. How I just wanted to. I might have missed this. How were you assigning OTUs? Were you doing a lot? Was it you aligning reads, or were you doing some sort of like K-ma-based approach? Yeah, I skipped this step because it's a long process, but people have moved a bit further away from OTUs, which is the traditional way to cluster your reads. So you get your sequences and cluster them based on shared sequence similarity off of a threshold that you decide, either 97, 98, 99. But the method I've used for my results is data 2. For my results, is data2, which is uses a probability model. It takes a pair of sequences, try to see if they share a minimum similarity between both of them, and then they use an error model that they've built to try to estimate if the read is an error based of another read or if it's the true sequence. So, if it's based on the probability model, if it's an error, it's going to be discarded, but if it's a true read, it's going to be clustered with that. So, their abundances are going to be. Abundances are going to be merged together. Data is kind of the golden standard now, I think, in my opinion, for ASV generation microbiome studies. So they're using a model to build the clusters. Okay. If there's no other questions, I just had a sort of a I'll let Lenin ask his question. There's one in the chat for you. Oh, okay. Yeah, I had just a quick follow-up. So, when you're assigning OT users, is there a way of quantifying the quality of those OTU assignments? Because when you are looking at including more reads or more, yeah, including more reads in it, it sort of affected the quality of the trees that we go to use. I was wondering if there was sort of more, yeah, lower quality. More lower quality of matches between those reads that you're clustering if you're including more reads? It's a good question. I don't, auto my knowledge, I don't think you set a quality to your clusters. Usually the sequence that is the most abundant is going to be the representative sequence in your cluster, and the rest you basically will never see them ever again. And so I don't know if there is a way to quantify the quality of your cluster. Quality of your cluster, you can definitely quantify the quality of that representative sequence, but from your whole cluster, not that I know of. But it's a question that has been tackling a lot of people in my lab, which look at how we cluster reads, where the reads are going, should we include reads or not? And there's multiple different ways to cluster sequencing reads, but not that I know of, unfortunately. But it's a great point. It could be interesting to include that as a parameter. Great. Thank you. Great, thank you. Thank you. All right, thanks.