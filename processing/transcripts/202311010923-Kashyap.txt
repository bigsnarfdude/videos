I'm sorry, who's next? Am I next? Yeah, we're next. Hang on a second, let me share my screen. Let's see if this works. Okay. Okay, so can you see? Very good. Okay, so thank you. Again, I have to apologize for not being there. For not being there, it's, I really wish I could have been. I feel like I'm missing out on a lot. In fact, this talk is actually going to be pointing to all the people who are there who will probably tell you more about what I'm going to be talking about. So I'm Vinay Kashyap. I'm sort of representing Shask Astrostatistics Center here. And I'll be talking more about a program. Talking more about a program that we've been running for several years now, modeling multi-dimensional data. And in particular, high-energy X-ray data. So just a couple of words about CHASC. I think Aneta may have mentioned this already. It's an astrostatistics collaboration, which started off between astrophysicists at the CFA. At the CFA, which is where I'm at, and statisticians at Harvard. And it sort of expanded to include people everywhere, practically everywhere in the world, including Canada, where we've got David Stanning at Simon Fraser. And we've been responsible or culpable, depending on your choice of where. Depending on your choice of word adjective, in about 40 PhD theses and innumerable master's theses. So, the thing about astronomical data, again, I believe, and I've told you about all this already, but especially high-energy X-ray data is that they come to you as lists of events, whether there's usually photons or flares or sunspots. Or flares or sunspots, some collections of fluxes. And we've got to model them in different ways and take into account different attributes. So I'll just give you a very broad overview of some of the stuff we've been doing. But there are people over there, like David Van Dyke, Anita Shimiganowska, David Stenning, Yang Shan, or Max Ottenreet. Ask them for more details. Please talk to them. I really wish again that I could be there, but. Again, that I could be there, but I'm sure they will do an excellent job of explaining things better than I do. So what's so special about high-energy X-ray data is that, as I mentioned, there are typically, the typical data that we get are four-way tables with spatial, spectral, and temporal marks. That basically That basically usually is written as a portable spatial dimensions, x and y, time and energy. And depending on how they are projected onto different axes, we get images or light curves or spectra. And we can also look at some combinations of, you know, we can do spatio-temporal, spatio-spectral with XYE, spectral variability. Structural variability, and of course, the goal is to do everything all at once. So, this is the main plot that I really wanted to show. What this is, is those of you who can do magic eye, you know, one of those detection things, see if you can just sort of superpose the two, and you should be able to see a significant depth in this. Depth in these images. So superpose the left and the right images, and you can see lots of things. But even for those who can't do that, what this is showing is a three-dimensional representation of the photon positions and time and energy in a small window in the Orion Nebula cluster. What you know facing you is. You know, facing you is the spatial coordinates, and going in is time, and the colors represent energy. Red means low energy, blue means high energy, green is sort of medium energy. And if you manage to do this superposition, you should be able to see, you should be able to see right now that there's a source over here that is a soft source that's probably a foreground source that's all red. Source that's all red. There's also a hard source that's probably behind the Orion Abela cluster that's sitting here. So sources in these cases are like long strings of photons. But there are sometimes there are sources which you can see that there's variability. This one, for instance, there are a lot of photons at the beginning. There are a lot of photons at the beginning and which tail off. And then there are sources here which sort of show up for only for a tiny little bit. And there are sources here which also appear for a tiny little bit. So there's a huge, there's a rich data set and you want to analyze all of it at once. And unfortunately, we can't. We have to look at what we can do to answer specific questions. To answer specific questions and take projections and do the analysis that way. So, yes, two minutes. So, let's, oh, what happened here? Ah, there we go. So, I'm going to sort of rush through these lists of things. So, we've been looking at various start from zero dimensions, which is basically, you know, what if you find nothing? You have one count. If you find nothing, you have one count, and you do you know if you have a source or not? Uh, so it's you know, we usually do that by looking at the balance of type one and type two errors and to determine the upper limits. There are some references over here, which you can sort of look through. I assume that the PDF slides will be present, will be available. For one-dimensional cases, you know, we've done spectral hardness using. We've done spectral hardness using hierarchical Bayesian modeling, model low-count spectra with narrow lines and low-resolution spectra, mostly using MCMC and dealing with multimodal posteriors. And then, of course, we have done collections of things to do log and log S, luminosity functions, power law distributions, sunspot numbers, flare distributions, time delays, you name it, using various, taking advantage of various characteristics like data augmentation, maximum product of spacing. Maximum product of spacings, multistage based analysis, Carnot processes, Gaussian processes, and so on. We have also done one-dimensional spectrum analysis by including some extra information. That's what I'm calling one and a half D in the form of systematic errors. I've done image D convolutions with error bars. That's Lira and Jolly Deco with multi-scale hierarchy. Multi-scale hierarchical Bayesians, including Ising and genetic algorithms to determine boundaries. We've done spatial analysis augmentation in event lists using graph seeded region growing and change points in spectrotemporal data using minimum descriptor lens. And also in 3D, you know, we've done spatio-spectral disambiguation of overlapping sources using reversible jump MCMC and Bayesian. Reversible jump MCMC and Bayesian mixtures, extended that time with Bayesian mixtures, called this thing called EBAS, and also done a four-dimensional seeded version drawing and minimum descriptor lens-based filtering, you know, change point setting in multi-filter data cubes. So, this is just a summary of things. If anyone has any questions, I can try to answer them now because I have some extra slides. Them now because I have some extra slides. But you're also, you know, I also encourage you to talk to the people who are there. Thank you. Any questions?