Thanks a lot to the organizers for inviting me here. It's wonderful to be here. It's my first time in Banfa and it's a very nice meeting. So I'm sorry for the change of topic. I thought this was more appropriate given the other talks. So I'm going to tell you about the system of interacting particle systems which goes under the recoctive markers, which is interesting because it's believed to be at the same time. interesting because it's believed to be an example of self-organized criticality. So let me start with a few words of motivation. I know that all of you know what self-organized criticality is, but I'd like to show this picture. So if someone, so imagine you're on the beach and you're playing with sand and you start dropping sand at the same location and what will happen is that you will have a pie of sand which will grow in time up to a critical configuration in which it becomes In which it becomes too steep. So the angle becomes too large, and at that time, the cell prefers to roll down the sides rather than accumulate on top. So the dynamics drives the system to a critical state, which is characterized by this critical angle. And this is what we mean by self-organized criticality. You have a system which, independently of how you initialize it, is driven to a critical state. Is driven to a critical state. So let me tell you, let me give you the definition of the system we're going to look at. It's an interactive particle system in which particles live on Zb and in many pictures I will focus on that. And particles appear in two states: they're either awake or asleep. The awake particles are colored in purple, and the sleeping particles are colored in light blue here. And I always assume that the time zero, a site could be either empty, or it could contain one or more active particles, or exactly one sleeping particle. I'm not allowing more than one sleeping particle at a given site, and if this is true at time zero, you would see that the dynamics preserves this property. Okay, my initial configuration is going to be taken IID Bernoulli. Be taken IID Bernoulli parameter mu. So at each site, I'm going to put a particle with probability mu and zero particles with probability one minus mu. And I'm going to assume that at time zero, all my particles are active. So this is not a valid initial configuration. So this is the rule to choose the initial configuration. This is a valid one. I either have one empty particle or an empty site. And each particle has an exponential Poisson parameter one. Of a Possum clock of parameter one, so after an exponential time of parameter one, a cloud will ring, and when it rings, the particle could either decide to move or decide to fall asleep. And it decides to move to a uniform which was a neighbor with probability one over one plus lambda, and it decides to fall asleep with probability lambda over one plus lambda. And lambda here is a parameter of the system, and you should think of lambda as the tendency of particles. As the tendency of particles to fall asleep. So, this clock rang and the particle decided to move, which was beautifully a fan of the neighbor and it moved there. It could have also moved here because I'm allowing more than one active particle at a given site. And now I start the clock afresh. Now, another clock rings, and the particle decides to fall asleep. It can fall asleep. Well, okay, it falls asleep and it stays asleep. And it stays asleep. When a particle stays asleep, the clock is removed. It stays there until an active particle comes on the same side and wakes it up. So sleeping particles have no clock. Now another clock means an active particle decides to move and maybe it moves on a sleeping particle and it reactivates it. So I have two active particles at the given site and so on. So you have particles. So, you have particles moving and falling asleep. And if you have more than one particle at a given site and one of them tries to fall asleep, then, well, you can either say it can't fall asleep because there is already an active particle at the site, or you can say, well, he does fall asleep, but it's immediately reactivated by the presence of another active particle at a given site. Okay, so if a particle decides to fall asleep at a site which is occupied by another active particle, I just don't see. In other active particles, I just don't see it. Okay, here's a picture of these dynamics, this is a simulation by Larola. And time goes from left to right, and the particles move on the cycle, the vertices of the cycle in the vertical direction. And here the colours are consistent with my initial drawings. So colorful particles are awake, light blue particles are asleep. Light blue particles are asleep, and the black here means that there are more, there is more than one active particle at a given site. So you can see that when particles are awake, they move asleep around the box, and when they fall asleep, they just stay in place. Except that, so let's look at this one, it falls asleep, it stays in place until an active particle steps on it, and so it wakes it up immediately. So there is a competition between the tendency of particles to The tendency of particles to fall asleep and the reactivation procedure. What is mu? So, mu is the initial density of particles. What are they upset it to? Ah, so wait a second. So, the question we want to address is, does activity persist forever? So, imagine you do this on ZB and you ask what happens in the long run. happens in the long run and the answer is well it should depend on mu it should depend on the density of particles or at least it should depend on how the density of particle particles relates to the sleep rate and well we think that if mu is small so if there are few particles around well they should all find some place to fall asleep and so at some point they will all be asleep and we just don't see anything happening anymore and so this is a big thing Anymore. And so the system big sales. To make this precise, you should look at the final window. You can't just ask the system to big sail after a human time. So we talk about fixation. And if mule is large, if you have many particles around, well, you might think that the activity can persist forever, because even if particles fall asleep, they are continuously activated. And so every finite photon is visited infinitely many times by active particles. Active particles. And there will be a critical value at which we would see a transition between criticism and explosion. So the simulation is for the critical value which corresponds to the slipping rate. And I don't know the value of the slipping rate because they chose, but this should be a near-critical configuration. Okay. So it's a result by Levola and Gladys Equitors back in 2012 that there is this phase transition. There is this phase transition. So take well to start with, take an IID initial configuration of the multi-new active particles, as I defined it earlier. Then for any sleep rate lambda, there exists a critical density mu C of lambda, mu critical of lambda, such that the probability that the system eventually fixates is one if we're below critical density and zero if we're above critical density. About critical density. So there is a transition between fixation and activity, and this is true for any value of lambda. Okay, I'll comment about the lambda equals infinity case of this later. And so you get a curve for each lambda in you, you have a critical density lambda. And well, it's a result of layering ladders together with. Leo and Gladas, together with Oriel Zindi, that in fact this is a this phase transition, this critical density mu C is universal with respect to the choice of initial distribution for the particles. In other words, suppose I give you, I place the particles in an IIT way, but using Poisson distribution of parameter mu rather than Bernoulli at time zero, then you will see the same critical density. In fact, you don't need to In fact, you don't even need IIDs enough for the initial configuration to be stationary intergodic. And the only thing that matters is the mean, the average density of particles, the mean mu. Okay, so you have this critical line and the question is, is this, well, are there non-trivial phases? So is this line bounded away from zero and from one? It's easy to believe that if you have an initial density of particles, Have an initial density of particles which is above one, then the system will not manage to fix eight because the density is conserved. And to fix eight, you need to have at most one particle at each given site. So if on average you have more than one particle, it becomes fixed eight. But there is the question whether it's simply smaller one or actually it goes to one. So already in the initial results by all antiquities, they prove Lens previous, they proved that the critical density is always larger than 1 over 1 plus 1. So there is a lower bound, and this lower bound comes from the totally asymmetric case in which you're on Z and you always move to the right with probability 1. So in that case, you can actually write down the vertical density again. It's lambda over 1 plus lambda, and it's a lower bound. For the upper bound, Uh, upper bound, but as I said, it's easy to believe that the critical curve is below one, but does it reach one? And it's a result of Chris-Hoffmann with Basukangoi and Ricci that it does not. So these are two papers and they first prove it for lambda small enough and then they extend it to all lambdas. So for every lambda, they reduce the value of mu, which is typically smaller than one, such that for that choice of mu, the system That choice of the system sustains activity even if is not one. Except if lambda is infinity, right? Yeah, so if lambda is infinity, then I'll come back to that. So if lambda is infinity, we know much more. Okay, so this is in dimension one. Yeah. Leo is also on the second paper there. Okay, so his name should be moved here as well. Thanks. And in fact, we also know how this curve approaches zero in dimension one, and this is a result of a Muna Cell and Ronald Shafira. We know that mu c of lambda goes to zero as square root of lambda, apart from multiplicative constant. And for higher dimensions, so when radicals are tension certain dimensions greater than record three, wherein Zotagi proved an analogous result, there is a non-critical Analobus result: there is a non-critical active phase with density strictly smaller than one. I haven't checked whether Lorenzo's result goes all the way to zero, but there is now a result which works in all dimensions and in particular Settles dimension two, which was the complicated one, which said that for all numbers small enough, there is a contrivial active phase, so there is a critical phase of density which is critically small enough. There is a density which is typically smaller than one, such that the system at that density sustains activity forever. This works in any dimension, but in dimension two, it was open for a while and I settles that. And it goes all the way to zero. And it's open to prove that this is true actually for any lambda positive. Here you should think that when the random walls are transient, the analysis of these models is a bit easier. When the random walks are occurrence, it's When the random walks are occurred, it's the difficult case of dimension one and two, but in dimension one, you have more constraints because what geometric constraints of dimension two is really the hard case. Okay, and I should mention that there are several other works by all of the authors which I wrote here and probably more, in which they consider a quick graph of what they did or affect graphs, which I will not survey. Which I will not survey. Okay, so now you would ask, okay, you started talking about self-organized criticality, and what is the self-organized criticality? You just picked the density at the beginning, and if you didn't pick the right one, then you wouldn't see this critical state. So I'm going to give you a different instance of activated random box in which we see this organized criticality. But at least we should see. Can you see, and this is activated on workers as a growth model. So, what I'm going to do is, I'm going to take n particles at zero at the origin. You can think of these as things that be, but I'll restrict to dimension one, so I drew the pictures in dimension one. And they're all active because they share the same site. And now I let the activated random workers dynamic run until the system stabilizes. It will stabilize after a while because I finally. Will stabilize after a while because there are finitely many particles infinite space. After a while, each of them will find a place to fall asleep, and at some age they will all be asleep. And the question is, at which density do the activated drumming workers spread? And so I wrote a video because I gave this talk twice already and I forgot in both cases to show the video. So this is the video. It's a simulation of Simulation of this system, in which so you start with n particles here, n is the colors are consistent with the ones I showed you. These particles are asleep and the purple particles are awake and you might have particles which are asleep for some time but then they're woken up by other particles coming in. But at some point as the time goes they will all find a place to fall asleep and Place to fall asleep, and you will have a cultivation which will not happen. Okay, so the conjecture is that there should be a shape and the shape should be a pole of the right density. So for any lambda in zero infinity, there exists a critical density mu A of lambda. Critical density of lambda, such that if I call a n the set of visited sites until stabilization, n is the number of particles in my system, then it should be sandwiched between a ball of radius of volume n over mu a of lambda to x1 plus epsilon and the same ball to x1 minus epsilon. So mu a of lambda is a different notion of critical density, a sense for aggregate mu aggregate of lambda. To new algorithm. I think again I got lost here. Yes, so I was the set of sites which are visited until complete stabilization, visited by some particle. So it's an interval on Z, but on Zb, it might be something else. And the conjecture is that for any lambda, there exists a critical density mu area of lambda, such that this again is very close to a ball of volume n over mu area of lambda. n over mu area of lambda. And when I say very close, I mean it's language between ball of volume in this times one plus epsilon and volume volume in depth times one plus epsilon. In any dimension. In any dimension. So the particle density will depend on the dimension. And so lambda equals infinity is something we understand well. Lambda equals infinity is internal DNA, internal diffusion aggregations in aggregation in which part In which particles move around as long as they're walking on sites which are already occupied by someone else, and as soon as they find an empty site, they fall asleep. And for internal artificial integration, we have these results. I mean, these results were already known back in the 90s. The shape theorem is due to Lawler, Brownson, and Griffiths. We know that, in fact, AM is sandwiched between two poles. Well, it's very close to a ball. And we also know that the maximum error here is... Know that the maximum error here is not only little of the radius, but it's logarithmic in the radius and in higher dimension, even square root of logarithm of the radius. There are very good bounds for the fluctuations. And we also know that the average fluctuations are given by a local correlated galaxy field. This is a result of Janison-Denier-Shatfield with MMT. So in terms of the A is very well understood, the case magnetic infinity is well understood, and then the density is one because particles star. Particles stop as soon as they find an empty side. But as soon as there is this lambda smaller than 3D, the competition between activity and inactivity makes the analysis more difficult. So it's no question in this formal statement, but do you believe that when the whole thing settles that in this ball the sleeping particles will be uniformly more or less distributed? There shouldn't be unif okay the density should be roughly uniform if you're far enough from the boundary but there should be correlation between the positions of particles there should be some repulsion because particles don't like to switch closer each other but that is the trough and the local structure is very unfair but none of this is known not even this year okay so I gave you a second notion of physical density and let me give you a third one And let me give you a third one. Now we're going to do activity thermomorphism, but on finite volume. This is my only picture in two dimensions, but you can think in any dimension. So I'm going to take a finite box in ZB and I'm going to place one active particle on the side, on the vertices of the box. And I want to play actively drumming box on this. And my boundary conditions are: if the particles jump out of the box, they are killed, they are removed. And okay, so you play activated on the workers, and sooner or later you lose some particles, probably a microscopic density of particles, and at some point you will reach a configuration in which you have other empty signs or sleepers, and that's a stable configuration, nothing will happen anymore. And you call this the stabilization of the initial configuration with slip rate lambda. So here there is no density, there's just a slip rate. And the density that you should get should be some kind of critical density, that's the self-organized criticality. So, a first conjecture for NSMIP is lambda that is gives by critical density in u s of lambda such that if I look at the density in the final state and I divide by the volume of the box, then that should have a limit and the limit should be this critical density. So, mu s stands for station. S stands for stationary because this is the stationary state of an associated Markov chain, and I'll say something about that. And I said, in which sense we believe this thing to hold. It's definitely an expectation, but probably something is gonna be more precise. And as a physician, you tend to conjecture that all the critical densities are the same, right? Or is it not a actual density? That all of these critical densities are the same, and this is the universality result peractivated from the book. The critical state should not depend on the particular experiment you choose to realize it. And today I want to say something in this direction. So I want to focus on the second experiment, activated London Walkers as a growth model. You take any workers and you make them some. take in workers and you make them stabilize and you ask what can i say about the set of visited sites until stabilization so we would like to say that there is a shape theorem meaning that the set of visited sites converges to an interval of a given length we can't really prove that what we can prove is that um well the the density the final density is sandwiched between two new notions of critical densities which we call mu out and mu in recall mu out and mu in. So the set of sites which are visited after stabilization is included in an interval of length n over mu out. So particles spread at density at least mu out. That's an upper bound. And the lower bound is the length of this interval is at least m over mu in where mu in is I'll tell you what these that is exactly in a second but these are two mu in. In a second, but these are two new notions of critical density, and so we note that the outer bound is centered. We believe we can prove it in any dimension. So I use B for the ball, but in fact, in dimension one is an interval. The inner bound is not centered. This is very frustrating. We couldn't prove that the center of mass doesn't move macroscopically. But of course, our conjecture is that these two... conjecture is that these two critical densities are the same as those critical densities so in fact if you can prove that then this would give a shape theorem for activity drone works in dimension one so instead of a shape theorem what what we can prove is that the aggregate density sandwiched between two neurots of density mu out and mu in and the nice thing is that mu out is just a quantitative Mu out is just a quantitative version of mu C of lambda or the critical density in infinite volume, and mu e is a quantitative version of mu s of lambda, the critical density associated with the marker chain with killing. Any question about this is what you prove, something about just yeah, yeah, this is what we are and do you know the to be any strictly smaller than one? Ah, so we didn't. Ah, so we didn't, but there is a recent result by Acela, Shapira and Rola, which shows that mu mean is smaller than constant times lambda as lambda goes to zero. So at least for lambda small, mu mean is smaller than one. So they don't spread at that CT one, they spread at that city strictly smaller than one. At least for lambda smaller than one. Well, that's not enough. We don't know that neural is positive, we had to assume it. Okay, and let me tell you what these densities are. I said these are quantitative versions of the other two notions of physical density I've produced. So, for new outs, remember the incident volume segment in which you start to dig at the only, and you ask whether this is. And you ask whether the system stabilizes or not. And suppose you're below criticality, so the system stabilizes. If it does, you can ask how many clock rings does a given site see up until stabilization. You see that it's finitely many, that it will be a random number. And well, you are know that it's finite almost certainly, whereas what we ask is that it has finite third moment. And we take the maximum density for which this holds, and that's what we call you up. Now, if you're below criticality, you believe that your system will not only stabilize, but it should do so quickly. So, in fact, we do believe that this is true up until the critical density. So, mu out should be equal to the critical density. But this is not known. So, this is our notion of mu out and the conjecture is equal to the critical density in. That it's equal to the critical density in its volume, whereas the inner density is slightly more technical to define, but you should think about the experimental assignment box with killing upon exiting the box. And you look at the small density such that if you look at, so the box is called I here because of that it's an interference. So stabilize the configuration of one active particle at each vertex of the box and look at the density of the resulting. Of the resulting configuration. And you must have the probability that that density is larger than a given value decays polynomially in the size of the box, in the bottom of the box. So you take the smallest density for which this holds. And okay, this should not depend on I, but it could depend on I, so you want to take the limit as I exhausts Z. And we don't know that the limit exists. We don't know that the limb exists, but we can do with the lim soap. So, this is our notion of eval density. And the conjecture is that the conjecture is that whenever you reach critical, okay, whenever in the finite volume experiment with killing, you should see this kind of concentration happen to the cavity. Up into criticality, and so this should be one S of L. But we can't probably. These results are very partial, and there are a lot of open questions. Is there any significance to the 3 to 20 mean pick right there? So, this is what we needed for our group to work, and we believe our projectures to be true with these exponents. Maybe you can reduce. Maybe you can reduce the three to two, but still it's okay whether yeah, we believe that all of these latest is the same as the critical ones. Okay, and for the ideas of proof, let me how much time do I have at least 20 minutes? Okay, for the ideas of proof, so usually when you prove shape theorems for this kind of interactive particle. Theorems for this kind of interactive particle systems, you first put an inner bound, and then you say, I don't have many particles left, so I can deduce an outer bound. This is what stands, for example, for internal diffusion depreciation, which is the Lambda situation case. But for us, we prove the outer and inner bound completely independently. And the outer bound is proved using the abeyan property combined with a coupling with infected DNA. With a coupling between Teta and DNA, where particles are only allowed to fall asleep on open vertices of a benefic percolation configuration, an alternate pulses. And the inner bound is more technical and we iteratively build the stable configuration from the inside out using that the configuration of each interval only depends on the odometer you want. Okay, you don't want you to function. Okay, you don't know what the opponent function is. So, this is only for the expert. We're using that the configuration one depends on the value of the thermometer function on the boundary. So, excuse me, Victoria, outer and inner correspond to which one in the outer bound says that the partial spread, well, the set of existed sites is contained in an interval of a given site, and the inner is that it contains an interval. This video that you showed us, did it also you? That you showed us, did it also use this abelian property? Yes. Because I saw that a lot of active particles are ceiling for a long time. Yeah, so I'll come back to that. I have another slide called video. So I'll tell you what the Abelian property is. And then I'll show you the video again. So for the Abelian property, I'm going to realize this activity of water dynamics in a different way. So I'm on Z. To each side of Z I associate the littering stack of... I associate an interim stack of instructions. The stacks of instructions are independent. And inside each stack of instructions, I sample either z instructions, left or right instructions with probabilities consistent with the definition of the model. So rate lambda is yes instructions, rate one over two tax one plus lambda is each other instructions. And these are independent within the stack and for different stacks. For different spaces. And now, on top of that, I'm going to put a particle configuration in which, say, the particles are active. I don't need the particles to be active. I want to stabilize it. What I mean by stabilizing it, I mean I want to run the dynamics until all particles are asleep. And now I don't have the clocks. And the rule is as follows. Let's say that the site is unstable if it's not stable and stable. If it's not stable, and stable here means that its ideal nature contains a sleeping particle. So at each step, at each discrete time step, I choose an unstable size. Let's say I choose this one. And I look at the instruction I have on the stuff. The instruction says to fall asleep. So I fall asleep. And then I delete the instruction. Now I choose another unstable site. Let's say I pick this one. And I look at the first instruction. It says jump to the left. So, it's jump to the left. So, I pick one of the particles which I had there, and I move it to the left, and then I remove the instruction I used. The particles are indistinguishable, and this is important. Okay, and then I go on, maybe I pick this one again. The next instruction is a sleeping instruction, and so I fall asleep. Now I pick this one, it says jump to the right, so I jump to the right and I delete the instruction, and so I'm out here, and I pick this one, the next instruction says to fall asleep. Says to fall asleep. I look at it. I try to fall asleep, but I can't because there is another active particle. So I just remove the instruction and nothing happens in my system, and so on. So you can go on and after a while, you will have used a bunch of instructions, and you will end up with a configuration with only slippers or empty size. And you might ask, does this final configuration depend on the order that That are the order of the choices of the sites for which we looked at the interactions. And it's a theorem by the agronomist and function in a project general setting, and then it was realized by Roland Ramishos and Nickman that activated drug bottles have this property. It's a theorem that the final configuration does not depend on the order of the top links. Top links here just means look at the size. means here just means look at the site look at an instruction at the given site. So you can you can choose whatever order you want for the stabilization, for the moves until stabilization and you will get the same final configuration. I mean really the same. But even more, the number of instructions that you use at each given site does not depend on the order of the top links, which means that the function that tells me how many instructions I used at a given site Instructions are used at the given site does not depend on the choice of the order. And so, this allows us to give a definition. The odometer function is a function w which tells us how many instructions we used at any given time. So, the ability property says that the odometer function does not depend on the order of the choices, that's the profile of the odometer function. And there's another property which I'm going to look. But there's another property which I'm going to need, which says that if the system stabilizes, it does so efficiently. And so if you ignore sleep instructions, you can only increase your dominant function. Ignoring slip instructions can only make this function point twice larger. This you should believe me and. Just monotonicity in the sleep frequency. So, if you change the frequency of sleep instructions, then you can show it's a things I'm monitoring. So, here I'm going to show you the same video. Here, actually, I didn't simulate this with Poisson clocks, but my rule was that I evolve an active particle until it falls asleep, and then I Falls asleep, and then I always look at the leftmost active particle, and I evolve that until it falls asleep. So, in fact, in these simulations, you see that on the left, you always have more sleepers than on the right because of how I chose to do the toppings. But the final configuration does not depend on this choice, that's why I have to do it. Okay, and in fact, so this is the profile of the function. If for these choices, the sleep rate is 0.3 and I have 15 particles. This is the final configuration, and this is how many instructions I used per site. And you can decrease the sleep rate and to decrease the sleep rate, the particles will spread wider because they have less tendency to fall asleep, and so you will have a larger profile for neutron defunction. Okay, and so just to tell you about the proof of the outer bound and then I'll close, what we do is that in order to stabilize this configuration, let's take a density which is slightly smaller than our target density and let's center the moonly vertex vertex percolation calculations are so so the vertex So the vertex configuration is roughly half the density which I'm aiming at, because you should think u is modern, but close to the critical density. And now I'm going to make the particles run until they fall on the sides, on the open sides of the vertex composition. Now, they might fall asleep, so I might not succeed to do that, but I can force particles which are asleep to wake up. This means ignoring. To wake up, but this means ignoring sleep instructions. And I know that by doing that, I will only increase the support of the odometer function. That's okay because I'm looking for an outer bound, not an upper bound. Okay, so now I have, so this is basically incremental diffusion on the lambda equals in 3 decays, but on a configuration which has the density I want. And so you can control the support of the odometer in this phase. This is basically the idea. In this phase, this is basically the argument by Laura Branson of Creepeth for the shape theorem of internal nutrition depreciation. These are the instructions we use up until destabilization, but not without time because these particles are awake. We have to make them fall asleep. And so now we have to stabilize this configuration, which has roughly the right density. So we want to show that the support of the odometer function does not increase by much. So we might visit. So we might visit new sites, but we shouldn't move macroscopically. And we will use new instructions when we make these particles fall asleep. And we want to show that this is at most epsilon. And the same on the other side. And let me, for now, let me forget that I already used this first bunch of instructions in order to spread the particles roughly at critical density. And I can do that because. Density, and I can do that because, well, there's a macro problem here. The SAXRI ID, I only use instructions based on my configuration. I never looked into the future, so I can forget about the instructions I used so far. So I remove them. And now I want to show that stabilizing this configuration does not increase very much the set of these sides. And for this, we use our assumption on the critical density. So here we are summarizing. So here we are stabilizing an IID Bernoulli vertex per collision configuration with parameter Î¼, which is finite. We have finitely many particles. So it's easier than stabilizing an infinite configuration, in which we put exactly one active particle on each of the results. And when we stabilize the infinite configuration, we know how many fractions we use. That's this red profile. We know that quite, it will be a random variable. That quality, it will be a random variable that is identical, but it's a random variable which has third moment. That's our assumption on the density. And so let's argue by contradiction. Suppose you visit many more sites in order to stabilize that configuration. Well, if you visit many more sites, then the support of your odometer function, the number of instructions you use, must be large. But you have a bound which is uniform. You have a bound which is uniform everywhere, and so it can't be too large, and so you get a contradiction. That's roughly the idea. And the key to show this contradiction is to argue that, well, suppose all the action happened over here, and you want to show that by stabilizing the IAP vertex pernovic vertex percolation perturbation, you don't visit many more signs. But then the particles come. But then the particles come from this side, and you know you have a bound for how many instructions you use at this perpex. Here we use the three indimension one. And so you can imagine that when you're looking at a movie and you only see trajectories which are over here and you don't see anything over there. And so you might have trajectories which come and then they go back again. And you think that each instruction Think that each instruction corresponds to an active particle, and the rule is the particles are killed upon returning to this line or if they move to the left. So you reduce to this simple problem, you have these many active particles. They do simple on the work. If they move to the right, they're free to do activated on the work, so they will fall asleep and come do it. But if they come back to this line, they're killed. This line they're killed. If they fall asleep here, they are killed. And if they go to the left, they are killed. And if you have these many particles, how far can you spread? This is a simple computation, it's a simple walk problem. And you can show that if you want to spread by n, you can't do it with less than n particles. So this includes the group. I think I'm out of time, so let me just say there are many open questions. I'm not. I'm not 23, so it's already 30. So, a few other questions. There are many other questions. One is the density conjecture, which said that these two conjectures that the densities are the same. And this is the main, the most interesting question in this area, I think. If you want some evidence in this action, you can think of doing this game. you can think of doing this game you you take your n particles at the origin and you do what we've done until now so you let the dynamics on and they will fall asleep you will get the configuration of sleepers and you take this configuration wake them all up and then you make them fall asleep again you will get a different configuration and you can ask how do these two densities How do these two densities relate? And so, this is a picture. Here, at each step, at each description step, I wake all the particles up and I plot the position of the leftmost and rightmost particle at the end of the stabilization. And if you believe that your particles spread roughly at critical density, then the system likes to stay at critical density. And so you should see roughly, these lines should be roughly constant. These lines should be roughly constant, except that there is no space outside. So at some points, they will decide to spread out. And you can run this for longer times and you will see that the rightmost and leftmost particles spread. And if you go to even longer times, the particles are so spread that they don't really interact much and they just move as if around the box. So it would be very nice to say something about this microchain. Nice to say something about this microchain, which you wake everyone up and probably lays. Okay, and for the final to volume case, well, we had, I said statistically density is related to an associated market chain. The microchain is each step you add an active particle, say at zero, and then you stabilize the resulting configuration. And then you do it again, you have an active particle and you stabilize it. Stabilize you get the mark of chain on the set of stable configurations. What can you say about the mixing time? And there is a result by Leibniz and Erin Bian and it says that the mixing time is at most the time it takes to fill the entire box, but that's the constant shouldn't be right. You would think that the density of particles, say, if you start from an empty box, the density of particles. The density of particles grows at rate one up until you get to the density, the chain lights, and then it stays there. So you see this kind of picture and you see it from the simulation. You see this kind of picture. And okay, here the scale of vertical and horizontal scales are not the same. That's why this doesn't have solar one. I have to compress. And this is the odometer function, the number of instructions you use. Function, the number of instructions you used at every site. Here you're killing at the boundary, so you use less instructions close to the boundary. And also for the critical status of what we're saying, it would be very nice to have a result on how it looks like, what it looks like. So we believe that there is a repulsion between particles. They don't like to fall asleep close to each other, but there's nothing in this direction. In this direction, and so finally, something that I'm guessing you will hear more about on Friday: activated ammonia works at fixed density. So, here there's no killing, and you start with a finite graph, and it puts a few particles on it, some number of particles. And but if they're all await, at some point, if the density is at most one, at some point they will all find a place. Point they will all find a place to fall asleep and the systems will stabilize. And the question here is: how long does it take to stabilize? If the density is very high, you would think it would take a very long time to stabilize. And if the density is low enough, the system will stabilize quickly. And so there is a phase transition at the critical density. And well, it would be very nice to say, to know something about the state that you get on this optimization. Of this stabilization or the mixing time of this market chain, in which at each step again, you wake everyone up to the lives. And then finally, a question which is very important in this area is what happens if we allow a positive density of slippers at time zero. I said I start with all active particles, so it's very important to understand how the slippers come in the picture. So if you start from a density which is higher than the critical one, but if you subtract the density of slippers, But if you subtract the density of zippers, it becomes lower than the critical one, then it's unclear what happens. And this is an important question. Okay, and I'll stop here. Thank you.