Yes. So we like to think about this problem that electronic structure is largely solved, right? At least conceptually, we have a way how to do that. You take your system, you figure out which physics is relevant for that, you solve Schuring as equation, and you have your properties, or at least the handle to get any of those. Now, I would argue that. I would argue that this is nice, but it has a huge cost problem. So I like to convert this into energies because these days everything is about energy. So if you want to have a full CI, complete basis set, limit estimate of energies, then depending on how you do it, methane is going to cost you about a short glass of fuel, Hen to about a barrel, and ethanol is going to cost you a tank. And ethanol is going to cost you a tanker. Now, of course, you can make your code much more efficient, but notice the scaling, right? The molecule is just ever so slightly larger, and we still pay a lot. Now, you're all familiar with the fact that we don't have to do that. We have modern approximations, which bring this down to roughly the energy of half a drop of fuel. That's very nice. But is that enough? If you look for molecules, there's a common There's a common estimate for the size of chemical space that ultimately we would like to be able to describe, to search, and to exploit for design. And that's roughly 10 to the 60. You can still argue about the orders of magnitude, but nonetheless, this is too large. So make everybody on Earth be brilliant chemists, look at a million molecules a second. You're still not chipping away enough orders of magnitude in order to make this anything. In order to make this anything which is sensible. And we've seen this the other days as well. There's an estimate for materials. You can do the same logic, even if you're on the very simplistic limit of materials that still again, the size is measured in orders of magnitude. So I would like to make this a little bit provocative statement that maybe speed doesn't matter. So the search space that we have is so huge that the moment you have to start to touch anything to To start to touch anything to predict one system, to predict many systems, the moment you start enumerating, you're already too slow. So, we would like to have something which not only does every system individually, so every point here is one system and the orange ones are the ones that we can calculate explicitly, we would rather have something where we can select regions in chemical space. We can say this direction is interesting, that direction isn't, which is exactly. Direction isn't, which is exactly how we do this in a lab. So, one way to do that is quantum alchemy, and you might not be familiar with that. Many people are, but I would like to give you this as food for thought and maybe as an inspiration for additional constraints that might be some relevance to you. So, the core idea is the following: you take a system which I represent here with three things, and now Things and now you can have components that can be functional groups, that can be atoms, and you alter them, for example, by changing the nuclear charges. That could be introducing a hetero atom in a material that could be doping a molecule. So, nonetheless, you do the individual changes. And you also figure out what does my system do upon those individual changes. Upon those individual changes. After that, it's exactly a Taylor expansion. So you say, well, I have these independent effects, and now I can mix and match them. And because in many cases, derivatives are well defined, we have seen some exceptions. But for example, for the total energy of a system, you can go forwards and backwards because the derivative to larger nuclear charges should be the same as the derivative. Should be the same as the derivative to smaller nuclear charges. Which means you can predict many modified systems. And of course, there might be more interactions and higher orders. I will give you an idea of how far you have to go, but the core idea is this. And I will motivate that for many properties, this actually makes sense. Because your mental model probably is going to be perturbation theory needs a small change. And how on earth is changing an element a small change? An element, a small change. Let's have a look. So, the core idea of this is: let's in towards the large space covering, let's not do many intermediate quality calculations for many individual systems because that happens to be what we can pay for. Let's rather do one high-quality calculation, including the derivatives, and then piece them together, accessing regions and chemical space from one calculation. And chemical space from one calculation rather than terribly many. And I will argue that this is mostly relevant for nuclear charges and positions because that's where the combinatorial explosion lies. The number of electrons or the spin, you can enumerate. Also, the derivatives with respect to number of electrons are not terribly convenient, as we've seen several times. So, this is also helpful to exclude that. Okay, so why is it called? Okay, so why is it called alchemy? Those of you who maybe know the classical free energy calculations, that's where the term originally was coined, that you change functional groups by just interpolating force-field parameters. It works well for them, but for some reason, this has even rarely generalized to quantum systems. Okay, so yes, we do those individual systems. We still do the same systems, but now we approximate everything which is close by. And I will argue that By and I will argue that the number of things which is close by is typically 10 to the 5 to 10 to the 6. We have applied this to many different things. So I will not show you all of that. I will show you a few examples and the slides are online. So if you want to look this up later, it's no problem. So you can do this for energies. You can do this for densities. That's quite helpful. So you also get the predicted, the density. Get the predicted the density change after you change the nuclear charges, and of course, because when you have the electron density, all one electron properties fall out for free. So dipole moments, for example, will be no surprise, but you can also do this for eigenvalues. Maybe not that interesting for this crowd. But it's, for example, depogenation energies, we've used that. And I will show a little bit more into detail our last latest example. Our last latest example where we can learn a little bit about the physics of a system. So, we can do this in very many different codes. It's a little bit non-standard, and this convincing the codes to do that is not so easy, but there are a few strategies, and you can do this with different levels of theory. Now, there's one connection to orbital-free calculations in particular, and maybe that is what Maybe that is what I want to hint at with the title. So, imagine you have two systems: a reference system. So, that's the one that you actually calculate, and you have a target system, which is the modified version thereof. So, now you can show that the change in energy between the two systems is a function of boring terms, the nuclear repulsion change, that's easy to calculate, but Calculate, but after that, you have the change in exotic potential, something we know very well, and electron density derivatives in that particular direction, which means there is a constraint between the corresponding change in energy and the change in density. That could be, for example, interesting to devise more constraints that the energy and density relationship need to have. Need to have. So, the same derivatives that you use that you get here are the ones that build up the electron density that would belong to the same target energy there. There are different ways how you can cast quantum alchemy. This is not the only way to do that. There's different ways how you can get the relativeships, but this is the one that is solarly expressed in forms of the density itself. Now, you might say, okay, you're doing this. You might say, okay, you're doing this terror expansion is very nice, but just because you can terror expand it doesn't mean that A it converges at all, and B that it converges to anything useful. Very simple examples where this is not the case. So here's some example. I'm not proposing that you actually do 40th order derivative, but I just wanted to drive the point home that choose however many significant digits you want. This would be. This would be where you stop your SCF usually, so I think that's that's sufficient. So, what you see here is going from CO to N2, changing the two nuclear charges, and the first few orders already get us pretty close, especially given the fact that this is Hartree-Fock. And the other thing I want to be very clear about from the start is you get finite mileage out of this. There is a radius up to which this teler. Up to which this Taylor expansion converges, even if you were to do 40th order, but at some point you run out of convergence radius. So, to give an idea, plus or minus one nuclear charge usually works. More is probably not reliable. Now, you might also say when I change my nuclear charge, my geometry is going to change. Fair point. So, here's one example. So, here's one example on what you can do with the geometry relaxation. So, the chemical perturbation that we make is going from helium to H2. So, you have one atom. Now, you reduce one nuclear charge, and I can create a new nucleus out of thin air at a given distance. Depending on at which distance I do that, I get a different energy, which means. Which means I get a bonding potential out of the point. So let's have a look how well this works. So you need at least second order because otherwise no potential, right? There's gradient going down, there's a Hessian coming back. So you need second order at least. And that's the light blue curve. That's no good. The correct one is the red-dashed one. Red dashed one, but you see third order and fourth order are basically fine to get the corresponding derivative. So for geometry, it's usually one second or third order. Now, I promised a space, and so for these were small individual molecules, right? We wanted to have something that can not only do one system, but they can do many systems close by. So let's cash in on that promise. Here you see one example of Example of covalent interactions. You have a coronine, the smallest, sorry, not coronine, a buckyball, the smallest fullerene that you can have, the C20, and there's about 3 million unique targets. It's a very nice combinatorial problem to figure out how many of those there are. But the beauty of this is you can reuse all the derivatives. So I need six calculations because of the symmetry of the individual atoms in order to get third-order estimates. Order to get third-order estimates. And that's what you see here. So that's something that with couple cluster derivatives, you can do on your desktop from a few years ago today. And you get an accuracy, which is roughly MP2 accuracy for energies if you come from CCSD derivatives. So that's about 80,000 times faster. You can do this for non-covalent interactions. In this case, now it's the coronine. In this case, now it's the coronine. So we have two coronines stacked, and you can have BN doping on one of the two and figure out which pattern is how to tune the interaction energy. This could, for example, be interesting if you have like a surface sensor sensitive to one particular molecule, but ignorant to others. That could be some direction that we're exploring. And this search space now is getting a little larger, 10 to the 10. 10 to the 10 possible targets, and you can validate this. We validated this with DFT in this case, and that works out now. These were our numbers. And let me say, if hard, very accurate numbers are what you're after, then this is probably the wrong way because it's the Taylor expansion, and the Taylor expansion has an uncontrolled error. It's good. It's good to have a good feeling about where the convergence is going, but it's not great to rely on this. So, what I think is more interesting is the fact that this is a closed form expression that you can look at. It's a Taylor expansion. Every term I can see, I can evaluate millions of systems at once for basically no cost, and then I can analyze them. Maybe the individual prediction is wrong. Okay. Okay. But the overall trends that I get from that, those is what I can analyze, and I can figure out what physical effects are driving a local chemical space. Let's try that. So here's one example. We call this a chemical Nanzimas. So I probably don't have to do much convincing that this one and this one have the same energy. Same goes for these two. Now let's have a look at this one as benzene. As benzene with the doping BNNB and NBBN. Now, you can ask your chemist whether those two should have the same energy and they will say, well, I don't know why they should, because they don't even have the same bonds. There's an NN bond here, there's a BB bond there, but nonetheless, if you look at the perturbation terms coming from benzene to here and from benzene to there, it turns out. And from benzene to there, it turns out that the first three orders are exactly identical, which means that up to third order they are the same. You can do this for a larger system. Here you have naphthalene, B-N-dope like this, B-N-Dope like that. And these are couple cluster energies for the two in atomic units. Actually, is less than one millihardt difference between the two molecules. Now, that pops out of the symmetry. You can't do. Now that pops out of the symmetry. You can't do this with arbitrary doping patterns. I will not go into the details subject to which conditions you can do that, but it's the mapping of the terms. Same geometry. This is vertical, so it's the same geometry. But based on this, if you do that, you can, for example, do this on a graphene sheet, and you can figure out based on that symmetry that there must be a symmetry. That there must be bond energy rules which are universally satisfied. You can generate all possible doping patterns on graphene sheets and apply the symmetry. And you can find rules for bond energies or for angles, all of which might be interesting to have a baseline for, for example, machine learning force fields. To use that symmetry, then this is what you can do here. You can about half the data requirements. Half the data requirement. This is the end doping, the end-doping graphene sheets or graphene flakes here. That symmetry allows you then to fold the two points on top of each other. The machine learning model doesn't have to learn that one and the other are almost the same if you can enforce the symmetry in the machine learning model. Of course, this is an approximate symmetry, but as long as the machine learning model still hasn't reached that accuracy of That accuracy of the error that you make, then it's a helpful way to speed up the model. And because this is a closed form expression, we can generate very many different derivatives. So here what we have is 414 million different ways how to be end of that particular molecule. And now you can. And now you can look at the symmetry and you can figure out: okay, so what kind of accuracy can I? So, what's the ranking of those different doping patterns? What is the driving force? What's the strongest way how to make this molecule stable if I b n dope that? The first one, not very surprising, is you can add b n pairs, but then the remaining ones you can extract from the sorting of the molecules. Of the molecules just because of that symmetry. So you get these design rules as a consequence of chemical and uncommon symmetry without any QM calculation whatsoever, not a single one. You can validate this. We did validate that numerically with DFT again. Now, I would like to go a little bit more into detail on this taking the terms apart. The terms apart to give you an idea how you can use them to dissect physical effects and the interplay of different things within the system. So this is about a collaboration with a colleague in CASA, and they calculate for photoelectron circle diachrism the angular emission. That is terribly expensive to calculate. And most importantly, it would be interesting to see what are the physical effects because you want to design. What are the physical effects? Because you want to design this. If you can design this, you can propose molecules which have strong caropic properties, and that's helpful for experiment to distinguish an LCMS. So what we have is a proto-molecule here with a handful of degrees of freedom. And what we would like to do is we would like to predict what those two coefficients here are. The one Coefficients here are the one tells you how strong the effect is, and the other one tells you the angular, about the angular dependency of the PCD effect. And ideally, what we want is that you can just choose different charges, different elements, different positions, and can tell, so what's going to happen to that effect if I change the corresponding results. So, in practice, this now becomes multi-dimensional Taylor expansion. So, that is not. So, that is not terribly complicated from the math perspective. But it's a little bit confusing because now you have many entangled degrees of freedom. You have the atoms that you can move about and you have the corresponding nuclear charges. So, first of all, can we do that to predict a new geometry, new charges, and see whether that's accurate? That's what we want after all. So, first thing is, can we predict that? And the answer is yes. And the answer is yes. So, in our reference data that we have, a strength of 5.6% was the maximum. And we optimize this for largest and smallest effects. So that works just fine. The number value isn't perfect, right? So there's the predicted value and the actual values. So that I give again. But then the question is, what can we say about the physics? What can we say about the physics of that by looking at the terms? And for that, we have to group the terms because there's too many derivatives in this. In total, there's 85 here. We have 85 numbers, which means we have 85 derivative terms. They need to be grouped, otherwise we don't see anything. So we'll have a shorthand notation. We will say anything related to a charge degree of freedom gets a Q, spatial degree of freedom get an R, and you have the energy of the incident. And you have the energy of the incident light that is the remaining degree of freedom. And now you just count this. So if you have a derivative with respect to position, that's R1. And if you have position and charge, that's R1Q1. All right. So let's have a look at this column here first. That's the contribution to Betten Beta1, so the strength of the effect. That's what's most important to the experimentalist. And so. And so, what you see here is a histogram of the contribution that you get from all terms that belong to that particular group for a million adjacent systems. So, what you see is that locally, of course, the energy is relevant. All first order terms are relevant. That's maybe not as surprising, but the interesting thing is, look at that. As you go to higher orders, the red blob down here, there would be all fourth order terms that we have. Be all fourth order terms that we have, they contribute almost nothing, which is good news. So go to higher orders, fewer contributions, that gives us, gives us, makes us happy. But what you also see is that some of the terms here, for example, R2, are terribly unimportant compared to other second-order terms. So, why is that helpful? It's helpful because now we can figure out how to do that for real molecules. You can say, what kind of physical interaction within my molecule is going to drive the effects? Do I have to change something in the geometry? Probably not. Do I have an interaction between charges and energy? Probably yes. If I change my nuclear charges, I also want to change the energy of. The energy of the incident light. So, in doing this, we can now see how important the individual terms are. Each of those, we can just see what happens if we neglect them, because they carry a cost. I don't get those derivatives for free. But you can see that for a real molecule, the number of coefficients that you have here, they become quite a lot. So that's basically the cost that you have. The more derivatives you need, the more coefficients you need. Need the more coefficients you need. So, ideally, you have a picture where important stuff up here is also cheap, and expensive stuff up there also happens to be unimportant. And that luckily, that's exactly the case. So if we neglect all of this here, then this is our correlation that's perfectly fine for modeling and estimating, informing experimentalists what kind of molecules to consider next. So, this is our speedup that we get. So, this is our speedup that we get. So, if you make the molecule larger, then we have three to the n different degrees of freedom that we can, that different systems that we can look at. And for that, we pay quadratically if we include everything which is here. Now, I want to be transparent about that. This is not standard. So, you can't go to your favorite quantum chemistry code, push a button, and then expect the derivative. And then expect the derivatives to pop out. I wish that were true. So, for the derivatives, as you all well know, those are numerically hard. Of course, you can just do finite differences and hope for the best. That's great, but also expensive. We did this for the 40th order, in case you're wondering, using an implementation of Hardfree Fock that allows to do arbitrary precision. To do arbitrary precision math, so you have no finite difference error, you just pay for that in waiting. But in order to get the true answer, this works just fine. But nonetheless, you see how many Feynman derivatives you know depend on the basis set. What's very new and quite promising, I think, is automatic differentiation. There are many codes that can do that. Some of them are even practical, like PyCfAD. Like Pi C F A D. There is a little bit of numerical issues. So the basis set would change along a chemical change. You have to know what to do. Pseudopotentials are not designed to be differentiable yet. But hopefully this is changing. And the most important thing is keep in mind there's a finite radius. So you can't just do one calculation and expect all of the results to pop out for free. That's not how far we are. But with that, I would like to conclude. I hope that I get. I would like to conclude. I hope I gave you an idea on what quantum alchemy is and how it might be useful in diagnostics and understanding the physics of a system and also in design. So maybe that gives you guys some food for thought. I'm happy to discuss anything. Thank you.