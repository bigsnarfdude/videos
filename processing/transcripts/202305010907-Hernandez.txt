Yes, so for those of you who didn't know this, I'm not from Kas, who was supposed to be here. And so today I'm going to be talking about this project called the Minfield Shortigen Problem Propagation of CAUS, which is something that I was introduced by Ludovic Pompey in the orphan department at Princeton University. And yeah, I try to keep it on time. So let me go ahead and this is the plan for today. I'm going to introduce the protagonist of the whole story. I'm going to motivate this. I'm going to tell you what are the questions we need for. And I'm going to tell you how we did it and what were we able to do. What were we able to do? So, the influencer problem. There are many ways to introduce this problem. I'm going to tell you the one that is of particular interest to us, which is this one. It is an optimal control problem. This particular version with this quadratic cause and this kind of convolution trick going on here was introduced. Was introduced by Julio and some co-authors in 2020. And the problem that they actually introduced is equivalent to this problem. And I'm going to explain why it's equivalent in the later slides. Let me, in the meantime, just highlight what is particular about this problem. What is particular about this problem is this terminal condition here on the loop. That's what makes it special, otherwise, it's just standard. Makes it special, otherwise, it's just a standard backing glass control program. So, why is it equivalent? Leads me to tell you why it is important, this problem. So, let me tell you a story about this problem. In 1932, Schrödinger asked what is the most likely path for a cloud of independent and scattering particles, conditional on knowing their observations at initial and at the territory time. In a determined time. And so, this problem, I mean, he wrote like a couple of papers discussing and giving some heuristics about how to interpret this problem. But it was not until Folner in 1988 that provided a rigorous treatment to this question. And basically, the whole story is that if you model these particles in the right way, the right way mean the dynamical processes. The canonical processes and the canonical space, this question of asking for the most likely path of this club of particles reduces, because of Sanov's theorem, to minimizing the entropy between the reference measure that you give yourself and all the possible measures that can model the evolution of the particles. Of the particles. So, this is kind of like the original formulation of the problem as an entropy unitization problem, again with initial and terminal conditions. And that's the whole story of how this problem, of the Schrodinger problem. Now, this problem written in this way is not quite the problem that I showed you in the previous slide. So, let me just continue a little bit. So, the whole story is that if you assume that you're going to be working with measures that are absolutely continuous with your spell to reference measure, we have, because of well, Gears and Off and that the density of your measure with respect to your reference measure is given by A reference measure is given by this density, which is the density of whatever is happening at the initial time. I'm working with measures in the canonical space. So this is like the margin at the initial time, plus our usual exponential margin. Which means that if you take logarithms and you take expectations of this quantity, you arrive here. Which leads us to the stochastic control formulation of the Control formulation of the Schrodinger problem, right? I have here my product because in this case, I just have a drift here that I'm choosing to minimize this quantity, then I have my initial and terminal conditions. So what does this mean? This means that the problem that I introduced on the previous slide is just the non-independent version of this problem, because I have certain interactions among the particles that are modeling. On the particles that I'm only here. Okay? Any questions? Yes? Can you elaborate a little bit on the boundary conditions? These boundary conditions? Yeah, so we don't know. It sounds like P is the probability measurement, right? Yes, P is. Yes. So the initial condition is a distribution, not a point? Yep. So yeah. I mean, remember it was the initial question, right? The initial question was... Initial question was: What is the most likely path of a certain cloud knowing their distributions at the initial intended? I mean, in particular, I can take it at buses, but I want distributions. Good, but yes? So for sure, the new terminal distribution must have a density, right? If you look at this possibility. Because uh if you look at this process at alpha t dt plus d w t by yes enough you show that the density as a low X t as a density low. Sure, yes, my answer to that is to that is the following. If you want to connect this problem to the shorting problem, yes, but I just want to study this problem. So I don't, I mean, when I write this problem, right? How can you hand a beef grain motion to a with motion to a singular motion. Because you want the terminal lo the terminal marginal load to be some fixed motion. Yeah, it's a that also problem. Yep. But you need that. Unless it will be infinity. Yeah, so it's it's a non-it's a non-something that we explore. Maybe I say something stupid, but when I look at I say some six to be, but when I look at this at this process, I think that for a resonable R charge, we are sure that the machine identity and this is much inhaled. So I mean if I say the rax mass here, this might be invisible? Yes. I think, but maybe I'll say something specific. I mean, this might be the case. My answer would be that when we look at this problem, we're going to be assuming that it's we're going to be working Going to be assuming that it's we're going to be working with distributions that make it physical. So, I was already asking a question. Do you put constraints on the control algebra? Nothing beyond integrability, like square integrability. Finally, I mean, um yes, so I mean to address your question, I am gonna assume that this problem is feasible. Well, there should be some condition. There should be some condition on the entropy between the terminal and the law and the initial law, otherwise, there is not always a solution to this problem. I think the condition is that there is entropy between the mu final and mu function is finite. Otherwise, there is no solution to your problem. The measure mu in and mu final with respect to the reference manager. So, here if the reference measure is right motion, then you have mu in with of a right motion and you find a right motion to lead the otherwise it will be infinity, but it still will be Yeah, I mean yes, so I'm aware that yes to have the finiteness of this problem I've seen this condition regarding a relocate entropy I guess I I'm just gonna go ahead and and just for the rest of the talk I'm gonna assume that this problem has a finite value, which could be I mean, this it would be this kind of condition. Be this kind of condition. Let me then tell you that when we consider the Schrodinger problem in this form, then it is the law of the optimal states of this problem that we interpret as Schrodinger pitches. These are the distributions that we are interested in. Good. What else? What else can I say? Yes. So there is also this nice connection between if you take the same original problem without any kind of interaction and you basically change the volatility of the granular motion, which is equivalent to changing your reference measure. It holds, and it is well understood in this. I mean, there are many reviews about this problem, one by Leonard. About this problem, one by Leonard, other one by Chen and others, but you can show that the value of this problem, this one introduced here, is equivalent to the optimal transport problem between the two measures and then sigma times the entropy between the problem of minimizing the entropy between the coupling of the two reference measures. With this, all I want to say is that. This, all I want to say is that when I consider this problem and I let sigma go to zero, I should converge to optimal transport, which kind of serves as another motivation to why I study this kind of problem and also why some people like Marcel Lutz and Coatov have been studying this optimal transfer with penalized entropy penalization. Okay, so that's kind of for the motivation. So that's kind of for the motivation of this problem. So let me go back to mini bits rotting a problem and what are the questions that we would like to ask about this problem? Well, the first one is: can I just study this problem from a purely stochastic control point of view? And by studying means what can I do? And by study means what can I say? Can I provide any characterization of the solution or provide any existence of the solution? But I just want to be using control QB tools. And also, can I say anything about the experiment of thinking that you have n particles that are conditioned on their initial and final distribution? Can I say anything about the value of this experiment compared to the value of the above experiment? To the value of the above spread. Okay? So these are the two questions that I want to address. Right, so since we're doing control, I'm just going to change to control the usual control notation. So this is how the two problems look. And I'm going to start with question number one, of course. So the admissibility of the controls. So, the admissibility of the controls will take care of the dynamics and the initial condition, to choose the solution to a Mach implants of SDE. And then, of course, the problem is how to address the terminal condition. And the idea here is just to take Lagrange point of view and to say, okay, if you can give me a function from the space of measures to the non-negative real line, Real line, then, well, I can introduce this quantity. And if this function is such that it's zero if and only if I am, the input is equal to my type terminal measure, then, well, I have that the value of the control problem is equal to the inf, then it's oop, because you have the usual condition. So this means that this is one of the conditions that these penalty functions need to satisfy, which we would all agree that. Which we would all agree that we are not asking for that much. Any distance will do at this point. What else do I know? I do also know that because of weak duality, I have this inequality, which leads me to introduce this problem, which is just fixing a value for k for the multiplier and then just minimizing over your invisible controls. And we expect, of course, you will. And we expect, of course, you always when you do a duality, you expect that these two values are the same. And because you notice that actually this quantity here, since this is non-negative, this is increasing in k. So this soup here is actually a limit. And so you expect that when you let k go to infinity, you expect that these two quantities are the same. So that's kind of the plan of how we are going to be starting this project. Again, Problem. Again, we're going to solve this problem and then we're going to send the unit k to infinity and see what happens. Okay? Good. Now, so this leads to a definition. So we said that G is a penalty function, what I already said, and if you give me a penalty function, we can show that it is. Show that it is the case that you have a strong duality. The limit of the penalized problem is equal to the entropic problem, which is good, right? But now I'm kind of here with this problem, right? So this is a Machine Plus of control problem and I want to study this problem. So the only well no, I say the only, but the tool we choose to study this problem is Choose to study this problem is via the stochastic maximum principle, which immediately tells us that, well, G cannot be just this, right? We need to ask something more about G. And for those who are familiar with, we need this to be differentiable, and we need this to be differentiable in some sense with respect to measures, and we're going to be choosing the sense of differentiability, which leads to what is our interconnection. What we are going to be calling a smooth penalty function. So, again, the first condition is just to have strong duality. The second condition is to help us in actually being able to understand or say something about this problem. Again, the strategy is the same. Once we have solved or said something about this problem, we want to pass it by as KOS infinity. Okay. So now is when, or some of you might. Or some of you might say, Well, do you have any examples for this? Because I mean, one is easy, right? There are many. Take any bash and but with two you start asking a bit too much. So I'm just gonna tell you that, yes, there are some examples and let me just briefly go through some of them. Your first test is not a good guess because it's not differentiable, which is the first guess being taken. Which is the first guess being taken to the Bachelorstein 1 distance. Then your second guess would be to take the square of the Barchestein distance, which is a better example, but not very good, because there is this paper of Alfuncina and Jordan that says that this guy is only differentiable if mu final is a Dirac mass. So meaning that this is an example when your tiger measure is a Dirac mass, which is some of you. Which is some of you might say that it's a bit too simple. But let me just tell you that, I mean, at least if you consider this problem, there is some interpretation. You can reinterpret this problem as some problem of optimal liquidation, right? You want to drive all your assets to zero at the end of the terminal attack. What other examples do we have? So now is when the people in So now is when the people in the room start to pop up to help you. Functibility is related to the uniqueness of transports. Why does it reduce to JIS? Should be equivalent to unique as a transport. Yeah. What is your question? Why is it re does it reduced to linear to delta X0? Delta X0. But we can discuss that first. Yeah, I mean, my first, I mean, we can easily go and look at this paper, which where they have an if and only if condition, right? This guy is going to be differentiable if and only if this guy has a unique transport map, which is the case only if you're transporting to a direct mass at the end. But we can look at the So, more examples. Then Jan Feng enters into the room and he has this paper in his causes the solutions to the master equation where he introduced this idea of modifying the Bartisan one distance. And basically, what his result says is that there exists as for you take As for you take this function in the space of measures, I can construct a sequence of measures that converge to g1 as n goes to infinity, locally uniformly, meaning in compacts. And these guys are single. So this is one example, but it will introduce like an extra approximation step in the analysis, but it's still possible. And then they introduce this. And then they introduced this idea in this paper and just very recently there is this other paper that does kind of the same idea but they modify in a different bas they approximate in a different way these functions. Cool, so let's say we have two examples. Then comes Meht. Mehti has this paper, which I think is the one that's gonna be presenting. The one that's going to be presenting, where they introduced this 40 evachest time metric on P1W1, which you can just think as a small version of the Bachelor time one distance, which is exactly what we say. So this is actually like a good example. And then interesting in the room, they have this paper where they are also working with With pink viscosity solutions to the master equation to marking class control problem, if I'm not mistaken. But they introduce this idea of, or they introduce and construct a gauche function for this space, which again is essentially a smooth version of the Marshall spine to distance. Okay? Which is actually what we need. Okay, so these smooth penalty functions exist. That's Functions exist. That's the whole point of this slide. Good. Can I ask another question? Another way of penalizing would be to penalize with test functions. So you want for every smooth function, CB1, expected value of f of mu equals expected value of f of mu for every test function. Yes, but then you For every test object. Yes, but then you do the min-max, I mean the usual duality in Oxford Passport. Instead of having an inf over k that you are doing, it will be inf over over smooth. Yes. But what's the problem with that? That's my question. With that approach? Yes. Because then if you if you switch the inf the the j max, then you end up with the linear function. And you end up with the linear function of Major S by density, you can choose F. I mean, we did not consider this approach. We poiled this one. But we are more than happy to. You said that it was talking? Maybe the option of the view is here it's So yes, so we went this route. Long story short. We went this route. Uh and uh yeah, we are not talking on the on the uh The empty set. So I'm allowed to keep continuing talking about a smooth ND function. That's the whole point of this. Okay. So now, well, we are in a good point because we can then go and study the penalized problem, right? So this was the original problem. So as I was mentioning, So, as I was mentioning before, to make our lives easier, we're going to be assuming that the value of this problem is finite. And in this particular formulation, which is like the guiding example for my talk, I'm going to be assuming the same context of the original paper, which is working with some interaction potential, and then he's just considering this convolution. Uh we're also going to assume that it's symmetric, and we're going to be assuming that it's twice differentiable and just continued to evolve. Differentiable and just containers. These are the only assumptions that we need for the mods. So, yeah, so I go and I penalize using my gauge penalty function and then this leads to the following result, which is basically a combination of using the fact that your cost function is complex and forts easy to extract. And for ERC to extract a sequence of admissible controls that are kinda converged to the optimal. Therefore, this is important that we are assuming that the value of the product is finite. But once you have that, we can show that it admits an optimizer. And then once you have an optimizer, then this focusing maximum input tells you that the optimizer is related to the solution to this problem with this kind of information. Where, of course, the problem that we are gaining is the fact that the terminal condition of the wide component of the LVSDE has this K in front of it, which is gonna be an issue when you try to send it to Infinity. So that's the whole thing that we need to be careful with this approach. Okay. Now how How do we do this? So, let me show you the first result that we have of this problem: is that this problem admits a mean field Schrodinger bridge with associated control alpha hat. The Schrodinger bridge and the control are related to this system in the following way. Then, the system has this particular feature that, of course, the terminal control. Of course, the terminal condition on y went away because I, from a practical point of view, was a problem. So, of course, that should not be appearing in the limit. And in exchange for the terminal condition on y, we end up with this terminal condition on the log x bar. How do we get here? So, as I mentioned, so we already have a system for the k-penalized process. For the k penalized problem, and it's all about passing to the limit. And the penalization at time k with value k gives you a relationship between the k penalized optimal control and the k value of y and also with the dynamics of x. So once you have that sequence for yk, if you're also able to define a sequence for z k. CK. It's all about showing that you can use those to arrive at this marking girl in the link. Where once you have been able to show that this guy is a martingale, you know that the C popping up here is the C associated to that marking girl. Okay, so that's the whole idea behind this result. So that's what we were able to see. What we were able to say about this problem, and how much time do I have left with it? So now let me turn to the other question that we were interested, which was about the limit as n goes to infinity of this experiment. And of course, so what is the idea? The idea is to penalize everything, right? So we're gonna take this problem, we're gonna penalize it. Problem, we're going to analyze it. This is going to introduce this problem NK. And the idea is just to know that by weak duality, you have an inequality between these two problems. This quantity always have assigned. And so this, which is the quantity that you're trying to optimize, you write it in this form. This tells you that you can forget about this part because you're going to get this inequality. And this, we already know. This was our structurality. This was our duality result. So it's all a matter of controlling this for fixed k as n goes to infinity. But in a way that when you're sending the k goes to infinity, it doesn't mess up your convergence. So let me just say a few words about this. So we present two scenarios in which we can establish this relationship. One of them is Of them is very straightforward, which is just including complexity. So this is just an slice saying that once I analyze the end particle version, I can do maximum principle there again. So this naturally introduces this FPSD, which also has the same kind of problem with the terminal context, right? And then of course the problem is how to handle those terminals. The problem is how to handle those terminal conditions because they're going to be blowing up when you send categories. Good. So now let me tell you one way in which you can handle these terminal conditions, which I already went ahead of myself, and I'll say that is using convexity. So if you have a penalty function, which is this Playman convex, you know that this inequality, or that's just literally the definition of displayman convexity, there is a This frame complexity. There is a type over here. This guy is one. You can take it as one. There. But then what happens is that when you then go and do Ito to this product, well, this is going to be the terminal value, which you get this inequality because of this learning complexity. And then from Ito you get some terms that are nice. But the good thing is that for the particular case of this quadratic cost, you get This quadratic cost, you get minus this quantity, which you can then pass to the other side, and then you can actually forget about this. You can drop this term, and you're going to have this less or equal than something that is next. So that's how things work in this complex case, which leads to this result. Now, the question at this point is: does this guy exist? Does this guy exist? Is there a display in. Is it, can you say that new final always admits a display in the convex penalty function? And there we are start to ask for a lot, meaning that we cannot produce a lot of examples, but we can give you one example, which is the other example that I already illuminated, because for this function you can actually compute the derivative, uh I can actually compute the second derivative, I think it's uh uh two. I think it's two, which means that this penalty function for when mu final is a derived is displaying convex. So this is one example where we can have this result. But then, I mean, one, something that is going on between on the side of this result is the fact that the penalty function is a degree of freedom, right? You will take any penalty function, a small Any penalty function, a smooth penalty function. And of course, this naturally raises the question: can you cook up a smooth penalty function that is displayed convex for any target measure? That we still don't know. We have tried with the gauss function, the Fourier vaccine, but it's not clear to me yet. But this is one example. And then we give another result which is based on Gilzanov and quadratic BSDEs. Because you think that since you do have proper Gilzanov, those FBSDEs, you can get rid of the drift of the forward part. It's going to pop up as a quadratic term in the ESDE and then you can match the loss if you do the gears and if you do Gearsalov, changes measures to both the end problem and the limit problem. end problem and the limit problem, you can match their loss, which are going to make the y capital D term cancel when you subtract them. The problem there is that you're going to be dealing with a quadratic ESDE. So when you try to do your isa priority estimates, you need to, for instance, make sure that the C is finite so that you can use your estimates. That's the other result that we have. And so Uh and so this is basically just a summary. So with this parallelization approach we provide the existence and characterization results of the mean future shortening problem. We are also able to establish some convergence results which I should mention that they are new even for the without the mean field but take the interaction not equal to zero. There was no proof about the convergence of the M problem to the new one. In the paper, we consider, of course, more general trees and cost functions that as long as you're able to separate them and this guy is sufficiently convex and coercive and nice close, not necessarily quadratic, the same kind of results are going to hold. In general, the neutral short-digen breach and its associated control, there are always limits in law of those K-penalized problems, which, I mean, sure. Which, I mean, sure, that's a result, but the nice thing is when you can actually write down this planning FBSD for the new gen product, right? This object is not well studied. There is no well-posed results for this kind of weird FBSDs. No terminal condition on Y or terminal condition on X are not available. But this approach suggests one way to approximate solutions. One way to approximate solutions to that problem, penalizing. And also, I'll just mention that as part of what we would like to do now, just to extend this penalization approach to the causing of this problem, which is called the planning problem, which is just essentially the mean filtering version of this problem. And with that, um, Peter, thank for some questions. One question when you first was able to actually change the initial and final distribution, because initial distribution you can consider those particles to final, but you can also say this is just positions for some particles. Then you may be interested. Then you may be interested in knowing also the initial distribution and the terminal distribution moving with L? And to uh distribution from the infinite would it make any difference or okay so let me just make sure that I understood your question. So you're saying here, right? Yeah, new would be indexed. Right? Yeah, new would be indexed by then, actually. Yes, okay, and but I guess this would be some intermediate step. I mean, okay, what's on my guide is the following. What is the end particle description of the Schrodinger problem? Right? The description is the technical distribution is to be fine. So, sure, that's a problem. So sure, that's a problem to study, but it it will be like adding an extra index so that when you let that index grow or whatever, converges to this one. Yeah, we didn't study. Our motivation was, well, this seems to be the pro appropriate description of the N Schrödinger, n-particle Schrodinger problems to focus on that. Results. Yeah? What we do, I will have to put something similar when we are ready in a measure which is in Iraq at the end, because we want something, you know, better definite uh entropy, we have some noise to solve the problem with the noise and then we go with it. I don't know if you if it's also what you're This is also what we are going to call. This is also one way of defending it. And maybe the second, a very, very quick comment. When you say that you take the passenger to the Europe, this is just the second one at all, you know, basically. So I don't know why you need to see passes time transport between mu and a point. But in this g right of mu g, this is basically a separate moment of the right. Or maybe just for a copy like just write I mean, so my point there is that to be able to write those FBSDs, I need to make sure that the G that I'm taking is differential. And for the convergence result, I need to make sure that that G is actually complex. So, I mean, the whole point with the bar system is that that system. With the varsity stand is that that is an example where I can easily compute the derivatives and they are complex. So I don't know if that I'm answering your question or not. I want to see it as the fastest one because then when you take the derivative, you can take the solution, like the large potential as the I can yes. So you write the derivative in terms of the transport map associated to maybe just because this is. Maybe it's just because this is related idea. I mean, you should put it in the direct mass. I think this is a question about Stefan before. I mean, here you're fighting against a bound motion with just a crystal. So in that case, most probably the problem is just infinity. So there should be a way maybe to circumvent this problem that you think was you won't find your problem that you discussed. You repeat that, that's right. The convex property, so not an example, but which worked in the case where mu phi is at the back. Yes, and probably the problem is just plus infinity in that case. Maybe there is a ball set with the simplest case, we have psi is zero, but no convolution. So you have no convolution. The other solution that we know, the optimal alpha for the simplest problem, not in propagation of colours, but the first one. The direct mass idea. You know alpha? Alpha cannot be zero. I'm sure that. I want alpha close to zero, but it's impossible because I have brain motion, so I cannot end up to a limit. So what is the solution? What is the optimal alpha? Alpha, what is the solution if we apply this your M inspires zero? So it's something that maybe I miss something and I'm very sorry. I don't want to push forward. Give me the simplest problem. Psi is zero and give me the solution. What is And give me the solution. What is the optimal alpha? Give me a description of the optimal alpha for the simplest problem, where at the end I have a direct math. Will you notice? Yes, exactly. What is alpha? The gradient of the logarithm, the expectation of density of the M line. I mean, which is what? Because it's a direct installed inverse, so I don't think so. I don't know. But what's your problem? No, no, my problem is I take the simplest problem I can imagine, psi zero. I just have a trispolement motion, and at the end, I have a direct direct measure. Because I want alpha as close as possible to zero, but it's impossible. But no. You have the static page to a point, right? So you have the value function. I would like to do a description of this result for the single side. I have two two questions on robustness. Two questions on robustness. One is: can the results go through if the cost is not quadratic? Some arbitrary convex function? I mean, what we did, we signed it up. You can make it depending on everything as long as you can separate them this way, and here you need to add more loss. Sorry, atoms quality growth. At the row quality, but if it's two because it's not gonna lose the lesson. I don't know. And the second is, what if you only restrict what you call the address to the signals? Is that a problem or is it at least the signal? I mean, I think that would be a problem. Sorry to interrupt. That's music. We started late because of the presentation in the meeting. 