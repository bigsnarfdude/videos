Okay, I would like to talk about some recent results made in collaboration with various colleagues, Julio Colombo from the University of Naples, Edigreso Souza Gama from the University of Recita and Pernuguco in Brazil, Marco Maria from the University of Como and Mart Priguli from the University of Milan. The purpose of our investigation. Our investigation is to study for which kind of manifolds rigidity results for entire minimum graphs which hold in Euclidean space could hold as well. So the setting would be the following: we have a complete We have a complete Riemannian manifold with a metric sigma, and we consider graphs of functions in m cross R. And we wonder whether, when the graph is defined on the entire M, whether this is original. Well, the choice depends, the notion of minimality itself, on the metric we put on the ambient space, and for this talk we choose the product metric. We choose the product. Other choices, whatever product choices are admissible elevators. We denote with G the metric induced on the graph. And since we have a global chart, we can think that the graph is M itself endowed with a different metric. So we can compare G and sigma. Sigma. We compute the mean curvature, and actually, sigma is meaning. And actually, sigma is minimal if and only if the mean curvature is zero, and the mean curvature gives rise is exactly this quasi-linear operator, where d is the gradient in m sigma. Interestingly, call it ms. This equation rewrites as the harmonic equation, Laplace equal to zero to zero, when we consider the Laplace of the graph matrix. With graph function, it is harmonic. function is harmonic in the graph method. A method which in general you do not control. But there's a parallelism between the theory of minimal graphs and the theory of harmonic function for some in some respect. Okay, what happens in nuclear space? Well the cornerstone result is a bursting theorem that says that if you have a solution defined That if you have a solution defined on the entire space, this is actually necessarily an affine plane. And this volts if and only if the dimension is at the center. This is a classical result known since 1915 by Bernstein dimension two. And in the 60s, there has been this huge amount of work to give a full solution up to a counterexample given by Vierda Georgia and just in dimension at this eight. Okay. Okay, well, if we assume a priori condition on the graph, there are rigidity results which follow regardless the dimension. In particular, if the graph function is above some code, meaning that the negative part has linear group, then the graph is affine in any dimension. And it's, in particular, positive solution to the minimum surface equation of constant. Note that the three properties in Note that the three properties implies B1 implies B2 and B3 implies B3. And B2 and B3 are obtained later with different tools. I just mentioned that there is still an open problem, a big open problem, coming back to the paper by Bomberi Justi, whether or not the solution to the minimum hyper surface equation draw. Must have to surface equation grow necessarily polynomially at infinity, not exponentially. And this is still open. And the question we address is for which kind of manifold we can expect results somehow similar to those. First observation is that in hyperbolic space, the picture is completely different. You can solve Plateau's problem at infinity. For every continuous boundary data, you can find a graph, minimal graph, unique. Graph, minimal graph, you make attaining this data at infinity. So you have plenty of bounded minimal graphs, plenty of positive ones because minimal graph equation is invariant by translation, because DT is killing. And this is due to Nellian Rosenberg, the Spirito Santo for Northern Court. And since then, there has been entire literature establishing the sharp pinching condition on the negative curvature of a Cartana-Damar manifold to guarantee the solvability. Damn manifold to guarantee the solvability of the plateaus problem. So by now, the problem of Catharin existence, problem of Catharina Damar manifold, or Plato's problem at infinity is very well understood. So the nature of assumptions to ask for something similar that happening in a previous basis, asking that the sectional curvature or the Richie curvature is no negative on our map. For various reasons. First of all, because the criteria space is the biggest such manifold by comparison theory. By the analogy of the theory of harmonic function developed by Cheng Yao, Shen, Chigarpo, Di Vinikov, Si Li Pang Wang, and for us will be a strict analogy because manifolds of such kind admit tangent corners. Admit tangent constant infinity, meaning we take a divergent sequence, any fixed origin, we scale our manifold by looking at it far behind, far at a far distance. We have a limit, which is a non-smooth space with no negative reach for the blowdown or a tangential cognitive field. So we have blowdown, which we do not have in our space. What happens? What happens for property B1? As far as I know, this is the only result which is a sort of for chlorine. I don't have a precise reference. If we have a manifold with a richie curvature non-negative, but the volume growth of this manifold is very low, quadratic in this integral sense. Then, if you have a non-constant solution to the minimal surface equation, then the manifolds. Then the manifold split, and the solution is linear. So you have the conclusion of Bernstein theorem, but only in very low growth conditions. So P1 holds for those manifolds, and it applies to surfaces with no negative such an operator, giving, let's say, another point of view, the original person. This is a simple argument by a parabolism. Apart from this, I do not know any counterexample to the possibility that Bernstein theorem holds up to dimension seven, maybe up to dimension four or five in manifolds with non-negative section. Very recently, Chodoschlier and Stryker proved that if you have non-negative sectional curvature, bounded curvature, bounded curvature in a sense of local. In a sense, of local chips, you want chart, and uniformly positive scalar curve than you are covering today. But I do not know any result with all this actual group. Even the recent striking achievements on the stable bursting period in Euclida space by Chodosh Li on one side, Catino Masseriero and Coroni on the other side, and very recently Chodosh Lee, Stryker and Winter have some tools. Have some tools, have some argument that strongly depends on the fact that you are in the limit space. What about B2 and B3? If the section is non-negative, we have this, we will concentrate on the non-negative rich curvature. Okay? But what happens for non-negative sector curvature? For B2 and B3, the best you can follow. If you have a graph which lies above some cone, Above some cone, then the manifold splits and the graph is linear, any dimension. So you have extension of the results by Bumperi, the Georgi, and Biranda to any manifold with no negative searching. Let us see the proof. Sorry, you wanted to take a picture. You succeeded? No, let's. Okay, it's great. But the this is for graphs. Okay, you are referring to this one or the other graphs. And if I'm not incorrect, the Comparede de Georgi-Justi example grows like R to the three over two, if I'm not incorrect. Doesn't have linear. Okay. Okay. Okay, the strategy. This is not difficult because it's basically joining the points and applying previous strategies. But serves the purpose to illustrate the difficulties when you go to non-negative region. The strategy is borrowed from Shigerkur, Diminikozi, and Mozer. First step is to prove that if you are above some code, you are actually a leap sheet spread. Actually, a Lipschitz crep. Okay. And this is a gradient estimate which was done, for example, by Rosenberg-Schulzen's program. The second that blowdowns split off lines. And performed by step two, there are two. Well, first, if the gradient is in any fit, you can also blow down the function by a score of zr, which you cannot do if you have. ZR, which you cannot do in general if the function is not initiated. And to show that blowdown split, you basically have to prove these two inequalities, that the average of the gradient of the function converges to two, meaning that the function gets more and more steeper in average. And then the average of the hash and properties in the scale to make it scaling variant converges to zero. Once you have these two, Once you have these two, you pass to the limit in a reasonable sense, and the first inequality says you that the limit function has non-zero gradient, and the second that it has zero hash. So the flow of this function gives the splitting of the menu. Okay, morally, it is this way. Technically, you have to use a genie splitting theorem pass through only function, but this is this is. But this is step three: if the tangent tool at infinity splits, the manifold splits as well. And this is a very specific fact of non-negative sectional consequence of the cornobo. And it is the point where sectional recurator is strongly used. And step four: once you have produced a Euclidean factor, you have a killing field, you consider the derivative in this. You consider the derivative in this kid interaction. This solves a uniformly elliptic PD. This is an argument of Moser, but you have a global ironic inequality of a magnitude with magnitude curvature, so this is constant. Partial derivative in S is constant. So you use a linear function of S plus function of something, some other variables, so it's a function of N. And you iterate. Produce eventually the other factors. So that's the idea. The idea: What's the problem when you have only a reaching kerbat in connection? I will say more on this. We'll say more. Perhaps this perhaps you use the You use that the grade U is bounded to say that the linearized operator is uniformly. Okay, but you don't use, I'll tell you how you use the distribution. The problem is exactly this. Step one, to get gradient estimates and to get the key inequalities that allow for the splitting of the tangent coles, you use the distance function. And if you use the distance function, you use the same. And if you use the distance function, you have to compute in those arguments the Laplacian of the distance function in the graph. If you have a control on the sectional curvature, you can control this Laplacian. If you have a control on the Ricci curvature, you can only control the trace in the matrix sigma. So you cannot use, even if the operator is uniformly elliptic, you cannot use the distance function to look at this. Okay, you have to find different. Okay, you have to find different arguments or some replacement to the distance function. Okay, what we were able to prove is the following that positive entire minimum graph are constant. Okay, and this was achieved by us and by Keating at the very same moment with different groups. Very interesting. And this was previously shown by Rosiber-Schultz and Sprock under a further condition on the sectional curve functions. And it parallels what happens for harmonic functions, Schoengia estimated for positive curve functions. Okay, recently we made a progress on this. So it's not necessary that the graph is positive, but basically that the negative part grows. The negative part close almost sublinearly, and one month ago, Ding did even better. Sublinearly means constant. Very nice paper. The technique is different from that one. And I'm going to talk about this technique because there is a gradient estimate that I believe is interesting in other settings. What happens for B2? For B2, we have been able to prove that if you solve the minimal surface equation and your gradient is bounded, then actually tangent could that infinity split, ever tangent could split. But the manifold may not split off any line differently from the sectional alternative case. There is an example in dimension four. There is an example in dimension four, which has actually not only positive Ricci curvatures, leaving positive so it doesn't split any line, but it has richy. This middle Richie curvature is defined as the infimum of k-dimensional sub-manifold subspaces of X-ray togram. It's an intermediate condition between Ricci and sectional. And it's a partial you trace on k-dimensional subspace, the section, the sectional curvature. And this example has reached two bigger equations. So you really need to split, you really need a section of bigger equations. You really need a sectional bigger potential to split the manifold and not only the tangent. Okay, and this parallels what happens for children. Unfortunately, we haven't been able to replace the u in an infinity with the u above some. We have been able to prove the gradient estimate, which is the only thing that lacks for the result, let's say, to be sharp, under further conditions. Conditions, and this is there are three different further conditions, mild completely skew one another under which one can prove gradient estimate, but there is still not a general proof of gradient estimate when you are above some only under reaching of magnitude. Okay, that's what let's move to the proof of this result. My plan is to prove this result. My plan is to prove this result and to prove the key integral inequalities for the other instance. Okay. The previous strategies proved the local gradient estimate by something exponential. We haven't been able to prove local gradient estimate. We have been able to prove a global, directly a global gradient estimate. And this is our. And this is our result, and it works in a rich bounded below. Suppose you have a solution to the minimal surface equation on an open subset omega sigma. The sigma graph over here. Suppose that these are technical. Either the value of u is constant on the boundary or the boundary is not too bad. Okay, meaning that it's locally Lipschitz and the growth of its area is at most exponential. Then the supreme The supremum, the value of 1 plus du squared, divided by a precise exponential factor, is no more than the maximum between the value of the boundary, sup at the boundary, and 1. In particular, if you have no boundary, you have this very neat gradient estimate. For k equal to 0, it gives 1 plus du squared less or equal than 1. So, graph is constant, and the graph is positive. In particular, if reach is bounded below, bounded entire minimum graph have bounded gradient. This can be applied, for example, if you have a solution to an over-determined problem. Let's say a CMC graph. For CMC, you have an analogous estimate with the constant boundary data and constant derivatives. So a capillary graph. A capillary graph. Graph, a capillary graph in a manifold with no negative energy character is bounded gradient, okay? Because this term is bounded and this condition is okay. The proof depends on the Jacobi equation. So we consider the Jacobi equation for one over w is the angle between. 1 over W is the angle between the normal and the killing field. For a vars method, localizes this function w by a carefully crafted cutoff function that depends on the distance in m sigma and on u and was able to contradict the maximum principle is that if the gradient is too steep. And the problem is that we cannot use R. So our idea is that in place. So, our idea is that in place of R, we construct an exhaustion function by means of potential theory. And this is an application of a duality principle which was discovered with the Nelebertorti in 2013 and then developed by Leandro Pessois in 2020 in its more general setting. Okay. So the first point The first point is that we needed to understand how Corebar's method works because at first size it seems quite miraculous. And actually, the method was somehow as important. We fix C bigger than our exponential threshold radio and define z w e to the minus c. What we want to prove is that for every fix of toe positive, for every toe this set is empty. Once the thesis is shown, you let tot to zero and then C to the sharp value. Okay, suppose that this is non-empty, so this is omega prime. This is omega prime, and this is sigma prime. This is an upper level set for C. On this upper level set, C satisfies a nice equation. If you define this weighted operator, Lg of Z, so it's a weighted Laplacian, is bigger or equal than a constant times C. A constant because here you have chosen C bigger than the threshold and the gradient does not go. And the gradient does not go to zero on this upper level side by its very definition. Okay, this equation is nice, but it's not enough to have a Lubil theorem only by this equation. The key information we have to use is that the graph is calibrated. So we have area bounds. Okay, so a piece, a ball in the graph. A ball in the graph can be estimated by the value of the boundary of this cylinder, and this grows at most exponentially since you have rich bounded. Once you have exponential boundary, and the two conditions on the boundary are designed so that the calibration argument. Once we have this nice volume growth in here, we double the manifold and we construct a complete boundary-less manifold with at most exponential growth, in particular at most square exponential growth, by simply doubling and putting a tiny link. Why these manifolds are interesting because if you have a man, If you have a manifold which is complete and the volume growth does not grow faster than a quadratic exponential, you have a Lubin theorem of this sort. Bounded, if you take any open set in N, a bounded subsolution of this equation attains the maximum at the boundary if the maximum is non-negative. This Louvre theorem is one of the many equations. Is one of the many equivalent conditions of the manifold to be stochastically complete. If you heard about it, it's the property that the Brownian motion does not explode in finite time. And it is one of the many equivalent conditions. And we use this duality. The property that the Lubian theorem holds for bounded subsolution is equivalent. Solution is equivalent to the possibility to construct an exhaustion super solution. Equivalent. In general, if you are able to construct a super solution which is an exhaustion, this gives you a Libre theorem by Fragment Leader of Method. Comparison theorem by Lubuski. But they are actually equivalent. And we use the other implications. So we produce the exhaustion. Produce the exhaustion. This duality principle, which we call Alfos-Karzninsky duality, because the new theorem, Dubit property is something that resembles something that Halford's doing for parabolicity, actually holds for many fully non-linear operators. First order, second order, non-linearity needed. A UV theorem for bounded subsolution is equivalent to the possibility to construct exhaustive supersolution that grows at infinity. Solution that grows at infinity as small as you wish. Okay. So now we have this supersolution. We take the log of V and we have a non-negative solution of this. And we use it to localize. So instead of C, which is W e to the minus Cu, we put an epsilon rho here and we Silent row here, and we subtract that. So since since u is positive, since u is positive, okay, for parameters small enough, this upper level set is not empty, which is given by replacing z with zero. But this upper level set is relatively compact. This is omega zero prime, relatively compact because Relatively compact because u is non-negative. So the part in the exponential goes to zero. So you see that the function is negative outside of a compact state. And we compute the L of G zero. You have an epsilon difference here and an epsilon there. You put almost all C by Young inequality on du square. The price to pay. Square. The price to pay is a big constant multiplied by epsilon prime, depending on epsilon prime, multiplied by epsilon squared. But if epsilon squared is sufficiently small with respect to epsilon prime, you can bound by epsilon plan. And the first, if epsilon prime is small, it's still positive. Bigger than the con, bigger than the constant as it was. As it was for epsilon prime, so now you use the fact that gradient and Laplacian satisfy this, and you still have an equation of that store, but on a compact upper level. So you contradict the maximum. Okay, so what we realized is that for core core method rearrangement, you don't have to. The rearrangement don't have to estimate the gradient and Laplacian separately, but you can estimate them jointly. And up to passing to the log, you forget about the Laplacian. Okay, so that's why the theorem works. And I think in the last 11, 30 Thirty so I have okay, yes, okay how to split tangent cones if the gradient is bounded so we have only have rich in or negative and gradient bounded if the gradient bounded the Laplacian is uniformly elliptic so if you Is uniformly elliptic. So if you multiply by W, which is bounded, W square root of 1 plus Q square, we have a uniformly elliptic operator in divergence mean. And we want these two inequalities. For the Laplacian, to estimate this in the case of harmonic functions, there are two methods that I know: an elliptic method due to Chigar called Diminikozi, and I guess also Lien Tan has. Lien Tan has it in the paper of the heaven and a parabolic method. The elliptic method still uses the Laplacian of the distance function in the graph. And even if the operator is uniformly elliptic, you cannot estimate L of the distance function by only knowing the Laplacian of the distance function. Okay, so still you have problems. We choose the parabolic. Problems, we choose the parabolic approach, which was developed by Peter Lee in a paper of 86. How does it work? So, okay, we have the function whose mean on both we want to estimate: sup of du squared minus du squared, no negative, and this is. And this is superharmonic for the operator L. Square root of 1 plus du squared. So w square is 1 plus du squared. 1 minus 1 erases. That's exactly the. So we have a super solution which is bounded. F is bounded, non-negative. And the other quantity whose mean we want to estimate is. Estimate is actually depends on LF, is bounded in terms of LF. So, what we actually want to prove is that if we have an elliptic operating on a manifold with no negative reaching permit and a bounded supersolution, then the average of F converges to the infimum. In this case, the infimum is. Infimum, in this case, the infimum is zero, and we are done, and the average of LF converges to zero. Okay, that's what we want without loss of generality. We can assume that the infinite is simple to translation. Okay. We take F and we let it flow by the heat equation. Since F is bounded, this is known that the solution is given by integration against a heat kernel, a kernel for the operator L. In particular, the solution stays non-negative and is bounded by the L infinity bar of F. And important for us is that on a manifold with non-negative rich curvature, For with no negative energy curvature, the heat kernel has a two-sided bounce which are Euclidean. So it can be bound up to a distortion factor, which will not be important for us, by the kernel in Euclidean space. I wrote the kernel with balls depending only on one point instead of half a bit ball of x, half of it ball of y, because we need it later. Because we need it later, and that makes the appearance and makes these vectors appear, but it's not important. And the time derivative as well is bound, but not the space derivative. The gradient of the heat kernel is not bounded. It is bounded for the Laplacian by Li-Yao in importance. But here we have only an elliptic operator, and the coefficients of the elliptic operator are bounded in L infinity, not their gradient. To get gradients. To get gradient space gradient, you need a bound on the derivatives of the coefficient, which we do not have. We want to show that the spherical mean, the mean on balls go to plus infinity and the ball of radius r is by scaling questions, play the square root of t plays the role of r and this relation was proved. Relation was proved in Ukraine space by Replik of Heidelmann in the 60s, and Peter Lee gave a different proof in 86. Maybe just one observation, quick look at those those averages are taken on balls even though the operator is not isotropic. So that may look a little bit strange. That may look a little bit strange. The operator is elliptic, but constants do not appear in the estimate. It goes exactly to the infimum. Okay. So here is the relation between the heat, the solution of the heat equation, and the spherical mean. If you write the solution of the heat equation and you get a lower, take the lower Get a lower, take the lower bound for the heat kernel. You integrate on b square root of t instead of n. f is non-negative, so this bigger or equal. And on this, all the factors come out as a constant, bounded by a constant, and you get a spherical. So, you to say that the sphere, the mean on balls goes to zero, it's enough to. It's enough to say that the solution of the heat equation goes to zero. And you fix x and t and you compute the time derivative of the solution. You can put the time derivative inside and you consider the exhaustion of M made by lower level set of the heat curve. By lower level set of the heat kernel. For XT fixed, the heat kernel goes to zero exponentially. So you can use upper level set as an exhaustion. You use them. DTH is LH. And then you integrate by parts. And luckily, the point is that if you integrate by parts, the boundary term cancel. Okay, not cancel. One of them cancels. One of them cancels one when h minus a appears, and the other, the normal derivative, is not positive. So at the very end, the time derivative is positive. Okay? This is the approach of Peter Lee. We just observed that you can use level set of eat kernel instead of balls. He used balls and he needed to deal with the boundary terms. With the boundary terms, and he dealt with his gradient estimate. So the solution converges nicely enough to a bounded stationary solution of the heat equation whose infimum is zero because the infimum of the initial value is zero. And the function is non-politically, it goes down on the trajectory, so the limit is zero. Zero. That's how we prove the estimate, and that's how we extended and somehow simplified this. Last two slides, our contribution showing why this works. I didn't find it in the detail. We were very happy. I'm a bit surprised not. Happy. I'm a bit surprised not to find it in previous work. We start with this, which is integration by parts on a level set. And now we use strongly the two-bound for the heat kernel that allows us to estimate, to bound the upper level sets of the heat kernel efficiently by bolts. In particular, if you choose how If you choose alpha of the order of a ball one over the volume of the ball of square root of t, one can prove that one can choose delta depending on the ellipticity constants, ellipticity constants and those appearing in the heat kernel, and k such that the ball of square root of t is contained in the set where h is bigger than 2a and the set where h is bigger than where The set where h is bigger than where h is bigger than a is containing the ball of radius k square root of t. And now, how do you conclude? Last slide, almost last slide. The mean of LF, you write one over one of the volume as A over delta. Now, Now, on the ball of radius t, h is bigger than 2a. So h minus a is bigger than a. You multiply by lf, which is non-positive. So you can put a inside, replacing it by h minus a. Now you bound from below by an integral on the larger set in which the integrand is not positive, which is omega a. Not positive, which is omega a. Now you integrate by parts, and you have this inequality, and you estimate dt dt of h. dt of h is estimated by minus the integral on the set omega a which is contained in a ball of radius k square root of t. And now the very, and there's a one over t here coming from the time there. Here coming from the time derivative, and now these are all stuff bounded. You just put an above and below the volume of the ball of square of K square root of T and you use comparison for the volume to bound the game. So the mean of F estimates T times the mean of L F. So if the latter goes to zero, the former goes to zero. So, if the latter goes to zero, the former goes to zero. And that's how the second inequality, the second limit relation works. Okay? So I think it's thanks a lot.