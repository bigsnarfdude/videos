We call morning section by rare sites and the the title of this web of is uh it's the same colour location of the pre-appart we get. So thank you for your thank you very much and thank you very much to the organizers. It has been uh great week. I've learned a lot and every time that I come to one of these meetings I say okay I'm gonna learn CR geometry finally and well I think I learned a little bit but maybe there's more soon. Next meeting I hope to meet here something. Next meeting, I hope to be here, so um I'm gonna talk about uh the KMAW problem that we heard a few things about, but I'm gonna repeat some of the ideas just to put them in context of what I'm gonna say. And I'm gonna start before I forget, this is joined with uh Maria Fernanda Spinal, who was supposed to give this talk, but she will that's why I'm doing it today. And just to put things in context, maybe I'm gonna Context, maybe I'm gonna raise the title. And I want to talk a little bit about the YAML problem, which is well known to most people here, but just to compare a little bit with the results that I want to talk about. I will say a few things about So, the idea here is: given a manifold and a metric, find a metric informal scalar curve. If you write that metric as 1 minus 2 not, then the equation becomes a little mess up the constants probably, but something like Q not you I'm gonna write it like this. I'm missing some constant here equal to zero. I didn't miss any constant. Maybe I missed a constant somewhere, but that's idea. So this is equivalent to solve. And one of the reasons to actually do this is sort of an extension of the idea of the uniformization theory. So the idea is that if you have some metric with constant scalar curvature, maybe it would be easier, for instance, to do topological classification. And that at the time I guess was one of the one of the goals, try to solve the quantary conjectures using The quantary conjectures using this. Well, it turned out like there are many people that have worked on this, as we've seen this week. So in the closed case, the problem has been known for a long time. And it's a combination of work of Jamabe himself, Tulinger. Wow, and finally, Shane at the beginning of the 80s. Well, and it turned out that the connection between geometry and topology somehow becomes weaker when the dimension goes higher. So, I mean, even if you have a solution for this, it's not clear that this would have given you, in any case, the concurrent conjecture that has not. The Poincar√© conjecture has now been solved using Ricci filter. And well, okay, but still it's kind of an interesting problem. It's analytically difficult because of this exponent here that sort of fails. I mean, it's kind of the critical exponent for the solvoless embedding, so it has a lot of analytical difficulties to get written in this way. And people kept studying this. And in fact, in the non-compact case, well, it's not true in general. What is not true in general? What in general is still open exactly when you have existence and what not? Because in some cases you do have, and in some cases you do not. Still not enough. I'll say a few more words about these in a minute. This is maybe a few words about that. I'll say a bit more about this in a minute. The Kinya Mava problem that we actually solved it a bit on Monday. Use this idea that the remote tensor can be splitted in two parts. You can write this as the available part and then the shadow tensor times the metric in some ways. A way that I'm not going to specify. And here I hope I don't mess up the tensors. So this is going to be some multiple colours that scalar curve and They never remember exactly what it is. And minus one. This transformed, I mean this is transformed conformally just by scaling, so it's it's kind of easy to see what it does. So somehow all the the information when you do conformal transformations is Do conformal transformations is here in the Schaudene tensor. So, somehow, trying to understand the Eigen values of the Riemann tensor and their conformal changes is enough to understand this here at the Schauten tensor. And well, one observation is that we saw a little bit also in USU's talk on Monday, the term gas on eight four dimensions. Actually, something like 8i squared, I think, those are characteristic. So it seems that if you want to sort of generalize more the topological aspect of the uniformization theorem, the correct quantity to look at would not be the scalar curvature, so maybe four dimensions, the sigma two curvature, and in general dimensions. Lower two are here and even so it seems from this. It seems from this that it could be good somehow to understand metrics instead of with constant scalar curves, or if you want to have a bigger connection with topology, metrics with some sigma k constant. So, and in general, I guess, if you want to do anything more generally, you want to understand systems. Systems metrics. Local conform flat. But not local convo flat is not true. This? Not that last one. Ah, yeah, yeah. You're right. This last one is not true in general. Yeah, this union is actually locally. Thank you. But this one is true in general. Uh but this one is true in general. Uh of uh of formal metrics formal metrics and as we saw in the talk of Monday somehow there seems to be a different behavior when you are when you are lower than this, I mean when k is lower than this number, so for k less than n over 2, it's different the behavior than when k is bigger than n over 2, and it's different when k is exactly n over 2. So somehow, I mean, you expect to see differences in these three cases, and what I'm going to say today, you're going to see also some differences there. What's it something that I forget what it was, but I guess it was not that important. Ah, okay, yeah, I remember now. I remember now. So, I guess we're gonna define again what these sigma case are. I'm gonna write the expression for what you see, which is kind of horrible, but the idea is for you to see that it's horrible. I mean, the only idea is to compare with this here that you see that you get a fully nonlinear equation, and then you have to somehow work around the fact that it's fully nonlinear. So, what is sigma k? So, in theory, you have a matrix, let me say, and then we can identify the one what answers with these matrices. matrices without maybe saying if you take sigma k of a it's gonna be the sum of all the products of eigenvalues then depending a bit on your conversion you may put a constant here if you want to normalize somehow but I'm gonna ignore the constants so here are the lambda i's all right Are the eigenvalues okay? Okay, um yeah, and actually this is this if you if you compute the the characteristic polynomial of this matrix A, what you see in this characteristic polynomial are actually the coefficients are. Are actually the coefficients are the sigma case. So it's kind of a natural quantity. I mean, for the eigenvalues, it's something that comes from the characteristic pooling moment. The characteristic polynomial. If you know all these coefficients, you know what the matrix is, you can recover the matrix. And you can express actually this in terms of entrances of the matrices. There are kind of sub-determinants and there is an expression if you don't want to compute the, I mean, if you cannot somehow compute the eigenvalues, but it's kind of a horrible expression. So, I mean, if you want to write this just in terms of gate entries of the matrix, I don't recommend doing this, but. You have an expression where this is the sign of this permutation, and then you take the entries. So, I mean, you have some horrible expression that means that you have to somehow multiply combinations of k elements of the entries of the matrix, and this can be written. The matrix, and this can be written in terms of the terminal. So it's kind of horrible, but at the same time, it has a lot of structure because it's a determinant. So it looks bad, but it's not so bad. In terms of this problem, the Schauden tensor, if you write now your metrics, just to compare with this, if you write your metric like 4K and minus 2K, then the shadow. The shallow tense we're gonna do again basic constants, probably let me check the constant so I don't have to make a mistake like that, but I guess it's not so important I'm never gonna write this again, don't worry. Gonna write this again, don't worry for you to be convinced that it's gonna be messy. So, well, it's kind of a big expression, and you're you will want, I mean, one way is to compute the eigenvalues. One way is to compute the eigenvalues of this somehow, and you do combinations of this. And the only thing that I want you to get from that is that when you look at the PDEs, with my k being constant, then instead of something with an Laplace here, you're going to get a fully not in error variable. So it's gonna it's gonna look a little bit ugly, let's say, and it's not it's not gonna be looking so so nice. So nice. Many people have worked on this problem in the closed case. There's a very long list of names that I think Jonah mentioned most of them on Monday. And I'm not going to get attempted because I'm going to forget many of the reportings. You just realize I forgot about case, there are fewer results. I mean, for even for the Yamabe problem, as I said in the non-compact case, Compact case is not completely solved in the sigma case, even less. This is not about it. So, what I'm gonna talk about today is more related to the non-compact case, more than the compact case. And actually, what I want to talk about, instead of the YAML problem, the KYMA program is the YAML flow. So, the YAML flow was an idea introduced. Flow was an idea introduced by Hamilton after actually a micro problem was already solved. I mean, they already knew that this had a solution. And he proposed that instead of doing all this, maybe one could do the following. One could do the following. Instead of taking this metric, here, you can take a metric that depends on time, that is conformal, so that means That is conformal, so that means that you're taking something like this. And then try to solve basically this equation with some initial condition. Like this, and then when you take a geometric flow, we saw a little bit on Tuesday, well, I don't remember what Eric's talks was, but like the idea of geometric flows is that they're much more regular while they're open, but they may have similarities. But at least during the evolution, you don't have, I mean, you usually don't have the regularity issue. I mean, solutions are smooth until they develop some similarity. So, somehow, this is this should be This should be easier in some ways. I mean, you don't have to worry about quick solutions so much until you hit a singular type. And around, I mean, a few years later, after this idea was proposed, in the locally conformative flat case, there were some works by first by the Xiao, I think, and by here that addressed the locally conform on the flash case. The locally conformally flat case, and this was maybe early 90s. And it had to be another like 10 years for the problem to be fully solved. And this was some brand that actually solved. And this is for the closed case. In the non-compact case, there are many, many papers about the non-compact Yama flow. So again, I'm not going to mention all of them, but I'm going to focus on. Mention all of them, but I'm going to focus on one case that is the non-compact case. It's a work by Totidas Calopoulos and Natasha Sestu. So, let me say a few things. You expect, in some cases at least, singularity. At least singularities infinitely and these are expected to be modeled. I saw those images. So, the work that I want to mention today is a work by Scaropoulos and Natasha Sesson. And here they classify Rotationally symmetric formally flat for the Yama Flow. So that that's The Yamabeflow. So that's their work, and the work that I want to talk today is an extension of this work. So, just a few words before saying exactly what we're doing. In their case, basically, they're thinking about solutions to the amount of flows that are of this form. So, if you have a gene that depends on T, You have a G that depends on T, and we want to write this as alpha of T and some diffeomorphism that depends on T on G0. So there are all solutions like that. And this is going to be represented by some U, I mean, or the T0 if you want. And we actually just look at solutions that are like that, where this is rotational and symmetrical. Where this is rotational symmetry. And then basically, this way of writing it means that you have some alpha of t and some parametrization here. This is what this means. So they look at solutions where the conformal factor looks like this and that they're conformal to the standard Euclidean metric. They justify the fact that they look at. They justify the fact that they look at rotationally symmetric solutions because when you have an underlying manifold with a positive sectional curvature, then you can prove that all solitons are actually rotationally symmetric. So they're classifying at least all the solitons that are with positive sectional curvature. So that's why they look at the rotationally symmetric case. The reason to look at things like that is actually that when you do blow ups, look at singularities, that is what you what we do eventually. That is what we do eventually with this work, you're gonna see things are flat after condition. You're not gonna see any more geometry, I mean, any other geometry after they blow up. So that's why they're looking at things like that. Yeah, so what we wanted to do is sort of to do the analogous thing about their work here, and this is what I'm gonna talk about today. So I'm gonna talk about classifying. These if I local conformally, I mean, conformally flat solitons are rotationally symmetric for the sigma k problem. And of course, I need to say what flow I'm going to take. I don't know if there are any questions so far. Yeah. Are these shrinking telegraphs or any sort of telegraph? Here, I mean, in this case or in the other case? But in this case they fully classify all these, all the rotational symmetrics and you you divide them in this case as expanding, steady and and shrinking, yes. And yeah, I'm gonna say a little bit what they what they see actually. But yeah, these are classified. Of course, I mean some examples are explicit, right? You still have spheres in all these things. But other than that, yeah. Are there any quests other questions about this? Okay, so the flow that we are gonna take now is the following. So the Yama, we're gonna take this version of the This is the flow that we're going to consider. The reason we're considering this one is because this function detects sigma k, sorry, sigma k of one over k. This function is concave and for some estimates it's easier. There have been other flows that have been considered, like in your work, right, where you take the normalized ones because you're in a compact setting and you take the larger ones. Setting and and like the logarithm of that. Yeah. Yeah, of course. Thank you. We are taking this one and okay then we let me see if I if I need to say something else and we're thinking about geo. So we're thinking about g of t being out of t star t minus one t and then the equation that you're gonna get for that in our case is gonna look like this you're gonna get that okay. Okay is gonna be theater G and here rho zero giving the little derivative yeah there's Oh yeah, there's one more thing I need to say. In general, if you take a vector, I mean, this could be any vector field in principle, in many cases it's known that this is going to be a gradient vector field. So actually, even in their classification results, they only consider x to be the gradient of some potential function. And then in that case, these are called gradients. So the classification result in their case, and my case is going to be for gradients only. And so I'm only going to consider here x being the gradient of some function. And maybe let me say in general, if you take a different, I mean, if you take k equals 1, you're going to see. K equals 1, you're gonna see a multiple of R, so you're gonna basically see the Yamato flow by scaling the row differently, so it's just the Yamana flow. Are you pulling back the Sharson sensor or the metro match? Oh, like, sorry, yeah, I don't know, yeah. Thank you, thank you, yes, yeah, and I'm just going back to the Yurglacian de Yamaba flow. And the yammamic flow because the scaling, I mean, if you rescale the flow, then you can just change the rho. So it's enough to consider rho to be 1 minus 1 or 0. Here, in some cases, it's more convenient to take a constant that depends on n and k. So I'm just going to leave it like rho, not to worry about exactly what is the correct normalization in this case. And I'm just going to leave it like that. So when. For rho to positive, it's gonna be we're gonna call this a shrinking solid or quote zero. Or raw zero, we're gonna call this a steady solution. Overproduct negative, we're gonna call this a spanitive. And I guess the the conical solitons that we saw on Tuesday correspond to to this case actually. I'm gonna say uh uh a few words about the three of them. The three of them. How many times? Yeah. Okay, so perfect. Okay, so the idea now is gonna give a classification result and sort of compare it with the Yamami case. And again, we're gonna see different situations depending on whether 2k, let's say, is bigger than n, smaller than or equal to n in the case of event dimensions. We actually We actually follow the same ideas of the proof of the work of Sesame and Vescalopoulos. And the result has several parts, but first let me give you Well, first they prove that positive sectional curvature. Second, they show that That if you write the metric in this form, which is kind of not the standard form. Satisfies. And the third step is actually there were lots of things new about fast diffusion equations. So it's basically interpreting the results that were already known for fast diffusion equations. They do a few more things. I mean, I'm simplifying. They also compute sort of became RAID and things that were not like maybe previous work, but they built a lot of things. Previous work, but they built a lot of things that were already known. Okay, so in our case, this part was already known. So this was already extended for more general proof. First, non-negative. By Catino Mutilas Macilli. So this actually, the first part, we started first computing things and then we realized that it was already done. So I'm not going to talk about that. And actually, in their case, because they allow parts with zero-sectional curvature, the result is more general. It's not only rotational symmetric, but you can have some splitting because you can have some zero directions in that case, you can have some zero-sectional curvatures. Which we're not addressing today here. And the second part, well, and basically we started here, and the second part we have. Here at the second part, we have our first theorem that is basically generalizing this. That again, you're gonna see maybe a little bit of an ugly equation because it's again only non-linear. But it's what you have, and the first round is this. No, uh the points should be symmetric. I think this part is actually probably not necessary. Probably not necessary. I mean, it's necessary for what I'm going to write, but I mean, for the computation, you can do it, I think, even if you're more formal or things. I'm using a matrix there. I'm using a matrix there that's just an identity. Here you have u to power as to p as well. And here what I forgot to say is what is the metric that I'm taking. And the metric that I'm taking is I'm taking G to be In their case they get a similar expression where this is just a trace, so they get a lot less power like that. And that's where the fast efficient comes from. The expression is not maybe that nice, but it tells you some things. So one thing that One thing that I haven't said, but it was mentioned actually on Monday, that to find solutions to this type of polynonlinear equations, you have to put further restrictions of where are you finding the solutions. So some restriction that I haven't added, but I will need to add for the next part, is that actually we're looking for solutions that are within the positive code. In general, you will need, I mean, if you want to work with equations. If you want to work with equations like this, you will need some conditions to make sure that your equation is elliptic. And there are different choices that you can make. The most standard one, maybe the easiest one in some sense, is to assume that your matrix, I mean that your solution is within a positive column.  I mean this is not the only possible condition, but this is I guess the most standard one if you want to start somewhere and that means that we're going to assume that these are matrices that satisfy Is being positive. And this is going to play a role in what I'm going to say in the classification result right now. But, okay, so maybe don't look too much at the equation, just I want to point out one thing. When you take x equal to zero, you want this to be a, I mean, in general, you want this to be a positive quantity, positive. In particular, when x is equal to zero, this is going to be zero if you're looking at a regular solution. zero if you're looking at a regular solution and this is going to be positive. So immediately if you're looking at the positive form, you will see that this here has to be, well if you want to be inside the cone, strictly positive, if you allow to go to the boundary of the cone, we put an equal to zero. I mean we're gonna ask for that to be strictly positive. So this is the first restriction that we see from this. That we see from this, and under that assumption that it's rotationally symmetric and that we are within the positive cone, then we have a classification result. I don't want to write maybe full generality on the theorem, but let me give you an idea of what was done. Okay, we're gonna assume we're there for more radiance all the time for pango. So promo the piece and then we do a picture rather than writing everything and then we have the following so bigger than zero equal to zero bigger than If n is bigger than 2k, then you have solutions that are shrinking, and you can have two possible, so here they exist. They have two little groups, so that's that pronoun exist, and you so the form has a decay of the form. Has a decay of the form minus two, one, minus n. Or decay like this. So, I mean, you have multiple solutions, and not all of them have the same decay. This would correspond to spheres, for instance, and this, in the case of the of the Yamada problem, correspond what they call barabod solutions. Call barablot solutions. And in that case, in the case of Yamabe, I mean, spheres, of course, are explicit in this case as well, but in that case, there are explicit solutions with this decay. In our case, we didn't try very hard, but we couldn't compute explicit solutions. Okay. For Reipol's theorem, you have existence. You have existence. And now all solutions are gonna decay like this, over in the x squared, would be 1 over 1 minus 10. And for all less than zero behavior that is like this, I mean they exist and they have you have a behavior. That's my You have a behavior as much as these. And yes, it depends on some parameters that I'm going to actually specify what they are in the row that we had before. And a parameter that theta that I haven't defined yet, but I'll define it. I mean, if this is a parameter, it's going to define the one parameter time and so on. Okay, so and this is actually exactly the picture that you had in the case of the MR flow, so more or less not so surprising. Not so surprising. In the case n equals 2k, you still are going to have all these types of solutions, but the decays are going to look a bit different. Actually, in this case, we know that they exist. And you have some decay. But this D we don't know exactly what it is. We know that D is something that is like here maybe. But here maybe the is between zero and some number that depends on the parameter over to theta or something like that. Here you also have existence, but um you have decay. In the case of the case And smaller than to k exists only under some choices of parameters. There would be a family of parameters that are related to this data here, and it is only for some data, for some failures. bigger than zero. So actually the condition is that theta is zero or two rho bigger than theta. These are the conditions that you need for existence. And in this case, solutions are not admissible. By non-admissible, I don't mean that they're in a different code. They're not in any code. They're not in any cone. Actually, you start in the positive cone and you leave the positive cone in finite R, let's say. So that will be the classification result. Let me see. I have like five more minutes. Maybe let me give you a very short idea of the proof. I mean, I'm not going to, of course, compute anything, but sort of how we proceed about this. I don't know if there are any questions about the theorem before I raise any customer space. So yeah, I mean, I think you see difference in different cases, and in that sense, if you interpret it in the sense of singularities, I guess for some situations, you won't see singular behavior. I mean, you won't see this type of singular behavior within the particular person. Okay, so let me give you a couple of ideas of the proof. So the first thing is because U is rotationally symmetric, then the shouting tensor only has two eigenvalues. And then the added expression becomes a bit less ugly. I don't know if I want to write what the action values are, but the thing is, because of that, the quantization simplifies a lot. Maybe I won't write it, but I mean, you have some lambda one that depends. I'll write that the first term to get an idea of what I want to say. Say, but R over U has four terms. So this has multiplicity one. And then you have a lambda two, where the leading term is going to be two or two r Please maybe I'll write the second thing because I want to say one thing. It's a small complexity and the next one. Because of this setting, you can see that being in the positive cone means that this lambda 2 has to be positive and the condition that I mentioned before. So positive being in the positive cone. Positive pain in the positive code. Let's say let me write it like this because it's not exactly so sigma k being positive and membrane two being positive. Number two being positive. And that gives you, I mean, both of these conditions give you a restriction. This is impossible, but it should look like. Gives you a restriction on where this quantity can be, where the R you are already has to be. Okay, so then in the case for fast diffusion equations, what what they do is they interpret the the equation, the large equation that I wrote before as a system of equations. That I wrote before as a system of equations by defining x to be. In our case, it's going to be like this. Okay, and C is going to be due to some power, but I think it's one R squared times that, I think. Anyway, it doesn't matter too much. This would be fine. This would be fine. And when you do a transformation like the one that Jesse mentioned the other day, you consider cylindrical coordinates for that. And this is going to satisfy a system of equations, but we don't care too much what it is, but basically this gives you a system that you have to analyze. And to analyze the system, what you have to do What you have to do in each case for n bigger than today the system has three dot points. three dot points plus an asymptote the solutions that I described before basically are orbits that join these critical points and they start at zero because you see from the definition here r equals zero which corresponds to s minus infinity you don't have to be starting at the orbits. So these are the three different behaviors that you saw are basically joining 0, 0 with one of the other two critical points or One of the other two critical points or the asymptotes. These are the behaviors. For n equal to k, there's only two critical points and symptom. But then there are certain behaviors that you see here that you cannot see here. For n, Less than 2K, you only have to put the elements, no asymptote anymore. And the fact that you don't have admissible solutions is because what was working here as an asymptote force you to stay within the admissible region and that doesn't exist anymore. And that's why you don't find admissible solutions in that case always. And I think I'm done with my time so long. I think I'm done with my time, so I'm gonna finish here. Any questions? Okay, well far press close.