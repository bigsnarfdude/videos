To get a self-adjoint restriction, so in particular we'll just assume that psi of minus one is zero. So in previous talks, we talked about, in the talks of Anton and Junko, we talked about the spectrum and spectral type associated to random operators. And in Anton's talk, we in particular talked about sort of the structure of the spectrum and the spectral type when you perturb by a suitable bounded background. So you'll recall from those talks, there were some assumptions that were needed. Assumptions that were needed to discuss the spectral type, you can really have random plus an arbitrary bounded background. In the case where they discussed the topological structure of the spectrum, you need this additional assumption that the perturbing background potential is generated by ergodic dynamics on a connected topological space. And then in the talk of Jungyang, we really talked about the spectral type of operators with hyperbolic base dynamics. Like base dynamics. So, in some sense, the content of the present talk exactly sits in the remaining square. So, I want to tell you a bit about the structure of the spectrum in the situation in which this transformation T is a suitable hyperbolic transformation. So, that's the goal for today. So I want to tell you about the exact setting in which we're working, tell you a bit about what the result is, and then explain a little bit about how the result is proved. Okay, so in this setting, there are a few standard objects, some of which we have seen before. So, once you have an ergotic setup, such as this one, there is some fixed compact set. And I'm going to sort of note the dependence on this choice of sampling. So given a choice of f and then omega, you get a family of operators indexed by omega. And so there is some set which depends on f, but which is independent of omega. Depends on f, but which is independent of omega with the property that the spectrum of f, sorry, this sigma of f is the spectrum of h and omega for mu almost every. So this is the set whose topological structure we would like to probe. And once again, I have to kind of pop from one foot to the other. This is, of course, true exactly as stated for the whole line case. When T is invertible, When T is invertible and H is acting on L to Z. If you are in the non-invertible case, you can, of course, get sort of some sort of noisy discrete spectrum. And so in the non-invertible case, so if T is not invertible, then what you can say is that you can find some sigma F, which is almost surely the essential spectrum. So sigma S. So you can ask. So in particular, you're probably very familiar with the sort of Pasteur theorem that says in the event that T is invertible, not only is there some set which is the spectrum of almost every realization, but in fact the discrete spectrum is empty for almost every realization. So you could in fact sort of take this as your Take this as your definition or choice for what big sigma is and to not lose any generality that way. So this theory is really informed by the choice of interesting examples. So there are two examples that I want you to keep in mind, which are representative of the kinds of things that we're interested in and the kinds of things to which we can apply the general results. So that being said, That being said, so the two examples you want to have in mind: so, one is the doubling map. So, here your basic space is the circle. The transformation maps omega to 2 times omega, modulo z. So, here for me, the circle is R mod Z. And then the invariant regarding measure is Lebesgue measure. So, the other example. So, the other example which you want to have in mind, which falls into what we consider the sort of hyperbolic maps that we're considering, is the cat path. So in this scenario, the basic space omega is the two torus, and the transformation, let's write it this way. So, you think of these as column vectors, and then you act on it by the 2111 matrix. And again, mu is. And again, Î¼ is two-dimensional effect measure. And so, what we would really like to understand is what can you say about the topological structure of the spectrum? What does it look like? So, in the previous examples that we looked at of random and random plus backgrounds, whenever one was able to prove a result about the topological structure of the spectrum, it was a finite union of intervals. So, in the case of the Anderson model, where the background really is zero. Background really is zero, and you just have ID random variables for the potential. You can say exactly what the almost ture spectrum is. It's just a Courtney-Anderson model. You can say exactly what the almost sure spectrum is. It's really just minus 2, 2 summed with the support. With the support of the single-site distribution. So what one would like to do is to understand what is the topological structure of the spectrum for these sort of relaxed, not exactly Anderson model, but these hyperbolic type base dynamics. So that's the. So that's the theorem that I want to state, and then tell you a little bit about the proof. So, first, I'll just formulate a theorem for the doubling map, and then I'll kind of tell you how it generalizes a bit later on in the talk. So, the main result, so this is joint. So, this is joint work with Praveen Demonic from 2023. So, if your sort of basic dynamics are given by the doubling map, so the circle, the times two map, and the weight measure. Then this set sigma f, which supplies the almost sure essential spectrum for almost every realization. For almost every realization, this applies the essential spectrum of almost every realization. This is an integral, so it is connected. So something kind of curious happens when you pass to the setting of at least the doubling map. You no longer have finitely many gaps, you have zero spectral gaps. And so, what I hope to kind of explain to you is that this is really a topological phenomenon. If you have a non-trivial spectral gap, If you have a non-trivial spectral gap, something happens, you get some sort of topological object, which I will try to describe to you. And this object is simply too good to be true. So that's the overall kind of picture that I want you to have in your mind. Okay, and the cat map also has this same property, so I won't reformulate it for the cat map. I'll formulate something a little bit more general, a little bit later on. Okay, so what is the main idea? The main idea. So, what is the main idea? The main idea is to use the gap labeling theorem, and specifically the gap labeling theorem as formulated by Russell Johnson in 1986. So, I'm going to have some very, very, very condensed discussion about gap labeling in the style of Johnson. So, I should say very much, I should definitely say at the beginning, this is the version of gap labeling that we use. This is the version of gap labeling that we use, which is useful to us. There is, of course, you are familiar no doubt that there are gap labeling theorems which use the theory of C-star algebras. That's due to Bellisard and co-workers. So we're not necessarily using those, but these are, of course, related. So what is the main idea? So let me give you just a few kind of key objects. So we already have the spectrum, and so what exactly are And so, what exactly are gap labels? So, first, what are gaps? So, any bounded connected component of the complement of the spectrum, that's a spectral gap. And so, what I want to tell you is, what is a gap label, and then what does the gap labeling theorem tell you about the labels of the gap? Tell you about the labels of the gaps. So, the key object here is the integrated density of states, which we have already seen, but let me, just for the sake of completeness, say what it is. So, integrated. So, this is, it can be defined in a few different ways. So, let's use the following definition. So, we'll call this K, and I'll subscript it with an And I'll subscript it with an F to denote that it does depend on the choice of the sampling function, but it does not depend on the ergodic parameter in big omega. So one way to define this is to take the following object. So you take the 0, 0 matrix element of the spectral projection onto interval from minus infinity to E of your operator HF omega. This now depends on the ergodic parameter omega, and so then you have. The ergotic parameter omega, and so then you average it out with respect to the ergotic measure. This is one of two equivalent ways to introduce the integrated density of states. I'm choosing this one because it's just a little bit more compact to write down. So if you're familiar with integrated density of states as the accumulation function of the density states measure, which is in turn the weak limit of the normalized counting, eigenvalue counting measures associated with cutoffs of H. That's also equivalent to this. To this. So at any rate, I just want to enumerate a few of the kind of important properties of this function because this is the function which gives the gap labels. So in particular, you can definitely see from the definition right away that this is non-decreasing. It takes values between 0 and 1 inclusive. And with a little bit more work, you can show that it's in fact continuous. That it's in fact continuous. So this function is continuous, non-decreasing. It's constant on each gap and it increases on the spectrum. So in fact, between putting those last two things, So, in fact, between putting those last two things together, the spectrum is precisely the set of points of increase of this function k sub f. And so, this is exactly what gives you the gap label. So maybe I will just draw a very primitive little schematic. So, here is energy. Here's what Kf may look like. So, below the bottom of the spectrum, it is zero. And then at some point, you enter the spectrum and you start to increase, and you have regions of increase and plan. Of increase and plateaus, and then at some point you get above the top of the spectrum, at which point you get one. So the heights, so these plateaus are exactly the locations of the gaps, and the corresponding values of k in the gaps are called the gap labels. So in other words, kf, so this constant value is the label of the gap. So the constant value, So the constant value assumed by k f and the f is the label of the f. So people who are very familiar with either the Johnson approach or the C star algebra approach know what is coming next, which is, in principle, this is Is in principle, this is just some non-decreasing function with some plateaus and some regions of increase. So, in principle, these plateaus can occur at any real number between 0 and 1. What the gap labeling theorem says is, in fact, there is a fixed subgroup of the real numbers, which is heavily restricted by whatever your base dynamics are, that allows, that tells you what the heights of these plateaus can be. How are we on time? Okay, great. So, the gap labeling theorem, or maybe I should say a gap labeling theorem, is something which tells you what values may actually be assumed by this function kf in the gaps of this vector. So, the gap wavelength theorem. So there is some fixed, and this is important, countable group. So of course, if I just set group, I could just use the whole real numbers, and this isn't very exciting. So there is some countable group, which I'll call script A. And the key point is it depends only on these base dynamics, omega, t and mu, such that Such that all labels belong to A, and in fact, just trivially, because as we said, this takes values between 0 and 1, it then belongs to this group A intersected with the closed interval from 0 to 1. So, so far, I haven't really told you what this thing is. So, that's really what I want to I want to do is to tell you sort of how you can compute this, at least from this Johnson perspective. And then, before I even do that, let me explain now how you could try to prove a theorem such as this one. So if you know there is some group which gives you the possible labels, so if So, for reasons that I'll kind of explain later on, this group always contains the integers because there's some sort of trivial mappings that you can produce. So, you always contain the integers. So the smallest possible a is always z. But if a equals z, then what are the possible labels? Well, the only integers here are 0 and 1. So that means the only spectral gaps that can actually be present are the semi-infinite gap to the left of the spectrum, which Semi-infinite gap to the left of the spectrum, which corresponds to label 0, and the semi-infinite gap to the right of the spectrum, which corresponds to label 1. Actually, that definition is a follow-up gap, so you can actually use the open definition. That's true, that's true. Okay, so just to be consistent, so really the gap labels belong to this since the semi-infinite gaps are not considered gaps. So there are, no, maybe for emphasis, bounded gaps. Gaps. Okay, so there, this is the overall strategy which one can pursue, and indeed, this is exactly what you do for the cat map. So when you study the base dynamics of the cat map, you can show, and we do, that this A is exactly C. For the doubling map, it's a little bit more involved because this all is really this formulation of the gap labeling theorem is for invertible base dynamics. Theorem is for invertible base dynamics. So you have to do a little bit of work to massage the connection between the whole and half-line settings. So I'm not going to talk as much about that because I really want to focus on interesting topology. So this is really what you should have in mind, is you are trying to sort of show that the set of labels, the possible labels, is as small as possible. And that tells you that the number of gaps is as few as possible. Okay, so we have a very. Okay, so we have about a little bit under 20 minutes left. So, what I want to do is, because I just told you that there is some group which someone can come up with, but what I really want to do is tell you how exactly it is generated by the base dynamics. In other words, if you know an omega, a t, and a mu, you, in principle, can calculate this using some procedure, which I'll try to describe. But this requires some. So, this requires some definitions if I want to do things properly and actually give you a sense for how these things are done. So, how is this done? So, we're going to start with our omega t and u, and I'm not even thinking about hyperbolic dynamics at this point. Really, just any ergodic dynamical system with this additional technical condition. With this additional technical condition that the topological support of the ergodic measure is the whole space. By the way, if you're not used to thinking about sort of this ergodic setting, that's not at all a restriction because if you have an ergodic measure which is supported on some proper closed subset of omega, that's a T-invariant set. So you could just pass to that. So it's not really a restricted assumption. So there is a multi- There is a multi-step procedure. So, before I do that, let me just outline what this group is. We're going to take our dynamical system, which is discrete time, put it inside of a suspension, which embeds this in terms inside of a continuous dynamical system, and then this group is, in a sense, all of the possible rotation numbers. So, if you're familiar with the theory of almost periodic or ergodic operators, this is really leveraging the fact that the integrated density of states is up to some normalization. Up to some normalizations, the rotation number. So, how do you implement this? So, starting with your basic system, omega t and mu, so we're going to form a suspension, which I'll write is x tau and nu. And again, the goal is to simply take your discrete times system. To simply take your discrete time system, embed it within a natural continuous time dynamical system, such that the time one map of the induced thing somehow looks like the original map T that you started with. So the space on which things happen, you take omega, Cartesian product with the reals, and now you basically identify as follows. If you translate by n units in the second factor, you have to say that's equivalent to applying. To say that's equivalent to applying the transformation n times in the first factor. If you studied some algebraic topology at some point, this is equivalent to what the algebraic topologist would call the mapping torus of omega and t. So tau, this is the translation flow in the second factor. So let me write it in the following way. So using square brackets, in order to denote the equivalence class of the pair omega and g, tau. Omega and T, tau, acting by some real number S, is just the translation flow. So it's omega T plus S signals. Okay, and now you can see exactly what's going on. So for each t, you can consider the set of omega, t's, where omega runs through capital omega. This is a copy of the starting space omega sitting inside of x. Sitting inside of X. Now, if you flow for one time unit, you map that fiber back to itself exactly shifted by the transformation T. So that's what I mean. Now, this is the precise version of what I said earlier, which is that this takes your discrete time system and embeds it in a continuous time system such that the time one map is more or less capital T. And this new is essentially the product of the ergodic measure and Lebesgue measure on the fundamental domain. Measure on the fundamental domain. So if you have some continuous function that you would like to integrate over x with respect to nu, then this is simply integral over omega, integral 0, 1 by so what the this group A, which gives the set of possible labels, really captures, is all of the sort of possible Captures is all of the sort of possible winding numbers of continuous functions on this space x. So that's the next thing which I will explain. And there are various equivalent ways to set this up. So one way to do this is to start. Uh but that's probably too low. So let me just come over here. So given some continuous function from the suspension, so you can really do any realization of the circle here, but it's most transparent to do this, say for the real projective line, so the set of lines through the origin in R2. You do the following thing. So you pick Some x in the large space x. You start at x, you flow, and as you flow, you observe what the function phi does. So this is now an s-dependent line in the plane R2. And so you can ask yourself, what is the change? The change in argument as s varies from 0 to t. So as s varies from 0 to t, this line, which is parametrized by s, changes argument and t normalized by pi t. So why is the pi there? This is just because if your argument changes by pi in the real projective line, that's exactly corresponding to going from where you started and ending where you started. And ending where you started. So the fact is, if you take the limit, so I'm going to write several things and then I'll explain what I mean by this. So this limit exists for new almost every x. So almost every starting point, you can take this limit. It exists, and you get a constant value. So in other words, there's a set of full measure and In other words, there's a set of full measure and a real number f of phi with the property that this limit is equal to this number f of phi for new almost every x. So that's really what I'm claiming. And moreover, this f of phi only depends on the homotopy class. So, in other words, if you take some continuous function on your space x into RP1 and you continuously deform it, you get the same value output for this script f. So in particular, what you now have is a map f going from continuous functions on x into the circle, and it is And it is well-defined modulo homotopy going into the real numbers. And again, this is very clearly some sort of, you can call it the rotation number. Some people will call this a winding number. I don't like that because I want the winding number to be integer valued. By the way. No, no, I don't want to do the by the way yet. I want to get to the punchline. So, and then I'll do the by the way later. So, you have this function. So you have this function which goes from continuous functions modulo homotopy into the reals. And so the key fact, first of all, is that there are countably many homotopy classes. So the range of this function actually is a countable subset of the reals. And it's not hard to convince yourself that, in fact, it's a subgroup. So the theorem, due to Johnson, so now I can give you the exact Johnson theorem, which tells you exactly what A is. What A is. So this is Johnson, 1986, which is that, so it's not formulated in exactly this language in the paper, but this is just, since I've introduced this notation, it's the range of f. Okay, so several by the ways, which I now want to say now that I've. Which I now want to say now that I've got everything up there and can talk about it. So, the first is it's relatively easy to see that this group always contains z, which is something I said before. Basically, you can forget about the first coordinate, just ignore it, and sort of project the second coordinate to the circle winding around n times, and that will give you something where f of phi is equal to n. So you always contain the integers, and that has nothing to do with the dynamics. It has nothing to do with the dynamics. So that's one comment. Another comment is that this theorem of Johnson really generalizes many results that came before. So in particular, sort of the elementary gap labeling that you know for periodic operators. So let me give you a few representative examples. So if you go through all of these steps where your base space is integers mod pz, integers mod bz. Your dynamics is just add one, and then the invariant measure is the only thing it can be. It's normalized counting measure, which I'll write this. I'll write counting measure is the pound sign. So this is just all of the fractions with denominator p. So this is exactly what you know from Floquet theory, that the integrated density of states of a p-periodic operator takes values in of the form integer over p in the spectral gaps. In the spectral gaps. So, maybe a more familiar example, not more familiar, but one step up in complexity, you can take the circle and you can translate that into irrational alpha. And then your invariant measure is Lebesgue measure. So this is z plus alpha z. And again, alpha is not rational here. And in fact, you can recover the sort of classical gap labeling theorem. The sort of classical gap-labeling theorem of Johnson-Moser for almost periodic dynamic systems by taking by doing this construction where instead of where your choice of omega is some compact abelian group, and the transformation is a minimal translation of the group. Okay, so I have set up everything that I want to set up, but this is probably a point where I want to pause and ask if there are questions before I get to some of the main punchlines. So one thing that I want to say is it does take some setting up, but everything is completely explicit. Once you have a fixed choice of base dynamics, what you need to understand is the structure of the suspension and the translation flow thereupon, and you need to know something about homotopy classes of maps from. Classes of maps from the suspension into the circle. And often, depending on your base space, this is a very elementary topological thing. For instance, what do you actually use to demonstrate this second line? You can convince yourself that in this case, where the base dynamics is the translation by an irrational on a circle, the suspension is going to be a two torus. And so what actually goes into proving this is just the fact that you learn an element. This is just the fact which you learn in algebraic topology, which is that every map from the two torus to the circle is homotopic to a character. So this is once you set everything up and understand everything, you can do some very nice explicit calculations. Okay, so let me kind of give one punchline. One punchline of this, which is the following. So, you can ask, what do you mean by hyperbolic maps? So, I'm going to be a little bit more general and also a little bit less general. So, let's take, for instance, as our base space, a D-dimensional torus, and we'll consider some, maybe A is bad since I've already existed. So, let's say M in SODR and some B. And some B in Td. So you can consider as your base dynamics the affine transformation, which sends omega to m omega plus p. So the theorem that kind of encompasses many of these things, so this is again a result with Dopitt from 2023. So with the setup as above, So, with the setup as above, I have to be careful about the formulation. So, with omega and t as above, if there is a fully supported ergodic measure, so if there exists. So, if there is a fully supported ergonomic measure, Î¼, then you can calculate this group, script A, so A, omega, T, and mu, is the following. So, there is always this factor of Z which is present. And so, the additional contributions are of the following form. Are of the following form. So it's all of the things of the form k.b, where b is your translation vector and k lies in the kernel of transpose of a minus the identity. So this is what it is. And now in particular, the application of the cat map is very transparent. If A is 2, 1. Transparent, if A is 2111, the kernel of 2111 minus the identity is trivial. Yes? This M needs to be SLDZ or DR? Oh, gosh, thank you. I very much appreciate it. Yes, it definitely needs to be an SLDZ. Thank you for your question. Yeah, and A star becomes M star because we change it A to M. Yes, absolutely. Thank you. Absolutely. Yes. Talking about transformations. Talking about transformations. What's that? Is it the model for M to be identity matrix? Yes. So, in particular, M can be the identity matrix. And in fact, that's a very nice, so if M is the identity matrix, then you were just looking at a pure translation. So this recovers the usual gap labeling theorem for Tori, because then you have sort of all of the K dot alphas, where the alpha is the translation vector. And that's exactly what you get from the general theory of quasi-theory operators. Quasi-feriotic operators. Does your theory also cover the second example? Yes. Yes, so this covers the second example. So why necessarily let me try the second example? Oh, sure, sure, sure. Okay, so why do we get the second example? So, in fact, let me do, let me explain, write both examples out. So, for the So for the cat map, so this corresponds to m is 2, 1, 1, 1, and b is 0. So m star minus the identity is 1, 1, 1, 0. Okay, which has a trivial kernel. So, indeed, A is C. And so, in particular, for this example, by the reasoning that we discussed earlier in the talk, there are no nontrivial spectral gaps. Okay, and then the other question that Wentz I asked is, what about this? So, what if, so omega is T? So, this is one example. Second example, T omega is. T omega is omega plus alpha. Alpha irrational. So the assumption of irrationality means that Lebesgue measure is ergodic, and in particular Lebesgue measure is fully supported, so we are within the purview of this theorem. And so then in this case, okay, what is m? It's the number one, or it's the identity operator on, right, so this m star minus i. This m star minus i is zero, so every so I should also put here that we only use integer vectors, so this should be zd. Okay, so then in particular, the kernel is all integers, and so in this case you have z plus all of the possible alpha times integer combinations. integer combinations. So a couple of comments about this is you can generalize this to sort of more general translations on groups. So this I want to say here, so this can be generalized to affine transformations. Transformations of connected groups. So this was some recent work that we did with David and our student, Iris Imelsdaffner. Okay, and so I have said all that I want to say, and I am basically out of time, so thank you again for the invitation. Thank you for your time and questions and I have a question. So the connection to spectral theory, how important is it that your operator is finite range? Could you do range three instead of near speakers? Yeah, it's both important and not important. It's both important and not important. So, the advantage of this gap labeling approach to Johnson is that it's very explicit and you can do it with all of these sort of computations. However, it's really limited to the range one case. As soon as you want to go to a range higher, then I think at that point you really need to use the C star algebra approach to gap labeling. Okay, different coefficients, not just one? Yes, absolutely. In fact, okay, this brings up, so I wanted to mention. To mention some other work. So you can also, you don't, it doesn't have to be a Schrodinger operator. So you can do all of this for Jacobian matrices. And so this was some work with David and myself and Jenga. So the interesting thing, or the thing that we found striking there is, I mean, all of this is sort of based on invariant. Invariant sections maps into the circle, which in the case of Schrodinger operators and indeed Jacobi matrices with non-vanishing off-diagonals, this is exactly given by sort of the expanding and contracting directions that you get from uniform hypervolicity outside of the spectrum. So the sort of neat thing in the Jacobi matrix case is you can actually handle very singular Jacobi matrices where the off-diagonals can vanish a lot. And this sort of uses the sort of new. The sort of new approach to identifying the spectrum as the complement of the set where you have a dominated splitting, and that's some work of Zhenghai and the student Katrina Alban. Okay, but so just to reiterate this, Johnson approach really is applicable in the case of range one. As soon as you go to higher range, you will need to use the C-star algebra approach, as far as I know. Would that work for your case too? Could you apply the same thing? Case too, could you apply the same thing? C-STAR approach? I think so, yes. Do I understand correctly that the same will work for the generalized KADMA and the K-12? Yes, absolutely. Under what case? Yeah, as long as the second term is absent of the eigenvalues in the real time. Yeah, so as soon as you have, as soon as you're M, regardless of B, as soon as you're making M. As your m regardless of b, as soon as your m uh sort of, exactly, as soon as it has no eigenvalues on the unit circle, then this is just the zero vector, and that's all that's in the kernel. Wonder what happens if you move from a house of different morphisms to double-like attractors that are connected but not locally connected. Like small wiggle solenoid or licking attractor or TV. Okay, I can't speak to the most general case, but I can say that in the work with David and Adis, we did discuss the doubling map on the dyadics only, right? And so more generally, sort of, you can fit those kinds of maps into this setting where the connected group in question is a suitable solenoid. Okay, but sorry, can you repeat the question? Repeat the question. So let's replace an OSF map in the base by a parabolic map, but you obviously need connectors. So let's take a tractor. Smell within Solomon. Right. So I think the I would very strongly expect that the same result is true because really what this boils down to is this sort of This sort of spaces that one is considering, it's disappeared by now, but these homotopy classes of maps into the projective line, you can identify these with the first cohomology group in sort of a canonical way. And so you really just want to know how does your base transformation, so your transformation on omega, induces an action on the first cohomology group. And sort of what's going on under the hood is that the This n star minus i is looking for fixed points of the action that's induced on the first cohomology group. So if one can understand that, then one can run the whole machine again. I don't know if that's a tall order or not. Confirm. So the value of the integrated density of states falls inside the this group A is doesn't depends on, how do I say? Works for all sampling functions. Yes, exactly. So this A depends on the choice of base dynamics and is totally independent and applies simultaneously. Of the sampling function. For continuous networks, for yes, for all continuous. But I mean, discontinuous. Yeah, I don't think you can say anything for discontinuous because the set of bounded Borel measurable functions is too big. Yeah, I mean like Stumian, right? What you can do is you can apply your discontinuous functions, then you get potentials, and then you push forward your system onto sequence space. Then your central function bears just evaluation of the origin. Function there is just a valuation of the origin, which is the calculus. So it does fit in there. It's just then you get a bigger loop once you remember. For example, for Stumien, what kind of loop you got? A plus z plus l plus e. However, if you take the interval not of length alpha, but of length beta, then you also get beta terms. So it's because if the length of the interval is equal to the frequency, you don't get any details. Yeah, I know. Yeah, I know that there's some results, I forget by which offers, that say in a certain sense, under some assumptions, you can hit every gap label in the set, right? Can you remind me what assumptions you need for that to be true? So, okay, there are many papers by many authors that cover this sort of dry tin martini type problem. So, this is the set of all possible labels. For any given operator, you may or may not realize an open gap with. An open gap with label A. So the first work that comes to mind is Avila Bochian Demonic, which says: essentially, if you have a dynamics that has an almost periodic factor, what's the first work that comes to mind as better? Okay. So at any rate, there are works that say with sort of suitable base dynamics, you can, say, for generic choices of sampling functions, make all the gaps open. What is interesting about the random What is interesting about the random case, so the Anderson model is given by taking your dynamics to be shift on a sequence space, and then the sampling function is evaluation of the origin. So you can, of course, take sort of longer range correlations and look at more general continuous functions on the product space. And so there, you can just give sort of a soft operator argument to realize you can never have all gaps open for a fixed gap just because of the density of periodic points in some sense. Density of periodic points in some sense. You're always going to have intervals inside of the spectrum. What you can show, however, is that for generic f, you put a lambda in front, the number of gaps goes to infinity as lambda goes to infinity. And in fact, you can say that for any gap, there is some threshold above which that gap opens. So that's something that you can prove in that scenario. That's come back to you in the six minutes. In some sense, you said everything's what everyone else would do. Uh I think I don't fucking care, but I'm not I'm not sure if I care. So really it's um it's just hyperbolicity and a little kind of mouse which are inside your point. No, no, this is really uh since it's not. F I drive so because it's not very high. Do you have quantifications of at least for this class? No, but I do want to say that it's true that it's just for atlantax, but I think you can sort of continuously deform these things because as soon as you okay, I have to think about this. It did occur to me at some point that someone, maybe they don't care about exactly this affine map, but something which is sort of like a deformation of that. And I think you can still. And I think you can still argue that if you do something which is like homotopic to CatMap, then it still has no gaps. But I shouldn't make that as a plan because I don't. By the way, collect your shoes.