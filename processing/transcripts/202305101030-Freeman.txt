Everyone's been very nice. By the way, it's Canada that you are invited to. So this talk will be a little bit strange in that normally people give a talk and then there's questions at the end. This talk, all the questions will be during the talk that I'm going to pose to you, and then at the end, you give me the answers. So it's a little bit backwards, but I think. Little bit backwards, but I think it'll be fun. So, I'm going to talk about six kind of categories of questions. Each of these will have multiple sub-questions in it. And I'm not quite sure how long it'll take me to go through all of it, but if I don't make it through everything, I'll post the slides and help me. Slides and so you can see it later. Feel free to stop me and ask questions during the talk. The goal for this is I would like you to think that phase retrieval is cool and something you want to work on and hopefully it'll inspire people to do that. Whoops, that's fine. Okay, so Mitchell great gave a great introduction. Give a great introduction. So, we're taking a Bonach glattis and considering a subspace E, and we say that it does phase retrieval if whenever you have the absolute value of two vectors in the subspace being equal, that it means that one's a scalar multiple of the other for some unimodular scalar. And in the real case, things work out really. Things work out really nicely. Doing phase retrieval is equivalent to not containing pairs of disjoint vectors. So the first question is, is there any nice characterization for when a complex bioch function space does phase retrieval? I think there's a lot of people that would be very interested in it. Interested in it? And what are some different necessary or sufficient conditions for a subspace of a complex sponge function space to do phase retrieval? So Mitchell pointed out two known necessary conditions, which, as far as I know, these are the only ones known. So any contribution here, I think, would be very well received. So we cannot have. So we cannot have the subspace contain non-zero disjoint vectors. So I'll draw the same picture that Mitchell drew. If you had some disjoint F and G, then this would be the graph of F plus G and here. And here, might be difficult to see green, but this would be the graph of F minus G, and we have that F plus G has the same absolute value as F minus G. And so that's a very clear obstruction for doing phase retrieval. So if you have a For doing phase retrieval. So if you have a subspace of a complex botic function space and it does phase retrieval, you know that it cannot have disjoint pairs of vectors. And in the complex setting, you can't have pairs of linearly independent real vectors because for the same thing as what Mitchell said, is if f and g are real, then real, then we have f plus ig as the same modulus as f minus ig. And these are the only known obstructions. So any contribution here I think would be really interesting. However, we do have some nice theorem that says that if you have a subspace and it fails to do Subspace and it fails to do phase retrieval, and you have some inner product on that subspace, then it fails at orthogonal vectors. So this was with my PhD students. We did it in the Hilbert space setting, and this is for general onic space. So the simple example would be if you. would be if you take i to the 2 pi x this is in L2 of the interval 0, 1, and e to the i 2 pi times nx, or let's just put 3x here. This is also in L2 of the interval 0, 1, and they have the same modulus and their orthodoxy. And they're orthogonal. And this kind of problem always happens if you don't do phase retrieval. So this is, this is F, this is G, we have F inner product, G is zero, but we have the sub modulus. Okay. So that's the first question, which I think is one of the most interesting. Which I think is one of the most interesting. Another question that hopefully we got a lot of motivation for yesterday. So let's consider a bonach lattice and a subspace. Doing phase retrieval means that if the modulus of f and g are the same, then that means f equals lambda g for some scalar lambda. And so if we define an equivalent. And so, if we define the equivalence relation on E by f is equivalent to lambda f for every unimodular scalar lambda, then doing phase retrieval is equivalent to this map from f to its absolute value is one to one on the quotient space. And then doing stable phase retrieval just says that this map, this recovery map, This recovery map of, or the interest of this map is C. Lipschitz. And so doing phase retrieval says that you can recover F from its absolute value. Doing C stable phase retrieval says that this recovery is C Lipschitz. So natural question is if you Uh here is um a Bonach lattice characterization of that phase retrieval map being C. Lipschitz. So we proved that if you have a real Bonach lattice, then doing stable phase retrieval is equivalent to there existing a constant such that the minimum of the modulus of two F, F and G. Of two F, F and G is greater than or equal to K times the minimum of norm F and norm G. So essentially, doing stable phase retrieval, like Mitchell said, is equivalent to, in the real case, not containing a sequence of almost disjoint pairs. And there's lots of examples of subspaces which do stable phase retrieval. So then the natural question is: what about different types of continuity or convergence? How does that behave with phase retrieval? With phase retrieval. So let's consider vector lattice. Take a subspace of E that does phase retrieval. So this recovery map that takes the absolute value of F and maps it to F, it's well defined. Now if you consider some convergence structure, we'll say that this convergent structure is preserved by phase retrieval. Preserved by phase retrieval. If whenever you have a net in E and X in E, such that the absolute value of the net converges to absolute value of X, then you can find scalars with unimodular scalars such that these vectors, lambda alpha, X alpha, converges to X. So we heard a lot of about convergence structures yesterday. Structures yesterday. So, what properties of a subspace of a vector lattice guarantees that phase retrieval preserves some convergence structure? And what properties are necessary for phase retrieval to preserve a convergence structure? So, these are very general questions. I think, even in the case where I think even in the case where you look at a subspace of C and ask when does phase retrieval preserve order convergence? I don't know. I have some conjectures on this, but I don't think I'm confident enough to pose them. But I think that this would be really interesting to consider. Another Another question. Suppose you have two different convergence structures. What are examples where phase retrieval preserves one convergence structure but not the other convergence structure? I think there's probably lots of cool examples that hopefully someone who knows lots about convergence structures would be interested in. Okay. Okay. So another theorem that we proved is that if you have an infinite-dimensional Bonach lattice, it always has an infinite dimensional subspace which does phase retrieval. And so not doing phase retrieval says you have disjoint pairs. You can always build a subspace where everything has lots of little overlap, and so you can do phase retrieval. It's not too difficult. And so suppose you have some convergence. So, suppose you have some convergent structure, such as order convergence. What properties guarantee the existence of an infinite-dimensional subspace where phase retrieval preserves that convergence structure? Another question. Suppose you have a bonic lattice and you've already picked a subspace E. A subspace E? Can you find a further infinite-dimensional subspace which does phase retrieval? And so we have this infinite-dimensional lattice. We've picked a subspace inside it already. Our worst enemy picked it. How can we pick inside of that a nice subspace? And so you can ask the same question about convergent structures. So your worst. So, your worst enemy gives you an infinite-dimensional subspace of X. Sorry. So your worst enemy gives you an infinite dimensional subspace of X. How can you find something inside it that's nice and preserves convergence structures? Okay, so uh I don't have no idea what time I'm supposed to end it. 1125 or 1025. Plenty of time. Okay. So we've been looking at subspaces of X, but you could consider a subset instead. So no longer a subspace, and ask the same kind of Space and ask the same kind of phase retrieval questions for that. And so consider some subset of x cross x. Then it does stable phase retrieval means that the distance in the quotient space is less than or equal to c times the distance between absolute value of f and absolute value of g. But now we only pick f and g in this subset. So we're restricting. So, we're restricting the vectors that we're considering doing phase retrieval for. So what are interesting examples of lattices and subsets which do stable phase retrieval? Let's talk about some cases from Some cases from applied harmonic analysis. So, if you take a Hilbert space and a continuous transform, such as like the Gaber transform, you cannot do stable phase retrieval. The image of H cannot do stable phase retrieval in L2. And so, this is Theum Alefarium Gross. But But if instead of looking, trying to do stable phase retrieval on this entire subspace, there's very natural subsets that will do stable phase retrieval in capital L2. So kind of the idea is if H is L2, you have lots of L2 functions in, but suppose you only restrict yourself to Schwartz class. Schwartz class functions that decay very quickly and their derivatives decay very quickly. Then, if you're only picking functions in that, then doing stable phase retrieval is possible. And so this is a very important thing that a lot of people in applied harmonic analysis do: add a lot more structure to the kind of functions that you're looking at. You're looking at. And our theorems that we've proven really don't work at all for this case where you're doing subsets because our best result says that stable phase retrieval is worst at orthogonal vectors. But if you're just looking at a subset and you try to orthogonalize something, you're staying in the span, but you could go out of that span. In the span, but you could go out of that set. And so there's a lot of room for constructing subsets which do stable phase retrieval. So another natural thing to consider is instead of talking about the phase recovery map being Lipschitz continuous, we could consider Holder continuous. Continuous. And so we'll say that a subset does C holder stable phase retrieval with some parameter gamma if this inequality holds. So the case where gamma is 1, then this part will go away and you get exactly what we've been talking about before. One thing to point out is if E is a subspace which does older stable phase retrieval. Older stable phase retrieval, then it does Lipschitz stable phase retrieval because orthogonality is worst at orthogonal vectors. I'm sorry, phase retrieval on subspaces is worst at orthogonal vectors. And there, both of this will be like 1. And so this goes away. This will be between 1 and root 2. And so then if you raise everything to the gamma power, you get back lip shits. You get back lip shits. And so, for subspaces, holder stable phase retrieval and lip shit stable phase retrieval, they're exactly the same. However, people have built subspaces which do holder stable phase retrieval where it's not known if it does lip-shit-stable phase retrieval. Retrieval. And so here these are subsets and not subspaces. And so it's a really interesting question to determine what's the relationship between different holder parameters. So if it does holder stable phase retrieval with some parameter, what do you know about some other parameters? And how can you build interesting subspaces which do you Subspaces which do holder stable phase retrieval but do not do Lipschitz stable phase retrieval. So the constructions in here they explicitly construct some spaces and prove that they do holder stable phase retrieval, and then it's an open question, does it do lip shits? And so I don't think there are any examples known of subsets which do some holder stable phase retrieval, but don't do lip shits. But don't do lip shits, which is somewhat surprising. I think that would be an interesting problem to work on. Okay. So when we've been talking about doing phase retrieval, in applications, kind of the idea is that F is some signal that you're interested in. You can only You can only measure its magnitude, its absolute value, and then you want to cover either f or negative f, or more generally in the complex setting. However, in applications, there's also a much bigger class of signals that you'd be happy with recovering. So, usually, you know, if you do some measurements and then you construct some signal, it's often the case. Some signal, it's often the case that you'll be happy with F, you'd be happy with negative F. There's also other things that you'd be happy with. So, one example that I think is kind of fun is if you think about sound waves. So, in audio processing, there's certain applications where you have to do phase retrieval. Now, suppose I have a sound wave, it starts off playing this sound psi. Sound psi. So it plays psi for two seconds, and then it's complete silence. And then it plays phi for two seconds. And so that's some sound wave. And suppose that you're only able to measure the absolute value of this sound wave, and then you want to recover it. So, sound, you can't hear. You can't hear a universal phase factor in sound. So psi plus phi, psi sounds exactly the same as negative psi. Phi sounds exactly the same as negative phi. And because there's this break in between, this sound wave sounds exactly the same as this one. And so if we're doing phase retrieval and I recover any of these different sound waves. Of these different sound waves, all of these sound exactly the same as F. And so this is one application where if I can't recover F, there's no way I can recover F or negative F just from its absolute value, but I'd be happy with recovering any of these. So suppose I have a subspace of a bottom lattice. Space of a bottom lattice. I have a bigger equivalence relation, so there's more things that I'm treating as equivalent. How can we characterize when the phase retrieval map is one-to-one? So for the case of the equivalence relation being multiplying by one or negative one, we have a lattice characterization of this, but Take a bigger equivalence class and get a different characterization. I think that would be interesting to see what kind of equivalence relations give what kind of lattice structure for doing this phase retrieval. Okay, so another interesting question. We're going to think now just in finite dimensions. In finite dimensions. So if you take a subspace which is finite dimensional of Rn and it does phase retrieval, it's necessary for the superspace to have dimension greater than or equal to 2n minus 1. Because if this was not the case, then you could find disjoint vectors inside E. And also, if you pick spaces at random, then with probability. Spaces at random, then with probability one, if you're picking n-dimensional subspaces of r to the 2n minus 1, that subspace will do phase retrieval. And so you can ask in finite dimensions, suppose you have a bigger equivalence relation, how big must this be for this phase recovery map to be one-to-one on E-mod, this bigger equivalent. E mod this bigger equivalence relation. So something might be interesting is you could think about doing phase retrieval as trying to recover projective space. And what if you quotient out by some out by something different, you could get a different manifold. And so something like what suppose you have this is some dimensional manifold of some dimension. How big does this bigger space have to be in order to do phase retrieval for that manifold? So that would be something to Be something that I think could be interesting. And also, how big must the dimension be so that phase retrieval is possible for almost every subspace of n dimension. So question 14 says that how big must the dimension of the superspace be for phase retrieval to be possible? And then 15 is how big must the dimension be to so that if you pick any Be to so that if you pick anything at random, phase retrieval will be possible. Okay. So one thing that's done in applied harmonic analysis is a lot of the continuous transforms that people work with, they do stable phase retrieval. They do stable phase retrieval for things that are very close together. And so we know that stable phase retrieval is bad at orthogonal vectors. What happens if we have some continuous transform that we like and we're only looking at vectors that are close together, then that continuous transform could do a good job. So, one thing that people do is they consider Consider local subsets where your continuous transform, phase retrieval works really well on those little sets for your continuous transform. You then piece those sets together, and then when you try to do phase retrieval, you can recover on each of these sets the function f up to. function f up to some phase on that set and then those sets get added together and so you can recover F but up to a phase on each of these subsets but there's not a global phase and so it's kind of like in that situation where I was talking you had a piece of sound where you play a sound then there's a pause and then you play another sound Pause and then you play another sound. So we could stably recover one piece of sound separately from a different piece of sound, but I don't know the relative phase in between. This is something that lots of people have been looking at. And so all these examples are applied harmonic analysis. You know, applied harmonic analysis. But what are interesting Bonic lattice examples? So, what are some fun ways to construct some subspace of a Bonic lattice in some bigger equivalence relation such that this phase recovery map is Lipschitz equivalence? Lipschitz continuous from the absolute value of E to E mod this bigger and On this bigger equivalence relation. I don't think there's, I think, much known. And what are necessary and sufficient conditions for this recovery map to be Lipschitz continuous? And so you have some bigger equivalence relation that you like. Like, and you give lattice conditions which characterize phase retrieval for this bigger equivalence relation. So, I think that would be really interesting. So, like, just for normal phase retrieval, we have you can't have disjoint pairs. Maybe if you increase your equivalence relation, maybe it's conditioned like you can't have. Maybe it's conditioned like you can't have disjoint triples. Maybe there's something like that. That would be cool. So next topic. We're going to have a Hilbert space, and I'm going to have a collection of vectors in the Hilbert space so that this analysis operator, which takes a vector, Analysis operator, which takes a vector in the Hilbert space, maps it to the inner product with xj. We're going to assume that this map is an embedding of H into little L2. So this is equivalent to XJ being a frame. So suppose we have that. So if we look at the image of H in little At the image of H in little L2. So we're looking at all collections of inner products of X with XJ in little L2. This does phase retrieval means that for any X and Y, the inner product, the absolute value of the inner product of X with XJ is equal to the absolute value of the inner product with Y with XJ, and it doesn't hurt to just put a square on that. And so this is the setting where a lot of the phase retrieval people are working on. So let's see what happens in this setting. Okay. So if I take x inner product xj to its absolute value squared, that is exactly the Hilbert-Schmidt inner product of x tensor x with xj tensor xj. So what this is doing. So, what this is doing is this is absolute value is nonlinear, but now this is linear about the problem. And so this is equivalent to doing phase retrieval is equivalent to x tensor x inner product x j tensor x j and the Hilbert-Schmidt inner product. If that's equal to the same with y, then that means the tensor x tensor y. The tensor x tensor y is equal to y tensor y. Because when you do this tensor operation, this lambda goes away. So this is a trick that a lot of people do to get rid of this ambiguity, lambda, and to linearize the problem. And so now that we have this, we can subtract. And this here, this is a This is a rank 2 operator. And so I'll replace this with t. And so now we have doing phase retrieval is equivalent to, if I look at the Hilbert-Schmidt inner product of t with xj tensor xj, this is equal to zero if and only if t equals zero. And so now this is an entirely linear formulation. Linear formulation of phase retrieval. The only difference is we were interested in doing phase retrieval in little L2. Now we're doing phase retrieval in the space of self-adjoint operators on H. So, doing phase retrieval for the subspace of little L2, it's equivalent to 2, it's equivalent to whenever t is a non-zero self-adjoint operator with rank at most 2, then the orthogonal projection of it onto the closed span of these rank 1 operators is non-zero. And now this is an entirely linear question. The only problem is that we've made our Hilbert space much, much bigger. Okay. Okay. So so take a infinite dimensional Hilbert space. Can you pick these xj so that this collection of tensors is a conditional basic sequence, so that there's a constant greater than zero, so that the Hilbert-Schmidt norm of t is always less than or equal to. Is always less than or equal to C times, oh, there should be a T here. This should be the norm of the projection of T. And so the idea is, can you build a basic sequence which does phase retrieval in this Hilbert Schmidt setting? And you can't do it with an unconditional basis because if these xj's form an unconditional basis, Xj's form an unconditional basic sequence in the space of self-adjoint operators, then, and this was true, then the sequence XJ would do stable phase retrieval in little L2, which is not possible. And so, this is something that I think would be really cool because we cannot. We cannot do stable phase retrieval for infinite dimensional subspaces of L2. But we can lift the problem to a question about self-adjoint operators. And does there exist a conditional scouter basic sequence which does phase retrieval for the self-adjoint operators with rank at most two. Variables with rank at most two, you can go even further and say: does there exist a conditional Schouder basis for the self-adjoint Kilbert-Smid operators on H consisting entirely of positive rank one operators? So this is, I think, a very bold question that I really want to prove it. Want to prove it and so I hope it's true and that we can prove it, but I don't know. So let's look at some examples of bases of positive functions. So the Faber-Schauder system, this is a basis of positive functions in C01. So those are the spaces, it looks like a bunch of triangles. Of triangles. For capital 1, there exists a conditional Schauer basis consisting entirely of positive functions. So there does not exist an unconditional Schauer basis for capital 1, but there does exist a conditional 1 just consisting of positive functions. And we proved that there also exists a conditional shadow basis for capital L2. Basis for capital L2 consisting entirely of positive functions. And it's well known that you cannot have a conditional shader basis for any LP consisting entirely of positive functions when the measure is not atomic. And so little LP has a basis of positive functions, just the unit vector basis. But for any not purely Not purely atomic measure, you can't have an unconditional basis, but you can have a conditional. So this is pretty similar to this question. So the space of Hilbert-Schmidt operators, self-adjoint Hilbert-Schmidt operators is a Hilbert space. I hope I don't anchor anybody. I'm by positive here. By positive here, I mean that dx inner product x is greater than or equal to zero for every x in the Hilbert space, not positive as an operator on a botic lattice. So, one of the difficulties about this question here is that this space of self-adjoint Hilbert-Schmidt operators Joint Hilbert-Schmidt operators, it's not a Bonic lattice. But I think it would be really cool to get a positive, a basis of positive rank one operators. And it would give a reconstruction formula for doing phase retrieval in infinite dimensions, which currently isn't known. So another natural So, another natural question considers what other Bonach lattices have a conditional shader basis of positive vectors, but not an unconditional basis of positive vectors. I think these are essentially the only known examples other than doing something silly like doing L2 plus L1. But that doesn't count. But that doesn't count. And I gave a talk on this in a Zoom seminar. It was like three weeks after COVID locked down. And of course, the 100 people came to the Zoom seminar because they don't have anything else to do. And it was lucky for me. And Vladimir Kaditz asked, well, instead of looking at the positive cone of a bonic lattice, what are other examples of cones in bonic lattices? In bonic lattices, which contain a shower basis? I think this is a really interesting question. And so I don't know. Okay, so this is my last topic for discussing what I do. Discussing what I don't know. And a lot of times in applied harmonic analysis, people prove theorems using continuous transforms. So things like Fourier transform, Gabbert transform, Wavelet transforms, they're really nice to work with. But in applications, you only want to take finitely many measurements. And so you want some discretization of the transformation. Discretization of the transform. So that corresponds to given some subspace of L2 intersect L infinity, how can you find sampling points such that the L2 norm on E is proportional to this little L2 norm of the sampling points. And so, a natural example is. Example is take Fourier transform on L2 of the unit interval. That's a continuous transform. If you sample at the integers, you get Fourier series. So this is probably the most famous example of this. And so for applications, being able to discretize is really important. And it turns out that this can always be done. Done. That if you take any subspace of L2 intersect L infinity, the L2 norm can always be discretized on that. The proof of this uses the solution to the Caddison-Singer problem. And so I was very lucky that some very smart people solved that, and then I could use it. However, in approximation theory, you have a subspace which is finite-dimensional, and you want finitely many sampling points. And so in approximation theory, people have been working with taking a finite-dimensional subspace of LP, where omega is a probability space, and now you want to sample and discrete. And discretize using a number of sampling points proportional to the dimension or proportional to the dimension log n or something like that, something close to it. And so there's a lot of recent work on doing this. And so in finite dimensions, where you're sampling a probability space, you take n sampling. You take n sampling points, you take the LP sum of the samples, and then you want to divide by n so that this is now still a probability measure, but on a finite set. Because if you didn't divide by n, then this is going to blow up to infinity. But the law of large numbers says that if you randomly pick these sampling points. Pick these sampling points, then this converges to the norm of LP. So it's easy to show that given any finite-dimensional subspace of LP, if n is huge, then you can do this. But the natural, the difficult questions is trying to discretize for small n. And there's a lot of research. There's a lot of research on this. Okay. So, but we're interested in doing phase retrieval. So we want to consider some subspace of the finite dimensional bonic lattice. We want to discretize the norm on the subspace in such a way that we do stable phase retrieval after discretizing. After discretizing. Okay, so this is a lot. But the basic idea is: suppose you have some subspace which is finite dimensional of LP on some probability space. Suppose it does C stable phase retrieval. So I have a finite dimensional subspace which does C stable phase retrieval. How can we sample it? How can we sample it so that the sampled points in LPN also does stable phase retrieval? I'm allowing this constant to be different though. It'll probably have to be bigger. And also the LP norm is preserved under this sampling. And so there's a lot of all of this work. All of this work right here, they're discretizing the LP norm. So, this question is: can you do what they do and also preserve stable phase retrieval? And the answer, the simplest, naive thing to do is look at their proofs and say, and check. And so far, it So far, the proofs don't go through exactly the same. We need some new ideas, which is good. If the proofs went through exactly the same, then it wouldn't be fun. And so I think this is a really interesting question. This has been studied a lot in the case for P equals 2, where you look at a subspace E, which is formed by the span of some. By the span of some independent random variables. So, in particular, if you take independent random Gaussian variables or independent uniformly sub-Gaussian variables which do stable phase retrieval, then picking n points at random discretizes everything really nicely with high probability when n is on the order of the dimension. The dimension. So essentially, the reason for this is that Gaussian and sub-Gaussian random variables have very strong concentration properties. And so if you know that something happens in expectation, randomly sampling sub-Gaussian random variables says that it concentrates very quickly. But all, so. But all so all of the solutions to this question, every single one is for sub-Gaussian random variables and sampling at random. And so there's a lot that's unknown about this. And one thing I want to point out is we prove that if you discretize the L2 norm on E in such a way In such a way that it preserves stable phase retrieval, then you're also, that discretization also discretizes the L1 norm. And so what's happening is before, if you're just looking at discretizing the norm on the subspace, you just care about the p-norm. But if you want to do phase retrieval, so one of the So, one of the theorems that we have is that doing stable phase retrieval means that the L2 and the L1 norms are equivalent. And so if you want to discretize just the L2 norm, you only care about Hilbert spaces, this theorem says that you can't stay just in the Hilbert space setting. You have to also discretize the L1 norm. The L1 norm. So, this is kind of cool that even if you're a pure harmonic analysis and you love Hilbert spaces and that's the only thing you care about, well, maybe you should also care about the Bonach space structure as well. So I'm hoping that this is something that Bonic lattice people could contribute in. And in this discretization, you have to care about the Bonach space norms and not just the Hilbert space norms. Not just the Hilbert space norms. Okay. And so that is those are the questions. We have a lot more questions in our paper and in Mitchell's thesis. And I put up all the citations. So if you are interested in what people are doing, I can tell you. Yeah, I could tell you. Okay, so Nebug has any answers for Graham? Yes, okay. I finished a few minutes early, so let's see if you have time to think about the answers. Then more questions. So I think about page nine, you had a question where you moved from a subspace to a subset, that was a script A. To a subset that was a script A, right? That one there, right? It seems to me that it's kind of a halfway house. Because you could say that, I mean, the original question looks at the script A is sort of a set of the form E cross E, right? But there are other subspaces of X cross X, right? So you could still say A is a subspace of X times X, right? Have you thought about that? Does that make sense at all? Yes, that is. Yes, that is a great question. Thank you. So I ask for answers, but I'll also accept very good questions. Yeah, so that's a really good. So our proof that stable phase retrieval is worst at orthogonal vectors, you have some f and you have some g, and you look at some linear combination of f and g. But if you pick a subspace of x cross x, it could be the It could be that the linear combination of something in the first coordinate with something in the second coordinate isn't going to be in it. And so that would be a really good thing to consider. So you say that the worst case is the case of control records. So I think you have a statement on slide four, if you can mind. Yeah, so here you say that inner product on E What does this inner product have to do with the original normal or that's? So that's a great question. So you get to pick whatever inner product you want. So John proved that every two-dimensional subspace is root 2 equivalent, the norm on any two-dimensional subspaces is root 2 equivalent to L2 dimension n. And so if you're only looking at, so we proved that if you have, if you pick any two vectors, just look at their span, it's a two-dimensional subspace, you can pick an inner product on it where the L2 norm in the norm is the norm, The L2 norm in that inner product is close, is root to, at worst, root 2 equivalent to the norm that you started with. And then in that L2 inner product, stable phase retrieval is worst at orthogonal vectors. And so it's a kind of thing that for this, you only have to consider two-dimensional subspaces, but you could have an inner product, you could define one on the whole space. You could define one on the whole space, and it would still work that stable phase retrieval is worst at orthogonal vectors. And so this is something that's useful for, like, if you consider subspaces of capital P, which are isomorphic to a Hilbert space, then you have an inner product to find on the whole space. But for this, no matter what inner product you pick, No matter what inner product you pick, the worst thing happens at orthogonal non-zero vectors. Can you then take semi-inner product and look at like Kirchhoff-James or analysis? So the problem I think in our proof we use the linearity imposed variables. Yeah. Maybe it might be interesting, though, to consider some inner product and see what happens. I think in general, it won't be the case that stable phase retrievals worsted orthogonal vectors, but maybe you could say something. Could say something. Like, maybe in terms of the continuity of the map from the space to the dual. Other questions? I have a question. Uh so suppose you can do a C stable phase integral, for example in capital L two. How much can you improve that? C? Can you do like one plus epsilon? That's equivalent to like one plus epsilon statement? Yeah, so yeah, an interesting question would be what is the smallest C can be? My guess is that would be for IID Gaussians because of the central limit theorem. But I don't know what the C is for IID Gaussians. For IECU states. I know they do say phase retrieval, but that would be good to check.