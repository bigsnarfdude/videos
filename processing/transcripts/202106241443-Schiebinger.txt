is in collaboration with a lot of people including Jung-kun Kim here in the audience and I hope to get some of you excited about these biological directions building towards a theory for developmental biology. So how do we come to be from a single egg cell to 20 trillion cells that can walk and give talks? So we'll think about a developing population of cells as a curve in the Cells as a curve in the space of probability distributions. And we'll see how new measurement technologies can give data along the data points along this curve, which we can then connect with optimal transport to form a piecewise geodesic approximation to the curve. And at the end of the talk, I'll show how this framework can be extended to include even newer measurement technologies that can give information about something called the lineage tree of the developmental trajectory. Tree of the developmental trajectory. So I'll begin though, since this is not a biological audience, with just a two-minute review of the 20 trillion cells that we have and how they form organisms and what it means for an organism to develop. So the cell is the fundamental unit of life. All of our, you know, we have 20 trillion of them. And And each cell, you know, each tissue that you can imagine is composed of these cells. So, in your skin, cells form a barrier between the inside and the outside. Same with the gut. In the brain, neurons process information. Glia support the neurons. In muscles, cells contract, expand, and in the blood, cells fight off. Blood cells fight off pathogens and also transport oxygen. All of these cells have the same DNA though. Okay, so you get this DNA from your mother and your father, and this is the genetic information that is passed down and encodes all of the stuff, encodes for the proteins that do all of the things that the cells need to do. Okay, so these. Okay, so these you can think of the DNA as a long string. It's actually one meter long in your cells. In humans, it's one meter long, but it's packed into the nucleus. And you can think of this as a long string with substrings called genes. Okay, so this is a long string of A, of letters like A, T, G, A, C, et cetera. But then there's substrings. So this is gene one here. This in between is not a gene. And then this over here is another gene. And this is another gene. Gene and this is another gene, right? And there's 20,000 of these substrings called genes. And what is a gene? Well, a gene is something that encodes for a protein. And then the protein is something that will go and actually achieve the cellular function. But like I said, all your different cells, even though they're different types, so for example, here we have in red we have neurons, which process information, and in green we have astrocytes, which are another type of supporting cell. Which are another type of supporting cell. They all have the same DNA, but they use the DNA in different ways by expressing different genes. So, here we're color-coding gene expression according to three colors. We have red, green, and blue, which are fluorescent tags showing the level of expression of three genes. And basically, only the neurons express the red gene, only the astrocytes express the green gene, and this third cell type is only found this. You know, it is only found, this blue gene is only found in some third cell type. This classical way of looking at tissues through the microscope, which people have been doing for hundreds of years, is it's only able to shed a partial picture on what's going on because we don't have 20,000 colors. So we can't tag cells and look at the gene expression for all the different kinds of genes that we'd like to, only for very low dimensional genes. Only for very low-dimensional projections, so three genes at a time, for example, or maybe if you really get creative with your colors, you know, 10 colors at a time or something like that. So, this new technology that's maybe five years, six years old at this point is single-cell RNA sequencing. It's based on sequencing, as the name suggests. So, we sequence the RNA. And when you sequence a molecule of RNA from a cell, Molecule of RNA from a cell, you know what the letters are, and you know which gene it corresponds to. And you say, aha, this is another molecule of RNA from gene 17 from cell number four. And you know which cell it's from because the cells are actually isolated in these fluidic droplets, which is another aspect of, which was a recent breakthrough that increases the throughput of these measurement technologies. Mathematically, we'll think of these cells as vectors in some high-dimensional state space. Concretely, if we're thinking about gene expression, we could record how many molecules of RNA a cell has for every single gene. So for each of the 20,000 genes, we could record the number of molecules of RNA. And then we would have a vector in R20,000 representing the state. R20,000 representing the state of this cell in terms of its molecular profile. So, for example, if we think about this slice of the brain, these, you know, the neurons in yellow here, so the color has changed, these neurons which are now in yellow, would have maybe gene one and gene four on, gene two and gene three off, whereas astrocytes would have a different set of genes on and off. So, if we think about this motivating. So, if we think about this motivating question, how do cell types emerge? It's really a miraculous process, right? So, the single egg gives rise to all these different cells. And we'll talk about a mathematical model for this, and that will be kind of the remainder of the talk because we're going to transition to the math now. And then at the end, we'll see some applications on real data. So, the classical mathematical metaphor is a kind of a potential energy theory for development. Theory for development: that a cell is like a marble rolling through a potential energy landscape where there are valleys for the different cell types. So this might be the valley for red blood cells, white blood cells, etc. And it's the curvature at the bottom of the valley that stabilizes the cell type. If we could learn the shape, one more thing, if we could learn the shape of this landscape, then we would understand. Understand, you know, we could say, okay, the cells are proceeding according to some, maybe there's some noise, so maybe it's a stochastic differential equation that governs the dynamics here. And if we could understand the shape of this landscape, that would be a precise mathematical model for how cells develop under normal conditions, how the cell types are stabilized, and maybe we might even understand how cells destabilize with age or in diseases like cancer, which is a disease of the cell type. Disease of the cell type. So, as cells change their state over time, we'll think of a cell as a point at any fixed time and describing a path as the cells change their state over time in this cell state space, which concretely we'll think of as gene expression space. But there's other measurement technologies which are emerging, which can measure other attributes of cell state. For example, something called chromatic. For example, something called chromatin configuration, etc., etc. There's now tens of these measuring technologies. The key aspect of all of these technologies, though, is that they are destructive, which means that when you measure the state of a cell, you destroy the cell because you break it open, for example, to look at the molecules of RNA inside. So we could either measure this individual blue cell at time t1, or it's say, Or it's say four descendants in red at time t3. Okay, so we'd like to understand these paths in order to learn the equations of motion that govern development, but we can't directly see the paths. And so we seem to be a bit stuck. But this is where we will leverage some mathematical modeling to try to infer these trajectories. So the basic experiment. So, the basic experiment that people do is a time course where they don't watch individual cells changing over time, but they prepare separate versions of the process. So, embryonic development is reproducible, right? Every time you fertilize an egg, ultimately you get an organism with two arms, two legs, etc. If it's a vertebrate. So, for example, if you want to make three time points, you could prepare. Time points, you could prepare three separate versions of the process. Allow one embryo to grow until time T1, a separate embryo to grow until time T2, a third until time T3, etc. And then you would measure all of these cells exist at time T2, all of these cells exist at time T3, and you'd want to infer that, for example, this subpopulation on the right gives rise to these two subpopulations on the right. So we want to infer the end. So, we want to infer the ancestor-descendant connections between the cells across time points. One way to do that would be again to recover this potential energy surface. However, if you're going for that directly, that cannot be achieved through convex optimization. You'd want to, you know, if you were going to try to do that, you'd want to parametrize the energy landscape somehow. Energy landscape, somehow. So consider some class of energy landscapes and say what is the best fit to the data. And I'm saying that would inherently lead to a non-convex optimization problem. However, we'll see, you know, through some joint work with Jung-hoon Kim and their collaborators, Hugo Lavenol, et cetera, towards the end of the talk, that the trajectories can. Okay, so let's now. Okay, so let's now see what the mathematical model will be. We'll consider a Markov stochastic process. So there will be a, remember a cell was some point in some state space. Now a collection of cells will be a probability distribution on that underlying state space. And we'll assume it's a Markov process. So at time t1, we'll have a probability distribution pt1. And that's the blue distribution here, which will give us the blue samples. So the measurement process will be. So, the measurement process will be modeled as sampling from this probability distribution. Then, the temporal evolution will denote by this Markov transition kernel gamma. So between any pair of time points, you can have a Markov transition kernel. And this describes the ancestor-descendant relationships between pairs of time points. And this is the object that we'd like to recover from these independent measurements. The approach that we'll use is optimal transport, hence my presence here in this conference. So we'll use this to couple the cells that we see at one time point with the cells that we see at the next time point. So the interpretation of the transport map here will be: if you have, say, a cell that exists at some state X, We'll consider this to be kind of a maybe we have a unit mass of cells there. We'll represent that with a direct delta function. And this will be pushed forward to some pile of cells pi. Okay, so the cells at x will be pushed forward to pi of x, dot, which will be a distribution over states y. Okay, and so we'll consider the optimal transport plan, just in the usual sense, to be the one that minimizes the expected cost. That minimizes the expected cost, where C of XY will be some cost associated with matching an ancestor cell at state X to a descendant cell at state Y. We'll use the squared Euclidean cost and minimize this linear program with some particular careful choice of source measure P and target measure Q. And these will be related to. And these will be related to the cells at one time point and the cells at the next time point. Specifically, borrowing this cartoon from a few slides ago, we'll have the true population on the right-hand side evolving according to the true coupling, and we'll approximate this with optimal transport computed between the empirical distributions. Jeff, can I ask a question? Yeah, please go ahead. Can I ask a question? Please go ahead. What is why the Euclidean cost? I mean, is that the biologically correct cost function to look at? The Euclidean distance? That's an excellent question. Okay, so of course, no, it's not exactly correct, right? And then this is a very deep, you have to go very deep down to say, what is it? It's going to ultimately be related to a lot of. Be related to a lot of things, you know, measurement noise is going to be related. Okay, you could imagine actually the time difference between T1 and T2 is so small, okay? Let's say one millisecond or something like that. So, you know, over one millisecond, a skin cell is going to stay a skin cell. It's going to stay almost exactly what it was before. Then we're going to be basically what we want to couple things basically to what they were before. Okay. And then really, it's an issue of measurement noise. Of measurement noise. So, how surprised are we if we measured a cell x and then we measured again and it looked like y? And so we use squared Euclidean distance because if we have a lot of data from every cell, so we see all the RNA in there, then maybe the measurement noise is Gaussian, and so squared Euclidean distance is kind of reasonable. So, measurement noise is one half of the answer to the question, okay? And then you could still ask if squared Euclidean really was the right thing there, if it wasn't really Gaussian, et cetera, right? But then the second side of it, after measurement noise, is related to the actual geometry of the underlying gene expression dynamics. So, these cells are describing some trajectories. I was talking about this kind of landscape, right, this potential energy surface. Write this potential energy surface, and the cells would travel along these trajectories. And maybe there is some manifold of possible cell states lower dimensional than the full 20,000 dimensional gene expression space. And so maybe instead of, say, Euclidean distance in the ambient space, we would want to have something like the geodesic distance in this manifold. But we don't necessarily know what the manifold. But we don't necessarily know what the manifold is in advance. So we, in practice, we do something like principal components, you know, we reduce the dimensionality somehow and then use square Euclidean distance. Does that help, Sameeek? Yes, yes, of course. Thank you. But it's a very good question. And we ultimately don't know the right cost function. So this is kind of, you know, also your first explanation is very entropy regularized because you're Is very entropy regularized because you're assuming that the noise is Gaussian and therefore it corresponds to the limit to the quadratic cost. So that's very entropy regularized kind of situation. Yeah, and there's going to be entropy regularization for another reason as well, because the motion of the cells will be according to some stochastic differential equation as well. And then the entropy regular parameter is going to determine, it's going to be related to the level of diffusion in the SD. Of diffusion in the SDE. Okay, so should we keep going? Okay. Yes, thank you. Thanks for the great questions. Okay, so intuitively, we'll think of this developmental process as describing a curve. And this curve will be somehow continuous with respect to some optimal transport metric. Metric. So far, maybe it's Wauserstein space, but ultimately we're going to incorporate entropic regularization as well. And then we're connecting these empirical distributions with optimal transport. So that's something like a geodesic, once we incorporate entropic regularization, it's a shortinger bridge between each pair of time. But we need to consider two things. Okay, so number one, cells can proliferate, but optimal transport conserves mass. So we will tweak the constraint. So, we will tweak the constraints. And number two, we will incorporate entropy regularization to deal with the fact that cells can be stem cells. So cells can give rise to multiple different fates. Okay, so first about the growth. So if we pick up a unit mass of cells and then we put it down as some pile pi, if the cells grow during that time interval, then we would put down a pi pi pi pi pi pi. Time interval, then we would put down a big pile pi. If the cells grow less rapidly, we would put down a smaller pile pi. So this growth rate will determine the amount of mass that we have after we pick up a unit mass. So what we'll do is we'll scale pointwise the mass coming out of the source measure, which is this distribution of cells at time T1, and then we'll transport them forward in time to the target measure at time T2. To the target measure at time t2. We'll add entropy regularization. Sorry, so this was the first, we're done with growth now. Okay, so the next thing we'll do is we'll add entropy regularization. And this has the interpretation of giving, this can be interpreted as follows. Okay, so consider a specific cell here if highlighted in dark green at time t2. Now, this cell will have some descendants at the later time point and some anti-s At the later time point and some ancestors at the earlier time point. In reality, a cell will only have one ancestor. In reality, a cell will have okay, so I see that Lior is asking a question. Lior, would you like to ask your question? Oh, did I was there a typo on the yes, you're right. Yeah, so there's a typo here. Yeah, I'm sorry. So the integration here. Yeah, I'm sorry. So the integration here, thank you. The integration here should be TX, and then your integration should be. The first slide should be PT1, I think. In the first slide, you integrate the mass, right? In the first slide, you just get PT1 of X, because just starting mass is just there. And then the second one should be on the right-hand side should be a T2 and a Y, right? This is correct. The right-hand sides are correct because of the way I'm doing it with growth. So it's growing. Doing it with growth. So it's growing. It's that the left-hand side should be dy here and should be dx here. So let me. Okay. So this should be x here and this should be y here. Thanks for catching this typo. Okay. Okay, so um Okay, so um okay, so now we'll consider a specific cell at um this this green cell. So this will have a distribution of descendants at the later time point and that's so you know so each entropy, it's sorry, each entry of this transport matrix will have units in terms of numbers of descendants. Okay, so so this specific cell will have some then distribution of descendants. Have some then distribution of descendants if we consider the whole row. And the level of entropy in the transport matrix will determine how many cells this is roughly connected to. So if we increase the entropy regularization more and more and more, then eventually we just get the independent coupling, which would say that this cell could have any cell as its descendant. On the other extreme, if we don't add any entropy, this cell would be coupled to one specific descendant. To one specific descendant. Now, that's kind of the intuition there, right? Even if this cell had just one specific descendant, we probably wouldn't sample that specific cell because there's measurement noise because we're sampling finitely many cells. So we always think it's a good idea to add a little bit of entropy to the transport matrix. Okay, and then the final model. Okay, and then the final modeling ingredient that we'll add is unbalanced transport. And I see that the typo didn't propagate here, so we have the right integration here. But we replaced the equality signs with kind of squiggly equality signs here. So more precisely, we would constrain the, for example, the Koblik-Leiben-Blair divergence or the relative entropy between the left-hand side. Between the left-hand side and the right-hand side. And that's because we don't know these growth rates exactly. So we don't want to, especially for this constraint here, we don't want to impose this too strictly. Okay, so let's first of all see how this basic idea works in applications, and then let's see how to extend it. So the first system that we tested this on in collaboration with my colleagues at the Broad Institute, my mentor, Colleagues at the Broad Institute, my mentors, and my collaborators, we tested this in mouse embryonic stem cell reprogramming. So we took skin cells basically from a mouse and reprogrammed them into stem cells over 18 days, collecting time points every 12 hours. The overall data set looked like this. We collected roughly 300,000 cells, and here's a point for every individual cell. This is a two-dimensional This is a two-dimensional visualization of this 20,000-dimensional data set. It starts over here in black and progresses towards a variety of different states here. So we can see these cells based on the gene expression profiles that they have, these look like stem cells. And we can then, with optimal transport, compute what their ancestors were and the ancestors at the previous time point and so on and so on and so on going back in time. And similarly with any other final destination. Other final destination. And then we can analyze the changes in gene expression along these trajectories. We've kind of deconvolved this mixture of processes into separate pure trajectories to these different states. One thing we did to test these trajectories, so to test to see how reasonable this was, was to see if we could hold out the data from time T. We could hold out the data from time t2 and then, through geodesic interpolation, infer what the distribution would be like, just connecting time one to time three directly, stop it in the middle, and then compare to that held out data. And when we do that, we see that we get the red curve here, which closely matches the green curve. What is the green curve? It's how well we would do if we just looked at the Looked at the green data two separate independent times. Okay, so repeat the experiment twice, collect two separate versions of the green data set, these cells at time two. Those aren't exactly the same. They're some distance apart just because we're sampling finitely many cells. And in kind of the later half of the time course, the red matches the green quite well, significantly better than this. Significantly better than this null model here, which is just an independent coupling. We've since tested this in a large number of different systems, including sea urchin development here, which I'm showing, but also we've tested it in plants, in root growth, we've tested it in humans, in blood formation, and a few other systems as well. Here I'm showing the results for urchin embryonic development. Here I'm showing the results for urchin embryonic development, where we collected 18 time points over 24 hours of sea urchin embryonic development, starting off in the lower left here with a fairly homogeneous population, which then differentiates into basically a continuum of states and then some rarer cell types down here. And this is in collaboration with Greg Gray Dave McClay at Duke with the student lead A.J. Masri, who collected the data. And we see that we're able to reconstruct the classically known Construct the classically known gene regulatory networks with a very high degree of accuracy. So you can read this like an electrical circuit diagram. You know, this gene turns on some other gene, which turns on some other gene, and so on. And for this, we focused on this time interval here where our data was the cleanest. And we found, so the genes with bold black font as opposed to light gray font. Font as opposed to light gray font, the black ones we get and the gray ones we miss. So there's 18 out of 21 that we're able to reconstruct here. So we're able to, you know, it's consistent with stuff that's known, so that's kind of comforting. The overall perspective that we get here on how you'd like to design these experiments moving forward is that you should collect as many Is that you should collect as many time points as possible. So each time you collect a time point, this means you prepare an embryo, let it go for some amount of time, and sample its cells. And you should have basically as many of these time points as possible, because if you think about this curve in Vosserstein space, then each time point is a data point along this curve. And the number of cells that we obtain is really the noise level. So I'll show some. I'll show some quick data to motivate this claim that it's better, namely these plots here. So in these two studies that I've shown so far, we're looking at the performance of geodesic interpolation, where we connect time one to time three and then compared to time two, which was held out in green here. And we see how well does that perform as we throw away data. So we're going down here to half the data set size, a quarter, all the way down to one. Size a quarter all the way down to one hundredth of the original data set size, and this geodesic interpolation gets worse. So in orange, it gets worse as we throw out cells, randomly chosen cells from all of the time points, whereas the results get worse much more rapidly if you throw out whole time points. So that would mean removing an entire time point here, as opposed to just throwing out cells would kind of make all of the time points noisier. Time points noisier. Okay, and we see that it's better to have the full temporal resolution. So the orange curve gets worse less quickly than the blue curve. What this motivates is collecting a lot of time points. That's difficult experimentally because typically you have to touch each embryo. So for example, my urchin collaborator and my reprogramming collaborator, they had to go into the lab and collect. Had to go into the lab and collect separately each time point, right? So that's why we have roughly only 18. You know, each one of those would take a day, the whole thing would take 18 days, right? With some collaborators here at UBC, we are implementing a strategy to collect thousands of time points for the first time. And that will be a very exciting data set to look at when it's ready. This motivates kind of new methodological directions. Methodological directions and kind of theory directions that I've been exploring with Yung Hyun Kim and our collaborator Hugo Lavenol and student Stephen Zhang, who just graduated. So we look at this problem of recovering this curve in Basserstein space. And compared to what I've talked about so far was connecting each dot to the next, right? But if you're doing ordinary regression, you have some data points, you never just connect each data point to the next. Connect each data point to the next, what you do is you fit some curve to the data. And that's what we're doing here in the space of stochastic processes. So we consider an optimization problem over stochastic processes R, where there's a trade-off between data fitting. So if we're reconstructing this green curve here, the green boxes should somehow be close to the black dots, but we're not going to say that they have to be exactly on. Say that they have to be exactly on the black circles, the green squares can be a little bit further away if that allows us to regularize better. So this first term measures the regularization, which is basically the squared integrated length of this curve in Bosserstein space. And we were able to prove a theorem, which was driven mostly by Hugo Lagnon, that if the ground truth If the ground truth, namely this red curve, is generated by a stochastic differential equation, so something like this picture that we had started off with in the beginning. Then, in the limit, as we collect infinitely many time points, the optimal solution of this optimization problem will converge to the ground truth. So, what this means, the ground truth is this. The ground truth is this curve in Basserstein space together with the paths, the trajectories traveled by the individual cells. Okay, and so we can recover this by solving a convex optimization problem in the space of measures. And we have a preprint on BioRxive, which can be found on our websites or by searching the title of this talk and our names. The thing that I want to end with. The thing that I want to end with, so this is the last little story I want to tell, and I'll thank you for your attention, is this extension to incorporate lineage tracing. So what is the lineage? Okay, so here we have another picture of a cell traveling in this gene expression space and then dividing and giving rise to, say, four descendants here at this time point where we've stopped the process. The lineage refers to. Lineage refers to a tree structure with a leaf for every cell. And this tree structure, you can think of it like an evolutionary tree for the species. Okay, but I mean, so in the context of this cellular development, the tree structure would tell you this cell shares a common ancestor with this other cell at some time point. Okay? So if we then never mind the letters. Never mind the letters just for one more second. I know these letters are distracting, but the letters are going to be related to experimentally how we measure the tree. I just want to explain a little bit more about what the tree is, and then I'll explain what these letters are. So let's focus on this middle picture here for a second. So here we have two realizations of this process. We have the blue process, which we've stopped at time T1, and then the red process, which we've stopped at time T2. If we can then reconstruct the lineage tree, Can then reconstruct the lineage trees. We would have a picture like on the right where there's now another axis here, which is time, and we have equipped each of these cells with this lineage tree. And I just want to say now about these letters, so we can reconstruct this lineage tree by looking at the mutations that happen over the course of development. Similar to how one could reconstruct an evolutionary tree by looking at the mutations. Evolutionary tree by looking at the mutations that happen over the course of evolutionary time scales, where you might have humans and then the DNA sequence of humans, the DNA sequence of chimpanzees, and the DNA sequence of rats, and you would see that humans are more closely related to chimpanzees than to rats. This process of mutating some sequence of letters can be kind of made more efficient by Made more efficient by making mutations on purpose in some artificially inserted piece of DNA that you're allowed to make mutations in without damaging anything. And that's called a barcode. And the way that that happens is with something called CRISPR, which is a base editing technology. It's a genome editing technology. So Aiden Faro and I thought about how we can leverage this new measurement technology, which allows you to get at the cell lineage. To get at the cell lineage together with the cell state information, because these barcodes are ultimately expressed as RNA and can be collected together with the other gene expression information. So we thought, how can we leverage this information? First of all, we observed that if you don't leverage this information, the trajectory inference, you know, trajectory inference can go awry, right? So you can make mistakes, right? So here I've shown this is the same setup as the previous. Shown this is the same setup as the previous slide, and these two cells here are matched to the wrong ancestor just because they're actually closer to the wrong ancestor, because there's this kind of complex crossing over event that happens here. What we propose to do, though, is to use this lineage tree to adjust the positions of the cells in some first step. The way that we do that is based on assuming. On assuming that the cells that we see at this time point are generated by a branching Brownian motion to give just an initial estimate at where those cells would be at time t1. And then we couple those cells from time T1 to the, you know, then we couple the adjusted cells to their ancestors. And that's with entropy regularized optimal transport as before. And we just have a preprint that will appear in nature communications. That will appear in Nature Communications shortly. It's just been accepted this week. So, with that, I know I'm at this point way over time. So, thanks for your attention. And if there's any students in the audience, we have positions available and UBC is a great place to live and do research. So, thanks, everybody. And again, sorry for being late. Thank you for your talk. Thank you for your talk. So, we had some questions in between, but maybe there are some further questions or comments from anybody. You can just unmute yourself and ask a question. Jeff, I just have a comment there. So, I wanted to mention that Matthias Weigelberg gave a talk in the morning session where he constructed this Wascherstein geometry for stochastic processes. Geometry for stochastic processes. So lifting Buster geometry from measures to stochastic processes, which is non-geodesic properties and distances and so on. Maybe that's relevant to this regression that you are doing. Just wanted to mention that. Yes, I intend to watch the record. I saw that. We're moving tomorrow, so we're really stretched to the limit here in terms of I really am eager. I really am eager to connect with him. It does sound very relevant. Some other questions? I was trying to understand the last slide. So when you do the kind of the distance coupling, it's not here. Are you so let's say in the So let's say in the penalty for the optimal transport, are you looking at the position of the ancestor and the position and this averaged position or the position of the various descendants? So this averaged position is obtained by, let's say, let's look at the cells from time T2 and let's go back. The y-axis here, this ancestry axis is time. Here, this ancestry access is time. Let's cut this tree at time t1, which is an earlier time. So they'll be adjusted to the same place. If we cut, let's say time T1 is here, then they really would be adjusted to, you know, these two cells would be the same spot. They would be averaged to the same spot. But if we cut at some time, like, let's say T1 is here, then they would be adjusted closer to each other, but not all the way. Closer to each other, but not all the way to the same spot. And so we more precisely, how this adjustment works is, say, assume that this branching, the cells that we observe here are generated by a branching Brownian motion starting from some unknown location. So then you have a normal random variable along every edge here. And then, you know, after you make this cut. You know, after you make this cut, you can come up with the posterior distribution on where all of these would be. And then, so that's the averaging. And then this second step, we then couple those new cells that we get, which just based on this second time point, that's our best guess of where they would be. To the measurements that we did make at time t1. Oh, oh, I see. So you're trying to model two different things, right? Oh, I see. So, so this step one is trying to model some this Brownian thing separately from the cell development or somehow separately from what you're trying to model with the optimal transport. Well, if we had some, I mean, we're using just Brownian motion because we have no idea about the landscape. So this Brownian motion is a. So, this Brownie emotion is kind of a null model for the development. It's saying, just given the data and no information at all about how the cells are developing, where would they have been at some earlier time point? And so, for example, if you want to say at time zero, where would they all have been, that would be the mean of the data on that time point. Just all else equal, that's the best estimate of where they would all have come from. But it's a bit so we've Maybe I'll ask you more questions in the fall. Yeah, go ahead, please. No, I'm saying maybe we'll wait for the fall to ask you questions in person. Sounds good. Okay. I don't know if there is no other question or remarks. We thank you again. So my clap for everybody. For everybody, thanks for giving the talk. The spider in the middle of moving, and I think I leave the floor to the organizer. Should they wish to say anything? I don't know if there is a... Yes, I think Brendan is here. Yeah, okay, Brendan. So we're planning at this point to have this. Open problem session. I only got one person who actually submitted or said they wanted to present an open problem, and it's Shumik. So do you want to start, or maybe somebody else has another one that they'd like to jump in with? Yeah, maybe. I don't know, okay. So I can say something, you know, it's one to two, you know. One of my things that I don't like, I don't know how to solve. So, throughout this workshop, we have heard about this approximations of entropy regularization to the actual optimal transport cost. And for Bachistein 2, there is this formula, which is that if you take the entropy regularized cost, it's the Baschistin cost plus epsilon times the sum of the two entropies. And then these entropies and then there's epsilon squared over two. Actually we don't know what happens for wp for p larger than two and in particular i'm very much interested in just just for curiosity i want to know what happens for w infinity i feel like entropy regularization for w infinity is just um just very very poorly understood but even for formulas for for p for p larger than 2 let's say w4 does it still remain epsilon the first order term does it change The first order term, does it change? Is that is the first order term even change from epsilon to some other power of epsilon? Even that sort of question says unknown and feel like it's something that should be known. So I think if people have responses or want to say something, they can just jump in. Don't be shy. I mean, I guess you can ask the same question. I mean, I guess you can ask the same question for any cost, right? Right. That's right. Yeah. So I know, for example, for all costs which are convex costs with Hesian non-zero, I mean, for other costs, yeah, certainly the order on epsilon is important, but that's probably too hard for arbitrary costs. But WP, like W4 seems to be a natural one. Why can't we do it for W4? And then W infinity seems to be the harder one. Infinity seems to be the harder one, but maybe you know, maybe it's still possible by taking some kind of limit, at least we can guess. But for w4, I don't even know what is the right order in epsilon. Like, okay, what happens there? So, isn't there an epsilon log epsilon term as well? That's right. So, there's it depends on how you state the problem. So, depending on whether you're looking into So, depending on whether you're looking into the entropic cost as cost plus epsilon entropy, or the way I write it is in terms of relative entropy by proper normalization, that takes care of the log epsilon part. But that will probably, well, I think the log term will always remain. Maybe the constant in front of the log will change. But that can be usually taken care of by redefining what is entropic cost. So, but that is also true. I mean, we don't know what is a constant sitting in front of logs. I would expect that there is a constant sitting in front of the log. We don't know what that constant is. We know it for p equals to 2. And then what is the next order term? Is it even order of epsilon? We don't know that. But this is a problem which might be solvable even from the dynamic method which. Luca and his co-authors have done in Comforti and Tamamini that maybe that can also be solved by the geometry. Yeah, I'm thinking about that. But I mean, just right now that you addressed the question, but I don't know, I mean, the case people too is really, I mean, static and dynamic are linked. Dynamic linked, I mean, in somehow in a miraculous way, I don't know if for different exponential this link. I remember I maybe I'm wrong, but there was something sorry, Luca. No, just saying that, I mean, in PQL2, I mean, everything is nice because you link the transport to the large. The transport to the large deviations and the semi-group that plays a key role in the dynamic formulation. Right, so I vaguely from maybe I'm wrong, but I think even for other values of p for p larger than two, there is still some kind of Brownian interpretation. Maybe this is in Christian Leonard's survey where you can additive functionals, right, or something of that sort might be any. Might be, I mean, um and uh if it is possible to relate this to this kind of again Brownian paths, maybe it's possible to again push well yes in that case I would I think so yes it's you are good yeah but W infinity seems to be a total mystery to me. I have no way of starting where you know how we can even start about it. Possibly, I will mention another problem, which is actually also quite important in terms of statistics, which is that we see from many of these talks that, okay, you have, if you take the entropy regularized problem, as epsilon goes to zero, it converges to the Marsh-Kantruvitz solution. But this depends on the uniqueness of the Marsh-Kantruvitz solution. If there are multiple Mon-Kanturich solutions, it would likely converge. It would likely converge to one of them, and it would likely maximize some sort of entropy among them, but we don't know how to characterize this because this is a theorem which in discrete finite dimensions is actually known. So if you just do the linear algebra problem and write down the linear algebra problem, okay, solve the entropy regularization for the linear algebra, then even, so it's always discrete entropy. So even if there are multiple solutions, Even if there are multiple solutions, among those multiple solutions, it will pick the one that has the maximum discrete entropy. Yeah, I see. Yeah, that's unique, right? Because the set of solutions is convex and this is strictly concave. Yeah. But in continuum, this doesn't quite work because differential entropy blows up as soon as any of your solutions is on a lower dimensional set. Yeah. So it's a natural question that we, I mean, it. A natural question that we, I mean, it's a tight sequence of probability measures, it will have a limit, and it's going to pick one of these things. But is there a notion of entropy by which we can characterize where it converges to? That whatever it converges to maximizes some sort of entropy? Yes, I see the point. And I mean, to the best of my knowledge, there is just one paper in the One D case by Di Marino and Louis. And Louis. But besides that, higher dimension is still an open problem, also for the quadratic case. Yeah, somehow where the marginals mu and nu are absolutely continuous with respect to Lebesgue, they some wait, let me just find the paper. Anyway, yes. Anyway, yes, they proved, I remember well, that on the singular part they somehow the entropic regularization converges to some kind of singular measure housed or let's say on concentrated on just one D. So the paper is this one. Do you know what the cost is, Yuka? Wait, it's W1. Yeah, okay. Maybe a possible approach. Bottom of page three, there is this convergence to this, let's say, this entropy restricted to. To the singular to some singular set. I see. But it's just in 1D and it's the only paper which deals with this. So they do find an S, some singular set. I wonder if it is possible to do this problem for this kind of semi-discrete setting when you are going from one finite set. Going from one finite set to a continuum, and maybe in that case, if we can even handle this problem. But this is another interesting problem for me. And it's actually, it's quite, it's also an important problem because in practice, often you don't know whether it has a unique solution or not. I had a sort of question that maybe one of you can answer regarding sort of a follow-up on. Regarding sort of a follow-up on the discussion you had about the dynamic version for this like semi-discrete case or even discrete case. Because so I was thinking, my understanding was that Shumek sort of suggested that if you have the semi-discrete case, if you maybe use as a reference measure, like the discrete measure mu as the sort of starting condition for your. As the sort of starting condition for your grounding motion or something, that gives some dynamics that maybe, but the measure that was in Luca's talk where it was the product measure of the initial and final also seemed very natural for the problem and even for the discrete problem where there's maybe not. And I think I've seen somewhere these sort of dynamics related to this kind of entropic problem on just a very discrete linear program type problem. And do you know if that if that exacts is this if that works in that case for just the linear programming problem and if that sort of generalizes to something for general measures when you have as a reference measure. Sorry, sorry if I kind of rambled a little. If I kind of rambled a little bit, but maybe someone else maybe can try to respond. Well, I don't know when both are discreet. I mean, I'm more confident, let's say, with the continuum case. Not well, I'm not an expert in this script. I don't know if it's still possible to get the Possible to get the dynamic picture or not for sure. If I mean, as in Niles, we said in the discussion after his talk, as he pointed out, yes, I think that's actually the change to reference measure and put some discrete measures, initial condition, in that case you still still may able be able to get the dynamic. be able to get the dynamic the benomo brainio formulation but if also the final one is the screen well it's should be sort of well still a sort of brownian bridge so maybe so this so this is where i would refer to the my work with zaid and lang because this is exactly what we construct because okay so because if you have two discrete sets suppose you have ten points and you have another ten points 10 points, and you have another 10 points. And imagine the Brownian motion starting from 10 points, they're going to end up in those other 10 points. There are 10 factorial possible ways that every particle go to each other. What is the probability that these 10 factorial possible ways are going to happen? One of these possibilities are going to happen. Well, it's e to the power minus one over epsilon times the total cost. Now, given that one of these permutations, one of these possibilities have to happen, what is Have to happen, what is the conditional distribution? Well, that is the basically a particular permutation has the product of the exponential of the cost divided by the sum of all the probabilities. So that solution is exactly what the Schrodinger bridge is for finitely many points. Okay, m if I i if I can just let me just share my screen and I'll just tell you what this is. Sorry. But this is the whole point of that. It actually we are not the first people to consider this. Actually, Brunier has already considered this in one of his papers. Okay. But this is what I mean. So imagine that you have, so imagine that you have Brownian particles. So, imagine that you have Brownian particles, let's say three points, and it ends up with another three points here. And so, there are three factorial possible ways that these particles can go from one to the other. So, one could be this guy, the another one could be this guy, and so on. So, there are three factorial permutations that can happen. Now, if you start from these three points, let's say x1, x2, x3, and you ask what's And you ask what's the probability that these particles end up in a particular permutation? Well, that's e to the power minus one over twice epsilon norm of xi minus y sigma i norm square, the sum. There's some normalization here, some normalization here. Then what's the probability that so you're conditioning on this thing to happen? So what is the probability of that in Of that, that you know, that this event actually happens. That means that the vector of 1 over n delta of xi lands up in 1 over n delta of yi. Well, that is the sum of all these probabilities over all permutations. Okay, I'm ignoring the normalizing constant because they will cancel out. And so, if I if I so what is the Schrodinger bridge? The Schrodinger bridge is basically about the coupling. What is the coupling? What is the probability of the coupling given that? The coupling given that one of these has to happen. And so, if you now ask what is the probability that particle xi converges to goes to particle y sigma i for some sigma in Sn well then that's the probability to the power minus twice over epsilon sum of xi minus y sigma i and then divided by the sum over all permutations and the same quantity here that's a conditional probability. That's a conditional probability. So, just for the notation on the left-hand side, you mean that for all i, right? That's right. This is for all i, given that terminal and initial and terminal. That's right, yeah. So, and this is just basic probability. Given that this has to go into that sequence of points, what's the probability that this is the thing? Well, that's this one. Well, that's this one. So, so this formula is the discrete Schrodinger bridge for finitely many points. What is actually, I want to stress here is that this is actually an expression involving what is called permanence. If some of you have seen this, this is a big topic in random matrices and so on. This is actually a formula involving permanence. What we are doing here is that we have this matrix of cost of this. Of cost of this cost. So this is C of Xi Yi. So, you know, you have this. Okay, so maybe I'm not seeing this. So what is a permanent of a matrix? This is just like determinants. If you have a matrix which is Aij, then its permanent of A is the sum over all permutations. Is the sum over all permutations the product of a i sigma i? Okay, that's the permanent of a matrix. And notice it's very close to being determinant, except it doesn't flip its sign between minus one and one. It's the sum of all of these things. And this is the permanent of the matrix of e to the power minus c, one over epsilon c. And so if you are asking like And so, if you are asking, like, okay, what is the Schrodinger bridge? If you write it in terms of measure, it's given in terms of an explicit expression in terms of the permanent of this cosmetrix C. And so it is an interesting object. But that is a finite Schrodinger bridge, explicitly. And once you do the Schrodinger bridge, then of course you connect them by Brownian bridges. Then, of course, you connect them by Brownian bridges, independent Brownian bridges. Yes, yeah, sure. But then, I mean, I agree that in this way you pass from static to dynamic, but then I don't know maybe if it's a dynamic problem, but in the sense of still entropy minimization. Right? Right, not dynamic in the Benamou-Brenier sense. It is not in the sense of entropy minimization, in the sense of Kuturi's entropy minimization. It's in the sense of Brownian bridge, Brownian motion condition to start from some given set of points. Yes. Some given set of points. Yeah, I always have in mind the Leonard's survey where he considers he always minimize entropy, but either on the path space or on the coffee. I think it's because the discrete entropy and differential entropy don't go hand in hand. It's their equivalent. But instead, if you want to pass from this minimization formula to this variational formulation to a Benam Rubrenier, like in that case, I mean at least the proof I gave with Nicola strongly relies on the semi-group associated with the Brownian. Associated with the Brownian motion. So, in this case, for this way, changing the initial measure does not change the proof since the second proof still remains the same. Conditioning both at initial and final time, I mean, at least our proof is not, I mean, does not apply, I think. So, maybe some other approach is more applied. Yeah, but this solution is different from the Kuturi solution of entropy level, so they may not be compatible. Yeah, yeah. Yeah, one of the references I was thinking of trying to compare this to was this body of work, for example, by Jan Maas and a bunch of other people where they're doing this concept on Markov chains, looking at trying to look at Markov chains as this gradient flow. To look at Markov chains as this gradient flow of entropy, and it seems quite different, I guess, from the continuous version, but somehow I don't know, like it should also be related. But unfortunately, he's not here either. Or Erbar, who's the other guy who was also referenced in one of today's talks, but unfortunately hasn't been here, I think. No, this is quite different. Yeah. I think anytime you have to go from discrete to continuous, because continuous is all local, and in discrete you have to do this kind of discretization, which is not quite local, it's integral. You have to have some change that is necessary. But yeah, but anyway, that problem about that, you know, where does the entropic regularization of solution converges, that has such a natural solution in discrete case, one would expect that it has a natural solution in continuum. But there is, yeah, this is the only one detailing that I learned today seems to be the only one. So, in the semi-discrete case, your reference measure, I guess, is like Lebesgue measure on the one side. Like Lebesgue measure on the one side and counting measure on the other side, and you take the product. Then, don't your solutions don't your solutions have finite entropy with respect to this? So then, maybe, you know what I'm saying? Yes. So, maybe this case is sort of like. So, maybe this case is sort of like the discrete case. You can that could be, yeah. Because you pair a point with like a Voronoi cell. Maybe you can. Maybe it's just like the discrete case. Maybe this one actually can be done because even the Voronoi cell has the same dimension as the ambient space, so the same differential entropy would work. Yeah, right. I think the problem is, uh, yeah, it's problem is really critical when everything is in continuum. Really critical when everything is in continuum. Yeah. Then we don't have a notion of entropy for lower-dimensional house, I mean, how to house dimensions smaller than the scale. But the conjecture, I guess, is it's the most spread out solution in some exactly. Exactly. And all we know, of course, all the solutions have to be supported on this cyclical homotron thing. So basically, it should be that measure which would spread out maximal, some kind of uniform measure, some kind of maximal measure on the set of cyclical humanoton. That's what should be the solution. All right, okay, Brendan, you had some other problem to discuss, or should we? You had something to discuss, right? I had no problems to discuss, and I didn't get any from other people. If anybody has sitting on it, they can bring it up now. Can I mention like a completely Can I mention like a completely speculative direction? Which, well, I've been interested and wonder if anyone else is kind of exactly the venue for that. Yeah, and actually, I think this is a bit related to Beatrice's talk yesterday about using entropic optal transport to generate these sort of sort of sampling, Monte Carlo sampling distributions to sample from. And I wanted to relate. Sample from. And I wanted to relate that somehow to this algorithm, which I'm not sure if people are familiar with in machine learning, of the alpha, alpha, zero, which in alpha go, which is this algorithm that DeepMind developed to have computers play Go and later generalized to chess and other board games. And it was famous for being the first algorithm to win against a professional human Go player at this game, which a lot of people. At this game, which a lot of people thought would be impossible. But basically, the algorithm, what it does is it learns this Monte Carlo sampling. And it does it by using this cross-entropy term in the loss function, which is clearly related somehow to the entropic regularization, right? And what's missing is any. what's not what's missing is any anything having to do with optimal transport i think because it's a completely discrete setting and probably there's no metric that's very important but i'm wondering if this algorithm maybe could be used in us in an optimal transport setting and if it has any uh any connection with with what uh v8g was uh working with me i don't know maybe can you say a couple of words about this algorithm or how does it maybe just How, how does it maybe just you know, two lines? Uh, okay, so so, so basically, it's a neural network and it's learning. So I'm a chess player, so I think about it in terms of chess, but you want to learn two things. You want to learn the evaluation of the position. So given a position, you want to know if one side's winning or the other side's winning or how close it is, either way. But you also want to learn a probability distribution on the moves. Probability distribution on the moves, and that's going to be used in this Monte Carlo sampling. So instead of trying to have it play the best move, you're just doing a Monte Carlo sample of all these moves based on a distribution which you're also learning in the neural network. And the way that it's learned is very clever, I think, by doing by having this loss function where usually it's just something simple, like the, there's a very Something simple, like the there's a very nice, simple paper published on this, which is a very short description of it, which is basically what I'm going off of. Maybe I'll try to find it and post it. But right, so for the value, for learning the value, you can just look at like the expectation of the squared difference from this sort of empirical value that you get by sampling a bunch of games. And for learning, but for learning the distribution, like on the moves for the Monte Carlo sampler, On the moves for the Monte Carlo sampler, you add to the loss function this cross-entropy term with the between the distribution you're trying to learn, it's like the log of the distribution you're trying to learn or something, and the Gibbs measure based on empirical this sampling of uh a bunch of positions. Positions. So, by sampling a bunch of times with these different moves, you can approximate this sort of Gibbs measure and put that into your loss function so that ideally you're learning a distribution that should approximate this Gibbs measure. So the Gibbs measure is just like e to the minus epsilon times the value of the position after the move or something. So I don't know if that makes sense. I'll try to post. I don't know if that makes sense. I'll try to post the link. Yeah, yeah, yeah. You have to forgive me. So midnight here, I had a long day. I started giving a talk at another conference at nine, and tomorrow morning I have to give another talk. So probably I'm not at the sharpest moment. But of course, if you send us a link, I'm happy to have a look. You're too popular. I don't know. This week, you know, but for sometimes it's okay, now that's enough for online talks. Like, you know, I said not when. For online talks, like, you know, I said no to a lot of things. And then now, this is the end of the term, right? And then, okay, of course, I was super happy to give you this workup. There is a conference and then the talk which I had to postpone. I said, okay, now, and then it ended up all on the same week. So I think that's also why I should go and get some sleep. But thank you so much for the discussion, all of you, for the organization. This has been really nice. Otherwise, I wouldn't have seen until that late. But really, thank you so much. Well, thank you for coming. Thank you. Well, thank you for coming. Of course, I will try to shop tomorrow. Tomorrow is a bit troublesome, but thank you so much. Yeah. And good night, everybody. And thanks for the link. I will have a look. All right. Okay. All right. Okay. Maybe we should end it here. Then, if there is no other discussion here. Right, okay. Thank you. See you in the morning, everyone, or the evening for the Europeans.