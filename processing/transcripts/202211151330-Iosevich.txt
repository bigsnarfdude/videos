But point configurations and complexity slash urged by problems in DC dimension. Okay, it's a pleasure and honor to be here. And I'm sorry that I couldn't be there in person. At the last moment, health issues got in the way, but I'm happy to be there by Zoom. And I just heard about curling and remembered my first experience with this wonderful sport, but I'll save the story for a different occasion. But I'll save the story for a different occasion. So, what I'm going to talk about today is how VC dimension and complexity in general enters in a very natural way into the study of Erdos-type problems in vector spaces over finite fields and how it serves as a sort of a motivating and organizing principle. So, first, a tiny bit of background. Ground. Okay, so we are going to consider subsets over d-dimensional vector spaces over finite fields. So FQ here is a finite field with Q elements. And we are going to define a distance set. And this is the set of the so-called distances from x to y, where x, y is an e. And here, what we mean by a distance is simply a sum of difference of squares. So So it is natural to ask in what sense is this a distance, since this is an element of a finite field. But to me, what is essential about the Euclidean distance, as far as combinatorial problems are concerned, is the fact that it's exactly that which is invariant under the action of the orthogonal group. So, this property remains in force in finite fields, and this is one of many reasons. And this is one of many reasons why this problem is natural. Okay? So there's a variety of questions one can ask. For example, in the analogy, in the analogy was the classical Erd≈ës distance problem. One can ask, given a set of a given size, how many distances can it determine? And this problem was studied by a number of people. There was a wonderful paper by Bourguen Katzenchau and by Paper by Bourguen, Katzentau, and by others, a problem in that form requires modifications because one quickly runs into arithmetic abstractions. So instead, I've been focused on a different type of a question, a related type of a question, and that is how long does E need to be to ensure, for instance, that you recover half the elements of the field in your distance set. Okay, and so for those of you who are And so, for those of you who are familiar with continuous analogs of these problems, see that this also puts it in line with the Falconer distance problem, which is a Euclidean variant of the Erdos distance problem. So this is the basic question that we ask. And Misha Rudnev and I proved in 2007 that if the size of E is bigger than a suitable constant times Q to the power of D plus 1 over 2, then in fact, One over two, then in fact, the distance set consists of all the elements in the field. Okay, and one of many topics that I will not have time to discuss in detail in this talk is the difference, you know, both practical and philosophical difference between recovering most of the elements of the field in the distance set and all of them. There's a considerable difference, but I'll leave that for a different occasion. Okay? Occasion. Okay, now, so Hartko, Rudnyov, and myself showed just a few years later that when d is odd, the exponent d plus one over two is sharp in any reasonable sense over general fields. So if q equals p squared, we constructed examples that showed that the moment you dip below q to the d plus one over two, you no longer recover a positive proportion of the distances. Proportion of the distances. So, in this sense, the exponent d plus one over two is sharp in all dimensions. Okay. And in two dimensions, right, so this is an example of even dimensions, the exponent d plus one over two, which is three halves, was improved to four thirds by Bennett, Hart, Pakyanath, and Rudnev, and myself. And myself. And if one further assumes that Q is prime, this exponent was lowered to five quarters by Murphy, Petridis, Famm, Rudnev, and Stevens a couple of years ago. What is interesting, just to mention in passing, is that the best known exponent in the Euclidean variant of this problem is also five quarters. So this is due to Guth, U Wang, and myself. Ou Wang and myself. But it appears that there's no real connection between the methods. However, it is interesting that both in the Euclidean space and in finite fields, the two problems are currently stuck at the same exponent. Okay, so this is a general overview of the underlying Erdos-Falconer distance problem. Okay, so one way, so So, one way, so one very informal way of thinking of the results above is that with respect to distances, if one considers general fields, subsets of size q to the fourth thirds are just as complex as all of fq2. That the moment we go above this threshold, we recover a positive proportion of all the distances. And even if you insist on all the distances, then if you go above a constant moment. Go above a constant multiple of q to the three-halves, one still recovers all of the distances, even for sets that are much, much smaller than the whole vector space. Okay, so what this suggests is that it might be interesting to look at more precise notion of complexity and to see what they say. Before moving in that direction, Before moving in that direction, I would like to give you a bit more of a background as to the questions that are going to arise. But let me begin by saying that one can organize our question and its variance around the following learning task. So learning task is a concept from learning theory that I'm going to say more about later in the talk. So in this learning task, In this learning task, the devil is aware of a circle of a fixed radius, pre-assigned radius, centered at a point in E and FQ2. We could formulate this question in higher dimensions, but let's focus on something that's easy to visualize. So we get to ask the devil whether a given point in E is on the circle, on the circle that the devil has in mind, and the devil has to answer truthfully. Truthfully. And the question is: how many samples do we need to take according to some reasonable strategy that would yield the right circle with a small error and high probability? So this is the game that we're going to be playing, and we are going to see that it leads to rather intriguing mathematics. All right. So a few definitions from So, a few definitions from learning theory. So, suppose that x is a set and h is a collection of functions from x to 0, 1. So, we say that h shutters a finite set c if the restriction of h to c yields every possible function from c to 0, 1. Okay, so we have functions that take values 0. That takes values zero and one. We test it on a particular sample. And shuttering means that we get every possible sequence. One way of thinking about it is that if this happens, we're not learning much about our collections of functions that take values zero and one, since we are getting every conceivable possibility. Okay, another definition from Definition that results from this is that we say that a non-negative integer n is the Vopnik-Schervonenka's dimension of H if there exists a set C of size n that can be shattered, but no subset of X of size n plus one is shattered. Okay, so this is a classical Wapnik-Chervonenka's dimension invented by Wapnik and Cherbonenka's in 1970. In 1970. Okay. So here are a few more definitions that are required to set up the learning theory perspective on the problem that I'm discussing. So given a set X, a probability distribution D, and a labeling function f that maps X to 0, 1. A labeling function is the true labeling function, the one that gives you correct label. The one that gives you correct labels. So let H be a hypothesis, namely a function from 0 to 1 that we hope is correct. And we'll define the error in the most straightforward possible way. It's a probability according to the distribution D that h of x differs from f of x. Okay, so this is the hypothesis here. And a notion that took me quite That took me quite a while to get used to is the notion of PAC learnability. So, this is probably approximately correct. To a mathematician, I think that initially this sounds a bit weird, but it's a very interesting notion. So, a hypothesis class is PAC learnable if there exists a function that maps 0, 1 cross 0, 1 into natural numbers. And the learning algorithm was the following property. Was the following property for every epsilon delta in 0, 1, for every probability distribution D, and for every labeling function from x to 0, 1. If the realizability assumption holds, which means that in our collection of possible classifiers H, there is a correct one. It's not an incredibly realistic assumption, but this is not the point that I want to make today. I want to make today. So, if the reliability assumption holds with respect to x, d, and f, then when running the learning algorithm on more than m h samples, so these are identically distributed examples generated by d and labeled by f, the algorithm returns a hypothesis h such that with probability of at least one minus delta, the error is less than or equal to. The error is less than or equal to epsilon. So, this is a notion of PAC learnability, which, roughly speaking, in anything resembling practical situations, is the best we can hope for. Okay? And so the following theorem is a quantitative version of the fundamental theorem of statistical learning, and it provides a connection between the VC dimension, which The VC dimension, which is really what we'll be talking about in conjunction with Erdos problems and learnability, probably approximately correct learnability. And the theorem is the following. So H is a collection of hypotheses on a set X. Then H has a finite VC dimension if and only if H is PAC learnable. Okay? So they. Okay, so the idea is that if you can shatter a set of examples, you're not learning anything about your collection. So it is pretty clear that you're not going to solve the learning task if the VC dimension is infinite. The really brilliant part of the Bopnik-Cherbonenkis idea is that if the VC dimension is finite, then you can complete the learning task. And moreover, they have. And moreover, they have a quantitative bound on the number of samples you need to take. And if you look at the formulas, the formulas make sense. Of course, the smaller epsilon is, the smaller error you want, the larger you need to take your samples. The larger the Wapnik-Schravoneck's dimension is, the larger you need to take your samples. And the closer to probability one you want to be, namely taking delta to Namely, taking delta to be smaller and smaller, the larger you must take your samples. Okay, so this is a thoroughly logical statement. Why the numbers work out in exactly this way takes a little bit of work, which we're not going to go into right now. But this is the statement linking VC dimension and learnability. Okay, so how does VC dimension? So, how does VC dimension apply to point configurations? So, we're going to take a subset of FQD and an indicator function of a sphere of radius T centered at some point Y in E. So what this does is give us a collection of functions that take on values zero or one. Hence, the notion of V C dimension applies. In a fairly simple calculation, Fairly simple calculation shows that the VC dimension of it says Rd, it should say FQD is equal to D plus one, though the answer is the same in Rd. Okay, it's not difficult to show that A, that D plus one points can be shattered, and more than D plus one points cannot be shattered simply because D plus one points determine a sphere in D dimensions. In D-dimensions. And the question we want to ask, and this is sort of harkens back to the notion of complexity mentioned earlier in the talk, is that can we take a subset of FQD that is much, much smaller than FQD, but large enough, so that the VC dimension is still equal to D plus one, which is similar conceptually to the idea that if you take a set larger. Idea that if you take a set large enough, it still recovers all the distances or at least positive proportion of the distances. And here, an interesting question is, what does that mean and when can you do it? And this is fairly recent joint work with Fitzpatrick, McDonald, and Wyman. That if E is a subset of FQ2, the two-dimensional vector space over the field was Q bigger than two elements, two is not. Elements. 2 is not a prime. I don't care what people say. Such that the size of E is bigger than a constant, a sufficiently large constant times Q to the power of 15 eighths. The only thing I want you to notice about 15 eighths is that it's less than 2. Then the VC dimension of Ht2 of E is still equal to 3. So the VC dimension of the classifiers, which are indicator functions of circles of a Indicator functions of circles of a fixed radius centered at points of E is still equal to 3, which is the same answer as the whole space. And what this says once again, in some sense, that finding a circle in a set of size bigger than constant q to the 15 eighth is just as difficult as finding one in the whole space. So let me go ahead and point out. Go ahead and point out what this means. So, what it means is that in a set of size bigger than Q to the power of 15 eighths, we can find the following construction. So x1, x2, and x3 are the points that need to be shattered. Okay, and to produce a sequence 1, 1, 1, we have y123, which is a distance. 1, 2, 3, which is a distance 1 from each of them, right? To produce a sequence 1, 1, 0, we have a point y12, which is a distance 1 from x1, distance 1 from x2, but is not distance 1 from x3, and so on. So the point is, is that this configuration is far more sophisticated than anything that has been established. That anything that has been established previously. Let me say this more precisely. Okay, so suppose that we consider a distance graph where the vertices are points in E and the two vertices are connected by an edge if the distance between them is T. Okay, so then the question becomes: is that given a connected finite graph G, can it be embedded in the distance graph? Okay? Graph. Okay? And let me just do a very quick illustration of complications. Suppose we consider a field so that the square root of three is not in there. Then by using fairly elementary Gauis theory, Bennett Pakyanathan and I showed that Fq2 over such a field does not contain any equilateral triangles. So any attempt to resolve a problem of this type runs A problem of this type runs into, I think, very interesting algebraic issues. So, K3 does not embed even in the distance graph over FQ2. Okay? And this leads to an interesting question of what is known about embeddings of general graphs in the distance graph corresponding to a given subset of FQ2 or FQD in general. Or FQD in general. Let me just mention one general result for context. So this is joint work with Hans Perschall, where we showed that if you take a graph with maximum multiplicity m, and so graph on n vertices, and if the size of e is bigger than 12n squared, q to the d minus 1 over 2 plus m, okay, then g can be embedded into the distance graph. Be embedded into the distance graph. Okay? The point of this result, so this is a general result, and it does cover lots of interesting situations. But the point is, is that if we look again at the picture that needs to be produced, at the configuration that needs to be produced to solve the VC dimension problem that I mentioned, this configuration. This configuration is far more complicated. So, the idea here is that the notion of a VC dimension serves as a guide as to what the most complicated configurations are or what the most complicated graphs are that can reasonably embedded in the distance graph. Okay? So, let me, in a few minutes that remain, That remain. If I take another three minutes, is this okay? Absolutely, yes. Okay. So the key object that needs to be constructed is a rhombus, because if you look back over here, this involves several rhombi, but in particular, you need to construct one. And what is the basic idea? So, by a result that Rudnev and I proved in 2008. Proved in 2008, we know that the number of pairs separated by a fixed distance is the size of e squared over q, a statistically correct estimate, plus an error which becomes very small when the size of e is bigger than q to the three halves. So what we do is we fix the direction and we look at the number of pairs pointing in the same direction. Pointing in the same direction. And we deduce that the number of pairs of a fixed distance pointing in the same direction is at least constant q to the three halves, as long as the size of E is bigger than constant q to the seven quarters. And now we applied the result with Rudnev again and see, so what you should be visualizing is a bunch of parallel segments. But since this number But since this number exceeds our threshold once more, it is guaranteed that that set once again recovers all the distances and allows us to produce a rhombus. Because as I said, you should visualize a bunch of parallel segments, and we take the endpoints of these segments all pointing in the same direction. And since every distance is realized among the vertices of these segments, Of these segments, in particular, it allows us to recover the rhombus, okay? Which is the key calculation needed to produce this. So just a quick comment about open problems. The key open problem, in my view, is showing that this result can be established in higher dimensions, namely that there is a non-trivial threshold beyond which the Beyond which the BC dimension of the set of classifiers, which are indicator functions of spheres centered at the points of E, is equal to D plus one. Okay? And a number of related results have recently been obtained working with McDonald and Soon and also with SUMS REU in Williams College. And so there's And so there's a considerable amount of work going on in this direction. And one of my goals for this talk is to get more people interested in, I think, this particularly, this potentially very fruitful area. And I'm going to stop here. Other questions for Alex? Yes, Tally. Okay. Can you hear me? I can hear you. Two questions for you. Maybe if you go to the last 18, especially since it's a higher dimension, right? Yeah. How about foul error analysis methods? How about Fourier analysis methods here? Are they going to be useful? I'm sorry, I couldn't hear you. How is what? Fourier methods. Absolutely. So absolutely Fourier methods are useful. Just as a quick remark, one of the key tools that I mentioned is this result with Rugniff that tells you how many pairs are separated by distance t. This is done by This is done by reducing this problem via Fourier analysis to bounds on the Fourier transform of the indicator function of the sphere, which quickly reduces to bounds on Kluster-Mann sums. So Fourier analysis is one of the key components to work on these types of problems. It is not by itself enough. As you saw in the study, Saw in the steps where Rumbai were produced, it has to be combined with a suitable combinatorial setup. However, Fourier analysis is one of the key tools. And the second question is, you have two exponents. One is, I remember, 15 eighths. And somewhere in your further illustration, there was seven quarters, right? And now. Yeah, and now there's a gap here. There's a gap. What happened between the two? Right. So the old, how do I put this? Most of the mathematical substance of the method is in the rhombus argument. However, in order to go from one rhombus to three rhombi, to put everything together, there are a couple of iterative pigeonholes. Couple of iterative pigeonholing steps, which forced us to go from seven quarters to 15-8. I'm a firm believer in honesty and advertisement, so I absolutely cannot promise you that that 15-8 is actually meaningful and is not simply a product of my stupidity. However, the method as it currently stands required us to worsen the exponent a bit in order to be able to pigeonhole. In order to be able to pigeonhole things well enough to go from a single rhombus to three rhombi. I have a quick question. You said that if a finite field doesn't have a square root of three, then FQ square doesn't have a, it doesn't have an equilateral triangle. Is that an if and only if? Is that an if and only if? Is this an only? Is this an only? Yes, I believe so. I'm 99% certain, and I'm running through a proof in my head. Yes, it is. Yes, it is, because if the square root of three can be constructed, that means that one should be able to construct the equilateral triangle by following a wasp prescription in the same way as in R2. I will write this down today just to be 100%. Down today, just to be 100% sure, but I'm 99% sure. Yeah. Other questions for Alex? Yep, there's one more question from Teddy again. Sure. On your slides, okay, this is usually troublesome in finite fields, but you have excluded few parts of two. I have a what? Sorry? Q is not two, you avoided that. You know, avoid it. Yeah, I avoid two because when the exponent is two, everything that I do seems to fail. In other words, Klustermann's sum bounds are different. Boolean rings come in and create all sorts of other counterexamples. In other words, I did not check specifically that this problem doesn't work out. Don't work out. But I tend not to work with that case because it's well, first of all, it's not the point. These really are sort of asymptotic analogs of Euclidean results. But I think that it would be interesting to check. I can certainly do that. I guess we're out of time. So let's thank Alex one more time. That motion is going to be very important.