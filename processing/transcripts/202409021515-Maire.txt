For organizing an amazing workshop. Thanks for as well to Tamra and Judika for amazing talks. And also thanks to Judika for setting up pretty much the scene to my talk. So today's talk is about joint work with Max Hurt from UCL. And I'm going to talk about this occlusion process as a tool to sort of As a tool to sort of reduce the variance of MCMC estimator. So the outline is to sort of start with a very brief recap on stratify sampling. So I'm pretty sure most of you know about it, but there's basically this interesting result that shows that if you do it correctly, you can reduce the variance of Monte Carlo estimator. And it's basically going to be the target of my talk to extend this to from Monte Carlo to MCMC. So this general idea. So, this general idea. And to do so, I'm going to use a tool that's been around in the literature, but not quite obviously, which kind of deals with a generalization of rejection sampling. So, I find this idea pretty cool, and I'd like to give some details about it. And then I'm going to define the process, give some illustrations, and see how it can help to reduce the variance of MCMC. And then I'm going to discuss, if I have time, about some 30. If I have time about some theoretical properties of our process. All right, so these are the definitions I'm going to use throughout the talks. And so we're basically considering a posterior distribution pi and a class of function, which I denote calligraphical f. And I want to sort of like estimate expectation of f of all those f here with respect to pi. And for all those functions, f, I already know. Those functions f, I already know that I have a CLT for the Monte Carlo estimator whenever I can have IID draws from pi. And here is the asymptotic variance that I'm going to use as a precision criterion for our estimator. So typically for Monte Carlo, it's just the variance of f under pi. And that's basically the setup here. And so what stratified sampling does, so it's come from like Also, it's come from like survey literature. Essentially, it's sort of considered a partition of the sample space. So, here you see I have R regions. This form a partition of X. And I'm going to consider a collection, like multiple collections of random variables, which I call YJT, each of which is a conditional, has a conditional distribution of pi given the region you're in. So, a lot of time, especially in So, a lot of times, especially in the MCMC sort of framework, we think of like conditional as like dimension-wise, but here, like, I just want to make clear that it's the conditional given a particular region of the state space. So I'm just restricted pi to whatever subset here. And basically, just writing the expectation as the conditional expectation, I can just show that, you know, if I want to estimate this expectation, I can also estimate, you know, our expectation. Estimates our expectations here, but now there are conditional expectations here. So I can just replace this by any unbiased estimator. So if I call nj the number of conditional draws from each partition, and then I can get straightforward an unbiased estimator. And provided that this and j are linearly linear, increase linearly with the total sample size, I can get a CLT as well. And now you see that this. As well. And now you see that this asymptotic variance is replaced by Monte Carlo, is now this stratified asymptotic variance, which is a weighted average basically of the conditional variance. So this is what we have. And there's a particularly interesting case, which is called proportional location, which makes things a little bit easier. If I take those particles for each, let's say, conditional distributions proportional to the mass of each region, then Of each region, then we have what we call proportional location design. And in this case, I can write the asymptotic variance as exactly actually the expectation of the conditional variance. And from this, I'm just one step away from showing that this is less than the Monte Carlo variance just by recognizing that using the law of total variance basically. So I know that this is not the optimal way to do this. There are better ways to do this, but. If there are better ways to do this, but for now, I'm just considering proportional location as kind of a target point. I know I can reduce the variance of Monte Carlo estimator by doing this sort of strategy. But obviously, we don't know the probabilities of each region and also therefore we cannot set up the number of particles for each region. And obviously, to do this sort of This sort of proportional location, certified sampling, I need to get IID draws from pi j. So I call pi j the conditional given xj. So in the rest of the talk, I'm going to assume that I don't have either, and I'm going to try to sort of generalize this kind of inequality, but for MCMC. So then the second sort of bit of introduction or material that's needed to understand what we're doing is what can be seen as rejection, generalized rejection. Rejection generalized rejection sampling. And here I'm going to assume that I have a distribution q, which can be seen as a proxy of pi. So q could be, could be, it could actually be anything between like normalizing flow in the variational inference like outcome, anything that can be used to approximate pi. And in a way, I'm asking two things about Q is that. things about Q is that I can sample quite easily from Q and that it dominates pi um so that's so you can see maybe Q kind of like as pi lambda a pi was lambda I think from Dudeka's talk so the Morio Cida approximation except in her case I think we can't sample easily she needed a Markov chain to do the sampling business but I'm gonna assume that I can get IID draws from Q here but the same idea that you have Here. But the same idea that you have a way to sort of tweak the problem and make something maybe easier to sample from, that's going to be helpful. And like in the Decast talk, I'm going to call W the sort of weight function, which is just technically the radon nicotine derivative between pi and q. And I'm going to call c star the supremum of this weight function, which could be infinity. And as you know, rejection sampling works as follows. So I sample y from q and then example, y from q and then uniform random variable independently. And then I have this kind of like acceptance test. And if it passes, if this event realizes, then I define x as y. Otherwise, I come back here at step one. And then doing this thing, I know that the law of x is like marginally is pi. And obviously, as you know, it can be very inefficient to. Inefficient to this scheme to produce draws from pi, and first of all, you need to start up with knowing C star. And even if you know it, it's still one over C star. And I guess a lot of our work was started from the fact that we realized that, you know, C star is by no means a sort of like meaningful representation of the closeness between two distributions. It's just you could have, you know, Q approximating pi pretty much very well everywhere, pretty much everywhere, but some pathology happened somewhere in this. Some pathology happened somewhere in the States, and then you get something that's very high for C, but that's not reflecting what you should expect from Q. So the idea was brought up kind of like in Tierney's paper 1994 and in other papers that I mentioned later, is to replace basically C star by any arbitrary constant positive and do the exact same thing as we did for rejection sampling except using now C instead of C star. Using now C instead of C star. And you can show very easily, like just a few, it's basically following the same proof of the rejection sampling algorithm that what you get is actually, depending on C can be not too bad. So you have some elements of like continuation between the distribution of X in this case, which I call pi hat C because it depends on C and the one from the rejection sampling, which was pi. Maybe it's easier to go down. Maybe it's easier to go down here, and we see that essentially as c increases and goes up to c star, this minimum here is always one over c and does not depend on x. And same here. So I retrieve pi, but whenever c is less than c start, and I'm not quite there. But interestingly, for all the sets a such that like the weight are less than c, we can see this by the way, as kind of like if c is like Kind of like if C is like one or something relatively small, this can be seen as such where Q and PI tends to agree. Then in this case, regardless of A, you have that pi hat C of A is proportional to pi A. So for all those set, you have this proportionality relationship that can be leveraged by simply imposing a second condition in your rejection sampling. And sampling test. So you have the same condition here. And here you have this second condition that you want in addition y to be to be in x c, so this set here. If it's not in the set and if it does pass this set, you still reject it. Call y11 whenever it satisfied both tests. And then you can show very easily that basically all those sets that were not in this set here, then they are now mapped. Then they are now mass zero because you've excluded them here. And you end up with a very nice draw from the conditional distribution, which we were interested in in the first place with stratified sampling. So essentially, we can get draws from conditional, from pi given some subsets, whenever the sum sets are sort of like levels of the weight functions. And you can do this for multiple, you can define multiple what we could see as strata, like. We could see as strata as like levels. So, if you define not one constant but multiple of them, let's say r minus one, you could define like a set of like different levels. So, this will be probably the easiest set where q and pi are close, very close to each other, and so on and so forth. And basically, you can draw by the exact same idea any draw from pi given x, any of these levels by using the same idea that I just said before. So you just Said before. So you just do a draw y given q uniform, and then these two tests need to be passed simultaneously, and then you end up with a draw from pi k. Obviously, what we can see here is that the sort of like complexity of this algorithm can be like sort of summarized by the probability of having one accepted draw from pi k, and this is easily calculated. And this is easily calculated. You get something like this: so, the mass of the sort of level of difficulty, if you want, and over a constant. So, for lower constants, and if you basically Q and pi agree where pi has most of its mass, then you expect this to be large and the constant to be relatively small. So, for at least those like lower levels of the partition, then you can sort of hope that rejection sampling is. Sort of hope that rejection sampling is going to be quite useful. But when you go up the energy sort of or the level ladder, then this is probably more difficult and you're going to struggle to get draws from this. So just as an illustration, I'm not going to do anything here. I'm just going to summarize this idea of sort of partitioning the state space according to the weight function. If you take this distribution, so mixture of two distributions here, which is technically, I think, in Which is technically, I think, in so my colors are not probably the same as you see them, but that's that line here with that look normal here, but then there's sort of pathology here around 2.5. And if I take Q as like, this is actually the variational approximation of pi, then basically I can draw the weight function here in blue, and I will define two constants one and 10. So whatever is under, whenever x is such. Whenever x is such that the weight function is less than one, I call this x1, x2, and x3. So I get three energy sort of levels. And the difficulty, the tricky part is obviously what's going to happen here because q and pi don't match. All right, so I'm going to define now the occluded process. I'm going to start with basic starting up basically where Dudika left off her talk with like MCMC-related notation. MCMC related notation and setup basically. So I'm going to consider here any sort of Markov MCMC kernel P, which I'm going to take pi invariant. So think of it of MALA, HMC, both if there are options, or Metropolis or anything. I'm just considering any pi invariant Markov kernel here. I'm going to consider that for this kernel here, it was initially designed. Here. It was initially designed so that I have a CLT for all the functions in F. So, again, I'm just taking this as an assumption. I can find kernels such that I have a CLT for all f in F. And now the CLT aesthetic variance here, again, we find by usual, we can find this sort of expression in the literature quite easily. You have the Monte Carlo variance up front here. Variance up front here, and then you have this term here, which oftentimes, like most of the time, is greater than one. Typically, this autocorrelation series tends to be positive. It's the case if the kernel P is positive in some sense. And it's also possible that this is less, this is negative for antithetic chains, but I'm not going to consider this. I'm going to just assume that the chain is well defined, but it is positive. Is well defined, but it is positive because it's the one that is the kind of chain that I'm gonna be interested to reduce designative variance from. But it works in all generality. So, and this is the way we can think of sort of boosting this pi-in variant Markov chain XT using this idea of rejection sampling, using those strata based on the levels of the Radal-Nicode derivative. Derivative. So you have here the Markov chain that's just transitioning according to P, and you have here your MCMC estimator, and you could essentially just decide to swap or consider replacing XT minus 1 here by a fresh draw of pi, but given the region where in which XT minus 1 is in. And you can do this for all the steps, right? I'm not saying that it's what we will do eventually, but you can. It's what we will do eventually, but you can think of it as a naive sort of idea where you replace all the xt by corresponding draws from the correct conditional distribution. And it's pretty easy to see that if the chain is in stationary T regime, then you will not add any bias by doing this sort of strategy here, because essentially the mass of each partition is unbiased. So you're going to get that marginally, each YT is going to be distributed. Going to be distributed with pi. But the interesting thing is that on events such that e here, where I stick to one particular region, so whenever the chain wanders in one particular region for a certain number of steps, then actually the correlation, the covariance of the sum of f in these tree is just, there's no correlation just by the correlation structure. The yt are conditionally independent. The YT are conditionally independent given the region. But now, if you think of your chain being positive, then this is always going to be less than this quantity because all those terms in the sum here are just positive numbers. And this is simply the covariance of the MCMC sum. So maybe by doing this, I'm not saying anything in general, in whole generality, but I'm just saying that for if you condition an event where the chains stay in one particular region, In one particular region, you have this kind of correlation reduction here. So, maybe that's just an intuition. Problem: we have two types of problems. The first one is that YT as it stands is not a Markov chain, so I cannot rely on the powerful tools that we have from the Markov chain theory to get error bands and asymptotic results on this kind of estimator. The second problem is that this is actually not straightforward to get. I just did it here, like I thought. I just did it here, like effort looking effortlessly, but it's not. You will need to pay a price, especially when you are in those regions where you have very high energy, where Q does not approximate pi well, then this is going to be very large. It could, in fact, be infinity. You might have those regions that are just impossible to sample from, so you cannot form the estimator here on the second line. All right, so we want to do, and that's how that's why we introduced the occluded process. The occluded process. It's basically to not increase the original computation cost of the original chain and make it in a way so that we can use basically we can inherit the good behavior of XC for our occluded process. I'm probably very late in time, so you'll need to give me a heads up in terms of how long I have left. You have about eight minutes. Okay, right. So I'm going to try to define my process and then I'm going to leave details for questions or further talks. But basically, so, okay, related works, there's been some elements that share some resemblance with our basically our process. I'm going to skip this, but I'm very I'm going to skip this, but I'm very happy to answer questions because if you know this query, for instance, the KitCAC process, then you might think it's related. It's kind of different, but I'll leave this for possible questions. And similarly, this idea of correcting an MCMC sampler that targets a different distribution by importance weight. And actually, I should have put Goudek's work here because I think it falls in this sort of category. But basically, how does the occluded process work? You are just going to occlude some of those states. So, in the naive idea, I said you are going to occlude all the states. So, all the states are going to be replaced by the YT. But in this case, to achieve my goals, I'm just going to define probabilities. So, R probabilities, so between zero and one. And what I'm going to do is that given the region Rt that XT is in, draw a Bernoulli-Renault. Is in, draw a Bernoulli random variable and only occlude Xt upon the event st equals one. So I'm just going to replace yt whenever st equals one. And if st equals zero, I'm just going to leave the chain, the original chain. I'm not going to replace the state. So here you see maybe this is a nice way to visualize it. This is four regions here, and just the first four steps of the Markov chain. So x1, x2, x3, x4. And these are draws. And these are draws from the conditional regions. So each in its regions. And basically, I'm going to assume here that S1 and S3 are zero. So the final sort of occluded process is going to be X1 because S1 was zero. And now I've replaced X2 here by Y2. I've kept X3 and I've replaced X4 by Y4 here. So this is the occluded process. I don't put any arrows because it would be misleading. It would be misleading. It's more like an HMM hidden Markov model sort of structure. But yeah. And this idea is basically that you only need to draw the YTs whenever ST is equal to 1. So that's the main idea. So if it's too difficult, if you're in an area that's too difficult, some perform, probably you can get away just by not occluding. And this is how we define the probabilities. We define them in the The probabilities we define them in a way by construction, they are defined in a way such that we can use at least one extra thread in parallel computing to make the occlusion process free of additional complexity. So, this is basically just paraphrasing the previous slide where you have the MCNC estimators that runs here, the main markup chain here, and then the regions that those X's are in. X's are n, and then the occlusion process where you replace only whenever s is equal to 1. So, one idea we use multiple ideas, obviously, but to summarize, to briefly outline the main idea is that whenever you want to sample from a Bernoulli, you just need an unbiased estimate of the Bernoulli. So that's one key idea. And to sample actually the couple like S T Y T, we are only going to use rejection. We are only gonna use rejection sampling. And in particular, we're gonna restrict rejection sampling to this kind of state space whenever you don't try to, if you don't, essentially, if you don't succeed to produce a YT from the correct conditional, then you just put any arbitrary number. It's not going to be used in the estimator here, so I just put zero. And that's how we define the occluded process. So you attempt to produce a draw from the Attempts to produce a draw from the conditional. If you fail, you fail, and then the chain is going to be, the occluded process is not, the process is not going to be occluded. And whenever you succeed, typically in those regions where Q and pi match well, then you're going to replace your state X by the corresponding Y. So maybe for the sake of, yeah, I can just illustrate this. I'll have another illustration, but I'm just going to stick to. Illustration, but I'm just going to stick to this one. In dimension one, in my illustration earlier, mixture of two Gaussian. Obviously, those experiments have like the exact same complexity. This is the main random metropolis on the top line. And then here I have the occluded process, which achieved about 0.9 occlusion, of probability of occlusion to about 0.9. So I occludes pretty much all like almost all. Includes pretty much almost all the time. But interestingly, when you go from dimension one to 10, using this, extending the target to whatever arbitrary D dimensions, you can do a lot of interesting increase in terms of reducing the correlation. So I had another example for the easing models that was obviously more interesting, but I'm going to skip this for sake of time. In terms of theoretical results, I think. Of theoretical results, I think. Um, I just want to highlight that basically you can't work with the occlude process itself because it's not a Markov chain. But if you look, you can sort of consider the whole HMM structure that is actually Markov and that has a proper invariant measure. So you can just look at your occluded process estimator as an MCMC estimator, but the MCMC, the Markov chain is on an extended space. And there's a nice set of And there's a nice set of results here that we were able to get that's basically showing that our extended state space inherits good properties of XT. So basically we're able to get that our estimator, which is not an MCMC estimator, sort of obey to SCLT. And obviously the big questions is to guess situations when we actually do reduce the synthetic variance of MCT. Variance of MCMC, which is not guaranteed. We actually have a counter-example in which it's not the case whenever P is not positive. Yeah, I'm going to skip those sort of technical details, but we're able to get relationships between the occluded process aesthetic variance and the MCMC aesthetic variance. And essentially, we would like to choose the partition NQ such that the sort of The sort of resolution, which is this object that we define, that sort of measure the conditional mean given any x is not too, does not vary too much. So whenever this does not vary too much, then you have something that is negative given the chain is positive, and you show that you can reduce the variance. So it's more like a tool to sort of define the regions and maybe the kind of Q that you like. And maybe the kind of queue that you would like to use. Sorry, the talk was really, it was very difficult to keep track of the time. Sorry about this. I'm basically done in terms of the results. I'm sort of trying to summarize the relationship between all the asymptotic variances here that I've defined in the talk. And our big question is to compare those two guys here, which we know that without any further assumptions, there is no domination. But basically, we've created an estimator that does not add any additional complexity to any MCMC estimator, and that's as I've explained in this one example, which is the variance. Yeah, but the general question is open as for this question. So that's it for me. Sorry for the talk. It was a little bit difficult to keep track of time, like I said. So I'm happy to get some questions. Thank you very much. Questions. Thank you very much. Let's thank. Don't worry about the time. You're perfect. Perfect. Okay. Sorry, I can't hear anything. Okay, is this? Can I hear? Oh, yeah, perfect. I can hear it. Yeah. Perfect. Thanks again for the talk. So I mentioned this to Max at his poster at ISBA. And now I think from the talk, it sort of compels the same question. Is there a way to view your proposed methodology as like a smart thinning of the original Markov chain? Thinning, like spacing between, like. Spacing between like thinning as in spacing in between states, right? Yeah, so obviously not fixed time thinning, but you know how like there's like now kernel thinning and other random time thinning. So on the augmented space, you have a full Markov chain, and then you're basically taking instances when one of those components has a favorable binary draw, right? Yeah. And so it might be a form of pinning which might get you to some way to analyze the variances, but Some way to analyze the variances potentially. So, yeah, I can just maybe. Okay, where is my okay? Just trying to find my slide on this computer. Okay, I can't seem to find my slides again on this. Anyway, I'm gonna address your question. So basically, we do have like thinning, that's kind of random time thinning, because the Markup chain does do jumps. But in between those jumps, you fill in with a lot of like conditionally independent samples, if that makes sense. Samples, if that makes sense. So essentially, you have like a bunch of independent samples conditioning in the region. So I'm not sure if you can fully consider this, for instance, the occupied process as a thin Markov chain because you enrich it with a lot of conditional independent draws. So yeah. Thank you. Yeah. I think we have time for maybe one quick question. I just wonder, so like your algorithm for multi-mode targets, you think like it would perform especially well? So basically for you we're only asking the question of like can we and can we enhance Of, like, can we and can we enhance any given MCMC sampler? Um, so if you're if you have an initial MCMC sampler that's not um able to get modes, then maybe you can actually you will actually you won't actually be able to visit those different regions. So if you think of like, yeah, any, any, any MCMC that's if it has two modes, and if the main markup chain is just getting stuck in one mode, then our thing is not going to help you. But what is going to help you is that. You but what is going to help you is that whenever you kind of design MCMC that are able to like search different modes, it could be the case that in order to achieve this, you need to have a large proposal variance, for instance, in which case you get stuck in one mode for you know potentially long time. And what our thing is doing is that basically once you're stuck in one mode, then you can use the sort of occlusion, you will have a lot of occlusion if your Q is sort of a reasonable approximation to pi in that. A reasonable approximation to pie in that one mode. So it can sort of, yeah, you can see this as it's not going to solve the problem, but you can tune, you can now tune your sort of main MCMC to, you know, be sort of focusing on exploration and be kind of aggressive in that sense, because you will not, you might not suffer from the high intercorrelation thanks to the occlusion, basically. I don't know if it makes sense. Thanks. Okay, so thank you very much. Thank you, Florio and again. Thank you, everyone. Thank you everyone.