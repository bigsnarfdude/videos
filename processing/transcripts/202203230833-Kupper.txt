The first speaker, Michael Coupa, he's a professor for stochastics and financial mathematics and chair of the group with the same name at the University of Constance. We look forward to your talk, Michael. Okay, thanks a lot and thanks to all the organizers for giving me the opportunity to present our research here. Okay, I will speak on Wasserstein perturbation of Markovian semi-groups and I will. Semi-groups, and I would like to mention that this is joint work with Daniel Bartel, with Stefan Eckstein, with Wayne Vohmann, and with Max Nandel. Okay, so my plan is to give a short introduction and motivation to uncertainty, and then basically I present the results, how we perturb some Hamarkov processes. And I would like to conclude with some relation to parametric uncertainty and examples. Okay. Examples. Okay. So I think that model uncertainty is everywhere and extremely important. And it might appear, for instance, if there is insufficient data to perform reliable statistical estimation methods. For instance, if we do not have enough data. Or certain aspects of a model cannot be determined. For instance, that we don't know whether some increments are independent, something like this. Dependent, something like this. Okay, so in a dynamic framework, this leads then to the modeling of stochastic processes under model uncertainty. And there, the very famous examples are the perturbations of the Brownian motion. So, basically, you can include drift and volatility uncertainty, which is mainly done by Shige Peng, or non-linear Levy processes. There, I would like to mention Ariel and Ariel and Marcel. And recently, there was also a lot of work in the direction of non-linear Markov processes. For instance, in particular, in this research group of imprecise probabilities, they study a lot these imprecise Markov chains, for example the Kuman et al. And more from a semi-group perspective, there's this work of Max Nandel. This work of Max Nandel and Michel Reichnov. Okay. Now, the focus of this presentation is distributional uncertainty, and I would like to start with this classical stochastic optimization problem, where basically an agent is maximizing his or her expected loss. Okay, so this is exactly this one. So this is the expected loss. And the expected loss is controlled by an action. Is controlled by an action set. He or she can choose a control to minimize this expected loss. And yeah, if the distribution is known, then this is the optimization problem. And under distributional uncertainty, this leads to the following problem, which was studied a lot recently by, in particular, by Fluk, by Svani Kuk. Of a flug by Svani Kuhn, but also would like to mention and discuss a little bit this nice work of Daniel, Samuel, Jan and Johannes. Okay, so basically now the task is the following. We no longer minimize the expected loss, but now we have uncertainty and the agent is minimizing now this upper expectation. Okay, and the distribution is not fully known. And what is done there is basically one takes into account all probability of all distributions which are close to the reference one. Okay, so basically there one maximizes over a Wasserstein ball of distributions and the level of uncertainty here is modeled via this radius. Okay, so the larger somehow this Okay, so the larger somehow this delta, the more uncertain you are taking into account. And then what you can do is, of course, you can compare now the generic problem and its robust version. And this has mainly been done in this paper here. And I would shortly discuss this one because it's related. So Daniel, Samuel, Jan, and Johannes actually studied the first order sensitivity. The first-order sensitivity of this problem, where basically you compare somehow here on the right-hand side the expectation and on the left-hand side the upper expectation as a function of the uncertainty. Okay, and the uncertainty is modeled in terms of this delta. And what they show, I mean, here I ignore somehow the optimization over A, but what they show is that this derivative or the first. This derivative for the first order sensitivity analysis, this gives somehow the LQ norm of the first derivative of F if F is regular enough. So you have a very precise description of uncertainty in this context. And what we are doing is something related. So what we are basically doing is really something related, but we are not perturbed. We are not perturbing an expectation, but rather a Markov process. Okay, so this is what we started in these two papers. So we start with the Markov process and then we take into account distributional uncertainty of the transition probabilities. Okay. And in the end, you can analyze related sensitivity results as in this cited work. Did a work. Okay, so in this first paper, this is together with Daniel Bartel and Stefan Eckstein. We basically studied the IID case. Okay, so this is more or less the Levy case. And then recently with Sven Forman and with Max Nandel, we extended this to more general dynamics and also to infinite dimensional state spaces. Okay, so let me start now with the Markov. With the Markov process, and more or less, the state space can be infinite-dimensional. And then we consider a reference Markov process. And this Markov process for our analysis needs the following particular form. Okay, so what we assume is that the Markov process set, which starts in X at time zero, has this RDD form. Where basically you have a deterministic path, this psi t of x, which depends on the initial starting point. And in addition, you have a random part, and this random part is independent of x. Okay, so this might look a bit restrictive, but at least it includes interesting dynamics. I will discuss immediately. Okay, so this is the structure that it needs. This is the structure that is needed in principle to construct the semi-group. We can also consider more general structures. However, on the level of the generator, we need somehow this additive decomposition. Now we assume that this is a Markov process, so basically the Chapman Kolmogorov equation should be satisfied, or equivalently we can describe now the distribution in terms of the transition semigroup. Of the transition semi-group. And the transition semi-group, this is defined as follows. So this is the expectation of f of a set. So this describes the distribution by testing here with enough test function. And here we work with uniformly continuous and bounded functions. And in infinite dimension, we somehow have to take a closure of some Lipschitz functions, which at least includes all. Which at least includes all weekly continuous functions. Okay. So in that case, the transition semigroup of the Markov processes is given as this convolution, or it's almost a convolution. I mean, it's somehow generalized convolution because we have here this psi t. And yeah, and this is the starting point. Okay, so this describes somehow our reference Markov process. Reference Markov process. And just to give some examples, for instance, in this class, we could consider the deterministics where basically the y is zero. And if the y is zero, then the process is simply given by this psi t of x and psi is of zero and O D. And this leads exactly then the corresponding R is a Mansemic group. Another example is the additive case. So, this was the paper by what we did with Daniel and with Stefan. There basically you have additive increments. So, this is the case of independent increments. This leads to Leby processes. What also works is if we interpret somehow this plus here as a multiplication. As a multiplication, then we can also allow somehow multiplicative structures such as geometric Barnian motions. So we have something of this form where y is a stochastic exponential or Ernstein-Ulenbeck processes. So these are the typical, so these are somehow the typical reference processes we are starting with. Excuse me, Michel? Yes. I also want to tell the audience you can interrupt at any moment to ask questions. Can interrupt at any moment to ask questions, of course. What is the underlying assumption on your process Y in your general framework? What does process Y have to satisfy? Okay, we assume basically that Z satisfies the Chapman-Kolmogorov equation. So in the end, it depends. I mean, for example, in the Warning-Motion case, this is normally distributed over there. This is normally distributed or whatever. I mean, the assumption in the end is that the sum satisfies Chapman-Kolm-Grauff or equivalently that R is a transition semigroup. Okay, and then this gives some conditions. This gives some condition on the psi and the y. Okay, so in combination, you have to be a semi-group. Okay, thanks. Okay, now we start with this Markov process. And what we want to do now is, I mean, these are somehow the To do now is, I mean, these are somehow the transition probabilities or the increments here are given by this Î¼. And what we do now, we robustify or we take into account all distributions which are close to this mu t. And this is done with transporter Wasserstein distance. So what we are basically considering is the P-Wasserstein distance, WP, between two distributions, mu and mu. mu and mu and then basically we start with this uh with with with this reference transitional semigroup and include now uncertainty okay so the but the mu t is now taken in this uh wasstein ball and what is very important here for this this analysis is that the uncertainty is proportional the uncertainty here this is the radius delta this is proportional Radius delta, this is proportional to the time interval. Okay, so the more we are looking into the future, the higher the uncertainty is we are considering, and it is proportional. One could also consider a different type of scalings, but in these papers we studied really this disproportional case. Also, one can more generally, I mean, more generally, one can also. I mean, more generally, one can also consider the convex case. So, this is somehow the coherent case in red, and here now in blue. This is the convex case, where basically we take into account all transition probabilities, but they are penalized. So they are penalized according to this penalty function, how far they are away from this reference measure mu t. And again, this penalty function, this penalty function has. Function, this penalty function has to satisfy a certain scaling property, and the scaling property is chosen such that the convex conjugate is again proportional to t. Okay. And in addition, we need that the penalty function increases fast enough. Okay. Now you can basically do the same as in this paper. In this paper, what I cited before. So we have somehow this expectation or this convolution here. And we have here the perturbed version. And what can be done now is to analyze what is the difference between the reference one and between the Wasserstein perturbed transition. So considering the difference between R and I. And this is very similar to what Daniel. Is very similar to what Daniel and the authors did. And the nice thing is here, we have here an expectation, and here is also an expectation. And what we see, if we take the difference between the two, then in particular, if f is Lipschitz, then this difference can be estimated with the Lipschitz norm of F times the Wasserstein distance between Î¼ and Î¼. And this leads immediately to related sensitivity. Related sensitivity estimates. Okay, so for instance, if F is a Lipschitz, then basically the Petroped version and the reference one in L infinity norm satisfies this bound if H is small. And even better if F is differentiable. So if F is differentiable, then the Wasserstein bitterb transition. transition I minus this reference one divided by h. So you take this differential quotient for h to zero. This again converges to the convex conjugate of the penalty function and then the norm of the fresh derivative of f. Okay. So this gives again something like first order sensitivity results. Okay. Now, very important. I mean, the R, this is the transition, this is the transition semigroup of the reference process. And this is a semigroup. This is a semigroup. So basically, we have the time consistency that R evaluated at T plus S is the same as Rt applied on Rs. Okay, so we have the semiconductor. On the other hand, in general, we cannot expect. In general, we cannot expect. I mean, in general, we cannot expect that for the perturbed version, we have the semi-group property, and it's even wrong. But what is extremely nice, and this was observed by Daniel, that we have not the time consistency, but we have this weak form of time consistency, what is sometimes called rejections consistency. Okay, so this basically means if you are doing two. This basically means if you are doing two steps, then you become smaller. And this is extremely important. I mean, this is extremely important for the construction now of this Wasserstein semi-group. Because what we do, we do not have a semi-group a priori, we only have this inequality, but now we can do some kind of a Chernov approximation, and in the limit, we obtain. limit we obtain or we get a semi-group. And this is done as follows. So we fix time t and then we are on this time interval between 0 and t and then basically we split this in 2 to the n intervals of length t times 2 to the minus n and then instead of doing one And then instead of doing one step from 0 to t, applying once this it, we simply apply 2 to the n times this one step transition i 2 to the minus n. So this should be illustrated here in this picture that we iterate basically these one step transitions. Okay, so this is simply very similar as constructing somehow A time-consistent dynamic risk measure where you do also take the composition of this one-step risk measure. So this is exactly the same. Okay. Now what is nice is because you have this inequality, because you have this inequality, it follows that the more step you are doing or the finer you take this this this partition, the the the smaller is this value. The smaller is this value. Okay, so this basically means that this composition here as a function of n is decreasing. So this is decreasing and therefore we can point wise, we can immediately write down this limit here. And this is very in the spirit of a general approximation of an exponential where you approximate. An exponential where you approximate somehow an abstract semigroup with something simple. So, this is exactly this Chernoff type approximation. And what is the difficult part here is to show that in the end this limit satisfies the semiconductor property. But here it works, and here it is very important that we use this Wasserstein perturbation because this gives it the Because this gives it the needed tightness. And from there, we observe that these functionals are continuous from above. This is exactly what is needed in the end to construct the semigroup. And then we have the following result. So this limit, I call this now the Wassensteiner semigroup, where we do the time partition final and final and pass to the limit. So this has. So these S forms the semiconductor of convex monotone operators from UCB to UCB. And also it's possible to show that this semigroup is strongly continuous. Okay, so this basically means that the trajectories are continuous. Here, sometimes it's in the norm, but in general, this is only in the strict topology. So this basically means. Topology. So, this basically means that for the convergences, we take something which is bounded and converges uniformly on compacts. What is nice, and this comes directly from the construction, and this is very important to analyze the properties for the limiting object, is that this Wasserstein semi-group by construction is smaller than this one-step. This one-step Wasserstein perturbed transition. And it is dominated from below by the reference transition. And more or less, we are explicit. I mean, for the R and for the I, we have explicit expressions. And from there, we can get everything also for the limit object for this S. Okay. And what is And what is probably the interesting result here is what is the generator. Okay, we have now a semigroup, and this semi-group is determined or the behavior of this semigroup is specified if we analyze what is the local behavior. And the local behavior is the generator, so this is the time derivative at time zero. And now suppose that B is the generator of the reference. Is the generator of the reference semigroup? So, for instance, we could consider a Brownian motion. In that case, the B would be the one-half second derivative or one-half the Laplacian. Okay. And then we do this perturbation and end up this Wasserstein semigroup. And now we can ask what is the generator of this limiting object. And the nice thing is we get exactly the generator of the The generator of the reference Markov process. And then we have this first-order correction term here. And the first order correction term is the V star. So this is the penalty function or the convex conjugate of the penalty function applied on the norm of the derivative of f. Okay, so we get only first derivative order terms if we use this proportional. This proportional scaling, what we did. Okay, so this is the result, and this works basically for this class of Markov processes. And yeah, now in the last minute. Can I ask you, is this both, is it true for both the coherent and convex case, or is it so? So what happens in the, as you call it, coherent case where you don't have the penalty, but you just have the radius of balls the same? If you have something, if you have the, in that case, you basically have the penalty function, which is zero and jumps to plus infinity. And in that case, you get an additive term of A, which is the radius times this norm. times this norm. Okay, so you have something which is, yeah, you can also see what happens in the coherent. Okay, thank you. What is probably interesting is that this behavior, this local behavior is very similar to what we know when we have simply only a drift, when we have simply only a parametric drift. Simply only a parametric drift uncertainty. Okay, and this is illustrated here. So the I, this is, okay, we start somehow with this reference one. We start with this reference one. And in the I, we really take into account all transition probabilities, really all transition probabilities nu which are close to the mu t. While here in the parametric case, in the parametric case, we only consider Case we only consider shifts. Okay, we take the transition probability and we shift it either to the left or to the right in the one-dimensional case. And what comes out? What comes out? I mean, basically for both this one, for both these families I and J, you can do this Chernov type approximation. I mean, I did it for the Wasserstein semigroup, but you can basically also do this one for this. one for this uh for this uh for where you have parametric drift uncertainty and by the way this is called the nisiosemigroup and what what comes out is that by construction is that the semi-group where you have a drift parametric drift uncertainty is up really always smaller where you have more uncertainty okay where you have this non-parametric distributional uncertainty but then since Then, since both these semi-groups have the same local behavior, so both they have the same generator, it follows in the end that the two are the same. Okay, and here I would like to mention our recent paper where basically we have some comparison, some muraro general comparison result for convex monotonous semi-groups. Okay, so this basically means in the end you collapse somehow to pure Collapse somehow to pure parametric drift uncertainty, which is maybe interesting. And here is an example which I skip and I would like to discuss maybe, I would like maybe to finish with this one. So if we consider a finite dimensional case, B is the Laplacian, this corresponds to the Brownian motion case, and we consider here a penalty term of x squared. term of x square to the divided by 2 then it follows mainly i mean this was our main inequality we always have that the s is the is the waserstein semigroup and the i is this one step wastein perturbed transition then basically in that case it follows that the s is nothing but this entropic risk measure while the i is While the I is this perturbation here, and from there you immediately see that this is a dual form of this colourborn T2. Okay, so basically these inequalities also leads somehow to simple form of color goal inequalities. And with this one, I would like to stop. Thanks a lot. Thanks really a lot for giving me the opportunity. For giving me the opportunity to speak here. And here are the papers. So, this is a nice paper of Daniel et Dahl. And the presentation was mainly based on these two. Okay, thanks. Thank you very much, Mikael. A very beautiful talk. We have time for a couple of short questions, please. You get other interesting inequalities if you consider, I mean, you took Brownian motion and the specific penalty function, but I presume you've tried other phi. Do you get other interesting equalities, possibly? Yeah, probably, probably, but I think all of them are known. I mean, the nice thing here is that for the entropy. Here is that for the entropy, I mean, you have it really explicit, otherwise, you get something like the conjugate of a g-expectation, and then from there, inequalities. I mean, this can be done, but I think we have not worked too much in this direction. My other question was: is the fact that S equals T, I mean, to a degree, this is of course maybe disappointing, but is this because the log? Because locally, the worst case measure will be, we can essentially, up to the first order, it's just a shift in the sort of worst direction. Is this what's happening? Yes, yes. This is exactly the intuition behind it. I mean, in the limit, you can see that, I mean, this is the intuition. And formally, you can compute the generator, and the two generators are the same, and then you rely either on. either on comparison with viscosity arguments or you use our results. Okay, thank you very much. I think it's time to proceed. So thank you Michael again. Thanks and bye.