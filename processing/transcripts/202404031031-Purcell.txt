Hello, from the kinds of things that Yo I was talking about on Tuesday morning. And the question is: this: Is not equivalence MP hard? Right, so unknot recognition, testing whether, so the input here, the input is two knot diagrams. Oh goodness, I'm in front of a bunch of knot theorists and I can't draw a figure eight. It seems to be embarrassing. It seems to be an embarrassing point of my career. So I give you two NUT diagrams, and I'm asking you up to test whether they're the same off. These are given as combinatorial diagrams. So if you see crossings, you're just listing which crossings are next to each other crossings. That's all the information you need. And what you want to show is this decision problem, which we know has an answer, is at least as hard as anything that is anti-complete. And there's like hundreds of problems you can. And there's like hundreds of problems you can choose from to start with, right? So, what you want to do here is take your favorite MP-complete problem, like 3SAP, like Hamiltonian circuit, like traveling salesperson, like whatever it is, and show how to solve that problem using an oracle that can answer this question here about recognition. Using a number of polynomial conversion into knots and a polynomial number of queries to the cycle. So, not unrecognizable. Suicide. So, not recognition, sorry, but general numbered equivalence. The other thing I will add is that you need it to be general numbered equivalence, because as John pointed out, if you're trying to recognize the unlock, so if you're trying to recognize whether a given diagram is simply a loop, then there's a lot of good hints that this is not going to be NP-hard. So, in particular, it's known to be NP, it's known to be in co-NP, which means if you trust computer science's gut feeling as a Gut feeling as a discipline is probably not NP heart. So you are going to need to use the generality of having access to all the knots that are available to you. That's it, that's the problem. I don't know if there's any questions. I'm halfway through the countdown and maybe I can just step down early if there's any guesses. So unknot recognition is presumably the not NPR. Unknot recognition is presumably not NPR. Do you think there is a possibility there is some not type where it is NPR? Where it is empty hard. I mean, let me say, my gut says yes. My gut says this, the general problem should be NP-hard. And my gut says, I mean, my gut says yes, that there should be some knot for which testing equivalents to that knot is NP-hard. But I somehow feel like this should be an easier problem to prove. But I can't prove it. Okay. Great. Thank you, Ben. Jesse, can I just ask, are someone writing these products now? I thought scribbles in them? Okay, now that one got erased and we don't have anymore. Yeah. We'll try to put them in the report. There will be a report. Right, that sounds great. Okay, that's great. Yoah, great. Right, thank you. So, okay, I'm just going to mention a couple of big, famous ones, but not too big. I'm definitely not going to write S4 recognition anymore. So, one question in complexity is complexity of the homeomorphism problem. For three manifolds. Oh, let's just write D equals three. So there is a paper that you can look at by Kuberg. So it's not surprising that the homeomorphism problem has a solution in light of geometrization. The geometric pieces are canonical. You need to compare them. You have massive rigidity that helps. You have most of rigidity that helps you when you, and you have sell as an isomorphism algorithm. If you want to compare hyperbolic pieces, you need to worry that you glue them correctly after. Cooperberg's algorithm, he wrote down this algorithm, which I think some people at least suspected before that. And the analysis of the complexity that he does, he says that it's primitive recursive. So, primitive recursive is allowed to be a tower of exponential, but not an unbounded tower of exponential. And I think he has a tower of like seven exponentials in there. Like seven exponentials in there. So it's very slow. There is a lower bound, which is due to Lacanby. Lacanby showed that it's at least as hard as graph isomorphism. If you're given two graphs, you can construct manifolds that these two will be homeomorphic if there is some isomorphism between the graphs. The problem is that graph isomorphism is not so hard. Babai proved that it has a quasi-polynomial time algorithm for that. There may even be faster. That there may even be faster algorithms. I don't know what people think about that, but it's certainly not expected to be empty hard. So, that's I think that's a very, very big one. And another question is complexity of unknotting. And so we know that unnoticed is certainly expected to be a lot easier than this, I think. So we know that it is in NP intersect co-NP, which Which means if it is NP hard, then all hell will break loose. But that does not mean that it necessarily has to be P. We expect there are complexity classes which are in this intersection that are not polynomial. If it is polynomial, by the way, there are complexity classes within polynomial too. So you can ask about that. But and so that's That one, that's kind of a big one. I don't know if it will help for this at all. I want to show you a picture. So, one thing that we proved is hard is, let's see if it gets, if it starts fast enough, if it starts early. So, we proved that deciding whether an anode diagram is An anal algebra can be sorry, can be untangled with exactly n not and sorry n crossing and rhythmized remove changes. That is hard. And the reason I mention it, that's the picture of the knot. That's the picture of the knot. So, and the reason that I'm mentioning it is there is a recent paper by, I don't know the peak, by Tanzar and a couple of Know the peak by Tanser and a couple of his collaborators, which is interesting for analyzing this kind of complexity. What they said is: let's look at, ask whether we can, they didn't ask about the number of Rydermis remove needed, but the excess number of Rydermis removed needed. If you have 100 crossings, you are going to need at least 50 Rydermeister moves. Because you can't get rid of more than two crossings. And so they looked at the defect, what they called, which is the excess, and what they showed. Access and what they showed about the defect is that this problem now it's this is NP-hard and it will forever be NP-hard, but it's fixed parameter tractable, which means if you fix the defect, then it's polynomial. And so anyway, you can look at their papers, but that I really want to mention that a fairly recent paper because I think it might be helpful for some algorithms. Sorry, my computer has to sleep on. Okay. Oh. Okay, here it's all time. Okay, two problems were mentioned. One is link isotopy, whether it's NP-hard. Another is three minifutoniomotors, whether it's NP-hard. Of course, they are related through or Of course, they are related through Gordon-Lucke theorem, which doesn't mean that one necessarily implies the other. One more related problem is you have two, three magnitudes, and given vectoring conditions, is their volume the same. And again, this is related to three, to link ISO to be able to homeomorphism. So easier, and these are two. So is there, and these are two, three main photos hyperbolic, is there hyperbolic volume this year? So how hard is that? And of course, once you have homeomorphism, then you can figure that out. But is it maybe easier than homeomorphism problem? And of course, Snepy will give you up to certain decimal rate, but then I guess how do you know the exact number? And maybe Nathan can see more about that, no? But basically, About that? No? But basically, how hard is it? So, how hard is it? How hard is it? Is it easier than street homeomorphism? That I wonder about it. I have no idea. Um Well, another interesting one is kind of going into the complexity spirit, how hard it is to say that the link is alternating. You know, you're just given any diagram, so you're given a link diagram. And there is an upper bound known. How hard is it to determine if it's a medium, if it's If it's on one agent, so Josh Colby and Green's work actually provides an algorithm for that, but is there a polynomial algorithm? Is there a polynomial algorithm? Or this may be this is a behavior, who knows? And then something that popped up yesterday was a notch in number, right? Was a notching number, right? So Jill announced our work on a notching number, and that was about lower bound. And previously, this Kenyan would also prove lower bound for unlinking numbers, splitting numbers. So this is a decision question given not or link is its notching number, linking number. Linking number, splitting number, equal to n, all less or equals to n, etc. So we now know lower bounds, but what about upper bound? In particular, for notching. So is so lower bounds known, awkward, unward. So lower bounds now known, due to our word, but what about upper bounds? Lower complexity. Lower complexity buttons, I mean, lower complexity, not lower bounds, unmotion number as remotely, lower complexity buttons, but is unmotioning number computable? Is splitting number computable? Is unlinking number computable? Is the problem does this link has unlotted number n decidable? The only work known is by Luckily, which for certain links says that is splitting number Is splitting number equal to one is a decidable question for certain weeks. And that's as far as we've got so far, right, as a community. Okay, so all these questions wait for people to solve them. All right. So the question I'd like to suggest is: suppose we pick a model for random knots. We'll be a separate question for each problem. So, random closed. Problem, so random closed break, break diagram, the kind of thing we're going to hear about on Thursday. And then the question is: with respect to this model, is the cipher genus of the knot, twice the cipher genus of the knot, equal to the degree of the Alexander polynomial of the knot? Generically, so I'm going to say asymptotically almost surely. Almost surely. Take a very, very large random knot. Can we actually compute the cipher genus just from the Alexander model? And the theorem for any knot, randomly generated or otherwise, is that you have this inevitable. And a standard way to show the cipher genus for a particular example is if you compute the Alexander polynomial and you find a surface of the right genus and you see You find a surface of the right genus, and you see this isn't evolved. And we know that, in general, the problem of computing the genus for a naught in the three-sphere, this is an NP intercept co-NP. And so it may, in fact, be a polynomial time algorithm to compute the genus. It's an interesting question if it is. But one possible reason, or one possible thing you might expect in this situation, is that. might expect in this situation is that at least generically the question should be easy. And that's what cis is saying is that this were almost always true that generically we can find the genus by just looking at the L's. That's all I know. Okay, good timing everyone. So now for something completely different. Now, for something completely different. If I had it in a eraser, I won't start here until you're ready. Well, that's good. But I don't think I'm going to talk for many long. All right. You have to start. Oh, I see. Okay. So the question is, what is the probability? That a random linear embedding M4, and I'll tell you what that is in a second, has OBS4. Okay, and we'll remind you of that too. Remind you of that too. Okay, so this is the question. So, in general, Mn is, this is as an abstract graph, is just a graph with 2N vertices. However many, well, that's not very many, 2N vertices, where opposite vertices, here let's put another one, where opposite vertices are connected by edges. Okay, so this is M3 because it has three. 3 because it has three of these things. Okay, so we can make it into M4. And so then Mobius form of, say, M4 is that it looks like this. Okay, so this is related to the stuff I was talking about with proteins, that every known protein that contains M3 or M4, it's in modus form. It's in Mogus form. And so we determined that if you look at M3, then the probability that a random linear embedding of M3 has Mobius form is like 98 point something or other percent. But M3 is much easier than M4 because M3 is the same as K33. And also we have these results of M3 that say that, well, not. Uh, well, well, not quite. I won't say that. But in any case, it's I think M3 is easier than M4. So the question is for M4, what's this probability? And then, of course, if you solve this for M4, the question would be for Mn in general. So, yes, Abby. A random linear embedding. So that means that you're putting a uniform random. Putting a uniform random distribution of, oh, this is in a cube. I left out that in a cube, sorry. So you're putting endpoints in a cube and then connecting them in this way, in some way. So what we were doing when we were doing it for M3 is we were putting endpoints randomly in a cube, and then you get Kn. Okay, and in our case, we were looking at K6, so you could do the same thing. Could do the same thing. And then look at how many M3s there are in that M6, in that K6. So then once you get the probability of the linear embedding of the points, then you can do that to deduce the probability of the M6 in there. Okay, but anyway, so one key thing in Mobius form, I mean a simpler thing than whether it's in Mobius form, is whether or not it contains a knot. not. So, and you remember we were doing when we were doing it, no one remembers because it was my child. We were looking at whether it's not less as one condition, whether it's paneled as another condition. Yeah. But M4 is paneled as an drawn. No, no. This one is panel, but this is the abstract one. So you can. That Mobius 4 is panel. Yes. Yes. Okay. Yes. Okay, but in general it isn't if you look at embeddings. Okay? I have one minute left, so I'm done. All right. Okay, this is going to be pretty short. I have to be very careful about open problems like you have because. About open problems I give out because I'm going to have nine students that are working with me this summer, and I have to have a lot of things for them to do. But what I have not said that they should do, which is for this audience, of course, is number one, random not to be a very important thing. And I think this is interesting for a variety of reasons, but you know, you want to be able to take notoids and create random diagrams and then ask questions like what are the expected values for various invariants, et cetera. And why might you want to do that? Well, you might want to compare that. Well, you might want to compare that to the natoids that appear in proteins and then say, gee, are you really getting sort of a random distribution of the kinds of natoids you see among proteins compared to what you see if you just randomly generate them? And then you have to ask the question, of course, what is your model for randomly generating natoids? It does turn out that natoids can be drawn in a braid form. So, you know, it maybe looks something like that. And so you could use braids potentially, but I think there's a lot of other options as well. There's a lot of other options as well. So that's one topic. The other topic is: you're not going to be surprised by this either: random state knots. And so state knots, so I take my random projection. I realized when I was teaching knot theory not too long ago that whenever I draw a random knot, it's always the same random knot. But anyway, so here's a projection, and then you're just going to say, okay, I'm putting, you know, stakes in here, here, and here. And then what happens when you do that? And here, and then what happens when you do that? Is if you're randomly staking projections, you can decide whether your projections that you're staking are minimal crossing projections or not. It doesn't, you know, it's fine if it's not a minimal crossing projection, and then you want to see what are the properties of those random stake points. That's it. All right, okay. So, a problem I like is. Like is to take your favorite group, finitely generated. So think, for instance, the pi one of the figure eight, not the complement. Oops. Not going to embarrass myself trying to throw a knot in front of you. So, and then you ask the simple question. The first question that I already don't know the answer to is I define Sn. I define Sn gamma, which is just the number of subgroups of index n out of in gamma. So just how does this mostly, I mean, the thing I mostly find interesting is how does this grow when n increases? There's a whole, I mean, there's a, there's a really, so this goes under the name of subgroup growth, usually. Under the name of subgroup growth, usually there's a really nice book by Lobotsky and Siegel, if anyone is interested, called Subgroup Growth, where they talk about such questions. So for instance, if this were a surface group, we know this very well. But anything three-manifold, like anything hyperbolic, we don't know how to do this. Why is this interesting? Because from hyperbolic. Because uh from hyperbolic geometry point of view uh random subgroups correspond to random covers, right? So if you can count this you can say something about random cover of the end of uh of your of the figure eight, not complement or really any hyperbolic manifold. So how do you usually approach this? This was already sort of, for instance in Ben's talk, this was sort of mentioned. This is equal to To the number of permutation representations of your group on Sn so that the action on the numbers 1 up to n is transitive. And that's not really, I mean it's not equal because there's some redundancy in this. You divide by n minus 1 factorial. The basic idea is just the action on cosets gives you a permutation representation, and given a permutation. And give it a permutation, transitive permutation representation, you can take the stabilizer of one, so that gives you a unique insight. Well, if you look, stare at it for a second, you see that this is n minus one factorial to one correspondence. So this turns this question really into a question-solving equation that is metric, right? Because what is a permutation representation? It's just images for the generators that satisfy the relate. So if it's a figure eight-naught complement, it's a reasonably short relation. It's a reasonably short relation, it's in two generators. So you're just asking how many solutions to this equation do I have in Sn? How does this grow? And then, so suppose you can say, suppose you can solve this, there's lots of questions I would like to know the answer to. So for instance, so the first one is, for instance, if I know this, do I know the hyperbolic volume? So if I know this sequence, can I tell you what the hyperbolic volume is? This relates to other. This relates to other questions about hyperbolic volume. For instance, because this, okay, so this is one one, there's another question out there that is, is the hyperbolic volume of, is that a pro-finite invariant? If I know all the finite quotients, do I know the hyperbolic volume? If you can do this, then the answer is yes, because this depends only on the finite quotients of the group. And then, well, then there's lots of other questions. So, for instance, now I take a random cover. Now I take a random cover, does this converge to H3? So the technical term is Benjamin Schroud convergence. This is somewhat reasonable convergence to X3. This is what happens in. So Benjamin E. Schramp convergence morally means. Which morally means that if I if I take my random cover, I put myself at a random point with respect to the finite volume measure on the cover, and I look around and at most points it's supposed to look like a hole in the hypermultiplayer. So that's what Benjamin-Schramp convergence is. And then, well, you can ask all sorts of questions, right? You can ask for the geometric invariance, like what's the spectral graph, what is the length spectrum like. I think that would all be very nice to know. Thank you. Very nice to know. Thank you. Okay. I'm just gonna have a random problem that popped into my head when I was volunteered by Jessica. So, okay, so we have the let's take a note. People already mentioned the Jones polynomial. There is more than that. So I want to talk about the Gallo-Jones polymorph. So this is a sequence. Okay? How do I wanna say it? Okay, I'm going to say JKN, I'm going to call it that, a sequence of polynomials parameterized by integers. They are, think of them as Laurent polynomials in a variable. So you have a maximum degree in your variable. I call it like that. And this could be something like not at all like that, but let's say it is also that. Safe to this position. And this is the minimum. Alright. B D, C C. This is small C, this is big C. And so I'm going to take this panel. So So this time dn is going to be d plus minus d minus. And the question was that K is alternating if you know about the picture. We can know that there is We can only get there is C, an integer C, an integer C, such that you computed this T N and you found it to be C N squared plus 2 minus 3 N plus 2 or rather minus 2. Sorry. Okay, we're and then C and then Then C, and then C is the crossing number of K. Okay, where does this come from? One direction, so K, this direction is true. The other direction is motivated by a conjecture about these things that says that they predict surfaces and not complements, and by the work of very simple. By the work of the recent characterization of alternating notes that we had from Josh Howey and Josh Green. Okay, so these are not just random numbers. In fact, they're not numbers. These are not polynomials. These are quasi-polynomials. But in the end of the day, we can think of this as giving you slopes of incompressible surfaces in the North Coast. Surfaces in the north continent, bound slopes. And then these terms here give you the topology. So, for this direction, there is the so-called slopes conjecture that is by Berlidis and then enhanced by myself and Tan. And so then this conjecture. This conjecture implies that if you computed these degrees and you got this, then there are surfaces SS star such that satisfying well, I don't want to even say that this conjecture if you want to ask me. If you're going to ask me, plus characterization of alternating notes. This characterization comes in terms of surfaces, so your nodes alternating if and only if you have two spanning surfaces that satisfy an integration. And this gives you Gives you that the node is alternating. So this gives you that K is alternating. That is the bit of evidence slash motivation. Now, I'm not even stating correctly, but when I have stated this problem, so if you really want to see it properly, it's in a prosthetics paper at the math. At the math 46 minutes before, but I was covered by the problem anyway, that's very good. We actually do have plenty of time because people are taking less than five minutes. So, if you need to go ahead The five minutes. So, if you need to go over, well, we'll yell at you a little bit, and then you can go into this was also kind of unprepared. Um, so I hope you can say something a bit clear. Um Say something a bit queer. So we're interested in circle packings. So if we're given a graph in the torus so for Venko and Springborn show, there exists a unique up to scaling Circle packing, which we can as an assignment of radii to each vertex. And given this assignment, there's a unique Euclidean structure on T2 that allows you to talk to fill it in. So this So the edges would correspond to, sorry, this must be a triangulation. So the edges correspond to points of time DC. So there's a very nice uniqueness in existence results. But so we are interested in what happens if we cut. If we cut the graph, the surface along a path, a simple path through the graph, and that's it. So now there's going to be freedom. The graph might look something like this. So this part here is repeated. So now I don't know if there's any. So now I don't know if there's any, there's probably no uniqueness results. So I think we can show some sort of existence. So if we assign some radii to these points, maybe under some conditions you can fill in the rest. And so the general question we're interested in is how much does changing the values on the boundary affect the values inside? Uses inside. Ideally, we're hoping that if you change by some amount here, the effects on the inside is like exponentially small. But I can say a bit about the moderation. You study volume densities of links or patterns. So we've shown So, this is if you just take the volume of a hyperbolic link, you divide by the number of crossings. So, Dylan doesn't show that this is always less than V opt, the V off the heat gun. And then Stefan Burton showed that this is dense in this verbal. In this interval. Then you can consider the subclass of hyperbolic links, considering where k is a fully augmented link, say in S3. And you can show this is this lies in this range. And we finally show it's discrete in a certain part here, up to 2p ought, and then it stands here. So then now we would want to consider fluid elemental links in torus, and torus. And you can show that it's something else in this range by Abbott's work. But the question is how whether or not it stands. And we're sort of following an idea where you take some link, two of these links. Some link two of these links, and you try to construct a somehow say, so files have called serial circuit packing. So from a file you can produce some graph, and if you find the right circuit packing for it, you get the volume of the function. So somehow, if you take the diagram you get from K and L, and if you repeat them enough times and maybe connect them, hopefully Can calculate them hopefully because if you make many copies, the stuff on the boundary doesn't affect the inside, and the volumes can't stay the same. So you can combine them, get all sorts of weighted features, so you get that speed. Anyway, so we'll back. Okay, I feel obligated to write this question down first. I'm going to think about random knot models. And so, well, link models. And so. And so the first question, which I feel like I have to ask, is: which of these are the same? And presumably, basically none of them. Or who did I talk to, Neil? Did you explain this to me at dinner the other night? Why two of the ones that I didn't think were the same were the same? Something like that. Presumably we know when they're the same and when they're not. You know, Peluma is definitely not GRID and so on. SAP is not ERP. We know this. However, for all practical purposes, However, for all practical purposes, like if I want to calculate something and it's easier in one model than another, can I reliably use the distribution from the other model to study my model? Or which ones are basically, generically whatever mark you want, the same? Or for some invariants, are they the same? So is the distribution of cipher genus about the same? About the same for, I don't know, grid and penalima. It's not. But maybe there's another pair of models for which it is. You know, maybe these guys. Which of their invariants behave kind of in a similar fashion. Okay. What was my next question? Oh, yes. Oh, yes. So, related to this, which models are best for calculating which invariance? And this isn't about a distribution, excuse me, the answer here, the goal isn't to understand that this model calculates genus better than that model. The goal here is if I have a not and I want to calculate genus, what model do I pick to calculate it? What model do I pick to calculate it most effectively? And I'm sure many people in this room already have strong ideas about when it's easier to calculate certain invariants from others. And I mentioned genus because I was just thinking about it. So I think for grid, genus is often polynomial time if you use the right algorithm. Often. And that's a very big word. I don't know what the real answer is. For braids, For braids, it's similar, I think. I'm going to put a big question on that one because I haven't studied that algorithm much. But how do the two compare? Which one is actually faster in practice? If I need to calculate something, which model should I pick? Because it's not that expensive to convert knots between models. But that's a follow-up question. Just from a practical point of view, if I want to calculate something, if I want to calculate the distribution of something for braids, would it be cheaper to convert braids to a different model first before I do it? And this is not really, I guess, a complexity question in the sense of which ones are P and which ones are NP or anything like that. It's a question of: is it n squared or n to the fifth? n squared or n to the fifth, I might care very deeply if I want to generate 10,000 knots for each size from 1 to 100. Okay, last question, which is a different kind of question. On all these models, if I grab a knot or grab a link and start changing crossings, what impact does it have on the distributions of the different variants or different properties? Marina, you kind of mentioned this one, or I guess hinted at this. This one, or I guess hinted at this, in a sense, when you were looking at your diagrams and asking about the distribution of the casting-locker invariance for a given diagram. So, I guess that's a related question. But if I pick a diagram and I change a crossing, what's the probability it will actually change different invariance? Like a skiing relation kind of idea? Yeah, sort of like a skiing relation kind of idea. I'm not thinking skiing relations in the sense, because when I think skin relation, I think something completely predictable. But yes, how far off is, I don't know, the grid diagram from satisfying some schemulation for genus. You know, ride, that can answer that question, but genus, yeah. That question, but genus puts you out. So, can I have one more? And my last one is a very general question, which I guess is more of a philosophical question. We've all been drawing knots mostly in teaching. Mostly in two-dimensional space. We've talked about a lot of diagrams. Some of the models we've talked about have been different because there was some sort of 3D interpretation involved. So are any of these models the right models to use for studying knots? And I guess, Erica, this is a question for you. If you pick an actual situation, like a biological situation where knots appear, what knot models or what mechanisms should you be using to study people there? Using to study people there. So I guess this question is kind of inspired by that, but it's also more philosophical. If I want to think about knots in the abstract, what's the right way to think about them? Are we being two-dimensional when we're doing this? Is there a better three-dimensional way to say knots? I guess I'll say it. Are any of these models actually 3D enough to understand them? Enough to understand them. A few years ago, John Conway was advocating a three-dimensional model that seemed angles. Yeah. And I guess this goes a little bit to Colin's discussion of what was it, stake knots and notchoids. You know, stake knots are very clearly three-dimensional in the way in which notchoids aren't. But again, there's a strong correspondence. Okay. Strong corresponds. Okay, well, if anybody figures out in a five minute. L is just the mean and R of L is the rope length of L. The rope length means if you tie your link with a rope of unit readings, the minimum length of the rope you need to tie. Need to tie into. So here is an open question. Actually, it's more like a conjecture. It says there exists a universal constant, okay, such that The log length of error is greater or equal to this constant times the crossing number of your error. And if every URL error is output clearly stated. So that concept should work for all Should work for all authentic links. What do we know about it? It is true if the number of components in your link is one. In other words, if it's an outlined knot. And that's about it. Okay, so if so the question is now what if the number of components is Component is bigger than one. Well, you don't know, but I've been working on this problem for many years, and my gut feeling is it is still true and have some limited evidence. For example, I know it's true if error is the two-breach. If it's two-breach, it has two components. It has two components, and for that one, it's two. Well, I think there's a chance we can send this to the serum links. If it's there, ultimately, maybe this cable is work out. I haven't worked out the details yet, but in general, it's your question. Thank you. So PN is a random polygon of lengths n N, and you want to think of this maybe as equilateral. And so it is known that the probability that this Pn is not goes to 1 as basically n goes to infinity, and that happens exponentially fast. And so in my talk on And so in my talk on Thursday, I will talk about this sort of thing if Pn is in confinement. So we will use a sphere, but think of it as any kind of confining space. And then the question is: is this still true? And of course you would expect it's still true, but as far as I know, there is no true. True, but as far as I know, there is no proof. Furthermore, here in the unconfined space, it is known that this thing essentially will be a composite knot of many, many compositions. And so the question is, in confinement, is it true that this is not only knotted, but prime goes to one as Goes to 1 as n goes to infinity. And so we have some sort of numerical evidence to support that, as I will show on Thursday. But that, of course, will be much more difficult. Arg asked such really good questions that I just wanted to follow up with maybe some refined versions of your questions. I guess we have all these random models and some of the random models are for our favorite invariant. And then, like, we have the listing of random models, the list of. Of random models, the civil invariants are sort of connected with this idea, but we haven't completed the complete census. So, maybe, even though it might be painful to choose a random model and a different invariant, one that doesn't exist, and start to fill out some of these details with the goal that we might be able to start comparing all the different ones to each other by comparing those distributions. So, I don't want So, I don't want to say that the random models are the same in the way that Margaret said, but maybe there are equivalence classes of these random models so that like these three models up to some kind of scaling factor or up to some kind of, you know, where you take these distributions and you realize that, like, oh, this distribution, if you multiply everything, or if you shift everything in some certain way. Of a certain way, maybe gives you one of the other models. I don't think we can answer that question until we start sort of computing a lot of different invariants that haven't been done yet. Okay. So two questions from my talk. The original question that motivates some of the things that I'll talk about is going to be: what information What information do we need to know to believe a random model? So of course you could say in this random model, such and such behavior happens, but then if we want to say is that model believable as a random model for what's actually going on in proteins or what's going on in knots, like Or what's going on in knots? Like, what are some basic things that we would want as like a, I don't know, as a way to test whether this model is giving us real data. And then another question that is popping up in my research is if the normal distribution is lurking Is lurking out at infinity for a bunch of these different random models and choices of invariance. How tractable is it to, like, how maybe far are we from these normal distributions? So we heard from Nathan about this and we heard from Marina about this, where for certain random models you're getting, and certain invariants, you're getting. Invariance, you're getting a normal distribution as the index, as n goes out to infinity. And so the question would be whether we get towards that normal distribution close enough to actually be able to use it for finite cases, than to be able to actually say something about the finite cases without having to worry about going all the way up to a thing. I don't know if that sentence is well. I don't know if that sentence is well formed. So I'll add just some things that I've been thinking about. Thank you. Okay, all right. I've got a few people who were question marks are now seeing that this is actually a reasonable thing, right? So keep coming. We've just got three minutes. All right, so this question is one that sort of came up in Erica's talk. So this comes up, I mean, I encountered it from sort of the biological world where you say, okay, we have nuts and proteins. And what does that mean? Well, proteins are open chains. They have open ends. Topologically, these things are not knotted, right? You can always undo them. But when we say, oh, there's a 5-2 in Ubiquitin, or there's 3-1s or whatever in whatever these things are, as Erica talked about, they last for billions of years of evolution across vastly different species. They're stable and presumably biologically meaningful. Meaningful. What does it mean mathematically to say that there's a truss foil in an open string? Now, I would say physically, in some sense, it's saying that the knotted thing is sort of very far in configuration space from the open chain. As Jason uses this analogy, you take a 50-meter piece of climbing rope and you tie a knot in the very middle, it's very, very hard for that thing to sort of spontaneously. Very hard for that thing to sort of spontaneously unlock itself frame, even though it is technically possible. So, what are some, and you know, the you know, Johanna and Eric Rodden and these people have this sort of idea of like, okay, well, take these things, connect them, you know, take sort of lines that go very far out, that are parallel, connect them out, you know, very far, and then once they're very far away, it's easy to close them up, do that, you know, across the entire unit sphere of directions, and sort of say, Your directions and sort of say, oh, well, the majority of the time when you do that, you get a treflo, therefore, this thing is a treflow. It's a reasonable thing to do, sort of computationally, but mathematically, what's the right notion of openness? That's it. I need to say that there are sometimes shallow knots. Not all the knots are deep, like what you were talking about. There are sometimes shallow knots, which are very close. Shallow knots, which are very close to the end, but still they stay there for biological reasons. Yeah, I mean, in the case that I drew, it's easy, but the real question is you have something where the ends are sort of in here. What do you mean to say that? And not close. I mean, maybe one's out here and one's in there. What does that mean? Is that really helpful very much? Okay, is there anyone else who has a burning desire to share a problem? Okay, let's do another one. All right, let me one. It's easy to state. I'm not sure you're going to be able to work. So I've been interested for a long time in this equilateral random polygons model, but let's just. But let's just take epilateral polygons from the space. Is the isotopy class of the unknot? Right, so I've got an equilateral unknot with the edges. I deform it to any other equilateral unknot, say the Any other equilateral unmots, say, the regular and gone through equilateral unmots? Betting equilateral, but open question. And if you're like, oh, that's easy, another one that's open is if I take the non-closed equilateral angon with open ends, is the ice is that a connected space? Is that a connected space? Can I deform any equilateral arc in R3 to a straight line through equilateral arcs? Still an open question. Okay, anyone, anyone else? Okay, if not, let's thank everybody for participating. Everybody for participating. We all have lots of things to work on. So see you next time.