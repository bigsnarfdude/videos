Or workshop. I'm very happy to be here. It's been very interesting, learning a lot of new things. So, what I'm gonna talk about is a classic portfolio choice problem, but with some new penalization or distance constraint, which I will explain in a bit. And so, this is joint work of a few people. So, first, Stephen van Doffel from the Free University of Brussels and Yang Yang, who's a PhD student who was visiting Stephen. And there we were looking at the Bretman-Basel study. We're looking at the Breitman-Baselstein distance, and with time Julian, we added the alpha in there. So you will see that there's a difference. So, and this is based on two forthcoming works, hopefully soon. So, the archive is soon coming, hopefully. So, the one paper with the pregnancy muscle stand is closer down, should be on archive in the next week, but the other one is still a bit more work in progress. So, what is this all about? So, what is this all about? So, let me recap the very well-known classical portfolio choice problem. So, if you have an investor who wants to maximize expected utility subject to a budget constraint, so we all know this. So, just for a notation, x0 will be my budget constraint throughout. And we have a complete market, so we look at the very simple problem, and we have a stochastic discount factor, which is the worst sigma there. Count factor, which is the var sigma there. Right, so this var sigma is the, yeah, we just, for simplicity, we're going to just look at the one period setting because all the optimization problem only pertains to the terminal random variable, so we just for simplicity only look at the one period setting. So the investors problem, the classical that we all know, is maximize utility subject to our budget constraints. And this is kind of something we all know, but what I want to do is I want to aume this. But what I want to do is, I want to augment this using this new alpha Bregman-Wasselstein of distance. Right, so some assumptions that we need. These are the classical assumptions on our utility functions, so strictly increasing, strictly concave, and twice differentiable. So we kind of to make life a bit easier. And we have the inada conditions that are also going along. So we're going to assume those throughout. So nothing surprising here. And probably everyone is also familiar with the solution. Everyone is also familiar with the solution to the classical problem. I'm going to just recall it because it's going to be useful later on, also for some of the notation. So, the idea here is to observe that the expected utility only depends on the distribution of our payoff. But here we have to find what is the optimal coupling, right? And the optimal coupling is the anti-tonic coupling. And so we can write this. Is this pointer work? No, okay. So we can write this. Okay, so you can write the budget constraint as this integral over the quanta function of g and the quanta function of the stochastic ant factor, which I denote by f sub or sigma and my breaths are going to be the quanta function. So whenever you see a bref, that's a quanta function. So the Wellman theorem states that if g star is a solution to this maximization over quanta function, then the x star given by the Then the x star given by the quantum function, then at one minus the C D F of the Stokes V scan factor is the solution to the original problem, and then the other way is way around. So if x star is the solution to our original problem, then its quantile function is a solution to that problem. So basically, if we start with the problem, we transfer it to the quantiles, and then this is kind of an easier, quote-unquote, easier problem to solve, right? Yeah, so you can explicitly Um, yeah, so you can explicitly write down the g star in this case, so depends on the utility, and then the lambda m here is such the Lagrange multiplier that satisfies the budget constraint. So this is, of course, very well known, and a lot of people have been working on this. So what is different that I'm going to talk of in this talk is that, well, very often an investor has a benchmark portfolio and wants to outperform or underperform, well, typically not underperform. Well, typically not underperform, just outperform the benchmark, right? I think for this quantile formulation we can work in this assumption of this price curve, I said that. Yeah, yeah. For example, it cannot have an atom. Can you remove that assumption? No, you can't. But we didn't do that. So I didn't put all the assumptions in my slide just because it's too but yeah, you're totally right. We assume that the price and kernel is nice and smooth. Yeah. The price and curl is nice and sweet. So, what we want to do is: an investor wants to outperform a benchmark strategy. So, again, I have a random variable that is the terminal wealth of my benchmark strategy, and I want to somehow outperform this. So, then the question comes: how do I measure deviations from a random variable that determines the wealth of my benchmark strategy? Right. And of course, what we want to do is we want to maybe have a comparison of different supports for our strategies. So, optimal transport is the natural choice to do. And of course, people have done it as well. One would be kind of the Valsa stand distance. But the problem with the Vaster stand distance is it's symmetric. So it penalizes gains and losses the same way. And if you want to, you know, outperform a benchmark strategy, we maybe don't want to penalize being. Penalize being better than the benchmark rate. So, this is kind of the key here. What we want to do is we want to have distances that are asymmetric, which allows to penalize gains and losses differently. And also, we want to be able to kind of penalize differently whether we outperform the benchmark and when we underperform. So, we have these two different types that we want to have. So, we want some asymmetry. On some asymmetry for gains and losses, as well as being able to say when we outperform or underperform the benchmark. So, I will still want to be in the realm of optimal transport. So, what I'm going to do is let me quickly recall the traditional problem of the one-pantorovich optimization problem, which I will use and create a new distance here. Right, so here, because my problem is only on the real line, so I have the univariate random variables, I look at this for this. Random variables, I look at the for distributions on the real line. So here. So the classical problem is you choose a cost function c and you find the minimal coupling that minimizes your cost. So here, if you choose, for example, x squared, you get the Wasserstein distance. So what we want to do here is choose cost functions that are asymmetric, which can give rise to asymmetric divergences, and therefore we can. And therefore, we can apply it in our problem. And the one I'm going to choose here is stemming from the expectile scoring function. So, I'm not sure who is familiar with expectiles, risk measures. So, if we know that they're elicitable, you can write the expectile as the argument of an expected score, and this score is what we're going to use as a cost function here. So, oops. Right, yeah, let me. I thought another slide will come first. So, let me recall the, well, what we define as the Alpha-Bregman-Wasselstein divergent is that we have a convex function phi, so it's strictly convex and twice differentiable. This is the Bregman divergent that we all know. And then the other Bregman-Wasterstein distance is defined as follows. Defined as follows. So we choose this as our cost function in our optimal transport problem. And so here we have the Brakeman divergence, and here we have this indicator function. So of those who are familiar with expectile, this is exactly the scoreing function. So if you have the argument of the expected value, if you replace z1 with the random variable y and you mean inverse over z2, you get the expectile of one. So this is the diagram. The divergence that we're going to choose. And it's a generalization of the Bregman-Wassenstein distance. So if alpha is equal to 2, you get what is called the Bregman divergent, which has recently been studied in the literature, also for not only on the real line, but for arbitrary dimension of distributions. And if you choose kind of alpha to be one-half, and phi to be x squared, you'd be covering the losses land distance, right? So it's kind of a generalization in that sense. So, of course, what you have to do is you have to see, okay, what is the actual optimal coupling here? It's the first step to be able to calculate that and then put it back in our problem. So, we did that in a work with Steven van Doffel, who's also one of the co-authors here. So, we actually looked at this problem here, where we replaced the cost function with the scoring function of elicible functionals, and then they all give rise to different varieties of. Different varieties of optimal transport divergences that are non-constant. So, there we've proved in that paper that the commonathonic coupling is optimal. And so, therefore, we can write the alpha-Bregman divergence as this integral over the quanta function. And here is exactly where we see this asymmetry. So, if fy is the benchmark quanta function and g is my alternative quanta function for Quanta function for an alternative strategy, then I see for the Breckman divergence, unless I choose phi and the x squared, I get some asymmetry on how I compare those. And then here, this is really the under and outperformance, right? So if I underperform the benchmark, which is g of u is smaller than the quantum function of the benchmark, I penalize with 1 minus alpha, and if I outperform, I penalize with alpha. So we get exactly this under an Exactly, it is under and out of performance. Okay, so now our problem becomes as follows: we're going to have still interested in maximizing the expected utility, we have still the budget constraint, but we have now this distance constraint on the benchmark. And so here what we're going to choose, we're going to choose alpha bigger than one half, because in this case, this is going to be convex in the first component. Yeah. We haven't figured out what to do with alpha. We haven't figured out how what to do when alpha is smaller than one alpha. Um yeah. What is the inside distribution function g and f, check t, checkf? So here this is the quanta function of x and g of y is the benchmark. Benchmark. Yeah, so you have a benchmark quanta function that you want to have, you have as your wealth, and you try to find an alternative payoff that maximizes utility but is close to your benchmark. Utility, but it's close to your benchmark. Yeah. And the close is measured in this alpha-Britman-loss-stand divergence. So the joint distribution is required calculated. You don't make, so here you don't make any kind of copular assumption on your X and your benchmark. There's no dependence assumption there. You could probably add a copular constraint if you wanted. So then, what we do, we're going to do the same as one would do, we do the quanta reformulation. And again, here, what we see is the optimal is to be counter-monotonic, which is not really surprising. So, again, if g is a solution to this optimization problem here, now in terms of quantum function, then x given here is a solution to p and conversely, around as well. So, what we're going to focus here is solving this optimization problem. Problem. Okay. So let's look at some boundary cases. So of course if epsilon is too large enough, we kind of recover the original problem. And here it's important to know that I don't assume that the benchmark satisfies the budget constraint. So it doesn't necessarily have to satisfy the budget constraint. So we fix x0, which is the budget, and I say, okay, if epsilon is too large, we recover the original problem. So this epsilon being too large is... And this epsilon being too large is epsilon being too large and epsilon m, which is basically the distance constraint to the benchmark. So nothing surprising here. But then you can also say what is if epsilon is too small, right? So what we're going to look at is we look at the smallest epsilon such that the constraint set is non-mpty, right? So which boils down to minimizing the Bregman-Walsenstein of a Breggman-Walsenstein subject to the budget constraint. Subject to the budget constraint. Why you want your portfolio to have performance close to the benchmark? Wouldn't it be better to beat the benchmark as high as possible? Would that be more natural? Well, yeah, you could do some goal reaching problems. For example, you can say I want to maximize the probability that your performance your performance beats a benchmark, right? And I'm sure that can also be solved by quantile. Can also be sold by quantile because that probably can also be refilled. Yeah, I mean, there's some research, but that's like a more an objective which is easier to understand. Well, I mean, if you have a benchmark portfolio that you like, maybe you want to be close to it, right? Because if you just say, okay, I want to, you know, outperform the benchmark, you don't have any control of what your actual strategy is going to be like. Whereas here, you Be like. Whereas here, you kind of follow the benchmark. But you kind of close to it's a different problem. I think both are bad. Right, right. You can still do probability, right? You maximize the probability that you maximize the probability that low performance and advantage by performance make close. You can do that. Yeah, well, you can chat about it too. What is the practical meaning? I think that's it's probably opaque. You know, it's hard for people to understand. You know, it's hard for people to understand. Well, we can chat about this philosophical question maybe in the break. Right? So, so if epsilon t small is basically this here, and then again, we have to find out what is the optimal coupling of this here. And as we can show, it's actually also the counter-monotonic one. So epsilon min is given by zero if the benchmark satisfies the budget constraint. And otherwise, you can explicitly solve it here. Right. So this is. Right, so this is the case. So, epsilon should be between this epsilon minimum and this epsilon m, so that we get a nice solution. And then, of course, you can do the other thing where you say, okay, epsilon is fixed, and if my budget is large enough, then I don't care about the budget constraint, right? So, you can also solve this problem and quantify how what is means of x0, the budget being too large. And this is given by here. So, the solution to this optimization problem, you can also. This optimization problem you can also solve fairly explicitly. And so here the lambda infinity is the Lagrange multiplier that makes the alpha Beckman-Lusselst time binary. And then so the x0 infinity is the budget of this solution. So if your budget is larger than this, then the budget constraint is irrelevant, right? So kind of to summarize this, so if So, if epsilon is too small, then there's no solution. If epsilon is too large, then we recover the original problem because the constraint on the divergence is not binding. And then if epsilon is between this range, but the budget is too large, then we get the infinite wealth solution. And the interesting case is when both constraints are binded, and that's what I do in the next slide. Right, and here it's important to note that the epsilon m depends on x0, and the x0 infinity depends on epsilon. So it's not, so you have, basically you have to have a pair epsilon x0 and then see where, in which category it falls. So what is the solution if you have both constraints binding? It's a bit messy. So what we have, so we assume some integrability constraint that this is studying. That this is satisfied. So, what you have is you have basically two cases: one case if the benchmark quantile is smaller than something, and one case if the benchmark is larger. And this is exactly kind of coming to outperforming and underperforming the benchmark. So, if your solution basically is outperforming, you get one quantum function. If it's underperforming, you get something different. You get something different. Right. And so here, this, this, what is this quanta function? This quanta function has a quite explicit representation. So the h is dependent again on the utility and the choice of the Bregman generator. And you have the etas, which are the two Lagrange multiplier that you have to find such that both constraints are binding. So here what is a bit challenging is that you have to find the Lagrange multiplier. Have to find the Lagrange multipliers, they're also in this indicator base. So for each u, you have to kind of check whether that is the case or not. So, something kind of a bit more to help with the interpretation, you can actually show the following, which is a bit nicer for the interpretation. So, this here, these inequalities can be kind of reduced to simpler inequalities, and it just means that the benchmark, the bench. means that the bench the benchmark underperforms the original market portfolio. Whereas here though the key is that the either so the Lagrange multiplier of the original problem is the optimal of this. So you can really play this role. And what we can view one of these solutions is basically this is the solution to the Bregman divergence where you scale the epsilon, the divergence. Scale the epsilon, the divergence, with the beta. So, this is kind of, you get these two basically solutions. So, if we look at the Bregman-Bostenstein divergence of alpha is one-half, we get a simpler case because in this case, the G alpha and the G1 minus alpha are the same, so it basically collapses, and you get this nice representation where you again you have. Where you again you have the sagacity scan factor comes into play and the benchmark. So let's look at some applications in the last few minutes that I have. So the applications we only have so far for the Freiban-Masterstein divergence, we haven't managed to implement it for including the alpha here. So we look at a very simple numerical example. So we have the GBM market model. Our benchmark strategy is a constant exposure of 80%. Exposure of 80% in the stock and 20% in a risk-free asset. Here we're going to look at the logarithmic utility, but we also look at more kind of general utilities in the paper. As I mentioned, we choose alpha to be one-half. And so we're going to look at two different generators and compare how the strategy is going to look like. One is x squared, which we probably the bosses line distance, so this is symmetric one, and the other one is x logic. And the other one is x log x. And so the epsilon that we choose, I mean, you can choose it exogenously, but what we chose is saying, okay, you have an investor that has some admissible or acceptable strategies, and then you calculate the maximum epsilon around each strategy, and this is your epsilon. But you could, of course, do something different. So this is a plot that we have. So the green one is the benchmark. Benchmark wealth. So, what I plot is I plot the wealth against the stock. So, here this green one is my benchmark, then the purple one is the one without the Bregman-Wasselstein constraint. And then the red one is the Wasserstein distance, and the blue one is the Breggmann-Wasselstein distance, with the phi being this one, the X log X. Of X. So, what we see here is, as we expect, we're closer to the benchmark in a specific sense, but of course, it's not really satisfying that we kind of, you know, where we actually make a gain, we kind of really underperform this part. So, what we're going to do is we're going to choose a different fragment generator. So, here you choose phi to be strictly convex and twice differentiable, and then I define this new. And then I define this new phi tilde to be this something complicated form. But what it boils down is that the Bretman divergence is going to be zero whenever Z1 and Z2 are larger than this beta. So beta is going to be the wealth threshold. And above this wealth threshold, you don't penalize at all. You only penalize below. So this is kind of one way what you can do with the Breckman Waster Standard Richards. The Breckland was the standard rigids. So, in our examples, we're going to still look at the x squared, in which case the phi tilde becomes x squared below the threshold and then linear above. And for x2 tilde, which is the x log x below the threshold, and again, it's linear above. So, the key is that we don't penalize above the threshold the well-threshold beta. So, this is how it's going to look differently. So, again, the green is the So again, the green is the same, is the benchmark. The purple is without any divergence constraint. The red one is the Wassenstein and the blue is the x log x. But now we have this new kind of Breckman-Wassenstein divergence where we don't penalize above the threshold. So here we choose whether or not equals to 1, which is basically the initial value of the stock, right? And so if we basically make a gain above 1, Basically, make a gain above one, I don't care, so I don't penalize anything. So, we observe that we can make a lot more kind of returns in the upper tip right there. And if I choose a different beta, so here we chose 0.95 just to compare what is different, and then here again, you basically have it's a slight difference on the quanta function here. Right, yeah, so for the inclusion. For the including now the alpha Bregman divergence, what we would have to do is, so this purple line would come more into play because you would see, okay, if the benchmark kind of outperforms this blue line or underperforms. But of course, the subtle point here is that this purple line, the Lagrange multiplier, is such that the budget constraint is satisfied. But if you look at the alpha-Bregman divergence, we have to choose the Lagrange multiplier optimal to our problem, right? So it's not going to be just. Of it's not going to be just in this situation and the other situation, it's going to be a bit more complicated. But yeah, that will be the next step for us to do. So, thank you very much, and I look forward to questions and comments. Any question? Yeah. So, for this reference uh distribution, can it be arbitrary or it must satisfy certain dedications that? Which distributions are you? So you want to outperform this reference distribution. Yeah, so there's some, you need some integrability assumption, right? So depending if you choose the, it needs to have some, the Bregman diversion needs to be finite for the reference, for example, right? So there's some subtle conditions in it, and we assume to be, it needs to be smooth as well. Yeah. So there's some, some, some. So there's some some some restrictions on it, yeah. So basically that you have not component memory distribution, or any distribution of the memory. Because here you only penalize the things uh which is below this distribution. The example you only penalize the performance if the the website is underperformed this variable distribution. Yeah, in this example, yeah, so if both Yeah, so if both yeah, if they're both above a wealth threshold, you don't. So in this example, you don't penalize if both your strategy and the benchmark is above the wealth threshold. For the alpha Braggman divergence, you would really out consider out an underperformance. I think because short is allowed. Like in your case, short is allowed. So it's possible to beat any strategy at some point. Any strategies? Is it there's no like a no-shorting constraint, right? Well, I assume that, yeah, no, then you have to be the extra. But it's possible. Theoretically. Yeah, theoretically. But the big question is still, how do you choose phi? So therefore it would be interesting, let's say consider putting some constraint, for example, like short team, then the problem would be highly enough. Maybe the problem would be highly enough to. I mean, I mean, so what kind of benchmark, right, you can compare this? So that would be an interesting question. Yep. Anyways, equation? Could you incorporate multiple benchmark constraints? They had two benchmarks that you wanted to be close to in some sets, and assume that there are some overlapping regions, so it's not an empty set. So, it's not empty set here? I guess you can do it for sure for the Breckman-Wasterstein divergence. The Alpha-Breckman divergence, because you have this indicator, it becomes a bit more tricky. So, I'm not sure what the case, there will be more cases than there's just two, different cases, I guess. But it might be doable, yeah. You mentioned Phi that you have to choose, you know, have any any thoughts on how you might go about? Any thoughts on how you might go about choosing the phi? There's also another family of phi's that you can make it parametric so that they have different tail parameters. So that would be maybe choosing a one-parametric family of phi's that have some properties you want, and then you only have to choose one parameter. Maybe that's a way to do, but yeah. To do, but yeah. Now you assume streeting from cap utility. Yeah, yeah. How do you know? Do you have any idea how difficult it would be to use, let's say, S-strap? Well, I guess you could do something with the concave envelopes. Probably with the Bregman buses then, it might work because it's nice and smooth. Because it's nice and smooth, but with the alpha part, because you have this indicator, you have like this non-differentiability at that point, might make it a bit more tricky. 