My well, first my what is my goal? So wait a second. Okay, so my goal is to give a there's a lot of recent works on unit sphere, including the following cartridge registering of best approximation by polynomials. That was an old one, go back to at least 80s and 90s. And then there's a much more And then there's a module smoothness on key functionals, there's a much equivalent sigma v inequality, there's a positive cubicle rules, there's a localized frames. So, and also on other regular domains, such as uniball and simplex. Well, recently I have been working on cones, cone surface, and cones. So, our aim is to provide a general framework modeled after unit sphere for all domains. Unisphere for all domains that possess highly localized kernel and some additional organality properties. So, this area has been, well, many people have worked on this area. I'm sure there's a whole several of you in the audience. There are many more, which is represented by the X at the end. Okay, and then so the idea is one gets to working on surface and corn. Working on surface and corns on the corn bodies, I was thinking I have to repeat all the work. That seems to be too much. So, therefore, I was looking for a general framework, which maybe we can just do it for all, once and for all. So, what's the setup? So, my setup is the well, I usually call them homogeneous space, but some people point out. Space, but some people point out it should be called a space of homogeneous type because that's a measure space omega mu D, where omega is a domain. D is the metric, or you call it distance. Nu is a non-negative W measure. W measure, as usual, means the ball of volume is less than or equal to ball, while double over 2R is less than bounded by a constant times r, where the ball is defined by your distance function. By your distance function. So, in this talk, I'm going to consider dÎ½u equal to wx dx, which really means it's a doubling weight. And we write space as omega w d, or omega being a regular domain, such as unisphere, unit ball, that's the familiar ones, and conical surface, which means x of t, norm of x equal to t, t belong to zero, and solar cone, which means x. And solo cone, which means X norm is a less than equality. Those are the domains I'm going to be working on. So, first, I need the orthogonal structures. So, on omega W D, we consider orthogonal polynomials. I simply call them OP for the inner product is fx gx times wx dx, where I'm calling v n dw a space of orthogonal. W as a space of orthogonal polynomials of degree n. That's degree exactly n. When I say orthogonal polynomial, I mean the polynomial is orthogonal to only polynomials of degree lower, but not among them shoes, not among the polynomial of the same degree. So if PKN is an orthonormal base of VND W, then the reproducing kernel of VND is defined by a sum. By the sum of one lesson, the k lesson dimension pnx times pny. Normally, this kernel is a mess because your orthonormal base is very complicated, usually. But when we define this as a kernel, we are hoping this kernel has some simple structures. So, what is this kernel for? You can consider orthogonal projection operator, which is from L2 to this VMD. L2 to this vm dw. You simply map it to this orthogonal subspace. What this operator satisfies is the integral operator with reproduced kernel as is kernel, time f of y wy dy. Well, this projection operator defines your fully orthogonal expansions. So fully orthogonal expansion of f in L2 is simply given by a sum. You decompose them in terms of polynomial subspace. Then, in terms of polynomial subspace, then add up all the projection operators. And you didn't see fully orthogonal series here. Well, hopefully, we don't need fully orthogonal series because whenever you have to work with orthogonal basis, that's usually a mess. It's difficult when we don't really know how to handle it. So, let's go on. So, what is a highly localized kernel? localized kernel so that eta in c infinity be a cutoff function so eta t equal to one with t between zero to one eta is supported on zero to two and eight is non-active so for a weak function omega define ln omega xy equal to reassembling of my repollution kernel but with eta k over n or k from zero to n. Of course, because the support side is on zero to n. Because the support side is on 0, 2, you could say it's k from 0 to infinity. Using Ln as a kernel, we can define an integral operator, Ln star F equal to integral Fy taking Ln as my kernel. The importance of this Ln is, first of all, it decays really fast and resembling the sum 831 means it really preserves polynomial up to up. polynomial up to up to degree n. You have ln star f equal to f if degree is less than equal to n. So then ln star f is also a polynomial of degree 2n. So therefore, this is a construction of a polynomial of degree 2n and it preserves polynomial after degree n. So you can easily produce something like this. It's the colour is near best polynomial approximate to best polynomial approximating to f so you can write down r n star f minus f is bounded by c infum of f minus g for all polynomial g less than equal to n so when the kernel is highly localized in fact for people who know this subject well you don't really need kernel is highly highly localized all you need is our n star f is a bounded operator so in a way this is what we call So in a way, this is what we call Galawali Pusung means, sort of like the old Galawali person means for free service. So okay, I still haven't decided what is means by kernel being highly localized. Here it is. The kernel omega is called are called highly localized if it satisfies two things. First of all, for every type of bigger than zero, x, y, e, omega. omega the ln is bounded by a constant times omega bx n well the ball with the radio n inverse that's the that's the measure then square root square root then times one plus n times dxy to the kai plus power and this estimate is highly localized for the reason if you if you think about it is for any kaiper of course you can Kaiper, of course, your constant depend on kaippa, but when kaiper is large, your dxy is bigger than some small distance, say dxy bigger than constant, say bigger than zero, then this polynomial kernel decays extremely fast because you have one over one plus n to some constant times a kaiplus power. So it's faster than early polynomial powers by choosing chipper large. Kappa large. And of course, if x is equal to y, then this term disappeared. So then, therefore, this is a really at x equal to y, this number can be large, but otherwise it should be very small. And I need a tool, a certain tool to say, for delta between delta zero bigger than zero, for some delta zero less than one, where x1 and x2, the distance is less than delta over n, then the distance of the kernel. the distance of the kernel is also bounded by a similar estimate where you have n times g which balance off is one but otherwise the two estimates are similar so but such kernel exists only for special omega for general omega you cannot expect something like this to happen but for special omega in particular we need this omega to satisfy the following assertion three which satisfies Assertion 3, which says for a sufficiently large kaiper bigger than zero, this integral has to be bounded. In a sense, if you have this condition, you can easily prove that the integral of Ln is going to be bounded. So it's a pretty mild assumption. The number one and number two are much harder. So we call omega W D a localized space of homogeneous type, if highly localized. Time if highly localized kernels exist. Of course, the question is: when do they exist? Well, as I said before, the talk was about this modelized by the study on the sphere. So let's see example. First one is the unisphere, where d sigma is a surface measure. sigma is a surface measure, while d casi eta is the geodesic distance defined by r cosine cosi eta. Orthogonal polynomials here are just usual spherical harmonics. Let H and D be the V and D d sigma, which is my orthogonal polynomial subspace. Then the dimension is given by this combinatoric number that's well known. They enjoy two key properties. key properties. So one is that orthogonal polynomials or spherical harmonics are eigenfunctions of the Laplace-Beissromi operator. In other words, you have Laplace-Beissromi operator delta 0, y equal to negative n plus d minus 2 times y for any y in H and D. Notice the eigenvalue depends only on the degree of the spherical harmonics. The reproducing kernel The reproducing kernel in this case satisfies what we call a Disney formula. Remember, we said that reproducing kernel usually is a mess. Ah, there's some error. The first error, casay eta, this should be casai eta2. So, but in our case, for spherical harmonics, it's beautiful. It simply says you add up our entire earth number base on pkn x casi pkn. x cosi t in eta, you end up with a one-dimensional thing. It's a George-Mar polynomial n plus lambda c n lambda t. Then you write down lambda equal to d minus 2 over 2. We have x dot y or casi dot eta. So highly localized kernels are proved using the adhesion formula. It simply means you reduce a lot of things in at sphere to In atmosphere to one dimensional. So, most important keyword is this one-dimensional structure. So, next one, let's consider unit ball. Unit ball, the classical orthogonal polynomial, is with this width function, w mu x is 1 minus x squared mu minus half, with mu bigger than negative half. Well, in this case, your distance function is dBxy, is alcohol. is dBxy is our cosine x dot y plus square root of y minus x square one minus y square. Well, if you take d equal to one, this is just negative one to one, where w mu become Geiger model weight, and this dxy is simply the projection from the unit circle to the interval negative one to one. So that's the distance function. Well, the dimension here is also changed because you are no longer on the no longer on the on the sphere you're on a solid domain so dimension is n plus d minus one choose n it's a n is a dimension of monomials of degree n so orthogonal polynomial on the ball also share these two key properties first of all orthogonal polynomials are eigenfunctions of a differential operator for u belong to vm dw mu which orthogonal subspace you have this differential operator times u equal to 19 operator times u equal to negative n plus 2 mu plus d times u where again the eigenvalue depends only on the degree of the polynomial. So I decided formula for the repository kernel. Well again if you add up all of our normal bases it's a mess but we have a simple formula. In simple size you integral negative one to one t square mu minus one times this thing. It holds for mu bigger than equal zero It holds for mu bigger than equal zero. You notice what is inside the integral is very similar to our distance function. The difference is t. You have the integral, the additional parameter t from negative one to one. And also your dynamic polynomial is mu plus d minus one over two. So those two are the classical ones. And the study of them essentially, well, Well, motives are studied here. On the sphere, they started going back years ago. And the ball is relatively new, but it's also modeled after sphere. Let's look at our next one. Next example is a coin. This is relatively new. Probably you can say three of probably three years of. Three years of old, which is really young. So we take this weight function t to the negative one, one gamma, gamma bigger than negative one. Notice my t does not depend on x, only depend on one variable t, where d v0 xt y s is r cosine xt plus x y over 2 square root plus square root t square root s. Even this, try to prove this is. This try to prove this is a proper distance function, it's not trivial. So let's study orthogonal polynomials on v zero d d plus one. Well, this domain is is a column. So t is this vertical direction, where x is the rotation variable. So my inner product is fg equal to integral f x t g x t where I have w depend only on t not on x. depend only on t, not on x. There be sigma x t, which is the surface measure on a conic surface. The inner product is well defined, but you have to model, take all the polynomial algebra, you model this ideal t squared minus x square. The dimension is similar to the spherical harmonic, but with degree d plus 1. Orthogonal polynomial on this domain also possess On this domain, also possess the two k properties. So, the first one, the eigenfunction of differential operator. So, you can say t times 1 minus t partial t squared plus d minus 1 minus g plus gamma t partial t plus t inverse delta 0 cosine, where I'm setting delta 0 is a Laplace Bach showing operator. I have x equal to t times cosine on the column. So this is. So this is again holds for all orthogonal polynomial subspace with eigenvalue depend only on the degree. Well, ideal formula here is more complicated. Look at it. You have a double integral, where in terms of zn have z2n, where v1 square root hc plus x by 2 plus v2. Well, if you remove v1 and v2, then this is the distance. And v2, then this is the distance function. But this has to be integral on v1 and v2 on dv1 dv2. This holds for d bigger than the two and gamma bigger than negative half. When d equal to 2 or gamma equal to negative half, this formula have to be taken as under limit, where c of course depends on d and gamma. So you can take limit here. Using additional formula, highly localized. Formula, highly localized kernel can be bounded by using the localized kernel of the Jacobi parameters. So, here and away, you reduce a multi-dimensional problem to a one-dimensional dimensional problem. Okay, so from now on, I'm going to assume there is a, I have a space I have a setup, then I have a highly localized kernel. So, let's first see what we can do. First, see what we can do. First, we do is much encouraging Ziggler inequality. Many people in the audience have been using this inequality. So, let's go be quickly see what this really is. So, let omega WB be a space of homogeneous type. First, we need a well-separate pawn set. So, its concept is a discrete set called psi. A finite classing of subside is called classing of subsides is called a partition. I'm basically taking partition so partition a side in omega in the union where the side are not adjoined. Now epsilon bigger than zero at this create subside is called epsilon separate if distance of any two point in its side is bigger than equal to epsilon epsilon is given. We call it maximum if the sum of this or the union of sum of this or the union of this side covers entire ball or in this case entire entire omega so you want to calculate this function of this less than c bigger than one and we're yeah so this is a well separate side is this it's a bit of too much of a definition so just remember that you need enough point so that distance between them is bigger than epsilon is bigger than epsilon, and the little ball centered at this point covered entire domain. So I'm going to denote pi and omega as space and polynomial degree less than n on omega. Here's a machine coverage inequality. So let omega be a doubling weight on omega. Let cossi be a maximum epsilon delta over n separate subset of omega and delta be going to zero. Omega and delta become zero less than one. Then for all one less than p less than infinity, and f is in pi m omega. Then you can write down m between n and c times n, you have this inequality holds. So the left side is a sum, where the right-hand side is the inevitable norm, where the p-norm satisfies. And this reverse also true, means the p-norm is also bounded by this discrete norm. Discrete norm. This is the Martian Kovichi Sigmund inequality. The proof for this one, you don't really need a highly localized kernel. Well, okay, you use it, but not explicitly. The method we use is essentially where you I'm borrowing this from what Fungai did with this maximum function. And then you can prove this thing with. Prove this thing with not too much trouble. Next, what we're going to do is the following. The crystal function. So crystal function is defined by this. So lambda nwx is the infum of gx one integral gx square wx dmx, where g is a polynomial of degree n. So So it is related to the partial sum of orthogonal polynomial kernel. So you write down lambda equal to 1 over kn w xy. So this is the crystal function. For people who know Gauss quadrature, you know this kernel, if you evaluate at the zeros of a thousand polynomials, that's exactly the weight of Gauss quadruped. This holds true also in multi-dimensional. True, also in multi-dimensional. So let's see what we can see about this. First of all, in this case, I do need my assertion one, which means I need highly localized kernel. So let W be a doubling weight on a domain omega. If W is a weight function for which this highly localized estimate holds, then lambda is bigger than or equal to C has a lower bound by C has a lower bound by the ball at x1 over n, radial one over n, centered x, bounded at times some kind of constant c bigger than zero. So this, of course, is easy because you take lambda is bigger than that. You take one over lambda, that's kn. So all you have to estimate the kernel KnWXY, and that you can estimate using the estimate of a highly localized kernel. So that's not too bad. kernel so that's not too bad they they for the upper bound we need something actual what is called assertion four there's one more assertion for which says i need a fairly fast decaying polynomial so farly decaying polynomial decides the four decides the following that omega be a compact side for each x in omega there's a non Each x in omega, there is a non-negative polynomial tx of degree at most n, such as that tx equal to one, tx is bigger than zero, bigger than n, if y is close to x and for some delta. And also, I want this highly localized property to hold. So, this polynomial decays really fast. In one dimension, this go back to, I guess, it's really tautic and also. Very taught and also Carmen Carmen Ivanov Carmen did this. So second, there's a polynomial Qn such that Qn Tiy is a polynomial degree and most R times N for some R such that Qx is bounded by C1 C2. So I need two conditions, a little bit extra than usual fast decaying kernel. I also need power two. So let's see what this thing does. See what this thing tells us. So, a cubicle rule of degree n for w is simply means that. Well, means you take the integral equal to lambda k f x k f is a polynomial degree up to n where lambda k is omega, x k lambda k is real, x k equals r. Sorry, x k is omega. We call this tributary formula positive. How does tribute formula positive if all the lambda k's are positive? So let lambda be the double weight. Then the formula theorem says you have a well-separate site, given a well-separate site, delta n-separate. Then there's a delta zero bigger than zero, such that there is a positive number, lambda z, so that this positive kernel holds. Moreover, this lambda z can be However, this lambda z can be estimated as bounded by WBZ delta n. And if I search in four holes, then lambda z is actually equivalent to this, well, equivalent to the size of this measure of the ball. Now, this is again well known in sphere. And then it goes to the ball. Now go to general setting. All we need is assertion one and four, which means we need highly localized kernel. So next thing, once we have highly localized kernel, then we can see that LNW is a kernel defined with cutoff function eta. I'm going to choose the colour of function. I'm going to choose the cutoff function such that the sum of g from 0, eta 2 negative gt squared equal to 1. And you can construct eta such that this holds. So what is this for? This, let me first define f0 equal to 1, fg equal to l 2g minus 1, wxz, g big one. Then we define fg star f equal to l 2 star F equal to L2 next GS star F of the integral. Then this condition, sum of this eta equal to one, really implies a semi-discrete decomposition. You can write down F equal to sum, projection K W F equal to that. This, by now, is a well established procedure. It is purely algebraic, so it holds for Algebraic, so it holds for every domain. And what we can do is we can apply a quadrature formula on Fg star Fg. That gives us the construction by Pancho, Petrushev, Johar, and Nakovich. So we get this used cubicle rule to discretize F star FG gives a localized frame. So for GA rule. So for GA equals zero, that casside be a maximum delta 2G secondary subside. So the lambda CGA equivalent. So this again is a strategy full. And you have quadrature formula, positive quadrature formula. Then you decide Possi Zg X equal to square root Fg. Then the whole collection of this Poseid Zg is a localized free. Is a localized free system. This localized frame is localized then because it satisfies this estimate. So this is why we call a highly localized frame. And that's why Pancho, they call this as needle lights. Well, the system is a tight frame, EL2. All you need is to write down, again, I'm recalling this norm. Recalling this norm, they will see omega wd is localized based on homogeneous time. Let w be a w weight start from ascinion four. Of course, in this case, it's new more than asynchronous four. We need one, three, and four. Then, if f e l2, then f equal to that. That's the localized frame. And it's R2 norm is equal to the discrete R2 norm. So, this is a well. So this is a well, this procedure. It's applied on the sphere, on the ball, and now you can add, it's also applied on the chrome, on the cooling surface, and also solid corn. So let me now consider approximation in a space of homogeneous type based on the existence of. Based on the existence of the two K properties which I mentioned before, one is a differential operator that has OP as eigenfunctions and a Disney formula for reproducing curl. We assume these two properties exist for the space omega w d. So what do I mean by exist a differential operator? In general, what I mean is the following. Omega is a weight function on width in function r we denote that d omega the second order derivation operator that has op eigen functions through d omega y equals negative mu u y n u y in v n so where mu is a non-negative quadratic polynomial so why is not seeing is a differential operator because this holds normally on a sphere on ball and a cone that are differential operators also on simplex Operation also on simplex, but it also holds with donkey type of weight function. In that case, your operator is not just a differential operator, but also a differential difference operator. So I'm simply calling a derivation operator. So in all known cases, the adhesion formula is of the form, the following. P and W X Y is 191 to 1 and Z N 91 to 1 n z n alpha beta cosine x y u d tau u. Well, remember when I said cone, I wrote down z2n instead of zn. Well, in that case, what you do, you take the Geigermar polynomial, you use quadratic transform to make it a zn. But when you do that, this cosine xy becomes very complicated. But that's fine. but that's fine because important thing is a one-dimensional dimensional property. Here m is a positive integer, zn alpha beta is the Jacobi polynomial, where hn alpha beta is the norm, L2 norm of the Jacobi polynomial. This holds under alpha bigger than beta bigger than or equal to negative half. Well, this is all the known cases you need this bigger than or equal to negative half. Cosi XYU Cosi xyu is a complicated function in negative 1 to 1m and symmetric in x and y and it's bounded by 1. Moreover, d tau is a probability measure on negative 1 to m, which can degenerate to have limit, a finite support. For example, when you go back to spherical harmonics, there's no integral, just x dot y. X dot y. So let t go to L n alpha beta, where L n alpha beta T1 is a localized kernel for the Jacobian formula. Then the Addison formula can be simply rewritten as Ln alpha beta cosi XT XYU1 d tau. So in a sense, your highly localized kernel now become an integral from negative 1 to 1 m of the one-dimensional kernel. The one-dimensional kernel. And this is what we mean when we say you can derive a highly localized kernel by using the estimate of one-dimensional kernel. Okay, with that, we can say, assume omega admits an addition formula. Then for f in L1, we can define something like a convolution, f star g, where g is a one-dimensional formula, where one-dimensional function where One-dimensional function where f is a function on omega. Now you can define f times g of beta times weight function dy, where the operator g to tg is defined by that. Remember, this g is one-dimensional, but cosi x, y, u is one-dimensional in terms of u. And then the tau u is an integral negative one to n. Then the usual Young's inequality holds. So this is a well-defined function. Well-defined function, however, uh, yeah, well, forget about that. Moreover, you can write down following theory. Assume omega satisfied is a five, is a highly localized kernel exists. Then for f in wp, you have this estimate. The f minus f times this highly localized kernel is bounded by same negative r times the differential operator. differential operator to R over two is fractional power F P L P naught. So this is again a well-oiled approach. So the translation let's define a translation operator as sigma omega by the projection operator. So the projection operator for this S C omega F C omega F is the Jacobi polynomial times projection of F. This, well, we call them a transition operator because if we look at their fully orthogonal series, you can see something. But operators satisfy the following properties. You can write down your F star G, the pseudo convolution, as in terms of transition operator, one-dimensional integral times the transition operator times Jacobi wave. Operator times Jacobi weight times G cosine theta. Well, it preserves positivity. And furthermore, it is bounded. So it's bounded by normal one. And limit theta goes to zero, it goes to zero. All these properties are set up for define of our module of schmuthis. So that alpha bigger than zero, f omega. Then for theta between zero pi, you simply define r. To pi, you simply define rth modulo smoothness by supreme state of universe identity minus this transition operator to r over two power f for t bet zero to pi. Then define the r k function of f by the volume. So this again k function definition is classical. So is our module of smoothness. Of smoothies. This has been done in the sphere back to the 70s, 80s, I guess. And then further, this is the general, well, in that case, it was usually, not usually, it was done for in stages for P equal to 2, then for P bigger than 1, bigger than equal to 1, and for R equal to 2, and gradually moving up. And Rockmanov eventually defined this. eventually defined as for gene was general used to characterize best approximation on the surface on the surface of the sphere. So but you can define this. Then you can define that omega be a wave function that admits a certain one two three five well I'll say what five is that F E L P is zero then you have these two things Then you have these two things are actually equivalent. So your k function and multiple smoothies are equivalent. So what are the one, three, five? One is the fast decaying kernel. You want the kernel to exist. Three means the kernel is also integrable. The number five is the following. Number five is an extension of number one. So number one, all I said is one all I said is I want our n is r equal to one zero case so number one assertion one is r equals zero I want this estimate to be true for r equal to zero but in this case we want the derivative also holds but derivative so r is not derivative we have mu k of r over two well nu k is the eigenvalue of my differential operator so in a way if you're taking derivative because you're taking derivative because pk as a kernel will take derivative with respect to x then that become an eigen well that derivative of this this derivative simply disappeared become the eigenvalue so that's where i'm where i give this what operator is the derivative operator i want derivative estimate okay so with that So, with that, you can also do the following. You can characterize the bias approximation. Let the EAFPW be the error of biased approximation 2F from the polynomial space. You write down Pw, then omega be a wave function that admits assertion 1, 3, and 5. Then you can write down EMF is bounded by, well, k-functional, derived estimate. You can also have traditional universe estimate. Also, we have traditional inverse estimate. Of course, this k-functional is also equivalent to the module of osmosis. So, in a sense, what I'm saying is by defining highly localized kernel and additional assuming a little bit more on fast decaying polynomial exist, all the mechanism people develop over years applied to the general homogeneous. The general homogeneous species. In particular, this is how I did all the cones on the surface of cones. So I essentially established this property first. Then next thing is a technical thing to prove all the assertions holds, means hard work of asymmetric kernels. But it's messy work, but it's not really in principle, they're simple. Principle, they are simple. Thank you. Thank you very much, John. Are there any questions, comments? I have a little question for you. When you talked about this Martin Kevich Sigmund inequalities, Sigmund inequalities. Yeah, basically, what your theorem says under all the conditions that you can take the points, any point from a epsilon neighborhood from that well-separated points. And this will be fine, right? Yes. And this is clearly, this is because of the property of this really well-localized kernel. Yes. But in some cases, In some cases, there is kind of a problem how to build this well separated points. Do you have any kind of comments on that? How to build this? This is the problem. I mean, this is basically epsilon entropy and other stuff, how to build those points. Right. I don't know because to me, I like this general theory, but I always think this general theory. Always thinking this general theory, there's a hole in there, not hole, but it's a theoretical thing. First of all, we can choose the point. I mean, nice separation point. But how do we prove, sorry, we know how to prove, but how do we find quadratus? Those width functions, we prove they are positive, but we even But we even know they are well balanced, but we don't know how to compute them. So, this we can only compute them in 30%. Oh, yeah, we can approve linear programming, but that's not really for high-dimensional, even two-dimensional. I don't think anyone knows how to find those roots. I was thinking how to find those quadrature weight is the main difficulty. Is the main difficulty for this thing to be useful? Yeah, yeah, this is yeah, that's clear. Okay, thank you. Are there any other questions or comments? Yeah. I have a question. Can you hear me? Yeah. Yeah. Hi, this is Dimitri. Yeah. Hi, thanks for a nice talk. So my question is, so you have results about the existence of positive cubisher formulas. I was wondering if on I was wondering if, under these very general conditions, can you prove an analog of the Bonderenko-Rachin-Kovyazovska result about the existence of spherical designs of particular order? Well, or designs in this case. So basically, can you prove that there exist cubisher formulas with equal weights of a certain optimal size, asymptotically optimal? It seems that at least. It seems that at least some of the ingredients that you need for that proof are there. So you have the Merson-Kabby-Sigmund inequality. Yes. Yes, and no. Well, let me say the following. I haven't had time to work on this, but let me say this. In order to have that, in fact, my kernel, which I showed up on there, looks very, very, very, very. Come very, very what my see, but that's actually not too bad. Let me show you. It's here. Did you see it? Yes. Yes. Because in this case, you don't really need it to be so complicated. Because for in order to have that, you should look at not all weight function, should look at the equilibrium weight. In this case, your W should be Should be gamma. Gamma should equal to negative half. When gamma equal to negative half, you're already taking a limit. So one layer of integral disappears. And therefore, your kernel function is actually simpler. So from that point of view, I would guess something like that should be possible. I guess I would first try. So if you want to try it, my suggestion is try the following. My suggestion is to try the following. Take d equal to one, not equal one, not d equal to two. Sorry, d equal to two, gamma equal to negative half. In that case, both integral disappears. You have a summation, sum of the basically Gagnon Mar polynomial, then you write down sums, four sums, and from there, you can. Thumbs and from there you can try to try the same technique as in Pononenko's paper. Okay, thank you. Okay, are there any other questions? If it is not the case, let's thank the speaker again. And after that, we convene at what 11 local Oaxaca time. Am I right? Am I right? Yeah. 10, 10, not 11. Why 10? In the program, it says from 10.30 till 11. 11. Coffee break and then at the 11. Okay. So thank you and we'll see you in an hour, about an hour. Okay, thank you, Johan. Thank you. Okay. Yeah. Okay. Not a problem.