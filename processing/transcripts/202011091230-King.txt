People who are actually in the audience, at least I hope, have given me the benefit of some really useful conversations over the last couple of years. I know for some of these people that they probably recall with some mixed emotions the badgering that I've given them. The badgering that I've given them on various little points. But those have been incredibly useful to me as I've tried to deepen my understanding. So I want to talk about phylodynamics. I don't need to define that, but I want to emphasize that what I mean here is really what Trevor was referring to, one of the challenges that Trevor was referring to in his talk of inferring aspects of dynamic transmission models on the basis of genomic data. So I want to focus on that aspect. Focus on that aspect of the problem. Can you guys see the cursor when I wave it around like this? Yes, yes. Okay. So obviously the dynamic models that we're interested in working with, here's just a sort of generic model for COVID that I've schematized here in the usual compartmental formalism. You know, these dynamic models, it's a really important feature of them is that we need to account for We need to account for stochastic effects, and so stochastic models are very useful. We can make progress ignoring stochastic effects, but there are quite a number of stochastic effects that are informative. And so we'd like to be able to fit stochastic models to genomic data. A sort of framework within which is big enough and robust enough to accommodate most or all of the models that I think we're Models that I think we're, as a group, interested in is this state-space model framework, I think, somewhat more evocatively called a partially observed Markovian process. And these, just to remind you, these processes are characterized by having a latent state process here indicated with X, which is Markovian, and then observations, variables that are actually observable, are related to that in a particular way. And the central quantity from the point of view of inference is, of course. From the point of view of inference, is of course the likelihood, which is just the probability density of observing the data that we observe, given the model structure and the parameterization. And likelihood-based inference in such models is facilitated really by an algorithm that's a workhorse in just about all applications, and that's the sequential Monte Carlo. And I'm not going to explain that very much in detail, but I want to call out a couple of key points. So it's based upon a particular factorization. So it's based upon a particular factorization of the likelihood. Here, if you'll recall, this is the direction of time is left to right. And here I'm factorizing these probability densities in a particular order from left to right. And that, you know, the sequential Monte Carlo allows us to compute these terms by basically a recursion that involves tracking a couple of different probability densities. But the key thing to take away from this is that whereas we could factorize that Whereas we could factorize that likelihood from right to left just as easily, we wouldn't be able to translate that into an effective computation. And the reason for that is that the transition probability densities of the latent state process, our SIR variables, if you like, are computable in forward time, but not in reverse time typically. So typically, we don't have access to be able to compute with these densities or even to simulate from those densities. To simulate from those densities. So, this is a complicated problem in general, working trying to build a tight connection between stochastic transmission models on the one hand and genomic sequences on the other. And of course, the genealogical tree that relates the sequences is the bridge between the one and the other. And to date, most of the work, I think it's fair to say, has relied upon two assignments. Has relied upon two assumptions that make that possible. And these are rather heroic assumptions. I call them to our attention here just to not because I'm going to do anything about them. I'm not going to relax these assumptions. I'm actually going to rely on these assumptions. But it's always worth keeping in mind that they are rather strong assumptions. In particular, that here's a transmission tree. This bloke has got a virus. He transmits to someone else. The transmission event occurs at a particular time. Transmission event occurs at a particular time. The blue here represents a genealogical tree that is reconstructed to relate one pathogen sequence with another. And one assumption that's made is that these branching points coincide in time. And there's all sorts of reasons why that might not be the case. Nevertheless, I'm going to be in good company, assuming for the purpose of this talk that it is. And moreover, and of course, that the sequences. Sequences themselves represent the genealogical relationships faithfully. So, those two assumptions are, as I say, heroic, but I think there are interesting problems even if we take those assumptions for granted. So, we'd like to be able to work with stochastic models as complicated as this, but for today, I'm going to simplify to a case where we have just a single infectious compartment and focus our attention there. So, if we think about So if we think about the continuous time Markov process that's sort of implied by this compartmental model diagram, we can think about that as a kind of generalized birth-death process. So in particular, births or infections correspond to births and recovery events or real death events correspond to deaths in as much as the population of infected hosts. The population of infected hosts is either increased or decreased by those events. So, I guess this is just to call attention to the fact that what we're modeling here are infections, not individual pathogens nor individual hosts, but actually infected hosts are the focus of the attention here. I'm going to use the term lambda here to refer to the overall incidence rate. So, that is the number of new infections per unit time rather than the more common. Time rather than the more common use of per capita incidence or force of infection. So I think it's fair to assume that we've all looked at simulations or stochastic realizations from this model. And of course, this is just to remind us that it's a stochastic model, that the number of infectives follows an infection curve in this case. It's a random function of time. If we look Function of time. If we look, for example, at the number of cases that occur in any given day, we can see that randomness quite pronounced. So how do we go about working out, how do we go about doing the inference for such models? So there are two big sort of categories of full information approaches, that is to say, likelihood-based approaches to the problem. Likelihood-based approaches to the problem. There are other non-likelihood-based approaches that have been used to great effect. But the likelihood-based approaches fall into two categories. I'm going to focus on one of them here, just for the sake of time. But both of these assume, they interpret the genealogy as a static representation of the history of transmission and sampling, which is really quite natural. The tips, this is a genealogy drawn from a simulation of that SIR model, and you know, the tips correspond to samples, and the branches correspond to. Samples and the branches correspond to transmission events according to the assumptions that I've already made. And so it's sort of natural to think about this as being a representation of the history of those things. And in fact, if we were to count up the number of lineages that are extant at any given time and record that here, as I've done with this lower graph, this is the number of lineages extant at each given time. The resulting quantity bears more than a passing resemblance to the epidemic curve. In fact, it's strongly. Curve. In fact, it's strongly correlated with that, and there's clearly information in the data about that. And the existing approaches have exploited that fact. And I want to focus on a particularly elegant and straightforward approach that was pioneered by Eric Voltz and adapted to the stochastic case by Dave Rasmussen and Kacha Coelh. And here, the connection between the The mathematical model and the data takes the form of the following form. So the process here is, well, what's actually done is a sequential Monte Carlo algorithm is applied in which the likelihood of the data is the likelihood of a branching process with the following hazard. I'm circling here. So little lambda here is again the overall incidence rate. There's this combinatorial Rate, there's this combinatorial pre-factor where the numerator is the number of lineages choose to, and the denominator is the actual number of extant infections at that time choose to. So, this is all a function of time, and that overall branching rate is, or branching hazard, is the key element of the likelihood. So, this bothered me a lot because the arguments that are used to derive this are heuristic arguments, and they're based upon the coalescent theory. The coalescent theory and a deep understanding of the coalescent theory, which suggests that this is a reasonable choice for the effective population size in that theory. And yet, if we take this literally as a physical process, it's extremely problematic. And the easiest way to see that is that this can't really be a physical process because it exhibits finite time blow-up. So the quadratic dependence on the number of lineages in Dependence on the number of lineages in the numerator means that if the number of lineages grows with this hazard, it will blow up in finite time. And clearly, that's not seen in, that's not really the intention of the approach. So that just calls into question, so how do we go about interpreting this? What is the right way to think about this? And more generally, can we compute an exact likelihood for an observed genealogy produced by a nonlinear stochastic birth and death process? And so approaching this, you know, banging my This, you know, banging my head against this problem for quite a while, I finally realized that a way forward is, we get a way forward when we view the genealogies dynamically. So we want to think about the process by which genealogies are generated dynamically. So, hang on a second. Right. So, again, we're thinking about this as a birth-death process that. About this as a birth-death process, that the eye compartment here is has a number at any given time has a number of individuals in it, and new infections represent births, recoveries represent deaths. All we need to do is keep track of the genealogy of all of those individuals. And so we need some sort of a formal representation of that genealogical process. So here's a little bit more mathematical formulation of what I just said. So I want to talk about not just an SIR process. Talk about not just an SIR process, but a much more general Markovian process. So I'm going to leave that unspecified as x. I'm going to assume the existence of a population size. So if my x represents S, I, and R, N would represent, for example, the number of infective. So N would represent the occupancy of the I compartment at any given time. And we need to have birth and death hazards, lambda and mu. I've already described what those are. Lambda here is actually already written on here. Mu would be. Written on here, mu would be this arrow here. And these are hazards such that the probability of a jump up or a jump down is proportional over small increments of time to these two different rates. So that's the general setting. We now need to give some kind of a formal definition of a genealogy. So reasoning about genealogies is typically done by reasoning about trees, but that's problematic from a number of points of view. The tree representation is Number of points of view. The tree representation isn't unique. It can be kind of difficult and squirrely to talk about trees. What do we really mean by a tree, for example? Multiple definitions possible. So thinking about this, I hit upon a metaphor that at least for me is florid enough that it's useful. It allows some visual reasoning. And that metaphor is to visualize the tree in terms of a number of players, a number of individuals. Players, a number of individuals who are holding each of them two colored balls. So the idea is that each individual, each internal node that we see here has two descendants. In some cases, those are terminal nodes here indicated with black balls. In other cases, an internal node holds one green and one black ball. Here's an internal node that holds two green balls, for example. So motivated by that kind of simple, simple-minded Minded visual analogy, I proposed a way of representing the genealogical dynamics in terms of a parlor game. So this is probably the most boring and pointless parlor game you'll ever play. But if you've got some kids at home and need to tire them out, then this is one way to do it. So basically, every we have some number of players. Every player has the following equipment. They have a slate upon which they're going to inscribe. Slate upon which they're going to inscribe times. They have one numbered black ball and a green ball, and they write their name on the green ball. So at the beginning at time zero, we have this many players, and we seat them in a row from left to right, left representing the past, right representing the future, and everybody writes the current time, which is zero on their slate. And then play proceeds very, very simply, right? So there's a Markov process X, which is run. A Markov process X, which is running along, continuous time process running along in the background. Every time there's a birth or a death event, a random black ball is selected. If it's a death event, that player holding that black ball is going to die. And what that means is that the player holding that black ball stands up and trades whatever other ball they've got in their other hand for the green ball bearing their name, so whoever happens to be holding that, and then gets up and steps aside, and all the other players shift. And all the other players shift down one seat to the left. If it's a birth event that happens, then some new player who's been standing in the sidelines holding a green ball with their own name written on it, as well as a black ball, comes along, sits down in the rightmost seat, trading the green ball with her name on it for the black ball that was selected. So for a randomly chosen parent, that random parent is chosen by selecting a black ball and becomes the ancestor. Black ball and becomes the ancestor of this new player. And she records the current time on her slate. So, simple rules for how a genealogy grows. You can illustrate this. I want to show you a simulation and an animation, and we're going to do that using the Moran demography because it's somewhat simpler. So, this is what it looks like: a genealogy evolving under this process in time. And of course, so we're all familiar with the Moran process. all familiar with the Moran process and what coalescent or Kingman coalescent genealogies look like. The only thing new here is that these are dynamically evolving. And so on the right hand side, it's evolving in a continuous fashion as time proceeds forward. On the left-hand side nodes are dropping out as ancestors are forgotten due to the death of all their descendants. So That's what that looks like. We can go into a little bit more detail. Have I been really talking for 18 minutes? Yeah, pretty well. Okay, wow. So anyway, we can turn this into a sample process. And what I want to do is just focus on the sample process. I'm going to show you an animation of that, and then I'm going. Animation of that, and then I'm going to wow, 18 minutes. Wow. So, time flies. Let's see. So, I'll just cut to the chase. So, one has to define a number of different mathematical quantities. I don't have time to do that. Basically, this is the theorem at the end. So, one can show that we can actually compute the likelihood for an arbitrary Markov process of this form of. form of any particular genealogy that's generated through sequentially sampling. And what turns out to be somewhat miraculously to me is we get this form appearing, the same form that appeared in the Voltz, Coelho, and Rasmussen approach, with three modifying terms. And if we, and these are to do with events that occur at coalescence points, at sample points, and also at direct descent events, which I haven't defined, but I'll. Descent events, which I haven't defined, but I'll talk more about if you're interested. Comparing this with the original paper that I mentioned before, papers that I mentioned before, we see that they're quite similar to one another. There's two terms that differ, one of which depends only on the data, and so that's not really relevant from an inference point of view, and one of which represents a correction due to the possibility of direct. Due to the possibility of direct descent. And interestingly, whereas in the original formulation, lambda and n appear only in this combination and are therefore not individually identifiable here, they become individually identifiable. So I think this is interesting. The dynamical approach to thinking about genealogies allows us to derive exact expressions for the likelihood. And when we do that, we discover that existing approaches are actually very good. Existing approaches are actually very good approximations to this exact form for reasons that weren't evident at the time. And a number of the different approximations that were believed to be necessary for these earlier expressions turn out not to be necessary. So I'll stop there and I hope there are some questions. Great. Thank you, Aaron. I think we're right up against time. So I think unless there's a very quick There's a very quick and pressing question. I have a quick question. I don't know if it's great, Erin. Thanks. I'm wondering, how generalizable is kind of that likelihood expression for structured models? That's a really great question. So what happens, it's more complicated, and we're working on that right now. I think that expression will, there'll be recognizable elements of that expression in the more complicated. Of that expression in the more complicated general situation. It is considerably more complicated, though, to deal with the structured population in a fully stochastic context. I'd love to talk with you more about that if you want at the break or at the discussion. Great, yeah. And so I do encourage anyone who does have other questions to join breakout session or discussion session two. Which will be led by Aaron after the remaining three talks. So you'll join, I'm sorry, you'll join, this is session two, you'll join the breakout session number one, which will be with Erin. So there'll be plenty of time to discuss.