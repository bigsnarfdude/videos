It is indeed bittersweet to give the last talk of this conference. It's been a great conference. I want to thank Jason and Chelsea again. It actually happened yesterday, but there's no reason we can't do it twice, even though Chelsea's not here anymore. So let's thank the organizers again for that. Great conference. Okay, so. Okay, so the topic of my talk has something to do with Wiekoff algebras, which I don't think have come up in any big way. Certainly they haven't been defined. And the last talk is not supposed to be scary. So I'm going to try not to define them at all, but still give you some idea of why you might care about them. But for the first part of my talk, it will just be. But for the first part of my talk, it will just be reminding you about some things about Hof algebras to set the scene. So this is joint work with Rob Juan and James. And the main theorem I'm going to talk about is, it's about three years old now. It's an unpublished paper by us, but I'm also going to mention some work in progress that's continuing the same theme. Okay, so suppose H is a Hofalgegral over K, so these have cut. Algebra over k. So these have come up a lot already this week. But just to fix some notation, you have some algebra given by multiplication and a unit. And you have a co-algebra given by a co-multiplication and a co-unit. And I'm going to use some less loopless notation. So delta will send H2, this H1, that's our H2. And you have an antipode. So you require delta and epsilon to be algebra homomorphisms, and there's some axiom for S that I'm sure you've seen, and if not, I don't think it's enough that you can draw. Okay, so the goal of what we were doing was to generalize some results on infinite-dimensional Hof algebras to the weak case and also some other Hof-like structures. Hof-like structures. But first, I want to start with finite-dimensional Hof algebras and then infinite-dimensional, and then go to the root case. And it's kind of nice that my talk bookends the conference with James's talk, the first one, giving some open problems, which included a number of these problems about infinite-dimensional Hof algebras that are motivating what we are doing. So, but that was four days ago. So, I will. So, I will kind of restate what all the problems are. And some of them are things that maybe James didn't talk about explicitly. Okay, so first, let's consider the case where H is a finite-dimensional F algebra. And there's tons of work about this, lots of results of trying to classify those, which is another direction. But one thing you can notice about a finite-dimensional Hof-Alder. You can notice about a finite-dimensional Hof algebra is just as an algebra, it is far from being some kind of arbitrary finite-dimensional algebra. It has special properties in some way. And ultimately, I feel like, well, of course, those come from the fact that you've got delta and epsilons by definition, but ultimately, I feel like they're related, especially to the fact that this gives you a tensor structure on modules. So I'll get to that later, but first, let me just describe some of these special. Describe some of these special properties about finite-dimensional alpha algebras, which are all well known. I didn't try to attribute these. So, first, H is a Frobenius algebra, so the vector space dual of H is isomorphic to H as left modules. Or as right modules. That turns out to be an equivalent condition. Turns out to be an equivalent condition. So, in particular, so H is self-injective. Okay, so for the five-dimensional setting, dualization interchanges projective and injective. So, this is injective, so H will be injective in this case. Some more properties we have. So, we have self-injectivity. Properties we have. So we have self-inductivity, we have more. So let us consider the trivia module. And this came up in several talks. I remember it was definitely in Frank's. So this is the module where the action is given by the co-unit on any scalar. Then we have there, there is a unique left inch. Left integral. So the notation is actually an integral sign, and this is an element of the Hof algebra, and such that as a left, this spans a one-dimensional module actually, which is isomorphic to the trivial module, as left modules. Well, this is unique of the scalar course. Let me not write that. And so, another way of saying this is if you take K to be the trivial module and you did comms to H, then there's exactly a one-dimensional space of those, the image of the integral. And of course, It's trivial that higher x from k to the h, k to h are 0 because h is self-injective. So that's trivial. So there's something nice homologically happening there. So what else? There's an Akiyama automorphism. So, any Frobenius algebra has one. You can define it in terms of the bilinear form that's equivalent to this. But let me not give the definition of it. Let me just show you that in this case, you can get it in another way through hot child cohomology. Not next. So, if you work with the enveloping algebra of H and take Homs from H, so here I'm taking the developing algebra, H tensor H op. So, an HE module is the same thing as an HHPI module. So, if you take the canonical HHP module structure and The canonical HH bimodule structure on H and let it be in the left HE module that way, then this is isomorphic to H as a bimodule, but with a twist by an automorphism on one side. And that automorphism is the Nakiama automorphism. So you can recover the Nakiyama automorphism through this Hockshell cohomology group. But it's just the zeroth cohomology. And finally, I want to letter these, actually. Say, of course, B and then 3. Say, of course, B, and then 3 comes after B. Okay. Numbers for sections, letters for these properties. Okay, let's see if I can actually remember them. One more thing. So any Frobenius algebra has an octavo automorphism, but in this case, you can also recover it through some relation to this integral. So it turns out that there's a formula for mu. For μ. So μ is through some automorphism ψ, which I can't write, composed with the second power of the antipode, which is always an algebra automorphism, where so this i is what's called the winding automorphism of a certain one-dimensional module. So let me just write it like this. So it sends a general h to Sends general H to, which side am I on? Pi 0 H1 times H2, where pi 0 is the map from H to the one-dimensional module, which you get by modding out by the right annihilator of the left integral. Okay, so this integral is by definition this, or it's a non-zero element in this. Non-zero element in this, but this gets a right structure through here. So this is actually, the case span of this is actually bimodule, and it's trivial on the left, but not in general on the right. And so when you take its red annihilator, you get some, you get some one-dimensional module here. And using this map to define a winding automorphism, μ is related to that winding automorphism. And that's just some adjustment by S squared. Squares. So it's a very nice formula relating the integral by Manach Yama automorphism. And I could go further. There are other things too. There's what's called Bradford's formula for the fourth power of s, which this is sort of a step towards that, which relates the fourth power of s to integrals in h and also integrals in h duals. But let's just stop with these problems. So in a very nice paper by James Ding Liu, Chen Zi Wu in 2007, they showed how you can give an analog of integrals in the infinite dimensional case. And so the idea is all of these sort of properties should be true for an infinite dimensional. For an infinite-dimensional Lehof algebra, if you figure out the right way to say them. And you can't use these properties as they are. A Ferminius algebra is by definition finite-dimensional. So there's no chance that an infinite-dimensional hop algebra is Ferminius. But you just have to figure out the right way to generalize these things. And in every case, it's just replacing a Hom by an X. So let's see how that goes. First, First, any questions about the finite dimensional case? So I'm a little worried that there are very few examples in my talk. Partly that's because I don't want you to worry about weak, and so I don't want to give a lot of examples of weak Hof algebras. But examples of Hof algebras have come up all week, and certainly finite dimensional ones, group algebras, groups of the Taft algebra, infinite dimensional ones, there's all sorts of quantum groups that have come up. That have come up. So, those are things you can keep in your head. My talk was first. If I was earlier in the week, I would worry more about not having done examples. I should try to leave that for a moment. Well, I'm not going to leave something that's half erased. That's not going to help anyone. And it's going to be recorded, so someone can just go back. Just go back and magically unerase if they needed to. Okay, so now I want to review how you generalize all this to the infinite dimensional case, not work of myself. Okay, so now H is an infinite dimensional half algebra. So So, first of all, the analog of A, it is conjectured, let's make it an Ethereum. So, there are some non-Ethereum infinite-dimensional Lehof algebras, which are a little more nasty. So, the nice properties are expected to hold only under some kind of fine-tune assumption. So, that's maybe the theory nice our assumption there. So, it is conjectured, and James mentioned this. This, that the injective dimension of H is finite. So that would be an analog of, in the finite-dimensional case, having injective dimension zero being self-injective. It's also conjectured that you have, it's called the AS-Ornstein condition, James also mentioned. So when you take x from the trivial module to h, you get 0 when i is not the injective dimension and something one dimensional when i is injective dimension. So these both obviously generalize the finite dimensional case where it's just that d was zero there. And together, so this is So this is these things are the Brown-Gooderall conjecture. And this certainly is proved in some cases. So this is true. This is true for want to get the right. I want to get the right hypothesis. Affine Ethereum PI algebras PI-Hof algebras. So, Chancy Wu and James two thousand three. But in general, still open. But all the examples we know satisfy this conjecture. But there are special things you can do in the PI case that make the homological algebra doable to actually prove this. Okay, what about an analog of C? So we could define a homological integral and And instead of om, you just define it to be x. Let's just be loose and say this. So the integral is any non-zero element in this x space, which of course is one-dimensional by this condition. Ah, let me say this. So now assume H is A squared st. So we don't know whether that's true in general, but for the rest of the properties, let's assume it's true, conjecture to be true, and then see what's known. So you can define this homological integral. And then when you take the dth hot shallow cohomology from H to N G, you get again Again, H is a bimodule with some automorphism twist on one side. So μ is this Nakian. Now it's defined to be the Nakyamu automorphism. Some generalization of Nakiana automorphism, because H is of course not rebenius. And finally, we get some formula that tells you how the Nakuyama automorphism is related to the integral. So we have, it's actually the same formula, S. The same formula, s squared compos, where psi is actually the same thing. I can just write down exactly the same. Where again, this pi naught is a map from h to h ma to write annihilator at the end of a row. So it's a very, very, in some way, simple and beautiful generalization. And let me say these last properties are due to round and jang. Are due to round and j no weight. The definition of the integral is wu, wu, and j. I guess it should be lu, wu, and j. Okay, so again, all of these properties support the idea that Properties support the idea that somehow half-algebras should be very special as algebras. Having the co-product tells you, because of course, AS-4 schemes is something about an algebra. Well, an algebra with a structure on K. But that could arise if, I mean, there are many ways you could have an algebra with a structure on K. It could be graded or vocal or something. And so somehow this A.S. Oristine thing comes first. Somehow, this Ace-Ordstein thing comes for free, maybe, conjecturally. And when it does, we get these nice other properties, including an octioma automorphism. Okay, um, so I'm almost ready, I guess, to head towards the weak case. Towards the weak case. It's a bit of a fortunate name. I mean, if you generalize something, you know, you don't usually want to use a pejorative. You can avoid it. But, you know, it's not our decision. It certainly is a weakening of the axioms of Hof algebras. And there are so many different kinds of structures that involve Hof somehow. So, like Hof algebra. So, like Hof algebroids and Hofish algebras, some of which I don't know what they are. So, I can't really say that weak hop is the worst of them. So, anyway, that's the name we're stuck with. I don't need this anymore. Okay, so to motivate the Hof algebras, I want to talk about the monoidal structure. The monoidal structure. So the goal is to say it again: generalize A through D or any other interesting properties of an algebra to more general Hoff-like algebras. And we started with And we started with WeCoff algebras basically because the year I was in Seattle, they became the subject of James's seminar. And I don't know whose idea that was, but it was a good idea. So like I said, I don't want to define those yet, and maybe not at all. First, I just wanted to motivate them in terms of monodal categories. So for the moment, I want to go back to the finite dimensional case. I want to go back to the finite-dimensional case. So, although most of what I'm about to say holds in the infinite-dimensional case, so suppose H is a finite-dimensional Hof algebra again. So, here are some more properties I haven't talked about. So, if we let H mod be the category of finite-dimensional modules, or finitely generated, it's the same thing in this case, then this is minority. Then this is monoidal. I'm not going to define a monoidal category precisely, but it's just a category where there's some natural operation that combines two objects to get another. So for two modules, M and N, and this already came up in Vance talk and others, I think, where for two modules, Where for two modules, the way you get a new module is just by tensoring the word K. And the action uses the coproduct. So the way H acts is take the coproduct on H and then have its components act on the two components. Okay, so this is a very beautiful example of a monoidal category. Category. And let me tell you some properties of this bifunctor, which takes n two H modules and returns an H module. So this has lots of nice properties. So it's bilinear on morphisms. It's biexact. So it's it's So it's exact under exact sequences and either coordinate. We also have a unit element. Well, this is actually part of the definition of a novel category I'm not giving. There is a, it's called a unit element, which when you tensor any module with that unit, you get the original module back in some natural way. So in this case, one is just the trivial module. So it's easy to see that when you tensor over k, the trivial module, nothing happens. This thing is associative in the canonical way. That's also part of the definition of monodal category. There's some special property that the endomorphism ring. The endomorphism ring of this object, and the category is trivial, it's just the base field. And all of this stuff just uses the bimodal structure, I mean the bi-algebra structure of H, that it's algebra and co-algebra, but we haven't used that there's this antipode. And the antipode gives you duals. So for V, some finite dimensional module over H, we have a left dual. A left dual, which is the usual notation for duals, and a right dual. And the notation for that is dualization on the wrong side. Such that, so there are various ways to define these, but the important property about them is that they give you some adjoints. Adjoints. So tensoring with V star is right adjoint to tensoring with V. And tensoring with star V is left adjoint. Okay, so tensoring with any object has left and right adjoints in there, and they're given has left and right adjoints and they're and they're given by tensoring by the left and right duals. And the duals come from the item code. The item code, the adjoint. No. It's antipode, the one that's called S. Okay, and how are these defined? So the left dual is just on from V to K, but so what is the action of H on some F applied to some? Apply it to some B. You just use the antipode. Apply it to H before you act on B. And the right dual is similar but using S inverse. Okay, so you need these antipodes, you need the antipode and its inverse. You need the antipode and its inverse to get these left and right tools. So it turns out that all of these properties are important things in the theory of monoidal categories, and this is called a tensor category. And uh it ha has even something additional uh called a fiber functor. So I want to find a fiber functor, but um fiber functor is just some functor to vector spaces that preserves the monodal structure. So all the fiber functor is saying in this case is whatever you're Is whatever your monoto product is in HMOD, it actually just comes from tensoring over k. So things, objects here have underlying vector spaces, that's obvious. And we're just tensoring the underlying vector spaces and then getting some module structure on that. So that's all we're saying with this fibrifunctor. And in particular, it's saying that, I mean, generally, monoidal categories, you have to say how. Monoidal categories, you have to say how the product is associating, but here we're just using that tensor product of modules over k as canonically as an associative operation. And the reason why I wanted to say all this is that there's actually a reconstruction theorem which says that if we carefully define a tenant, If we carefully define a tensor category, which I didn't, but it's basically a monodal category that has all these properties, then let's say, which says tensor category with fiber functor is H mod for a Hof algebra H. Finite dimensional, because I'm just doing that setting right now. That setting right now. So, this is one way to say, kind of just explicitly, categorically, what a Hof algebra is. It's exactly what will give you a monoidal category with certain nice properties, namely all of these. And then with a fiber functor saying that the monoidal product comes from just tensoring over k. And I restricted to finite dimensional. There's some reconstruction theorem in the infinite dimensional case, which is a little more complicated. I don't want to try to write it down. But the general idea is that all the changes, if you replace h with something infinite dimensional, so now h is infinite dimensional. And we take H mod to be all modules. We could also take finitely generated ones, but that's not really that helpful in this case. Then all these properties hold. All the above holds. We have a monoidal product given by the same formula. We have that one. The only thing is about duals, except About duals, except V has left and right duals only if V is finite dimensional. So only the finite dimensional modules in the category will have those duals. But otherwise, we get all the same properties. So we'll get the fiber functor. Unfortunately, the reconstruction theorem does not. Unfortunately, the reconstruction theorem does not, it's not as simple as just saying assume all these properties except only finite-dimensional things have duals, then you must have the categories over a possibly infinite-dimensional Hop algebra. Just reconstruction theory for infinite dimensional things, you have to work with co-modules instead. So I'm not going to touch it. And this is all in the book, the very nice book, by it's an EGNO book. I won't remember all of the authors' names off the top of my head. Authors' names off the top of my head, but it's the Bible for tensor categories. Okay, so what is a Wykoff algebra then? So in this language, so now suppose we have we have a tensor category. We have a tensor category. Again, I didn't define that, but it was all of these things and duals for all objects. So I want to go back to the finite dimensional case in some sense. So part of the usual definition of tensor category is to have all the objects have finite length and HAM spaces be finite dimensional. So when you have something like this, it's called a ring category. It's called a ring category, but in any case, let's go back to the tensor category thing, but generalize this fiber functor. But instead of a fiber functor, we assume a functor f which is called colour. But now the underlying structure on an object, instead of being a vector space, it's going to be a bimodule over something semi-simple. So for our finite dimensional semi-simple. I haven't worried about the properties of the field K. I don't think it matters. But if you wanted to assume K is algebraically closed, that means it would just. Closed, that means you would just be finite products of matrix frames over 10. Then the reconstruction theorem in this case, if you do it, gives you a Liekhoff algebra. So the only difference is instead of having an underlying vector space, well in fact, we will still have an underlying vector space because ours is a K-algebra. But instead of just using the underlying vector space to define the monodo product, you're using an underlying bimodule structure. And this functor then says that your product is essentially tensoring over R, which if Over R, which if you have two RR by modules there, you get another RR by module. And that's the thing that underlies your Winodo product instead of just sensor over K. And in some sense, it's a minor change, but if you go back and see what that means for axioms of this thing, you get something that looks very unintuitive. And in fact, there's many different ways of writing the axioms, and the ones that seem to be accepted now are just one choice. Or just one choice. And if I give them to you, it won't help. But I can just say that the main difference is in the unit and the co-unit. So you still have an algebra, it's still an algebra, it's still a co-algebra, but the way they're related is weakened, so that the co-product does not send one to one. And the co-unit is not multiplicative, but there's some kind of weak multiplication. But there's some kind of weak multiplicativity. So, axiomatically, it's a bit of a strange structure, but when you think of it in terms of tensor categories, I think it's quite natural. And this is certainly one justification for why you would want these. So, the people that study tensor categories are especially interested in fusion categories, and this is the case where your tensor. And this is the case where your tensor category has all of its objects are semi-simple objects. And in that case, they've actually shown that any such fusion category always has a functor like this for some r. So in some sense, any fusion category can be described as in category modules over a Wield Koff algebra. It's not quite true if you just have tensor category, but if But it shows why finite-dimensional Wiekoff algebras are something you would want to look at. And infinite-dimensional ones come from, well, they'll satisfy the same thing. They'll have a functor like this. You could get them from some kind of infinite-dimensional reconstruction, or you just use the axioms that people came up with and now just take them in the infinite-dimensional case, and you get something interesting. I guess I'll say one reason why you might care about the infinite dimension. I'll say one reason why you might care about the infinite-dimensional ones because it's related to some other things that came up this week. And this is recent work of Walton. Oh boy. So Chelsea, Elizabeth Nicks, Rob Wong, and Hong D. And so it says that so there's a lot of results about Manines universal coacting by algebras or a Hof algebras. And given a nice enough algebra, you would hope to find a co-acting bi-algebra or Hof algebra, which is universal in the sense that it surjects onto all other co-acting algebras. And I forget all the talks this came up in this week, I think in Kent's at least. But if you do this construction, starting not with, say, a regular algebra, but with Algebra, but with Clavier algebra. So say A is a path algebra of a quiver, mod sum relations, and that this is twisted Clavio, to equiver, then the most natural co-acting thing, this universal H that co-acts. So you have So you have some, so what this is, you have some collection on the right and some collection on the left plus axioms that say that those are compatible is a Wiekoff algebra. Okay, so to be fair, as I realized in talking to someone this week, they set up their theorem. Up their theorem so that they're only looking at the universe of weak Hof algebra that coax. So it's a weak Hof algebra by definition. But I think it's the natural thing to look at in the case where your algebra has eidem potents. Weak Hof algebras naturally occur on algebras that have eidempotence structure. And so they're the natural things, I think, to co-act on something with eidempotens, like a path algebra. Path algebra. So, in particular, they show that the thing that co-acts on a path algebra is what's called Hayashi's phase algebra, which is also defined on a quiver, and that if you have a factor here, then you just get some factor of Hayashi's phase algebra, which is a Wykov algebra. So I really liked this paper when Rob told me about it in August because it gives another motivation for why he would care about Lykov algebras, and particular infinite-dimensional ones. So they do seem to come up quite naturally. Seem to come up quite naturally, which you would never guess if I showed you the axioms, which I am not going to do. I decided. Okay, so now let me get to Ethereum. Any questions at this point? One quick question. Yeah, is it are the axioms already nasty if you just say R is a 2x2 matrix ring over K? They could be. Yeah. But there are examples. I'm not giving you any examples, but there are easy to write down examples. So the simplest one is: so if you have a finite group, So, if you have a finite group and you take the group algebra, that's a Hof algebra. If you have a finite groupoid, so you have a category with finitely many objects, finitely many morphisms, where every morphism has an inverse. Then you can take the groupoid algebra, same definition as the group algebra. And that is naturally a weak Hough algebra with the same definition of product and co-product as for the group algebra you would take. But you just see that. But you just see that it doesn't satisfy the Hof algebra axioms, it satisfies the weak ones. So I think that's a kind of natural finite-dimensional example. But coming from this point of view, like saying if I replace k by the simplest possible r, actually the simplest r would just be k times k. And even in that case, I don't think it's much simpler than just the general thing. Things. Okay, so let's do actually a theorem that I had some part in, unlike anything that came so far. So this is again Rob, myself, and James. Okay, so let me make H. Metherian. I don't maybe need that for. Theory in. I don't maybe need that for the whole theorem, but maybe for part of it. So let's just throw that in. Over K, of course. So for all projective modules, P and all I We consider the functor x to p, and this is exact. But not on all modules, just on all finite dimensional H modules. So you take an exact sequence of finite dimensional modules. The x functor, the x die functor, is exact. So this is a little weird, but if you think of the A. S. Gordstein condition, so if you have something A. Gordstein, If you have something a squared stick enough to mention D, then only the X to D to H survives. We're just making a minor change, letting it be projective here. So of course, if there's only one X to D, then it's going to be exact, because from the long exact sequence, all the other X's go away. So somehow, this is a weak version of the Gordstein condition, seeing that all of these, for all i, you get an exact sequence on X. But you could also But you could also get that by, say, taking some A's coordinate algebra and taking a direct sum of them. Maybe they have different dimensions. So you would still have the exactness of these x, but maybe more than one hex functor will be non-zero. So that comes directly from the tensor structure on the Wyckoff algebra in some way. And then the second thing is if h is finite, H is finite over an affine center. Then you can settle the Brown-Girl conjecture. So in this case, the injected dimension of H is finite. We call it D. And we have the Skorenstein condition. But we want to state it in a slightly different way because. It in a slightly different way because k is not the correct version of the trivial module and the weak pop algebra case. So we just state it like this x i from b to h 0 when i is less than d. Already said the thing I wasn't supposed to say. Then is d, and h is a direct sum of some AS Gorenstein algebras. Do A1 to AN where for each AI is AS Gornstein of dimension DI. So that means that X J. J from something finite dimensional to that ring is zero when J is not the injected dimension, and it's to something finite dimensional when it is for all finite dimensional v. Okay, so you could phrase this in terms of a trivial. There is a version of the trivial module for Wiekoff algebra. It's not necessarily one-dimensional. You could just use that instead, but it's easier just to say for all finite-dimensional modules. It's easier just to say if we're all finite-dimensional modules, the x functors are almost all zero, but then there's one s functor that sends finite dimensionals to finite dimensionals. But we can't just get one a scoresting thing here. It has to be a direct sum, because unlike Hof algebras, a direct sum of weak hof algebras is naturally a weak hof algebra. That's kind of a nice thing about it. There's more flexibility about constructions like that. But that means, of course, that any direct sub. means of course that that any direct sum of Wyckoff algebras will come up in the theorem so so we can't avoid having direct sums of it as words in things of possibly different dimensions so I was going to write something about the proof but I'm definitely not going to do that now I just don't have I don't have time and I'm not going to run over in the last talk that's just really dumb no no one wants that so let me just talk through the So, let me just talk through the proof quickly. So, the reason I stated this in two parts, we also do that in the paper, but the first part really is a very quick proof that just comes from the fact that the Wyckoff algebra has a monoidal structure. And really, you just use the fact that finite-dimensional modules have duals and play around with some adjoint operations. And this falls out. Very nice. Very nice. So, this, in fact, this is a property that holds. We don't need to solve the Brown-Gooderhold conjecture for this. This is always true just from the fact that you have a tensor structure. But somehow it's not enough just knowing that all of these X are exact. And so, in the case where you're finite over an affine center, then you can use some dualizing complex magic. So, you have what's called a residue complex. Complex, and it's the same technique that was used in the infinite-dimensional non-vi case to prove that the algebra is finite. Injective dimension in Gorenstein, just in this case you have to work a little harder and you just get direct sum of Gordon's things instead. So, but two is a consequence of one. One really uses the tensor structure. Two really becomes a ring theoretic result about algebras that have property one. About algebras that have property one. So it doesn't just apply to weak Hof algebras, it applies to other things that have a tensor structure or something called quasi-Hof algebra where you mess around with the associativity relation. Again, without knowing the definition, the theorem just holds verbatim for those just because they satisfy one for the same reason that they have a tensor structure that's nice. Okay, but this is sort of A and B, and I wanted to do C and D as well. So the last stuff is work in progress, so I left three minutes for work in progress so that it's not a talk I could have given just three years ago. So there is a version of homological integral. Let's assume that H is weak off. And A S-Gordonstein. Not a direct sum. So we know it's, we hope that all Wyekhof algebras are direct sums of A.S. Gordonstein, but then we just, if we want to go farther, we might as well work with one of the sum n's. Then we can define this homological integral in a very analogous way to before. It's just we use the unit object here, whatever that happens to be. Here, whatever that happens to be. So, in general, it's some finite-dimensional module over H, not one-dimensional. But define that in the same way. This is just a right module, not a bimodule, but it's only the right structure we really cared about before anyway. The left structure was trivial, so it wasn't useful. So, this is at least a right module. And you again have some. And you again have some hot shelf cohomology. That works out nice. The difference is you don't necessarily get H with a twist on one side. You get an invertible bimodule when I is D and it's zero when I is not D. Ah! I am going over. So, again, very clear analogs of what happened before. And finally, D, if you'll indulge me, one more line. This bi module U is related to the integral. So it's the integral tensor in the right module structure, the right tensor structure you get, because H is a weakoff algebra, with some twist of H. With some twist of H twisted by S squared. So this is just, I can't state D the same way as before because we don't have a not diamond onomorphism if this is not of the form H1 mean. But in general, still, it's related to the integral. You tensor these two right modules. That gives you a right module, and there's still some left structure coming from here. So that gives you the flow bi-module structure of u. So it's really an analogous result to what happened before. Okay, so those parts. Okay, so those parts are anything about homological integral is work in progress, but it does seem to all go through in a similar way as for regular and fifth-dimensional model algebras. Okay, so let me stop there. Thanks very much. Any questions? I mean, at times can can you turn out to be an honest like twist by non- Yes, like twist by not. Can you characterize what cases that happens in? Possibly. I'm sure that happens in some good cases. These examples that come from quivers, so when you look at a twisted collabio algebra, which is a path algebra with relations, in general, their Nachema bimodules are like this. Like this. So I think once you start having item potents around, you expect something like this to happen. So maybe you can characterize when it doesn't, but I think this becomes more natural anyway in this setting. Any other questions that you're online? Yeah, hi Nan. Hi, Brian here. Um in your in your serial part In your theorem part two, you know the one where it was finite over an FI center and then it was a direct sum of A S Born schemes and finite injected dimension. Yes. Is the finite injected dimension equal to the GK dimension of H? I think we might have proved that. Yeah. Yeah, so we proved that and we proved that we, you know, it's Austin's a regular Cole Macaulay, all those good things. Macaulay, all those good things in that case. Any other questions? Let's thank Dan and all the speakers for the comments.