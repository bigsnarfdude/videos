Okay, great. So on the theme of movement and symmetry in graphs, though I'm not going to make it explicit in this talk, most of these problems are sort of inspired by mathematics that we come across when studying quantum walks. And one of them, there's actually an explicit paper, and I actually have a screenshot of the paper. So it'll be very clear where these problems come from. I was going to start off by introducing graph eigenvalues. Graph eigenvalues, but then I looked at the MITs and felt that was maybe a bit overkill. Right? So let's just do a warm-up. We have a graph, X, because Chris Godzel is in the audience. I didn't want him to be upset by APG. And now we look at the adjacency matrix, which is the 0-1 matrix indexed by vertices of the graph. And you have a 1 when they're adjacent and a 0 when they're not adjacent. It's a symmetric matrix. Adjacent. It's a symmetric matrix, so it has some eigenvalues. So now I have a graph, and here is its characteristic polynomial that I've computed for you. I've even factored it, and then like an expanded format. So let us warm up by doing something. Oh yeah, so I taught an algebraic methods course in algebraic methods and combinatorics course, and this is one of the questions I put on my assignments. So let us warm up. Given this day, the characteristics. Thing, the characteristic polynomial. What is the number of vertices, edges, and triangles? 11. 11. Vertices, edges. What? I'm just guessing. Did you guess about? Did you just write them out on the slides? Oh no, I take it to the ten to twenty. Either eleven or twenty-two. No. No? So 11 is the number of vertices, and then you have the next coefficient, and this is the number of edges. Is it the T10? What? The the next the T10 is 0? Yeah, it's always 0 because um yeah, if you look at the d the um determinantal sorry? Determinantal, sorry, the trace is in fact zero, so the coefficient of t to the n minus one is always zero, so that term always gets skept. We know there are 11 vertices because this thing has degree 11. There are 25 edges because the coefficient of t to the 9 is 25. Yes? I agree, I think that I said the wrong thing. Oh, I didn't hear. I'm sorry, because you can't give me the answer. Okay, you have to work number of triangles. Yeah, so if the number of triangles is captured by this number, this number should be six times the number of triangles. Every triangle is counted three times in the basic subgraph expansion when you look at the determinantal expansion of the graph. So we know a lot about this graph already. 11 vertices, 25 edges, not that many triangles. Not that many triangles. Crap. All right. So, show that it is not a regular graph. So, is this thing a regular graph? Well, it seems to imply no. Okay. How do I convince you it is not a regular graph? It has 25 edges and left edge. Yes, very good. Yes. So, the other way that you can know this is, yeah, so even if the number Yeah, so even if the numbers would work out that it would have had even number of vertices or even number of edges, what you can always do is just say, suppose the graph were to be regular, what would be the degree? Well, the degree would have to be the average degree. You can know the average degree because you know the number of vertices and you know the number of edges. So you can compute that number. And now a graph is regular if and only if this average degree is an eigenvalue. So whatever number you got for the average degree, So, whatever number you got for the average degree, if it is not one of these things here, the roots, then it is not regular. So, we can, in fact, determine this thing is not regular. So, next, if it's not regular, it has some number of degrees. And at this point, it was determined that it was too difficult for the homework assignment if I let the students determine how many degrees and how many and what they should be, because it is a special case of an open problem. But anyway, Problem. But anyway, what they can do is if I tell them that there are two degrees, then they can show that one of the degrees is 10. And you do this just by some counting arguments, also just by looking at coefficients of the characteristic volume of y. Okay, and then the next two things we're not going to do because this involves some argumentation. But basically, what do we think the next line is going to be? So this x is obtained by adding a vertex adjacent to. By adding a vertex adjacent to all vertices of some 10-vertex graph x prime, which has no triangles or four circles. So what is x prime? It is the Peterson graph. Right, so as a simple exercise in reading the coefficients of the characteristic polynomial and considering what these numbers count, you can figure out a lot about a graph. And in this specific case, you can And in this specific case, you can figure out this is the only graph with these eigenvalues. Of course, that is modulo, the part where I told you that there were two degrees. So this is sort of like the warm-up exercise for the first open problem, which is a long-standing open problem about graphs with three distinct eigenvalues. So if a connected graph has just one distinct eigenvalue, then it has no edges. Then it has no edges because it just has to have zero, and then it's because the trace is zero. So then it will just be the zero matrix. So what if the two distinct eigenvalues? If you have two distinct eigenvalues, there are many ways to show this, but the trace is again zero, so the sum of all the eigenvalues should be zero. It always has a positive one due to the paraphramius theorem, so it then. Due to the parallel for Benius theorem, so it then has to have a negative one. So the second eigenvalue is already negative. So now you can show by interlacing that it has no non-edge. Because if you had two vertices that induce no edge, it would force the second eigenvalue to be non-negative. But it's not the case. So also, through a simple argumentation, life is very boring if you only have two distinct eigenvalues. So if it has three distinct eigenvalues, Has three distinct eigenvalues, some stuff happens. In particular, if the graph were regular and it has three distinct eigenvalues, that's a class of graphs that some members of the audience know a lot about, that's strongly regular graphs. Robert. Yay! Okay. And I hadn't considered this, but apparently, if it would be irregular, apparently anything can happen. Not really anything, but let me. Really, anything, but let me elaborate on what I mean. There's this open problem of decaying that seems to make sense in some sort of way. That do connected graphs with three distinct eigenvalues have at most three different valencies. So you have to look at the degrees of vertices in the graph, how many different numbers could there be if you only have three distinct eigenvalues? So, yeah, I don't know what was the original motivation. Maybe this three is. Motivation, maybe this three is very similar to that other three. It seems to make sense, but it also seems to be quite difficult. There are only finitely many such examples. So there are some constructions how you get three distinct eigenvalues. If you take the cone over a strongly regular graph, like we had in our first slide, that does work with some number theoretic stipulations. Stipulations. And then there are also some other constructions that have this. The connected here is very important because if you allow disconnected graphs, you can make any sort of weird things you want. Yeah, Gaza. Finally, many examples of what, huh? Of graphs with three distinct eigenvalues and exactly three valences. So that's known? No. There are finitely known examples. It is open to find an infinite family of such graphs. Graphs. And it is not, and in particular, it's not ruled out that this thing has four different values, but no such example exists. So on the next slide, we have an example, a little morsel from Van Dawn, Kuhlen, and Xia, where they have a putative graph that may or may not exist. So it's possible that there is a graph on 51 vertices, and the spectrum is 30, 3 to the 20. 3 to the 20, and 30 copies of negative 3. Okay, so that's okay. Does it exist or not? So they did actually a lot of computations to show that such a graph, it has to have four different valencies, 13, 18, 34, and 45. And not only that, if you partition the vertices based on their valencies, that partition is equitable, and this is the quotient. So I think this is the right ordering. So I think this is the right ordering. So if you're a graph, sorry, if you're a vertex in this graph and you have degree 13, then you have two neighbors that also have degree 13. You have 10 neighbors that have degree 34 and one neighbor who has degree 45. So this is quite determined. And actually, a huge part of the graph is already determined. Because I think for one of the induce subgraphs here, there's only one choice of graph. Graphs here, there's only one choice of graphs that could go there. And even this 13 thing, it's degree two, it has to be a union of cycles. So there are like very few choices. Actually there are many choices, but some of the parts of this graph are hugely determined. So when I set this assignment question in my class, I asked a postdoc across the hall from me, Tilcher Baus from Amsterdam, to check my question. And he got so interested, in particular. And he got so interested, in particular, in why I wouldn't ask the students to prove there were two different degrees. So then I showed him this thing, and we worked on it. So we came up with some ways of arguing about the neighborhoods and giving vertices colors depending on how many neighbors they have of a certain type. And we actually went far enough such that Kilter made a constraint satisfaction problem to solve for things that were feasible. And that thing was successful. And that thing was successful. It found millions of examples, none of which led to a graph. So then we started considering: there is a problem with this. This may be too strong. And what we think is that the partition, I think if it's equitable, the graph cannot exist when there are four different degrees. That maybe this is the thing. So to summarize this sort of classical open problem about graphs with very few eigenvalues, there are only finitely many There are only finitely many graphs with three different degrees and three distinct eigenvalues, and it would be interesting to find more, an infinite family, or maybe even more interesting to show that such a family doesn't exist. There are no known graphs with four different degrees and only three distinct eigenvalues. So I don't know why the number of degrees should be smaller than or equal to the number of eigenvalues, but it does seem to be. But it does seem to be. Is it known that you can't have five different degrees? Ah, okay. So that's an important thing: that if you have four, oh, five different degrees, sorry, yeah, also no. Sorry, I got this confused. But if you have four distinct eigenvalues, then you can have as many degrees as you want. Then it's just like anything you want. So it it really blows up at that point. This is the turning point. I I think there is a number after which you can have half of them, but I don't have it on the top of my mind. But I don't have it on the top of my mind. And it could be five, but I think it's not. Yeah, so this is a, and in particular, if you did have four different degrees, I think it is no problem to determine whether or not that degree partition is equitable. So, first of all, we don't have any counterexamples student because we have no examples period. But I think for three But I think for three different degrees, there the partition must be equitable if you had three different degrees and three distinct eigenvalues. And so this four different degrees, this is sort of where things change. That maybe now something crazier can occur. Okay, so this was a completely classical thing that just exists in the literature and I brought it here. Let's move on to some things that are more recent. More recent. So, with my students, we work on various things where we study perfect state transfer in discrete on quantum blocks, which we don't really have to worry about too much right now, except that it's a movement in a graph that has symmetry and maybe orthogonal symmetries. So recently we made a variant of this perfect state transfer where it isn't perfect, but it is very high and it is happening periodically. And what we need is to look. What we need is to look at, for the ARC-reversal model, we need to look at the normalized adjacency matrix, where you just have the adjacency matrix and you normalize the rows and columns. And then what we kind of needed was to characterize all graphs where this adjacency matrix has only five different eigenvalues. In particular, these five, and not exactly five, but I want the eigenvalues to be contained in this set. So this would be an easy way for it to satisfy our characterization. Way for it to satisfy our characterization of the peak state transfer. And it would be interesting for this problem, for these graphs to be known. And just before someone says, did you check the tables in the back of BCN? Yes, we checked the tables in the back of BCN. And we determined whether or not it occurs. And we determined all bipartite this behavior in bipartite incidence graphs and symmetric designs. And as a byproduct of that, we also found all of Byproduct of that, we also found all of those which have eigenvalues of this form. Sorry, maybe once I normalize it, it has to be one, a half, and zero. Sorry, I was thinking for a regular graph. So one, a half, and zero for the normalized adjacency matrix. If it's regular of degree k, then these are the eigenvalues. Sorry, I was thinking distance regular graphs. So yeah, this is a very specific scenario. Specific scenario, and maybe Shala already knows the answer. No, I haven't thought actually. What is normalized adjacency? Okay, so it's just the usual adjacency matrix, and I divide by the square root of the degree of each vertex in the bth row to make the rows and columns normalized. Yeah, so if it is just a regular graph, you just divide by the degree. And some of us think a lot in regular graphs is us think a lot in regular graphs as evident by various mistakes. Okay, so this is a problem that we were looking at something for quantum blocks and then we came across this completely classical thing. You don't need to know what a quantum block is to attack this problem. Although if you had only three of these eigenvalues, I don't know. Okay, so the next one is about what is the most central vertex spectrally in a graph. Spectrally in a graph. So here's our quantum inspiration. Gabriel Coutinho found this paper and sent it to me. It is not a paper in nature, even though it says nature.com, nature has many journals other than nature communication, but it is in scientific reports, which is like a tier one multi-disciplinary journal. So it is a journal like nature and science, but and also top tier, but not one of those. Good? So this is like a very I don't know, it's a very central paper. And what these people basically do is they look at graphs or weighted graphs in this case, and then they define one of the vertices to be spectrally centered. You don't have to read the article. I will summarize it in math in the next paper. Page. All right. So, again, we have our adjacency matrix. And now we take the spectrum decomposition. And now we take the spectrum decomposition, where we write A as a sum over its distinct eigenvalues. So these theta r's are the distinct eigenvalues of my A, and E R is the eigenvote projector onto the theta r eigenspace. So these are projectors, and there's a unique way of writing this spectral decomposition. Okay, so the centrality measures, it's not really apparent if you read the paper, but I swear I translated correctly. But I swear I translated correctly if I can offer a proof. The centrality measure of a vertex V is the V V diagonal entry of this matrix. Okay, so what is it? So these are the eigenpotent projectors, and I am taking the matrix J, which is the all-ones matrix, and I'm projecting it into the Bosemisner algebra of the graph. So what will this be? It will be the projection of this. This be? It will be the projection of this matrix J onto the space of all matrices that commute with the adjacency matrix. If that's not helping, then it's just a product of these three matrices. And you can sum over these things. If I have ER, ER, ER squared is ER itself. So I'm introducing this thing in the middle. So the diagonal entries of this thing are what they're calling the centrality measures. And then the central vertex is the one that maximizes. And the central vertex is the one that maximizes this thing, the one or potential many, many vectors which maximizes this value. Okay, so it was like a lot of physics, so I didn't really understand why they have defined it, but it has been published in scientific reports. So some people have agreed that this is the correct definition for these applications, which are quantum walks. And now, maybe mathematically, we can look at what this is. So, first thing to know. What this is. So, first thing to notice is that if your graph is regular, J already is one of the eigenpotents, so it commutes with everything. So, the diagonal will just be constant. So, every vertex will have the same centrality if you're regular. So, this would be only kind of useful for irregular graphs. And the second thing is, if you have an isolated vertex or maybe a disconnected component of small size, those entries will be huge in some ER. So they will have huge centrality measures. They will have huge centrality measure, so we should maybe restrict ourselves to connected graphs. Connected, non-regular graphs, what does this mean? Well, the thing is, is there are many other choices for what is the spectral center of a graph. We have used the diagonal entries of some other matrix, but we could instead have used this one. This is the average mixing matrix of a quantum walk, of a continuous time quantum walk, and that has been studied by Chris and By Chris and Harmony and other people. And you can also rank the vertices based on the entries of the parron vector, which will just be E1 for the largest eigenvalue. There's also, you could just declare the most central vertex to be the one with the largest degree. And then if your graph was a tree, it has a central vertex or edge, which are fixed by every automorphism of the tree. So then there. So then there are questions of when do these things coincide for these matrices, for these different measures of what is central in a graph, when do they coincide and how do they compare with this thing that they have defined? And when you have such a question, and I've never looked at that matrix before, the one with the ER, J, ER, the sum, so I want to put it in the computer and see some behavior, but what should we even compute? Should we even compute? I think the most reasonable thing is to compute these other things and compare which vertices are still central. But yeah, so yeah, it's an interesting choice for spectral center. I did not understand physics motivation. However, I think it is well motivated for their application. And mathematically, it is some matrix that is fully classical. You didn't need to have ever heard of a quantum walk to define it. And it's something that maybe our methods can. That maybe our methods can reach. Okay, so last one. So the last one is more of a looser open problem. And the motivation comes from quantum stabilizer codes used for quantum error correction. Which, again, maybe we don't have to know so much about. But there are, maybe intuitively, the quantum computer will be very, the quantum computer that may or may not be built in 80 years, a universal. Or may not be built in 80 years, a universal one, it will still be very noisy. So it will require error correction, quantum error correction. And what is used there is the stabilizer states. And a specific type of stabilizer states are called graph states, where there is an underlying graph structure. And there is also an equivalence relation between these graph states. And it's a local Clifford equivalence where you apply a small polymer. You apply a small polymatrix to some part of your system. But we don't have to worry about what that means in terms of matrices because it corresponds very nicely with an operation called local complementation in graphs. So if you have a graph, sorry, now it's G. I think I'm very tired. I'm a bit jet-lagged. My apologies. But anyway, we come across G and then Rotex V. So then the look. And vertex V. So then the local complementation of G at vertex V is the graph that is obtained by complementing the neighborhood of V. So you have your graph V, and then it's adjacent to some stuff, and then in it, you delete all the edges and put the non-edges. You do not touch the rest of the graph. None of the other incidences between this group and other groups change. Only that neighborhood changes. Okay, so this does not play nicely with any of the matrices that we have used so far. So far. But perhaps you can still say something about it. And I think the least bad matrix is the sido-adjacency matrix, where you have another matrix that is not the adjacency matrix, but it is the adjacency matrix minus the adjacency matrix of the complement. So you have zeros on the diagonal, and you have a one when the vertices are adjacent, and minus one when the vertices are not adjacent. Not adjacent. Okay, so then what has to happen here? It is not that we flip a whole row or column to the opposite sign. That is just normal sidel switching where you delete the neighbors of a vertex and add the non-neighbors. That's not what has to happen. But what does have to happen is that in this matrix, you have those rows and columns, this principal submatrix indexed by the neighbors of the vertex V, and there you need to change all signs. So what do you want to do? I can make a little, sorry, now X is a matrix. How X is a matrix. I can make a characteristic matrix. It has ones on things that are indexed or both ends are in my set gamma of v. So it's just a matrix and in it there is a square block of ones. And negative ones, sorry. And then I get the other matrix by taking the entry-wise product. Sorry, it has ones on the outside. I'm very tired. Okay, so it's a matrix. There's mostly ones everywhere, except in this one component where there's negative one. And the matrices are related in some way. So, of course, this does not, even if I had written it correctly, it does not preserve the eigenvalues of s. But you still have classes of graphs that belong in the same class, and now you can still look at all possible matrices. Possible matrices that are matrices, cyto matrices of graphs in this class that are related by this operation. And what I thought would be interesting is to relax it, to take arbitrary x, where you have mostly ones and just one principal submatrix of negative ones. It doesn't have to be the neighborhood of a graph, maybe. And then in this generalization, maybe it is easier to understand what happens to the eigenvalues of this matrix when you do this operation. There are some things that Operation. There are some things that you can sort of see. That if you look at the trace, the trace will correspond with the Foulenius norm of this, and I can, in fact, move X sort of to the outside. So there are some simplifications that can occur with this operation. It is not as nice as any of the other switching operations that we have, but there are many problems about local complementation where it would be that people in quantum computing want to know for the purposes of determining when stabilizer. In when stabilizer codes are equivalent to each other, and that it would be nice for these to admit also algebraic attacks. Okay, so in conclusion, this has been three adventures in quantum blocks without seeing any quantum blocks. So we have these things, these research projects where we work on quantum blocks. And then the things that come out are open problems or things that we don't know. Or things that we don't know about just matrices and eigenvalues and these eigenvalues that could have been defined without ever knowing what a quantum walk is. So now is a purely combinatorial problem, which I hope that someone here can help with. So I will stop there. Questions for this one? It's not about the math, I'm sorry. It's about that journal. Oh, yes. So, I mean, I read the journal Science, which is inter multidisciplinary, right? Yes. In the now, so I started reading when Trump was first elected, so eight years, I've seen one paper that I could, at a stretch, say was math. Saving was math. How many math papers, if you're looking in these other journals, like, do you ever see math papers? Do you see multidisciplinary scientific journals? Well, I think there are hybrid papers. And also the other papers that appear, they're also not pure chemistry or pure biology. There are multiple fields. And quantum is sort of a natural thing because it is a thing that lives at the intersection of computer science, physics, and math. Science, physics, and math. So it is like a natural home for these things. But that paper, it was very mathematical. They at least define the spectral item phones somehow. So, yeah, so I think that in terms of pure math, no, but a pure math paper is not multidisciplinary. So that's also not in its purview. But I have seen other ones that have math and chemistry and math and biology and like some statistics. And yeah, so it is really multidisciplinary. Yeah, the only papers I've seen in science that were in any way. Papers I've seen in science that were in any way mathematical were all dealing with quantum. Yes. There was like the quantum 36 officers problem, and then the quant, you know, the quantum superiority in terms of circuit depth versus classical. And very mathematical, but. Yes. Yeah, but I think that satisfies their requirement of multi. But science doesn't require that the articles be multi. It's just they don't limit any discipline. Yes. And still no math. Yes. And still no mouth. Yes. Yeah. So if you characterize this behavior, perhaps you can also submit your thing to scientific reports. Which again is not nature, but it is another of the nature journals that are in the same category. Any other questions?