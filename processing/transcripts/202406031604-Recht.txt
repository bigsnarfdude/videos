I mean, at least the things. Wow. Or maybe you guys. It's not a competition Asia. Well, I would like to promote. We were called to promote. So I'm going to talk about some of the historical developments of medical decisions. And I think this really stems from, I've been thinking a lot about how much history, history inertia, historical inertia has great explanatory power when we're thinking about questions of like, why are things the way they are today? Why are things the way they are today? Slash, you know, why do we do the things we do, or why are outcomes the way they are? And so I had to give this talk. I've been thinking about this very broadly, but we have to do it on like medical space stuff. So two examples of medicine that I've been thinking about. One is kind of trying to understand why this idea of risk correction is used in medical risk assessments. I've been talking a lot with Burke and Deb about this. I could give a whole talk. About this, I could give a whole talk on that, but I wanted to do something much more simple about this metric that I kind of low-key hate and I had to teach about in my class, which is this AEC-ROC curve. You guys might love it. This might be a little provocative, but I don't know. I've actually talked to a physician who's like, I love that. I get it. It's like, totally, like, that's my bread and butter. And this stems from, I went to this conference at MGBA, Mass General. At MGB, Mass General, it was like MIT, MGB conference, and everyone has their posters. And literally, in about 95% of them, they're like, look, my method is better because this AEC ROC is like higher than spade of the art. So like, my, you know, random force should now be used. So I was like, okay, well, I'm developing this course. I have to teach on this. Why don't I explain what this is to these people? And so I, you know, looked it up, consulted. And so I, you know, looked it up, consulted my students, and I came to this. Oh, yeah, AAC is a normalized version of the Wilcoxon rank zone statistic. It captures what fraction of pair of patients are misranked by the model, and therefore you should use it. I was like, ah, this isn't quite nail yet, so let me just give an example. Here's an example. Let's say we have two tests. It's a real example. To test for pulmonary embolism. We can either take a CT scan. Can either take a CT scan or we can do this serological test called a D-diver test. And we want to assess which one is better. So we present these two curves. They cross. Most curves cross when you plot them in this TPR, which is the true positive rate that gives the false positive rate. So we look at this and we're like, okay, which one is better? So I kind of like, you know, hand-wave to my students. I'm like, okay, if we want to, if we want to look at the top right corner, this is like where you want. Top right corner, this is like where you want to be super sure they were treating all the patients with pulmonary embolism. And then I was like, oh man, I got to look this up. Like, oh, yeah, the bottom one is, it's hard to interpret, but like, this is roughly the space where we want to make sure we want to give treatments to all the people who don't have PE. And I was like, well, if we're in the middle, like, we just got to get a position of expertise to inject some knowledge that's going to tell us the FPR we care about, and then we can decide which one is better. And I just think this is like nonsense. People don't think about. Like nonsense. People don't think about decisions this way. People don't really have a priority. Is that right? I should have thought this in the chat. I knew someone was going to have a serious right there. I was asking physicians, do you feel comfortable generating an FPR? And eventually what I told students is like, look, we can just put this uniform prior on all the FPRs we care about, and it's uninformative. Then it's AEC, I guess, makes sense. Then it's AC, I guess, makes sense. What does it mean to generate an FPR? Does it mean we start an FPR chain for? Yeah, so like at the end, we're going to sweep out some sort of threshold and deploy that. So we got to kind of pick the threshold and then the curve that's above that is the one we care about. But like, honestly, this is just nonsense. Like, this is, I found this extremely hard to explain and very hard to motivate for students. And then when I talked to doctors, they were also kind of like, They were also kind of like, yeah, I mean, it's just the, you know, better the AUC, the better the thing. Like, no one quite understood. This didn't comport with the way I feel like people make decisions. And I think I had, so my student actually really loves owls and decided he was going to send me a bunch of owls if he's going to talk. So you're going to see a lot of these. So I think you guys are using the same model, you know. My AI generated now. So these are all. Generated now. So these are also really identified. Not this time, I guess. Yeah, there you go. So I just feel like, you know, you want to make things vivid for students, and it's very hard to compare outcomes for students. There's no way to inject that knowledge when you're giving curves like this. It doesn't take into account base rates. These are very, very well-known classic problems with this curve. And there's just a calibration problem. If I give you two tests, what if we're testing? If I give you two tests, one of which is completely miscalibrated, let's say it multiplies everything, the risk by 10 times the actual risk, then it will assess that these two models are the same, simply because it's measured in rank. That's like actually what it's getting at. So, I mean, in medical decisions, it's not really kind of getting at the core of what we maybe want from a prediction. And so, and I was thinking about why do we use this? It's clearly like this historical artifact, it was generated in the Artifacts. It was generated in the pre-war years in the context of agriculture. And it was really popularized when using, you know, for radar. So that's kind of why we use it. Actually, I mentioned after the war. Oh, was it? After the Cole War. Yeah, there. The earliest reference I found was this, actually, this paper called Rock Solid, where. I think they meant it as a funny dad. I just want to compare and contrast this with curves that I think make way more sense. If you think about irrational, scarce resources like ICU beds, then everyone's heard of this precision at K curve. It's very classic and it's way more intuitive to use. Just to reformulate this, this is a precision at K curve. I just kind of made it so it's, I think, more intuitively read this way. Intuitively read this way. Essentially, if you want to know how many patients you have per ICU bed, if you actually know that, then you can just see which test requires more treatments per success. So if I read off on the scan, CT is better until you're getting, until you've got an ICU bed for every 3.5 patients or so. So basically, yeah. Maybe I'm just like not reading this. Yeah. When you say patients per ICU bed, like I'm like, there's one patient bed. No, so you have an influx of patients coming in. An influx of patients coming in, let's say a pandemic of scarce resources. I want to know, if I have a sense of how many patients are going to come in, I have a constrained resource. I basically need to know N over K. And if it exceeds 3.5, then I need to be handing out this different kind of treatment. If I have a surplus of ICU beds, then another decision rule would actually be better. So this So, this is a context I think that makes sense. You have scarce resources. And more generally, I think we tend to think in terms of limited supply and limited demand. So, which predictor do you use when we have more subsoils to give out and which predictor would spend unlimited sources? Exactly. Exactly. So, if you look at this curve, this was actually generated in the 1960s. Actually, Ben might. In the 1960s. Actually, Ben might correct me on this, but from my understanding. I don't know if I know this one. Okay, okay. I'll find out. This came from information science, basically, library sciences. So they had this like kind of recall curve or recall, and then they had this precision ratio. And they basically wanted to decide the average precision over how many documents were returned. So they wanted to make sure that, like, oh, I'm returning roughly 10 documents per request. So this was. So, this was information sciences, very classically understood. So, just to give some context at this time, the number of search results in the whole university for a question about, let's say, aerodynamic theory might be like four. So, information retrieval obviously changed with the internet. Now, there are infinite results for whatever you search for. So, this is a little bit outdated in the context of library science. Like, I asked about Ben Rex's swole advice, and there were about 9,760 results. You should totally Google it. Basically, the internet changed this. This is not a useful metric for information science, but I think it makes sense in contexts in which you are resource-constrained in medical settings. So I was going around this conference and I was trying to see how much this is used, and it was about 10 times less. And I think that might make sense in the sense that, like, this was not a medical conference in which we're thinking about. Not a medical conference in which we're thinking about maybe a lot of decisions where there are constrained resources. So, just to like wrap up, where I think we should go, because I do think there's a solution to this. I think that there are perhaps better ways to comport our like graphs that we present with the way we actually make decisions. And I don't think that the AUC does that. So, let's just pretend we're giving out a drug. It's not an ICU ped. There are There's an unlimited amount of this, but there's a cost. There's a cost to the drug. And so I want to figure out, you know, which drugs should I be giving out? And of course, I think the AUC conspiracy is that the ROC paper suggests that if you don't know your base rates or you don't know misclassification costs, this shouldn't be what you're using, and yet we use it anyway. I'm going to sound like an economist, but I think. like an economist but i think that we should make we should make prices explicit and be deciding based on the prices of that we think exist with regards to our mistakes um so especially if this is the way we are doing kind of decision science more generally so this is a curve it exists and i talked to some clinical collaborators and they thought that this was more consistent with at least how they hopefully make decisions um so a statistical judgment The statistical judgment that we might be using is what's called a Richardson problem. It exists. All you do is you have your confusion matrix and you actually specify the cost embedded in treating a sick person and a healthy person, this might be the same, and an actual cost to doing nothing when the person is sick. People don't like this because it means that you're putting costs on human lives and they hate this. And I think this is why we don't use this. And yet, when you ask you to. And yet, when you ask a hospital administrator and when you ask anybody how they actually make decisions, this is how they're making decisions. It's just being masked by FPRs and TPRs. And I just feel like we should at least be honest and visible about how we actually ultimately make decisions. And so I just think this should be more copularized. And I think there are other ways to visualize this. There's actually really nice math behind this. Obviously, it's a provocation. I can't go into Richardson blocks more extensively. Extensively, but I just wanted to say it exists. I don't like the AAC. I do think that we should probably be doing things better, and I think a lot of things are the way they are because of historical legacies that don't comport with today's values and the way we do things now. Okay, that's really it. Thank you. Can all the panelists come to the front please? That was a bit of a message. Put a cost on me. I'll be working on it. Oh, yeah. Oh, dance.