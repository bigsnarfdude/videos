Okay, thank you. And thanks to the organizers for the invitation to come and speak today. So continuing on Nagos's talk, I'll be looking at some sort of specific examples of extending classical results to the course settings. So the first of these is the characterization of graphs with no K4 minor. We'll look at graphs with no fat K4 minors. And then the second is And then the second is the theorem of Galai on A-paths. So remember, an A-path is where A is a subset of the vertices of the graph, and an A-path is just a path with both endpoints in A and no internal vertex in A. And Galai proved an approximate packing result for those that either you have k disjoint A paths or 2k minus 2 vertices in. But before we do that, I want to give a, at least present a lemma which shows the equivalence of Which shows the equivalence of quasi-isometries to the existence of bounded radius HD compositions. And this is because, at least for me personally, I find working in the context of HD compositions much easier than working with the quasi-isometries. And we'll see inductively how that comes into play in the proof of the excluded fact K4 result. So first, again, let me just put up the definition of quasi-isometries. Definition of quasi-isometries. It's a map, so I have two graphs G and H, a map between the two, which approximately preserves the distances between the vertices. So we have an example of a 2,1 quasi-isometry from concord into 2. And it's an easy observation. You can work out that if I have a quasi-isometry from one graph to the other, I have a quasi-isometry back. A quasi-isometry back between the two. So, really, this is sort of an approximate equivalence between the two graphs: that the two graphs have roughly the same global structure. So, in terms of fat minors, the exact definition, so I like to think of it in terms of maps. So, I have an example here of a fat K3 minor. So, normal minors, again, for each vertex of the small graph. Vertex of the small graph, we map that to a blob, a subset of vertices of the bigger graph. Here we have to map not just a bag for each vertex of the K3, but also a bag for each edge. And now I want every pair of bags to be pairwise far apart in the big graph G, except in the case where it's an edge and an incident vertex. And an incident vertex. So these two have an edge going between them, but between any two edges or between any two vertex bags, those are going to be pairwise far apart. So as Aguilos also already showed, that if we have fats K3 minor for some large value of R, then we're not going to be quasi. Then we're not going to be quasi-isometric to a tree. So the converse of this is also true: that if I have a A plus M plus 1 fat H minor, then G is not going to be MA quasi-isometric to any graph which excludes H as a minor. So this led to the conjecture that Aguilos stated last time, which is that if I exclude some fact H. Some fact H as a minor, then the graph would hopefully at least be quasi-isometric to a graph which excludes itself H as a minor. But again, as we saw that this is false, there's an example given by Davies, Hickenbotham, Illingworth, and McCarthy. And what can we do going forward? So, again, this is a conjecture, and there are. So, again, this is the conjecture, and there are a bunch of cases which are true. So, we already talked about the K3 case, excluded K3, and more generally, that case we're looking at quasi-isometries to a forest. You can also look at quasi-isometries to subgrass of paths. There, you have to exclude as a fat minor the excluded minors for subgrass of paths. That is K113 and 1,3 and K3 itself. K2, 3 excluded K2, 3 fat minors, K4 minus fat minors, K1M fat minors, and today, sort of the biggest graph of all those, or most complicated perhaps, is excluded K4 fat miners. Yeah, can I just add to the list? Alex and Maria and Tom and I can do K2T. Okay. K2T. K two T? So is that more or less complicated than K4? I haven't checked the book K4. Okay. No, it just does a graph, K two T data. But as I said, I want to look at H decompositions of graphs. So this is sort of a generalization of tree decompositions of a graph. So H is now any graph, and an H decomposition is going to be a pair HW where W are W are subsets of the vertices of G indexed by the vertices of H. So this is sort of the exact analog of a tree decomposition where I have subsets of the vertices of G indexed by the vertices of my tree. And now the usual tree decomposition thing, I want every edge to be contained in some bag. And now I want for every vertex of g, if I look at h sub v. If I look at H sub V here, that is the subgraph of H indexed by, subgraph of H given by all the vertices which contain V in its bag. I want that to be a connected subgraph of H. So again, if H is a tree, this is just the exact definition of tree decomposition of a graph. But now for a general H, the red vertex, for example, here is contained in all four bags, but still induces a connected subgraph of H. Is a connected subgraph of H for T. So again, I said it in bags. Let me put it up on the slide as well. These subsets associated to each vertex of H are the bags of the decomposition. So 3D compositions were primarily concerned with how big the bags are. We want to get as few vertices as possible in the back. In general HD compositions, this is not the right. This is not the right notion. Really, what we're more interested in is we want the bags to be a bounded radius. So, when I talk about the radius of the set of vertices in G, so the radius of a bag, I want the minimum R so that U is contained in a founded radius ball in G. So it's not the radius of the induced subgraph, but rather the smallest ball. But rather the smallest ball of G which contains all of those verses. So the radial width then is just going to be the maximum radius in G of any of the bags of the decomposition. So in this example, the radial width is one. Each of the bags is just one of these triangles. So the radius of each of the triangles is one. Now the radial spread of the decomposition is the maximum radius. Decomposition is the maximum radius in H now of the subgraph H sub V for each vertex B and G. So the radial spread here is 2, right? Because if I look at the red vertex of G, the subgraph of H that composed of vertices which contain that red vertex is the all of H, which has previous. Okay, so now the relationship between The relationship between HD compositions and quasi-isometries. So, this was a lemma with Albertsman, Diestel, Elm, Fluk, Jacobs, Ganap, and myself. So, I should say that sort of all of these letters are students at Harvard. I was working with them while visiting, except for Dee Still, who was not a student in Hamburg. So, G admits an honest R1, R2 radio. An honest R1, R2 radial H decomposition. Then there is a max 2R1, 2R2, max 2R1, 2R2 quasi-isometry from G to H. Very difficult with R1 and R2R. What's the definition of radial definition? So maybe I didn't actually say it. But one is the radial width and one is the radial spread. R1 is the radial width, R2 is the radial spread. And honest is a little technical non-thing that doesn't mean anything, but it's inconsequential. And then the converse holds with different functions between the MA of the quasi-isometry and the radial width and spread of the radial H decomposition. So we can go sort of back and forth between the two. And forth between the two. So this quasi-isometer just maps into the back, right? So for tree decompositions, it doesn't matter if you say radius in the whole graph or radius inside the subgraph induced in the back, comes to the same thing. That's true for your more general decomposition. We do need the radial spread as well. So if you just measure radius of the bag using the distance function of the graph. Using the distance function of the graph, or radius of the back using the distance function of the induced subgraph on the back. Does it come to the same thing? Different constant? I mean, shouldn't it just be up by like a factor of two? But here your your bags might be disconnected. So if you ask that the radius within the bag is not, it will force connectivity and probably changes the yeah. So we don't require that our bags even be connected? But you could grow the bags and then that should just The bags, and then that should just double the radius at once, right? Because you're just as central just as you can. Or I think you just add the center of the ball that certifies the radius for that. And then you have to adjust the backspan fit. So translating into this H decomposition statement, then there exists constants C one and C two such that if I have no R fat, K quorp minor. No RFAT, K chord minor. We then have instead a C1R plus C222 radial H decomposition and a graph H where H has no k home. What does honest mean? Honest means that for every edge of H, the intersection between the two corresponding bags is not empty. So it essentially means that H is sort of, has no inconstant edges that I could do. There's no income. So I'll give a quick outline of the proof. So we start with a graph G which has no fat K4 minor. And what we're going to inductively maintain is some big subgraph G0 which has a bounded radial with decomposition in H0 with no K4 minor. K4 minus. Moreover, we're doing so so that the part of the graph which I haven't accounted for yet, g minus g naught, attaches onto two bounded radius balls, B1 and B2, which are themselves bags of the decomposition. So they're bags of adjacent vertices of H0, and there exists a path in G0 linking V1 and V2. Making V1 and B2. So, this is sort of the structure that I'm going to maintain inductively as I go forward. And now, what I want to try and do is find two pairwise PowerPoint paths inside this G minus G0 linking B1 to B2. Where that distance D is going to be some parameter that I picked. Going to be some parameter that I picked that makes the rest of it proof for me. The D is going to be much smaller than the radius of B1 and B2. It has to be much smaller than the radius of B1 and B2, but much bigger than the R that I'm looking at. R, the fatness of the kick. And so fortunately, we have Menger's theorem in the course setting at least for two paths. So either... So either, if I have two sets of vertices x and y, either I can find two paths p1 and p2, which are pairwise at distance d, or I get a bounded radius law, which separates x from y. So as also, as Agulos mentioned earlier in his talk, the uh analog is false for k greater than or equal to three uh with the constraint that d is also greater than equal to three. The constraint that D is also greater than zero. So if the two paths do exist, I'm well on my way to finding the K4. Because I take these paths, I take the shortest path, Q, in G minus G naught, linking P1 and P2, and I take smaller balls inside here, and I found my theta 4. If it's that the paths do not exist, then I get a ball Z separating left from right. And again, I've reduced down to my inductive structure. I have again, essentially what I've done in the decomposition is I've subdivided this edge and added a new vertex. And now I have two balls in adjacent bags with a bunch of studs attaching here and a bunch of studs attaching here. So, really, what I'm doing is So, really, what I'm doing is I'm sort of modeling the proof of how you would either find K4 minor in the graph or actually find a treaty composition with facts of customer. So, said like that, it doesn't seem particularly hard. What I have swept under here is picking these orange balls here and making this work. Also, maybe not. Also, maybe not necessarily true that these two B1 and B2 are nice and far apart, but they overlap. And we have to analyze those cases a little bit more carefully. Questions about that before I go on to the Galaxy? When you stop, I mean, at some point, you're. At some point, there's just G minus G naught is empty. Just cover the whole graph, absorb the whole graph into the decomposition. And so, to answer your question from before about additive versus multiplicative, I don't know. Because once we moved to the H decomposition context, the additive versus multiplicative sort of disappeared into that equivalence theorem. So the short answer is I don't know. Answers, I don't know. How horrible is this when you do the decodes? How what? How horrible is it when you do the decodes? It's like 20 pages, but not 20 hard pages. 20 pages, like doing K4 minus also. So it's not too bad. Okay. Okay, so Galilei's theorem. So, again, an A path is a path with both endpoints in A and no internal vertex in A. Galilei's original theorem said that either we have k disjoint a paths or a set of at most two k minus two vertices intersecting all the a paths. And now this spring at Barbados, Jim Gielen asked whether it was true that either we would have k disjoint a path pairwise at distance d or bounded non-distance. Distance d, or a bounded number, bounded radius balls hitting all the a-paths. Sort of the exact analog for the Kourse-Menger theorem, but in the A-path case. And what we're able to show, so this is with Sandra Alversin and Paul Napa, we can prove the following. So for all k, so now we're looking at for any number of paths, we have a radius r, which depends on k, and a number t, which also depends on k. And a number t, which also depends on k, such that either we have k distinct a paths which are pairwise at distance two, so these are going to be anti-complete a-paths, or t balls of radius in most R, which intersect every such A path. So, yeah, I have time. So, I'll give a little bit of indication of how we improve this one as well. So, just sort of blindly starting off. Just sort of blindly starting off, what would you do? You'd start by finding the shortest A path in the graph. So, since it's a geodesic path, I could take lots of balls around each of the vertices and they sort of naturally extend along the path. They don't, the ball from the beginning of the path doesn't overlap the ball from the end of the path because it's geodesic. And now I look at what's left and take another shortest path from the other average. Shortest path from the other A vertices into what I've found so far. So that sort of terminates at a bigger ball, and then I have another geodesic path, which is disjoint from what I have coming in. So I mark that ball where I landed, and take balls around the geodesic path, P2, coming into lip. And I repeat this process. So I keep taking shortest geodesic paths in, marking the path. Geodesic paths in, marking the end points, and continuing. And now the new path coming in could either sort of land at a new vertex, new ball here, or it could alternatively land at one of the green balls that I've already set aside. But what I'm really doing here is growing what we call a blob tree. So, a blob tree, the vertices are going to be balls of some radius r, pairwise d, far apart. Far apart. And then the edges are going to be shortest paths, geodesic paths, linking up two of the blobs. And I have the property that my blobs are, sorry, my edges, what do we want to call them, edge paths, are pairwise D far apart as well. Moreover, where are the vertices of degree one? The vertices of degree one are going to be The vertices of degree one are going to be containing vertices here, right? And it's possible that I have a vertex of degree two where one of these shortest geodesic paths landed on a vertex of degree one. But all the vertices of degree one or two of the blob tree, all of them are going to contain an a vertex. So note that as we're growing this blob tree, Growing this blob tree, the radius of the blobs is going to increase at each step. So, why is that? Here, when I found my new path coming in, maybe it didn't land exactly at the green blob, but it landed close by. I want my green blobs to be parallelized far apart. So, if I landed too close, So, if I landed too close, I couldn't make a new green blob here. I just had to grow this green blob to contain it. So, every time I'm adding a new path in, it's possible that I have to grow my blobs to make it. Moreover, the diameter of these red balls is going to have to go down in each time, because I want the red balls here to be destroyed from the red balls here. So they're going to have to shrink by half every time I add a new lash to it. So, the distance between the distance between The distance between the paths is decreasing at each step, and the size of the blobs is increasing at each step. But the nice thing is that as the blob tree gets big, either it's going to contain K pairwise distance DA paths, or it's going to have a large blob star. So that's the lemma. That I'm able to grow, either I can find I'm able to grow either I can find k-disjoint A-paths, pairwise at distance D, or a large blob star, or at a certain point I'm not going to be able to grow my blob star at all because the blobs kill all the A-paths. And I have no other shortest A-path that I can think of. So what do I do with the blob stars? Well, now we need to I do with the blob stars. Well, now we need a separate result about your growing process, you pick a shortest path coming in and landing on something you grow already, and it might land on your green blobs. But doesn't that count as your green blob hitting all the A path? Yeah, so actually when I look for my hitting set, I just delete the leaf backs in A and then look for an unoccupied A vertex that I've recovered. So you're saying, why didn't I just delete the sender blob and link into that? Is that what you're asking yourself? And so the reason is we want that path to be geodesic. Path to be geodesic. So when we start linking in, we're not linking in the deleted graph. So we have to possibly link into one of the green blobs that I already found. So how do we uncross the blob stars? So I start with B1 as a big blob star with legs pairwise at distance D1. I delete the center, the big green blob here, and I apply the lemma again. Maybe I get my Kgisto and paths, maybe I get my bounded hitting set, well that's good. But what if I get another blob star? So here I have B2 is a blob star with legs pairwise and distance d2 after deleting the center ball d1. And now, in order to make the let me go through, I want the radius of V2 to be. I go through, I want the radius of V2 to be much smaller than the distance here, D1. And so, what the limit says is that either I can get many pairwise disjoint A paths pairwise at distance two, or two smaller glob stars which are disjoint, that all their legs are pairwise at distance two. And now you're saying, why distance two? I mean, sort of intuitively, I mean, sort of intuitively, maybe I should find my many pairwise A paths to be pairwise at distance D2, the smaller D here. Well, this D2 is fake, because this D2 is the distance in G minus B1. And so these red paths are not necessarily far apart in G. They could have common neighbors inside the boundary of B1, which prevents them. But they are anti-complete. But they are anti-complete because any edge connecting them would be an edge also in GMS. So this is sort of, well, this is how to uncross two blob stars. If I can uncross two, I can inductively uncross K. But now again, here's the theorem statement. And this is why our proof is fundamentally giving two here. Is that this inductive step where I delete some blobs and inductively find And inductively find in the smaller graph means that what I find in the smaller graph doesn't preserve the distance function. I can only find anti-complete structures in the distance and hope that those are going to also be anti-complete in the original graph as well. Yeah, it's GDZ, but the one you're throwing in is GDZ. Yeah, we actually have to be a little more careful because each one is sort of GD. Have to be a little more careful because each one is sort of geodesic in G minus the previous block. We don't completely forget the geodesic in geodesic. Okay, so there's a lot of room for improvement in this statement. So this was the original conjecture that either I can get them, well, first off, the radius of the balls that we delete shouldn't really depend on the number of paths. Really depend on the number of paths I'm looking for. It does depend on the number of paths I'm looking for in the proof because the radius was growing as I grew my blob star. But really, it should only depend on t and now when I'm looking for anti-complete paths, it really should just be some constant, absolute constant. The number of bulbs could be improved. At the moment, it's exponential in k, but the best possible would be k equals to K equals 2. So these are sort of things that should be true, probably could get by fiddling about or something. The much more fundamental question is here, what about for general D? And again, there's this sort of, we're seeing here like a real disconnect between the proof techniques, because any sort of inductive proof where I'm deleting blobs and proceeding inductively is fundamentally not going to help me find distance d. Find distance D objects in the original graph. So I'm going to end with a separate list of open problems. And let me say number four first, which is what's a proof technique? What's, this is sort of a wishy-washy problem. What's something that would allow us to do inductive type proofs and still work with general distance D in the graph? Work with general distance D in the graphs? How could we? Maybe we, I mean, I've played around with lots of things like deleting the ball, but somehow trying to register distances in the deleted graph, and nothing like that seems to work. But maybe there's something else that would allow us to do inductive type proofs, still looking at general distance theory. And now, an alternate variant of the coarse-Menger theorem. Variant of the coarse-Menger theorem, which could be true, is instead of just deleting the optimal number of balls, k minus one balls, what if we just delete some arbitrary number, some f of k balls, to hit all the pairwise distance dA paths. Oh, sorry, to hit all of the x, y paths in the graph. We can also look at an approximate version of the fat minor conjecture, which is that if I exclude some fat H, then I Then I have an S decomposition for S which excludes some KT, where T is going to be a function of H. So it's not the exact that I have an S decomposition where I exclude some H, but just some minor close class of graphs admits an S decomposition of boundary to deal with. And also, And also Agulos mentioned this Agulos mentioned the possibility that the fat minor conjecture could be true for our planar graphs. For any planar H, if I exclude H as a fat minor, I have a decomposition in a graph which doesn't admit H as a minor. And minor. I think this is a weakening of that. So, is it possible that if H is planar and I have no fat H minor, then I have a tree decomposition where every bag consists of a bounded number of bounded radius balls. So this would follow from the planar version of the Fat Minor conjecture, but I don't believe it implies it. So it should be eaten zero. And I'll finish there. Quick questions. There's an analog for passes as well or with the three that three minor. You fix some tree, you exclude that tree as a FET minor, and then you have a path decomposition with bags of bounded number, bounded radius posture. I tried to approve it many years ago. Okay. What did you say? I tried to approve the three version, the pathways version. Before all the course minor stuff? What was the motive? Was there a motivation? To serve one extra contract or sort of like some quicker topic tried to treat it. Yeah, I'm gonna go to the next one.