I will talk about some games which are motivated by the pricing of tickets. I put tickets in parentheses deliberately because I will not have anything serious to say about tickets or ticket master or what your airline did to you to get you here or anything like that. But this is a model and a framework and maybe something later will come with data and so on and so forth. So in the context of this workshop, and I don't know if I'm going to make this full screen, let's see if that works. That works. I'm going to do full screen, but okay. So, in the context of the games and the topic of this workshop, I'm interested in extending dynamic revenue management pricing models, which have been used for, for example, airline ticket pricing and so on, to a setting where there is competition, where there's many players, and to see how that affects. uh that affects the how that affects the uh the the prices um that are charged for tickets in a probabilistic model so in this uh you know there are sellers of tickets who set the price and the price affects the probability that somebody buys a ticket so the demand for tickets is elastic it reacts to the price um and stochastic because the uh Because there is uncertainty about consumer behavior. Just because the price goes down doesn't mean that everyone is going to rush and buy the ticket. So, a classical model of this is in the single-seller monopoly model, which was in a paper by Gallego and Van Reisin 30 years ago. And this was influential, but it's only one seller of tickets, and it's supposedly used by some airlines I heard it described as the black shoals of refugees. The black shoals of revenue management, if that means anything. So, here are some questions that I want to try and answer by introducing competition. So, I want to try and capture competition from a similar good, e.g. tickets on other airlines or from different sellers or by different routes to get to the same place. How to solve computationally a stochastic dynamic game of intensity control. Intensity control means control. means controlling the probability of making a sale. A mean field approximation, which would be useful computationally and to try and show existence and uniqueness of an equilibrium. And just one question that has always bugged me is why do the prices go up as the event date, the flight or the concert approaches in practice and in this Galeglo and Van Reisen model? In other words, Van Reisen mall. In other words, if you want to buy a ticket tomorrow to go somewhere, you will probably pay much more than you would have paid six or seven weeks ago. And why is that? Is that because it's not a properly competitive market? Or are there other reasons for that? Okay, so yeah, so here, okay, so that is okay. Okay, but that's it. But just click on the he's doing it for me, his computer. My computer, so you need maybe to click on the slide so that maybe the whole screen doesn't. Okay, here we go. All right, okay. So let me sort of build up from simple things. So starting with a simple competition, bringing in randomness and then going to continuous time. So this story, most of you have looked at. Have looked at games know that there is a classical motto by Cornel, who, in a book in 1838, introduced games of quantity and price setting, as well as early examples of Nash equilibrium long before Nash. There was a book review by Bertrand, which came out in 1883, which is portrayed as him saying that quantity setting where people choose the quantity of the good is kind of ridiculous and people set prices and not. Ridiculous, and people said prices are not quantities. And so the price-setting game became known as Bertrand competition. And if you know, this people looked into this afterwards, and actually, it seems that Bertrand, you know, probably didn't read the book very carefully. And B, if he did read it, he didn't really understand it. And so he really shouldn't get credit for price competition because in that book, Kono has a chapter on quantity setting and a chapter on price setting. So they should really be known both as Kono games, but it's too late to change that. To change that. So, what we're in is a form of Vertron game, but we want to introduce the uncertainty as well. So, in the simplest Vertron game, P is the price, and there is some function A minus B P, which says that if the price is P, the amount of goods, the amount of tickets that the market will demand is given by this demand function. And so, in the simplest Bertram thing with one player, no competition, et cetera, et cetera, you maximize overprice the quantity. Over price, the quantity that you would sell if you set the price P, which is A minus B P, and then price minus, let's say, a unit cost, a marginal cost of production. And so this is your simplest quadratic maximization. This is the optimal price that you would set, as long as that's bigger than your cost of production. Otherwise, you would just set the price including the cost and make no profit. And so that's the simplest setting. Now you could say, all right, suppose I kind of change the story a little bit and say Story a little bit and say that the sale of one item comes at an exponential time. So instead of the demand function, there is an exponential time whose rate is lambda of p, which is also a minus b p. And then I want to maximize, you know, if you say, if you think that lambda delta t is the probability of making the sale, then that maximization is basically the same thing with the delta t there. So that gives you the same thing. So that's a form. A sort of a simple way of introducing some randomness, and then you could take the time horizon more seriously. And so, some of this in the earlier talks that you have some discount radar and you want to maximize the expected profit that you make by choosing the time, by trying to influence the time of the sale. But if the sale comes late, you lose because of discounting, or you can put a finite time capital T and so on and so forth. So, there are lots of. And so on and so forth. So, there are lots of ways you can build up to introducing randomness and tailoring Bertrand to be in this kind of thing. So, here's the dynamic revenue management problem, the monopoly. This is sort of the Galego and Van Reisen. So, you have a single seller who has X tickets to sell. And one of the things is that this is again on a finite state because the number of tickets is clearly discrete. And you keep track of how much. And you keep track of how much the seller has left at time little t, so that's x of t. And this goes down by some counting process jumping, and lambda is like a Poisson process, except its rate is changing with time. And so the number of tickets goes down according to the changes of this Poisson process up until tau sub x, which is the first time it hits zero, starting from x tickets initially. Initially, and this lambda t, which is influenced by the price that you choose at time t, is what controls the rate. So, with probability lambda delta t, you make a sale over that time period lambda t, and with probability one minus lambda t delta t, you don't make a sale for small delta t. Okay, and so then you jump to dynamic programming, the value function, the discounted maximization of profit. So, here's your value function. Here is your value function. I have to choose a price policy starting at time t up until I either run out of tickets or capital T is the date of the flight, the date of the concert, et cetera, et cetera. You discount future profits at rate R, and every time the pass-and-process jumps, you sell one ticket for the price you've set at that time, and this is the value function for this single monopoly. And I'm assuming that what was seen before is not there, but there will be a shadow. Is not there, but there will be a shadow cost because, or a scarcity cost that will come into this when you get to the differential equation for the V. Okay, so again, this is just one player, the classical thing. So I'll denote by delta V the jump in the, you know, the difference between the value function between when you have x tickets and when you have x minus one tickets. So the jump in the value function downwards when you, when you make a Downwards when you make a sale. And then the AJV associated with this is Vt minus Rv for the discounting, and then the maximization over P of the intensity function as a function of P, and then the price, and then minus delta V from the generator of the X process. And so you see, as usual, the AJB here, where there was a C before, this is the static, this is the one period problem that I had before. This is the one-period problem that I had before. And so, Delta V plays the role of tickets running out. And then, this Gallego and Ved Risin is famous for having an explicit solution in the case where you have the model of the intensity function being an exponential like this. This is the formula that's here. This is also applied for optimal liquidation in a paper by Erhan Berecher and Michael Lukowski, both here. And the optimal structure. Influence here. And the optimal strategy is the optimal price is to at time t is to choose the delta of this function, like the derivative of this function in x, plus this constant here. And if you plot this for that formula, you can see that basically this x is going across. Basically, the slope of this function is the price that is set. And you see that it's getting steeper as you approach the date of the flight or the date of the. Date of the flight or the date of the concert. And that's the thing that shouldn't possibly, probably be happening in a competitive market. Okay, so that's the starting point. And so now I want to go to multiple sellers. Suppose there's N bigger than one sellers, each sets a price PI. So the prices are different because a flight on Delta is not the same as a flight on United. On United and Air Canada, and you may have loyalty to one seller. So, just not everybody is going to go to the person who sets the lowest price. So, the goods are differentiated in the jargon. And so, for Player Eye to make this an interactive model, you want an intensity that is decreasing in their price. So, in other words, if they lower the price, they increase the probability of making a sale, but increasing in A sale, but increasing in their competitors' PJ prices. And so, naturally, this is a game of interaction through the controls. And, you know, first assumption is to say that United doesn't discriminate between its competition, whether it comes from Air Canada or whether it comes from Delta. And so the players are exchangeable in that sense. And so that means for convenience, we go straight to the interactions of. The interactions of mean field type. So, for player I, you know, given the vector of prices set by him or herself and the others, the intensity of a sale is one minus pi, just to make a few number of constants, plus some interaction parameter epsilon, and then the average of everybody else's prices. So, that's the simplest way, in some sense, to bring in competitiveness, mean field, exchangeability, and so on. Changeability and so on. But as we saw in a couple of the talks this morning, you know, there is an absorption, meaning that once people run out of tickets, they're no longer competing with you. So if Delta sells all its flights on a certain route, or Ticketmaster sells all its tickets for a concert, then they no longer should be influencing the other ticket sellers. So, you know, the issues that come up, if you, you know, if you. You know, if you try and take this issue seriously, is that players are disappearing and the model, the market is becoming more monopolistic as we get down to the last few players. So there is some work that goes into understanding a model when the number of players is changing. And I'll probably go quickly over that. So there is a way that people have That people have thought about so everything here is going to be linear in terms of the relationship between prices and quantities. And so people have thought about, for example, if I start with Kono competition, that means given the quantities, what are the prices? And so this is the natural quantity to price relationship in a linear setting that it's decreasing in both because quantity increases, price decreases. Quantity increases, price decreases. So it's decreasing with respect to my quantity and epsilon times the average of everybody else's quantity. So this is the basis of Cornell competition. And Bertrand is the inverse of that. So that tells you how in a, you know, in a market or no games or anything here, just, you know, people come up with quantities, what prices will they get? Conversely, if you come up with prices, a price vector, what quantity would we? What quantity would we get? What demand would you get? But what you have to do is eliminate the people who set such a ridiculous price that they wouldn't get any demand whatsoever. So I could pretend I'm a player. I sell you a ticket to New York for $10 million. Should that really influence the, I don't have a plane, should that really influence how Delta sets its prices? I should not be able to move the thing. So then there's a thing where you do this inversion. thing where you do this inversion, you see, you have to order the prices and you'll see that some of them will get zero demand. You eliminate them and you say there's not really n capital n series players, there's little n serious players who will actually receive demand. And all of that leads to that the demand function is some linear function decreasing in money price, increasing in the average price of everybody else, but only counting the people who are seriously, serious participants in the market. And these coefficients a And these coefficients A, B, and C they depend on the number of players left. So, that very quickly is the structure of a changing market if you really take seriously the linear relationship and the fact that people are disappearing. And so, this is something people have thought about for a while. And so, that leads to what is the demand system for capital N players, but some of those players may not really be. Some of those players may not really be players, and the a n's, b n's, and c n's are given by these introversion formulas. And you can see basically these depend on n divided by n, n divided by n, or they're ignorable when n gets large. So if you now go to a large number of players, then you can sort of replace that little n by, or divided by giga n by a number eta between zero and one, which is the proportion of players who. Which is the proportion of players who receive positive demand because some of them obviously are not always gonna be present. And so the generalization, as you go to large N is a demand function of this type, A of eta minus B of eta P plus C of eta times the average price. And the A, the B and the C are given by the large N analogs of the thing that you saw before, which are given by these formulas. By these formulas, and so the demand is this as long as that's positive, otherwise, it's zero. Okay, so this is a way to come up with the demand structure when players are not equally created, if you like. And so, then this is what I want to discuss mainly. This is the mean field game. Okay, so it's a discrete space space, but let's say there's There's a continuum of players, in some sense. And again, you look at, as usual, the representative player who has X tickets left at time t. And the exit time tau x. Okay, so I put here that tau x is the first time the x reaches k underbar. Typically, just think of this k underbar as zero, but you could extend this to where, you know, like the airlines do, they oversell tickets, they sell more. Oversell tickets, they sell more tickets than they have. Um, and um, you know, you could put a penalization structure, but I won't have that here. And so, motivated by the fact that this is a Bertrand game, I want to put an intensity, which is like we had before, A minus P plus C of eta, P bar. Eta is the fraction of players. Here's eta. And I'm jumping straight to the mean field setting. So I'm going to keep track of a representative player. Of a representative player, I'm going to keep track of the density of players. So n sub k is the, you know, is the discrete distribution function of how many players have k tickets left. Okay. And so eta of t is, so like take this k bar to be zero is, and k bar is the maximum number of tickets that anyone could have. So this is the number of players who have tickets left at time t. So that's the variable that's keeping track in some sense. That's keeping track in some sense of what is how the structure of the market is changing. And that goes into the coefficients A and C. And the other thing is, again, going to the mean field, meanfield game structure of it, is that the average price, instead of writing down the full Nash equilibrium with a value function for each player, I'm going to jump to this way of looking at it, that PFAR is the average price by which. P bar is the average price by which I mean the average of the players who have tickets left divided by the fraction of players who have tickets left. So people are, in this sense, is going to be defined like that. And yeah, and I think that's everything. So I don't know if there's any questions at this point. Just I'm going very quickly because it's fast. If anything's not clear. I feel like it's not clever. Okay, so all right, so then, okay, so we have then, you know, this is the generalization of the value function. And, you know, the value function is a function of the number of tickets that you start with at time t. So k is the number of tickets that I start with at time t for a represented player in this midfield setting. Similar thing, maximum. Similar thing, maximizing discounted price. The indicator just means as long as I have tickets left to sell, and dn lambda is the warning or zero if a sale is made or not made. And then analogous with the single-player thing, you have the HAB for the representative playlist value function, which is given here. The only difference is that the intensity now depends on p bar. Depends on q bar, the average price of all of the players, and through those coefficients a, b, and c, the fraction of players left, which is zero, but you could just say this is the law of the underlying process, x t. And then you have boundary conditions. So when you reach capital T, your value function is zero. You have no tickets left. When you're at the lower, when you're out of tickets, when you're out of time, you may have tickets left. When you're out of time, you may have tickets left, but you have the flight is left. And when you've run out of tickets, you're out of the competition. And delta V, as before, is Vk minus Vk minus one in this notation. And then, as we've heard several times already, the mean field game approach is to think of the p-bar as given first and solve this as a And solve this as a stochastic control problem in discrete space, which, given the p-bar and the eta, gives you this formula analogous to the quadratic maximization before, and then look for a fixed point so that the p-bar and the eta are the ones that come out of this thing. And that's also naturally how you would do a numerical method, which I'll say a little bit about. So, okay, so as you So okay, so as usual you have the in your GB equation, so in the soup the P on the soup is this a scalar or is a function? It's a function of time. It's a map. Function of time, yes. Yeah, so it's a function of the state variables, which is k and t, functionally. So in other words, here's the formula for the optimal one given given the domain. So the superlute is not point-wise. No, here, yeah, here it's point, it's like in the AGP. So this is assume that eta and p bar are given as parameters, right? This is this is a quadratic. This is a, you know, lambda is linear. So this is a quadratic optimization, right? For each t, for each k, for each eta, for each p bar. So it's just a it's just a quadratic in the scalar p, but this is done at time t when the thing is k. So I just denoted p. thing is k so i just denoted pkt thanks okay and then there's a common gold equation which uh you know which looks like this in the discrete state space and the edge cases at the lower limit and the upper limit um look like this okay and there's a related model of stock liquidation which is which is which is referenced here which has a model related to this okay so then Okay, so then numerically, again, it's analogous to some of the numerical methods for the problems that were discussed this morning. You make a guess of the average price as a function of T, the average, how the ticket selling will go as a function of T. You solve the AJB using some PV. So, well, these are ODEs, right? So that's the advantage of the discrete state space in some sense. You solve the ODEs. Sense you solve the ODEs, then you go back, you solve the Kamakura using the optimal strategies that you got. You recompute p-bar and eta using the new density function, and then you try and minimize this error until it gets small. And so this works well, which is for reasonable parameter values. And so, you know, that's the advantage rather than solving for value functioning. Solving for a value function for every single player itself. So, here, okay, so here is a very simple computation. So, there's only mass initially at four, five, you know, at five, five different, sorry, so you start with everyone having four tickets, right? So, this state space is zero, one, two, three, four. And so, let's start with a delta mass of four. Of four tickets. You have 20 units of time before the flight leaves. The discount rate is 10%. The lower limit is zero, the maximum limit is four. And so what you see here, there's a lot on this graph. So if you look at the purple first, the purple, so across the x-axis is time from 0 to 20. This is showing that initially everybody was at 4, nobody was at 0, 1, 2, 3. And then tickets got sold. And then tickets got sold like that. And then again, you see, so yellow is three tickets. This is two tickets. This is one ticket that goes up and down. That's how you'd expect the game to evolve. What you care about is five minutes, right? So what you care about is what I complained about before, which is the prices. So this is a measure of the prices over time. So these are the prices. So, these are the prices coming from when there's four tickets, three tickets, two tickets, etc. But what you want to see is that these things, maybe not, I don't know how quickly they're coming down, but they're coming down towards the end as the thing, you know, as you run out of time, as the event date occurs. So, with more competition, firms at every level decrease their prices. Eventually, they go up and they go down. Go down, um, and um, uh, they have more, you know, so the urgency of the competition: if they don't sell their tickets, someone else is going to sell their ticket. So, there is a competitive effect, which at least in this simple example, we're able to identify. Okay, and then this is a measure of the average price, again, going down as the expiration date, as the event date occurs. Okay, so let me say a little bit just about what we can prove about existence uniqueness. So, so you can. So you can rewrite it as a fixed point of this system of ordinary differential equations plus the boundary conditions. And here's the sketch of what we have in this work. So we can prove the existence of the solution for a sufficiently small epsilon. It's very dependent on being able to linearize around epsilon. Being able to linearize around epsilon equals zero, which is the case that is well understood without any competition, you can set it up as a fixed point between the appropriate spaces, use the appropriate fixed point theorem to prove existence. And then uniqueness, which is more difficult, or which is difficult, is using energy estimates, which are everything here is linear, so you can get a lot for those things. Those things. And you know, and this is a lot of technical work. And in sort of previous work that we have done for a continuous system with Brownian motion and so on, this paper here with Graeber, you know, it's a lot of work to do it at least by these PDE methods. Okay, I'll skip this. This is another example of a discrete game, which is to do with Bitcoin mining. And so I'll finish here. So just to summarize, I think, you know. You know, mutual games, if you want to look at it as what is this in terms of mutual games, then you know that started in continuous time with Brownian noise. There's a lot of, you know, this sort of came later, interest in problems with finite state games, which are natural for, you know, this kind of thing where things are necessarily discrete. So here are some references, Erhan Berechter, and Asif Kohn, for instance. And then we're working with the spin. And then we're working with a student to use discrete time and discrete state systems to prove convergence as a different way of proving convergence, but for those games of intensity control. And then finally, there are examples which motivate studying this, maybe the master equation for this kind of thing, not Brownland motion noise, but this kind of noise. So ticket pricing, I talked about oil discovery is another one that we have worked on before with Michael. That we have worked on before with Mike Lukowski, scoring goals. If you're following soccer, that's a discrete random event. I hope it's sort of random. Sports betting has applications, Bitcoin mining, et cetera, et cetera. And so these are different forms of problems, which are being motivated by control. Competition usually works quite well, and existence uniqueness is usually quite hard. So I'll stop there. Thank you. Yes, so the buyers in your model are not very rational. No, we're not. What did you pay for your tickets? Can you let them interact? The buyers? Yeah. I mean, they know the price goes down. Yeah. So why should they just submit their orders at a constant rate? If I understood the model correctly. You ticket? Put the model correctly. Your ticket price goes down at the end, right? But is it unanticipated by the buyer? Yeah, the buyers are A minus B P. That's it. It's a response function, right? So there's not, they're not, I mean, I go on, if we're talking about tickets, even if we're talking about ticket master and all that stuff, you go on, you kind of take, you know, take the price, you don't look at what your neighbor is doing. You don't, and these are not traders. These are, you know, these are just, what do you call it, you know, consumers, right? So in errors, we're not, that's just a response price. That's just a response, price-response function. That's the model. There's no rationality for them. Like the market is controlled by the sellers in this setup. Could you incorporate, let's say, a more active buyers in this one? You know, if you're talking about stock traders, maybe, but if you're saying like the next batch meeting, we all get together and say, we're not buying tickets. None of us is buying our ticket unless the price goes down to this. Possibly, but I don't know if that can, I mean, this is the. If that can, I mean, this is the, you know, someone mentioned Ticketbaster, like, this is what they're trying to do to try and give the consumer more, you know, either legislatively or somehow that they can't have this monopolistic behavior over tickets. But I think in these kind of examples that I had in mind, the buyers are far a long way from colluding, being rational, being optimal. You know, it's not like the two-sided market that you have for liquidation. But yeah, I mean, if there's an app that does that, then There's an app that does that, then possibly that to the level of the playing field. So I don't have that yet, but it's a good point. I propose for it because I'm sorry. Stay tuned.