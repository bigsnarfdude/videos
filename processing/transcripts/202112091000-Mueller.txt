Okay, thank you very much for the invitation and for organizing this meeting. I think it's marvelous. And I look forward to when we can all actually meet in person. I think there's definitely added value there. So I'm from Colorado State University and the math department and also the School of Biomedical Engineering. And I'm going to speak on the D-Bar method and pulmonary applications of electrical impedance tomography. Of electrical impedance tomography. So, a brief outline. I will begin with an intro to EIT in case anyone's unfamiliar with it. Talk about the ill-posedness, an outline of the D-Bar method, and then the focus is on a new approach for post-processing the D-Bar images to increase spatial resolution. And I'll show you some results on patients of Children's Hospital, Colorado, with cystic fibrosis. So, EIT consists of applying a low-frequency, low-amplitude current on electrodes. When we did the one-minute slides, I showed you my team. I'd like to acknowledge their contributions to the lab and the project. What you see here is a healthy human subject being imaged in the lab. So, for 2D EIT imaging, electrodes are placed around the surface of the body and the Around the surface of the body, and the goal is to form an image of the cross-section of the plane of those electrodes. So the low-amplitude current is imperceptible. The voltage is measured on all these electrodes, and the inverse problem is to determine the distribution of conductivity and or permittivity from these voltage measurements. So, the medical applications of EIT, it has a potentially important niche to fill. You know, as I will be emphasizing. To feel, you know, as I will be emphasizing, the resolution simply doesn't match up to that of CT and MRI, but it does have a high temporal resolution. 30 frames per second is very typical. Some systems can go faster. It's important for continuous or as needed patient monitoring or situations where a CT scan or an MRI is inaccessible. So examples of these include patients with spinal cord or headaches. Include patients with spinal cord or head injury. They often cannot be moved safely to the CT scanner. Continuous monitoring. Obviously, you can't leave the patient inside a CT or MRI. Ambulances or remote locations or during pulmonary procedures where the subject is upright, doing what's called a pulmonary function test. They're active, and that can't take place inside a SAT or MRI scan and getting. And getting regional information about the air and blood distribution throughout the lung during those procedures can provide the physicians with some useful information that can't be obtained by those tests that just provide a number. Okay, furthermore, monitoring ventilation and perfusion in ARDS patients including COVID-19. We have an ongoing project with that that launched recently. That launched recently. I won't be showing results on that work today. That's for the future. Diagnosis of epilectasis, pneumothorax, lung collapse, hyperdistention, pleural effusion. Those are all pathologies that could be detected in real time at the bedside with EIT. Visualization and quantitative measures from pulmonary function tests. That's what I mentioned already. Patients with cystic fibrosis, asthma, other chronic obstructive diseases. Obstructive diseases, pulmonary obstructive diseases regularly receive pulmonary function tests. And finally, identifying regions of obstruction of consolidation in children with cystic fibrosis. Okay, so I already mentioned the spinal cord and head injury. So small pneumothoraces and atelectases are not visible on portable x-rays. And so again, by monitoring with a non-ionizing, non-invasive Ionizing non-invasive modality at the bedside, these things can be potentially detected in real time much sooner than they otherwise would and allow for interventions. Okay, so equations. Let's express the admittivity as a function sigma of x plus i omega epsilon, where sigma is the conductivity. And in this talk, I'm going to just focus on the real problem of determining the conductivity. Problem of determining the conductivity. But this is in general. So I is the imaginary number I, omega is the angular frequency at which the current is applied, and epsilon is the permutivity. In other words, the tissue's ability to store a charge. So the electromagnetic problem is governed by Maxwell's equations, but with simplifying assumptions, it reduces to the generalized Laplace equation. And so that's satisfied by the admittivity. And the variable u here is And the variable u here is the electric field or the electric potential inside the region omega. We're going to focus on cross-sectional images, although 3D is also of interest in these talking focusing on 2D cross-sectional images. So omega is just a cross-section of the chest. Okay, so the data in this problem, classic Calderone inverse problem, would be knowledge of all voltage patterns on the boundary, and that's modeled by a Dershaw boundary condition. That's modeled by a Dersley boundary condition arising from all possible current densities applied on the boundary. That's a Neumann boundary condition. So the data is this Derzelet to Neumann map. However, in the literature, it's typically posed as knowledge of the, I think I just said Jerusalem to Neumann, Neumann to Derrisley map. But in the literature, which is why I misspoke, it's always posed as the Derusley to Neumann map in the theory. And these are inverses of each other. Are inverses of each other as long as you have things like choice of ground and conservation of charge satisfied. Okay, so it's well known that EIT is a severely ill-posed problem. And the reason for that is that the solution does not depend continuously on this data. And we're denoting the data by the Jirichleit Neumann map, lambda sub sigma. So, what this means is given any epsilon greater than zero and any delta greater than zero. And any delta greater than zero, you can find conductivity distributions sigma one and sigma two, such that your data is arbitrarily close in the operator norm, but those two conductivity distributions are arbitrarily distant in the L infinity norm. So there's various ways to look at this, and I'd just like to briefly show you how you can tie it down in the classic example by Alessandrini and in an analysis of simulated data. Simulated data. So, just briefly, I'm sure some of you are familiar with this example. And I'm sorry if my menu up there is obscuring anything. On my screen, it is. I don't know how to make it stop doing that. So let's consider two conductivity distributions, sigma one and sigma two, on the unit disk. This is Alexandrina's classic example. So we'll assume the background is sigma equals one, and then you have a disk with contrast. A disk with contrast of amplitude A at a radius r inside that disk. So each of these satisfy the generalized Laplace equation, and we're going to assume we have the same voltage. We're doing just so voltage being applied on the boundary. Okay, so the solution of the forward problem with those two different conductivity distributions can be easily found by separation of variables. It's a nice little exercise you can do by... It's a nice little exercise you can do by hand. I always have my students do it. And then you can compute the difference of the Dirichlet-Neumann maps applied to that sigma. I mean, sorry, phi. So here I took phi to be the set of e to the i n thetas. You can choose different phi, for example, just classic tree patterns or other patterns and crank this out. The important thing is that you've done separation of variables. You know, you've done separation of variables, and so you have this infinite series, and you can find a bound on it. The bound in the operator norm is A times R. So this is just a bound on that quantity you saw under the summation sign. So for any n, it's bounded by AR. And remember, R is the radius of that disk, and A is the contrast. So, you know, for a fixed contrast, You know, for a fixed contrast, which you can choose to be larger than that epsilon, that arbitrary epsilon that we were given when we were talking about discontinuous dependence on the data. So choose your A as large as you want. Then you can choose R, you know, to be arbitrarily small. And so you have that your data and operator norm is arbitrarily small. But these conductivity distributions can be significantly different in amplitude. So, how this plays out. So, how this plays out in the measured voltages, I'd like to show you with some simulated data. So, let's consider two phantoms. And this may be a good time to remind everybody, CT images are in DICOM orientation, and so that means the viewer's right is at the subject's left. So I do know my right from left, and I'll be calling the right-hand side the left because that's the subject's left. We'll just assume everything is dichotom orientation. So, the left lung has a significant pneumatic. Has a significant pneumothorax in this model, which is modeled by a region of low conductivity because that would be air, which would be less conductive than healthy lung tissue, which is the light blue. Okay, so I simply ran the forward model with trigonometric current patterns being applied on the electrodes on the boundary, one milliamp of current amplitude. And what you see on the right here are continuous plots of measured voltages on the boundary. Voltages on the boundary again, this is all simulated. So, with the pneumothorax, so the data from the phantom on the right is plotted in blue, and the data from the phantom on the left is plotted in red. Okay, so the voltages we measure in the first place when we apply one milliamp of current amplitude and use realistic values for the tissue in the simulation are on the order of millivolts in the first place. And so, you know, these barely discernible differences are on the order. Discernible differences are on the order of single millivolts, and they get smaller as the spatial frequency of your current amplitude increases. Okay, so what that means for the Jerusalem to Neumann map, and I am sorry that this is not really easy to read. Maybe on a big screen it would be, but anyway, the scale on this axis is 10 to the minus 4. So the difference in these maps is on the order of 10 to the minus 4, which is really. Of 10 to the minus 4, which is really, really small. So there's the opposedness in action. These two conductivity distributions are significantly different, and we care about the difference a lot since one has a pneumothorax and one doesn't. And yet the data is very, very similar. Okay, so what is the state of the art? Well, EIT is being used clinically in hospitals in Europe, not yet in the United States. Yet in the United States. So, Draeger, for example, has a commercial EIT system called the Pomo Vista 500. And if you go to their website, which I pasted below, you can find lots of information, including examples of their images. Here they are. So these are cross-sectional images that they use in the clinic. Okay, you may not be impressed by the spatial resolution, and that's what I would like to address in this talk: how can we improve that spatial resolution? We improve that spatial resolution. Okay, so the use of spatial priors has been a successful approach for both iterative and direct methods. However, you know, it shares some things with machine learning. Great care has to be taken not to bias the images with the prior. So I'm going to present an approach to post-process D-Bar images using a statistical prior constructed from an anatomical atlas. And it's included in the D-Bar method using a SHER complement. In the DBA method using a share complement method. So, this is joint work with my postdoc, Tales Santos, Mikio Nakanishi, and Eric Camargo from University of Sao Paulo, Marcelo Alamato from University of Sao Paulo, Yari Caipio, who was at Auckland but has moved back to Finland, and Raulina, also from University of Sao Paulo. Okay, so that will be the Approach for post-processing, I'd first like to review the equations of the DBAR method. So, DBAR methods are really a class of methods. There's not just one. And they capitalize on the direct relationship between the conductivity and complex geometrical optic solutions to a PDE that's related to the inverse problem. They have the attributes that they're nonlinear, mesh independent, and trivially parallelized. Dependent and trivially parallelizable. So, here are some intermediate functions that I'm going to be describing to you to go from the data, our Gerzade Neumann map, to our conductivity distribution sigma. Okay, so the first step will simply be to transform to the Schrödinger equation. That's a classic transformation. Different D-bar methods capitalize on different transformations, but in this case, On different transformations. But in this case, this is the DBAR method based on the 1996 uniqueness proof by Adrian Machman. And that transformation is to the Schrodinger equation through this change of variables to get your Schrodinger potential. And psi is defined to be the square root of sigma times u, where that's the u from the generalized Laplace equation. Okay, so that transformation results in the Schrodinger equation. We can extend it to all of our two. We can extend it to all of R2 because sigma is only supported on the finite domain omega. And so outside of that, we can assume the conductivity is zero and just extend everything to the whole plane. And then we can talk about the Dirichlet-Neumann map for the Schrödinger equation. It's related to the Dirichlet-Neumann map for the generalized Laplace equation through this formula. And I included it because I'm going to Included it because I'm going to use these notations interchangeably. The reason being, if we make the assumption that sigma is constant on the boundary, this term drops out since it's an outward normal derivative on the boundary. And you just have sigma to the one-half times lambda sub sigma. And so there's this very simple relationship between the two. And it's straightforward to get an approximation for to sigma on the boundary. So well. So we'll use those two notations interchangeably. Okay, so let's go through briefly the equations of the D-bar method based on Adrian Nachman's 1996 global uniqueness proof. So I already showed you the change of variables that leads to the Schrodinger equation. So that is what this function psi is, but you'll notice it has another variable now. And I should explain z. Z is going to just be associated with a Is going to just be associated with the point xy in the plane. So xy is a point in omega or outside omega. We really don't care outside omega, but anyway, it's associated with the complex variable z through x through z equals x plus iy. And then we introduce an artificial complex frequency k. So k is a complex parameter. And it comes in as follows. We assume We assume that psi has the asymptotic behavior e to the ikz. I apologize, I didn't write it on this line, but that's how k is introduced through the assumption that psi is asymptotic to e to the ikz in a certain sense. And then psi will satisfy the Littman-Schwinger equation. We also care about mu. Mu comes out over here, but it's simply related to psi. Related to psi by multiplying psi by the reciprocal of its asymptotic behavior, e to the minus ikz. So then mu is asymptotic to 1 for large k or large z values, and it satisfies this Lippen-Schwinger equation 1 minus GK convoluted with Q mu, where GK is a fundamental solution for this PDE. This PDE minus Laplacian, that's not a surprise from the Schrodinger equation, and this term with the d-bar operator, and that's a d-bar derivative with respect to the variable z, comes in if you just take this change of variables and plug it in here. Okay, so we care about psi because it's an intermediate function that we're going to need in the steps of the solution. Steps of the solution. T of k is the scattering transform that I'm going to introduce in the next slide. So if we need psi to compute t of k, which we do following these arrows, we need to be able to construct it from the data. You know, the Lippmann-Schwinger equation for psi would involve Q convoluted with psi. Really, I can just tell you what it is. It would be psi equals e to the ikz minus the Fiday of green. Minus the Fide of Green's function convoluted with q psi. And you know, you don't know q unless you know sigma. So the saving grace is this equation for psi on the boundary that involves the Dirichlet-Teneuman map. So again, this GK is the Fiday of Green's function for the Laplace equation, which takes that asymptotic behavior into account. And so then Into account. And so then we have this formula, the boundary integral equation for psi in terms of our tersitime among data. Okay, so the scattering transform is the key thing in getting our sigma from the d-bar method. I mean, mu and psi are critically important too. It's a kind of nonlinear Fourier transform of Q. So this is the definition of T of K. And from the definition, K and from the definition, you can see the similarity to the Fourier transform because the asymptotic behavior of psi is e to the ikz. And if you plugged that in, you would see that in the asymptotics, this is a Fourier transform of Q evaluated at minus 2k1k2, where k1 and k2 are the real imaginary parts of k respectively. Okay, again, we don't know q, and so the definition isn't going to be. The definition isn't going to be useful in the steps of recovering σ. Again, we need a boundary integral equation, and that was also part of the constructive uniqueness proof of Nachman. And here it is. We have that T of K satisfies this integral over the boundary of E to the I K bar Z bar times our dressed and Roman data applied to Psi. And we know Psi on the boundary from the box in the previous slide. Previous slide. Okay, almost there. μ satisfies a d-bar equation, a first-order partial derivative with respect to k bar. And here it is. It involves t of k on the right-hand side, 4 pi, k bar in the denominator. This exponential function has modulus 1. And then on the right-hand side is also the unknown function mu. It's the conjugate of mu. You okay, that can also be cast in integral form. So, if you use, for example, the generalized Cauchy integral formula, you can write it in integral form, or you can think of it as convolving this right-hand side with the Green's function for the d-bar operator, which is just 1 over pi k. Okay, so these are all the equations that we're going to need to solve numerically in order to compute psi. Once we have mu. Once we have mu of zk, you can see from the Schrodinger equation that if you evaluate at zero, mu squared has got to equal sigma. So you're home free once you've solved for mu. Unfortunately, we can't solve directly at k equals zero because in this equation, you can see that you need to solve it for all k simultaneously. But you can solve it one pixel at a time for z. Um, pixel at a time for z, so it's trivially parallelizable in z. Okay, so I'm going to go through these steps briefly one more time. I'm not going to go through how they're all solved computationally due to a lack of time, but if you have questions, please feel free to ask. I'm happy to tell you or point me to references. So, the first step is to get an approximation to your data. So, in practice, what we get are matrix approximations. Matrix approximations to these mappings. Then you want to compute psi from the data by solving the boundary integral equation. S is just shorthand for that integral operator that I showed you on the previous slides. We want to compute the scattering transform from this boundary integral equation once we have psi on the boundary. Compute z of zk in this case from the integral form. From the integral form of the d-bar equation. This can be accomplished through Vas Fourier transforms because of that convolution with the Green's function for the D-bar operator. And then finally, we simply, I wrote it as a limit, but we evaluate at k equals zero to compute signal. Okay, so some computational considerations and regularization. The computed scattering transform is going to blow. The computed scattering transform is going to blow up for large K. That's where the opposedness manifests itself. And so the K domain has to be truncated. So truncating the scattering transform, solving for mu in the truncated domain following the steps above, and computing sigma as in step five constitutes a nonlinear regularization strategy. So the proof of that can be found in a paper in inverse problems and imaging that's cited here. Imaging that's cited here, which is joint work with Kim Knudsen, Mati Lassis, and Samuel Seltanen. In that paper, there's formulas for what the truncation radius should be. So maybe I should slow down for just a minute because this is an important point. So truncating T of K, in other words, setting it equal to zero outside of some radius capital R in the K domain is a regularization strategy. And so that means the smaller So that means the smaller the truncation radius, the more blurring you will have in your reconstruction. So it's desirable to have a large truncation radius. But unfortunately, in the presence of noise, the scattering transform blows up. And the more noise you have, the sooner that will happen. So this is a relationship between the noise level epsilon and the truncation radius that you could expect. And as the noise level goes to zero, then you can take your truncation. Goes to zero, then you can take your truncation radius out farther, and then your reconstruction will converge to the true conductivity. However, in practice, you must always truncate. Okay, so before I go to the sure complement approach, I wanted to very quickly show some two slides on results of a deterministic approach to regularization. So, one natural thing, and this is Thing. And this is joint work with my former student, Melody Alsacker, who worked on this for her PhD thesis. A natural approach is to consider a spatial prior and extend your scattering transform by appending it in an annulus outside the truncation radius that would be appropriate for the problem given the noise level. So if you have a spatial prior, you can compute the scattering transform from the definition and simply append that scattering. And simply append that scattering transform in an amnulus. Now, the tricky thing is: remember, the conductivity is known, so it's unknown, is unknown, but it needs to be known in the prior. And so I won't go into the details here, but matching these is important. And finding the proper conductivities to assign to the prior is a tricky problem that can be. Is a tricky problem that can be solved separately using a constrained nonlinear optimization problem. So that's how that was done in a study where we constructed a dynamic spatial prior from CT scans. And this was also joint work with Rashmi McMurthy, who is at the University of Helsinki on a postdoc and was one of my former students as well. So we had inspiratory and expiratory CT scans of, again, these are cystic. Of again, these are cystic fibrosis patients from Children's Hospital. And we used segmentation of those scans to construct a dynamic prior. So here are four snapshots of a prior. And then we use that to assign conductivity values and compute the scattering transform in that annulus by the definition and append it to the scattering transform from the data. Scattering transform from the data. And that was done dynamically because we had a movie of EIT reconstructions that we could compute from data that was taken off this patient during tidal breathing. So here you can see the results. This was the reconstruction of peak inhalation, peak X or partial exhalation, and further exhalation. And I didn't mention, this is the diaphragm here that was coming into the plane of the electrodes, which is Electrodes, which is a higher conductivity region than the lung. And so you can see it's showing up and making a difference in the reconstruction that would otherwise be interpreted as an artifact. Okay, now I want to turn to the post-processing approach, which is quite different. So suppose we have a set of 2D cross-sectional conductivity images that are computed from an anatomical atlas. From an anatomical atlas. So, in other words, in this previous work, we had access to the CT scan from that specific patient. They received a CT scan as part of their standard care that same day that we were taking the EIT data. In fact, immediately after we took the EIT data. But suppose we don't have that. Well, if you have a bank of CT scans, cross-sectional images, you could compute what's called an anatomical atlas by segmenting. An anatomical atlas by segmenting them and assigning conductivity values to them in different ranges. And I'll talk about that for our specific examples in a few slides. So you have this atlas of conductivity distributions that somehow represent your group of patients. And let's denote this set by sigma sub i. Let's say we have n of them. And let's let sigma bar denote the mean of the sample set. So this is. Set. So, this is just to give you a visual. This is the mean and standard deviation of the anatomical atlas that we're going to use in the results I'm going to show you towards the end here. Okay, so for each conductivity distribution in the sample set, we can compute a d-bar reconstruction by first simulating data that corresponds to it and then computing the reconstruction. So let's call that reconstruction sigma sabi. That reconstruction sigma sub I hat, and if we put a bar over it, that's going to be the mean of that sample set, so the mean of all the reconstructions. And we can denote by gamma sigma sigma and gamma sigma hat sigma hat the marginal covariance matrices of sigma and sigma hat. In other words, those sets. And then here we have the cross-covariance matrices, and we can arrange them. And we can arrange them in a matrix where the marginal covariance matrices are on the diagonal and the cross-covariance matrices are on the off-diagonal polygons. Okay, then the post-processed estimate, which we'll denote by sigma sub PP, of the actual sigma given a reconstruction can be computed by this formula for the expected value. Expected value. And I'm not going to go into the specifics of how the share complement property is being used here just due to concerns about time constraints, but I can point you to references. So that expected value is given by the mean plus the matrix element, so this cross-covariance matrix, sigma, r gamma, sub sigma hat. sigma sigma hat the inverse of this element of the diagonal just going to say that so i don't stumble over all these subscripts and then the difference of that particular reconstruction minus the mean okay so this is you know given a reconstruction okay then there's a concern that this may not be invertible due to the small sample size and so we regularize it by replacing We regularize it by replacing it's not necessarily symmetric positive definite, so we just add a small parameter kappa times the identity to it to force it to be invertible and replace that sigma gamma sigma hat hat sigma hat sigma hat by this regularized matrix. Okay, so rearranging terms here on the right-hand side, you know, just distribute this to the To the sigma hat, that's this first term, and then group this along with this distributed to the mean of the sigma hats, that's the second term. And then we can see that this is a matrix applied to sigma hat. Remember, that's our d-bar reconstruction. So we'll denote this matrix by A sub kappa since it depends on kappa. And then the right-hand side or the vector B sub kappa. B sub kappa, which is also obviously dependent on kappa. Okay, so I think the notation can get a little intimidating here, but I hope that was relatively clear. So the important thing is that this is the reconstruction, the raw reconstruction by the D bar method from the data. And this one is the mean of the reconstructions of the samples from the anatomical atlas. From the anatomical atlas. Okay, and that is how we post-process the image. So I'm going to show you two test cases. So we'll consider data from two patients at Children's Hospital, Colorado with cystic fibrosis who also received CT scans as part of their care. So these patients are going to include a 17-year-old male who was in stable condition, who was in for just a routine visit. These are These are two snapshots of his CT scans, so you know, those don't look too bad, right? Those are his lungs. And then the second patient, though, was an 18-year-old male, and the radiology report said there was significant air trapping through the majority of the right lung. Remember, this is the right lung, as well as the presence of peripheral mucus plugging, most prominent within the right lobe, and cylindrical bronchiectasis throughout the chest, bilaterally. Throughout the chest, bilaterally, which was greater on the right-hand side, which is our left. Okay, so these are the specific CT scans, but they were not part of the anatomical atlas. In fact, the anatomical atlas was built from CT scans of 74 adult male subjects, and those had been collected for a previous study at the University of Sao Paulo. So, those there's some steps to show in the construction of this atlas, and they need to be. Atlas. They need to be segmented. They need to be scaled so that they are the same size when you're constructing the atlas. And then you have standard deviations in the contour and things like that. But they are segmented in terms of the bones, lungs, heart, and muscles. And then, you know, we want to change those over to an atlas of EIT images. So conductivity values were assigned. Assigned at random with these means and standard deviations. And this data was collected in vivo for heart, lung, and muscle. That's where these values came from, was from an in vivo study, but it was on pigs and in vitro on bone. Okay, so in case you're interested in the values, and then this is the mean and standard deviation. It's actually the same set of images I showed you earlier to give you a visual of. Give you a visual of the anatomical atlas. So, I just want to emphasize that the atlas doesn't contain any patients with cystic fibrosis. They're adult males. Okay. So this maybe before I go to go, this is where it ties in to several things. You know, you want your atlas to be representative of your patient group. However, at the time, we didn't have sufficient didn't have sufficient CT scans to form an atlas of cystic fibrosis patients. So we worked with what we had, and our atlas consists of something like 15,000. I have to double check the paper scans actually because we used, you know, the layers are very tiny, like one millimeter, sometimes even half a millimeter thick for CT scans. So we used multiple layers so that we would have more scans. And then these different perturbations of the conductivity values. So our sample size in the atlas actually is around 15,000, if it's not 74. So we capitalized on that to increase N. Okay, so we, I kind of wish I would have put a flowchart, but hopefully it's clear in your minds that from these scans. That from these scans, from these elements of the atlas, we then simulated voltage data from applied currents and computed d bar reconstructions. And so that formed our set of samples. So the sigma sub i's are the elements of the anatomical atlas, and the sigma hat sub i's are the d bar reconstructions. Okay, and then just using the formulas. That I showed you above. We computed reconstructions. And I denoted the post-process reconstructions by the word sure complement because that's a piece that went into the formula for the post-processing using the expected value. These are the D-bar reconstructions in this row, before any post-processing, and we also compared to one step of a Gauss movement method. Of a Gauss movement method. So, this is the patient one who is in stable condition. So, here you can see, let's just go through it row by row, the Gauss-Newton reconstruction of the data collected at full inspiration, the data collected at full expiration. We actually collected continuous data during the pulmonary function test, but I just want to show two snapshots here. And then we can take the difference: inspiration minus expiration and look. Minus expiration and look at that image. Okay, so that's what was yielded by just a straightforward regularized one step of the Gauss mutant. And I stuck with one step because that would be a real-time reconstruction, just like d bar is a real-time reconstruction method. So this is the d bar reconstruction here for inspiration, expiration, and inspiration minus expiration. And then these are the post-processed results using the Shirkon. Using the Schur complement method with kappa equal to 10 to the minus 5 and kappa equals 10 to the minus 12 for comparison. For this data set, they are extremely similar. Okay, let's take a look at patient two. I didn't include the CT scans for patient one because I think they're easy to remember that that patient was healthy, and so the ones should look relatively symmetric and intact. I can flash back if anyone wants to see those, but I did include. Those, but I did include them for patient two here. And to keep the slide from being too busy, I just showed the right-hand column: inspiration minus expiration. Okay, so for the Gauss-Newton reconstruction, reconstruction of the inspiration minus the reconstruction at expiration, we have this image on the left. And, you know, again, it shows that there's definitely pathology in that right lung, the kind of That right lung, the conductivity is much higher than that of the left lung, which you would expect with all of this air trapping mucus plugging your bronchie to system there. There's just a lot more dense tissue, and dense tissue does correlate to a higher conductivity. Okay, here's the D-Bar reconstruction. Quite a few artifacts there. But again, the left lung is less conductive than the right lung. However, the post-processing really shapes that up, and you can see. Shape set up, and you can see better definition in the shape of the lungs and the fact that you have this pathology in the right lung. So let me see, I need to check something. Yeah. We formed quantitative measures. You know, there's different ways of looking at these, right? You look at it. Yes, this looks better. We also have quantitative measures that I didn't. Measures that I didn't include in this talk due to interest of time, in which we again segmented those CT scans, used assigned conductivity values, which were normalized because one really needs to ask how do you compare a CT image to an EIT image when they're measuring two different things, density versus conductivity. So we normalized those things and we used SSIM measures to quantify the accuracy. To quantify the accuracy of the reconstructions. And in every case, the accuracy of a D-bar raw was higher than that of Gauss-Newton. And then the accuracy of the Schair complement method was significantly higher. So that's one way of measuring besides just visually to see how the two compare. Okay, so I'm just about out of time. In conclusion, At a time. In conclusion, you know, this was a feasibility study. It was a new method to show that the use of a statistical prior as a post-processing tool has the potential to significantly improve the spatial resolution of these images. I think it's promising for bedside imaging of patients with ARDS and chronic lung disease, as well as monitoring. And this overall method is applicable to other reconstruction algorithms and other modalities as well. So I thank you for your attention. So, I thank you for your attention and I thank the NIH for their support of this work. Thanks again for this opportunity to speak here.