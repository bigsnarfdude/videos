Equally wonderful patient with lots of interesting people and friends of the family on the fundamental limitations on of content computing. And me trying to be faithful to the theme of the workshop, that's also the title of my talk. So when I recently put out this title publicly or this slide publicly, it was a bit of an outrage, saying, how dare you? This looks so negative. Well, in a way, I will kind of have a rather optimistic stance to the problem. Stance to the problem to be a bit of a manic depressive phase when we kind of look at potential and limitations of near-term quantum computing viewed from a rigorous perspective. So some of the interest in the field stems from the fact that quantum computers not only promise advantages in computational tasks, but this promise seems to be moving closer. Seems to be moving closer and closer to reality, creating a lot of interest in the field, mostly for good reasons I'm tempted to say. Now, quantity computing is not a new idea. Randof Deutsch and Feynman looked at the problem already in the 80s, but only in the last five, six years or so protagonists set out to actually build such devices to a reasonable scale. These machines are still Machines are still not super large, they're noisy, they are what they are. But to be fair, such machines seemed totally inconceivable not very long ago, creating an interesting state of affairs. Now, the elephant in the room, however, is the question, whether we can reasonably hope noisy, realistic quantum devices to provide some sort of speed up over classical computers in a meaningful way. Computers in a meaningful fashion, and what can we say about this from a rigorous perspective? Good. So, for very much paradigmatic problems, there seems to be an advantage of a kind within reach. There's some, I mean, the simplest of all quantum problems are sampling problems where you just go into the lab. I mean, not me, never let the theorists into the lab, but somebody goes into a lab and just takes raw. Into a lab, it just takes raw data following the Bohr rule. And if you take these raw data, there are some settings which are so subtle that you are generating samples that are pretty close to being uniform, but they have funny tales so that you cannot classically re-simulate from a nearby distribution or simulate sampling up to a constant area with the total regression distance is classically harder. You would get a collapse of the polynomial hierarchy to the third level. The polynomial hierarchy to the third level. Such things cannot only be done, but they have been done. I was in Santa Barbara at the time when they did the first experiment of the type, and literally every Uber driver would be talking about this. So that's exciting, but there's also lots of fine print that makes this interesting and subtle. You just put a review out on the matter in the areas of modern physics. For example, it's hard to verify that you've done the right thing. So if you go into the lab and check, You go into the lab and check whether things have been right, or you just look at classical data, want to do black box verification, and asking whether you can, in a device-independent fashion, verify the correctness of the distribution. There is a hard obstruction in polynomial sample complexity, so you cannot do it. So, to build trust in the functioning, what people usually do is like things like linear cross-line GP benchmarking, which is computationally inefficient, but sample is. Computation inefficient, but sample efficient to kind of build trust in the functioning of the scheme. Picking up a line of thought that you heard yesterday, what is interesting, if you have trust in the quantum measurements, you can do something. So there are schemes where you can take quantum data and from the quantum data you can infer that you've done the right thing, but you cannot make predictions on the samples. You have to do the experiment, but you can verify the correctness of the scheme. The correctness of the scheme in an efficient fashion, which is kind of interesting. Noise is harder to live with, and we've heard a couple of times that under noise, there's good reasons to think that you can classically simulate the output distributions of random circuit sampling. So, the last word hasn't been quite spoken here, but that links to the theme of this function. So, that's in conversation. So that's encouraging. There might be scope for quantum devices to outperform classical computers, at least on very much paradigmatic problems, but that cannot be the end of the story. I mean, that's surely not very practically minded. It has no application whatsoever. It's not quite right, but not very convincing applications. Also, well, you Well, you're going to kind of see what happens, like what kind of practical applications you can think of. So, like the answer to this question depends a little bit on who you ask. So, if you talk to more physics-y-minded people, they get very excited about things like programmable quantum simulators with Redberg atoms and so on. More computer science-y or practically-minded people will presumably talk about the wish to find applications in optimization. Applications in optimization or machine learning, or so. And in the first optimistic part of the talk, I will indeed meditate on the question: what extent we could hope to find applications in machine learning and optimization from a rigorous perspective. That said, there's not only the good, but also the bad and the ugly, which is that it doesn't seem to be so easy. In particular, noise seems to be spoiling part of the show. Part of the show, and there's the seminal result by one of the organizers here showing that basically in log depth or in polylog depth, you're close to the maximally mixed state or the Gibbs salvaru ball, which means that you're pretty much exponentially quickly sinking in the ground of noise. So, what can you do in the light of this? And we will look at new ramifications of this story and look at other, possibly even stronger, limitations. Possibly even stronger limitations for quantum computing under noise, and then we will meditate at the very end, depending on how it goes with time. I'm a bit ambitious with my program, so let's see how it goes. Good. Oh, yeah, good. They're good. On applications and machine learning and optimization. Now, machine learning has changed the world we live in. There's very little ground to deny that. Basically, every algorithm that makes predictions. Algorithm that makes predictions based on earlier training data originates in one way or the other from a notion of machine learning. Chat GPD is everywhere. You play around with these gen AI image generators. Well, it's hard to avoid. I've also lots of stories about this, but I will not bore you with this. So, I mean, given that machine learning is so impactful on the one hand, and that we know that quantum computers can solve some highly structured problems better than classical. Structured problems better than classical machines, it does make sense to think whether there is scope of quantum devices to improve matters in meaningful machine learning tasks. So is there scope for quantum assisted machine learning and what does that mean? Well, in the perfect world, it would mean that we would like to have rigorous guarantees for state-of-the-art learning algorithms applied to real-world Applied to real-world data sets. That would be nice. So you would have data sets like pictures of cats and dogs or these numbers here applied to stochastic radiation sense, some training mechanism or some model, say, parametrized quantum circuit, and it should be working better in a way. What can that mean again? It can mean that we take pictures of cats and dogs and numbers, whatever it comes in. Cats and dogs and numbers, whatever it comes in, and you take fewer samples of cats to learn how a cat looks like. That's an advantage in sample complexity. You could think of taking pictures of cats and dogs and you think quicker to make a conclusion. So you have an advantage in computational complexity. You could think of generalization bounds that make predictions based on unseen data. Even better would be like Even better would be like quantum upper bound and classical lower bounds in the way that you say, Okay, I think of a specific quantum algorithm, or algorithm of the quantum side that's very detailed, very concrete, is explicit, and a specific model like parametrized quantum circuits on the quantum side that is there and specific. And you compare this with any classical learner on the right-hand side. Side, no matter what, you say, is this specific quantum algorithm better than any classical learner on the right-hand side? This is presumably the strongest possible advantage you can hope for. That's a wish, I mean I'm young enough to wish, but that is a meaningful setting. And while this may be too ambitious, we will look at this question first for very much finding. For very much fine-tuned data sets, no pictures of cats and dogs, but fine-tuned data sets asking whether there can be an advantage of this point. So, specifically, this would mean in generator modeling that you take seed randomness and the generator would spit out data from a given family of distributions called complex model class in this concept class in this setting. And then, given Class of this setting. And then, given the randomness and you spit out samples, the task of the learner is to take data, learn the concept, and then spit out new data, new pictures of ships, cats, dogs, whatever, based on the training data. And it should be similar to the pictures this learner got. And the task is to learn a generator of a given distribution. That's generator modeling. You can also think of density modeling, where you want to learn. Also, think of density modeling where you want to learn the actual distribution. Let's not go there for a moment, although there's something to say about it. So, you want to learn the generator of a distribution. Let's have a bit of fine print here. The setting we are in is that of probably approximately correct learning, which is a kind of notion of being learnable in the sense that if there is an algorithm A, that for every distribution. Every distribution and the concept class and every epsilon delta given access to an oracle. Careful. This oracle is not a qpex, qrum, q sample oracle. It's just taking classical data, classical samples from this classical distribution taken as the input to the algorithm. So just stuff you can write on a sheet of paper. And outputs in time is polynomial, all the parameters with probability at least one minus delta, a generator. At least one minus delta, a generator of a distribution that spits out samples of a distribution that's nearby in a meaningful distance, so it's approximately correct. So you take pictures of cats and dogs, you think, and you want to pit out pretty likely, pretty much pictures of cats and dogs. That's what clock learning is about. So, can there be a quantum advantage? So, are there distributions that are efficiently quantum? Are efficiently quantum generator learnable with an explicit quantum algorithm on the left-hand side for the Kubernetes-Leipzer divergence and the natural sample oracle. So, again, classical data you can write on a classical paper, which are not efficiently generator learnable no matter what. On the right-hand side. And the first result in one is to say that. To say that, yes, indeed, this is the case, under my technical assumption. This is the case. In fact, this is a super polynomial advantage of quantum over classical learners in this very strong sense. How does this work on the highest level? Well, I will not go into the details of the proof, but on the highest level, if you show it's kind of quantum easy and classically hard. And if you are used to these problems, you will anticipate that the classical part is. That the classical part is harder to do than the quantum part. For the classical world, we are standing on the shoulders of giants in that we, well in fact, on the shoulders of Kerns and collaborators who look at pseudo-random functions, which are collections of key functions that cannot be distinguished from uniformly random functions by any polynomial time algorithm. On one set, you have just a number of entries in the domain, in the other one, you have. Domain and the other one you have uniform filling of the domain and you cannot discriminate the two by a polynomial metric algorithm. And that's used to set up hard to learn distributions in that you take seed randomness and you append the output to this pseudo-random function and this turns out to be a provable hard to generate a learn family of distributions, ARCA concept class, that's the hard bit on the The heartbeat on the classical side. Well, that's the high-level argument that the actual reduction is more elaborate, there's entire polynomial reduction behind this. But in the machine removal of this argument, it's a one-way function, a discrete logarithm, in fact, and we know how to deal with one-way functions in quantum information. School's algorithm solves the discrete log problem in polynomial time. So ultimately, the quantum algorithm. Ultimately, the quantum algorithm works by going backwards in this Mikali-Gold-Rice-Goldwaser tree construction for these pseudo-random functions using this discrete logarithm, works itself backwards and cracks the hard-to-learn distribution class with a quantum gift wider that gives rise to a classically hard-to-learn distribution. So, quantum computers can learn better. There is a proven quantum generator learning advantage in the sense that quantum computers can learn exponentially. Colleague beaters can learn exponentially more efficiently in this strong sense, but not from pictures of cats and dogs. But at least in principle, the field exists. There's something to be done which is very encouraging in a way. How about pictures of cats and dogs? I never thought: is there a different approach to the problem? And on this, And on this front, we thought: is there a way of using actually quantum computers to not use them in variational quantum algorithms, but to use them to train classical networks, in fact, large-scale pruned networks in classical machine learning. And for this purpose, we devised variants of HHL for training sparse classical networks and showed how that is possible compared at least with the family. Compared at least with a family of meaningful classical training networks, where we trading algorithms, where we found that in some settings there's a superparanormal separation of the quantum learning over the classical learning for suitable families of sparse classical networks. And that also works indeed for highly unstructured and natural data. So we applied this to the CIFAR-100 data set, which is like an industrial standard for machine learning problems, where it performed quite well. For machine learning problems, where it performed quite well, which is kind of a different stance to the learning problem. This time, it's not a quantum algorithm for evolution itself, but a quantum algorithm for the training of classical cats. This also works for pictures of cats and dogs. Actually, that's a picture of our own cat. It's kind of interesting because I get up every morning very early at 4 o'clock, and the cat is new, it just moved in three months ago. Moved in three months ago, and the cat. I mean, I get up at four, I open my computer, I have a coffee, and start working on papers. But the cat thinks that's the way to do it. So the cat comes up, wakes up, sits on my computer, takes its claw and puts it into the coffee cup and licks it. There's no medical application on the board. It's kind of cute because the cat thinks that's the way to do it in our family. That answers the question of Michael earlier today, whether this is a human behavior. No, it's also a cat. Human behavior. No, it's also checking. Yeah. So it's the technique for proving that it's super cool. Ah, I mean, so we have like four pages of text and then 30 pages of appendices. So we basically, it's a kind of dissipated version of HFL in a way, which we compare with families of stochastic radio descent for the training of the data. But then there's lots of fine-pretty coming in, of looking that it's sparse enough, but not too sparse, that you cannot find a classical sampling algorithm for the same. Classical sampling algorithm for the same thing, decantizing this, so that's what we do. It's like a speedup in terms of the number of steps. Yeah, it's in computational complexity, that's right. Yeah, it's not in a super complexity. Okay, you elaborate more on that file print. I'm just curious. Yeah, but can I do this at the end? Then I will do this. There's also something I will not talk about on near-term, like short-circuit separations. I will cut this out. Maybe I have one more example and then we move to the negative side of things. But I've done. Things, but I don't forget your question, which is on combinatorial optimization. It's another application that's much discussed in the literature as a potential application of long-term or near-term quantum computing. But every day there's something, you see, like lots of fuzz about this. But it's not so easy to think what it even meant by that. By that. So, I mean, the problems we have in mind here, say, integer programming, they're surely valuable in basically any kind of industrial context, but then they also empty hard in worst-case complexity commonly. So that means, of course, that classical algorithms cannot find efficient solutions for all instances, but it also means that quantum computers cannot do this either. So it's not so clear what even on the desk in what way. What even on the desk, in what way one can hope quantum computers or algorithms like quantum approximate optimization to provide a speed up over classical algorithms? And there's lots of claims about this. There was a German Hundredsbud article saying that, oh, quantum computers can solve all problems. I mean, no. I mean, I was making up this joke recently: that the marriage problems of my neighbors are surely not solved by this, but surely also not optimization problems that. Optimization problems that all instantly be solved internally in time. So, what's even on the desk, and in what sense can you hope for advantage? And in this work, it's a technical reduction over computational learning theory, Occam's razor, a la curns, and showing how this relates to approximating optimization problems, where we conceptually understood in what way one can even think of an advantage. Where it's true that a quantum computer can actually approximate some hard instances of integer programming that. Of integer programming that originates from the heart is of inverting the RSA encryption function. So the only assumption is that you cannot invert the RSA encryption function, but then you can approximate some instances of polynomial time on a quantum computer, which you cannot approximate efficiently on a classical computer. So the hardness, easiness region is kind of shifted, and some problems can be solved in polynomial or approximate polynomial time on the quantum computer, which cannot task. Cannot class. So there is a superparanomi speedup, at least in principle. It's an interesting reduction, that's a technical result. I couldn't resist on writing down a Hamiltonian problem, the energy of which would correspond to the energy in a variational problem, but it's not variational. By no means, I wish. But it's constructive, it's a carp reduction, so we can look at specific instances of the problem which we are just exploring now, which is interesting. Which is interesting, but the connection to quantum approximate optimization is not settled yet by no means. But it gives, it's a nice baby step in a good direction in what way we can hope quantum computers to offer an advantage in meaningful problems of combinatorial optimization. Very good. I was so worried about time that I'm actually pretty good in time. It's 20 minutes into the talk, which is a good moment to. Which is a good moment to meditate what we've achieved in the first part and also then move to the negative part. And then there will be time for questions. So the first part looked at idealized settings, showing that there is progress on showing separations of quantum over classical devices for practically inspired problems in machine learning optimization. It's good to know that there's some scope for this. Of course, it's not the full. Scope for this. Of course, it's not the full setting. In learning, we can find in the principal advantage. We can look at training, classical networks. There's even some short-circuit advantages that I didn't speak about, but you don't seem to be getting all this together in the same paper. But it's progress in a good direction. You also look at scopes of combinatorial optimisation, which is positive, it's motivating in a way that there is scope of an optimisation of an advantage. Of an optimization or of an advantage of a comp. But yet, there also seems to be limitations for near-term devices, and that's coming to the theme of this workshop, where we have good grounds to be optimistic, but we should also see things in perspective and not over promise and rather see what is on the desk that we can reasonably do with real-time devices. And let's start from the learning problem that our Problem that I just mentioned on trying to pug learn distributions. At the end of the day, most algorithms in machine learning can be seen as learning probability distributions in one way or the other. So taking data, you want to partner in the distribution, pictures of platforms involved. Now, we've seen that there is such an advantage in principle for photor and quantum computers, but of course we want to see how this works in the How this works in the near-term regime, and it's not so easy to make progress in this NISC near-term regime. After all, I mean, the data we have, like pictures of cats and dogs, are usually not so structured and not easy to address in an emergency mathematical study. Also, the algorithms used of guns and restricted Bolsonaro machines are not so easy to capture from a mathematical perspective. So, to address this problem, we To address this problem, we looked at a vehicle to make some sort of progress in this direction. And given that in variational quantum algorithms, you seem to be having a quantum algorithm sitting in the center that's surrounded by a larger classical algorithm, you could think of how you could learn the output distribution of the quantum part that is part of a big algorithm and ask how easy it is actually to learn the output distribution of a quantum cell. To learn the alpha distribution of a quantum circuit, followed by measurements. And since you apply the Bohr rule when evaluating the distribution, such machines are also called Bohr machines. So what's the how easy is it to learn the output distribution of Bohr machines? And this was a kind of a manifest depressive setting in its own right with ups and downs and interesting insights. So if you have a very deep circuit, Have a very deep circuit, you can generate all kinds of distributions, and we know that there's hard-to-learn distributions. For very short distributions, you get product distributions, surely they are easy to learn. So, at what point does partner set in, and in what way can we learn the output distribution of quantum circuits? Again, in the park sense, in the generator or density modeling sets. Now, interestingly, under Now, interestingly, under reasonable technical conditions, even if you have a depth that's just a bit larger than a constant, the learning of the output distribution is hard, both for generative, where you want to get new samples, or density modeling, where you want to get the distribution modeling of the problem. So, that's surprise. Not very deep circuits give rise to hard-to-learn distributions, and that's actually true for any quantum and classical algorithm. Actually, true for any quantum and classical algorithm, which means that this time the pseudo-random functions cannot be broken, and also it means that the quantum algorithm will not do better. So, in a way, quantum computers cannot even learn their own output distribution, which is kind of funny when you think about this. This is for the sample oracle. Take data, you take the raw data, and put it into the device. What is also meaningful is the statistical query oracle, where you are promised to be like epsilon away from the expected. Epsilon away from the expectation, that's kind of the reasonable static where you take expectation values, and I want to learn what the distribution is based on expectation values. Strangely, maybe I missed it, but what is hard? What does that mean? Ah, you cannot PACLEN the output distribution, the generator or density modeling sense for polynomial many many samples. Authentic number direction. No, no, no. This will come in a second. And for basically expectation values, it's even true at logarithmic depth that you cannot learn the output distribution from polymeny samples in the statistical query oracle sense. Okay, that's interesting. Log depth is just very, very shallow. Also, in particular, in one dimension, you can efficiently simulate. Simulate this setting. So we thought, wait a minute, that's funny. So we could, there's a setting which you could perfectly efficiently simulate, but you cannot efficiently learn the output distribution in the SQ oracle, in the statistical query oracle set. So this is interesting because there's lots of discussions, claims in the literature on the connection between simulation and learning, argue that if something is hard to simulate, then you can also learn it, or if it's hard to learn it. Then you can also learn it, or if it's hard to learn, then you can simulate this. So things get a bit criss-crossy, and people wonder about the connection between learnability on the one hand and simulatability on the other hand. And we wanted to look at this a little bit in more detail. And so, what could be more natural to think of Clifford circuits for this question? We ask, okay, we have a Clifford circuit. For this question, we ask: okay, if you have a Clifford circuit and you look at Clifford circuit followed by measurement, can you park learn the alpha distribution of Clifford circuits? And here the answer is fortunately yes, you can do this. This is efficiently learnable. That's a relief. But it's also much less trivial than it might sound. But I mean, there's still many Clifford circuits around, but this is still possible as the Is still possible as the Clifford output, circuit output distributions are uniform over a fine subspace of the finite field. Then you can basically think of a finite field Gaussian elimination problem to learn the output distribution. So the Clifford circuits are actually easy to learn in this setting. Now we also know that Clifford plus T gates give rise to a universal gate set. So presumably if you have Cliffords and add T. If you have cliffords and add T gates, then you should be generating more and more distributions. So at some point, the problem should become intricate or it should be hard if you add T gates in the setting. So we asked, how many T gates do you need to add for a random Clifford circuit to make the problem hard to learn? And we were surprised to see that you can take a T-gate as a resource, you place it in the circuit. Resource, you place it in the circuit, and a single T-gate makes the output distribution hard to learn. What? I mean, it's crazy, yeah, because clearly you can easily, efficiently simulate the setting. I mean, you would be able to do this for logarithmic MET gaze, both in the strong and the weak sense of simulation. Coming back to the last talk we saw yesterday. Oh, but a single T-grade renderer is learning how. That's an interesting. T gate renders learning hard. That's an interesting reduction by apparently learning about noise. It's funny because there's no noise, but the T gate acts a bit like noise in a way that is used in the reduction. So even though this is perfectly classically simulatable, I mean how not, it's just one gate, you just simulate both branches and you put it together, the learning of the output distribution, you cannot invert the problem. The forward is easy, but backward, you can't go back learning output distribution of flip-flop circuits with a single T-gate. With a single T gate happens to be half. This is actually, technically speaking, even average case heart, which is adding to this. Of course, quantum circuits with logarithmically many the case can be efficiently simulated both in the strong and the weak sense, but you cannot learn. You cannot go back, which is kind of intricate on the learning to simulation or learnability to simulatability setting. I have a question about the average case. So, like, on the average case type is pretty. No, this is for clear quality. Yeah, same thing. So this is a connection between simulation and learning. This seems to be more intricate than thought in the sense that a setting that's not, I mean, simulation and learning do not imply. Imply each other. And this can be seen as an obstruction to proving quantum advantages if you see these kind of short circuits as parts of bigger algorithms. So that kind of shows how intricate this connection is. It's the first biggest insight in the learnability of outputs of quantum circuits. It is what it is, but the the the last word hasn't been um uh spoken here. But it it it shows that the the learning of of of of a distribution is is a very different problem from simulation. Different problem from simulation. In fact, the technical results were shown in the reference I gave earlier. I should give credit to these people here that didn't have the technical results, but they asked many questions in this paper also on relationship between learning and learnability and simulation. And given that this was about the quantum advantage, quantum supremacy of Borne machines, they dare to call their paper the Born Supremacy. And given that we And given that we looked at the identity of this problem and proved theorems about that, about Born machines, we thought to call our paper the Born Identity, but I didn't get this across my course, so we have a very technical title for this one. So, this is about obstructions for learning the output distribution of short quantum circuits. Now, that's set. No, that's it. Actual circuits are. Yeah. Yeah, sorry. Well, yeah, you just said that you can simulate certain circuits, but you cannot have the output of the circuit circuit. I'm wondering whether there are also classical analog, sorry, an analog classical statement, say when you have a probabilistic Turing machine, an analog statement would also make sense. This is true, this does make sense. This does make sense. Yeah, okay, you can automatically do it. But can you always learn the Turing machine description from sampling the output? That's a good question. I mean, I would say I mean the the simulation is much less clear, but the learnability question is very clear. So I would that's a good question. I I would suspect there might be a n uh kind of classic analog. No, that's right. But I mean, you can tell me in the part I didn't speak about, like the separation from constant depth quantum to log-depth classical circuits. We look at classical circuits that have a further locality constraint, like bounded starting gates and so on. Bounded fan in gates and so. So we have to make some sort of locality assumption on the classical side as well. And that seems to be fair in your setting as well. If you think of local classical circuits in the sense that all classical gates have like not geometrically local, but local support, and then you could cook up a nano. That's an interesting question. You have the coffee break after, or the lunch break after this. Thanks. Good. Yeah, okay. The hardness results mentioned that you have one key here and you can't learn it. What kind of hardness is you? What kind of hardness the products have? What's your finding complexity? It's again sample complexity. It's a parity learning with noise problem that's kind of encoded in the problem. And from polymer many samples, you cannot learn the output distribution in the Park sense, that you cannot formulate a generator that would spit out new samples from the distribution, or that in the density modeling sense would give you the description of the parameters up to a given accuracy level. A given accuracy level. Is it both the SQ model or just general measurements? Both, actually. The SQ and the sample error. Good question. Sorry, I have a point. So I think I answered from Paul's question. So I think the answer is there is a parcel analog, and this is because zero random number generators exist. So we know that such generators generate machinery that are computationally hard to learn, but they also do so efficiently. Yeah, but that's what I meant earlier. I mean, maybe that's really something for the lunch break, but I see the point. And you could play with further rules like look at bounded fan indicates and so like restrict the locality, then you might think of a meaningful wondering whether we should be surprised at all. Wondering whether we should be surprised about the result of what is up to you whether you're surprised or not. I mean, I don't know. I find it surprising because it seems like obvious that you could just try the placements of the T-gain and you just kind of check, so to say, but that seems to be not an option. But again, when you come from the classical tradition, you could say, well, I couldn't do this there either. I mean, that depends a bit on whether you're trained from the classical side or the quantum side. I mean, okay, given that there was. I mean, gi gi okay, given that there was so much connect uh uh like reasoning that once you can easily simulate something that should have implication on learnability from that perspective, surely not intuitive. But what you say is also valid, yeah? I don't know. Good. Quick question. Ah, yeah. Yeah, no, it's very quick. So if we replace the T-gate with some noise less than eight-year-old some algorithms? Oh, I don't know. Oh, I don't know. I mean, this is usually this reduction that we follow, and then I mean, the other thing, of course, Clifford was basically any gate would be universal, so presumably the same thing works for any gate, whatever you pick, except for colleagues and Cliffords. But I mean, the specific reduction is tailored here to the static. Presumably, something similar should work. There is actually a paper that does the exact same thing, but multipolly. Oh, but noise, but he's talking about another game. Ah, noise. Ah, that's an interesting thing. That's the matter stays if you have to have a different model. Oh, no, that's right. I missed that point. I thought you meant a quantum gate. That's interesting because our argument originally is already a noisy argument, although it was originally for this T-gate thing. But that's right. That's fine. Good. Speaking of which, that's a perfect keyword to move on. But that's also my last point. Don't worry too much. Also, my last point, don't worry too much. On actual noisy gates. We know that noise is a big obstruction. Actual circuits are noisy, so what can we do with noisy quantum circuits? So ultimately, quantum computers are about implementing circuits. You have a quantum circuit, you want to do measurements, and then you want to infer expectation values or samples from that setting. And while this is an interesting prescription, that's not how it goes. In the real world, there will be noise. In the real world, there will be noise in the setting, and you can ask to what extent you can reasonably estimate expectation values or samples from short, noisy quantum circuits. And that's not so easy. So how would you model noise? A common way of modeling noise would be one where you think of perfect quantum gates followed by channels that capture decoherence and noise. For example, simple depolarizing noise, which is not such a bad model, where you just Not such a bad model where you just apply steps of depolarization of strength p to each of the qubit. You have a perfect layer of gates, you do depolarization and so on. But you could also think of other models or non-neutral models. This is the most common model of picturing noise, which is actually not so bad. I sometimes have called it the Volkswagen of error models in the past. Actually, at some point, I gave a talk at a funding meeting on quantum error correction, and I was referring. On quantum error correction, and I was referring to this model as the Volkswagen of the error models. And after me, there was a speaker speaking about quantum machine learning and was talking about the collaboration with the Tori code of the car makers. I found this kind of cute. Anyway, this is in some settings a reasonable model, in others not, but for much of what follows I will stick to this, although the results also follow for non-euthorised. So how do you deal with it? Well, one answer is you can do quantum errors. Well, one answer is you can do quantum error correction, as Ben has beautifully explained in this tutorial on the first day. That's great, it will give rise to scalable scheme, but it comes along with substantial overheads that may not be within reach in the near-term setting. So what more near-term people would say is that they would do error mitigation, meaning they run the circuit, they take classical data and try to undo some of the noise based on the classical post-processing of the data taken in. Data taken in the experiment in the family of problems that together would be error mitigation schemes. One common scheme of that type would be zero noise extrapolation, where one takes data and accepts that removing noise is not so easy. I wish. But adding noise is easy. You put more noise on it. You add noise levels, and then you take appropriate data at different noise levels and then you interpolate suitably to Interpolate suitably to zero noise, which is a compelling idea, which works, albeit that there's good evidence that this would work with exponential sample complexity, but there is a way in which this would work in a certain sense. But there's an entire family of problems of that kind. You want to see to what extent that can work and what limitations are of this kind. And to approach the problem, we formulated a kind of abstract. Formulated a kind of abstraction of this where you take in states, quantum channels that are noisy, modeled in this way of gate, noise, gate, noise, and so on, taking data, and then you run your classical mitigation algorithm that spits out expectation values or samples, but let's stick to the expectation value setting for now, basically undoing the noise. And this idea of like taking samples and then inferring about expectation. And then inferring about expectation values of meaningful families of observers from a given set of observables, that already smells like a problem of statistical inference. And this is also how we approach the question. So this is seen as a statistical inference problem where we ask, like, how many times we have to go into the lab, how many shots do we need, how many, what's the sample complexity of this? What's the sample complexity of this? We're going to have a lower bound to the sample complexity, asking how many copies of the input state, that state plus circuit, would be needed to estimate the family of expectation values from a given set of observables to precision epsilon and with probability 1 minus delta. Depending on specifics of the problem, you could think of, say, the circuit depth D, you can think of the width of the circuit N, and say the P, the depolarizing P. The depolarizing parameter that runs between 0 and 1 that captures the strength of the noise. So, how well can error mitigation work? And here's the results. So, actually, the samples you need are exponential in P, so it's P, this noise strength, to the power of omega n times D for, so they're the For the depth times the width, both the width and the depth appear for mitigating depolarizing noise in a bound that sets in at log log depth in, log-lock depth in n. There's the mathematician's joke that log-lock is upper bounded by 4. It's not such a bad joke if you think about it. So just a bit more than classical depth, you get an exponential dependence both in n, the width, and d, the depth of the circuit. The depth of the circle. For noise to the noise, there's a similar result, but I'm not going there for the moment. So, how's this, so how can you interpret this? So, one needs e to the power of, like, exponentially of the order n d many samples to achieve mitigation. Previously, it was thought to be exponential, that just reflects the exponential sinking into the ground in the presence of noise. But since in the NISP regime, the depth is supposedly. That depth is supposedly log in n, our results are exponentially stronger in the sense that for given noise levels, the outbound would give a polydependence, but we get an exponential dependence in n in the system. So, there's a severe challenge for variational algorithms in that at log-lock depth, you seem to have an information-theoretic obstruction against mitigation. So, how's the logic of the proof? I give three. Logic of the proof. I give three snippets of three insights to the proof. The first one is to basically set up a learning problem that can be solved with error mitigation in the sense that once you have solved error mitigation, you can also solve the learning problem at hand that we call noise state distinguishability, where you have a fixed set of states from a given set sent to the channel that you classically know. And then it was so can you discriminate the outputs of the known states from the known states? The known states from the known set sent to the channel at the end of the day. Specifically, do so, discriminate the output of noisy circuits from computational basis states on the one hand and maximally mixed states on the other hand. So, that is a kind of a discrimination problem. So, this has a flavor of a multi-hypothesis hypothesis testing problem. This is also the next step of having a lower bound to the Having a lower bound to the sample complexity of this part. And this uses, that builds heavily on Fano's lemma. It's basically given a sample complexity bound of this hypothesis testing task in the sense that any single sample test that distinguishes n plus 1 distributions, so the probability distributions p1 to p n minus 1 of the basis states from the last one originating from the maximally mixed states must fail with this probability here. That's given a weighted sum AAA. Sum, like a weighted sum of red entropies of Kulberg-Leibner divergencies of the distribution compared to the one from the maximally mixed state. And this applies to the noisy state distinguisher of the computation-based state on the one hand and the maximally mixed state on the other hand, where this alpha on the right-hand side that gives this right scaling, like this e to the power of nd, that's expected on the right-hand side. And much of the work is actually functional. And much of the work is actually finding families of circuits that do that, that have that scaling, and construct circuits for which this bound, this relative entropy is huge, for which we invoke a construction of two designs, exact two designs, which are random circuits that look like power random circuits judged on the level of second moments, which happens in log n squared depth for Clifford circuits. Circuits, which we use, accepting that it's good enough to make the purity of the output distributions small, the intuition being that the random service shifts the purity contribution to larger weight Paudi words in that the depolarizing noise acts more drastically on longer Paudi words to set up a quantum circuit where the noise acts in the most malicious fashion and most drastically. Fashion and most drastically in that these high powder words appear in a circuit that is set up to be locked and square deep clifford circuit doing the kind of scrambling thing that makes the bound as nasty as possible. So there are strong obstructions against error mitigation at log-log depth. That's just a bit more than class than constant. That shows that you cannot. Shows that you cannot do error mitigation in a way. So it does not constrain error correction because we do not allow for mid-circuit measurements. But it does apply to a large family of error mitigation schemes that are also used in practice in reality. It should not be interpreted as error mitigation not working. I mean it's a strong obstruction, means in log, log depth you cannot do it. It just means it's just not scalable. It just means it's just not scalable as is. I mean, we've got lots of phone calls from IBM Zurich on that day, but respectful ones. So it says that it's not scaling. It's good for what it is, for finite settings. Things are finite, computers are finite, my life is finite. So get over it. But it also doesn't work for all circuits. You can see that the invitation to think of new intermediate schemes, like coherent schemes, like virtual distillation. Like virtual distillations or like new types that bring in a coherent component, but it also gives advice on understanding that noise and very long-range circuits don't go together so well. You have mentioned this work also earlier today, in that if you have very long-range circuits all over the place and noise that doesn't seem to go well together. So there's a bit of room for Maneuver because it's a worst-case result in that. In that you may have circuits that are a bit more local, so that may make the scaling a bit more favorable. In worst case, at log-lock depth, you will not be able to do error mitigation in this sense. Also, non-unital noise seems to be special in a way, as I've not said so much about this, but that's what it is. Which brings me to the last point, technical point I wanted to make, which is that in fact, non-interference. Non-neutral noise seems to be very different in its effect than anticipated. So it makes a difference whether you have like this Volkswagen type depolarizing noise or non-neutral noise. You have a question? Yeah, so you mentioned the depolarizing noise and non-unital noise. What about the unital noise that is not depolarizing? Does your result long log that apply to any unital noise? Any unital noise? Any unital but not depotarizing. We get bounds for any noise that's also not unital. What I say now will drastically depend on the non-unitality of the noise. But for the mitigation, it doesn't matter whether it's... We have also bounds for other types of unital, but not t polarizing notes. But that does it also give you that log logo. Some variable of log thing. In a sense, you get a different, the constants are complicated, the sequences. Okay, yes. So let me end by this, the insights we had recently. There's a paper coming out anytime in the next days or so on the impact of non-neutral noise because maybe this kind of depolarizing picture was taken a bit too much for granted as the one-size-fits-all model for reasonable noise and for superconducting qubits is actually not such a bad model. In other models, Bad model. In other model settings, this can be vastly and fiercely misleading and really wrong. Sometimes you do have non-unital noise, and what impact does it have? And let me show you three snippets. The first snippet is that if you have a deep random quantum circuit under any uncorrected, possibly non-neutral noise, there's an kind of an effective log-depth picture that effectively gets truncated. So the influence of gates on power expectation values of the end decrease. How the expectation values of the end decreases exponentially while going away from the end of the circuit. So that only the last bit that matters, and the stuff before doesn't really matter. That's a logarithmic picture that applies to all of them. And that answers also, or anticipates your question. And that would work for also non-like unital non-depolarizing models. Good, so there's an effective logarithmic depth. So that's. Depth. So that's interesting. So we also thought about the tradability in the Baron-Prator setting. Baron-Prators, as you might know, are seen as an obstruction to the tradability of variation quantum circuits because the cost landscape is too flat, the gradients are small, it's a barren plateau and that you don't know where to minimize to because the gradient is small in all possible directions. And for random circuits, we all have all the evidence that with high probability the platform. That with high probability, the plateaus will be very barren, the waves will be tiny, and there's a kind of trendability question. Our friends at Rosalam was like making big points on this problem of trainability from barn plateaus. Interestingly, for non-neutral noise, that picks up again your point. This doesn't happen to be the case. There's no barring plateaus for non-neutral noise. There's a provable lack of barren plateaus for local cost function, in that the cost function is never flat and the gradient never vanishes. And that's also a bound to the That also abounds to the variance of the problem of the gradient under non-neutral noise. So there is no barricados on a non-neutral noise. And that's true also for a bit non-neutral noise. In the right scaling, a bit of non-neutality makes it non-barred, which is interesting. That's an unintuitive insight, but it is what it is. But it doesn't mean that you shouldn't be too optimistic, because it doesn't mean you can train. Be too optimistic because it doesn't mean you can trade it. Because, for other reasons, there might be obstructions. In particular, for the third insight, which is that we can classically simulate on average, so in the strong sense, expectation value sense, the expectation of any observable to added the position with 0.1 minus delta with a runtime given by this expression here, which is for constant position efficient and for inverse polynomial position, still efficient in one spatial. Still efficient in one spatial dimension, and but for constant precision, it would be efficient in any dimension. Which is a bit of a bummer because it relates also to David Sandstock. Yeah, so this is under noise, a concentrated noise after every gate. That's right. It's similar model that you have gates, you have noise, gates, and noise, but this noise is non-can be deep, but it's Is like can be deporizing, but it's also non-unital. That's right. But same model. It's like noise intertwined with perfect gates for a random circuit on average. I mean, this is like an average result. And it's very difficult. There cannot be a worst case result. I mean, we can discuss this on the lunch break. I mean, even ontologically, this cannot exist. Yeah. The assumption is also locality assumption of the gates or? Yeah, yeah, it's a breakwork circuit. That's right. That's right, because otherwise the notion of That's right, because otherwise the n notion of dimension doesn't really make much sense if you go all over the place. Yeah. I think more accounts are passable, but are you finding these large partial vertices in the last layer or also in no in the derivatives would be um no no that's right that's right so the the the the the large the The bounce to the varies would be for the last drop layers, so that's fine. But okay, but this kind of is kind of, it is what it is, but large families of circuits for a constant noise level in this sense, like layer, circuit, you can just classically simulate this, which is a is an obstruction, so non-noise acts strikingly differently. There's no baripators in the setting, which is interesting. In the setting, which is interesting, which can be seen as a positive thing, but then there's also obstructions for classical simulation and other constraints against trainability. But it's interesting that this non-unitality seems to be mattering so much in certain fine prints of the problem. We found that interesting, there may be a paper out very soon with more than half of the author lists being organizers of this conference. Good. Coda on near-term devices. I come to the end. So, this talk was about the potential and limitations of near-term computing with all ups and downs as a kind of magic depressive phase of a cut. So we thought about the question whether we can hope noisy, realistic quantum devices provide a speed up over classical computers and started out with some good stuff, some insights that seem to be quite motivating in that there seems to Quite motivating in that there seem to be applications that have a bit of a practical feel to them. They're not like near-time applications in the sense that industrial players would like to see them, but you have to start somewhere they're rigorous and precise and they say in what sense one can approach the real problem from various sides. I think that's a respectable progress and we find that there's a superparanormal advantage in PAC learning of meaningful output distribution in the presumably strongest possible way. In the presumably strongest possible way, as a superparameter of a separation of quantum to classical in density modeling and generator popularity of distributions. Well, that's for highly structured problems. So how much structure do we need? Well, it is where it is. And we also found that a single T-gate renders learning hard in the sense discussed, which is seen as a bad and ugly thing. It's a bit of an obstruction to the problem. But then there's constant depth advantages. This I haven't mentioned yet, but this will also come out soon. Ask me about this. Come out soon asking about this. What this is about. We can separate constant depth from log depth classical circuits, also any meaningful power set, which is again encouraging. Then we found strong limitations against quantum mitigation or large families of quantum error mitigation already at log-log depth that's exponentially tighter than previously known bounds. It's pretty stiff, it's pretty hard obstruction against the known schemes for mitigation. See this as an invitation to think out. See it as an invitation to think outside the box of new schemes for mitigation. I have my own ideas about this. So there might be loopholes. No-go theorems are invitations to think better, but it is what it is. Many schemes will not work at log-lock depth, which is basically a bit more than constant depth, which is an interesting result when it's over. Good thing I didn't mention, sometimes noise is seen as the big evil thing, but a bit of noise can sometimes help in that if you're stuck in the saddle. In that, if you're stuck in a saddle point in some settings, you can show that a bit of noise brings you to the closest local optimum and you will get an advantage from some noise. We even made a nice IBM experience experiment that actually tackles the noise to see whether this was compatible with our theorems. That was kind of interesting because it's a meaningful application of such an experiment. Symmetry can help. Yeah, that's a good thing. I will not go into this. I will not go into this. What is there? You have insights into generalizations and explicitity. That's interesting. I will not say so much about this, but that's also a good thing. Gadgets can be good and bad. There's been work on breaking down anatomy to smaller parts. This does work in a small scale and helps in variation problems. Asymptotically, there seem to be issues. This is somewhere between the good and the bad. Classical sorrow. Classical surrogates, so the lead author is here sitting in the third row, where we had a bit of a heart attack, thinking at some point that because variation quantum circuits can be seen in the full picture, that for large classes of models you can classically sample from the output distribution generated by variational models. And that's indeed the case. So, for some settings, the evaluation of a circuit is indeed classically efficiently possible, but that doesn't necessarily mean that you can efficiently train the model, which Train the model, which gives rise to an interesting state of affairs that the training may be done on quantum devices, but the classical evaluation can be done on classical surrogates efficiently, classically. But that was also a motivation to look more deeply into the mathematics of this. And you have a paper on random fuel features that we can discuss in the frame. I will not go there to really see to what extent you can also have an efficient modeling of the problem for rational quantum circuits. Quantum circuits on the one hand, or in what settings you can hope for a quantum advantage. We found that non-unital noise acts differently. There's still an effective depth picture, but say for Barry Plateau's, non-unital noise is strikingly different. And I end on the note of your talk, namely that this is kind of very encouraging in a way, also a bit demoralized. Is kind of very encouraging in a way, also a bit demoralizing. It is what it is. So, maybe applications of the internet computing, noise makes it pretty tricky. So, the noble results I've shown and you've seen in other talks are pretty challenging in a way. So, maybe the best application we have still to date is to think of simulation, analog simulation, where some of the error scaling and the conjuring up seems to be slightly more favorable over. Be slightly more favored over digital settings, that the cancellation is a bit better. So, maybe we should not push analog simulation completely from the radar. And that's interesting physics-motivated application of this, and this may indeed be the most near-term application of all of this. But this makes most sense if you think of settings like that, where you take data, but you also learn what you have. You can use ideas of Hamiltonian learning to learn what you have. And once you've learned what you have, you can make And once you've learned what you have, you can make new predictions, but now based on a calibrated Hamiltonian that you know because you've Hamiltonian learned the setting. I think this is a good and healthy way of thinking about analog simulation in a semi-certified fashion where you learn things and then you get new predictive power based on the analog simulation of the analog problem. So, can we hope noisy, realistic quantum devices to provide a speed up over classical Over classical computers. This was the big question of this long and winding talk. And my answer to this question is definitely maybe. And on this note, I'm looking forward to potential further questions you might have. Thank you very much for your interest here. So in the presentation part that you talk about the Part that you talk about, the deporizing noise follow when each layer is a gas. Many error mutation principles also apply some intermediate operation during the circuit. For instance, like you apply some gate probabilistically, but you report what gate that you apply there and you use that information in the post-processing stage. I mean, some of these guys are included in our setting and some aren't. So, I mean, if you just, I mean, we know the circuit, we know the noise, and we know the input, so to say. So, in a way, if you kind of apply gates and want to record what gates you've applied, then this would be included in our setting. When you start having like mid-circuit measurements and so on, it would be outside our setting. And some of them are reasonable and should be done. Others are like basically error correction. So, I mean, my short answer is many of these models would be included. Many of these models would be included if you just include information about the circuits in your classical post-processing. If you do like sophisticated mid-circuit measurements, then you might overcome our limitations, but then see this as an imitation to think of intermediate stuff, stuff that's not fault-tolerant, but also not just error mitigation. I'm actually wondering, like, this is a bit of a cultural mismatch, that there's very little good work on. Very little good work on the intermediate realm between classical error mitigation on the one hand and fault tolerance on the other hand. So, I mean, you need more of that. I mean, maybe the threshold is too much to ask for, but maybe you can reduce the error levels. And what you say might contribute here. But, I mean, again, it's a set. Mid-circle measurements, I exclude it from our set. Maybe QAS has something to add to this? Yeah. Um, yeah, I agree with you. Yeah, good. Yeah. Um, I have two questions. Yeah, go for it. Well, it depends on the champ. The first one is related to Aromato being used. Have you ever considered a non-Markovian noise? Haven't you all considered non-Markovian loud noise? Um but I personally have in many settings. Here not. I personally have a main setting, fear not. I'm not, no, no, I mean, it's not so easy to make sense out of that. I mean, depending on the non-MacObian noise, it's completely incorrectable. I think the nice Google paper on the impact of cosmic radiation to quantum computers that really strike and make a catastrophic impact is incorrectable. That's a highly That's a highly non-Macovian noise. But presumably, if you have a non-Macovian noise with some range in space and time so that you can coarse grain, so that you can make up an effective model on a bigger scale, then it would be presumably included in our setting. If you have very temporary, nasty, long-range tails, then it would be outside our setting. Although I would find it surprising if this would help. Surprising if this would help in your setting, unless you really cook up a very beneficial noise that's kind of intricate. Most of the time, when you have memories, it will make things much nastier. So if you can't do it in this setting, my hopes are relatively low that if you have some fanciful non-Macovian noise, that you can magically mitigate this. But mathematically speaking, we are not covering this. So, actually, what you said about number Uh what you said about the number code anyways I would um but if you do have somewhere code anyways it's not that catastrophic. We can actually correctly prove that the LCP noise. Ah, very good. Oh very good. But then that's also not completely incompatible as said with course grading and so on then this might like on the on the on the error on the Hamiltonian learning stuff that's actually something we do consider so we have like also tools for Lebundian learning and that's not so Learning, and that's not so different from Mamiltonian learning. And then you can say, I have certain types of Macovian noise, or even non-Macovian noise. We have insights into non-Macovian noise, and then you learn this, and you can make predictions. That's not correction, but it's learning and then hoping for the best of predicting. So, in that realm, we have this very much on the right. So, I'm actually with a master's degree in non-macopy noise, so I'm quite educated in this, but not here. Question here as it relates to the So you can do read and descend. Are you like uh sure the answer you descend to is the right answer to your question? That's the shift. No, no, no, no. I mean this is like a there's common like myths in fields and I mean the the Barbadot problem is basically complain that in in like random circuits gradients are small. I mean honestly it will be a big recorder but Honestly, it will be a big recorder, but I think it's not the full answer to the question. First of all, I mean, just that the gradients are small for most of the variational landscape doesn't mean so much. I mean, at the end of the day, you just want to learn, you want to optimize in the region where you want to be. I mean, maybe it's flat everywhere, and here is the nice part, and it's nice and rough, and you just optimize it. The good news is, even if you're barren, you may be able to train it with the right bomb style. The right bomb starting, as they say. You start with a very sophisticated classical solution that you optimize in the vicinity, this might well work. So, perpetuals are not as negative as they sound. But now you come and say, but how about local optima? Yeah, sure, there's lots of local optima. And I mean, the answer to this is common times that you have over-parametrizing, that you have lots of parameters so that saddle points are more plausible than local optima. But ultimately, these are, I mean, these are. These are non-convex polynomial optimization problems. So, up or speaking, there will be local optima, and you have no guarantee if you go down here that you have a global optima. And there are some ideas on metropolitan sampling, initial conditions, warm starting, and so on. But the short answer to your question is no. Okay, good. Everything else is in the lunch break. Thanks for the interest. 