For inviting me, especially because I'm not really known for randomness. So I might mention the word random later in the talk, depending on how far it got. And there's some experimental data in a certain sense that I might mention, that I will mention. So maybe we can say that my talk vaguely fits under the theme. But in any case, thanks to the organizers. So I want to talk about new theories of how proteins not, but let's go back in time. So until the mid-1990s, So until the mid-1990s, it was believed that all native proteins were just topologically simple. That is, they were just a squiggle in space. The biologists are good at going from this picture to this picture. I haven't quite mastered that yet, but anyway. And in fact, it went so far as in 1994, the biochemist Mark Mansfield, who's quite well known in the theory of proteins, postulated that non-proteins can't exist. Can't exist. So, in a desire to prove him wrong, Liang and Mislow, who are chemists actually, identified the first knotted protein by including disulfide bonds and copper atoms, which of course Manfield didn't want to include. But in any case, what you can see here is that this is acerbic acidase in zucchini, and the backbone is this long thing that's red and yellow. That's red and yellow, and then you have these copper atoms and you have these disulfide bonds. So, what you have to erase is if you erase all the yellow and all the turquoise, then you get this, which is a knot. Okay, so there is a knot in there if you're allowing, if you're counting the bonds. Okay, but that wasn't really what Mansfield had in mind. And so, currently, there are And so currently, there are over 200,000 proteins with experimentally solved three-dimensional structures, and 1,612 of them have knotted backbones. So that need not exist. And most recently, about a year ago, using machine learning techniques, the databases AlphaFold and EMSFold predicted 3D structures for hundreds of millions of proteins. So these are not solved. So, these are not solved, these are predicted, and this includes 700,000 proteins whose backbone contains complex knots that have not previously been predicted. So, these machine learning techniques use as a learning set the already known proteins and then use that to predict more proteins. Okay, so this is just some examples of some complex. Some examples of some complex knots here that have been predicted by AlphaFold. So they're actually change, that is to say, you should remove these red arcs. They're chains with endpoints. In general, they aren't circular, but the energy required to undo the knot is large. And so we want to think of them as closed knots. Of course, we could use Collins' approach and think of them. Excuse me, and think of them as not toys. And that has been done, but that's not what I'm doing. And so, what we want to do is we want to model them by closing them, like with these red arcs. And the way we do that is, so we take the picture and we extend the ends in hundreds of directions, and then we choose the knot type that occurs the most frequently when we do that. So, we join the ends at infinity after extending them. So, what that means in particular is. So, what that means in particular is if you have this structure, which looks like this, when you simplify it, this green thing is not going to be the most prevalent. Okay, so it makes sense, or at least it makes a kind of sense that we accept. So, that means when we're looking at these knots, these knotted chains, we're actually thinking of them as closed circles, because this could be that. All right. So it's not really known whether the knots in these proteins serve a purpose. these proteins serve a purpose or just a random random word a random occurrence that's been preserved by evolution so analogously it's not really known whether earlobes serve a purpose or whether they're just a random occurrence that's been preserved by evolution i mean i know that elephants use their ears right to look to cool off i believe but i don't think we do that so anyway um so but instead So, but in fact, if not literal random occurrence, we wouldn't expect the same protein to be knotted in different organisms. So, for example, carbonic hydrase containing the 3,1 knot is found in humans, bacteria, and algae. So, there's all these different organisms that have the same protein, and it's always in a 3-1-knot. Similarly, plast2 keto. Similarly, Class II ketyl acid reductoisomaurase containing the 4-1-0 is found in E. coli and spinach. Again, these are very different organisms. Ubiquidin hydrodase, which I'm going to talk about more later, containing the five tunons found in humans and yeast. So it seems unlikely that it's a random occurrence. So now it turns out that in terms of medicine, we can have good knots and bad knots. So for example, So, for example, Parkinson's disease seems to be caused by the degradation of ubiquitous hydrolase as it passes through a narrow pore of a proteasome and it unfolds. So it's the passing through that pore that's causing it to unfold and degrade. And on the other hand, the 5-2-naught, which I said was in the humans, in ubiquitine hydrolase. Ubiquitin hydrolase, the 5-2-naught is generally there and it makes it difficult to go through the pore. So we're imagining a pore as like the eye of a needle, and if you have a knot, you can't get your thread to go through there. And the idea is you don't want it to go through that hole because going through that hole is what causes it to unfold and degrade. So having this knot in your brain is probably saving you from having. Saving you from having carpet sweets. So that's a good knot. On the other hand, I think more often knotting is a bad thing. So, in particular, protein entanglement has been linked to Alzheimer's disease, oculopherolin muscular dystrophy, and certain kinds of cancers. And some members of the spout family of proteins, which is a large family, that contain a deep trephloom, very much in the center of the protein, are known to cause. Of the protein are known to cause genetic diseases. So there's a lot of knotting and entanglement that seems to be affiliated with diseases, despite the fact that maybe the 5-2 knot is saving us from Parkinson's disease. So this is all to say that understanding protein knots is important. It's important. For medicine, it's important. For biology, it's important. And so we want to understand it. And one of the things we want to understand about it is how does a protein not? Protein knot? What causes it to knot? How does it fold up into the shape of a knot? So, in 2012, in 2007, William Taylor was the first to expouse a general theory of how proteins knock. And what he said is that a protein twists, and then one of the ends threads through this, what he calls this a hairpin, and it threads. He calls this a hairpin, and it threads through the eye of the hairpin, like a bobby pin. And so you can see this: you could get the 3,1 knot, you could get the 4-1-knot, you can get the 5-2-0. In fact, at the time when Taylor developed this theory, all of the known protein knots were 3,1, 4, 1, 5, 2, and 6, 1. That's it. And they're all twist knots. So that means they all can be achieved in this way. So that was like a reasonable theory. So he thought that the only knots that could occur. Thought that the only knots that could occur in proteins would be twist knots, even if in the future you would find more of them. Although, I should say he hypothesized that there wouldn't be too many of them because it's energetically unfavorable to twist a lot. So, you know, four twists may be the limit. In any case, so Bollinger and Sielkowska looked at 6-1, which is a twist knot, and it could occur that way. Could occur that way. And what they did is they did molecular simulations in order to figure out whether or not it's likely that it folds that way. And they found that it's likely to fold in a different way. And so they put forth this theory of how 6,1 folds. So the first step is that this green loop forms and a red loop forms and they align, so they're like lined up in a sense. Up in a sense. And then there's two possibilities. So either we go up here, and when we go up here, you can see that the green loop flips over the red loop, and then the blue end goes through both of them. So generally, when there's threading, it threads like this with a little U-shaped thing, and then it straightens out like that. So that's no big deal. That's just what they do. Okay, anyway, and then the other possibility is that. Another possibility is that instead of the green flipping over the red, the red is threaded first, and then the green flips over the threaded red, which causes both of them to thread. So one of these two ways. So that's what they found on their molecular dynamics simulation, which I think is now accepted as the way that DEH folds. I should say they can't take a movie of it folding and then look at it. So the best they can do is do these molecular dynamics. They can do is do these molecular dynamic simulations, which you can then slow down the movie and look at the individual frames. Okay, so together with He and Wong, so He was a student of mine who's getting his PhD now in computational biology, and Wong is Helen Wong. And what we did is we generalized this, the theory, from the DEI simulation. So we said, well, why can't this happen in general? So, what we're going to do. So, what we're going to do, so this is the same picture but more generalized, is we're going to start with a red loop and a green loop, and they come together. And then you have this blue end, and it could either go in front of the red or it could go behind the red. Okay, and then it comes up, and either we have the green flipping over the red and the blue end threading, and then it threads through the red, as we did before, or we have the blue end going through the red. Blue end going through the red, and then the green flips over both end threading. So it's like what it was for the 5-2, but now what we're going to say is: well, we could have any number of crossings here, twists, and here, except for this energetic issue. And so we actually limited ourselves for the moment to two twists here and two twists. They're in either direction. And we can have either one of these happen, either in front or behind. And in that way, we get quite a few. And in that way, we get quite a few knots. So we developed this notation to refer to it so we can keep track of it. And what this is, is first you look at the red loop and you say, is the right side of it or the blue side of it in front? And write down R because the right side's in front. We look at the green loop. Is the right side or the left side in front? We write down L because that's in front. Now we look at this crossing. If the black is going over the red, it's positive. And then we look at the Positive, and then we look at the number of twists in the red, they're zero, and the number of twists in the blue as a signed number of twists, and we write it there. So that way we can keep track of these. And in fact, we have all possibilities here, so we can write this sort of like in a more schematic, general way so that we can see all the different possibilities. So these are all the different possibilities where A and B here are up to 2 or negative 2. And doing this, To. And doing this, we found that we get this collection of knots that we can have, which of course includes the 6-1, the DEHI1, as well as all the twist knots. And of course, if we'd allowed more than two twists in each, we would have more, but we were concerned about this energetic issue. And what we found is that actually most knots can be obtained in multiple ways. This is a table, I don't expect you to read it, but this, if you count up the number. This, if you count up the number of these, you get 12, which means that the 3,1 knot can be formed in 12 different ways using this, and so on. So, of course, the 9-3, because it requires so many twists, doesn't have that many options. But anyway, and we actually conjectured that the more ways it can occur, the more likely that knot is to end up being actually a knot that's found. But at that, when we did that, that was, we were. That when we did that, we were still in the situation where only the 314151 and 6-1 knots were the only ones that we found yet. Okay, so while the twisted hairpin theory and what we call the loop flipping theory, which is our generalization of the DEH them, can explain the folding of all the knots in the PDB, because that's just 3, 1, 4, 1, 5, 1, and 6, 1, 5, 2, 1, 6, 1, whatever. It can't explain the folding. It can't explain the folding of some of the 700,000 complex knots now predicted by Alpha Fold. And so, and in fact, neither composite knots nor this 8,3 knot can occur with either of these theories, with either the twisted Herrick theory or the loop-filtered theory. Now, one conjecture would be that composite knots, oh, no problem, if you have only two, you could just like twist up on both sides and then thread on both ends. On both sides, and then thread on both ends. But this is not what the way they study this thing is with molecular dynamic simulations, and no simulations have one and both ends threading. It's always just one end that does the threading. So this doesn't seem likely. So how composite knots form is still quite unknown. But okay, but now we wanted to look at 6.3 in particular. In particular, so 6,3 is predicted by AlphaFold. It hasn't yet been crystallized, but Solkowska's group is trying to crystallize it, and they wanted to figure out how it could form. And so they did molecular simulations to try to see on three different proteins that are predicted to contain the 6 foot 30. So they're quite different proteins, and therefore, you might think they would fold in quite different ways. So we saw. So we saw that the 63 knot, you can see it on our table back there, can form in eight ways with our loop flipping theory. But we compared the steps of the molecular dynamic simulations to the steps of these eight different loop flipping things, and none of them matched. So it doesn't seem likely that the, and 6.3 is not a twist knot. So 6.3 doesn't form with Taylor's twist knot theory. With Taylor's twist knot theory, and it doesn't form with our lead-flipping theory either. So, one second. One time I was giving a talk, and I like to drink during my talk, and I had my glass here, but it was glass. And then I took a drink, and then I gesticulated, and I went flying into the audience, and the glass shattered. Exactly. So, there we go. All right. But I won't do that. I do have a tendency to just. All right. So, let's see. So, we developed new theories that are sort of in the same vein as our loop flipping theory. They're generalizations of it that might explain the 6-3. So, here's one of them. So, we call this the double threading. So, it simply twists up here and it twists down. Twists up here and it twists down there, however many times, to whatever. And then now the end, which we colored orange, threads through this and then it threads through that. And then we get, so we, and we use the star to indicate this is where one of the loops is at the top and one of the loops is at the bottom, as opposed to the previous theory. And then this theory, which is, we really just developed this to try to describe one of these proteins which seemed so. Proteins which seemed so different from everything else. So, this is a very weird thing. So, this one, the end goes under, and then what happens is that the green arc flips down, so it goes from there to down, which causes it to actually thread, both the red and the green. So you thread without threading, and then you have this little thing that comes up, and then it threads through, and you get your 6-3. But what we did then is we took this. So, what we did then is we took this, turned it over, and sort of moved this crossing over there and slid the one up to see this is actually the same. So we get this configuration, which is the same as this, but the pathway is different. So, what's important is the pathway. And then we compared our theories, so these theories, we wanted to compare them to the MD, the molecular dynamic simulations of the folding of the 63. The folding of the 6.3, but first, excuse me, I'm getting over a cold. But first, we wanted to check one more thing. So one way to distinguish proteins with the same knot, or to distinguish any chains with the same knot, is to look at their subchains. And so, for example, here are the sub knots of one configuration of 6,3. So, using this configuration. Using this configuration. So, what I did here, I sort of made it a little lumpy here, but anyway, is I'm going to cut at the places where the color changes. So, if I cut between the red and the purple, then I get this, which is a 3,1 knot. So, this is telling me that this 6,3-kn has a sub-chain, which is a 3-1 knot. And that if I cut it a little further over here, then I get the unknot. And no matter how much I cut after that, I get the unknot. And that's cutting. The unlock. And that's cutting. This is cutting just on the purple end. But we could equally cut on the blue end. If I cut here on the blue end, I see that I get the unknot. Cut again, I get the unknot. But interestingly, now when I cut here between the orange and the green, I get a 3-1-knot. So just because you get an unknot doesn't mean it's unknots all the way down. Okay, so this is interesting, but this, so this is just one way to So this is just one way to look at a given configuration of 6.3 and to be able to compare it, yes. That's a material. I thought DNA was sort of like... This is protein. Oh, so okay. So what, like just sort of any kind of protein? This is, well this is, we're looking at this particular protein with six swing, but yeah. But well but so again, so DNA will be a little different, but my my general impression was that the the the sort of the dynamics of it. The the sort of the dynamics of it was that it was sort of like a sort of like a garden hose where if you twist too much it snaps. I don't think that's true with proteins. So with DNA it's twisted up a lot because it's in superheliases. So when you're twisting too much you're going beyond a lot. So with these proteins do you get uh flexible joints that can disperse? Oh yeah, they're very flexible. They're very flexible. But as I said, you can't really twist too much. That's why we had the limit of two twists in a row. At the limit of two twists in a row. So, but yes, but they do twist like that. So, the problem with this, so this is like an interesting way of comparing a given configuration of 6.3 to a different configuration of 6.3 to see if they match, because we're trying to figure out if any of our configurations match what they find on the more the dynamic simulations. But this is like a one-dimensional way of thinking about it when it's a two-dimensional thing. It when it's a two-dimensional thing. That is to say, we're cutting on, here we're cutting on the purple end, here we're cutting on the blue end. But what about cutting also on the blue end and the purple end at the same time? This doesn't describe that. So instead, Sopkowska and Eric Rodden and some other people developed the idea of knot fingerprints. And a fingerprint is a two-dimensional picture that represents all of the subknots. So, what it says is that you have Is that you have starting here? So here you have the full length of the protein. So this is one end of the protein, this is the other end, and this is the opposite end and that end. And now here you have this orange, which represents the 6,3 knot. And then if you cut on this end, if you cut on this end, you get the unknown. And if you cut some more, then you get this negative 3, 1 knot. On the other hand, if you cut on this end, then you're going to get the positive. Then you're going to get the positive 3, 1 knot. As you cut some more, you get the knot. So eventually you get the unknown on both sides. So this is a two-dimensional way of representing the information about the sub-knots, which gives you more information than just doing it like the way I was doing it there. Okay, so these are from the 6.3-knots that they had. These are two different proteins that they were looking at, but basically their fingerprints are the same. You can see that this one has a You can see that this one has a wider band of the negative 3-1 than this one does, but basically they look the same. And so, what we did is we looked at all possible configurations from our loop flipping and our double threading, all of them, to see which ones had fingerprints that agreed with these. And we saw it's only these. Those are the only ones whose fingerprints agree with those. So, that means that if we're trying to test, That if we're trying to test whether any of our configurations, which represent a folding method, whether any of those could explain the folding of the 6.3, we only need to look at these. Because the other ones, already we know that the final configuration doesn't agree with the final configuration of those and these simulations, because they have different figure prints. So that simplified it a good deal. Yes, of course. We're talking about cutting. Is that modeling something? Is that modeling something going on in biology? No, it's cutting. So in biology, they are doing this. They're taking the, so like if you look on NotProt, which is a database, they have all the fingerprints. And what the fingerprints are is they took the protein and they, or they took an image of it, and they cut it, just like I'm doing. They cut it and cut it and cut it and saw whatnot. And they determined the knots using tolerabilities. So, okay, so with this in mind. Okay, so with this in mind, we then looked at the MD simulations. So here's the MD simulations. So, this is one particular protein, which is this one, which is predicted to have a 6,3. And this is the picture, simplified, of course, pictures from the MD simulation of how the 63 folded. So, this is the final configuration, whose fingerprint looks like I had on the previous slide. So, then we had to take these, and among Take these and among the ones we had on the previous slide, see which ones we could sort of mold so that it looked like these. So, like, here's A and here's B, and then on C, we're doing this, we're threading like this, okay, and then on D, we're going down, so we're this corresponds to here, we're going down, and we're going to thread here, and then we thread here, and so this is our double. This is our double friend. That is to say, it's where there's one loop at the top and one loop at the bottom. So we said, okay, this turns out to be the closest of all of those. There were like six possibilities that could match with this. And then, so there were three proteins. And so then this is another one. Similarly, we did this and we decided that this is the closest. And again, it's of our loop flipping. Of our loop flipping thing with one, sorry, our double-threaded thing with one at the top and one at the bottom. And then this is the crazy one where we basically couldn't match it with anything, and we developed this theory particularly to describe this one. So in any case, so this sort of shows that it could be the case that these proteins, which are not known to exist yet, could fold with these theories. Could fold with these theories and end up having these knots. The fact that these theories are very similar to the theory for DEHI, which is known to exist and has been crystallized, makes it more believable that our theories match. Okay, so this is where we are with this. And now, I get you know interactive. Is that true? Yes, so I'm going to keep going. Yes, so I'm going to keep going. So I'm going to change the subject. Yes. Yes. Using, you did with the previous model, you like predicted all the different knots that you could get. Using the new ones, do you have the list? Yes, we do. It's long. So I didn't put it here. Yeah, we have that. So, and we also have extended the first one to three twists in each, and we have a list. We have lots of lists. Yeah. Yeah. You can't do crossing changes with proteins. Is that very expensive? Sorry, what? So you can't do crossing changes. Oh, no, you can't do crossing changes. It's not like DNA where they have recombination. No, no, no, you can't do that. That's a chain. They don't have to each other. Yes, John. Could you say anything about how you check the reasonable mass compared with the molecular simulation? Good question. So we have the molecular simulation and we have all these slides. I mean, it's, you know, like thousands. You know, like thousands, whatever slides. And then we look at the fingerprints of each of them, and we look at the actual pictures of each of them, and then we look at the fingerprints of each of ours at each stage, and we look at the actual pictures, and we compare them. Yeah, yeah, yeah. So the molecular dynamics has, like, it is a dynamic which shows it folding into the NAT, and then we slow it down, and we can do We slow it down, and we can do each individual slide, okay, and then look at the fingerprint for that and look and see if we can get, like, at a reasonable point in our model, if we can get it to match. And so these ones match all along. The fingerprints match all along, and the pictures sort of match all along. Yeah. How successful are the molecular simulations? Is it very repeatable? Is it characteristic? Repeatable, is it? Yeah, yeah, yeah, yeah. It's very repeatable, and they've done it a lot. This group does, that's what they do. They do simulations. But as I said, they're also trying to crystallize this, a 6-3-0, because so far it's not known to exist. So. And Eric, what you said, then we look at it and just compare it with it. You mean literally. Literally. We're looking at it. So luckily there's a graduate student. That's what you always need. That's what you always need. So Joanna Sokaska, who does the simulations, has a graduate student who actually will take the horrific picture and then draw it and then give it to us. So we literally are looking at pictures, but we're not looking at the horrific thing. He's doing it. And he does it wrong regularly. Like he'll give it to us and we'll be like, no, that's not the 6-3. You go back and do it again. So, yeah. But at least he. So, yeah, but at least he does that, so we don't have to. Other questions? She is a whole group. I mean, that's what they have in biology. So, all right, I'm going to change the subject. Okay, so this is all about knotted proteins, but that's not the only kind of entanglement of proteins. So, I want to talk about links. Okay, so because a protein is just a Because a protein is just a chain, normally you wouldn't expect it to have a link. But if you allow these cofactors, like extra pieces, then you can have a link. So the most common type of protein links are hop flux, as you see from this one. So you can cut out the irrelevant stuff and you have a green-purple link. Okay. So in fact, Ling and Misla, who were like, they were out to prove everybody wrong about everything. Prove everybody wrong about everything, they also came up with this example of a protein with cofactors that's a key ring. And then more recently, there's this chain male protein capset that protects the bacteriophage 8K97, which is inside of it. And this whole idea is actually really exciting that they create these capsids, that is to say, a capsid. Capsids, that is to say, a capsule, like a sphere made of proteins. And the idea is that you ultimately want to use this for cancer treatment because you want to put the horrible chemotherapy drug in there and have this protein fall apart exactly when it gets to your whatever, thyroid, you know, or wherever. Like it's coated up so that that particular piece of the body will cause it to melt and the Will cause it to melt, and the chemotherapy drug will go just there, and it won't affect you aesthetically. This hasn't been done, but this is an idea, and it seems exciting. And the idea of using links and all that sort of cool for that. Okay, so anyway, so there's a lot of, well there's not a lot of, but there's interest in links, link proteins. But what I want to talk about is entangled spatial graphs. So So, if we include the disulfide bonds, then we get spatial graphs, that is to say, graphs in space. And they can certainly have different embeddings, just like knots can. And so these are lassoes, so lassoes have been found in proteins. So this is just simply a protein chain, it's the black, and this is a disulfide bond. And this creates a circle, and then you can have something go through it. This is different because it not, this is called. Is different because it not, this is called the tail, because the tail has a knot in it that is linked with that circle. They also have theta graphs, that is to say, if you have two disulfide bonds, then you end up with a circle here, and then you have this red thing, which makes it a theta graph. This is a Kinoshido theta curve, so it's a theta graph which has no knot, but it's entangled. It can't be S-tucked into a plane. Can't be acetoped into the plane. This is what's called a cyclotide, which is in the form of what's known as a Mobius ladder, which looks like a Mobius strip, but it's a ladder. This is a cysteine knot motif, which you might not realize is actually in the form of a Mobius ladder. If you join the ends, then, and you can, let's see what we can do here. We can pull the 3, 6 over that hump so that it goes like that, and then we have the 1, 4 there. And then we have the 1, 4 there and the 25 there. And then we just push this guy down, the dotted thing in the back, and then we can just swing the two up to there and get them over slide. So anyway, so these are different things that have been found. I mean, this hasn't been found, and this hasn't been found, but the others have been found in proteins. And the idea is: well, we want to study what kinds of entanglement we can have in these kinds of graphs. And so, in particular, And so, in particular, we're interested in non-planar graphs because they're topologically interesting no matter what, that is, if they can't be isoducked into the plane. And we have Kurtowski's theorem, which is that a graph is non-planar if and only if it contains a K5 or a K33. But what's interesting about the K33 is it's actually a Mobius lab. So right now I'm just looking at this as an abstract graph, not as an At this, as an abstract graph, not as an embedding. You can see that A is attached to 1, 2, and 3, B is attached to 1, 2, and 3, and C is attached to 1, 2, and 3. So I sort of use the word Moby Flatter and K through 3 interchangeably because they're the same breath. Okay, but the interesting thing is how they're embedded. So often metalloproteins, that is proteins with metals attached to them, Metals attached to them are non-planar, and this is a particularly complicated example: nitrogenase. And this, if we look at it schematically, nitrogenase is made up of a so-called Fe protein and a MOPHI protein, which has two P's and two M's. And then, if we look at it in more detail, there's just one M. One M looks like this, and then I simplify. And then I simplified it and replaced some of these letters by A, B, C, and 1, 2, 3, and I see that it's actually a K33. And similarly, this is the P cluster. So here's the backbone. You include that. And now I'm just going to, again, change a few labels and erase a bunch of junk. And then I see I have again a K33. So that nitrogen. So that nitrogenase contains multiple K33s. And the question is: well, what do those K33s look like? How are they embedded? And what it turns out is that they're embedded as a Mobius string. So I'm going to call any embedding of K33 that looks like this to be in Mobius form. So, okay, and we saw that the Okay, and we saw that the K33 in cyclotides in these things is in Mobius form. And here's a so-called cysteine knot, which I deformed, and it's in Mobius form, too. So this is interesting because, of course, when we think about proteins and knots, the simplest thing would be to have no knots. But the next simplest thing would be to have three one knots. So you might think, well, all So you might think, well, all proteins that are not have 3,100 because it's the simplest. Well, so you might think, well, all proteins that contain a K33 is in Mobius form because that's the simplest. But why should that be? It's not the case with NOTs. So with NOTs, we have higher NOTs, so we should have other forms of K33. So I just wanted to get in the conversation that a Mobius ladder doesn't have to just have three rungs, it can have any number of rungs. Any number of rungs. And so, for example, M5, so all it is is a loop where antipodal points are joined by edges. So, vertex I is connected to I plus N. And here's it in MOGIS form. And here's another metallic protein, which you can simplify, simplify, simplify. And you see it's got an M4, and it's in bogus form. So this is all very bizarre. Like, why is this that they're all in momus form? There's no known protein. Form. There's no known protein that contains a Mobius ladder that's not in Mobius form. So Kenji Kozai and I were trying to think about this, and so we approached this, oh, and Yo Nikuni also. We wanted to determine the probability that a random, random, yeah, linear embedding of K33 in a cube is in Mogi's form. So just so you don't think. So, just so you don't think that every linear embedding of K33 is in Mobius form, here's one that isn't. Okay, so that's a linear embedding of K33. It's not in Mobius form, and one way to see it's not in Mobius form is the red is a knot. So what we consider, we consider three related conditions on embeddings of K33. Being in Mobius form, being knotless, that is having no knots, and being what's called pound. And being what's called pound. So an embedding of a graph is paneled if every cycle bounds a disk in the complement of the graph. Now you might think this is the same thing as notless, but it's not less. Because even though paneled implies it's not less, because every circle bounds a disk, this is a K33 that's not less, but not paneled. So I've drawn out all of the cycles in it. The cycles in it. So you can see that none of them contain a knot. Here's the graph. And you can see that, I mean, this isn't a proof, but you can see that it's not pound. You can't like undo that wiggle, the orange wiggle. So in general, not list doesn't imply pound. However, so a few things that are interesting. So Robertson, Seymour, and Thomas, who are a powerhouse, proved that an embedding of K33. Proved that an embedding of K33 is in Mobius form if and only if it's paneled. And then Kenji, Kozai, and Yonakuni and I proved that a linear embedding of K33 is paneled if and only if it's notless. So what we, in order to study what's the probability that it would be in Mobius form, we wanted to study what's the probability that it's not less. So that's what we want to do. And so first we actually did some And so, first, we actually did something more general, which is that we realized that a random uniform distribution of endpoints in a cube determines a random linear embedding of Kn, just connect them all in pairs. And then we proved this theorem, which is the expected value of the sum of the squares of the linking numbers over all pairs of disjoint cycles in a random linear embedding of Kn in a Q is this thing, where Q is this. Where Q is this thing, and P is the probability that a random linear embedding of two disjoint triangles in Q are linked. And then we wrote a program, or I should say Kenji wrote a program, to generate one billion embeddings of disjoint triangles in Q and determined that this many of them were linked. And this gave Q to be this with a 99% confidence. So this is sort of like a different result that we had with Kenji, but then we decided to apply it to this. But then we decided to apply it to this question that we're interested in about K through 3. And so we first applied that theorem to K6. So if we put this into K6, this is the same theorem into K6, realizing that we have K equals 3 and L equals 3, and so then we end up with 0 over here and 6 over there, and this gives us, simplifying, gives us 45Q, and Q we know, well, we know it here. Okay. Okay, and so then we needed to go from link triangles, which are in K6. We don't have any link triangles in K through 3, to we want to go to knots because we're interested in knots in K through 3. So we use this theorem, which was proved by various people independently, which is that a linear embedding of K6 either contains one trefoil knot in a six cycle, with three hopflakes, or no knots and just one hopflink. knots and just one hop field. So here's a picture of a linear embedding that contains one knot, which is a six cycle, and three hopeless. Anyway, so we said, okay, let's let P1 be the probability that a linear embedding of K6 has one hop-length, and let P3 be the probability that the linear embedding has three hop-lengths and also not. And we recall that the expected value, the sum of the squares of the linking number, The sum of the squares of the linking numbers of a random linear embedding of K6 is 45Q. That would mean that 45Q is 1 squared times P1 plus 1 squared plus 1 squared plus 1 squared, which is the 3 of them, times P3, which gives us this, which gives us this, and which gives us this, and now solving for P3, we have this. So the probability that a random linear embedding of K6 contains Embedding of K6 contains a not is this, where we know what Q is. Okay, so then Kenji and I proved that the probability that a random linear embedding of K33 contains a knot is this. It's the same, but it's over 20, which gives us this. And I'm out of time, so maybe I'll stop there and leave it at that. Are there questions? Yes. So, when you, in the first part of the talk, when you recognize notes, do you ever get to apply invariance? Do you get to the stage where you have two notes and you have? Yeah, that's how they distinguish the notes. So, we weren't doing that. We were doing the model and comparing it. But definitely, Silkowska and your Sikowska and her group, what they were doing is they would have this picture and then they would apply the Jones, in general, the Jones polynomial in order to determine what not it was. Yeah. Other questions? Yes, I'm not sure I completely understood the so you have you have a model and you predict uh uh situations, but uh and then after that And then after that, proteins are still being discovered, and to discover some which fit the models, that's how it works. Yeah, so the idea is to try to have a model that would describe how knots occur, because that's completely unknown, okay? And to try to have something that is general enough that it can sort of describe most knots, or variants on it can describe most knots that are formed. But the problem is that right now. Formed. But the problem is that right now, the only knots that have been crystallized are these simple ones. And even those, they don't really know how it forms. They have the Taylor theory, which seems possible. For 3-1, it's like anything you do corresponds to the Taylor theory. And they believe that for the 5-2-knot, sorry, for the 6-1 knot, the DEHI, that it forms with this loop-flipping theory. But now there's no other knots that have been crystallized. There's no other knots that have been crystallized yet, although Silkowski's group and other groups have been trying to crystallize some of the proteins that are predicted to contain knots according to alpha fold. So, yeah. Yes? So, just to connect this to what you were saying before, so this means that it's not lists, and so Lists and so. Yeah, so let's go to the next slide, pretending we did all that. That's okay. So then we put it all together, right? So Robertson, Seymour, and Thomas said that K33 is in Mogus form if and only if it's paneled. And then we said that a linear embedding is paneled if and only if it's notless. And then we computed that the probability that a linear embedding contains a knot is this thing which is very small. Which is very small. So that means that the probability that it's not less is very high, which means, mean very high, like 98, right? And this means that the probability it's in Mobius form is very high, which is consistent with the fact that they never found one that's not in Mobius form, which is not to say that it won't be found at some point, but it's unlikely or rare. Or rare other questions. We'll resume at 4:13 for short talks. 