Okay, perfect. All right, and you can hear me well, right? Oh, yeah, very good. So, hey, hi, everybody. I would like to thank all the organizers for inviting me to give this talk. It's a pleasure for me. So, I'm Nicola Busr√©s. I'm a scientist working at ECMWF. I'm working in the data assimilation group. Simulation groups, but also I'm part of the CAMS team. And so today the purpose of my talk is really to present the research activities in data simulation at SMUF, but focusing especially on atmospheric composition and source inversion. And doing so, I will also try to highlight the main challenges and opportunities of data assimilation methodologies applied to Earth system model. And I think I would like to thank Laurie for And I think I would like to thank Laurie who has provided a great context and introduction to policy and to the sorry, who gave the context for scientific and policy context for my talk, actually. I think she really made the case for the use of air system model. And so I will try to go into more details in this talk. In this talk. Okay, so first let me present Copernicus and ECMWF and the link between them. So Copernicus is the European Union's operational Earth Observation and Monitoring Programme. And so basically it's leveraging observation from satellite and non-satellite data. And by combining them with the model, Combining them with the model to provide the value-added services. So I have listed the six services that are run by Copernicus: the atmosphere, climate, land, marine, emergency, and the security services. And so it provides a user-driven service which provides free and unrestricted data access for the citizen. And so that's the So that's they sorry the now the SNWF as you know is a is a well-known operational weather prediction center and it has seen its role significantly expand in the last two decades or so after the European Union entrusted it to run two of its Earth observation services, so the Atmospheric Service or CAMS and the Climate Service or C3S. And the climate service or C3S. And it turned out to be a very successful experience. It attracted many more scientists to work on the SMWF data assimilation and forecast system. It enabled also new synergies between weather, climate, and the atmospheric composition research, and spurred the development of new approaches and methodologies. So it turned out to be very productive at the end. Productive at the end. So, what has the Copernicus Atmospheric Monitoring Service? What offers a Copernicus Atmospheric Monitoring Service? So, it built its portfolio over the last 15 years or so. So, it includes past, current, and near future global atmospheric composition data. So, in particular, we have air quality forecast. We also monitor the ozone layer. Monitors the ozone layer. We have also products which consist of top-down emission and then surface fluxes of key pollutants, methane, CO2 also, solar radiation products, UV, pollen forecast, climate-radiated forecasting. So that's all the ensemble of products that are provided on a routinely basis. Provided routinely by the service. And so, all this data, of course, needs to be carefully checked. So, we provide detailed evaluation and quality control information via quarterly reports that you can find on the website together with the data. Okay, so how does SCAM work? So, we start from Earth observation, both satellite and in-situ. And in situ. Then these observations are ingested into the global data simulation system, which is based on the ECMWF IFS system. We provide five-day forecasts, forecast twice a day for roughly 40 kilometers special resolution. But also, we have a real analysis mode which is run at 80 kilometers. So this is for the global component, but then we have also a suite of But then we have also a suite of regional models. And we have 11 of them, which are run at 10 kilometers special resolution, and they provide a daily foray forecast. The CAMS data are then utilized by many downstream services from air quality TV bulletins to smartphone applications. You might recognize some of them, such as a weather channel or Windy. Windy. So at the end, it tax has a major multiplication factor, and we can estimate that in Europe it reaches about 23 million people and 229 million people worldwide. So we have a very good visibility with those products, and that's increasing every year. So CAN strives to stay at the forefront of global atmospheric composition. Of global atmospheric composition data simulation. It does so through continuous uptake of new satellite observations. So, here in this table, I have listed in red the satellite data that are currently assimilated in the operational system. I'd like to point out, in particular, the recently added S5P data for NO2 and SO2. They have been assimilated for a bit over a year. Have been assimilated for a bit over a year now. And in the pipeline, we have the methane FIP data and the OCO2CO2 data, which are being monitored for near future integration in the data assimilation system. Okay, so the last IPCC report has just been released today, so I think that's a perfect timing to talk about the current landscape in GHG emission research and PhD emission research and the coming opportunities. So, because of the, in the context of the Paris Agreement, new monitoring needs have emerged, and in particular to support the nationally determined contribution and the global stock take processes. And so, in this context, the European Commission in the past 10 years tasked 10-year task group of experts to develop a vision for to develop an operational monitoring service for CO2 emissions. And so they released three reports two years apart. The first was published in 2015, provided the vision, global general vision and strategy for this project. Then two years later, we had more detail on We had more detail on more suggestions on the building blocks and the implementation approach, and finally the requirements for the data. And because of its experience in operational system services, SMLF was entrusted by the European Commission to build this new operational system, which means that it managed basically the European project associated with this endeavor. Endeavour. So what I'm showing here is basically the idea. I mean, this is a schematic of what the system, operational system will look like. So you can distinguish different components here by color. You have the observation data stream made of satellite data, in-situ data, meteorological observation, etc. Etc. You have prior information on the flux. So it's basically bottom-up inventories, but also process-based biosphere flux model, etc. And this is the observation of the prior information are integrated in a standard Bayesian framework to provide posterior estimates at different scales. So we have a global scale, but we want also to have a But we want also to have hotspot information as well. Because it's an operational service, we need also to have sophisticated evaluation and quality control processes before providing consolidated output in the form of country and region posterior fossil fuel emission and hotspot emission, which are then feed to the decision maker. To the decision maker, etc. So, now my last slide on this introduction part. This is a timeline to build the system. So, as I said, we started in 20, the adventure in 2015. The first big project started in 2017, the CHE project. Then today we are in the last year of the COPO2 project. Are in the last year of the ProPO2 project, which is supposed to finalize the building blocks of the prototypes. And we are now starting the operational ramp-up period to have something ready by 2026. And 2026 is basically where we will obtain, be able to assimilate the CO2M data. So, along this project. So, along this trajectory, we would say we can see that we assimilate progressively a new data stream from the new satellite missions. Okay, so now I'm going to explain in more detail what system we are using. So, as I said, the IFS Global Inversion System is the Earth system model. So, which means that, as you know, that we are trying basically to model. We are trying basically to model all the components of the system and the interaction between them. So we can distinguish three parts. We have the input data set in the form of bottom-up inventories with different temporal and spatial resolution. We have vegetation and urban maps as well, ocean flux. And this is used by the AFS atmospheric transport model, but the modeling could also But the model includes also online processes for the biogenic fluxes, for the urban emissions. We have also the chemical reaction simulated by the system. And we assimilate observation in a four-level system. And we will come to that shortly to explain more details how we do it. But in addition, But we in addition to the optimization of the chemical and the atmospheric state in general, we also provide uncertainty quantification using an ensemble approach. So the approach here is really an integrated approach, which means that we want, again, we optimize both the meteorological variables, but also the chemical components. And we take into account not only And we take into account not only the transplant but the chemical reaction also. And we do that by minimizing the fall ever cost function using an incremental formulation. So you might be familiar with this cost function, which is a weighted sum of prior departure for the state and the parameters and model observation departure. And the weights are given by the covariance matrices of each of the respective variables. Variables. So we use a 12 or 24-hour window, depending on the application. And we have the CO2, methane, OX, CO emission, as well as other species, but I'm focusing here especially on those species during this talk. The biogenic CO2 flux comes from a process-based online prior, so we model them directly. It's not offline. It's not offline. We have also a wealth of observations that are assimilated that I'm listing here. Tropomy in particular for NO2, CO and methane. And also for the B-match weeks, so we have a wavelet-based spatial error correlation. But we model also the cross-species correlation, and soon we will have also temporal correlation included in the system. In the system. We use a tangentier and Android model for a simplified chemistry mechanism because it's too expensive to include all the chemical mechanism. We have co-emitter prior correlation so that we can use cohemitor observations such as NO2 to constraint to constrain anthropogenic CO2 emission, for instance, which is very useful given the sparse observation we have for those species. As I said, As I said, the posterior covariance is estimated using an ensemble approach, Monte Carlo-like methodology. And the limitation, of course, here, and I will come back to that later, is that we are dealing with a very short window, which is not appropriate for long-lived structures such as methane and CO2. I will come to this problem later. I think I will not spend too much time on this slide. just i just want to uh just to introduce the first results we obtained with the system for mesan for methane emissions so we run the system over a 24-hour window on the bottom right here you can see a three of this three cycle of this data simulation system where we optimize currently the prior emission and the and the state and and so we optimize the missile emission daily we use the gosat gaussian Daily, we use the Gossat-Cazi entropomy colon, mesen-colon observation. Um, and yeah, we use different sources of observation to adjust the prior errors. Note that we run the forward model at 25 kilometers, but the increment resolution is effectively at the Dangeline era joint resolution, which is a bit coarser, which is 80 kilometers from our. Those are some preliminary results we obtained. We can find the resultance results in the McNaughton et al. Results in the McNaughton et al. 2022 paper. This is over the Permian basin. So we run the system to try to see if we could match previous estimates, in particular the one from Zangetol. And the take-home message is that we are doing a relatively good job in capturing the underestimation in the freighter inventory over this area. We also, with the same experiment, so we looked at we looked at methane emission during 2019 globally. So on the left, you can see the prior on the top. The increments at the bottom. So you can see that over Asia, we capture the underestimation of the emission. Of the emission in the bottom-up inventory. This is reflected on the right when you look at budget. So, on the x-axis, you have the methane emissions, the posterior methane emission, and the y-axis, the change compared to the prior. And this is for the top emitting country. And you can see, for instance, that we captured the overestimation in bottom-up inventories over China. Over China. And we found generally consistent, I mean, good agreements with previous top-down estimates for other countries as well. And this was actually submitted, this results were submitted as part of a document to the first global stock take this year jointly with other products from the Coco 2 project I mentioned earlier. Okay, so now I would like to have a more general discussion. More general discussion about discuss the benefits of integrated Earth system data simulation. And then I will mention the challenges. So that was my title. So I think that because that's really the characteristic of the system we are using here. We are trying to model all the components of the system, but it comes with the cost. And I will explain that later. So the benefits, obviously, that we are using the estimation. The estimation: we have a physically consistent observation-based estimation of the state of the air system. By that, I mean that we are modeling the interaction between all processes and also in the data simulation, when we propagate the prior errors, the distribution, because we have this online modeling of the processes, we model the prior covariance online between all the variables and parameters. So, as a consequence, the Bayesian we have a consistent. The Bayesian, we have a consistent Bayesian estimation. So, we, as an example, several examples, we model the aerosol rejective effect feedbacks, and I will give some examples in the following slides. We can model, we have also the online chemistry impact on the methane lifetime. I think Laurie described this problem a bit earlier. The atmospheric trace observation can construct. The atmospheric rasso observation can constrain the wind field. So, this is something which can be very useful for even in the stratosphere, for instance. An important aspect also, because Laurie was talking also about errors, and the transport errors are often prescribed on an ad hoc basis in offline inversion systems. But in online inversion systems, such as this one, you implicitly account for a significant part of the transport error from Of the transport error from meteorological uncertainties in the initial condition. Also, you can model the impact of meteorology on the chemical fluxes. So, for instance, we have the online-based model for wetland methane emission, and we have, I will show also that we can also use the meteorological information for the prior anthropogenics emissions themselves. Okay. Okay. What time do I have? Another sorry? Another eight minutes. Eight minutes. Okay. So I'm trying to okay, it should be fine. Okay, I won't spend too much time on this one. It's pretty simple. So I'm showing the impact of using prognostic aerosol, which are modeled by CAMS, on the surface temperature forecast. Okay, so on the left. Forecast. Okay, so on the left here, you can see an interest, a very strong episode of aerosol transport from the Sahara, so a dust episode. In the middle here, you have the impact on this prodostic aerosol compared to a climatological aerosol on the surface temperature. So you can see significant impact in Southwest Europe here. And on the right, you can see actually that the comparison. That it's the comparison against observation. So it shows the difference in root mean square error against observation between those two simulations. And you can see that you can improve by one or two degrees, sorry, the forecast at the surface of Arcissarium. Same here, this is another example for an Arctic event, of wildfire events, and you can see that you can actually improve the root mean square against observation up to What mean square against observation up to two or five degrees here? Okay, then as I said, we can use also because we are using a forever, we have got the dynamical information built into the data estimation method. So we can using trust observation constrain the dynamic of the system. And here I'm showing a single observation experiment. This is another observation over the UK. And it's a six-hour simulation window on the top. Hour simulation window on the top, you can see the increments you get when the observation is placed at T0 at the initial time. So, obviously, you don't have dynamical information, and so the fall eval is like the sweet eval. You just get another increment at the bottom here. You placed, we placed the observation at three hours and six hours, respectively, after initial time. And now you start to build the increment and use the dynamical information. The dynamical information of Forever. So, this is you have an ongoing project to try to basically operationally use this kind of information to improve the dynamics. Very quickly, this is an example where we actually, as I said, so I just showed the impact of the atmospheric composition on the meteorology and how we can improve the weather forecast. And now that's the other way around. We use the meteorological information. We use the meteorological information of this online system to improve the atmospheric composition via the improvement of the emissions themselves. So, what we did is that we implemented a U-band tile and we combined it with a heating degree day model, which means that we use the temperature information to have information on the residential heating and the consumption of energy and therefore the emission of CO2. And so you can see on the CO2. And so you can see on the right here, the magenta colors represent the time series of gas consumption, which is a proxy for emissions. You have the CO2 emission and you have the CO2 emission also for two different models, from an offline model and from an online system. And you can see a very nice correlation between the emission from this online system and the gas consumption. Consumption. That's an illustration of this. Now I will end my presentation by presenting the challenges after the benefits associated with integrated Earth filter data simulation. So one of the major problem is the high computational cost involved. So it requires efficient algorithm to meet the operational time constraints, obviously, and it limits also the resolution capabilities. And I will come to Solution capabilities, and I will come to that in a moment. We have also the problem of non-linearities. So, we need to use a short window forever to avoid convergence issues, typically multiple minima. And therefore, currently, as I said, the short window we use, the 24 hours, is incompatible with the greenhouse gas inversion problem. And incremental forever, obviously, as you go to much higher resolution, as we are trying to do now. As we are trying to do now, can pose issues because you might have the tangenier approximation might not hold at much higher resolution. So first, the problem of the size of the window length. So what we chose to do here to tackle this issue for greenhouse gas inversions is to have a hybrid approach for the model for the Tangentina. Model for the tangent linear and adjoint model. So, we for the short window which contains the current observation, we use the tangentina and adjoint solver, which contains everything. So, the meteorological processes, the chemistry processes. And then, for the previous window, we use a Laurent approximation of the transport Jacobian. So, it can be done via an ensemble or a deterministic approach. And then we basically. And then we basically combine and connect those two operators, the solvers and the Lauranc approximation, and proceed with for lever as usual. So then for the non-linear part, you have all the processes, and then for the linear transport part, you have a Lauranc approximation, which then is very cheap to run. And we can meet the operational constraint in terms of computational cost. Once we have done that, as I said, we use ensemble-based post-IOD. As I said, we use ensemble-based post-higher approximation, so we can do that with EDA or some other square root approaches to be more efficient. We approximate the new Jacobian and we iterate the algorithm. And that's my last slide almost. Now I would like to mention the problem of resolution for our system model because, of course, it's very costly to run. Of course, it's very costly to run the system at very high resolution. But in fact, for greenflow-gas inversion, it is very key to be able to run a high-resolution transport simulation. So what I'm showing here is our simulated CO2 column corresponding to the future CO2M instrument. On the left, it's the simulation. So it's over the Berlin area where you have many very large power stations. On the left, Station. On the left, you have the nine-kilometer simulation from the AFS, and at the center on the right, you have respectively five-kilometer and one-kilometer resolution simulation using the COSMO GHG system. What you can see clearly is that in that situation, you really cannot extract any signal from those emissions with a nine-kilometer resolution, which is pretty high already for a global system. So we see clearly the limitation here. Even though the IFS special resolution. Even though the IFS special resolution is planned to eventually reach two to one kilometer within 10 years, in the meantime, we need to address this issue with the resolution of our global system. And so the idea here is really to leverage the idea that we have regional local system, limited area model that can be run at very high resolution and they are complementary to the global system. The global system, and we want to leverage this information. The way to do it that we envision is to assimilate those posterior products as observations, like we do with other type of observations, satellite and in-situ. So, we will have as a core system for the global component, the AFS, the four-levae AFS, which assimilates satellite observation and in-city observations. It will provide boundary condition to the regional and To the regional and local systems, and in turn, those systems we provide posterior estimates that will be assimilated as observations in the global IFS system. So then you get a very nice feedback of information across different scales. So that's what we are building. It's a work in progress. So I don't have results yet to show. And that's my conclusion slide. Conclusion slides. So, the take-home message really is that recent developments in data simulation for Earth system models open new possibilities to have a better understanding of the state of the Earth system. So, currently, as you know, this research area has a high societal impact and visibility. So, it opens new opportunities for collaboration and funding between our research groups. At ECMLOF, we have. At ICMOF, we have been undertaking significant development steps toward building a comprehensive system for atmospheric composition data simulation, in particular by integrating the flux optimization jointly with the state. So it involved extending the four level window to accommodate long-lived trussers, so the size of the window, as I said. The joint optimization of cluster emission, including prior error correlation, to enhance observational constraints. Enhance observational constraints. And also, a key part of this system is really to try to integrate complementary information from external products, so limited area models that do also a joint state emission estimation into the global system in order to be able to tackle all the scales involved. And finally, transformative approaches are required. Yeah, transformative approaches are required to meet the scientific and the operational constraints. So, we need to make the algorithm more efficient using machine learning surrogates, for instance, for chemical models. But also at the level of the algorithmic level, we need also to come up with new approach to parallelize the for lever and be able to meet the time constraints. And I will stop here. Thank you. Thank you. Before we go to the question, Nicaragua, I would like to revisit our schedule. Okay, so what I propose is that we go for lunch at noon, instead of 11.30. So we have one hour of lunch. Then shorten a little bit our coffee break, but ask more time for. Ask more time for questions because Lee, I think you have a short time as well as Nicola. So, what we could go through is a question for Nicola and then another five, ten minutes for a question for Laurie. We go to a coffee break and then David Hence would start at 10:50. So, if David Hans is there, is that okay with you? You need to understand. You need to understand. Yeah? Okay, fine with me. Okay. So that said, so any questions for being on the same phone? We canceled the clock. Oh, is it? Yeah. Oh, okay. All right. So then. Got it. That sounds good then. So why don't we I don't mean it's better than I expected. Thank you. So, what we could do is to have more discussion after lunch. I don't know what you would like to have before the photo, more questions for Laurie and perhaps Nicola, but let's go through the questions for Nicola and then from perhaps 1:30 to 2, we could get back here and have. And have more questions, or although we could go for lunch later, okay? So we could go for lunch at 12:30 because the lunch is served until 1:30. Just so you know, the tour of the BEM Center was cancelled. Yes, yes, I took that. Perfect. Okay. So you'll have a longer lunch for sure. Yeah, okay, thank you. So, any show your preferences. And, Dylan? And Dylan, what would you say? I'm still coming up to speed, but it sounds as though what you said earlier, in terms of taking some energy time now and starting lunch later would make sense. That way, you know, I miss Lori's talk, but Lori's talks will be more, talk will be more fresh in people's minds so we can have some discussion on that sooner rather than later. Okay. So how about lunch at 12.30? Is that okay with you guys? Yeah. Okay. So let's. So let's have some questions for Nicola Agusarais. Not yet, David. David. And we'll have a short coffee break and then we'll go with the mathematics section at 50. Two things in the chat, Richard. I don't know. I'm not sure I have a I'm not sure I have access to that. Let me see.