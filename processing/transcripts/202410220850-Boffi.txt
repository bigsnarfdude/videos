So, let me start by acknowledging my collaborators. So, the main collaborators of this ongoing project is Lucia Gastaldi from Ratia and Fabio Credali, who, I mean, I promptly put here his former affiliation because he just came to Kaust as a postdoc. So, he was in my PhD student at Kausta, then he moved to Pavia with. Pavia with the postdoc position, and now, since less than one month, it's back to Kausta. And then I also have collaboration with my actual PhD student, Najua, from Kausta, and my collaborator, Luca Elte from Pisa, and my former postdoc in Italy, Nicola Cavallini, who is now in Ispra. And I will discuss a long-standing project about the approximation of About the approximation of fluid and structures. And we'll focus a little bit on the continuous problem because it's always a little bit annoying for a numerical analyst to deal with a discretization of something for which you don't know whether there is a continuous solution or not. But unfortunately, this is the case. I mean, for fluid structure interaction, the highly non-linear coupling between fluid and structure makes the analysis of the continuous problem very difficult. And there are only partial results in this direction, but I will just comment. In this direction, but we'll just comment a little bit on what we did in this context. And the main focus of the talk will be, of course, discretization of the infrastructure interaction and with particular emphasis and focus on the final part, which is the more recent result, what we are working on right now. And since we are using an unfitted approach for the approximation of flu structural interaction, it's very well known that the common Very well known that common methods like CATFEM, all methods based on Nietzsche approach or something, they degenerate when you have small cut cells and you need a suitable stabilization on some way to recover the stability and the conversions of your method. And I will show you that actually our method doesn't suffer from this pathology. So it survives also when the cells are small and there is no restriction on the size of the cell in our analysis and there will be Size of the cell in our analysis, and I will confirm that also with numerical experiments during this talk. And well, I'm sorry that I'm not after a high-order approximation, so I am just plain non-fitted approaches. So we will, of course, be affected by the low regularity of the solution and the consequence about the convergence estimate. But I mean, you know, there is no, this is what I usually teach to my students: there is no best method. There are many methods. Method. There are many methods, and then depending on what you need, you use one method or the other one. But if you hear about someone that pretends that their method is for everything, is the best in all situation, then you should be doubt about what you hear about them. Because, I mean, I'm honest and I say that my method is good for something and some other methods are good for something else. I think that's life, right? And this is, I think, the good approach for everything. And okay, so let's just describe the model very briefly. Just describe the model very briefly. So, we deal with well, here is just a cartoon in 2D, but the same analysis works also in 3D. And it also works for co-dimension one, I think. This is the cartoon for codimension zero. It means that I have a solid which is immersed in a fluid with the same dimension. Here is two and two. And I mean, some of the things that I'm stating today are specific. Stating today are specific for this situation, but we can also approach the other situation where, for instance, in 2D, we have just a one-dimensional string immersed in the fluid. And the main feature of our method is that we have a domain, which is something like a box. So we don't care about the approximation of this boundary because the geometry is very simple, that includes the fluid with some solid inside. Fluid with some solid inside, and there is a container in particular, big omega, which is the union of the two. And all the numerical computation will be performed on this big domain that contains both a fluid and solid. And the solid will be simulated by an approach, which in our latest version is along the line of the fictitious domain approach. So basically, we extend the domain of the fluid also. The domain of the fluid also inside the solid. And we use an Eleanor description for the fluid with velocity and pressure, like Navi-Stokes equation. And we use Lagrangian description for the solid, where the variable is denoted by little s. And okay, so this is the idea. And in particular, the idea is that we have a reference configuration for the solid that we call B. Solid that we call B, and which is mapped at time t to this domain omega ts, which is immersed in the fluid, which is fixed. And well, this is just not impressive, but it's just a list of a very limited list of references of what people did in this framework. And I mean, in particular, there are two main philosophies. One is the boundary-fitted approach, and the other one is the one we are working on. Is the one we are working on, which is non-fitted, and uh, well, some methods are better, as I said before, for some situations, some others are better for others. And but what is known is that the boundary-fitted approach, of course, have problems when your solid undergoes a large deformation because of the of the difficulty in remeshing a solid that is moving so much. And our research, of course, stems from the immersed boundary method, and there are super experts in this room about that. And we moved then from the immersed boundary method to fictitious domain, and they are somehow related to each other. And we found at the end that with infinite elements, it is much more natural to use this fictitious domain approach. And for our references, I mean, just a limited reference. I mean, just a limited reference also from outside. So we started, I think, in this paper here. I think it was the second MIT conference. I mean, when Professor Bat at MIT was organizing this conference. So we introduced a finite element version of the IBM method. And then we joined forces also with Charles Peskin to work in this direction. To work in this direction. And then at the end, we move to, as I said, to the fictitious domain approach, also along the line of what my former PhD student, Luca Herte, who is also a collaborator in this research, is doing in this paper when he writes a variation on implementation of the immersive retirement method. And we started by working on interface on. Work in the interface problem in this paper. And then we realized that there is some formalism which carries over also to free structural interaction in this business. And well, this is probably now the latest survey paper where we describe all the model and all the possible approximation. Plus, the cutting-edge research that I'm going to present at the end about the small cut cells. Small cut cells and the condition number of the problem that are not included in this paper yet. Other contribution in this direction, of course, when we talk about non-fitted approach and fictitious domain, some of the technicalities that we're using are not so different from what is done also in the framework of mortar finite elements. And I quote this paper, which is one of the first paper about mortar finite elements. More term finite elements. And let me also acknowledge the contribution by Rolf Krause and co-authors, where they present a very deep implementation strategy for the transfer information that you need to perform from fluid to solid when you have this solid that is described by a mesh that doesn't fit the mesh of your fluid. And okay, so this is the And okay, so this is the equation. I think this audience is pretty much educated in this business. So we have a Navistoks equation for the fluid, and we consider a hyperelastic material in the solid domain. And this is the main kinematic condition that links the velocity of the fluid with the displacement of the body. So capital X is the. So, capital X is the map, the mapping that describes the displacement of the body. So, when you have the, when you take the derivative of X with respect to time, you have the velocity of the body that should match the velocity of the fluid. And this is the usual equilibration of the stresses at the interface that gives you the transmission condition on the boundary. And, well, we use a Piola-Kirchhoff. We use a Piola-Kirchhoff stress tensor that comes from a potential energy W, like this. And our fictitious domain approach, as I said, starts from, as usual, in fictitious domain, by extending the fluid domain also in the region occupied by the solid. So I will denote by U and T velocity and pressure that are fictitiously extended also in the domain. Extended also in the domain, in the solid domain. And the kinematic condition is the one that I mentioned before, which is written like this. And in order to impose this kinematic condition, this is the main key property of our model, we consider a bilinear form C that has the property that, sorry, whenever C lambda Z is equal to zero for all test function lambda, then z must be zero. Then z must be zero. So z will be the difference between these two quantities. So we want to match the derivative of x and u. So we take their difference and we test against any lambda through this balliner form. So this is the original way to impose the kinematic condition in our setting. And with this balliner form C, that has to be defined somehow. Defined somehow. We have this variational formulation for our problem. So we are given some initial conditions. So we are looking for velocity, pressure, displacement of the solid, and this Lagrange multiplier lambda, such that all these equations are satisfied. So we have this system where the first equation is Navi-Stokes equation up to here plus this term that involves the Lagrange multiple. This term that involves the Lagrange multiplier lambda. Then we have the divergence-free constraint everywhere. So we are dealing with an incompressible fluid, but also an incompressible solid in this setting. We can also extend to compressible solid, but I will not do this in this presentation. Then we have the equation related to the hyperelastic body, again, plus a term that involves a Lagrange multiplier here. And then we have the kinematic. And then we have the kinematic condition that I mentioned before. So, this difference u minus dx dt is tested against all mu in the same space as the Lagrange multiplier lambda that shows up in the other two equations. And well, this is just A and B are the usual ballinar form related to the Navi-Stokes equation. And the delta rho allows us also to deal with different densities for the fluid and from the solid. For the fluid and from the solid. So, if fluid and solid have the same density, which is usually the most difficult case because you could suffer from the added mass effect in some other discretizations, this term is zero. So this means that you don't have this term with the second derivative of x. Okay, so how about the continuous problem? First of all, I have to define C because I just gave this definition of the ballinal form, but I didn't tell you what I'm using. So is the ballinal form here, C that shows up in the kinematic. That shows up in the kinematic term and in the Lagrange multipliers, multiplier terms over there. So, we have two options basically. So, the first option is to consider a duality pairing, which is probably the most elegant from the mathematical point of view. So, you since we have our variable in the solid domain that are defined in H1 of Are defined in H1 of B on the reference configuration of the boundary, then one way to get this property that C lambda y equals to zer means that y is equal to zero is to take c exactly as the duality pairing between h1b and the dual of h1b. Or by using Ritz representation theorem in the continuous level, this would be the same. We can also represent the We can also represent the duality pairing by an inner product in H1. This is an identification that usually is done in Hilbert spaces. So option one and option two at the continuous level are actually equivalent to each other. But they will lead to different approximations. Because in one case, at the discrete level, you have to approximate the duality pairing, and in the other case, you have to approximate the scalar product in H1. Of course, this also Product in H1. Of course, this also gives you different possibilities for the Lagrange multiplier space. Because in the second option, you require that the Lagrange multiplier is in H1. So it's the same space as the body displacement. So you cannot deal with the discontinuous Lagrange multiplier, for instance, in the finite element discretization. On the other hand, if you consider the duality pairing, you have more flexibility for the Lagrange multiplier approximation. You can take also. Lagrange multiplier approximation, you can take also this continuous Lagrange multiplier that ensures some more local mass conservation in your kinematic condition. And well, for the existence and uniqueness of the problem, here also is a limited but yet a little bit impressive list of references that you have. And there are several situations, as I said, all simplified. There is no general theorem for the model that. For the model that we described, but in some particular case, people obtained some partial results. And what we did, I mean, we, first of all, we linearized the problem, because I mean, if we cannot solve the linearized problem, of course, we cannot solve also the fully non-linear problem. So we neglect the convective term for Navi-Stokes, and then we take the Piyola-Kirchhoff stress tensor just like a multiple of the Or just like a multiple of the formation gradient. And C, in this case, it's a scalar product in H1. So it's not the duality pairing, but it's the inner product in H1. And the linearization means that in the coupling between fluid and structure, here we take some X-bar, which is given. So, in general, it should be fully coupled, should be a fully coupled system, but we consider. Kappa system, but we consider the fixed x-bar in this place and in this other place, and then we solve for the remaining variables in the rest of the domain, including x that comes from the elasticity equation. And with this setting and under these assumptions that are pretty natural on the data, we are able to prove that you can find one and only one solution to this inner ice problem. One solution to this in a rice problem that satisfies this regularity property. And well, this I think is what we need. And in particular, I mean, this could be also a first step towards the full. We're not analysts, so we didn't continue this analysis, but we believe that since the regularity of the solution that we find matches with the one of the input, this could be a starting point for trying to analyze some fixed point argument to get the unique that exists. To get the existence of the solution. Maybe not the uniqueness, but at least the existence of your solution. And well, having said that, let's go now to the discretization, which is the main topic of our project. And one of the properties that were very important in this framework, and this is what convinced us to continue investigating this problem, is that we were able to. Problem is that we were able to prove from the very beginning an unconditional stability in time, which is very, very, very important because we are not using a full implicit scheme. We are using the same explicit, as I will show you later on. And on the other hand, if you use other approaches, there is a very famous paper in the business of fitting approaches, like the ALE, that shows that if you don't use a full implicit scheme, then your scheme is Then your scheme is unconditionally unstable, which is the nightmare, the biggest nightmare you can face in your discretization. But in our case, even though we are not fully implicit, we are able to prove unconditional stability in time. So we don't have any CFL restriction, which is of course very appealing because this means that if you refine in age in space, you don't need to have a very small time step to, well, if you want accuracy, of course, you have to refine, but if you just Fine, but if you if you just want a control of the energy, it is you have no matter what is the delta t. So, this is the continuous result, so continuous in space. So, let's so we consider this modified implicit Euler where we treat explicitly the coupling between the two. I mean, these are the two terms that we considered like. Two terms that we considered, like x-bar in the also in the existence theorem for the continuous problem. So, analogously, for the discretization, we treat those terms explicitly. So, otherwise, you would have a big monolithic system to solve, which would be very, very, also very expensive from the numerical point of view. But this xn instead of xn plus one allows you for a solution that involves at each 10 step just the resolution of southern point problem, basically. Southern point problem basically. And with this scheme, I mean, in the continuous problem, you have this energy estimate that tells you how the energy is bounded in time. And we can do something similar also at discrete level with the price of adding this term here. But at the end, you can find that this is bounded above. bounded above by zero. So this means really that if your potential w sorry, if the potential w is convex and if the ratio between the two densities is positive, then you don't have any time restriction whatsoever, any time step restriction whatsoever for the numerical solution of your problem. And starting from that, then we proceed. And starting from that, then we proceed with the space discretization. And at the end, as I already said before, at this time step, what you have to solve is a sequence of stationary settlement point problem like the one that is written here. So we analyze this stationary system in the setting of mixed problems. In the setting of a mixed problem, so you have to analyze some if subcondition of the problem of course, of course, depend on the discretization that you want to perform. And this is the discretization that we use. So we have, and this I think is the important description of our method. So we have, as I said, one container, omega, that is a big box that contains both fluid and solid, is the fictitious domain that we are using. Are you using and on that domain? We have a fixed grid. So that mesh is fixed once and forever. So if you have a box, it could be just a mesh of cubes or a uniform mesh of tetrahedra or triangles into D or squares or whatever you want, but this is fixed once and forever. And then you take on that mesh a stable pair for Stokes, so your favorite finite element for Stokes. There is no restriction. For stokes, there is no restriction on that. Then you have a second grid, ES, that is on the reference configuration of the solid. So no need to remesh, because the two meshes that we have, they are fixed once and forever. One is in one fixed domain, which is omega, and the other one is in another fixed domain, which is the reference configuration of the solid. Then, of course, the mapping X will map the reference configuration. Reference configuration to something which is inside the fluid domain, but our mesh is the one that is described on the reference configuration and is not changed at any time. And on that mesh, we have a space of continuous polynomials, continuous pieces polynomials that is the one that is used to approximate. One that is used to approximate the displacement of the solid. This is SH. And then we have another space for the continuous, for the Lagrange multiplier. This could be continuous or could be also discontinuous, depending, here is written continuous, but it could be also discontinuous, depending on the option one or option two that we're using, as I said before. And in particular, I mean, in general, we try. In general, we tend to use the same space for SH and lambda H. This is just for historical reasons. This is what we did at the beginning. But recently, and in particular, this is a work of the PhD thesis by Najua, now at CAUSTA, in particular in the case when we use the duality pairing approach, so option one, in the two options that I mentioned before, we are considering also discontinuous approximation of the Lagrange multiplier, and this seems to pay. Lagrange multiplier, and this seems to pay off in terms of local mass conservation. And let me also comment what is written here. So, as I said, we have two options. One is the duality pairing, and the other one is the H1 inner product. For the H1 inner product, there is nothing to be said. I mean, at the discrete level, you do the same. But how do you discretize the duality pairing when you have finite elements? Well, you can just simply. Well, you can just since your Lagrange multiplier space is smooth enough, is in L1 lock, is in L2, if you want, you can describe the duality pairing by the inner product in L2. So this is what we do. I mean, so basically the two choices numerically are either you consider the L2 scalar product or you consider the H1 scalar product. And L2 scalar product allows for this continuous multiplier. H1 scalar product doesn't. So you need Scalar product doesn't. So you need continuous Lagrange multiplier. And this is the system that you have at each time step. You have a system like this. So you recognize a nested subtle point structure. So we have this is the block that is usually called A in the mixed vanity element. This would be B transpose and this would be B. So you have A, B transpose, B. So you have AB transpose B0, where the matrix A is itself something that has the structure of a static point somehow. And for this choice of discretization space, what we did, we were able to prove that you have all the subconditions that you need for the stability and for the convergence, so that you can get some error estimates. And the error estimates are that. And your estimates are that your four variables have an error which is bounded by the best approximation of the four variables. And as usual, in mixed approaches, I mean, the best approximation are linked together. So you cannot consider one variable separate from the others because they are all together in a big mixed system. So it means that you have to somehow tune the approximabilities of the The approximabilities of the four spaces that you have here in such a way that you don't lose computational time. I mean, it doesn't make sense to raise the degree of approximation of U or P if you don't do the same also for the others. And also estimates depends on the least regularity of the solution that you have in this. And of course, you have a cap of regularity, which is given by the regularity of the Lagrange multiplier. Of the Lagrange multiplier, somehow, which is leaving, which is affected by the interface between fluid and solid. Okay. And now let's go to the more technical details that are also the latest investigation that we are performing these days. So, this integration of the coupling term has been the PhD thesis of Fabio and And of course, the fact that you're not moving the mesh doesn't hide the difficulty of the problem. I mean, somewhere, I mean, there is no free lunch, somewhere you have to pay something. And where do you pay? You pay in the fact that you have to compute integrals that connect together the two different meshes. So you have one mesh on the background, which is the one of the fluid extended to the solid, and then you have the fluid. To the solid, and then you have a second mesh, which is the one on the reference solid, which is mapped inside the container. And these two meshes, of course, they don't match because they are non-fitted. And you have to compute some quantities. And exactly this coupling matrix coming from the balliner form little C, and which in the case of option one is just a scalar product in L2, and in the case of option two, is a scalar product in H1. And the shapes. And the shape functions chi and phi that are here live on different meshes. So, how do you compute these integrals without losing accuracy? And of course, I mean, this is the situation in 2D. So, this is your mapping from the reference body. This is one element of this mesh that is mapped inside the fluid mesh, the background mesh here. So, you have to compute. Ground mesh here. So you have to compute an integral. I mean, these integrals are over B, which is this domain here. How do you do? As usual, with different elements, you sum over all the elements here. And in one element, you have to compute an integral on this geometry that involves shape function defined on one mesh and shape function defined on the other mesh. And of course, there is a mismatch between the supports of the basis function. Basis function. So, a basis function related to this node here, for instance, usually has a support, which is this yellow region that intersects my triangle here on this polygonal region, which is maybe a pentagon or something like that here. And this pentagon also contains a shape function on this triangle, which is smooth because it's just a shape function, and the triangle is a polynomial. But this shape function. Polynomial. But this shape function here is pieces polynomial on the different pieces of the star or the support of this shape function. So you have to take care of this singularity of your function that you have to integrate. I mean, in 1D, this would be the picture. I mean, you have one node here in the fluid, which would be this node there. And then you have a shape function, which is like this. And you have to integrate along this interval here. Along this interval here, and of course, I mean, you cannot use. I mean, no matter how many points you put in this interval for a quadrature rule, you cannot get a good accuracy of this integral because it's not a smooth function there. And so, okay, so you need somehow to compute the intersection between the two meshes if you want to perform the integration exactly. And this is exactly what we suggest. So, we have two possible ways to compute. Possible ways to compute these integrals. So, one way is the theoretically exact integration. That means that you just sub-triangulate your mesh and you get some composite rule in such a way that in each of this sub-triangle, you just integrate smooth functions and then you sum them up. So, this is the exact integration. Or there is the lazy or sloppy approach that is okay, just don't care, and you take. And you take a quadrature rule of some degree in your solid triangle here, and then you take the value of the function that is associated with that node. So in this node, you will take a shape function which is on the fluid smooth here. On this node there, you will have, on the other hand, something on this triangle. And on this node, you will have something on this other triangle here. This other triangle here. Of course, this is not accurate, it is not optimal order, but we analyzed also this setting because, surprisingly, we have that in some cases, you don't lose anything if you do that. So, you gain a lot in terms of computational time, but you don't lose anything. And this is the error estimate that I showed before. So, we want to deal with these approximation properties. Approximation properties. And let's denote now a suitable quadrature rule, CH. I mean, in the case of exact integration, it will be just C because there is no error. But in the case of the sloppy approach, it will be CH. And the first thing we have to prove is that the IMSUP condition now holds true because it's not guaranteed a priori that you can solve the system. I mean, if you since the existence Since the existence of the solution to this mixed problem relies on the Insub condition, you have to prove the Insub condition also for the perturbed system, and we did that. And then we used some sort of stranger lemma to estimate the consistency errors induced by the approximation of C. This is what we have. And this at the end is the final estimate that we get for the consistency error. So in the case of the L2 scale, So, in the case of the L2 scalar product, which is the one that works well also with the approximation of the integrals, you get this rate of convergence of the consistency error, h to the three halves, times the allogaric term. And three halves is good because it's exactly what you get due to the singularity of your solution for the error estimate. So, you don't lose anything if you have this consistent. This consistency error. And on the other hand, if you take the H1 scalar product, so the L2 of the gradients, then you have a similar term like this, which is H1 half, which again would be optimal. But you have this additional term here, which is bad, because it's the ratio between H of the multiplier and H of the velocity. And these terms, of course, can kill you because if. And these terms, of course, can kill you because if you take comparable sizes for the two mesh, this term is of order one, doesn't go to zero. So it requires, I mean, optimal conversions would require that the mesh of the multiplier is defined much faster than the mesh of the velocity. And this leads, of course, to the final error estimate for the L2 scalar product that includes this term here, or the final error estimate for the H1 scalar product that includes all the terms. H1 scalar product that includes also this bad term here, and this is confirmed by numerical experiments. So, we did some numerical experiments to check our theory, and we had three tests, one where h lambda goes to zero, one where h lambda goes to zero, and also this ratio goes to zero, and another one in L2 for which h lambda goes to zero without the compatibility condition. So, we know that h1 should. So we know that H1 should work also only in test2, but not in test1, while test 3 should work anyway. And this is what we get. So this is the H1 scalar product, and here is the generating because we don't have the compatibility in the, also here is the generating because you don't have the compatibility of the mesh. But if you take compatible mesh, then you restore optimal convergence. On the other hand, in L2, no matter what you're doing, Two, no matter what you're doing, you don't need any compatibility, and you get good results. And this, I think, is a good message because it allows you to deal with the cap in terms without paying too much in order to get optimal results. I think I have only a couple of minutes to talk quickly about the small cut cell. The paper here is not yet submitted, but we are almost there. The paper is finished. We just have to submit it. But the idea. Submit it, but the idea, as I said, is that when you map the body into the fluid, you may have cells that are cut very little. I mean, for instance, here in this node, you see that you have something that is at the intersection of the other mesh. And of course, what happens in this case? So there are also here references about that, in particular for the CAT feminine, you need to stabilize ghost and ghost penalty. Uh, ghost and ghost penalty approaches, and so on. But in our case, we don't need any stabilization. And let me just show quickly one numerical experiments. This is what we did. We shifted the immersed body in such a way that we have a situation which is perfectly matching or not. And we want to see what happens when the shift tends to zero, so the cut cell becomes smaller and smaller. Becomes smaller and smaller. And this is the condition number of the matrix, which has, of course, some change depending on the shift. But you see the range. Basically, this is constant. So we just enlarge the y-axis to make it appear. But you see the difference from here to there is negligible. So there is really no difference in the condition number of the coupling term when the shift is zero. And here are the errors. Also, for the errors, you see that the range is basically the same. So, the error is constant. So, there is no influence on the error coming from the shift between the different meshes. And I have plenty of numerical results, but I don't have time to describe all of them, but they are all in agreement with what I said before. So, you have the condition number that really doesn't depend on the area of the smallest intersection. intersection and all the the convergence really don't depend on the on the on the small cell that we might have in our intersection of the meshes and uh just to conclude i should reach the conclusion somewhere yes we have also now an estimate for the condition number of the of the system which scales like h to the power minus two in the case of h1 and h to the power minus four in the case of One and h to the power of minus four in the case of C0, and this is rigorous and confirmed by the numerical experiments, also, and is coming from this abstract setting by M and Guermont. And well, these are the conclusions, and I thank you for your attention.