This wonderful workshop. It's a real pleasure to be here and talking about this work. So I'm going to talk about a variant of an assortment optimization problem, a sequential variant. This is joint work with Orestis, Papadi, and Opulas and the South CD at Colombia and Salal Humair who's at Amazon. So Orestes, he was a postdoc. He was a postdoc at the Data Science Institute at Columbia working with me and Asaf. Tragically, he passed away last October. It's taken me a few months to start talking about this work, but I know he would have been very happy for this work, really his work, to be presented at this venue, at this workshop. So thanks to the organizers who helped make that happen. Make that happen. With that dedication, let me jump into the problem. So, assortment optimization, the classical version of assortment optimization, seller knows the universe of products and has to decide the subset to offer to the customer that maximizes the expected reward. So, in this work, we consider We consider a sequential variant of that assortment problem where the seller does not know upfront the universe. This was really motivated by an application that came up at Amazon. The work is motivated by that is not solving that application, but let me mention that application anyway. So, when Amazon is trying to buy inventory for really think about For really think about fashion products. Here, I have ski jackets for the venue. Yeah. They observe the catalogs or they observe the products of different vendors in some arbitrary order. Because these vendors do trade shows in some arbitrary order. At that point, they learn about the product offering of that vendor. And because those vendors And because those vendors have long lead times, they value order commitment. So, at rate show, if you can make the order commitment, you get a significant discount. So, it's really an irrevocable buying problem when you observe. So, you will observe these products sequentially. You don't know the future. You may have some distribution about that, but you don't know what the future vendors are going to offer. When you observe the When you observe this product, you have to make a sort of irrevocable buying decision. Yes, in practice, they don't have to make it there and then. There is recourse. There is some penalty for reneging on the order. You can add on to the order. But for this work, and also the decision includes both whether I would want it in my assortment and how many units to order. Units to order. So, in this work, we abstract away all those complicated details and, in fact, focus just on the assortment decision. So, the abstract version of the problem that we focused on in this work is you observe products sequentially from, so there's a universal product for which you probably know a You probably know a distribution of features and rewards. You will observe these products sequentially, and when you observe, you make an irrevocable decision to include it in your assortment or not. So, we are not talking about the inventory decisions here, just including it in the assortment. And the goal is to find a policy to construct an assortment that. To construct an assortment that maximizes the expected reward or revenue from one random customer. Yes. Is it one customer comes at the end or is it your customers along the way? No, there's no customer along the way. So think about the ski jacket example. This is for the next season, these vendor shows would be happening now. So the selling is going to happen next year. Selling is going to happen next year. So, this is way before the selling. So, here's a seller observes this product with the feature and the revenue, decides to include it. The second one not included, third is included. And let's say this is the assortment, you get the assortment DAC. The reward you get is Reward you get is the reward from this set, which depends on the choice probability, the demand model, the choice model, and it's an expected expectation over the subset. So the constraints that we consider are of the form of cardinality constraints or capacity constraints. Constraints. And the choice model, in this work, we focus on the simplest choice model, which is the multi-nominal logic. Is there a way to make this specific positing a distribution over the 100%? Instead of positing a distribution over features and revenue, we just posit a distribution over attraction values and revenues. Both Ri and Bi are unknown? Both Ri and Bi are unknown. We know the distributions. Yes, so let me put the set up here. So multinomial logic with the attraction values, that is the choice probability. We assume the attraction of the outside option is. Attraction of the outside option is one without loss of generality. And what we know is these parameters for each product, so Ri and Vi, they are drawn from a joint distribution, but independent across products. So for a product, RIBI could have arbitrary correlation, that's a joint distribution, but independent across. But independent across products. Any question about the setup? So, in the same target regime, where you have more and more arriving products, does the no-purchase option matter anymore? Okay, so that's a good question. So, it may, depending on if you have more if the revenue is going to zero. So, or VIs go to zero. or Vi's go to 0. So, yeah, if Vi's are expected Vi's is a constant, then actually it will still matter. Let me think about this to be 0 and you have the same problem. It's still this actually reduces to the classical version of the profit inequality. And in fact, And in fact, you'll see that's the hardest case for us. So, are the constraint systems on that? So, the constraints we'll consider is cardinality, so at most k or capacity. Each item has a wave, and you have a weight. That's it. Okay. Okay. So, so this is this is our setup and And when you observe an item, as I said, it's an instantaneous and irrevocable decision to include in the assortment. So what is our, so to begin with, let's forget about the constraint version, let's focus on the unconstrained version. So you can pick any assortment you want. Now, in the Now, in the unconstrained version, you may think that, like in Antwan's talk, in MNL, only two quantities matter. The Ri Ui, the sum of that, and the sum of UI, or sum of Vi, Ri Vi and sum of Ei. Total attraction you have gathered, collected so far, total Ri Vi you have collected so far. So, you may think that Dp, I mean this is just two states, I can keep track of it. States, I can keep track of it. Maybe with some epsilon discretization, you can do dp. And yes, that is true. Only thing is that requires knowing the order. So yes, if you know the order, it is the DP is, you can do the DP for MNL. The policy will be much more, I mean, we are aiming here for a simple policy. DP would be a messy policy, but yes, you can implement that. Even in rapid Even in random order, it's not clear DP is tractable, right? So in this case, we for fixed order, is it tractable? For a fixed order, the two you just keep track of these two states in some discrete, in some discretized manner, you can get some epsilon out. But we are not making any assumption about the order. And in practice, I mean, the motivating example we saw. Motivating example we saw actually there's no predictability on the order that you can you can assume. You mean order the order of the distributions? No, order in which you will observe. Yeah, yeah, but you observe like the order of the distributions. Yeah, okay. The orders. The order of random distribution. The order of the distribution. Yes. You only observe the realization. Yes. Yeah. So a DP is not So, a DP is not feasible if order is not fixed. So, what's the benchmark we compare to? So, the benchmark we compare to is the profit benchmark. It's expected optimal in consent. Now, this is a very strong benchmark. It's a fair question. Why do you want to compare against this? In the absence of DP, DP doesn't exist. The absence of DP, DP doesn't exist because there's no order. So, in the absence of that, this is a actually, I would say this is the only benchmark that I can think of which is reasonable. But if you're not convinced with that, if you can compete with this benchmark, you're competing with other policy wishes. Question: So, if I have a search class and I look at the learning we can get from that search, and then somehow I randomly kick out the elements from the search, it probably has. Would that currently? Would that guarantee a half-hour solution to the other? Because if it does, then you can probably use something like online content as a butcher. So you can kick out for free? No, no. So imagine there's a randomized procedure that somehow eventually guarantees that every element is going to be kicked out and probably has. Okay. Would that just figure out every element? I don't know if it would be good enough, yet. Good enough. You might want to have some fractional solution and then you kick out the piece of it. That's true. So for the fractional solution, you get to see the active maximum plus and. But I don't think for a revenue function, this is a statement. You won't have the basic L V, like you'll have this L V with some tricks and things. It's a property that's preserved for submoderal functions, so for proud curvature, probably. So this is in some restricted sense, you have some submodularity? Other way of doing property inequality, right? That you solve an LP and then the relaxation is rounded. So, I think if I understood Rob is asking if we could do the same, because for ML we have the LP-based element. I see, I see. I guess for a special case when all eyes are equal to each other, then it's just coverage. Yeah. Yeah, I yeah, I don't I haven't thought of the pincher. Yeah. So this is the benchmark wheel company. So, this is the benchmark we want to compete against. And we want to find a policy which gets us expected revenue that competes with this profit budget. Okay, so this audience doesn't need this slide, but have it anyway. For MNL, the unconstrained assortment is Assortment is nested by revenue. Depending on the realization, the nested by revenue solution could be ABC or something more. But it depends on the realization of the revenues and the attraction models. Now in this picture, so on the y-axis, I have the expected Expected revenue of the threshold itself. So, all items bigger than certain threshold, and this I just plotted the items in increasing order of revenue. So, now in this picture, this is the optimal threshold you should pick. This is your optimal set. Here, this is the threshold, and this is the optimal sequence. The algorithm. The algorithm, the policy that we are looking for is a policy, a simple policy, a threshold policy like the original profit inequality, which means the question that we are asking is, is there one threshold that works well across these realizations of revenue sign-ups and so in particular, is there a single threshold that will work well in expectation? So, you let us say we pick this threshold, for this realization the optimal is there, our threshold picks a bigger cell. We will also be on the contrary when the optimal is bigger and we pick a smaller cell. So, our first main result is what you would expect once you have set up this problem. Once you have set up this problem, it took us a long time to show it, but we have a result analogous to the original, the simplest version of profit inequality by setting the threshold as half of the expected optimal that you can compute by Monicado because you have access to samples. Set this threshold, look at the expected value of the threat, so expected value of So expected value of the threshold policy picks all the items with revenue above this threshold. Expected profit revenue you will make with that policy is at least half of the profit. Now we didn't quite implement we so the next yeah so when you get a new product the value of VI doesn't matter you just look at Vi doesn't matter, you just look at Vi. The value of Vi mattered in this in the threshold. Yes, so we tested it numerically. We didn't quite implement this, what we did is because it's a scalar search, threshold is a scalar search, we just did a scalar search on the threshold, and this is the plot we got. This is much better than half. Okay, so let me explain what I so the x-axis here is. x-axis here is picky to flexible buyers, which is in the hindsight optimal solution, what is the property of no purchase? So property of no purchase is high here, which is weak bias, property of no purchase is low here, which is flexible bias. In the hindsight optimum, expected value of, so that's how I'm plotting the x-axis. And you get much better than half, especially. Got much better than half, especially here. So, maybe there may be two things happening. One, we are probably using a different threshold than the one that I showed you in the previous group. And maybe there's a better analysis if, let me call this parameter gamma, the stickiness, which I have a parametric bound which can get you much better. The other remark I want to make. Remark: I want to make flexible buyers, which means probably of no purchase is zero in the hindsight optimal solution, which reduces to the original profit inequality, and that is where we are getting closer to the half. So, the hardest case for us is actually the original profit inequality when the hindsight optimal solution is actually trivial. Hindsight optimal solution is actually trivial. You pick the highest. So this motivated us to look further and we were able to, so we define this gamma as 1 minus the expected property of noble change in Halcite optimal solution. And by setting this threshold, we can show you get a 1 over 1 plus gamma compared to. competitive with the profit. So the analog bound is actually more for profit than competitive. Oh, the analog is more okay. So gamma is the profit that's basically none of the random variables is larger than the change. I see. Okay. So yeah, good. We can talk of a reference. That's a good correspondence. So we can get, and for gamma equals And for Dhamma equals 1, which was the most, which was the flexible bias, we get the half. So this is always better than half, and in case of picky buyers, you actually get much better. Okay, so we can also show that for any fixed comma, this is the best you can do compared to the profit. To the compared to the profit, and like Omar pointed out, this algorithm, the online algorithm implementation is oblivious to attraction values. So, you do not have to observe attraction values to implement this online policy. You needed that to compute the threshold, but not for the online policy. Okay, so do I have 10 minutes? Yeah, so I think. I think the proof is actually very simple, so I should be. I will aim to go through most of the proof for this case and then mention the result for the Cardinalty and Deplacy instruments. And the proof actually is in hindsight, it breaks down like the proof for the profit inequality, just getting it to work took us a long time. I think that's true for many profit inequality proofs. And in hindsight, yes, every. In hindsight, yes, every step seems yes, that's the right thing to do. So you have A tau is the thresholded set. So picking all items above tau. That's what I referred by A tau. So that's the expected revenue from this set for one particular realization is this. I can break it up in the following two parts, which is exactly what. Which is exactly what I do in the profit inequality proof as well. And now, what the profit inequality proof, the original profit inequality proof, was able to do was bound this in a way such that you create two terms that you can balance. And that was the hard part for us. So, this term was bounded by the probability that the algorithm doesn't pick anything times maximum of. times maximum of this guy or actually summation summation of the x's. But here this part bounding this part in a way that we can balance the two terms that was the hard part. In hindsight it's easy and let me show you the proof. So what we could show is this is the this was This is the this was the first term. Go back. This is what I am looking at, or expected value of this. So, what we can show is this expected value can be bounded by it is at least lambda times the profit benchmark minus a similar term for the hindsight optimal system. And lambda is expected no purchase for our policy. So each and every term actually corresponds to the proof in the original property inequality. Now let's believe this claim for a minute. Let me finish the proof with this claim. So you have expected value of our policy is bigger than this term plus this term. This term is bigger than this, so I have this. Now set this threshold to be 1 over 1 plus gamma the profit benchmark. Actually half might be easier to see but yeah even this. But yeah, even this is simple. By setting the threshold here, it just and plugging it in this inequality, you would get the expected revenue our policy makes is at least one over one customer. And I was thinking I would I was thinking I would go through the proof of this claim. It actually is these four, is these five inequations and really the proof is, let me not go through these inequalities, but just focus from this equality to this inequality. All it uses is a property of the choice, the M and L choice property, which is this choice property is bigger than. Choice probability is bigger than the product of these choice properties. So, in fact, any choice model that satisfies this property from here to here, you would get this result. So, this was the property we used, and then the other trick we used was we could take fresh samples, and that doesn't change expectations. So you have taken a sample of i and n minus i, but you can take fresh samples of n minus i that allows us to allows us allows us to rearrange expectations in some way because expectations didn't change because of fair samples. So, so with these two properties we were able to show this this claim that that shows us. That that shows us. Okay. So uh now for the for the constraint case, for the cardinality constraint case to begin with, now you in a the online policy has to pick an assortment with at most k items, and the threshold we use is the following. So, So set tau to the half of expected opt constraint op now, which you can again solve for a minute. And you pick an item i, if you have still not picked k, k items already, you pick an item i if b i times r i minus tau is greater than tau tau over k. Now see the resemblance with the L P, optimal L P for Optimal L P for the cardinality constraint M and N. That basically picks the top K of V i times R i minus tau, where tau was actually optimum. Here we do tau to be half of optimum, and this has to be bigger than tau over here. And this gives us a half. So two points. Two points. This algorithm is not DI obliges. So we need to observe both the attraction and the revenue to get a half. But this is the best possible. One remark I would like to make here is we set K to N, that also solves the unconstrained problem. For some reason, we did sensitivity analysis in our numerical experiment. That this version gave us better results than the unconstrained version. Results than the unconstrained version. So I don't have an explanation of that, but maybe we need to test it more roversely and you don't see anyone doing better. Yes, so we thought the other one would be better for unconstrained, but this was somehow marginally, but yes, but there was a systemic lease. So we get a half-competitive. So, we get a half-competitive for Cardinali constraint. For knapsack constraints, if we have each item, the weight is small compared to the size, you can get half minus epsilon. And that epsilon actually depends on what that small bit or small size assumption is. But in general, without that, we can only get one-fifth. One-fifth. So there might be this may not be tight. There may be some room for improvement there. And again, these are non-oblivious to attractions and size. So we can extend the results for generalized retraction model, which is really an extension of Really, an extension of MNL, but also to any choice model that satisfies that property that I had mentioned in the proof of that proof. Although in terms of concrete models, these are the GAM and independent model are the only other ones that I can show satisfy this. Markov chain does not. Okay. Okay, so yeah, so we get the same result for the unconstrained setting, half, but it's slightly worse for cardinality and capacity constraint. Okay, so I am out of time, but I'm out of slides as well. So I'll stop here.