Thank you very much for the introduction. And also, thanks, Peter, for the invitations. It's such a shame that I couldn't be there in person due to some visa issues. But nevertheless, I'll be very happy to present my recent work on causal discovery for observational heterogeneous data. Can you guys see my screen, the slides moving to the next slide? Yep. Me to the next slide, yeah. Yeah, we will. Okay, cool, thanks. Uh, so before I talk, I would like to first acknowledge the two collaborators I have on this project: Fran Tingzhou from Texas NM, she is now a PhD, fifth-year PhD student, and also Kojing He from Renmin University of China. So, obviously, all the work is being carried out by the student founding. And also, I'd like to acknowledge the National Science Foundation for their generous support. So, the topic of today's talk is causality. So, arguably, establishing causality is ubiquitous or the common goal of any field of science. For example, scientists have been trying to figure out how genes talk to each other, how they regulate each other. Well, how can we prevent one natural disaster to another? Or does smoking really cause cancer? Or does this vaccine really work for preventing, for example, COVID? For preventing, for example, COVID. So, as you can see, one common thread behind all these different types of questions is it's all question about causality. So, establishing causality for unknown systems is absolutely crucial to answer questions like what will happen if you do some intervention to that system. So, the goal standard to discover causality is control experimentation. For example, let's say if we're looking at a gene. Let's say if we're looking at a gene regular networks, so if we know, let's say the gene regular network on the bottom right is the true graph, what happens is if you do interventional, in this case, knockout experiment, you would expect the following result. Let's say if I knock out gene one, which is sort of the regulator of gene two and gene, gene two and gene three, and assuming the regulation is positive, then if this causal graph is true, then knocking out gene one should decrease the expression of gene two and gene three, if the regulation is positive. The regulation is positive. On the other hand, if you knock out gene two, again, given a graph, if the graph is true, then we should expect to see a decrease of expression of gene three, but not gene one, because gene two is not a cause of gene, a gene one. So similar for gene three, because gene three is the effect of gene one and gene two. So knocking out of gene three should have no effects on gene one or gene two. So that's given given a causal graph. If you assume the causal graph is true, then that's what your expected outcome from. What are your expected outcomes from performing those knockout experiments? The reverse is also true with some mild assumptions. If you do these experiments and you do observe those observations after experiments, then you can infer that the regulatory network between these three genes are indeed given in the network on the bottom right. So that's kind of the sort of gold standard for discovering causality in answer if you can do control experimentation. If you can do control experimentation, of course, in many cases, control experimentation is often infeasible due to many reasons. For example, it may be too expensive. For example, the no-call experiments on last slide is feasible, but it's very hard to scale to a large number of genes. Sometimes the control experimentation may be unethical. For example, forcing people to not to smoke is unethical. So if you can't do that, of course, it's much easier to figure out whether there's Course, it's much easier to figure out whether there's a causal relationship between smoking and lung cancer, but we cannot do that because of ethical reason. And in other cases, it's just physically impossible. So if you want to understand how sort of climate change affects our life, you cannot really just change the climate as you wish. So this is just physically impossible to do so. So lack of control experimentation in many of control experimentation in many uh in many many areas is it still the next question is is still possible to identify causality based on observational data so if you cannot intervene the data all you get is some observation or passively observe the system is it still possible to identify or at least generate some causal hypothesis about about the system so the answer is yes but of course you have to uh assume make additional assumptions because after all there's no free lunch if you don't After all, there's no free lunch. If you don't only have observational data, but you want to infer causality from that, you need to make some assumption. So, the specific motivation of this talk is from cancer genomics. Particularly, we're interested in breast cancer in this project. So, breast cancer is one of the most common cancers in women, and it's known to be molecularly very heterogeneous genetic disease. And also, from the literature, we know that gene regulation. We know that gene regulation can change over the course of cancer development in breast cancer. So that's actually one of the reasons why traditional one-size-fits-all treatment often fails in treating breast cancers. And people or researchers have already shifted their focus from one-size-fits-all treatment to personalized treatment. So just a little very brief history of sort of cancer treatment. So starting from 1800s, people have been using surgery to sort of cure cancer, try to cure cancer. But obviously, Try to cure cancer, but obviously it doesn't work once the cancer, so the tumors escape the original sites to other parts of the body. So, surgery would not work in that case. And then about 100 years later, radiation therapy and chemotherapy came along. Radiation therapy is more or less the same as surgery in the sense that once the tumor escapes its original site, it's not going to work. Chemotherapy is, in some sense, a more global approach, where even if the tumor sort of escapes, it can still improve. Sort of escapes, it can still, in principle, kill the tumor cells. But the downside of chemotherapy is it also kills healthy cells. So there has a large side effects associated with chemotherapy. Then in 2000s, target therapy becomes really popular. So in a nutshell, target therapy can be sort of illustrated with this cartoon where suppose I know in the tumor cells, there's a sort of pathway or a direct network between for the proteins or genes, which leads to sort of Which leads to sort of indefinite proliferation of tumor cells. In order to stop tumor from living forever, maybe we can design a drug to block this pathway. So for example, if we can design a drug to block this triangle, which is sort of the bottleneck of this pathway, then we can in principle stop tumor from live forever or duplicates indefinitely. Or duplicates indefinitely. That's kind of the sort of high-level idea of target therapy. But of course, we are not, the cancer is not cured yet. The problem is not 100% solved yet, because target therapy, although conceptually appealing, but it does not work for every patient. One of the reasons is because, well, because patients are so heterogeneous, even patients with the same type of cancer, let's say breast cancer, they actually have very different disease. Very different disease. So, if let's say if the drug you design is blocking the triangle, but if for some patients there's actually an alternative pathway reaching from sort of the upstream of the pathway to the diamond downstream without going through this triangle, then obviously this drug that is designed to block triangle or the signal from triangle is not going to work for this particular patient. So, therefore, to sort of improve psychiatry. To sort of improve psychotherapy, people have now been designing a personalized treatment. So, potentially, you design a drug for patients or for each patient's potentially. So, one of the first steps in designing personalized treatment is to understand how genomic or genetically, how those genes are connected each other, proteins connect each other in each patient. So, that will be the focus of this project. So, the goal is to basically illustrate in this box where we have a bunch of patients and they are. Where we have a bunch of patients and they're all quite different, even though they are both diagnosed as breast cancer, but in fact, genetically, they are very different. So, the goal is to construct a personalized genetic network so that at least in the future, potentially this personalized genetic network can be used to develop personalized drug. So, just an overview of the talk. So, the goal is to, again, construct individualized or personalized subject-level gene networks. There are a couple of challenges associated with genetic gene gene gene gene There are a couple of challenges associated with this estimation problem. One is, in some sense, we have a sample size one problem because we want to estimate a network for each patient. So, if you think about covariance estimations, it's very difficult to estimate covariance matrix if you have only one sample. Second challenge is since this talk is about causality, so we only have observational data, so I cannot really intervene the patients. So, we only passively observe. only passively observe what are the gene expressions of this tumor sample from this patient. So it's observational data. On top of it, the patient's population is heterogeneous, so that adds another layer of challenge. And third, it's not really a challenge, but there's some feature that we would like to have for our model is although patients are heterogeneous and we wish to construct gene regular networks for each patient, but we do want to have some But we do want to have some type of smoothness, meaning that similar patients should have similar gene networks. That's both for interpretability of the output of the model as well as for statistical parsimony. So our proposal, we develop a Bayesian network with latent trajectory embedding, which we're going to focus on in this talk. So just a little bit of background on Bayesian networks. So I had a direct executive. And a direct executive graph. So, a direct executive graph is an object that consists of two sets. The first set is set of nodes representing a set of random variables. In our case, those random variables are simply the genes. And the second set in direct X-Graph is the direct edges, which connect those nodes. And usually, those direct edges are used to represent conditional dependencies among X's. But later, these conditional dependencies will connect to causality later on. Uh, connect to causality later on, but for now, uh, DAG only or commonly DAGs are used to represent conditional dependencies of the variables of the nodes. Beta node is really just, you know, pair these DAGs with probability distributions so that we can use this model to model our data. So basic network is a pair where G is direct-assisted graph and a probabil model that factorizes That factor factorizes over a degree of g in the following fashion. So we can write a joint distribution of x, which is a vector, as a product of conditional distribution of each variable given its parents. So by parents, I simply means the parent of J is all the nodes that point towards J. So for example, 4 is a parent of two. So in this simple example, we can write this joint distribution of x1, x2, x3, x4 as a factorized form by looking at it. A factorized form by looking at each node and its parents, right? So in the end, if x4 does not have any parents, then the conditional distribution is degenerate to just marginal distribution. So what is a Bayesian network good for? Well, first of all, Bayesian network provides a compact or polymonious representation of the joint distribution. Because normally, if you have a, if you write down the joint distribution of x using chain rule, then you would have, for example, x1 given x2, x3. X1 given X2, X3, and X4. But now, because we have an underlying sparse Bayesian network of direct AC graph, then the first, at least the first conditional distribution, becomes smaller. The number of variables that you condition on is smaller than the full chain rule. So that gives you a sort of parsimonious representation of joint distribution. More importantly, for our purpose, the Bayesian alcoholization also implies conditional independences of x. Independences of x. Conditional dependencies of x are sometimes also known as the Markov property. For example, what is known as the local direct Markov property says each variable is independent of its non-descendants, given its parents. So if you're assuming your joint distribution factorizes with respect to that, then the local direct Markov property has to be true. So in mathematic notations, that says for each node xj, it is independent of its non-descendants. It is independent of its non-descendants, given the parents of J, where descendants of a node is simply all the nodes that J can reach to by following the errors. So non-descendants is everything else. Again, for example, in this simple graph, I can say that x1 is conditional independent of x3 given x2, because first of all, x2 is a parent of x1, and x3 is a non-descendant of x1. So based on local Markov properties, this conditional independence relation has to be true. Conditional independence relation has to be true if the distribution factorizes with respect to this graph. On the other hand, if you have a reverse both arrows, I can say that marginally x1, x3 are independent because, first of all, they don't have parents. And second, again, x3 is not a descendant of x1. So based on the local direct Markov properties, the marginal independence between x1 and x3 has to hold in this graph if the joint distribution factorizes over this graph. Factorizes over this graph. What is important is the Bayesian L factorization and the Markov property of conditional independence of X is if and only if relationship is equivalence relationships. So if your distribution respects conditional independences of X according to the local Markov property, then that distribution also has to factorize this with respect to that graph as well. So it's equivalence relationships. So far, DAG, Bayesian network has nothing to do with causality. It's really a way to compact or parsimoniously represent a joint distribution. So in order to infer causality, we first need to represent a causal model. So what people use in literature is something called causal DACs. So causal DAG is a DAC with the only exception that the direct edges now are used to represent direct causal relationships rather than conditional independences. For example, using the same Dependencies. For example, using the same graph as before, now instead of interpreting this graph as a condition independence of those three variables, for a causal graph, the interpretation goes like this. So given this graph, the first graph, I would say x2 is a common direct cause of x1, x3. If you reverse these edges, then x2 is a common direct effect of x1, x3. So the only difference between colodex and decks are their interpretations of the direct edges. So, the next question is: how causal graphs and Bayesian networks are connected? How do they work together? So, in order to interpret a Bayesian network causally, we need to make a causal markup assumption, which is very common in causal graphic model literature. So, the causal markup assumption says the following. Each variable is independent of their non-effects, given their direct causes. So, for example, if we're looking at three variables, smoking, lung tissue damage, and lung cancer. Lung tissue damage and lung cancer. And suppose, let's say, smoking causes lung tissue damage, and lung tissue damage in turn causes lung cancer. And also, suppose there's no other pathway from smoking to lung cancer. So there is no other causal pathway. Suppose this graph is true. Then perhaps it's not unreasonable to assume that conditional on lung tissue damage, lung cancer, and smoking are become becomes conditional independent. So if that's going to be. So, if this causal graph is true, then it's not unreasonable to assume that Markov. But of course, there's a big if. So, obviously, this assumption can be violated if there is a measure confounder that's not represented in this graph, or if there's a selection bias in our data set. So, yeah. So, if this three, this cartoon, this graph is a true causal graph without confounded with a selection bias, then a causal graph. Confounded with a selection bias, then a causal Markov assumption is a reasonable assumption. So if you have, if you believe, if you're willing to assume causal Markov assumptions, then if you recall, Markov property of Bayesian network that we briefly mentioned in last slide, which says each variable is independent of its non-descendants given its parents. So if you see the connection between non-effects and non-descendants and direct causes and parents, and because there's an effort. And because there's an if and only if condition that I said earlier. So, if we assume this Markov with respect to the causal graph, then the joint distribution has to factorize this with respect to that causal graph as well. And that's how we connect a causal deck with a Bayesian network. And once you connect the causal deck with a Bayesian network, the Bayesian network is called causal Bayesian network. That's under the assumption of causal lockup assumption. All right. All right, so how do we actually write down the mathematic formula for a causal Bayesian network? Well, a causal Bayesian network is really just a Bayesian network where the direct AC graph is a causal direct AC graph. So we have essentially, because of equivalence relationship between Markov properties and Bayesian node factorizations, I can write down the joint distribution of X as a product of conditional distribution where each node is now conditional as direct causes. Node is now conditional as direct causes, which also is the parents in the graph. And suppose we have ID data, I index the observations. Then really, if I put everything together, the joint distribution of all the observations from X1 to Xn is really just a double product of conditional distribution of each node for each observation, given its direct causes. That's the representation of a causal Bayesian elk, where we assume the caudal graph is somehow. Where we assume the caudal graph is somehow known. So, given the knowledge of a caudal graph, how do you write down the joint distribution of the variables? So, representation is hopefully intuitive, but learning is actually very challenging, especially if the data are purely observational. That's because of the non-identifiabilities for a Bayesian network. So, Bayesian evolution can be classified or can group into Markov equivalent classes, where each class basically contains Markov equivalent Bayesian, which have the same set of conditional independences. For example, the first three graphs, A, B, and C, they look quite differently, and they obviously have very different causal interpretation because the direction of edges are different. But unfortunately, they have exactly same conditional independences. So, because of this observation method. But because of this observation, methods based on conditional independences alone, for example, the very well-known PC algorithm cannot uniquely identify the causal graph. Let's say if one of the first three graphs is a true data generating graph, and you apply methods that are based on conditional independences alone, the best you can say is one of them is true, because all you discover is X1, X3 are conditional independent of X2. And you cannot further identify which one is the true data generating graph. Graph. So that's one of the most important, the most pressing challenges of sort of causal discovery based on causal Bayesian network for observational data because of this equivalence. But since 2006, there are many, many methods that are proven to be identifiable even with observational data with additional assumptions. Again, there's no free lunch. If you want to discover causality based on observational data alone, And based on observational data alone, you have to be willing to make assumptions. So, having proven that causal Bayesian network is identifiable, for example, if the distribution is assumed to be non-Gaussian, or if you assume the causal effects to be non-linear, or if you assume your data is not IID, they are actually heterogeneous. That's actually the sort of the framework we're going to work with for this talk. We're going to assume that our data are not IDID. Actually, in fact, this heterogeneous. Actually, in fact, this heterogeneity of the population where you draw a sample from is actually helpful in identifying causal relationship. So, most of the work in this sort of heterogeneous data causal discovery area focus on assumes causal invariance in the sense that the causal graph is assumed to be the same across all the observations, even though the observation may be heterogeneous. So, that's kind of the common assumption in many of the heterogeneity work. In all cases, Work. In our case, we actually assume the opposite. We're going to assume that a causal graph, in fact, can be different across observation. If you recall from much earlier slides where we do want to identify potentially different causal graph or potentially different gene regular networks for each patient. So it may be reasonable to assume that different cancer patients may have a slightly different gene regular networks. So the main difference between our method and the other methods in this area is they are assuming causal invariance. We, in some sense, assume there's a causal variance. All right, so the proposal, so our proposed model, we call it Bayesian with its introject embedding. So recall that if the data were IID, so this is the same equation that I copied from earlier slides. So I can write down the joint. From earlier slides, so I can write down the joint distribution of x1 through xn as basic a double product of conditional distribution given its direct causes. So that's the IID model. So we don't want to assume that our model is IID, because each patients are quite genetically different. So in our model, we're going to introduce a latent variable, which is observation-specific. So it's indexed also by the sample index I. And given that latent variables, we're going to assume that XI are instead of ID, they're now Iid, they're now conditional independent given Zi. They're not identically distributed because each P of Xi given Zi is a distribution that indexed by this Z sub I. So if you put that together, the joint distribution of the samples X1 through Xn, given all the observation-specific latent factors or latent variables, again, can be written as a double product form, but each distribution is different across both variables and across observations. Across both variables and across observation as well. And it's indexed by the latent variable ZI. We call this ZI a pseudotan, which is borrowed from genomic literature, specifically from single-cell RN-seq literature. And these little factors may represent disease stages in our case, may represent cell states in single-cell RN-seq analysis or other things in different applications. It's latent. We're going to infer this latent variable together with. Latent variable together with a graph from observational data. So, we make one specific example of this sort of more general framework of BNLTE by choosing by making a specific choice of this conditional distribution of Xij given its parents that index by the latent variable Zi. So, our specific choice is write down this Xij as a sort of a linear combination of its potential causes. Potential causes, but the weights are the weight depends on the latent variable z sub i plus some independent noises. So some special cases, if all the causal effects BJL, they are zero for any ij and l, then of course this model is simply reduces to latent factor model. Of course, it's a non-linear latent factor model. But what's more interesting is when this b function is not zero. B, this B function is not zero. Particularly, by looking at which region of B this B function is not zero, we get individualized causal graph in the following sense. So whenever BJ L is evaluated to zero, to non-zero for a given Z sub I, then we say that L is a parent or L is a direct cause of J in graph I or in the causal graph of observation I. Okay, so there's an equivalence between these two. Equivalence between these two notions, the sort of causal effects functions, evaluate to be non-zero, and L is regarded as a direct cause of J in graph I. So the overall idea is we imagine that there's sort of a latent trajectory of Z, and our causal graph is kind of sort of aligned along this latent trajectory. And the causal graph structure itself, as well as the causal effects, can sort of As well as the causal effect, it can sort of vary across this latent trajectory. So that's sort of a high-level idea of the proposed model. So as I said earlier, one of the most important or most critical challenges in causal discovery with causal Bayesian network is identifiability. So can you identify causality only based only on observational data? So yes, in all case, Yes, in our case, for the proposed model, we can prove that it is identifiable if you're willing to make the following two additional assumptions. One is we assume there's no confounders, which is also known as causal sufficiencies. And second, we assume the distribution is faithful to the graph, meaning that there's no accidental cancellation of causal effects. So, under these two assumptions, we can prove that it is indeed identifiable even with observational data alone. Observational data alone. So the intuition is given sort of on the left-hand side of the slide where on the top, suppose I have some data, subivariate data with X1 and X2, and they are not cause and effect of each other. So there's no causal relation between X1, X2, but they are correlated maybe due to some common causes or common confounders. So if that's the case, if you look at, let's say, the marginal variance of X1 as a function of. Variance of x1 is a function of z of the latent variable z. In this for illustration, let's assume z is observable. And you will see that the variance of x1 is pretty much a constant over z for both variables. On the other hand, if I simulate some data from a causal model x1 causes x2, but x2 is not a cause of x1, then again, looking at the marginal variance of x1 or x2 as a function of z, then you will see that the marginal variance. See that the marginal variance of x1 is still a constant with respect to z because x1 is cause, but is the cause of x2. x1 itself does not have a cause that vary with z. So for that reason, it will still be a constant. But the marginal variance of x2, once x2 being x, sorry, once x1 being marginalized out, the marginal variance of x2 as a function of z is not a constant anymore because the causal effects, we assume the causal effects is heterogeneous. So change over observation or change over 0. Uh, you know, observation or change over different values of the latent variable z. Okay, so that's sort of intuition, of course. Uh, to prove it, well, we need to use a sort of characterization of Markovic-Klon class of Bayesian network. So, um, so that was so that theorem suggests that at least in principle, you can identify causal relationship given observational data. So, to actually implement it, we need To actually implement it, we need to make some specific additional choices of different modeling components of a model. For example, we need to choose how to model this A and B function, where especially B is the critical functions, where B is essentially a function of causal effects as a function of the latent variable Z. So, to make it flexible, we model this as spines, by splines. And in order to learn the causal graph, we put a Learn the causal graph, we put a spec and slap prior, which induces sparsity in this b function. And for latent variables, since we also need to infer the latent variables, without loss of generality, we'll assume this latent variable is in this compact set 0, 1. And we'll assume a repulsive process prior that used in one and downson in 2015. Our theory does not really depend on the choice of this prior, but empirically or in practice, this prior works very well. This prior works very well because they're also trying to avoid sort of because they encourage Z1 through Zn to fill out the entire interval Zn1 because it's a repulsive nature. So with this sort of property of this prior, it essentially avoids identifiability issues of the latent variable due to scale and translational invariance. So one of the features of the model was to identify individual Was to identify individualized graphs, causal graphs. So, how do we actually do individualized selections? Well, because we're using splines, particularly B splines, cubic B splines, one of the nice feature, or at least the feature that are useful for us for B spline, cubic B splines, the bases have only a finite support. Okay, for example, in this, let's say, look at the top left corner. At the top left corner, in this plot, we have a bunch of bases which is represented by this green lines, gray curves, and each of them actually only have finite support. And on the very top panel of this graph, I plotted sort of spline coefficients corresponding to each spline basis. So if you set sort of adjacent spline coefficient to be zero, let's say, then if you do the spline expansion expansion. Do the spline expansion expansion multiplication and take the sum, you will get a curve that is represented by this black curve in this plot, such that there's a region where this curve is exactly zero. That's how we manage to force some region of this b function to be exact zero, whereas for other, you know, the region outside this zero region to be non-zero. Okay, so how does that translate to personalized y for individual? Translate to personalized graph or individualized graph. So imagine that you have three patients with their latent variable z1, z2, z3 taking values on the z-axis or the horizontal axis in this case. So let's look at just one cause of effects between one and two. So obviously, if z equal to z2 for the second patients, this b function is evaluated to zero. So that corresponds to a missing edge between one and two for graph, for the color graph. Graph for the causal graph for patient two. On the other hand, since the first patient and third patient, their B functions do not evaluate to zero. Therefore, the causal edge between two and one is present in GZ1 and GZ3 for the first and third patients. And through this sort of piecewise sparse functions and the relations between this B function and a graph, we'll be able to identify sort of Be able to identify sort of individualized causal graph based on heterogeneous data. So, for the interest of time, I'm not really going to talk about simulations, but we do have extensive simulation to both, you know, sort of empirically support the theorem. So indeed, we can identify causal relationships if the assumptions are met. Second, we also have simulation to compare with competing method. There are plenty of competing methods that we can. Of competing methods that we can compare to. So we have extensive simulation in the paper, but for the sake of talk, let me just say it worked well in general. So I'm going to skip the simulations, but if you're interested, of course, I can talk more after talk. So let's look at the motivated example that we started with, which is the breast cancer data. So we download some data from TCGA breast cancer gene expression data from the Uh, data from the TCGA portal. The data set has over a thousand heterogeneous tissue samples, tumor tissue samples, well, tissue samples. 113 of them are normal tissues samples, and over a thousand tissues are tumor tissues. So we look at 58 genes from this set of pathways that are known to be very important for breast cancer. And we run our algorithm as an MCMC-based algorithm. We run our algorithm as an MCMC-based algorithm, and in the end, we obtain the point estimates of the graph by controlling the posterior expected FDR at 5%. So first of all, we're going to look at basically three set of results. One is the estimation of the latent variable Z. Second, we're going to look at a graph on the population level. And then we're going to look at graph estimates from the individual level. So for the pseudo-definition, So, for the pseudo-time or latent variable estimations, we well, so that's the color is essentially the estimate, is the estimate latent variable or the value of the latent variables. And notice that I also denote this sort of dots by using two markers, one with a star, the other with a circle. And a star represents the normal tissues, and the circle represents the tumor tissues. And this is the data that reports on the first. And this is the data that are plotted on the first two PCs. So, as you can see, that the color sort of matches quite well with the type of markers, indicating that the latent variable that we estimate from the model coincides with the sort of the state of tissue, whether it's normal or tumor tissue, very well. Note that we didn't use this information, normal tissue versus tumor tissue in our model fitting stage. So, that's kind of orthogonal information that we later used to. orthogonal information that we later use to sort of validate to validate whether our estimated single time is reasonable or not. So given from this part, it looks like it's pretty reasonable. So the second summary or second result we can obtain from applying our methods to this data set is the population level gene record networks, where we essentially take the union of order graph across all patients. So that's kind of the union graph for this. kind of the union graph for this data set. So the solid line represents the positive causal relationship and the negative, sorry, the dashed line represents the negative causal relationships. So there are a couple of things that can be sort of read from this estimated networks. I will just mention one of them by looking at, for example, the hub genes or the genes with a large number of connections. So we identify a couple of hub genes. We identify a couple hub genes where degree is greater than four. So these are the genes that have a degree larger than four. And all of them seem to be sort of preserved across all patients. So if you look at each individual patient networks, all these hub genes remain hub genes in those individual networks. And many of them have, you know, their importance is well reported in breast cancer literature. The last summary that we can The last summary that we can draw from this analysis is individualized gene-report networks. So we randomly pick sort of six patients with very different Z values. And so with our model, we are able to sort of visualize their gene record networks based on their latent variables. So because their latent variables are very different for these six representative patients, their gene record network can be quite different. Can be quite different across these six patients. And some regulatory relationships vary sort of significantly across patients, some sort of preserved. The one that are very sort of the ones that do vary significantly across patients are those two sort of relationships. And of course, since we don't really know the ground truth for this data, so in order to verify them, In order to verify them, additional experiments need to be done for this sort of two pairs of genes. But of course, one of the utility of the proposed method is to sort of generate a hypothesis so that a follow-up experiment can be carried on on this more focused hypothesis. So, lastly, I would like to conclude by mentioning a few extensions of this work. We actually have We actually already extended this model to cases where there are confounders. Remember that in our theorem that I presented, I assume there are no confounders. But in fact, if there are confounders, meaning that measured common causes, with some additional assumption, the confounding mechanism, it is still possible to identify the causal relations between the observed variables. And also, we also extended already extended to cyclic graph. So Bayesian L is by definition. So, Bayesian network is by definition acyclic, but in biology, especially in gene-regular networks analysis, it is known that there's a lot of feedback loops among the genes. So because Bayesian network does not allow cycle, direct cycles, we need to extend this Bayesian network framework to direct cyclic graph in order to identify feedback loops. So that's two extensions we're already done, but we also may also want to extend the current framework further. To extend the current framework further to sort of non-Gaussian noises, also non-linear causal relationships. So, our current model is based on Gaussian noises and linear relationships. So, that will be interesting direction that we might pursue in the future. With that, we would like to thank you for your attention, and I'll be happy to take any questions if there are any. Thanks. Thanks a lot, Jan. Um, any questions for you from Um any questions for you hi Jang, it's an excellent talk. Um, I must have missed something, but uh, I would like to just ask once again, uh, how are you inferring on the directions in the graphs? Yeah, so uh, that's first theoretically it is identifiable, so you don't. It is identifiable. So you don't. Let's say if you only have two variables, x1, x2, there's only three models possible. So x1 cause x2, x2 cause x1, or there is no causation between x1 and x2. So in this simple case, you can just compare. Let's say if you're a frequentist, you can just do likelihood. You just compare the likelihood of these three models and you pick the one has a higher likelihood. Or if you want to penalize complexity, you can do BIC. For Bayesian method, you can put a prior and compare, let's say, base factor. let's say base factor uh for all cases where we have you know many more genes than two so what we did is putting a spec and slab prior so if you do not if you don't have the identifiability theory uh or identifiability property of the graph putting a spec and slab may lead to sort of you know exploring exploring the posterior distribution on equivalent graphs but since uh with this heterogeneity assumption additional assumptions we can show that each graph is actually uniquely different in terms of the Actually, uniquely different in terms of the posterior distributions. So, with Spike and Slab and Plus Gib Sampler, we'll be able to explore the sort of posterior distribution of the graph and identify sort of the high posterior region of the graph space. What I was asking was probably perhaps like in your earlier slides, you had some cartoons with X1, X2, X3, and you said that so. That so a graph can be interpreted in different ways. So, which is the parent and which one is the node? So, the same conditional dependence independence, with the same conditional dependence independence relationship, the graph can be interpreted in several ways. So, which direction to take? The causal, I actually that's my confusion. Yeah, very good question. So, let's say if you have a Bayesian network that is linear and Gaussian. Bayesian network that is linear and Gaussian. Let's say if you're looking at compared these three graphs, since they have exactly same conditional dependencies, and if it's a linear Gaussian model, they also have the same likelihood. So in fact, in this case, you cannot identify which one has the higher likelihood, let's say. But then, because we have additional assumption, distribution assumption, for example, heterogeneity and other assumptions, indeed, let's say if the first graph is the true graph, which generated data, and you have a large enough sample sizes, you And you have a large enough sample sizes, you will find that the first graph have a higher likelihood than the next two. So they are identifiable in that sense. So, for example, in our MCMC, what we're going to do in practice is for each edge, we're going to propose either deleted, add edge, or reverse edge. So because of their likelihood posterior are different across different graphs, even within the same equivalent classes, we can in fact differentiate, let's say, graph A from graph B. Say graph A from graph B, because if the graph A is the true graph, if we have enough sample size, the posterior of the graph A is higher, even though they have exact same conditional independences. I don't know if that answers your question. Yeah, thanks. There's one on the that's all we get to discuss. Do you want to know where we have so? Yeah, just for clarification, I may have misunderstood, so I'm not sure my question makes sense, but for you, I Makes sense, but for your identifiability theorem for your model, are you fixing the distribution of the Z and so it's under this distribution of the Z that things are identifiable or it's not under the distribution of the Z? Not really. We don't have to fix the distribution of Z in this case. So the theory that I present is the identifiability of the graph itself. And one propositional theory that I didn't present. One propositional theory that I didn't present in this talk is there's additional assumptions we need to make on Z, the distribution of Z, in order to identify Z itself. Okay. Luca, I think you want to ask a question. You can ask now. Okay, thank you. Jang, well, let me first tell you that I like your presentation, but I'm a little bit But I'm a little bit worried about your approach to the Z variables because you said you were taking a prior on them, but I guess they are what they are in the population. So they are more part of the sampling distribution than on the prior. And so I guess how much, I mean, it looks like it works because you say that in the end you double check it. But I mean, that is possibly worrisome. Possibly worrisome because, um, I mean, if your observations are diverse, then you are all right and your repulsive distribution is appropriate. But if they are not, because they are similar, I guess you could have problems. So, that was, do you have any comments on this? Yeah, yeah, definitely. I think it's a very, very good question. Because we don't observe any of the Z's, the estimation of Z itself definitely depends on. Definitely depends on what distribution choice we make on Z. We make a choice of repulsive prior, but if you, instead, for example, using a uniform prior, we may have a different result in terms of Z estimations. But what is important here is it doesn't, in some sense, it doesn't matter what these values are, as long as they are monotone transformation of each other. That's actually one theorem that we have. So we cannot hope to. We cannot hope to identify Z exactly because we have no observation at all for Z. But the hope is we can identify Z up to a monotone transformation. So that is still useful in some sense sorting observations, which has application in genomics, where I want to see how gene or how observations align on sort of a one-dimensional manifold. Yes, we may miss the sort of the absolute value or the magnitude of each. Value or the magnitude of each z, but as long as sort of the in terms of the order they are preserved in terms of monotone transformations, the graph itself is can still be identifiable. And yeah, so I think that's a very valid question where we cannot hope to identify Z without any observations, but our hope is to identify sort of monotone transformation of the true Z if there's a true Z. Okay. Okay, thank you for this additional insight. And let me also thank the organizers for these beautiful, let's say, four nice afternoon for me in Italy. Thank you. Thank you. Thank you for your question. Thanks to Luca for joining us. Jang, very nice story, as always. Can I follow up a little bit to Noerit and Jurid's question? And I guess also a little bit Luca's question. I think all of us left a little bit puzzled. All of us are left a little bit puzzled by the role that these latent sets are playing here. Can I try to rephrase it in my words and you tell me how I got it badly wrong or right? Kind of a point. Would a valid pointed answer to Norik's question be that while for one patient you cannot identify, you cannot distinguish the different options of equivalent conditional independent structure. And conditional independent structure. If you have other patients with like adjacent set values, then suddenly you can, because they have to be kind of monotone transformations of the earlier. And kind of following up to Judith's question, can I ask a similar question in different words? How are these pseudo-times set? How are they different from just yet another latent variable, yet another latent or missing confounder in that case? Or missing confounder in that case, if it's latent, Xi P plus one. Yeah, it could very well be a latent confounder. So in fact, on this slide, if we forget about causality for the moment, if I let's say all the causal effects B are zero. So in fact, this model is reduced to sort of a non-linear latent factor model. So, and this non-linear latent factor Z can represent many things. It can represent, for example, It can represent, for example, in my case, maybe it's a cancer stage, which can be thought of as a latent confounders. If you don't have that observation, if you don't have this information in your data, if you only look at gene expressions, this Z variable may very well be representing those latent confounders. If that answers your question. So, in some sense, this Z is really just summarizing how similar, in some sense, it's sort of using one-dimensional latent variable to summarize how similar. To summarize how similar patients are in terms of the observation data we do have on gene expression. Can I ask a related question? In your results for the breast cancer data, it looked almost too good to be true because all your normal tissues had like an early latent time and all the tumor tissues had a later latent time or vice versa. Yeah, all the tumor tissues, they're like, they're going into the dark. Tissues, they're like they're going into the dark blue. It looks almost too good to be true. Did you include some informative priors? Or no, not at all. We didn't put any, other than the repulsive prior on these, we didn't put any stage or sorry, tissue state information in the model. There's some miss, yeah, I agree. It looks good, but there are some, for example, this piles, this couple dots are really blue, which is far away from the red. So there are some sort of misrepresentation, but yeah, overall. But yeah, overall those Asians probably just don't yet know that they have the tumor. Yeah, but yeah, short answer to your question: no, we do not put any questions. Almost magical. Louis has a question. Thank you. Can you go back to your model? The linear model? Yeah, that one. Just to understand the notation, the A's and B's, they are functions of the Z, or the Z's are just subs. The sets are just sub-index X, so as a function of Z, as a continuum, we assume it's a piecewise smooth function of Z. What are the four? These are the splines or? Yeah, it is the splines. Yes, they are splines of Z. Back to Peter. Sorry, yet another stupid question because Luis just brought it up. In the Bayesian network, everything is like normal linear relationships. And I think sometimes in the beginning, you mentioned that in order to identify things, one option is to assume non-linearity. Is it possible that the thing works with those latent pseudo-times because you allow for non-linearity with your splines, right? Yeah, but yeah, something's latent on top of that. Yeah. But also, there's a difference. So when I say non-linearity, So when I say nonlinearity, I mostly refer to at least that existing work that works on nonlinear Bayesian network is it's nonlinear in X. So here we still assume it's, you know, for simplicity, we still assume it is linear in X, but yes, but the causal effect self is nonlinear in Z. But as I, you know, at the very end, I said I want to extend that to nonlinear case. That also refers to, I want to extend that it's nonlinear in X also. Linear in X, also. So, our current work assumes linear in X for simplicity. Any other question? Nope. Okay, if there isn't any, then we thank Jan again for his talk. Thank you.