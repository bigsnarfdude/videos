Here, welcome back everyone. I hope you had a nice break yesterday afternoon. Our first speaker for the day is Professor Antoio Domovsky and he's going to talk about chaos and complexity, the lens of dynamics in kilospace. Thank you very much. We're happy to be here. Wonderful workshop. Amazing nature, hiking. And you said welcome back everyone. I think it has some second meaning, right? Second meaning, right? All right. So I will be giving a short overview of the Kurlov business. So the title of the talk is very elaborate. Chaos and complexity through the lens of dynamics in Krillov space. Through this talk, I try to convey the following idea. There is this new approach, which is called Krillov something. Different people call it different. Different people call it differently, and different people focus on different aspects of it. But nevertheless, there is this new field, if you wish, or subfield, new topic of dynamics in Krillov space. And I will try to give my personal understanding of what people are trying to achieve. And if you look at the papers, there are already many papers on the subject, dozens and dozens of papers. This is an active topic. Losens of papers. This is an active topic. If you look at these papers, or at least when I look at these papers, they try to monitor what is going on in the field. I see that they try to focus on different aspects. And some of these aspects are the following. The original one, which goes back to the paper by Berkeley Group, Parkin' et al. This is related to universal operator growth hypothesis. This is an attempt to detect chaos or growth chaos with help of Chaos with help of Krillov business or Leich's coefficients to be more specific. There is also a very intriguing connection to Autoc and more generally to operator growth. And then this is all related to complexity, real complexity spreading, complexities. And when you look at those papers, it's not really clear what's the starting point, or if you look at the original paper by Parker et al., it's not really clear how they come up with their suggestions or proposals. Come up with their suggestions or proposals or conjectures. So, I want to demystify this Krillov business a little bit. And I will start with the following statement, which is, if you think about it, it's a completely obvious mathematical statement that all this Krillov business knows is just a two-point function. The starting point is always a two-point function. You have an operator, you consider a two-point function. I write it in very general notations with brackets of some sort. Brackets of some sort, you can specify what it is. It's a thermal two-point function, infinite temperature two-point function. But in the end of the story, all you study is a two-point function, or in case of state complexity or spread complexity, this is a very similar object, which is the fidelity decay or survival probability, which is essential. This is just a different name for the same quantity. So, basically, you're considering a function of time. Mathematically, both the Mathematically, both these objects are very, very similar. I will focus mostly on this, but many of my conclusions are automatically extended to this case as well. So, basically, what you're dealing with is a two-point function, as a function of time, and that's all. It's one function. Now, the relation between this function of time and what people call Lunch's coefficients or what people call Kurlov complexity, which is another function of time, is very intricate. Very intricate. It's one-to-one. If you know C of T, in principle, you can calculate all of these objects. And the other way around, if you know B of N, you can calculate C of T. So it's one to one. And that's a blessing and the curse at the same time. It's a curse because the relation is so intricate. It's a curse because if I give you C of T, it might be very difficult to calculate P of N or K of T. You need to do it numerically. It's not clear how to do it analytically. It's not clear how to do it analytically. If you do it numerically, you need to keep very high precision in your arithmetics. So that's the curse. But at the same time, it's a blessing because maybe by studying these objects instead of this object, you will be able to look at certain aspects of C of T which are not objects. When we discuss two-point function as a function of time, we usually focus on early time evolution or maybe some late time profile, but there are certain intricate properties which Intricate properties which are some intricate properties of the two-point function which are not obvious, but eliminate those properties. Okay, but in the end of the story, if C of T, the two-point function, doesn't know about something, you can be sure that the N will not know about it and K of T will not know it. So there could be no mystery. If you study an aspect of physics which is not captured at all by the 2.5. Is not captured at all by the two-point function, be sure that whatever you do in curl of space will not help you illustrate that. Okay, with this introduction, that perhaps was the most important slide. Now I will give you some technicalities, but if you're working in this field or looking in the papers, you know very well what is on the slide. The screw-love business is simply the following: you have a starting operator, then you start acting by the Hamiltonian on this operator, and then you On this operator, and then you build the basis of Krillo. I suppose it was just no, no, probably not. I'll just continue. So you have an operator. You act by Hamiltonian on this operator. You build what is called Kurlov basis in mathematics. You build the basis by acting by an operator on a vector many, many times. And then you apply orthogonalization procedure. Orthogonalization procedure, and when we speak about orthogonal basis, it means that we are introducing a scalar product. I want to emphasize that mathematically, scalar product is an additional structure on top of the action of a Hamiltonian on the operator, or the state, it doesn't matter. So, action of a Hamiltonian on a state or an operator is defined in its own right, and then scalar product is introduced as a new mathematical structure. As a new mathematical structure. If you go back to linear algebra, you have a vector space without any basis involved, just a vector space. You have an operator on that vector space. You have a vector. You add a linear operator on that vector. That's all defined without any basis. That's all defined without any scalar product. Now we introduce a scalar product as an additional structure. Then you can talk about orthonormal or orthogonal, not necessarily orthonormal, just orthogonal basis. Just orthogonal basis. That's maybe important for the later, and that's completely clear when you look through this. And then, what people call the Louville and this three-diagonal, I'm skipping a lot of technical details, assuming that most people in the audience know what I'm talking about, and this three-diagonal matrix, which consists of Lancashire's coefficients a n and bn, they're just a representation of the adjoint action of the Hamiltonian. And in case of the spread complexity, in case of the state complexity, that State complexity that would be just the regular action of a Hamilton. Okay? How do I do that? Do it like that. So the mathematics, I already spelled this mathematics a little bit, but the mathematics is extremely simple. You have a state, it's completely abstract algebra. Krilov introduced his Krilov method with no connection to quantum theory, right? He was interested in taking certain matrices and diagonalizing them in a cheap numerical way, right? So he suggested. So he suggested taking a matrix H, you need to study properties of matrix H. You start with the initial vector, you act by this matrix many, many times, that produces a basis. And then you can act as many times as you want. If your matrix is finite, of course, you are, at some point, will start repeating yourself. Your basis will be complete. And then, if you want, you can introduce after that scale a product to make an orthonormal basis. But an important thing is that, and this is also completely clear, that if you This is also completely clear that if you start with this vector v0 and you ask yourself how would Krillov basis, full Kurilov basis, correspond to the full original basis of correspond to the full vector space where V belongs? It will be clear that what you need to do is to diagonalize H. And then if your V0 has a projection on an eigenvector, particular eigenvector, then the Kriddle space will include that eigenvector. Will include that eigenvector as a part of a Krillov space. If there is zero projection to begin with, it will not involve. If you have degeneracy of spectrum, so there will be different eigenvectors with the same eigenvalue, then you will count that eigenvalue once, because V0 will have a projection not on the particular eigenvector, but on a particular eigensubspace. And there is only one projection of this V0 on that eigen subspace. This v0 in that eigen subspace, and that particular projection will enter into Krillov space. So if you have degeneracy of h, each eigenvalue will enter only once. There will be no degeneracies. Okay, good. Now there is a very simple mathematical statement. Since scalar product is an additional structure on the curl of space, by change in scalar product, you will change your basis, but you will not change your operator and how it acts on the curl of space. And the Kurd of space. And if you start changing your basis, it means that you will start changing your representation of the operator. Like what we write as a matrix, it's a representation of a operator in the basis, right? That's what it is in linear algebra. So if you start changing your basis, you'll start changing representation of, oops, start changing representation of your operator, but not the operator itself. And therefore, if you start continuously changing your scalar product or Scalar product or your definition of your correlation function, it will not change Leuvillian as an operator, but it will change your Leuvillian as a matrix. But all of those changes are what is called isospectral changes, because you're writing the same operator in different bases. That's all you do. And that gives rise automatically to the integrable structure, because what you're doing is the isospectral deformation. If you're a little bit familiar with the integrable structure, you immediately recognize. The integral structure, you immediately recognize what you have is the Lux representation, because Lux representation automatically preserves the spectrum of the corresponding networks. Okay, so we wrote about that in the context of the Skrillov businesses in this paper, and there will be a talk later today by Nick, who will be speaking about this business as well. And one example which Nick will be focusing on is the following. You consider two-point function which is temperature-dependent. You define two-point function as a function of time and temperature. Time and temperature. When you change temperature, you physically change the two-point function, but from the point of view of Krillov business, you're only changing the definition of scalar product. So that should give rise to integrable structure. Okay? But then in the end of the story, if all we do is we are rewriting C of T, then that will give us another edge on understanding how these VNs are changing with respect to temperature. With respect to temperature or any other physical property. Okay, now let's discuss a little bit. Do we have? Okay, this is the time. Now let's discuss a little bit the connection between Krillov, business, and chaos. Now I'll try to review the original universal operator growth hypothesis, but instead of starting with this hypothesis, I will try to start with the answer. I will try to present what I think is physics behind the Is physics behind that hypothesis? When you read the original paper, they motivate the hypothesis, and perhaps it's in the spirit of many recent conjectures when people say, well, this is the bound. I just conjecture in most general things, in most general case, the bound will be saturated. There are hypotheses like that about complexity, and Nick talked about that two days ago. There are similar hypotheses. There are similar hypotheses in all parts of theoretical physics, but this thinking does not necessarily illuminate physics behind this hypothesis. So, what I will try to do, I will try to present my understanding why this universal operator hypothesis works. So, the idea is, again, to start with the two-point function, but instead of introducing Langevin's coefficients, I will simply do the Fourier transform. I will work with this power spectrum. And then it's very, very clear that it may. Clear that in many physical systems you will expect exponential decay of this quantity. And exponential decay is the slowest possible decay of power spectrum at high frequencies. You cannot have a decay slower than exponential because you need to be able to make a reverse Fourier transform to obtain the correlation function in the time domain and correlation time in the correlation function in the time domain. Correlation function at the time domain should have a good Taylor series near t equals zero. It could be divergent at a finite distance away from the origin, but at t equals zero should have, it should be well defined. I'm now talking not about necessarily field theory, I'm talking about lattice model. Maybe I'm talking about field theory. You might be worried that when two operators collide, the equal zero will have a singularity. In that case, you need to introduce temperature and regularize things by moving operators. things by moving operators away from each other thermal circle. So t equals zero should near t equals zero you should have a good Taylor series and it means that f squared should decay at least as fast as exponential, could decay faster. In field theory it will always decay exponential because when operators collide you must have a singularity in field theory. Okay? And then as I said in the time domain it simply means that you have a singularity along the imaginary axis. Along the imaginary axis. In field theory, it means that you have a thermal circle, two operators collide on the thermal circle, you should have a singularity. And this behavior is consistent with the linear growth of Lancashire coefficients, which is a separate story. But then the question is, how is that all related to keros? I believe the very first statement of that kind appeared in this 2014 paper by L. Say that all, who studied numerically correlation functions in a lattice model of class. Lattice model of classical spins. It was a lattice model of classical spins. And I observed that whenever you have a classical system which is chaotic, then F squared behaves exponentially, but when you have integrability, it decays faster than exponentially. They did not try to explain this observation, they just made this observation, and this observation was in the context of classical spin systems. But then, more Spin systems. But then, more recently, and after the paper by Parker et al., with one of the authors of that paper, we were trying to elaborate on what happened. And our understanding is the following. You can start discussing the growth of norm. It's a type where I did not put it in other vertical line. You can start to discuss a norm of operator, an infinity norm of any other norm of an operator. When you evolve operator in the lattice system, In the lattice system in imaginary time. So you conjugate it with exponent th and then exponent minus th. It's not a unitary time evolution. Therefore, norm of operator will increase. Well, it will change. And you can actually convince yourself by counting things on the lattice that it will increase and within a finite period of time it will diverge. This is very difficult to prove. What we do in this paper, we try to show. In this paper, we try to show the bound, but then we try to argue that this bound will be saturated. It's in the same spirit as I just mentioned a few minutes ago, that you try to show there is a bound and you try to explain that the bound will be saturated. But what you can actually do, you can try to count nested commutators, and then you say if those nested commutators will not somehow miraculously cancel each other, then there will be a singularity of the norm. Of the norm at the finite distance away from the origin, if you move in the imaginary time. And that automatically means that if you consider two-point function, which is after all some scalar product, you will also have a singularity of that scalar product in the imaginary time. So basically, mathematically, it's the same. You have a singularity in the imaginary time. It means that your F squared will decay exponentially. So this is a mechanism, I believe, which explains the... The asymptotic of square as being the probe of caps. If you have a generic non-integrable system, nested commutators will not cancel each other, and therefore you will have the slowest decay possible, which is consistent with platonity. If you have integrable systems, then you will have nested commutators canceling each other because there is certain internal structure. And then instead of exponential decay, you can have much faster decay. You can have much faster decay. Okay, so that has nothing to do with Lange's coefficients in Krillov space at this point. But then if you go back to the original paper by Parker, Kao, Avdoshkin, Scafidi, and Altman, then which appeared roughly here before we put our paper. So obviously their paper preceded our result. Our result was on. Preceded our result. Our result was on the heels of that paper trying to understand what exactly did there. They say the following: instead of considering this asymptotic behavior of the power spectrum, let's recalculate Lancashire coefficients. And that's one-to-one correspondence, but it's non-trivial correspondence. And instead of looking at the high-frequency tail of F squared, let's look at the behavioral Einstein's coefficients. And if it is, they predict that it is linear in the most general. Linear in the most general case, and that's a signature of generic system. They didn't say the word chaotic, but they said that in general case it would be linear. Now, mathematically, it's almost equivalent. There are some subtleties. If you have f squared decaying exponentially, from here you can actually argue that bn will grow linearly. I said just the wrong thing. If you have bn growing linearly, if you have bn growing linearly, If you have Bn growing linearly, then you can argue from here that F squared will decay exponentially. If you have F squared decaying exponentially, and you assume that Bn are smooth function of n, then you can conclude Bn grow linearly. But if you just have F squared decaying exponentially, but you do not know how Bn behave and you do not know if they are smooth, then there is no proof that as a result of going from F squared, you will have this behavior. So there is some subtlety. So there is some subtlety that might be important, might be unimportant, but I will be showing you examples where VM do not behave smoothly in physical systems. So this is an unfaithful reformulation of the observation by Al-Said et al. It's unfaithful, but maybe it's a smart reformulation because they introduce a new quantity, which in most cases is related to the previous one, but in other cases the related is not such a smart, excuse me, it's not such a Excuse me, it's not such a trivial way, the smart way, because it elucidates certain parts of F squared behavior which is not obvious. And it's not clear at all, I will try to argue through my talk, that it's not clear at all that this reformulation in terms of BM provides any edge when it comes to chaos. It's not obvious. But what is completely obvious is that it gives you the whole new tool to study dynamics in grill of space and an immediate benefit which would And an immediate benefit, which was already present in this original paper, and that's why I think this paper is very, very interesting. That was my take, why this paper I think is very, very interesting, is that by reformulating in this way, they were able to formulate the quantity which is called Krillov complexity. They were able to notice that in general case it will be behaving exponentially, and they were able to conjecture that this exponential growth is related to OTAP and in fact bounds OTAP. And in fact, bounce Autoc. Okay? So that's a completely new twist in the story because they immediately made a connection to Autoc, something you will not be able to do in any reasonable way if you try to do it like we did with the lattice and if you study norm of an operator or anything like that. In this language, it might be mathematically almost identical when it comes to chaos, but in our language, audit was nowhere to be found, right? So a very important step which they A very important step which they did was that they introduced Krillov complexity. They conjectured that it bounds OTOC. And more recently, there was a partial proof by this group who actually have shown that indeed OTOC is bounded. But this, I say it's a partial proof because this group did not relate bound on OTOC to the behavior of Bm. They related the bound on OTAC to the behavior of F squared. So it's still not. So it's still not clear at this point. So historically, the relation between chaos and auto went through Krilov space because of this paper. But as things stand now, you can completely forget about Krillov business and formulate everything in terms of F squared. Is it a feature or a bug? I do not know. I'm just presenting things how they are right now. All right. So now I introduce some general. Some general picture. Now, let me try to give you an overview of what I think is happening in this story when people try to relate two-point function to chaos or behavior of BN to chaos. The original paper, I sometimes write 2019, 2020, it depends whether it's archive version or the paper version. It's the same paper. They look at the SYK model and they saw that SYK model confirms their behavior. Confirms their con well, behaves according to their conjecture. Then there was our paper where we argued that the same behavior should come from the analysis in lattice models and the normal infinity norm. Then there was a very, very interesting paper by one of the authors of the original paper, that was a single author paper, where he considered non-integrable Eisen model and through some novel tools analytically have shown that in 1D Eisen model, Lanchus coefficients will behave as Will behave as the conjecture proposes. They will grow maximally within constraints of locality. Since the model is one-dimensional, the growth will not be linear. There will be some logarithmic corrections. But he was able to show that this is the case. This is a highly non-trivial result because analytically it's very, very difficult to show that something grows with a particular rate. Usually you have a bound from above, that was a bound from below. From below. And then another very interesting result, which is numerical. So it's a cultural thing. I'm less excited about numerical results. But nevertheless, this group by Rigdel et al., they're experts in numerical modeling. They considered integrable model, xxz integrable model. They calculated f squared and they saw that it decays faster than exponential. Now, numerically, it's difficult to see. Numerically, it's difficult to see because in one dimension you cannot have exponential decay. The slowest decay would be omega to the power minus omega, which would be exponential E minus omega logarithm omega. So there's logarithm omega always there. They claim to see beyond that. They claim to see something like E minus omega squared. But it's a numerical work. So in the paper, without knowing anything about Paper without knowing anything about this growth of business, they claim it's faster than exponential, so that gives it credibility because it's a prediction, not a prediction. But therefore, I think this is a very interesting result. But strictly speaking, I would like to see more research done on XXZ model or models like that, interacting integrable models, which would try to show that F squared behaves, it decays faster than exponential for large objects. And if that's the case, that will be. And if that's the case, that would be a highly non-trivial indication that this F squared, asymptotic of F squared, is indeed a good probe of case. So these are good things, but nevertheless, there are problems. There are problems and obvious imperfections with this conjecture. So I will give you an example when Bn grow linearly in free theories. And if they grow linearly in free theories, it means it cannot be one-to-one corresponding. It cannot be one-to-one correspondence to chaos. You can still say what the original paper says: that in general case it will grow linearly, but you cannot say anymore that whenever it grows linearly, it's chaos. That's one thing. Also, there are examples when Vienna are not smooth, and then it's not even clear what the original conjecture says about it. And then there is also a very interesting paper by this group who were building on the earlier work on cow, and they're saying the following: in fact, you will have links. In fact, you will have linear or maximal growth of VM whenever you have scrambling. So they're saying, they're giving an explicit example when you do not have chaos. You do not have chaos. But you have what is called saddle-dominated scrambling. And in that case, you have maximal growth of OTOC, you have maximal growth of BN, but no chaos. So it means that this relation between BN and KAOS is not as perfect as we want it to be. Perfect as we want it to be. But nevertheless, relation between BN and relation between BN and chaos is not as perfect as we want it to be, but relation between DN and OTOC seem to be solved. Because in both cases, in the case of this cell-dominated scrambling, both DN and OTOC behave the maximal way. Okay? So now I will give you an example which we, yes, I think definitely the only. In the free theory, no. In the free theory, no. In the free theory? In the free theory, no. But I will speak about that. So that's okay. I will cover your question. So let me present some results about free field theory. We just wanted to test this conjecture a little bit more. So we look at free field theories or conformal field theories. In the field theory, you define things like this. So you basically separate the operators on the thermal circle. We put them in the opposite. We put them in the opposite locations of the thermal circle because, in that case, things are most symmetric and the Launcher's coefficients are identically zero. Then in field theory, because you have singularity when operators collide, you always have exponential decay of power spectrum. F squared always decays exponentially in field theory. It still gives you the room to think that maybe Bn will behave in an exotic way. Behave in an exotic way because, as I said, f squared does not fully control Bn. Mathematically, it does, but in a very non-trivial way. So, you might hope that F squared will result in some strange Bn. But we calculated Bn, and it just behaves beautifully. It just behaves linearly. And then correction to that is related to the dimension of the operator. And numerics confirms that there is absolutely nothing unusual happening. Unusual happening for field theory, but that applies to all field theories: chaotic field theories, non-interacting field theories, all field theories, at least conformal field theories. And then it basically tells you that you cannot use behavior of BN as a probe of chaos right away. You need to improve that. You need to do something with that. But if you try to compare the behavior of Krill of complexity and OTOC, you immediately see that the conjecture. See that the conjecture that Kirillov complexity bounds autoc reduces to the original Noldasena-Stanfor-Schenker bound. So that's an interesting result. You do not improve this bound, you do not deform this bound, but you have a conjecture which is a new conjecture that Krilov complexity bounds OTOC. And in the case, which was behaving in a little bit strange way, you saw that you immediately reduced that conjecture to Multisener-Stanford-Schenker bound. Injection to Moldova stand for Schenker bound. So it means that the relation between Krillov complexity and Odog is not so bad. It's actually quite robust. You reduce it to the bound which you know is correct. I have a slide. Maybe I should skip this, but I have a slide how we derive this formula. To derive this formula, we developed this whole path integral over dig paths. So basically I was announcing that the relation between F squared and Bn is very complicated. Is very complicated. If you claim that dn is smooth, you can recalculate f squared, but the way to do it is actually a very non-trivial step. You need to do the path integral, but then path integral can be done semi-classically when you have a classical subtle and so on and so forth. So you can do all of that, then you recover this formula where you have linear growth, but also correction, which is dependent on the dimension of the operator. Okay, this is this is maybe technicality. Now, some numerical results for yes. What the n log m case? How did f square game? Oh. Is it known? E omega minus omega. Omega to the power minus omega. That is actually known. Omega minus omega is what we know. n divided by log n, is that what we less know? Log n is only leading part of the Is only leading part of the asymptotic behavior. So, this is a numerical result for scalars, free scalars in four and six dimensions. You see that red line is this analytic formula I have shown you. Color dots are numerical BNs. Basically, you have two branches which join together and grow linearly, and this is for the free theorem. Okay, so linear growth of BN cannot tell. So, linear growth of Bn cannot tell you that there is chaos, at least not in this way, but then the growth of kernel of complexity is exponential. Okay, I also have the same for interacting theory. This is for holographic theory, the same thing, the same behavior. Okay, but then we started thinking that maybe we can improve this conjecture about the relation of Bn and chaos by introducing the couple. And the idea was that in field theory, you always Was that in field theory you always have this behavior which is basically the result of locality? Then we have the whole set of arguments why locality will always force Bn to grow linearly. I will skip all of this for the sake of time. But basically, we had a prediction that if you introduce temperature, it will introduce another scale. And when temperature is very, very slow, if you introduce the cutoff, you will essentially put your field theory on a lattice. Field theory on a lattice, but if you simultaneously introduce temperature such that temperature is much smaller than the cutoff, you first will have field theory behavior with a linear growth. But once you hit the UV cutoff scale, you will discover the lattice. And there you can use the original conjecture. And linear behavior will tell you that your lattice is non-integrable. And below linear behavior will tell you that your lattice is perhaps integrable. And this was a prediction about the effect of time and the cutoff. Of time and the cutoff. And then we tested that numerically in the spin chain case. And numerics, this is all numerical thing, and it completely confirms our prediction. If you have temperature, well, this one level one value equals one, that's the UV cutoff. It's a lattice model, but you can always take cutoff to be one. The smaller temperature. The smaller temperature is, the longer linear growth you observe, because basically, here at very small temperatures, you have effective field theory emergent. And as we just saw numerically, and I was trying to maybe quickly argue analytically, field theory does not care about chaos or no chaos. You always have linear growth. So you first have linear growth. But once you discover that you're on the lattice, now you see what your behavior is, and that's how you can conclude whether you have integrable or non-integral. Whether you have integrable or non-integrable case. This model is completely integrable and therefore Bn do not even grow, they become constant. They approach to a constant. These are identical plots. This one is plotting Bn, this is plotting beta Bn. They just to show that this slope, this slope is exactly in accordance with the field theory behavior. F squared is proportional to E minus B beta omega over 2. Okay, so there is just the temperature behavior. So, there is just the temperature in the table. Okay, so this is the result of temperature and the cutoff. So, we were happy with this result because conceptually it means that you can save the relation between Krillov and chaos. You just need to introduce the cutoff. And maybe this is not such a big price to pay. Because if you think about other probes of chaos, for example level repulsion or level statistics, you also need to introduce some discreteness in some UV couples, right? Say some UV couple, right? So here it's conceptually similar story. It doesn't mean that the size of the Hilbert space is finite, because in this case, excuse me, because in this case, you introduce the UV cutoff, but the system is assumed to be infinite in space. So it's a thermodynamic limit. You don't have an infrared cutoff. You only have UV cutoff. And the number of states in your system is infinite. But nevertheless, conceptually, it's sort of okay to think that we need to introduce sort of Think that we need to introduce sort of some cutoff to chaotic behavior. Okay, so this is the conclusion about this universal operator growth behavior. Our preliminary conclusion is that when you look at the true asymptotic behavior, when I say true asymptotic behavior, I mean that your PN are at the level of UV cutoff or maybe larger. Not the initial behavior, but true asymptotic behavior in the system of infinite size. In the system of infinite size, then perhaps indeed you can see the relation between the behavior of BN and chaos. And in the end of the story, at least at the current level of my understanding, I do not think there is more there than just the divergence of the norm of operator evolved in Euclidean time. So the explanation we were trying to give with Hadoshkin in 2019, I think, is the best explanation out there why this relation between being Why this relation between Bn and Knops exists? Because you have a physical effect that if you have Euclidean evolution of operator, the norm of the separator will diverge in finite time. Okay. Right. Sorry, I lost drug. I don't remember what this refers to. I don't remember. So one question, Atoll. Yes. What does the grill of complexity do when it reaches the plateau for the VN I the free theory, what what does it do? What do you Good question, I I don't I do not know. I don't I I don't think we calculate acrylo complexity in that case. I do not know. I do not know. Yeah, no. I think the question is about this plateau. In this case, it's truly a plateau. It just goes. For the plateau, it goes linear. Yeah, but for the pre-thinity, for example, where you don't get the plateau or you get something. If it's slow, the change, it will... In this case, we're talking about thermodynamic limits. So your system is infinite. You have a spin chain which extends to infinity in both sides. So Pn will just go like that up to infinity. Like that, up to infinity. I think it might be even possible to calculate analytically what KFT will do. Perhaps it will grow linearly. That makes sense to me, this answer. But I did not look at it. I do not remember what these words mean, but I want to comment on this paper, and I know why it is on this slide. This was my understanding why there was a relation between BNs and KOs. And chaos. But this paper already mentioned, it's a very interesting paper. I want to return to this paper again because it actually shows that the relation between the end might be not to chaos but to scrambling, as well as autocrat exponential growth of autocay not a sign of chaos but scrambling. And this is something to keep in mind. I think this is an important paper because quite often we mix these different phenomena, scrambling and chaos, and maybe we should not mix. And maybe we should not need stuff. All right, the preliminary conclusion is that reformulation of this business of Euclidean operator growth or behavior of F squared at very large omegas in terms of Krillov space, maybe at technical level it did not produce. Yes. Could you just remind me one more time what is the difference between chaos and scrambling? I mean, just so good question. It really depends on your definition, right? Depends on your definition, right? There are different definitions of chaos, especially when it comes to quantum chaos. There is a classical definition of chaos, right? That's when you have exponential divergence of classical trajectories. Then you have a quantum manifestation of that in the quasi-classical quantization. That's the level repulsion. This is neither of that. That's just when we say, oh, you don't have integrability. That's when you have chaos. That's when you have chaos, and that's what many people do, but that's yet another definition. Then you also have autoc, which people in the original paper Maltese said it's a bound on chaos. But then people were looking into this and saying, no, this exponential growth of autoc, you cannot relate it to chaos how we knew it in classical or semi-classical settings. It's a new phenomenon which we should call scrambling. And I think an important person who did this work is Kepler. Person who did this work is Kevin. Yeah, yeah, I was so that slide maybe two or three slides ago when it said that the BNs growing one way or another was a sign of not of chaos but of scrambling. That specifically, the example in that paper would have what kind of behavior? BN grows linearly and auto grows exponentially. That's it. Bn grow linearly. Yeah, so that's the same paper. That's the same paper. Yeah, so that's the same paper. That's the same paper. I just wanted to emphasize that that distinction might be important. We did not think about this distinction much, but this distinction might be important. So in what sense that is not chaos? Because the system they consider is classical or semi-classical, and as a classical system, it doesn't exhibit classical. Thank you. Okay, so what I wanted to say on this slide should speed up a little bit, is that reformulating Up a little bit is that reformulating things in terms of Krilov does not give you obvious advantage just at the level of relation to chaos, but it certainly gives you many more tools and connections to other things. Now, a new attempt to connect grill of business to chaos is to actually define chaos in a proper way. I want to define chaos as level repulsion. I have energy levels, I will reduce, we'll consider finite system size, and I want to see level repulsion. At system size and a what we see level repulsion. Is it possible or not? Should I expect this to be possible? The answer is yes, that should be possible because the two-point function we consider, blah, blah, blah, it knows about level repulsion. Because if you look at the Liouville, this three-diagonal matrix, the spectrum of the Liouvillian is exactly the spectrum of energy gaps. It's exactly the spectrum of En minus En, where En are energy levels of the original phenotype. So mathematically, I So mathematically, I know that CT and Leuvillian do know about level repulsion. Therefore, if someone tries to relate that relate VNs to conventional chaos, defined as level repulsion, I know that this is a good question to begin with. But unfortunately, the answer is a difficult one, and it's not clear what the answer is. You can relate the coarse-grain behavior of Bn to the density of energy levels of the original Hamiltonian, and this is the plot. Hamiltonian, and this is the plot very similar conceptually to what Javier has shown us in his talk. We consider in this case the spin chain, non-integrable spin chain. You calculate Bn and then you have a theoretical plot which is just produced from the density of energy levels. And you see that the fit is very, very good. There's also a caveat because if you start reducing temperature, for example, the spectrum Temperature, for example, the spectrum of Levilian remains exactly as it was. And therefore, the theory plot, the black line, would be exactly as it is here. But the VNs will be all over the place. I don't have this plot because it doesn't fit theory very well, but not because theory is faulty. You don't have Bonafide theory to describe Bn in terms of density of states, but you But if you assume that there is a certain smoothness behind Bn, you can relate the shape of Bn to density of states. But density of states is not what you want. What you really want is a correlation of density of states. If you think about ramp and plateau, ramp behavior is the correlation of density of states. If you think about level repulsion, that's related to correlations of density of states, actually many correlations. And where this correlation And where these correlations are hiding, I know mathematically that this pattern of points knows about these correlations, but where exactly they are is a more complicated question. This is work in progress. And in his talk, Javier presented some answer, not in terms of BNs, but in terms of K of T. We do not know if that answer goes beyond random metrics theory they consider, whether it will work in spin models. Skin models, maybe it will. There was also a very recent paper where people considered another proposal that they considered like oscillations of these points around this line. I'm reformulating what they did. I'm not sure this proposal is accurate, but what I want to say is that the question is well defined. We still don't have the answer, but the question is a very good one. And we know that mathematically DiEM know about level statistics. Statistics. I'm done with chaos. I don't have much time. Now I want to discuss relation to Odog. I already announced that there is an original paper proposing relation to Odog, and I think the relation to Odog is best formulated in the following way, in the form of double inequality. Here is a conjecture, which is, if you wish, an improvement on the original conjecture by Parker et al. Conjecture by Parker et al. The conjecture is the following. If you have Krillov complexity, you introduce the exponent. It might be zero if your Krillov complexity is not growing exponentially. And then Krillov complexity will bound OTOC, but also in its own right will be bounded by 2 pi over beta. So that's an improvement on both Parker's conjecture and the Moldesanistan for Schenker conjecture. If you remove this middle part, you have Moldesonistan for Schenker. If you remove this part, you have Menerchener Senchener. If you remove this part, you have Parker et al. This is basically the conjecture we started formulating with Obdoshkin back in 2020. It's not necessarily the same conjecture as Parker et al. because we do not necessarily say that the N grow linearly. We can have more exotic behavior. Then there is a partial proof, that's the same paper I already mentioned today, partial proof which doesn't really look at lambda k, it looks at the behavior of f squared. Of f squared. So it cannot really account for this whole story. This story might be more interesting. And we gave an example of when the story is interesting. This is also related by a recent talk by Kim at this workshop two days ago and the paper they had. The idea is the following. This is just an example of a particular system. You consider free massive scalar field. You consider free massive scalar field. You know from You know from mathematics I presented that the ends will grow linearly, but in this case, what happens? They grow linearly, but they split into two branches. And those two branches never merge. Okay? So that goes beyond universality proposed by Parker. And you don't really know how K of T will grow in this case. You have two branches, they never merge. When you recalculate Krillov complexity in case of zero mass, when In case of zero mass, when those branches actually merge and become one branch, you have linear growth, you have exponential growth of a curl of complexity with the exponent 2 pi over beta. But when you have mass and when you have two branches, you still have exponential growth, but with a smaller exponent. Okay? This is a numerical result, but you see that this is a pretty much linear plot with the slope smaller than here. And therefore, you immediately Here, and therefore, you immediately have a non-trivial example of this identity when theory is free, so autoc is zero, but you have lambda k, which is strictly smaller than 2 pi over beta. Okay? Now, it doesn't prove things in generality, but I'm just trying to say that this is genuinely an improvement on previous bounds. And there are examples when this is non-trivial while this part is trivial. And I gave you an example. Trivial and I gave you an that would be for example a case of conformal field theories but there are also examples where this is trivial but this is non-trivial and this is an example of massive field theories. It would be great to have an example when both this and this inequality are non-trivial. That would be more interesting. We don't have such an example. It would be even more interesting to prove things like that. But this is all for the future. Okay, so yes, 10 minutes. I'm almost done. Yes, 10 minutes. I'm almost done. I'm pretty much done with the relation to OTAC. Maybe I should only say is that I think the relation to Autoc is one of the most exciting aspects of the scrule of business because when Autoc was introduced, it was such an orthogonal perpendicular thing to all previous attempts to study chaos. But now we sort of have a tool which knows about level repulsion, at least conceptually, knows about other Knows about other aspects of chaos, like let's say growth of norm and stuff like that, and seem to know about OTAC as well. So it seemed to me that Krylov space is our best bet to unify different aspects of chaos together. So that's one thing. And another thing, it's very interesting that Krillov business is simply a story about two-point function, and Auto is famously a story about four-point function. About four-point function. And the relation I have shown you between Grillov exponent and Lapunov exponent seems to be a bound on four-point function in terms of the two-point function. But not like a stupid bound when you just write it as an equality. It's a bound in a very intricate way. You take four-point function, you extract the exponent, you take the two-point function, you formulate it in terms of dn, you calculate kt, you extract the exponent, then those two exponents bound each other. But nevertheless, Bound each other. But nevertheless, conceptually, a two-point function bound in four-point functions, that's an interesting question, how that really works. Because usually we think that four-point function is completely independent from the two-point function. Okay, the last part is about Krillov complexity. This is yet another exciting theme. Most papers these days is about Krillov complexity. Now, Krillov complexity is a notion introduced in the original paper by Parker et al. They have people. At all. They have very small, in terms of volume of the text explanation, why they introduce the quantity and why they call it complexity. They don't say that this complexity should be related to holographic complexity or computational complexity, nothing like that. But then along comes Porbon and Rabinovich, who in 2000, and maybe also other authors, I think Borbon, Rabinov, Shir and Sinfa, who in 2019, very soon after the original. 2019, very soon after the original paper, made this bold claim. I think it's a very bold claim. They say Krillov complexity is actually genuine complexity. We should be thinking about it along the lines of computational complexity, along the lines of holographic complexity. On surface, it looks completely different because Krello complexity is again a story about two-point function. It depends on the operator, it depends on the initial state, if you wish. Well, if it depends on the initial state, then it Depends on the initial state, then it is more similar to computational complexity. But at no place of formulating cruel of complexity, do you have gates to anything like that? So this is a very bold proposal. It got traction in the community, and people started thinking about that. I'm ambivalent about this because it's absolutely not clear to me why curl of complexity should be related to conventional complexity. But I have to say that there is a lot of different work. That there is a lot of different work in this direction. I am only mentioning some of the works. This group is one of the most active, and they have a number of papers where they have been calculating complexity in SYK and other models. This plot is very similar to the plot I have shown you with the theory part. This is a plot from their paper. They basically say that this is an initial linear growth, and then you have this decay, which is stretched on exponentially long number of indices. Lone number of indices, and therefore, if you normalize things properly, it will be very, very slow decay. And from this slow decay, and as Japier said, they derive linear growth of Krillov complexity at long times. And they say that this is qualitatively very similar to holographic complexity. And more recently, just very recently, a few weeks ago, they were able to argue that the behavioral complexity is very much related to. Behavioral complexity is very much related to bulk complexity and NSV and GET gravity. Not NSVK and GET gravity. So there is a lot of work and a lot of suggestive results. And there is another, well, there's many groups of people. Another person I should name is Pavel Kaputa, who is also very active. Khanier is another person. I'm not able to mention everyone, but there are several groups of people who are really working in this direction, and they got very suggestive, very interesting results. Suggestive very interesting results showing that in many instances Krillov complexity indeed behaves as holographic/slash computational complexity, but exactly why there is such an expectation, it's unclear. And I feel like I need to put a grain of salt on this. And therefore, as one of the last slides, I want to give my calculation for scalar fields just put on Scalar fields just put on a compact manifold. If there is a general proposal that we should be thinking about Krillov complexity as holographic complexity, then this statement should be general enough. So I can consider this example. And if you consider this example, it's a field theory. You know that f squared will decay exponentially. There is still a singularity when operators collide. So f squared still goes like e minus beta omega over 2. But in this case, But in this case, Bn are not smooth. They split into two branches. Those branches now go at an angle, and this has a profound implications for Krillov complexity. The implication is the following. Krillov complexity is bounded in time. And that is qualitatively very, very different from what holographic slash computational complexity would predict. Because Because that is free. It's a free. Here you would see completely a difference if you consider the interaction. Interacting, you would get the interaction would be different. I agree. I agree. Completely agree. You can even argue this is more difficult to prove right or wrong, but you might be right that if you introduce interaction, this picture will completely change. That might be true. But I want to emphasize that when you compare with computational complexity, computational complexity is always divergent. Computational complexity is always divergent when you introduce the cuddle because the more fine-grained your underlying lattice is, more gates you have, and so on and so forth. This picture with the tracked complexity at very, very small values is UV cutoff independent. You can introduce UV cutoff, and it will be somewhere here, and your complexity will never grow to discover this. And if I understand correctly, in free field theory, you will still have divergent complexity. Will still have divergent complexity if you introduce very small couple. So, my point is that this is an example of complexity behavior, and the same thing we saw in thermal ADS, also perhaps because of some symmetries, because when we consider black hole, it doesn't behave like that, on thermal ADS, it behaves like that. So, mathematically, I think it's because of the very peculiar property that a correlation function is periodic in Lorentzian time. And it's periodic in Lorentzian. Time. And it's periodical Lorentzian time, schematical because you have a free field moving on a sphere, so it's moving with a constant period. If you deform the sphere and reduce interaction, it will scatter. You will not have periodicity. So I'm taking that as a valid criticism, but I'm just trying to say that if you try to formulate something very, very general, something like rule of complexity should be related to holographic or combination of complexity, then these counterexamples should be proper. Conterexamples should be properly taken into account. Let me just finish. Oh, okay. Yeah, yes. I would say that actually that is not a counterexample. That is more suggestive that the Hiloff is the right quantity. Because you expect that, for example, in the thermal regime, I mean below the Hawking-based transition, where everything is free, you would expect complexities of this sort because things are periodic, exactly as you are saying. So it's the other complexity that tells you that. Complexity that tells you that in three theories you have this crazy behavior. I mean, this is suggesting that that order is the bad notion. This is, I think, suggestive for if you argue that kernel complexity is an interesting thing to study, I have no problem with that. I write a paper about it, which is a confirmation that this is an interesting object to study. I'm just saying, and I cannot be too strong about this because this is one of the this is only one example that's This is only one example, it's rather special. I'm just saying that to claim that Krilov complexity qualitatively behaves the same way as computational complexity, I think is an overstatement. It should not completely take away from research about complexity in SYK and GT, where people see qualitative similarity. So, just to say that people, I think people, well, this ourselves, I think Sonia and people, and we are not saying that this is. And we are not saying that this is equal to computational complexity. We know very well that this is not equal to computational complexity. What we are saying is that this is much better for as a notion for logographic complexity. Those are two different things. We don't know if computational complexity was the good notion for logographic complexity. So there are two different notions. Well, there are probably more. There's photographic levels. There are many notions. There are many, but for sure, we know that this is not equal to computation. We know that this is not equal to computational basis. It has nothing to do actually. Just maybe it behaves similarly in some scenarios. But uh the question is whether this is better for all active basically. And this I think is is is is very suggestive that it is better than QuickBSD. Okay, I will proceed to the conclusions. Let's conclude and then we can continue. I have another slide with the computation in the lattice model of free bosons where we simply show the same behavior numerically and it splits and it's And it splits and it demonstrates all these other features, which means that it's not just one model, but it's still a free model, so it has the same things. But these are my conclusions. Let me conclude, and then if we're allowed, we can have a discussion of questions. I want to conclude by saying the following. I think Krillov space dynamics or Krillov space approach currently is our best chance to unify different To unify different approaches to chaos and complexity together. It seemed to be the place where many. Oh, I do not know what happened. That seemed to be the place where many things come together. So that seemed to be a very interesting place to be because you can simultaneously discuss different aspects of chaoticity if you wish. The result, okay, I'm essentially done. The result, which I think is most interesting, at least. Most interesting, at least in my view, is this relation between grillof complexity and Otto. And the conjecture which I would put my money on is this one, that you need to improve or extend the Moldusana stand for Shek conjecture by inserting Krillov complexity in the middle. And there are partial proofs by Kidaev and collaborators, and there are non-trivial checks in our papers. But I really think that this double inequality deserves more research. Deserves more research. So I'm just advertising this to you as I think a very interesting question. Another open question, more general, I was speaking a lot about this universal operator growth hypothesis, but formulated very generally. The question is the following. Can we relate behavior of the end to chaos? And we understood in our research that we need to introduce Yuvi Kadov, but that's related to field theory. But another very interesting question, which I will re-emphasize. Very interesting question, which I will re-emphasize, is the relation to level statistics. And I hope that will be more progress in this direction. And in the end of the story, would emerge as a very good probe of chaos. And finally, there is a very interesting direction of Krilov complexity, its relation to holographic or computational complexity. There are a lot of suggestive results. My complaint or my word of caution is that they may not be fully universal. So maybe, as Javier said, we need to align the question. we need to align the question what do we really try to what do we really try to do if you say that all we say here that krill of complexity is an interesting new quantity i completely agree with that and uh with that i think i will conclude thank you so wouldn't you expect that the circuit complexity is also periodic uh at at an interval just An integral system? I'm not very knowledgeable. My understanding is that it is not. My understanding is that even in the free system, conventional computational complexity would just grow indefinitely with time. I mean, up to certain cutoff, which is exponential, I'm not sure. That's my understanding. Wouldn't you get like cancellation between gates in such a way that the optimal circuit programming state is like the time evolution is one? Like the time evolution is one circuit which prefers a state, but that might not be the optimum on any integer system. So, what I would expect is that you get cancellations, or maybe there is like a much shorter. I see what you're saying. You're saying that if there is an exact time periodicity, maybe there is a way to restart. Maybe. I honestly don't know enough, but maybe if that's the case, then it would be interesting. If that's the case, then it will be interesting because maybe it will give you an idea what Krillov complexity qualitatively should be compared with. My understanding was: the argument we make in the paper is the following. It was not based on the linear growth of computational complexity, but on the cutoff dependence. I know that if you take cutoff to infinity, complexity grows to infinity because you make your gates smaller and smaller and smaller. But krillov complexity becomes cutoff independent because it's dropped at the Because it's dropped at the infrared values. So that was the qualitative difference we emphasized in the paper. But maybe there is more to it than I just understand. Then thank you for the next one. We'll be back at 10:30. Yes, I know.