Individuals in work. And so the background of this project is part of the liver-human cell atlas. We're trying to collect single-cell data on liver samples from people of various ages and stages of development. And so like every other cell athletes project, one of the big goals is to really look at, for each cell type, try to characterize what changes in gene expression, correlating with age, and so on. And so there's obviously, you know, here's your standard UMAP of a liver cell atlas. And as with every other tissue that you do this for, you can find a lot of genes whose mean expression tracks with developmental stage or age. And so the question that we were interested in is whether or not we could actually, whether or not we had enough cells to infer networks for different time points along development and then compare them to figure out. And then compare them to figure out: are there specific modules that are time point-specific, or is there global changes in the network structure that you can see with development? What's a circle there is a gene, and a line is correlation? Sorry, yeah, in this particular plot, this type of plot, nodes are genes, and edges are strong co-expression. Okay, and so starting with this developmental liver atlas data that we had, we spent a lot of time, you know, obviously there's a few decades worth of work on gene network inference. And so we spent a bunch of time trying to apply existing gene network inference methods, infer these ball and stick representations, and compare them to see what change in structure we could find. And it was pretty difficult because, as you all know, it's hard enough to infer one network, never mind trying to infer many of them. Infer many of them. And so we wondered whether taking maybe a different approach that doesn't involve inferring ball and stick representations of networks would work. And so the general idea that we tried to do was to basically, instead of inferring explicit network structures, we would instead try to embed the networks in some low-dimensional representation and draw our favorite UMAP visualizations where instead of each cell being represented by a single point, now each point. Single point, now each point actually represents an entire network structure over some set of input genes. And you know, again, just like with our other UMAPs, hopefully, points that are close to each other in this space represent networks that have similar global network structure. So, the way that we actually perform this embedding is that we basically, so my library spent a bunch of time training different kinds of racial autocoders on gene expression data, single-cell data. And so the idea that we had is that what if we, for every individual in a cohort, basically trained a separate variational autoencoder on each donor separately, but tried to tie them together by doing some multitask learning. And so the general idea here is that if you standardize, for example, all of your input features, then hopefully if your VAE is learning anything, hopefully a big part of what it's learning is co-variation structure in your input features. And so the idea was that if Features. And so the idea was that if we do multitask learning and basically train one model per donor and just allow a few number of differences between the donors, hopefully those differences in the parameters would basically encode differences in the code expression networks of the individuals. And so that's what we basically did. So for a given data set, we basically train a VE per donor, and then we basically train them all together with multi-task learning. And then what we get at the end of the day is basically just Get at the end of the day is basically just a giant matrix where essentially the rows represent different donors and the columns represent different parameters of those Vs that we're training. And then because we're doing multitask learning, basically even though there's say 100,000 parameters here, then hopefully maybe only like a few hundred parameters might differ significantly between the donors. And so basically we started out by Basically, we started out by doing some basic simulations for zoning checking. And so, we try to do two sets of simulations: one in which there are large differences in the co-expression network between the individuals. So, here, these represent three different hypothetical individuals. And again, these are gene co-expression networks. Nodes are genes. Edges are high co-expression edges. And we did another simulation where we tried to make the differences a little bit more fine between the donors. And so we used. And so we used SCE Design II to basically take some existing data from tiny numerous, fit gene fit a co-expression, or sorry, covariance matrix to one of those cell types, and then perturb that covariance matrix before simulating different populations from it. And so basically, here's a plot of that discrete case where we try to make big jumps between the different co-expression networks of the individuals. Co-expression networks of the individuals. And here, basically, again, each point represents a network that was kind of implicitly inferred from a donor. And they're colored based on the different individuals. And you can broadly see that at least the differences in the parameters of the VEs kind of broadly captures differences between individuals of the same population. Here's the case where we simulated more smaller differences between the individuals, and you can still see that they're See that they cluster at least by individual. And so, at least in this kind of very, you know, very artificial simulation case where we fix the number of cells, all of the genes have the same mean expression across individuals, and all the UMI counts are the same. At least you can still see some separation between the different populations. Okay, so going back to the fetal liver atlas that we started out with. Atlas that we started out with, we had basically data from 13 individuals across different time points. And so, what we did is we took each of basically six different cell types for which there was enough cells, and we basically did some feature selection and standardization to try to wipe out any differences in mean expression between the different individuals for a given cell type. And so, an important point here is that features. Point here is that feature selection is extremely important for doing this kind of network analysis because, essentially, as we all know, there's basically things like library size or fraction of cells in which genes are detected can really kind of strongly influence your ability to detect co-expression. And so we had some really heavy feature selection to make sure that we're not including any genes that aren't correlate. We aren't including any genes whose immune expression are correlated with developmental time. With developmental time, and that aren't significantly different in their sparsity between individuals. And so, when we generated these networks, instead of using like 3,000 HPGs, these networks are generated only over about 1,000 genes, for which there's no kind of strong relationship with phenotypes. And so, here's five of those cell types that we, whose networks we inferred from these individuals, and I've colored them based on the developmental time point of those individuals. Elemental time point of those individuals. And you can kind of, if you squint your eyes hard enough, you can kind of see broad differences between the blue and the red, which correspond to kind of the first and second trimester. But we were kind of, yeah, we were kind of stuck with this data set because there's just too few individuals that have enough data. And so we're currently repeating this analysis with 150 people to get a little bit more power. But at the current time, this is kind of where we're at with the living room. Kind of where we're at with the living here. So, what we did is there was another project in the lab where we're kind of interested in the whole problem of reprogramming and trying to control cell fate. And so, in the process of, you know, in the whole problem of reprogramming cells to IPSCs and differentiating them, as you've seen from these one and ten lamps feed pictures, the idea is you start with fibroblast, for example, and you program them to some plural potent cell and you differentiate. And one of the key problems in these reasons. Problems in these reprogramming tasks is that when you actually take fiberbots from different individuals and you reprogram them, you don't end up with cells with, even though they're all technically, for example, IPSCs, they don't always have the same differentiation potential. So when you apply the same differentiation protocol to different IPSCs, some IPSCs, you almost get no, for example, terminal neurons, whereas others will actually differentiate very well. And so one of the questions we were looking to answer is: you know, is there any Looking to answer, is you know, is there any specific part of the network that's associated with low versus high potential of these IPSCs? And so we took a look at this data set. We're essentially in this study, they generated 215 different IPSC lines from different donors, and they basically measured their differentiation potential. So, what they did is they took these lines, they applied a differentiation protocol to try to generate some neurons, and basically they did some sequencing at different time points, and they basically Different time points, and they basically measured efficiency in terms of or measured potential by basically calculating at the end of their protocol how many of the cells of a particular line ended up being neurons versus neurons or progenitors. So the idea is that cell lines with high potential will have a very high ratio of neurons to progenitors. So we took that data set and we basically subset it. That data set and we basically subsetted it down to 75 donors that had enough cells and that had very little variation in library size and sparsity and so on. And we basically trained, we multitasked training across all of these donors. And we basically drew this PC plot of the parameters. And then we basically asked the question of what parts of the network are associated with these different PCs. And so when you do that, you essentially get a group of about 33 to 50 genes. About 33 to 50 genes that are basically highly enriched in wind signaling, which isn't particularly surprising. But yeah, basically, we ended up with genes that are enriched in wind signaling. What we then did is that we took the efficiency measurements that they calculated in this original study and then plotted them on top of our visualization. And basically what you see is that particularly PC1 seems to separate low versus high efficient lines. His high efficient lines fairly well. And so that was particularly, that was a little bit surprising because, again, when we trained these models and we inferred the parameters of these VAEs, we didn't actually use any information about the efficiency of the lines. And so we, yeah, this was a little bit surprising. When we again try to focus in on those 33 genes and try to use classic gene network inference methods. Use classic gene network inference methods to see how do those network structures vary with efficiency. What we generally found is that for those 33 genes, essentially with increasing potential, there's a loss of connectivity in that particular module. We had a little hard time believing that was actually true. So we did a number of experiments where we basically split the lines into mutually exclusive sets, repeated the entire analysis, and then tried to do more richer testing of the genes that are changing the structure. Testing out the genes that are changing the structure, but we still end up with wind signaling, so it seems to be at least a kind of a robust signal. And what's a little bit even more surprising, actually, was that, so all of the analysis that I showed up to now is based on the pre-potent cells that they sequenced. What we also did is we kind of repeated this experiment, but we instead looked at the terminal neurons. And so the terminal neurons were identified based on a few marker genes. Marker genes. And so we actually basically just took the terminal neurons from each one of those donors, we retrained a separate set of VAEs, and then we inferred the PCs and plotted the efficiencies of the IPCs on top of them. And what you see again is that it seems like the terminal neurons themselves actually seem to separate based on efficient based on potential, even though those terminal neurons presumably shouldn't maintain that much memory of their... Maintain that much memory of their original IPSEs. But again, it seems surprising that maybe there's a potential for that, even though you have these terminal neurons that all express the key markers, there's still differences in the structure that are kind of maybe potentially resonant from the original IGC results. Okay. Yeah, and so finally, we took a separate data set where they performed a similar experiment. Where they performed a similar experiment, except instead of differentiating into neurons, they had a protocol for differentiating into definitive endodons. And we basically wanted to see whether we could recapitulate the single signal. So in this original study, they again came up with some measure of efficiency or potential. They did it differently from the original study. They instead did some pseudo-time analysis and tried to track an affirmative after three days of differentiation how many of the cells did they sequence? Of the cells, did they sequence from a particular line? Like, how far did it progress along this trajectory that they drew? And so, we basically repeated the same analysis, except we focused just on the 33 genes that we identified from the first study. And so, this is the plot that you get from doing that on the second study. And again, the signal is quite a bit weaker, but you can still see a little bit of separation between the low and the high efficient lines. And this is, again, using just the 33 genes that are. Using just the 33 genes that are enriched in wind signaling. And so, just to finish here, yeah, so basically, what I've tried to present is basically what we think is maybe one alternative potential way of trying to infer co-expression networks and compare them across individuals. It's important to note that this is definitely not an approach that can generalize to any set of individuals because you have to make sure. You have to make sure that a lot of things line up. You have to make sure that the library sizes are consistent, the sparsity is consistent, and this doesn't generally hold for a lot of different data sets, but it did for the IPSC data sets. And we basically identified some nice genetic variants in those genes that are associated with efficiency that we're following up with some cloud rates. And so this work was mainly done by my graduate student, Roshan Veen, together with some of our local cloud rates. With some further local functions. Thank you.