Okay, so thank you very much for the presentation. Thank you for the organizers for inviting me to this very nice event. So I'm going to present a project that I joined last year at Cambridge and it's a collaboration with William Depevin and Carlo Vaschonlip from Cambridge and also Oza Nuttem from KTH in Stockholm in Sweden. So does it work? Yeah. Yeah, okay. So Yeah, okay. So the project is about reconstruction of biological molecules like proteins, for instance. And the kind of data that we are going to use is cryogen data. So cryogen is a technique in microscopy and it's quite popular these days, especially in structural biology. Structural biology. And the technique consists of having a sample with the molecules of interest, and then it's frozen in some liquid and it becomes ice. And then it's imaged with an electron microscope. So you put the sample in your microscope, then you throw an electron beam through the sample, and then you detect the signal with an electron beam. Detect the signal with an electron detector. And then you obtain a micrograph, which is the image that we see on the left. And it's basically noise. But if you look closely, then there are small particles there. And that's what from these particles, you want to reconstruct the structure. But first, you need to select where the particles are. And then when you have the data set with a single particle, Data set with single particle images, you reconstruct the volume. And ideally, you want to, from the volume, obtain the structure of the protein in this case. And there are several challenges that appear in this kind of inverse problem. So first of all, in the imaging process, the electron dose is very small because you don't want to damage the proteins. So it makes the image very noisy. emits very noisy. So the signal to noise ratio is between it's around one percent. So it's mostly noise. Then the other inconvenience that you have is that in the molecular sample, you don't know what's the position of every particle. So at the end you have tomographic projections of your particle, but you don't know the orientation of the particle in every image. Of the particle in every image, so that's also another inconvenience. And sorry, I'm gonna send this okay. And then the other challenge is that every particle may have a different conformation because these molecules are flexible, so the same particle may have different conformations, so the structure can be different. And then, what you are actually imagining is a different thing in every, so you have different. So, you have different projections correspond to different volumes in every image. So, that's another problem. So, this is how the image formation is modeled in CryoM. So, you start with the UI represents the density of the particle, which is the electrostatic potential of the molecule of interest. Then, there is a Rigid transformation applied to it, which is a translation. Applied to it, which is a translation and a rotation. Then T is a ray beam transform, parallel beam transform. And then you obtain a projection like this, 2D projection, and then you apply a convolution with the point spread function, and then you add Gaussian noise, and then you obtain this with a very low signal-to-noise ratio. And then also in our case, we're going to consider that every image has a different conformation. Has a different conformation. So that's why here the volume density associated to every particle is indexed set by I, meaning that for every element in the data set, the volume can be different. So it's a very difficult problem. So it can be like tomographic reconstruction. So I'm happy that here there are a lot of experts in tomographic reconstruction, but in this case, I think there are all the possible difficulties. All the possible difficulties that you can imagine altogether. Okay, so here in the Cryogenian pipeline, there are several steps. I'm going to focus on this step, or well, or maybe from here to here, but we're going to use some intermediate step taken from other techniques. Okay, so this is the goal. The goal is to determine the The atomic structure of the molecule. So basically, in the case of protein, you want to know that you know that the protein is a sequence of amino acid residues, and you want to know this chain of amino acids, how it's folded. So you want to determine what are these kinds of structures, like these LICs and this, how. This is how this is folded, like a spaghetti, and then you. And so we have two kinds of data. Here we have the cryogen data, which has a lot of images of particle, different particles, which are very noisy, but it contains information about all the possible conformations. The problem is that it's a lot of information, but very noisy. On the other hand, we also have biological knowledge. Have biological knowledge. So we know the more or less the chemical composition of the macromolecule. We know that there are amino acids. We know the chemical composition of every amino acid. So this is very precise information, but it's not very useful for the structure determination because it's very hard to know the structure just from the chemical composition. That's nowadays unfeasible. Nowadays, it is feasible. There are deep learning techniques that have been developed very recently, namely alpha fold, in which you input the sequence of amino acids and it tells you this. But of course, it's kind of a black box and you don't really know what you are getting from it because it gives you a conformation and you know that the protein can have different conformations. Protein can have different conformations. And it's actually very important to determine the different conformations that a protein can have because it's important for the function of the protein. So yeah, our goal is to kind of combine the biological knowledge, like the chemical composition, we know the number of amino acids, we have some information, we may even have information about these structures, which are Information about these structures, which are called secondary structures. We can use also like the alpha fault prediction to have an idea. And then we want to combine this with the heterogeneous cryogene data set to determine how this kind of prediction from alpha fold, how this can be default or using the heterogeneous data set. Okay, so this is what we want. So we want to construct a map that associates to every conformation the corresponding structure. And here M determines the set of conformations. And this set can be like a finite set in the case of discrete heterogeneity, but we are going to consider that M is a continuous set, like a continuous. Set like a continuous manifold with low dimension, so but we don't know that this manifold, and we, of course, we don't know the structure. So, we want to using the cryogen data set, we want to determine the manifold and the map that associates to every point in the manifold the corresponding structure. For the the the D3U figure, I would like you know, and you want the con you want the inverse for AMP. Sorry, can you say three papers? I want to know photos. Yeah, these are not data that you know. And you want to read. No, I made it with the computer. This is just one example. Yeah, but mathematically, these are what data that you know. And you want to construct fee and no. So, what I have is like I have like one of these structures, only one, and I have all these images which correspond to projections. Images which correspond to projections of this structure but deformed. Okay, so in the molecular sample, in the microscope, this structure is deformed. So there are many particles and every of them has a different conformation. But I only know one. Or maybe this one is not even correct. This one is the one that you get from AlphaFold or from another technique. So password can then be for that member account. Sorry? Sorry, M in the next slide. Yeah, three four things are a member of these are a member of M. Is that correct? Yeah, M is like a set that represents the conformations. Like, for instance, if you only have one conformation, that would be a singleton. If you have two conformations, then that would be a cell with two elements. Imagine that you have a protein, you have the imagine that you have. Imagine that you have this and you have one of these arms is rotating, right? So then M would be a circle. Carlos, I actually want to understand what is P, what is M, what these figures that you show in the slide. This is ample. I just want to associate so that I know if you are looking at the okay, so this is a manifold that represents the space of conformations, which is only for if. Which is only for images that we saw before. Yeah, like every image corresponds to one point here. And then you want to map this space to the corresponding structure. Okay, so maybe here it's more clear because this is like techniques that are used in practice, which are based on variational auton colors. So you have the input is the Have the input is the cryoim image, then you have an encoder, you encode the conformation of the particle in some low-dimensional space, which is called the latent space, and then you use the decoder to go from the latent space to the particle density. And here you include the image, the orientation of the particle. So you assume that you have computed the You have computed the orientation of every particle, and then you can use this very solant encoder, and then you compare this with the image, and then you train it. So, this is like the most like the state of the art for heterogeneous reconstruction. And this is a similar approach. It's also based on a partitional analog encoder, and it's the same. You input the image in your encoder, you have a latent spare representation of. Latent space representation of the conformation, and then you here instead of mapping the latent space to the density space, you map it to the atom space. So here, instead of a density, you have a point cloud, which represents the position of the atoms. And then from here, you again compare the prediction with the curioim image, and then you do this training. Okay, so what we want to do. Okay, so what we want to do is something similar to this, but we're not going to use a variational encoder, we're going to use something different. Okay, and this is another technique for heterogeneous reconstruction, which is like a classical version of the variational encoders, and it's based on PCA, on principal component analysis. So you have your heterogeneous data set, and let's assume that you know the orientation. And let's assume that you know the orientation of every particle. You can use it to estimate the mean volume, like the mean density map. And then you can also estimate the covariance matrix. With this, so this is a big matrix. So then you can compute the principal eigenvectors and you estimate the volume. Estimate the volume as a linear combination of the principal eigenvectors. You have the mean volume, and then for every particle, you determine the PCA coefficients, and then you write your density prediction as a linear combination of the principal eigenvectors of the covariance matrix. So, here you also have a like a You also have a low-dimensional representation of the density of the conformation, which is the PCA coefficients. Every particle has a different PCA coefficients, and these are the same for all the particles. The drawback of this approach is that, of course, here you need to take n not to be, because otherwise it's unfeasible. So, this is good for a trigger reconstruction by. A triginal reconstruction, but you don't have a very high resolution. Can you do like diagonal approximations? Yeah, you can do approximations, but you cannot push a lot. And also, we are not really interested in recovering the volume, but we want to go from the what we want to do is to go from this low-dimensional representation of the conformation to the atomic structure, like the atom positions. Okay, so this is what we want. So we have, we assume that we have a low-dimensional representation of the conformation that can be the PCA components, or it can be also the latent space from the variational encoder, like another technique. We are going to assume that we have the pose of the particles, so that's the orientation. And we are going to assume that we have one structure, like we know this kind of alpha fault prediction, or we have. Alpha fault prediction, or we have we know one conformation, and we want to use the cryogen data set to estimate how this structure is deformed into the other ones. And then we may have also other information about properties of the protein, like secondary structure, like these LECs, or maybe some other kinds of knowledge that we can use. But in principle, these three ingredients. But in principle, these three ingredients, we assume that we know, and then we want to construct the map from the manifold of conformations that we don't know to the corresponding structures. Okay, so let's formulate it mathematically. We make this structural assumption about the atomic structure, which says that the distance between every ad-s and amino acids is. Every adaent amino acid is constant. So we want to determine the atomic model, which is the position of the amino acids. They are represented by a point cloud. And we make the assumption that the difference between every two consecutive points is constant. Okay, and then we want to minimize. So we want to solve a minimization problem of this form where we have the point cloud for every structure. Every structure. This is the density associated to the point cloud. Then we apply the forward operator and we compare with the image. And the constraint is that every point cloud has to satisfy this. But here we still need to use the what is the relation between every point cloud. So we know that the point clouds, every point cloud represents a structure. We have to determine many structures because we have many. Many structures because we have many images. So we need to use here in this formulation what is the relation between all the point clouds. Okay, so this Z naught is like the given conformation that we know. And we know that all the other point clouds, like atomic structures, can be obtained from the original one by a deformation, like with A deformation, like which accounts for the different conformation, and then a rigid transformation, which accounts for the different pose of the particle in the cryoim image. So here, as I said, we know the rigid transformation, we know the pose of the particle, we want to estimate this deformation, which is the like the different conformation, let's say. Different conformation, let's say, like whether the protein is open or closed, or how it's deformed. Okay, so what we are going to use, since we are at the end, what we want to determine is a curve, which represents the chain of amino acids. We are going to use this idea from continuous curves, like regular curves, which is the representation of the curve using the Freneser formulas. So we can any We can, any smooth curve can be represented using OD. Here, X determines the curve, and F is a trajectory in SO3 that determines the orientation of the curve at every point. And then here, the parameters of the curve are the initial position, initial orientation, and then this RS, which is a trajectory in the sigma algebra associated to SOC. Algebra associated to SO3. And so from this parameterization of the curve, we observe that the rigid transformations, like translational rotations, account to modifying the initial condition for the ODE. And then the non-rigid transformation, which is like deformations of the curve, can be obtained by changing this R of S. R of s, which is a trajectory in SO3. So, using this parameterization, we are going to assume that for every particle we know these two parameters and we want to estimate this. And now, of course, we are in a discrete setting because we have like this sequence of amino acid residues. So we use a discrete version of the previous kind of representation. Okay, so with this parameterization of the structure, The structure, like the yeah, atomic models. We can any point cloud, we're gonna represent it like this. We know this, we know this, we want to estimate this. So, at the end, so this is our parameter space for every, so every particle is represented by a point here. We know these two parameters, we want to estimate this, which is just the rotation. We want to estimate this, which is just the rotation associated to the rotations associated to every point in the chain. Yeah, so this is what we want. We want to construct the map from the manifold of conformations to the corresponding rotation matrices. And the approach that we are going to use is this. So we are going to use that we know one of the conformations. That we know one of the conformations that is represented by theta zero and psi zero. And then we want to determine in every point in the manifold, we want to determine how this structure is deformed. So we want to determine this part here. And we're going to write it down as a linear combination of the eigenfunctions of the Laplacian Beltran. Laplacian-Beltrami operator on the manifold. Okay, so let's say we know the manifold of conformations. Then we have the Laplace-Beltrami operator, and then we have the eigenfunctions which form a orthonormal basis of L2 in this manifold. And then we can take like the principal eigenfunctions, which are the eigenfunctions associated to the smaller eigenvalues, and then we can write down the And then we can write down the so this is an approximation of the function of that we want to approximate. And the reason of taking the eigenfunctions associated to the smaller eigenvalues is that we want to estimate only like low frequency deformations of the protein. Because of course these structures, there are a lot of vibrations, but we are not interested in the vibrations. But we are not interested in the vibrations, we want the like the small frequency deformations. So that's why we use like only the eigen functions associated to the smaller eigenvalues. Okay, so then we need to compute two things: we need to compute the eigenfunctions of the Laplace-Beltrami operator on M, and we need to compute the coefficients. So, if we look at the Laplace Beltrami operator on M, the problem is that we don't know M. And here we use the low-dimensional representation of the particles that can be given by the PCA reconstruction. So, with these PCA coefficients, we can construct a graph of similarities. Like we can use, for instance, this kernel, but we can use other kernels. This kernel, but we can use other kernels, maybe sparse kernel, which is going to be more efficient computationally. But well, the idea is that we have these gravel similarities and we're going to use this as an approximation of the manifold of conformations that we don't know. And then instead of using the eigenfunctions of the Laplace Galtermo operator, we are going to use the eigenvectors of the Gravel Laplacian using this matrix of similarity. Uh, matrix of similarities, and then we have results from well, this is known. There are theoretical results that tell you that if you have enough particles, meaning enough like samplings in the manifold, then the eigenfunction vectors of the Giraver Laplacian converge to the true to the continuous Laplacian triangle operator on the manifold. Okay, so that's for the eigen functions. So here for every particle, we need to determine like this. So this is no, this is the given conformation, and this is like the deformation of this given conformation. Here, these are the These are the eigenvectors that I mentioned. Now we need to determine the coefficients here. Okay, so we in order to approximate them, we are going to formulate this minimization problem. So for every particle, we can compute the corresponding parameters of the point cloud. And we need to. And we need to estimate these two matrices A and B, which are of size. So it's the number of eigenfunctions that we take times the number of atoms in the number of atomic, sorry, the number of amino acid residues. And then we, with this parameterization, we compute the curve, we compute the volume associated to the atomic model, and then we apply the forward operator. We obtain this. Forward operator, we obtain this and we compare with the quadrim image, and then we solve the well, we minimize this functional. And this is a non-convex optimization problem. But the good thing here is that we are given one of the conformations. So if you have a good initialization, this actually works. And it's not clear why, at least to me, why it works so well, but. Why it works so well, but it does work. And this is probably the next step in our research to study this kind of optimization problem. But here, the good thing is that the initialization of these parameters is taken to be zero. So we take A equal to zero, B equal to zero, so that the prediction of our model is the same for all the particles. And then as you apply stochastic radium descent to this functional, these parameters. These parameters change, and then every particle is deformed accordingly to the data set. So, this is the idea. And of course, there are no convergence guarantees because, again, it's non-convex. But I think this is a good initialization to take these parameters equal to zero. So, in the initialization, all the predictions are like close to the. Are like close to the actual atomic structure. Oh, sorry. Yeah, and now I'm gonna show some toy models, like numerical experiments for toy models. So here, this is a two-dimensional case. This is not a protein, of course. This is just a two-dimensional structure, which is a sequence of points. And here I'm considering a structure which is A structure which is a box like this and has two arms. And then this structure can be deformed in every image. And this is the possible deformations. So this arm can go up and down, same for this arm. And then the box can be tilted in either side. And then we generated a set, did a set with tomographic projections of structures like this. Projections of structures like this, like rotated and deformed. We added a lot of noise. So, from here, we want to recover this for every particle. And every particle has a different structure. And we only know this. We know this and we know these images. So, first we apply the PCA reconstruction. Reconstruction, and we compute the eigenvectors of the Gravela Placian. And this is like a representation of the first eigenvector. So this is kind of a visualization of the manifold of conformations here. Well, I don't know. I really don't know how to interpret this, but it's like a manifold of conformations taking into account this. Taking into account this structure that can have like this movement of the arms and then also the orientation of the box that can be deformed. But then we apply this minimization. We minimize this functional to obtain the coefficients a and b. We initialize it with zero. So in the initialization, all the predictions are the same. This is the ground truth. This is the ground truth, and then this is the prediction. So it captures more or less like the possible deformations. I mean, if you think about the possible deformations, it could be anything. I mean, so the box could be like completely destroyed if you apply any kind of deformations. But here, I mean, the main structure. So, this is the ground truth, this is the reconstruction. This is the reconstruction. We see more or less that the main deformations are captured. Then there is another ingredient that we can add in our approach is that if we have more information about the structure, like here, we know that there is a box with some sides and we know that there are arms that are kind of rigid. So, in the parameterization of the structure, we can use this information and the parameters associated. Information and the parameters associated to the deformation of these parts of the structure can be set to zero and we don't optimize them. And in this case, we have less degrees of freedom, less parameters to estimate, and then the reconstruction is much better. Like here, we observe that the reconstruction is almost perfect. But I mean, this is an ideal case. And in practice, for real proteins, you can have some idea of what parts are. Some idea of what parts are more likely to be deformed, but it's not like so good as this work. But yeah, so it's just to show that the method can be improved with more knowledge about the protein structure. And this is an example in 3D. So we have a protein which initialies in this closed position and then it can be open. This is a simulation. Like this is a simulation from molecular dynamics. So, this is a synthetic data. But then we generated a data set with tomographic projections with the particle in different conformations and from different orientations. And we added noise. So, here the SNR is like 0.01. So, 1% of the signal is the data, 99% is just noise. Just noise, and we want to recover from these images. We want to recover the different structures. Again, we compute the we do the PCA reconstruction with low resolution, only 16 voxels. And then this is like a representation of the manifold of conformations. Of the manifold of conformations. Here, since we have a molecular trajectory, so it's a trajectory of the molecule, it makes sense that it's so the manifold of conformation is one-dimensional. So, it's this kind of curve. And then we minimize this functional to estimate the parameters A and B. And then this is what we obtain. So, this is initially. Obtain so this is in the initialization, they are all the same. This is the ground truth, and this is the reconstruction. So, we see that more or less it works. Now, why it works is work in progress, but probably for the next time. So, that's my presentation. These are my collaborators, and I'm happy to listen. And I'm happy to listen your feedback. Comments, questions? What is the computation time? Oh, the computation time. Yeah, so in these small data sets, it's Small data sets, it's maybe 10 minutes, but it's everything is done in the CPU. So it's not realistic data sets, it's just a proof of concept. Yeah, I haven't tried it with real Cryo AM data, which is much more challenging. Also, the data sets are bigger. It's like millions of images. So here I'm using some thousands. Thank you. Hi, um, well, it wasn't quite clear whether, like, so are you taking the images using tomographic tilt shift angles? Yeah. Yeah, yeah. So you have the particle and you have tomographic projections, but the problem is that in every projection, the structure is different. So the volume is different. Yeah, do you face any issues with the alignment of Alignment of the tomographic images because that also, like the beam-induced motion, also is found to be like quite a big indicator of not being able to match these confirmations together. Like, do you think this would also account for that, potentially? Yeah, well, here I'm using the fact that I know the orientation of every particle. I don't know, I'm not sure. I mean, here. I'm not sure. I mean, here I'm using also the PCA reconstruction. In the PCA, these PCA coefficients for every particle, it kind of encodes the formation of every particle. Okay. But then, I don't know. So, in the minimization problem, I don't correct the deformation. Okay. Okay. So, but. Okay, so but maybe it's a good idea to instead of deforming so using the inverse of the deformation I don't know to correct it probably