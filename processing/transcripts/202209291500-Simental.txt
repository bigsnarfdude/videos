Who will talk about it's still a pleasure to introduce Mantel who will talk about cluster structures on brain varieties? Well, thank you so much for the nice introduction and thank you to the organizers for inviting me. It is a great pleasure to be here speaking about this specialist in honor of Bernard Aleclerc, whose influence in this project I think should be clear. I think it should be clear, as Melissa mentioned, but his influence, but his work also pervades some of my other work in mathematics. So it's a great honor to be here speaking in honor of Bernard. So Melissa mentioned in her talk this morning that there was another group of mathematicians working on the same problem with a different approach. I am part of that group. And the other part of this group is Rojeka. Part of this group is Rojeka Sas, Eugene Gorski, Mikhail Gorski, Ian Lei, and Lin Hui Shen. So let me get to it. The goal is to prove that for any positive grade beta, there is a cluster algebra structure on this algebra, which is the algebra functions on some variety that I will define again. And the plan is, well, to define what these varieties are, what the... Define what these varieties are, what the braid varieties are, then give you a bit of a motivation to care about them, such as realizing double-bot Samoson cells as braid varieties and also richers on varieties as braid varieties. Then we will see the combinatorics that go into proving that braid varieties have cluster structures. I will not mention 3D Plavic graphs. We use other combinatorial objects that we call Material object that we call algebraic widths. And to manipulate them, we define some functions on these waves called Louis cycles that allow us to construct both the quiver and the cluster variables. And finally, I will tell you some properties of this cluster structure. Okay, so well, let me begin by giving a bunch of definitions and conventions. G will be a simple. Conventions. G will be a simple algebraic group with Lincoln diagram V. For example, you can think throughout the talk that G is SLN. B will be a Borel subgroup. In the case of SLN, you can think we just have upper triangular matrices. T is a maximal torus, for example, diagonal matrices. And by W, I will define the value which you can present by its coxeter generators. So it's generated by. Generators. So it's generated by Si for I, a vertex of the Dinking diagram, with relations that Si squared is equal to one plus some other relations. And W naught will denote the longest element of the value. The break group, sorry, by Br, I will denote the positive break monoid, meaning I have generator sigma i. Again, I is a vertex of the Lincoln diagram, and these ellipses are And these ellipses are the same as these ellipses, so same relations, but we remove the relation that si squared is equal to 1. And because I take a monoid, I don't allow for inverses of the generator. And by curly B, I will denote the flag variety that admits a Bruhet decomposition into a sugar cell, BW. Okay. A few more definitions. A few more definitions because before we can actually get to the braid varieties, I take a tuple of vertices of that inking diagram. We're going to define its demosure product inductively, greedily, as we saw this morning. So the demosure product of the empty tople is just identity. And if I know the demonstrated product of the top i and I adjoined one more element, i L plus one. More element, il plus one. Well, if I don't increase the demo the length, I just take delta of i. And if I do increase the length, I multiply by s i l plus. So this is an element of dog. And one can check that even though I define it for a topple, if two tops define the same element of the bread monoid, where this is how a topple defines an element of the bread monoid, then it's An element of the bread monoid, then its demonstrative product is the same. So I will just take the demonstrate product of an element of the bread monoid. So for example, for w equals to s3, the demonstrated product of sigma 1 squared, sigma 2 cubed is just S1 S2. So the first sigma 1 gives you S1, the second one you would decrease, so you just don't multiply it, and then you multiply by. Okay. And now we can define the parallelities, which is slightly different to how many... Slightly different to how Melissa introduced them, although the definitions are equivalent. So let us first recall that two flags in G mod B are in position W in W if the element X inverse Y belongs to BWB. Easy to check that this doesn't depend on the representatives. For example, as we saw this morning for SLN, two flags are in position SI if they differ in precisely the ith substrate. And we will denote this by Xb. Note this by xb, right arrow w, white. Now, given a topo i of vertices of the linking diagram, the braid variety is defined as the space of L plus one toplos of flags. Well, not really L plus one, but I require the first flag to be the standard flag. I require the last flag to be the coordinate flag given by the demoswork product of I and two consecutive flags are Consecutive flags are in position as whatever the top is. So the first flag is in position I1 with respect to the second one, the second one in position I2 with respect to the third one, and so on. The way I think about this is you start with the standard flag, then you change it little by little according to the topple I, and you require that at the end you have a coordinate flag, which is as far as theoretically possible from. As theoretically possible from this standard plan. And this, as far as possible, is precisely this demoswork product definition. Okay. Some properties of these bread varieties. Well, they were studied by many people. For example, if you look at the work of Laura Scovar, these are called open breed varieties. Melitt didn't give them a name. Shannon Weng called them braid cells. Braid cells and well, first of all, this braid variety smooth affine all dimension L, which is the length of the topo, minus the length of the demosore product of it. Number one, if the topos define the same element of the braid monoid, then the varieties are canonical isomorphic. That's why they are called bread varieties. And from now on, I will define, I will denote them by x beta, not xi. Beta not xi. And number three, if you have a tuple and you add one more element in such a way that the demonstration product increases, then the braid variety doesn't change. This last property allows us to assume that the demosure product of beta is always as large as possible. So from now on, I will always assume that the demonstration product of beta is doubling. As a simple As a simple example, let's take G to be SL2 and beta just sigma squared. So this is like the simplest non-trivial example. Then I claim that the braid variety is just a torus, C star. How do we see this? Well, we have this configuration of plaques. I want the first one to be standard, last one to be anti-standard, and the middle one to be different from both of them. So I have P1 minus two points. That's a system. Points that's a system. To see that these varieties are affine, we are going to use the notion of a pinning, which is nothing but a compatible set of maps from SL2 to G, one for each element of the Dinkin diagram. And we're going to define Bi of C to be phi i of this matrix in SLT. For example, when we are in type A, what we're doing is we are considering a matrix which is almost identity, except for the i than i plus first row and column, so where we have this little two by two matrix. And for a braid beta, we're going to define the beta of z, where here z is an L to complex numbers, to be just the product of these elements of the group. Elements of the group according to the rate, each one depends on its own value. And it's not too hard to check that a presentation of the braid variety as an affine variety is just given by all these tops of complex numbers in C to the L such that delta of beta, where this is lift of delta of beta to g inverse times b beta of z is in the world. Is in the world. So this gives you some equations that define the bread. They need to satisfy some version of the bread relations, for example, and some other conditions. Okay. So the braid variety is actually affine, and it is known that a pinning always exists. So this is. Always exists. So this is fine. Okay. For some more examples of braid varieties, the so-called double-bottom Samuelson cells that, as far as I'm aware, were defined by Lin Huixe and Da Pin Weng, given any braid beta, any positive braid beta, we define its configuration space to be just the set of topos of complex numbers such that this matrix, the beta of z, B bit of Z admits an LU decomposition or the analogous of an LU decomposition. This is a principal open set in C L, which is given by the non-vanishing of several generalized minors of this matrix. And it is not too hard to see that this can be realized as a break variety, where here delta will always denote a minimal lift of W naught to the positive break map. Breakmap and a theory of Shenan Weng says that this variety always admits a cluster structure. So that's the first indication that these great varieties maybe admit a cluster structure, although this is a very special case. Richardson varieties, or rather, open Richardson varieties, are also bread varieties. Let's recall that the open-Richardson variety is the intersection of a sugar cell and an opposite sugar cell. This is non-empty if and only if B is less than W in the Bruchat order, less than or equal to W. And in this case, the dimension is just the difference of the lengths of W and B. And well, and theorem, which is not very hard to see again, is that if by bit of W we denote a reduced lift of W to the positive red monoid, and similarly for the inverse. And similarly for V inverse W naught, then when we concatenate these two grades, we take the bread variety, we get something which is isomorphic to this open rejection. And this isomorphism is not super hard. So we have this sequence of flags. And because the first k, let's say, form a lift of w, a reduced lift of w, this flag is going to be in the Schubert of W. To be in the Schubert cell of W. And similarly, the same flag is going to be in the opposite Schubert cell of B inverse W. And that's the definition of the Richardson variety. So the isomorphism just picks this middle flag. And of Richardson varieties that they admit cluster structures was conjectured by Leclerc a few years ago. The case of positroids is known thanks to work of Galachi Nam, who Of Galachi-Nam, who in turn based their work on the work of Serijenko, Sherman, Bennett, and Williams. Positroix is just in type A, where the big element is Grasmanian, meaning that it has at most one descent. Okay. And the main theorem that we will spend some time seeing is that for any simple algebraic group G and any positive braid beta. Positive braid beta, the braid variety admits a cluster, meaning that its algebra functions is a cluster algebra, where, by the way, just specify, I always take invertible coefficients. As we have seen this morning, there is independent work of Galacian Lambs Sherman, Bethel and Lambspeier that constructs also a cluster structure here. These constructions are different of that, I am sure, but how different than I am sure, but how different? That's a good question, and it would be interesting to compare these two clusters. Okay, so we will spend some time seeing how to prove this theorem. Well, the very basic thing one needs to do is, well, there should be cluster tori. So the first thing that we're going to do is we're going to find candidates for this cluster tori, which is very similar to what Melissa did this month. We define the cluster tori before defining the Before defining the cluster variables, after we find the cluster tori, we need to find a system of coordinates for each one of them that are regular functions on the interpreted variety. It is not too hard to find coordinates, but they are going to be rational functions. And the hard part of this is to find a change of variables that will turn this into regular functions. And once we have that, we need to find a mutation rule. We need to find a mutation rule and show that whatever we found in step two remains regular once you muted. So, I don't know how much I will go into three, but one and two we will see more or less in someday. But before we go there, are there any questions? Okay, so to find this story, we're going to use comedatrial objects. All right, we're going to use combinatorial objects called algebraic griefs. For simplicity, from now on, maybe if there is time at the end, we will go back to the non-simple list case. But for simplicity, we will assume that G is simple. Just things are simpler. And maybe I will say what happens in the non-simpleless case. So an algebraic wave, match frag w from beta to its demonstrative product, is a graph. Is a graph on some rectangle whose edges are colored by the vertices of D and that has vertices of many types, well, three types. Vertices of valence E1, they are all either on the top or on the bottom edge of the rectangle. And moreover, we require that when we look at the edges which are attached to these vertices on the top, Vertices on the top, they are going to spell beta, and on the bottom, they are going to spell some reduced word for delta. So we want to start at beta and somehow end at delta. Then we have trivalent vertices, which are located in the interior of the rectangle, and they look like this. These three edges have to be the same color. Then we have vertices of valency. Then we have vertices of valiant C4, again located in the interior of the rectangle. And here, these colors are not neighbors in the Dinkin diagram. They are not connected in the Dninking diagram. And finally, vertices of valency six, which again are located in the interior. And here we assume that I and J are connected in the Nincing diagram. So if you want to think of this as the braid relations, that's a good way to think. Okay. And then we have this weird. We have this weird trivalent vertical. So that's an example of a width that goes from sigma 1, sigma 1, sigma 2, sigma 2, sigma 1, sigma 1, sigma 2, sigma 2 to its demosore product. And you can check that all the vertices are of the allowed type. And there are many ways to think of algebraic widths. We're going to see, I think, three of them, but there are some more. First, we can think of them as flag moduli. So we have this rectangle. We have two special ridges, which are the boundary, the ones that the one that touches the left edge and the one that touches the right edge. I want to put flags here such that in this left region, I have the standard flag. In the right region, I have the coordinate flag given by the Demosur product of beta. And I want to somehow fill all these regions. Somehow, fill all these regions in such a way that two regions which are separated by an edge of color i are in position si. And I claim that this defines a torus in the red variety. The main point here is that everything is determined by the flags on the top. If you look at the flags on the top, this defines an element of the bread variety just by definition. Right, just by definition. And the point here is that, sorry, go back. So, here, for example, if I know flags on these top regions, then the flags on the bottom regions are determined by the ones on the top. Same here, if I know the flags on the top, the flags on the this flag is determined by these other three flags. Determined by these other three flags. And here we have the torus condition because what this is saying is that, well, let's say in type A, I have a flag, I change the it subspace, I change it again, I am not allowed to change it back to how it was. That's what this trivalent vertex is. So this defines some torus inside the breakbrain. And these are going to be microcellatori, but somehow it is very convenient to keep track of all these torus. Of all these flags, not just the ones on top. Okay, so this is one way to think of the braid varieties, and this is the way that gives us the cluster to write. But to find coordinates, we need some other ways to think about them. The second way is to just think of them as patch on braidboards. So you start with the top that reads beta from left to right. Reads beta from left to right, 1, 1, 2, 2, 1, 1, 2, 2. And now you do generic horizontal cuts of this width and you start reading what braid word you have. This will give you a path of braid words. That's another way to think of these widths. So the trivalent vertices just tells you that whenever you have two sigma i's together, you can merge them. And the other two is just the break relation. In other words, the WIF gives you a way of going from beta to its demonstrative product. Note that none of the vertices change the demonstrative product of the word. And we end with something like this. So somehow this last condition that we need to end the demo product of beta is a bit. The demos of product of beta is a bit superfluous. We don't really need it. Okay. Okay, so that's the second way to think about with. So you don't even have to draw them if you don't want to. The last way is to think as equations on these braid elements. So to do that, we need to put some labels on the edges, not just the color. And these labels are precisely the coordinates on the Coordinates on the variety. We start with C's on top, and we're going to change them as we move down to the bottom. So, this six-value vertex is just telling me that we have this equation of elements in G. This is just an SL3, a computation. This is just telling me that BI of C and B K of W commit. And the more subtle one is the trivalent vertex. is a trivalent vertex because this is telling me that if I multiply bi of c1 times b i of c two, this is going to be bi of c1 minus c2 inverse. So I need to assume that c2 is invertible times some matrix in double software. And because of this, if I think of this as in the middle of the braid word, I need to somehow take this matrix, well this element u and push it. This element u and push it to the right. Because of this, whenever I have this type of vertex, I will affect all the all the levels of the edges to the right. And that makes it a bit annoying to work with, but it's actually quite computable if you know how to program things. And I don't know very well, but some of my co-addresses. So that's why we are able to obtain actual closet coordinates. Okay. Okay, up to here, are there any questions? And this is giving us already some coordinates for the cluster toroid, because essentially what this is saying is that this vertex is going to give you a C star with coordinate C2. But once you start going very deep into the width, already here. Very deep into the width. Already here, we have C1 minus C2 inverse. You can imagine that this can enter another trivient vertex. You have another coordinate which is C1 minus C2 inverse, which is not regular on the interbreed variety. That's the problem. But somehow thinking more deeply about this already gives you coordinates in the closure tori. And what we need to do is we need to find a way to make them regular on the interpret. Okay. Okay, so this is essentially what I just said. So for a trivalent vertex B, we're going to define its S variable to be whatever variable is labeling its right incoming edge. And the S variables are already coordinates on the torques, which, as I said, they are rational, not regular on the variety. So the problem we need to solve is we need to make them regular. Is we need to make them regular and we also need to find a quiver. And we're going to solve those two problems simultaneously. Okay, to solve them, we use another combinatorial object, which we call Lustig cycles, because they satisfy some versions of equations given by Lustig a few years ago. So, for any trivalent vertex V, maybe I should observe before, sorry. Observed before, sorry, that the number of trivalent vertices is precisely the length of beta minus the length of the demaster product, which is a dimension of the breakpoint. So it's the number of cluster variables that we should have. Each cluster variable will be labeled by a trivalent vertex. Okay. So for each trivalent vertex, we're going to define something that we call a cycle, which is nothing but a function from the edges of this graph, of the width. Graph of the width to the integers as follows. If I have any edge above the trivalent vertex, its value will be zero. If I take the outgoing edge of this vertex, its value is one, and from there I can read the value in every edge by following some tropical version of LuSTIC's rules. I'm not telling you which rules, but Which rules, but they are the following. If we know the values on the two incoming edges of a trivalent vertex, by the way, I think of the waves as going down, so incoming just means the two that are above. And E3 is the outgoing edge. Then the value on E3 is just the minimum of the values on E1 and E2. And the way this most of the time appears to you is as follows. You have this. Folllows, you have this cycle, which is this yellow thing. And so let's say that, for example, this is one, this is zero, then the cycle stops here because this will be zero. The minimum is zero. So this is how this first rule most of the time appears to be, not always, but okay. The second rule is a bit easier, although maybe not the way it's written. If we have a four-valent vertex and we know its value and the two edges on top. The two adjacent top, then the value on the adjacent bottom on the bottom, they just flip. So you just keep reading. And the way this will present to you most of the time is as follows. If you know, for example, that this is one, this will keep being one here. So they just go to. And the most complicated one is what happens at a six-volume vertex. Again, let's say that we know what the values are on top. We want to know what the values are on. On top, we want to know what the values are on the bottom, and on the bottom, they are given by these beautiful rules. So, on the left bottom edge, we have the value of the top middle plus the top right minus the minimum between the top left and the top right. In the bottom middle, we have the minimum between the top left and top right. And on the bottom right, we have something very symmetric to the bottom left. To the bottom yeah, this is also the same project over the first stage, but it could be streaming fighting networks and like they just spoken languages and yeah, I was going to say this in the conference, but it's a okay. Oh, okay, great. I didn't know that, so it's great to know. Thank you. Yeah, okay, and and the point is what. And the way this will present to you most of the time is as follows. If you have a cycle that, by the way, when I don't put the yellow, it means that the value is zero. So you have zero, zero, one, then it moves as one, zero, zero. One, zero, zero moves as zero zero one. And here, the cycle like branches. And if you have two branches, they're going to merge. So this is how they will present to you most of the time, not always. And I will give you an example where this doesn't happen. An example where this doesn't happen right away. So let's compute the cycle for the top triviant vertex. On all edges which are above, it is zero. So everything that doesn't have a label means that the value is zero. We know that here the value is one. And here by the third rule, it is going to bifurcate. One. Here it also bifurcates. And here, I would say it bifurcates, but we don't know yet. Say it bifurcates, but we don't know yet because we don't know the value here. We need to keep going here, it just moves it bifurcates. And here now that we have 0, 1, 1, and then we need to go to our boost. So this comes out with a level of 2. That's why this is yellow, just to point out that the values though are not always 0 or 1. Minimum of 2 and 1 is 1. It is going to move, and minimum of 1 and 1 is 1. So this is what the Loustic cycle is for this top trevolium. Well, if it is not, then it is just zero. Yeah, that's that's more or less. Okay. Okay. And with this, we can already say what vertices are going to label frozen. Vertices are going to label frozen and what vertices are going to label mutable cluster variables. Frozen means that when you compute this cycle starting at V, you will find some edge at the very bottom that has a non-zero value. For example, we just saw that this top vertex is going to be frozen because we have this one at the bottom. We can check, for example, that this Can check, for example, that this orange vertex is going to be mutable because, well, I go, this is one, here it crosses, this is one, and it dies at this vertex. This is also going to be mutable because the cycle starts here, it goes following the hand, and it dies at this vertex. And these two are going to be frozen because they go. If you really didn't like this and you don't like to compute Louis X cycle, This and you don't like to compute Louis cycles. I give I have you I have for you another way of deciding what vertex is frozen and what vertex is mutable as follows. Remember that we can think of the wave as some sequence of grade works. Okay, and so a triviant vertex is just something that gets you from beta one sigma i sigma beta two, and it just merges these two. Well, this vertex is going to be frozen if whenever you add If, whenever you actually delete both of these, you decrease the demos of so going back to the example here, this is going to be frozen because the leading boat means that I essentially don't see this red line. And the demonstrated product of the race is going to be, well, I have one, one, one, one, two, two. Then the demonstrated product is not doubly normal. Product is not doubly naught. Same here, if I don't see this red, I have one, two, two. Demonstrate product is not doubly naught, and here the same demonstration is not doubly naught. But for example, if I don't see this blue line, I'm going to have one, two, two, one, two, whose demonstrate product is W. So that's another way of deciding which vertices are frozen and which vertices are mutable. But I have to say, even though Have to say, even though the claim that these two definitions of frozen I just gave you are equivalent is something purely combinatorial, I don't have a purely combinatorial proof. I need to know that we have a cluster algebra, and then I can say that these two are equal. So if you can think of a purely combinatorial proof, I'll be very happy to see. Okay, and now that we have that, we need to define a quiver. That we need to define a quiver. And we're going to define a squeezy metric matrix using something that we call intersections of cycles at trivalent and hexavalent vertices. If I have two cycles that somehow meet at a trivalent vertex like this, then their intersection is this determinant. I don't expect you to learn this, but intuitively, what we have is, let's say that we have. What we have is, let's say that we have a cycle that goes here and dies, and another cycle that starts here, I will have an arrow from the green cycle to the purple, or from the purple to the yellow, or from the yellow to the green. And so we decide arrows at these three variant vertices and arrows at six variant vertices are a bit more complicated. But again, the gist of it is that if you have this. That if you have this purple cycle and this green cycle, I don't know why it changes color, I guess, because the blue and the red behind have some effect. And then we're going to have an arrow from this cycle to this cycle. And we just put all of this together, and that's how we define it. Let's give an example. Let's take this. Example: Let's take this nice long wheel. So I have the word 213223122132 inside S4. And I have some trebal and vertices. We can compute the cycles that I'm just going to draw like this. And then we can compute intersections to form the quiver. So, for example, So for example, we have this purple cycle is going to intersect the blue one here, and it's also going to intersect the yellow one here and the well, this little blue one here. And for example, this green cycle is going to intersect the purple cycle twice, once at this six-valued vertex and another one at this six-variant vertex. The mutable cycles are on top, and the frozen ones are on the bottom. This is the quiver. Now I need to tell you how to compute the cluster variables. Yeah. I guess as long as you do it consistently, it is. Okay, so now let's see how you compute the cluster variables. Remember that we had these S variables attached to every trivalent vertex. And we're going to use these cycles to define a change of variables that will make all these s variables actually regular. And we do this as follows. So we have a width. A width such that for each trebaron vertex, either its right or its left arms go all the way to the top. We have a rule for every wave, but this simplifies a lot. And for these waves, we have an expression in terms of these s variables. Otherwise, we don't. We need to do something else. So then we define this function a sub b to be the s variable of b times. Variable of B times the cluster variables of vertices that come above B that we have already to some power. And the power is, well, we look at the two arms that come into this trivalent vertex and add whatever function of V prime we have, the value of the cycle of V prime. And one of this is always going to be zero because for each vertex V, either it's... For each vertex v, either its right or left arm go all the way to, and the theorem is that this function is regular, and together with the intersection form, they give x of beta cluster structure, meaning that the cluster algebra defined by this coincides with the algebra functions on x of beta. So let's go back to this example. Well, we can compute the cluster variables. They are these very, very nice functions on c's. Very, very nice functions on C's. You can see, more or less, the deeper we go into the web, the more complicated the closure variables are going to become. But they are computing. Oh, for example, here in this top, you follow the right arm and you get all the way to the top of the. Well, it doesn't go all the way to the top. Yes, yes, yes, one or the other. Yeah, yeah. And it's always possible to do this. For example, the way we found this weave is by like reading the word beta from left to right readily in such a way that you put a trivalent vertex as soon as you can. So here we have two, one, three, two, two. Well, here we can put it. To too well, here we can put it as and we put it there. And these weaves will always have the property that the right arm of every vertex goes all the way to the top. If you read the word on the opposite direction, then the left arm will go all the way to the top. And it's always possible to do. Okay, so we have these nice, nice variables and we have a quiver. If you're bored one day, you can check that we have the exchange relations and Exchange relations. And I want to point your attention to two things. Number one, when we mutate here in A2, we get something very nice, which is just C9. Let's go back to see what the second variable was. So it was this blue one. And this C9 is precisely the label of this other edge. H. And in fact, with mutation for us is doing this. If we perform this change on with, what it amounts to is to mutating at this cycle that is born here and dies here. And well, there are some equivalences of waves that I didn't give you, but if you consider those equivalences plus meters. You consider those equivalences plus mutations, then any two waves are mutation equivalent, and any two weaves are going to define the same cluster solution, like mutation both in the weave and in the variables that we define for this. The second thing I want to point your attention to is that if you're bored one day and you want to do this, you will not need any of the relations. Need any of the relations that define the bread variant. These exchange relations are already valid in the polynomial value. You just don't need the relations. Geometrically, what this is telling us is that if we just take the cluster variables, which are frozen, and we invert them in the polynomial algebra, they are going to define some. They are going to define some open set U in C to the L and the inclusion from the bread variety to C to the L is going to factor through this U. Well, that's more or less obvious. The non-obvious thing is that U also projects to the bread variety, and this composition is identity on the bread variety. And it is not too hard to see who this set U is. I define the bread variety by specifying. I define the breadth variety by specifying that the last flag is a coordinate flag given by the demasre product of beta. Well, we can now just say that I take the same construction, but the last flag is not necessarily a coordinate flag given by the demonstrated product of it, it's just some flag inside this shoe base. And this is precisely who this space used. So we have a cluster sub-algebra of the algebra of functions on this. I have no idea if the algebra of functions on this is a cluster. And yeah, I just don't know. Also, this, well, when you project the fibers here are precisely affine spaces of dimension being the dimension of this sugar cell. Of this sugar cell. And in some cases, for example, in the double-box Amoson case, we have a trivial bundle. In general, I don't know whether this is a vector bundle, although I suspect it is a vector. But I don't think it will be trivial. Okay, so that's one property that I call a polynomiality of the closer variables. You can do everything already in the polynomial algebra that rejects into the algebra functions on this rate product. Functions on this break variety. More properties on the cluster structure on this bread variety. Well, first of all, you can cyclically rotate that I think Melissa already mentioned. If you have Si star that you obtain by just conjugating Si by W naught, then you can move a sigma i on the right to a sigma i star on the left. This is not going to give you a cluster isomorphism, but it's a quasi-cluster isomorphism. Isomorphism, but it's a quasi-cluster isomorphism. So I'm not going to go into the implications for not theory, but somehow this is telling me that if you want to say that the cluster structure is an invariant of some not in type A, you cannot do that. You have to say that a quasi-cluster structure is an invariant of the node, maybe. And this is related to work of Rodjeke Salz and the Pinwenk from Irrar Disease. Number two, we have A is equal to U. So we can show, for example, that the upper cluster algebra is containing the algebra functions on the x of beta by using, for example, the star-fish lemma. And moreover, all these coordinates on the braid variety are cluster monomies, which gives you the opposite information. The exchange matrix has full rank. One thing I didn't say. One thing I didn't say, by the way, is that we can also define what intersection between frozen vertices are. We need to do something different from what I've just said because you can somehow keep the width going below. That will change intersection, and we need to account for those changes to make it well-defined. But there is a way to do it. This cluster algebra is also locally acyclic. And in fact, the break. And in fact, the braid variety can be covered with cluster open sets, which are of the four, also braid varieties for smaller braids. So we can do some induction to show that this is locally acyclic. Upon the identification when this X of delta beta is the configuration space of beta, or the double Watts Amerson cell defined by Shannon Weng, we get the same cluster structure. Cluster structure. And we get, I mean, we can get the same quiver by doing this procedure I described a bit earlier, just by reading this a bit greedily and just putting every trivalent vertex as soon as you can. That's exactly how we get the initial seed that Shannon went. If you attach a letter I A letter I so that you don't increase the demosure product, and you take, for example, this sort of widths, then the quiver for x of beta is obtained from that of x of beta sigma i by deleting a process sink, which is going to be given essentially by some trivalent vertex involving this last guy, and freezing all variables that were adjacent to this frozen bar. And well. And well, if you put it on the other side, then you have a frozen source. That's fine. So, these two tell us, for example, that all these quivers belong to the class P. And I don't remember who defines them. I want to say it. And for example, it follows that this cluster structure admits a green to red sequence. Whether it admits a maximal green sequence, I don't know. And it also follows because the exchange matrix is... Folllows because the exchange matrix is of rank that this alier admits a basis of theta functions. I think it would be very interesting to say what they are as functions on the breaker. In the remaining, like, I don't know, three minutes, I will say what happens in the non-simple lace case. But before, are there any questions? Okay, so for the non-simple lace case, Non-simple lace case, well, let's say for example on B2, we can always unfold a weave in a non-simple lace case to a weave in the simple lace case. For example, in type B2, we're going to have an eight valent vertex. And by unfolding, I mean that this one is going to be replaced by one and three, because that's how you get b2 from a3, or maybe it's c2. And this eight-valent vertex is going to become this sequence of four and three-valent vertexes. Then you can play the game with the simple lace case. You're going to have a very symmetric quiver and just take cluster folding of that quiver. For example, we have this weave. Each one of these black edges is going to leave to a pair of a blue and a green edge. We obtain the equiver for this width. So it's going to look like this. And then we need to identify these blue and green to the same black. So we need to take a morphism that, well, a symmetry that identifies one and one prime with four and four and four prime. And that's how you obtain the cluster structure on the type B red product. And you can do this for any number. And you can do this for any non-simple lace case, just unfold it and fold it again. We do have a way to treat simple lace and non-simple lace on equal footing, but that's much more technical than what I said. And with that, well, thanks for your attention. Thank you, Jose, for this beautiful talk. And first, we see if there are any questions online. Well, if that's not the case, then maybe there are some questions here. Yeah, Bernard. Yes, so in the non-simply laced case, the quiver that you I mean, you obtain a cluster algebra with a You obtain a cluster algebra with a quiver or with a valued quiver? I mean, is it associated with a skew symmetric or skew symmetrizable matrix? Skew symmetrizable. When you do these symmetries, you need to put some multipliers. So do these beads variety or braid varieties, do they have a Or braid varieties, do they have a canonical Poisson structure? Yeah, that's the cluster algebra is compatible with the Poisson structure? We can define a canonical two-form that is going to coincide with the X-Man Python Shapiro two form. Yeah, yeah. I can maybe explain how to do this, but. Maybe explain how to do this, but somehow does it come from the canonical structure on G or any more questions? You said that you do not obtain the same cluster structure than in this morning. Could you say? Than in this morning, could you say a little more what are the differences or how you can be sure that they are different? Well, in very simple examples that we computed yesterday, they are different. So, yeah, they are different. I mean, in the examples we computed, they are quasi-cluster isomorphic, but they were too small to say anything, you know. I do expect they will be related by some sort of twist map, but yeah, thanks. Mm-hmm. I guess the theme with the cluster structures and twist maps is that sometimes when you define a cluster structure, you get to choose some convention, and it seems very innocent, but in fact, the two different convention choices result in some very non-trivial automorphism. And that seems to be probably exactly what's going on here. Probably exactly what's going on here. We have made some different convention choices. Yes, exactly, exactly. All right, everyone. No more questions? Let us answer that again. 