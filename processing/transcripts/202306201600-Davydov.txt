Have Alexei Davidov today from Ohio University. He'll speak about the fine structure of third cohomology. Thank you, Alexi. Thank you so much. And yeah, it's a pleasure to participate even remotely. And I am a bit of an outsider, so I'm an algebraist and a category theorist. And I will try to be entertaining, but I might be just a little bit of. Just a little bit over technical, so yeah, please. Uh, my apologies, uh, but whatever is unclear, uh, please interrupt me this time and ask for demand clarity. So I'll try to do my best. Sure. And yeah, it's the third emoji of a group with coefficients in a group of invertible scalars of some field. So that is supposed to be irreminiscent to. Oops. To another sort of to more canonical topic for the conference, to the Ogomolov multiplier, which is a subgroup of the second homology. And this is supposed to be like a third degree analog of that. And my way of seeing this sequence now of subgroups will be. Sequence now of subgroups. It won't be just one subgroup, but it will be two. My way of seeing them in a more or less natural way is through a story of tensor categories. And there will be actually two parallel stories. So one is kind of like sleeker, easier, at least for my understanding, easier to see at once. And the other will be a little bit more technical, but more amenable for computations. Um, more amenable for computations, so the answers will be coming from the reformulation, but they will be both categorical. So, that is the outline. The beginning of the story is a strange way of interpreting Frieke cycles of theme thought cocomology of a group with coefficients in invertible scalars as some sort of natural mathematical object, but again, natural in the eyes of the beholder. In the eyes of the beholder. So, the way this thought etymology is appearing is as the group of certain categories. And the categories will all be, transcategories will all be fusion categories. So what they will be, they will be really like very, very, very simple, simply organized fusion categories will be categories of basically of graded vector spaces with vector structures. And objects will be graded vector spaces. And objects will be graded vector spaces with active structures, and the categories themselves will be categories with active structures, not just tensor product. But in all appearances, vector spaces are tensored as vector spaces, but sometimes associated is perturbed, is twisted by a Freaker cycle. So that's effectively the way Frica cycles enter the story. But just to frame the to really capture the group structure, here is Structure here is kind of like a sleek construction. So we could start with a symmetric tensor-ray diffusion category and then look at what are called minimal extensions. I will be briefly defining them later. And then it happens as absorbed by Lancol and Ren first, and then many others join the chorus that this That these minimal extensions of a given symmetric category form a group. Equivalence classes of them, of course, will form a group. And for the easiest example of a symmetric tensor category, namely representation category here of a finite group, this group of minimal extensions of this E will be nothing but the physical homology. And then, so that. So, that is again, that is the first way of interpreting three cycles as categories. In each of them, will be a braided fusion category containing this one in a special way. But being monoidal categories, being braided monoidal categories, we could start dropping the sort of The sort of the whole set of structures making something embraced by the category is one list. We could start dropping bits in this list one by one and getting less and less sort of restrictive structures and still we'll be able to form corresponding groups of those minimal extensions but with less structures. So that is the natural for me way of seeing this. Natural for me way of seeing this filtration. And the sort of the sequence of structures and conditions we can drop one by one is the following. So we can just look at the tensor, which is the whole thing, and then we could relax them to what I'm calling COSI tensor. And that is basically forgetting, not requiring associativity to satisfy the pentagon self-consistency axiom. So just having associated. So just having a social activity, but just as a natural collection of isomorphisms, not requiring that it is talking to itself nicely. Or we could just forget about having associativity altogether and then just have a category with a tensor product, not even requiring it to be associative. Or we could forget the tensor product completely. So that is just a natural sequence of relaxations of this notion. Of this notion. And each time we could make sure that the group of certain minimal extensions in each of those classes will be possible to define. And then we will have the sequence of such groups and connecting homomorphisms just coming from the fact that we have, yeah, more structures, so we think we have that. Structure, so we particularly have that. And looking at now the kernels of those homomorphisms, so just to remind you that Lancon and Ben said that this is just the photo homology. We will see filtration on the photo gomology. So that will be the kernel to the to the which one to to so the kernel to this thing will be trivial, the kernel to this thing, or the kernel to that thing. To this thing or the kernel to that thing, and then we will have two successive kernels. So, what will happen is that this is not really giving us any interesting kernel. The kernel here is nothing really, but the kernel here will be just trigger. So that will be effectively an embedding. And yeah, I will try closer to the end. I'll try closer to them to indicate that this is not a sort of low-dimension phenomenon. This is persistent for all degrees. So really, we have filtration of step filtration on n-degree chromology for any time group. Okay, so done with outline, let's start briefly defining things. This minimal, what... This minimal, what does it mean to be minimal extension? What is minimal extension? First of all, it's a category which is a tensor of fusion, even and graded. And then we have this symmetric category. So really just the same gradient, but on this subcategory, it is symmetric, meaning that the double bradian on any pair of objects is identity. Identity and then this extension is called minimal if what is called the rated centralizer of the subcategory inside the big category D is just the category. So nothing else centralizes in the braided sense, but just epsilon itself, sorry, E itself. That is again, that is a braiding, that composition, the composite is a double. Position other composite is a double gradient, and we require it to be trivial. So it's saying in sometimes things satisfying this equation for a given x. So objects y are called transparent with x, x and y are mutually transparent. And then we're saying that for objects in E, what is transparent jointly with all of them is just again objects in E, which is, of course, true. Objects in E, which is, of course, true for a symmetric edge, but nothing else. So that is the minimality. And for such, we minimal extensions, we can define sort of a more or less natural operation, which is, yeah, it's a weird way of defining it. It's really the way of, it's really good for computations. What it says really in this formula. So first, we just put these two categories together in what is called the lintel and the product. In what is called the Linterser product. So that is just taking the Cartesian set of objects in the objects of C and objects of D, just making pairs of them, calling them objects of the new category. And then home spaces between these are just tensor. So that is the easiest way. And then in this big result will be two copies of E. So that some power has to be shrinked. That some power has to be shrinked down to one to make it again a minimal extension of E. And that is this shrinking process. So, shrinking is done by taking modules over this algebra, which is called delta for diagonal algebra, and the modules of special appreciation called local modules. I will not be defining this, but yeah, this is some nice class of modules in braided categories. Not all modules are the same, some are better. Are the same, some are better. And to make the category of modules tensor, all you need to have is just the community of algebra. So delta will be one of those community algebra. But to make it braided again, you need to restrict yourself to local modules. So that is really the reason of doing this local modules. And then the algebra is really just the diagonal sort of algebra in the doing. The lean products of the symmetric categories itself. So, in the examples which will come, I will make explicit sense of these algebrais. But really, again, is a semi-simple category. It has some number, finite number of isomorphism classes of simple objects, and we will just take the sum of them, basically. The object, simple object, and again, another copy of that simple object in a second. Copy of that simple object in a second category, and that underlying object always has a special sort of structure of an algebra of a special algebra which is commutative and which is code-separable and it is good for doing its construction. Can I ask a question? So is this operation defined only on minimal extensions or is it defined? No, no, it's operation defined for any commutative algebra, any commutative algebra in a branded category. Well, I don't mean modules. No, no, no. Yeah, this again, this separation, yeah. So it just what it means, the separation is a special diagonal archipelago in E in a box E, and it is always there for fusion categories, for example. But even beyond that, for finite sensor categories, you always have it. Do C and D have to be minimal? Yeah, you don't need that. So you can still be defined. You don't need that, so you can still be defined, but yeah, to make to make to get the result being minimal, yeah, CND better be minimal. So, yeah, what happens is that this is minimal, which is not written on the slide, but this is minimal if C and D will minimal. So, this is again staying in the same class. This is an operation of minimal, and moreover, this operation has a unit, and this unit is just the greenfield center of the Manual greenfield center of the category. So if we just take this is always a minimal extension. Again, I forgot to mention. So for example, minimal extension of E as a subcategory in its monoidal center, because E is symmetric, in particular, it is braided, so it is sitting naturally in its own center. In a category of worldwide computer. In a category world when we compute the center, you don't really get the same answer, even if it is commutative, because commutativity is not a property but a structure. And then when you build the center, you really sort of add this particular choices of such commutativity structure to your objects. And that really makes category to double in certain sense. So this is also called infield double. So this is. So, this is never the same as E unless it's just like spaces. And in size, it's really like twice and r square of the dimension of this. And if E is graded, it always sits inside, but it sits at least in two ways. But these two ways coincide when E is symmetric. And this extension of E sitting inside its menodal center is the archetypal minimum. The archetypical minimal extension. And if we take this as a minimal extension and put it together with another minimal extension, we get this other minimal extension back. So the window at the center serves the role of unit in this set of minimal extensions. And moreover, any minimal extension is indegaciable with respect to this. So the inevitable is given by the category, by the related category. By the category, by the braided category, with the reverse bridging, with the opposite bridging, so we with the inverse bridging, and that makes it a group, or at least on the set of equivalence classes, will be a group. Itself, it will be a group, or maybe even something weird that can be made. But I'm interested in the shadow, which is the third cocomology. If he is If E is representations of a group. Actually, there's not that much we can do if we want to be in the characteristic zero situation of an algebraically closed field. And there are not that many choices for a fusion symmetric category to start with. It will be either representations of a finite group or it will be representations of a finite. Will be representations of a finite group with a slightly modified symmetry. And the symmetry will be modified by choice of central element of the two. And then it will be a super sort of symmetry will be objects of dimension negative one, but that is all we can do really. But the super case is very interesting. Is very interesting, and people are working computing this group of minimal extensions. So that is something which the story applies to, but I will be concentrated on what is called Tanakian symmetry category. So this is the representation categories of finite groups in this pseudo-scientific terms are called Tanakian symmetric fusion categories. Fusion projects, symmetric fusion controversies. So, okay, this assignment taken associator, sorry, taking precaut cycle and using it as an associator, say, one way of explaining this category, which again will be a generic example of a minimal extension of this category of representation. So, G will be take graded vector spaces, perturb the assertion. Perturb the associator using this tricker cycle, use a tricker cycle to define a new associator, and then take the dream filled center of that category. So that is one way of defining it, but I will also spell it out in terms of explicitly in terms of objects. I'm sorry, the screen enough. I hope it's not very destructive. So, this is an assignment of using associated to define in one of those minimal extensions. And Vlam Kron and Ven say that. Plan, Corn, and Venn say that these are all possible minimum extensions up to equivalence, and the group structure on them, which is here, is really just multiplication of the case. So we have the group isomorphism. And just sort of spelling out an equivalent category to this. So I said that this is a monodal center, but we can also interpret its objects in the more In a more straightforward algebraic way, we could look at them as graded vector spaces graded by the group G, and then they also come with a compatible G action. I'm skipping some interesting details because in the presence of the associator, great vector spaces will be translated in the usual way we translate vector spaces, but the associator will be twisted and the compatible. Twisted and the compatible action, which I'm only specifying on just graded components or the dustograded components. It will also be not a proper action but a projective action with Tulka cycles coming out of alpha. But I'm all brushing it under the rug, just sort of really explaining the vanilla case when Alpha is trivial. But yeah, again, the general case is just take the All cases just take the vector spaces graded by the group with associated alpha and take the monotonic sample. So, in all the cases, we will always have just ordinary representations being special type of objects. And here, they all appear as trivially graded vector spaces when the whole vector space is concentrated in the identity group element degree. And then, uh, projective nature of the action will disappear. So, it will be anonymous action, anonymous group action on just a vector space without any gradient. And that is just what the representations are. So, the category of representations will be appearing in this way inside this ZG alpha. Okay, so that was a sleek way, and now to the way which is good. The way which is good for computing. So that is a passage between minimal extensions and what of representations of G and something which is called cross-g categories. So cross-g categories are, yeah, I think Turaif is to blame for introducing them and his motivation was that they're just Was that they're just something naturally appearing when the topological field theories anchored in some nice topological spaces like classifying spaces or fine groups. So when you put an extra structure on a topological field theory, you end up with not just the modular category, but a weakening of it. And in this case, with this particular anchoring, you get this crossed module cross. Crossed modular cross-g caches, but I'm just interested in cross-g parts of it, and the way of manufacturing them out of our minimal extensions is what is called de-equivalentization. So I'm sorry if I'm delivering too much of this algebraic or categorical information, but maybe it will be useful something else. So the way we do is Way we do is we basically now contract the whole symmetric category inside. We replace it by vector spaces. There is a natural way of doing it and again it will be using modules of an algebra, of an internal algebra. This time it will be this regular representation inside the category special object, which is just a group representation on the On the functions on the group. And it's not just a vector space, it's not just a representation, but it has also an algebra structure which is a homomorphism of representation. So this is a commutative algebra inside the category. I'm definitely saying elementary things, but I'm saying them in this weird categorical language. But this is nothing but saying, okay, we have a multiplication of this vector. We have a multiplication of this vector space, and the action really results in multiplication. And moreover, the group of automorphisms inside this category, so group of G-evariant maps from here to itself, which are algebra automorphisms. They will be just group G. So there will be just if we're acting on one side, as we should, like if it is left, action of G on this vector space. Of G on this vector space. So that will correspond to inserting the acting element in the function on the right, then the left side of the argument of the function. That's how we see these automorphisms. And that is what deaccentization effectively is. So we contract this by taking Taking modules over this algebra. And if we take modules over this algebra in the category of representations, so this is probably one of the first exercises. Yeah, I would recommend it as one of the first exercises for this general categorical algebra. What happens when you compute internal module? What is an internal module which is Internal module, which is a vector space representation of the group G, and at the same time, this algebra, which is just an honest function algebra, acting on it as an energy covariance wave. So if you put all these structures together, you will end up with just a vector space. So the structures will somehow cancel each other. So the category of such objects will be just vector spaces. Such objects will be just vector spaces. Everything will be controlled by just a vector space. And that means that when we take modules, internal modules in this category over this algebra, we will be just seeing vector space. So effectively modules will be all free, but just all free in this special sense. They will be as representations, tensor products of a module and a vector space. Products of a module and a vector space. But that is for representations of G. It's not the same for the whole twisted center. So I will be just calling it twisted center of G for sure. What will happen there, we will still have the residual structure gradient. It will be degraded and the gradient will be sort of probably not what you think. It will be not coming from the gradient of. not coming from the gradient of all or on or which make on vector space which make them objects of this category it will be coming from different ways modules can can work so again this locality condition which is really a condition that when you I will have to do it with my hands I'm sorry I should have put a picture on the slide but if we imagine module action as Imagine module action as a string diagram, just connecting two strings into one. One string is a module string, and the other string is an algebra string. Then what we can do in the braided category, we can basically do all the braiding. So we can braid it twice before. And that will be algebraically, it will be pre-composing module action with double braiding. So locality, you So, locality is really the condition that such a composite is nothing but initial module actions. That is for a module to be local. That can be twisted with automorphisms of an algebra. So, you double break and then you put an automorphism of an algebra. And this triple of quadruple composite is now the same as the original module action. The original module action and such modules are called GMO. And then we will, so what the statement here is, is that any module will be one of those, or rather any module will be possible to decompose into direct sum, where summons are just geolocal modules. And that will be making this category geographed. And all in all, at the end of the day, the category will be, so the category will be degraded, and the trivial component. category will be degraded and the trivial component graded grades component with trivial label will be just the component coming from computing modules over this algebra in this category which is just vector spaces so it will be degraded category and it will have a very trivial component in a trivial degree and that will force it to be trivial in every graded degree and so it will be just the category as a monoidal category with simple As a monoidal category with simple objects satisfying some group multiplication law. The fusion rule will be just a group rule. And surprise, surprise, this group is G again. So what we will get is just vector spaces graded by the group with these associated which we embedded from the start. So why am I doing it? But what now this gives me is a natural This gives me a natural operation on this category, which somehow would not be probably so natural if I would just start with it. It was a natural operation on minimal extensions. Now I can translate it through this deprivatization process to this crossed G categories. And first, yeah, this operation is reversible, so not losing any information. We can go back, we can do this equivalentization. Go back, we can do this accuratization. This category now has a compatible g-action by functors labeled by the group G and play in the group role of G. And then we can take equivariant objects with respect to this G-action, and we will get back the category. So this twisted center as we start with. And what this reformulation basically of minimal extension is giving us is that we now have the Is that we now have the way of natural way of multiplying together these cross-G categories and they will form a group and the multiplication is weird. So when we take these two graded categories, the grade component of their product is just, we're not mixing different degrees, we're just picking degree G in the first and in the second and putting them together instead of in product. The lean product way and then diagonal junction. Sorry, just too quick. But I have to speed up because, yeah, I'm staying on this because the slide slides too long. Okay, but yeah, the most demanding. So now we can do this hierarchy of structures. We can do a drop-in sort of bits and bobs in a tensor structure one by one. And here are the definitions. So, what I was calling near tensor is something just equipped with a tensor prune. And what is quasi-tensor? And what is quasi-tensor? It's something more refined. It's a tensor product which has an accompanying associator. But associator is not coherent yet. And when it is, the category is naturally called tensor. So what is really important is how we compare them because we want to use them to form corresponding groups of minimal extensions and then look at how much Then look at homomorphisms which forget the people structure and look at the kernels of these homomorphisms. So that is all really hinged on how we identify this. So we really need near tensor functors and quasi-tensor functors. Tensor functors, everyone knows what they are. And they are again easy to make sense of. And when one does, it's easy to see. When one does, it's easy to see that quasi-tensor functor is the same thing as a tensor functor because what it will be, it will be a functor. So, here, compare compare functors, comparing near-tensor categories, near-tensor functors would be just something which would have a comparison for the functor of the tensor product and the tensor product perfect. Or the other way around. That will be just it, just an isomorphism. For quasi-tensor, this comparison should satisfy a coherence condition. Coherence condition involving associators in the source and the target of the functor. But when associators are satisfied, if associated with satisfying pentagon axiom or not, this compatibility doesn't really care about. And so quasi-tensor functors are naturally the same as tensor functions. And that's why, as I was saying before, there will be only two components in the filtration, ignoring the whole group, not three. Ignoring the whole group, not three. So that is again the sequence of groups of minimal extensions, and that is the names for the sequence of groups of invertible cross-G categories of different strengths in this tensor hierarchy. Okay, so let's now look at what they are. I'm copying it again. So the first kernel is when we just drop down to just cross G categories without any terms of product. So that's what I'm calling PB. And the second will be the kernel when we forget sort of look at equivalent. Look at equivalent. So, this will be really things which are equivalent as vanilla cross-g categories without tensor products to the trivial object in minimal extension group, meaning just to the unassociated center. This will be things equivalent as cross-g categories. This will be classes of minimal extensions which are Extensions which are trivial equivalent to the unflavored center as near tensor, and that will be all. But what they are again, okay, I'm repeating myself, which I can really jump through quicker. Maybe I shouldn't be speeding up because I'm not that much behind the schedule. So, what what was what was a real What was a real motivation for me when I started this project? That was initially a project with a student who then unfortunately just left the program. And that was the reason why the project stole. Because yeah, it's fun to do it in a company. And so now it's in the desk for like probably what they call it. But what was But what was then a hot topic, and what was the motivation for me is people were asking things like people who were looking for examples of fusion categories with the same fusion rule. Fusion rule is just basically the isom sort of Grottendig group of the category, just the multiplication table of simple objects. And the even more elementary question is just. A more elementary question is just rank here is the number of simple objects. So, this is just the rank of the Grotenj group as an abelian group. And that's what this filtration seems to control, that first component of the filtration collects all categories with the same number of simple objects as the trivial. The trivial minimal extension. And modifying the second component is comprised of such minimal extensions, which have the same multiplication table for the tensor flow. Okay. So here I will briefly run through what CrossGCA. Uh, what cross-g categories are. So, they effectively, because of this restriction that the degree trivial degree component is just vector spaces, they will be themselves categories of vector spaces. But objects will be just vector spaces. What will be interesting is the sort of external structure, not inside a definition of a the definition of an object, but the internal structure to the category. So Internal structure to the category. So we'll have G gradient, and that gradient will be just coming from this gradient on vector spaces. But there will be also an categorical action of the same group G on the category. So there will be collection of functors. And here I'm just specifying how functors are changing one graded vector space into another. So they don't change the vector space as a whole, but they change the gradient, basically relabeling graded components. So here's Graded components. So here is the weird sort of formalic way of saying that the degree of the same vector, but after we apply the functor, will be just the normal conjugate with the label of the factor. And that is the same. These functors, these are just defining them as functors to make them to be functors exhibiting. Functions exhibiting a categorical action, they have to be connected by isomorphisms like that. And then this collection of isomorphisms has to satisfy certain coherence. So, first of all, these isomorphisms may be natural. They can only be just scalar multiplications because, at the end of the day, the functors don't do anything to the vector space, they only just change, change. They only just change the labels of greater components. And for naturality, whose naturality was only one solution, just some scalars depending on the degree, x, z degree of the vector, as I say here, and the f and g are just these labels for the group acting functions. And yeah, they have to be notable scalars because these are isomorphisms. And then the coherence they have to satisfy to make it a categorical act. Satisfied to make it a categorical action is just this lovely token cycle equation. So the upshot is that the group of such cross-two categories, which are invertible with respect to the sweet tensor product when we tensor on the same degree components of categories, is nothing but the eco-mology group of this. So this will be the Group of this. So, this will be the second cohomology, but with interesting coefficients. Coefficients will be maps from the G to K star with the adjoint function, with the conjugation action, with adjoint action of G on this. So that is a non-trivial module. And the first filtration now is the kernel of rather natural homomorphism from third cohomology to the second hole. So the explicit So, the explicit form of this homomorphism is in here. That is a homomorphism. You take alpha and you do this to it, and then you will end up with a Tuca cycle, and Tuca cycle arguments f and g and h is an argument from the coefficient. And then to be in the kernel for a cycle is to satisfy this equation for some co-boundary, and this is this delta. And this is this delta. So, yeah, the first law of the equation. And let's look at the second component in the filtration of the third cohomology. It's sort of the finest bit in this fine structure of thought cognomology. This is these things which I equivalent as neotenser categories. And first, we will just have this. Have this fixed, which gives us the structure of the cross-G category. And then we will need to make sense of a tensor product on this cross-g category. And that's what it really comes down to. So the only choice of the tensor product, because again, objects are just vector spaces with some gradient, but the only choice of the tensor product is to have it just as vector spaces. Just as vector spaces with ordinary gradient, but then the action has to be compatible with the tensor product, and that is the source for a new set of numbers, these etas. And now they are labeled by just one acting group label, which labels this acting functor, and we have two labels on the other side of the divoid, which are labeling the degrees of the vectors. Degrees of the vectors. And then the coherences, again, which are kind of imposed on us from these being the coherence of the group action case and for the tensor product. There will be these lovely equations. So this and the previous equations are familiar if you remember all papers on twisted. All papers on twisted group doubles by physicists and mathematicians, they are naturally appearing there. So the group, now the answer for the second component, sorry, first of all, the answer for the group of invertible near tens across G categories is this pretty construction. So there will be pairs of things. Of things. One defining a cross-structure, the second is defining this compatibility between tensor, actually making sense of the near tensor structure on the cross-G category. And then their compatibility is this coincidence of two differentials, which letter suggests that we are having a double complex, but the double complex in this story is obvious. Complex in this story is obvious. So we have double complex because we are looking at group cognomology with coefficients in the standard coaching complex for group cognomology again with trivial coefficients. And just writing the answer for the second filtration component. So the first condition that alpha is in first, alpha is. In first, alpha is this trivial as a prosthetic category, but then the second condition is this, is even more prettier. So to try to make a little more sense of these equations, here is this double complex. Again, what I'm looking at is standard complex for cognomology of G, whisk. Complex for cognomology of G with coefficients in the G module, and the action is by conjugation on the arguments in here. And this is also a complex, but this time it's with trivial coefficients. And so we have a differential delta, which really is a differential for this complex. And you see the differential differentials in here and everywhere coming up. And then horizontal differentials are differentials of these. Of this complex with coefficients. So we have natural bicomplex, and what happens is that the ordinary complex has an interesting set of maps making all together making a homomorphism of complexes if we if we total how to say it if we take the So, how to say it? If we take the totalization of this double complex, if we take the diagonal of this double complex, then we will have a homomorphism from this cognomology to the cognomology of the double complex. So they will have a sequence of these maps. That's what those equations were. They were just saying that we are looking at kernels of certain sort of truncations of these maps, or rather, kernels of this map. Truncate of kernels of these maps into certain truncations of a double complex. So the first kernel was when we're just looking at the maps into the truncation after the ground level of the double complex. The second filtration component in photogomology was when we just truncated double complex of this line. And that was really it for degree three. And for degree two, the stabilization happened even earlier. So that's now the link with Boga model of multiplier. We could interpret it as, sorry, I'm just recalling how I like to interpret it, but first of all, what is the second degree homology? Degree of homology. We could see it in this very story as automorphisms of this minimal extension, automorphisms of the braided category, which are identical on this symmetric subcategory and automorphisms as of a braided category. And the only things we could have are just identity functors, but with monodal structure controlled by a certain locus out. So that's they could. that's uh the the isomorphism classes of those um of those uh out equivalences will be just um forming the group which is isomorphic to the shur multiplier and then um the um yeah that's what i said and then the the only filtration component uh we have in this uh second degree is just uh yeah this kernel so again there's an actual So again, there's a natural homomorphism from the second, from the Schur multiply to the first homomology with non-trivial coefficients. And the kernel, I'm claiming, is just the Bottomalov multiplier. So yeah, for this definition, we don't really need much from coefficients. We could enlarge them to be any trivial module at least, and still can make sense of this generalized of this. Generalized of this filtration component, then it will be an analog of Ogomold multiplied for sure multiplied. So just recalling the sort of categorical meaning of them, there will be those braided outer equivalences of the trivial minimal extension, which are not doing anything interesting on the Not doing anything interesting on the level of the growth in decrypt. So, which are really fixing all simple objects or all objects at all up to isomorphism. Let me finish with, yeah, so it's all good, and but yeah, anything concrete, any interesting examples. So the one The one class of groups, namely abelian groups, are the easiest groups. And that's what is done, that's what is calculated in a paper with another student. So that time we managed to finish this paper. So this paper is published quite a time ago. But when we were doing it, we didn't really see it the way I'm presenting it today. We were just analyzing the internal structure of the topology of an ability. internal structure of society of an abedon group coming from sort of similar but not exactly the same categorical interpretation. We were looking, yeah, we're effectively doing the same thing, but we're looking just at how many simple objects twisted group double has and all that, and how can we read it all from recycle. So in the language I'm using today, what we have is We have is so first of all, when G is abelian, we have an actual homomorphism like that, and that is really the incarnation of the homomorphisms into the groups of invertible cross-g categories like I had before. But this time we just, yeah, it's easier to understand. We've just taken the complete anti-symmetrization of the Plika cycle, and that will be a sort of trying. Is sort of a trimultiplicative map on a group, so tricharactor, an anti-symmetric tricharacter. So we can manufacture an anti-symmetric tricharacter from any trigger cycle, and then those which give us trigger answers, they will make this first filtration component. And then there will be interest in second filtration components, but only for two parts for two torsion. But yeah, first. But yeah, first of all, how they can be defined, there will be another homomorphism now from this first filtration component to the extension group between G and its dual. So this is a group of characters. This G hat is a group of homomorphisms from G2K star. And then the kernel of that homomorphism will be the second component. The second component. And the easiest way to see this connection is to interpret the first component as yet another thing. But this time it will be classical interpretation. So we'll be just looking at the group, G as group, and then we'll be looking at certain extensions of it. So larger groups in which G is seated in a special way, larger groups coming with an extra structure. And these are the And these are these Lagrangian extensions. So, this is short for the group of Lagrangian extensions. And what is Lagrangian extension? It is a group, so this larger group coming with a quadratic non-degenerate function. So, quadratic meaning that when we polarize it, it will become a bicharacter. Non-degenerate means as a bicharact, it will be sort of a non-degenerate by character. Will be sort of a non-DeGenian bilinear form. And yeah, that is saying by character. That is saying it's not really linear much. And then finally, that is just to make this a quadratic group. But what makes G Lagrangian and side L is that, yeah, the restriction of this quadratic function on G. This quadratic function on g is trivial. It just when it happens, the subgroup in the quadratic group, in the group as a quadratic function is called isotropic, but it's maximal isotropic, so that is just easiest way of saying it. Maximality formulating here is saying that the larger group is square in size. So So, Lagrangian extensions, I'm skipping that bit, they form themselves a group. So, that will be this group of isomorphism classes of Lagrangian extension. But what is easier to see is this homomorphism, manufacturing out of Lagrangian extension, manufacturing an ordinary extension of abelian groups. And that is that is straightforward because G. Um, that is straightforward because g sits inside L, but then we can use this by character to turn any element of L into a function into a character on L. So really we have a homomorphism into the dual group on L. But yeah, we can just look at how these characters on L restrict to G. And then this homomorphism will be subjective because the bi-character is non-degenerate, and the kernel will be exactly G. Will be exactly G. So that is going to be an honest extension of groups, short exact sequence of groups. And that is this homomorphism. And so what these interpretations say in particular is that those Lagrangian extensions which give rise to split short Split short exact sequences like that, they will all have to come from quadratic functions, which are effectively characters of order two. So they will satisfy, they will be trivial by multiplicative, and they will still satisfy this equation which is supposed to discriminate linear things, but there will still be some PTA. Of a PTA. And that is where I probably should stop. So that is the example which is not possible for this class of groups is not interesting for Vogomolov multipliers because for abelian groups, Vogomolov multipliers are trivial. But for this next degree filtering, For this next degree filtration, even for abelian groups, even the smallest filtration component can be not trivial, but yeah, for very special abelian groups for two torsion groups. So that is it. Great. Thank you, Alexi. Any questions for Alexi? Questions for Alexei? Yeah, Carlos. So, Alexei, so I don't understand well, but then you give a proposal for Pokemon Lord multiplying dimension three? It's yeah, it's hard to say which one is Pokemon multiplied, but yeah, what happens is in uh what what I what I was mentioning and not without. Mention it not without without properly writing it is that in any degree, so Hn will have a filtration like that, but it will have n terms. And that's, sorry, n minus one terms, n terms counting the whole HN. So there will be HN and there will be n minus one subgroups in it. In H2, it's just Mogomolt multiply. In H3, we'll have two subgroups, H1 and H2. two subgroups h1 and h2 and h4 will have three and so on so that um that is uh that is yeah sorry uh and well we try to to find some definition of pokemodel multiplying dimension three yeah with some students but at the end we fail but we arrive sometimes sometimes to some double presentation of groups no it appears in your work double presentation i will i'm not sure I'm not sure I know what double presentation is, but there is certain doubling. So I'm not sure if it's the same, maybe, but let me take time. Maybe I'm just scrolling it. Sorry for flushing. That will be quicker. I want to go back to the double complex and And maybe I'll just do this. Sorry, please close your eyes. Okay, double complex. So here's double complex and then how the homomorphisms come about. It's really the double complex computes something which is cognomy of the symmetric product of g's itself with adjoint action, which is just g cross g. Which is just G cross G. And so in this interpretation, so yeah, that is a doubling, which might be what you're looking at. No, I will check it. Yeah. Yeah, but again, my motivation was totally different. I wasn't really just trying to construct something. I was trying to see how to get categories with the same rank with the same fusion rule in one with twisted doubles. Doubles and out of that, yeah, this is already like some sequence of discriminating conditions, which is supposed to give some filtration. And it's all now that the components of this filtration, all those associators which give the same rank and the same fusion rule, they form subgroups, not just subsets. That was a nice surprise. And then, yeah, something to Yeah, something familiar was coming up when we looked at the problem in this sort of way of minimal extensions of their cross-G category counterparts. No, no, thank you. I know I have to see your presentation in detail. Okay, yeah, but yeah, hopefully I will manage to complete the paper sometime so in a couple of months. In a couple of months, and then you'll have all the details. I guess I have a couple of questions. Maybe since we're on this slide, I'll ask for a little clarification. So it sounds like you're basically using this figure here to define for each N, you'll get a filtration on CN. So how exactly does that work from this double complex? Because, like, you're not just taking the kernels of these individual dotted arrows, right? No, no, no, no, it's sort of It's sort of making this double complex smaller, so chopping it. We could just chop it along this first level, and then we'll have a homomorphism from ordinary complex to this. Or we could, yeah, can I highlight it like that? Or we could just chop it up to here. It's not, it's not here. Like, we can keep this, keep this truncation. Keep this truncation of the double complex and look at the kernel into this, and that will be finer. And then we could keep up just chopping higher and higher and looking at the kernel. But it will be only giving us new answers if we go far enough to the right. Sure. So you could also use the filtration, the vertical filtration, right? So will you get you won't get a different answer that way? Is that I'm not sure we can use it really. Oh, maybe. Oh, maybe sure if it will be possible. But yeah, maybe you're right. Maybe I'm just not seeing it. Maybe I'm not seeing it. Yeah, it's good to look at, but I'm not sure because from the categorically motivated point of view. Yeah, somehow it's like maybe if I can scroll back again, I can point to something. I can point to something. Again, sorry for damaging your eyes. So this is a Tuka cycle. This is not. Somehow there is a certain sidedness in these two functions. This was the function controlling the just cross-G structure, the coherence for the action. This was the function making sense of the tense product cross-g. Making sense of the tensor product, cross-sense of the tensor product. So, this is a toker cycle, this is not. It becomes really e-tukacycle when it comes together with this, and it is a took a cycle of this truncated complex. So, that's what makes me suspicious if we can chop it vertically, because then we'll just see this first and then it will be paired with that. But this is not a tuka cycle in sort of at least straightforward naive way. Okay, yeah, interesting. Um, yeah, interesting. So, I did have one other question. So, it sounded like you were saying you could construct examples of fusion categories with the same fusion rules using this. Right. So, yeah. So, can you get them in Yard Schauernberg examples this way? Maybe that's a yeah, I was going to check is if this had been. To check is if the Sabelian case gives the same answer, but yeah, as I was saying, the student left the program and I moved it to the site. But we were doing that and then Schumberg's paper came out and we, yeah, he beat us to do that, but yeah, we wanted to compare. But so, is it feasible then with the calculations you did at the very end, where you had a Very end where you had abelian groups. So, is it clear that you can always construct abelian groups where this filtration is non-trivial? Yeah, so just the two groups should. Okay, cool. Any other questions? Yeah. Yeah, sorry, I will come back to my previous question. Yeah, is it possible to find or is it rational to have some hot formula? Some, yeah, okay. Yeah, okay. That's not the way I'm looking at that. That's not how I think. I can't say much. I know that hope formula for Bogomolov multiply is really useful, but yeah, that would be really sort of looking at the homology incarnation of this filtration. Can't say much. Can't say much. Anyone else? All right. Well, thank you, Alexi. This is very nice. Oh, thank you so much. It was pleasure.