A little bit on what Peter mentioned in the end about the coherent sets or the Gary Frodand approach. So this is joint work with Maxim, Gary Frodand, and Peter Koltheim. So I will give a little bit of motivation. Okay, so we can consider some type of Some type of maybe atmospheric or oceanic movement. In this case, this is images from the ocean. And you see these little swirls or streams. This doesn't have to be blobs, but they can also be longer structures. And these are somehow staying somehow together over time. Whether they really stay together over time in a particle sense or not is a different question. Or not is a different question, but generally we consider particles that move through a time-evolving drift field. And generally, as a physical system, they do have some minor diffusion. And then we do find these like regions that over time still somehow stay together. They don't mix very well. These are these coherent sets, which we will describe in this talk. So the mathematical set. Mathematical setup that we consider is that we have some physical space which I will denote by x. And for simplicity, we are in Rd, so finite dimensions and compact. A smooth boundary will be nice for some normal boundary conditions. And the dynamics that we consider is just simply a time-evolving, so non-homogeneous drift field and some additive small noise. Noise. And so, for some initial condition in these space, we can just let the system evolve. We get some densities or so, depending on the Brownian noise. But so far, we have this time dependence on the drift field. And in general, if we just consider any drift field, then long-time estimates will be almost impossible to make because we can't have any asymptotic behavior if the drift field is like. Behavior if the drift field just like changes over time as much as it wants. So Freudland and Kolthai in 2017 considered the setting where they assumed that this field is periodic in T. And this is of course rather restrictive for many applications. So what we consider today is that there might be multiple parameters that change over time with different periods. And just for completeness sake, we will always assume that this is divergence tree so that our equation. Divergence free so that our equations look a little bit simpler. Okay, so how do we model this? So, additionally to the physical space, we introduce parameter space. So, this is just if we have k parameters that have each their own period, then we consider as a parameter space just the k torus. And these parameters is what I call the driving. They just change by some vector alpha. They just change by some vector alpha, where alpha is a rationally independent vector flow. And then I have the driven system, which is just the SDE that I just described. And now our initial conditions have grown. We now have an initial parameter condition and an initial point where we start. And since we choose this question independent, we know that this flow is ergodic. So it kind of looks like. So, it kind of looks at the entire state space. So, I will have an example of how something like this could look like to motivate the coherent sense. This might be this. So, on the left-hand side, we have the parameter space. So, in this case, we just have two parameters, and they have different periods. So, this will be an ergodic torus rotation. And on the right-hand side, we do have some vector field. So, our domain x is just Main x is just, yeah, for example, some square in R2. And what I mark with these kind of like regions here is these are just level sets of the vector field. And somehow we can imagine that if we put particles only on one side, then they will more or less stay in just that one side. Or we put like blue particles on one side and red particles on the other side, then over time we might expect that they maybe stay together or not. That they maybe stay together or not. And this is kind of what we would like to find. Okay, so to go away from the particles to distributions, we will consider entire particle distributions, so just L1. This shouldn't be M, this should be an X. And they, of course, evolve according to the Fokker-Planck equation, but actually, this equation will, or determine. This equation will, or the terms will not matter for us at all. We do, however, have some reflecting boundary conditions, so no boundary conditions. And the operator that we consider is the peritrobinous transfer operator, so the forward operator. So we have some distribution, some starting parameter. Now I don't say time zero, I rather say a parameter theta zero. So I have some initial state, then the current parameter. Then the parent-Robinius operator tells us how the distribution of particles looks like over time t. And note that we can also like those distributions only have to be integrable, but they can have negative values. So negative particles, positive particles can somehow cancel out. And what is a nice property of this is that this has a cosign structure because we have kind of like a skew product flow in the sense that like if I Um in the sense that like if I first let some time involved in the parameter changes a little bit and then running some extra time t doesn't doesn't change anything. So this lets us like kind of consider this in a study Yapunov exponents and something like that which we will get to now. So if we have any distribution then over time since there's a diffusion and the distribution will like always kind of level out because we have a compact. Always kind of level out because we have a compact. So, any distribution, if we let time run to infinity, will just converge to some constant function. And well, since the parent-Forbenos operator somehow conserves entire mass of particles, this will converge to the integral of this function. So, what we can also see is that if we have a constant function in the first place, then nothing changes over time because we have a divergence-free field. So, what we can do: Field. So, what we can do is just kind of throw out all the constant terms and just consider functions that integrate to zero. And any function that integrates to zero will just decay to the zero function over time. And this is kind of how we can study the, let's say, coherence of these functions. So, the rate at which a distribution converges to zero, we can describe by the Lyapunov. converges to zero we can describe by the Lyapunov exponent. So this is basically speaking that the norm of our the L1 norm of our functions kind of behaves like e to the Lyron of exponents times t. So this will always be some negative values because they decay to zero. And heuristically we can see that like if a Yapunov exponent is rather close to one, so a large Yapunov exponent Large upon exponents in like a negative sense, then we kind of have that the positive and negative parts like kind of move around a long time next to one another before they kind of level out and form a constant function zero. So we would assume that these particles may stay together longer. And on the other hand, if the function like the positive and the negative parts kind of like level out very quickly, then we would assume that the particles are mixing a lot and I put mixing in. I put mixing and quotation marks because in our body theory mixing might mean a lot of different things. So then, for all of these Yapunov exponents that we found, we can consider the Yapunov spectrum. And I did cheat a little bit here. I did drop some almost everywhere under the carpet. But basically, this Yapanov spectrum is just all the different Yapunov exponents that we can find. And since our parameters We can find. And since our peripheral Binius operator has quite nice properties as a compact positive Markov whatever operator, we know that this Yapanov spectrum only consists of some discrete points. It starts at zero, which is just like a constant function, would behave constantly. It doesn't decay, so this would have Japan of exponent zero, it stays constant. And then the decay rate goes all the way up to infinity, and we can imagine something that. The way up to infinity, and we can imagine something that has like a lot of ups and downs, hills and valleys, would have very, very, would decay very, very quickly to zero. So this actually goes all the way to minus infinity. And this here means that, so if we have some detail, let's say somewhere here between lambda 3 and lambda 2, then all the ones that behave quicker than that are somehow finite-dimensional. So the co-dimension of everything that decays. The co-dimension of everything that decays slower has a finite codimension, which kind of like tells us that these basically have finite multiplicities, which will be then later important for something like Moselle that splitting and so on. And we had on the slides two before that somehow heuristically large Japanov exponents or Japanov exponent close to zero means that they uh are that these functions might indicate coherent sets. might indicate coherent sets and this we describe on the slide. So if we have some time-dependent subset, so AT, so A is some space in the domain that can change over time, this is where we would want the particles to stay in for a long time. Then we can consider how does the probability behave that I stay in that like a particle stays in AS for the entire duration until time T? The entire duration until time t. Of course, this will kind of like start at one and then decays to zero. So, again, we can consider the exponent at which this decays. And then Gary Froden and Peter Kalte found the following theorem, which actually extends over the periodic case, so this holds in general. That if I have some function of a certain Yapunov exponent, then I can consider the positive sets of the function and the negative sets of the function. function and the negative sets of the function, so the parts where the function is positive or negative over time, that these sets in fact decay slower than the Lyapunov exponent governance. So if we find a function that has a Lyapunov exponent close to zero, then we also find sets that are coherent as as coherent as the, or at least as coherent as the Lyapunov of the function was. But the problem is that kind of like determining the Lyapunov spectrum and finding functions that admit these, which we would like to do in order to get the coherent sets, isn't generally very hard. Or like, I mean, determining Yapanov exponents is, I think, famously hard. And something that we can do much better numerically is somehow find the spectrum of an operator. Find the spectrum of an operator and finding eigenfunctions of this operator. And somehow we would like to solve this problem by solving something like this. But kind of what prevents us from doing this is that the Lyapunov spectrum describes an asymptotic behavior as t goes to infinity, whereas a single operator would just be like a static object and we don't have any like time dependence of this operator. Dependence of this operator. So, somehow, if we want to find an operator that bridges this connection, this operator needs to encapsulate the entire time as t goes to infinity. And the way that we can do this is that we manage to capture this like infinite time sequence of t to infinity by observing that actually what the only thing that this depends on is the parameter. Like these, and what we saw in the picture, there's like two parameters that just. Saw in the picture, there's like two parameters that change over time. And these are in this k-torus, which is big theta, and that is compact. So we can kind of capture the long-time asymptotic in a compact parameter domain. And then we just consider not one distribution changing in time, but rather an entire family of distributions for each parameter, we have one distribution. And then we can consider what is called the Martha evolution semigroup. Evolution semigroup. So this basically, I can't draw this. If this would be, let's say, theta, then for some point we would have some kind of distribution, and for some point in the past, we have a different distribution. And then if we let's say this goes back by time t, then if we Then, if we let this entire system evolve, then what by time t, then we just like to find what the distribution is in this point. So, this would be n t of my entire function f in this point. We'd just be taking this function of time t back. So here we go, time t to the past, and then let it evolve forward in time by t, and then we might maybe get something like this. So, this is what the smart evolution. So this is what the smart evolution semi-group does. And it has a generator. Okay. And this generator actually has very nice spectral properties. And it turns out that at least in the periodic case, one found that this cryptic-looking generator of some group that, semi-group that we constructed, actually, so in blue is the entire spectrum, it forms this bar. Spectrum, it forms the spark pattern. So actually, one can prove that these always just extend to the imaginary axis. And they have discrete values, and these discrete values precisely land on the real axis on the Lyapunov exponents. And so we managed to describe the Lyapunov exponents now in terms of the generator or the spectrum of the generator. But of course, we would also like to find eigenfunctions. But of course, we would also like to find eigenfunctions. So we can look at the point spectrum, so values of the spectrum that actually have an eigenfunction. And it turns out that also these are not everywhere, but at least like the real parts match. So this was, I would think, a big success of the theory. And now we would like to find something like this, not only in the periodic setting, but for the multi-periodic setting. So with the multiple parameters that With the multiple parameters that we considered. But in general, it does not hold. So, for example, we wanted actually at first to consider general ergodic driving systems, and it turns out that this failed quite spectacularly for something like a Lorentz attractor or something like that. Because what might happen, even in our setting now, is that the point spectrum might be empty, so we will not find any eigen. But we can still maybe see that the real part of the spectrum might coincide with the. Coincide with the Yakunov spectrum so that we at least can determine the rates at which sets might be coherent. And for this theorem that describes which conditions this hold involves the nosalitate splitting. And I will not go very deeply into this, so I will omit quite some details about what an ozelite splitting is. But formally speaking, an osalotate splitting is our Is are finite-dimensional subspaces that depend on the parameter theta, which kind of like capture the functions that admit that particular Lyapunov exponent. So for each Lyapunov exponent, we have a space that consists of the functions or the characteristic functions that admit this Yapunov exponent. This should be, of course, invariant under time because the Under time because the Japan of exponent doesn't change over time. And this is generally known for like classic theory and is always just formulated for almost every parameter. So there might be null sets for which this might fail. And it turns out that in our setting, because we have an entire operator, the operator doesn't care for null sets or not. The Yapunov exponents and those elements. Exponents and those elements, everything is like as an ergotic theory is commonly done, only done for almost every point, almost every theta. But it turns out that even null sets might create spectral points in this generator G that will like make this spectral connection not possible anymore. So, what we actually need is a Bosillian splitting that is uniform and continuous, which means that uniformity is means that uniformity is that it holds everywhere, not just almost everywhere. The convergence to the Yapanov exponents is uniform in theta, and that these spaces are, they usually might be measurable, but here we actually need that they're continuous. So somehow we would have that if this is now on the main theta and here at this axis I have L1, then we really want that of Of the each of the uh uh or the let's splittings might be like kind of a graph of a continuous function over the parameter domain. Which leads us to the kind of like main finding so far. I mean, this project is still very much work in progress, and we have not found a conclusive answer whether this works or not, but we have at least found this. But we have at least found this connection, or like this theorem, which is that the spectral connection that we would like to hold holds if and only if the parent Robinius operator admits a uniform and continuous ZLED splitting. And that is indeed already like kind of a useful result. Actually, both directions of the if and only if are useful. On the one hand, we have that if we can find that our parent Frobenius operator is sufficiently regular that we do have a uniform and continuous. That we do have a uniform and continuous ausonetic splitting, then we know that the spectral connection holds. On the other hand, for some previously studied systems, we know that this connection holds, so we actually know that there is like a uniform and continuous Azelli splitting. And something that is not listed here, which is actually, at least for me, a very kind of like nice point about this theorem, is that it kind of like shows in which direction one has to look. In the beginning, we didn't expect this entire machinery that we need. Like machinery that we need to be strong enough to claim something like a uniform and continuous azilli splitting. There's many systems that already are very easy to show that they don't fulfill this condition. So it allows us to already eliminate a lot of systems that might not be able to satisfy this condition. So as the next goals, we would kind of like study what conditions we need for these. What conditions do we need for these uniform and continuous azillid splitting to exist? So, one of them is, for example, that our base driving is uniquely ergodic, which is luckily the Taurus rotation is, but something like a Lorentz attractor is not, so we can already eliminate that one. Then, actually, we never used any properties of the parent-for-benius operator other than it being a positive Markov operator. So, we might have like a different base dynamic. So, not. So, not like something like a Fokker Planck, but maybe a different type of transfer operator. And then we still need to numerically extract the coherent sets because, as we've seen, there might not even be eigenfunctions. The point spectrum might be empty. So, somehow we can find the Yaponov exponents numerically, but we still need to find the coherent sets, but we at least know that they exist. And then we would like to apply this to some real-world data, for example. This is to some real-world data, for example, atmosphere or ocean, to actually see whether these methods work in a higher-dimensional context. So that concludes the talk. Thank you very much for keeping the time too, and the floors are open for discussion. You're assuming that you have irrational ratios between the driving frequencies, which in some sense gives you a rhodicity, but in some sense it's violated in certain situations. I don't know. How critical is that? I mean, if you have if you still have parallel flow and it's been periodic at a high period, what's that still um so do you really like that periodicity for all of that or is For all of that, or something closer now, could it happen? I don't know. I don't know whether I understand the question correctly, but if you have some rotation which is where not all the periods are irrational to one another, then you can just take two of the periods which are rational dependent and just kind of collapse them into one period because you can just take the minimum and then just like you know. Yeah, and then just like you know, have one larger period where you and then you reduced the dimension, you maybe have made this space a little bit so make the period slower. That's of course true, but I'm thinking say in applications, right? I mean you hard to verify and you can do this, but they would need to know that very exactly very hard. Generally, I would not, I mean, I don't know, maybe Peter has something to say to that, because he's very much involved in the project. I would say, like, Because he's very much involved in the project. I would say, like, I mean, at least what I presented here is a very, let's say, theoretical work until now. And I will think about the problems and application when we actually get topic. But in pets. Yes, just one comment. How I would frame perhaps what Ben is asking is: if the torus rotation wouldn't be ergodic, would the constructions of your collapse? Constructions of your talk collapse to results of Gary's and my paper. That could be one way to phrase it. If you have two frequencies for example, exactly. So you have a multi-periodic system, but what if it's not a multi-periodic, it's a single period, it just looks like uh you know a rationally dependent step on the torus. We even consider, you know, rational approximations of the matching numbers to How some sort of you know what what is this in between? How bad is it? Anyway, this is probably some coffee break. So perhaps come back to the slide where you introduce the Yeah, so here you say that it's much simpler to determine the spectrum of this G. I think you said that it's because G is a set operator now on some space of distributions. But I don't really um so I get that this might be more convenient. Ah, uh uh uh your uh um I don't uh but with an actual X sample system and you want determinants in spectrum, I don't see how determining a spectrum would be more simple than computing would be in a which kind of So my question would be in which sense is this actually more simple? I do have to admit I am not an expert on the determining spectra of operators. I've assumed from what I've seen in the maybe literature or another talks or so that if we have some generator and we want to do this numerically now, that like numerically Now, that like numerically determining somehow like a spectrum I would assume that you can, I don't know, maybe find some bounds or like group resolvent or something like that, which I would have, I mean, I have some ideas how to approach this type of problem. I can like write simple code to maybe not efficiently, but somehow to determine the spectrum of an operator if I discretize them in some way. How to determine Yaponov exponents or the Yapunov spectrum, I would actually have pretty no idea. I would actually have pretty no idea how I would go about that. I mean, you can do this, of course, also with very well-established algorithms, but of course, you always need the asymptotic time aspect to that, right? So you have no complete security grid aspect. You have the grid s aspect on the other side. But still, I mean, it's it this change but then you have at least a variability, right? So if you if you don't know really how how well your your system will How well your system will approach the cyber spectrum, and sympathetically, at least if you can go to the spectral approach of the operator, at least you have two ways to how you will be able to express it. At least it gives you some flexibility based on the problem. Go ahead and put your conclusions file back up? Do you think you'll ask for this? Yeah, I don't think it will. Thank you. Um so again, just thinking about your last uh point here about the application. Here about the application of normal data and thinking about the fact that if you have an oceanic or atmospheric problem, that the associated parameter variability may not be on the torus. Do you have, and I've not even done this yet, but do you have a sense for how you have a more turbulent flow, that that last bullet point might be in conflict with your first bullet point of the uniform continuous enzyme enzyme that's splitting? Sorry, I don't think I quite got it. So, what do you mean with like that it clashes with these two? So, you mean that like I mean I will very much expect that like these are kind of like more of a rectification justification of uh why we might apply our theory in in the first place. But of course whether it then like works uh in in application or not is uh An application or not is a completely different topic that has to be seen empirically. And I was wondering, do you have any intuition about that? If we can have a turbulent flow problem. I would very much expect that already one has a little bit of problems when applying it to the real world data, in the sense that a lot of the kind of like mathematics behind what I was talking about here are very analytical constructions, are very analytical. Analytical constructions or very analytical properties, like talking about problems of null sets, there is, of course, something that the application doesn't care about at all. So I would assume that actually like kind of the these two points, or like kind of like what these two points are aiming to do is, let's say, a different type of project than doing this. It's not that like doing these so that we can have a good application to a real. Can have a good application to real-world data. This is rather just like we do this to have kind of a theoretic background and maybe have some theoretical paper on this. And then let's do some application, which might not have to do anything with these two. Okay. Thank you very much. 