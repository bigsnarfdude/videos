Not yet. Okay, there you go. Okay, that's fine. You guys are just quiet. My channel. Okay, good. I think. Okay. You're already so well dressed. You put the rest of us together. Participants on Zoom, can you hear me? Yes, yes. Okay, excellent. All right, so we're going to start now with our talk on moments of alfunctions, which is one of the themes of the CRG. I'll be giving the talk with Nathan Ink. We'll alternate on some of the slides. So here's a plan for the talk today. We're going to talk Plan for the talk today. We're going to talk about moments of alf functions, but with emphasis of families of alfunctions that are of interest to us. So we'll start with moments of the Riemann Zeter function, just give an overview of the results on moments and recent developments, moments of quadratic alfunctions, moments of alfunctions associated to automorphic forms, and we'll very briefly talk about the multiple Dirichlet series and spectral receptors. Dirichlet series and spectral reciprocity approach to studying moments. And then I'll talk about discrete moments of the Riemann data function. So that will be, that'll end the kind of colloquial style talk. And then after that, we have a list of projects and open problems that we would like to tackle. So we're going to talk about these problems. And along this discussion, we'll perhaps talk about online working groups, FRGs, just who's interested. Just, you know, who's interested in working on which problem, and we'll plan accordingly. So, that will be so. The colloquium talk will be about an hour and then half an hour for that discussion. All right. Okay, so for moments of the remedy of function, we're interested in the 2kth moment of theta at half plus it. So, here we denote that by i sub k of t. So, i sub k of t is the integral from 0 to t of the integral from 0 to t of the absolute values of 2k of data at half. So these are the 2k moment of the Riemann data function along the critical line. Now, and we're interested in understanding the asymptotic behavior of this quantity as t goes to infinity. Now, the studying the asymptotic behavior of this quantity really was motivated historically, was initiated by the deep interest and the strong desire to understand. In the strong desire to understand the size of the Riemann data function on the critical line. So, to this end, there is a famous conjecture, one of the most famous conjectures in Arloic number theory, Lindelof hypothesis, which is the assertion that theta at half plus i t is less than or less than t to the epsilon for any epsilon positive as t goes to infinity. So, that's the Lindelof hypothesis. And as it turns out, so the idea here is that when we are The idea here is that when we're, you know, instead of studying, instead of studying zeta at half plus it point-wise, particular t's, why don't we study it on average? And that's why we're studying these moments, I sub K of T. And as it turns out, one can prove in a relatively straightforward manner that the Lindelof hypothesis is equivalent to the statement that for any epsilon positive, the two kth moment of the Riemann data function is big O of t to the uh t to the one plus epsilon for all positive integers. For all positive integers. All right, so now let's focus on this asymptotic I sub k of t being big O of t to the 1 plus epsilon. What do we know in that direction? Now, it's widely believed, a folklore conjecture, is that I sub k of t for large values of t is asymptotic to c sub k t log t to the k squared for some unspecified constant c sub k. Now, what cases of this conjecture? Alright, now what cases of this conjecture do we know? Not so many. We only know the cases, and the unconditional results are for k equals 1 and k equals 2, so for the second and fourth moment of the Riemann-Radium function. So Hardy Littlewood, in their attempt to get results towards the Lendeloff hypothesis, they proved in 1918 that I1 of t, this is sort of the second moment of the Wiemann data function, is asymptotic to t log t. So that kind of verifies this conjecture. kind of verifies this conjecture with the constant C1 being one. And Engel then elaborated more on this question and got an asymptotic formula with a power saving and the error term. So t times some polynomial, well linear, degree one polynomial log t plus equal t to the one-half. And in this case, it is conjectured that the error term should be of The error term should be of size bigger of t to the 1/4th plus epsilon. And as far as I know, the state of the art here is t to the 0.31. And I think it's a result due to Bourgain and Watts in 2017. All right, so the fourth moment of the Riemann-Zeta function. So in that same paper where Ingham studied the second moment of the Riemann-Zeta function, he's also studied the fourth moment, I sub2. Also studied the fourth moment, I sub 2 of t, and verified that it's asymptotic to 1 over 2 pi squared t log t to the 4. So again, that verifies the conjecture for k equals 2, with c sub k being 1 over 2 pi squared. And then 50 years later, Heath Brown improved this asymptotic formula and got a power saving error term. So an error term of big O of T to the 7 over 8 equals an epsilon. In this case, it's conjectured that the error term should be big O of t to the 1 half. term should be big O of t to the one-half plus epsilon. And what we know is right now the best result towards this is big O of t to the two-third plus epsilon. Sorry. Yeah. Pull back. Does P2, is that mean it's degree? Degree, that's degree four. So it's T log N. Okay, so the index is for the moment, not for the degree. Yeah, yeah. Uh yeah, that's the degree four volume. Yeah, you should be wondering why it's P2 and not P4. Yeah, perhaps a more intuitive choice would have been maybe P4. All right, so that's about it for unconditional results towards the asymptotic formula for R sub K of T. But we do have some lower and upper bounds that are of the right order of magnitude. right order of magnitude. So Radzivill and Sound in 2013 they showed that for all positive real numbers k, we have that I sub k of t is bigger than bigger than t log t to the k squared. And then there's another result by Sound and further improved by Harper. It's conditional on the Riemann hypothesis. It gives an upper bound when bio optic regulators. All right. Now, let's Now, let's go back to integral moments, even integral moments. We have conjectures. So, remember how we said that I sub k of t is asymptotic to C sub k T log T to the K square. So that's a wide, that's our belief. But it went for so long that we didn't have even conjectural formulas for this constant that appears in that asymptotic formula until 1998. Until 1998, where Connry and Gosh gave a conjecture, gave a more precise conjecture for the sixth moment of the Riemann data function, I sub3 of t. And they conjectured that, well, it says simply as we know, or as we expect, t log t to the 9 times an explicitly given constant. They've written it as a product of two factors, G sub three, which is usually people refer to it as the geometric uh fa factor and A sub three being the arithmetic factor. 3 being the arithmetic factor. A sub3 is a convergent oil product, as you can see. And G sub3 in this case is 42. And then around the same time, Henry and Garnick, they made a conjecture. They actually made a conjecture also using different methods on the sixth moment, and also they made a conjecture on the eighth moment of the function I sub 4 of t where they explicitly determine what that constant in the asymptotic formula should be. And you can see. Should be. And you can see it here on the slide. And then around the same time, almost exact same time, Keating and Snaith used random matrix theory, so a completely different approach, and came up with an asymptotic formula for I sub k of T and precise conjectures for what the constant C sub K should be for any positive number K. So, and as it turns out, if you plug in 3 here, you'd get 42, which is what Conry and Gosh and Conry and Garnick predicted. And if you plug in 4, you'd also get what Conry and Garnick predicted for the Riemann, for the eighth moment of the Riemann function. Alright. Now, Now, recently there has been a lot of work on this topic. Nathan Ing proved that the conjecture of Conrigonik and also Keating and Snafe for one K is 3 is true under a ternary additive divisor conjecture. I will say something very briefly about the connection. What do I mean by these additive divisor conjectures? But Nathan showed that isactive. Nathan showed that I sub 3 of t is indeed asymptotic to 42 divided by 9 factorial times A sub 3 T log T to the 9 as T goes to infinity. And also in collaboration with Chang Li Chen and Penji Wong, Chang Li was a PhD student with Nathan and Habiba and Penji was a PIMS postdoc at Lethbridge working with Nathan and Habiba as well. So they showed that under a quaternary additive divisor conjecture and Additive divisor conjecture and the Riemann hypothesis, we have the expected SMP formula for the eighth moment of the Riemann state function. Now, what goes into a proof of this result? Of course, the proofs are highly technical and complicated, but the point of departure in these kind of proofs is usually an asymptota- an approximate functional equation. So you represent the values of the Riemann Zeta function on the critical line. function on the critical line by some short duration polynomial or a rapidly decaying influence series. One of the most powerful approximate functional equations is a smooth version due to Heathbrown. So instead of using an approximate functional equation for theta at half plus I d and then raising that to the power of k, what people, a better idea would be to get an asset, an approximate function. Get an approximate functional equation, y for theta at half plus i t to the 2k. And use smoothing here so that we can have a better error term. All right, so we can represent the values of zeta at half plus i to the power of 2k in terms of this infinite series weighted by this rapidly decaying smooth function phi up to a certain error term. And then And then, you know, well, our interest is in I sub 0 t, so we would need to integrate against t from 0 to t. So you integrate both sides, you pull that integral into the summation, you do a little bit of computations where you isolate the diagonal terms coming from m equals n, and then the off-diagonal terms coming from that double sum where m is not equal to n. Yes? What is the other factor? What is the other factor of the gamma factor? Oh, the gamma factor, yeah. Would it be in this case, would it be in phi? It's in phi. In phi. Phi is a transformer. Okay, so it's phi. Yeah, so and then in dealing with, so the diagonal terms are usually easy to deal with. Now for the off-diagonal terms, With. Now, for the off-diagonal terms, you'll see that with some manipulations, sums like that will appear. These are what we would refer to as additive divisors, or sometimes they refer to as shifted convolution sums. And as it turns out, the problem now boils down, and somewhat boils down to figuring out an asymptotic formula for these sums with an error term that is uniform. An error term that is uniform in an appropriate range of R. Once you plug that in, so that's basically kind of like the very rough framework of how these things work. And another thing here is that, you know, this shows us the intimate connection between moments of the Riemann data function and what we're going to refer to as mean values of short Dirich-like polynomials. So if you look back, if you look again here at this approximate function equation and Approximate functional equation. And if we're not being careful or anything, just ignore that factor of that smoothing factor of five mn over n. And if you just replace it by a short cutoff at n, basically you would see that this sum here right here is a short Dirichlet polynomial, a sum from n equals 1 to infinity, d sub k of n over n to the half must i. n over n to the half plus it in absolute value squared. That's more or less, that's what it is. And then when you're integrating both sides with respect to t, you'd see that, roughly speaking, of course, I mean the relation is more intricate than that, but you'd see that the two-kth moment of the Riemann data function can be very well modeled by mean squares of Dirichlet polynomials. In this case, I said short, I should stay long. Most of the interesting. Should stay long. Most of the interesting cases where our Dirichlet polynomial, the length of the polynomial, will be longer than the length of the interval we're averaging over. And so this has been this paradigm, its connection between moments of the Riemann data function and mean values of long duration polynomials. It started with, well, it was investigated in Conry. That's so that it focuses back on the slides. In the Conry Gonick paper, where they established an asymptotic for the sixth moment and a conjectural asymptotic for the sixth moment and the eighth moment. And then in recent years, starting in 2015, Conrie and Keaton took up this project and elaborated, studied this relation extensively. But instead of looking at the two-case moment of the Riemann data function and mean and mean. function and mean and mean mean squares of long Dirichlet polynomials associated with the classical K divisor function, they looked at mainly at shifted moments of the Riemann data function and Dirichlet polynomials associated with shifted versions of the divisor function. So in a series of papers they established this relation, they elaborated on this relation and then came up with many conjectures on the asymptotic form. On the asymptotic formula for mean values of long-Richelier polynomials. And in recent work with Nathan, we were able to prove some of these conjectures regarding the asymptotic formula of a certain type of long Dirichlet polynomials associated with the shifted divisor function under the assumption of a smooth additive divisor function. Smooth additive divisor sum conjecture. So we had to kind of assume that some of this form with the D sub K and D sub L is replaced by the shifted versions of these functions. And we have to assume that this satisfies, you know, you can come up with a good conjecture using the delta method of Duke Friedlander and Iranik. And under that conjecture, Under that conjecture, under that assumption, we prove a result on mean values of long Dirichlet polynomials. Now, in particular, the statement of the result is pretty complicated, and that's just an overview talk. So I'm not going to go into the details of that. But one of the consequences would be a result about mean values of long duration polynomials associated with the regular divisor. The regular divisor function. But our work should give us a result like that, a more general result like that, with DSAP to be replaced by DSAPK. So as I said, this work was initiated and elaborately studied. They made a lot of predictions communicating in a series of papers. And there has been an influx of work in the recent years on investigating long Dirichlet polynomials associated coming from. Polynomials associated coming from various moments of various families of L-functions. For example, very recently, Baliu and Caroline Turnh Bacherbaug, they considered this problem with the Dirichlet polynomials associated with Dirichlet L-functions associated with characterism on Q. Q goes to infinity over the heinth. Goes to infinity over the primes, and then Conry and Rogers they have a similar result for quadratic Dirichlet L functions. And Conry and Fasari have a result on Dirichlet polynomials coming from studying moments of model functions. Yes. Hi, Adia. Um is the P of eta any typo independent of T? P of eta. E of eta. Yeah. Eta of eta. Eta is here. It depends on T. Eta is depends on T. Yeah, yeah, for sure. As a matter of fact, in our work, we even get an asymptotic formula with not just this main term, but some lower-order main terms and a power statement in them. So how complicated? Well, I still don't understand the integration is over T and how eta depends on T, so R. Yeah. By saying T, they mean little T. Little T. Oh, that's why the capital T is entity. Yeah. Yeah. Well, that makes more sense. Okay, thank you. All right, that's fine. This capture. This captures like one swaps. Zero swaps and one swaps, yeah. Yeah. Up to one swaps. Because, yeah, because eight is less than. Yeah, yeah. Further would be very difficult. Yeah, we should, I mean, theoretically, we could push it even further. We could push it to, what is it, 1.61, using a recent result of Parzat Aryan on the additive. The additive divisor problem for the regular divisor production. So, I mean, for the regular division, maybe I should say something here. For this kind of problems, we have asymptotic formula, of course, for, you know, when k equals l equals 2. Recently, due to work of Topakivulari and Draco, we have formulas for any K with L equals 2, but that's about it. Yeah. All right. I think now we're Alright. I think now we're gonna start the forward in it. All right. So I'm gonna talk about moments of quadratic Dirty L functions. I'm not really an expert on this, so if there's experts in the room and I say something wrong, please correct me. So Tai D is a character, of course, D is a fundamental discriminant. So there's this conjecture of Connry, Farmer, P. Of Connry Farmer, Keynesian Women Science Nathan 2005 says that the kth moment is asymptotic to ckx log x to the k k plus 1 over 2. And then there's a more general thing with a polynomial degree k k plus 1 over 2. That explains degree. Yes. Yeah, we didn't coordinate very well. Okay. In the case, so Connery and others, they made a conjecture. And others, they made a conjecture that the error term was size square root of x. And I don't know if they're still sticking to this. In the case k equals 1 for the first moment, I think the conjecture is x the quarter. I think Alderson and Rubenstein suggested that. There's no typo there. K equals 2 should be x to the half plus epsilon. So and for k bigger than 3, there's a paper of Diacano and There's a paper of Diacono and Twist which is suggesting the error term should be size x to 3 quarters log x to ck. Okay, so that's a paper from 2020. So I'm just going to tell you what do we know? Yeah, so sorry, k equals 2, it should say square root of x. So we'll go through this. What results do we know? 81 utiliter the first moment, got the full main term with error term x of 3 quarters, and then And then here's so Goldfeld and Hofstein improved them to X to 19 over 32. Actually, their paper apparently gives X to half plus epsilon. So Young wrote a paper in 2009 with a smooth version getting X a half plus epsilon. But apparently that was already in Goatfeld-Hofstein. So really this error term hasn't been improved essentially since 1985. Flurry Okay, Flory did the function field case and got x a third plus a lower order term. So I'm not sure. I think the order term is supposed to be x a quarter plus epsilon here. That's what I've heard from experts. Maybe people can confirm this. Okay, what about the second moment? This was done by Utila, but he did not get the full main term. He only got the leading term as something a little bit smaller. Sound in 2000 got the full main term with Eritrem XFI6. Florida Flory in 2015 did the function field case, got an error term of square root of x. And Sono also in 2019 did a smooth version of this, got an error term of square root of x. I think this is supposed to be the correct size for the second one. Okay, third moment. Okay, so this is written a little bit different. It's chi 8D. In the other slide, I had chi D, where D is a fundamental discriminant. People write papers. People write papers with this more simpler case because it's just a little bit easier to do, it's just fewer cases. So you could do it for all fundamental discriminants, but maybe, I don't know, adds 10 to 15 pages to the paper, so people don't do it, okay? But it can be done. So sound got the full main term with error term X1112 in 2000. And then here's a whole list of people that improved it. I mean, there's the Diakano Gofelkovsky with the Malta Po Dershle series method, they improved that 1112s. Series method, they improved that lament false. Now, if you remember the conjecture of Connery and others, they said their term should be x to the half. There was a long debate whether it was that or not. In 2005, Jean, Goefeld's student, said it should be x to the three quarters plus a smaller error. And he didn't really prove that, but he said assuming some technical thing on a multiple dirt shape series, you get that. And then about 10 years later, About 10 years later, several people verified, they verified the X to three-quarters error term. So there's a paper of Young and then Flory. I mean, that doesn't really verify it. But in 2018, Diokano did the function field case, and he got an error term of X is three-quarters plus a lower-order term. So I think that sort of settled the question at that point. And then in 2018, Diocano and Whitehead. 2018, Diocano and Whitehead, they did this case here. So with the smooth version, they got X of three-quarters, and then something of size X of two-thirds. So that's super interesting. Now, what about the fourth moment? Chen Li Shen in 2020, assuming GRH, got the leading term for the fourth moment. So that's only one term of One term of there should be 10 terms there in power savings every term. Florey, in the function field case in 2017, got the first three terms. I think her paper actually gives the first five terms, but she didn't do the fourth and fifth term. Now, there's a recent paper of Shannon Lee that came out, I think, this summer, and he did the moment L1 half F justed by Kayate D, and he improved on a paper of Sound and Young and And he improved on a paper of Sound and Young and removed the GRH. And it appears that the methods from Shannon's paper is going to extend to this moment too. And it looks like Shan, Chandli Shan, and Josh Ducky in progress, they have probably done this unconditionally and get some of the main terms here. So there's another recent preprint in multiple Dirches series using multiple Dirches techniques by Dia Kano. Techniques by Diocano, Paso, and Poppa in the function field case, and they get the full main term. So it looks like, and that's in a function field case, it would be very interesting to get the full main term for the fourth moment with the power savings error term. And maybe I could see if people worked hard enough, maybe in the next five, ten years we might be able to do that. So I'll pass F modular form of 10 and 8. Yeah, this is a modular form, yeah. Okay, so Alia is going to continue. Alright, so now we talk about modular L functions, functions associated to modular forms. And since modular forms are perhaps lesser-known objects, I thought to start by reminding you or telling you very briefly what these objects are. Briefly, what these objects are, and then we'll discuss questions about them as pertaining to their moments, to moments of modular functions. So, how do we define a model or form? We start with a congruence with the, I'm sticking here to very specific settings. So, consider the congruence subgroup gamma 0 of Q for an integer Q. It's a subgroup of all 2 by 2 matrices in SL2Z, that is the state determinant 1. Z, that is to say, determinant 1, such that the lower left entry here is divisible by q, so that's gamma 0 of q. Now, SL2Z in general, it acts on the upper half plane as such by Movie's transformation. So gamma z is Az plus B over Cz plus D. Now, what is a modular form? We start with a function that is holomorphic function f that is holomorphic on the upper half plane. So h here is the upper half plane. Is the upper half plane. We say that F is a modular form of weight K with level Q, or, you know, in more words, with respect to the congruence subgroup Q, and a character chi mod Q. If F not only is holomorphic on the upper half plane, but it's holomorphic at all the cusps of gamma zero of Q. I'm not going to go into the details of that, but in a sense, like it, F is bounded as the imaginary part of that. Part of z, imaginary part of z goes to goes to infinity. More or less, roughly speaking, I'm not being very accurate here. And so, and more importantly, f satisfies the following transformation relation. So, f at gamma z is f of z times that automorphic factor cz plus d to the k times chi of d. And that should be true for all gamma in gamma z or q. Now, if f not. Now, if F happens to be not only holomorphic at the cusps, but also vanishes at the cusps, then we say F is a cusp form. The space of, we're going to be working with cusp forms mainly. Well, in this talk, we'll focus on model of forms associated to, on L-function associated to cusp forms. So the space of cusp forms of weight k, level q, character chi is, you know, we're going to denote it by S sub k, gamma 0 of q chi. Now, if it happens that chi is the principal character, Happens that chi is the principal character mod q, then we're just going to drop it from our notation. We'll simplify our notation to that as sub k of q. And a well-known formula, this is a finite-dimensional vector space over the complex numbers, and its size is order of magnitude kq. Okay, so now by virtue of their periodicity coming from that transformation. Periodicity coming from that transformation relation that they satisfy. Cusp forms or modular forms in general, they admit the Fourier series expansion, which gives rise to the Fourier coefficients right here. And these are going to be the coefficients of the Dirichlet series that's going to make our modular function. Alright, so here you can see that lambda of f the term at n equals 0 doesn't appear because Equals 0 doesn't appear because we're dealing with a cusp form that vanishes at the cusp, so the coefficient, the constant term is 0. And then we say that f is normalized if lambda f at 1 is 1. Alright. Now, this space of cusp forms, there's an action of haka operators on that space. These operators, they commute and they're self-adjoint. They commute and they're self-adjoint. Well, I mean, if, yeah, they do commute and they're self-adjoint for most of them. And so there, by the spectral theorem of linear algebra, we have an orthogonal disc of cus forms of weight k, level q, character chi as an orthogonal basis of normalized primitive eigenforms. We're going to denote such the We're going to denote such basis by h sub k of gamma 0 q chi. Once again, if chi is the principal character in 1 q, we're just going to drop from our notation and go with h sub k of q. All right, and here, when I say eigenform, I mean a simultaneous eigenfactor for all the hacker operators. And you know, what's so the modular forms that we're going to attach an out function to, they are from. To they are from this orthogonal basis, so they are all normalized, primitive eigenforms. So, more importantly, their coefficients are multiplicative. So, the lambdas for these are multiplicative. And so, the L function that we're going to create is going to have an Euler product, and that's fine and nice about numbers. So, associated to a modular form F, an eigenform F. form F, an eigenform F of weight k, level Q, character chi is the following Dirichlet series whose coefficients are the Fourier coefficients of the modular form under consideration. And by the multiplicativity of these coefficients, we have this Euler product expansion. One can show, and it's standard textbook material, that this function converts, this series converges absolutely for real part of S big written. Absolutely for real part of s bigger than one. It admits an analytic continuation to the entire complex plane and satisfies a functional equation that relates its values. Here, lambda is basically L, it's L multiplied by a bunch of gamma factors at a power of Q. But the functional equation relates the values of the L function at S to the L function at 1 minus S. And epsilon here is the root number, and it has multiples 1. Alright, so now, okay, so we have an L function, LSF, and we're interested in studying its moments. So what kind of moment are we gonna, what shape does this moment take? So we're gonna consider, instead of just averaging over all, so ideally what we would do, we would take L half f and we would average over all f and h sub k of k. Over all f and h sub k of q. And then, and study, well, not just L half f but powers of that, and study the asymptotics of these as k goes to infinity or as q goes to infinity. But instead of that, we're actually going to consider a harmonic average that's just more practical to use. So, here, this h, which maybe shouldn't be here, maybe it should have been here. I'm not sure what command I use for that. I cannot use for that. But yeah, I should have. Anyway, so the harmonic average over all f in H sub K of Q is basically, so of alpha F, of a quantity alpha F is alpha F, but weighted by this omega F, this factor gamma of K minus 1 over 4 pi to the K minus 1 times the Peterson. The Peterson norm of f squared, that's omega f. So basically, our averages are just weighted by this omega factor. And by a recent, well recent, by very powerful work of Hofstein and Lockhart, you can think about this factor. So this product along with the norm of F is right here. This is basically Q, QK. QK to the power of negative 1 plus little o of 1. So it's kind of like you're just dividing by the size of your fan because remember we said that dimension of this space is approximately KQ. So it's basically like your usual average. It's just like, it's just because we use this harmonic average later point when you're dealing with these moments, you're going to apply a Peterson trace formula and then that harmonic average is just, it appears naturally. It's just, it appears naturally there. But you can go from this moment, when you get an asymptotic formula for this harmonic moment, harmonic average, you can go back and forth between that and the natural average. It's there. All right, so these are the moments we're going to be interested in. So the LF moment of L half F is basically the sum over all F in H sub K of Q chi of q chi of L half f to L. All right, now this one, the way I've written it, I'm interested in it. So to start with, we're going to study these moments in the level aspect. That is to say, we're going to fix the weight k. We're not going to care about it, what it is. And we're going to study the asymptotic behavior of this expression as q goes to infinity. All right, so what kind of results do we have in that direction? We have, right, so let's start with the first and second. So let's start with the first and second moments in the level aspect. So I'll be looking at sums like that, harmonic averages like that. So I'm averaging overall. Here I'm just considering modular forms of trivial characters. So as we said, so we're looking at eigenforms of weight k, level q for a fixed weight k, and q goes to infinity. Now notice here, these values are actually real when because we have we're considering Because we have, we're considering modular forms of trivial nibbon type as trivial character, these are going to be real. All right, so what do we have in that direction? We have a result due to Duke 1995 that establishes the first moment and second moment. And this has been further, so but here, a very important fact is that, so they, Tube does that for a fixed weight k equals. For a fixed weight k equals 2 and a prime level q. So q goes to infinity in the primes. And so if you still fix the weight k, but consider any even weight k, and if you let q go to infinity over the square free integers, which satisfy actually, there's a condition. In their paper, they say not just q goes. Where they say not just q goes to infinity over the square free integers, but it should say five q over q, five q is as a product q. So anyway, they have a result on the first and second moment. Now for the fourth moment, there has been a breakthrough in the year 2000 in the coalescence. In the year 2000, and Kowalski, Michelle, and Vanderkam have a series of two papers on this topic. So, one of them is dealing with the fourth moment of modular L-functions in the level aspect. And they showed that for modular forms of fixed weight 2, as Q goes to infinity through the prime numbers, the fourth moment is equal to P log Q plus an error of size Q to the minus. error of size q to the minus 12 plus epsilon, where p here is a degree polynomial, is a degree 6 polynomial with leading coefficient 1 over 60 pi squared. So their result is way more general than that, but for the purpose of this talk, I'm just going to look at this particular corollary of their work. And that agrees, I mean, the family here, this family is orthogonal in this This family is orthogonal in the sense that there's this philosophy of Kotz and Sarnak where you can categorize families like that. And you can look, you can kind of predict how these moments will look like by looking at the sine and the functional equation of that family of functions. And for this particular family, the sine is plus or minus 1, so it's an orthogonal family. So getting a degree 6 polynomial. So getting a degree six polynomial here is so six is four times four minus one over two, so k into k minus one over two, which is what you would what you expect for the the Convry and Convict names. What you would predict as an asymptotic form. And improving on this work, Baltanova and Frolenkov, they improved the error term in the fourth moment somehow. The fourth moment, somehow. And then Belkanov also considered in the level aspect a very interesting family. So k is fixed, the weight k is fixed, only q, the level, is of the form p to the v, where p is a fixed prime number and v goes to infinity. And she studied the fourth moment of his family and obtained this asymptotic formula for that. Okay, now what do we know about higher moments? Exact asymptotic formula for higher moments have been out of reach, but what people notice is that if you enlarge the family you're averaging over, then you can get some results in terms of asymptotics for these moments. So for a fixed, so if you look here, so you consider the LF moment. The elf moment, and then you average some more over whole characters chi-mod q. So, for those of you familiar with the theory of modular forms, basically here, instead of averaging over all modular eigenforms of weight k for the congruence subgroup gamma 0 of q, you'd be averaging over those for the congruence subgroup gamma 1 of q. That's a bigger space of model assessment. So, if you do that, then Jankovich showed for the sixth moments. So, when L is six, you get that these moments are bounded by Q to the epsilon. And then Chandi and Li observed that in a beautiful paper, that if you actually add on an extra average, if you average over Average, if you average over a short interval on the critical line, you actually get an asymptotic formula. And then Stacy, who was a PhD student of Chandian Li, he used their approach but lost the asymptotic formula with the gain of not having to average over the critical line. And then also Chandi and Lee. And then also Chandi and Lee, they obtained similar results for the eighth moment. So again, that's a moment taken over modular forms for gamma1 of q rather than gamma 2 of q. Alright, for the weight aspect, what kind of results do we have? So now we're fixing the level and we're letting the weight k go to infinity. infinity, it's a more difficult problem because if you look at the conductor of this, the conductor, the analytic conductor of a modular form of weight K, level Q is K squared Q. So in the K aspect, the conductor is bigger, and that makes things more complicated. So again, so we're considering LF moment of these. Of these modular L functions, fixing the level to be one. So our modular forms are for the entire modular group SL2Z. Alright, so Valkanova and Frolenkov, so the state of the art here is a result by Valkanova and Frolenkov for the first and second moments. So as k goes to infinity, the first moment is 1 plus i to the 2k plus big o 2 pi e divided by k to the k. And then the second moment And then the second moment is 2 log k over 2 pi plus 2 gamma. Here, gamma is the Euler constant, plus big O of k to the minus half. Now, these, the moments that they study, actually, again, the results are more general than that. Not only do they consider moments like that, but they twist them as well. They consider twisted moments. But for the purpose of this talk, I'm just focusing on these regular moments. And actually, these general, these improved results of Ivani Ksarnak. If you remember the previous slide, I mentioned work of Ivani Konsarnak for the level aspect side of things for moments. And so they had in that same paper, they had a sympathetic formula for the first and second moments. In the weight aspect, only they actually averaged further over K in a dyadic interval. In a dyadic interval. So, this removes that extra averaging. Okay, so that's for the first and second moment. For the third moment in the weight aspect, Frolenkov recently proved that the third moment in the weight aspect is less than, less than, log k to the 9 over 2. And that improves previous result of Peng in his PhD thesis, I think, around the year 2012, where 2012, where they've gotten k to the epsilon in that work. And in most of these papers, you compute these moments, but mostly the main target of the paper is either, for example, getting some non-vanishing results for these values at half in the spirit of childhood conjecture or obtaining sub-convexity bounds towards the Lundelov hypothesis for that particular family. And then for And then for the fourth moment, if you apply an extra averaging over k, then you'd get that this is k to the 1 plus epsilon, which is in agreement with Lindelof on average. And Han, in a recent paper, showed that, again, if you again apply an extra averaging over k, then for the fifth moment, you get k to the 1 plus 2 theta plus epsilon, where theta is. plus epsilon, where theta is coming from the Ramanujan-Peterson conjecture. So if that is true, then you would, you would, you know, that would be, there would be a sharp aspect. All right, and it's interesting here in the paper of Frolenkov, the way he studied this third moment is he used like, so there's, I'm going to mention Motohashi's spectral response. Spectral reciprocity formula that relates the fourth moment of the Riemann data function to cubic moments in the model on the modular work. So, Furolekov actually kind of obtained an inversion of that formula. So, he represented these third moments under consideration in terms of fourth moment of the Riemann data function, averaged by some, weighted by some rapidly decaying function. That's how we obtain that. Function, that's how you think that after that. Alright, how am I doing on time? All right, okay. Okay, so now another way you can, so this is basically, so you have a family of modular forms, you shape to them L-functions, you study moments of these L-functions, either in the weight aspect or the level aspect. Now, another direction that research in this field can go have been focused on the... Can have been focusing on is studying asymptotics for moments associated to rank and cellular convolutions of modular forms. So, very quickly here, what do I mean by that? So, that's kind of, in a sense, you can think about it as generalizing, you know, twists of modular L functions by characters. So, that would be GL2 by GL1. This is GL2 by GL2. So, if Q and N are relatively prime, if F is a modular form-wide. Prime, if F is a modular form, weight A, level Q, G is a modular form weight R level N. So let's just say they're both eigenforms, so they're, well, of course they're eigenforms because I said H there. Alright, so the Rankin-Selberg convolution of F and G is given by this Dirichlet series that is absolutely convergent when with part of S is bigger than 1. Okay, so here there's an ink system that should be lambda F. So the lambda coming from the So the lambda coming from the free expansion. So lambda sub f of n, lambda sub g of n, L F. This L function again, this series has an analytic continuation to the entire complex plane, unless f equals g, and it has a functional equation that relates its values at its values at one minus s. And for this particular family that I'm considering, you can see that the sign in the functional equation is always one. In the functional equation is always one, so that's a symplectic family, and you'd, you know, sort of can make some predictions about how the smallness would look like. All right, in the level aspect, what do we know? So again, we consider fixed weight, fixed weight K and level, the varying level N. So, alright, so here, oh no, no, okay. Here, oh no, no, okay. So, you fix a modular form G. One of the modular forms that are in your L function are fixed, so G is fixed, and F is varying over a family of weight K level Q. Alright, now let's say the weight K is fixed and the level Q is going to infinity through the primes. Then, Liu in 1999, he obtained an asymptotic formula for the first moment of his family. And Kowalski, Michelle, and Vander Kamelo, at the same time where they established the fourth moment of modular L-functions in the level aspect, they've also computed the second moment of this family of alpha fragment cellular convolutions. So P here is a degree 3 poly. Now in the weight aspect, again it becomes much harder because here, if you're fixing G, G is fixed, it's weight. G, g is fixed, its weight is fixed, and you don't care about it, then the conductor of this family is k to the 4, where k is the weight of the modular form f. Alright, so when r is fixed, n is 1, and k goes to infinity, again, Gooley, Hofstein, and Sengoette, they have an asymptotic formula for the first moment. And Lomer and Harpus and And Blomer and Harpus, they studied, they obtained actually an asymptotic formula for the second moment only with an averaging over k and an extra averaging over the critical line. That's the one way you can get an asymptotic formula. So the formula is a little bit complicated, so I'm not good on. And Starnak in the year 2000, he obtained The year 2000, he obtained an upper bound on the second one of these L functions as well. So, again, here, f is varying over this family, but g is fixed in the weight and the level aspect. All right, so what happens if both the weights of f and g are going to infinity? So, for example, if f and g have the same weight k, this is in a recent paper with Naomi Tanabe. Paper with Naomi Tanabe, we showed that the second moment is less than less than log K to the C for sub conference C. And in work in progress, we are working towards obtaining a sympathetic formula for the second moment by, of course, I mean it's out of reach not to average, so by invoking an extra average over the weight scheme. And because the conductor of this family, so when Family. So when r equals k, the conductor of f by g is k squared rather than k to the fourth. So we're thinking maybe we can get away with not averaging over the central line as well. All right, now in the last, there's two, well there are two slides remaining for me here. So I want to give a very short short introduction to some other techniques. Some other techniques that are used or approaches that are used to studying moments. So there's, you know, all the work that I've been discussing, basically the approach towards studying these moments is the approximate functional equation approach. So you express your central values in terms of some Dirichlet polynomials, you do your averaging, you know, Peterson-Phrase formula, ornament summation, and it works. Different applications. Different approaches use multiple Dirichlet series and another one on the other side spectropersipass formula. So in studying, so as it pertains to the, let's go back to the two-kth moment of the Riemann data function, I sub k of t, so Diacuno, Goldfeld, and Hopstein introduced this multivariable complex function. So Z of S1, S2 up to S2K, W, and that's the integral of the. And that's the integral of these data factors weighted by 2π over t to the qi t to the negative t dt. Of course, there's a dt missing here. And basically, the idea behind this approach is that if you take, if you can prove the, so in a sense, you look at this as a You look at this as a series with coefficients being the kth power of state or whatever object you're interested in. And as it turns out, this multivariable complex function inherits a lot of functional equations from the individual data factors here. And if you can prove that it is, if you can prove some metamorphicity results on this function, Results on this function, and if you can tell exactly where the poles are and what the residues at these points are, then you can, well, they were under some assumptions on the neuromorphicity of this function and the location of the poles and the residues. Diakuno, Galfield, and Hofstein were able to retrieve the conjectural asymptotic formula for the two-kth moment of the Rivenzeta function. Moment of the Riemann zeta function with exactly the same constants g sub k and a sub k. And there's been a lot of very powerful work recently, for example the work of Dercono and Whitehead for studying the third moment of quadratical functions, where they not only retrieved the matron, but also they also extracted the factor of x and fourth. All right, now another approach. Alright, now another approach is that of using some kind of reciprocity formula. So Motohashi here, Motohashi initiated a study with an exact formula that relates the fourth moments of the Riemann-Zener function to cubic moments of L-functions from the holomorphic world. Well, holomorphic and non-holomorphic world. And so in a sense, basically, Basically, you can obtain the fourth moment of the Riemann data function. You extract the main term that you know, what you expect it to be. And then the error term is a sense written as moments of modular functions. So the different objects in these formulas, these omegas here are just certain integral transforms of omega rapidly decaying. And this summation here goes over mass-form out functions. For the full modular group, this summation here goes over holomorphic modular alpha functions. And then using this formula of Motahashi, that one was able to do that, I'm sorry I'm mispronouncing the name, did use that error term of big off d to the two-third plus apsical for the uh fourth moment of theta. Fourth moment of data. I think I'll stop here. How much time do we have time to talk about discrete moments? 720 minutes. All right, so this ends the talk on colloquial style talk. We do have some slides on discrete moments, but the slides will be available on the BERS webpage and/or on our events webpage, so you can access them from there. You can access them from there. Now, what we have planned for the next half an hour is a discussion on a set of open problems. We have a few here on the slides, and we also have a problem list that we started creating after the moments out function at UNBC in the summer. So we're going to talk about that. Then maybe we'll take a minute break. Yeah. I guess I can ask for questions as well. Maybe we should make for that. Ask for questions, yes. Okay, so as somebody who's not really in the deep with this, one thing I'm trying to understand is, so we're pretty close to getting, at least from my perspective, an asymptotic form of all IKT right, because you have a lower and upper bound of the same order of magnitude. So what's the problem with getting an asymptotic formula from fast? With getting that entire formula from bounds. So constant and upper bound is conditional on our H. Okay, well assume R H. But that's not an issue for people. So with lower bound, you can get constants, but to get the asymptotic, we're very far away from that. So even the upper bound is only of our age. And I think there's a student of Alexander Flory who's computed that constant. And Inu has computed that constant too, I think. How far is it? I think they're very far from each other. From each other. Okay, but like, how far? Is that something like quantify? I don't know this work of. We can look at Inu's paper. I think they're very far. So like one is like exp xv to something, and the lower bound is maybe close to what's correct. Okay, because I have a theorem where I also have this sort of thing where I have a lower and upper bound and a backorder magnitude, but I did not really attempt to compute the constants, but I kind of qualitatively know why. Qualitatively, we know why the constants, you can't snap them together. So I'm just wondering if there's some sort of, it's not just like a matter of, like, okay, well, if we work really hard and hammer the constant down, but there's some sort of theoretical obstruction to it, that you can't just bridge the gap. Some reason that you can't bridge the gap. I mean, the lower bound method, if you work really hard on the lower bound method, maybe you could get something within a constant. Get something like within a constant of what the conjecture is, but the upper bound method is not efficient right now, so it's open problem to improve the upper bound. Also, just getting the conjectures for run the matrix theory. We don't know how to connect this to like just to get the g k for k up to for k bigger than uh or equal to five to match. or equal to five to match with any extra average. Yeah, we're only going up to about fifth or maybe fifth moment, sixth moments in all families. That's sort of the best you can do right now for asymptotics. Yeah, so like I said, I don't know the subject very well. So I'm trying to understand, like, there are other methods where if you have a lower bound and upper bound are close enough, you can kind of. Upper bound are close enough, you can kind of just do some sort of recursion and then just keep snapping closer and closer together until they hit. Right? I'm not sure. What is the obstruction? I don't know. That's what I'm trying to understand. What is the obstruction? I mean, the obstruction is nobody knows how to deal with it. Well, nobody knows how to do divisor sums. That's the obstruction. If you could asymptotically evaluate divisor sums, then you can answer almost. Divisor sums, then you can answer almost all these questions. That's a problem that goes to the circle method or the delta method, and we don't know how to do it. Correlations of divisors, right? Yeah, correlations of divisors. And even more general things than this, that the Connery and Keating introduced, nobody knows how to do them. I I have a naive question. So the divisor uh divisor uh function, it comes from the Function, it comes from the fact that the Riemann Z function has a digital service factor. The fact that the Euler product, is it being used in the known results or the conjectured ones? The fact that the Riemann zeta function has an Euler product, is that the fact that it has a true data? Questions from participants? Like just maybe a what do we call it the geometric constant? Is it like uh the volume or something? I think there are volumes of certain not the dimensional integrals. Sort of fundamental region and some random graph series. Yeah, just people. Yeah. And a gala numbers and things like that. Should I go through some of these problems? So we've compiled a list of the So we've compiled a list of some open problems just based on this talk. And then there's also a list of open problems on the website that came from the Elf Functions conference. If anybody wants to contribute problems, send me an email or Alia an email. I'd like to add to the list. And I'm going to add some of these to the list too. So I'll just start the discussion. One open problem that we can't even do is D3N, D3N plus 1. Now, to do the 6 million zeta, you need D3N, D3N plus H, okay? And you want H. h, okay, and you want h up to square root of x. So let's just go to the easiest problem, d3n, d3n plus 1, do that. Here's another challenge problem. Can you do dn, dn plus 1, dn plus 2? So I asked this question at ICERM about seven years ago. Now, shortly after that, Blomer wrote a paper on DN, DN plus H, DN minus H with H average. So here's the, can someone do So here's the cancel and do that. Okay. Another open problem is get an omega theorem for dKn dn plus h. There's papers of Topaka, Ghilari, and Drapeau. They asymptotically evaluate this. So this is about, you know, these papers were written in the last five years. It's expected the error term is size root x. Nobody's proven that yet. When k is 2, there is an omega. K is 2. There is an omega theorem. I think it's Bogdan Salisdo or something. I can give the reference. But K bigger than 3, nothing's proven. Now, David Wynne, postdoc at Queen's and was at AIM last year, he's written a paper this past year where he does numerical computations of, I think it was D3n, D3N plus H, and that's showing square root oscillations. Oscillation. So it would be interesting to do more calculations. It's very hard to write down the main term of dkn dln plus h. There is a formula for it. But working out the coefficients is really tricky. So I think David in his paper did some small cases with K and L3. There's a paper at me and Mark Tom, and there's a blog post of Terry Tao where we write down formulas for the very first coefficient. Down formulas for the very first coefficient. Nobody's written down formulas for the lower coefficients. So that's actually another problem. I think it's on the problem list. One thing David Wynne did in his paper was he connected the problem of evaluating D3N, D3N plus 1 to Elliot Hauberstam for DK. So he showed, assume this conjecture here, it's super strong, he has a square root error term. Square root error term. In Elliot Hubber's stamp, I think it would be x over log x dA. I mean, maybe people could even look at his paper and have weaker terms and see, assume Elliot Hubber's stamp, what does it imply about dkn dn plus h? Because that would be nice because that's sort of a more accepted conjecture. And one thing sort of suggested in David's paper, you could maybe assume LA Haberstem and get a And get a very sharp error term for D3N, D3N plus D3. So that actually would imply the sixth moment. Alright, so those are some questions. Alright, here's another set of questions I have. The fourth moment of the zeta function, I think it was 1989, Zavorotny got t to the two-thirds plus epsilon. And then Modahashinovich, they studied his paper and they got t to the two-thirds log t to the c. That hasn't been improved since 1989. That hasn't been approved since 1989. So, can that be approved for the fourth moment? I actually believe that maybe you could prove with the smooth fourth moment t to the half plus theta plus epsilon where theta is a bound in Ramadan's conjecture. So I'm wondering, people that know spectral theory, can you prove it that way? I think with the method of approximate functional equations, maybe you can get something like this with a smooth moment. With a smooth moment, I don't know about taking off the smooth weight. I don't, probably won't beat to you to two-thirds, but I don't know. There's a paper of Demi and Bernard which does the same thing for the second moment of modular L functions. Okay, so that's a question I'm putting up there. For the sixth moment, all right, we gotta touch this. Okay, for the sixth moment, can you prove an Can you prove an omega theorem for the sixth moment? Assuming that it's two divisor conjecture? And I'll discuss that in a second. What about the full main term for the eighth moment and the shifted version? So in the paper I wrote with Chen Li Shan and Peng Ji Wong that we posted this year, we only get the very leading term for the eighth moment, but can you get everything? It's a degree of 16 polynomial. You can get everything down to the bottom. Polynomic, get everything down to the bottom with power savings error term, so that's a challenge problem. Okay, so what is the size of the error term for the 2kth moment? So let's raise that question. So I'm going to say EKT is Ikt minus the main term. Well, Connry and others, they conjectured in the paper to the half plus epsilon. But I think they're not conjecturing that anymore. I'm not sure. But it's in the paper. But it's in the paper. I think the conjecture for the square the second moment should be t to the quarter. That's what I think is the answer. Because there's an omega theorem of t