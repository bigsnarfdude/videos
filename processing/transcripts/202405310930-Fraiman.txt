Thank you very much. And I'm sorry, the last talk is not even, usually the last talk is hard, but this one is even remote, so a little bit less entertaining maybe. But thank you for staying there and paying attention. And obviously, And obviously, you know, a big thank you for the organizers for putting this together. I wish I could have been there, but I'm sure from what I heard that it was a lot of fun and successful workshop. And I, well, the talks that I was able to see, I really enjoyed as well. All right, so I'm going to talk about quasi-stationary distributions for semi-supervised community detection. And I kind of planned this. Planned this a little bit like a colloquium talk. So, some of you that you know know this stuff will get a bit bored, and I apologize about that, but I figure that because of the different people in the audiences, it would be a good idea to have a relatively broad scopes. Okay, I will show a little bit of math as well. It's not only, but yeah, all right, so let's get. Yeah. All right, so let's get started. So, first thing, yeah, this is joint work with my student, Michael Nissenson, who's a PhD student here at the Department of Statistics. And he's done pretty amazing job so far. So let's talk about first just some strokes about community detection, and then we'll mention maybe semi-supervised. Maybe semi-supervise and our methods, et cetera. Okay, so often in network analysis, networks organize into communities. And typically, this is a picture that we have in mind, although they don't have to be like this, but we kind of think of communities as being well connected inside and relatively separated from the rest. Separated from the rest, right? And this is usually explained by assortativity or homophily or, you know, the tendency to sort of like to connect more with people that are similar to you in some sense. So it is a very, very common phenomenon. Here, I'm going to show you some examples, very well-known examples of this thing. This is from Moody 2001, and these are social interactions among high school students, and they, you know, And you see two big clusters separated by mostly by ethnicity. You have like black kids and white kids and some other ones that I don't know how easy you can see them, but there's like some like that. But you see clearly that there are more interactions in each community than across communities. This one we're going to talk a little bit more. It's a pretty famous one. Pretty famous one. These are political blogs. Blogs kind of faded out, you know, Twitter and other things have taken over. But in the 2004 election, there were a lot of different blogs. And these were in this paper by Alemikin Glance. And they are essentially separated by sort of conservative and liberal, or Republican and Democrat. And it's basically, you know, a link if they interacted, if they commented on each other, etc. Here's another example. This is an ego net. So these are, you look at the neighborhood of friends of somebody in Facebook and their connections among them. And you can see clearly some social circles that could be, you know, like family and school and work and things like that. That's right. I think this one is like his club, but I don't know. It's this paper by Mikole and Leskovic. One, perhaps not too surprising, but also I kind of like it. I mean, it's a small example that it's easy to explain. These are college football games, and obviously, you know, teams play a lot more games in the same conference than across. In the same conference than across conferences, but you play games outside as well. So each one of these circles is, you know, the different conferences here, like Merri-American, Big East, the ACC, etc. And there's a few teams that are in no conference. Okay. This is by Mantheos and Genekis. And this is just to give you an idea of the problem of what we want to do is, so we see this network, and this is what the adjacency matrix looks like. Know this is what the adjacency matrix looks like. Okay, so it's a spy of the matrix, it's you know a black dot if they if they're played a game against each other, and you know. But if you permute things and put them in the right order, like you know, all of this and then all of this and then all of this and so on, that matrix becomes like this. So you see this clear block structure where the communities are very apparent. But you know, when you look at this picture, a little bit less obvious, right? Bit less obvious, right? So that's the problem that we, you know, we want to think about. You know, we are going to give in a graph and perhaps it is adjacency metrics like this. And we want to sort of find the permutation. We want to find the labels, the communities that will make it look like this. Okay. A small caveat. All of what I'm doing and saying is sort of assuming that assortative behavior sometimes communicates. Behavior, sometimes communities are not assortative, and sometimes there are, you know, you tend to pick and link across the community more than inside your community. This behavior is called this assortative. And a clear example of this are romantic and sexual relationships in high school, where usually, you know, there's a more, a lot more edges between, you know, male and female than between female, female, and male. Okay. Excellent. Except all right. But there are tools to deal with this, and one, you know, one can come up with sometimes one thing that people do is look at the two steps. So if you go two steps, it becomes assortative again because you go back to somebody of the same community. But anyway, all right, so we want to find communities. One thing is then, you know, how do we decide what are good How do we decide what are good communities, right? Visually, I mean, it, you know, it's maybe clear, but like, we need, you know, we want to have a mathematical formulation of that. And there's a lot of, you know, here's, there's a lot of different things that one can do. One can try to minimize the cut size, so, you know, number of edges across communities. There are variations of this called ratio cut and normalized cut, where you, you know, it depends on the sizes. Basically, you want to avoid. Depends on the sizes. Basically, you want to avoid like maybe, you know, having a huge community and small guy, and maybe just one edge. This would be a very small cut, but this is also like a very small community. So, if you want something more balanced, you know, you have to sort of normalize or do something like that. You can try to minimize conductance between the communities or the escape probability as we maybe. Maybe, maybe, um, I don't know if Jeremy or Benio mentioned our previous work, but it's related to something like that. Or you can also try to think of like things that maybe it makes sense to maximize, like, well, I want very dense communities, so maybe the internal edge density or the neighborhood overlap between nodes in the same community, some measure called modularity, which was introduced by Newman and kind of like measures how. By Newman and kind of like measures how it's a measure of quality, so you want high modularity basically. Um, resistance distance and min exit time. This actually is related to the some previous work with the collaborators that are there, Jeremy, Zach, Braxton, and Peter. Well, Peter is not there. So, one issue with, you know. One issue with many of these optimization problems is that they're hard to optimize. Like finding the mean cut is one of the classic problems that are known to be NP-hard, but many, many of these formulations are NP-hard generally. So one has to come up with algorithms which has actually made this a very popular and very active field, right? So, because you cannot maybe just do Cannot maybe just do, you know, find the optimal. What can you do? You can do approximations, you can do greedy heuristic, you can do convex or other types of relaxations, you can do agglomerative and divisive methods, so hierarchical clustering, etc. And without being exhausted by any means, this is just telling you that there are some very classic stuff from like coming more from maybe the computer science literature of. Science literature of Kerning and Lin is a classic iterative mean-cat algorithm, spectral clustering from the classic Fiddler vector. So second eigenvector separates communities. Then Gibran-Neumann algorithm, modularity maximization, percolation methods, methods based on statistical inference. So sort of assuming. So, sort of assuming that there is a model guiding that and trying to, you know, do like maybe Bayesian statistics, et cetera. Label propagation, super popular method, Dubain, you know, different types of matrix vectorization. And also, this is the paper that I mentioned where we are looking at not the, you know, just the mean exit time, that's different difficulties and behavior. That's different, difficult it's and be hard that we can regularize it and find a you know a good solution. So lots of tools for the classical setup. But I want to talk about semi-supervised learning. So what is this basically? So we have the same thing, but the community labels of some of the nodes are rebuilt, right? So now I know these two are blue, these two are red. Are blue, these two are red, this guy is blue, it's green. And the obvious question is: how can I exploit this partial information? What can I do? And well, many of the methods that I mentioned can be constrained, sort of like if you are doing like greedy or some stuff, or sometimes you can put this or penalize stuff that differs from the labels, from the partial information. Partial information. So many of the methods that were in that big list can be adapted. People have also come up with some other more specific methods for semi-supervised learning. And I want to think of that type of thing. I'm going to present an approach using quasi-stationary distributions that really leans on having the partial labels and using that. And using that to label the rest. So, what are quasi-stationary distributions? Basically, it's a concept that started with, I think, with somewhat with branching processes and population models. The idea is that you have a Markov chain that will eventually. That will eventually be absorbed. If you're thinking of a population model, eventually maybe everyone dies, right? And then from there, it's over. You cannot leave that state. But it often takes a very long time to reach that state. So you end up in this sort of like almost equilibrium that, yes, eventually something catastrophic will happen and everyone will die, but for a very, very long time. die but for a very very long time you are in some sort of stationary almost equilibrium state and that's this is the this is the uh you know formalizing that is what uh quasi-stationary distributions are for um so in our setup we're going to have a markup chain on um states in our case it's going to be a random walk on the graph we're going to have some forbidden states that are you know the extinction event right and everything else we're going to call a And everything else we're going to call allowed states. And we are going to look at the process until it actually hits this forbidden state. So the hitting time is, you know, the minimum time where you hit this boundary. And a quasi-stationary distribution is basically a measure over the allowed states such that if you start with that measure. Start with that measure and you are, and you condition on not having been absorbed or extinct by time t, then xt still has that measure. So it's kind of like stationary, conditional on survival, right? So you start with mu, you still have distribution mu conditional on survival. Okay. Okay. Yeah, is this a sorry, I see somebody standing. Is there a question? Hello? Here. Is that better? Yeah, I can hear you. Okay. We're all just trying to figure out how to work a microphone. No big deal. So that big T in the bottom. So that big T in the bottom, is that that big T is also a random variable, right? Like that's before that particular walker gets absorbed into the forbidden state, right? Yeah, this guy is a random variable. It's a hidden time. Right. So basically, you have this notional giant population of random walkers, and you just track them until they get absorbed. Exactly, yeah. So, you know, if I remove this condition, If I remove this condition, basically, you know, this would be basically a stationary distribution for the chain, right? You start with mu, and then after T steps, you still have this region mu. But if you have an absorbing state, the only thing that could that have, everything else is transient, and the only stationary distribution is being stuck in that absorbing state. So, thinking of So, thinking of a population, if you think of what is the stationary or the limit distribution, eventually everyone dies, and that's where all the mass is. But it just takes so long that if we condition on survival, we can have this sort of like quasi-stationarity. Yep. Okay. All right. So, I want to, you know, build. To you know, build some uh um mention some results about you know how QSD works. Uh, this is very classical from like the 70s. Um, but you know, one thing is this is gonna be an eigenvector, okay? It's not gonna, you know, the same way that the stationary measure is the, you know, the left eigenvector of eigenvalue one. Here, the eigenvalue is not gonna be one anymore because there's some sort of leakage of mass. Of leakage of mass of being absorbed, but it's still an eigenvector. And one way to see it is that it's very easy: well, first, let me just tell you that, you know, the condition that I just shared is equivalent to this. And why is that? Because, you know, what's the probability that you are at a state that it's not allowed? Well, if you are here, you haven't been absorbed. So you might as well add that. So, you might as well add that because it's not changing anything. And then you just use conditioning to write it like this: that this is the mu x term. So it's equivalent to that. And that tells us that the heating time is geometric. So it's going to be, you know, the probability that it's bigger than t is going to be some lambda to the t. And again, it's a very simple. Again, it's a very simple calculation. You just prove that it sort of factorizes like in powers, right? So, what's the probability that it's bigger than T and S? Well, you just condition on being at state X here. But if you are at state S, like, you know, it is a Markov chain, so you might as well start it in X here and just survive for S longer and then just use. And then just use that this guy here is this thing to put it there and rearrange, right? Then all of this thing here becomes just that. So we have geometric heating times, and that basically tells us that we have this behavior, that mu times p to the t has to be lambda to the t times mu. Right? Because if you go back here and now you put this. go back here and now you put this this guy to be lambda to the t right you can think of this guy as mu piece um mu p t right you take t steps t transition steps and this guy is just mu lambda to the t so we get our eigenvector with some value lambda okay so that's going to be useful to compute this guys because then we can you know we can there's a lot of tools There are a lot of tools to find that eigenvalue to solve eigenvalue problems. And in particular, it will be the dominant eigenvalue. It's going to be the Perron Provenius eigenvalue. This is what people realized in the 70s that you can get asymptotics using the Perron-Frovenius theory if you, you know. Um, if you introduce also the right dominant eigenvector, normalize this guy to be to sum to one so that it's a distribution, and this guy's to be orthogonal, well, not orthogonal, but inner product equal to one. Then this guy's proved a couple of different things. One is called the Jaglom limit, because this was done, Jaglom proved it in the 40s for this sort of branching processes. These sort of branching processes, but basically tells you that quasi-stationary is quasi-limiting. So you can think of a stationary measure as a limit measure. So no matter where you start, if you survive for long enough, p goes to infinity, you know, your distribution is going to be this mu x. Okay. So so I mean that's that that theorem can go because you don't need to add a data. Because you don't need to add an aperiodicity type type. Sorry, can you speak closer to the microphone, maybe? Is that better? Yeah, that's much better. Okay, sorry. Yeah, I mean, the theorem's cool because we don't need an aperiodicity type condition like we would need in a, you know, without the absorbing states. I guess that's just because you can't cycle around forever and you have to eventually have a problem. So, okay, so I was. No, that's a great question. This is true with the usual irreducibility. Irreducibility, like if you have a component that is completely separated, obviously it's not going to converge to this thing, right? So you still need a periodicity. Cyclical behavior you can get away with, but the usual hypothesis are still acyclic and a periodic and irreducible. If you don't have that, you can do it still, but you have to sort of treat each component. Each component separately and so on. Oh, okay. So it is really analogous to the it is analogous, yes. But yeah, so making, you know, having the conditioning here makes stuff a little bit more awkward. One interesting thing is that the other, the right eigenvector, can be thought about as the difference in. As the difference in survival rates for different starting points. So they all sort of die at rate lambda to the t, but there are slight constant differences between the different places. And those are given basically by this other eigenvector. And combining these two, you get the occupancy rate, which is basically if you look at the number of visits up to time t, right, divided by t. Divide by t, assuming that you survive for at least time t, then you get 5x mu x 5x here. One thing that perhaps is a bit surprising is that, you know, in classical Markup chains, this guy and this guy are the same. That's the ergodic theorem, right? Or not even the ergodic theorem. And or, or, or not even the ergodic theorem, that's like a Cesaro convergence, right? You know, you average these things, you get that. Um, here you cannot average because the condition depends on this guy, right? So you cannot just write, so you would like to write maybe, you know, one over n sum, you know, py xi equals x given t. equals x given t equals t but to say that that this guy converts to mu x well we have an issue here because this is not time t you know this is not the same time okay so it's uh that's why why you end up having this extra guy here for example okay so i mean that's that's and perhaps the most interesting part of their paper or um but that gives us some But that gives us some ideas that this mu and phi certainly tell us a little bit about how you behave before you're absorbed. Okay, so now that we have that in mind, what's the heuristic for using QSDs? Well, suppose we have some partial information. So we have some, you know, nodes that are revealed in a given community. In a given community. So, the idea, you know, assortativity would tell us that nodes from the same community are well connected to these revealed nodes. And nodes from other communities are less connected, right? So the picture is kind of like, here's C1, here's C2. And I actually maybe revealed that's like, right? And then this guy's. And these guys will have more edges to the revealed guys that guys over here. So if you think of the QSD when you actually kill it or make R absorbing, if you have trajectories that have many steps in C, these are going to be less likely to survive because they are actually, you know, they have more chance of eventually hitting R. So if you conditional survival, the random walk is going to spend less. On some variable, the random walk is going to spend less time on c so in that picture where we have c1, c2, and sort of like are here. If you think of like the entries of mu, well, mu restricted to c1 should be smaller, you know, generally that this is what we have, right? So there's the stationary measure for these guys is lower than the stationary measure for these guys. Measure for these guys. So then it should help us detect. That's the idea. Okay. So how do we use this? How do we turn this into an algorithm? Well, if you have many communities, you just think of the revealed guys for each community, find the QSD for that random walk, and then use each one of the stationary. And then use each one of the stationary measures, uh, or quasi-sorry, quasi-stationary uh measures to embed in Rk, and then just you can do just k-means, for example. In terms of two guys, which is what I'm going to focus on this talk, what this means is like, again, this is C1, this is C2, here I have R1, here I have R2, right? For any V here. For any v here, mu1 of v is going to be sort of like small, and mu2 of v is going to be high, right? Because being absorbed on this, you know, these guys will have large mu2, these guys will have small mu2, and so on, and so on. So you end up having something like, well, obviously there's noise, but like something like this and something like this for C1 and C2. Something like this for C1 and C2. And for the other eigenvector, it's going to be looking at exactly the opposite. So with only two, instead of k-means, you can do a little bit easier. You just take the difference and sort of like see if it's positive or negative. Okay? So you kind of use the two signals. You use the signal from this guy to say, well, if you are in this community, To say, well, if you are in this community, you should have low mu1, but you should also have high mu2. So you take the difference of the two, and that's going to be a bit more helpful. Okay. So that's the algorithm. One important part here is, well, we need to compute these guys. How can we do it? Well, luckily, we saw that this is an eigenvector, and it's the leading one. So we can use simple. It's the leading one, so we can use simple stuff like power iteration, okay? Or we can also use slightly more sophisticated stuff like QC algorithms and a bunch of other things that probably Jeremy and others know better. But also for very, very large graphs, one thing that is kind of cool is that we can use stochastic schemes, approximation schemes, to find the QSD. Instead of actually solving an eigen Solving an eigenvector problem. We approximate, you know, we use that this is a quasi-stationary measure and simulated, you know, we use some sort of Monte Carlo scheme that simulates the random walk and does something. And there's a couple of things that you can do. One is you simulate the random walk. Once you are absorbed, you resample from your history. This is this occupancy reinforcement. This is this occupancy reinforced random walk. Another one is say, well, actually, let's have many particles, and when each of those is absorbed, let's resample its position from the other particles. And this is what Fleming-Biot process does. So these are some cool schemes that scale quite a bit larger than Nico, can you hear me? Yeah, I can. Nico, can you hear me? Yeah, I can. I had one question. So, obviously, if you start taking larger and larger graphs, then yeah, computing eigenvalues can be challenging. I'm just wondering if, in this case, the stochastic approximation schemes are related to like numerical linear algebra stochastic schemes for trying to find the largest eigenvalue and eigenvector of a matrix where you do some kind of like stochastic Krylov scheme. Crylab scheme. Those related to these stochastic approximation schemes, or are they? No, so these are, yeah, that's great. Great question. So these are actually really thinking about this being quasi-stationary. So exploiting the occupancy and exploiting the trajectories of the random walk, and basically saying, one of them basically does, you do the random walk, right? And when you hit the boundary, you just resample. You just resample from your history and you restart where you were, you know, and do it again and do it again and do it again. And then this essentially starts reinforcing places that are your random walk is more likely to be before being absorbed, right? Yeah, and so, I mean, in practice, these actually can scale more than something like a trial object or something. Yes. So Yes. So, I mean, it probably depends a bit on how the graph is and how sparse it is, right? So, like, in numerical linear algebra stuff scales very well for sparse graphs. But yeah, in general, this could scale even further. And like so for the first one, you really just are simulating one particle many, many, many times and then the other one presumably this parallelized really well together. Just parallelize it really well because you're doing a bunch of random walks. Is that kind of how that goes? Yeah, so this guy here is one particle, and every time it's absorbed, you resample from the history. This guy here is n particles, and every time any of the particles is absorbed, it goes to where one of the others, you know, you pick one other particle and copy its position. That's cool. And there's more stuff. In particular, we had a paper with We had a paper with another student here with Adam Waterbury and where we studied sort of like a hybrid method where you have many particles, but you also want to reinforce the history. It's kind of like you combining both of it. All right. Okay. So let me show you a typical experiment. And, you know, think of this as just a proof of concept. Know, think of this as just a proof of concept. I don't want to, I'm not saying this is the best experiment to do or whatever, but like, you know, we I like this one because a lot of people tried it, so we get to compare with different people. So it's the political blogs, okay? It has the actual data set has a few more nodes than this, actually, but that's the largest component where we. That's the largest component. So we're removing like a few very small components that are not part of it. That's what everyone does with this experiment. And this is sort of like the state of the art error for unsupervised methods. If you just run, you know, spectral method, you recover, you know, you do quite well. You missed like about 100 nodes. There's a There's a regularized spectral clustering that improves that a little bit and gets to 64. Gene, a paper on anal statistics that has like a lot of citations and this, I think this is a very popular method called SCORE. Until recently, actually, it was a state of the art. So I now find, I forgot to add it because I actually found it yesterday, but there seems to be a method that does 54. Method that does 54 here. There's convexified modularity maximization gets about 62. You know, other methods, latent space community detection gets also 52, and so on. So that's kind of like just a benchmark of how you can do if you don't have any personal information. Now, a lot of people. Now, a lot of people have looked at what you can do if you have some revealed labels. And basically, 5% seems to be what I found in other papers and I could sort of like compare with because I didn't run these methods. We didn't run them yet. We hope to run them ourselves to have a more comprehensive list. And the approximation here is that some of these are actually come from plots. So it's unclear if it's exactly 80. It's unclear if it's exactly 80, you know, that number or something like that. But, you know, generally, well, this is another method based on random walks. It doesn't do very well. This paper actually was, I don't know if Ping is still there, but Lee was one of the speakers. Was one of the speakers at their workshop, and they get about 62%, so about also 5%. So, message passing algorithms, these two are message passing algorithms, they get close to 52. And we are able to get a little bit better. We get 57. I'm not saying this, you know, this is a significant difference or anything, but what I do find a bit surprising, I do like quite a bit, and I want to show you. Do you like quite a bit, and I want to show you is that well, you still get 57, not with 62 nodes, but only with four nodes revealed, and with only two nodes revealed, you get 58. So this has quite a bit of power in terms of like just exploiting the l even a b a tiny amount of labels. Have you looked to see if you think those mistakes are real mistakes or if it's label noise? Or if it's label noise? Say that again? Have you checked to see if those mistakes are real mistakes or if it's label noise? Like when you start to do this well, I kind of wonder if the, and if everyone kind of is maxed out here, I wonder if the labels are a little bit more. Yeah, so indeed, 57 or so seems to be kind of like if you look at, I'll show you, let me show you the code actually, because I was. I was, this is something that I did at the airport. I learned how to show code like a presentation. So I'm excited about this part. So let's see. It's basically what you're saying. There's about 50-something nodes that if you look at the graph, they actually look like they maybe are mislabeled. They are not because the label, you know, those are the true labels, but those are maybe you can think of they're more as like troll block trolling blogs or. Trolling blogs or something like that because they interact a lot more with the opposition than with the same community. So they are a little bit weird in that sense. Do you have access to the actual names of the blogs? I wonder if you could just look and see what the content is on one or two of them. They are. I don't know if the blogs are online, but if you're interested, we can explore that for sure. Yeah, I'd be interested. So let's see, I post that. I paused that. I didn't want to. Sorry. Why is it paused? Let me just stop here a second and see if we can do that one. Okay, can you see this? Can you see this? I think it should be visible, right? Yeah, we see it. Good. All right. So, some of these cells are just importing modules, et cetera. That, you know, power iteration, right? So I'm actually running these cells with you right now here, reading the data from political blogs. This is just safe position so that I don't compute where to basically. Basically, it's a dictionary of positions so that I don't compute them, I store them. This is what it looks like: there's this number of nodes, this many in one community, and this many in the other community. So somewhat balanced, not perfectly balanced, but somewhat balanced. Just painting red one community and blue the other. This is what the graph looks like. Okay. Okay, and as you can see, I mean, these are the true labels, right? There are a few red here that I would naturally say, well, those should be blue, right? And there's a few blue here that I would naturally say those should be red. And those are what most of the algorithms I think. I mean, I haven't checked the output of the others, but I believe that those are what why, you know, lower than 50 seems pretty impossible. All right, so what, you know, here's the All right, so what, you know, here's the adjacency matrix. This is what it looks like. Okay, so yeah, I mean, it is sorted in this case. So these are sort of, you know, so that it's easier to visualize one community, the other community. This would be 5% data, but I want to show you this guy. So I'm going to say you see one node from community zero, one node from community one. This is the drawing of that. Let's see if I can. So, there, this is the revealed blue guy. This is the revealed red guy. Okay, just those two. You know, they're not particularly super central, especially this guy, right? This is just to count the errors, doing a little bit of block. Little bit of blocking with the matrix, computing degrees. I can tell you about the scales of it. Basically, you know, adjacent times the inverse and transposing because we want the left eigenvector, not the right eigenvector. And then we just remove the first, you know, the node so that we get the restriction to the other part and get eigenvector, do it with the other guy, and look at the difference. Guy, and look at the difference, and we can plot it. And there you go. So, okay, some very large values, which is why the scale is kind of like you know, somewhat different, difficult to see. But, you know, most of these guys are negative, most of these guys positive. We can do a histogram of values in one community and values in the other community, and you see indeed most of the blue are negative. Indeed, you know, most of the blue are negative, most of the orange are positive. There's some overlap, right? Some orange that, a few orange that are negative, a few blue that are positive. And then we can just count the errors and we get 58 errors in this case. Okay, so one only one from each gives us 58 errors. Yeah. Can I ask you a quick question? So, okay, so just so I understand. A quick question. So, okay, so just so I understand the dominant eigenvalue that you're computing, you compute the dominant eigenvalue, the sub-stochastic matrix that you get by removing the corresponding rows and columns according to the labels that you've been given. Is that correct? Yes, but you do it one at a time. That's the important part, right? Right, exactly. But, because that's what's going to tell you the relative distribution compared to that known label. So you could also actually, you know, assign that an absorbing boundary. Absorbing boundaries like table properties. So, like, you know, put that as a one or a zero. So, if you make that into absorbing, then what happens is that the leading eigenvector becomes just everything in the absorbing set. Right. So, okay. So, I was wondering if this is what I was getting at. So, you look at the dominant eigenvalue of that substochastic matrix with the label set removed. Yeah. What do you know anything about what the spectrum of the corresponding Sure complement? Of the corresponding share complement of that set as a boundary would give you in terms of like a spectral clustering or spectral information relating to the relationship to that node. I don't know yet. I mean, I think it's likely to give something similar. But the substochastic nature of this still gives you such a nice hitting probability interpretation of what's going on that there's something not interesting. Yeah, I believe that there's nothing. Yeah, I believe that there's nothing in terms of numerical, yeah, it's probably gonna be similar, but the, you know, this has this nice interpretation that gives us some tools to work and prove stuff. Yeah, so I mean, I can show you, you know, this is, let's actually maybe just do EA. We run this guy. Yeah, right. So this is much. So, this is much harder to see, especially because of some high values. But the idea would be that it's lower here and it's higher here. To really see it, one has to sort of trim, like I would have to, you know, change the y-axis and I don't, you know, I'm not fluent enough to do that live. But when you take the difference of the two, then it becomes easier to visualize. Okay, but each one of these is actually already kind of. Each one of these is actually already kind of like low and high, and high and low. Um, okay, so 58 with just one guy, that's pretty, pretty neat. Um, and if you look, you know, those are, you know, let's color them and let, you know, do it, see what we're getting. And that's what we're getting. And that's why I think, you know, okay, yes, it does make a lot more sense that all of these are blue and all of these are red, right? Versus like the true. Versus like the true labels, right? This is what the algorithm outputs. This is actually the true labels. And of course, it's going to get some of these guys wrong. And I think any algorithm would. And Nico, so neither of the two label points that you picked were in that anomalous set. Is that true? No, I mean, I run this several times, picking. Several times picking the guys at random, and I never had. I think it would be yeah, if you pick one of this, it's probably gonna do a lot worse. Okay, I was just wondering if what happened if that was the case, but uh we could we could try. I wouldn't I would need to check exactly which guys those are, but yeah, yeah, I'm curious. I suspect it may not actually be bad, it might label them differently. I think what well, maybe, yeah, it will flip the colors maybe. Yeah, it will flip the colors, maybe, right? So that's what I was wondering. But if you get one red here and one red here, then that would be a mix. Yeah, exactly. Okay, so just to tell you, you know, let's, you know, find, let's do the Fiddler eigenvector, right? This just classic spectral clustering. So this is the largest eigenvector for adjacency, the eigenvalue, second largest, right? So that's what it looks like. That's what it looks like. And again, also kind of like negative here, positive here, but you know, quite a bit worse when you do the label here, you get about 100, 100 mistakes. And, you know, what I like really is that you get the pretty good behavior just with one or two notes. You change this to two. Or two notes, you know, you change this to two, and we run. Um, so whatever in this case, uh, now we have you know, these two guys here, and these two red guys here. Uh, and it does become a little bit better, but it's not even that one. Um Like maybe just go to this, and you get okay, 57. But, you know, still, it, you know, maybe change one over here. I don't know. It's hard to see what it was doing. Okay. All right. So that's some code. Let's go back to the slides. If I can. Yes, okay. All right, so it works. It's kind of nice. It's fast. But we like to prove stuff. And what people do is typically assume a model, and that is the most common is the stochastic block model. Most common is the stochastic block model. I'm going to focus just on two communities. I'm going to talk about the most simplest scenarios, although one can make it a lot more complicated. Basically, this is a random graph on n nodes that has two parameters, P and Q. And nodes have labels that say uniformly at random. So communities are about the same size, but they don't have to. And then edges have, you know, occur with probability. You know, occur with probability P in each one of the communities and with probability Q across communities. So typically, you know, more edges here, more edges here, fewer edges across, which is what we want. So what do people know about the stochastic block model? They know a lot. There's really a lot of papers. Basically, you know, the problem that we want to think about is: can you reconstruct? You want to think about is can you reconstruct these labels from the observed graph? And one way to sort of try to characterize this is looking at the error rate. Notice that there's this z here. So it's not counting just whether the labels are the same. You get to, and with more than two, you get to permute things. But basically, this is saying, well, I'm going to count this correct if I put plus one and minus one. Put plus one and minus one, but also if I put minus one and plus one, right? I mean, those are essentially separating the communities that you know, not necessarily saying this is the right the right label for that one and that's the right label for the other one. So either all the labels are equal to thing or everything is opposite of the correct label. And people have focused on a bunch of different things. Focus on a bunch of different things. So, exact recovery, namely, like recovering all the labels. Almost exact with the, you know, in terms of statistics, is basically what people think of consistency, a consistent estimator, namely the loss goes to zero. Partial recovery, when you want, you know, loss being, you know, I want to recover, you know, make an recover 90% of the graph. So basically, my error has to be less than 10, you know, 0.1, so 10%. And just weak recovery, where your error is less than a half. And this is also the less than a half is for the special case of balanced communities, et cetera. Basically, what people think of weak recovery is, can you do better than random guessing? Obviously, if one community is huge and the other one is small, you're better random guessing, you know. Better random guessing this community, and you're going to get more than half just because that community is much larger. But if they are about the same size, then you're flipping coins, and that's where the one half comes into play. But weak recovery is basically, can you do better than random? Okay, so that is resolved in this case. In this case, it happens basically in the sparse regime where P and Q are of order one over n. And there's a negative result saying if A and B are not separated enough, and that means A minus B squared is smaller than 2A plus B, then you cannot do it. And if they are separated enough, then you can do it. And these two papers propose slightly different algorithms. Slightly different algorithms. This uses a non-backtracking matrix. These guys are using message passing bleak propagation, basically. But basically, you know, that sort of solves the question of weak recovery. Then you can think about partial recovery. And the question here has to do with the results have to do with the signal to noise ratio, which you can think of this as. Which you can think of this as the second eigenvalue squared over the first eigenvalue, or in terms of the thresholds that we saw here, it's precisely this over this. And basically, all the results that I'm going to mention require kind of like large signal-to-noise ratio. There's a minimax rate, and it's of the form e to the signal-to-noise ratio. And then there had been several papers trying to reach that. Several papers trying to reach that. You know, constant factor away by Abby and Sandon, special constant still away by Chin Rao and Bu, and then these guys with some other co-authors managed to get optimal rate. Sorry, there should be, there's no over two. It actually matches this, except for the little one, with a two-step procedure. So you first do like. Procedure. So you first do like spectral clustering or something like that, and then you use that as a startup, and you do another step where you vote with your sort of like previous labels. And then finally, exact recovery also pretty much solved by these two papers. And this happens in the connectivity regime, namely because if you have any node that is not connected, then you Node that it's not connected, then you know you cannot do better than random for that guy. Um, so you're not going to get all the labels easy if you have isolated nodes. So, you have to go to the logarithmic connectivity regime. And again, you need sort of enough separation of the labels to sort of distinguish of the communities. Okay. So I'm getting close to end of time. So Getting close to the end of time, so I will try to speed up a little bit just to get to what we did. And the partially labeled SVM is the same model, but we also have some nodes revealed with probability delta. So we see this, each guy with probability delta. I'm going to skip previous work, but mostly has focus on local algorithms, okay? Namely, algorithms that can see Algorithms that can see up to sort of like T neighbor, T distance T neighbors, and kind of like propagate the labels from those and so on. And they, you know, they show that you can do some stuff, but they are not, you know, in other cases, it doesn't do much and so on. One paper that looked exciting was this by Saturn Nostrad. What was this by Saturn Nostrinia that basically said, okay, you can actually do exact recovery even at a lower separation. But we were able to prove that that requires so much side information that basically you can just vote with the side information and recover everything. So they do a complicated method, but you don't need to. Complicated method, but you don't need to do this semi-definite program on all of that. So that's one of our results. And then we wanted to say something about this QSD estimator, right? So we do what I just discussed, right? So you have revealed nodes for each community, you have the mu for each QSD for each reveal set, and then you just do the sign of mu minus. Do the sine of you know mu minus mu plus and I'm going to tell you what we can prove. And I'm going to do it again in the logarithmic regime because it's a little bit easier to formulate. We can prove a minimax rate. So any, you know, any estimator is going to have at least this error, okay? And we can prove that QSD achieves something close to that error. I mean, there's a factor away, right? So we have. A factor away, right? So we have an epsilon here, and the minimax is one over log, square root of log. So there's like a square root of log constant factor, but it's definitely nice that we get the sort of same exponent, same rate. And okay, so just to finish, so these are some ideas of what we have to do. ideas of what we have to do. The main thing is that we want to look at mu i and see it as a perturbation of mu bar times this and then the difference. And we basically show that this difference is small and this classifies correctly most of the time with you know with that rate. So this guy's this guy is going to be sort of like This guy is going to be sort of like big and positive when it has to be. This is going to be small, so this guy will still be positive when it should be, and so on. Um, all right, the last thing is some ongoing work, so here we don't have many results, but um, if we want partial recovery, so uh, you know, what's kind of nice is that we can get some recovery even in the region. In the region where you without site information, you cannot do it. So that's something I'm a bit excited about. So if you don't have any labels and you're on this part, then basically no algorithm can do better than random guessing. But if you have some site information, you can do better. Better and you know, how you know, trying to quantify how much better it's kind of what we are trying to understand, but it does do better, which is kind of nice. So, basically, that's kind of what I'm trying to say. So, that's our ongoing work. And the other thing that Michael is working hard on trying to get ready is a Python package that will make this pretty easy to use for. Pretty easy to use for people using network X or iGraphs. Okay, so that's it. Thank you very much. Yeah, no more questions. I think that's turned off. I couldn't hear what you said. Does it work now? Can you hear us? Yes. Okay, cool. Yeah, no, I think that was... Thank you, Nico. That was really cool. Very nice talk. Yeah, I'm still curious what, if anything, one can see from the question of how the. Of how, so, yeah, the substochastic matrix, it's somehow, yeah, it's measuring sort of ways things would propagate from the rest of the graph towards that absorbing state. But the pure complement should tell us something about how things flux into that state. I'm really curious. Yeah, we would be interesting to look at, I'd just be curious to look at the spectrum of Speak here is to look at the spectrum of both. I think we chatted a little bit about that. So, there's two things. One, that I think some of the lemmas that we proved, like, you know, concentration of this sort of transition probability matrix and so on, and should be useful for something like that. But generally, I think I agree. And the sure compromise will, it might actually work the other way around, right? Actually, it works the other way around, right? Like, it might be higher when you're in the same community and lower because you're going to flux more into the that, but it should have a similar behavior. Yeah, just curious. Of course, yours is much cheaper to compute, right? Like, you don't have to convert it. Yeah, I mean, it's kind of nice that we can use like, you know, just power it, you know, it scales pretty fast. I run it to like, you know, 10,000 nodes and it runs. Nodes and it ransomware. The other thing that's really nice is a lot of the error estimates on the dominant eigenvector and eigenvalue still be done for subcast PDFs. So, you know, probably you could have a lot of robustness. Yao had to leave. Thanks, Yao. Thank you for organizing. I think she's probably done. Okay. Well, thank you, Nico. No, thank you so much. All right. And have, yeah, thank you. Right, and have yeah, thank you for talking to the organizers and and uh i hope you all have uh safe flights back uh with no disruptions hopefully no disruptions no more delays for cancellation okay thank you nico yeah that's uh the end of uh this workshop uh we will continue the discussions okay thank you 