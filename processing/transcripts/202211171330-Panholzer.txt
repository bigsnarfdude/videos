To present some of my favourite topics to Naijame, I have to say that I realized afterwards that I already gave a talk on the same, with almost the same title, Cutting Down Trees, revisited in 2003 in Italy, that A of A 2003, but I promise it won't be the same context because I visited again. You can visit it again. Really, really visit it. Yes. So all starts with this cutting down procedure by Meyer Krun not far from here, from the University of Alberta in Edmonton. They considered this, as I mentioned, cutting down procedure for rooted trees. You pick Tree, so you pick a rooted tree, you choose an edge at random, you cut the edge and you discard, you remove the sub-tree which does not contain the original root. So this is, yeah, this one. And then you iterate this procedure. You just random edge and cut it off. Like this tree here. You cut it off, and after since you started this, finally. Since you started with the finite tree of the finite number of steps, you end up with the root isolated, and then questions of interest were how long does it take? So how many steps will you have to carry out? How many cuts until the trees cut down? This is the main interest here. And they started it to consider. To consider for a random tree model. And this tree model, we already heard several times. These are random KD trees, just rooted labeled trees. You could just end this famous recursive trees, random recursive trees. So for these two models, which behave often differently for various parameters because the shape is completely different, etc. So it's also here what they realized. What they realized, what they got is that if you consider the expectation of the variance for KD trees, you have the square root of n number of cuts. And if you do it for recursive trees, you have much more n overload. They are much pushier and so on. So they really behave different. And they used a recursive approach. It's very simple to do. It's it's very simple to to describe. I mean you make a cut and then the tree is smaller. Yes, and this is how much is it smaller? It's a distribution here. It depends on the family, of course, of trees. And then you iterate this. So you have this stochastic recurrence. And of course from this stochastic recurrence you can get a lot. So I just write it down here. What are these What are these distributions of the sub-tree size? Because it's for recursive trees, it's for Kv trees. And I also do it there because this is because of probabilists that got interested in that. It's because these are also certain models for fragmentation or for coalescence. So there's Althausen-Smittman coalescence and for Cool lessons and for the additive colours. Okay, but combinatorial, it's just this. And well, what I want to point out here is that, of course, this approach has quite a lot of limitations. I mean, the main limitation is that it's only applicable if the remaining subtree is again a random tree from the tree fundamental. Random tree from the tree family you study. So, this holds for Kali trees, this holds for recursive trees, but it doesn't hold, of course, for many other important random tree models. So, there's, of course, this limitation that you always have if you use this approach. Anyway, this is when I got into it, I tried to do this, tried for more tree families. Tried for more tree families. There's a characterization, which we already heard about simply generated tree families, so which one can preserve this randomness. These are probabilistic speaking, they have good one also if this off-stream distribution is Poisson binomial or negatively binomial distributed, but in this other world of combinatorial tree, it's okay with the... Combinatorial trees, occasion trees, theory trees, or generalized border trees. And what you get is, if you do it for more moments, or not just the first two, then you can really characterize the limiting distribution. So that's for all of these families you can do that, and you get the Rayleigh limiting distribution. For recursive trees, this doesn't work. This is unfortunately what This is unfortunately what we have seen also. This approach, this stuffing out moments, this cannot work. Let's keep qualities later. There we just realized the moments do not characterize the limit law. Okay, later on a generalization of that with Jim Phil, Nevin Capu and myself, we thought about We thought about cutting is costly, so it costs something, a toll function. So, and we had in mind some applications also for algorithmic, you know, algorithmic side, in particular, what we also heard about here today, union-fined algorithms. So j a study of this this so there we so each uh cutting costs something, the costs depend uh as as a function of the size of the tree and so on. Of the size of the tree, and so on. And we got limiting distribution where I could discharacterize this. And as I said, a slight extension of this together with Marcus Huber, we then did some analysis of this, you know, and find algorithms where the point was here that the tall not only depends on the total size of the tree, but also on the sub-tree sizes. This made it a bit more technical, but essentially. Made it a bit more technical, but essentially it's, of course, this problem. So, and then last but not least, there's this paper by Dermot Exon of Ruisler, where they really solve the problem for recursive trains. So, they got the limit law, it's a stable distribution, like this, this one stable Cauchy distribution. And of course, you have to use the right normalization. The right normalization, of course, and find it and did it. So, this is also an application of the recursive approach, but it was more involved here since they had couldn't use, of course, this moment approach, but they had to consider the binary generating functions, a generating function approach, and by careful analysis, of course, of the singular behavior, then they could treat this also. And that's essential. This is also. And that's essentially all of the recursive approach. And then there came the seminal paper of Swante Jansson, where he get a completely different approach by describing it via records. So you think about edge labels, every edge gets a label, and we say an edge is a record if it is the smallest, just the smallest. Smallest, just the smallest label along the path to the road. Here is most these dadges in red here. Here, the records. And then, of course, you don't need this randomness preservation property, as mentioned before, since you can a sum of random variables, indicate the random variables, if you study that from this point. Studied it from point of view. Well, and they made a lot of, okay, I think it's clear that this is equivalent. Each cut is an edge record and makes a vertical visa. And then he could generalize it a lot. First, he could, for all Golden Watson condition Golden Watson Reed or the common simply generated trees, you have this Rayleigh limit low, of course. So, of course, this parameter depends on the offstream distribution, and you could get many more results on that. In particular, what I also want to mention is it doesn't matter if you use the edge cutting procedure, the vertex cutting procedure, the vertex cutting, you choose vertices, not edges and cut off, is sometimes simpler to slightly simpler to study, but with the results and then. And then Cecilia Holmgreim, sorry, did a lot on cutting on split trees or log end trees. And there are many important families for which Leo could characterize the behavior. And well, then it started that in the probabilistic world there are many, many. World, there are many, many studies since there are treatments of this cutting procedure related to that, and they got many, many more extensions, refinements, and as I mentioned, relations to coalescence models, and so on. And I thought a bit: is this old approach, this recursive approach, maybe also useful to add at least the cleanse a bit to? Glimpse a bit to the whole picture of the many new studies that here came out. And there are a few things where maybe that one can add a little bit to what is already there by this alternative approach, by this original recursive approach. There are a few topics I promise I won't go into all details and and but I will not And but I will not do that all here, but and maybe focus on more on the on the first one, but I just wanted uh to list it here. There are several topics where one could do at least something with this recursive approach also. Okay, K-cutting. This is a nice generalization which was motivated also by resilient networks. Resilient network. So, if you cut once single network and there's some attack or something, so it will not break after the first attack. So, maybe only after the case one. And then you have this cut. So, each node has to be cut K times before it really is discarded or removed. So, this is the difference here. And one can, of course, this And one can, of course, this consider for various tree models, and in this paper, De Roud, Hollingren, and Spearman, or by Del Son and Holling, they did it for several trees. The first one, which I will refer mostly here, are pass and then as a generalization, paths like grass, but stick here to pass. Others were called Watson trees. We're called Watson trees that has also been studied. So, what is the limiting behavior of the requested cuts to cut down a tree? And it turns out it changes a lot if k is 1 or it is larger than 1. Okay, k equals 1 is, of course, very, very classical. You have a pass here. I stick here to pass now. You have a pass. The number of rays. Are the number of records in the sequence of writings? So the number of left to right maxima or minima by the cycle representation, the number of cycles in a random promotation. Yes, this is very classical, this result that you have your expectation, har harmonic numbers, so log n and square. The the the the variance also of overlog. For the law, normal limit law, and much more, of course, as well. Okay, and but for k larger than one, it's a quite complicated structure, quite complicated characterization of the limiting behavior. And in this before-mentioned work, so the moments were considered, of course, you already see here, of course, it's no more log n, it's something else, n to the one minor. n to the above 1 minor, minus 1 over k expectation. And well, there doesn't seem to be any nice coefficients there. It starts get quickly rather complicated. And it's also what mentioned in this work. The moments are rather complicated, rather involved to get to them. But they were able to already describe the limiting distribution. Described the limiting distribution. Also, not so simple, as you can see, as here involved infinite sums, etc., of random variables which are constructed by the uniform distribution, by exponential distribution. Cable just stated there, so it's rather complicated. And let's see what this recursive approach can do. Uh can do. Um I first stick on this uh k equals two because everything uh can then be transferred also to larger k. But k equals two has everything inside, let's say, for the recursive approach and it's not technical, it's not too complicated. So the recursive approach. We want to to cut a pass. That means if we cut a brick, so this is our wall, if we cut a brick or we hit a brick, We hit a brick once, okay, it well, it's still there, okay, but it changes color for some reason. And so we know it's already handsy to do that game. And after a while, you will here again meet a the brick for the for the second time and then it breaks, the ball breaks and everything behind. So this is so is this is still refusive. This is still requisite. And do that, you'll quickly see this. Yes, one has to take care, of course, of the nodes which have been cut already once. And this immediately leads to an Earl model description. You have your white bricks and your black bricks and a certain non-deterministic ball replacement scheme. You have a white brick, it changes colour, or you put it out of the urn and put back a black brick. But if you uh go to your own have a black brick, then again you will take a random number of bricks out and throw it away. I mean the randomness I mean can describe, but it's a certain random number of bricks that you put out. And that's it. That's the scheme and of course this is a can recursively described and attacked. So if you do that, so extending If you do that, so extending the problem by, of course, take care of this new parameter, then you have again a stochastic recurrence, which is not too complicated. It's just the novel description there. And then you can attack it, for example, this preferred method with generating functions. And what you get is, if you do that with generating functions, then you get, yes, as known, also from. Known also from many work before PDEs, but they are nice, linear, first order. And it didn't matter that you have here a random whole replacement scheme, it works anywhere. So you have here a rather nice PDE which can be solved explicitly, and we are only interested, of course, in the original problem, we are no more interested in this extra pyramid, the how many black bricks. How many black bricks are there in also? So, this was just an auxiliary variable, a catalytic variable, however you want to call it. Afterwards, it's no more interesting and we can step back. So, you get a rather explicit generating function. And if you have something explicit, it should be possible to say something about it. And this exactly, for example, you can now pump out the moments. So, from this, you can do that. So, from this, you can do that. And just for the, I stick here, I want to bring here the expectation because it has a nice explicit formula. And you see here the harmonic numbers, and you see here Ramanujan's Q function. And this should bring some connection to another possible description of this, since Description of this. Since you could also think about first, this is coupons collecting. Yes, you collect your coupons, you have here your N, your list, and you collect coupons. And if you have the first pair, yes, then you will cut. But what is this coupon collecting? It's the expected number of coupons you collect until you have the first pair. This is exactly given by Ramanuj-John's Q function. So it's somehow nice that and the number of cuts you would need, expected number the harmonic numbers. So it's somehow fine that they are nice that they are all there in some sense. Okay, but what I wanted to say about the asymptotics. Yeah, the asymptotics of the integer model. You can characterize it completely. So this, I cannot give you it in a much nicer form, but it's just, it's given by. Just, it's given by the coefficients of this elementary function. And that's it. These are the coefficients of this elementary function. I mean, you could. The exponent has a nice expansion, of course, but not, of course, the whole exponential of that. But that's it. So these are the. And from this, of course, you can just say by Foucher more. By Foucher moment convergence theorem, also, it must, of course, converge. And if you like, you could also write down the moment-generating function in some nicer way by using the Neutral-Gleflo transform and just a generalization of the Laplace-Borel transform because you have here not the m factorial, but some, let's say, m half-factorial or something, yes, and therefore you need another transform, but it does the same, and this mid. Same, and these mitra-Glefler functions have a nice, a rather nice description for, for example, one-half where one needed it. So, therefore, one gets also a representation of the moment-generating function. This is the mid-degree-GLEFLAR function, given with the error by the error function, and this is just what we see. So, this is the representation, so an alternative representation. Representation here via method of moments or the moment generating function, which is possible. Oh, this was not. We lost this. Oh, okay, great. So, as I mentioned, for general K, things work also. Everything is a bit more technical, but you have much more ball colors, more type of balls, and then you get, of course. Then you get, of course, linear first-order PDEs with a lot of variables, but still it is explicitly solved. This is the nice fact. You can really get an explicit form. And here it is. And when you see, it's rather simple. It's just the truncated exponential function which is there and everything. And if you go into the paper of Flageolais, Gardi, and Flageolais, Gardy and Timonier, I guess, about coupon collecting, Boisley paradox and so on. There should be some other, some alternative approach to get it directly, not via the PDEs, because it looks somehow from this structure. But at present I only have this approach via PDEs, and then you end up with this. And then you end up with this. Okay, and everything works out fine. Also, for this kind, and I don't want to go into detail, you get the same thing and characterize the moment. They are in general then this phi of w no more an elementary function, but integral of elementary function, and then you can get it and characterize. Get it and characterize it via the moment generating function again by using the meta-graffler function. Okay, so this is a bit on K-cuts in pars. What about trees? Well, monk could do something, but I guess it will not give you can add something interesting because everything has already been been there in these nice papers. Nice papers by Sunsearchondre and also by Wam, where they characterized the limiting distribution for condition called Watson trees, and they characterized it via the moments. So what we see now for parsley did it for moments. And there's also a description as a function of the Brownian continuum random tree. And if you try to do that with this recursive approach, Approach, you can, of course, stick to one instance since you know the function of the Browning continuum random tree, so you stick to any preferred representation, for example Cayley trees. Yes, and you get again linear first-order PDEs. That's according to the approach. This is what you will get. But one cannot hope that any such PDE is explicitly soverable and Is explicitly social, and so it's the case. You won't get here an explicit solution. You can, of course, stick to the moments and pump out iterately the moments. And then, yeah, you cannot get more than what is already there. One could rephrase it with this. Okay, there would one we did a bit also on other problems, isolating multiple nodes in trees. Isolating multiple nodes in trees, or separating nodes from the root in trees, some things which also have been studied by probabilistic approaches recently. But I don't want to go into detail there. I think it's maybe better just to stop it here and I will well of course lo uh upload it then so if someone is in interest you can look at me. Thank you. Those distributions that you characterized by moments, were you able to identify them as sort of classical more or less? Or well distributed. According to them they are According to them, they are this is what I said, definitely no classical distributions. In the paper mentioned first, there also have been a bit done about the density. So it's known that the density exists, but I guess not much more. The last two things that you were referring to are also for very simple. Are also for very simple tricks? Is there any chance you can do it for recursive tricks? Yeah, this is what I did not mention. Of course, the approach is applicable and you get the PDE, first order linear PD. But the point is, and you could again try to pump out moments, but this won't help, even for the case k equal 1. Yeah, definitely there is again some kind of distribution where the moments they That the moments, the integer moments do not exist. Therefore, I do not think that it is possible to attack this problem directly by this approach because I don't see a way to solve the PDE directly, and so I'm not too optimistic. I'm not too optimistic about this, but of course, it's one of the things I will consider further as we are. The cases you mentioned where the density can be proven to exist, is it by treatment of the characteristic function or what? No, not by the characteristic function. But this is more because the characteristic function hasn't been given before. Even before, but then I have to say this question I should refer to. Like, we see Ramanojan's Q function in the memory. That's quite interesting. I was wondering, we also see more general functions. Well, I mean, as I mentioned, Ramanujan's Q function. function somehow that it appears is due to the is simply due to this coupon collecting. So then since essentially the problem you could always think about you do coupon collecting and after you have a pair or a trickle or whatever, okay times, then okay, so then so it's a mixture of two things: coupon collecting and the cutting. And the cutting. Well, the cutting then is again random. I mean, it's the same cutting as k equal one. You cut off. This doesn't change. But the time you have to wait until the cut. This is of course given for k equal two. Here you have, if you start random, then you get this Raman-Newton's Q function. But the point is, afterwards, if you do this for the first time, then you have already a set. then you have already a set of a certain compose you collected, yes? So you do not start by zero, you have already some. And then of course this I mean one could do that and describe it, let's say this is what I'm not strong enough in probability, but it's rather simple if you do this approach, then you get it characterized as a fixed point. Yes, this is a fixed point equation. Of course not one has to add a Um one has to to add a a second parameter, another since it it depends on how many uh uh how many of the coupons you already have. So this, you know, so this ratio over squareable fat is important. But so I was not so maybe I did not answer your question, but it's not so surprising that this q function occurs, I guess. Since it's just q control. Okay, let's think our speaker. Can we press the button to stop the recording? To stop the recording?