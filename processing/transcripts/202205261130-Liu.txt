Joint work with Jen Chen and Jen Sun from MSU and Robert Burridge from UNM. And we'll discuss two kinds of inhomogeneous problems satisfying, for example, the scalar harmonic equation. The very first one is suppose we have this square computational domain filled with some inhomogeneous six-lones and another. Is n. And the second one is in homogeneous subdomain sitting in a background media, which is homogeneous. And I mean, there's a variety of numerical methods for solving these problems. And today we're going to touch three of them. First one is a finite difference frequency domain, or FDFD, which can handle both type of problems. And this descriptes the whole domain with NF grids, including the PML layer, and describing the wave equation. Know describing the wave equation leads to a nf by n for a spar system to be inverted. And the second one is the volume integral equation or VIE, which can essentially only handle the second kind of problem here. Oh, sorry. It formulates the problem into integral form and discretize the homogeneous sub-region with the MV basis functions. And MV is typically smaller than F. And this leads to, however, And this leads to, however, dense system to be inverted. And the third one, which is the main focus of today's talk, is the one sort of asymptotic method that we found works pretty well in many scenarios. And for all these three methods, we leverage the so-called butterflock compression to reduce essentially the solver cost for high-frequency regime. And let me first quickly discuss. Let me first quickly describe the state of art of the FDFD and the VAI direct solvers. The FDFD sparse system is typically handled by multifrontal sparse direct solver, which reorder the sparse system due to this net dissection. Each node here represents one row or column of the matrix. And the real system will only introduce non-zeros. Will only introduce nazios, new nazos into this hard-colored blocks during the LU factorization following the arithmetics and guided by the so-called multifrontal tree or assembly tree. In this recent work, we leveraged the butterfly algorithms to accelerate this multifrontal solver. And the resulting solver actually can attend linear complexity for 2D high-frequency ham hole. For 2D high-frequency ham holes and quasi-linear for 3D high-frequency ham holes compared to, say, HSS is essentially has the same complexity as exact hours in hypercompany regime. So these two figures show two updated figures based on, I mean, following this paper, which is this is the CPU complexity, this is the memory. And we actually combine this butterfly alzone with some, you know. Butterfly algorithm with some lower algorithms for smaller blocks in this pattern, and we're able to go to almost 500 cube problem. This is like using 15 points per equivalence or something like that. However, any different equation solver can suffer from numerical dispersion. Also, the metric inversion can also suffer from other numerical issues, for example, zero purity or Zero purity, or of course, your conditioning-based accuracy requirement. As a result, it's very hard to attain high accuracy with FDFD. And then typically, any different equations over, so one typically needs a large number of grid points per evaluation to compensate for that. And for the second kind of problem, which is a subdomain that is inhomogeneous, the very solar formula is the problem. However, we'll formulate the problem into Graham equation form using the background green function in terms of the equivalent source in the scatter. And described as the MV by MV system can be inverted by fast direct solvers and described by a few fairly recent papers on different formats. And we also developed in this paper about the battery direct hours for involving the VIE. For inverting the VIE, which essentially kind of turns NS3 half-log and complexity into the NS3D. And there we show that this is CPU and the memory. And the yellow triangle and the red circle are essentially the compression time and the immersion time of this button of these solvers. And however, the size of this base system to be inverted is still very large. To be inverted is still very large, even when direct factor suffers are used. And again, the inversion can suffer from things like high contrast breakdown or negative permittivity breakdown. So these existing methods require large system inversion to construct essentially the numerical grain function for those in homogeneous media, which can suffer from these few numerical issues. Numerical issues. And in contrast, if we can, you know, I mean, we can also consider direct constructing the Green's function, right, with high-frequency asymmetrics and using phase and amputee functions. One popular choice is the geopric Ansar, but a few of us already mentioned it this morning that it suffers from accuracy degradation near the south region. Near the south region. Another one is the Hadama Baby trans, which actually has uniform convergence in the entire domain, except, of course, the point south itself. And the Jen Lang chan shows that one can compute the phase and amplitude function to a high accuracy, a higher accuracy, and in the entire computation domain. However, that's only demonstrated for a point source. If we can quickly Source. If we can quickly construct the Baby Channels for arbitrary source function s, and then it means that for this first kind of problems, we only require, you know, tabular discretized Green's function, and we require no inversion. And suppose there's, furthermore, if suppose we have the surface inclusion inside, then we only need to inversion of the surface IE operator. This is just a small operator. And for the second problems, also, now we only. Problems also now we only need to solve a transmission problem, which only involves surface size operators of the outside green function and this green function answers. So the Barbish transfer actually works as follows. So assume the slowness or the n is smooth without permitting any caustic phenomena in the domain. And then the answers can be expanded using the Can be expanded, you know, using the phase function tau and the amplitude function vs, and typically, and including, I mean, in addition to some, you know, how other Hancock function. And typically, one need, you know, one or two terms in this expansion. And the phase function satisfy the kernel equation or square kernel equation in this sense. And the amplitude function Vs, again, S equal to zero or one, or two at most, satisfied this recurrent system transport equations. And for suppose the point source is located, what's going on with my sorry, so the point source is located at R0, and one can compute this phase and amplitude function to how the accuracy in essential quadrilinear time by using a time by using some some Helder initialization using Taylor expansion near near near the soft point and the Hilder window scheme or weighted essentially auxiliary schemes on financing some difference grades for solving the ukerno and the transport equations and and now uh consider arbitrary source function s in the square domain again we consider the first problem kind of problem first and and and uh want to compute this you know discretized nv by n v operator Syncretized NV by NV operator or Barbish integrator, P V to V, which tabulates all the answers and interactions of the entire domain. But of course, we cannot afford solving the phase amplitude function for all NV point sources. And also, we cannot afford forming or fully computing the bit V operators. And we rely on, we propose two steps to compute this bit V operator in quality. This bit we operate in quadrilinear time. First, we notice that the phase function and the amplitude function denoted by f is not oscillatory and it permits a Lorentz representation, which can be constructed using Shabbatshaf interpolations. So here, the Ti and the TJ are Lagrange interpolation interplongs, and the Ri C and Rij, sorry, IJC. J, sorry, ijc, rjc are the shepherdshoe interpolation nodes. And this and I, the shepherd interpolation order is a small constant, or it represents the rank of these functions. And now we need to compute, right? Compute and store this ingredients, face ambulance ingredients at this Shapiro interpolation node pairs. And to do that, Node pairs. And to do that, we'll perform the window computation of the Kernon transfer equation for each of the point source located at the shape of nodes using, say, a finite difference grade of NW grid points. For example, here we have a source point denoted by red that's located on one of those black shapes of nodes. And we run window and we get the results. And we get the results on all the uniform grids, you know, by grid points here. And then we interpret the fields on the, I mean, the results on the grid points onto the observation shape of nodes in yellow using, say, say, a local interpolation, say, cubic interpolation. We realize that the grid size in Windows is frequency independent. So this step can be done in the offline stage. On the on-land stage, the F function. Stage the f function of any source observation pair that can be computed in constant time using the interpolation. Then we construct the compression of the K to K operator using say this hierarchically off-diagonal butterfly representation or HO DBF. So this off-diagonal off-diagonal block of this k-v2 operator is represented using the butterfly format. The butterfly representation or algorithm is what. Of representation or algorithms was essentially started by Eric Smichosen, and then many experts here or in the community have contributed. Mike, James, Lexing Ying, Hai Zhao, Ken Ho, Ying Zhou, and the Dela collaborator, etc. The butterfly representation relies on the fact that the numerical ranks of these sub-blocks shown here are small. And then we can construct a multi-level factorization of other login levels, and that is the size of this block, by essentially computing the Lorentz products of each of these sub-blocks. Note that we don't need to fully form these blocks before the compression. And because each of the sub-block highlighted here corresponds to one of the sub-domain pairs in below. So this is the completion domain. Completion domain. So the top of the angle block corresponds to the interaction between the two left half and the red half. And it turns out that we only need to feel matrix entries that corresponds to the pairs of the green dots, which are the skeleton dots and the red and yellow dots, which are some near-field buffers and some uniform far-field proxy points. This means to get these entries, To get this entries, G of these pairs, we need the ingredients, the free phase and the amplitude function ingredients, which are again computed from the already existing Lorentz representation. And now I can compress, we'll have a compressed representation of the width operator, and then we can compute the field everywhere in the domain by Sorry, but you essentially meta back of the discretized source function vector. And we can do some comparison between FD and the Barbich integrator. And here we consider three types of the inhominous media in 2D. The first one is a constant gradient where the inverse of the slowness has the constant gradient in a y direction. And then secondly, the profile has a sinusoidal sub-soil variation in both directions. solidal variation in both directions. And the third one is a waveguide media where you start from max equal to 0.5, you should have a decaying, exponential decaying inverse of the solidus. And we consider different source functions. These are point sources and this is some sort of Gaussian packet source, which is Gaussian located at Rc, but also have some sort of a frequency modulation. And this first column is This first column is the field computed by the Barbish integrator in linear scale. And the second one is the difference between the FTB result and the Barbish in log scale. And this is some field on a certain y value across the domain with different servers. And we can see for the first one, it's like 200 equivalents in each direction. So it's too difficult. You know, too difficult to see the oscillations here. But yeah, it's 200 reverse in each direction. And we can see the Barbish integrator always needs at most 10 points per evalence, PPW point per evaluance. And the FD solver sometimes oftentimes requires more than 50 points per evaluance to be comparable with the FDFD result. Sorry, with the Barbish integral result. Result. And we can also look at 3D domains. And here we consider the domain. Again, it's a constant gradient. It has a inverse of slowness as the inverse of slowness has a constant gradient in Y. We consider the point source and the Gaussian wave packet. This is about 27 wavelengths for the domain, excluding the PML FDFD is used. For FDFD, we can only go up to almost 10 pounds per. Go up to almost 10 points per awareness, then it becomes impossible to invert by the FDF dissolver. And for the Bifer-based Barbish integrator, it's about 5.1. And in fact, for this 3D constant media gradient media, there's analytical expression for the Green function. So you can see that it matches perfectly well with the analytical, I mean, with the Shui. I mean, with the Shui solution. We can also validate the complexity of this barbage integrator for the 3D example. The CPU is here, memory is here, memory is called a linear. CPU here actually behaves as n four-third. And this is really due to the fact that we're using some this kind of a weak and weak unmissable type of hierarchical metrics, this H-O-D-B-F. And on the other hand, so. And we can essentially drive this down to quadrilinear by using a strong admissible version. What we found is we tried the strong admissible one, but it sounds like it feels, I mean, it seems like the accuracy we see for the strong case, admissible case, is worse. And the leading constant is quite high there. So we stick with the weaknessability here. We'll also validate the 2D complexes on a later slide. Is on a later slide. Now, here we can, you know, basically understand how the Barbich integrator behaves, but by looking at this again, this is 3D constant gradient media. I mean, it has, as I said, it has an analytical solution for the Green's function and also for the phase function. So if you look at the error source of this barbage scheme, it consists of, say, the expansion error of the Babbage and Of the barbage and the face ample errors due to the window computation, and the phase and amplitude error due to the interpolation, and also the butterfly compression error. So, here I'm only going to consider the first type of two types of errors by considering a point source. So, there's no interpolation needed, there's no butterfly compression involved. So, the first figure shows that if we use, say, a better order we know for solving the Yukono equation for the phase. Solving the Yukono equation for the phase, we can attain a better order accuracy in terms of the winnow grid size for tau, and at most better minus two for zero, better minus four for one. This is what I did here by using three orders and looking at the phase errors. And to assemble the arbitrary integrator, we have to consider the fifth. We actually consider fifth order window. So third order for V0, first order for V1. And if you just look at the Barbish expansion, for 3D, if you just had one term, then it's one over K convergence. If you have two terms, it's one over omega square. Here we actually validate that, but you can see after some further analysis, you can show it's actually composed of these several terms. It's actually composed of these several terms. The first term is one over so this is only a two-term formula. So the first term is the Babbish expansion error, one over omega k squared. This is the third order for the V0 and first order for V1. So this omega comes from the integrator where you have the omega vectors in front. Omega vectors in front of the Hankel function. And then for the phase, it's fifth order, and it's amplified by the frequency because it's a phase. So that's what it's showing here. And suppose each, so in the beginning, as you increase the frequency, you see the one over omega square, but later it's dominated by this linear term, so it's becoming linear. But again, we can just reduce the H0, the great size in window, to. H0, the grease thing we know to suppress this term to further push the cross over point. And again, we need to mention that this H0 is a window grid, so it's frequency dependent. And it doesn't affect the size of it, doesn't affect the computational cost of button compression because we already interpolated those field values on the interpolation nodes. And now we have a way to construct the in-home. Uh, we have a way to construct the inhomogeneous medial grain structure. Let's see how what else we can do with it. First, let's try this sound hard inclusion discrete as with an S line segment. The solution operator for arbitrary results, again, I mean, it takes the following form. Now, we also have a surface operator that is again discretized, I mean, stored as the HODBF format. And we have the surface to volume, volume to surface operators, which are constructed. Are constructed as a single butterfly. So again, we'll apply the trick, the two steps to avoid the corrective cost for handling this B2S S2B operator. Once again, we test these three types of inhomogeneous in 2D, constant gradient, soido, and a dialectical waveguide. And again, you can see that for FDFD, one typically requires 50 points per wave lens. Requires 50 points per live loop. This is the 2D complexity validation. In fact, including a surface inclusion, and you can say this CPU, this is the memory memories, everything is quadrilinear. For CPU, the V2A operator corresponds to the fact that the case where there's no inclusion, which is already quadrilinear, but if there's inclusion involved, then there's this 7-6 term, which corresponds to the single button representation of the B2S and S. But of a representation of the V2S and S2A operator. So that still can be reduced to linear by using some strong missible variant. We can also consider the second type of problem where we have this inhomogeneous subnoman V2 sitting in a background V1. And again, this is the solution operator similar to the previous case, but now this surface operator involves basically solved the transmission problem of two domains. Uh, of the two domains. So, here it's uh uh so this subdomain has a constant gradient uh media. This is a homogeneous domain where we have this uh Gaussian with a packet sales function. And uh we compare the FFD and the Barbic, this SAE Barbic solver, as well as the VIE solver, because VA also applies to this case. So, all the three solvers are part of the compressed, and and this is you know at And this is at one y value of this image. Again, I mean, the FDFD requires at least 50 points problems. That number can only be worse for larger problems. And the VA and the Barbish equals are both pretty accurate. If you compare the three solvers for 2D cases, either with a surface inclusion or two or multiple domains, for the FDF data VIE, we requires inverting a large system. Requires inverting a large system, but the barbage software requires at most small inversion. And then the FDFD has the lowest CPU cost. Barbage SAE has second lowest, but again, it can also be reduced to linear. And FTFD requires large point coordinates. That's the message we want to convey. And the VIE and the barbage require small point coordinates. And however, FTF and VIE can both handle arbitrary slowness profile, but for the barbage server, we can only support. Barbish solar, we can only support currently support the smooth media without permitting caustic effects. And the bay, of course, I said only applies to the second kind of problems. On us of studying the barbish integrator is also related to what Mec asked this morning is it shows us how the butterfly rank would behave in the inverse operator for the FDD and the VIE systems. And, you know, at least for this small. At least for this smooth media, this shows the ranks of this inverse operators should be bounded. And this is some software. So we're relying for the FDD, but we're relying on the strong pack and the butterfly pack. For the VIE and the Barbage, we actually use the Bataval Pack. It supports a variety of formats. I guess I don't have time to talk about it. For inclusion, we will focus on the Barbage. We focus on the Barbie trans-based solver and compared to FDA and the VIE solver for inhomogeneous media and the dielectrics. For point source, the Barbie trans can attend high accuracy at high frequency, assuming the media is smooth. And for arbitrary source, we propose a level representation of the phase amplifi functions and the button compression of the statistical test IE operator. It requires no system inversion or at most a small SIE inversion. A small SI immersion. So it's fast and accurate compared to other methods. And for future work, we're working on extending the Barbie chandlers to, you know, I mean, to again leverage the Baby Trainers to understand the ranks of the inverse of the VA in FDFD and extend the Barbie chandlers to handle nasmus media with caustics and also demonstrate its 3D max or elastics problem. That's all. Some acknowledgement. Thank you. Thank you. Great. Thanks very much, Hang. We've got a couple minutes, time for one or two questions. Gunner, got your hand up from before. Is that from before? All right, can you hear me now? Yeah, I got you now. Oh, okay, great. So one comment and one question. So the comment, I think it's a little, I don't fully sympathize with the statement that you need 50 points per wavelength for discretizing the differential equation. You certainly can use high-order methods there. Right, right, right. Right, right, right. My question was your statement on slide four that if you use a Lippmann-Schwinger formulation, that leads to ill-conditioning. Like that's Alex mentioned something along these lines as well. So I'm a little surprised. Like, are you saying that Philip Marshwinger equation introduces artificial ill conditioning beyond what's in the physics? Or? I mean, so at least empirically, we see for studying. Empirically, we see for studying Maxwell that if the permittivity is very high, then you can suffer from your conditioning. It seems to me it's more like a high-frequency ill conditioning because when the contract is high, the wave number in the medium is in the subscatter is high. Also, it's also, you know, when the It's also, you know, when the permittivity is negative or this meta-service busyness, the system is also very ill-conditioned. I think in the, depending on the maximal representation you use for the solution, there's factors of the ratios of the permeabilities or the permittivities out in front of various integral operators. So it artificially makes sort of the number in front of the first kind terms large. First kind terms large. Exactly. Exactly. But I don't know if that's true for all representations. I can't think off the top of my head. Again, I mean, as I mentioned, for the way I, the main issue is really the inversion requires a large system. Maybe sometimes it's not necessary. For soft media, it's definitely not necessary. Thanks. And then Alex had a question too. I guess so. Is it still on? Yeah. I mean, just to respond to Kanner, my understanding, and having talked to Charlie Epstein about this and tried to analyze it a little, is that the things like for the Helmholtz, the volume integral formulation, just like Yang has on the screen right now, are sort of there's fundamental cancellation. Sort of, there's fundamental cancellations occurring. So you can't avoid a condition number growing, at least like K. So I think it's a problem with the formulation. So, and if you look at Green Guard, Vico FFT iterative method to do volume integral scattering. It almost doesn't matter what the medium is doing, even if you don't have to have a high contrast, but the If you don't have to have a high contrast, but the thing just you're getting to thousands of GM res iterations, and it just, you know, once you get a lot of wavelengths across, then the condition number grows. So I don't know, I still think that's an open problem. And so that's why direct solvers for volume integral are important, I think. So this is really cool work. Yang, I mean, there's an awful lot going on there. So thank you. Just a comment based on your comment that I mean for AIE makes the problem, the high-frequency problem easier. I mean, because the size of the system is quite large and in terms of wavelengths in each direction, it's typically much smaller than 2D. So, I mean, the capability of existing butterfly of lower-hand-based direct servers are only be able. Only be able to reach a certain number of wiles per direction because of that. So, in that case, you can see in this figure that the lower hand-based number is not that bad until 10 million unknowns. Right. So, I guess my question is, yeah, I mean, this is impressive. There's an awful lot packed in there. You're kind of compressing this greens function. Compressing this green function that comes semi-analytically, and then doing volume compression using butterfly scheme. But it sort of leaves the question: why can't you, I mean, you have these formulae for the smooth eigenal solutions. Why can't you just use the, and those eichenal solutions are, they only have order one information, right? They are not, they're omega-independent. So, why can't you? Omega independent. So, why can't you? You've basically already written down a compressed representation for the Green's function from any point to any other point in terms of these Eichenel solutions. So why don't you just Chebyshev the Eichenel solutions or something like that? It seems like you're doing this extra work where you first construct the high-frequency solutions and then you butterfly compress them away again when in fact... Away again when in fact you could just work with the Babbage formulae every time you need to apply the greens to the interactions. Do you see what I'm getting at? It's technical, but I don't know if you look into it at all. If you're just interested in the solution of a point source or arbitrary source, but at a given observation point, of course, you don't have to do the compression. Have to do the compression, but the trick is here: we want to tabulate this out-to-all interaction because we're interested in seeing the field in the entire domain due to arbitrary source functions. So, it's really a discretized solution operator that we can hardly use. So, that's why we do this compression. And also, this low-rank compression, I don't know whether that's something also you ask, but this. That's something also you ask, but this lower compression of these phase and amplitude functions, we cannot compute them on the fly, right? Because we can only compute them by running the window on a reuniform grade for point sources, right? Right, you have to do a PD solve. That's right. So we have to tabulate the flow. Yeah. Yeah. Okay. Well, it's really cool stuff anyway. So thank you. Thanks, guys. Okay, so we should turn it over to Jason. It over to Jason.