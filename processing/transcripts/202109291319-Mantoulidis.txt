Property that they only encounter spherical and cylindrical singularities. And so, by using this infinitesimal information, you can hope to go back to the original picture, the non-infinitesimal picture, and say that, oh, the actual nearby flows also encounter only spherical and cylindrical singularities. So, this is a very, very high-level overview of what's going on, but I just want to speak. But I just want to spend a few minutes to say something about this classification stuff, the classification machinery that we had to develop. So, we have two different classification theorems. The first one is technical, and it's the theorem that we use in the first part of the first theorem, the one that has no entropy assumption whatsoever. If you recall, this part has no entropy assumption whatsoever, whereas everything else does have an entropy assumption. Else does have an entropy assumption. So, this part, the first one, requires a very technical classification theorem, whereas the ones with the entropy assumption just rely on a quite elegant but very soft geometric classification theorem. So I won't spend time on the soft classification theorem here because I only have so much time. Briefly speaking, it says that if you have Have a shrinker, and if you can center another shrinker on one of its sides, flow them both, and have these things not intersect, then this places very rigid constraint on what your shrinker is. And this allows you to conclude, but it's not what I want to focus on. What I want to focus on is what I was saying here. Focus on is what I was saying here. So let's suppose sigma is your singularity model that you're hoping to understand well. In our case, what we want to rule out is a singularity model based on a compact, unstable shrinker or an asymptotically conical shrinker. Okay, this is what our theorem allows us to flow away from. Then the conclusion is that there Then the conclusion is that there is a unique ancient mean curvature flow that sits on one side of the shrinker. So, this is the evolution of a shrinker, right? Because it shrinks homothetically, and then the only power of t that works to shrink u homothetically in this flow is just root, root negative t, if t is the singular time. Then, up to multiples, so let's place an entropy assumption to prevent multiples. This, there's only one. There's only one flow that sits on one side of that shrinker, and that shrinker, that flow is what is called shrinker mean convex. But more importantly, that flow has only spherical and cylindrical singularities. So, okay, this sounds very geometric, but the proof is very analytic. So, the proof is essentially a souped-up version of a very elegant. Of a very elegant dynamics lemma by Merlin Zag. And let me tell you a couple of things about what's going on. We essentially have a solution to a parabolic equation. So let's look at the flow that sits on one side of our shrinker as a graph over our shrinker. So we can view it as a time-dependent graph, which evolves according to some According to some flow, which we can linearize with an error term. And most importantly, this flow is ancient, meaning it exists for all negative times. Now, this operator, the linearization, has a nice spectrum. And the key steps are that, first of all, well, the first step is to just break apart your Just break apart your U into its modes. So write U. So project U onto all the modes, onto all the eigenvalues, or rather, all eigenspaces. The second part is a consequence of Merle and Zag. This allows you to conclude that You to conclude that the stable eigenspaces are actually negligible as you go to negative infinity. So all the stable eigenvalues will be dominated by the unstable eigenvalues as you go to infinity. So stable eigenvalues are dominated. So we're really only therefore interested in understanding the dynamics over a finite dimensional. The dynamics over a finite-dimensional space of the non-positive eigenvalues. So, then by an iterative version of Merlin-Zag, one can prove that there exists a dominating eigenspace, and all the other eigenspaces are little O of this dominating eigenspace. But now, if you have a dominating eigenspace, this means that the eigenvalues dominate the L2 behavior. You can also prove they dominate in a specific way in a point-wise sense. But then let's keep in mind that our solution u is positive. Now, because we're working in this codeimension one setting, we know that the only eigenvalue that has a positive eigenfunction is the first one, and it's a simple eigenfunction. First one, and it's a simple eigenfunction. So, because u is positive, we can conclude that it's the first eigenfunction that dominates. And because it's the first eigenfunction that dominates, we can conclude that L U has a sign, which is what allows us to conclude this shrinker mean convexity. And therefore, the nice geometric consequence that it affords us. This technique of Merlin-Zag, I need to say that we got very deep inspiration from the work of Angenant, Dascalopoulos, and Sesum. It's a co-authored work. Co-authored work, and it has been used in a lot of cases recently to settle very interesting questions in geometric flows by Brendel, by Kyung Su Choi, Hasselhofer, Kershkowitz, and so on. But I've said enough. Let me stop here and thank you for your attention. Thank you for the very nice talk and nice results. Are there any questions? Feel free to unmute yourself and ask. Hi, Christos. Very nice talk and amazing result. I'm just one quick question. So in these theorems, you talk about the generic. Yes. What do you mean generic? I mean, can you give like an example of like initial condition where this is the theorem works? So this is an example of a condition where you have to perturb. Is an example of a condition where you have to perturb it in a generic way. So the Anglian torus is non-generic. Yeah. But if you perturb it in one direction, then you can approximate. So, okay, specifically by generic, I mean bare generic. So the intersection of an open dense set of initial conditions. This is specifically what I mean. And you can prove that kind of thing by these approximations. If you have a sequence that approximates it, you can do a trick to prove that, oh, okay. It you can do a trick to prove that okay, you do have bare genericity, but specifically, I mean bare generic. So, let me write it down somewhere. And you mean dense in C infinity? Density? Yes, yeah. Any topology that you can do would be fine. That is correct. But if you can do like C2 alpha, that's totally fine. People will still be very happy. Very generic here. So, in the sense of a bear category. Is that what you were this is the usual genericity that we use in these kinds of things? So, the same genericity is used for minimal surfaces and so on. So, I think it's kind of like the standard one. I think it's kind of like the standard one. I have a quick question. So, Otis in his talk on a different problem emphasized the analogy between these lambda p lanes and this linear phenomenon of eigenodes. Is there a linear problem that we're all familiar with that has the same character of perturbing initial data to see only good singularities, or is this too non-linear a problem for such an analog to exist? Um, let's see. In the linear world, you have this issue where, like the dynamics, I guess, they're they just come from matrices. So it's a bit more standard, right? Yeah. So I don't have a good I don't have a good answer to that off the top of my head for a linear problem, to be honest. Yeah, some of that. It's possible that somebody in the audience does know the answer to your question that I don't, but off the top of my head, I don't have a good linear analog. Because again, the issue is that even if you linearize things here, the issue is that you need to get into the situation. That you need to get into the situation where the linearized problem persists for sufficiently long to allow you to say anything useful. So, you know, what I sort of slid under the carpet there is that, okay, this trick allows us to avoid one bad singularity, but you might be worried that, okay, you just avoided this one and then you bumped into it one second later. This is the kind of thing that we also avoid in the paper. So we do have a way of doing that, but that requires some geometric things that I. Geometric things that I didn't have time to fit into the talk. So, all that stuff has to do. The reason I'm saying this is because in the non-linear world, the dynamics, not only are they complicated in the short time scale when you're near this linearized point, but they're very complicated when you go away from the linearized point, when you look at the global flow, because then you have nothing to project on, you have no good approximator. So, yeah, that's yeah. That's yeah. I'm sorry. I don't have a better answer. I'm sorry. Sorry. Okay, I realized we're actually behind schedule. Somehow, there's no break schedule between Chris was talking and Yoshi's. So anyway, so thank you very much for the very interesting talk. And let's move on finally. So