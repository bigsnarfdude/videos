And so there exists some, so I'm talking about exponential localization, so there is some part of the there is some region, I mean some interval, let's say i, non-empty, for which you know that the continuous component of the spectrum is absent, within which the continuous component of the spectrum is absent. And you have exponential decay of eigenfunctions, right? So this is what I'll think of as localization. And of course, there is another way to say this. Actually, so that's the version we heard about this morning. Meaning, you consider the operator on the whole space. Here I put Rd, I could put Zd, or I D could be one or above. But there is also a local version of it, which is somewhat different. And which is the following. So imagine now you take a compact region in RD, finite volume, and And we say that localization inside I holds if, well, I take P as an exponent, it doesn't need to be larger than D, but it has to be actually later on to get what I want. If you can find some u, which is going to be the rate of decay of the eigenfunction, and such that if you take, so here, obviously, lambda L, this is my region omega, is going to be just a cube of, well, center it at zero side length L. Side length L and with a good probability, so that's important, you need the probability to be pretty close to 1 when L gets larger. If you take, of course, now if you restrict your operator, we're thinking of Schwinger operators, you restrict it to lambda L, obviously the things, the spectrum is going to be discrete, right? The resolvent is going to be compact. But nevertheless, what you ask is that you have such a condition, the diagonal satisfies such a condition, right? Such a condition, right? So it's a little bit stronger than what we saw this morning. We had an exponential factor in N this morning, right? Also, sub-exponential, not exponential, a sub-exponential factor in L this morning and here. So this is just the IDK estimate from some localization center. And so that's another way to write it. And for actually, if you think of physics, well, of course. Well, of course there is no absolutely continuous spectrum, no singular continuous spectrum, that is just eigenvalues. But the properties of the eigenfunctions are going to be the important properties, right? And from a physicist point of view, if you think of that, well, even though the systems can be big because the atomic scales are very small, it's always finite samples. I mean, the infinite sample is a mathematical quote-unquote simplification, right? Right, which is useful, but it's well not the true physical situation. Okay, so this is just to remind you of the localized scheme. And so what I'm interested in is now an n-body system. So I take n-particles, take my large cube. For the moment, I don't specify what random shredding operator I look at. It's going to be specific later on, quite specific even. And what I do is I consider the three operators. I consider the free operator, so it means that my n middle n particles, I submit each of the particles to the same random background, right? And the same induction, of course, the same kinetic energy. And I consider them independent. And of course, they are independent from one another, the particles. And well, one thing I did, oh yeah, I said it here. I consider fermions, meaning that I look at wave functions that are enter symmetric wave functions. Metric wave functions only. I could look at bosons, but I choose to look at fermions, and of course, both have quite different properties. And well, to this free, non-interacting, so free in a mathematical way could be understood as explicitly solvable model, right? And explicitly solvable must be understood as it's explicitly solvable once I explicitly know what the eigenfunctions and eigenvalues of one particle operators are, right? Which is what. R, right? Which is what was the point of localization in the slide before. Okay? And so now take a pair interaction, so it's just a function. So, yeah, so it should be Rd here. Let me correct this. So this should be Rd and so uh And so, and define the interacting Hamiltonian. So, you just add the interaction potential. So, I assume that my particles are only interacting pairwise, which is, well, I think for many models it's quite reasonable. There may be more interaction than that, but for many models, it's quite reasonable to just assume this. And the important thing is: well, the thermodynamic limits, so maybe. Thermodynamic limits, so maybe I can blend in this right away. What I'm interested in is studying this system when both n and the volume lambda go to infinity and in such a way that there is a finite density of particles and non-vanishing density of particles, meaning that the ratio n over lambda, volume of lambda, goes to some constant rho positive. So in this sense, you cannot perform the infinite volume limit as in the one particle model, right? The one-particle model, right? Because of course, your eigenfunctions depend on n times t variables. So in the limit, they're not functions anymore, right? They're not well-defined functions. You could try to understand phi, this, which is complicated. So what I mean, I have a modest goal is understanding what I can. So of course, this is a Schrodinger operator, right? This is just a Schrodinger operator on some huge space. It's n times z-dimensional cube, right? But as a Right, but as a Schrodinger operator, it's going to have a ground state, right? The potential, if I imagine that u is a bounded function, is going to be nicely bounded, right? And going to have a ground state, which is going to be unique, non-negative, the usual properties of Schrödinger operators. And the ground state, what I'm going to try to study is what happens to the ground state energy, and in particular, more interestingly, to the ground state. When I let n and lambda go to infinity according to the thermodynamic limit rule. So, of course, in this level of generality, I don't have much to say. I need some more specific model, otherwise, well, and so there are two ways to be specific. There is an uninteresting way, even though you must go through this, yeah. So there is another interesting way which is, well, uh oh no, before that actually what I'm going to do is uh address the problem of what of the many variables, right? So the standard way to do this is the same as in probability theory, it was introduced a long time ago, is to look at, so we're looking at a normal state with n electrons, and what we do is we just define What you do is we just define what is called the k-particle density matrices, right? So this state defines a projection, and you just take the reduced trace of this projection, tracing out n minus k variables. So k is now a fixed number, right? So here I have a nice kernel of the operator, which is going to be compact, actually it's going to be trace class, it's going to be non-negative because here I have a projector, right? And because of this normalization factor, it's going to be a normal normal norm Normalization factor, it's going to be to have a trace which is equal to the number of k groups of k particles I can pick within my n particles. I have to normalize this in such a way. And now here I can hope actually to find the limit when I let n and lambda go to infinity in the thermodynamic limit without having to tackle with. So it's just like studying the marginal of a probability, of the marginals of the random. Of the marginals of the random variables in infinite-dimensional space, you just look at finite-dimensional marginals, right, and you study this. Okay, this gives you at least some picture. Not the full picture, but some picture. But if you study all of them, you get essentially the full picture. So I said there were two trivial things, well, simple things to be done, right? So imagine I just have the model, right, I wrote down. What I can do is I can first. What I can do is, I can first forget about the interaction, in which case I said the thing is explicitly solvable, right? Because of the following thing, if I take the one-particle Hamiltonian, I can write down, even though I don't know the numbers, know the functions explicitly, I can write down the spectral decomposition of this operator with a few or so with actually a discrete spectrum, trying to point with discrete spectrum. points of discrete spectrum. And I can actually I know so this is a basis of L2 of lambda. So I know an explicit basis of the exterior n times tensor product of L2 of lambda, right? Which is going to be given by, so let me call it, I've called them psi, psi p1, exterior, exterior psi pn, right? X0 ψ Pn, right? I take all of these P1, Tn and well I assume that they are ordered increasingly, right? So none of them repeats. And well, it's easy to see that the Hamiltonian H0, the one with potential equal to zero, this one, is diagonal in this spaces. And the diagonal, sorry, the eigenvalues of this diagonal. Sorry, the eigenvalues of this diagonal Hamiltonian are just the sums of what they call here the energies EP1 to EPN. Oops, here. These, right? And in particular, the ground state is just going to be the sum of the n first random first eigenvalues E p, right? Sum for j going from 1 to n of ej. So if I want to understand what's happening to the ground state, of course, the more Of course, the more particles you add, you can't expect the ground state to have a limit, but it's reasonable to expect that it has a limit per number of particles. Right? So you just divide by the number of particles, and well, it means you compute this. So you can do an approximate computation, sorry, replacing, introducing the counting function, the normalized counting function. If you introduce the normalized counting function, this sum, or this average, is going to be equal to Average is going to be equal to volume of lambda divided by n times the integral of the energy according to this, and well, under reasonable conditions, right, it converges to this object, right? Where E rho is what? E rho is the asymptotic solution to this, meaning it's the limit of the solution to this equation when n and lambda go to infinity in the thermodynamic limit rho. Right? So it is what is called the firm. So, it is what is called the Fermi energy for this non-interacting system. And so, this can be done. You can compute everything, right? And you can look at what's happening to the non-interacting ground state. For example, if you look at this one particle density matrix, you find that this just in, well, let's say what you're in strong in the strong yeah, in strong convergence, right, it converges to the spectrum projector. To the spectral projector of the full Hamiltonian on the real line up to the Fermi energy. But that's a simple computation. Now, the other way to try to do things, if you want really to do something for the interacting model, well, you need a simple enough random model to be tractable. And so, as you see, I take a very simple model where localization is very strong. So, the model was actually introduced, I mean, the one particle model was introduced. I mean, the one particle model was introduced some 50 years ago in the 70s, even maybe 60 years ago now, in the 70s by Littinger and C on this side of the Iron Curtain, and it was called the Pieces model on the other side of the Iron Curtain, which existed back then. Actually, it exists again. I think we managed to rebuild it in a record time. And it was studied by Lifshitz as far as I remember. At least it's it's inside the book of Lifshitz plus two hundred Esco. Schittz Postur and Rodesco, which date back to the 70s, I think. And what is it? It's just, it's very simple. What you do is you throw Poisson points on the line and you look at the Poisson points falling inside some large interval, going, let's say, from minus L over 2 to L over 2. And at each of these Poisson points, as well as at the points minus L over 2 and L over 2, you put some Dirichlet boundary conditions. Dirichlet boundary conditions. You could put Narbonne boundary conditions, doesn't really matter, right? But let's say Dirichlet. Okay, we don't know Dirichlet very well. And so you just take this direct sum of these operators. So of course you know explicitly what the spectrum of this is. You know what the eigenfunctions are. It's very localized because indeed the eigenfunctions are compactly supported. Its main drawback is that it's not a Schrodinger operator, right? That's the Trinity operator. That's the price you have to pay for. In particular, by doing this, you have killed tunneling for the one particle Hamiltonian. Particles never tunnel from one interval to the next one, to another one. There is no tunneling in here. But this is a feature that's going to be useful. And you are going to partially reinstate tunneling by putting up, I mean by adding the by adding the interactions between the particles. Adding the interactions between the particles. So you can compute the integrated density of states explicitly, right? The formula is here. And the n-particle system, well, it's going to be constructed using this one-particle Hamiltonian. So now d is equal to 1. So I assume that my potential here, my interaction potential, is of course non-vanishing. I take it even. I take it even, all right bounded and compactly supportive, right? So bounded is well bounded is important, well it just simplifies matters and oh yeah, one thing, yeah, I know one thing I did, it's written here, but I didn't say it, it's non-negative, so it's a repulsive potential, right? So what I put is a potential that repairs particles, so it wants to delocalize things, right? It wants to Delocalize things, right? It wants to pull particles apart from one another as much as it can. Okay, so to study, imagine that you don't assume the potential to be positive or non-negative. Well, it will lead to some technical difficulties, meaning some estimates which are trivial in this case will not be trivial anymore. In particular, the fact that the operator, the free operator, serves as a lower bound to the free operator. Serves as a lower bound to the folder operator, right, is not going to be correct if u is not non-negative. And so, compact support is the other restrictions. I mean, some parts of what I'm going to talk about can be done without this assumption, but you need, nevertheless, a decay assumption on you. Okay, I'll say a word about it when I'm there. So, and of course, as before, you define the interacting model. The interacting bubble. And the first, and not the most important, but yeah, essentially, the most important feature is the following thing. If you look at H omega L, I mean the Pieces model as defined, it comes with an actual decomposition direct or orthogonal decomposition of the Hilbert space L2λ according to the pieces, right? And it commutes with this decomposition. Commutes with this decomposition. And this decomposition, you can plug it into the exterior tensor product. And just expand it algebraically. And you get a new orthogonal decomposition. These numbers here, these sequences, I call occupation numbers, because they define exactly how many particles to put in each of the pieces, right? Of the pieces, right? So the Q equals Q1 to Qm. So M is the number of pieces. The number of pieces is random, right? But it is essentially, yeah, one thing I didn't say, I didn't say I take a Procell process of intensity one, okay, just to fix the rate. It doesn't matter, I mean you can scale everything. Okay, so if you change the intensity by your scaling, you're just going to put a constant here in front of the potential and scale the distances. That's the only thing that's going to change. That's going to change. Changing the density of the Poisson process, you can just scale it out. Right? By using, well, just do a change of. You misspoke, right? So it's M is the number of pieces. M is the number of pieces, but M is a random number. But asymptotically, M is equal to N. These two numbers are equal to one another. Okay, asymptotically. Strong law of large numbers for the Poisson process tells you that the number of pieces Sol process tells you that the number of pieces, because the intensity is one, is with a good probability equal to n plus small over the third. Symptomatic to that. And so what you have is that this decomposition yields the following or thermal decomposition. And of course, what you can check is that, of course, H0 omega Ln commutes with this, but Hu also commutes with this because these are functions. With this, because these are functions, right? Doing the cutting off will not change the functions because you change things at the measure zero set in the functional space, right? So actually HU commutes with this decomposition here. So instead of studying HU directly on this space, you just need to study it on that space. Meaning you can assign at first how many particles you put in each of the intervals, right? Each of the integrals. You can compute the ground state for this one and then minimize over all the possibilities for the particles. That's one way to do it. It's not the only one. That's not the way we're going to do it, but that's one way to think about it. And so to find a ground state, you just compute the ground state for each HQ and compare it for different HQs. So the non-intricate So, the non-interacting ground state, that's also a way you can use to decompose. Instead, if you don't want to do this direct algebraic analysis, you can also try to decompose, right, understand that what is the ground state in the non-interacting case using this idea. Well, using this idea, if there is no interaction, you can look at the pieces individually, meaning for each piece, you define, you look at the operator with n particles inside this piece of with q. This piece with Q particles, sorry, this is with Qj particles inside the piece. And of course, if you restrict the total operator with n particles, right, over restricted to the space with occupation Q. Look at the infimum of this spectrum, right? It gives you some number, which is just equal to the sum. So you just have to take the minimum in each of the pieces. Minimum in each of the pieces, right? Because of the alpha decomposition. And so, what you want to understand is now for each Q, you want to minimize. So, for each Q, you just need, so sorry, here you have the explicit function, so you need to understand what is the minimum of this function under the condition, under the constraint that the sum of the QJ's is equal to L. Right? If you want to understand who the minimum, what is the Q that is realizing. What is the q that is realizing the minimum of this? You just need to look at eq. So look at this sum and minimize this sum under the constraint of qj equal n. But this sum, the functions that are coming in here, that's a computation that actually is explicit. These functions here are convex in Q. What does it mean? So these are discrete functions, right? On discrete algorithm. So what I'm saying is. So, what I'm saying is that if you take the function at q plus 1 minus the same function at q, this is an increasing function of q. So, in physics, it means that the levels inside your small systems are well defined. This is just the q, the eigenvalue of the Laplacian on this piece that has this index q where you put these q variables, right? The pj or the pi, the piece pi, here, it's called pi. And it's exactly that. And these they are increasing, right? And so, what you can do is, well, you can just use Lagrange multipliers. So, here you have a convex function to minimize under this condition, right? So, imagine that the cues, they are not continuous, right? They're discrete. But imagine they were continuous. So, what you just can do is apply Lagrange theorem, look at the Lagrange. Apply Lagrange theorem, look at the Lagrange multiplier, right? And what does the Lagrange multiplier theorem tell you? Actually, in this case, it's even simpler because this thing, E0Q here, is cubic in Q, right? Something cubic, because you are summing the eigenvalue quadratic. So it gives you something cubic in Q. And when you compute, you see that, well, what is important is that you can go up to some energy level, E rho. Energy level E rho. Oh, sorry. No, I get this. Some energy level E rho. Oh, yeah. So the battery is almost dead, actually. This is why it's fading out. That satisfies this equation, but that's the equation that defines the Fermi density. Right? I mean, because of the Lagrange multiplier theory, you fill all the energies to the same level. Okay? And so what the only thing you need to do is you take all The only thing you need to do is you take all the pieces that can contain a level below this energy, so they need to be large enough, right? So they need to have a length. The pieces to contain an energy below Euro need to be of length at least pi over square root of Euro, by the definition of the eigenvalues, of the Diracly, the free of the Dirac Laplacian on such an interval, right? And for each piece, you take all the states below your own. You take all the states below your row, and you form this later determinant, and you get the same answer as here, right, for the ground state. But the interesting part is, if you analyze this, you're going to be able to do the analysis also in the other case, right, once you add the interaction, if you're trying to analyze in this way. So, for the picture of the non-interacting ground state, you get this in pieces. So, here, this is a picture where you put the length of the pieces in Axisa, and in order. Of the pieces in Axisa, and in Ordnette, you put the number of particles that such a piece having length between, for example, L rho and two LO contains. So when the piece has length below LO, it doesn't contain any particle. Between LO and 2RO, it contains one particle, 2LO and 3L, 2 particles, and so on. And the basic lemma is that if now you add U, now I'm dealing with the potential with the interaction, right? With the potential with the interaction, right? And I assume that rho, the density, is small. So if I take rho subdivision small, then for L large enough, in the thermodynamic limit with a probability which is nice, if you define l rho u to be equal to this, so it's arrow. So let me, yeah, so one thing I should have written, I didn't put it down, but what I didn't put it down. But what you know is that Rho, remember, that's the Fermi length, right? So we have n of E rho is equal to rho, and we computed explicitly, right? So that's for the free. These quantities are given for the free model, right? That's the Fermi density for the free model. Meaning non-interactive. So this is approximately. So this is approximately e to the minus, there was a constant, I don't know, some constant e to o, y minus e to the minus e row square root, sorry, yeah, that's, yeah, well, actually, if you define it in terms of the Fermi length, right, so this is pi over square root of u. Right? And if this tells you that. And if this tells you that L rho is of size log rho absolute value when rho is small, l rho is of size log rho, so it's big. So if you now define a rho minus c of u, it's a constant that you pick, actually, there is an optimal value for it, but it doesn't really matter. Take any constant large enough, minus c times rho. So this is still a log rho, right? When rho is small, this is still of the same order as. When rho is small, this is still of the same order as rho itself. If you take any ground state, in this model, I don't know how to prove in general that the ground state is unique, because of the derivative boundary conditions. It's not Schrodinger operator anymore. I don't have any operator theoretic proof that the ground state is unique. I can prove that it's unique under the assumptions that the potential is analytic, but well, if you add that it's confaction supported, it doesn't give you anything very interesting, right? So I prefer to forget about unicity. I prefer to forget about duality and try to study something real. So, take any ground state. If a piece has length less than k arrow u particles, this one is dead, so I'm going to use this, gives the same beam in green. So, if a piece has length, right, which is less than k times l rho u. times Lρu, then for any occupation inside the ground state, we know that the number of particles inside such a piece is at the most k minus 1. So for short pieces, just like in the free model, you can't put many particles into short pieces. Put k particles into a piece, it needs to have length larger than k plus one times L or u. k plus 1 times l over u. Okay? And the u is positive, so u is positive. It raises of course it tends to push the particles apart, right? But yeah. And so that's the basic fact. So only big pieces are going to be populated, just like in the free one, in the non-interacting model, right? And the idea is actually quite simple to prove this, it's quite simple. What you do is look at the number of available pieces, right? Pieces, right, for the number of available pieces of a given length, right, this number is decaying exponentially with this length. When rho is small, you have few particles, right? So what happens is that you have many pieces that are not populated and that are still pretty big. So if you would put a particle inside, You would put a particle inside a piece of length lower than that. Then you can, what you prove is that you can find the piece of that size that is not occupied yet. But you can actually move this particle and in such a way that it's not interacting with anybody. So you actually lower the energy. And so you can move, as is what I just explained, right? And now what you can do is the following. You're going to decompose. Going to decompose instead of looking at the pieces, maybe a picture of Zenodra, instead of looking at the pieces alone, what you're going to do is, you know that only the pieces in the ground state, only the pieces of size larger than L rho U are populated. So these people's pieces are pretty large, so there are not so many of them. So here you have smaller pieces. You know that these in the Brand state don't contain any particle. In the brown state, don't contain any particle. Right? So imagine, and what you're going to do is you take these big pieces and you group them together as long as they are separated by something which is less than the diameter of your potential, of your interaction potential. If the separation here is less than the diameter of the potential, it means that particles in here and in there can interact. So there is no way you can separate. So, there is no way you can separate them. If it's larger, if this is larger than the diameter of u, then you can separate it. And you consider these groups together. So, this is exactly what I call the chains. So, groups are chains of pieces. Okay? So, d of u is the diameter of the support of u or the convex height of the support of u. And well, it picks up to chain, so that's the definition of a chain, but the picture resumes it, I mean, sums it up pretty nicely. And for such a chain, you can consider this Hamiltonian, right? It's just the Hamiltonian reduced to this chain. Okay? Well, if you take any ground state, what you have is that such that if you take a ground state and look at its component on um on an occupation q. On an occupation Q. So you project it down to Q, you can take a given occupation. You don't know what the occupations inside the ground state are, but you can fix an occupation and assume that you have a component of psi on this occupation. And then you know by applying the Hamiltonian that actually, well, the part, I mean the energy that you get from psi q on this occupation, right, is going to be equal to the sum of. Be equal to the sum of the energies of these chains that you are looking at at the occupation Q, right? You take the chains inside the occupation Q, you obtain that the sum of these energies, psi Q. And so what we have to do now is we have to minimize this function under the constraint that the sum of the q's over the chains is equal to n. Formally, this is the same thing. Formally, this is the same thing as before. The only difference is, well, I don't know that these functions here are convex. If I know that these functions are convex, I could do the following thing. I just take the levels, the energy levels defined by these functions. Just take ECQ, ECQ plus 1, right? And you take the difference of the two. This difference would be increasing. Two, this difference would be increasing if it's convex, and just define these levels. And to understand who is the ground state, you just take the smallest level. Take the n smallest level, right? And you're done. So you don't know that this is convex in general. And we only know it for short chains, right? In particular, we know it for chains that contain. Contain well essentially one particle, of course, two particles, right? But even for three particles, it's not obvious that the thing is convex. It goes on the following thing. So let me draw three. So that's a chain with three intervals, three long ones, two short ones, separating them. And of course, in your And of course, in your random system, right, on the interval, minus L over 2, L over 2, this being less than du and this being less than du, right, has a positive, and this being larger than L over u, L rho u, this has a positive probability of appearing. So such chains will appear L times this probability, right? Just by independent. Right, just by independence of the croissant points. So there'll be many of those. But the problem is for these, because of the symmetry, it's not easy to understand what's happening when you put, you go from two particles, so two particles, this is going to be better because they will kill the interaction here, right? To three particles. Okay? How you place the particles, and so in such a, because of the possible symmetries, it's difficult to understand whether convexity is horrible. Understand whether convexity holds for this or not. And for the moment, I don't have any replacement for that. And so, as soon as you have at least three particles, I run into this problem. So, for two, that doesn't happen. For two, you can actually make computations. And if you do this, you do the computations, where the first thing you compute is an expansion for the ground state energy with the first correction. So, that's the free ground state energy that we computed using the density of states. And you have a first-order correction. And you have a first-order correction, right, which comes from the interaction. And this gamma scar is just given by the difference between the lowest eigenvalue of this one and the lowest eigenvalue, I'm sorry, the lowest eigenvalue of the free one. So that's the lowest eigenvalue of the free in the free case, and that's the difference here. It's coming in. And so the blue curves here, that's the same picture as before. The blue are the particles. Blue are the particles that are sitting within pieces of length between LO and 2L, and then 2LO and 3L. And what you did actually to go from the ground state, from the free, if you want to understand, you take your free system, no interactions, and you switch on the interaction. What's the effect of the switching on the interaction on the ground state? It just takes pieces, right? Here you had two particles in the blue line here when you were between. In the blue line here, when you were between these two numbers, here, between here and here, you have two particles in the blue line, right? But only one particle on the green line. So, and this particle is actually going to be thrown to much smaller pieces, right? Because there is some gain in energy by doing this, right? And so this gives you an idea of the picture. So, this is exactly the repulsive effect we're speaking of. You move some particles down to three pieces. So, now let's look at the two-particle density matrix. So, the definition I recall here, and in the free case, meaning non-interacting. And in the free case, meaning non-interacting case, you can actually compute it explicitly, right? And you obtain this formula as in terms of the spectral projector associated to the one-particle Hamiltonian. And what you can prove is that when U is not vanishing, right, so you have an interaction, U is still compactly supported, when the rho, the density, if the density of conicers is small enough, then what you get is that, well, I don't. Then, what you get is that, well, I don't compute the point-wise bound, I just compute some expectation bound on this, but you get the same exponential decay that you got, right, in the free case. Here you need the two terms, right, because the thing is anti-symmetric with respect to the variable xy and x prime, y prime, right? You can replace y by y prime at no expense. So, because of the anti-symmetry, you need the two terms in here, and you get the same decay. And you get the same decay. Okay? The same decay rate. Well, actually, the rate is not the same. But you get the same kind of decay. The rate is not the same. I can't prove that the rate is the same than in the free case. But nevertheless, you're expecting to be the same? I don't know. I don't know. I guess it shouldn't be much different. When rho is really small, these things should be continuous in rho, right? So, but I don't really know, actually. I don't really know. It's actually the rate of decay here is going to depend on because the idea, so you see the idea to get this actually is that at larger, so you can do the decomposition in chains, right? You know that only the chains the chains that are long long enough, right, contribute, right? Enough, right, contribute, right? But here, because you take an expectation, so you fix the numbers x, y, x prime, y prime, right? And so, what's what's playing against you? Well, this is going to be big, this expectation is going to be big, only if x, y, x prime, y prime fall into some chain, right? But of course, when x, y, x prime, y prime start being pulled apart from one another, the chain needs to be long. So the probability Needs to be long. So the probability to have such a long chain is going to be small. So actually, this exponential decay comes from this probability partially. It's not an exponential decay on the function, but it comes from the probability partially. You can also look at it at positive temperature and do the same kind of results. So you take the Fox basis over, so you take the number of variables of Variable of so until what time? When do you use it? Oh, okay, already. Well, okay, so I can stop here, actually. Depends where we want to hear more. Because actually, I still have a few slides. But okay, let me just say one thing. So, oh, actually, that's the goal. Oh, I see. Oh, no, because he came up after the other day. Ah, okay, yeah. Well, okay, so that's Okay, so let me just say this. You can do the thing, so to introduce the fuck space, right, and look at the GIF states, so the grand canonical ensemble, look at the give states, and you can look at the two-particle matrix for the GIF state, and you get the same result. Here it's even a bit more complicated because I don't want to give point-wise bounds because there are technical difficulties, but I can give an integrated bound. So I integrate over some small cube around. integrate over some small cube around the values xx prime yy prime right and when you integrate this out then you get something in expectation right so it's a bit weaker than what I had before okay and well I'm sorry that was a sequel but for another time okay thanks very much Maybe you can still say something about the okay, so there's one difficulty because we're dealing with fermions, right? To define the entanglement entropy. So what's the, yeah, maybe I should recall in this part, it may be less well known to people. But the idea is you have your system. So minus L over 2, L over 2, right? And you put some L star, and you cut the system. And you cut the system, I just cut it into two pieces, not three, right? I cut it into two pieces. And what you do is you cut it into two pieces and you look at the ground state for the system with interactions. You cut the thing into two pieces and integrate out all the freedom on one of the pieces. Which one you choose doesn't really matter, right? Because you can recover simply the other side, but you integrate out. Other side, but you integrate out. So you see, because you are dealing with fermions, the system does not decompose naturally because there is already some, due to the fermionic nature, due to the fact that you have required that the functions are anti-symmetric, they are actually correlating all the places in space, right, due to this anti-symmetry. Because you remember, more so as you're looking at the thermodynamic limit. So imagine you take two random particles. Imagine take your random particles. The number of particles is proportional, right? It is proportional to the volume. So you have really particles everywhere. And so this is, so what you need to do is there's an algebraic trick, but it depends, this trick actually depends on the eigen on the basis that you choose. Right? You have you you take a basis, right, you can do this, but it depends on the basis. Do you get a you don't get a number. Jump it along. No, no, no. I don't. Yeah, yeah, there is no logarithmic correction. It's a constant. This is what I want to tell you. It's a constant. Yes. The thing is a constant. Yeah, sure. The thing is going to be all the zero, there is no boundary turn. Sure, sure, sure. You get what you expect. But you can compute what it is. The thing is, it's going to be again given mainly by the small pieces, and you can compute what it is. Well, so the only person interested has an answer, so that's fine. That's fine. Sure. So, this is in some sense a toy model with the pieces, right? So, in many cases, actually. You want to place centers around the localizations, boxes around the localization centers according to localization lengths, right? Yeah, it's not, actually the right thing is not localization length. It's more the onset length that we defined with Jeff. Because the look at me, the Lapuna fixpon is not important. The decay at infinity is not really the important thing. It's more the extension, the local. Important thing. It's more the extension, the local extension of the state, right? Before actually the Yapunov exponent behavior kicks in. And that's what is important. And then, is there a sense that what you're doing here will extend to that? Well, I've been thinking about this for 10 years, right? I haven't found yet how to extend it. But some of it, yeah, there's one thing that's going to extend for sure. One thing, there is some positive message. It's the simplest one. It's the simplest one. This one I know how to extend. It's this estimate. This is going to extend just to draw the energy. There is an expansion of exactly the same thing. If you take, for example, minus Laplacian in 1D, take minus Laplacian plus Poisson, but with a bond, a simple bond function, right, at the Poisson points. Then you can prove that the ground state energy has such an expansion. But I don't know at all how to extend the statements about the ground state, the ground state itself, which in this case exists at no charge. It exists and it's unique. I mean, what I mean is it's unique. But I don't know how to state anything like I stated for this model. I think it's going to be true, but really, I don't know what the estimates are. Yeah, so you were saying you didn't have this convexity. You were missing this convexity estimate. Yes, right? So what but you still get some results without it. So what do you get with the convexity estimate? Oh, with the convexity, you actually can get rid of the rows normal. You can deal any row. You can deal any row, right? And you can go, you can compute things in terms of these chains. Of course, you cannot solve what the energies of the chains. Not to solve what the energies of the chains are, but in terms of the chains, you can put a picture actually. You can go to any order of magnitude here. You can, well, it leads you much further, right? Okay. Sure. One message for your talk, definition of MBL. I mean, there was this question, how do you define it? And you simply very positively say it's the exponential decay of the reduced two-particle density matrix. What is like with Eliara versus Bollinger or with what Yingbuy is shown? Yeah, sure. I mean what this tends I mean if for this model if I if I would know the convexity of these chain functions, right, of these chain energies, then I would actually be able to prove that the situation is the one that physicists The one that physicists describe when there is no thermalization, right? Meaning that the particles even interacting live locally at least if U doesn't decay sufficiently fast. If you is complex support, then you could say that everything lives locally, right? And you get exactly the clusters that well physics talk about. And you have one model where actually this. And you have one model where actually this happens to be correct. Yeah, that's true. That's true. So you can do something beyond the short range, beyond the compact range? Yeah, one can do, again, what one can do about the short, beyond the short range. This is going to be true as long as u decays faster than x to the minus 4 at infinity. And my suspicion is actually the true limit should be 1 over x, but I'm not sure about it. I mean, this is a type of the Android calculation that I don't know how to make. The angle of calculations, but I don't know how to make any math out of it. But rule should not play in Euro. Okay, let's thank the leaving it. So, we'll be switched. So, Jake will speak at 9 a.m. tomorrow. Oh yeah, sure, sure. The same younger person in Brazilian scare. And his mother's interesting or for interacting or not interacting. Interacting. So, what did he prove? He got very adult II. And then at the same stage, it was too difficult to have it through. So he changed. Suspicion was remote. No longer. So it's not here. So basically, it's a suspicion of people just drawing it. So you have example for a sample? Yeah, you just use example. So I have to use some density, which is just a matter of the microphone. Because one of the difficulty is if you take just one term and you want to compute the density, the tensor density, you need an idea of how to estimate what's happening. So there is a first order, and then there is only remaining ideas. I mean, I think it's a good idea. Because it took me a long time. It took me a long time to understand, but then finally I understand.