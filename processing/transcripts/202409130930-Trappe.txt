Now, I have to say that we have developed these methods mainly with having in mind simulation of ultra-cold atomic Fermi gases, not so much electronic structure. But since this is a workshop about electronic structure or materials, I will shift focus a little bit towards that. But be prepared for some quantum gases. Okay, nevertheless, we want to. Nevertheless, we want to develop methods, systematic methods that apply to essentially all quantum systems. And when we are talking about quantum anybody methods to simulate systems in chemistry and material science or for systems under extreme conditions, we have to acknowledge that in practice there will be a trade-off between accuracy, which is particularly important for chemistry, scalability that maybe is particularly important. Scalability, that maybe is particularly important for material science, and universal applicability of transferability that refers to methods that are essentially applicable to all quantum mechanical systems. Okay, but 100 years of experience tells us that we cannot have all three objectives in full. We have to compromise. And at one end of the spectrum of one-to-many body methods lies, of course, the Kr√∂ninger equation, which is by definition perfectly accurate and Perfectly accurate and also completely transferable. However, in practical computations, we have to limit ourselves to something like maybe five electrons if we want to have a quasi-exact solution. And this is why we do a DFT, of course, where the increase in scalability comes at the expense of accuracy and universal applicability. Okay, let me elaborate a little bit on this. Elaborate a little bit on this unavoidable trade-off. So, we have methods like the Schrodinger equation and Hartree-Fock that are explicitly Hamiltonian-based and therefore can be immediately applied to all systems. Now, Hartree-Fock can work for hundreds of particles, but of course it misses all the correlation energy. Okay, so this is the trade-off here. We look at Cohen-Shant DFTN. Well, for each interaction functional, for each physical interaction, we have to. Physical interaction, we have to create an interaction functional, and this makes Cohenchamp DFT a little bit less transferable. The same is true, of course, for all DFT methods, like also the Thomas-Fermi Melt model, which is totally scalable, but is not accurate enough for most applications. So, in fact, the Thomas-Berman model is Spermi model is the lowest order of a series of systematic approximations of what we call density potential functional theory or DPFT. Therefore, I label this Thomas Fermi theory here DPFT1. And in this talk here, I want to introduce to you higher orders of this scheme that we call TPFT2 and TPFT-4, which are more scalable than More scalable than Thomas Fermi and less scalable than Thomas Fermi and more accurate. So I indicate this here. DPFT2 is less scalable but more accurate. And this even more so holds for DPFT4, which can come close to the accuracy of Kohen Sham DT for many systems. This is what we believe. Be what we believe, haven't of course tested it for everything. And the thing is that it is more scalable in principle than Khohen Shan DFT. And at the moment, it is not more scalable in practice, but with enough effort, we hope that it will become so. And I want to show you some slides on that. To complement the picture, maybe here, let me introduce one more method called. One more method called WKB because it builds on Lange-corrected WKB wave functions. And this method has been developed in the group of Kiran Berg at UCF Irvine. And strikingly, this method is totally scalable, linear scaling, and is very accurate, almost completely accurate. But it can only be worked out for one dimension. Out for one dimension. It doesn't seem to be possible to go to two or three D genuinely to essentially on top of the exact quantum mechanical density. Guess also this density oscillations right. Okay, as I said, it's not possible, it seems, to transfer this to two and three dimensions, but it's not the only metal, of course, that has transferability problems. This is also the case for the standard. For the standard gradient expansion of the kinetic energy function. So there is no problem in three dimensions, but in two dimensions, for example, the first order gradient correction on top of Thomas Fermi is ambiguous at best, and it even diverges for one dimension. Of course, one can cure these issues in an ad hoc fashion if one wants, but it is difficult to say the least to build a system. The least to build a systematic method out of this. However, such a systematic approach to the kinetic energy functional is exactly what density potential functional theory, or DPFT, can provide. And let me show you how this works. So we start with the standard energy functional of the density. And now we define a new variable V here and a Legendre transform, not the total. Not the total energy, but only the kinetic energy with respect to this new variable. And this gives us a new functional, which we call E1. Then we can split off, if we like, the interacting part of the kinetic energy, as we would do in Coinchan theory. And then have an expression, E1, that does not depend on the density anymore due to this Legendre transform, but only on. Legendre transform, but only on this new variable v or v minus mu. Okay, this also means that the total energy is now a function of three variables, this v, then density, and the chemical potential mu, which also means that the ground state we get three equations that have to be solved self-consistently. Now, the third equation is telling us that the density. Is telling us that the density is a functional of v and it is given simply by the functional derivative of v1. And this v of v is a functional of the density, which is simply the combination of the external potential and the interaction effects. Now, the advantage of this whole thing is that we can write down explicitly the functional form of this E1. This E1. It's a simple, has a simple form here. It's a single particle trace over the single particle Hamiltonian H here, a function of that. It's just H minus mu and times the step function mu minus H. And H is just the Hamiltonian of your kinetic energy, whatever it might be, and an effectively non-interacting external potential. And And we can also do this for a finite temperature. And then we have exact and explicit expressions of the Legendre transformed kinetic energy. And these are expressions that can be then systematically approximated. One can even introduce gradient corrections, not in terms of gradients of the density, but in terms of gradients of the But in terms of gradients of the potential. And so, this we did in these publications back here. However, I don't want to talk about gradient expansions. I want to show you another way of getting quantum corrections without a gradient expansion based on this PPFT framework. And this is work that goes back to a publication of ours in 2018. And let's focus. And let's focus first on the ground state density, n, which we just saw is just the functional derivative of respect to this effective potential v. Now, this involves then just the step function, which we can fully transform. And this reveals, of course, the time evolution operator that we can then approximate systematically with the Suzuki Trotter type decompositions, where we split this exponential into a finite number. Into a finite number of factors that separate the potential energy from the kinetic energy. For example, we could look at these three factors here, where we take half of the potential energy to the left of the kinetic energy and half of the potential energy to the right. So we call this U3. And then we just have to undo the Fourier transform of the step function. And we end up with this momentum, with integral over momentum that we can. Momentum that we can evaluate analytically. And this will give us the Thomas-Fermi density, which we could have also gotten from just two of these factors here. Now, if we instead take the kinetic energy to the left and to the right of the potential energy, we get another three-factor decomposition, which we call U3'. And then again, And then again, plug this into the integral here, and we obtain momentum integrals that we can perform analytically again. And we end up with this formula here that is a spatial integral over something that involves the Bessel function. Okay, so this is a non-local expression where the density at position r is informed by a potentially very large neighborhood. Informed by a potentially very large neighborhood around R. So, by splitting the time evolution operator into more and more factors, we can derive a systematic hierarchy of density expressions that becomes more and more accurate. So, for example, as we just saw, we get the Thomas-Fermi density from U2, which is correct only up to first order in the time t here. Then U3. Then U3' is correct up to second order in T. And U7, which is based on splitting the exponential into seven factors and doing some tricks, is based on, is accurate up to fourth order in T. So this is why we call these two approximations of DPFT, DPFT2 and DPFT4. Now the quasi-classical chromosomy density is quasi-classical Thomas Fermi density is local, but N3' is non-local and therefore includes, in some sense, some quantum corrections. And N7 even goes beyond the first order gradient corrections in accuracy. First order gradient corrections would be accurate only up to third order NT. And on top of that, U7 is also exact if the effective potential is linear. Okay, now, okay, so how about Okay, now okay, so how about computational cost? Well, so in quantum gases, it's not the case, but in electronic structure, the particle number that we can simulate is roughly scaling like the spatial grid size. So for the Thomas-Fermi density, this means that at each position r, we get the density from just one evaluation of the effective potential, which means that the scaling is proportional. Which means that the scaling is proportional to the grid size or to the particle. So for N3', at each position R, we have to integrate over the whole grid, which makes this scaling n square. And interestingly, the same scaling also falls much more accurate and seven, because it also involves only one spatial integral over space. But the But the increased accuracy still comes on at a computational cost because of this scalar integral over the area function that can be quite expensive. Nevertheless, it's n-square scaling. For n3 prime, we have derived also more efficient representations and also for finite temperature. And in this case, the scaling even reduces to n log n. So we have a n so we have a quasi-linear scaling uh for getting a density that is uh can be much more accurate than half than than uh thomas fermi okay so and the following i want to show you examples of this uh different expressions and their accuracy um so here first let's look at uh two non-interacting particles and a one-dimensional mass potential so for you guys this is a very synthetic For you guys, this is a very synthetic system. Nevertheless, it gives us some insights. So, here the N7 in red pretty much captures the central part of the exact density, which is this black dashed line here, and also captures to some extent these density oscillations. So, although we have a semi-classical hierarchy of approximations, we do get quantum oscillations of Dell structures. Of Del structures. This is not the case for Thomas Fermi and for this N3' here, which are this, for example, this blue and the red dashed line that gives some sort of semi-classical average over these density oscillations. And the Thomas-Bermian density, of course, drops to zero at the quantum classical boundary, whereas all the other expressions give us a smooth decay into the classically forbidden region. And N7 does a particularly good job here. And seven does a particularly good job here. Now, you also see these unphysical oscillations here into negative densities, which we'll see will go away for larger particle numbers or for finite temperature. For example, for this green line, which is entry prime in finite temperature, for finite temperature, which essentially, even for two particles here, lies on top of the exact finite temperature density. Exact final temperature density. Okay, so let's move on to a different system now in three dimensions: a harmonic oscillator potential for 42 particles. And let's look at the scale density, R square n. And 7 in purple deviates just a little bit from the exact density, which is this black dotted line here. So we have very small deviations from the exact density. From the exact density. And this is only the error that we make when writing down the non-interacting kinetic energy functional E1, or rather its derivative here, because everything else is treated exactly. So this is the error of our kinetic energy functional we see here. Okay, of course, this plot could have also come from an interacting system. If this them if this harmonic oscillator potential were the effective potential as a sum of some other external potential and in the action that was. Okay, so now the question is can we make this N7 maybe one of the strongest orbital-free TFT solutions on the market and a real alternative to Cohen-Chant DFT? Okay, so let's have a closer look. Again, here for thermons in MOS potential, now 100 particles. Particles for which we plot the density, the complete density, the full density profile here, and the inset where we don't see any real deviations. So let's scale up, scale the density extremely by this, by multiplying with this exponential here to reveal any small deviations there might be. Well, indeed, N7 in green lies almost on top of the exact density here and gets all the quantum oscillations pretty much right. Pretty much right in contrast to N3, which is looks like out of phase. Now, N7 maybe looks accurate enough for many purposes here, but the problem is computing time. This example, we got N3 prime in five seconds and N7 to the month. So, where does this come from? Well, N3' works with best of functions, which we know everything about, and N7. About and seven works with another type of spatial function which we call kd. Here, d stands for dimensions. So, here we have a one-dimensional geometry for which we calculated k1. And obviously, this took a long time because these are very, very nasty integrals to evaluate numerically. Okay, so our target would be to evaluate these KDs as efficiently as, for example, Bettle functions, in the best case. So, we know a few things already about this special function. It obeys a certain differential equation. We know letter operations that switch between Kds of different dimensionality. So, knowing K1, we can produce K2 through these letter operations, for example. Then we have asymptotic expansions of these guys, and we know also some families of flow constables. Know also some families of load constructions. So we have quite a bit of material to work with in future. Another option would be to maybe machine learn an approximation of this KD and then get the according machine learned density, which is this red line here, where we have produced a prototype, a very simple neural network from a very simple neural network. Here for 10 fermions in a harmonic potential, and you can see the shape is roughly. You can see the shape is roughly there, but of course, there's a lot of room for improvement. Nevertheless, one would get a significant speed up, of course. Okay, but for now, we have to do with the less accurate but more scalable N3'. That would be the blue line here. For example, we can look at a repulsive two-component Fermi gas in two dimensions with the contact interaction. Dimensions with the contact interaction of strength alpha here between the two spin components and one and two. And if we crank up the interaction strength to something like two pi, we get a phase transition where the two components with 10 particles in each component split into two semi-spheres. And if we go to larger particle numbers, for example, 55 here, we did We did a check against Hartree Fog, and we see that N3's has a quality very similar to a Hartree Fog. So the densities are compared here, Hartree Fog in colored lines, colored solid lines, and N3' in the dashed lines. And you see that the overall shape is pretty much there. In particular, also at the interface that is important for molecule formation. So we have an accuracy here. Uh so we have an accuracy here for larger particle numbers at least that is comparable to hardware fog. Now for many more particles it will become infeasible unfeasible to run hardware fog but our semi-classical expressions should be even more accurate relatively speaking. Now question is how does this entry prime perform for Perform for electronic structure. Now we wanted to look at atoms, diamonds, and nanoparticles. And this was something we published last year. Now, our main target were here looking at the valence electron densities also in bond regions. Now, this was really a proof of principle study for which we borrowed the GGA pseudo-potentials from COFES. And then we wanted also. And then we wanted also to know how this performed for many electrons by looking at a larger nanoparticle. We also did some all-electron calculations with simple pseudo-potentials, but that's not something I want to focus at the moment. All right, so let's start with atoms. Now, here, the aluminium atom with three balanced electrons. The density is shown here in the inset. In the inset and the scale density R square n in the main plot. So, first the conchant density in purple lies pretty much on top of the coupled cluster result, which is this black dotted line here, the fat one. And now, how does N3' in real dashed compare? First, it lies on top of the blue line, which is the finer temperature version, where we just chose a temperature that is small enough so that the two. Is small enough so that the two curves coincide. But yes, these densities are not as good as Kohn Charm, as you can see, but first of all, they again take an average account of the density oscillations near the core. And more importantly, they have a high quality in the valence region. And also a reasonable decay into vacuum. So overall, this looks like. So, overall, this looks like good results, in particular if we compare with another systematic method, namely the standard gradient expansion, which is this black dotted line here, that first overshoots significantly like the Thomas Fermi density, which is this gray dashed line, and also underestimates the Valenza region, like the Thomas Fermi in a sense. Okay, so we pretty much. Okay, so we pretty much get the same picture for a magnesium atom, which was the other atom that we looked at. So let's move on to dimers. Here's the magnesium dimer then for four balanced electrons in total. Again, the N3 prime in green dashed gives a reasonable match with the Kohn-Sharm density in purple here in the density tails, but it kind of produces. But it kind of produces maxima at the nuclei instead of minima. Again, this can be viewed as a semi-classical average over the real density oscillations. Now in the bond region, results are a little bit better, but there are still quite some deviations to the Kohn-Sharm density. And the reason could very likely be that only four-balance. Be that only four balance electrons contribute to the bond region, and N3' is, after all, a semiclassical method that should work better for larger particle numbers. Okay, so to confirm this, let's look at a nanoparticle here, aluminum nanoparticle with 200 one atoms, meaning 603 valence electrons. And we see here in the blown-up picture of the bond region that N3' in blue 3' in blue really captures nicely the concharm density. Here, purple. Cohen charm in blue is just with LDA, concharm in purple is with PBE. And we also, yeah, so we see that, and this is maybe not unreasonable because now there are in the center here about eight atoms that contribute then in total. Atoms that contribute, then, in total, 24 balanced electrons to the bond region. So, it's maybe not unexpected that there the N3' performs much better. Also, much better than, again, the second-order gradient expansion here that overshoots these density oscillations. Okay, now where are we going from here? Where are we going from here? First, my feeling is that the most impact would come from developing more efficient numerics from N7. We can pull this off, we have something really great at our hands. Then another topic I have not mentioned are energies. It is a principle impossible to produce kinetic energies that are consistent with our approximation. For example, this U3' here, for which we can produce a density. Here, for which we can produce a density matrix and then get the kinetic energy. Turns out that it's not much more accurate than the Thomas-Fermi energy, maybe not surprisingly, because this here is formally the same expression as the Thomas-Fermi kinetic energy, functional in terms of this effective potential V, just that at the ground state, these different effective potentials would be different. So, we get different kinetic energies, and it turned out to be a little bit better than Thomas Fermi. Bit better than Thomas Fermi in this case, if we take this self-consistent N3' approximation here. But yeah, maybe the hope would then be to get kinetic energies consistent with N7 to have some improvement there. Alternatively, one could get from the density non-self-consistent energies than from a single quantum Sharmic relation. So instead of constructing the density from of constructing the density from the consumption orbitals we would take our dp density plug it into the effective in the functional of the effective potential which would be the same functional as in cohen sharm then and then from the cohen-sharm equations get the total energy just from a single calculation of the eigenvalues now another option of course would be to compute quantities for which Would be to compute quantities for which a decent entry prime density is already sufficient, possibly electron localization functions, for example. Okay, so I think pretty much there. Thank you very much.