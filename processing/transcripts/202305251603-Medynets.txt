They actually can you know tell you a lot of things about the group. Sometimes they actually can tell you actually everything about the group. And which is not a surprise when you're talking about big groups, maybe homeomorphisms of the Kantry set or automorphisms of rational numbers. Those massive polished groups actually remember they're so tightly connected to the underlying structure, so it's not a surprise. But sometimes you get smaller groups and that say countable that still remember a lot about the underlying. Remember a lot about the underlying structure. Alright, let's start with the homeomorphism of the Cantor cell. Just T is any homeomorphism. And what can you do? You can look at its orbits. Pick a point, start looking at the iterations. Some orbits will be infinite, some will be finite, and you have this very natural decomposition of the space into two subsets. When you have periodic orbits, things might be really, really difficult. So, right now, what I'm going to do, I'm going to just assume that we only work with what we call apiodic holomorphisms. Every orbit is infinite. And there is this famous result that goes back to 1940s, I believe, by Rocklin, and that describes the structure of any, say, transformation, if you wish. Transformation, if you wish, over measure space, over topological space, the Canter set. And what it says is that if you pick a number, n, and it can be any number, a billion, then there will be a clopen set so that the transformation T will just move it around and you'll get a bunch of disjoint copies, images of that set. And there'll be some remainder. In organic theory, when Rockman proved his Theory, when Rockland proved his result, this remainder was very, very small. You can make it as small as you want, you know, with respect to the measure that you have. When it comes to topological dynamical systems, actually, the remainder is super important. Even though it can be small measure-wise, but actually topologically, it has still a lot of points in it. And a lot of things happen here, actually. All right. And in fact, if you'll start to zoom in and see what's happening. In fact, if you'll start to zoom in and see what's happening in this remainder set, you can actually learn quite a bit. Turns out that the whole space can be decomposed, broken down into local towers. So there is a nice combinatorial kind of structure. So I don't know what the height of each tower is going to be. I know that's going to be as large as we want, but I can't really control the relative heights. And each point here goes up, up, and once it reaches level, it goes somewhere down to the base. Somewhere down to the base, I don't know where. We can't control it for the moment. Same here, go up, up, up, up, and then somewhere into the base. And this is actually the key observation for any apiotic homeomorphism. That's the structure that you have, and you can make those towers as large as you want. If you have a minimum, so minimum homeomorphism is when every orbit is dense. That's a topological version of organicity, if you wish. Organicity, if you wish. So, for minimal systems, everything is recurring. You pick a point. I don't know, I was reading Peterson's, Carl Peterson's book on dramatic theory as a student. I remember that example that somehow, I don't know, struck me. If you take a box, put a divider in it, and pump the air out of just one half of the box. So, one half is completely empty, and all the air is just in this part. Then remove the divider, the molecules will start to move around. The molecules will start to move around, they're going to fill up right the entire box, but at some point they will go back to the original half. There's probability one. We might have to wait, you know, like, you know, yes, more than that. But so here, for minimal homeomorphisms, you can start with a point, with a set, and everything will come back, and using trace as those orbits, you will get this construction. For a periodic systems, when you For apiotic systems, when the only thing you know is that every word is infinite, that's actually much, much harder to prove. You have to be creative, that's some version of the pigeonhole principle that you have to use. But it's still true. All right, so here's in this picture what's going on. What I will do is let's start with this set and see and only look pay attention at the points here. And they'll have to go up, up, but then they're going to split. Up, up, but then they're gonna split. Some points will turn to this tower, some points will go to this tower, some points will go to this tower. And just for this illustration, I'm gonna trace like green points and blue points as they cover those, trace those towers. As you'll see that, now I've got two new towers. One is green and one is blue. So the green towers will have eight levels. Will have eight levels. The first three they go through the first tower on the left. The next five will go through the middle tower. And the blue towers will have, I believe, 12 levels. The first tower, the middle tower, and the third tower. But these cloud sets here now are smaller than what you had before. And now you can actually encode it using graph. Actually, encode it using graph. Greater graphs, right? They are ubiquitous in mathematics, and here is another example of that. People who studied operator algebras have seen Bradley diagrams, and that's what we are getting. And so you can use graphs, graded graphs, to encode embeddings. So that's the goal. So you start with one vertex, that's your set X. Then you have three covers, you have three vertices. You had three vertices. And then you connect this level to the root, to the very top, using as many edges as the number of sets in each of your towers. Then what you do, you have one green tower, one blue tower, and see, okay, the green tower went to the leftmost tower, then the middle tower, and the blue one started on the left, middle, right. And now you can encode this kind of like consecutive embedding. This kind of like consecutive companion. And maybe you'll get something else, and more and more and more levels as you start to refine those towers and so on. And you'll get this infinite graph. So it turns out this graph pretty much knows everything about the system. That's just another representation of the system. What's important here is the order in which we trace those here. There is a ordering on the incoming edge. On the incoming edges. Each vertex, if you look at the edges that enter that vertex from the level above, you can actually put an order on those, order those edges. The left tower, the green tower went through the left tower, then the middle one. First, second, and here have 0, 1, 2. Left, middle, right. You can change the order sometimes, and maybe here, once you start to refine your partition, your towers will trace. Your towers will trace the towers from the previous level in a different way. But you get this nice infinite graph with kind of like partial ordering on the edges. Infinite path that start here and go all the way down. They form the Cantor set. You might have isolated points, but we're not worried about them. And there is a nice transformation that this ordering defines on this point. On this path space. So the way it works, it's pretty much a diameter. We're just going to add. Let's take a look at this red path. I want to find its image. Starting from this top level, I find the first edge that is not maximal. 0, right? This one is greater than 0. So I'm going to just move this one over here. And I'm not going to change anything below. Now, again, to Now, again, to find the image of this pass, I look at 1. Well, that's a maximum. Go down, this one is not maximum, there is 2. So that's why I'm going to change 1 to 2. I'm not going to touch anything below it. I'm going to connect this vertex to the root using zeros. And the image of this pass will be this pass, and so on. So essentially, you can change, you have this natural transformation on pass space as a diagram. Path spaces diagram and yeah, it's not always a homeomorphism, depending on how many maximal paths, minimum paths you have. If you have two maximal, three minimal, there's a problem. You want to have the same number and you have to worry, you know, be careful with the continuity. But what it turns out that for any minimal system, Hermann Padmanskal proved that from any minimal system, That from any minimal system, minimal homeomorphism is conjugate to a transformation like that, to a Bradley-Bershett model. In my PhD thesis, I proved that for any aparyotic system, you have the same result. So there is a natural model for your homeomorphism of the Cantercel. Okay. So here, what you have, you know, see in this slide is this kind of history. This kind of history, roughly, of private Vershek systems. Versik actually was the first one to observe that if you have a measure-preserving transformation, say, of the unit interval, he actually was the one who came up with this idea using the crater graphs to represent the dynamics. He called that Markov compact. So, and he said that in his paper: for the Markov chain, you have a stationary chain. Chain, you have a stationary chain, right? There is there are two kinds of transformations as he writes in his paper: one that is just regular shift of the Markov chain, but there's a reversal transformation that just counts orbits. And that's what he did. He didn't have to worry about recurrence, continuity, any of that, so it was just a nice, nice model. Again, Herman Panoscal did it for minimal holomorphisms. I did it for atriotic systems. And here, in between, what people have been working on. Between what people have been working on during all those years, that we're trying to understand, you have a class of transformations, substitution systems. Can you describe the Bradley diagrams? The answer is yes. You have toplet systems. Can you describe the Bradley diagrams? The answer is yes. And so. And there is lots of papers on that. Now, if you really want to dive in and get some good references, I can't recommend this book enough, actually. Book enough actually. Flavian Juron. He was the one who described bradle diagrams for primitive minimal substitution systems. And he wrote several books, and this is his latest book with lots of references. So how it will come in. Now, you have a graph, which actually knows everything about the system. And now you can ask all the questions. Can you find measures, invariant measures, by just by looking at the graph? Just by looking at the graph? The answer is yes. Can you say maybe the system has zero entropy by looking at the graph? Maybe sometimes. If it has, the answer might be yes sometimes. What about spectral properties? Again, there are lots of papers trying to uncover those relationships. All right, and I spent a great deal of time actually looking at the invariant methods. Now, for people interested in operator algebra, there's a very nice Algebras, there's a very natural k-zero group you can associate with this diagram. And traces on the k-zero groups are precisely mirror measures of the Bradwell diagram. There's one to one correspondence. And there's a beautiful kind of matrix theory. You can look at the products of matrices and so on to understand what the traces, what they are. Alright, now, here's the main object what I'm interested in right now. Interested in right now, called platofal groups, some people call ample groups, and so on. I'll give two definitions. The first one, given by Ian Potnam in his paper 1989, you look at the cross-product sensor algebra. You have a group acting on the Cantor set. He was looking at the group of integers, Z, minimal action. And you look at the cross-product sector algebra and And what you do, you take all possible unitary normalizers of your Carton sub algebra, 2 of x. And that's the topological full loop. I mean, that's just kind of sister algebraic description, not very useful. What's happening actually, if you just explain what that means, really loop, and you can prove that this definition is equivalent to To the definition that the full group consists essentially, take a group action G, and then what you do, you take all possible partitions of this space, and you use different group elements on different atoms of the partition and glue them together. You expand the definition of the group, essentially, while still keeping the orbit cooling structure the same. Essentially, we can make Essentially, we can make it on this piece, there is this element that acts, on this piece, there's just another element, and there's a way to glue it together. That's a topological filter. And the two things are equivalent except for the indentation. That's my type of examples. So, one more thing. Here, it doesn't have to be Z, it can be any group, amenable, good, non-amenable, use, reduced cross-product. You can use group four. Product, you can use group point, and so on. There are many, many different generalizations of this definition. The Thompson group V is of that class. You just have to use group four, some group four. So what is the Thompson group V? Let me just remind you the definition, right? You have the unit interval, you break it up into dyadic sub-intervals, and you just maybe rearrange them and maybe stretch them a little bit. You have to keep the slope. A little bit, you have to keep the slope powers of two and so on. The group of rational permutations. You just take the interval, divide it into equal lengths, segments, and you permute them. You're not allowed to stretch, you're not allowed to shrink. The difference here is that this group preserves the Lebesgue measure, this one does not. This one has no invariant measure actually at all on that space, except for no invariant. Except for no invariant measure. This one is local finite, so it must have an invariant measure. The one above it is non-amenable. If you have a minimal homeomorphism of the Cantor set, then the topological group is amenable, and you should manoeuvre that it's a really beautiful result, actually. And in 2013, just recently, Vilo Salo proved that. He proved that if you have a two-sided pernobile subshift where A is a finite alphabet, then this group is actually big. It contains every right-angle order group, it contains freeze groups and so on. And you can pretty much build a lot of different things actually by changing the underlying structure of this space or transformation. All right, again, the main question here is really proper. The main question here is to relate properties of the epidemic system to the algebraic properties of the full group. For example, what Hirokima to prove that if G is the integers and it's a subshift, the computator subgroup is finitely generable. There are different ways to do, you know, many, many different things to do that. I was trying at some point, I was really interested in this group actually knows a lot about the system. Knows a lot about the system. For Z actions, this group remembers the transformation up to the time reversal. So it will remember the entropy. I would spend a great deal of time trying to understand the entropy. I couldn't. I didn't succeed. But to me, you have to look at some kind of rectangles in the Kayla graph to encode words, but it's still wide open. Can you find the entropy inside the group? I'm sorry, just before I go. In your two examples, in the second example, about In the second example, about Solow's result, that T is just one transformation. One transformation. But the line above, the T is a group. And here it's also one transformation. Yeah, when there is a group, I could use G. Here, T is a single homeomorphism. And you look at this topological full group. I meant to say Z. That would be the problem. In the second one, a two-sided shift over CHAP. Yeah, that's Bernoulli shift, that's transformation, and it's topological for group. Full group is contained to every routing group. This one here is minimal, even though it can be again a subshift, but the group is kind of smaller, way smaller, so it's a minimal. There is this really interesting survey you can find in archive. It was he summoned a master's thesis from Austria. Beautiful region has everything, I mean, a lot you want to know about four groups. Groups. Yeah, I don't know what happened to that person, but unfortunately, there were no other publications. But this is just beautiful. I can't recommend it enough. Okay. All right. Group characters. Representation theory of groups. Let's actually see it. What I'm going to explain today is: can we find group characters in the topological groups? Are they related? Are they related to the underlying dynamics? The answer is yes, as you would expect. So, final group, a character right, is a you know, the trace of a unit representation. We're going to normalize it so that the character of the identity is one. And this is what I need for you know, permutation representation, right? Use permutation matrices and calculate the character of that permutation of the transparency of that representation. Of that representation. And if the group G acts on your finite space X, if you calculate the trace, you'll see just how many elements, how many ones you have with the diagonal. How many points the group don't move, doesn't move at all. So that's a set of fixed points, cardinality divided by the cardinality of x. That's a permutation character. And all right, for infinite groups, what is the definition of the character? The character. Again, you have to go back and just kind of get the properties. Value of the identity is one, class function, constant of the conjugacy classes, and which is a little harder to see is that the matrix is positive indefinite. But any combination of g of i's. Here, for infinite groups, you can use the Gelphan method. Infinite groups, you can use the Gelfand memory typical construction. And actually, again, if you have a character, you can construct what is known as a finite type Fourier algebra representation. And the trace of that algebra will give you the character that you start with. And you can go in both directions. There is this nice representation theory for infinite groups. Characters that are not combinations of other characters give you what's known as a factor. What's known as a factor algebra? Alright, back to the permutation characters. That's the definition we just saw. But there is another way to actually get a permutation character through a group action. Imagine that now you have an Ethan group that acts by preserving transformations on a probability measure space. Big rational permutations of the interval, if you wish. If you wish. Now, what you can do in the same way, you can now look at the measure of fixed points of the group value. And you can actually prove that that's a character. Bershik observed that, that's an actual group character. And the question is, or conjecture, question, or maybe a kind of framework that for each transformation groups, every character must be a permutation character that comes from an action. That comes from the action. So, I mean, it's not always true. The group must be simple, because if it's not simple, you can build something interesting that it's not real value. But if it's a simple group, large, and acts on some space, or maybe doesn't act on some space, if it's large enough, then that's all you've got. And that's what I've been interested in for a bunch of years, actually. Here's the first example: theory of that are. First example, theory that Artem Dutko, my collaborator in Warsaw, Poland, proved that for the Thomson group V, or F, F prime, F is not simple, so its commutator is simple. If you look at the action on the zero-bound interval, there is no indirect measure. They compress the set. And actually, in this case, we prove that there are no non-trivial. No non-trivial characters. There's always characters that equal to one. There's a character of the irregular representation, but that's it. That's it. And again, it had to do with the fact that the action is compressible. They compress sets. There is no end, you know, invariant measures. It's just an interesting observation of that. It has actually some, the fact that the group has no characters. That the group has no characters actually has can say a lot about its invariant random subgroups. There are no non-trivial invariant random subgroups. And which actually would mean that for Thomson group, right, the F that everybody's, you know, many people curious about, whether it's amenable or not, if you could, in your group F, this is the space of subgroups. And this is a trivial subgroup, and this is the entire group. And you have a lot of other subgroups inside of this space. That's a compact set. And the group itself acts a little bit by conjugation on the subgroups. And the question is, if you can find an invariant set inside of it that does not contain E or does not contain F, that would mean that the group is non-animal. Automatic. So, if inside the space of subgroups, you can find an invariant subset, a closed invariant subset, that does not contain trivial elementary subgroups, this one and that one, that would mean that the group is non-aminable. It's also like an invariant subset problem. But I mean, the answer is actually it's any invariant subset will contain either this or that. So, but um just an interesting kind of application of ideas from one field into into another. From one field into another. Now, back to Cantor minimal systems. We have a single homeomorphism right now. Look at this topological full group. The Kim-Ketter subgroup is simple. In fact, it's a property for any minimal group action or minimal group point and so on. That is a commutator of the topological group will be simple. Simple. There are some technicalities there, but for now that's all we need. This group actually, for a single homeomorphism, contains the Brandel diagram that you saw at the very beginning. So that's Bradley diagram, for example, an example. You take a homeomorphism, construct a Brandle diagram for it, and each diagram gives you a locally finite group that we call A. What do you do? Each level gives you. Each level gives you a group. So, this level here, for example, will give you two sets here. So, you have the permeation group of two elements. And one point here, there's one edge here. So, that's the permeation group of one element. If you go down to this level, you can count the number of paths that connect this vertex to the root. You have exactly five, four here and one there. You have S5, and this vertex gives you. And this vertex gives you six paths connected this way, you know, to the root. So you have S6. So essentially, we have S5 that just acts on the initial segments that terminate in this vertex, and S6 that acts on the initial segments that terminate in this vertex. And they're dependent, so you have this product. And now, as you go down the diagram, you'll just take the union, and they embed naturally with each other. You get this union of. In each other. You get this union of finite groups, and in the end, you get a local finite subgroup group. It's not always simple, but for minimal systems, its county is going to be simple, always. And this group is simple, is the diagram has its properties. It has even number of edges will pass between you know any two vertices, roughly speaking. There is a way to describe something here. There is a way to describe something here. So, this group here contains this local finite subgroup. It's huge in size. And what Slava Rogorchki and I, we proved that actually the whole group itself is generated by this local finite subgroup and T itself. If you just combine them together, that's all you got. But the actual interplay is quite interesting. That's what makes hope, how they interplay. Okay. Okay. So, with Artem Dutch, we had this paper back in 2013 where, under some assumptions, for example, that the diagram is uniformly bounded or an algorithm measures, the quadratic measures is finite, we prove that, we describe characters for this locally finite sample. And they're all of permutation type. We prove that to result. Yeah, this group actually can be described or characterized by the K0 group of the diagram, if you know what that is. All right, this is the main result that I'm going to announce that we are polishing right now. And the hope is we'll put it out on archive very, very soon. Is that for the Cantor Benial system? If you look at the camutinar subgroup, that is simple. Simple, then any character is of permutation type. Meaning there is an action of this group on n copies of x, on the product, the power of x, on the pass of your space, and you take a robotic measure of the space, the diagonal action, and the character is a measure of fixed points. What that means actually means that for any character or you know Or in decomposable character, you have maybe there is a finite number of organic measures on the space, but the character actually describes what this point simply calculates the measure fixed points, uses each of those measures, and multiply them together. Again, this very nice description of characters. And they all come from group actions. So that's the main result that I want to announce. And there are no constraints here on case diagram, on anything, just minimal items. Anything just minimal. I believe this result is true for any aminable group action. It's not true for non-aminable group actions. So I just need a minute, if it's okay, to finish it. And yeah, so here, what you look at here, there are three pictures. This is here actually, the A group that I defined for this diagram will be the group of rational permutations of the unit interval. It's a little hard to see, but actually that you can describe. It's a little hard to see, but actually, that you can describe it. And now there is only one measure, the Lebig measure, and you can get this result for free. And actually, that it was characters for that group was studied by Vershik's, I think, students, Gurechk and Petrov. They described them for the rational interpretation of the interval. But here we get it just for free. So this diagram actually has just one ergonomic measure. This diagram has. This diagram has two cadet measures, even though they're not that much different. But now you can actually use matrix products, you can actually apply all the diagrams and calculate measures and traces and just get many, many different things. So there are papers actually out there where people could do diagonal embeddings of symmetric groups and try to describe characters. And most what they could do, they could do just for diagonals of this, embeddings of this kind. Embeddings of this kind. And here, but now we can do with for any diagram, for any, because we don't have to worry about embeddings, because we just use like a totally different theme. Right, that's it. Thank you. Since we're running o out of over time, I suggest you remember your questions for quality for an hour and we can take a look at the picture. Thank you very much. Thank you very much.