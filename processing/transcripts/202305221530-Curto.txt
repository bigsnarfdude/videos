Thank you, Alina. It's a great pleasure for me to be here. When we thought about the workshop, we also thought about having each of the organizers teach a mini course in their respective areas of expertise. So this is my turn to tell you what I know about algebraic and spatial spectral theory. So these are the two types of spectral theory. Spectral theory. This is what I have in mind. We're going to try to cover one, two, three today, maybe four through seven on Wednesday, and this will probably be left for the notes. I plan to finish my slides and then we'll post them, right? So we're going to start from looking at algebraic joint spectra, which is a traditional way in which you have taken a course in several complex variables. A course in several complex variables, you surely have seen this. Yeah, right. Spatial joint spectra are more for the study of operators in Banach spaces, Hilbert spaces. And there are two key properties that we're going to consider, the spectrum mapping property and the projection property. It turns out that the projection property is the key one that implies the spectrum mapping property. And that, then we're going to construct an analytic functional calculus for the Taylor spectrum. That's what sigma. Or the Taylor spectrum, that's what sigma t stands for. And then this is sort of a little bit of Isiman decay frequency or the an multiplication by the dependent variable on Vermont spaces. So first from the beginning. So we have a unital commutative Panach algebra, the character space or the maximum ideal space of B, and the Gelfand transform, everybody knows how it works. It takes a character and evaluates them at the point A. At the point A, an element of D. And then the spectrum is the range of the Gelton transform. So the way I like to think of the spectrum is that whatever is in the image of the Gelton transform, that's it. But if you want to define it traditionally, it's like this. All the complex numbers so that A minus lambda does not emit an inverse. You cannot find an inverse for that. Okay. Okay, so A is invertible if and only if the Gelfand transform does not vanish throughout the maximal ideal space. Now, moreover, there is a homomorphism f to f of a from the algebra of analytic functions on a neighborhood of the spectrum, right? Taking one to one the identity function, which we write here. function, which we write here as c of z equals z, but normally we will write just simply z of a equal a. And then f of a hat is equal to f composed with a hat. So this allows us to expand the collection of elements in the algebra for which we can calculate spectra. For those of you who like to have a record of the lesson A record of the lecture I had said that I will be posting the slides later on. So if you want, take notes, of course, that's great, otherwise, don't worry about it. Now, if gamma is a smooth rectifiable curve, which is the boundary of an open set containing the spectrum, then there is a specific formula for f of a, which is using Cauchy's formula, but now with vector values, right? So this quantity here. This quantity here, Z minus A, which is the resolvent, C minus A inverse, is taking values in the Vanach algebra, right? But other than that, this is your traditional Cauchy formula from complex analysis. So as a consequence, when I calculate the range of the Gelfand transform, I can realize it as F of the spectrum of A, and that's what is called. Of A, and that's what is called this spectrum mapping theorem. That when I calculate the spectrum f of A, that's F of the spectrum F. And this is true for any analytic function on a neighborhood of the spectrum. When B is non-loading commutative, say B L of X, where X is a Banach space, boundary operators, one looks for a commutative sub-algebra A containing little L, right? And so. L, right? And so then you say, well, what if I take sigma sub A of A as my notion of spectrum, right? It will depend upon A, but it turns out that if I select A to be maximal as an abelian subalgebra, then the spectrum turns out to be independent of that. So if I make sure that my algebra is maximal abelian subalgebra, then I Subalgebra, then I do have a notion of a spectrum. And I could then define sigma B array to be sigma A array, where B is not commutative, but A is the maximal ability subalgebra is commutative. Now, it turns out that if R is the smallest inverse closed subalgebra of B containing A, then this spectrum is equal to the spectrum of A in B. Of A in B. And so this would be a Roman R, this type of there. And we also write R with a Roman because it's going to be for the rational spectrum. So we want to identify that as a special sub-attribute. And so amongst the collection of all of these spectra, we select the one corresponding to the smallest inverse closed sub-algebra of each. In the case of several bands, In the case of several Banach algebra elements, you say, well, what's going to be the joint spectral theory? It turns out to be more complicated, but not at the beginning, right? Because I could now look at the n-tuple of elements and take the joint image under the Gelfand transform, right? So I would look at the Gelfand transform, which is coordinated by coordinate and evaluate it on the maximum ideal space. And that could be my definition of algebraic space. Algebraic. In these lectures, we're going to concentrate on the elementary aspects of the commutative theory, and first looking at the algebraic viewpoint initiated by Arns, Calderon, and Welbrech in the 1950s, and then turn into the spatial approach, which was initiated by several people, but culminated in the wonderful work of Joe Taylor in 1970. For spatial For spatial spectral systems, we're going to restrict attention to the Hilbert space situation, especially since we can build a functional calculus using ideas from sister algebra. And that's the approach taken by Florian Vasilescu. And we're going to offer a number of simplifications and improvements. So part of my work is to understand what Taylor, Vasilescu, Arnold Swelberg, Calderon had done and so on. Welbert Caldron, Caton, and so on, and bring it more down to Earth, particularly the theory from Joe Taylor. It's very abstract, a lot of homological algebra and things of that nature, which can be simplified using the Vasilescu's approach. And then the work of Zelasko, who was the first one to identify the projection property as an essential condition to get the spectrum mapping theorem. So we're going to say how spatial. We're going to say how spatial notions of non-singularity really amount to the non-vanishing of the Gelfand transform on suitable subsets of the maximal ideal space. So if I took at the entire maximal ideal space, I get the traditional sigma V of A spectrum relative to the algebra. But if I take compact subsets of that, each one of them is going to generate a spatial spectral system. So there's going to be then a correlation between having. Then, a correlation between having compact subsets of the maximum ideal space of certain commutative algebra and a collection of spatial spectral systems. Throughout the mini course, we will keep an eye on the applications and the connections of several conference variables, and toward the end, we will also have time for frequent theory and the study of Vermont tuples over Ranker domains. Many more interrelations with complex analysis, sheaf theory, complex geometry, complex geometry. Theory, complex geometry, complex geometric matrix theory take place. And I have chosen not to delve on those because we want to keep the level elementary. But for example, the work of Eschmeier and Kutner should be mentioned when we talk about using chic theory to understand spectrum theory. The spatial theory is already almost 60 years old and various simplifications have been provided. And various simplifications have been provided, at least in the Hilbert space case, to make it accessible. Only basic notions of eight-parallel algebra, single operator theory, and several complex variables are required to follow the mini course. Here is the notation that we're going to adopt throughout the course. First one is a vector space or Banach space. H is a Heber space. L of X is the unital algebra linear. L of x is the unital algebra linear transformations, boundary operators on x. B is a unital Banach algebra, the maximal ideal space Cn. Omega is a boundary open subset of Cn. The symbol for definition, range, and kernel projection, orthogonal projection of a human space into a closed subspace, similar to what Michael used for definition of template operators in the previous talk, and then the exterior algebra that plays a central role in. That plays an essential role in the definition of the Taylor spectrum. I have tried and made every effort to give proper credit to the mathematicians who participated in this tour. And I want to make sure that if I don't mention a name attached to a result, that doesn't mean that it belongs to the speaker, right? Keep that in mind. I will have an opportunity to mention what results I have proved that don't. Results that have proved, but don't make any assumptions about the theorems that don't have a name. So let's start with the algebraic joint spectrum. So we have the Barnach algebra, maximal ideal space, the Gelfand transform, and the definition of invertibility with respect to the algebra is this operation A circle B, where you take AI A1B1 plus A2B2, AABN. The A and B n, kind of like the dot product in a certain sense, and that has to be equal to one. And when that happens, we say that A is invertible, the inverse is B, and the spectrum is the collection of all the lambdas for which A minus lambda is not invertible. And so the following is a well-known fact that the spectrum is equal to the Lambdas for which a minus lambda circle b to the n is not b and is also equal to the range of the joint Gelfand transform. This is the magic of this, is that you do a joint Gelpin transform. So, as a corollary, if you take a polynomial mapping from Cn to CK, so it's a map that coordinate by coordinate is Coordinate by coordinate is a polynomial, right? So it goes on Cn to K copies of C, and for every P1, P2, PK, each one of those is a polynomial in n variables. And then the spectral mapping property for polynomial mappings, that's released. In particular, if I take one coordinate, Ai, I get the projection property by taking lambda. Property by taking lambda pi over here. Is this notion due to Homender? Because I first noticed this definition in his book. Well, it's there, it's in Gamelin's book. Yeah, so you can go, I think it goes really down to what Aaron, Stalderon, Welbrick were doing, saying in the 1950s. It's definitely the 1950s. Damned in his book is 1959, or Manders, I think, is 63 or so. Or Mondays, I think it's 63 or so. So people there, but they are not, Gamelin is collecting information from other people. Gamelin does put emphasis on the polynomial convex whole, which we'll be doing right now. Can I ask a very primitive question? Just from the definition on the previous slide of this spectrum? So is this an analytic subset of CN? What kind of, is it a hypersurface? hypersurface uh higher co-dimensional oh it's a complicated it's it's it's it's going to be compact because it's it's in the range of the uh gelman transform it's definitely compact but beyond that yeah we can we can study there's plenty to it's very very it depends upon the banach algebra it depends upon the elements and so on yeah say it again it could be any compounds Say it again? It could be any compact size. Any compound, yes. Any compound. One of the things that we're going to prove actually is that if you take a commutative Fanak algebra and you look at any compact set of maximum ideal space, you can build a spatial joint spectrum that will capture that compact set. So compact sets and spatial spectral systems are in one-to-one correspondence. All right, so let's look at polynomial convexity. At the polynomial convexity here. So, here we're going to take all the lambdas in Cn so that P of lambda is less than or equal to the norm of P over K. K is this compact set, bounded set really, doesn't have to be compact. And the algebra of polynomials. And so K is containing the polynomial convex whole. And when they are equal, we say that K is polynomial convex. K cat is convex. K cat is always closed because the polynomials are continuous, right? Continuous functions. So if you take a sequence lambda n converging to lambda, p lambda m will be less than or equal to this, and so p of lambda will be less than or equal to that. So it's clear to be closed, and since k is bounded, then it's also going to be bounded, compact, and so forth. Here's an example. When n is equal to 1, k is polynomial convex if and only if the first cohomology. Only if the first cohomology group of k is equal to zero, so k has no holes, right? So there are no bounded components of the complement of k. For any bigger than one, there exists contractible sets which are not polynomial convex. And one of the ones that is my favorite is the so-called L-shaped domain. I'm going to just draw this is Z1 absolute value, and this is Z2 absolute value. C2 absolute value, this is A and B, say, or if you like, delta one and delta two. Right? And so we're talking about this. That's your K, and the polynomial complex whole graphs is hyperbola. There is a hyperbola there, and it's obtained, it's added. Despite the set being perfectly contractible to a point, no holes of any kind, you pick up a whole bunch of additional information. Bunch of additional information from that hyperbola. Now, when n and k are bigger than or equal to 1 and k is in Cn and L is in CK, you can take the Cartesian product and still polynomially convex. Actually, the convex hole of the Cartesian product is the Cartesian product of the convex holes. This is the unit ball in Cn with the Hilbert space norm. It's a polynomial convex. Is a polynomial convex. The union of two disjoint compact convex sets is polynomially convex, and so is the disjoint union of three closed balls. However, the union of three disjoint polydists cannot be polynomial complex, and to my knowledge, this is still an open problem. It is unknown whether the union of four disjoint closes. Four these young closed boxes is for an element. That I think remains an open value. It's been open for a long time. Okay. Here is the question. Yes. Is there a number where it's known that it's false? Oh, five. Five is false. Yeah. So, can I ask another question? I'm sorry, I'm just trying to. No, no, sure. If your domain is pseudo-convex, is it? Oh, what's the most implicit which directs? Input which input convex is pseudo-convex, not the other way around, right? And pseudo-convex is important because that's what for the del power complus. OKA and oops, what did I do here? I think I did something. Okay, so now how do I get rid of that? Okay, here we go. Okay, so Okebaye proved that when k is polynomially convex and omega is an open subset containing k, analytic functions in omega can be approximated uniformly by a sequence of polynomials. So the value of polynomial convexity is that you can always approximate an analytic function by Approximated analytic function by polynomials. Polynomial convex sets can only be regarded as maximum ideal spaces as the following result shows. If you take a compact subset of Cn and P of K is the closure of C of Z, then M P K is canonically homeomorphic to K hat P at this map. I don't know what's going on there. Oh, close that. Look, look. Look at the left corner of that upper left corner of that. It's gone now. Okay, is that okay now? It's fine. But I have to return to the full screen view. View hopefully, I won't pick it up again. Full screen mode. Oh, there. Okay. I must attach, I think there is another extra button here that I must attach accidentally. Okay, so we have this canonical representation for every compact set and P of K in the closure of polynomials. Then the maximal ideal of PK is the polynomial convex solid K. Convex hole of K, right? And this theorem 1.8 says that if I have an n-tuple in B and assume that the generators that generate B, so the polynomials in A, A1, A2, AN, is dense in B, then the maximum ideal space of B is identified via this map. And therefore, the And therefore, the spectrum, the joint spectrum of A in B is polynomial complex. So whenever you have an n-tuple that generates as an algebra, the entire algebra, B, you're bound to get something polynomial complex. And the proof is somewhat straightforward because you need to just establish a map from the maximum ideal space evaluating at A. And to prove that this is polynomially convex, you look at it, take an arbitrary polynomial and calculate the P of lambda dominated by this for all p in C. Okay, so if I restrict attention to the spectrum, this is the image of the Gelfand transform. I can bring the Gelfand transform inside here and then Inside here and then dominated by P of A. So that tells me that evaluations of P at these guys are going to be dominated by P of A, and that's what I need to extend this to a multiplicative linear functional to entire P. Okay? Here A is equal to lambda, so lambda is in the image of the Gelfand transform, which is a spectrum. So our next goal is to construct an analytic. Goal is to construct an analytic functional calculus for this. There are at least two instances where the construction can be carried out explicitly. I think by now you will believe that this is true. If I have an open polydomain, a polydomain means that I have a domain in each of the coordinates to take the Cartesian product, right? I have a Cauchy formula for each of the variables, and I simply just multiply all the Cauchy kernels. All the Cauchy kernels. There is one Cauchy kernel per coordinate, and that's my new kernel to represent the analytic function working in a poly domain, right? And so the distinguished boundary is the Cartesian product of the boundaries of each of these poly domains. And so that's my f of A. That's the definition, official definition of the F of A. I have this formula, I write this one with A there. With A there. All right. And when F is a polynomial, I get what I want. So is the evaluation of the polynomial at the point. Now, when the spectrum of A is polynomially convex and F is in H of omega, so analytic in omega, omega containing the spectrum, I pick a K for. I pick a K, polynomially convex, so that it's in between, right? I can find a K between this and this. And then what happens now is by the Okabayel theorem, I can find a sequence of polynomials, Pm, converging uniformly to my function f. f is analytic, Okabayel says. Ochabias says you can find a collection of polynomials converging to F of A. And then that's what we need to construct the functional calculus. And I'm going to follow the guidelines from Woelberg. So first we need to recall what a functional calculus is. It's supposed to be a map going is it's supposed to be a map going from this would be H, A, analytic functions on the spectrum into B, indexed by n-tuples. And I'm going to adopt the notation here, which is whenever I have a commuting n-tuple in B, I'm going to write A subset B. So A subset B means I have an N tuple any length whose elements come from B and all the elements are are commuting. The elements are commuting. So, what we need is: given an analytic function in the neighborhood of the spectrum of A, I want to find an element f of A that extends the definition of a polynomial in that element. So, Wembrick said the following. Let's look at the rational spectrum of A in here. We're going to denote sigma R of A. This, remember, was the spectrum relative. Remember, was the spectrum relative to the smallest inverse close subalgebra of B. And in general, we know that it's the largest possible algebraic spectrum. And we're going to say that we also observe that this is rationally convex because the same inequality that we have with polynomial convexity. Quality that we have with polynomial convexity is now true for rational functions with singularities off of the rational spectrum. And so given a polynomial mapping and given open polydomains, we construct this gadget here, which is given by P, D, the polydomain, and then delta, okay, is one, there are two polydomains. There are two points of range, one in Cn and one in CK, right? And then we look at the closure of these as a polynomial polyhedron. And polynomial polyhedron are automatically polynomially convex. So it's a special kind of polynomial convex set that we're going to need. And this is in order to have this iota nap, which is inserting Z as a Z as a pair Z, P of Z. So it's like the graph of the polynomial P, polynomial map on P. And rho is I star, so it's the dual map. And what Cartan showed is that this map is always onto. Under those conditions, rho is always onto. And so if I choose my G C W as P C minus W, like here, then Like here, then the idea generated by g satisfies the following property. If a function is in ig, then rho of f has to be identically equal to zero. So this is coming from the fact that Cartan was able to show that that rho is is horizontal. So the following theorem asserts that that known space is precisely I of g. Precisely I of G. So OCA, Cartan, and Wolbrick show that the analytic functions on B cross delta, this should be a delta, not a delta, divided by the ideal generated by G, G is this map Pz minus W, that ideal, is exactly the same thing as the analytic functions on this polyhedra that was generated. polyhedra that was generated using P, using omega, and using so here is a construction of Wilburg, but we need a key result that says if you take an n-tuple in B and omega an open subset containing the rational spectrum, then there exist all domains so that the rational spectrum is containing here containing omega. So what Wilbrech was worried about was I have Was worried about was I have my rational spectrum and I have omega, but I need to insert a polyhedron, polyhedra in between. And so the construction of the functional calculus is now not too hard once you have that approach because you define f of a as being this capital F of A in P A, where the capital F is where the capital F is some function analytic here, which comes from the fact that Cartan proved that this map rho is onto. So given my F, I can realize it as rho of capital F, and I'm going to use that capital F to define the value of F of A. Okay? So in a certain sense, the IOTA map took Z, P of Z, then the then the row map took a new function g of z w as f of z minus w and by combining the two and knowing that rho is surjective, I now have a clean definition of what is capital F of A P A, which is going to be for me F of A. So this is all well defined, but in order to be a functional calculus, I'm going to have to, for example, prove that if I were to take a polynomial here, I were to take a polynomial here, I get the same polynomial, right? Because all is well and nice, assuming that you can check it on the polynomial. It's supposed to extend polynomials. So one needs to check, first of all, that this is independent of the polyhedron, right? And also, we need to check that if I take two analytic functions that agree on the intersection of omega 1 and omega 2, what I get for F1 and what I get for 1211. For F1 and what I get for F2 are one and the same element in the Panach algebra. And finally, if I take a polynomial, I have to come up with what I have here. Here is a calculation for a polynomial. So there were three things to check, independence of the polyhedron. If two functions agree on the intersection of two of them, then I get the same value. And if I take a polynomial, I get this expression, which is supposed to be the right expression. So, but here comes what Wilbrech couldn't find initially, which is the Arens-Calderon trick. And the Ahrens-Calderon trick encapsulates already the projection property, because they say take an element in Bn, an n-tuple in B, and take omega containing the spectrum. Then there exists B, B1, BK, some dense, so that omega containing the spectrum. so that omega contains the projection onto the first coordinate of sigma hat of AB. So I have my A, I'm going to tack on a B, I'm going to form an M plus K tuple, calculate the spectrum of that, algebraic spectrum of that, project it onto the first n coordinates, and I'm going to be inside omega. So it's a trick that consistently you need more space, so you're going to add You need more space, so you're going to add elements V1, V2, VK, calculate the joint spectrum of the big one, project it, and then you are inside this on it. So although not explicit in the work of Aaron Calderon, it is, the projection property is realized there. So oops, I think I went too fast there. Here was the proof and Here was the proof, and it's essentially what I just mentioned before. So I just move on to the next one. And so you get if a lambda that doesn't belong to the projection of this, and remember that this can be identified, this is the polynomial, the convex hull of the expanditional spectrum can be identified with the Laxman ideal. Can be identified with the maximum ideal space or the algebra generated by A and B. And so there exists an open neighborhood of lambda so that lambda, gamma of lambda intersection, this projection is empty. I'm saying. Remember that P of A is compact, so lambda is not in the ideal confining neighborhood. And by a compactness argument, one can then conclude that this is. That this is inside the nature. And now you may need finitely many interpoles, each one coming from an application of the RNS quadronal trick, but to finish the proof, just take the whole slate of all L tuples to get what you want. Is there a control on the size of L? Not really, and it's not really important because all you want is that to be able to start from L. want is that to be able to start from A, make it bigger, calculate the spectrum, project and B and contain the initial spectrum. So the theorem is the following. It's the Shiro, Ahrens-Palderon, Wellbrick. There exists a continuous homomorphism from the analytic functions in a neighborhood of the spectrum into B so that number one, one of A is equal to one. 1 of A is equal to 1, the constant goes to the constants. Zi of A is Ai. And F of A hat is F composed with A hat. And consequently, the spectrum of F of A is F of the spectrum of A. So you get the spectral mapping theorem for analytic functions out of this construction. So construction is such that you construct the functional calculus and you prove the spectral mapping theorem property at the same time. That's in this algebraic joint spectrum. Now, a couple of remarks. If you take finite degenerative Arnach algebras, this result was already proved by Shiloh, so that's why I attach his name to the result. For an extension to locally convex algebras, Sebasti√£o Silva, a Portuguese mathematician, was able to do the same thing. And there is a uniqueness of the functional calculus. The uniqueness of the functional calculus, which is if you assume that there is another functional calculus satisfying this, then it will have to agree with this one. Later on, when we study Taylor spectrum, we're going to see, in my opinion, much better result due to Mikai Putinard that says that there is uniqueness for the Taylor spectrum. And Taylor spectrum is relevant because all the algebraic spectra are going to be Taylor spectra. Okay. So we are ready now for a spatial joint spectra, which is what I call the axiomatic approach created by Silasko. We're going to try to think about a joint spectrum with certain properties, not specific examples of joint spectrum, but just the properties. And based on the properties, we're going to build axiomatically a theory. So first of all, take a unit Albanach algebra, notice not necessarily. Algebra, not necessarily commutative, n being or equal to 1. And then we're going to say b ncon is collections of n tuples which are commuted. And this is the notation that we already introduced. When b is a non-commutative unit of Banach algebra, say L of X, where X is Banach space, one would try to find the spectrum by saying, well, let me see. Well, let me see. I have my entrupal. I'm going to look at the maximal abridgment subalgebra containing that, and that's going to be my definition of the spectrum. But Ernst Albrecht comes into play from Saarland and says, wait, there exists one X space X, and then two pole A, maximum Saval. Maximal ability and subalgebra and a2. These two are different. I was there when he found it. Okay, actually, he had visited my house first and then I went to Sarlan to give a talk and then he told me about this. It's fantastic, right? So this means you're going to have to try something else. Okay. So given a set x, we're going to say p of x is the power set. Say P of x is the power set, C omega is the Cartesian product of the numerably many copies of the complex numbers. So, what is a spectral system? Spectral system is a map that sigma tilde, right, going from the union of B and con to the power set of C omega, because a spectral system is going to have different sort of sizes according to how. Sizes according to how many was the size for n, right? And with the properties, the following properties: if A is in B, sigma tilde has to be non-empty. If A is in B of size n, sigma tilde has to be in Cn. I do not want my my sigma tilde to be spread all over the place. Since I have countably many coordinates for the power set, I The power set, I want to, if I have a pair, I want this sigma tilde to appear in the first two coordinates, not in the 17 and 18 coordinates, right? So, this is kind of important in order to have some kind of correlation between the different situations. And I want it to be compact. So, non-empty, compact, and this property. That's a spectral system. And a spectral system only of an x-based spectral system for L of X. To 4L of x. All right, I take a Banach algebra, I look at spectral system with the projection property. It's what you would imagine. If I take a pair of tuples, commuting tuples, sigma tilde of that projects onto sigma tilde array. So that is a fundamental property of spectral systems. Say that sigma tilde possesses Sigma tilde possesses the spectral mapping property if for all polynomial mappings from Cn to CK, you get what you're supposed to get, which is that quality here. Examples. If B is commutative, sigma B, sigma R, sigma F are all spectral systems. This is the first one that I show you at the beginning. The first one that I showed you at the beginning, this is the image of the Gelfand transform. This is the rational spectrum. This is sigma hat, this is a polynomially convex spectrum. They are all spectral systems. However, only the first one has the projection property. This one, which was a favorite of many people for some time, does not have the projection property. And you cannot expect spectral mapping theorem if you don't have the projection property, because the projection property is a special case of the projection property. This special case of the spectrum mapping theoretically. Alright, what else? I have, I can look at the Banach algebra in A by A, the conmutant of that, the double conmutant of that, right? And then sigma cut, which is the, using the Garen's Galon trick, is nothing else but the spectrum of A. Spectrum of A with respect to its own Banach algebra. A generates its own Banach algebra. So if I calculate the spectrum there, I get polynomial convex spectrum. Sigma double prime is the spectrum relative to the double condutant, and sigma prime is all the things of this form here. I cannot write it like this because this is commutative, this is commutative, but this may not be commutative. The commutant may not be, so I cannot. The condutant may not be. So I cannot just say that it's sigma a prime of a, right? I have to do it in the other way, which is using the simple operation. More generally, if A is any close sub-algebra containing A in the center, we can let sigma sub A of A to be even in that form, right? And sigma hat, sigma prime, sigma double prime are all expected. Sigma naught prime are all expected system without the projection property, something shown by Shawkovsky and Zelasko. And sigma prime is contained in sigma naught prime contained in sigma prime. One thing that Taylor is going to do, his spectrum is going to be contained in sigma prime. Taylor's spectrum is going to be smaller than each of these. Certain sense what people say is that small enough to be of Enough to be of significant use because you have many analytic functions that are functions that are analytic in the neighborhood of the Taylor spectrum and big enough to have beautiful results for this. Okay, so we refer to an antibacterial spectrum. We mean sigma A for some A. Now we're going to define spatial spectra. One is the left. Spectra, one is the left spectrum, although this can also be considered somewhat algebraic because we're taking the circle operation here, right? So if all the lambdas of which A minus lambda does not have a left inverse, all the lambdas of which A minus lambda does not have a right inverse, the hard spectrum, which is the union of the left and the right spectrum, and so we see that sigma L and sigma R. That sigma L and sigma R are contained here, containing sigma prime. And sigma L, sigma R, and sigma H all possess the projection property. So these three have the projection property. Now comes the approximate Boolean spectrum and defect spectrum. This is defined in terms of bounded below, when all the lambdas for which When all the lambdas for which a minus lambda is not jointly bound below, and then it's not jointly onto, right? So this is sigma delta, the defect spectrum. Now jointly bound to below is what you anticipate, is you take the sum of the norms of Ai acting on X is bounded below by epsilon X for some epsilon, and jointly onto means. And jointly onto means this over here. Now, if your banach space is a has complements for all subspaces, closed subspaces, then left spectrum and approximate point spectrum are the same, and right spectrum and defect spectrum are the same. Hilbert space, left and approximate are always the same, and right and defective defect spectrum, that would be the same. Spectral delta set. Okay. Sigma pi and sigma delta are the spectral system with a projection property. And now here comes the Shokowski spectral systems introduced in the early 70s, a couple of years after Taylor had published his first two papers, he showed that they are spectral systems with depredation property. When we look at the Kosu. When we look at the Kosovo complex in a minute, you're going to see what this KOSUN complex is going to be a co-chain complex that will detect some spatial similarities for the L-tuple. And what Schokowski did is grab the front end of the Kausum complex or the back end of the Kausum complex to define his approximate point spectra and detect spectra the event here. So these are Here. So these are partially, they detect singularities in portions of the tail of the causal concrete. More in a minute. And then the product, partition product spectrum, which is simply not having any ideas in mind, you say, well, how if I just take the spectrum rate one, cross-the-spectrum rate two, cross-the-spectrum ray n, that's going to be a spectrum. Expect a way and thus will be a spectral system, right? So, and it has the projection property by definition, right? All right. So, it has the projection property, but bad news in terms of polynomial mappings. I'm going to take an eigenpotent, non-trivial eigenpotent in LOX, so the spectrum is going to be 0 and 1, and then look at p, p. So the The product spectrum is going to grab the spectrum of P times the spectrum of P, so 0, 1 times 0, 1, which gives you four points, right? But if I took 2p, right, I'm going to have the spectrum has to be 0 and 2, right? But however, when I add these, I get 0, 1, and 2. So the spectrum of 2p is not the same as p of the spectrum. As P of the spectrum at the product spectrum of P P, right? So problem here. So it has a production property and doesn't have the spectral mapping property for polynomials. And Raul, I think you said at the beginning that production property is very much related to that, assuming that you have some bound on the spectral system. That's what we're going to discover now. So this example motivates and say what is the best. Example motivates and say what is going on here. Why is the projection property not giving me the polynomial spectrum mapping property? Because there has to be some control on the size of the spectra. Okay, so we will see in section three that if the spectral system satisfies locally an inclusion of the form sigma tilde containing sigma b, where b is commutative, then the spectral mapping property implies the spectral The influence the spectral, the spectral, the projection property influence the spectrum. So, this is the bound that we need. For some commutative anacalgebra, my sigma tilde has to be inside that sigma. And that property is not satisfied by the product, the Cartesian product spectrum. And so, here comes the Taylor spectrum, which is the start of the show in a certain sense. So, start with the exterior algebra. So, I don't have to tell you in this what the serializer is, but there is a definition. So, the key property is that Ei Ej plus Ej Ei is equal to 0, so in particular EI square is always equal to 0. And then we form these maps, which are called the creation operators, where you take a form and you multiply by the generator. In the first talk this morning, I mean we First talk this morning, I mean, we had something similar because you had a tree, and you have a map taking that tree one level down. So there was creation of the new strike. But this is for the exterior algebra. Okay, and they automatically have this relation, Eij plus Ej Ei equals zero. And if we regard this as the Hilbert space, which doesn't take much, you simply need to look at this collection of Need to look at this collection of products and declare them an orthonormal basis just by fiat. You say, you guys are going to be an orthonormal basis. And so when you do that, this becomes automatically Hilbert space. And this here, the EIs are now going to be partial isometries. So every form is going to emit a decomposition. So think of a form. You grab the EIs in front. The EIs in front, which you can do by maybe switching the signs and so on. So EI times C prime plus something else, whatever you said. And these two are automatically orthogonal because of the definition of the inner product, right? And so we have an element in the range of EI and an element in the kernel of EI star. And anybody who's done study partial isometries will know that's a. study partial isometries we know that's a that's a code for partial isometry because EI star EI plus Ej EI star is equal to the delta Ij and in a situation algebra we say something is a partial isometry if V star V V star is V star or if V star V is an orthogonal projection by me by that we mean idempotent and also self-adjoint okay okay so now I take a vector space so Now I take a vector space. So Taylor is not focusing entirely on Hilbert spaces. It's Banach spaces, but the exterior algebra is a Hilbert space. Exterior algebra, Hilbert space, and then tensor Banach space. That's the idea from Taylor. And we're going to have a boundary map this way, which is given by the AIs, tensor, the EIs. By the way, this is the cohomology version of Taylor Spectrum. Initially, in his Spectrum. Initially, in his first paper, he did the homology version, which was a little bit more complicated. But just an algebraic tensor product of the different space products. Algebraic tensor product. Yeah. Algebraic tensor product over the complex algebra. Okay. So notice what happens with the square. You have AJAI, but then because of the conductivity here, you can replace it by this sum over here. This sum over here, right? The case i equals j I can eliminate because EIEI is equal to zero. And so because of the commutativity of these AIs, I can write it this way, but I know that this is the delta ij, right? And so as a result, I get zero. So the square of this map is zero. So I have created a map which is a nimboten of order two. The order 2. So it follows that the range is containing the kernel. Very easy observation. And actually, this is something that Vasilescu exploited very nicely in his work. So we say that A is non-singular if the range of dA is equal to the kernel of da. So we have a a pin button of index two, and it's a the range is in the kernel. Of ranges in the kernel. When they are equal, I'm going to declare this to be a non-singular tuple. When n is equal to 1, this is exactly what we say 1 to 1 and onto, and therefore invertible. And then the Taylor spectrum is going to capture all the lambdas for which this is not an equality. And now I'm going to show you the construction of the Cozou complex, which was an object known. Was an object known from the times of Kozul in the early 1900s, and it was a generalization of the Durand complex. That's what Kozul wanted to do, just generalizing Durand complex. Okay, so here we're gonna take care of the forms of degree 0, 1, 2, 3, and so forth, much like what this morning we were seeing in terms of level, different levels for the tree. Different levels of the tree. This is the same kind of idea that you are cataloging, what I would say, the homogeneous forms of degree 1, 2, 3, 4, and so forth. And this map, which is defined in terms of the creation operators, is going to take me from one level to the next. So I have a chain complex, or cold chain complex, actually, and saying that the range is equal to the kernel is saying. The range is equal to the kernel is saying that this causal compress is exact at every level. So data respectively detects the lambdas for which this is not exact. Here is an illustrative example, which I like very much. I actually was bold enough to teach this in my Calculus 3 course, the multivariable calculus, towards the end. I always did one more together. Towards the end. I always did one more to the end. Because I love it. It's and it's a way to remember the identities for divergence, curl and and clearance, right? So here we go. And I consider C infinity functions that vanish at infinity, right? So that way I don't have to deal with when the gradient is zero, what happens, and so on. So the gradient first, right? Then comes the curl, and then comes the divergence, right? The divergence, right? And you can name exactness is each of those, the divergence theorem, the stock theorem, in my case you may equal to Green's theorem, and so forth. It's all there. I love it. The students, I'm not sure. They learned their choice. We love it. So you can see that that's the composition thing. But those identities, they have trouble remembering. And if they knew the cosmic composition, they don't have to worry about it. Just the composition. Taylor showed that infected finite space, and then the Taylor spectrum is compact and non-empty, and then it's containing sigma prime. So here we go. Remember that sigma prime is containing sigma cat, which was the requirement that we were going to impose to make the projection property imply the spectral mapping property. So moreover, sigma cars and Moreover, sigma t carrots and an anti-functional calculus in particular has the projection property. We take a close look at sigma t in section four. For now, we would like to indicate how dA reflects the joint spatial behavior of a1 a2n. So I'm going to start with case n equals 1. And so what is dA? Well, we only have forms of 0 forms and 1 forms, and this guy takes 0 forms to 1 forms, so we have to have an a there. To one force, we have to have an A there, so VA is very boring. This is what it is, right? But it captures everything. The kernel of VA is the kernel of A plus X. The range is 0 plus the range. Take the quotient, you get that. And this means injective, and this means subjective, right? So everything is there in one single diagram to have the spectral theory of a single operator. Now, n equal to. This becomes more interesting because you have a1, a2 here, and minus a2, a1. And minus a2a1. This is the first boundary operator, which goes from one copy x to two copies of x, so it's a column operator, and the other one goes from two copies to one copy, so it's a row operator. And notice that if I multiply, if I take minus a2, a1 times a1 and 2, right, put a1 and 2 over here, I get 0 in the composition. All right. So if you look at the kernel and the range, and you At the kernel and the range, and you think about this for a minute, that's what you get. So, when you take the approximate point spectrum, this is the lack of exactness here, right? In the first, in the zero stage, the defect spectrum captures this over there. So these two are contained in the Taylor spectrum. And the set sigma p, when it's not much. When it's not one-to-one, it's called the point spectrum and consists of the joint typing values, right? And unlike sigma delta and sigma pi, sigma p, in general, is not a spectral system, but this is because it's often empty. If you've given an operator, chances are it's not going to have eigenvalues, right? So that's the problem with that. And Taylor proved that if B is a commutative Anac algebra and A is containing V, if we let L sub A denote the left quantification. Denote the left multiplications, then the beta spectrum of AB is the spectrum of A relative to B. So this is to me one of the major accomplishments of Taylor. Realizing every algebraic spectrum is really the Taylor spectrum of the left multiplications acting on this. Right? This is. So the Taylor spectrum is canonical. Every algebraic spectrum can be written as a Taylor spectrum. Okay, so we are almost there. So here comes the way in which he proves this. So he actually manufactures a special form so that when you apply D to that form, you end up with this identity here, and that gives you one. So I'll let you look at that for a second. But the key is that you have to eliminate one. One AEI per term here in order to make it so that when you do the multiplication, you pick up this minus one to the I minus one here. It's clear. It's something that he discovered, right? So, and then conversely, if you know that A s equal B is equal to one, this is the easy part. You can just write down what the equation is going to be. DA DB tilde plus dB tilde dA is equal to 1. is equal to 1. Okay, the same result with identical proof also holds if these non-commutative. And then every algebraic joint spectrum can be thought of as sigma t. I proved a spectral permanence in 1982. I was very proud at the time of this because what happens is that when you look at sister algebras, the Taylor spectrum is the same with that you regard the element as part of the sister algebra, as part of the algebra as part of L of H or acting on H. All those Taylor spectra are exactly the same. And that's my signal that my time is up. So what I want to finish with is saying that there is a way to interpret this, a way to understand spectral permanence, because it all comes down to looking at the invertibility of this guy over here, which is what we're going to call the Laplacian when we continue. The Laplacian, when we continue on Wednesday morning. So you look at the boundary map from the Laplacian. It looks like Laplacian. It looks like Laplacian, right? It's going to be the boundary map from Taylor plus the adjoint, but properly understood, we have to take a transpose over there. And then we're going to say the invertibility of A detected by a classic. So this is a good stopping point. Thank you very much. Are there any questions? That's roughly the analog Hodges map that defines harmonic forms. Yeah, sure. Exactly. The other one was L Taylor. Yeah, the other is Lawrence Later. Oh, yeah, yeah. Unfortunately, he passed away, Giottellio passed away about five years ago, I think. First of all, may we have access to your slides? Oh, yes, yes, of course. And second. Have people computed the sort of the joint spectrum for the example of like the Fourier? For the example of like the Fourier algebra of a group? Some people have done that, yes. Is it interesting what happens? I believe so, yeah. There is lots of, I mean, we are scratching the surface here, there is so much done in terms of joint spectrum. Yes. And this is not not even completely separate from what uh Ron is going to talk about, because we're going to talk about the projective sector, which is fascinating. Which is fascinating. Do you know who did this work then? I can get you first. Thank you. Do you want access to the slides now or at the end? Now I may be good, so we can. Okay, sure. It's easy enough for me to just grab this PDF of the end. I remember in the 70s and 80s, there were so many people working on this. Yeah. Every math conference innovative here you have at least one conference. I know we do at least one opportunity. I was going to say what you do is do a specific training. And then basically what you do is what you do is well, so each level as a result is there's one different left and two different. But you're only allowed to create things that are classical or triangles with each other and things that are anti-strangeless with each other. And then what you do is you say you graph an integer before the thing. Integer before well the thing is that due to these rules there's kind of this path of all the black circles so you just grab the distance of each being the farthest one down where your orientation starts and that is the only thing you get right but it's but the thing is you don't get whites the home of the integers you get right yeah you really shouldn't Really shouldn't. Right. What you end up with is this sort of conjugation by I haven't quite worked out what it is. But basically, instead of, you know, M minus M, you kind of get in and then compose somehow some type of mutation composed with its sponsor. Right, yeah, I appreciate that. No one's like set one and just put it in the end. Right, yeah, so this way you always have to reflect on the menu down, so it still makes sense. So you divide it, so you basically pull like somewhere and the And so your tree is just lacked out to the right. I think that's probably lined up. So that's what we understand. I mean, I think the answer is roughly the idea is what we're saying. So here you go. And if they have all white circles, then the whole thing. If the top is a white circle. Everything below a white circle is white circles. Yeah, the tangle is very important. Right, and I realize that's the same thing. Right, I realize the measure of the message. This is my pleasure to welcome Ray Jan, who is going to give his first lecture maybe first before the mirror is very much. Okay, so let's get started with the very elementary saves. It's a project that I started in 2009, but later it gets involved with many different Get involved with many different fields of mathematics, many collaborators join the project. So, in a finite-dimensional case, the theory relies on a definition of characteristic polynomial for several matrices. And in the infinite-dimensional case, the definition just generalizes to any alphabets. So, the fundamental part is the finite-dimensional case, and that is why I call it. Case and that is why I called it the linear algebra in several variables. So let's start with the classical one. So suppose you have a k by k matrix and then it's a characteristic polynomial defined by right, and it's plain and simple, and it's an important subject in video. But the natural question is: Can you define a characteristic polynomial for two matrices or more matrices? Now, this question is non-trivial even for two by two matrices. So, how do you define things that can capture two matrices or more at the same time? Now, the definition was done much earlier, and there are connections with works by Connections with works by Dead King and Frobenius, even in the late 19th century. But we actually tried to input this question to AI, to ChatGPT. Yes, yes, yes. So I want to see if the answer is canonical. So let's say, suppose you have two matrices, A and B. What is the definition for characteristic part? The definition for characteristic unknown. And here are the answers. Okay, so first, consider the determinant of AZ minus P. That certainly makes sense, right? I have a very simple question. Did you start recording? Yes. Oh, is it in progress? Very good. Yeah, yeah, yeah. Very good. And is it your answer or chat, GPD? Oh, this is a chat. Oh, this is a chat GPT, but it is not the first time because there are human mixing definitions to that. Well, it can't do a human answer. So this is called the linear password. And then I click and it's answer again. So then he gave me some other options, like things like determinant of z minus a times. Okay? And then third time I give you something like determinant of z minus a plus. And none is very satisfactory because