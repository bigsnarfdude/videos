Okay, so welcome back everyone and it's our pleasure to have our third speaker for the morning is Gekai Zhang from the University of Chalmers and also Goetheberg in Sweden who will tell us all about multiple cities of SU2 representations for quaternionic symmetric pairs. Yes, thank you. Thank you for the invitation to the workshop. So do you hear me well? Yes. So the slide is visible. Slide is visible, yes. Okay, so this is so actually, this will be some very concrete example of branching problems. So I will eventually find some multiplicity of certain representations. It's a finite dimensional representation of k appearing in a representation of g where g is. Where G is a GK is a patternic symmetric pair. And this is based on my joint work with Climate West and Jung Yui. Eventually, I will give you a reference in the end. And here's some outline. So I will start with the precise question and the motivation. And then And then I will present the result the multiplicity computations. And if I have time, I will indicate the idea of the proofs and some applications. And let me read the title, I have a smaller G without like stopping like no, no, let's change notation, right? G0, K0 is like non-compact irreducible quadrionics measure. have irreducible quadrionic symmetric pair. Meaning that K0 is SU2 plus L0. So we with two ideas. One of them is SU2. And then we get a Garden decomposition and then we write the complexification, dropping the sub. Yeah, dropping the sub-index zero. So that's the setup. And let's take like a finite dimensional representation of G, so with highest weight lambda. Eventually, lambda will be paramountized using the fundamental weights and so on. And then gamma m will be. And then gamma m will be the irreducible fine-dimensional representation of SU2, of course. Also, as a representation of a k, so the previous k. Now it's a SL2 plus L complexified. And here's the precise question I will solve. Finally, the multiplicity of this gamma appearing in this V lambda, V lambda. Oh, no, no. Oh, no, no, it's a G and yeah, this multiplicity, this yeah, this is multiplicity this integer. So that's the main question. You take a finite representation, so you have a symmetric pair, SL2 plus L, and you consider you find this multiplicity. So I will give a precise solution to this question. Solution to this question. And here's the exact motivation. The motivation I have been studying this induced representation from Heisenberg parabolic subgroup. So there are two, basically, there are three kinds of induced, yeah, G that one is the Hermitian Hermitian. Hermitian. Yeah, Hermitian actually, we could have a very nice understanding if we take a piece of the Sago parabolic. And another, like the opposite one is the also maximal is the Heisenberg parabolic. So yeah, for this one, yeah, we, of course, we always, if we study the Study the representation using analytical method, and then we have to find the multiplicity and so on. Yeah, and then there's also the quatronic, quationic, yeah, another quationic like G and split G. And then the third kind of you take this complexified. Complexify the G, so now it's a G operating X C and then you complify this P I view that real group. You view that real group, you study this one. So that's my main interest actually. And namely, we study complementary series, minimal representation, appearing, and so on. And so on. So for this first, for this class of induced representation, for the Heisenberg parabolic, what we need actually is this. For this first, for this induced representation, if we study the analytical model, then we have to understand the general. And the general, we need a generalization of the Gardan-Herrigson theorem due to Schillich rule for the Hermitian metric pair. So the bottom line is this. Actually, when you have a G, P, you have a K, you have a K, and the P actually intersects K is more or less like this L. Actually, this is another. Actually, this is another formation pair, but you can take a u1, so it's one extension of your k intersect p, and this is a hermitian symmetric pair. So it's a beautiful theory. So this is a Hermitian symmetric pair. Okay, so then you in principle, we are setting L2 over K over L, but then you can you can consider line bound over. Can consider line bundle over of this conditions matrix space, then that the line bundle the L2 space is decomposed by this Gadnon-Herrickson-Shirich theorem. So that's for that's for this induced representation. However, if we take the complexification, yeah, for this is the first, yeah, the first kind of induced representation. Induced representation, I just explained. And for the if you consider this complexified Lie group as a real group, now the maximal compact subgroup now is a GU. So that's the real form of G. And this, so then more or less we have this, this is the L2 space. Uh, the L2 space where L2 space of this homogeneous space where we have to find the multiplicity and so on. And now this comes this pationic symmetric pair. So you so this U1, you enlarge that, you extend that to a bigger group, say SU2 times L. This is a polyonic symmetric pair, not a pairing. Uh, yeah, appeared in the title. So, this is a compact quadration symmetric space. So, that so for more or less finding uh finding the um you're finding this like L2D competition more or less is like finding the multiplicity of SU2 representation inside G representation. So, that that motivate what So, that motivates what I'm studying. On the other hand, a kind of a side remark is that actually this kind of G say over PC, you may think this GUU1 at least viewed as a flag manifold, which is a G say over PC. This is a very important class of complex homogeneous space of Picard number one. Picard number one refers to the Picard group of. Refer to the pickard group of this complex manifold. And it has a very similar geometrics property like this compact machine symmetric space. So yeah, what I'm saying is all this kind of question that they fit very well in a geometric context. So that's so much about the motivation. The motivation. And now come to the precise statement. So we recall that this will be a complex simple diver. So this will be some quadrationic real form. And this is the symmetric pair, and where K0 is SU2 plus L0. So So for the younger colleagues, maybe I mention the examples. You may take SU2 plus Q. So this is SU2 is one copy of K0 in K0. And then if you consider SO4, then there's the SO4. And for example, for the exhibition one, you have the EC. For the exhibition one, you have the E6 and four. So, this kind of a real form, you have a quantionic symmetric pair. So, that's the T and K I'm studying and the examples. So, we have the data. Here comes the precise data that we. The data that we need. So we take a real Gaddafi subspace inside P0. So we have the complex side US-AWA decomposition. And I need this because I will recall the Costing's theorem. So what we do is we take A here, A here. So we take A here, then we take, if we extend it. Then we take we extend this A to a larger complex subatrib inside G, and we take eta M and yeah, referring to the eta, yeah, this commitment here. And then we have the um yes, when I can see this surprise. Yeah, there we take some sample roots. We take sample roots here for this adding G. So this I call this alpha. Eventually we will have we have we have to take some compact and then I will use delta. So here, all right, so here's eta and there's alpha and then And then we take the fundamental roots and we take the highest way, yeah, the fundamental region number by this one. Eventually, because there's absolute way of numbering, I will eventually fix this. What is alpha one, alpha two? So, but it depends on the root system. So, here comes the precise numbering. Numbering and we have the same data as before. Now we have to take a Cayley transform. We take a Kelly transform. This Kelly transform will be in this Kelly transform will be in K. So namely, since we are in this equal rank setting, so we can take a Kayla transform from mapping T to T to this A. GT2SH and the Kelly transform here. We need all those precise data. So we take the, how it's defined, we take the strongly orthogonal non-compact roots. Okay, so we take strongly orthogonal non-compact roots, namely A roots in G, and we take strongly orthogonal non-compact. And we take solid orthogonal non-compact roots, then we can define the Cayley transform. And here it doesn't matter. I take the beta highest, highest, highest, I take beta the highest root. It doesn't matter. So you may say you start already here, you take the alpha roots, you take beta. Now here comes the precise numbering. So this is in the statement. So, this is in the statement, okay? Finally, I have this statement where I will explain the numbering. And let this be the irreducible representation with highest weight lambda. So lambda parameterized about the elemental weights and so on. So, gamma m is this irreducible representation of this highest weight. So, This beta, the highest weight beta precisely actually make this SL2, this SL2 actually correspond precisely highest to, okay. And yeah, of course, in our usual notation, this is M is like M half beta. And then the multiplicity here, the result is like this, the multiplicity of this. like this the multiplicity of this um uh multiplicity yeah multiple this multiplicity i defined previously is this number so that's the uh that's the um integer part of this uh uh half integer so this uh so this half integer first you have the m has to be even so m has to be even all right so then m is even then m is even and then uh lambda i there's will be uh uh will be lambda yeah paired with of course with alpha one alpha two and so on but here we only have two so then i have to say what is alpha one alpha two so you have a highest highest root and we called beta and then there's a you know there's a sample root connected to minus beta. To minus beta, and then you have another alpha two, which is the sample router connected to alpha one, all right? So, this is the highest one connected to alpha one, alpha two connected to alpha, alpha two connect to alpha one. And then you pair this one, you get alpha one, alpha two, because you only need two, okay? So you only need two, and then you take beta. You take beta, beta, b b i is the minimum of those two integers, lambda one, lambda minus epsilon epsilon i. And here, d is here, lambda is this evaluation. And epsilon i is some parody of this lambda i minus d. Okay, so this is this parity, and that that's the that's the. And that's the result. So the result is that, okay, you gave me a representation, lambda, you find lambda one, lambda two, and then I will find b1, b2, and I get this return. Okay. So that's the result we prove. Yeah, of course, it's part of the statement that this multiplicity is non-zero only when this lambda actually is zero on this eta m and this lambda for alpha we yeah alpha check and that's zero mode too because we that's impressive in the statement so that's the So that's the result. So I started with this rank four cases. Those cases are like rank four exceptional quantities metric pair. So the next one is other cases here. The same result is also proved for the F4 and the G2. And then And then here comes the classical quadronic symmetric pairs. So GK, so this must actually be studied by NAP. NAP had a little bit more general like pairs. But in any case, for this bionic symmetric pairs, that's the result is in MAPS paper. But rather, he formulated that using the certain, there's a certain kind of some. There's a certain kind of something like related to some cases, are related to theta correspondence or something like that. So it's, but in any case, he formulated using Littlewood-Richard coefficient. He didn't have the precise formula, but of course, those Littlewood-Richardson coefficients for smaller rank, you can compute. So that's the classical quaternion symmetric pairs. Yeah, just stop me if you have any questions. No questions here at it. One question, question? No, no, please go ahead. Okay. Thank you. So now so much for the results. The results, and now we already come to the proof, okay? So, I'll spend some time explaining this constant theorem. There's a classical, there's this Adan-Herrickson theorem, somewhat mentioned in the previous lectures. And then, Costent actually found a generalization, which I explained here. We were basically mostly using this Costner. Using use this costing formula. Of course, there are formulas like computing mathematics using this alternating sum and so on, but it's far from being practical. And then the cost and theorem actually remote more complete, a little bit more accessible. And here, what we take the G is tape. Is K, yeah, K plus. Yeah, that's the previous setup. I don't repeat. And here we take a further, we like, yeah, because eta M and this eta M actually is gotten subscribed M. So we have a, we can take this triangular decomposition. And then those are the previous data. So that's the sample root. But now we need those, yes, stronger. But now we need those, yeah, stronger orthogonal. In previously, drank four cases, we have only ranked four of them, and then we have also the Cadet transform, so which is also new for standard work. And then this Cadet transform, we are, of course, mapping alpha to delta. So this delta will be for the compact cutdown. This is for the extended. The extended real split and extended button. And previously, we had this representation of K, which is gamma m, so the m plus one dimensional representation. This is a general. So you take a representation of k is higher with the mu. So this is will be a real, yeah, this is inside k, that's h. This H is inside. Yeah, the real split. And what do you do is you find, so look, this is a, you find this isotypic component of this lambda m. So when you need this lambda restrict to HM, so of course H dominates the weight and so on. So you take this isotopic component. So okay, so you have lambda, you have mu, you have lambda. You have a lambda research with Hm, you have this isotopic component. And what is the critical this space? You take the M plus high speed space of high-speed vectors inside here. So this is mu lambda m plus. And then so you would have to find this the k-power. This the k-part of the root vectors. So, yeah, for those alphas, you have the like real root, you have a real root are some generally not necessarily real root, you have like SO2. So, this is the main, yeah, zeta alpha j, you have to find a k component of the alternative vector. And so the constant. So the Hosten theorem is stated like this. So this multiplicity we were looking for K representation inside G, mu in lambda. It's the dimension, you find all the m highest rate vectors. And then there's some specific polynomials. So this would be polynomial in one variable. In one variable, so for each root or each root, so that you have some specific polynomial. I will not state the, yeah, it's a little bit too technical to state here. So it's some polynomial of this one variable, one variable, the algebra element in k, and you compute, yeah, if this is there, or any alpha i, alpha i in a is not there. In a is not there, but but I have a let's say that I in there's the equal rank case, so let's say this one to simplify that's what I need in any case. So this is some polynomial determined by lambda and alpha. Okay, lambda is here and and then you you you find this space, you compute this space, it's a linear algebra problem and. And so, some historical remark is that, yeah, originally there's this Cardano-Harrison term, but to my knowledge, it's first approved using the analytical method. This is an analytical method, and basically, there's also this generalization by a Shirichi Duku for Hanishi. crew for her nation for her nation one you have a uh yeah you have a k you you are not just interested in a case for representation in g you you you might consider representation of g containing one dimensional k type of k determined by z so that you've got a gadon helics and shirich theorem which is now a consequence of causing theorem and And as well as I know, they are proved. Yeah, the analytic proof is using the Herchandor safe function. Basically, you integrate highest weight and you prove it's non-zero using Herchand save function. And then the Causon theorem is proved. Yeah, he proved that using purely his proof as a consequence of his proof that that's a purely accurate. So that's uh. Purely actually. So that's so. When I was giving a talk in Protestant Lepovsky immediately said, oh, he had also algebra proof shortly after Hagsen's proof. So there's also Leposki's proof. Some of these, yeah. So Causon's ideas more or less, he really paramountized the representation space. So the Polski proof is like a verma model also. So that's about the causing theorem. Now let's try to apply the causing theorem to our setup. And the same thing as before. So now we have data, there's our sample routes respective compact ones. We have the highest route determined by determining this SO. Determining this SO2 inside K, we have the Kelly transform and so on. And then here the real issue becomes like how would we compute this projection, our kind of projections? And you would, because we are trying to find the SL2 beta representative, we would have to find this projection actually, this component in this component. Component in this component because the K is so each route, not necessarily each route will like cross or in the K part where crossing all part, not necessarily in one SL2 beta, it will be crossing. So you will have to find projection and then we would have to solve this equation. So this solve this equation. Solve this equation. Because those polynomials, those rules, those projections, they are not commuting. Even inside SO2, technically, it's not a trivial problem. So for this first part, basically, we do the SO44 computation. So roughly. So, roughly speaking, all the like let's say the exceptional quadrant symmetric pair, basically it's more like SL44. As far as we, the R problem is concerned, you do the SL44. And if we do SL44, sometimes we could also go G2. So that's the computation we did. And let me explain. And let me explain for the second part. So, how do we solve this equation? This is a linear algebra problem. So, let's see. So, yeah, so this is the SL2 beta triples that we, yeah, let's say realize, realizing like this. And after we, you need another X prime, so it's like a conjugate. prime so it's like a conjugated h prime so the polynomial that appear appeared in in causing theorem will become something like this okay so that's polynomial uh this b actually is that b that uh yeah somewhat related to this b1 b2 in my statement so that's a q q of b that's a polynomial so what you what you do is that you you consider some representation space of gamma 2d So, this is this space, and you consider the current this you could join the kernel, the dimension of this. And so it's certainly this kind of computation, some relevant it's appeared also in in in the Also, in the process, they study Markov process and so on. So, what I'm saying is that that's classically, it's also interesting question. In any case, so our theorem eventually will reduce more or less like this proposition, saying that we can compute this kernel. We can compute this kernel dimensions like this. It's like this. And so the idea, this is some rough idea. Ideas that we consider, we use some AB and as a conjugation of E and F. Then this is one idea because you would have to compare this H and H prime. And then another idea is we write this polynomial Q using an. Because once you have H and another, you have H prime, H prime is E of F, it's a polynomial using non-commutative like attribute. At least you can control the dimension that's bigger than this one, smaller than one. And then we do some induction. So that's the that's the The so now some application of coming back to this induced representation. Yeah, so this question motivated from induced representation which I explained. Which I explained roughly. And here comes this induced. Maybe better I take a precise statement. So, for this one, okay, for this one, I can find all the k-types. Types. For this one, we need this Garden Hex initiation crew. And for this one, I find all the K types. So it will be bigger, because this will be quadratic. So that will be that will be quadratic. Yeah, that's what I. Yeah, that's what I mean. So, this, yeah, yeah, of course, the whole process is more or less standard. So, you have this. This is a space we want. We take a kind of fibration and with this T1 orionic symmetric pair with this fiber. And then we eventually find this one. And that result is this induced representation, indeed, that's all I could find. So I could find all the K types and all the multiplicity so you can listen to our presentation. Yeah, if you are interested, there's this archive. And I think I stop here and thank you all. Thank you. Are there any questions where I see it? questions for our speaker. So the result that you're describing, it feels like it should be really, really classical. Are the formulas that you're getting much simpler than what we would have gotten out of those costly type formulas? One more time. Sorry. So it seems that the results you're calculating seem so classical, but your formulas are so short. Your formulas are so short and elegant. Is that where the gist was to produce these brief formulas? Because I see such a music. Yes, so yeah, there might be because you usually this kind of the point is that usually this kind of data group riches and coefficients and so on for expression one are not very well developed, I think. Developed, I think. Yeah, so for this classical cases, I'm sure that we can find those formulas using later with Richardson coefficient. But for the exceptional ones, they are not very well available in a way. Thank you. Thank you, Martha. Are there any more questions, including online? Oh, I see a question in the room. So just I have a question. So I guess I have a question. The polynomial QB that you get is just in terms of one variable X? I didn't know what did you say? The polynomial QB that you get is just in terms of one variable. Is the polynomial QB that you get just in terms of one variable? Yes, for each root, basically for each root, you have a polynomial. For each root, you have a polynomial. Yeah, for each root alpha, you have a polynomial, and that polynomial depends on our depends on lambda. Okay, okay. So if you have a say like if you have a four simple roots, say, then you have four polynomials. And yeah, the polynomial depend on the alpha and depend on the there's some. Can depend on there's some pairing between lambda and alpha.