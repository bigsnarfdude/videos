Are are you sharing the screen you are looks like? Yeah, something showing up. Yes, something showing up. Okay, it looks like I'm connected now. Is this visible to everyone? Yes. Great, thank you. So first of all, thank you to all of the organizers for the invitation to speak. I would have loved to be there in person this week, but several things prevented that from happening. So today I'll So, today I'll talk about the question of classifying global solutions to a class of equations related to the minimal surface equation, which arise in several models in applied mathematics as well, which hopefully is enough connection to the of the conference to be of interest to you. And much of what I'll talk about today is joint work with my student Yang at UC Irvine. So, to start, let me just set up the question. So, to start, let me just set up the question we'll be investigating. So, we'll be interested in, say, hypersurfaces in Rn plus one. Sigma is an oriented hypersurface. So it has at each point some unit normal, nu. And we'll be interested in functionals, which are generalizations of the area function. generalizations of the area functional. So we have a sub phi of sigma given by the integral over sigma of the area element, but weighed by some function of the unit normal. And this function phi is assumed to be one homogeneous and smooth away from And smooth away from the origin with uniformly convex level sets. But it's a bit more geometrically natural to write phi as a support function of a smooth convex set. Support function of a set which might look something like this. Say k containing the origin. K is smooth and uniformly convex. Within uniformly convex. And k is sometimes known as the Wolf crystal associated to the functional. And the geometric significance is that K is the solution of the isoparametric problem associated to A sub phi. Namely, if you minimize A sub phi subject to a volume constraint, then the shape that you will get is precisely the convex. Get is precisely the convex set k. Another way of saying this is that k is the gradient image of the one-homogeneous function phi. And the question that we'll be discussing is the following, is that if sigma is a critical point of a sub phi And also, sigma can be written as the graph of a function over all of Rn. Graph of a function. So u from Rn to R. Then can one conclude that sigma is flat? Was it true that sigma is a hyperplane? Sigma is a hyperplane. Okay, so in terms of PDEs, I'll write to count a couple of PDEs. So in the case that phi is the unit sphere, or the k is the unit sphere, then this is simply the area functional. And what you're studying is global solutions to the minimal surface equation. So if the case that So, if the case that phi of is just absolute value p, or k is equal to sn equivalently, looking at global solutions to equations of the four, so to the equation divergence of gradient t over one plus gradient squared is equal to zero. Or more generally, you're looking at global solutions to equations of the form. Solutions to equations of the form divergence of gradient of a function psi of gradient uij is equal to zero, where psi is the restriction of the integrand phi to a hyperplane. Say psi of x equals phi of minus x Where x is a non. So you're interested in understanding global solutions to this quasi-linear elliptic PDE. The reason it's elliptic is because the function phi is convex. So these coefficients form a positive matrix. And furthermore, as the gradient gets very large, the epicity coefficient. The ellipticity coefficients degenerate. The ellipticity ratio goes to zero as the gradient of u goes to infinity. So I think even asking the question of whether global solutions to equations of this type necessarily linear is kind of remarkable to begin with, because one could view this as sort of a geometric version of the Laplace equation. And we know that there are many, many global solutions to the harmonic, you know, global harmonic functions. For example, eta. Functions, for example, e to the e to the z, they can have extremely fast growth. The fact that one can say the non-trivial results about linearity of global solutions to equations of this type with no growth hypotheses is kind of remarkable. And to begin with, let me just discuss the history of the problem. So, first, I'll talk about what happens in the case of the area functional. So it turns out the answer to this question, known as the Bernstein problem, is yes. The global solutions to the minimal surface equation are linear if and only if the dimension n is less than or equal to 7. So it's sort of a funny answer. Why 7? Why do things change all of a sudden? And the contributions were due first to Bernstein. Contributions were due first to Bernstein in 1915. He proved this in the case of two variables. And his proof heavily used two-dimensional techniques. So he used the fact that the unit normal to a minimal surface, which is two-dimensional, is a conformal map into the sphere. That's a consequence of the fact that the principal curvatures of a minimal surface of two variables or a two-dimensional minimal surface have the same size and opposite sign. We use that fact and we use some 2D topology. And because the proof heavily used two-dimensional techniques, it was a difficult problem to extend. A difficult problem to extend his result to higher dimensions. The next big contribution came from Fleming quite a while later in 1962. He gave a new proof in dimension n is equal to two, or two-dimensional minimal surfaces in R3. And his proof was based on the so-called monotonicity formula, which says that minimal surfaces That minimal surfaces have a conical structure at small or large scales. And more precisely, showed that if there exist nonlinear global solutions to the minimal surface equation, then there has to be a non-flat area minimizing cone in that same dimension. See, there exists a non-flat. You already minimized. You're already minimizing cone. I'll call it, give it a name, say C in Rn plus one. And in particular, if you look at cones which are surfaces in R3, they have only one non-zero principal curvature. So the only way they can be minimal is if they're flat. Okay, and so Fleming reduced the problem to the study of area minimizing cones. Of area minimizing cones. And from there, the problem fell relatively quickly. So DiGiorgi in 1964 gained one dimension. And he used the graphicality of the problem to say that this cone C has a special structure. It's a cylinder over an area minimizing cone in one dimension lower. Georgie showed that C has to be. Georgie showed that C has to be some area minimizing cone in Rn cross R. And as a result, gained one dimension. And then people initiated the study of area minimizing cones using the stability inequality. So Almgren in 1966 in Simons in 1968. In 1968, they proved that stable minimal cones are flat in low dimensions. And Olmgren proved this for Cohn's in dimension 4 and Simons up to dimension 7. And finally, one year later, Bombieri DiGiorgi and Giusti constructed. Lambieri DiGiorgi and Giusti constructed a counterexample in dimension eight. They constructed a nonlinear global solution of the minimal surface equation. And I'll discuss more what they And I'll discuss more what they did in a couple of minutes. So, that completed the proof, the solution of the Bernstein problem for the area functional. But I think a natural question from the point of view of PDEs and applications more generally is whether or not this result holds for the more general class of functionals that I talked about in the very beginning. So, is the iso, is the So, is the isotropy of the problem so important to get this Bernstein-type theorem up to dimension seven or not? And the main tool that is lost in the general case is the monotonicity formula. So it would be quite interesting what we're able to obtain classification results for global solutions and more general and related PDEs that don't rely on the monotonicity formula. So, what was known in the more general case, following? So, first of all, global solutions to this general class of PDEs are linear in dimension n is equal to 2. This was proven by Jenkins in 1962. And again, the approach of Jenkins heavily used two-dimensionality. Kevil used two-dimensionality. He used the fact that the unit normal to the graph of a solution to this equation of minimal surface type is no longer conformal, but it's quasi-conformal. And there was a well-developed theory at the time of bounded quasi-conformal maps that have to be constants. So that's fine. There's this result for. So that's fine. There's this result for global solutions to these equations in two variables, but two variables, oftentimes there are stronger results in 2D. So this is maybe not so surprising. And something that is surprising is that global solutions are also linear in three variables. This is due to Leon Simon. And the proof of this result was much more sufficient. Of this result was much more sophisticated. So I'll just write in the interest of saving some time. But this is difficult. And it relied on a regularity theorem of Almgren, Shane, and Simon for minimizers of the parametric problem. Okay, so once you see that global solutions to these equations are linear in three variables, you get some hope. You say, okay, maybe it's true up to at least, you know, maybe not dimension seven, but up to a pretty high. Maybe not dimension seven, but up to a pretty high dimension. And the question is: how high can you go? So, a couple years ago, I constructed a counterexample in six dimensions. And so, this counterexample, I'll discuss it more in a few minutes, but it says that indeed the isotropy of the problem. Indeed, the isotropy of the problem really did help you for the minimal surface equation to get a Bernstein-type result up to dimension seven. You get non-trivial global solutions for the general problem in lower dimensions than before. And the idea of the construction and the general case in six variables was completely different from what Bombieri, DiGiorgi, and Giusti did, as we'll see. And finally, in joint work with the Fed. In joint work with Yang, we constructed a counterexample in the minimal possible dimension in which one could exist, and is equal to four. And the techniques that we used really return to the more classical techniques of Bongieri DiGiorgi and Giusti to construct this example. In the remaining part of the talk, I'd just like to talk about what. Like to talk about what Bombieri de Giorgi Giustia did, the 6D example, and the 4D example. And since this concludes the introductory part, I'd like to just pause to see if people have any questions. All right, it seems not so. Let me talk about the Bombay de Georgian Giusti example. Just the example. Okay, so unsurprisingly, the Bombay de Georgia Gusti example, the starting point was the existence of an area minimizing hypercone in eight dimensions. You need one of those things to exist, to have the existence of a nonlinear global solution to the minimal surface equation. Their starting point. Point was to construct an area minimizing cone in R8. So, in this picture here, we have two copies of R4, a horizontal four variables and vertical four variables, coordinates x and y. And the simplest cone with zero mean curvature, which is non-flat that you can think of constructing, is the symmetric cone epsilon x equals epsilon value y, known as the Simons cone. Known as the Simons cone. And the reason it has zero mean curvature away from the origin is because of the symmetry. It looks the same from each side of the cone. And what Bumbiri, Giorgi, and Giusti did was they performed a careful analysis of a nonlinear ODE to construct an area, say a minimal hypersurface, which is like a desingularization of the Simons cone. So it approaches the Simons cone from one side and lies on one side. cone from one side and lies on one side. And all the dilations of this hypersurface form a foliation of each side of the cone by minimal surfaces. Minimal surfaces. And as a general principle in a variational problem, if you manage to foliate each side of a Foliate each side of a solution to the problem by other solutions, then this may all be minimizers. One quick remark is that if you try this in lower dimensions, if you replace this R4 by R3, for example, then if you try to solve the ODE, which will give you a minimal hypersurface, what you'll get is a surface which crosses, begins to oscillate around the cone. So its dilations will no longer be a foliation. Longer be a foliation. So, R8 is the first magic dimension in which these surfaces lie on one side of the cone. And one important feature of these, analytic feature, is their approach rate to the cone. So, if you move out a certain distance along the cone, say distance r, and the distance between a leaf and the foliation and the cone. Between a leaf and the foliation and the cone decays at the rate r to the minus two. And this minus two, where it comes from, is it comes from the eigenvalues of the Jacobi operator. So if you perturb a little bit away from a minimal surface and you have a new minimal surface, then deleting order, the difference between the two is a solution of the Jacobi equation. And its eigenvalues will predict this approach rate. This approach, right? But the reason that's important is that to construct a non-linear solution to the minimal surface equation, their idea was to build a function whose level sets resemble those of, they resemble the leaves in the nation. And what will such a function look like? Well, they build a function which is going to be zero on the cone, say one on one of the leaves in this foliation. And so this function, it'll go from zero to one. This function will go from zero to one over a distance roughly r to the minus two if you're a distance r from the origin. So the gradient growth should be quadratic as you go to infinity. And so it's natural to look for a function whose growth is cubic. So the derivative will have quadratic gradient growth. And this was their starting point. And from there, it's a little bit of guesswork. So they first show that if you look at the function, so pretend this is a 2D picture, let little r be the distance. Let little r be the distance from origin. If you could r cubed cosine of 2 theta this function, use sub bar. Your little r is distance from origin. Tangent theta is y over x. Then it happens that this function here has level sets that close to resemble those of the leaves and the foliation, and this function. The leaves in the foliation, and this function is in fact a sub-solution of the minimal surface equation where it's positive and a super solution where it's negative. Otherwise, and that's a relatively short calculation, and the really hard. And the really hard part for them was to construct an accompanying function which has the same asymptotic behavior, but which is a supersolution in the region where the other is a sub-solution and vice versa. So they basically introduced a bunch of parameters, and it's not easy to see how they all interact. You basically start off with something similar, cubed cosine of 2 theta. You multiply by 1 plus a certain constant cosine to the lambda of 2 theta. To the lambda of two theta, you add r squared, cosine of two theta, and you compose all of that with a certain one variable function. And it's not at all clear. It just looks like complete magic how all these things are chosen to make everything work. So if you choose this one variable function h, and these parameters a and lambda carefully. Then, this function, which I'll call you superbar, is going to be a super solution of the minimal surface equation in the set. Sorry, this should have been x bigger than y, vice versa, x bigger than y. Subsolution otherwise. And from there, the proof proceeded by the maximum principle. So the picture is: here's the Simons cone down here. I have this function u sub bar, which is a subsolution in the region where it's positive. Super bar is going to lie above the other one. It'll be a super solution where it's positive. And the idea is then to. And the idea is then to do an exhaustion argument. So you solve the minimal surface equation in a ball of radius r with boundary data given by one of these guys, for example, sub-bar. And when you solve it, you can use the maximum principle to trap the solution in between the two. So solve the Dirichlet problem for the minimal surface equation in the ball of radius r, with the boundary data. Given by the sum of super solution and take R to infinity. So I won't say anything more about this. I'll just say in words, the maximum principle is what guarantees that the solution that you get in the limit is in fact bounded between the super and subsolution that you constructed, and therefore it has cubic growth at infinity. Okay. Okay. And there's a lot of very deep elliptic PDE which goes into this result, which I haven't talked about. Namely, in order to get a solution in the limit, you also have to get some interior estimates for the solution. Use an interior gradient estimate of Bombieri, DiGiorgi, and Miranda, which guarantees that the limit actually exists and is smooth. And that interior gradient estimate is itself a cornerstone in the theory of elliptic PDEs, so it's quite a challenging result. Challenging result. Okay, so now let me change directions and talk about the 60 example in the more general case. And the philosophy here is completely different. So, our goal, again, is to solve an equation of the following form: psi ij of gradients u, uij is equal to zero. J is equal to zero in Rn. So let's say I want to solve an equation of this form. But now we have two unknowns, both the solution that we want to find and the integrand, which we haven't chosen yet. So the goal is to find an integrand with the correct convexity property such that there exists a nonlinear global solution. And when you're given that freedom to choose the integrand, And when you're given that freedom to choose the integrant, or choose the functional itself, the idea is to instead start with the guess for the solution and then build the integrand. So you go backwards. So what we'd like to do is to start with the guess for u and build the function psi. And a convenient trick for doing that is to use a Legendre transform. And the reason is that that turns this into a linear equation. So if you look at the Legendre transform of u, So, if you look at the Legendre transform of u, then the second derivatives of Legendre transform are the inverse of those of u itself. Those are evaluated at creating Q. So, if you fix the solution u, what this becomes is it becomes a linear equation for psi, and any good guess. And any good guess for a solution will have positive and negative Hessian eigenvalues because this is some positive sum of Hessian eigenvalues of u that needs to be zero. So there needs to be positive and negative Hessian eigenvalues. So this will be a hyperbolic equation for psi. So the philosophy in this example is much more likely to be a very simple thing Philosophy in this example is much different. So you fix a guess for a solution, and then you can try to build all functionals for which this guess is a critical point. And you just hope that one such functional satisfies the convexity conditions that are required. That's the hard part. And where does the 6D magic come in? So if we take u to be a simple quadratic polynomial in R6, x squared minus y squared, where x and y are in R3. And we assume that psi has the same symmetries as u under rotations in x and y. Then after some simple change of variable, This equation here becomes just a 2D wave equation for psi, the exact 2D wave equation. And the reason is that is so advantageous is that you have an explicit representation formula for solutions. So if you impose the appropriate Cauchy data, you can write down exactly what psi is. And by choosing that Cauchy data, And by choosing that Cauchy data carefully, you can guarantee that this function psi satisfies the right convexity conditions. Oops, I satisfies the right complexity conditions. Okay, so that's just the structure of the R1. Choosing that Cauchy data carefully is a tricky problem in and of itself, but at least it's fairly concrete because you're just dealing with this D'Alembert formula for solutions of the wave equation. Okay, so before I go on, let me just quickly remark: geometrically, what does this integrum look like? So if you look at the set where psy So if you look at the set where psi is less than a large constant, what it looks like is the following. Here's a copy of R3, here's a copy of R3. The set is going to be a convex set, but it's not going to be very round. It looks more like a box. And the reason that this is geometrically or variationally natural is that. Natural is that the solution, the x squared minus y squared, u, if you look at the graph of u and you look at the unit normals, overwhelmingly they point in diagonal directions. And so you would hope that the functional that you choose grows more slowly in diagonal directions than it does in coordinate directions. You get a smaller energy. And that is indeed what happens in this picture here. You take a longer distance to go. A longer distance to go to a certain height in diagonal directions than you do in coordinate directions. So the functional you get agrees with your intuition. Okay, and now finally, let me go to the 4D example. And just to gauge how much to say, do you mind if I ask how much time I have remaining? Have remaining? Yeah, it's nine minutes approximately. Perfect, thank you. So we'll just spend a short time outlining the steps of the construction here, which are much more inspired by what Bombieri, DiGiorgi, and Giusti did. So I should remark before going on, you could ask, why doesn't the 6D approach work in 4T? Well, it's not completely obvious. There's an analytic answer if you look at the corresponding function x squared minus y squared, where x and y are two variables. y squared, where x and y are two variables, then you can show that this function does not solve any equation of minimal service type. You try to build the functional, you can guarantee that some of the second derivatives of the function psi are going to go to infinity by solving an ODE problem. So it simply won't work. So you have to try something different at 4D. And what happened to work was something more classical. Let me just say what the four steps are. So first of all, Steps are. So, first of all, we begin by looking at the Simons cone in R2 cross R2. And we construct a functional and a foliation of each side by minimizers, a la Bambieri, Georgian, Giusti. So, one will just say foliation by minimizers. Of some elliptic functional ape psi bar. Apsi bar is an integrand on r4. And the key analytic feature is that the leaves in the foliation, as you go a distance r out, are roughly a distance r to the minus mu from the cone, where Î¼ can in fact be anything you like between. Be anything you like between zero and one half. You give you give me any number between zero and one half, you can pick a functional such that deleves in the foliation approach at that rate, or to the minus mean. Okay, so what does this tell you? This tells you that once you fixed one of these functionals psi bar and the corresponding parameter mu, you want to look for function. You want to look for functions which have level sets that look like this. So, roughly, these functions will be homogeneous of degree one plus mu. But instead of just guessing, the idea is to proceed in a more systematic fashion. What we do is we, so this is nonlinear ODE, this first step. What we do is we linearize around one of the leaves and make a small perturbation so that the And make a small perturbation so that the corresponding anisotropic mean curvature points towards or away from the cone. So you get super sub solutions. So your perturb leaves. This is linear OD. So let me just quickly draw a picture. You have a perturbation of the original leaf. We'll call it significant. Of the original leaf. We'll call it sigma sub bar. And this is no longer going to be a minimizer of the corresponding functional, but it'll be a sub or super solution. So the mean curvature of this one, or the anisotropic version of mean curvature, will point towards the cone. And then you just perturb a leaf in the opposite direction. A leaf in the opposite direction to get a turblea sigma bar, which has the same asymptotic behavior, but the antisymotropic mean curvature will point away from the cone. I would say this is where we clarify what happens in the Bombay de Georgia juice D example. We start off with the minimal leaves, and then we explicitly perturb them so that their mean curvature vectors point. So that their mean curvature vectors point towards or away from the cone. And then we just pick functions which are exactly homogeneous of degree one plus mu and are one on one of these perturbed leaves. mu1 plus mu and equal to one on sigma sub bar. Sigma sub bar and sigma super bar zero on cone. Okay, so these are going to be our candidates for super and sub solutions of the equation we eventually wish to solve. But we haven't chosen them in a sort of random way. We've perturbed the leaves very precisely and then chosen them based on that perturbation. Perturbation. And the third step, we need to actually pick the equation we eventually want to solve. So fix the integrand phi. And the way we do this, we'll just say very roughly. So the integrand phi is going to be a one-homogeneous function on R5. Because of the homogeneous Because the homogeneity is determined by its values on a hyperplane. We'll pick this function psi. This function psi is going to be related to the functional that we started with up here. So, this guy here, this is a one-homogeneous function in R4. It has a singularity at the origin, which It has a singularity at the origin which we need to remove. And the way we do this is from the we take square root of one plus side bar squared. Just to be a little bit clear here, the function psi bar, what it looks like is something like this. If you have a, if you're looking for a one-homogeneous If you have a looking for a one-homogeneous function on R5, which is smooth outside the origin, then restricting it to a plane tangent of the sphere, you won't get something that has a singularity. It should be smooth. The function psi is going to be sort of a desingularization of psi bar. And for this choice, phi will have all the right convexity properties. And then you can check for this choice the functions w sub bar w super bar that you chose. They almost are super sub solutions to the equation you want to solve. So, for example, the equation solved by the perspective subsolution. The perspective subsolution. So you'd like this to be positive everywhere on one side of the cone. It happens to be positive on most of one side of the cone, except for a region that separates sublinearly from the cone. So everything is good in most of one side of the cone, but you experience some problems right nearby the cone. And the reason this is a subsolution in this large region is purely by virtue. This large region is purely by virtue of the curvature of the level sets. And the point is that you have one more degree of freedom. So if you're looking at the curvature of the graph of W sub bar, there's a vertical one as well, not just the level sets. And so by sort of restacking the level sets appropriately, you can take advantage of that extra degree of freedom and get an upwards vertical curvature to take care of what happens near the cone. And this is the last step. And this is the last step. So, this is what I call restacking the level sets. So, instead of going into details, let me just say that for this function w subbar, what you want to do is you want to pick a function which takes the level sets near the cone, but makes the function curve upwards a little bit more than before, so it behaves more like a subsolution. You'll have more positive second derivatives. Derivatives. So, for example, you take a function which looks like this, bigger than zero and has linear growth at infinity. And you look at this function h sub bar of w sub bar for an appropriate choice, which is sort of clear how to make once you do the calculations. Then this guy will be a subsolution. Of the equation you want to solve everywhere on the side of the cone in a super solution. Otherwise, and you can do something similar for the perspective super solution. And from this stage, you can argue as in Bombay, Diji, and Giusti's example. Okay. So you can see that you have some freedom in the choice of this parameter mu at the very beginning. That determines the growth rate of these functions. And so by choosing your functional correctly, you can get nonlinear global solutions with a pretty big variety of growth rates in R4, anywhere from basically one homogeneous to three halves homogeneous. Basically, one homogeneous to three halves homogeneous, or at least, morally speaking. Okay, and let me just say a couple remarks. Using this technique, which is a bit more systematic, you can also recover the Bombieri de Georgi and Giusti example in all high dimensions. However, one might be interested in finding that using this sort of technique to build solutions which are not asymptotic to these cones in even dimensions, but maybe odd dimensions. In even dimensions, but maybe odd dimensions. Maybe you want to find one in R5 so that the graph is asymptotic to one of these cones over S1 cross S2. And the problem is that hidden in this argument is a symmetry of solutions to the Dierschlet problem, which you do not have for these cones in odd dimensions. So I don't know how to do that, for example, in five dimensions. For example, if you just extend this 4D example trivially in a variable, you get a 5D. example trivially in a variable you get a 5d example but you might want more exotic examples and I'm not sure how to do it but with that I'll end the talk and invite any questions questions yes Philip hi this is Philip um so just a question maybe maybe you said it for the interview significant example sorry Sorry. Sorry, can you hear me? Now I can hear you. Okay, so I was just wondering. So you said if you extend your example in five dimensions, trivially, somehow, you get a counterexample, right? So you get one, but you said you wanted more exotic ones. It's good to have one, right? Right. Yes, so for example, in five-dimensional In five dimensions, you have cones which minimize elliptic functionals. So, for example, if this is R2 and R3, then this cone, absolute value of x equals absolute value y, you can prove that it minimizes an elliptic functional in R5. And you would like to prove that there exists a nonlinear global solution to an equation of minimal. Linear global solution to an equation of minimal surface type, which is asymptotic to the cylinder over this cone. And that is what I do not know how to do. So if you just trivially extend the 4D example to be constant in the remaining direction, then it's still basically asymptotic to the Simons-Conan R4 cross R. Yeah. Okay. There are no other questions. Let's take colour again. I'll let people export the morning session. Thank you.