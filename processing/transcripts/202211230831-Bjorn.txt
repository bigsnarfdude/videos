In Rn and for simplicity, let's take n greater than or equal to three, so I don't have to worry about the kernel. And if you have a measure, then you can take the convolution with the Newtonian kernel, and you get a function called the potential for this measure. And this function is known to be harmonic of the support of the measure, so everywhere else it will be nice and harmonic. And harmonic can be reformulated and uh equivalently using It in equivalently using local minimization of its energy, as everybody knows. So I'm not going to dig into that anymore, so just keep in mind it's harmonic outside of the support. On the whole space, it is superharmonic. There are apparently two types of mathematicians, those who study superharmonic functions and those who study subharmonic functions. So I'm just recalling here that superharmonic functions that minus here is subharmonic. And that also means that the minus or plus of the function is a non-negative measure, and it's actually this very measure that comes from the convulsion. This function, the superharmonic function, is in general a little too big to make sense for these integrals, but if it's bounded or somehow otherwise controlled, then this. And this minimization property will hold not for all functions V but for the ones that are larger than U. So maybe I could draw a picture for this minimization property even though I suspect that everybody is familiar with that but it will be appearing again in the metric spaces and for the pi harmonic function. So here you have our You have Rn, and then say this is this function u that we have there, and this measure would be then somewhat supported here. And then of the support of the measure, if you take a set G here, that we like, and you perturb the function by something, let's pretend this is a function. Function, then the energy of the red perturbation will be simply larger than the function itself. And for the superharmonicity, the same should be true, but you have an extra restriction that the function that you have a true base must be, and you can do it actually, even for G, that includes the support. And you do the same thing. Of course, if I would go here, I get small. Of course, if I would go here, I get smaller energy, but by only allowing functions to be that far above, you then still the perturbation will have to have a large. So that's a picture that you might try to think of concerning the harmonic and the superharmonic function that I got soon. We have to talk about it. No? I guess maybe. No, I'm not quite enough. And another property that superharmonic functions. Another property that superharmonic functions have is in general they are not continuous, the harmonic ones are, of course, but superharmonic functions are lower semi-continuous, but they actually finely continuous in the fine topology. And I will come hopefully back to fine topology a little bit more, but just roughly speaking, think of that the set where the function values differ by more than something. differ by more than something is thin at the point x. So for continuity as you approach x you should have a limit at that point and here you approach but you can actually have a thin region where you approach back so you have them but otherwise you approach and in that that's the fine continuity you can think of it. And another notion that I will also be discussing and Notion that I will also be discussing, and that's related to a potential like this, is the capacity. If you have a compact set, then the capacity, Newtonian capacity related to this kernel of that set can be calculated in various ways, but one of the ways is to consider all measures that are supported on that set. You take the potentials of this that are less than or equal to one, so consider all of those and take. So we consider all of those and take supremum of those bases. So we basically charge the set as much as we can to get still potential and most of the. And that gives you the capacity. So all these three notions I hope I'll be able to discuss in this talk in the set of metric spaces. Before that, let me recall that the nonlinear theory as well. I was talking about harmonic functions, but since about seventies or even earlier, 70s, or even earlier, one has been studying p-harmonic functions, and those are just non-linear generalizations of the Laplace equation. So we take divergence of this power of the gradient times the gradient that should be equal to zero called P Laplacian. If P is equal to two, you get back just the Laplacian and standard harmonic function. And analogously to before, these Obviously, to be four, these are local minimizers of this energy. So rather than having our two here in the energy, you have power. These equations are in general non-linear, so they are a lot more difficult to study than say Laplace equation. Also, you have a fundamental solution, which would be the solution to the Dirac in the right-hand side for this P-Laplace equation, and it's a suitable power of the A suitable power of this distance. So, again, this maybe reminds you of the Newtonian kernel I had on the first slide. So, this is one generalization in the non-linear direction. But then, of course, you can think of a lot of other generalizations. Instead of having this Lebesgue measure, you can take a weight. Then, people have been studying manifolds. If you take Romo-Hausdorff limits of those manifolds, you're The limits of the manifolds converging to non-smooth spaces. One can wonder what happens there. These functions have been studied on manifolds. Also in subriuminal geometry, they have been studied. And also on graphs, there's a possibility to define harmonic and pi-harmonic functions on graphs. And all of these have one thing in common. They are matrix persistent, we know, right? So let's have a look at At the metric space theory for these guys. So, this is a metric on a metric space X. We've already seen this many times, so I can look it quite quickly. I hope mu will be a regular measure. Balls should have positive and finite measure, all of them. And the definition of upper and p vic upper gradient we have also seen several times. Also, seen several times. So, a function g will be an upper gradient. If all on all curves, you can control the function values difference by the curve integral of G. If you only do this on P almost all curves, then you get the P weak upper gradient, which in descriptions today. The p uh of p almost all curves is in the sense of the p modulus that I think was defined yesterday. Models that I think was defined yesterday in some talk. But don't worry about it too much. Just think of that, there is a notion of a P-big upper gradient. And if you have one upper gradient in LP, then that is the minimal P-bar gradient. Denoted G, also I'll be denoted this way. It's minimal in LP and it's minimal point-wise for most of the other one, I guess. Okay, and just to relate this to the mentions from RNL, this minimal TV couple gradient is of course modulus of the standard gradient, so we can include the RNG. So I guess this is known to basically everybody in this room. So maybe I can go on. So then having this type of gradient, you can define Newtonian space. Newtonian spaces, Sobolev-type spaces. That's what's been done by Nagas. And the nice thing about this is that you can do this on any metric space. So in particular, if you have a subset of the metric space, you can easily define Sobolef type spaces, Newtonian spaces, and that's. You just need measurability for that. That's an easy, cheap way of defining Sobolev spaces on subsets. Chiger gave an equivalent definition that was yesterday. An equivalent definition that was yesterday also discussed in a talk by Simone. So that one is the one given by approximation by Lipschitz functions and they are equivalent to greater than one. Okay, so now we can define the harmonic functions. So let's take to start with an open set in our metric space and we And we say that the function is function u is p harmonic in this set for p greater than 1 and finite if it locally minimizes the p energy, as we had on the first slide. So the picture here, this would be now my omega. If I have my gradient for the u, that's its energy here, then I perturb it by some legit function with compact subpoena. Some legit function with compact subport. In omega, that would be this red perturbation, and then the energy should go up, or at least not get small. So that's the definition of p-harmonic functions. And this, of course, makes sense in, well, we can do this in many metric space because we can define the so-f space, we have the gradient, and then we get open sets and things. So this makes sense very generally, but as you Generally, but as you also know, if the space has very few rectifiable curves, or if you put on a bad measure, then this gradient will become identical with zero. And then the Newtonian of Sobole space is the same as Lp. Here you have just zeros for the gradient, and you do not get anything. So that's not very interesting situation. So to avoid such So to avoid such a situation, we put on some reasonable assumptions to get a reasonable theory. This. And these have also been, I mean, it's so good, everybody has already introduced these notions before me. So these assumptions have also been already discussed. The measure we have on the space should be doubling. So if you blow up the ball twice, Blah, blah, blah, ball twice, you should still control the measure. And then the P Poincaré inequality, I will be make it for short by Pi. And it says that for any ball and any set any function u, the mean value of the function u, the mean value oscillation. So u b is the mean value, and then you look at the oscillation. At the oscillation in the average sense on that ball, and it should be controlled by the diameter of the ball times this averaged P norm of the gradient on a slightly larger ball. We allow that. It's a bigger ball. It controls this oscillation. So this is also, I guess, familiar to most people. And then usually it's convenient to have X complete. To have X complete. So these are the standard assumptions. Sometimes you say instead some local versions instead of them as a relaxation of the assumptions. Under these three assumptions, Chiger also showed that there is a differentiable structure, so rather than just working with the s scalar gradient, and there is actually a way of defining a vector value differential. vector variable differential view and then one can actually write down and study a P-Laplace equation, Shiger P-Laplace equation, in the same sense as in Rn. This is the power of the Shiger differential or a kinematic divergence of that. And this can be done in the weak sense of by integral identities. And so that becomes really relatively close to the Rn situation. To the RN situation, and you can prove more things in this setting. At the same time, the chig gradient is a little bit more abstract, you cannot so easily get hold of it. Whereas the upper gradient, it's just very geometrically clear what it means. And one can actually do quite a lot for the p-harmonic functions, even working with Even working with this definition, with the upper gradient. Anything that can be done for p-harmonic functions defined using the upper gradient can also be done for the cheaper ones. But here you may have a little bit more to see. I will be mainly concentrating on the ones given by this minimization property using the upper gradients. So let's see. Okay, so to give you some examples that I guess are familiar to most people here as well, but maybe not everybody is used to magic spaces. Well, in this audience, I guess everybody is. But anyway, you can take nice. I wanted to move the pointer. So if you take nice open or closed sets in RN, you can treat them as a metric space. And if they are sufficiently nice, you get these three assumptions of double inequality inequality and the completeness. One example that One example that nice domains of course are, but even if you take the the Fonko snowflake domain like this with everything inside, the boundary is pretty bad, but it still satisfies as a space the Ponca inequality and the doubling condition and it's complete. So that can be included in the theory and then all the manifold Heisenberg groups. Lux of spaces, graphs, hyperbolic. Hyperbolic fillings can also be included, and they often satisfy the point assumptions. I would just like to give you this example, because it's a nice picture, Scherpinski sponge. In this version, it's a recent result of Sylvester and this one. In the two dimensions, it's a little bit older by McKejer and McKyson. By Mike, Jeremy Tyson, and Frederick. And so you do the Scherpinski carpet or the sponge in higher dimensions. But rather than removing the same thing, scaling the same way, you remove different, so you use different factors. So here we remove one third, but then here in this picture, I remove one fifth, and then here it will be one seventh, and you can sort of take any numbers. Any numbers that you try to have the squares and then remove the middle one. And if you have this condition, then the thing that you get outroot will actually have a doubling property with respect to the two-dimensional Lebesgue measure, so it will have two-dimensional measure on it, and the P-punkering for any P. So you can use this as your space for. For doing potential theory and p-harmonic functions on it. I'm aware that this is not the standard Scherpinsky aspect because then this would diverge, so then it of course is not very useful, but you get a lot of nice examples this way that you can use for this here. And this brings us to, I was asked to give some questions. So here we have one kind of major question: which spaces do support? Question: Which spaces do support the concern inequality? And if you have some such space, can you make new ones out of it? And this was already an example where you can get a lot of examples of such spaces. One way of making new spaces is you multiply them and put on a weight. It's in a suitable way. Uh, with a suitable AP class. Uh Lufty recently got a result that you can remove sets that are sort of smallish in some sense. So if you have a space with a quonker inequality, you remove a smallish set in this sense, you get a new space that also has a Poincaré inequality. And there are other results as well. This is just a flavor of what can be done, and of course, it's not completely clear. So, any Clear. So, any new ideas that are welcome. Also, one can take various definitions of sub-alerf spaces and gradients. We have already seen the correlation spaces and even the Haylas spaces have been mentioned. Those are defined using this point-wise inequality. So, you control pointwise the distance between the function values by something that's a By something that's a high-large gradient. No, this is a high-large gradient H, and then the distance of the two points to some power. And I think they have partly been mentioned already as well. And there are other definitions, so a major question is also how do they compare to each other? If you take these gradients, does it make sense to study their energies and their energy minimizes? How do you compare this? So these are very vague questions. This. So, these are very vague questions, but they can be worth studying. Okay, some properties of p-harmonic functions that are probably not very surprising to you, but we have some bad news. Since the upper gradient is only a scalar function, not a vector, we cannot really get an Euler-Lagrange equation. We have to work with the minimization property, with the integral, energy integral. No equation. Also, it's non-linear in this sense, so Linear in distance, so even for p equal to 2, the minimization problem gives you a non-linear problem. And even a shift property, if you know that the function is p-harmonic in two patches, like this, it is at least not known, or at least I don't know whether it's known, if it is actually p-harmonic in the union of those two patches. So there are some bad news which make it difficult to work with these functions. Business functions. There are good news. But Anagas has been, and there are several people in Finland, I don't list them all, and two pairs in Lynchhopping have been doing some of these things. And okay, so half recontinuous, the proper data, we've got enough books. Help your continuous maximum and comparing zone principle. Again, here I would like to warn: we have no linear. They have no linearity for the problem, so you cannot subtract two p-harmonic functions from each other and get a new p-harmonic function. So the comparison principle has to be formulated this way. You cannot just add zero here. You really have to compare two functions. If they are ordered on the boundary and they are pyramid, then they will be ordered in the segment in the second as well. Anakin quality. Panac inequality on compact subsets, the maximum and minimum are comparable. There are lots of convergence CRMs, Liouville CRMs. And so these are good news. They have a lot of nice properties. Some more properties that have been studied is that you can try to solve a Dirify problem. So take an open set in your space, a function f on the boundary. On the boundary, try to find a p-harmonic function in the set which has boundary values. And this has been done and solved by various methods: variational methods, parallel methods, binar approximations by nice regular domains from inside, and various boundary data. As an example, if we have a Newtonian function, let's say on the whole space or on the closure of omega or just Of omega, or just continuous boundary data defined only on the boundary, then all these methods give the same solution and one gets existence and uniqueness for such boundary data. And the major question in this setting is the resolvativity for general boundary functions in the parent method. So, if you have any function on the boundary here, non-continuous sort of Non-continuous sort of any function. The Perron method still gives you two p-harmonic functions, the lower and the upper Perron solution, that somehow are attached to these boundary data. But it is by far not clear and not even known when are those two solutions equal to each other. So if if they are equal, you would get get a nice parallel solution. Nice Perl solution to this Griffa problem. But for many functions, it's not known whether they are the same. So, this is one major problem as well. For which functions do we have resolved? When do they coincide? And they do it for these types of functions. And this is actually open even in RN, info generally. And another question that we've been also working on, which is related to this, is if you have your have your domain here and your boundary data and you find your solution here to the Dirichular problem and then you may so this is F1 and then you change this F a little bit and you do it on a set of capacity zero zero. So I will now have F2, somehow I change it arbitrarily. And then the invariance result is that if you only change on a set of capacity zero and this function f that we had is one of these two at least, then this change of the boundary data is the Change of the boundary data will still give the same solution. So it does not see such changes. But it's only known for this type of functions and their perturbation. Again, in general, it's not known. Sorry, shout. If you take this F in the N1P of the closure of omega, and then I guess it has a kind of restricted to the bound. Restricted to the boundary because it's basically everywhere defined. Yeah, like with a continuity. So now that has a continuous representative, that itself need not be continuous like a point-based restriction, right? Like the restriction if this is continuous, then the restriction to the boundary will be continuous. No, no, but I mean if the solution. No, no, no, just just if. No, no, no, just F itself. This is a bit of a maybe a. The F will be only quasi-continuous, so it need not be a continuous report. Sure, sure. But what I'm wondering is, so you take your F, restrict it to the boundary, say that the restriction to the boundary has a continuous representative. Not the whole F, just that one. Replace F with the continuous representative, and now you have a new function. You get the same. You get the same. You get the same. Okay, so this was the perturbation. Here I just recall the definition of capacity. Maybe not everybody is familiar with that. So if this is our omega and we have b in that you take all functions that are zero outside of omega and they clump above or at least equal to one here and you consider all of them and they And you consider all of them and take the smallest energy that they produce. That's the variational condenser capacity. It may be appearing again. So this perturbation I had here, I want to give you an example of, well, you may think that I'm perturbing on a set of capacity zero. Well, that's basically not. Capacity zero. Well, it's basically nothing, so I'm not really perturbing. So, what's the big deal? This example illustrates that, well, it's probably not still not a big deal, but you may actually be perturbing on quite a large set. So, my omega will be a big square, this square, and I'm removing a fat control set. So, you're removing squares, but you're sort of You are sort of scaling so that in each generation, in proportionally, you remove a little more than what you would have removed in the previous generation. So the fat composite like this. So that's the limit of these removed since it's a boundary. It's fat K. That's what we get left there. And No, that's not okay. The boundary is what we have removed. And now we look at the set K. And so, in the first generation, I had all these big black flags here, but for my set K, I will only look at these really inner ones. So that's the bottom mark in red. And then in the next generation, I have these squares, and then I there look. And then I dare look only at the inner ones, like this, here, this. So the ones that are sort of only outside of each generation, I don't take them in that generation. And then in the next one, I take these inner squares here, and then small. So this will generate a set, a compact set K is the limit of these sets, which will be a part of the boundary. Be a part of the boundary of my set omega. It will have full measure in this part of the boundary, and of course, I have this boundary as well. That's nice. And if I take a new capacity, not the one I gave here, but one that's a little bit adapted to the set omega, that only sees points from inside of omega, this big set with full measure will actually have zero capacity with respect to omega. And so the result. And so the results I briefly mentioned that before, or they can be modified a little bit, you can actually, on this full measure set, perturb your boundary data. If you start with continuous function, you can then perturb it as you like on that full measure set. And you still get the same solution to the reclaim problem. So even a set of zero capacity can be relatively big if you see it through a good capacity. Some more properties. This is about boundary regularity. It may be a little side of this thought, but there are results on that as well. So as Kerry was asking, if you have a continuous function here, the boundary data, then you can solve the Dirichlet problem, and a priori it's not clear and it's not even true that the solution will always The solution will always assign the boundary values continuously, like this. The points where it does for any continuous functions are called regular points. And with Nagas and Paul-McManus, we have shown the Wiener criterion, which gives you a sufficient condition for when points are regular. So that means that the boundary values will actually be attained at such a At such a boundary point for any continuous boundary data. Maybe I draw a picture for this as well. So when is a set? So let's assume that this is our omega. Here we have a boundary point x and then in here you take more balls around there and you look at the part so A here Here is the complement of omega in this picture. So if the complement of omega is thin at this point, then no, the other way around. If the complement is not thin, then the point will be regular. And here I'm drawing how you check whether this is thin or not. You'll look at these pizza slices, the red pizza. The red pizza slice, and you compare the pizza slice to the whole pizza, which is in the denominator in the sense. Anybody can help me with this? So you're comparing pizza slices, comparing them with the full pizza. Slices comparing them with the full pizza. If this integral converges, that means that these pizza slices are very thin, so this is thin. If this diverges, then you have the substantial part here. So there's enough complement and that makes the point regular. So the Dirichly problem actually sees the boundary data here. If this is thin, then it may not see it. So that's a question of. So that's a question of boundary regularity, which has also been studied. Number one. So as I said before, using the matrix based approach to Newtonian and symbolic spaces, you can define the Newtonian space on any measurable set. So in principle, you can go and try to solve. Basically, you can go and try to solve your Dirichlet problem on any measurable set. You do not need to take an open one. You can take any set measurable. Well, yeah. So try to minimize this energy integral with some boundary data on an arbitrary batch set. And that's possible to do, but what turns out is that it will be non-trivial if and only if. If and only if the fine interior of the set is non-empty. So it does not really make sense to study it for really fully general sets because if the set has fine integer that is empty, so basically all of it is the fine boundary, the solution to the minimization problem will be equal everywhere to its boundary data, so you do not get anything. So, we do not get anything interesting. So, this brings us to fine potential theory. This has also been started in metric spaces. And maybe here it should give you a definition what fine in the open set is, this is the one that give us the fine interior, and that's also related to this Wiener criterion. So a set is finely open if its complement is same at every point. Is same at every point in the set. So, in this example, I had an open set, and in the previous situation, this was a boundary point. But I can actually take this point and add it to my set, omega. So I take the open set, and I add this point to it. This is not an open set anymore. What happened here? Yeah. But because the complement here is syn at this point, it's still in the fine. It's still in the fine interior of that. So that's a distinct view. So this gives us a larger cost of finding. Yeah, so we have studied fine potential theory, obtained some properties for Newtonian functions on such sets, p-harmonic functions on those sets, convergence theorems, their own methods. A major problem here is that in general Is that in general it is not known whether finely p harmonic functions on such sets are finely continuous. And that's also open even in RF. These sets are quite general, so it's a bit more difficult to work with them. Maybe it's if here we have an example of a of um rather rough, finely open sets. Finely open sets called Swiss cheese. So it's lower dense. So you take the cube and then you remove in various generations you remove both balls from it of so at the dyadic points. So here is one and then I take the next dyadic points here and then At positions to to minus n. And then the radii are given by magic formula. You choose the parameters correctly. And what you get after all this removing, you get a set that has empty standard interior, but in the definition of define topology, using this finish, it is finely open. So for solving. Open. So for solving fine Birichler problem, it still is perfect. You can put on boundary data on that set and you can solve the Birichler problem there. Even though the Euclidean interior is empty, so it's not really seen by Euclidean measure. Sorry, just to make sure. So you mean P high D o, yeah? Sorry? P, you mean you mean P high D. P, you mean, you mean P. P is finally open. Yes, with respect to P. So P are the same. These two P's are the same. So, yeah, I should have graduated. You usually suppress the P's and I try to put them in the store but forgot this one. Okay, and now I want to come to oh, I should finish, right? I wanted to come to B superharmonic functions, but I guess I cannot. So the B superharmonic functions were So these superharmonic functions were this one, they had this super, could do perturbations, and they were minimizing energy for functions that are bigger than them. This one should be non-negative. I add this non-negative. And one property they have that Rika has been involved in as well is that they actually are finely continuous in that fine. Again, in that fine topology, and maybe I just go on. And they also play a role for singular functions. That was what I wanted to say. Can I take a minute or so? Two more minutes. Two more minutes. Okay. So if you have a set of mega and a point in there, you can actually find singular functions corresponding to the So corresponding to the Newtonian and kernels and fundamental solutions of omega here, the point here. And you can find function that would be p-harmonic here, and it will be superharmonic everywhere, and zero on the boundary. So it corresponds to the Newtonian panels. Yeah. If you have two such functions, it's not in general known whether you have unique. In general, known whether you have uniqueness, but they are at least comparable. And there is an estimate for their size in terms of condenser capacity of balls. So on a ball around here, the size here can be estimated by this capacity. And okay? If you properly see If you properly scale the singular functions, you get a green function. That's maybe not so interesting. But maybe the last thing I should say here is that you also manage to get sharp estimates for the capacity of an annulus. So if you have two balls around some point, the capacity of this annulus is exactly comparable to this value and the measure of balls. And you just indicate this. It's very similar to the Bineck integral. And from that, one can also get sharp estimates for this singular function in terms of such an integral. And then if you want to look at integrability of the singular functions, let's see, you could just sort of integrate these things and This thing, and then one can you define also dimension sets that sort of control the rows of balls in various ways. There are four of these sets and using them one can give more precise and concrete estimates of capacities and also the green functions and look at their interoperability when they belong when they belong to these are the green functions, when they belong to various LT spaces or when the gradients belong to various LT spaces. There's some exponents and these are up to borderline cases. These are shocking. Since it's just a lot of letters I'm not opening on the there are some such results. And that's it. Are there any questions? Bada?