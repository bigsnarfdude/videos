Exactly more or less what Stefan wanted to give. So what I'm giving is a talk about a recent result that I have with Stefan and Barnaby that was part of his talk. But I concentrated more on only on our result. And this result also presented that complexity. So what about this result? So this result is What about this result? So this result is essentially starting from a discussion we had with Stefan and Barnaby about understanding binary principles, what we know by binary encoding of combinatorial principles in REST-K, in resolution of a KDNF. Well, I'm just skipping this slide because it was a slide that I was presenting for people in complexity. That I was presenting for people in complexity, so all of you know about that. Let me just give through the definition of the rules of the system of REST. Oh, I'm calling RES what we usually call RES-K, RES-S. This is just for not going into trouble with the K of the K-click principle that I'm considering along the talk. So, these are the rules that we have in the system. So, it's a kind of extension of resolution rule over. Of extension of resolution rule over S literals. Here we have an end introduction up to S, okay, up to this point here, S. And we have two weakening rules of these two forms. So we are considering these two weakening rules. So what we do is, first of all, working all over the proof instead of in the calculus with a form of kind of Kind of extension of branching programs where that we can obtain by just turning a proof upside down. So in this case, what we have is taking the recess proof and what we get and negate the SNF on the vertices. And we get a special kind of restricted branching S program whose nodes are labeled by SCNF. And so each node, at each node, we are querying some disjunction of literals. And then we proceed down by just evaluating this disjunction to true or to false. So the rules of the system correspond to these three cases. The third one is the next slide. So we can query a new SDS junction from some C that we had before and go on. That we had before, and we are going into these two cases here. We can query for an address junction which is already known. For example, it's a part of this junction that we already have. So we are going into, went through this case and we are false in this other case, G2. And we have, as usual, two ways of corresponding to the weakening rules, two ways of forgetting information. So we can forget some part of a conjunction, or we can add some literature. Uh adding some uh some metals inside this junction. Okay, so um oh sorry something is wrong. Full screen or presentation mode? No, full screen. Yeah. Okay, I don't don't mind. So let me just remind for those of you that what is the K-click print? What is the Keyklick principle? So, Keklick principle is a principle, a formula, a propositional formulas which we aim to be satisfied, we want to be satisfiable if and only if a given graph we apply to a graph contains a k-click. So, these are the usual axioms that define the formula. So, and the important axiom here are this one. So, here we This one. So here we are saying that this and each node in each position, no two nodes can go in one position of the click. And the no edges cannot be in the click. The no edges in the graph cannot be in the click. So this formula is satisfiable if and only if G contains a key click. And we are interested in the unsatisfiable version of this formula. So see if if G doesn't have a key click, this formula is unsatisfiable. So what we are using in the So what we are using in the paper, it's a simplification of the formula of k-click, where we are assuming that the nodes of the graph are kind of grouped into k-blocks of n node each. So our graph can be considered as some collection of k block. I'm calling block this. This is the reason why I'm calling P here, so I'm using this P here. And the variables, we have variables. And uh the variables we have variables of this form uh V I A for I in K and uh a block and A it's uh one of the nodes in the block. So this is an edge IA. It's a node in the graph. So under this assumption on the graph the click formula can be simplified in this way here. So these are the actions corresponding to no edges before. So in this case are Before, so in this case, are of this form: a node, it's a pair, remember, a pair which is a block, and a node. And in this case, also the click is unsatisfiable. If G doesn't contain a click, then the formula is unsatisfiable. So, here is an example. Just uh I want like I want to keep you in mind this for understanding a thing which is coming before. So, these are sort of block. These are three nodes. These are three nodes. Here is a very simple example. And the formula click and Kg that I was defined before is essentially the conjunction of these clauses here. So I'm skipping the motivation for studying these formulas are well known. Essentially, they were coming from the root of all this interest in this formula was this paper by Stefan Dancer Martin, Bannami Martin and Stefan Seider. And then, so in this paper, we were really making clear why this formula were interested. Making clear why these formula were interesting, and then they were studied in several proof paper that I will mention later. So, what is the binary version of the principle? The binary version of the principle, let's start. So, I will introduce two binary encoding here, two binary versions of the principle, one for the code-catlique and the other for the PGER principle. So, what is the binary version? So, here, So, what is the binary version? So, here the variables that we have are variables that are intended to be bit values, capturing some bit. Okay, so what we have is we keep the block, the k block, but instead of having n node, we are understanding each node identified by like kind of an address, so by log n bit, essentially. So let me just use this notation. Let me just use this notation, wij with ij. So let's say that j in n, so the binary, the binary, let's say that the binary encoding of a node j, original node j, it's the vector log n vector A. So then A J is just J coordinate in this vector here. So I'm introducing this notation here. So I'm introducing this notation here, uh omega ij of a j uh a j. It's just this, the variable if the bit is one, and the negated variable if the bit is zero. Under this notation, so the variable, the original variable I was using before, vij, are essentially corresponding to the conjunction of this binary variable here, where a is the vector corresponding to the binary. To the binary representation of the node J, of the node J. So, and if you just reason one second on this notation here, so then the binary version of the click of the click principle can be obtained using these variables and previous unary encoding just by the conjunction of these clauses here. These clauses here. Where essentially you are taking two nodes that are no edges in E and just taking this junction of this. So you want to negate both this one and this one for i and j. So you get 1 minus a1, 1 minus a log n here. Just matter, so it can seem a bit complicated, but if you know the principle, it's immediate to see. So actually similar construction. So, actually, similar construction, let me go very fast here. Similar construction can go through for the P-general principle. So, here again, I'm using some binary variables, omega ij, and essentially the binary version of the Pigeon principle, it's a conjunction of these clauses here, where you can see that there are some important differences on this. so important difference from this. And let me just skip all the details about that. It's very similar to the to the click what what is happening here. So essentially in this case omega j are encoding that pigeon i it's mapping it's mapped to all h and the j bit of h is h of j. Okay, this this is the the idea of this of these binary variables here. So uh why um why an interesting uh um interesting why we are studying binary binary principle binary version of principle well in general we have that they preserve the combinatorial hardness of the unary principle so they are still useful for proving uh interesting lower bounds. I mean I was generic here, it's it's kind of formal. Lower bounds uh significantly lower bounds means that Significantly lower bounds means that, for example, can be used to prove size lower bounds or maybe also space lower bounds and still simplify, so are less exposed to the details of the encoding when we are attacking this formula with the lower bound technique. So, this is, for example, really very clear for the Pigeonal principle, for the binary version of the Pigeon principle on space lower bounds, for total space lower bounds, for those of you that know what it is. For those of you that know what it is. So, in particular, an example where one very simple example where you can notice an immediate difference between binary and the unary version is, for example, if you have in mind the size-width trade-off for resolution or the space-width relation for S, where the initial width of the formula is playing some important role in this trade-off. Okay, so notice that when you are skipping, when you are jumping from U. Skipping when you are jumping from unary to binary, there are significant differences in the initial width. So, this sometimes can make difference, and in this sense, these are less exposure to the details of the coding when attacked with the lower bound technique. This is just an example. There are other things. Another thing that it is not difficult to notice is that so if we are So, if we are under these two ideas, this equivalence that I was explaining before, so it's very easy to understand that if you are considering resolution proof, you can map resolution proof, small size resolution proof of unary version, into a small rest-logen proof of the binary version, both of the click principle and the Pigeon principle. So, this is immediate, essentially. So, that means that we can. So that means that we can go and try to understand how to prove lower bound for the binary version of this principle. It's interesting to understand lower bounds for the size of binary version of this principle in REST S. Okay. So what is the situation for the Krick principle? The click for the K-Click principle. That was one of the main motivations we were just starting this work. So, so the motivation, so the results are collected in this thing. So, here you have this. Okay, no, this is just for lower bounds. For upper bounds, we know that there are n to the k proof, size proof in three like resolution. This is just brute force proof. And if g is the k minus 1. If G G is the K-Mengu's one partite, complete partite graph, then click NKG as read-once resolution of size 2 to the k times n squared. This is a result of 1 and 2. And these are difficult. So we can prove a lower bound for this Kemmer's one-partite graph for the click principle of this graph in three lacquer solution. And in general, it is. And in general, it is difficult to find a graph without a click making R to refute this formula. So, that is the reason why, in general, the lower bounds that we know for the unary version and also in this case for the binary version are using a random graph. So, with the Erdos-Reni model with a probability essentially in this around this threshold, 2 to the around this threshold, 2 to the minus 2 to the divided k minus 1 and 2 to the minus 2 divided by k minus 1, which is a threshold where after that k-click started to appear in the graph of the type of probability. So what are the results that we know here? So we know that for a three-like resolution there are lower bounds when j it's a random graph in for the unary version and in regular resolution. This is a recent work by Albert. Work by Albert Ilario and many other people here. And I wanted to mention everyone, I cannot mean it's a limited one, but you know very well all of them. So this is a very nice paper, I have to say that it's a very nice paper. So there are uh some result some recent results that I think that uh uh we learn something uh later in the uh Something later about this. It's a kind of open and this did the result, but we have some initials. I'm not sure about this because I don't know precisely all the details of the paper, but it's essentially open for a resolution, the lower bound. And in recess it's clearly open. For the minor reversion, okay, here we don't have anything because we already know that. And we know a result of We know a result of Lauria Pudlak radolet tapen that is proving uh a lower bound for the binary click in resolution in resolution, so res 1. So what we are doing is just going into res S and proving a lower bound of this form n to the k. But we are so we have this bound on the s so we are stuck here essentially. The square root of a small little square root of log log n. Of square root of log log n. We are trying to improve, actually. I want to say that we are trying to improve after this, this to log log n. It doesn't seem very easy, but let's see. So, what I want to do, okay, for the Pinano principle, we also have this to this sorry, I don't know, at what time I have to stop? Sorry. Ten more minutes and then ten more minutes. Ten more minutes, okay. Okay, so um So for the Pigeon principle, for the binary version of the Pigeon principle, we are proving this lower bound, this lower bound here, and we are also proving an upper bound in 3-like res1 for the binary version of the P-General principle of this form here, making some difference with the Euleri version in 3-like resolution. But what I'm doing in the next 10 minutes, I'm trying to explain you. I'm trying to explain you a bit of the ideas that we were using for proving the lower bound for the binary version of click and k. So, here are the main ingredients of this proof. So, let me just comment a bit on this ingredient. So, first of all, we are using the notion of covering number on SDNF. This is a notion taken directly from this old paper studying lower bounds in rest. Studying lower bounds in REST S by Segal in Bass in Pali also. So, what we prove is that essentially that when the covering number is small, and you will see this what exactly means, we can more or less efficiently simulate res proof into res S minus 1. So, this is suggesting, already suggesting that maybe we can try an approach, an inductive approach over S and see if we can get if we can uh get something. So then a second ingredient is the defined the definition of some classes of random restrictions that will work in particular for binary principles. And actually, so we'll work precisely trying to implement these inductive ideas that is suggested by this result here for binary principles. Here for binary principle. So, in the case of the click principle, the binary click principle, we study, so we will use an hardness property that is essentially quite similar. I will explain this in a bit different way from what it is so what it was studied so far, but it's essentially very similar to what were used in this paper where we were proving. This paper where we were proving the lower bounds for the three-like resolution of the unary click version, and then we are trying to go by induction of S. Going by induction on S, we have so for free the base cases because it's essentially this result of maximum parallel and rather than Mil. Okay, so that are the main ingredients, and I will try to explain you a bit of the main point. So, the main point of each of this. Let's see. So, first of all, the covering number: it is what is the covering number? So, the covering set of an SDNF is a set of literals L such that each term of F has at least a literal in this set here. So, and the covering number of an SDNFF is the minimal size of such a covering set. I don't know, I was running the max, so this is not wrong. Okay. So the lemma that I was telling you before about how to try to simulate, so when the covering number it is small, how to see what happened, how to simulate in rest S minus 1, rest S, proof in rest S. It's captured by this lemma that I was calling simulation lemma. It's not a difficult lemma. So what it's saying is saying that if F is a refutation saying that if f is a refutation in recess where the covering number is smaller, is strictly smaller than d, then we can find a recess minus one refutation of size at most two to the d plus two times n is the size of the proof in recess. Sorry, I was forgetting this. n is the size of, it's a size of it. Okay, the proof of this is not difficult. I was, let me just. I was let me just. Then it's not a market. It's a hitting set for the hitting set for the clause variable, for the term variables. So it's a hitting, yeah. Yes, you want. Essentially, here is the proof. So I can show you this proof here. So I won't understand what this is. So I'm not the same with this. So let's say that some disjunction at some node is queried of this form here, and assume that the covering number of this C here is smaller than D by our hypothesis of the lemma, and this is witnessed by this set of variables, V1, Vd. Then what we are doing is building essentially a complete tree over these literals. These literals, okay, over these literals here, and then we are just making the right step to go exactly where we have to go here. Either in this direction or in this other direction. So the point is that this 2 to the t plus 2 is coming from the fact that we are just using this This complete brute force on the literals, on the set of literals, with messing the covering down there. So, another concept that we are using is a bottleneck, a C-bottleneck. So, a bottleneck in a recess proof is an SDNFF whose covering number is gridder or Whose covering number is greater or equal than C. So this is the C bottleneck. And let's say that CS is the bottom number at press S. So we are just using this notation here for CS. So another not difficult fact that we can notice, it's not difficult, is the following. That if C it is R times S for R greater than R greater than 1, and the covering number it is greater than C. Then it is all then in F it is always possible to find pairwise disjoint S tuples of literals, T1, TR, S tuples, such that the conjunctions of these literals are terms of F. It's just a a simple counting argument, it's nothing difficult and It's nothing difficult, and essentially I'm calling this independence because this is the main property that we are using at some point to making disappearing the bottleneck from the proof, because that is what we want. So restrictions are what kind of restriction we are using on the binary, on the on the click, on the binary click principle. So an S restriction, I'm calling an S restriction, I'm calling the NS restriction. It's a restriction that is assigning log n divided 2 to the s plus 1 variables omega ij in each block in k. So this is an S N S restriction. It's log n divided 2 to the S plus 1 with variables. So also another very simple fact to notice is that if sigma and tau are disjoint as restriction, then composing them it is them it is an S minus one restriction. So we are using randomness restriction for a big so this is an important property that we have. So this property here so this definition and this property are important that is so this property that I was mentioning you before about the fact that so this argument it is working for this rest argument it is working for this restriction specifically for binary principle. So a random rest restriction uh is uh is an S restriction choosing independently in each block I these numbers of variables among this one setting uniformly at randoms. So can I can I take three four minutes more? I'm not too okay thanks okay So the main property that we are using to understand hardness, so to including hardness of the principle, is the following one. So let's say that we assume we have the graph G and alpha. And alpha, it's a number between 0 and 1. So we call a set of block U alpha transversal if the cardinality of U it's alpha time K, so we are getting a fraction of the K blocks. And for each block B, we are touching at most one variable, either zero or one variable. So, for example, in this case, U is So, for example, in this case, U is this set here. You see, you're touching one variable here and zero variable here. So, the complement of B of U is just the set of blocks that are not touched in U. So, and then we call U extendable in a block B here, if there exists a vertex A in the in this block, which is a common neighbor of all the nodes in you. Exactly in this case, yeah. Like in this picture here. So the main property that we are using is the following: that we call U an alpha transversal beta extendable if for all beta restriction sigma there is a node in each block B in the complement of B of U such that sigma is consistent with this node. So means that can be extended or is not creating any contradiction. So and then Contradiction. So, and then we can prove essentially this extension lemma that we take probability when G is in this distribution here and beta and alpha have some relation between them, all alpha transversals at U are beta extendible and G doesn't have a kick ring. Okay, so the idea of the proof is done it is proceeding by induction. So, this is Proceeding by induction, so this induction is essentially working for S smaller than little of this function here. And so the main point in the proof are that a sequence of steps. So essentially, the base cases is provided by the result of the inductive property, the inductive step, it is provided by this lemma here, where essentially Here, where essentially we are using the independence property to prove that the probability that when we are hitting the proof with a random mass restriction, the probability that a bottleneck survives is very small. And so, we are proving that the covering number is sufficiently small by union bound. Then, we can use the simul the simulation step here. Simulation in this step here. So, here I was not putting any number, but I was isolating just this parameter here, ds, ls and ps here, and the cs. Okay, so essentially we know ps by this result here, we can know this, and then we want to define ds and cs in such a way to force this property that we need to contradict to get the induction. We need to contradict to get the inductive property and to make the argument work, essentially. So, these are the steps of the fix. So, the important point is that at some point I'm defining a restriction which is the composition of 2 S restrictions, so I'm going into S minus 1 by that observation that I was doing before. And that's the step of the proof. So, okay, let's just skip this. We have several other results about Other results about binary encoding of many other or many other principles and classes of formulas, but let me just skip. And essentially, Stefan Barnaby and a student of them are using a similar approach for Sherali Adams and that was the so Stefan wanted to talk about so all this result together. And that's it. Thanks. Sorry for the delay. Thanks. Sorry for the delay. Sorry. Oh, Stefan, I think I had some health problem. That would be less if I didn't have to. Okay, that's I can be quite a bit. 