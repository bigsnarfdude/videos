I probably put too many words in my title that don't need anything. So we'll first introduce things by looking at some algebraic geometry. Before we get to that, I want to thank the three organizers for putting on this fantastic workshop, the invitation to be here. It's always great to be back in BAM. So let's give some sort of motivation and some introduction to sort of the problems that I'm interested in. And so you have some sort of parameterized. And so, you have some sort of parametrized system. Maggie's talk is parametrized system with some sort of polynomial system. Here, I'm going to leave it very vague as to sort of what this is. Some sort of parametrized system. So, p will be my parameters, and y will be some sort of output. So, in a four-bar linkage, you have a certain set of parameters. So, you need to know where is this pivot, where is this pivot, how long are these pivots? It. How long are these legs? And then what is the vector connecting to this output? So if you tell me those parameters, then you can put a motor inside here, and it'll trace out a curve. So this x will trace out a curve, and so your output is this curve. It's all the possible locations there. So that's the forward problem. I tell you the parameters, you can draw this curve. This curve. Now we want to look at the inverse problem. Suppose I tell you that curve. What were the set of parameters that could yield that curve? So we want to do sort of inverse problems. I give you a curve drawn by some four bar. What were the four bars that yielded? This problem was solved in 1875. This has been known for a long time. Robert solved. Time. Robert solved this and it's triply generated. So there are three such four bars that generate the same curve. So this is just a if I found online that has some curve, and you see the three draw exactly the same curve. So you get the three four bars that go through the same curve. So that's what we want to look at: is sort of these inverse problems. Sort of these inverse problems. I give some output. What were the parameters that you'll jump? Yes, please. By giving us the curve, giving the idea of the curve? I'm being very vague on what I mean by giving you the curve. Because I'm going to immediately change this to now a differential equation. How do I give you the output of The output of a differential equation. I can't write down the ideal per se of it, but I can give you the equations that define it. So you can write down the equations that define it and somehow give it to me. So I'm being very vague here. Okay? So this F could be this system of differential equations. So you have five rate parameters. So these parameters sort of tell you. Parameters sort of tell you how fast you're moving between these different: are you infected, are you recovered, how much is being generated? So, your parameters are these rate constants. And then what you can measure is you can measure how much of this RNA. So, this is an HIV model from about 20 years ago. So, what you can actually measure in the lab is how much RNA there is per milliliter of platinum. So, you can Platinum. So you can measure this, and so this is the output y. And now from the output function, you want to know what were the parameters of the function. I can't continuously measure this, and so you have to do some sort of discretization. So, if I could do this continuously, have a device on someone that continuously measures this, then you would get. Measures this, then you would get some kind of curve. But you can't actually do that in practice. You have to do it sort of time-stepping along the way. And so you get some data. So in the exact problem, if I can tell you this exact curve, this actually has four sets of parameters that could define it. It's actually kind of interesting. It's the same data on the output. Data on the output, you measure the same set of RNA, and you actually can come up with four different sets of parameters that will give you that same thing. So it's hard to know which set of parameters corresponds to me, because there's four of them. It's already nice that it's finite. That's right. It's nice it's finite, but you then want to predict what's going to happen. So is there intersection, but links with different possible parameters? Possible parameters? Is there a way? A good question. Absolutely. Absolutely. What kind of which parameters? So in this one, there's actually a Z2 cross Z2. There's a negation and then a, I forget the other one, but some sort of... One should just factorize, factor out the civic. That's right. Then there's sort of a unique one up to. And so sort of this whole probability idea is. Idea is we can't measure things exactly, so what happens under noisy observations? That's the data I can give you. I can give you these data points along here, and now we want to be able to recover the parameters that define them. Okay, so the first part of my talk will be very short. It will be in the exact data case. So if we have exact data, how do we count the number of solutions? How do we count the number of solutions? And then the rest of my talk will be on this noisy data case. How can we use a homotopy to be able to come up with the probability distribution of these parameters? Okay, so that's the quick introduction. So now let's think about identifiability. And usually this is called structural identifiability because you're looking at the structure of the equations. Of the equations. And so you have some model. For me, the parameters are always finite. You always have finitely many parameters. And this model is always polynomial in the parameters. So you get a nice sort of setup. In the output, maybe it's a differential equation. Maybe it's some sort of analytic thing. I don't really care. Somehow I can create something that's generic. And then you want to look at the And then you want to look at the fiber over that. So I tell you the output, and now I want to know what is the set of parameters that could describe that same output. Okay, so you get a general fiber. If things are polynomial, this is what you would expect it to be. So you get this general fiber, and now you want to look at its dimension. So Sandra mentioned, hey, it's finite. So you want to look at its dimension. You want to look at its dimension. If it's zero-dimensional, so it's finite, then this is what's called an identifiable model. So, an identifiable model means that there's finitely many parameters that we want to describe. And then you can look at its degree. So, this is sometimes called the identifiability degree. And so, you just count. How many are there? If there's a unique one, that's the really nice case, and so these will be called. Nice case, and so these will be called globally identifiable files. Still generic, right? Still generic. That's right. Generically globally identifiable if you want to, if you want there. But if the degree is bigger than one, it's called locally identifiable. So that means if you know some region where it has to be, then there's a unique parameter value in there that describes it, but if you want to look over the entire But if you want to look over the entire space, you're not sure which one. So you get these sort of two different regimes. And the case that I'm mostly interested in is this locally identifiable case. We want multiple solutions so that when we perturb the data, we get some very complicated probability distributions. So these typical problems you've published are how can we identify them? Absolutely. That's exactly the case. So, minimal problems are exactly structurally identifiable because they have a zero-dimensional framework. That's right, that's right. Here I'm allowing things to be over-determined. You can tell me as much data as you want. Want. And if it's exact, then they're sort of zero-dimensional. So instead of having five cameras, suppose I gave you ten cameras, and they could measure the exact same point, and you would still have finitely many solutions. Okay, good. So, how do you count the number of solutions in the fiber? Well, hopefully. Well, hopefully, the picture sort of suggests you want to do some sort of monodromy loop. If you have one point, if things are nice, you know, your fibers nice, the monodromy group is transitive, you can start at any one point and do loops around and be able to populate all the points in the moment. Okay? So this is a fantastic method that. Method that you start with one point, you do a loop, hopefully you end up at another point. If you end up at a new point, now you have two, you do another loop, hopefully you get four. And so you get this exponential growth up until things start to repeat. So the question that my student Sam and I asked is: if we used the data collected, meaning how many points did we find, how often Did we find? How often did we get repeats? Can we use that to estimate the degree? So, can we estimate the degree just by using the data that we gather along here? Okay, and so we looked, and there's a biological method that's been used in biology, I think, since the 50s. And so, think about trying to estimate the number of fish in a Estimate the number of fish in a lake. So, what you do is you go out and you go fishing for a day and you collect a certain number of fish. Hopefully, you can count, let's say, 10 of them. And then what you do is you put some sort of mark on them and you throw them back in. And then a couple days later, you go out and repeat the exercise. You go fishing again and count the, collect the same number. Collect the same number of fish, and you decide how many new fish did you see, and how many ones did you already count. The probabilistic model here is that everything is equally vibrating. So the probability that I catch a fish or this fish has the same probability. I'm not a biologist, I don't know, but you know, maybe that's not a good idea. You know, maybe that's not a good assumption. Maybe there are hungry fish that always just want to go eat the hook in the water. Maybe also killfish. Maybe when I'm pulling them in, things get ruined internally in the fish and it dies. But the biologists say, all right, this is all we got. Let's assume equally likely, and then you get what's called the Lincoln-Peterson estimate. So it's the sample. Estimate. So it's the sample size. So in this case, you're collecting 10 fish, so your sample size is 10. And you divide it by the ratio of the repeats. How many repeats? So in this cartoon that I found online, they collected 10 fish again, and five of them were repeated. So your ratio of repeats is 50%. And so 10 divided by 0.5 is 20. And so you can do this. So, you can do this type of estimate. Of course, you need to be able to find repeats in order for this to work. If you're not finding repeats, that's actually good because now you're finding new solutions and you're gathering new solutions very quickly. Or you're killing a lot of fish. Or they got smart after getting caught once and know never to go back to that lure again. That lure again. Fortunately, solutions are not vertebrates. And so, what I want you to think about is: I want you to think that the points in the fiber are the fish. These are the things we're trying to catch. So, we're trying to go fish, and the fisher, the person that's catching them, is these random monotropes. So, we're going to start with some subset, and then we're going to go try and fish for. And then we're going to go try and fish for some other things. And so the degree, the number of points in this fiber, the maximal likelihood estimate is the number of known solutions you have divided by the ratio of repeats. So you get exactly this Lincoln-Peterson model. You can also do confidence intervals on this. So here's a sort of a pictorial image of this. Pictorial image of this. So this one on the left, we start with one point. It goes, it gives me a new point. So now I start with two points and then four and then eight and sixteen. And so I never get repeats until somewhere around here. I start getting repeats, somewhere around 15. And so my denominator is zero until somewhere around here. And then once I start getting repeats, then I can use this. Use this approximation or this formula to be able to come up with the estimate. And then this shaded region is the 95% confidence interval that I want. The fantastic part of this is that when do you expect to see repeats? And it's when you have the square root of the degree number of solutions. So the time you start to see this denominator be non-zero. This denominator be non-zero is when you have the square root of the degree. So, in this problem, I have about 300,000 solutions. The square root of 300,000 is somewhere around like 550. So I only need about 550 points to be able to give good estimates on the number of. How many did you have in this? I think it was like because things double, I think it was like. Things double. I think it was like 580 or somewhere around there. It was a little over that. Obviously, you just collect numbers. It's just random data. That's right. What do you actually saw? That's right. And so this actually is really nice. Okay, biologists can assume he's picking a fish at random uniformly. How do you pick a solution uniformly? Absolutely. And so that's the next question. Question. This doesn't always work. So, this is what we would love to have. Sort of, as soon as we start getting repeats, you know, things don't change too much. And then the more data you collect, the only thing that's really changing is your confidence interval. It's shrinking. You're getting so much more confident. Maybe I didn't pay attention, sorry, but if the square root of degree comes in, is it some standard standard probability independence argument or where? No, it's just very simple. So if this is the square root of degree, It's just very simple. So, if this is the square root of degree and this is 1 over the square root of the degree, then that's equal to the degree. It's very simple. That's right. Very, very, very simple. So, the key takeaway of this is that you don't really need too many points to be able to give good estimates. So, that's the key takeaway. If you can sample randomly. And this is the picture or an example. The picture or an example of a picture where we can't sample randomly. Your estimates are terrible, and you know, kind of each iteration, you're not really getting the expected, you know, what you'd expect to see here. And then up until some point, then it finally starts to level off. So I call this the crane graph because it kind of looks like a crane. And cranes like to eat fish. And cranes like to eat fish. So they're eating my fish out of the monodroming loops that I'm trying to find. What prevents you from being able to take them randomly? Right. How do I know what a random monodroming loop is? How do I know what the distribution of the branch points are so that I can find random loops to go around them? I have no idea. I have no idea. Someone brought this up at Taylor, at the Monday's thing. How do I do this? I don't know. Is there some underlying structure? So this comes from a Watt1 synthesis problem. Is there some underlying structure of this problem that's telling me that my model of equal likelihood is incorrect? Previous slide, you also didn't know. Previous slide, you also didn't know it was just work. It just was working. Just was working. That's right. That's right. You know, so you get both cases. Things just work and you're happy. You look at the data and be like, wow, that really worked well. And then you look at the data and you're like, oh, that was terrible. Yeah, something like that. So when you write expected something, so intuitively, I would like to think that generally. I would like to think that generically among your problems it works. Right. That you have exceptions where it doesn't work in the chat. But maybe the two branch points that you need to go through that interchange these roots are so close together that your branch points aren't aren't usually equally distributed on your space. It's not that bad now, because 3000 solutions for the almost accurate list. It's not terrible. You need about half. I would really like it to be the square. That's right. It's not terrible. Don't get me wrong. You also don't know when you're smoking until the end, right? Yeah, exactly. Exactly. Is there symmetry here? What happens to the market? I don't know. I don't know. That's one of the. I didn't check in this problem. But in what example you have. But in both examples, you have finite number of solutions in the fiber. Yeah, you know there's finitely many. In both examples, you know there's finitely many. Yeah, yeah. You know there's finitely many and you just want to count the number. And so, Jose, if you're interested, it's the Watt1 synthesis problem that you're trying to. Maybe there's some underlying Galois structure. I don't know. So you did. I don't know. So you did a few other, at least like four other mechanisms of higher misdemeanor? Yeah. I picked the worst one. Okay, but are other ones also bad? Like her Sandra's question, right? Like does it... No. Are all the other ones fine and it's just this one? So here's, if you really want to know, here's the reason why I think this one goes wrong. Is your data is both points as well as angles. As well as angles. And so you're trying to, your parameter space is both points and angles. And those have different metrics on what is angle, how do I do angle space and two different tail sprays. Exactly. And so I think that's what's happening here. I don't know. Okay, so that's random monodromey loose. This was sort of our first foray into sort of this. Foray into sort of this probabilistic outbreak geometry and random outbreak geometry, try to say something about degrees. And then the last half of my talk will be about, I don't actually have data that's exact, what happens in the noisy data case. So if I have noisy observations, you don't have exact points, you now have probability distributions that could explain. Distributions that could explain your data. So there's some sort of posterior probability distribution, and you want to be able to sample from that complicated distribution. So I want to be able to find points that sort of are high likelihood in this probability distribution. There was a recent paper that called this one of the core problems in modern statistics, to be able to. Statistics to be able to do this. The statisticians really care about this, and it's really hard. Okay, so what is the distribution that we care about? And so we'll take a Gaussian likelihood. So from Kathleen's talk, you were just looking at sort of this residual, and then we're just going to put it in an e to the minus something. Take the residual back. In Kathleen's talk, this was a linear function. This was a linear function, and here, I don't know, whatever is the right function that fits the curve. So you're given some data, you have some estimate on your measurement error, and so that's the sigma, and you have some functions that tell you sort of how to generate those points from your parameters. And so this is our likelihood function that we want to be able to approximate, sample from, compute. From compute statistics about, and the whole point of this talk is to say we can use homotopy continuation to be able to solve this problem. Okay, so before we get to the homotopy continuation, you might have heard of MCMC methods, Markov chain, Monte Carlo methods. So these are very, very commonly used. Problem is they're expensive. That's not to say our method isn't expensive. It is. Expensive, it is. But if you have something that's extremely complicated, sometimes you can lose features and things. So it's hard to sort of get the right MCMC convergence in these complicated ones. So what do you do? Well, you, instead of looking at this complicated one, start with, say, a simple Gaussian. Start with your simplest thing, and now construct math. And now construct maps that map you from this simple probability distribution to here. And so the term variational inference in my title just says find the best map from your family that approximates this. How do you find math? Exactly. That's why it's in quotes. So that's right. So you have to pick. That's right. So you have to pick a family, and then in that family, what's the best one? Just a map. That's right. Just a map. Term of variation reference is a huge field. Huge. It's not meaning. Huge field. Huge field. Absolutely. Okay, so this idea of finding the best thing from a family has shown up already at least twice this week. Twice this week. Very common framework. So, in Liza's talk, looking at spectrahedral regression, trying to find sort of the best thing that explains the data. Kathleen's talk was looking at sort of these linear convolution networks and trying to be able to sort of minimize those, or look at the critical points. If you take a very simple statistics course, well, the first thing you do is find the best line. You do is find the best line that approximates your data. So each problem has its own meaning of best. And so exactly as Sonia said, I need to tell you what I mean by best. And so that's what this is. So I want to measure the distance between probability distributed K L divergence. So this is a famous formula from the 50s, and this will tell us. These, and this will tell me which ones are best. Meaning, I want to minimize this function. Minimize this function. It's non-negative, and it's zero if and only if they're equal. So it follows a lot of the nice properties you would like from a metric. It's not a metric because it's not symmetric in P. You see that there's a difference behavior in the P and V. So it's not a metric. Here in a key map. So it's not a metric, it's a divergence, but it has all the same properties. Okay, so this is your problem. I give you some family of maps, and I want to find the best one in there to minimize this. Okay, and so here's the maps that we're going to be looking at. So, exactly from Kathleen's talk, we look at these These sequence of maps, and you can add more and more layers if you want to. So these are called planar flows. They make for some nice, easy way to implement things. And so you have this activation function inside of here, which gives you the nonlinearity. So the nonlinearity comes from this activation function. Releu. Functions, Reylu or hyperboly tangent. That gives you the nonlinear inside of there. So I fixed k, and now I want to know what is the set of parameters that minimize this. So you look at this paper from Resende and Mohamed, which sort of proposed these planar flows, and they give these beautiful pictures. So this is the exact distribution. Is the exact distribution, and then these are the best ones when you use two layers, when you use eight layers, 32 layers. You kind of see as you add more and more layers, you start to get more and more of the structure and these distributions. All right, so this is great. Our statistic friends said, implement this and try it out. So we pressed enter and it And it converts to something like this. We were trying to approximate this sort of bimodal distribution, and you would press enter and it would converge to something that approximates this one or something that approximates that one. And where did you press enter? That's right. We developed our own Python code to be able to. With gradient descent, or that's right. Stochastic gradient descent. Yeah. Yeah. Yeah. And so what happens is you get these local minima throughout your space. And so you want to find the global minimum, but many times you just animate the local minimum. And it sort of misses the structure of this. So for you at the head of the room, this right. That's right. And it's something that doesn't approximate all of the structure. I thought your family of distributions that you're Your family of distributions that you're allowing to use are going to be these Gaussian. So, of course, there's one peak you're trying to do. But once you put a Gaussian under these non-linear maps, they start to split things. Because since you're using like a sort of parametration, I guess like possibly that you get like minimal only come from the parametrization and not from the actual thing. On the actual thing. Right. This could also be bad. That's right. That's right. But you have to put that balls. That's right. So the key point was: if you just try the naive thing, it doesn't work. Good. So this is where we can come in and say, I have a tool that helps us find minima homotopy continuation. Okay? And so you're reading. And so you read in their paper, they go through this whole thing, and then in the example section, they have this one sentence. A simple annealed version was used since that was found to provide better results. And so what you have to understand is annealing is a homotopy. So they were using a homotopy here without actually describing all these things. So, what I'm going to do is go through a few. So, what I'm going to do is go through a few slides to sort of give you a very basic idea of homotopy continuation, and then we'll turn it back into homotopy continuation for probability distributions. Okay, so classical homotopy continuation, you're given some polynomial system that's hard to solve. And so you say, okay, that's too hard. I'm going to change the problem into something that's much easier to solve. So I can solve this system g easily. x is plus or minus 2, y is plus or minus 1. I don't need a computer to be able to do that. Whereas I have no idea what the solution is that far. Okay, so the idea is replace your problem with something easier and then deform back to the original one. So classically, you can use sort of a linear. You can use sort of a linear homotopy between F and G. So in this picture here, we're just using a linear homotopy between F and G. We have some known solutions here, and then we let T vary, and it goes to 3. So when you're trying to implement this, there are some things that you need to make choices about. So one thing that you need to make a choice about is how big of a step should I take? Steps should I take in order to increment T? And so the common way of doing this is use some sort of local conditioning to sort of tell you how big of a step should I take based on how fast is your path changing. Once you sort of know, then you want to predict, okay, where's the next point on my path? This is a cartoon, please know that this doesn't actually. This doesn't actually, it's not that terrible. But as a cartoon, you want to be able to predict what's the next point on the path. In classical homotopy continuation, you can use sort of the Davodenko differential equation to be able to do this proportion. That has error, and so then you want to remove that error, and so you do some sort of correction. So you want to correct back, and classically, you can use Newton's method to correct. This Newton's method to correct it. Okay, so here's a picture from a paper a while ago that shows you the relationship between the condition number and the step size. So in particular, when the condition number spiked, you take smaller steps. When the condition that come there is kind of nice, you can take bigger steps. That's the key point: you have this inverse relationship. Relationship here. Okay, so now what we want to do is transform this into a homotopy in probability distribution space. And so here's the homotopy we use. We just take what we're looking for and we raise it to the t power. So in polynomials, say you linearly interpolate. In probability distributions, we're going to raise it to the t power. Distributions, we're going to raise it to the t power. As t goes to zero, this thing becomes more and more flat. A non-zero number raised to zero is one. So it becomes sort of nice and big and flat. Okay, so nice and big support and sort of flat. As you take t smaller and smaller, it becomes more wide and more flat. And then, of course, when t is equal to 1, And then, of course, when t is equal to 1, I'm back to where I want to go. Okay, so this is the bimodal that I want to approximate. And this is my so-called start distribution that I'm first going to approximate. And then I'm going to homotopy from this easy one to this more complicated one. So, exactly as Sony was saying, this is a nice one, it sort of has a big One, it sort of has a big support, sort of almost unimodal, like those things these can approximate well. Once you start getting sort of this bimodal structure, you really have to rely on the nonlinearity of these maps to be able to split. Okay, so that's our homotopy. We just raise it to the t power. Of course, these are probability distributions. There's some constant out in front. We don't really care about that too much. Care about that too much. It's not there. Okay, now I need to tell you how I'm going to do predictor-corrector tracking. We tried and tried and tried to write down a nice equation to be able to predict how these things were changing. And it got so ugly that we're just like, we're just going to take the constant predictor. We're just going to say, wherever we are, we just move that forward. So it's. So it's zeroth order. Not very good, but it's easy. You can do zeroth order homotopy continuation for polynomials, and it works. We don't have Newton's method, but we do have stochastic gradient descent methods. And so you can use stochastic gradient descent to be able to converge back. These methods will converge locally really nicely. Locally, really nicely. So there's a basin of convergence, and as long as you stay inside there, you'll hit, you'll correct back to just like me. Okay, so that's our predictor and corrector. And now the next thing I need to tell you is how are we going to do the step size? Okay, so well, here's an animation first. You see things sort of bouncing around, that's the stochastic gradient descent. Gradient descent. Yeah. Okay, so you start with some distribution, and then as t goes, it sort of nicely deforms to the one that you want. So that's the beautiful animation of what we're doing. So let's break this down a little bit closer. These are, so other than this first one, these are all uniform in t. So the step size is 1/8. What you should notice here is these three don't really change. There not much difference between them. Whereas these three have a lot of change between them. And so the change in this probability distribution is not uniform in t and so we want to be able to do adaptive steps that are not uniform in t. We want to be able to say, okay, this is moving really fast. Moving really fast, we should take really small steps so that we can make sure to approximate. So you pull up condition, Peter's book, and inversely proportional to the condition number. Sort of the key thing here. So we want to take our steps inversely proportional to how fast it's changing. And the only problem with this. And the only problem with this formula is delta t appears on both the left and the right hand side. So, how do I know how big of a step to take when that step depends upon knowing where I'm going? And so, this is where the theorem comes in. How to be able to approximate this thing that I don't need to know where I'm going. And so, this is the theorem. Surprisingly, Surprisingly, it wasn't written down before is that this thing has this, the first order term is zero, and so the second term of the Taylor series is delta t squared over two times this variance. And so the nice part is, is we say, okay, this has got to be the piece that we want. I forgot it too. There's a typo in here. There's a typo in here. I forgot it. Square root of two in here. But anyway, let's say it gets incorporated into the proportionality thing. Perfect. So if I take my step size to be proportional to the reciprocal of the standard deviation, that will give me these steps which are approximately uniform in how fast it's changing. And the key point is this thing can be computed really easily. Can be computed really easily. Okay, and so we call this adaptive annealing. My co-authors really love to have a catchy name, and so they said, Atta-Ann. Adda-Ann. They thought that was catchy. Saying it's not barking, that's right. It's not bargaining, that's right. Just like so the C mapping log P, so is the standard deviation of the logarithm of P is the density. P is the density you want to compute, and P T is the density you currently have. That's right. Because of that choice of measure of the density. That's right, exactly. Absolutely. So you change what metric you want, this is got it. Tricky wife, this is going to change. Absolutely. Okay, so in the Resende Mohamed, they took a constant predictor. The first thing you have a student do who wants to implement homotopic continuation is just say, take constant steps. And so that's what they did. They just took this constant predictor, took a worst-case estimate for the step size, and kind of slow. Kind of slow. And so, what we have is now we have this adaptive approach. So, at the beginning, things start off slower, and then you see the slope increasing, it's changing. It's becoming bigger as you get closer to. And you can see the difference between adaptive and this constant one up when you just quickly get to the answer. Okay, so let's go through. Okay, so let's go through some examples. So here's the Lorentz attractor. You pick some parameters and get some data. And so you have X, Y, and Z as your three outputs. And you want to try to recover the values of the parameters that imparts. And we took two different size of error here, just so you can see what is your additional. What is your adaptive step size going to do? Well, when your error is small, it's really hard to approximate it. You're going to have small support, you know, these small areas, it's going to take a while to get there, and so you're going to need many more steps. If you have big error, you have wide places of support, much easier to be confused. There is no probability distribution here, I think. There is no probability distribution here, anyway? That's what there is a probability distribution, and here it is. So you have your three parameters, S, B, and R, and you have a probability distribution there. So this was the homotopy in we want at t equal to 1, and this is the output. And so then you can look in each one of the parameters, and so you see here's the true one. And so you see here's the true one, but once you throw error in there, of course you perturb off the true one and so you can recover the distributions. This one was a unimodal. Nice unimodal ones. So those ones are actually really easy to approximate. And so let's go to something a little harder. So let's go back to the HIV model where you were asking about sort of what's the Sort of what's the map between them. Let's fix some parameters so we make it a little easier. And so now we have three parameters: p1, p2, and then what was the initial value of x2. And so you have a simple z2 operation here. When we fix the parameters, we go from 4 to 2, and you can see the map that maps you between them. So your identifiability degree is 2. So what that means is you're going to have a bimodal distribution at these two points. Okay? And so these are the two points, or so the two bimodal pieces. Without annealing, again, you just press enter and try to let stochastic gradient descent go, and it oftentimes ends up It oftentimes ends up at one of these things. It doesn't really, really work nicely. So, with annealing, i.e., with homotopy continuation, you're able to be able to approximate these things. And so, this plot shows how fast did I move in T, and you see that I move really slow in T until I reach a certain point, and then it's like, okay, now I understand the distribution, I can go really fast. I can go really fast. And then this orange is sort of the step size. And you can kind of see that you can speed up and slow down and speed up and slow down as you move around here. And so you get this nice bimodal distribution from there. And then you can compute things like what's the mean, what's the standard deviation of these bones. Okay, so in the last, say, minute, what I want to tell you about is sort of where do I see this going. And David Kale was supposed to be here, but maybe joining virtually, I'm not sure. The hope was he would come here and we'd finish this paper. Instead, we're going to meet next week and hopefully finish the paper. So, now what we want to do is we want to put these sorts of distributions instead of centered at points, we want to center them along varieties. So the standard Gaussian is centered at a point. Well, what happens if I don't want to center at a point? What happens if I want to center it along this curve? Well, then you can get a probability distribution along this curve. So let's say I want uniform. So let's say I want uniform along this curve. Or if I want some sort of beta distribution along the curve, you can get these. We call these variety normal distributions here. You take the Whitney umbrella, and now you put a normal distribution along the Whitney umbrella, and you get these different thickenings based on sort of how much standard deviation you want to off there. So you can start to see. So you can start to see, sort of, if you look along this line here, you have a little bit, and then as it goes, it gets more and more fuzzy. And so the important point of this is now you have a probability distribution that you can then sample from. So here's a complicated curve, and I want to sample points from that. And so I forget how many points are in each one of these pictures, but once you start sampling enough points with this. Sampling enough points with this probability distribution, you get a really nice picture of that. So that's where we're headed with these probability distributions. Okay, so let me wrap up. Homotopies in the space of probability distributions allow you to sort of be more robust. They're more efficient than other methods, but they're still not. But they're still not efficient. So they're still expensive. So this simple bimodal took about 11 minutes. This Lorenz system took about an hour and 20 minutes. And then this HIV model took about a little over a day. So these are still really, really heavy computations. And you notice this is in one. And you notice this is in one variable and three variables. And so the curse of dimensionality is killing us here. So, how to overcome the curse of dimensionality to be able to compute these distributions? I don't know if there's a way. So, let me stop here.