I'm sure we'll all have a very good time here. And of course, thank you to the Institute for hosting us. Our first thought this morning, so we will start with some mini courses. And first off this morning is by Rob Morris from Institute of Pure and Applied Mathematics, Geo de Janeiro, and he'll talk on bootstrap perpellation and other problems. Rob. Thanks very much. Thanks very much. So, hi, everyone. I'm very sorry I can't be with you in person, but I hope you have a great week. Okay, so my job today is, I guess, to give you some kind of overview of some stuff that's been happening in Bootstrap percolation over the last 10 or 20 or 30 years, and then also maybe suggest some things that people can work on this week. Please, please do interrupt me if I don't explain anything, or if I don't define something, or if you have any. Define something, or if you have any questions or comments. Okay, let's see if I can do this. Okay, so what is bootstrap percolation? So, as we just saw, there's two different communities here that I guess come upstair percolation in two opposite directions. So, for the combinatorics people, then I guess we just think about it having a graph and it's some kind of nice simple process on the graph. And maybe for the probabilists, it's more natural to think of it as we're interested in. Natural to think of it as we're interested in these models from statistical physics, and this is a sort of simpler toy-like monotone version of it, which turns out to be surprisingly useful when studying things. We'll see a couple of examples of that later. Okay, so what is my plan? So I want to talk a bit about our neighbor bootstrap percolation, which I guess everyone is familiar with, but just sort of just to put us all on the same page. And then I want to talk about some general models that were introduced about 10 years ago. That were introduced about 10 years ago. There's been a lot of work been done, and more recently, in D-dimensions, and tell you some things that have been proved. I also want to talk a little bit about some of these applications to statistical physics, and particularly the easing model and kinetic constraint spin models. And a big chunk of the talk at the end is going to be me suggesting some open. Be it's going to be me suggesting some open problems. Um, so I sort of selected a fairly big range of open problems that I quite like. That hopefully, hopefully, some of you will solve this week. Um, is it possible to go full screen a bit more? Sorry? Is it possible to go more full screen? Let me see if I can do that. Is that better? Yep. Okay, great. Okay, great. Okay. Right, okay. So, what is our neighbor bootstrap? So, in general, if you take any graph, take any subset of the vertices, they're infected, infected vertices remain infected forever, and each time step, we infect new vertices, or at least our infected neighbors. I guess everyone already knows this. Right, so just to set some notation. So, if we're working on Z D, then, or any graph, and then the critical probability. Any graph, and the critical probability is just the smallest p such that, well, if you want Zd, the probability of percolation is one. So this is closed bracket to mean the closure of the initial set under the R-neighbor process, the eventually affected vertices. The fundamental theorem of the error, I guess, is this result of Schoenman from 1992, says that, right, if r is bigger than d, then you're Bigger than D, then your critical probability is one, because there exists these little two by two by two by two squares you can't invade. If r is at most d, then your PC is zero. And that's just because somewhere in the infinity of space, you find some giant critical droplets. And that critical droplet so big that you find sites on the side and it manages to grow. Okay, so this is not so easy to prove as I suggested, but that's basically why it's true. Okay, so. Okay, so this suggests that maybe we can ask some finer questions. So, okay, let's suppose instead of working on the infinite grid, we work on this finite chunk of the world, so the torus, the n by n by n by n torus. And the PC is defined the same, except now we should put the probability to be something between 0 and 1, at the point of the critical probability. Right, and so Sherman's theorem tells us when this thing tends to zero. There's only if and only if r is the most d. only if and only if R is the most D. And Isman Lebowitz sort of started the study of these more precise questions, and they proved this beautiful result in the 80s. So in two dimensions, this says the piece, the critical ability is about one over log n. And why is that? It's just saying that this critical droplet you find has size roughly log n. Because to grow by one step, then it costs you basically a constant factor. A constant factor when it's just about the critical size. And so, what's your chance of finding it in n to the d? Well, it should be sort of e to the minus log squared, log n. So this is the point where the expected number gets big. Okay, so just to warn you, so Evailo will tell you much more about this in the rest of the mini-course. And so it's from a combinatorial. From a combinatorics perspective or a probabilistic combinatoric perspective, it's natural to think about this value Pc, the threshold. From a probabilist perspective, it's maybe more natural to think about the critical length of the process on an infinite lattice. So a Vilo may well express things in this way. But you see, this is just the inverse function of the threshold. So if you set n equal to, sorry, p equal to one of a log n. p equal to one over log n to the d minus one, then n is this e to the p to the minus one over d minus one. There's two basically equivalent ways of looking at the same thing. Okay. Okay, so there were two big breakthroughs about 25 years ago. So one of them was by Ander, who determined the precise threshold, so the sharp threshold for percolation. Threshold for percolation in the two-neighbor model in two dimensions. This very surprising number pi squared over 18 turns out to be the correct thing. And for the three name model in three dimensions, Serf and Cirillo made this breakthrough result that showed that actually there it's not polylog n, it's order one over log log n. Essentially, what's happening, this was a conjecture beforehand, but this is. This was a conjecture beforehand, but the upper bound comes from Sherman's result. And essentially, what's happening is you have a three-dimensional droplet, and on the side, you have essentially a two-neighbor process in two dimensions. And so if your droplet is size log n, then your droplet on the side of your droplet is size log of log n. That's where this log log n comes from. Okay. So after these two breakthroughs, then there are a number of following developments. So Serf and Manzo. So, Surf and Manzo extended this method of Surf and Cirrillo to higher dimensions. It turns out that when you look at the R neighbor model, then you get a threshold that's of order one over log log, log, log, log, log, log, log, log n with r minus one logs. So this notation for this sub r minus one is saying the number of times I'm writing log. So it's log, log, log, log, log, log, log. This is for the same reason. Every time you go down one dimension, Same reason, every time you go down one dimension, your critical droplet goes down by a factor, by a vice, to a log of the previous value. And then with Yoshi and Belo, and Urgor, we managed to get the sharp threshold there as well, sort of combining all these techniques. Ah, so in two dimensions, then that even more is known. So Janko and Anda prove the upper bound as a result, and then Ivailo and I prove the lower bound. Evilo and I prove the lower bound, so getting a order of the second term. And things are happening very quickly. So just last week, Evalo and Augusto managed to extend this even further. So they not only determined the correct constant in the second term, but they proved actually something even stronger. But I think maybe that will be in Augusta's talk later on. So they got some very good, good control over this. Very good, good control over this, even control over the third term. So, anyway, so things with the Arlen model are pretty well understood, at least on the Taurus. Okay, okay, so that's just the reminder to everyone of what was happening with the R-Nabour model. Yeah, so I guess there are no questions, but please don't be shy. Okay, so now we started to go to something which perhaps So now we start to go to something which perhaps people are less familiar with, which is a vast generalization of our neighbor bootstrap pertillation that was introduced by Baylor and by Paul Smith and by Andrew Rosell about 10 years ago. So what's the model? So in the R-neighbor model, then there's a set of neighboring sets that infect you. Sets that infect you, which are all the sets of subsets of your nearest neighbors of size R. If any R of your nearest neighbors are affected, you become infected. This can replace that, that family, with an arbitrary finite collection of finite sets. Okay, so in step T, so P plus one, you get infected if your X, if you can see me doing this, if one of these sets shifted by U is entirely infected. Is entirely infected at the previous step. This is essentially a completely arbitrary monotone, monotone cellular automaton. Okay, so when I first heard the model, I mean, my reaction was that there's no way you could prove anything at all about this. It's completely impossible. It's just far, far too general. And the shocking thing about this paper was that actually, you can. Actually, you can. So, the correct level of generality to look at things. So, okay, so they proposed this partition. So, they proved that one of these families, what they call supercritical families, I'll say what it is in just a minute, the threshold is polynomial. So, polynomial in n. There's another set of families that we call critical to have polylogarithmic thresholds, so, like the two-neighbor model. And they said that they conjectured that all other families, which they call subcritical, have thresholds bounded away from zero. So a very different behavior. This is proved by Paul and Baylor and Michal and Paul. This was about 10 years ago. Okay, okay, so let me talk just a tiny bit about this result so we all kind of understand what's going on. Okay, so this is the theorem. This is the theorem. So either U is supercritical and has a polynomial threshold, or it's critical and has a polylogarithmic threshold, or it's subcritical and has a non-trivial threshold, so even on the infinite lattice. Okay, should be perhaps a very surprising result. There's only these three different kinds of behavior possible. Okay, so what are these three things? These supercritical, critical. These three things, these supercritical, critical, and subcritical families. Okay, so to define them, we need to think about the set of stable directions of a family. Okay, so what is this? It's a subset of a circle, so a set of directions in two dimensions. And okay, in the direction you, let's think about the half space. So you think about everything on one side being infected and everything on the other side not being infected. You ask, you run the process starting from this. Ask you, run the process starting from this configuration, what happens? And there's only two things that can happen: either nothing happens, or everyone gets infected. Okay, and it just depends on whether there's one of your sets of your family inside this half space. Okay, so okay, let's write C for the collection of open semicircles in S1, in the circle. So, the definition is: if there exists an open semicircle with no stable directions, then you're supercritical. The reason is because there's an open semicircle, you can grow very easily in the direction of the center of that semicircle. You can grow without any help from outside, as long as your critical droplet is big enough. Your critical, if that's not true, If that's not true, so you have a stable direction in every open semicircle, but there's one open semicircle which only has a finite number of stable directions. Then you can grow in that direction, but only with help from outside. So you need to keep, as you're growing in that direction, you need to keep finding some infections in order to help you grow sideways. This leads to polylogarithmic. So just like in the two-neighbor model. So for a supercritical model, you should think like the one-neighbor model. Neighbor model, a critical family should think of a two-neighbor model in two dimensions, and subcritical otherwise, meaning every open semicircle has infinite intersection. Sorry, let me be able to do this, have I? Okay, oops. Okay, so those are the three. So it's incredibly simple and elegant trichotomy. Trichotomy. And the theorem, just to say it again, says the following: for any two-dimensional update family, either you have an unstable open semicircle, in which case you're supercritical and you have polynomial critical probability, or every open semicircle has at least one stable direction, but the number of stable directions is finite, sorry, but there exists an open semicircle with a finite number of stable directions. Of stable directions, so you're polylogarithmic, or every semicircle contains an interval, so it turns out that if you have an infinite number, you also contain an interval of stable directions, in which case you behave more like classical percolation. So, you end up with some interesting, so interesting family of percolation models which have this long-range dependence. Okay, so this is the situation in two dimensions. And it turns out, so with Bayla and Ugo and Paul, So with Bela and Ugo and Paul, we managed to actually determine the, don't say much more, so determine the order of the critical probability for critical families. So there's three sets of questions. So three different sort of families and models that you could ask more detailed questions about. So each of them is interesting. So the subcritical ones look more like classical percolation. So for the probabilists who are lists in in uh who are who are there maybe maybe there are those the questions interest you most from uh from a from a combatorial point of view or perhaps also from a from a um well from a from a purely combinatorial view perhaps the supercritical seem most interesting but we'll see later that there's uh they're actually while they seem like they should be very easy they're perhaps the most difficult to study the critical models are sort of where the combinatorics and probability meets um and perhaps the the so those are things that uh the so those are things that uh that usually need ideas from well perhaps needed from both directions or perhaps they have applications in in uh in both anyway so we study the critical ones and we manage to determine the the the the pc up to a constant factor so either you're balanced i'll say something about what those in a second uh and no more questions No, okay. Or you unbalance and this extra extra polylog log term. Okay. Okay, so rather than define these things, which takes a, take is a little bit messy, let me just give you some examples so you get a feel for what's going on. So, okay, so in the two-namer model, so what are all these definitions I've been giving? The two-name model means that your U is just all subsets of these. Is just all subsets of these four nearest neighbors of size two. Your stable set is just these four points. So those four directions you don't grow, but every other direction you can grow. And each of those has a difficulty, which means basically how many extra sites you need on the side of a droplet in order to grow by one. And all these four directions don't need one extra site to grow. Okay? Extra site to grow. Okay, so this is a balanced family because so the easiest direction, sorry, there's yeah, supposed to say one unbalanced family is in a second, but you can see this shouldn't probably be a balanced family. And alpha is one, because that's basically the most difficult direction. Okay, so alpha is one because there exists an open semicircle that you can grow in, in which every stable direction has difficulty at most. Every stable direction has difficulty at most one. Okay, here's another very natural model that's been well studied. So here's a new neighborhood. We're going to consider all subsets of this neighborhood of size three. And once again, it's easy to see that there's only four stable directions, these four axis parallel axis directions. But now some of the directions But now, some of the directions are easier to grow in than others. If you want to grow horizontally, you already have two infected neighbors to your left, say, so you need one more infected neighbor to your right to get the three you need to grow. If you want to grow vertically, on the other hand, then it's more difficult. You only get one for free, so you need two more. Okay, so this family is unbalanced. Alpha is still one. So why is alpha one? Because So, why is alpha one? Because there exists an open semicircle, either to the left or to the right, in which there's only the most difficult direction has difficulty one. Okay, so once an open semicircle, not a closed semicircle. But it's unbalanced because there does not exist a closed semicircle with the same property. Okay, so you're balanced if you can also find a closed semicircle. Semicircle with difficulty, just alpha, and you unbalance if not. And you unbalance, there are always these two opposite directions that are more difficult to grow in. Okay, and so I want to do one more model, the Duate model, particularly interesting model. So this is the stable set. So the model is you're infected if you have any two neighbors of this neighborhood of size three. And now it's impossible to go left. And now it's impossible to go left. You just, you just, you, you, you, you can't do it. But, okay, not impossible, but it's very difficult. So every direction on the left is stable. There's only one stable direction on the right. And once again, this alpha is one because there's this open semicircle of difficulty one, and fermi is unbalanced because there's no closed semicircle of difficulty one. Okay, so this basically. Okay, so this basically basically tells you what this alpha is. Okay, so it tells you whether you're balanced or unbalanced, and it tells you what alpha is. Ah, you should perhaps say, so you might be wondering about sharp thresholds. So sharp thresholds, please. Sorry, wasn't the for critical, the description was that every single circle contains finite unanimous. Circle contains finitely many stable functions. Sorry, so the yeah, thank you. So maybe I maybe I didn't quite say it correctly. You're critical if every open semicircle contains at least one stable direction, and there exists an open semicircle that contains only finitely many. Right, so in this case, yeah, this is a good example of this. So there exists an open semicircle, so you can. Exists an open semicircle, so you can grow to the right, you can't grow to the left, but it's enough to just be able to grow to the right. And what happens is you sort of grow to the right, and then you go up a bit, and then you go more to the right, you go up a bit, and more to the right. And because you're on the torus, you eventually wrap around, so you don't need to grow to the left. Yeah, thank you. This is very, it's a very good, yeah, like it's an important district. Great. Great. Okay. Okay, so these are the balanced and unbalanced models, and this is their alpha. An important open question, which perhaps some of you might want to think about this week, is when you can determine a sharp threshold. So the people to talk to about that are Evailo and Adam. Are Ivailo and Anda? And I mean, I guess Ugo is not there, but so Ugo and Evailo have a recent paper on the topic. But there's still lots of interesting open questions, even in two dimensions. Okay, so two dimensions were sort of fairly satisfied. What about higher dimensions? And so fairly recently, meaning a couple of years ago, Fairly recently, meaning a couple of years ago, we put an archive three long papers which basically solve this problem. So with Paul and Paul and Baylor. So here's what happens. So once again, you can either be supercritical or critical or subcritical. And I'll say what that means in a second. If you're supercritical, then you have polynomial threshold. What's supercritical. Threshold. What supercritical basically has to mean is there's some finite set, some sort of bounded size set that then just grows and infects everybody. You don't need any help afterwards. It's not exactly what it means, but it's sort of what you should think. I'll say what it means in a second. You're subcritical if you act like regular percolation. So you can trap things in small areas, maybe to stop growing. Small areas, may just stop growing. And you're critical otherwise. But this time, critical comes in D minus one different flavours, which it kind of had to, because critical includes all of the R neighbor models. And we remember from, or perhaps we don't remember, but from the results of Cerf and Manzo, that two neighbor models have threshold one of a log n. one of a log n up to some up to some power so poly log three neighbor model has uh uh has threshold poly log log the four neighbor model has threshold poly log log log and so on so the r neighbor model has satisfies this property with r equals r and what this result is essentially saying is very roughly speaking Very roughly speaking, there are no other possible behaviors. So every single d-dimensional update family has to look, at least very roughly, like one of the R-neighbor models. Up to this exponent, which is not determined by this statement. Okay. So what do things mean? What do things mean? So, u is supercritical. So, now we have a stable direction, sorry, a stable family, a family of stable directions. They're directions in d-dimensional space. So they're points on the d minus one, the d minus one dimensional sphere. If there exists an open hemisphere in this sphere, which has no stable directions, then you're supercritical. And it basically means you can grow in that direction. means you can grow in that direction without any help. You're subcritical if every open hemisphere contains an open set in S, or a set of full dimension. It has some non-zero measure. That means you're basically blocked in every direction. Any direction you try to grow, there's some set of stable directions that block you. And you're critical otherwise. New critical otherwise. Okay. And what is this R? This R is some function of the stable set that's defined sort of iteratively, inductively. So I won't give the definition, but you can sort of calculate it without too much difficulty from the stable set. Okay. Okay, and here's the sort of slightly shocking thing that you'll hear about later this week from Paul: is that, okay, so we. Okay, so we determined this up to some constant factor in the exponent. Surely we should try to determine the exponent. No, in general, you cannot. So in general, this exponent is uncomputable. You can sort of encode an arbitrary Turing machine as one of these problems. Only when r is less than d. When r equals d, then we conjecture that you should be able to determine that. That you should be able to determine this. So, the exponent should be computable. So, one of the biggest open problems left is to determine the correct exponent of one over log, log, log, log, log n in the threshold for when, sorry, when r is d. Okay. Okay, so there are many open problems. Um, uh, yeah, so I'm basically, I guess I'm halfway through now. I'm not sure what time it is, actually. Halfway through now. I'm not sure what time it is actually. I hate my phone. Ah, perfect. So, yeah, please do ask questions about this. I'm going to now leave general models behind and talk about open problems. But if anyone has any questions about these general models, this is a good time to ask. No? Okay, so there are many open problems in two dimensions. many open problems and two dimensions and trying to understand sort of certain families of three-dimensional questions. So as you say, Professor, that the yeah, so the problem with this is the supercritical families, these supercritical families that have this uncomputability problem. If one restricts in certain ways, then there are still interesting things to ask. So for example, one could restrict to families that only have To families that only have subsets of the axes, in which case it seems very likely that the version is computable. But it seems already to be quite a difficult, complicated question. So Daniel Blanquisette has some partial work on this and others. Okay. Okay, so now the talk will change quite a bit. So anyone who's fallen asleep or is lost can wake up. Lost can wake up and we start again afresh. So, here's some open problems. So, I just picked out some problems that I particularly like, and I tried to make a fairly broad sort of give people ideas of what you can discuss. Okay, so here's a question. So all of this was being done in D dimensions, but with n going to infinity. So, for d fixed and n very large, right? Okay, what if we change that around? Right, so okay, what if we what if we change that around? We're going to still work on a grid, but let's let D be large and n be perhaps not so large. The extreme version and so following up on some work by Yoji and Beyla, Yoji and Beyler and I managed to determine the sharp threshold for two-neighbor, the two-neighbor bootstrap process on the hyperqd. QD. Okay, so two-neighbor phi. What about the three-neighbor process on QD? And that's completely open. So we have absolute, I mean, sorry, we have no idea. So we have a conjecture, but we have basically no good lower bound on this process. So for the comaturics people, this seems like People, this seems like a very natural thing to attempt to understand. Sorry? What is the lambda? Sorry, some constant I don't want to write down. It's defined by some sum. So the sum of a bunch of stuff equals the solution to some equation. Yeah. Yeah. Yeah, but it's just some constant. Yeah. But yeah, but so for the two-neighbor problem, then we can control this extremely well. But for the three-neighbor, I mean, I'm not asking for anything anywhere near as accurate as this, right? Just say for the three-neighbor, can you show it's roughly e to the minus d to the quarter, right? And I have no bounds at all, like nothing. Like nothing. Okay. So I think this is a very nice question, and perhaps it's something that could potentially be solved in a week. Okay, here's another related question. So, okay, let's think not about n equals 2, but still n is large, but d is now growing as well. Okay, so what do we do? Okay, so what do we prove? So if d is much bigger than log n, then essentially you already look like the hypercube. So understanding the hypercube actually allows you to understand the two-neighbor model even when n is almost sort of exponential in d. So that's somewhat surprising. Okay, so this hypercube-like behavior actually appears pretty quickly as d is growing. Okay, so okay, that's fine for two-neighbor. What about the majority? Another natural end of the spectrum. What about the D-neighbor process? Well, if you just work out what Sherman's proof gives you, which is the upper bound in the result we saw before, then you need, right, your PC is like one over log log, log log, log, log, log, log, log n times. n times. Okay, turn that around. You need n to be bigger than a tower of twos of height d. If n is much bigger than a tower of twos of height d, then your PC is zero, like in Sherman's theorem. Okay, but what if n is smaller? Well, we managed to prove that if n is smaller than something like 2 to the 2 to the root d, then P C is actually much closer to a half. So you need half of your neighbors to be infected. Half of your neighbors to be infected, then you perhaps should need almost half of them to be infected at the beginning. Okay, so here's the open question: what's the correct critical length? How large does N have to be for PC to be smaller than a half, to 10 to 0? How high is this tower of twos? Yeah, I remember thinking about this at some point. I think the answer is that you should need. I think the answer is that you should need a pretty high tower, maybe even linear in D. But yeah, I don't know if I have a really strong, strong feeling about it. This seems like another sort of very, very fundamental question about that we have very little understanding of, right? These bounds are extremely, extremely far apart. Question. And so the heart here, where does that come from? Is that something just because I've Not somehow just because of how you define PC, right? So maybe, yeah, about the high P cube or something. So suppose your P is smaller than a half, right? And suppose your N is maybe not 2 to the root D, maybe your N is smaller than, is sub-exponential in D, right? Then you're just unlikely to have any vertices that have more than D infected neighbors. more than d infected neighbors at the start. So this result is basically trivial if you take n smaller than two to the today to be two to the little O D, right? So it's by Chernoff or whatever, and a union bound, no one will be affected. The process will stop immediately. So the content of this result is pushing this 2 to the D up to 2 to the 2 to the root D, which is saying, okay, Just saying, okay, even though lots of guys will be affected at the start, the process stops pretty quickly. Does it make sense? Because every vertex has two D neighbors. And so if your P is a half, then that's when you have roughly D each at the start. Does it make sense? I hope I'm not talking nonsense. Good, great. Great. Yeah, so in the top half of this result, the process stops extremely quickly. To get this R of twos, then the process has to go on extremely long time. You have to somehow have this critical droplet that grows via things growing on the side, they grow on the side, they grow on the side. So we understand that if D is fixed, but we don't really understand it at all when D is growing at any kind of reasonable speed. Okay, let me give a um so that was uh all kind of common hetericsy. Let me give you an application of what I just said to uh to something in uh more in probability theory. Okay, so let's think about the easing model, let's look at the kinetic ease, the glaud dynamics of the easing model on z to the d. And let's think zero temperature. Okay, so you could also allow, it also makes sense to allow a sort of a small positive temperature, but uh but let's Temperature, but let's stick to zero temperature. So, what does that mean? For people who don't think about these models so much, it just means each vertex has a random clock, has a random exponential clock. When it rings, your vertex wakes up and forgets what its state was. Its state was either plus or minus. It looks around its neighbors. It says, okay, it lets your neighbors vote. So it just says, have I got more plus neighbors or minus neighbors? If you've got more plus neighbours, you become plus. If you've got more minus neighbors, you become minus. If you have more minus maybe you become minus. You have equal numbers of both, then you pick randomly. Okay, and then you run this process. Okay. So is the question. So suppose you start out with people being plus with probability p all independently. Do you fixate at all plus or all minus? Or do you kind of fluctuate forever? But does each vertex swap values infinitely many times? Okay. Okay. Okay, so let's define this critical probability to be the smallest P. Yep. What's happening if it is tie? If it's a tie, then yeah. So I want to say you just pick it random. So you don't care what you were before. You just independently choose probability half, plus or minus. And probably a half, not probability a half. Yeah, sorry. Yeah, sorry, there. I mean, you can imagine immediately several variants, which are also very interesting, but I just want to stick with probability of health. Fixed state means just that it won't change anymore. Sorry? Fixed state means that it doesn't change anymore. Fixate means, yeah, sorry, exactly. Thank you. So if you fixate means you only, so a vertex fixates, if it only changes state a finite number of times. So and to fix it at plus means. So, and to fix it at plus means you end up at plus. Okay, so here's a beautiful folklore conjecture. So for this event, you don't want every vertex to fix it at the same time. Right. Exactly. Exactly. Each vertex fixates, but at any finite time, not every vertex will yet have fixated. Will yet have fixated. Thanks, exactly. Okay, so here's the conjecture. The conjecture is this PC is a half. This is a sort of a famous folklore conjecture that any P larger than a half will cause fixation. It turns out if P equals a half, then in two dimensions, you do not have fixation. Every vertex flipped an infinite number of times. Flipped significantly a number of times for three or more dimensions that, unless I'm behind times, is open. It's an open problem. Okay, so this beautiful open problem seems to be extremely difficult, but very much worth thinking about. Okay, so what's this got to do with booster percolation? Well, booster percolation is based. Well, booster regulation is basically a monotone Bosnian Easy model. And Fonci, Sherman, and Sidrovisius managed to use this fact to prove not that the PC is a half, but at least that PC is strictly less than one. This is already a highly non-trivial result, just showing that PC is less than one. They used a very clever multi-scale argument together with Eisermann and Lebritz's bound on the two-neighbor process. On two on the two-neighbor process. And a few years later, so I managed to show that as d tends to infinity, actually this P C tends to a half. And this is just a modification of the method of Fonti's German Sidovicius together with these results with Yoshi and Bayla about majority bootstrap pertillation. Majority bootstrap pertillation in high dimensions. If you basically swap the first step of their argument for, instead of using Ismail-Lebowitz, you use our results, then with a bit of work, then you get this result. So these questions, which seem sort of, which perhaps seem a bit combinatorial to the probabilists, actually do have these nice applications to Applications to things you're perhaps interested in. Okay. Okay. Okay. So here's a generalization of this. So this was all for the R, this is for the sort of the D neighbor process or the two neighbor process on Z D. Again, we ask the same thing for an arbitrary update family U. Okay, so define the U dynamics to just be instead, so it's Instead, so it's sort of the natural thing. You have a clock when it wakes up, then you look around. And if you have a family, so if one of your sets X in U is entirely plus, you want to become plus. If one of the sets is entirely minus, you want to become minus. And then you can decide exactly how to define these dynamics. Perhaps you can have two different clocks, a plus clock and a minus clock. But anyway, so I conjectured that for sort of a natural version. I conjectured that for sort of any natural version of this process, if u is critical, then PC should still be less than one. Okay, so this should be true for any critical d-dimensional update family. And this is open. So Daniel Blanquiset, who is my PhD student, he's participating online, has the best results on this. So if anyone's interested, then he's a good person to talk to. There seems To. There seems to be a challenging missing step in this, which is a very interesting open problem. Yeah, and here's perhaps an easier version of this or a related problem. So maybe if D is one, then PC should be one. This is proved for the standard model by Aratia a long time ago. But yeah, so I conjectured that this should be true for. So, I conjectured that this should be true for every one-dimensional panel. Okay. Okay, so there's a bunch of questions. Ah, here's another direction which has been studied by several people who are in the room. Okay, so what is polluted bootstrap percolation? So let's take z to the d again. Let's remove each vertex independently with probability q. So let's kill a bunch of random. So let's kill a bunch of random vertices. Okay, so all the results so far have been about this very homogeneous lattice. Okay, we should start thinking about, maybe we're ready to start thinking about things that are less homogeneous, that have this kind of have some pollution in them. Okay, so what should the PC now be? So suppose let's go back to our neighbor bootstrap on this supercritical percolation cluster. Percolation cluster. Okay, and we can't hope to affect everybody, but maybe you can hope to get an infinite component. This was first studied by Yanko and Elaine MacDonald about more than 25 years ago. They studied the two-neighbor process in two dimensions. They showed that as Q tends to zero, then the PC that you need is... The P C that you need is scales like square root of q. It's quite an intricate argument to prove this. Anyway, so I, 20 years later, started thinking about this and I came with this conjecture that I thought about quite a long time, for quite a long time, maybe around 2010 or something, and made no progress with at all. But sorry, I Sorry, I believe it quite a lot of the time. I'm not completely certain I believe it anymore. But anyway, his conjecture is that for any R strictly less than D, then PC is not a nice function like of order root Q, like in two dimensions. It's actually zero. So as long as Q is sufficiently small, then arbitrarily small P will be enough. Will be enough. That should be should look a bit surprising at first sight. So if r equals d, it's not too difficult to convince oneself that this won't be true, that you really will have some function of q, like Janko and Elaine found. But yeah, as soon as r is d minus one, I conjectured that the PC is zero. And this is known. And this is known, it was proved just a few years ago by Janko and Anda in sort of r equals two. So I've stated for three dimensions that for D larger, it follows automatically. Yeah, they proved that. So this is sort of the main step, the main result, that if you're in three dimensions, the two-neighbor model has PC0 for all sufficiently small q. So also, so Janko and Andrew. So, Janko and Ander and David gave bounds on this on PC for the three-native process in Z-Cubed, but were unable to determine the correct threshold. This is another beautiful and very interesting question. So I think these are two excellent directions, r equals d and r smaller than d. Yeah, and I know there are several other people who are there who I've talked to about this problem. Who I've talked to about this problem. So, yeah, you should find each other if you're interested. Okay. Okay. Ah, so let me tell you another extremely interesting application, which several people, several people there, have worked on. So these things are called kinetically constrained spin models, I mentioned at the beginning. So, okay, so this is a model. So, okay, so this is a model of the cooling, the formation of glass by cooling some viscous liquid. So, there's an attempt to model this liquid-glass transition. Okay, so what is the model? So, each site has a clock, like in the easy model. So, when the clock rings, then it resamples itself. But now, But now, sorry, it resamples itself only if one of the neighboring sets, so you have some family U, if some X in U is entirely infected, so they often call it empty, then you resample yourself. But unlike in these in models, so Yoshi's question is very relevant here, you don't resample with probability half, you resample with the original probability. Okay, so you start out with. Okay, so you start out with a very sparse set of infected sites or empty sites. And then, if one of you have a suitable neighborhood, then when your clock rings, you can resample yourself, but according to this sort of very sparse probability measure. But it says if you start off being independently infected with probability P, then at any future time, you're also infected independently with probability P. However, at different times, However, at different times, you're correlated. So, another way to think about this, which I like to think about it, is we're running a biased random walk on all of the percolating configurations in the U bootstrap process. So we're given this random set of infected sites. And in U-bootstrap, we would just, if someone has an infected neighborhood, we would infect it. Infected neighborhood would infect it. Here we certainly, those guys are allowed to turn themselves on or off. So we're doing this kind of random walk on the configurations. The question is basically how long does it take this random walk to mix? What's the relaxation time of this random walk, this Markov chain? Okay, so just give one particular sort of simple and very beautiful, well simple to define, but surprisingly complex. But surprisingly complex model, an East model. So it's a one-dimensional model, and U is just the family, the guy to your left. This is already a very sort of interesting model to look at. So the combinatoricists in the audience can look at this paper by Chung Dakeris and Graham from about 25 years ago called Combinatorics V's Model. Right, and what I want to tell you about, so in recent years, sort of paralleling these developments in bootstrap percolation. These developments in bootstrap percolation, there have been some very exciting breakthroughs by Availo, by Lomaresch, by Fabio Martinelli and Cristina Toninelli. So let me just tell you, I won't tell you all of the results, but just let me tell you a couple of them. Okay, so here's a thing you might observe. The time at which the origin gets infected in this process, let's just stick to two dimensions. Okay, so some random variable. So here's what they proved. They proved that there's these two different possible behaviors, these two sort of very broadly speaking both behaviors, which refine what happens in bootstrap percolation. So this alpha is the same alpha as in the theorem I told you much earlier for U bootstrap percolation. We define this alpha by the open semicircle. Open semicircle, it's the easiest, the most difficult direction, open semicircle, that's alpha. If you have a finite number of stable directions, then the correct behavior is still determined by this alpha, up to some polylog. But if you have an infinite number of stable directions, then suddenly things become much more difficult, and the experiment becomes two alpha. This is a beautiful result proved in two papers by In two papers by different subsets of these authors. He said, even more recently, Sora Valo and Law have managed to go even further and determine, they've categorized exactly which families have which power of log. There are seven different possible behaviors. So two different kinds when you have infinite number and five different kinds when you have a finite number. So it can be a power of, but the power of log can be zero, one, two, three, four, and you can. Three, four, and you can also have a log log as well, depending on the staple set. So this is extremely, extremely difficult result. So using a lot of the results and techniques from booster population, adding a huge number of extra beautiful and difficult techniques. So if anyone is interested in this, then these are the people to talk to. Okay, so I'm basically done. So here's just a few more ideas, perhaps for things that one could study. So people have studied booster percentilation in lots of different places, but a very natural one was with GMP, random regular graphs, Yoshi and Boris Patel. So random hypergraphs we've been working on recently, inhomogeneous random graphs, trees of various kinds. Various kinds, Cayley graphs of groups, some particular non-abelian groups. I think, so maybe Gabo is going to talk about this later in the week. I'm not sure. Random geometric graphs seem like a very natural thing to work on. So somewhat related to polluted bootstrap. So we sort of, I mean, we're motivated by these models and statistical physics. And so it makes sense to work in some kind of geometric setting. It's much easier when you work in a homogeneous setting where every In a homogeneous setting where every vertex is the same. And so, really, perhaps the next frontier is to understand things in sort of more randomized settings. So, polluted bootstrap is one important direction in this way, in a related thing. So, one could think of perhaps bootstrap percolation on a random Voronoi tiling or something. It seems like a very nice and natural question. I thought about it at some point and didn't make much progress, but it seems extremely natural. Natural. And then so graph bootstrap percolation, which some of you have worked on as well, it's another sort of interesting direction. Right. And yeah, there'll be more coming soon. Anyway, so thanks very much and have a great week. Any questions for Rob? Any questions for Rob together with the talk? What's the picture of? This is the Duate model stopped halfway through. This is thanks to made by Paul Smith. This is usually one of our papers. What's the other picture of? The other picture. The other picture is Paul and I discussing bootstrap percolation about 10 years ago deep in conversation about bootstrap in higher dimensions. Those who have been to Rio have have some idea. Sorry, go ahead. Not a question, but a comment just among the many patterns. Just among the many fascinating things that you talk about, right near the beginning when you talk about the second order term, where you have the sharp physical, you have the visual routine, you have this second order term very well understood. I mean, what one interesting thing is. Here, of course, is that the size of the window where you transition from probability moving n zero to n one is much much smaller than the second or the term. So and that's for sort of quite a bunch of reasons. Right, absolutely. Yeah, so it has to has to be a most one over log n squared. I believe that if Viola Gustu managed to get this the managed to get this the third term is like log n to the five over three I think if I if I managed to back it out of their their statement correctly um yeah so I haven't I have my friend I haven't read the paper yet that came out last week but yeah so they're perhaps the yeah the people to talk to about this yeah so luckily both both are both are present Augusta's waving at you I think It's not expected to be shut for the certain one I was coming. I was just coming down the window. People might, if you're not familiar with it, people might be interested to know that the window where you came from year zero to day one is much smaller than the second one at terms. So like if you just take your parameter to be equal with the hyperphone every. Parameter to be equal with the type of AD, then you're web on one side of it. Right. So, um, so I don't know the latest things. So it just follows in the general machinery that the window is size at most one over log n squared, right? It's always at most PC over log n, if I'm correct. I don't know if there's any kind of how improves a lower. Of how improves the lower bound on the size of the window. Is the window off-size whenever login squared? Have you got any idea? Yeah, I don't know where the window goes. So, Rob, if I remember well, I think there was maybe a log log that was our log log that is not known. So, I think that was just for the window in terms of P, for the window in terms of M, it was a bit different. It was a bit different from what it was in the country financially paper. So it really depends. But it should be basically what we said. To what extent people know these things, but higher dimensions? I don't know, yeah, essentially nothing for higher dimensions, I think. Yeah, so for the two-neighbour model, then one could probably. then one could probably can probably push through similar techniques i would imagine i'm not i'm not sure whether uh how much uh valo and i could have thought about that um uh but yeah for r at least three i think uh there's an upper bound by andrea but uh but yeah essentially nothing from below yeah i think it's another yeah very interesting and and probably a very challenging question Any more questions or comments? Okay, well, let's thank Rob again for thank you, Rob. Thanks. 