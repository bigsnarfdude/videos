So my talk is mostly focusing on applications of graph neural networks in neuroimaging and some work that I did more recently with PhD students from a few different universities actually. So the collaborators are from the University of Queensland in Australia, EPFL in Switzerland and also And also the Alenturing Institute and University of Southampton in the UK. And that is building on past work from the late days of my PhD. So at the high level, what I'm going to talk about is how we can estimate brain networks from functional MRI data and how we can use this data to perform a set. Data to perform semi-supervised transductive learning with graph neural networks. And then I'm going to introduce some fairness considerations that are relevant to health applications and in particular neuroimaging applications and how certain decisions that we make about the graph construction in population graphs, what kind of implications those have with respect to fairness considerations. Fairness considerations. Given that it's the first talk of the workshop, I also kept some very kind of introductory concepts. So apologies to those of you that are already very familiar with those. But just to make sure that everyone is on the same page. First of all, like an important distinction between classes of graphs is whether these are natural, so whether These are natural, so whether we observe them, their structure in like the data inherently lies on this graph structure that we observe, and we don't have to make any explicit decisions as to how to construct a graph. And these natural graphs emerge in social networks, like who follows whom, for example, in biological networks, as well as communication and power networks. Power networks. The second class, the constructed graphs, are more the focus of functional MRI and neuroimaging studies. So these graphs are constructed from the data and the computational time is normally quadratic with respect to the number of nodes available. And this is quite tricky to actually. Tricky to actually construct those graphs as there's no universal recipe on how to do so. And there are only some common good practices that we can follow. In terms of like the basics that we need to fully define a graph, we need a set of vertices or nodes. The cardinality of the graph is the number of nodes. Then we have a set of edges E. These can be either And this can be either this can correspond to an undirected network if Eij, as you can see at the bottom, is equal to EJy for nodes Vi and Vj, or if we have a directed network, then those edges are not symmetric. And this also characterizes the structure of the similarity or adjusted C matrix W, which will be. Matrix W, which will be symmetric for an undirected network and it won't be symmetric for a directed network. Then there's also another distinction between binary graphs where our edges can only take two values, zero and one, and more generic graphs that can take real values on the edges or even hold feature vectors if we want to generalize even more. Generalize even more. So, why are we interested now in looking at the brain from a network perspective? And this was a question that was pestering me throughout my PhD. And one of the main reasons is that cognition is a network phenomenon. So many of the cognitive functions that we perform arise from interactions between functional units in the brain. So there are certain regions that So, there are certain regions that specialize in certain functions, and by coordinating between those regions, these give rise to more and more complex functions. Another reason why looking at the brain from a network perspective is interesting is because for several disorders, neurodevelopmental and neuropsychiatric, there is no physical trace. So, there's nothing that we can observe in an MRI scan, but there's only change. But there's only changes in the wiring or the strength of the connections, either structural or functional. And those are more subtle. Now the question is, how do we arrive to a network representation of the brain given the raw imaging data? So we normally start by parcelating the brain into a set of functionally coherent regions. So this can be So, this can be based on anatomical structures. There are soci and jari on the cortex of the brain that can delineate functional anatomically functional coherent regions. And there is an alternative way of parcellating the brain, and that is data-driven. So, brain parcellation is a whole field in itself. In itself, and the problem of procellation is equivalent to the problem of clustering. And there's various ways of evaluating the quality of these pastellations. But more often than not, they are used to reduce the dimensionality of the signal that we capture on the brain cortex. Then we have some imaging data. If this can be structural imaging data, like for example, Imaging data, like, for example, capturing the white matter tracts with diffusion MRI, or we can obtain some electrophysiological signals like time series data with EEG or functional MRI. Then, by either counting the number of neuronal streamlines that connect to brain regions or by looking at correlations. Looking at correlations between the time series obtained with electrophysiological signals, we can construct a structural or functional brain network respectively that is characterized by an adjacency matrix. Then each of these regions that are defined by the brain pastellation corresponds to a brain node, and each of the connections and elements of the adjacency matrix. Elements of the adjacency matrix corresponds to the edges of our graph. And we can perform either traditional network analysis or more complex machine learning techniques. Now, moving on to the applications, we explored a quite complex data set that has been acquired by 20 different imaging sites. Most of them are. Most of them are based in the US. And this is called the ABI data set. And it includes individuals that are neurotypical and individuals that are neurodiverse as in they have been diagnosed with autism spectrum disorder. So you can see in this matrix that the size of the Of the population in each of these emerging sites is very different. So we have some sites like NYU, for example, here that contributes more than 100 participants. And there are other sites like CMU that have only acquired data for 11 participants. So if we wanted to develop a method that is A method that is robust and can be used across different imaging sites, we should be able to learn from all of these imaging data and at the same time generalize to new unseen sites. We wouldn't want to build an algorithm that only works on a particular scanner or on a particular imaging site. And this setting is actually quite challenging because. Quite challenging because fMRI data itself is quite noisy. And originally, when we tried to predict the imaging sites from the fMRI data, we were able to get quite high accuracy in the order of 80%, which means that there's a lot of information that is scanner-specific that is still present in the data after various layers of. Layers of data cleaning and filtering. Now, the analysis pipeline for this data, steps one and two I already referred to, but these are different essentially anatomical parcelations on the first, sorry, Harvard-Oxford is anatomical parcellation, and then there's other parcellations like ICA, k-means. CA k-means that are based on the data from a large population of healthy individuals. So in terms of the setting, something that is particular to the Abaya dataset is this multi-sites aspect. So in order to make sure that we test for reproducibility and we ensure that the And we ensure that the algorithm is not only accurate for a certain set of sites and not for others, or that it doesn't generalize. Prior studies, like this one published in NeuroImage, used two different settings. The intrasite cross-validation setting, where a certain percentage of each site would be visible at training, both at training and a test time. And there was a second setting, the interside cross. Second setting, the intersite cross-validation, where a particular site as a whole was left out for validation and never seen during training. And they explored mostly simpler methods for classification like SVC and ridge classifier, where the data, the data from the adjustancy matrix was basically. Matrix was basically vectorized with the naive embedding and then fed to these classifiers for prediction. What we observed when we started working with this data was that if we focused within the same site and looked at the distances between the connectivity matrices for controls and individuals that were characterized as neural. That were characterized as neurodiverse and compared those distances to the red box plots here that correspond to connectivity networks of individuals that belong to different classes. There was a cleaner kind of separation within a single site, but as soon as we started mixing individuals across sites, then those differences were kind of vanishing. So, it was very clear that similarity between brain connectivity networks was affected by the acquisition sites, as I mentioned earlier. So, our objective was to robustly classify diseased and healthy individuals from the imaging information, while at the same time accounting for imaging and phenotypic data like the acquisition site, sex, age, and so on. Age and so on. So, in order to capture this information, we wanted to leverage methods from graph representation learning that were coming up, that were emerging at the time and were showing very promising results in kind of transactive setting. So, what we did is we constructed a population graph where each individual was Where each individual was represented by a node in this graph, and they were associated with a feature vector that's corresponding to their imaging data. So, in the case of functional connectivity networks, we vectorize essentially the upper triangular part of the similarity matrix. And then we use the phenotypic data that often is abundant in this kind of Is abundant in this kind of studies and is often neglected in more standard techniques that are only looking at the imaging information. So we use the sphenotypic data to connect nodes with each other with and the strength of the connections was specified by whether they were corresponding to individuals of similar age, of the same sex, and also a weighted Weighted by the similarity between the feature vectors. So we applied this to two different settings, two different applications and predictive tasks. One was autism spectrum disorder and the other one was Alzheimer's disease, but I'm not including the latter in this talk. Now, once we constructed this population graph, then we had a set of convolutional layers and then at the output layer, And then at the output layer, each node was associated with a feature vector that had the same dimensionality as the number of classes. And then a softmax layer that was applied on each note. And the whole architecture, the whole model was trained with the cross-entropy laws. And it was semi-is considered. It was semi is considered to be a semi-supervised or transactive learning setting because we would observe the features of all available nodes at training time, whereas only the labels of the training data were offset at training time, and the rest were left for validation or testing. In terms of the analogies between The analogies between Euclidean and irregular domains. Again, I assume that most of you, or if not all of you, are familiar with these analogies. But yeah, in terms of like image intensities that we would normally refer to for standard 2D or 3D images, and that would correspond to our signal, we have a node feature vector in the case of the regular data. Of the regular data. So, in this scenario, that I just described, it would be the functional connectivity information of each node. And the task that we're focusing on is node classification that is somewhat equivalent to an image segmentation task in the traditional Euclidean setting. So, in order to perform this like In order to perform this, like, to use GNNs and perform these graph convolutions on the population graph, we rely on elements from a spectral graph theory. So given a graph signal X that is defined on the nodes, on the vertices, and assuming an undirected weighted graph in this particular scenario, we can use a spectrograph theory to analyze the data on top of the network. On top of the network. And the most powerful operator in this setting is the Laplacian matrix, and that is used to analyze and process networks. So it's also used as a diffusion operator. So if you look at the bottom right part, if we have a heat source starting at a particular node, and then we multiply the signal time, the node signal at time the node signals at time t with the Laplacian matrix, then we will get the signal on the nodes at time t plus one. So there is also an analogy between the traditional Fourier 1D Fourier transform and the Graph Fourier transform in that we can expand the signal defined on the nodes in terms of the eigenfunctions of the Laplace. Of the eigenfunctions of the Laplace operator. And this is done by decomposing the Laplacian matrix to a set of eigenvalues and eigenvectors. And the eigenvectors form the orthonormal basis or the modes of variation as we normally call it. So as with a 1D signal, we have Signal. We have the first component, the blue line here, being the lowest frequency component, and this is the same at the bottom if we look at the signal across the nodes for a particular eigenvector. And then as we move to the right at the bottom, then we can see that the frequency increases as we move to the right, and that leads to sharper. The right, and that leads to sharper changes between neighboring nodes. So, what we're learning essentially with this graph and neural networks are the parameters that we need to weigh each of those eigenvectors in order to compute the value of the featured vector of one node at the next time step. And then also, these filters are. So, these filters are isotropic in the sense that they treat all neighbors as equally important, unlike other methods like gated attention networks and other techniques that will be mentioned in future talks. This is just a reminder of how the method works. And so, we apply this to the abide setting. This is to the abide setting. So, this is the intersight setting that I referred to earlier. The task is distinguishing between neurotypical and neurodiverse individuals. And here we're looking at the area under the curve. If we compare different graph structures, so looking at the k-nearest neighbor graphs, a graph that is weighted by the similarity between the feature vectors. Between the feature vectors across all nodes. A complete graph is where every node is connected to every other node but not weighted. Then there is a random graph where the edges have been defined based on similarity between feature vectors and phenotypic data, but randomly permuted. And then the phenotypic graph is the one that I described. Graph is the one that I described earlier, where we encode information about the imaging sites, but also about two individuals having the same sex and weighted by the similarity of the feature vectors. On the x-axis, we have different polynomial degrees for the polynomial parameterization and the Parameterization and the filters that we learn. And if we focus on one of these polynomial degrees, then we can see that actually the graph structure of the population graph does matter. And we can see that the random graph actually yields the worst performance in a cross-validation setting, and that the phenotypic graph did consistently improve. Did consistently improve performance in terms of area under the curve for this task. Something to note, because you might see that the values, like the performance overall is not super impressive. That's mostly due to the fact that we reduce essentially a spectrum disorder to a single class. So that has implications. That has implications with respect to how well we can separate neurodiverse and neurotypical individuals. So, this is something to consider. And then, we also look at the effect of the graph structure for the phenotypic graph. We look at if we consider the site and age information at the bottom versus the site and sex information weighted by the similarity between the feature vectors. The similarity between the feature vectors, we see how the accuracy varies. So, again, we can see that the most informative is the graph that relies on sex and site information weighted by the similarity of the feature vectors. Now, where does algorithmic fairness come into play here? There is a lot of work in general in machine learning, but more recently also in machine learning. More recently, also in healthcare to understand what are the potential biases that are present when we develop our models. And there are different kinds that you can see that emerge during model development, like for example, missing data bias, there is cohort bias and minority bias. But also there are biases that emerge. There are biases that emerge during model development. For example, when we have live patient data, there is a drift over time, or there are patients that are not being served by the model. And this is characterized as a privilege bias. And there are also other types of biases that are more related to how experts use these models. These are called like automation. Are called like automation or dismissal biases. And as you can see, there are various stages of model development and model deployment where these biases can creep in. There was a very interesting study in 2020 that was published at the PNAS, and they looked at an open source data set called the SexPer where they Where they're looking at pulmonary diseases based on chest X-ray images. So, what they did was they looked at what is the impact of the composition of the training set in terms of the split between male and female individuals, and what the effect of this composition is on the performance of the model on male patients, which is. Male patients, which is at the top, versus on female patients, which we can see at the bottom. So, overall, I don't know if you can see my cursor actually. So, if we focus on these two box plots, we can see that by training purely on females, female patients, then we get much better performance. Performance basically across all possible diagnoses in comparison to if we train purely on male, on the images of male patients. And then here they show like what is the split, basically how that varies with respect to the percentage of images from female patients included in the training data. Included in the training data. And we can clearly see that the higher the percentage of females, then the better the performance on the same subgroup and similar results they observe for males. Another study in this paper called Sex Clusion is looking at also different Is looking at also different axis, like different sensitive attributes, like for example racial disparities. And they're focusing on whether a predictor satisfies the equal opportunity with respect to the sensitive attributes A and the label Y. So the equality of opportunity creates. The equality of opportunity criterion tells us that the probability that a model predicts one or like of a positive prediction, given that the ground truth is also a positive prediction for a value of a sensitive attribute, is equal to the probability that a predictor gives a positive predictor. Gives a positive prediction or positive diagnosis if the value of the sensitive attribute were different. So, as you can see here, for different values of the sensitive attribute, so different colors correspond to different racial backgrounds, the performance of the model is actually different, especially for lung opacity. Lung opacity and pneumonia, you can see that Native Americans are actually not discriminated against, but the model underperforms consistently for these subgroups of the population. So, given that we previously relied on this information of the sensitive attributes to construct our graphs, we wanted to see. We wanted to see what is the effect of that on the fairness of our predictions. So, given that we have the semi-supervised setting and we use sex to essentially introduce inductive biases in our models, we wanted to see if the accuracy for males is equivalent to the accuracy for female participants, or the true positive rate is equivalent to the. Rate is equivalent to the true positive rate of the other sex. One thing that is challenging in the fairness community is the fact that there's different definitions of fairness. One definition has to do with disparate treatment, where a system yields different outputs for different subgroups of people with the same features, except the sensitive attributes. Features except the sensitive attribute. There is also disparate impact that is often described as statistical or demographic parity, and that was introduced, it was coined by Dwork in 2012. And the most relevant in the healthcare domain is this mistreatment, where the system fails to achieve the same classification accuracy or error rates for subgroups of people with different values of a sensitivity. People with different values of a sensitive attribute. So, friendless metrics are also often at odds with each other, so it's very hard to come up with a method that satisfies all of them at the same time. In terms of mitigation strategies, there are pre-processing techniques like undersembling the prevalent class, in processing techniques like introducing adversarial components to the model and fairness constraints, And fairness constraints. And there are also post-processing techniques like classified calibration and equalized olds that was introduced by HAD in 2016. Now this is just a reminder of the demographics of the data for the eight largest sites. So you can see that NYU is mostly comprised Is mostly comprised of neurotypical male participants, whereas there are other sites like Trinity that only captured imaging information for males and there is no data for female participants and vice versa. So, given this multi-site setting and given other studies that have recently shown that fairness doesn't transfer, so if a new Fairness doesn't transfer. So, if we focused our analysis on the largest sites, that wouldn't be sufficient. So, what this study showed was that ensuring fairness in a source domain does not guarantee fairness in a new target domain. And this is one example from dermatology, actually. But what we see is that each dot is essentially a single model with a different seed. So, we can see that we have So we can see that we have parity between males and females here and across ages here. But then as soon as we deploy the model or we run inference of the model on a target, a new target domain, then this parity does not hold anymore. So we cannot get those guarantees by performing our analysis in the source domain only. So, we looked at the impact of two things mostly. The first one was the impact of certification strategy, because our original certification strategy was based on diagnosis. And the reason for looking into that is because most studies have highlighted the importance of the composition of the training sets, which is also understandable. Like, if a certain Understandable. Like, if a certain subgroup is underrepresenting at a training time, then it's more likely for the model to underperform on that subgroup at test time. And we randomly selected, in order to keep our results comparable across the different certification strategies, we randomly selected 10% of the individuals as a held-out test set. Test set. And this included two males and two female participants, one neurotypical and one neurodiverse for each of those. And we used 10 different random states to select this held out set, so that would change for each state, and 10 different model seeds so that we have some estimate of Some distribution, let's say, of performance, given different initializations of the model. And then we compared this to a Bayesian, which is a rich regression model, a complete graph, and then a graph that captures sex and site information, only site information, and then sex information. And what we observed is that the certification strategy actually didn't matter so much. So, results were very. So much. So, results were very similar across the different stratification strategies. And that led us to stick to one of the stratification strategies, sex and diagnosis. And then we explored the impact of the graph structure. And in this scenario, because we had a single stratification strategy, we could then perform 10-fold cross-validation with 10 different model C. So in total, we had 100. In total, we had 100 estimates of performance. And then we also saw that if we look at the difference in true positive rates between males and females, again, this phenotypic graph based on sex information or sex and site information was the one that led to the best outcome in terms of fairness. And here this is for sorry, this is the distribution across the hundred models in terms of area under the ROC curve for males with purple and for females with green. And if we look at the median, the sex graph is the one that achieves the best fairness. So, overall, and to conclude, and leave some time for questions. Leave some time for questions. Our observations were that the certification strategy did not have a significant impact on fairness metrics in the setting, which was kind of surprising, but it could be justified by the fact that we're looking at the transductive setting. So most other studies have looked at an inductive setting, but in our scenario, we do observe the features of all available participants and only Participants and only observe the labels for the training data. So, this might be why we didn't observe this effect of certification strategy on the fairness metrics. And we also observed that the higher performance of the GNS in our original study did not come at the cost of higher true-positive rate difference. So, again, something that is often observed with these studies is that having higher Having higher accuracy or better performance overall comes at the cost of certain underrepresented groups. But that was not the case with this setting. And our results also align with previous studies that highlight fairness through awareness, so being aware of the sensitive the value of the sensitive attribute actually allows the model to perform fair predictions. Perform fair predictions. Overall, the graph structure itself was more important than the composition of the training set. And the fact that we used a sex graph that yielded the best fairness outcomes, that means that we had essentially two disconnected graphs, one for males and one for females. And the fact that this was the case might have to do with. This was the case, might have to do with the different patterns of functional connectivity in individuals diagnosed with autism spectrum disorder. So, there is literature that has highlighted hyperconnectivity in females and hyperconnectivity patterns in males. So, this can hint that different latent representations need to be learned for the two subgroups. In terms of the mitigation strategies that we experiment with, Strategies that we experimented with, like just trained twice and fine-tuning on the underrepresented group, this only led to marginal improvements. So yeah, to conclude, there is a lot of potential for applications of graph representation learning in life sciences and neuroimaging and for disease understanding. But it's very important to focus on the robustness and interpretability of the representations. Of the representations. And in order to ensure equitable and fair outcomes across the population, we need to very carefully audit the models that we develop in these domains. So that's all from me.