Well, thanks so much, everybody, for coming, and thank you for having me here. It's really, I really enjoy this seminar series. I'm happy to be part of it. I will be presenting a paper that has been just published and it's been several work, several years that we worked on this. We started when we were all still at the same institution, and the lead. Institution. And the lead author is Valentin Hugner, who is a PhD student at Institute of Science and Technology Austria. And this work is called Efficiency and Resilience of Cooperation in Asymmetric Social Dilemmas. All right, let me try to see how this works. So, the base premise for this work is the focus on social dilemmas, and we know that. And we know that there's a lot of literature on this topic from many different perspectives, from many different fields. And basically, the idea is that cooperation is a very widespread phenomenon, but it's very vulnerable to defection, so to free riding. And cooperators are often being used and they pay costs for providing benefits for the group, but they might not get the benefits. Group, but they might not get the benefits back from others if they're not cooperating. And we know there are many different mechanisms for this behavior to emerge in the populations, and we're still trying to understand what kind of mechanism can facilitate or determine reasons for why cooperation can unravel. And recently, inequality became one of the focus in the focus. One of the focuses in the field, and it seems that inequality is very abundant in societies in general. There is a lot of heterogeneity. Inequality can be interpreted here loosely. So it could be individual heterogeneity. It could also be inequality in wealth. So it really depends how you look at it and what kind of problem you're trying to model. We're specifically focusing on the wealth inequality at the first. Inequality at the first. And it seems that inequality naturally evolves even in seemingly egalitarian societies. So even if you start all equal at some point, the group will converge to something more unequal. And it was shown that this phenomenon then hinders cooperation. So it makes it a bit harder for the group to cooperate, especially in the setup of social dilemmas. The setup of social dilemmas. And so there is a lot of literature that is trying to understand how to undo inequality, how to do it at the behavioral and societal levels. And in fact, this is actually one of the sustainable development goals currently, I think it's number 10. And so, one question that we are trying to address in this work is: if we, for instance, can reallocate wealth within the group. Reallocate wealth within the group, and it's a very strong assumption. But if we can do it, what is the best way of doing it? Is it that we just have to allocate wealth equally to everybody else and then this solves the problem? Or is there other ways or if there is something else that we have to take into account? And we naturally then emerge into the premise of optimality of endowment distribution. When I say an endowment distribution, And when I say an endowment distribution, I am meaning really the wealth distribution in the group. So every player is endowed with some wealth, and this is what we are mainly concerned about. And the basic idea is coming from the linear public goods game. So imagine we have three players, they have all different endowments. In this case, it's E1, E2, and E3. And they can control. And they can contribute some part of the endowment towards the public good that is produced in every time step. And another level of heterogeneity that we're introducing in this model is the individual heterogeneity. So it could be that contributions of each players are multiplied by some factors, R, and they are not necessarily the same across players. Necessarily the same across players. So it could be that every player has different productivity factors, we call it, RI. And then basically, the entire public good of the group is a sum of these products, EI times RI. So you get all effective contributions together. And this is what we call the public good. And then we divide it equally among every individual in the group. So it doesn't. Individual in the group. So it doesn't matter if the person contributed or not, they will still get the one-third of the produced good by the group. And for the simplicity, we assume that the endowments are normalized and say the sum of all EIs is equal to one. So you can just think about it as a fraction of wealth, the total group wealth that every player gets. And it doesn't matter in our model. And it doesn't matter in our model how big the total wealth is. It just matters what is the distribution of this wealth within the group. And for three-player case in panel F, you can see we then deal with the simplex, where each point in the simplex represents a possible distribution of endowments. And basically, what we are after is understanding what is optimal for corporate. Understanding what is optimal for cooperation. The first way of thinking about it, you could say, okay, we are optimizing something that is to do with wealth. So probably if we are to maximize the total public good, it would be good for the group. So in this case, we would be concerned with efficiency maximizing distribution. So we would try to maximize the total production of the public good in the group. Good in a group, and the second objective that we could think about could be: okay, we're talking about interactions among players that have different endowments, they might have conflicting incentives and different strategies. And so probably one thing we also want to consider is we want to maximize the chance that they actually do cooperate, right? So they actually do contribute their endowments towards the public good production. Towards the public good production. And this is what we call the resilience maximizing distribution. And let me now try to walk you through each of those and try to show you what happens when we are working out each of those objectives separately. But before I do that, I just would like to put this slide here for those interested. This is the mathematical bones of the model. Of the model, we have the classic linear public good game with a repeated interaction. And one key thing to take from here is that our game is repeated. So there is actually a probability attached to every round happening. So if we are interacting today, then the round tomorrow, the probability that we interact again tomorrow, is equal to delta. To delta. And this delta is coming from two interpretations. So, first interpretation is that it is the probability of interaction. So how likely it is that we're interacting tomorrow again. Or you could also see it as how much I value the future. So how much weight I put on my future payoffs. So basically, if I am to consider all my future payoffs from our All my future payoffs from our interaction, I would then use this delta as a discounting factor to discount my future payoffs. And the bigger the delta, the less I discount, the more weight I put on the future. And if we are talking in a classic scenario, delta is usually equal to zero, meaning that there is no repeated interaction, it's just a one-shot game. And in In public goods game, this kind of delta would mean that there is no cooperation that can be sustained. So, usually, defection is the equilibrium. And so, we use this delta to define and find the resilience maximizing endowment distribution. The basic idea here is that delta puts this pressure on Puts this pressure on how much, how likely it is that we're interacting again tomorrow or how much value I put on the future payouts. And so the lower the delta of the player, the less value they put on their future payouts. And so thus, they're less likely to take into account how their player, other players will react in the group to their actions. So naturally, if we put more values on our future payoffs, we would more. Values on our future payoffs, we would more value the interaction with the group and we would try to make them cooperate and play nice. And so when we're trying to measure how hard it is to sustain cooperation, we are trying to define the lower bound on delta and try to understand how big it is. And the bigger this delta is, the harder the cooperation is for the group. Is for the group. And so the resilience of cooperation can then be seen as the inverse of this delta. So you would have the opposite measure, right? And the endowment distribution will then be the endowment distribution that corresponds to the minimum delta, to this lower bound, that can still sustain cooperation. And we can fully characterize this endowment, so we can actually. Endowment, so we can actually calculate it for any size of the group and for any parameter distributions. And what we find is that when you have heterogeneity in the group at the productivity level, so this is our panel A is the productivity distribution in one example. So if you have players that are asymmetric in their productivities, you would also get the unequal resilient. The unequal resilience maximizing endowment distribution. So, this means that when you have a heterogeneous group, then there has to be inequality for cooperation to be sustained. But you can see that the effect is different, so it really depends on what kind of productivities we're dealing with, how many players are in the group, and inequality can be lower or higher in the areas. Lower or higher in the resulting endowment. And as the number of players in the group grows higher, it actually is more likely that the resilience maximizing endowment will become equal. So for large groups, sufficiently large group, the optimal endowment in this case would be close to equal endowment distribution. However, if you go into However, if you go into smaller groups, their inequality becomes more pronounced. And it is more pronounced when you have, say, in panel E, you can see this endowment distribution is very unequal and it corresponds to higher productivity values. And yet, even though it is very unequal in panel F, you can compare panel F to panel C, you can see that the light, light Light shaded area corresponds to the endowment distributions that can sustain cooperation. And basically, this means that in panel C, there's only small area of endowment distributions that can sustain cooperation and in equilibrium. And in panel F, for higher productivity, is not surprisingly, you see that there's a much larger set of endowment distributions that can sustain cooperation. And so, And so cooperation does get easier if you increase productivities, but it also increases the inequality in the endowment distribution. And to mitigate this effect, you could increase the group size and then you would basically converge in panel A, I, you can see that inequality reduces and it goes almost to equal endowment distribution once the group size is large enough. The group size is large enough. So, resilience is one thing that is very important for cooperation. So, when we are trying to understand how to sustain cooperation, how to increase the chances that people actually want to contribute towards the public good, this is one measurement to use. But now, another measurement that we could use as well is the actual welfare of the group that we. Of the group that we can also try to optimize. So, what we do, we define the group welfare as the sum of total payoffs, right? And because of the productivity factors, the total welfare is going to be higher if players are contributing towards the public good because of these productivity factors that are greater than one. So, it is more efficient to contribute than to keep your endowment to yourself and then your productivity. Endowment to yourself, and then your productivity is one that you're multiplying it with. And this problem, unfortunately, is not as nicely behaved mathematically as the resilience. We could not come up with a general way of characterizing the efficiency maximizing endowment. But what we can do, we can numerically calculate for any Productivity factors, we can calculate this problem and we can fully characterize it for a two-player case. So, this is a snapshot of both of the endowments. First is the resilient endowment, resilient maximizing, and the second is efficiency maximizing. And I put them together against each other just so that you can see the difference between the two. And you can see that the resilient maximizing. And you can see that the resilient maximizing endowment, the first row, this endowment doesn't really have delta straightforward in it because the E star is coming from delta mean, the lower bound on the delta mean, which is fully determined. And the efficiency maximizing endowment will then depend on delta that players have, because this endowment distribution is not concerned with optimizing the delta, it's concerned with optimizing. The delta. It's concerned with optimizing the total welfare. And we can now compare how the inequality works out in these two different endowment distributions that are both supposedly optimal for cooperation just from two different objective functions. So imagine we have a player, a group of three players with productivities as shown in panel A. So you can see that one player is there. So you can see that one player is very productive, and player two and three are still not quite as productive, but still sufficiently productive. And the resilient maximizing endowment will result in panel B in some inequality, but you can see that players two and three are not too unequally endowed, so they still get sufficient amount of endowment. And of course, player one is more productive, one receives a higher. Receives a higher share of the endowment. However, if we are to maximize the group welfare, and in panel C, you can see the distribution of the efficiency maximizing endowment, there the inequality becomes much more significant. And player three, for example, now receives unproportionately low endowment in this group. And player one and two are the ones that endowed most. And down most. So, we can, because these are two basically two different optimization problems, we can try to find the trade-off between the efficiency and resilience as the Pareto frontier between the two. And this is shown in panel D. So we're concerned on x-axis, we're concerned with resilience, and on y-axis, we're concerned with efficiency. And we plot them against each other as the in the pink. Other as the and the pink line as the proto-frontier, and we have the highest efficiency for the lower resistance and the highest resilience for intermediate efficiency. So this is an interesting trade-off. Basically, this tells us that the efficiency and resilience are two different things, and they are sufficiently different so that you can't just be concerned with one. So you might Concerned with one. So you might want to take into account both when you're trying to optimize cooperation in your group. And it really depends on what the objective is. So in panel E, we just map this panel D onto the simplex to show what happens for each endowment distribution. So the highlighted area is again where cooperation can be sustained. And you can see the darker And you can see the darker color corresponds to the lower delta minimum. And it is the lowest at the highest resilience. And the highest efficiency is where delta min is equal to one. So this is the very boundary. And this basically means that operation is very, very hard to sustain at this point. So, okay, this is all an Okay, this is all analytics and this is all nice and interesting, but we know that there's a lot of criticism for repeated games because of the folk theorems. And what we then do, we try to test our predictions using the evolutionary simulation and try to understand what actually happens and what kind of endowment better predicts cooperation. For this, we use the introspective. This we use the introspection dynamics. And it's basically a stochastic learning dynamics where you are learning based on your payoffs, right? So whether your payoff towards the strategy you're using now or another randomly generated strategy, you're comparing the payoffs. And if the payoffs difference is so that the randomly generated strategy is better, then you're more likely to switch to the new. More likely to switch to the new randomly generated strategy. So, this is a different dynamics from the imitation dynamics because, in imitation dynamics, you would learn from the strategy of the opponent. But in introspection dynamics, you are learning from your own process. So, you find strategy that works better for you. And we cannot use other dynamics in this particular problem because of the heterogeneity in players. In players, so the strategy spaces are not compatible for other dynamics. So that's why we're using this one. And we're also using implementation errors. So there is if a player has a strategy P, then the player might actually, by mistake, execute a different action that is prescribed by their strategy. Okay, so with some epsilon error rate. With some epsilon error rate, they make mistakes. So, when we simulate our process cooperation in the groups of two or three, what we find is that neither resilience maximizing nor efficiency maximizing endowments are better for cooperation in these learning dynamics. In fact, there exists a point somewhere in between the two where the maximum Where the maximum welfare or maximum cooperation rates are observed in the dynamics. So, and it actually is located on the Pareto frontier. So, you get this trade-off already. You can see it in the learning dynamics itself. So, it is converging to a point somewhere in between the resilience and efficiency maximization. Resilience and efficiency maximization. So, basically, evolution, in this case, learning process, has to take into account both objectives and find a point where both of them work together. And we do these simulations across different parameter spaces, and we find that this effect is quite robust. So, once you, the first row corresponds to the players that are not. Players that are not heterogeneous, they're homogeneous in terms of their productivities. And the second row is the group where you have heterogeneity in productivities. And you can see that once you have that, once you have the individual differences between the players, then this learning process converges to the endowment distribution that takes into account both resilience and efficiency together. So So, in short, there is no straightforward way of determining which endowment distribution is better. But we do observe that inequality is something that is very persistent and it is actually often better for cooperation, especially if you have heterogeneity in the group. So, some level not too high, if once the inequality is too high, it also hinders cooperation, but some media. Cooperation, but some immediate level of cooperation actually might be good. For the sake of time, I will skip this slide, but I did manage to get to my main point and to reiterate: there exists this interesting trade-off, and both objectives have to work together for the benefit of cooperation. Cooperation. And I'll stop here. Thank you so much. Thank you. That was really interesting. Do folks have any questions? Jeremy? I mean, that was really, wait, let me sorry to get you on the right camera here. Yeah, that was very cool. Yeah, that was very cool. So, I guess one question I have about what does inequality mean in this model when you're looking at a full, so if everyone at equilibrium here is giving everything, so even though they have asymmetric endowments, they're still giving all of their endowment to the public good. So, there's a sense in which, so I mean, everything that's a that's a very cool, cool setup, but there is sort of like maybe a further step too, because people's sense, I think, about inequality isn't just the endowment. Isn't just the endowment inequality, it's also how much you're giving at equilibrium. But anyway, just what are your thoughts on that? Thank you so much. That's an awesome question. And you're kind of peeking into our future research. So the basic idea here is that, yes, indeed, we are mostly concerned with full cooperation when trying to understand when full cooperation can be sustained. And indeed, once this is happening, where everybody contributes everything, because Where everybody contributes everything because of the equal shares, right? The everybody gets the same from the public good, the inequality kind of loses its meaning because while you have the same share from the public good if you're contributing everything, it doesn't really matter how much endowment you have because you would still give it all up. Right. And in this sense, inequality is becoming more of a construct in this model. But of course, the But of course, what often people do in this kind of models is they're trying to understand when full cooperation is sustainable, but it doesn't mean that it will be sustained, in fact, in, for example, in the lab. Once you're taking it to the experiments and let people play this game and let them try to figure out what the equilibrium is, they will converge to something close to equilibrium, but they will never contribute 100% of the endowments. So they will be just contributing some fraction. They will never actually contribute everything they have. Never actually contribute everything they have, and this is an interesting phenomenon, but it often follows the directional prediction. So, for example, if we say that for this parameter set, full cooperation, it can be sustained in equilibrium, then in the behavior, it is more likely that people are showing higher cooperation rates. So, they don't contribute everything, but they show higher cooperation rates. So, there is a bit of a mismatch between the theory and the experimental. And the experimental literature. But we treat it as if it's a directional prediction, right? So if we say that for this parameter space, there's no cooperation, then we should not observe any cooperation in the lab, or the cooperation rates should be sufficiently low so that people just cooperate by mistakes. And this was one of the reasons for why we use the learning dynamics to test our theory because theory has this kind of limitation. Has these kind of limitations, but starting from another point of view, you can also, of course, try to look for equilibria where you have partial cooperation, right? So where you people let players contribute something that is less than the endowment. So something that is not quite the full cooperation. And then your equilibrium space actually becomes very large, right? In fact, it could be infinitely large. Infinitely large. But you could try some, find some regularities in this equilibrium space and try to understand what could happen, what kind of partial cooperation can be sustained for different levels of inequality, how inequality affects it, and so on and so forth. And this is something we're trying to do is a work in progress. It's not so straightforward, unfortunately, because of this infinitely large equilibrium. Infinitely large equilibrium space. And yeah, but it's a very cool question, and it's a very fair question. I mean, that is the limitation of the Eurasia. Yeah, but still, very cool that it's even, it's predictive in those experiments. That sounds awesome. Thanks. Dave? Hi, thanks for the really cool talk. I haven't really ever heard something like this before, so it was super exciting to listen for the first time. My question is. My question is with about some of the assumptions. When you're talking about your populations, is there any sense of idea of maybe like having structure like within a population? Or is that just essentially equivalent of adding another player to the game and counting that as two? Thanks so much. That is a very good question. So, currently, we don't assume any structure on the population, and we are On the population, and we're mostly operating in small groups because, as I said, in larger groups, this effect is kind of going away, right? We don't observe inequality anymore. So, we're trying to also cooperation is generally a bit harder to sustain in larger groups. It seems that the group size has this negative effect on overall cooperation. So, when we are trying to work out this, we're trying to work out this model, we're mostly focusing. Trying to work out this model, we're mostly focusing on smaller groups and trying to understand how this works. And there, we didn't assume any structure. But I think once you get larger groups, this structure becomes quite important, right? And sometimes, especially with ideas like social networks where people are embedded in some kind of network and they're interacting within this network, and then something else happens. And there's a whole literature on this where they put public goods game in the networks, and then they're trying to work on that. To work on that, and I know that there were some papers published by Kisu and Alex Makabo and Joshua Plotkin that work in this space. But we don't actually assume any structure for now. Thank you. Great. It's three o'clock now, or it's the hour. It's not three o'clock everywhere. It's not three o'clock everywhere. I want to thank the speakers again for giving two wonderful talks, and I hope we get to see you next week on Wednesday. Thanks so much for coming.