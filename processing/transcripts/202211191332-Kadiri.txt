Alrighty. So okay, well um hello can you hear me? Yes I hear you. Do you? Do you want to record your lecture? I pushed the button. Do you not? Okay. We're recording in progress. Okay yeah yeah it just there's been an issue so I'm just going to record an extra copy and zoom here. Okay thanks. Okay, thanks. Shall I start? Yeah, go ahead. Thank you. Super ominous, what was so welcome for this afternoon session of our overview of our CRG themes for this afternoon, explicit number three. Okay, there's actually three essential themes. The fourth is Essential themes, the fourth is the same as the third. So, first, I'll give you a four-step guide to solve a conjecture. I mean, that was that easy, everybody should do it. Then, an overview of the story of a prime-number theorem, so from Gauss to today, what do we know in an explicit point of view? And then, generally, looking at things in the more general context of primes and number fields. Okay, so here's your four-step guide to solve a conjecture. Take the Goldbach conjecture, let's start with the ternary one. I'm going to give you one that's solved. Every odd integer is a sum of at most three primes. As usual, when something is too hard, when we look at the neighbor result, we look at something that is not necessarily much simpler, but still. Something that we can start saying a little bit about. So, for instance, Schneelman's theorem that proved that there exists an absolute constant such that every integer is a sum of at most these number prime numbers. And when Schneelman established his theorem, the value was established at 800,000. There's a few results before the next ones, but not that many actually. And it jumps down to And it jumps down to Lydia Ramarie, who in 1995 proved at most seven prime numbers were needed to represent every integer. And finally, Tao in 2013 reduced that to five prime numbers. So maybe to clarify, the old Gottmach conjecture would be proving Schneelanman is four. So we. So wait. Um so what do we know uh in terms of partial answer? In that sense, what can we verify? So every odd integer up to a certain value n, how big can we make n so that all these integers are the sum of at most three primes? So I've given here a sample of such verification. Starting Amarian Sauter, Olivera Esilva, who you can see here. Oh, I've done a lot of pictures. Who we can see here. Oh, I've done a lot of pictures in my talk, so at least you can enjoy the pictures. So he's from Borneo. Have I got, I don't know if you can read actually very well the numbers. There will be a lot of numbers. Every time the idea is like we want those numbers smaller or bigger. Okay, so that's gonna be the goal. But let's say that in early 2000s, we were verifying things up to 10 to the 22. To 10 to the 22. That's the method that we actually did with Alisa from Olivier and Sauter in 2013 to reduce that, to increase that to 10 to the 27 and Helfcut and Platte push-PAT verification without this method actually, up to 10 to the 30. And that number of 887, 10 to the 30 is important, please remember it. I was just mentioning that how we would get those verifications, like here and there, it's a direct consequence of finding short intervals containing primes. And I give you here the actual sample that we need. Starting at x bigger than e to the 60, you have that interval between 1 minus 1 over that, almost a million, x up to x, that would contain a prime. So next So next third step of proving our conjecture here, let's prove it when n is asymptotically large. So this is what Vinogradov proved in 1937. The next step is, well, what do we mean exactly by sufficiently large? So here I give you a sample of the last results. So the conjecture, the outbox conjecture is true. The Goldback conjecture is true for the first one here, is 10 to the 1350. That's a result again from the early 2000s. The second result here was consequences of a bunch of results I had proven back in the days in my PhD. I could reduce that 1350 to 850. And then HealthCut and a lot of other little helpers here have this long argument. You can find them on the archive. Arguments you can find them on the archive, split into two main papers right now: the minor arcs, study of the minor arcs, study of the major arcs for the orb of a conjecture. But they can prove that for n bigger than 887, 10 to the 30, you can write every integer as a sum of free prime. So Pada, 887, 10 to the 30 was what makes the partial verification and the asymptotic results made explicit. Results made explicit join together and actually prove the old Robach conjecture. So let's say that what explicit results are useful about? Well they help us quantitatively understand like how strong our methods are or how strong how weak they are often and how far apart we have to actually get complete results. So this is an illustration, perfect illustration of that. Illustration about. And this is very hard to actually use. Okay, so I'm going to give you an overview of the prime number theorem. In the audience, I haven't checked, but I have invited our grad students undergrads that are taking this introduction to analytic number theory, so there's a few slides for them here. I wanted to show here the calculations that Gauss did to establish. Did to establish his conjecture about the estimate of the number of crimes after X. So we, I'm sorry, maybe I know I'm going to say things that you've heard hard at times, so bear with me. So counting primes by interval of 1000, he recognized that there was a certain frequency in the average number of primes in these intervals that he estimated to be of size 1 of 11. To be of size 1 over log n around n. So that's how he came up with this conjecture that is very calculative at first: that pi of x is about the size of the integral from 2 to x of t of the log t, this quantity we call the Logari integral. And these are a sample of his calculations here. And the prediction later for the error term that we're going to talk about, of course, is that the error term is a size. That the error term is of size x to 1 half plus epsilon. That was not part of what Gauss did, but it's just to get a little bit ahead. That's something that now, with looking at these tables extended, you can actually see. So how did analytic number theory came about, how analysis came about? Well, by what I guess we call the fathers of analytic number theory. Of analytic number theory. I'm gonna do my little comment here. There's no mothers because I guess at the time they could only burst childs. But thanks to Dirac Lee and Riemann, here with Dirac Lee and the introduction of multiplicative characters, multi-chi and the Diracle series here as we know them. This characterizes these primes in arithmetic progression, so of a form A plus NQ, where A and Q are co-prime. And the first main thing. And the first main theorem in our field is that the L function doesn't vanish at one, proving that there's infinitely many primes with any kind of arithmetic progressions of the sort. Riemann here with the Riemann Zetas I'm sorry, I'm gonna get all my words in the wrong order today. Here written as our oil product. Here written as our Euler product when real part of x is bigger than one. Showing in an explicit formula of this shape, so that was in his moire here. Pi of x is of this form of r of x, where r of x is expressed in terms of the zeta function and minus the sum of all the zeros of zeta here. So the relation between primes and zeros are very much. So we're all dreamlines first. Yes. What? Yes. I'm pretty sure he did not die in 1966. And now I'm wondering why did I choose that date? Maybe eight. Is it eight? Maybe? Yeah, because he died young and fifty sixty fifty nine was in his forties, right. So that must be my age. Yeah. So as you said, we were looking for an animal to go up or down. We were looking for numbers to go up or down. Yes, I mean, actually, intentionally going up and down. Okay, so yes, here illustrating with a little picture, because sometimes it's more efficient than words, what happens to the zeros of a Riemann function here, thanks to a functional equation relating zeta at s and one minus s. And 1 minus s. So allowing us to know everything about the zeros outside what is called the critical strip here, shaded, I guess, for real part of s between 0 and 1. You have the pole here. Here you have your trivial zeros and negative even integers. And the conjecture being that all the zeros align on the half-line. Here, just to illustrate the symmetry, we have put a few outside the half-line to show that something like. To show that something going from here is here and there and down there. So we have, I mean, we have the his memoir was famous for the conjecture that it contained here. But the ideas of using all the tools from complex analysis and free analysis were exploited later on. And this is when this is what a load to prove Gauss conjecture. Uh to prove uh Gauss' conjecture now called the prime number theorem. So independently but simultaneously, Adamar and Delavalle Poussin proved that is there another single word minus four. Minus four to record. Memorializing all that stuff. Yeah, so yes, anyway, so this is the prime number theorem as state as a conjecture by Gauss. And these are the equivalent versions because I'll be referring sometimes to psi as well, a Chevichev function. Psi and theta, so I just took the time to write them here. And I put the quote of and I'm not just because I love to speak French as much. I love to speak French as much as I can now. Just to illustrate how to prove something about real numbers, prime numbers, sometimes the easiest way is going through the complex, because going in the complex way. So what I'm going to talk about now is what we know about the error term in the prime number theorem. So, under what is the true error term, or estimated true error term? Since from Koch, we know that Greemann hypothesis is equivalent to the fact that the error term is essentially of size x to have log x. And that's also why that became, I mean, the prime number theorem became central as well as the Riemann hypothesis here. Numerically, what can we do? Numerically, what can we prove? Well, Riemann hypothesis implies that we have that constant of 1 over root 8π for all x bigger than this little 2657. And what we can verify, so these are the latest results that you to be here. So we can go up to 10 to the 19. We have this specific bound for psi of x minus x, so 094 volt x. Vortex. And so up to 10 to the 19, lie minus pi is positive and no larger than this quantity size vortex of a log x. So we know that our skews number are to be looked after between numbers with 20 digits and 316 digits. So there again, it's a bit humbling of how much work we have still to do. Yeah, maybe for our students, SKUs number would be the first Students, skews number would be the first in first real first rule x, where we have the sign change of line becoming bigger than pi here. So that's kind of like my tiny nudge at comparative prime numbers theory here. Okay, here I'm giving you a little list of the various shapes for the error term. And so we know it's a So we know it's a if we, so what I'm looking at, e of x, it was written at some point in one of the slides, but it is psi of x minus x over x. Okay, so by the prime number theorem, we know it's a little of one, so that's a result that you can see, for instance, here and there. These are constants working for it. And more specifically, how does it depend on x? How does it decrease in terms of x? You have that it's You have that it's some power of log x, we can prove actually three half, exponential minus a certain constant root log x. This is something we can prove using the classical zero-free region. I'm going to talk about that. And we can prove something stronger, going up to a power of three over five, divided by a log log x to the y five, that is going to be deduced from a copper vinogradozo region. Region. And from there, these results, which you can also rewrite as here, you can prove results of the form a constant divided by a power of log x. And you can put any higher power of log x every time you have to increase this constant here. What I've listed here are the last results in the list. There are a lot of different techniques coming into play, and I'm going to try to talk about And I'm going to try to talk about those techniques as they are scattered results in the literature. So, one thing that's going to be obvious is like, well, can you take all these techniques and do something better? And the answer is going to be, sure, we can. Let's do that. But so, just to let you know, Johnston and Jang here are working from Canberra. They are students of Team Trigender. Andrew Fury is here. Jarz Svielinski was. George Svielinski was an undergrad at the time. He's finishing his master at SFU. Jan Britté was a student in Bonn. And the long B-K-L-N-W. This is Nathan I, but with Sam Broadband here, Kirsten Wilk, who at the time were undergrad. A loss for mathematics, but a big gain for music. He was actually a music major. Kirsten went on to, I think she's 50. Went on to, she's, I think she finished now her master with the program Algon. Maybe some of you know about it, which gives students in number theory opportunity to do their master degrees or PhD degrees in different universities in that cluster. So she went to Netherlands and to Bordeaux, my hometown. Okay, I feel that I needed to say some uh a little bit something else about these things here. Else about these things here. So, as I said, there's different techniques. The one that is coming here, even if it's stated for all, but that's working for all X, I'm giving you here where they're becoming actually stronger. So you can see that, for instance, if you use Kovogov in Ogradov and you do something about what does it give in terms of root log X, it then starts to get better at exponential 100,000. So depending on what you're looking for, that can be awesome. Of what you're looking for, that can be awesome or not as awesome. Here, the result that we have is actually going to work before that. Beauty here for constant size, Beauty's result is going to be the strongest for smaller axes. And if you want something about log X, I refer you to a web paper where we put everything in a shaker and get something like that. Get something like that. It is not always as trivial as you would think. You have to mix different methods, and you have to always be very careful of how big is x depending on what method you're using. Some methods are going to be more tailored for certain ranges of x. Okay, so what are the main ingredients though? Well, I'm just summarizing here something that after this first grad course you should be aware of. The error term in the prime number theorem is going to be relying essentially on these three tools here. So you can rewrite your error term usually as first constant term here plus the sum over the zeros of big F of rho over rho, where big F is some million transform. So that's a Merlin transform that corresponds to when you do your inversion formula going from the primes to the zeta. Formula going from the primes to the zeta function, and this x to the beta minus 1 here. So, smoothing, for instance, your psi function, you would get that delta f. If you go with Perron's truncated formula, that delta f doesn't appear here. On the other hand, you just get a truncated sum. So, you have to give in something somewhere else to counterbalance. So, what you would like is to have these two quantities as small as possible. Possible, and that means that you control your milling transform, that you control the size of the beta here, so you want it as small as possible, ideally a half, and that you also control the whole sum so that you know that you have also some good control on the number of zeros inside the critical strip. So, this is what I would like to talk about a little bit. One thing that is less that One thing that is less, that wasn't, for instance, really in the original proof, is how you come, I mean, you counted the zeros in the rectangle between zero and t, and real part between zero and one, but things that we have added here lately is zero density results. So using the fact that you don't have many zeros close to the one line, and that you can also split your critical. Split your critical strip into other rectangles and the way you slice everything optimized to get at the end an error term as close as close as you can. So at the end there were a few new notions that were tailored for the explicit results here. So from the Labeles Poussin you can you can actually you can just go through the proof and calculate the constant. And calculate the constant. That's how everything starts. What Ross and Schoenfeld did here, they had this series of articles between 1941 and 1976 where they start by improving on the zero free region and counting the verifying the zeros of zeta, but the first one are on the half-line. And for Russia in 19 in the In the 1940s, counting the zeros inside the critical strip. So, they actually are, all these papers are giving us the first explicit results that allow us to get some bounds in a prime number of pi of x here. So, I was just describing here a little bit what they do. If you go at Dane Valperson's proof, the idea is to compare psi with psi. To compare psi with psi one, so you just compare it with the mean value theorem with an average and a short interval around x. And what Russer and Schumper do, they just generalize that. They say, well, we're going to take an nth integral to compare that. And so we're adding that parameter m, and at the end, we're virtues. You can, I mean, they don't phrase it that way, but that's how you can interpret it. Then you can play with. Then you can play with M and see what you would get, what would be the size of a constant that is now going to say something about the size of your Mellin transform here. So just to notice, you can notice where the tension is going to be. This delta is coming from when you do the average around x, and so you have that tension between delta and 1 delta over m. And then you're also going to have that CM here, which as you can see is growing exponentially with m. So you can't really. Show you with M. So you can't really, for instance, with M, if you take your gamma to be M, that would give you a very converging series, but you're going to be locked with that CN here. So that idea was used later on by Dussau in a series of articles up to 2016. And then in the context of prime and arithmetic progression, so by Mike Gurley has a result on that, and the latest, I don't, sorry, I have one. I don't want. Sorry, I have words coming in. I wanted to say monstrous result, but really not in a bad way. Monstrous innocence. A lot of information by Mike Bennett, Greg Martin, Richmitzer, and O'Brien. Who am I forgetting the first names? Anyway, so that was one first way to approach things. With Laura at the time, we looked at what Rash and Florida. We looked at what Russ and Chalf and did, and understanding well, what they're doing is just the same as looking at inverse Mario transform. Let's just put things with a general weight and see if we can choose or optimize as much as we can the weights with a certain number of conditions. So, with the conditions that we were looking at, which is we're going to approach, so this is our way that would be your prime number third, and you have the prime to x here, and then you just smooth up. Then you just smooth up under and over, giving you a little bit of room with delta here. So you just smooth with those polynomials here and the choice of polynomials that were optimum in our context was some legendary polynomial, giving us that kind of constant now for the size of f. So anyway, this is actually giving something better if you can. Actually, giving something better if you can increase your M. And so that works better for smaller values of X. And if you have a smaller verification of Rh. What I mean by that, we actually want to know more about Rh, but in contexts where you do not have as many information, that would be actually very useful. It's also something that we use with Alisa Lemley to look at primes in arithmetic progression and with Surat Das in the And with Surat Das in the context of primes in which you put our density theorem. So, following on that idea of let's put, let's look, let's move at let's move psi and let's choose a good weight, beaute literally out of the woods here because this is not something, I mean, and I would be very interested to know if other people have used that in this context. Use the logo. Context, use the log, what's called a logon function. And the interest of that weight is that it has a very short cutoff. And so what it means is that when you weight your sum over the zeros, it essentially puts all the weights on all the zeros where the verification of RH is happening. And so you automatically have an x to the minus a half coming up as your mentor. So this method is extremely strong, especially when x is large. And especially when X is large, namely large value of 25,000. Finally, the one that you're going to be more familiar with after studying Davenport is the truncated Perrot's formula here. So you truncate your sum of the zeros up to t, you get this error term, and then you have that nice exercise of how to balance t and x to get at the end the To get at the end the average term that you're looking for to make the prime number theorem work. So, this actually was not. I have to say that, I think for a long time we believed that this is not going to be good enough numerically. And we were actually wrong. Because there's work of Polke and Ramare that provide a explicit truncated Beros formula. Oh, okay, then. Okay, here's another one. Not committed. Goldstone also has one on which Kalihagil and Johnston here based their work and Dudek here also made the neural completely explicit. And so these are, there's essentially two truncated explicit neurons formula that are now out there. Now out there. But one of Ramaret here, so you will see there's a lot of 2022 plus because a lot of results have been appearing extremely recently. And Odithi actually presented this week his explicit trunk, his Peron's formula, and he's invited students in particular to join and complete, prove, verify each step. Because as for everything with explicit result, you can't have comma wrong, which I'm doing a very boring illustration here. A very boring orchestration here. You really want to have everything extremely rigorous. So that's a project actually for students that you can jump on. But as I said, you can get some really good results from that. Yeah, so I was just summarizing here how the ideas were articulating. How the ideas were articulating. So you have to control the largest value of beta, ideally you have RH, but if not, well, you verify it up to H0. Afterwards, you look at zero-free region, so things of this form. Zeta does not vanish beyond 1 minus 1 over a function of the log of imaginary R of S. And what you do at that point, you split your sum over the zeros this way. Your sum of other zeros this way. So up to H0, you're going to have to x to the half an x to a half, so you expect this to be very small if your big f is not messing things up. After h0, you split vertically at sigma 0. And for the zeros before sigma 0, you will get that error term of x to go sigma 0 minus 1. And here again, you can play a game with balancing your sigma 0 size of f to make sure that this is not going to become too big. And after sigma 0, Big and after sigma zero and beyond H0 for an imaginary part, you have you can use your zero free region here. And at this point here, what is interesting to do is to actually have zero density results. So to ensure that in that region you have much less zeros than when you count, for instance, zeros in those regions. So that idea of chopping at sigma zero is something that we made explicit the first time with Laura here. First line with Laura here. That's also something that Platt and Chujin used, and based on an argument of Keen's. Johnston and Young, that I showed earlier in that list of 26 results, also used this based on planet trigon, but adding a better zero fur region. And then finally, with Andrew and Josh here, we went and added some other ways of slicing this size. This sums here. So, I should let you know what we know about all these different tools. So, what do we know about the partial verification of a Riemann hypothesis? Well, first we knew what Riemann had done since Ziegler uncovered Riemann's sorry here. Riemann's draft. So, Riemann calculated the first zeros himself. First, zeros himself. And the latest result now is due to Platt and Trojan. So we can go up to 310 to the 12. This is really thanks to the method that Platt pushed forward here in 2017. That was really the breakthrough. The previous results here, even though they seemed to be stronger at the time, were not as rigorous as uh Platt. Platt uh actually have a rigorous uh calculation using intervolal arithmetic. So In ultravolo arithmetic. So these were real advances. And this has been really used and very useful to get some error terms of the prime number theorem that were very interesting in terms of size. And what do we know about the zero free region? Well, the two that we're looking at are the classical one starting from the Laba de Poussin. So your F of T that I was mentioning earlier is Your F of T that I was mentioning earlier is of the shape R log T. T is your imaginary part. I'm just listing here the list of people who contributed to it in the actual order and I don't need to skip anyone. The result of Ford, I can just mention that it is different in terms of methodology because it is a as a a consequence of Ford's result making Korobov Vinogradov completely explicit here. Completely explicit here. So Korobovinogradov is of a shape log t2 square, log log t2, one-third here. What else can I tell you? Well, my work here was based on Stetschkin, but also on some work of Heathbrown. And then Musinghoff and Triggen here refine what I did going with a bet much better trigonometric polynomials, if you remember, how you prove such results. You prove such results. The difference between those two is that the classical region, even if asymptotically is worse than Korbovinogradov, is still the best up to exponential 10,000. When you want to prove things about prime, you may need to know what happens for imaginary part of T before exponential 10,000. But afterwards, you would use a false result. I have 20 minutes left. Do I have twenty minutes left? Four? Huh? Twenty-four minutes. I may have to speed up. Okay. Okay, if you want to know something about counting the zeros inside the critical strip, I refer you to the work of, it's gonna be Hassan Alizad, Shan and Wong. As you can see here, El Chin is finishing his PhD with us. Chen Mi finished and is now Finished and is now faculty in Shandong University. These are the constants that we have. Now, as an editorial comment, and this is really what happened, Laura and Russer and the Trojan based on some idea of Beckham here, but the constants, there is a little bit of improvement, but at this point we know so much about the zeros of the data function that improving here, I'm gonna say, is not going to have some extremely significant impact. Extremely significant impact. What is interesting, though, is how you can generalize that to counting others. So that's where continuing working on these questions is useful. Okay, oh my god, I really won't have the time. I've been far too slow. Sorry about that. Okay, I still need to tell you about zero density, though. Okay, the first one from Boron Lando. So we're gaining a coefficient of log t here in terms. Of log t here in comparison to the size of n of t where we had t log t. I throw at you the first explicit version that it was literally a lemma here that I wanted to have to apply to the zero to the Prague of theorem. One thing I'm going to say because I wanted to do a segue into the second moment of zeta on the half-line, so we'll see about that. If you want to, the next result, something that is a little bit more interesting, is when you can go. More interesting is when you can go beyond that power of one here. And at this point, you need to have results about the size of zeta on the half-line. So Ingam proved in 1937 that if you have this kind of boundary to the C for zeta on the half-line, then you can deduce that shape of zero density for zeta. So t to the two plus four c1 minus sigma, so where c is coming from the size of zeta. And as a consequence, you can, for instance, there's something wrong with the uniformity, right? I'm going to have more about. Uniformity, right? The upper and lower bound are the same. It's just one. Oh, yeah. Oh, yes. I should give a prize for whoever is going to pick up all the stakes, because it's going to be close to the resonance. Yeah, up to one. And actually, so as you can see, as sigma goes close to one, that's relentless. Close to one, that zero density is becoming, you know, giving you something better and better. So that's the kind of zero density that we're interested in for the motivation I gave you earlier. And then as a consequence, also, you will have a result about the gap between two consecutive primes here. And in the idea of like what implies what, RH implies Lindelof, which is face with c equals zero, which implies a density hypothesis, which implies prime gap. Which implies I will prime gap of size no larger PN. So, what do we know about the. So, we need to have some information to start with the size of zeta on the half-line. I just, every time these slides are going to have all the same structure, so just so you know, it's going to be the conjecture, the first result, the first, let's say, the first result that we made explicit, and then what is And then what is the best known result in literature asymptotically? So we're going to focus on how the unital root here, but proved the first convexity bound of T2416, which Harry was the first to make explicit, but the last bound is by himself, one of his former students, Patel, and Wong, who is working for who's working a student of Tim in Australia. Of TIM in Australia. But anyway, this is the explicit result that you have for all T bigger than 3, and you have also that numerical verification up to 200 here with the two constants, which you can see are fairly, very close. Once you have that, you can reduce some zero density following Ingham's argument here. So we can prove that n sigma t is no larger than 10 to the 8 third 1 minus sigma. And 10 to the 8th third 1 minus sigma power log t. I just calculated here the 8 third just to show you what in comparison to the best result possible here. So there is a lot of work and very challenging work. So, but what can we do explicitly here? So we can calculate those constants here in front of power t and also that. And also that log here. So, namely, we have something of this form. The first result was given by Olivier Ravare here, and this is something on which we improved. So, we actually, in the proof, we also actually improve on Ingam in the choice of the weight to localize the zero event we're using. So, I'm going to try to not forget when there is actually some improvements, even on the classic. Some improvements, even on the classical result here, and that was the case here, and that's also what manifested in how the constants were much smaller. So, this type of zero density was used in the results that I'm listing here. Am I ready? Okay, that's my little segue on moments because I was trying to first still look at. Still look at all our themes in the CRG. There's not going to be much, but still, there are some very recent results. So, literally, the past few years, some results have really appeared regarding the second moment of zeta. So, it was proven here by Landaușini that the second moment of zeta here is of size zeta 2 sigma t. As I said, this was at the time something that I needed to prove. The time, something that I needed to prove my prime number theorem thing with Laura. You know what I look like. This is what was happening in my life at that time. That's an exact. I'm sorry. Yes, that's inferior equal. It's not exact, of course. Yes. And wait. And this one also is not exact. Yeah, yeah. It's inferior. Yeah, yeah, it's infravory cool for these two collaborative projects of the day. List demo. Yes, and so this yeah, this has appeared this year. I think it was out for about three years already. But there's also, and please, yes, this is an inequality. Okay. So, yeah, and so Jorgena's health code, Donna, and Zuniga. So Joe Benny's health code, Donna and Zuni Galterman are where students, I think maybe one of them is a postdoc somewhere. So there you go. So I yeah, but we actually have something stronger than what I've shown you here. I mean we know that it should be that formula, I mean, plus an error term here of size t to the theta of this epsilon. Of size t to the theta of this epsilon, where theta is conjectured to be one quarter. Engan proved it with one half, and not listing everyone who contributed to make it smaller than a half, as close as possible to one quarter, but I think right now we're really still close to one third. Well, no, actually, it is getting closer. So, yes, the first actually non Uh yeah, si s anyways, Simoni Chair proved that error term with a three-quarter. So it is not it's not as good as Ingam, but still this was the first one that appeared. And this one just appeared, I mean it's on the archive for a month maybe or a few weeks. So where they recover the one half of InGam here. So there are there are some things happening right now. Are some things happening right now and there are a lot more to do. I mean, I just looking at what's going on in this topic. It is related, as it was already mentioned this morning, to the directly devisor problem. And more, so that's why I'm taking the time here to just let you know what is happening explicitly about the directly devisor problem. So there is a lot of Volonoi here, which gives us that the error. Here, which gives us that the error term is of size x1/3rd log x. This has been made explicit by Bertian Borderless and Pama Rey about 10 years ago. And it has been generalized also for higher degree device or higher degree for the TKR band by Trujem and Kali Hagil. I think also quite recently, maybe I think. Um okay, so I'm just thinking of my time. So I this is like the third part where I want to so I want I took a bit of time on the prime number theorem. First, the results are easier to state than anything that I could state in the Chibotarite density theorem. So there was a little bit of that also happening at the end. But also because all the methods that are being developed right now, every time you have to wonder Every time you have to wonder, can this be generalized? And I know that a lot can. So it is not fun work, but it is one that needs to be done, I think. So anyway, what do we know about, let's start with the prime numbers in arithmetic progression. This was a result that lasted for a very long time from Olivier Ramarais and Robert Remy, giving those explicit bounds for some. Explicit bounds for Psi XQA, bare return for Psi XQA here. And at the time, there was, they did this, verification of GRH for moduli up to, well, 400 something, and up to age, I think, 1,000 that was at the time. So we were able to calculate, to estimate the error terms here, giving you here a bit of sample with Elisa at the time. At Lisa, at the time of her master, we actually improved on that based on some further verification that Clata did for moduli up to 400,000 and going up to height, that could go up to 10 to V8 for a lower moduli. So using that, but not only, using like some of the tools that were developed for the prime number third at the time, so they were. For the prime number third at the time, so there were the zero-free region, the smoothing weight. And also, how we were using something that's not specific to primes and arithmetic progression, going from a lower modulus to a higher one, we were recycling the values that we were using for a lower moduli. And finally, I think there was also a vintage marsh inequality in the lot that helped us a lot into that. So there were a lot of ingredients we put in there. Ingredients we put in there. Maybe one day that will be published because I'm still hoping we can get it out with Elisa. But the master's thesis is out and we can consult it. And so the latest result here by Mike Bennett, Bennett et al., and it often appears in the literature, here one of the results, for instance, for Q bigger than 10 to the phi, here with an error term of good log x, the exponential. term of root log x exponential minus root log x and the x beta zero is just manifesting only when of course you have to consider the existence of the exceptional zero beta zero so that turns out here otherwise. I just asked a quick question here. Yeah sure. So would things like this go away if Jean's like preprint is actually right or no? Um um wait, uh that uh what do you mean? It it will just uh it will still be there. So that term will not appear. Or if you increase x, bigger than exponential of log q to something bigger. And you can remove because the the the gen claimed zero-free region isn't quite as large as the classical zero-free region with one exception. If you're reaching with one exception. Oh, so if you increase pulse mode, then you could. Yeah, because I know you didn't claim to show that CL0 doesn't exist, but it's like some explicit that that's basically the main attraction of that default. Yeah, I have to, to be honest, I was aware of it last weekend and I just even looked at what he's saying. Okay, so now moving from the cyclotomic case to the more general case, like writing things in generality for Galois field extension here, just looking at the prime counting function that corrects. The prime counting function that corresponds to this, and stating here the Chibotarv density theorem. So that was in 1922, and it was 50 years later that Lagarius and Olivier School gave an effective version of it, so a first error term here. So taking X large enough in terms of a degree and the discriminant, I'm sorry if I'm spinning here a bit. Welcome back if we need. But there exists constants here such that you have this size for the error. There are some results that, they are not published, but they are results of a PhD here of Binkler. I think he was in Bordeaux when he did his PhD, where the constant here are made explicit. And Surah in his master, so that was the topic of his. His master was to, well, not redo Vinkler, it was to implement the results that we have about the zeros of dedicating zeta function and the smoothing weight for size, getting this type of result here. So improving on the exponent. You can forget about the log here, it goes inside the exponent. And improving the range also, like for x where this would be valid. This would be valid. Conditionally, what do we have? Well, we have the results of Grony of Molteni in the case of the chewed art density theorem here. And we have Mval, Hitonen, and Paolo-Jamvi. And I'm sorry if I'm mispronouncing, but this is in the case of directly primes in arithmetic progression. So this is what we know explicitly in. We know explicitly conditionally. Opposite to the case of primes, one of the big questions for primes in everything progression or primes in the number field is what would be the size of a least prime entering a specific conjugacy class or arithmetic progression? And so it was conjectured, I mean, the generalized Riemann hypothesis gave us the size of this prime should be known. us the size of this prime should be no larger than q to the 2 plus epsilon it is actually conjecture something smaller than what g RH gives us more something of the size like q times a certain power block q and this is something that we have numerical verification to support with that stuff I mean they are old now but that supports that heuristic up to 10 to 44 that supports this heuristic that pays what we larger than this the main result regarding the Result regarding the least prime, we start with Linik that proves that PAQ is no larger than a fixed power of Q. And finding what power here, I mean ideally 1 plus epsilon, I guess, but this is what has been proven. The main result that in terms of method and strength is still the one of Heathrow from 1982, where the power of 5.5 Where the power of 5.5 here was proven to work. So, that in terms of article to study, this is a very rich article if you want to learn about not only the zero free region, but really sparsity of zeros and zero density theorem in the case of Dirac Lau functions. Here, this is just to show you how far we are explicitly. We are explicitly. So, that is not even a theorem, I think, at the time. It was just a consequence of what I would get with the region. Backwards, here we go. In the case of a Jupiter density theorem, under GRH, you can prove that the size of a least prime is no larger than that square log dl, log log dl to the 4 for dl sufficiently large, which balance, for instance. Large, which Balance or Renson actually produced or proved that it's not quite as big, it's really log dl square plus two times the degree here. And what Andrew Fury here proved is that Bahan Sorensen bound here is essentially close to optimal, as he found an infinite family of number fields for which you could find that lower bound for brand P. So you remember I was just talking about clinic for primes and arithmetic progression that was made, that was generalized by Lidarius Montgomery and Lovisco in the late 70s, where they proved the generalization here of Limig for primes in the primes in number. Primes in the Jupiter density theorem. And this is a topic that got some revival really starting, I think, in the early 2012 with Nathan. We were starting to, I mean, that was our open goal to make B explicit. But for that, you needed to have explicit zero free region for delegating data function, counting the zeros. You had to come up with everything. And all what was available at the time was Stark's zero-free region for log. Darks 03 region for low-line zero. So there wasn't much, there was a lot to build. And what has been wonderful is that this has been built in the meantime and it is now growing exponentially. So we are able to say some interesting things about B here. So Asif proved the first exponent here with 40, which is amazing. If you think that we start at constants of 800,000 Forscher and I think it started also in the 100 and And also in the hundred of thousands for Linux. So, directly, using a lot of what we have been able to build along the way, for like, for instance, prime analyst cooperation, you can hit constants that are starting to be interesting. That's something that with Nathan and Pengi Wong at the time who was in postdoc with us, we looked at this result as well. And in the case where DL is shortly large, and for all DL here. And so with we have we are down to 310 here. One of the on giving the refinement as well when you don't have accessible zeros. Just to give a hint on how this result came upon with PNG and Nathan, it is actually an improvement on the original result of refinement of the original result of a diaspora. Of the original result of Adelias, Montgomery, and Olisco regarding repulsion of zoos. I think that's what I'm saying here. So I'm trying to give a crude list of ingredients for this type of result, mixing a little bit what works for primes in the AP and primes in number field here. So it is interesting if you have some numerical vivification for the first time. Numerical verification for the first fields, and since Andrew here, we do actually have such results for the least primes. While you need to relate your prime ideals to zeros of Dedekin, Zeta function or Heckel function, you need to have a good idea of weight that you want to use to locate the least prime ideal here. And so these are different weights here. You would need to be able to count your zeros. Your zeros, and this is here the last result. I'm just I just I guess I don't have the time to tell you about Zoofree regions for dedicating zeta function and the During Helper phenomenon. Do I have the time? Two minutes? Two minutes? Okay, I'm gonna jump above the zero three regions because you know what it looks like and if you want to see the results, I'll just I think I should make a list actually of all I think I should make a list actually of all these papers, make them available. Actually, that's one of our projects. But yeah, don't maybe just about the repulsion here. This is what such results looks like. So if you have a zero close to one, why is it, beta zero? It exists, then it's going to repel all the other zeros on the left, yes, on the left, further left. Further left, and the close of a zero to we have such results for gamma bigger than you know bigger values, but really the part that type of result is important when gamma is less than one and even more important sometimes when gamma is real. So beta zero getting very close to one, you can see that that log term here is going to explode here, especially if beta zero is close to one with respect to one log dl. And that gives you, if you want, an unlarge zero if you really You, if you want, an enlarged zero-free region in that case. Well, I mean, where you just have that exceptional zero. And we do have explicit results. Okay, so first with ACIF here, then with PNG, and as I was saying, what we do is we come up with a better Juan's powersum method than in the original paper of Lagaris, Montgomery, and Odlisko, and that's how we just to repeat Benji's formula. Benji's formula, you just it's free lunch. Once you have that, everything is completely bad. Yes, actually Foner actually tried that and said, what do we have for the reclaim function? So that's awesome because now it's, I don't, I don't know if it's published yet, but it's very, it's fresh hot. So that's things that you're going to be able to say. You know, you're going to be able to say things about primes in AT here, list prime in AT, for instance. This is just, I was trying to give you a list of like star results that have been using explicit results. So I've told you, I've told you, I've introduced you with Harold's proof of the old ternary conjecture and Tao's merch Nihang II. We mentioned Mike Bennett. Or did I mention Mike? There. There. Yeah, so I think I can finish on that because what comes afterwards is maybe more like, this is some ideas, what can we do next? What I'm hoping you can see with those slides, it's a little bit of, it's just, I was starting to try to have an idea where are things at. One thing as you can see at this, at the end, I'm rushed. There's, I'm going to call it like the school of Olo at Foner. Of honor, of honor of these American students that are producing lots of results in the context of Chipotarev density theorem, satotate conjecture. So, there is a lot of things happening in different parts of the world. I'm not talking about them. But yeah, I just wanted to try to have where we are at. And as we start listing, you know, what we can do, there's a lot of like, but can you do this, can you do that? But can you do this? Can you do that? So I'm hoping that we can open these questions actually and see what we can do. And that's it for me. I run out of so how does it work? We have a break and then we have a discussion. Yeah, five minutes. Five minutes. Let's get a coffee. Let's get a coffee. Can do we have a coffee? No? Okay, water. I'm gonna get some water. How long is the break? Maybe just five minutes because the coffee break is after. Alphabet is something your thoughts. Thank you.  Discussion. I have to push that button. Wait, why do I stop recording? No, it's just recording.