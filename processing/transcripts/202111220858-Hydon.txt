There we go. I guess blow away. Okay, blow away. I don't. Okay, can you see that? Yes, we can. Brilliant. Fine. If you have questions, please do just interrupt and ask me because I may not see your hand. So please go ahead. My background is a little further along in Canada, just off the coast of Vancouver Island near Tofino, where we went whale watching one visit to Canada. So I'm sorry not to be able to join you in Banff just now, but I have very happy memories of visiting Banff and indeed other parts of Canada previously. Of Canada previously. So, this talk comes from work done partly by my PhD student, Lewis White, and partly by myself. It stems from a paper that Liz Mansfield, Anna Roho, Eke Barua, Lin Yupeng, and I did on ordinary difference equations. And what I want to do in And what I want to do in this one is to try to set out a little bit more about the geometry of partial difference equations and how that relates to standard differential geometry. Because I think that's essential for getting a clear understanding of where moving frames fit in and how moving frames actually capture the different structure or can capture the different structure. So without further ado, I will continue. Without further ado, I will continue. So, a little bit of notation. I'm going for the simplest case of everything being defined on the easiest possible space, which has m independent variables in Z and Q dependent variables, real dependent variables. And so the total space is just the Cartesian product of Zm. Cartesian product of Zm and Rq. The thing about each independent variable is that they are ordered. They're not just discrete points, but they're coordinates in an ordered set. By contrast, the dependent variables are very familiar and they coordinate continuous fibers. So Although I've chosen the simplest case, we can take this as a local picture and string things together to put them together on complicated lattice varieties with holes and things like that, building on some work Liz Mansfield and I did some time back on how to put together difference forms on topologically non-trivial spaces. We can also look at fibers that are not Not copies of RQ, but I wanted to look at the simplest case today. So, this is the total space, and in the case of one independent variable, one dependent variable, here it is in the case of two independent variables and one dependent variable. And more generally, if you've got more dependent variables, you're going to have some continuous fibers sitting over discrete base points. So, this is a disjoint. So, this is a disjoint union of manifolds, you could say. Now, to do moving frames, what we want to do is to represent this as a connected space, as a manifold, and we can do that by using and exploiting those ordering properties. The thing about the total space is it's invariant under translations, and a translation by J By J, where J is in Zm, takes each fiber to the fiber J along from it. And the translation only changes the independent variable. The dependent variables are unchanged. So it's purely a straight horizontal translation. And what we're going to do now is to Do now is to prolong the fibers infinitely in all directions to get the infinite product space whose coordinates are the pullback by those translations of the coordinates on the other fibers. In other words, we're reading off all the other values and making that part of the space, the prolonged space, over a single. Over a single independent variable n, a single point n, I should say. And so any graph on the total space, which I've abbreviated to u as f of n, is going to be represented on this prolongation space by each coordinate taking the value that f would take at the fiber over n plus j. Now, of course, this whole picture doesn't depend which n you use. So every n has a prolongation space. And if you compose the pullbacks in the usual way, you get a relationship between the coordinates on the prolongation space over n and the prolongation space over another point, n plus k. So all this is quite standard differential geometry. Is quite standard differential geometry. All we're doing is relating maps between manifolds, and it's all nice stuff. But it means we now have a continuous space on which to work. In order not to clutter us up with notation, I've done a somewhat simplified notation for the space of functions. And I'll just put an f in front of any space to denote the space of functions on that space. On that, uh, on that space, with a limitation that all prolongations must be finite, so I don't want to deal with singularities, we can deal with them, but that detracts from the generality of the easiest case. So the pullback then, which takes functions on the prolongation space over n plus k to functions on the space over n. Space over n is going to be represented on the prolongation space over n by the shift operator. And these two things are quite different. So it's worth just recognizing that the pullback maps different fibers to one another, whereas the shift operator is an operator on the single fiber over n, the prolongation space over n. So it's a discrete operator. It's a discrete operator on a continuous space. And it acts exactly as the shift operator always acts. It replaces n by n plus k wherever you look. And that includes in the indices under functions. I hope this is clear. I've tried to simplify the notation, but it is true to say that there's a Is true to say that there's a very notation-heavy area, and it's quite difficult to convey it simply. So, we've got a prolongation space, we've got a representative of the translations, that is to say the shift operators, and we're going to work with that prolongation space rather than the disconnected token space. All functions are going to be in this. Are going to be in this functions on the prolongation space over n. Okay. And that means we're going to assume all prolongations are finite. Okay, now difference operators are not the fundamental operators in quite the way that differential operators are for the differential case. It's really the shift operators that are fundamental. But nevertheless, Fundamental. But nevertheless, you can make the forward difference or indeed the backward difference by combining shift operators. And if we let the shift in each direction be denoted by SI, that's the shift in the ith direction one step forward, and the identity is stay where you are, don't shift it at all, then the forward difference is just the distinction, the difference between those two. And so you get the idea of the divergence being pretty much exactly what you would think from the finite difference approach, except that we don't have a step size in here. Nothing to stop you rescaling and putting a step size in if you want to do numerical approximation. But a difference divergence formally is just an expression of the form given. So that's summed over I. I'm always using, incidentally, the Einstein. Always using incidentally the Einstein summation convention and indices rather than vectors, matrices, and that sort of thing. I think it's less confusing, but I know there are differences of opinion. So a nice easy lemma: every expression of the form shifted j minus the identity of something is a divergence. Is a divergence. And that's just a case of unpacking the definition. Shift of J is the product of a lot of shift of i's, and you just unpack it, and you can always write it as a divergence. Another useful lemma is that, well, it's a theorem really, a function is a divergence if and only if it vanishes, it's in the kernel, that is, of every. Kernel, that is, of every Euler operator. So we introduce here the Euler operators, and you can see it's you differentiate with respect to the forward shifted U, but then pull that back by using the backwards shift the same amount. Please stop me if you. Please stop me if anything isn't coming across clearly, or you can't hear me. Just let me know. So a difference operator is basically not what we would think a combination of the DJs, rather I want to write it as a combination of the shifts, each fj being a function. And typically we will only look at finite combinations. Combinations, but in principle, you could generalize. The formal adjoint of a difference operator is the unique operator such that that quantity displayed is a divergence for every F1 and F2. And so, for instance, the adjoint of the forward shift is the backward shift. Of the forward shift is the backward shift by the same amount. It takes you back to where you started. But other things are found very readily. The shift operators are extremely intuitive. They're homeomorphisms. And a conservation law of a given system is a divergence that vanishes on all solutions of the equation, not identically zero. Not identically zero by convention, but we could include zero. Okay, a few definitions there. So for those that are more familiar with the differential case than the difference case, I thought it would be helpful just to spell out what notice theorem looks like in the difference case. And we're looking here at Euler-Lagrange equation. We're looking here at Euler-Lagrange equations with the Lagrangian. I'm using upright font L for things that are in terms of n and u, the variables. This square brackets around a variable or any expression indeed means the expression and a finite number of its prolongations. So that really means a finite number of the uÎ± j's. The Euler-Lagrange equations are EU alpha of L is zero, as you would expect, but EU alpha we've already met. It's just back there. So it's that same operator. Also, we can talk about generalized symmetries. And if it's point symmetry, the characteristic doesn't depend on shift. Doesn't depend on shifts of u, just on u itself. If it's a generalized symmetry, you can depend on shifts of u as well. But the generator is extended in the usual way. And this is a variational symmetry if when you apply V to the Lagrangian L, you get a divergence. This means that This means that summing over all points, that essentially the Lagrangian functional isn't changed. So, this is very, very much the same as for differential equations. A little bit of algebra here. If we take this expression on the left and unpack it slightly, shift J operates on a product term-wise. product term wise. So shift j of q alpha s minus j is going to be s j of q alpha times this thing, which is exactly v of l and so unpacking that and I don't expect you particularly to follow the algebra. It just gives you something on the right hand side that looks like this. If you've got a variational symmetry with this thing being zero, what you've got Being zero, what you've got on the left-hand side is a divergence, and on the right-hand side, you've got a sum of characteristics times Euler-Lagrange operators. And so, on the solutions of the Euler-Lagrange equations, the right-hand side will be zero and the left-hand side is a divergence. So, in other words, every variational symmetry yields a conservation law for the Euler-Lagrange equations. Lagrange equations. And the converse is absolutely the same as in the differential case. That's also true. All you do is reverse the argument. This doesn't say anything about unique bijections or whatever between equivalence classes of characteristics and equivalence classes of conservation laws. To do that, you have to get into. To do that, you have to get into something like Kovalev-Skyaform. There's a difference version of Kovalev-Skyaform, and you can prove uniqueness in that respect. But this is purely Noether's version, which establishes the two-way correspondence between variational symmetries with a finite group and conservation laws. Okay, so this is a workshop on moving frames. I've got to get onto moving frames. We're going to consider a Lie group of point transformations, left action on this prolongation space being free and regular. Now, the prolongation space has all prolongations on it. So the normal necessity that Necessity that, or the common necessity to prolong, is not needed here. It's there already. Every characteristic, and we're talking about point transformations here, so Q doesn't depend on shifts of U, just on U. Every point, every characteristic generates a one-parameter subgroup, and there's the one-parameter subgroup. Equally well, the action. Equally well, the action of every group element prolongs to an action also on the prolonged coordinates u alphaj. Okay, we're in a continuous space. We can do the moving frame construction and we'll do it as usual. As this is the first talk, I felt I was allowed to. I was allowed to put in details of the standard construction because I thought it should be mentioned somewhere. If no one else has put it in, then I've won. And if not, then I apologise to the people who are coming after me. But we choose a local cross-section transverse to the group orbits defined by some equations. And we're going to choose. And we're going to choose these points, z, to be our coordinates from u and its prolongations, and wherever possible, u at n, that's all the u alphas at n, and nearby points. One always has to choose a normalization that is going to be sensible and efficient, and there's a bit of an art to that, but one can use. One can usually manage it by restricting to U and at n and nearby points. So, the picture of a moving frame is you've got some distinct group orbits here coming across. You have a cross-section that is transverse to those group orbits. And on a particular orbit, ODZ, there's a single point where the section and the Section and the orbit meet. And the moving frame is the group element that takes a point Z, the point Z, I should say, to the intersection there. And so this splits up the space into movement along orbits and movement transverse to the orbits. First, to the orbits. Very handy. So, a difference moving frame, we're looking at an equivariant map in this context from the prolongation space to G obtained by solving the normalization equations. And here they are. You're just looking for the group parameters that will satisfy these normalization equations. Equations and that gives us the frame g is rho of z. I ought at this point to say something about the link between the difference moving frame and discrete moving frames, because the framework for discrete moving frames, the paper by Gloria, Liz Mansfield, and Jingping Wang, is really, I think, the best. Think the best thing to read on this subject, it really is. So a difference moving frame is a discrete moving frame. But a discrete moving frame is defined on a finite prolongation of the total space. And basically, you're defining product spaces that are large enough to make the action free. And then you're comparing these product spaces as you move from point. Product spaces as you move from point to point. This isn't any discrete moving frame, however, it's a moving frame that's invariant under those translations. And so the effect of that is that the shift operators play nicely and you preserve the ordering. Now, in fact, in the paper by Gloria, Liz and Jingping, I think all the examples they considered were of this. They considered were of this type. But this sort of formalizes a little bit. The point is, discrete moving frames are more general. There's no need particularly to have them in an ordered space. They are quite distinct. So a function is invariant under the action. invariant under the action of the group if when you apply the group to it nothing happens and that's basically defined in that condition and that should be for every group element g the moving frame defines an invariantization operator which I'm using dotless i a fairly standard convention and what we do there is to apply the group element define To apply the group element defined by the moving frame. So g here is rho of z. And that takes a function and invariantizes it. And the Thomas replacement theorem then says if you invariantize an invariant, it stays where it is. A useful result here is that to Here is that to find the settable G invariants, all you need to do is to look at the U's on N, that is U alpha naught, invariantize those, and also use the Marakartan invariants. And these were defined in the paper by Liz, and Gloria and Jing Ping, adapted to the context of difference frames. When I say generated by, what I'm concerned with here is if you can apply shifts, you can create functions of these things, and all of those things will be invariants. So these are the fundamental invariants from which everything else comes. Invariance from which everything else comes. I thought I've been a bit heavy on the theory so far, so I want to just consider an example. And this is an example with a bit of a catch. We've got a Lagrangian here, and it's actually a Lagrangian that arises in practice for a particular tota-type Euler-Lagrange equation, and it's this one, which people from integral. This one, which people from integrable systems will be familiar with, at least discrete integrable systems. It's an equation that is satisfied by both the discrete potential KDV equation and also the cross-ratio equation. It's created from the three-legged form for those that are keen on integrable systems and know about such things. So it's a genuine Are genuinely an equation of interest. It's got quite a lot of symmetries, apparently. There's a six-dimensional Lie algebra of characteristics, and here they are. In fact, they sort of look quite paired up, really. There's one set over on the left, which looks like One set over on the left, which looks like an SL2, and there's something else on the right, which is just minus one to the n plus n times those original three. And this does indeed make two copies of SL2, but in a rather unusual way, which I'll explain in a minute. I'm only going to look for this example at the subgroup generated by the first two of those. Lewis has looked at a lot more. Lewis has looked at a lot more. There's a limit, I think, to what one can do in a talk, and it gets a bit messy. However, this subgroup is just scalings and translations in U. And I've given the action on all of the U's. So that is straightforward. A here, however, is. A here, however, is in R plus, and that means that we have to use a normalization that is consistent with that. So I have to assume for this one that u11 is greater than u naught. And if I do that, then I can take this normalization. And then that gives me my coordinates in terms of the two values. Two values of u, u at zero and u at one one. If u had been less than u0, then a normalization with g11 is minus one would have been appropriate. Okay. So the Marie-Cartan invariants give us some generating invariants. Give us some generating invariants. And these two here that I just want to focus on, and kappa and lambda, they're slightly unusual in that one is a shift two along in one direction rather than one, and the other one is a shift one forwards and one back from zero, or if you like. From zero, or if you like, it's one one shifted backwards by two. But they're perfectly good generating invariants. And indeed, you can then work out the invariantization of an arbitrary UIJ and write that in terms of kappa and lambda within reason. This is an arbitrary UIJ that This is an arbitrary UIJ that occurs in the equations. And the invariantized Lagrangian is then this thing. Now I'm using a slightly different notation for invariantized quantities. So whereas my Lagrangian in terms of n and u is denoted by an upright L, the Lagrangian in terms of The Lagrangian in terms of lambda and kappa is denoted by a slanty L. This is to try to stop running out of symbols, because, as I say, it's a bit notation heavy. Okay, there's a problem with this equation, and that is that a phenomenon arises with this that only occurs for difference equations and Equations and indeed differential difference equations, but not for differential equations on their own. Because the total space is disconnected, things can happen differently on one fiber without affecting another fiber. And if we go back to the Lagrangian and indeed the Euler-Lagrange equations. Euler-Lagrange equations, you will see that the Lagrangian here involves U and it involves things that are an even number of shifts from U00. So we've got U1 minus 1, 1 forwards, 1 back, U11, U20. But there's nothing there that's an odd number. There's nothing there that's an odd number of shifts from u00. And equally well, the Euler-Lagrange equation also has an even number of shifts from u00. And indeed, this apparently six-dimensional Lie group gets worse, because if you combine the generators, if you combine the characteristics, I should say, if you take the average of, let's say, Q1 and Q4, you get something that is one when n. That is one when n1 plus n2 is even and 0 when it's odd. If you take half the difference, you get something that's 0 when n1 plus n2 is even and 1 when it's odd. So actually, you've got two completely independent lattices here stuck together, each with an SL2 Lie algebra of their own, and in principle, each being able to act entirely independently. Able to act entirely independently. And that's shown in this picture by the fact that some of them are red and some of them are blue. If you think about initial conditions, if you specified some initial conditions on a blue lattice, the differential equation on a blue sublattice, I should say, the differential equation would tell you a number. The differential equation would tell you enough to specify it on all the other blue points, blue lattices, but not on the red ones. And so you really have different things going on here potentially. It can get worse in the sense that you can have partitioned equations like this, where you've got a number of lattices working completely independently. You can have them with different symmetry groups on each lattice. them with different symmetry groups on each lattice. There's nothing whatsoever that says you have to have the same symmetry group on each lattice. For the case of this total type system, it is the same. And so I perhaps ought to say, to confess that when I said the Marakartan invariants yield generating invariants, the Marakartan invariants are actually first order departures from this. Departures from this, and we had to take two steps by composing two of the Marakartan invariants to be able to maintain our position on the lattice of a single parity. It doesn't really matter because you can, there's nothing to stop you using the same normalization on both lattices, but it is a complication and should be borne in mind when you're dealing with difference equations. Peter, can I ask you a question? Yes, of course, please do. Goes, please do. So, I thought you had said at the beginning that there is some sort of shifting variance here, playing here. Yeah, not shifting variance. And I was wondering if that would relate the two fibers that you have there in any way. Because the way you're talking about it, they seem to be completely independent once you choose the initial condition. So the fibers themselves are related because absolutely the translations are there. But when you restrict to solutions of the equation, because the equation only does, say, the blue ones or the red ones, but not both, once you're restricting down to solutions of the equation, then you only see the ones of the same colour. And therefore, it's only the shift. So you can still build your prolongation space. But the equation is the same, right? But the equation is the same, right? The equation is the same, but it acts on the two bits separately. And so, what you get is a solution that takes one set of values for n1 plus n2 even and another set of values for n1 plus n2 odd. Okay. So, if you were if you were to choose the same initial condition in each fiber, you would get the same thing. You get the same thing. Yes, absolutely. Great. Thank you. Okay. Okay, so with that sort of background, I think we have enough now to construct the invariant Euler-Lagrange equations. More generally, we won't just have two invariants, we might have a fair number of them, so I'm going to denote those by k beta. And I'm going to restrict attention to Lagrangians that are invariant under the group action. This is just for simplicity. One can do a transformation to deal with the other problem. To deal with the other problem. Other sorts of problems where you have divergence variational symmetries. But we'll just take the branch into be invariant for simplicity. So then we define slanty l, which depends on n and the invariants and their prolongations to be the invariantization of the Lagrangian in the original. Lagrangian in the original coordinates, and that, of course, is the same as the Lagrangian in the original coordinates in terms of what it actually does. If we introduce an invariant dummy variable and think about it going along a smooth path, an arbitrary smooth path in the prolongation space, then just doing a standard calculation and Differentiating L, we get some derivatives of shifted quantities. And if we move the shift back to the other side, we get the Euler operator acting on that should be capital L, sorry, upright L. That's a typo. I'll fix it before I upload the talk. Times U naught alpha dashed. Okay. Plus a divergence. Plus a divergence. Okay, and the divergence is whatever it is. And so if we define sigma alpha to be the invariantization and apply the sorry, I'm getting Peter. Are you talking? Thank you. I've got a lot of feedback. Thank you. I got a lot of feedback, but no, I couldn't hear what you were saying, Gati. Sorry. As a reminder, if you're in the room, make sure you have your speakers off and you're muted. Okay, brilliant. Thanks. So yeah, the invariantization goes across and there is a bit of non-trivial stuff to do to prove that the invariantization of this particular divergence is also a divergence. That's not trivial. That's not trivial. You can do the same calculation with the form of the Lagrangian in terms of the invariance. And again, you get an Euler-Lagrange operator acting on the invariantized L. The difference, I think, being that setting these to zero is not the same. These to zero is not the set of Euler-LeBranch equations. It's a little more complicated than that. And again, a divergence. Now, this divergence I'm writing in terms as a difference operator acting on these quantities, because I think it's quite important to emphasize here that this expression is linear in those derivatives. To complete the calculation, we need to write down the differential differences, scissogies. And basically, it's a case of writing each kappa beta in terms of the u's, differentiating and finding out what difference operators, and there'll be invariant difference operators, occur here, multiplying the or acting on the sigma alphas. And so you plug that into there, integrate one more time to replace this H alpha beta sigma alpha by the adjoint and this thing by a sigma alpha. And that gives you an extra term over here, another set of difference operators acting on sigma alpha. So So, comparing what we have on this slide from what we had on the last slide, there's only one set of terms on the right-hand side of each that is proportional to sigma alpha. And it's this one on this slide and this one on the previous one. So the two are equal. And this is the invariantization of the Euler-Lagrange equations. The final step then. The final step then is to say, okay, suppose we don't just take any path now, but we restrict attention to a path that is actually to do with the group parameter for the group subgroup, one parameter subgroup generated by the characteristic QR. Kappa is invariant, so kappa dashed is zero, and so L dashed is also zero, because L is a function of N and Kappa. Also, zero because L is a function of n and kappa and prolongations. And so you get that rather complicated expression from the last time shrinking down. And that term vanishes. And that term, those terms, I should say, vanish. And you've just got a short expression there. This looks quite a lot like Nerta's theorem in the case when there's no divergence, in the sense you've got the Euler Lagrange equations here. Got the Euler-Lagrange equations here, and that's the invariantized Euler-Lagrange equations, and you have a divergence here. The last little bit of that is to do some calculations as to what the sigma alphas are on this path. And it turns out, it's a bit of a messy calculation, so I haven't included it, but the sigma alphas are exactly. That the sigma alphas are exactly the invariantizations of the characteristics multiplied by the components of the adjoint matrix for the moving frame. And so essentially we have Noether's, an invariant version of Noer's theorem here. Okay, that's a very speedy tour through Through what I see as essentially the bare bones of moving frames for difference equations. It's a slightly different approach to approaches taken using product spaces more widely because it restricts and tries to build in the ordering that's their intrinsic indifference equation. Intrinsic in difference equations. Obvious applications are to things like numerics, but there are plenty of discrete systems that are of interest in their own right, not least discrete integrable systems. So I think I'm going to finish there and ask any questions. Thank you. Please shout out because I can't. Please shout out because I can't see you. If nobody else has a question, I actually do have a question. So, in the example for the difference equation that you did for the Euler-Lagrange equations, you had this decomposition into the even and odd parts of the lattice. And I was just curious, because I had read recently from Bobenko, who's over in Berlin. Who's over in Berlin? He has integrable systems that are defined in terms of the black and white graphs. Yes. Is that what's happening here? And can you speak a little bit more to that? I don't feel as qualified to speak about it as he would be in the sense that I'm not really from integrable systems. I just have a nodding acquaintance, let's put it that way. So he would certainly be able to tell you a good deal more about these sorts of systems. About these sorts of systems. I've come at it more from the differential geometry point of view of: okay, let's think about these as geometric spaces and what happens there. But there is this oddity, and it's really to do with when you restrict it to particular differential equations. And integrable systems are a prime source of such equations. So there are plenty of examples. I've just chosen one of the easier ones. 