Amazing so far. So, the story that I want to tell you is one of random edge flips and a bit later random planar maps. It mostly comes from joint work with Alexandre Stauffer, who's now at the University of Baath. But to begin with, I'd like to present something about random edge flints that's a bit more classical, sort of an archetypical problem in this. Problem in this field that concerns triangulations of the n-gon. So suppose you have a triangulation of the regular n-gon, so maximal arrangement of diagonals that do not cross each other, and we're going to consider a random operation on this triangulation. That is, we're going to pick an edge, well, a diagonal uniformly at random, draw n minus. draw up n minus 3 and then with probability one half we're going to do nothing and with probability one half we're going to flip that diagonal that is we're going to replace it with the other diagonal of the quadrilateral that's formed by the two triangles adjacent to that original diagonal and this way from our original fixed triangulation of the n gon we get a random triangulation of the n gon. Triangulation of the M-conf. Now, if we perform a sequence of independent edge flips, then we're defining a Markov chain on the state space of all possible triangulations of the end-gone, right? So this is the triangulation walk. We're walking in the space of all possible triangulations. And the sort of questions that we're going to be asking. That we're going to be asking concern the behaviour, the long-term behaviour of this month of June. So if you perform T steps starting from any fixed triangulation, it's quite clear to see that what's going to happen is that the probability distribution after t steps will approach the uniform distribution on all possible triangulations of the end-going. And the sort of question that And the sort of question that we're going to ask concerns the timeframe over which this convergence actually takes place. So how long does it take for the Markov chain to sufficiently approach the stationary uniform distribution? Where this approach, well, one good way to formalize it is via the total variation distance between the probability distribution at time t. Distribution at time t and the stationary distribution. And we could define the mixing time of this Markov chain as the number of steps necessary to come within a certain threshold distance of stationarity. Let's fix 1 over 4 as a standard. Whatever the starting triangulation. Right? So as a matter of fact, having fixed n Having fixed n, this mixing time for a single Markov chain is just a number, what we're actually interested in is the asymptotics of this mixing time as a function of m, which is a parameter that's of course related to the cardinality of the state space neuron, which in particular is essentially exponential in M. And so the sort of result that we would like to Result that we would like to see, and we'll see what results are available in the case of the triangulation walk, and then I'll generalize to some different models, is, well, a polynomial estimate for the mixing time as a function of n. And as a matter of fact, okay, I've let n tend to infinity. This should not be half me, but hopefully But hopefully, we were here, more or less. So, the triangulation walk was introduced originally by David Aldiss in the nineties, and it came more or less immediately with a conjecture. With a conjecture for the growth of this mixing time of polynomial type. Now, as a matter of fact, what I've written there is not T mix, I've written the relaxation time. In this talk, I will use mixing time and relaxation time kind of interchangeably because what I will care about is just polynomial growth and polynomial bound for the mixing time is a Bound for the mixing time is equivalent to one for the relaxation time, even though it's a little bit different. And while the relaxation time has a bit of a more intrinsic definition, it still gauges the rate of convergence towards stationarity. We can write the transition matrix for this Markov chain V, and the relaxation time is nothing but the inverse of the spectral. The inverse of the spectral gap of this transition matrix. What is the extra factor for mixing time? Is it like n? It's n log n in this case. So for the upper bound and then the mixing time is greater than or equal to the relaxation time. N to the 5, yeah, as well as the 0. Yeah. So right. So just for clarification, the reason you did well passed. And the reason you did one house is it because you wanted to add laziness to the master. Precisely. Indeed. That's all it is. Alright, so and one reason why I'll be mentioning the relaxation time more often than the mixing time is that there are ways to estimate the spectral gap. In particular, you can use a variational characterization of the spectral gap as a minimum over all possible. A minimum over all possible real functions on the state space of the Dirica form. And this computed in that real function. And this means that we'll have a relatively easy way to give at least lower bounds for the relaxation time. And this will come into play at the very end of the call. Alright, so that was a conjecture. What is known about the What is known about the mixing or relaxation time of the triangulation walk? Well, a lower bound of the same kind, so this sounds good for now, but as far as upper bounds for, say, the mixing time, so up until recently, the best known upper bound was from a paper of Thetalian McSchein, still from the nineties. Still from the 90s and of order n to the five log n, so n to the four actually for the relaxation time. So as you see, there's a big gap there, not exactly what we were expecting, right? And as a matter of fact, a paper has appeared on the archive this summer by David Epstein and Daniel Frischberg. I haven't put it into the slide up. Push it into the slide, unfortunately, but they give an upper bound of order n to the 4.75 for the mixing time. So indeed an improvement, but we're extremely far from what we would like. So let me give you a little bit. Did you say that now and no end 10 to infinity doesn't fix and is it known something about the mixing time or relaxing? Any maximum time of relaxation? I mean fix which fixed M in what? Just a fixed M and then it's known, like a not M going to be, let's say. I mean you could compute it. But yeah, the interesting behavior would be for a very large N. And I'm not sure how far you Not sure how far you can go with finite. But yeah, so what I wanted to give was a little extra context and say this problem of estimating the mixing time of the triangulation walk came together with other problems about similar Markov chains on cladograms, for example, which have possible implications in. Possible implications in systematic biology and generation of cladograms for modelling evolution of species was part of the motivation for considering this triangulation walk. And something I wanted to say is I think already with the first slides it's been pretty clear that it's a difficult problem to give sharp bounds for this mixing time, but you could Same time, but you could consider, of course, edge-flip chains on all sorts of different models. And, for example, a model I like very much that we're working on right now with Ali Jambre is that of lattice triangulations. And for edge flips on lattice triangulations, not even polynomial mixing is known, for example. All right. What we have considered is. Considered is edge flip Markov chains on a range of models that have to do with planar maps. And now I will try to present a little bit of that, how that works. I have a question. I may be stealing your thunder from later on. Go. Are we going to find out? I mean, that is, have you solved the edge cliff, the triangulation question? No. No, okay. Absolutely not. No, okay. Absolutely not. Very, very disappointing, but we've started there to argue that it's a difficult problem in general. There's still 15 minutes left in the talk. Well, by the end, we'll see if you have ideas. Okay, so what I wanted to do is discuss how would edge flips behave on models of planar. On models of planar maps, which are those I've been mostly working on. And within this talk, I will talk mostly about quadrangulations of the sphere, just because it's the easiest case. But we can work with a range of different things. And so a quarangulation of the sphere is something like that. I'm hoping that the picture already says basically everything. But let's say that a quadrangulation of the sphere of size The sphere of size n is a multigraph endowed with a cellular embedding into the two-dimensional sphere such that the faces induced by this cellular embedding are n and each face has a contour of length 4. So it's a quadrangulation. Plus, we're going to be considering rooted quadrangulations because that helps immensely with That helps immensely with enumeration, everything works better. Our quadrangulations will be endowed with a distinguished oriented edge all the time. And on these quadrangulations of size n, I can still consider an edge flip Markov chain, which will work how? Well, I will choose an edge uniformly at random. Now, if there are two n if there are n faces, there are two n edges. Faces, there are two n edges, actually. And what I will do is, with probability one-third, the edge stays the same. With probability one-third, it rotates one step clockwise inside the hexagon formed by the two adjacent orangular faces. With probability one-third, it will rotate one step counterclockwise. Alright, so that's my random edge flip. As a matter of fact, I've only lied a tiny little Only light a tiny little bit. I don't know if we can see it, but in this model for quadrangulations, not all edges are adjacent to two different faces. So there's the possibility that I pick an edge that's adjacent to the same face on both sides. What I'll do is just with probability one-third it stays the same, and with probability two-thirds, it flips to the other edge within the current face it's in. But this is not. Phase it's in, but this is not important. So if you consider this edgeflip-Markov chain, what we have is a lower bound for the relaxation time of order n to the 5 over 4 and a polynomial bound for the relaxation time not that near n to the 5 over 4, as you see, because it's n to the 11 over 2, but still polynomial. And I wanted to tell you. And I wanted to tell you a few words about how the proof of the upper bound goes, but just a few words. So that's the most interesting part, of course, and the most difficult. The way we prove the upper bound is via, for people who know how that works, probabilistic canonical paths. And the way we construct these canonical paths, which perhaps I should have focused on. Which perhaps I should have focused on because people here, I get the feeling, might have been interested in this topic, is by building uniform growth schemes, in this case for quadrangulations. So what we do is essentially couple quadrangulations of size n with quadrangulations of uniform quadrangulations of size n, with a uniform quadrangulation of size n plus 1, in such a way that the quadrangulation of size of Way that the quarangulation of size n is obtained from the one of size n plus one by squashing a single face with probability one. Equivalently, we're giving a way to grow quadrangulations uniformly at random by adding faces at random locations one at a time. This is the main ingredient in the proof. And the other ingredient is explicit enumeration asymptotics. Enumeration asymptotics, which are really easy for quadrangulations, because essentially those are enumerated by Catalan numbers. Times 3 to the n. Okay, and this is what I wanted to say about the upper bound and the fact that these main ingredients were able to replicate for a range of different contexts. General maps, so no restrictions. General maps, so no restrictions on the degrees of the faces. 2p angulations are still pretty easy. Simple triangulations are more difficult because they're not bipartite and that's somewhat bothersome in this context. You can do similar things on trees. You can apply this same method to the triangulation walk. Unfortunately, you get a polynomial bound that is not better. It's quite near, but it's not better. It's quite near, but it's not better than the best known upper bound. So this is it. And I think I still have a few minutes right now. Yeah, right. So what I wanted to do, because in talks, however short they might be, I always try to at least prove a little bit. I'd like to attempt to give you an idea. Attempt to give you an idea how to prove the easier part, that is the lower bound for the relaxation time, and thus maybe give you an intuition that might bring together the different lower bounds that you would get in different contexts, including the triangulation work. So let's do this. So let's bring back our dear cliff form as I'd written before. So that is Written before, so that is the spectral gap of my chain. Let me rewrite the Dirichlet form in a way that makes it ready for us to do a few computations. I've just written what was there with some specific big F. That's a function from the set Qn of all possible co-angulations of the sphere with n faces to the real numbers. So I want to choose a nice function. To choose a nice function f that will give me a good estimate for my spectral gap. And the function I'm going to choose is the radius of my quadrangulation risk scaled by n to the 1 over 4. Now the radius is the maximal possible distance between the origin, the tail of my root edge, and a vertex of my cograngulation. And now the scaling. The question: why people need to scale at all? Question: Why do people need to scale at all? Because they take the scale. You don't. You don't at all, but I've scaled it already because it will make it easier to track what's going on in there. And it already gives us an idea of why some n to the 1 over 4 will appear inside that estimate. And the reason is that that is the typical scale of a uniform quadrangulation with n faces. With n-phases. And as a matter of fact, you've heard about the Brownian CRT multiple times this week as the scaling limit of various models for trees. Now, for uniform random coangulations, you can still arrive at a scaling limit, and that is called the Brownian map. Yes. Yes, in the gamma that you are calculating, it's not infinite, it is minimum, right? So it's achieved. So it's achieved. So can you get that fixing? No, I mean, I wish I knew that that was the minimum, but I don't. So that's just about. You can try different functions. Lots of different functions actually will give you the same. So that makes the conjecture that that's the actual minimum stronger, but I can't prove that to you. Alright, so yeah, I've Alright, so yeah, I was arguing that n to the one over four is the right scaling for the the diameter or the radius of a uniform quadrangulation of size n. Alright, so let's do a couple of things. First of all, first silly trick, let's just, instead of summing over all possible flips, since our flips are symmetric, we're just going to sum We're just going to sum over the flips that increase the radius of the quadrangulation and double. So that's it. And then notice that the reason why I rescaled already was that if you look at the denominator, the variance at stationarity, pi is the uniform distribution of my f, I've rescaled it in such a way that now if I let n go to infinity, f. And go to infinity, f converges towards a random variable which is the radius of the Brownian map and is a non-trivial random variable whose variance is finite. So I can just get rid of that and get a constant as an upper bound. All right, let's work within that a little bit. The probability of a single flip that P of Q goes to Q prime is essentially one over N. Is essentially 1 over n, right? It's 1 over 6n. And why have I chosen the radius? Well, because the variance it achieves is not too small, but at the same time, it's really difficult to change the radius a lot by performing a single flip. That's the idea of a function that's going to work well for this bound. And in particular, if I make a single flip, the radius of the A single flip, the radius of the quadrangulation is going to change at most by 2. And so I can replace that difference with a constant over square root 10, that difference squared. So I have 1 over square root 10 and 1 over n. And all that is left for me to do is to estimate that sum of pi of q, which is, for a uniform quadrangulation, the average number of flips. The average number of flips that increase the radius. And so, one last idea is what I'm going to do is consider all the vertices that have almost maximal distance in my quadrangulation from the origin. Those are the red vertices. They have distance at least radius minus 2. And now for each of them, I'm going to draw a geode. I'm going to draw a geodesic to the origin for the graph distance in my programmation. And now notice that if I flip an edge that's not part of this red network, the radius cannot increase because distances of vertices that are not red will not reach and go over the radius. And the red ones will still have their geodesics intact. And so I can. Intact. And so I can estimate the number of bad flips just with the number of red vertices times the length of the geodesics. So at most the radius of the quadrangulation. And now all I have to do is, well, I can just do a Cauchy-Wartz to separate these two random variables, the number of red vertices and the radius of my quadrangulation. Micrograngulation, I need to absorb n to the 1 over 4 in order to get my original f squared. But this is just what I get with the Cauchy watts. And E of f squared now is finite. I've said that f converges to something whose moments are all finite. And it's not difficult to see that the number of The number of red vertices is also going to be a random variable whose moments are all finite. And so that doesn't count, and all I'm left with is an estimate of n to the minus 5 over 4 as an upper bound, times a constant, as an upper bound for the spectral gap. And so as you see, you have a one over n that comes just from the flips. comes just from the flips, right? And an n to the 1 over 4 that comes from the typical scale of the distances or the radius in a random quadrangulation. If you think of the triangulation walk for triangulations of the n-gon, you get a 1 over n from the flips that you can't avoid, and then 1 over square root n, which is the typical scale in terms of the graph distance. Terms of the graph distance of a uniform triangulation of the angle. And with this, I'm done. Thank you very much. Yeah? I have a question for the upper bound on the relaxation time. You had a slide where you put the word probabilistic in parentheses before canonical tests. Does that mean you're choosing the canonical test? Mean you're choosing the canonical path randomly? Yes. Yep. So I guess I just am wondering for the triangulation random walk if there's like a mathematical reason why you want the laziness if that's like better than not. Just for enforcing eye periodicity. And so and it doesn't really change. I would change the mixing time by just a factor of the same thing. Yeah, exactly. Precisely. Yeah, it's precisely a little speculative, but if the Markov chain is fed up of the appropriate factor, but we don't know what that is, then it seems like it induces in the limit some kind of stationary process on the Brownian map. And I don't know if you know anything about that. We've looked at it. It tells you anything about what scale it should be? So that would be a really really interesting project to take on and it's something that I would like to look at in the future but so far so with much easier Markov chains that we understand better, we know what the mixing time is, it's been possible to show convergence to a process on real trees, right, that has the Brownian CRT. That has the Brownian CRT as stationary distribution. But this has been actually quite hard. Like, there are two independent groups that have formalized this convergence in slightly different way. You need to weaken the notion of convergence a little bit. And it's an easier chain. So it would be very, very nice to show convergence to a process that has. Convergence to a process that has the Brownian map as stationary, but I'm not that hopeful that it's technically that feasible. And in particular, I'm not sure that it would be easy to go the direction of first showing something in a continuous limit and deduce something more about the discrete Markov chain from that. Or at least. From that. Or at least. So, from these other models, there is already a dynamical Brownian map that some stationary process has a Brownian map, but every time it comes from a different way of getting the Brownian map of the limit sometimes. So that's four trees, but yes. But is that it's the same limit uh object Brownian map, but not necessarily the same stationary cross-legged on the column. So, what I was saying is nothing exists for the Brunian map for now, but a version exists for trees. It's just technically quite difficult for trees already and for chains that are easier than those related to, say, the triangulation walk. And so, that's why I'm not super hopeful that it's feasible in the middle. Yes, but even if you can't prove it. Yes, but even if you can't prove anything, that should give you a conjecture as to what the right answer is, right? That is, if you can conjecture what the right scaling is for the convergence to the Brownian map, then that should give you a conjecture for what the... Well, I mean, the right scaling is m to the 5 over 4. Pretty confident about that. But then proving it, I don't know, we're pretty far. Um you have a slide that said that you have a tree and then then you put some leaves, I think, or at least one edge and put it in another side. Yeah. So you have something which says convergence of a process moving like that to some limiting tree or something. Okay, so that was a first proof of our balance for these For these flip chains, was via a chain on trees that is basically, we've called it leaf translation chain. So you pick an edge uniformly at random. If it's a leaf, you move it one step right or left in the contour. And we've shown polynomial upper bounds for the mixing time of that chain. But there as well, we haven't shown any. We haven't shown anything sharp. Because we've been using canonical paths in that case as well, it's quite unlikely that that will actually give you the correct order of the relaxation time. And for that chain, again, there isn't any proof of a limiting process in the continuum. The only one that I know is for a simpler chain on trees, on which we have more control. On which we have more control on the discrete level, already. But it would be very cool to do. We'll see whether we manage at some point. Okay, thank you. Look, thank you to be here again.