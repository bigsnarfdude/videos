In this talk, I will try to give you a flavor of some of the English problem for normal diffusion and probably some of these features. And a second part is I'll try to indicate some of the problems that I would like to see that it is solved, but it seems that we still know that yet. And so let me also like apologize now because clearly I will not be able to give very comprehensive. To give very comprehensive review, and this is strongly biased by my own experience, and many important references. So, they are missing. So, if your name is not mentioned in the slides, so please do not feel being offended. So, let me just start with the motivation. So, as we all know, that there are two ways to derive the standard diffusion equation of this form. So, there's like Of this form. So, there's like a microscopic way. So, we started with fixed loss, which is a flux proportional to the gradient of the concentration. And then, the conservation of mass. So, if we combine these two pieces together, we get the standard diffusion equation. And another way that we can derive it from the microscopic way, so we start assuming that the particles follow blown in motion, and then we consider the Motion and then we consider the probably density function of the particle appearing at some time instance spatial location. And then it turns out this actually will also satisfy some equation of this type. And one of the distinct features of the Brownian motion is that the mean square particle displacement will be linear with respect to time. However, so in many experiments, people observe Experiments, so people observe that this kind of scaling law is actually not valid. And all these cases or diffusion processes where this linear scaling law is not true, so we call them normal diffusion. And in particular, so we observe quite often that this scaling law is sub-linear, alpha for some alpha between zero and one. And in this case, we call the diffusion process sub-diffusion. And there are many practical applications where this kind of enormous diffusion appears. So here are some very small set of examples. So like from the 75, so we have this electron transport in copy or printer. And more recently, so there are many works in like at the PRL. So there are many such works. So where people actually determine that the different plots. Uh, the different process exhibits sub-linear scaling load, and one thing is uh, clearly, so there are people tried very hard to try to describe this kind of process. And one possible way is that we can start with the lattice models or the so-called continuous time learning work. So, we have similar procedure as a blog motion, but now the jumping time between the consecutive jumps. Consected jumps the follow, it follows the heavy tail distribution or divergent mean to be more precise. And if we consider the diffusion limit of this kind of stochastic process, then it turns out the probably corresponding probability density function will satisfy the following fractional order differential equation. And here, this partial TR is something we already see, we already saw yesterday. Yesterday, so the Japanese capital derivative and alpha is between zero one in this case, and so clearly, this is a like a non-local operator in time, so because it involves this integral over there. And so, here I just describe everything in strong sense by assuming that actually the function we consider there sufficiently nice. And one can show that as alpha 10 to 1, so this kind of deleterate actually will recover the UU first order deleter. The UU first order divisive, in which case we recover the standard parabolic case. So, this means that we are considering some time flexion or counterpart of the classical parabolic problem. And in this talk, so I will only focus on the following model in this problem, so for sub-diffusion or sometimes also diffusion wave, so where alpha is between one and two. And one and two. And the setting is that this domain is always assumed to be smooth. And when we consider this numerical approximation, then we will consider the convergence polygonal domain, just as yesterday talk. And then this diluted, as I mentioned, so this capital diluted I mentioned earlier. And all these coefficients like A and Q, and so they are assumed to be smooth. They are assumed to be smooth and f and u0, so they are suitably smooth. So that this problem somehow has some meaning. For this model problem, actually, there has been quite a lot of studies in the past two decades. So for example, we know the verpos of the model in hilbert space or sometimes also in host. Hilbert space, or sometimes also in holder space. And we also know quite a lot about the regularity, about the solutions to this kind of problem. And there's a great amount of work on numerical analysis and also a lot of work on English problem. So this English problem will be the focus of this talk. And before I move on, let me just recall this one, too. Uh, one tool so I will use very often in this presentation. So, this two kilometer meter left flow function defined by this NKNA serial. So, this function, so you can easily see that if we take alpha equal to beta equal to one, so this becomes a standard exponential function. So, it's a generalization of the exponential function. So, this function has some amazing properties. So, at least two of them here. So, one is that for So one is that for alpha between zero and two, so on the nectar or on the sector containing the nectar rule axis, we have this kind of asymptotic behavior. So basically means that it decays sub linearly in Z on a sector containing the negative reaxis. So this is one of the properties that will be used very often. And another property is if alpha is between zero and one. Property is if alpha is between zero and one, so this e alpha one minus t is actually completely monotone. So this means that if the function is non-negative and the diluted is non-positive and we just continue the procedure. So especially this implies that this EFR1 minus T does not vanish on the on the positive real axis. And so one And so one of the clearly one of the interesting from the numerical perspective that is interesting thing is logarithmic. And to see this or to gain some insight, so we can start with the simple possible case. We consider this initial value problem for this ordinary differential equation involving fractional diluted or order alpha between 0 and 1. And then in this case, And then in this case, so the solution is given by U T is equal to E alpha 1 minus T to power alpha. And clearly, near T2 equal to zero, so we have the following very simple expansion. So ut is equal to one minus T to power alpha up to some constant, and then the next term is smaller. And one can see that this function is actually continuous at time t equals zero. At a time t equals zero, but it's the first dilutive blows up. So this means that actually the solution does not have very good logularity in standard soft leaf space. So that's one of the messages we can see immediately. And especially it fails to be C1. And so this implies that the solution operator here will have a limited smoothing property. And this controls. And this contrasts the standard like integer order diluted, like a first order due to that case, the solution is given by e to the minus t, and clearly it's an infinity. So that's a big difference between the fractional case and the integer order case. And this kind of result carries over to the sub-diffusion model I showed you earlier. So one can describe this kind of locality like in this dot HS. like in this dot H S space. So if we are using this eigenvalue and eigenfunctions or this elliptic part, and we can define like H dot S space. And one can also easily write down the solution representation in terms of this metal left function as a standard separation available. And based on this expansion, so one can easily deduce that, for example, if we only have the initial value Only have the initial value, then the right-hand side is zero, then we have this kind of regularity result. So this means that if we do not take any fractional deleted, then we can take at most two diluters in space. And that's the maximum thing we can do. And if we take one fractional diluted, though, then we can do even less in the spatial direction. And the overall And the overall message is that in this case, we have limited smoothing properties. So, for example, in space, we have maximum order two lifting. So, all the irregularity. And this kind of result clearly differs markedly from the classical parabolic case. For example, in the classical parabolic case, we can take an optionally order spatial and time derivative. There's no such restriction. And that's one of the big differences between these two. The big difference between these two cases. So, the main message is that the solution operator in this case generally has a limited smoothing property. And generally speaking, we cannot assume that the solution to the sub-diffusion model or general time fraction or diluted models, they are non-smooth in general. And this kind of result is actually quite well developed. So, if you are interested in more details, there's a very nice. Interesting more details. So, there's a very nice book by Professor Yang Moto and his collaborators appeared last year, two years ago, and then another book from myself. So, you can find a lot of details in these textbooks. So, let me now turn to English problem. So, for the English problem, which is slightly different than the previous, so in the previous case, I have assumed that everything is known except this U. Everything is known except this U. So this U is unknown, but everything else is known, including like domain and all the parameters and coefficients, initial condition, boundary condition. So all of them they are known. And for English problem, so we assume the following. So some of these parameters indicated in red, so they may be unknown. But additionally, we assume that we have some knowledge of the solution. We have some knowledge of the solution. So, this knowledge may be in a subdomain or in a subdomain or on the boundary. So, and then we given this knowledge, additional knowledge, so we want to determine one or multiple parameters from the Or multiple parameters from this additional knowledge. And basically, there are two issues. So, we are interested in one that we want a unique determination or stable determination. So, that's one thing. So, like this is more like a theoretic question. We want uniqueness and some kind of stability result. And another part is that we also are interested in this reconjunction algorithm. And if possible, so we want the L estimate. So, these are two parts. These are two parts of this any specific English problem. So, we are interested in this question. And so, clearly, so by the different combinations of these given data and also the unknowns, so there are many, many possibilities. And I will focus on three model problems. One is this backwards problem. This is a backwards problem. Now there's a determinate order, and now yet another ingot coefficient problem. So I will just focus on these three problems and then try to give you a flavor of these problems and then where some of the issues may or may challenge issues may arise. So let me begin with the backup problem. So the backup from the standard sub-diffusion case, The standard sub-diffusion case, so we have this problem, and here I omitted this zero detector boundary condition. And so the backup problem is that instead of this u zero, so we actually do not assume it to be null, but we have the knowledge of this u at some final time, t. And then, so given this final time, so we try to recover this u0. So this is one of the probably the most well-known examples for the time flexion. Known examples for the time flexion model. And for this problem, Sagamoto and Yamotus include the following stability results for the case alpha between 0 and 1. And this result basically says that the L2 norm of the initial data can be controlled by the H2 norm of the measurement. And the results, so the proof is actually quite straightforward. So basically, Forward. So basically, by the solution representation, so we can represent the initial data in terms of the final time data as follows. And so clearly, if we can ensure that this E alpha1 mass lambda ch does not vanish, then this division makes sense. And in order to bound this quantity, so we need to estimate how this denominate will grow or decays. And both properties mentioned earlier. So we know that. Mentioned earlier, so we know that this EFI1 is actually a complete monotone. This guy does not vanish. And this it decays linearly. So this means that its inverse glows linearly with respect to this argument, magnitude of the argument. So in this way, we immediately obtain this stability result. And another thing one can observe from this estimate is that backwards Estimate is that backward sub diffusion is basically more or less take two diluted in space. So, because we have this equivalent relation, so it's a two-dilute loss. And the result itself is somehow, I mean, the proof is quite simple, but it's quite interesting because when we compare this result to the standard parabolic case, so in that case, actually, so there's no way that we will be able to. So, there's no way that we will be able to obtain this such good stability result. So, this means that in that case, the problem is exponentially. So, this means that we are not able to bound things in any visible like Sophia space. And so, this is just due to the excitement that probably if we make the inverse plump for flexion model, so we For flexion models, so we can always make the problem less air posed. So, and then accordingly, so numerically, so it will be somehow much easier to do. And unfortunately, this kind of observations, generally speaking, it's not true. So, we actually have a lot of examples showing that this kind of statement is false. And so that's about this problem theoretical. So, we have very good. About these problems theoretically. So, we have very good stability results. And how about the reconjugation? So, the reconjugation is in this case, so we consider noisy data. So, we have this G data and its accuracy is data as measured in a two-norm. And then, so we need to realize the problem so that we want to contract some new micro procedure and which will give you somehow. And which will give you somehow a reasonable approximation. And clearly, there are many different ways to do this. And one of the post ways to do this is a so-called quasi boundary value method that's proposed by Ji Jung Liu in 2013. And the idea is quite simple. So the original problem, so we can write this directly without this term in red. And this is quite a clearly scale airport because G data does not have the required log length. And one way. And one way to stabilize this is that we localize by adding a term like this one. And one can show that this indeed considers a valid numerical procedure. So we can derive a consistency result and also L estimate under some condition. But this is still not yet like numerically feasible because everything is still like a continuous operator. So for the approximation. So for the approximation, so we we can approximate everything like by new all these continuous stuff like by discrete quantity. So a very simple procedure to do this is that we approximate the fractional derivative by some discrete convolution like backward or convolution quadrature, which is given here. So I do not try to omit all the details here. And then we approximate the spatial diluted by the Spatial diluted by the colloquium finite element method, and then so for the data, so we buy the with a standard L2 projection, and by means of this, so we end up with like a finite dimensional linear system. And for this problem, so was the first systematic study by more recently by Zhang and Zhou. So they prove that actually one can obtain some regular LSM. So it's like gamma to some power, and then relative mesh size, and the spatial mesh size, and then some localization parameter, all of them. So they will end. And so this estimate is somehow interesting because with this estimate, so we can choose these parameters properly so that all the terms are somehow balanced so that we can still have some computable scheme and yet we still retain. Yet we still retain the overall optimal convergence rate in terms of the data, which is somehow comparable to the previous result. This is more like a classical numerical analysis, but it has a slight different case. So that's for about the sub-diffusion case. So we have this good stability and we have the reconjustion axiom with the regular Just an axiom with regular LS myth. So everything is nice here. And then so one another very natural question is that what happens if we can move on a little bit? Consider case alpha between one and two. And in that case, which is known as a diffusion wave, and clearly it has also a lot of applications. And because if we consider this case, then so we need two initial conditions. So that's the only slight change. Is the only slight change and in order to determine these two initial conditions, so we need somehow like two sets of measurements. And there are many possibilities. One possibility is that we at the final time has a solution itself and also it's deleted over there. And or we can measure the solution at two different final time. And then Florida and Yamoto. Florida and Yamoto the proved last year. So if we choose this measurement time wisely, so then so this we basically have the same stability result as before. So exception, so there's an exceptional set which is defined as the zeros to so here this eta one to up to eta n, so they refer to the zeros of this. Refer to the zeros of this special function defined here. But a module is this set, so which is countable. And we basically have the same stability result as before. And so this kind of expressional set arise because probably one intuitive way to see this is that because for alpha equal to between one and two. alpha equals between one and two and in that case we do not have like a completely monotonicity anymore and so this means that we cannot simply divide this by some special function involving e alpha one to minus something like that anymore because there's no guarantee that this kind of quantity is actually non-zero and if it indeed is zero so in that case so clearly so we will not be able So, clearly, so we will not be able to recover the corresponding Fourier model in that case. But apart from that, we basically have the same result. And let me also mention that this kind of stability result is also true that if we consider, for example, two final time measurements, and if it's taken sufficiently large, and the numerical procedure I mentioned earlier, so is also still valid. So, let me just. languages so that's about this uh very uh very simple so model uh ingo's problem so we have it's quite well understood in some sense and the numerical analysis is also possible because we have reasonable stability result but the situation is actually not not that simple for example if we change the setting slightly consider the time dependent electrical operator in that case so we will not able to will not be able to use this meta left This meta left lay function anymore, then so all these stability results I showed you earlier, so suddenly so they all break down. We actually up to now, so we still don't know. So if we change this operator to some time-dependent operator, so this kind of stability is still valid, even though we expect it's still valid. But there's still no proof of this. And another thing is that there's in the flash no case, so clearly there's a case so clearly so there's this additional one scalar parameter alpha and one may one may ask whether so given the final time measurement is it possible to recover both the initial condition and this order simultaneous this appears to be unexplored but there's some some work in this direction like by masohilo in his uh in his recent paper so that's about this uh this simple uh This simple inverse problem. So, let me now turn to another quite simple problem. Like, so clearly, so in this fractional order model, so there's one single scalar parameter alpha, which characterizes the type of this viewing process quite well. And so, and generally, so we are not able to specialize this parameter directly, and we need to estimate this parameter. We need to estimate this parameter. And so, one very natural English problem is that can we determine this parameter alpha uniquely by some additional measurements? And so this is probably the most natural English problem for time flexion model. And again, so this problem has actually been studied quite intensively. So in like in 2013. 2013, Hatano and her collaborator, they prove the following results. So if we assume that the initial data is smooth and the right-hand side is yellow, and then the initial has a compact support and this additional condition, then so the and if we are able to measure the time chase of this solution at the point x0. point x zero belong in the interior domain then so we can compute this the flexion order using this expression here so this means that we actually have this unique determination under these conditions and also we have like a constructive procedure to do this so basically so if your observation is sufficient regular in time then you can take a first order dilutive and basically The diluted and basically so that's the uh give you the reflection order and so they also uh derived a similar formula so for large time asymptotics and both of them so they are derived by like the asymptotic behavior of this metal left functions I mentioned earlier. And there are many such results. So if you are interested in you can refer to this review paper by Xiuang Li, Yikan Liu, and Masahilo. Master Halo, so like in 2019, is handable. So, that's these are the early results. So, then so because in this very special case, so the unknown is actually only a scalar value. So, we naturally ask ourselves, so maybe we can determine it from another scalar value. So, this because we only have like one unknown scalar, so maybe we can determine just from another. Maybe we can determine just from another schedule, which is measurable. So, and here's like two such results. So, the first result is they assume that we can measure this kind of quantity, which is similar to like some kind of energy. And then they prove that if we have access to this kind of quantity or measurement, then we will be able to determine this. To determine this alpha uniquely. And this proves again based on some very delicate analysis of the metal left lunch. So some kind of monotonicity result, which is not obvious. And so that's one possibility. Another possibility is by Xin Su and Xi Yan Li and so they proved that actually we do not need so much. We do not need so much information. So we just measure the solution at one single point at one fixed time instance. And then under some reasonable assumption, which is not too strict, they prove that actually in that case, we not only have like a uniqueness, we also have lipstick stability result. So this means that just as expected, because we are only interested in one species. Because we are only interested in one scalar quantity. So, if we can measure this solution at one spatial location at a fixed time instance, that's sufficient to determine this alpha stably. It's a little bit stable. So that's another result. And there's a third result. So, and so recently, so we also consider or played with this model a little bit. So, again, so the So again, so the setting is that we still consider this time flexor model, but all these quantities in red, so they are assumed to be unknown. So basically, we have this raw and elliptical operator and the source term initial condition and boundary condition. So they are like they are unknown. And then we can measure this solution of flux at one point on the boundary for some time interval. For some time interval, so close to the final time. And given this piece of information, so we ask ourselves: so, what can we say about these parameters here? And clearly, it's hopeless to find all of them because the information available is actually quite limited. So, we have the flat measurement at one point. But the number of unknown quantities here is quite. known quantity here is quite quite large and so to to study uh this problem so we need to clearly we need to assume something uh so we assume that uh all the everything is nice so even though they are unknown but they are nice so that actually uh this flux measurement does uh does make sense so in some function space then in that case so uh we have the following results We have the following results. So, if we assume some sign condition on either the initial condition or the source term or the boundary condition, then if we have this flux measurement, they are identical at some point for some time interval. Then, we can deduce that these two orders, they are the same. So, this means that the flux measurement actually uniquely determines the order. Actually, uniquely determines the order, even though we don't know all the other quantities like this rho and A and F all this stuff. So, but we still be able to uniquely determine this alpha. So, the message is that one single measurement actually can uniquely determine the title of the fielding process, but we cannot see much more than that. So, only determine alpha. The idea of this is actually quite similar to the previous case. We just expand everything in terms of solution representation and then we have asymptotic behavior. And based on the representation, we can show that the flux measurement is actually analytic, so at large time. And basically, that's it. And then, so there's we have this sign condition. This sign condition. So, this sign condition just makes sure that the asymptotic expansion, so, or the leading term in the asymptotic expansion actually does not vanish. So, based on some like a maximum principle. So, it's a it's not a difficult argument. And so, here's like a numerical illustration. So, one can have this flux measurement. And if we have this measurement for sufficient large time intervals, so we can. Large time interval, so we can clearly observe like a polynomial decay. And based on this polynomial decay rate, so we can deduce the fractional order. And this observation is valid for both like a zero initial condition and non-zero initial. In the non-zero, zero initial condition case, so the decay rate is much faster because the exponent is much larger. And so we also have similar. And so we also have a similar observation for the diffusion wave case. There's a minor difference that before this asymptotic thing, we actually have a wider oscillation. And this is due to the fact that in the different wave case, as I mentioned earlier, so this metal left function, so they are no longer complete monotone. All the corresponding solution of plate actually does not satisfy something like the maximum principle. So that's the reason that we observe this kind of. That we observe this kind of oscillation. But the main message is still the same, so the order still can be estimated. So, if we have this observation for sufficiently larger time. And so, again, so for this inverse problem, we have something quite nice. So, we have like uniqueness and sometimes we also have. And sometimes we also have stability. And clearly, there are many possible extensions, like a multi-term case. I think Ikan will give a talk about this. And also the distributed order cases. So we also have some results, like results by Stone and Randel. And also the results by Luchko and quite a few others. And recently also we have some results in the variable order case. So, but also it's like less understood. And the concussions, it turns out, is sometimes quite highly non-trivial. So at least in my personal experience, even with like a multi-term case, so it's numerically, it's quite difficult to, for example, recover two orders. They are close by. It's just impossible to differentiate them like numerically. And if the medians is unknown, so it Like a medium is unknown, so it's like a total mess because, even in that case, so because we cannot define the forward operators and all these familiar technique, we know all like the least square type method. So they are no longer available to use. And this makes things quite difficult, a lot of cases. So that's about this. So that's about this second inverse problem. So this order determination. Let me now move to the last part. So this inverse coefficient problem. So this is a very large class of inverse problem and depends on the unknown and also depends on the type of given data. And so there are many subclass like Inglus conductivity, English potential, and convection coefficient. coefficient and then non-linearity and sometimes we can also attempt to recover multiple of these parameters and so there's a very nice review paper so by ziwanli and mass halo so again so from this 2019 and it discussed many many such results uh maybe just let me begin with the probably the most well-known results so probably everyone so in this That probably everyone in this room actually knows this result. So, this is an inverse conductivity problem. So, for one-dimensional case. So, we have this standard problem, but with normal zero-normal bounding condition and the liquid, and this data function as initial data at the one end point. And so for the And so for this problem, Jing Cheng and Masahilo, they proved that we have the following unique determination result. So given this measurement of the solution U at the left end point, so we can uniquely determine this diffusion coefficient A, which is a function of X in one variable, and then we also have this. And then we also have this alpha, so uniquely determined. So, given one piece of information, so we can determine this conductivity and also the flexion order. And the proof is based on the Laplace transform. And so then, so we can from the Laplace transform, so we can deduce the alpha and also deduce some special information about the correlating stem reveal. About the correlonding stem reveal problem, and then so we can use the Gaffern and Levanton theory to recover A. So that's the rough idea. And this piece of work probably, so because everyone knows, because it becomes so influential, and basically it started the whole business of Ingle Spoon for Norman's diffusion. And so there are many, many. There are many, many follow-up works from here. So, for example, one very natural question is one may ask that what about the multi-dimensional case and a multi-parameter case? And so, this has been investigated like using the data as a delector to normal map or something similar to that. So, for example, by Mars Hillo and his collaborators, and then yeah, both of them. Yeah, both of them. So the blue, for example, if we have a declared normal map, so we have you can recover two coefficients. And for this specific inverse problem, clearly, so one of the very natural thing to ask, at least for this setting, is that because we are, for example, here only interesting the coefficient, which is space dependent. So probably we should be able to recover this conductivity. This conductivity from the measurement at some final terminal time. And it turns out that this is not so trivial in most cases. For example, even in the standard plebolic case, like from last year, so there's a result by Fauzi Chiki. So he proved that under some positivity condition, only initial condition, then for sufficient large time. For sufficient large time, so we actually have a unique determination and also Lipsis stability. And this positivity condition basically means that if it's a initial condition positive and you wait long enough, so all the stuff remaining is basically the first flea mode. And the measurement is more or less like the first eigenfunction, something similar to that. And so that's the last idea of the proof. That's the last idea of the proof. So, but the analysis is quite delicate because you need to analyze the spectral behavior of this kind of elliptical operator or some perturbation results. So, quite serious. And for the fractional cases, we don't know any such results. So, at least I don't know. And this is also mentioned by the review papers. There are no publications on Inglass coefficient problem. Is on inverse coefficient problem with the final time observation. So, and uh, so let me just comment that actually after this review paper, so there are some results about the final time measurement for the inverse potential problem, like the one by Babla and Bill. And then also, after that, I think there are a few others. So, about, for example, the linearized English problems that we are posted. Problems are well posed, and if the measurement time is efficient large, then it's also nearly well posed. And if it's sufficient small, again, it's also nearly well posed. So there are a bunch of results of this type of for the inverse potential problem. But for the inverse conductivity problems, we do not have exactly the same result, but they have a weaker result. So if we consider that our conductivity All conductivity is like space-time dependent, and also the problem additional data is also space-time dependent over the whole space-time domain. And in that case, so we actually can prove a result, so a weighted estimate of this type. So here, so we require that we have the measurement over the whole space-time domain, so which is quite logistic. Domain, so which is quite logic, but if we assume this, so we have some weighted estimate, and with the weight given as follows, and so it turns out that this weight, so it's not too badly behaved. So, for example, one can show that this weight is actually not too bad. So, it it's non-negative and also near the boundary, so it does not. Near the boundary, so it does not decay too fast. And so, this kind of estimate is indeed valid. And if we assume this kind of estimate, so we have like a standard L2 estimate or something like a conditional stability result. And to obtain this kind of estimate, so one can use like a maximum principle and Green's function or elliptic operators and some additional assumption on the problem data. So, one can prove this kind of one can prove this kind of weight does have nice property. And the idea of this kind of results first appeared like in the paper by Bonetto, Cohen, and Devo and several other people. So and recently we applied this idea to this fractional case. And this kind of stability results, one can also obtain some numerical procedure. Numerical procedure. For example, one can formulate, assume that we have this noisy observation with acclass data, and then we can formulate a standard regular least square formulation. And then we also quit the forward problem appropriately. And then just like before, so we can apply like back to the order convolution quadrature for the flux dilute and the Galaxy infinite element method for the spatial diluting. For the spatial diluting. And so we end up with some numerical procedure. And so clearly, so one interesting procedure is that the question here is that can we derive some L estimate for the approximation obtained here? And the answer is yes. So it's a bit ugly. So we can obtain this kind of L estimate, which is similar to the stability results. At least the weight is exactly the same. And so And so if we ignore all these quantities here, so basically says that if we choose this mesh size and time status size and every stream time properly, so we'll get some L estimate exactly the same as before. And if we have this some nice property on the weight, so we actually get the standard estimate like in L2 or L2L2, depends whether the coefficient is time dependent or not. Is time dependent or not? So that's the kind of estimate we can obtain. So I will not show you the proof because it's just quite ugly. So it's lengthy and ugly. And so that's about this very nice situation. So we have measurement in the whole space-time domain, and we can see something. And then, so clearly, so this is not the idea. So clearly, so this is not the ideal situation. So we may ask ourselves, so whether maybe we will be able to recover multiple coefficients from one measurement. And this is also indeed possible, at least in theory. So for example, if we choose the delivery boundary condition of this very special type, so I will not show you why they choose this way. But in any case, there's like a special way to contract the boundary condition. The boundary condition, and then so somehow this kind of special boundary condition it's like a magical, and then so uh and uh young moto so they prove the following result. So if we assume that we have this very special type of boundary condition, a delivery boundary condition, and then we can measure the flux on another like sub-boundary. Another like a sub-boundary. And then this measurement actually can uniquely determine two coefficients out of three of them, like this density, conductivity, and the potential term. So under some minor condition. And the catch is that here, so based on this special type of boundary condition, one actually can go step. Actually, can go step by step so recover almost like a whole delete line to normal map. And because if we have the delicate to normal map, and based on the previous results, so one can show that we can recover two coefficients out of three of them. And there's also a later paper by Yava Kien, which also I think consider the cases like right-hand side of the orders here unknown. And you can also recover some of these information. You can also recover some of these information as well. And this is quite a nice, and probably from if we are introducing the numerical procedure, then there's a small drawback because this contraction actually involves like a series which will have some numbers that tend to converge into zero. So this clearly, so we cannot do this numerically. And somehow, so numerically, it's not easy to realize this directly. Not easy to realize this directly. At least, I don't know how to do it. And this considerations lead to the last example here. So this simple one-dimensional problem. So we consider a simplified model and in one-dimensional case, and then we have this like order alpha and ellipse operator is not fully known, and then we have this. Have this right-hand side is like a source time is only space-dependent, and the initial condition is unknown. And but this conductivity I assume to be known. And so, give this model, so I assume that we actually, in addition to this, so we also can measure the solution at one end point on the left end point. And then we ask that given this is one observation at one end point, so can we say something about the So, can we say something about all these unknown quantities like this alpha and Q, U0 and F? So, under these given assumptions. And generally speaking, it's not possible to see anything. So, if this G is arbitrary, so there's no, one can easily contrast some counterexamples, say that there's no way to determine any of these quantities if we just see arbitrary. Just a G arbitrary. And but it turns out that if we make a little assumption on this G, so which is a normal data on the left endpoint, then the assumption is that at the beginning, so it's zero, then at some later time it becomes a non-zero. So somehow we can control the excitation of the boundary. Then, so the measurement that we have can unique. measurement that we have can uniquely determine this alpha and q and also u zero if the source term is known or a source is uniquely determined if u zero so this is uh this means that if we have all this one measurement so we can repeat uh recover three uh three quantities and the idea of proof is actually quite simple so it's basically already contained in this paper by bill By Bill and Marshal, like a few years ago. And so we have the solution representation, and then we have the asymptotic behavior and analyticity. And so clearly, so there's some kind of gaff and 11 stuff show up. And the whole procedure is somehow like a semi-constructive. So we first do the analytical continuation from one interval to the next one, and then from the next interval. And then from the next interval, so we can determine the Q. And then, so once we have the Q, so we can determine alpha and user this. So that's a basic idea. And we can also turn this proof into numerical procedures. For example, the first step is that we need to perform some analytical continuation from a small interval to some larger interval. And all these Uh, all these given observations, and this is basically the fundamental step, and in the case of that data, so we have some quite simple procedure. So, this triple A algorithm by Nico Jifferson, so it works very well. So, basically, it's a rational approximation of special type and it can perform this kind of task very well. But in case of noisy data, so it turns out that it does. So it turns out that it does not work so well. So and that's the reason that for this very specific English problem, so we can only work with exact data. And once we have this extended problem data, then we can reconstruct the Q so from this measurement on the boundary. And this problem turned to be quite nasty numerically, even with X data. And so no matter how. So, no matter how hard we try, we are not able to get some good reconstruction. So, it's somehow reasonable, but it's never so good. And but once we have all these estimates, then the recovery of this initial condition, if we assume the source term is known, is actually quite reasonable. So somehow it's much better. We still don't understand why the behavior of these two problems. The behavior of these two problems, they are so different. So we have no clue why this is the case. I think I'm at the end of my talk. So let me just briefly summarize my talk. So I will show you like basically three model class of English problems, like initial condition orders or some coefficient. And there are what kind of possibilities. There are all kinds of possible combinations and I just show you some examples and to give you a flavor. And clearly, you can see that there are many things missing here. I do not mention either intentional or unintentionally. So clearly, one thing is that you do not see some stability result. And there's a reason for this is that many of these tools from classical PDEs, they are no longer valid. For example, we do not have like a simple formula for integration by path. A simple formula for integration of parts. And as a result, we do not have a good common estimate in many cases. And so that's one of the big situations we clearly nearly all else is missing here. And another thing is that we also have many issues with the numerical stuff, like either design the exam or analysis or L analysis or like like efficient algorithms. So they, I mean, most of them, so they have not received a very serious investigation so far. And clearly, so there are many other more slightly more complex models like multi-term or distributed order or variable order. So clearly, I do not mention anything. This is probably true that actually we do not know so much results about this density. Results about this situation. I think I will finish here. So, if you are interested in more details about all these problems, I would suggest these review papers and also this upcoming textbook by Bill and Barbara. And so I think I will stop here. Thank you very much for your attention.