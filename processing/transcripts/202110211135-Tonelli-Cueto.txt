Thank you very much to the organizers for the opportunity to present my work. So, this is joint work with the Lias Garitas. Okay, so in order to make some ideas less technical, I will just focus on the setting of homogeneous polynomials. This is used because symmetry will make such Symmetry will make certain things easier in how to present some of the results. So, some notations, so x0, x1, xn will be homogeneous variables. Then we will have hdn will just be a tuple of n homogeneous polynomials where the first one is of degree d1, the second one of degree d2, and so on. Then for a homogeneous Then, for a homogeneous polynomial system and a point on the sphere, I will just work on the sphere because it's more comfortable for the reals than working over the projective space. We will consider the essentially this is the higher order derivative. And the most important thing here is that when I don't put the bar above, this is just the derivative on the sphere. So, this is the derivative restricted to the. The derivative restricted to the tangent space on the sphere. Okay, we have the Bile norm, which is this norm with this wheel scaling, and of course we have the zero set. Nothing new here. So let's talk about discriminant numbers. So we have the usual discriminant variety. So this is the set of homogeneous polynomials where the zero set is singular. Singular. So, this is essentially where the changes can occur. So, when we pass to the discriminant, is when something interesting can happen with the number of real zeros of the system. So, in particular, we have that if we remove the discriminant, then the function that sends a polynomial system to the number of zeros is locally constant. So, then a discriminant chamber is used a connected component. A connected component of this, of the set of polynomials, removing the indiscriminate variety. And the question that here I will make is: okay, we are given a random polynomial system. We want to know what is the probability that this random polynomial system belongs to a particular discriminant chapter. So, let's remind a little bit what is a random KSS polynomial system. So, we have System. So we have a random polynomial system. We put these scalings for making it easier or live with this KSS definition. So in the KSS definition, superslan supersmail, the Ci alpha will just be identically distributed normal random variables of mean zero. Then we can also do this with in the dorevo case where we have independent. Dobbo case, where we have independent and anti-concentration plus two Gaussians in the coefficient assumptions. Or we can go to more general assumptions like Ergur, Bauris, and Roche has doing, which we just assume that the polynomials are independent, and then we just assume that the valuations have the anti-concentration plus Gaussian property. So let's introduce now the condition number. So given a So, given a polynomial system, the condition number has this expression, which is just this maximizer of looking at every point, the norm of the evaluation together with the least singular value, which in this form is written as the inverse of the norm of the inverse. Important thing of this guy is that this number is infinity if and only if the polynomial system has a singular pseudo-set. So this can be made more explicit with the so-called condition number theorem, which tells us that the condition number is up to scaling the inverse of the distance to the discriminant variety. So in other words, we can say that kappa is kind of a metric discriminant. What's this denominator that you have? What's the distance in the bile norm? So we In the bile norm, so with respect to the bile norm of the polynomial f to the discriminant variety. Okay, thank you. Okay, so now let's go towards the in radius of the of the discriminant chamber. So if we get a discriminant chamber and we consider the meet the best condition polynomial. The best condition polynomial in the discriminant chamber. Yes, KSS is Kauslan sup smell. Okay, so if we consider the discriminant chamber, we will look at the best possible condition polynomial system in this discriminant chamber. Then, if we make the observation that the farther away you are, this is equivalent to, so if you have a ball inside the chamber, this is the same as. Chamber, this is the same as being far away from the discriminant. So then one can relate the inverse of the condition number to the in of this optimal condition number in the chamber to the in radius of the chamber, essentially. So, okay, if you have a ball inside, you can bound the probability from below, but we want to bound it from above. Here is where condition numbers will come useful. Come useful. Here, I only point that this norm of the polynomial appears because this is like a conic. We are considering the chambers in a conic fashion. So we just have to put the scaling by the norm of the polynomial to don't mess around with the geometry. Okay, so we have this inverse, which is like the biggest ball that you can put inside your radius of the biggest ball that you can put inside your discriminant chamber or it or it. Or it or it can also be interpreted as the best possible condition polynomial system in this chamber. So now let's go and bound probability. So we consider a random polynomial system, KSS. Then we take the probability that this belongs here. Then of course, this will be less or equal than the probability that the condition number of your random polynomial system is bigger or equal than the best possible condition number in this channel. Condition number in this chamber. Then we use a result by Cooker, Griffith, Malahovic, and Bessevor to bound the later probability. So here, capital D is the maximum degree. This calligraphic D is the Besu bound, and capital N is nothing more than the total number of coefficients of a dense system. So we have this. Now we want to get a lower bound for capital. To get a lower bound for kappa of A in order to get an upper bound of this probability. The reason is we can do this. We can even do the middle step. We can also do it for more general distributions. We don't necessarily need KSS. It can also be done with the result of Ervers, PowerIs, and Rojas, or with these results for Dovero random polynomial systems. So the answer. So, the unexpected inequality that appears in this is the following one. So, if you get a polynomial system, then you can bound the number of real zeros of this real polynomial system by essentially the square root of the maximum degree to the n times the logarithm to the n of the condition number. An important colorary of this is that the condition number The condition number will be bigger or equal than two to the end root of the size of the zero set divided by the square root of the maximum degree. An important color of this is that if your polynomial system has many roots, then your system will definitely be ill-conditioned. So now this is a deterministic implication. So now we go back to probability. So now we go back to probabilities using this inequality. So we use substitute it, do some bounding, put some absolute constants to make the things easier. And then we have that the probability that the polyrandom polynomial belongs to our discriminant chamber that we are considering is just bounded by, okay, 2 to the n log d. Okay, this is something that will appear in the exponent. So this contributes to the probability bigger than 1. Bigger than one. But then the part that we have on the right is the number of roots that, of zeros, that any polynomial system in this indiscriminate summer will have divided by the square root of the degree. So if this number is big, for example, d to the n, then we will have a minus d to the one half. So this will be exponentially small in the degree. Degree. So, in other words, we can conclude that discriminant numbers with systems with many real zeros are always small. So, we will fall into them with a small probability. And we can also use these results also for bounding the use the number of real zeros that a random system has. We can say System has. We can say that this the end root of the number of roots is superexponential with this constant. Okay, if you don't know what super exponential means, this just means that whenever you consider the any moment, this will be bounded by this quantity that is here. So essentially, by the square root of the degree to the n. So this is like a universal bound in almost all the moments of a random k. Moments of a random KS system, and also this holds for Dobro and the systems of Gurpauris and Rotas. So, what's behind this unexpected inequality? So, this comes from a paper from Moros. What he does is to solve a univariate polynomial, he uses a lot of extremely low-degree approximations based on Taylor expansions. So, we generalize this technique of Morocco to higher dimensions. To higher dimensions. This is sort of what the theorem would look like. The idea is that you consider several balls, and in each one of these balls, you have a log kappa approximation. And you have a warranty that the roots of this log-kappa degree approximation, the zeros of these are good approximations for the roots of zeros of your original system. So in this small ball, you cannot have more than log kappa to the n. And then since n and then since for this radius you have d to the n half bolts to cover the full sphere this is where the bound will come from so this is comparing to maybe other technique introduced by the atal lerario the idea here is to do a lot of extremely low degrees instead of just doing a single low degree approximation to get so other cases we can deal with we can also We can deal with. We can also deal with CAC random polynomials, also with undetermined polynomial systems, only the volume for now, not the topological invariance. And then some form of sparse CAC random polynomial systems. Still, we have to see how strong can our results be. And then, future work that this suggests is if we can have algorithms working with complexity. Working with complexity that depends on the logarithm of kappa to the n instead of the condition number to the n. So, what this will translate into will essentially be very fast algorithms in numerical real algebraic geometry. Issue here is how to compute, how to avoid computing the condition number in the process of the algorithm if you want to obtain this complexity. So, muchas gracias por vest. So, muchas unacias poru estradención. Thank you. Okay, the word.