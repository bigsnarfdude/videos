So thank you for your invitation and thanks for putting up this uh very nice conference. I'm very glad to be here and to have the possibility to speak about this uh joint work with the Vesa Esposito, where James Ganny Federica Security, who is also here. And it's actually a project on, let's say, gamma convergence uh for let's say a general class of um phase field pro um functional that I'm also ready and um with an application of homogenization of those functions. Our homogeneous software functionality. And so, to get started, let me start with the starting point, which was the Manfa-Char functional, which was introduced by Manfort Char. This is a prototypical type of a free discontinuity functional. So, a function defined on SPV functions, functional defined on SPV functions. And so, just to as a quick reminder, if you have a SPV function, it Reminder: If you have an SPD function, its distribution and derivative can be decomposed in this way. So, a part which is absolutely continuous with respect to the background, and the part which is supported on, let's say, n minus one-dimensional sets on the jump set of u. And so somehow the two parts that you see here, they correspond to the two parts that you have in the derivative. So, this is the density with respect to the back, and this is simply the length of the junction of your function, if you want. So, split. So, if you want to think about it as piecewise subordinate functions, this is maybe the easier way. So, the term sensitive volume and the server is part, and this is, let's say, typical ingredient for free discontinuity functions. They have actually a lot of applications, let me just mention that there are applications, for example, in image segmentation of fracture mechanics, as we have maybe already seen in the talk by Elise. So if you want to think about fracture mechanics, this uh you could think about this as an underlying displacement. Undlined displacement, then this would be your elastic energy stored in the material, and this is the energy which is necessary for an extract. And this way you have a material which can undergo fracture. So what the Ambrose-Potorelli approximation does is provide an approximation actually in terms of gamma convergence via a sort of phase field, sequence of phase field functions. So the Ambrose-Sorelli functions, I will be maybe more precise in the next slide. I will be maybe more precise in the next slide on them. Are epsilon-dependent sequence defined on so-called functions? And the B variable, you can think about it as a phase kill variable or as a damage variable. I will come to that later. And it has actually been shown by Ambrosio Tot already that those gamma converge to the Manfort Shah function. I will give you some idea about why this is the case in the next slides. Next slides. Let me just mention that although this was originally, let's say, an approximation tool for Manfort Jar functional, which is notoriously difficult to minimize, let's say, numerically, they have been reinterpreted as gradient damage models, as we have seen also in the talk of Elise maybe. And the gamma convergence result can then be seen as a passage from a damage model where this parameter heat is seen by preparation. This parameter here, the seamless variation parameter epsilon, forces the damage to concentrate, and you get a fractured model in the limit. So, and let me just mention that there's a very important feature of the approximation, which is that you have revealed decoupling. So, this first part here will approximate the volume part here, and the second part here, which is reminiscent of the Modica-Motula function that we already saw in the talk. Function that we already saw in the talk by Arim really approximates the surface part here. And this is what I would like to be more precise on the next slide. Let me come back. So there is a small parameter epsilon here, which I didn't spend too much time on, which is going to the zero faster than epsilon, which here is not really important for the gamma conversions analysis, but somehow it ensures cohesivity at the level epsilon. Level epsilon. I will come back to that later, so we'll play a role later. But on the next slide here, for a moment, I'm skipping that parameter. I'm also changing the exponent. So let's say we have several functions which are of p inter degree and p is strictly larger than 1, and your phase field variable v is between 0 and 1. And then we still denote these by the modulus of these functions. And there is an obvious change of exponent here. Those gamma converge, so let me still call it the Manford Schar functional. We have now here the surface tension is given in this way here. I will say something more about that. And the space we need to enlarge a bit to GSPVP functions, which are also mentioned, I think, in the talk by ELISA. So you need that for compactness reasons uh to enlarge a bit to your space. You can think about that tractation at every level belongs to S P T. At every level, it belongs to SPT. Okay, and then this is the surface tension, which is given by this optimal profile problem. So, what should happen is for small epsilon, if you think about having a sequence along which the ambrosial variant functions can be bounded, then of course the v variable should approach one in large regions. At the same time, you can have regions where the v becomes small and the u develops. The U develops a jump. So let's say if you think about damage, you have a regimental damage concentrate, and the elastic moduli becomes worse and quartz, and in the end, you get a fracture. And then the optimal way you can do that is by solving this optimal profile problem. Let me observe something about this optimal profile problem. So, of course, you see that here is two because you need to approximate a jump in. Need to approximate a jump on two sides, from two sides. But you have symmetry, so you could actually rewrite it on the whole line. And you observe that this can be equivalently written by observing that you can minimize among those functions which admit the value plus one at infinity, and such that you can couple it with a function which let's say coincides with the characteristic function at infinity, minus infinity, and plus. function at infinity, minus infinity, and plus infinity, and such that the couple here Vu prime is equal to zero. So in some words, you don't see the first part of V and A. So because this is zero if V gradu is zero. So okay, this is a one-dimensional picture, but we say that this is also also in higher dimension. So let's keep that in mind, we will need it later. So in this sense, you will really see a decoupling here. So also before, the surface tension really only depends on the surface part. Part and okay, here you have a simple thing. Okay, let me say this is the one-dimensional picture, but it's uh essentially it's also the the n-dimensional picture. Um let me say some more remarks on this decoupling. Actually you can see that if your volume energy becomes degenerate, then you may have really an interaction between surface and volume part, you can may have energies that depend on the jump opening. And On the jump opening, and at the same time, this fails if the exponent p becomes 1. So the integrability p larger than 1 is really essential. And this, let's say, change of the Manonman for P equal 1, okay, of course you have it in several instances, for example also for the Kamal convergence of re-discontinuity functions, or if you just think about relaxation. And we also observe that this. And we also observed that this decoupling still holds for a lot of variants of the Mbrosoto-Valli functional. So, if you go to factorial or an anisotropic case, if you consider like second-order variants, if you consider disputizations, it still holds and is actually very useful and sometimes really necessary to get this decoupling to prove the gamma-limit convergence. And this will also be the case for what we want to consider today. Let me also mention that it's also very essential. That it's also very essential to treat quadratic static evolutions, let's say, both for general pre-discontinuity functions of automotive auto-ready functional to preserve union vettable conditions like we saw at the top of Elise. So there's an interest in this decoupling, just to motivate the question that we had, namely, can we push forward this decoupling from Proto Totovale to a general class let's say? Total value to a general class, let's say. So let me come to the setting and the first main result. So we are now considering this factorial setting. So having an integrability exponent p larger than 1 and the functions that we are considering are still of the same type Ambrose-Totovelli function in the sense like okay that I will be more precise about later. So that means that say you can think about before we just did a gradient to P and this expression here for And I have this expression here for Gruto Dorelli. And let me maybe fill it completely. We have some integrability bounds on, let's say, our superlinear growth for our x-degrams F and FG, etc. So they belong uniformly to a class Calligraphic F and Calibra G. And the important things that I want to observe is that we will equal from our business model. So essentially, this was the second thing. So just to give you an example. So second thing, so just to give you an example, you can think about homogenization. So if you have f and g, which belong to these classes, and you just think about the scale dependence in the way that you have oscillations, then this is obviously an example for a sequence of integrals belonging to this class. And of course, the growth conditions are chosen in such a way that we can bound our final final content already. So the question is, now in this general Now, in this general class, can we characterize first of all the gamma limit of our functional which type is it? Do we still get a volume surface decoupling and do we still get let's say a brittle type of free discontinuity function gamma limit, so meaning that there is no dependence on the traces of the Q on its jump set. And the answer is actually yes, at least it's up to subsequences. This is the Subsequences. This is the first main result, which is, let's say, an integral representation result, which we obtained together with Eta Katerina. So we can say that up to sub-sequence, our gamma limit is always of this form. So you have brittle energy in the sense that there is no dependence on the traces of you. Of course, in this setting, you expect that this is inhomogeneous, actually also unisotropic. And up to now, I didn't see. And up to now I didn't say what is F0 and the G0. They are actually given by asymptotic minimization formulas. And let me just try to explain to you with the picture how they should look like and why they imply that we have a giggle capping. So to characterize F zero, essentially what what you do, you you zoom in around the discontinuity sorry, an approximate differentiability point where let's say you have an approximate gradient psi. Have an approximate gradient psi, and then you minimize on smaller and smaller cubes around this point just a spike part of your energy, and with some boundary conditions, which are, well, you are equal to the fine function on the boundary of the cube. I hope there's no confusion with the notation. Okay, this was written what I said before. So, along the gamma convergence sub-sequence, you minimize and smaller and smaller fixed but there's no reversions. Similarly, for the For the now for the let's say around approximate jump points, or let's say you're here sitting in an approximate jump point for the limiting function, you're going in smaller and smaller cubes, and you minimize just the surface part of the energy, but there is some coupling, or let's say there is some relation to the first part. You cannot really forget the first part. Remember that we want to have the first part to be equal to zero. So there is a condition, so you minimize among those phase gears. Among those phase fields, let's say, for which you can find a corresponding displacement field, such that on the boundary of the cube they coincide with what we want to have, like the pure jump, jumping between E1 and Nu. Maybe this one is the pure jump would just be the duke's value x, so here you're zero, and here you're jumping to E1. Okay, and you have this condition that. Okay, and you have this condition that this pair couple here vanishes. So, in particular, the first part, thanks to the Growth condition, the first part of your energy is equal to zero. Okay. And of course, this you need to understand in the correct tense because we are taking several functions, so you need to smooth a bit. But essentially, you want to have the pure jump on the boundary. And let me just say that the F0 that we actually obtain here, it coincides. 0 that we actually obtain here. It coincides with the bike integral of the free discontinuity functions, the government of free discontinuity functions. And also in the way that these densities are defined, the bike and the surface contributions really become. So here you only have a minimization involving the surface part only commodular part, and here you have a minimization involving only the bike part of the energy. And actually as a consequence of this decoupling, we obtain that the G0 is We obtain that the G0 is independent of the job folding. Okay, and let me just say that this is not for free, and I will not go into very much detail about how you prove this result, but just try to show you the main strategy. Well, also be clear that this is not for free. Any questions so far? There was a reason which cooking to send. Gervaise, Buiser, and myself, and Leonich. Yes, let me know. Actually, this will be one of the main tools. Maybe I can. No, no, let me say, okay, uh I will I will come to that because it's one of the the main tools. You mean the the integral representation results for S D V for US? That's that that's UN so no, but uh maybe I'm I'm I'm confusing, but you're referring to the integral representation for SBP functions. Yeah, but there's a case of course SBV and SBV. Yes, sure. This will be on the next slide because we are using it. But it's for SBVP functions. I see 2021 already. No, I need it. It's unprotected. It's unprotected already. It's let me go back many years too far in the Go back. Maybe I was too fast. I was too fast from the beginning. Okay, maybe it will show up. Next slide. Maybe. Let me just clarify because if I was too fast here, then you should have interrupted me. I mean, these are our functionals. So this is for sub-modeler functions. There is a general, let's say, bike part. I'm saying calling bike part, so there are two terms, let's say. One is which is of what if a modeler type, let's say, and one which is of volume type. Which is of uh volume type. But this is, I mean, it's at the moment, this is also a volume energy. It's a modicum model type, but it's still a volume energy. We want to absorb the Linux decoupling. So indeed, your result was very helpful, but there was still something to do, and I will try to convince you about that in the next slide. So now we have to do that again. Okay, so this might look like familiar to you. So, actually, the first step is So actually the first step is that you show that up to subsequences you have an abstract gamma limit, which is in this way, and I'm sure you recognize the formulas. I didn't want to go into the detail for the formulas, but actually, so let me go to the tools. What we do is we introduce the localization method of gamma convergence and we combine this with integral representation proved by Irene and he, Leoni and Masteranias, to show that Yuga limit exists up to subsequence. Yoga limit exists up to subsequences given for by an integral in this form, by energy in this form. And you also have derivation formulas. For this, you need essentially to show that your abstract gamma Lim Zoop satisfies nice properties which are in your paper. You need to work with it. Indeed, the crucial step is here to prove a fundamental estimate or obtain sub adductivity because we have a non-convex term. So you need to be a bit careful when you do a usual cutoff. Be a bit careful when you do a usual cutoff procedure. You need to be careful, but this can be solved, and we can luckily use your result. And we also get these derivation formulas, which let me not go into detail, but you see that it's implicit in the sense that it depends on the ordinary effort. So, okay. And then, actually, the second step is well, you want to identify this. You want to show that they coincide with the integrals that I showed you before. And this is really where the main work comes from. Let me just mention. Main work comes from. Let me just mention here, okay, to give you an idea how you do that, you have a minimization problem which depends on your abstract gamma limit. You use the properties of gamma convergence to write this as a minimization problem along the gamma convergent sequence, sub-sequence, which obviously at that point involves the whole energy. Well, and then you need to get rid of either the second or the first part of your energy to get these characterizations that I showed you before. And well, for the And well, for the the bike part you use it for aria type argument and uh which then allows you to rely on the result produced by um Filippo, Katarina, Johnny Lamaso and Lucia for 3DS continuity problems. And for the bike part, for the surface part, it was a bit more ugly and we were lucky to find a nice argument in a paper by Giacomini for the static evolution, which we could adapt to our setting because essentially static. Because essentially, starting from an almost optimal pair for your whole energy, you want to get rid of the first part. You want to modify your V variable in such a way that you don't see the first part of the energy. This was a bit bad. So, this was really the main challenge, let's say, in this problem. So, this part was, let's say, the the easier part, except for this uh uh sub productivity issue. Uh this part was the thing we really need to work. Part of the thing we will be working with. Okay. Is it Bosch here? So we wanted to look at the decoupling. So the gamma conversion to Australia is the decoupling which is a bit difficult. Yes, so that's right. So the main change was really that the decoupling and then the I mean it goes together. The characterization of F0 and T0 and the decoupling. And actually to get the decoupling, I mean it then allowed us to apply the result to homogenization. And okay, it's the level of. And okay, I still have enough time because actually it was too fast in the first part. So, are there questions so far about this abstract setting? Because then I will leave the abstract setting and come to the application to homogenization. So let me start with the settings. So now we are taking a bit simpler integrants because we want to get an explicit homogenization formula. So now we are really assuming that our general surface Molecular modular integral can be written in this way. So you have one well potential, let's say, plus function which depends on X at will depend on X at the brain. You assume for a moment that our integrals are That our integrants are periodic, q-periodic, and that the modicumortality grant, let's say, is too homogeneous in actually in the gradient area, but it's not. Okay. And then the functions that we considered depend actually on two parameters. So let me maybe compute this. So you have the elliptic perturbation scale or the singular perturbation scale. Perturbation scale, phase with the parameter we want epsilon, and the oscillation scale data. And then this was the example that you saw before. Here you have oscillations in an integral which belongs to your invisible class. And what you actually expect is that the limiting behavior will depend on the mutual convergence rates of your two parameters, which is the same, which also has. Which is the same, which also happens in the Modicomodula case, which also happens for discrete functions. And actually, you also saw in the talk by Arena on Monday. Also, if you don't have the oscillations in the gradient variable, but in the well itself, I mean, there is a crucial difference which parameter, let's say, goes to zero faster, or if they go to zero, let's say, on the same side. So, the aim was to characterize the gamma limit and the effect of this. And the effect of this mutual convergence rate on the gamma energy. So, can you characterize, let's say, these two parameters, relying on the abstract result that I showed you before. And let me continue by just stating you the main result at this moment. So, yes, actually, you can get the homogeneous gamma limit of brittle pi, where now you have homogenized bikin surface energy densities. And surface energy densities, and you already see from the notation here that, and this is actually thanks to the decoupling that your homogenized bike integral does not depend on the rational convergence rate. So it's independent of n. And this actually coincides with the usual volume integral that you would get for homogenization of solid functions, or also with the volume integral that you get for homogenization of uniscontinuity functions. But that you just say the solid functions here. So it's essentially a rescaling of the A rescaling of the cell formula that we saw before. Instead, the homogenized surface integral will depend on this parameter L. And actually, if you will see in the next slide, is that if L is one of the extreme points, let's say, so if it's either zero or infinity, then you will have a separation of scales effect. And if the L is intermediate, so critical regime, let's say, then the two scales. Regime, let's say, then the two scales, so the oscillation, the perturbation scale would attack, so you cannot really separate them. And let me just say that to characterize the G-Hom, it was really, in particular in this intermediate scale regime, it was really essential to have recoupling. And this is what I want to show you now before I come to the extreme regimes. So let's consider the intermediate. So let's consider the intermediate origin. Let me just recall, this was the formula that we saw before. So I was minimizing my body commodular part, which now looks this way, and I had a certain constraint on my visceral functions, which I wrote now here explicitly. So you have a corresponding u variable that you can couple with your v such that it is vanishing v gratures constraint holds true. So this is the Straightfolds too. So, this is, let's say, a picture of what your U variable should do. Essentially, as I told you, you need to be careful in, say, an epsilon neighborhood of your hyperplane, because there you cannot really let your variable jump. Okay. Maybe something, a simplified figure that you could think of is, I mean, one needs to be careful with that, but essentially what you should maybe think of is you have a set where the V is equal to zero and where U will transition. But you cannot really say. You will transition, but you cannot really say how this set looks like. But to have a picture, maybe this has. So then your surface energy will be essentially obtained via a change of variables. So let me say that one thing, so what you can show is that if you are in homogenization setting, then this G0 will not depend on X, so on the position of your cubes. So you can assume that this X is simply 0. And then you just simply perform a change of value. And then you just simply perform a change of variables, which means that you're going from smaller and smaller cubes to diverging cubes. So this is what happens. So this layer becomes of order one, and the cubes become of order rho to the L delta. So you have a divergent parameter here, and this is simply a change of arrays. Yeah. Okay. Can I just ask you a question related to the class of V on which you are minimizing? The class of V on which you are minimizing your volume. So V is equal to one on the full boundary of the Q. Yeah, okay, no, no, I should have. That's why. So I leave out actually this area here, a saturn region around the hyperplane. So that's why essentially you need to read this carefully. I I was cheating here a bit. So there's always you can each other. Yeah, exactly. So that's the point. Also the U cannot really be the pure jump on the boundary, so you need to leave out this uh So, you need to debouch this region here. And actually, so you know that in this region the V will be zero somewhere. But here, you don't really know what value will be equal to zero and where you will be allowed to do a transition. So, still think about you have a set value is equal to zero also beyond the boundary, where you can do it, let's say, diffused transition or a diffused approximation of your jump set. Okay, so yes, this This is where I stopped, and okay, actually, to perform this change of variable and to show that this limit exists, it's really important that you only have the surface part of your energy or part of your energy, simply because due to the p-growth, the two terms, the two terms of your function, they scale completely differently. So you're lost if you have a full energy here and you want to prove the coexistence of a limit. Because let me just wrap up this regime so you can show that this limit exists. You can show that this limit exists, and then you perform the change of variable. This limit exists independent of your gamma-converted subsequence, and you get your whole gamma-convertence in the case of homogenization in this critical regime. Okay, this was, I would say, maybe the most technical. Now, I think for the extreme regimes, one can maybe argue a bit better by try to understand a bit better what happens by oilistic arguments. Eulistic argument. So if your L is equal to zero, so this means that your epsilon goes to zero faster, so your elliptic parameter goes to zero faster than your oscillation parameter. So you would expect that you can theoretically think of let the delta be fixed, pass to zero in epsilon, and you would end up with a free discontinuity function of this type which goes back to a result by the Fairy. So here essentially you have to square root, you'll see why this pops up. And then you would let your delta go to zero, use the result by the writer's de Frances Pivitale, and And obtain your limiting functional for homogenization of use of functions in the theoretical case. Okay, and this is indeed what we get. So this would be the homogenized integral that you would expect to get from the result by Pradesh, Pachewski and Vitani. So essentially, you have again an asymptotic minimization problem now on a surface scale, and you are taking into account You are taking into account, let's say, characteristic functions. So, B V functions taking now in a vectorial setting values in 0 and 1, you want, and which coincide again with the pure jump problem. So, this is your minimization problem. Instead, if you are in the other extreme regime, you think about letting epsilon be fixed, first homogenized. So, you would end up with the Ambroso Turtle Ready function of this type, and now you have this homogenized This type, and now you have this homogenized integrant here. I didn't write the formula, but essentially we saw it already in the last talks. So, and then you would let epsilon go to zero and rely again on the reflection current. And indeed, this is what you get. So you you get uh the essentially the this homogenized uh bike integral as a as a surface temperature density. Okay, up to now this is uh very six, so maybe uh let me let me fill this with a bit of details because obviously you cannot do that because you still go to devil uh simultaneously. Um so let me start with the let's say easier case, so the the extreme case where you first um uh let your elliptic parameter hydrolytically go to zero and then Hioretically go to zero and then your beta parameter, your oscillation parameter. Just recall that this is the limiting integrant. And keep in mind that now we minimize among the functions. Okay, so the idea would be we have our abstract integrant, which now I know that I can remove the x, so simply consider that it keeps standard at zero. I start with an admissible pair in the sense that, okay, to be redirected in the correct way, I maybe put the picture again to be read. Put the picture again to be read in the correct way, these boundary conditions, plus the constraints. Okay? And I would like to modify the view variable to go and get a competitor for this one. So obviously, I need to pass from similar function to a V V function. Actually, what you can observe is that, I mean, what I said before, the the U is essentially a piecewise constant, except for a region where you need to do a transition. So actually, when the V is not equal to zero, your U will be one of the values zero. U will be one of the values z1 and e1. I mean, the picture is simplified, but the proof, how you prove, or you construct your competitors like this. So, what you need to do, you need to modify u to obtain a sharp interface. Okay? And so this is what you do by using a generalized color formula and the mean value theorem. And I will go into more detail, yes, I have the time, go into more detail on that. On that, on the next slide. So, let me just give you a sketch. So, let me go one slide back. So, yes, we want to modify the U variable, but the information how to modify the U variable will come from the V variable. This is the typical thing in Shatensbaum Brussels. They are common patterns. So, you use the surface part of your energy to get the information how to modify your U variable. And you use actually a standard, so this is a standard Modica modular trick, let's say you. That Modica-modular trick, let's say in this inhomogeneous case. So you use this Young inequality together with the two homogeneity of H, which allows you to put this gradient here of this integrated, let's say, well here inside the H. So this is really the standard Monica modular trick. And then you actually use a collaria formula. Formula, in the first step to rewrite, so generalized, to rewrite this as an integration of the superlevel sets of this function phi. And then you use the minimal theorem to choose one nice superlevel set. So this is what you get. So you also see why there's a curve popping up. And this is almost what almost what we want to have. So it looks already it's already difficult that we want to have, except now this is just a super level set here, so we okay. Level set here, so we still need to do something. Let me just give you a picture of maybe how you can think about that. So the V was equal to zero in this set. So on both sides, you expect to, it's a bit a simplified picture, but on both sides of this, let's say, connection here, you expect to have a boundary of this variable set. So net of one picture, it's quite clear what you would do. You actually see that you get two functions, and this is good. Two functions, and this is good because we lost factor two here. So actually, you get two functions which essentially jump first on one part of the boundary from E1 to 0 and the other one on the other part of the boundary from 0 to 1. So this is just a picture, but I mean essentially how you obtain this is by, let's say, choosing two convex combinations of your original u variable with your boundary values. So this is what is written here. And essentially you observe that the boundary of your Observe that the boundary of your superlevel set is decomposed into the jump set of these two functions, which are now PV functions, taking only values 0 and 1. And okay, this is up to HA minus 18%. But essentially, these are the two competitors that we get. And okay, now these two functions, you can plug in your minimization problem that we saw before, or back here, and you rescale it. I mean, again, you want to go to large scales, but it was the same. To large scales, but it was essentially the same rescale in some form. So, to a change of variables, you need to be a bit careful with the boundary conditions because you don't match them exactly, but this is only in epsilon neighborhoods. You can work with them, so you can extend it in a nice way. Okay. This was, let's say, the easier case. Let me say there would have been also another way to not work with our integral, so to not work with our Work with our formula that we had, for the abstract formula that we had, but in the end, we so let's say this was the easier case. We had even two proofs in the end. The regime where we were stuck with for quite some time what the other is really, but do we have to do it? Yeah, yeah. Because usually with this kind of proof at some point, you get some troubles because you have you have a bad constant in front of your uh surface energy. Compensate by the fact that compensated by the fact that uh since you have a boundary which essentially reduces to a to a jump set, this pass constant is compensated by the multiplicity. I mean, you have a boundary of Epsilon which essentially shrinks to a junk set, to a line. And yes, so there is a yeah, so it's actually Yeah, so essentially this should happen, but on that side of level you still have, let's say, two-sided approximation. Yeah, yeah, so with this multicamorphola trick and the mid-value, usually you get too low the filter with a factor one half or something like that, which is supposed to be compensated by a yes. So actually there is that we lost the factor one half here because you are only integrating over zero one half. I don't know if this is what the you lose the factor. Know if this is what the PLC, you lose the factor one-half, because of the two values. Because of the two, but we get two competitors. Two competitors gives you the right constant. Yeah, exactly. Two competitors, that's why essentially to get two competitors. Two competitors gives you the right constant because on the epsilon level, you're not collapsing. So you get really decomposition of the boundary. And you get two functions. Yes, you have two jump sets. Exactly. Exactly. Okay. No, but it is. So actually, at some point, we thought, no, it doesn't work in this way. And then we realized that we can actually. Yeah, okay. No, but you reduce the factor and you do. Thanks. So then let me try to speak about the last regime. And let me admit that I was cheating to you before because I was not giving you the complete statement of the proof or the complete correct statement of the theorem, sorry. Because actually in this extreme regime you have you need one additional thing. One additional thing, somehow you need to at least you need to relate your blow-up rate of your u-variable with the oscillation scale. And that's why we considered actually the perturbed functions in this way. So remember, when I showed you the Ambrose-Totorelli functions in the first instance, we had this additional parameter here, which in the first place was just a parameter going to the zero faster limit failure, which is exactly the case in this one. Which is exactly the case in this regime. So, in this extreme regime, we have the result for these hedgehog functions. And so, the idea is now, of course, I cannot rely anymore on our abstract formula that we have, but you can go ahead. So, you still have an integral representation without saying. So, to get the lower bound, the idea is: okay. The idea is: okay, if you start with a sequence which converts to a Q jump and your Q-oriented retinue, so to characterize your surface energy density, you would like to replace the original phase field variable with an, let's say, average phase field variable, which satisfies essentially this inequality. At least approximately. So, asymptotically, sorry. Okay, and the way this is done is essentially by averaging our, let's say, data size Q. Averaging over, let's say, data set excuse. You expect to average when you homogenize. There is, of course, a problem with that, which is that you cannot really forget the first problem of your part. It's non-convex, so if you average, you are not equal to the troubles here. And this was actually where we were stuck for quite a long time. Let me just say that in the one-dimensional case, this is easier, because you have a point-wise control between your original phase field and the average phase field. And the average phase field because you have solo formatic. So if you average your point-wise control, this gets lost in high dimensions. So you only have, let's say, a control in an integral sense using Ponkerland inequality. And so actually, you are not sure anymore that if you do this averaging procedure, that your f bike integrant will stay even uniformly bound. But what we discovered at some point is that Discovered at some point is that since now in this perturbed regime we have this additional control on the L2 norm of our gradient, you can actually get, let's say, a worse bound, but still, let's say, a uniform P bound for some P between 1 and 2. So you need to lower a bit your exponent, but this exponent will be still larger than 1. And this is enough. So we are getting a bad constant in the bioed part with a bad integer ability, but we don't care because we only. But we don't care because we only want to characterize the surface part. The bypass we already know. So, actually, with this estimate, where essentially now you use the control between average and original function in the integral sense, so using Boca inequality and Helean inequality here, you get this estimate, so then you can actually use the gamma conversions for again these functionals here, where you can rely on the resulting by Foucaulti. Obviously, you don't get the conversion. For Cardi, obviously, you don't get the correct right part, but you get the correct softest part that you would have expected. And so, this was how we're able to solve this problem. And with this, I think I'll just wrap up. So, to give you a summary of what we have seen, so we have characterized the gamma limit of that state general phase field function as a result of Really type, and we have actually obtained the volume surface decoupling in this setting, which was the. The setting, which was the main motivation, let's say. And then we could apply this to homogenization and see the interplay between these different parameters, there's singular perturbation scale and the oscillation scale. And well, of course, there are some open questions, let's say. So up to now, I showed you the periodic homogenization. So actually, the stochastic homogenization we did in the intermediate regime, but in the two extreme regimes. But in the two extreme regimes, it's then of course something very nice would be to do that, to do such general results to obtain a setting of linearized elasticity. But Flamiana is already smiling. There are a lot of issues if you pass to linearized elasticity, and essentially the tools that you use to obtain a decup and they fail. So, okay, and then of course, once you have this decoupling, And then of course once you have this decoupling uh it would uh would be natural to to try to consolidate body static evolution in the set of of Jacomini. But I think with this uh thank you for your attention. I stop here. There's time for questions. Well actually um you can take it work on boundary conditions. It was already so it was a bit hidden but every time that that we considered this minimization problem on cubes they were with boundary conditions. So I did not go into detail about that but so maybe I can go back to this oops no it was not okay. Can I still go back? Yeah. Oh there's a go. So So if you think here, you have a minimization problem on the gamma limit in one of the boundary conditions. And essentially you approximate it with a minimization problem along the gamma convergence of sequence satisfying the same boundary conditions. You need to work a bit to show that you can match the boundary conditions, but this is where you use a fundamental estimate. Fundamental estimate comes again into play. But you can take boundary conditions, yes. But of course, this is also starting from the bulk, satisfying boundary conditions. We could start on the boundary of A. Not at the level of the self-formula, right? Yeah, I mean, yeah, sure, you can do it in general. So I was just saying we used it already here, but in general, you can put boundary conditions, yes. Yes, if you need to do hardware conditions. Of coordinations on the bottom. Where can Billy I love you? I'm not sure why I would set U equal to U naught on the boundary. Right? Yes, but I'm quite sure you can do it with a fundamental. Yes, but I'm quite sure you can do it with a fundamental estimate. I'm quite sure that you can treat the bar uh that you can well with the fundamental estimate. Not really if you do the cut really, it's well first of all you have to have all the coalitions which agree with the wells, some senses body. I mean, it's not body. It's not forced in the wells, so there's no preferred state. No, no, I agree. So now I understand. Of course, if you are in the modicum modular setting, it's different because yes. But here, I mean... No, no, here these are the modules. Here is actually, I mean, if you have the fundamental estimates, so the work is in the fundamental estimate. Yeah, of course, here it's different. Yeah. Okay, now I got it.