Of this session is Giselle Estrada Rodriguez from the University of Oxford, and she's going to talk about diffusion and super diffusion in complex. Thank you, Liao. First of all, thank you to the organizers for inviting me. It's a great pleasure to be here in Granada for my second time, at least at university. So my talk is going to be very applied for this crowd, but hopefully you will find some interesting analytic questions out of this. Out of this. This was work in collaboration with Ernesto Estrada and Heiko Guipper. So I'm going to start with some general motivation of why we were interested in studying diffusion and super diffusion processes in complex domains. Then I'm going to introduce a new entity, a metaplex, and I'm also going to define diffusion and super diffusion processes in this entity. In this entity. And then towards the end, I'm going to show you some numerical results using a very simple toy model and also using data from real world. And I'm also going to try to keep this last part short, the numerical results. Okay, so super diffusion and diffraction of Laplacian has been studied from many different perspectives. Many different perspectives, so either from the analysis or numerical analysis point of view, and also from the modeling perspective. And I am more interested in this part. And in fact, during my PhD, I was concerned about describing or deriving microscopic equations that are physically relevant from the kinetic description of certain movements. So, for example, Movement. So, for example, we obtain fractional Keller-Stigel equations from non-local kinetic equations that describe the non-locality of the movement. You can think of it like a kind of a levy process in space. And then at the macroscopic limit, what you obtain is something like this fractional galactical equation. Also, we studied fractional space and time. Space and time, space-time fractional equations. This case was motivated by the movement of immune cells in the brain. So, in this case, there is a combination of long waiting times and long runs. So, there is non-locality in space and time. And then, at the macroscopic level, again, you start from a kinetic description of these two populations of moving cells and resting cells. And what you obtain at the macroscopic level. And what you obtain at the macroscopic level is this type of space and fractional diffusion equation. And furthermore, we studied this super diffusive process, also combining them with alignment and collision avoidance in a system of interacting particles. And this was motivated by swarm robotic systems. But in all these cases, we were only concerned with the movement in Rn. So there were no. In Rn. So there were no boundary conditions, no obstacles, no interfaces. But what happens if I want to study this movement in more complex domains, for example, such as the brain, or in a non-complex, very complicated geometry. And in fact, this research was motivated by a discussion that we had one day. So imagine if there is a part. So, imagine if there is a fire in the Buckingham Palace. What is the best strategy to find the queen if we don't know where she is? So, this was our main motivation. So, what is the best search strategy in order to find the queen? You know, you have to search. Sure. Yeah. You have to search. I mean, now the clean, obviously, you have to search a lot of rooms on. Lot of rooms, and also you have to go along corridors. So, what is the best strategy? You use a super diffusive process, you use a diffusive process, a combination of both. What is the strategy here? So, in well, a typical assumption, for example, when you study these processes in the brain, is to approximate each brain region by a point node. And then you study whatever process you are interested in. Whatever process you are interested in in a network, right? But then, with this approximation, you lose a lot of information about what is happening inside each brain region. And then, what you observe at the macroscopic level, you don't know if it's a result of these internal dynamics. So, what we propose here is to give some structure to these nodes. Okay, so now they are not going to be just point nodes, but domains. But domains banded domains in R2, right? And then the idea here is to have a continuous diffusion process happening inside each node, coupled with a discrete diffusion process across the network. Okay? And this is what we call a metaplex. It's a fancy name, but it's basically a network where you have some geometry of the nodes. Okay. Okay. So, of course, you can think of many other examples where you can profit from given some internal structure of the nodes. So, for example, in metapopulation dynamics, right, when you have a city that is composed of neighborhoods, there is always some transport and diffusion inside each neighborhood, but at the same time, you have things that move across the city. Okay, so and also, for example, in non-local. So, for example, in non-local foraging strategies of certain animals, when you have patches of lands and then animals search in each patch, but also across the landscape. So, in these examples, and you can think of many other, you can profit from knowing the internal structure of the nodes. So, the main question that I'm going to attempt to answer, or the main message that I want to convey. That I want to convey is the following. So, how the global dynamics in a network is affected by the internal structure of the nodes. Okay? And for this, I'm going to look at three particular ingredients. So, I'm going to describe the internal dynamics in the nodes. You can think of it as diffusion, super diffusion, or a synchronization process, or your favorite process. I'm also going to look at the geometry of. I'm also going to look at the geometry of the nodes. So, what is the impact of the geometry of the nodes in studying the diffusion across this metaplex and also the connection between these nodes? Okay, so let me first start by formally introducing a metaplex. So, a metaplex is a fortuple capital gamma where VE it's a graph. So, V is the set of vertices and E is the set of edges. Is the set of edges. Omega is a set of compactly supported metric spaces where you have, you can think of it as any geometry that you have that you want. So omega j is just any domain. And I it's going to be a map that is going to assign to each vertice a different geometry. Okay, so again, you can think of any complicated landscape or metaplex that you want. Metaplex that you want. But of course, this is very complicated, this is very general, so let's try to simplify things a bit. And for this talk, I'm going to consider that all the domains are balls of radius R. So this is, for example, let's say a typical metaplex where all the nodes have the same geometry. So they are just R2. And with the Lebesgue measure, and of course, then I is a. And of course, then I is a constant map because I said that all the domains have the same geometry. So, as I mentioned at the beginning, we are going to have a discrete diffusion process happening in the network and a continuous diffusion process happening inside each node. Okay, so I'm going to start by describing the discrete diffusion process. And here, the diffusion among the nodes of the graph is given by this. graph is given by this by this equation here. D is the shortest path distance between two nodes and dmax is the diameter of the graph. So basically the longest distance in a graph. Here the Laplace D is actually the d-path Laplacian operator on a graph which is defined in this way. So basically it allows the diffusive particle to jump not only Particle to jump not only to neighboring nodes, but also to nodes that are at distance d away. Okay, so for example, if d is equal to one, then this is the classical Pas Naplian. But now what I'm doing is allowing this diffusive particle to jump to further away nodes. This coefficient C D is going to tune the hopping of the diffusive particle and between And between long-range hopping for the Meline transform D-Path Laplacian, or it could be also short-range hopping for the Laplace transform D-Path Laplacian. So basically, this S-net, it's positive parameter. And here, basically, what I'm saying is that the probability of jumping to a node of length D decays algebraically with the distance. While in this case, the probability of While in this case, the probability decays exponentially with the distance. Okay, so you can think of it as for this case the long-range hopping will allow the diffusive particle to jump to further away nodes, while for the case of the Laplace transform, the path Laplacian, it only allowed short-range jumping. Okay, so with this, I can describe the continuous. I can describe the continuous diffusion dynamics inside a NOT, which this is not new to anyone here. So, a diffusion process is described by this equation here, where UJ is a probability density in the node VJ. Here, S node is going to be a parameter that is going between 0 and 1. When S node is close to 1, then you are close to diffusion. When S node is close to 0, then you are close to super diffusion. zero then you are close to super diffusion or the process is more super diffusive and the application of this uh fractional laplacian to at some time at some given time is given by this expression here that i think we have seen yesterday um well this is just a constant that depends on the dimension and this parameter s node uh pv is the cauchy principal value of this integral and in fact for numerical reasons that i don't have the time to explain here That I don't have the time to explain here. What we use, in fact, is a bilinear form of this fractional Laplacian with Neumann boundary conditions. Okay, but just think about it as a superdiffusive process happening inside the node that is controlled by this equation here. And well, this parameter S node will give me faster or slower superdiffusion. Okay, so. Okay, so now, of course, we have to describe this global diffusion in the metaplex, and this is given by a coupled system of diffusion equations written here. So, let me go term by term, step by step. So, divergence J is just a generator of a diffusion, of a diffusive process, which basically describes what is happening inside the nodes. Inside the notes. Then the edges Vi Vj are realized by a map, which basically describes the jump between the nodes. Okay, so if I have a particle at position X in one node, it's going to jump to the next node and it's going to appear in the position psi JIX. Okay, so this just basically describes this jumping across. Describes this jumping across nodes. And finally, alpha ij is just transition rates between the nodes. So basically, it describes how strong is your coupling between the nodes. For simplicity, in all that we are going to see, this is going to be independent of x, but in general, it could depend on the space. So, here what we have is again a diffusion process happening. Diffusion process happening inside the nodes. Then I have some density that is leaving this node BJ at some given rate, and at the same time, I have some density that is appearing in my node from neighboring nodes. In general, you can prove that this conserved the density in the whole meta place. And in fact, it's a bit easier to write this in matrix form. So you can see. form. So you can say that you can define a vector of solutions u, where each uj is the solution of the diffusive process inside the node. n is the total number of nodes. And then the diffusion, the whole metaplex, you can write it in this more compact way, where capital D is an n by n block operator matrix, which is composed of these two terms. So here H is the data. Here, H is the diagonal matrix that again just describes the continuous diffusion process that I just mentioned before. And capital T is this matrix that describes the transition between the nodes. So Tij are transition operator between the different nodes. And this transition operator is defined in terms of sync and sources. So a sync is So, a sink, it's a subdomain inside one node where the diffusive particle or the diffusive density leaves this node and appears in the location of a source in the next node. Okay, that is what this transition operator here is doing. It's just basically transporting density from one node to the other or from one node to nodes of at length D. Okay, so. Okay, so before going to the numerical results, I wanted to briefly mention some preliminary analytic results that we obtained, which basically are not for metaplexes, it's just for diffusion in general. So just trying to understand the structure maybe a little bit. I'm a little bit confused by these things and sources. So the interchange of the mass between two of these nodes happens in a specific Happens in specific regions, right? You right, say I have a constant flux between the source and the sink, or you know, I should really think that this is how my what is setting the geometry and the location of these things and sources? You, uh, there is, I mean, you can define it in any way that you want. And it basically, it's not even a flux because what you do is you map the density that you have. So let me, in this picture, you basically take the density that you have in here. Density that you have in here, right? This is a thing, and you map it into the next node. Very good. Where exactly within that node? It's a region that you define. It's a region. I mean, what you have here is a discretized solution, right? So you can define another subdomain here where you call it a sink, and then you define another region here that you define. Exactly, the doors in the palace, and these doors could be. Doors in the back, and these doors could be, you know, at the disjoint sync and sources, but you could also think that they are at the boundary, right? So, this is something that you define. The connection between the nodes, it's something that you define depending on your problem or that's also part of the structure. Yes, yes, yes, yes, yes. Yeah, yeah, yeah, exactly. And then in the numerical results, I'm going to show you that it really matters where you put these synchron sources. So, it's not the same to have this type of a structure or to have a A structure or to have them with the sink and source in the middle. So it's very because here you see that they are disjoint. So this one appears here and then this density kind of travels onto here and then moves to the next node. Okay, but if you have them coupled through the middle, then the dynamics is completely different. Also, if you have them through the boundary, you then get another dynamic. So it's very important where you put your synthesis sources. Uh, your synthesis okay, so um, as I was saying, this is uh something that is uh already well known, but uh it's something that we can profit or that we can borrow to study in a diffusion in a metaplex. So you can consider that this uh HJ is either you know the fractional Laplacian or some self-adjoint elliptic operator with normal boundary conditions and the Conditions. And then you know that the solution in a node omega j is going to be given by this integral operator where khj is just the evolution of a point mass, right, at position y at time equals to zero. So and then for some constant greater than zero and away from the boundary, for the normal diffusion case or for the classical Laplace. Or for the classical Laplacian, what you get is that this satisfies a Gaussian estimate. Okay, for the case of the fractional diffusion, on the other hand, you know that it decays algebraically, it has an algebraic power law decay, and it satisfies this Poisson estimate here. And this estimate is char but only on the bundle. But only on bundled domains and for short times. We don't know for long times. And with this estimate, of course, you can say something about the diffusion inside the nodes and across the metaplexes. Also, you can quantify, for example, the waiting time. So, the time that it takes for a density to travel from one sink to the other source. And this is something that you can. And this is something that you can quantify with these estimates. Okay, so I think I'm going to start with the numerical results, which, I mean, the first part, I'm going to only focus on the toy model. If you have more questions, I can discuss the real world examples, but I don't think I would have time. So the toy model is just a metaplex that is composed of Azalea. Is a linear graph. Okay, so all the nodes are connected in a way of a path graph, and we start with the uniform distribution in the first node, and then we're going to study how this initial density evolves across the metaplex. As I mentioned at the beginning, we are going to play with this parameter. So the S-Net controls the diffusion across the network and the S-node controls the diffusion inside. Node controls the diffusion inside the nodes. Also, we are going to consider different sizes of the nodes. So, we are going to have nodes of radius one or radius 100. Also, as I mentioned previously, we are going to consider different coupling points. So, either the nodes are going to be coupled through the center or they are going to have disjoint sync and sources, as in this example here. And also, of course, we are going to. Also, of course, we are going to consider either a short-ranged coupling between the nodes or a long-range coupling in the metaplex. So, the first result that we observe is that internal superdiffusion accelerates the hopping in the metaplex, but the culibration is slower. So, basically, the diffusion helps the diffusive particle to travel faster. Diffusive particle to travel faster across the metaplex, but the equilibration of the densities is slower. And this is a bit counterintuitive, right? Because you would think that super diffusion would acculate things faster as well. And the reason for this is that when you have, imagine that you have a superdiffusive particle or a super diffusive density, right, that arrives at some point, then due to the nature of the Levy process, with certain probability, it will jump, it will have. It will jump, it will have a long jump away from the sink, and then it will have some time until the diffusive particle finds again the sink and can move to the other nodes. So, there is some time delay in this density in each node. While for the normal diffusion, what happens is that you have a normal diffusive density moving here, then it will stay around the sink. It will stay around the sink and then it will travel again to the next node. So the normal diffusion is slower, but it's more effective. Let's put it this way, to equilibrate the density. Then, of course, the geometry and coupling points of the notes play a crucial role. And this may seem like something very obvious, but it's really not. So let's So let's see an example. So here we have the case of disjoint sink and sources, and we have considered only short-range coupling. And what we are going to look at is at the eculibration of the density in the first node. So here U naught is the initial condition in the first node, N is the total number of nodes, and this just quantifies the eculibration of the density. Here on the left, we have the result for the small node and here for the big nodes. And here for the big nodes. And let's forget about all these parameters here. Let's just bear in mind that the discontinuous line represents the normal diffusion inside the nodes, and the continuous line represents the super diffusion inside the nodes. And what we see is that normal diffusion inside the nodes equilibrates the density faster than super diffusion for the case of the small node. And again, the argument is. And again, the argument is the same I explained before. Okay, there is some time delay in the density when it travels inside the node. While for the case of the big nodes, totally the opposite happens, right? So the super diffusion inside the nodes equilibrates the density way faster than the normal diffusion. And this is because, in this case, for the case of the big nodes, the synchant sources are very localized and far apart. So for this case, So, for this case, the super diffusion is actually more effective than the nervous diffusion. Then, we saw that super diffusion inside the nodes accelerates the diffusion in the metaplex, but it doesn't lead to superdiffusion in the network. And this was my main question at the beginning, right? So, can the internal dynamics affect the global dynamics? And the answer is it depends on the And the answer is: it depends on the topology of the network. Okay, so we are going to see that for this type of linear metaplexes, the superdiffusion inside the nodes doesn't affect the diffusion in the metaplex. So here we have on top we have the short range coupling and here we have long range coupling. And what we observe is that in Observe is that independently of the internal dynamics, so either diffusion or superdiffusion, in all these cases the density inside the nodes decrease exponentially. So this is a log-log plot. The density decreases exponentially, so it's a diffusive process. No matter how strong the super diffusion inside the nodes is, if I have a short range coupling, then I'm going to get diffusion in the metaplex. Diffusion in the metaplex. The same happens for the long-range coupling. So here we see that the diffusion in the metaplex decreases algebraically, which is the case of a superdiffusion process. And this happens no matter the slow the density is inside the node. Okay, so basically for these networks, for this topology of the network, the internal structure doesn't affect the global dynamics. And finally, And finally, from real-world data, this is the only thing I'm going to mention. We have that when we have densely connected network or densely connected metaplexes, which means that basically all the nodes are connected between each other, then in this case, the internal dynamics dominates completely. So, for densely connected networks, the internal dynamics is the The internal dynamics is the one that drives the diffusion or super diffusion in the metaplex. And for this, I'm going to skip this. So this is the real world example that I want to mention. So it's the connections in the brain, in the visual cortex of a macaque. And what we have here is the density, it's a network of 30 nodes, very densely connected. Densely connected. And what we have here is the density in each of these nodes over time. And we have that for very different dynamics in the network, so for very different external dynamics, the internal dynamics dominates. It doesn't matter how strong the superdiffusion or how strong the diffusion is in the network, the dynamics in the metaplex is driven by the internal diffusion. Driven by the internal diffusion or super diffusion. Okay? Okay, so just to conclude, there are a few things that we can consider, I mean, from the modeling and probably from the analysis side. For example, you can think of other dynamical systems to put in a metaplex. Here, I did only diffusion and superdiffusion, but as I mentioned before, you can think of synchronization. Before you can think of synchronization or firing neurons or I don't know, your favorite dynamical system. Also, one thing that we didn't do was to study the long-time behavior of these metaplexes, so the steady state, how this steady state looked like in the whole metaplex. And finally, another thing would be to rigorously prove some of these numerical results. So, for example, example um for the case of the of the densely connected metaplex you could uh probably rigorously prove uh this result of okay if i have a network and i then this um the the vertices tend to infinity what is what is happening in the metaplex do i get that the internal dynamics dominates with this limit so i think uh i think it's this is something uh doable and that Something doable and that this result can be proven rigorously in certain topologies of the network. And okay, I think I'm on time, so thank you very much for your attention. I think this stuff for the very interesting results. Any questions or thoughts? I don't have one. I don't have one. So well when you say that actually um in a very connected network uh everything depends only on what is inside the domains. You assume that the connection between domains have the same weight or yeah but if you change that do you believe then I don't know yeah I don't know if changing the strength of the connection will would change. Strength of the connection will change something. For this densely connected network, it was real data, so it was a real network of pieces of brain that are connected in the visual cortex of the maca. I don't know if it would be different if we consider certain regions that are connected stronger than others. I don't know. A very quick one. Okay, then I will talk to Tennessee. Yeah, okay. Thank you to the time to change. Let's thank you. So, yeah, thank you.