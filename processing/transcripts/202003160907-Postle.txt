I'm going to begin. So I had to change my title, as Paul said, because I'm going to have to give two talks together. This would be Improving Grounds for Habuger's Conjecture. And this joint work with Sergei Dalin and Julia Song, I'll be talking about their work. And actually, they've decided to make a joint paper of the remote together. Together. So half sets. Okay, let me maybe move on. So as you all know, you probably know Hadriger's conjecture from 1943. I'm going to assume a somewhat basic level of graph theory confidence here, that you know what a minor is. But Hadriger conjectured: if you have no kt minor, then the chromatic number isn't minus k. And this was a nice conjecture because it. And this was a nice conjecture because it's far reaching, because it's a lot of nice spectral cases. And it's kind of fundamentally the best you can ask for. Want to relate having no computing on or if you like to schematic because it can look like some brief history. So originally I'll give you history, but it's joint. We'll just say a little bit. So here cases, T at most four were proven by Hadlinger in 1943. Hadlinger in 1943. Previously to the conjecture, Wagner had already done work that would show that the T equals 5 case was equivalent to the four color theorem. As you all know, the four colors theorem proved by Oppel and Hawkin in 1977 in the 70s and a later new proof by Robertson, Sanders, Seymour, and Thomas was in the 90s. And now it's been formally verified with provers. So everyone believes the four peller theorem, which is great. The T equals Which is great. The t equals six case was actually done by Robertson, Seymour, and Thomas in 1993. And you should note, though, as a special case, it has the four-color theorem, right? Because to any planar graph, I can stick an apex vertex, and that graph won't have a case X minor, and I have to then have the four-color theorem as a special case. So, in particular, that'd be very hard. And so, Robertson and Seymour and Thomas didn't reprove the four-color theorem. Reprove the four color theorem. I mean, they actually had separately done that anyway, but they didn't do that because that would be a lot of work. Instead, they just wrote 150 pages, which reduces this case to the core color theorem. And so that was very hard. And so maybe it won't surprise you to know that T at D7 is open and been open for almost 30 years now. And T equals 7 just seems very hard. And so maybe a kind of better question is what can we do in general? So, you know, a lot of people have worked on special. So a lot of people have worked on special cases, and I won't go into all of the history or proving it for certain different notions of coloring, defective, clustered, et cetera. So Paul has a nice survey on Plotwiger's conjecture. So I won't go into all of that in the interest of time. But so what's nice? Let's talk about doing general bounds. And in particular, if you, the four color theorem, the four color theorem is very Is very hard, but somehow the five-color theorem is not very hard, right? And so, actually, it'd be nice to even wonder if the linear version of Hadlago is true. Is there some constant, 100t, 1000t, wherein, you know, if you have no KT minor, is that? So now let's maybe move over to general bounds. So, what is true for general bounds? So, what are the best general bounds? So, one So, one theorem we have comes from Vostachka and independently by Thomason in the 1980s, which it's really not a coloring theorem, it's a structure theorem. It says if G has no KT minor, then G is O of T root log T degenerate. So exactly they figured out what the correct degeneracy is needed. So earlier, Monero proved something like 2 to the T degenerate that there was some bound, and this was eventually improved to T root log T, and Thomason actually. log t and Thomason actually in kind of early late 90s early 2000s figured out the exact constant it's something like 0.6 depending on how you phrase it that goes here so you know we very there are tight examples and this implies that though that the chromatic number is at most t root log t so this is kind of was the best general bound but it had nothing really to do with coloring because you just use the degeneracy to do greedy you just delete vertices one at a time and One at a time and color greedily. So, in that sense, it's really a structural result. And I should mention here that the tight examples are random graphs, or one kind of family of tight examples, or random graphs on about. On about t root log t vertices and say, like with p being a half. And you can argue that small random graphs here will not end up having complete minors. And so in that sense, you know, they're tight for this degeneracy argument that they're not counterexamples to Heidewicker's conjecture, right? If they were, we'd already be done. were we'd already be done but they're not because in fact random graphs you can actually see it around a log t vector so you can color them t over root log t here and but these present a problem right if you want to make any improvement you have to somehow get over this case you have to get over these these ones which okay random graphs are easy to color but generally how do we how do we deal with such and there's a lot of uh flexibility to these counterexamples because you could change the p a bit you could make the size of P a bit, you could make the size a bit larger, and you still you maybe lower the minor number a bit, but you're not going to get down to say linear. And so we have to deal with this whole range of kind of random, niche, small examples. And how are we going to do that? So I'll get back to that part. But in the meantime, the main results of this talk are these two advancements that happened recently. So Noreen and Song put a paper on the archive. The paper on the archive back in the fall, and they showed they made the first improvement over the exponent of this bound. So I should say that this bound had been improved slightly. So there was an additive improvement that was made. David Wood had a nice result there where you subtract off some number. With my student Tom Kelly, we had put some multiplicative improvement, but like 0.98, like a lot of work for other things just to change that. So we didn't, we're, you know, battling. To change that, so we didn't we're you know battling the constants here and not the actual functions at all, not even dividing by like a log r t. And so, there had really been no movement in the last 30 years on this exponent in particular. And well, until this Norium's all bigger. And what they were able to do is get this from a half down to 0.354. Or rather, there's an irrational number that you just want to be bigger than, but let's say 0.354. And I'll go through their argument. And I'll go through their argument because basically I came in and was able to help them to improve one of the parts of their arguments. Basically, they have a kind of a two-part argument, two cases, and in one, I was able to improve, and we get this result that you get t log t to the beta for any beta greater than a quarter. And so, really, what's happening is you get t log t to the quarter and something that's sub-logarithmic, something more like two. Sublogarithmic, something more like 2 to the log t, something like log log t to the 2 thirds. So you're getting some weird function there, but for simplicity, let's not talk about that and just say for any beta, fix beta greater than a quarter. So that was a very nice result. And so, yeah, together, and I'll kind of go through then the proof is the plan for the talk, and to show you this overall nice big plan of theirs. And what's really nice. Big plan of theirs, and what's really nice about the Noreen Song paper is actually, to some degree, it provides you a roadmap for maybe not proving Heidewiger's itself, but proving the linear version of Heidegger's or something very close. At least I think the sub-logarithmic would be nice. They can get t log t to the beta for any beta greater than zero, or t log log t. Results like that would be very nice and exciting. And their plan essentially. And their plan essentially gives you a hope, a roadmap, that you could actually get that result. And they actually have a conjecture, which maybe we could talk about at the end, that's kind of clear from the proof of that would give you hopefully such results. So that is what I'm going to talk about. Again, if you have any questions, I guess you are all muted, so you can't tell me, but maybe you can type in the chat if you have anything specific or unmute yourself and then ask a question. Unmute yourself and then ask a question. Okay, gotcha. Yeah, actually, let me say people are free to unmute themselves if they want. Just click on mute in the bottom left and then you can talk. But please mute yourself again afterwards. Yeah, you don't want embarrassing things, exactly. But yeah, this is all new and experimental, but okay. We'll continue. Okay. So lots of boards here. So lots of boards here in that space. All right, so then there are no actual questions about the history or these results. Then I'm going to get started on the big picture plan. So I promised you that they have this very nice kind of overall proof strategy, this overall plan of how to really make this big advance. And so that's what I'll just prevent. And so that's what I'll just present, I'll present it kind of in miniature, the overall structure. Then I'll go in and I'll do some minutes on their part, on that kind of that first big case, and talk through that without doing all the details. And then I'll talk some about kind of the second case, my part, and that. We'll hopefully have some time for questions. Okay, so here's really the plan. It says that I liked about it as there's I liked about it as there's small graphs and large graphs. So let's talk about small graphs. Wherein small graphs will mean, so the word small here will mean that the number of vertices is at most say something like t poly log t. So are we okay with this? So this will be a nice idea. If you have a now, you know, you could debate. But now you could debate what is small. This is in some ways very small, right? It's not even t squared, it's not t you know, 1.5, it's t poly log t. And again, it's a poly log in our practice, maybe you need a lot log to the fifth if you did this correctly. But just some constant is fine to think here. And that's very small, but importantly, it's enough to cover the tight examples from the Kostachka-Thomason bounds, right? Kostachka-Thomas enacts, right? Those were small, and so then you know they will be covered by kind of a very simplistic case that we'll do. And all that's going on here is we're going to use independent set, you know, or if you wanted, you could instead use fractional results to iteratively cover, to iteratively cover. And so here we can do it in about O T log log T and that's actually quite nice and you actually kind of see there's a little bit of room so this is not where the bottom ethics actually if you're not trying to go for linear then and just sub logarithmic this is not the where the odd t to the quarter comes from it's not the small graph Quarter comes from, it's not the small graphs that are the main issue. So maybe I'll just quickly, yeah, actually, let me finish the thing and then we'll do the small graphs. This is not very hard. I can actually just prove this to you, but let me finish the large graph. So the large graphs are, of course, the bulk of the work, and there's really two big cases. So case one will be there exist many, and I'll just go ahead and tell you what the And I'll just go ahead and tell you what the word here will mean. So this will be something like square root log t over 2. So, you know, poly log t would also be fine, but actually square root log t over 2 is enough. And what is it going to be? They're going to be vertex disjoint graphs let's say, you know, you'd have Let's say you know you'd have H1 up to Hm such that essentially the density of each AI will be or average degree rather either way or not just two constants will be on the order of t log t to the quarter so not beta but rather here would be fine to have a quarter. But rather here would be fine to have a quarter. Quarter is somehow the magic number that we need. So either there's kind of lots of disjoint, you know, high density subgroups, and that will be very good. So here the plan will be, we'll show that you can get a KT minor, assuming connectivity. Connectivity. And we're going to be able to assume it's connected from a result of carbiology, but I think we mentioned again in a little bit, but that's our case one. And now we'll move over and we'll just go ahead and talk about case two. About case two. So, in case two, okay, so that's kind of a dream. If we have lots of nice, dense subgraphs, that sounds good. Maybe we can build a minor by using them to kind of build the minor. And case two would be, well, they're do not exist. The opposite. What do you do in this case? Well, somehow the idea is to consider. The idea is to consider a maximal collection, h1 up to hm, with that properties. And so then if it's maximal, but you don't have that many, n would have to be my most square root log t over 2. And now the point is that the union of the m's Of the M's is a small graph. Except I have to tell you something, where they're small. Take and each HI is small. So it's not important to case one that the things be small. That I'm just happy to use connectivity and build my minor. But here it's going to be quite important because I'm disguising this next statement. Important because of this cathedral, this next statement. I would like them to be small because I would like their union to be small. So if they're all polylog t and there's only poly log t of these, then the whole thing is polylog t. And so this is a small graph and or rather the g on the union of the vertices on the union of the vertices. You know, this part of the graph can be colored with With, as I mentioned, O T log log T times. Right, and now what's the last part? Will be that, okay, so what about the rest of the graph? So the key will be that if a graph With no KT minor has no small subgraph with average degree at least omega t log t to the quarter. So what can I do? In the rest of the graph, I can't find another. I can't find another h to add to my collection, right? It's maximum. And what would that mean then is there's no small subgraph with a high average degree inside of that, but it doesn't have a kt minor, and we'll have a lemma that will show then the entire average degree, it won't be too large. So it'll be t log t. So the beta, for any beta greater one, that's the key. That's the key lemma, the key theorem that we will talk about and prove. And so now, given this and that, it's kind of obvious because it implies that g minus the union of the h's is O T log t to the beta, degenerate and hence color. And so it's G. That's the point, is that? That's the point, is that right? You can somehow it's very nice because it it you know, it takes all the things that are kind of small and dense, all these because you could be you know the disjoint union, you know what, you could be the disjoint union of the type counter examples, right, to tight examples of Costachka Thomas. And this takes care of that, right? It throws them all together, and it says either you're going to kick a lot of them, or it'll be that we end up, they're together kind of small, and then we. They're together kind of small, and then we just color the rest, which will be kind of sparse. So that's the overall game plan, and I'm going to go ahead and try to go through each of the cases in the form that we have left. Going again a little slowly, and if anything's confusing, you can ask questions. Okay, so small guys. So I'll just remind you of some known classical results. How do you do small plastic? Small graphs without KT minors. Well, there's a nice result of Duchet and Menu from the 80s, which says that if G has no KT minor, then alpha of G, the independence number, rather large. So you can find a large independence of something linear in fraction. Something linear in fraction of t. So here, kind of with a factor 2, 2, t minus 1. This was improved or generalized by Reed and Seymour around 99. And they said the same thing, but they show that the fractional chromatic number is in most 2t minus 1. In a very nice paper where they talk about eggs and yolks. Eggs and yolks has a very nice proof building on that. So we don't actually need that, we just need the independence one, essentially. But you know, so actually, one of the specialized or weakenings people have thought about is this fractional or this independence. And so the fractional one is not known to be true, but at least up to a factor two. So that's very pleasing to see why Hardwickers couldn't be true. And so actually, let's not even use that one. Let's not even use that one. Let's use a slight strengthening of this one that Paul noted in his 2016 paper, but it's just implicit in the proof of that. And it says that, you know, if you have an OKT minor, then actually you can find a subset of the vertices that has size at least half and where the where the chromatic number, the chromatic number of gx is at most t minus 1. So essentially, in their proof, or if you understand this, how that would go there, you end up with something like that you kind of have t minus one layers, and in each layer, they have an independent set that's at least half of that layer. set that's at least half of that layer. And so here you just choose the layer that's largest and get a large independent set. But actually if you use kind of all of the big independent sets in each layer together, you get one that has the least half and has the most t minus one in it. And so given that, you can, it's not so necessary, just a little cleaner to get the following corollary that or theorem that will cover our small draft case. Case and it goes like this. So, corollary is that then actually the kramatic number is the most log base of 2 g of g over t plus 2 all times t. So you can kind of get a number which you can kind of get a number which has something like, you know, there's a t there, but you kind of have this weird log base two of v over t. So this will give you something nice for small groups. But even, you know, at t squared, I should point out this doesn't really do much, because then you get a log t here, and then you know, you'd get t log t. And we can already beat that with the cast Katomsky. But it'll cover the small graph, and the proof is just kind of obvious by taking. Obvious by taking the induction, namely by this theorem, for every s at least zero, there exists x1 up to xs. Luke? What does that say? The chromatic numbers at most what? So that says log 2. Is there a t there somewhere? Yeah, there's a t here. There's a times t here. T here, there's a times t here. Yeah, but on the line above it, there should be t times that, right? Yeah, I put it down here. So, right. I of G is at most t times this. Is that good? It kind of leaked onto the next lines. Yeah, that's something that's happening. Okay, so you have this T, and then yeah, you have this kind of this log factor. There exists X1, XS, disjoint sub. Subsets of BG. And what do we want such that? So what's the property? So we have a couple things that B of G minus all these Xi will have in the most, so you're going to lose half every time. So you're going to get half, half, half, right? You're going to get V of D over 2 of the. half, right? You're going to get v of d over 2 ds because each time we'll extract one and they'll have of course have the property that chi gxi is at most t minus one for every i and hence that chi the union the most s times t minus i Right? And now, what's the point? Where do you stop? Well, so this kind of is nice. We can extract these T minus one, you know, large sub-independent set, or rather, T minus one colorable sets. And now, where are we going to go from there? Well, yes, you just finish off by saying we should stop when you get below. So, namely, So, namely, that at this somewhat magic number. So, namely, if we stop at log 2 v of g over t, well, let's take the ceiling because that could be a fraction. And then what you would find would be, well, so if I put in that number and I raise it to 2 to that number, then I get to cancel, and what we'll find is. To cancel, and what we'll find is that v of g minus the x size number of vertices left must be at most t. Right? And so if it's at most t, then I can actually just color with t colors. So color with t colors, and we find that a nude set of t colors, right? And so we get chi of g is the most t from here plus what we got before. plus what we got before, which say is at most, you know, s times t plus one, or s sorry, s plus one times t. And since I round it up, let me add a two maybe. And you get the nice theorem, right? This corollary. So we've done that. So really just extracting ends up getting you the things. And I'll just mention then an obvious corollary. And I'll just mention then an obvious corollary of this is what happens for the small graphs. Right? And so, corollary, you know, if V of G is small, so at most O T o T of the C and has no K T minor, then then we get the thing I claim that pi of g is at most t times c log log t plus 2, which is all over t log log t. So we can do small terms. And then you can do a bit bigger, right? So you don't need polylog, you can figure out what you can put here, but you know, so you could be, but you can't go So, you could be, but you can't go too high, right? So, you really need to maybe, if you want sub-logarithmic results here, you can't really go into polynomial powers, just kind of long or weird ones with exponents. Okay, so if there aren't any questions about the small graphs, that's the easy stuff. I'm going to move on to the large graphs. And in the large graphs, let me back up and say two obvious one obvious point, one non-trivial, but we should assume point on large graphs. Before even breaking into the cases, for all graphs, I mean the small graphs being handled that way, we can do two things. That way, we can do two things. So, one, we may assume without loss of generality that g has minimum degree t log t to the beta. And this is just by you know, critic counting. Right, so by you know you could just delete small degree of vertices and that would be fine for color. Unfortunately, that's not enough for the case one that we're gonna do to build a minor, right? Because we're gonna need, in order to build a minor, it wouldn't be enough just to have lots of small dense subgraphs if it's not connected. They could just be those counterexamples. And so we need connectivity. So we need stronger than this. And that's the next point I'll mention. The next point I'll mention. So, if you haven't seen this before, you can say G is contraction critical if chi of h is less than chi of g for every proper minor h of g. H of G. So here's a nice idea that comes up in the history with Hadwiger is you should study not only critical graphs, vertex critical for coloring, but also contraction critical, wherein, strangely, if you contract any edge as well, which is not at all useful for coloring, but saying then that your coloring number goes down. And that's useful because of minus. In particular, why isn't this widely studied? Well, Well, Audrey's conjecture just says that if G is contraction critical, G is a clique. These are boring, right? They're just cliques. They're the only things that are of interest. And so, you know, if we could prove Adwigers, we could just kind of ignore this very nice. I mean, in that sense, it's very nice. This very natural. I mean, in that sense, it's very natural and strong. But since we can't prove Adams, what can we do? Well, we can still prove facts about contraction curve. And right, we can assume that our graph is contraction curved. We may assume without loss of generality for us that G is contraction. Right, because if we could take a minor color than If we could take a minor color, then this would be a smaller calculus. And so, what can we do? And that's in the context of all graphs, not just the large ones. But we could have assumed at the beginning this. And now there's a nice theorem for biology. Remote seven, that says that if g is contraction critical. Then you actually get large connectivity. That this is at least its chromatic number and something like 2 over 27. And here we don't really care what the constant is. With somewhat simpler proofs, you could do something like 1 over 80, but you actually know pretty good bounds of the conductivity. We can prove exactly chi, but we can do. But we can do that. Let me just mention again. This is the conic kappa will represent the conic minimum number where it's kept. The maximum number where it's kept. Okay, so we have high conductivity, which is even stronger than min degree, right? So in particular, and that would mean that we get to start with high quantum. I want to do. And that's going to be very useful. We may assume, without loss of generality, g is omega t log t to the beta. Because now, if the overall graph has large connectivity and we can get lots of dense subgraphs, then maybe we can actually hope to build. Actually, hope to build a KT minor somewhat more efficiently than you would just with the Kestach tons because we're going to have all these dense sungrounds. So that's going to be the plan and what I'll be talking about next. Okay, so back to case one. There's this many dense subcrafts. Dense vertex. And vertex disjoint. Subgraphs H1 up to DJ. Well, what can we do with these many subgraphs? And so we want to show that you can give them mark. So what we're going to do is we're going to re-index them. Re-index them. We're going to have an H0, which will be kind of a root or central hub, if you would. And then we're going to make an Hij. But I have to tell you what the Hij will be. So let me write on that board. So hold one cell. I'm going to make kind of pairs. Of pairs, what will the pairs be? Well, let me fix two numbers. So let's make an X and a Y. So let Y be the floor of Y. The floor of log t to the quarter and let x be t over y raised to the z. So here's my plan is I'm going to divide up, well really it's their plan, but we're going to divide up into h zero, and I'm going to make a i j, an h i j for every i j, i not equal to j in y. Y. So let me draw the picture here. So we'll have our, you know, our hub, which we'll talk about. Maybe I'll draw a hub. And then my plan is I'll have a, you know, an H, well, we don't really need an H11, but H12 up to H1Y, and then onward again. So we'll have H22 to H2Y, and all the way down to HYY. And all the way down to HYY. So we're gonna have kind of, for every pair in the set Y, we're gonna have a private, a private kind of subgraph. And our plan will be use that private subgraph to kind of build a complete minor on the appropriate size subset of the vertices. So this is to build our KT minor. Let me just Let me just move a little bit. So let me go here. So what you do is let me define two sets. So it doesn't really matter how you do this, but so let's call them xij xj. Ij Xjij be disjoint, all disjoint to be subsets of H0 and have the Yi Ij Yjij be disjoint Subsets of H engine. Here's this. So let me now kind of enlarge the scope of this. So what's really going on is inside of this H0, which is going to be rather large, right? Because it has t log t to the quarter. So it's in particular at least xy squared. We're going to find these different kinds of, you know, x1, 1, 2, x. 1, 2, x 2, 1, 2. So we're going to find different sets of vertices for all these pairs. And I'm going to do the same down here. We're going to find a y1y2y212. And now maybe you see the goal is we're going to build linkages from each pair. So those are supposed to go to one, two, I guess, to each pair. Each pair separately. So from the central hub, we're going to send Xi Ij to Yiij, Xi Ij to Yiij, Xjij to Yjij. For all Ij assignments. So we're going to link this central hub so that each Ij pair goes to each Ij subgraph. And now my plan is twofold. We're going to build the complete minors. The complete minors sitting on top of each bag, and then back here, we're also going to connect up all the existing. So let me write that out a little bit. A linkage connecting all the Xij to Yiij and the Xjij to Yjij. So you link them all and then plan for each, for every i not equal to For each, for every i not equal to j, make a complete minor in H Ij, connecting all of it together, the Y I I J and Y K I J do that, and then so we'll do that, and then and connect. And connect all xij over all the j's in the root node, right? So our root node will do all the connecting, the kind of all the other subgraphs will do all the work of the link monitors. Okay, so now we're going to say some words about how this was done if you haven't seen it before without getting into too much detail. The one thing I should mention is there's a theorem of Mater from the 70s. The 70s, which says that G has an average degree at least for D, and there exists a D-connected subgroup with P of G. So you know that. So you know that high average degree implies high minimum degree. 4D, you could always find one of minimum degree 2D. And Motter showed that actually if you had minimum degree 2D, you can find a deconnected subgraph. You have no control over how big or small that is, where it lives, the whole graph could just be, but you can find one. And in particular, this means, so for us, it means that we may assume without loss of generality that each That each HI is large connected, t log T to the b and this seems a lot more helpful for building up minors inside of things because you'll actually have high connectivity and there's no real cost there and that'll be actually fine for the case too because it'll just pass from small dense HI to small connected HI. So that's that. So that's that we can do. Now, what can we further do? Well, I should remind you of theorems of Bolabosch and Thomason, and this is in 96, which said that if G is 22K connected, then G is K linked. And what is k-linked? So if you haven't seen it, it just says that if I give you k vertices S1 up to SK and K vertices T1 up to TK, that I can find disjoint paths connecting SI and TI. So it's stronger than connectivity, right? Connectivity just says, you know, between a set of sizes A and C. You know, between a set of size A and size A, I can find vertex destruction paths here. I can actually get them to you from terminal to terminal as you wanted. And that was done, proven linear. So like Robertson and Seymour had shown K, kind of root log K using the minor theory, but this they improved it to linear. The best known results at the moment for this is 10K by Thomas and Mullen. But here we don't actually care about the constant. Actually, care about the constant. But we do care, it's linear. So we just need, we could use this one, for example. And so if you understand that point, it's obvious then that inside of H0, we could build kind of a linkage to connect up. It's also more obvious than that we could get that linkage in the first place. The only trouble is that one most of the complete graph thing and And more problematically is that there's a site technicality wherein my picture was false, right? The paths don't have to just go from the hub to each HIJ separately. They can just run around. Right, so what I mean is we have this nice H0, and we have this nice linkage to H12. At H12, and I kind of drew it like that. It doesn't do that, right? I mean, you have no control where this goes. So we can go through all the other H's and then eventually find their way. So they could be, you know, messing up. So that's a slight problem to overcome, but this can actually be overcome by using this Bolomosh-Thomas toolkit. So actually, if you go through and really understand And really understand their proof, you can make more out of this than the conductivity. So you can actually get the following ideas. So let me try to write it. It's slightly complicated. So, well, maybe I should tell you one other. Well, maybe I should tell you one other one. So, if you didn't know that, is that there is a theorem by Bolivasch and Thomason that does even more than Calik. So there exists a C greater than zero such that if the connectivity of G is at least Cs and And you kind of have disjoint subsets empty disjoint subsets aren't too large. Then there exists C1 up to CK disjoint. disjoint connected such that Si is a subset of C. What this means in picture is you don't even need linked if you actually linear connectivity suffices to if you give me sets of vertices so you say you know here's three and that's connected that actually I can find some graph that Some graph that links data and S2 and separately SK. So the K links would be just when there are pairs. Actually, more generally, you can kind of do connect up any different parts. So that would have handled the H0. But then I'm going to have to tell you the other theorem, which that finishes off the proof. So, the theorem by Doreen and Slong basically would tell you if the conductivity was at least something, some big constant times, the max of something like L and S square root log s. Then, actually, what you can do, then I can actually do Can actually do linkages and complete minors at the same time. So then, given, yes, S1 up to T L, S L, T1 up to T L, and R1 up to R S, we can get a linkage. P from S to T, S's to T's, and a Ks minor on R's, and both of those are disjoint. When picture terms, it's very strong, right? So you can really build these big So I can do the S's and the T's, and you tell me some R1 up to Rs. And so I can find a model of the Ks minor on them that does all the connecting and do that all disjoint. As long as you're bigger than L, and you can only get kind of the connectivity over the logger. You know, the connectivity over the log square root log. And so now maybe you see how this finishes. Let me move over. So I'll just use this picture for one moment and then we'll be done with case one. So I'll just finish off again with the picture. So let's go back to our picture. We've done our H0 and right we said we do these kind of X. We do these kind of x112s, x212s, etc. And now, you know, here's H12, and it had the Ys. And I built these nice languages. And again, they went around everywhere. So now do you see the plan is, okay, I want to apply their nice theorem to H12 to clean it up, right? Clean it up, right, to build the complete miner on all of these. So it'll link up the, you know, the kind of the set of size, these are of size x again. It'll link up those two x kind of vertices who might need to be minor. And I can do this obvious thing with the thing. I just also have to make sure I don't ruin the overall linkage. But you can do that, right? Because maybe other things come in and use this linkage. Come in and use this linkage. They may even kind of swiggle in and out other paths in my linkage. But then I can just say, take the first and last of the path, forget everything else, the first and last time you entered, and now I'll just make, kind of preserve the linkage inside using those L's in the theorem. And we can do that, right? Because, well, again, x times y is basically equal to t. So I'm going to get large enough. And what is... going to get large enough and what is xy squared though this is only actually t log t to the quarter right and so if I have you know 22 times that or 100 whatever constant you get from that theorem then I can do this because right I only need to find a 2x minor and 2x here is you know 2t log t to the quarter right So the quarter, right, over or sorry, t over log t is a square importantly. This is so this is where the quarter really comes from, is that you use these pairs, these y squared of them, and so inside each you can find a t over log t to the quarter and then build them back up. So you only need t log t to the quarter in general. That's the power of the many gives you. It lets you save this kind of log t to the quarter factor. Logs you to the quarter factor. So you do that inside all of the HIJs, preserve one at a time, say, go through, you make all the complete minors, and then you just go back to H0 and you do the same thing. So there you just need to find a linkage, you know, connecting up each pair of x's there, or sorry, all the x, sorry, all the x1s, all the x2s, etc. And we can do that as well basically with the Can do that as well basically with the variant of this. Actually, just this would be fine because we also want to then again preserve outside linkages if we want to. And so that's case one. We can build a minor with this computer. So that would be a good time to ask any questions about that. If you wanted to unmute yourself or if you want to type, if there aren't any questions, I will continue on with the next 20 or 30. The next 20 or 30 minutes. How to do the other half? Where does noise is naturally? And so basically, I already explained all that. I just need to show you this key lemma or theorem, right? I need to convince you, right? So there's going to be the H1 up to. There's going to be the h1 up to hm, our maximal set, just to remind you, where each hi is small. And here the density, you know, average degree would be at least omega t log t before. And you promised me we couldn't, we're in this case, so we can't find them all. Just a reminder. This reminds me that would mean that the union of the Hi's is small. We have O T log log T others. And then I want to argue that G minus it is sparse. That is T log T, so the beta generates and hence colour. And combined. And hence colour and combine those. So I have to argue to you why is it that those are sparse together. So to do this, we will... So basically, Noreen and Song had a theorem that kind of does this. So it does it with the 0.354. If you have 0.354 degeneracy, If you have 0.354 degeneracy, then you can get a t log t to the quarter small dense graph. And here we end up proving it is a better zero. So it goes like this. For every delta greater than zero, there exists a c greater than zero, such that for every d greater than zero, one of the following. Let g be a graph. There's a minor technical thing. Be a graph, there's a minor technical thing where you need so. Let me define the density of a graph. That'll just be a little easier if I do this. To be edges over vertices. So I've been saying average degree, you could use that. And this is just slightly easier. And you tell me that it has for kind of simple simplicity. For kind of simple, simplistic reasons, we need the density to be at least some large, not constant. I mean, not really that large, but depending on this delta. But what can we get? Let S be d over d of g. Then I claim we can get one of the following. This is the key theorem or lemon for this second bit. Then B contains. G contains at least one of the following. So, what's the idea? So, you either have a liner j with density at least d or the other outcome is. The other outcome is you get a subgraph that's kind of small index. So on subgraph H, the number of vertices will be at most S, that number, 1 plus delta, Cd, and its number, and its density will be at least s to the minus delta d. So let me talk about this theorem a little bit and then we'll talk about how you go about proving it. So what is the theorem really saying? It's saying, okay, so for every delta there exists a C. So delta is kind of a knob of how tight do you want to be. And what it says is, you tell me a big D, capital D, that you want a minor of. This is all this says, right? Off. This is all this says, right? Can a graph, can I get you a minor with density at least big t? So for us, for Hodwigers, it'd be if we could actually get density t root log t, right? So here you should think that in our application, then this will be, d will be the t root log d or h or something, enough so that it would apply a kt minor. Enough so that it would ply a KT minor. So either I can get you a really dense minor, and then that could get you a KT. This will get you KT as a minor. Or what do I get? I get a small subgraph. So here this would be applied with, you know, t root log T. C is just some constant. And what was S? Well, S, well, we know we have density T log T to the quarter. To the quarter, and this is like t root log t. Luke, that red is pretty hard to read. Oh, sorry. Okay. I'm trying to use red colour. I guess no colour is wrong. So all I'm saying here is you have, in the application, you'd have t root log t over t log t to the corner, which would be log t to the corner. That's what s means. That's what s means. And so here, you know, we'd have either our t root log t, and it imply a kt minor, or what would we get? We'd have t root log t to the d, some constant, and then we have a log t to the quarter. So you get, in particular, this would be small. Right? It's t like log to the t like log to the t to the three-quarters. I mean it's t poly log t, right? The number of vertices is small. But importantly, what's the density? The density is our t log t to the quarter. Well actually we started at beta, right? We started at beta, which is bigger than a quarter. And what do we lose? We lose something like, you know, this is log t to the quarter to a minus delta. It's that delta that makes it tight. Delta that makes it tight. So, what you end up with is: this basically just says, I can either get you a minor of any right density, or basically at the cost of s and an extra s to the delta, I can get up to this number of vertices. And density, you don't lose too much. You kind of lose a very small power of this ratio between where you start and where you want to end. So, you know, that's the thing, right? So, you know, that's the thing, right? Our ratio is, you know, log t, and so powers of that would just be tiny powers of log t. And so we won't lose much in the density. And our number of vertices kind of blew up to, you know, t log t or something, but that's still small. And we can apply the small subgraph. So it's from that you can get any questions about this theorem. This is really the theorem I want to talk about. That's important. And it's very general. important and it's very general it's not about oddliners it's not about kt minors really it's just you know there's no there's no assumptions or bounds it's just saying either I get kind of a minor you want or essentially a somewhat asymptotically best possible small dense subcraft so you have to give up a bit on the density you have to give up a bit on the size but other than that so basically they originally had some version of this but instead of s to the delta they had Instead of s to the delta, they had more like an s to the 0.2 or something. And so when you put in log t, you ended up with this extra 0.154. But here I was able to tweak it to get kind of as close as you want to in density without losing. And that's kind of the real trick to get the quarter. So you're not really going to make improvements on the quarter. So I'll just say that before I go into the proof, on the quarter by improving this theorem, like it would only improve the kind of sub-law. It would only improve the kind of sub-log terms, and it's unclear what's exactly the correct, but it won't affect the overall quarter in the exponent. To do that, we'd have to come up with a better argument in the first case. In that first case, Noreen and Song are conjecturing that actually, as long as I had many disjoint, you know, 100 t or t sub log t connected subgraphs, then I could actually build a K T minor. And we're just bad at building them. They have a T log T in the quarter. They have a t log t in the quarter. And if and this theorem would let you do that. If you could actually prove that kind of conjecture, this if instead you had the original density be you know 100 log t, it would give you lots of small dense subgraphs of the desired density with just a sublog factory. So that's kind of where the roadmap is made. Think about that and we'll go through briefly how to approve. So we don't actually prove that theorem. We prove a theorem on the way to that theorem. So I will state this theorem because it's a little strange, but it will essentially tell you the roadmap. So I'll give you a K and an L and an epsilon. Let G be a graph with kind of large enough densities that it's cool for epsilon. Let G contains at least one of the following. All right, then we'll do one. We can either get a subgraph H, this will be the small dense case. So with V of H say at most something like 6k cubed times D, and the number of edges will be rather. So epsilon squared, d squared. So what is this? This would be a subgraph, I should say, with d being density. So I have this density. You can think average degree. You can think E over G, it doesn't really matter. I want to either deliver you a subgraph, and you should think that K and L will be constants. They're large, big constants, like 1,000. You pick them based on that delta. And the same with epsilon. You set it to be, say, 1 over 0. You set it to be, say, 1 over 60 kicks per. And so, what's going to happen is I can give you basically a subgraph where the number of vertices is basically some constant times your original density, and where the number of edges is basically some constant, you know, epsilon squared fraction of your original kind of density. You put these zero, you know, you actually divide, but you end up with kind of a small subgraph like linear size where it has linear density. That would be great, but we can't just. Would be great, but we can't just do that. And so there's two other cases which you could make into one, but I'll explain that it's actually two. So you can either get an L plus one bounded minor with, and I'll say what bounded is in a second, don't make it obvious to some. Let's call it keygron with density. With density at least like L over 2, basically, times your original density minus, you know, sometimes. And you can do the same with the K downliner keep run with. with yeah d of g prime at least 8k over 8l and then times d and so again you lose a little let's go through this right so what am i trying to say well let's define uh let me just move down slightly See the terms there. So, what again, definition, what's a k about a minor? So, a k about a designer will just be a minor where every bag will As in most k vertices. So it's kind of saying you don't do too much contraction. So I want to keep, right, I want to end up with a small dense subgraph at the end. And so you can't contract too much. So kind of the plan is I'm going to iterate this, and I won't really go through that to imply that theorem. Because either originally I just find something small and dense as a subgraph. Find something smaller, dense as a subgraph, and then we're done. Or I can find a minor that's bounded in size that grows the density. And again, so I'll get to why there's an L at a K. I could state it kind of just without this, but we'll actually need two cases. So I'm just showing you that. But basically, you know, and you're giving up a bit. You know, you could maybe hope to get L times the original density if you're contracting to L vertices. Density if you're contracting L vertices. Here I'm only getting L over 2, and this is like negligible, but basically L over 2. Here I'm even doing worse, I'm getting K over 8 L. But if I choose K to be, you know, L squared, then I'm getting either L over 2 or L over 8. And if L is something gigantic, a million, then I, you know, at every step, I'm kind of doing some L bounded minor, but growing it by a factor of density of like L over eight or L over two. And so at every slide. L over 2. And so at every step we are increasing. And then what that means is, you know, we just do this amount in the second case, that looks like negative to me. Amount in the second case looks like negative to me, so maybe you can cover that. Oh, this one. L over 2. 1 minus 14. Oh, yeah, I mean, really, you should make this like. really you should make this like you shouldn't you should set epsilon a proof and like make let's make it 60k and then epsilon oh yeah yes yes did i put epsilon maybe i already write epsilon yeah this will be something you can choose it so this will just be like less than a half and it will be small but you can really choose these as kind of as small and large as you want for epsilons okay so you choose epsilon after you choose k now and you just make all of that kind of negligible and And so that's that's kind of so we're not really getting exactly as much as we could get, but we're getting pretty good. And then we just kind of iterate, and what happens? Eventually we find we have to eventually either get a minor that was dense, and then we don't care about the size, or these don't happen because we hit the limit of our density. We can't go any higher in density, otherwise we win. So we have to find this small. So we have to find this small dense subgraph where the density is not the original, but rather the density like when we stop. So the density when you stop may be that very close to that big D. And so you get kind of linear and big D, edges and big D. And that's a subgraph in a minor after many steps. And the subgraph in the minor at many steps, we then have to pull back. We have to say, okay, we get this big minor. Well, where did it live? Minor, well, where did it live? And this is what the bounded does. Or you pull back the subgraph to build and say, okay, blow them up. They grow by, you know, size L or K each time. You know, you do that. And so that will eventually give you a graph, though, that's not too big. So you kind of pay a price for unwinding the vertices. And you also kind of then pay a price in the density. The number of edges don't really drop when you blow up because we got rid of multiple. But the ratio. Multiple. But the ratio between, if this is kind of increasing, then you're going to have to pay a ratio of the density. And that's where all those numbers come from, is that interplay. That when you blow up your subgraph in your minor, you end up with kind of paying a price here in the vertices. So I won't really, again, go through that. You could read the paper, but let me just maybe say, how do you even? Let me just maybe say, how do you even prove this theorem in the time I have left? So I'll just say some words about it. Namely, that there are kind of a couple nice ideas. And then we'll be done with that. So actually, this proof goes by two cases as well. So that's why we actually have the K and the L. Even though they look kind of redundant, and they would just help, because then I can just tell you what the two cases would be. So either, case one, you'll either get kind of a dense unbalanced subgraph. So you'll get a bipartite subgraph, say AB, where the minimum Where the minimum degree, somehow every vertex in A has like at least something like the original D, but maybe you lose some k epsilons, but I'll get into. Neighbors in B. It's kind of dense, close to the original, and importantly, it's unbalanced. That means Importantly, it's unbalanced. That means that A will be at least L times the size of B. So you're going to get this kind of big, dense, unbalanced system. These have a fair number. So in particular, B would of course have lots of degrees the other way because it'd be much smaller. And then the plan in this case is just to get either the small thing or the L plus 1 down. small thing or the L plus one down to mine. And how we do this is we'll build essentially what I called an L claw matching. And all that means is what we're going to find is we're going to use the B's as centers of stars. So we're going to basically put each to have L E's. And not all of them, but I And not all of them, but some. We're going to build kind of this star forest that we'll use to contract. And we actually don't want to do it just on this subgraph. We'll restrict to some special subgraph. And then we'll contract it. And each of these. Now, the question is: is this good enough? So there's two concepts maybe I want to say. So maybe I'll keep that picture up so you can see it. Keep that picture up so you can see it that show up in both this case and the other case. I mean, the other cases there doesn't exist such a thing, and then we do something different. So two concepts that are important are the concept of a mate, that u and v would be mates if they have something like at least epsilon d common neighbors. And then we could talk about something like clean. We say F is clean if somehow when you contract it, you don't end up losing too much, would be the definition. So we'd say at most C times. C times D times the vertices. So you can kind of be. You don't want to lose, you can lose some, and based on the number of kind of vertices, you end up contracting, but that you don't lose too much. These are kind of the two big ones, and the other ones is we want to use small vertices. Something like at most k squared d degree. Degree. So here we can assume basically all of A is small because we could just drop their degree down. But the trouble is kind of you kind of want to avoid mates, right? So if two of these had lots of common neighbors, you want to make sure that they don't end up in the same star. And we can actually do this. I mean, so essentially, if you wanted this just to be made free, Wanted this just to be made free, you can kind of do this if you understand matching theory. Because if you have a at least size L B, you can just kind of take a maximum L matching, ones where have, you know, and most L neighbors, and that will actually lead you to a subgraph. You'll get some stuff over here, which maybe just ends up in small stars, but you'll definitely, because of the unbalance, get a subset that have to be in big stars, stars of size L. Stars of size L. And then you say, okay, can, well, you know, would it be mate-free when I apply like Koenig's theorem to build this alternating path? We'll just avoid the mates. And the point is, being point, so I should maybe have said if a small vertex has at least epsilon d means, then H exists are small dense subgraphs. This is the main point. Why can I avoid mates? It's because if some vertex had lots of mates, well then if you look at the neighborhood of that vertex, they have lots of common neighbors, they have lots of, it becomes dense. You can find a small dense subgraph. So kind of these are really the things. Of these are really the things: the three cases. Like, am I, you know, heavily mated? You know, is there somebody with lots of mates? Then I can just get small. If I can assume that naught, then I can do kind of the two cases I'm going to mention, one being this bipartite case, and I can just, as I build this, I kind of avoid mates. The trouble may be that I avoid mates, but I don't, I still end up with lots of kind of extra edges between the stars. Between the stars, not maybe because of common neighbors, but by four cycles. And Sergei and Ziggy have a very nice argument where you then try to switch these edges. So I won't go into that, but basically, I realized you could take the bipartite case that there is and apply some switching argument, matching theory, and get this. So maybe let me then just move over and do the last bit. Again, if I had more time, we could get into this, but you could squeeze the paper out of the archive. So that's kind of one, and the other one's very similar, but it's like, okay, how does this bipartite come in? What do you do in general? So in my last five minutes, I'll just try to talk about the other case, or case two. No such bipartite. And it's kind of actually what should you do in general. So what happened with So what happened with Sergei Etzizia is they kind of had a version where you did two minors, two bounded minors and three bounded minors. And the three kind of look like this bipartite case, and the two kind of look like what I'm about to say. But this kind of does that much more generally, is with Ks and L's. And what you, for the K case, here's what we're going to do. So we're going to actually define something called the K shrubbery. And they have this with twos and threes, but we'll just say it in. With twos and threes, but we'll just say it in general. And what this will be is a forest F where every component, let's call this K of F, the number of vertices, is at least K over, sorry, it's called K, let's call them T, is between K and K over 2. So here's a really nice idea. Two. So here's a really nice idea. Is okay. How do you, you know, you want to build a k-bounded minor, right, that does well. Well, you should use a forest where the vertices of, you know, the components of size and most k, that's what it would mean. But crucially, what we're going to do is we want to make sure we actually get progress. We want to make sure that we have, you know, kind of lost a lot of vertices, so well not losing too many edges. And if we can do that, then we actually will be done. Then we actually will be done. And how do we do that? I'm only actually going to contract things in this case that have size at least k over 2. So I'm going to build a large shrubbery in which all the components will be large. And we're going to do that to keep it clean. So let me maybe move over and draw you kind of the final picture of how this is. So plan, I'll just say what the plan is build a large, that's going to be like maximal K shrubbery F which is clean. Is clean from the appropriate choice of C and D, and no component of F has a pair of mates. Which is what we did in the in the, so that's kind of what we do again in the clock case, in the bipartite one. We want to build it first to be mate, then we go in and we clean it and we make it clean. Here we actually will keep this all at the same time. We're gonna make sure whenever we enlarge F, we're gonna make sure now. Large F, we're going to make sure never to violate this and to always keep it clean and just avoid growing it if we can't actually keep these properties. So that was an important thing. We said, don't come up with a separate cleaning stamp. I tried that. That just doesn't work. You just have to do this. And so what's the plan? So we have our large F. And they're not stars, though, right? I mean, they could be. Stars, though, right? I mean, they could be just any components, and then we have the rest. And so if this is small, we win. We get the g prime. Basically, if this is really small, then we kept everything clean. If we could get most of the vertices, then we just get, that's our minor. That's what we choose. We just contract. We want. We choose. We just contract. We won. So somehow we have to, we can't somehow make further progress when we get to this point. We have to say, somehow there's a lot of vertices that we can't do anything with. And what are the cases for that? So let me just move over slightly to keep this one, but let's keep this picture up and tell you the kind of the three important things that we can take this. So if we choose some vertex B that's not in our shrubbery and we want That's not in our shrubbery, and we want to add it. What could we do? So, case one is V has many neighbors in V of G minus N. Then what do you do? In that case, you can just build a star. You can build a K star, a K over 2 star, and you can choose iteratively in a way that will keep it meat-free and that will keep it clean. And that will keep it clean. Because basically, as you add to it, you just say, okay, void mates of anybody I've chosen. And then you kind of make sure, oh, okay, don't do anyone who won't make you clean. There aren't too many of those. You get a small dense subgraph. So there, you just find it in that. So case two will be that B has a neighbor in many components of F. Of f with vertices less than the case two is, well, if I can get, look at all the components with at most k minus one, then look at one of these components. If I have a neighbor, I'll just add v to it, and that will keep me a shrubbery, a k shrubbery, right? I don't violate the condition if I go to small things. And the only thing, though, is I have to make sure. And the only thing though is I have to make sure I stay mate-free and clean. But again, I avoid any of them that have mates, and I avoid any that make me unclean, and then we win. And then the last case here would be, what if I have many neighbors, you know, equal to me? And then the last word there is centroid. So if you know what a centroid is, every tree has at most one or two centroids, which split up the tree into kind of peripheral pieces. Of peripheral pieces, small pieces. And here's the key: can I go to a non-centroid? So, for example, if this had size k, this would be probably the centroid. If I went to some other vertex, some non-centroid, then I can actually, I could do this if I do it in lots of different things. Basically, like leaves, I'm going to pick off like a leaf, a peripheral piece from every one of these. From every one of these, and to build a big shrubbery, build a big piece for B kind of at the center, keeping it clean, keeping it meat-free. And that really works because these peripheral pieces, that's exactly what a centroid does, have the property that when I delete them, I maintain at least k over 2 in size. And so it keeps my, so I'm kind of like, I either break up the large ones, and then we win that way. Or there's one last case, so to non-centroids would be. Would be you go to lots of centroids. What if you get stuck? What if you have this large set and they don't go there and they don't go to small things and they only go to the centroids, right? These, like imagine they're stars. What if they only go to these centers of all these big things? Well, here's the point. There's at most two per tree, and the trees were large, right? They had k over two, so there's at most four over k centroids. There's a There's a small fraction of centroids, and this is where the L comes in. I'm happy to stop when this gets down to size like 1 over L, like 1 over square root K. And so this, like, so as long as this ends up being L times that, I'll get a dense, right, unbalanced bipartite subgroup from my extras. And so then that's what we end up doing. We kind of do all these nice cases just easily works. And the centroid idea is really. Easily works. And the centroid idea is really nice and great. You've been around computer science since the 80s. And so we just kind of really use that to exploit building this nice shopper. Okay, so I think we have to end now. I don't know if there's time for questions. Maybe I'll turn it back over to Paul. Hi, thank you. Thank you very much. So can we clap? I mean, please unmute yourselves and clap, I guess. Yeah, so any questions? I mean, again, you can always email me or read the paper. Sorry, I muted myself. Yes, any questions? That's what I tried to say. Anybody have any questions? Can you say a few words? Why can't you get rid of this K and L? So why having one? I think one, I mean, so you can, you could, I could have written the statement that way, right? I could just choose k to be l squared, and I could have just written it with l. I just kind of wanted to prep you for, I couldn't really figure out how to get rid of these two cases, the two cases in the proof, though. So I really tried to do this thing first, and I kept getting stuck that I didn't know if you have them be the same size, then it's not really unbalanced. And that's what I was like trying. Not really unbalanced, and that's what I was like trying to do. And then I said to myself, but if I just care about improving, you know, the density by some amount, then I can make two parameters, k and l, and I'm happy if I would do l, and I'm happy if I do k over l. And the thing was, I'd actually already realized from their proof and things that I could do this by part, unbalanced by apartheid case. So I already had that in my arsenal. Like I could only find that. And that's exactly what kind of comes up here. You know, so somehow. you know so somehow there what you do is you end up you end up building the this claw matching on top of the centroids themselves right and and kind of doing it separately and cleaning them so i did you know i don't really see how to kind of combine the two cases kind of into one this is really the main case this is the thing you should try to do build a nice case shrubbery but you just kind of have to decide oh i haven't gone as far as i wanted okay i will Not as far as I wanted, okay. I will, I will quit then, and I'll use this value. So maybe that it's you know, some you don't need it in the statement, just just prepping you to, I don't know how to figure out the two cases. And if you care about those sub-log terms, that's where you get like something like log log to the two-thirds instead of square root. If I could get rid of it, if I only had one parameter, I would get a somewhat better number in that. But if you don't really care about those sub-log factors, sure. All right, thank you. All right, thank you. Any other questions? All right, well, thank you again. Thanks, everyone. Remembers, I guess Paul will announce that it will be a different link, right? Yeah, yeah. We have to leave this meeting now and click on to the next meeting. Steve, don't hang around and talk. Something else is going to happen here. You have to leave. Okay. I'll see you all later. Well, I'll see you all later and uh thanks. One day we'll meet. One day, one day. Uh, how do I quit?