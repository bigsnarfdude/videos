Zoom? Yes, no, maybe? Yes. Okay, cool. Well, sorry for the technical issues. And Olivia, thank you so much for that lovely introduction to phylodynamics, because that will be quite a helpful segue into this. So very good timing. All right. So let's see if I can actually advance slides. All right. So as Olivia discussed, So, as Olivia discussed, the basic idea of phylodynamics is to start with some epidemic dynamics in a population. On a realized scale, this comes out as transmission through a network. So you have transmission amongst individuals. And amongst these individuals, I know you can't really see it on this slide, but we have genome sequences sampled from the pathogens in those hosts and the sampling dates that those sequences were collected. Together, this can create a sequence alignment. Together, this can create a sequence alignment and a time-calibrated phylogenetic tree. And then the idea of phylodynamics is to close the circle and take the phylogenetic tree and do inference about the underlying disease dynamics in the system. Today, however, I want to challenge us to not think about this as phylodynamics, but as phylo mechanics. So, if we think about instead of having dynamics in some epidemic dynamics in this. Some epidemic dynamics in the system, if we think about some epidemiological process happening in the system. So, an SIR model or an SEIR model, like Olivia brought up. So, we have some epidemic model. Now, this is often implicitly assumed. So today we're going to distinguish between cases where it's implicitly assumed versus explicitly assumed. All right, so can we infer the Can we infer the epidemiological mechanism from a phylogenetic tree? To answer this question, I'm going to start by developing a general phylodynamic model, which will allow us to go across many different epidemiological mechanisms. As an outsider, recent outsider of this group, one of the main reasons I wanted to do this was to understand the assumptions of existing models because there's a lot of them. And then it will also And then it will also let us study the whole class of phylodynamic models mathematically and understand the mathematical properties of those models. And then it will enable us to fit specific compartmental models to make estimation, epidemiological inference. All right, so starting with some implicit mechanism here, we have a simple SIR model with some sampling. So I distinguish between unsampled infectious individuals and infectious. Infectious individuals and infectious individuals, where we have sampled their viral sequences. When transmission events occur, this corresponds to a split or a speciation event in the tree. And when a recovery event occurs, this corresponds to a death or an extinction event in the tree. When I have a sampling event, that nicely corresponds to sampling in my tree. All right, so now I can use those three different types of events. Three different types of events to create a phylogeny and formulate a likelihood of observing some phylogeny given an epidemiological process. So if this is well known to you, feel free to fall asleep. There's nothing particularly novel about what I'm going to present next, but I find it useful to help orient myself about the types of assumptions that are being made. So I'm going to formulate this livelihood in six steps. The first of them In six steps. The first of them is trivially to specify the model. So there's several different things we have to specify. We have to specify where the epidemic began, the time of origin. We have to specify three different types of rates, the rate at which birth events occur through time, the rate at which extinction events occur, and the rate at which we sample. Now, I want to point out that here we're going to use lambda, mu, and psi as arbitrary rates through time. So we're going to let them take on any So, we're going to let them take on any shape possible. This is the one tiny little bit of novelty here, and it doesn't really take any effort, but we're just going to assume that they're any random functions of time. Arbitrary, sorry, arbitrary functions of time. Then there's some sampling parameters, sampling at a particular point in time, sampling and removing lineages. We can go into those assumptions more. There's extinction events. There's extinction events and there's conditioning. And I'll come back to what this conditioning means. All right, so the next thing we need to do is we want to calculate the probability of seeing everything inside of this blue box. So this is this GE of tau, which is the probability a lineage E gives rise to the observed phylogeny between times tau and the present day. So it's the probability of seeing exactly what's inside this box. Exactly what's inside this box. To calculate how this likely, this probability changes, we just ask what happens if I make this box just a little bit bigger. And so if we make this box just a little bit bigger, there's two things that can happen. Either nothing can happen in between the small box and the big box, in which case we have this term, or we could have had a speciation event between those. And if there was a speciation event, then one of the lineages that was born has to give rise. That was born has to give rise to the observed tree, and the other lineage has to go extinct. So that's good, but it leaves us with this E of tau term. So we now have to calculate what E of tau is, which is the probability that a lineage that was born at some time tau never is observed between tau and the present day. So it's the probability of this red branch, of not observing that red branch. So just like we did with So, just like we did with the blue box, the way we calculate the probability of seeing this red line is exactly the same way. We say, what happens if I move up this red line just a little bit? And there's two different things we can do. There can either be nothing that happens along that branch during that small amount of time, or there could be a speciation event. If there was a speciation event, then both things that were born have to go extinct. So I have an epsilon squared or sorry. Term or sorry, E squared term. And then finally, if you had an extinction event in that little time interval, then it was never going to be observed because it went extinct. Finally, we need to obtain the likelihood, the likelihood of our tree. Well, now this is actually very easy because we calculated the probability of seeing everything inside of the blue box. So well, we just make that blue box bigger and bigger and bigger until it contains the whole tree, and that's the likelihood. The whole tree, and that's the likelihood of our tree. All right, so I lied to you, that wasn't quite done. We have two other little steps here. Right now, this likelihood has kind of an annoying form. So it has one term, which is the probability of seeing all the birth events. One term, this is the probability of seeing all the sampling events in the tree. And then there's this really unfortunate iteration over all the edges in the tree. This is a little annoying because it's hard to iterate over. Annoying because it's hard to iterate over that edges. Luckily, we can take advantage of the fact that this GE of tau equation is a linear differential equation to reorder things so that we end up with three different sets of terms. One is the probability of seeing a lineage that started at the top, then the probability of seeing every lineage that arose from a birth, and the probability of not seeing anything after each one was sampled. Sampled. So now it's just a little bit more convenient. And we have one more term to put in there, which is the conditioning term, which is simply saying that you're not going to study a tree that doesn't exist. So there's different types of conditioning that we can put on here, but the trivial one is if all of my lineages go extinct, I'm not going to study that tree. So this gives us our likelihood. All right. So this is how most of these. This is how most of these models are created, so there's nothing particularly novel about this, but it can help us understand the assumptions and the connections between existing phylodynamic models. So from a historical perspective, we can think about phylodynamic models kind of like this. So there's three different types. There's macroevolutionary models where all the lineages are sampled at one point in time. There are epidemiological models where we have sampling through time since viruses evolve on the same. Since viruses evolve on the same time scale that they're sampled, we actually have to account for that sampling. And then there's these multi-type models where you can have transitions between two or more types where speciation and extinction happens at different rates in those different types. So lots of different models going on here. What are the actual assumptions of these models? Well, we reorganize this so that on the top, you have those epidemiological models. On the bottom here, you have the macro. On the bottom here, you have the macroevolutionary models, and now we're characterizing them by four different types of assumptions. You have the assumptions about the rates. So a lot of models assume that rates are constant over time or piecewise constant functions. So here's a constant, piecewise constant. Then there's fun things like a stochastic SIR model. There's assumptions about sampling. So do you keep lineages around after you sample? Lineages around after you sampled them, or do you assume that they recover at exactly the same time that you sample? One of my favorite, which is mass extinction events. So we can incorporate mass extinction events. And then there's lots of different types of conditioning, like conditioning on observing exactly a certain number of lineages or more than this number, so forth. All right, so that's the assumptions of existing models. But what this But what this lets us do is it also lets us study that whole set of models as one mathematical object and understand the properties of all those models at the same time. So one of the things that we wanted to study about these was whether or not we could identify birth rates and death rates or speciation and extinction rates from one another. We might not expect that we can pull these apart because of this recent result. Because of this recent result by Stillian Luca and Matt Pinnell on macroevolutionary trees, where they found that you cannot individually identify speciation and extinction rates in trees where everything is sampled at the same time. Now, this isn't particularly surprising in retrospect because the amount of information included in this tree is captured by this orange curve here, which is the deterministic number of lineages through time. Of lineages through time. So the solid orange is the stochastic realization of the number of lineages through time, but as the amount of data gets bigger and bigger and bigger, this will approach this deterministic number of lineages through time, which is what you're trying to fit. This is one curve, so that phylogeny can be summarized in one deterministic curve, but we're trying to infer two different parameters, a birth rate and extinction rate, but we only have one piece of information. And sure enough, we can rewrite this. And sure enough, we can rewrite this likelihood in terms of only a single, single time-varying rate. And so you don't have enough information in the tree to individually characterize speciation and extinction. Now, the question was, does this extend to an epidemiological case where you're sampling through time? Now, you might not expect it to, because if you're sampling through time, you're collecting a lot more information. You know the tree had to exist at a lot of different places. The tree had to exist at a lot of different points in time. But you're also trying to ask a lot more of the model. You're trying to ask: at what rate am I sampling through time? So now we have a likelihood that depends on three parameters. Do we have three independent pieces of information to pool speciation, extinction, and sampling apart? And sure enough, we don't. So yes, indeed, we have more than just a single curve here. We have Than just a single curve here. We have the number of lineages through time, and we also have the number of sampled lineages through time. So we have two pieces of information, but we're trying to figure out three different things. And so once again, we're back in the same situation where we just don't have enough information to pull all three of those apart. All right, so what does this mean for the practicality? Well, it means that there's a whole set of models. Whole set of models that we call congruent models that all fill into this bubble that are equally likely. So, a whole infinite combination of birth rates, sampling rates, and death rates that will give us the same likelihood of producing a tree. And so, one of the consequences of this is if we constrain the models that we're looking at, for example, by assuming that you have piecewise constant rates through time, what you're essentially doing is you're drawing one of these lines. Is you're drawing one of these lines, and if that line intersects this congruence class, your model will fit that congruent model, not the true one. If the line does not intersect the congruence class, you're going to find the model that is closest to the congruence class, not the one that's closest to the truth. So, this leads to adding constraints can lead to misleading answers. So, as a result, if you have a true Result: If you have a true model that's given by these black curves, so a true birth rate through time, a true death rate through time, and a true sampling rate through time, we can sample alternative models that are equally likely. So all of the colored models are equally likely, give the same probability of observing our tree as the black one, the true one, but they give us very different epidemiological inference. So if we had the black one, our R0 or R. One our R0 or Re is above one the whole time, but we can have colored models that fall everywhere in the spectrum between being always higher than the truth to being less than one. So we get a huge range of possible outcomes that are equally likely to come out of our inference. All right, so just to add some more texture here, we wanted to show that this identifiability problem occurs even if you have really, really Occurs even if you have really, really, really huge trees. So we can't fit really, really huge trees in a Bayesian way, as Olivier demonstrated. So we just fit them using a likelihood model. So we have 175,000 tips. The true model is shown in blue. The model that we successfully fit with our maximum likelihood is shown in the black dashed line. And we get very different answers. The plot down here is just this Linus 2 time plot. This linear time plot, and all this is saying is that the true and the fit model explain the phylogeny equally well. So it's not like we're not fitting the phylogeny well, we're just getting the wrong answer. So it's not because of limited data. It's not because of not very strict priors. So we used a much smaller data set and put fairly strict priors on our parameters. And once again, we don't recover the true model. Don't recover the true model. It occurs in the real world. So we used 563 HIV sequences from Alberta and used BEAS to fit the phylodynamic model of RE through time. And then we used our congruence class to sample different traject alternative trajectories for RE through time that would also fit within the That would also fit within the priors. And we get a whole range of different outcomes. So, if the black is the true one, we get a whole bunch of different lines that have very different RE dynamics through time. So, this applies to real world situations. Congruent scenarios undermine our understanding of epidemics. All right. So, if I were to leave the talk here, this would be incredibly depressing. So, I'm not going to leave it here. Going to leave it here. So, what do I suggest we do in the future? Well, I suggest that we go from this implicit idea about linking epidemic models and phylodynamic models to making it more explicit. So, one of the points that I hope I've made is that this identifiability issue is not an issue of data limitation. So, even if I had infinite amount of data, there's still going to be have this inference problem. So, we have to. Problem. So we have to add something other than data. So what I propose that we add is that we add mechanism. So this identifiability issue arises when you let yourself sample any arbitrary function through time. But we know that epidemics don't follow any arbitrary function through time. They have to follow something that is reasonably created by disease transmission. So what if we constrain ourselves so that we start with ourselves so that we start with an explicit epidemiological mechanism. We simulate an outbreak or sample an outbreak. Then we guess some parameters that fit the same underlying epidemiological model. Then we turn this epidemiological dynamics into a diversification model or a phylodynamic model and then do estimation. Do estimation. So, the difference here is you're not trying to infer the transmission rates through time, you're trying to infer the transmission parameters. So, we're transitioning between inferring arbitrary rates through time to trying to fit a specific epidemiological model. Luckily, I have some very, very hot off-the-press results from Theobashiazzi about whether or not this actually works. So, he simulated He simulated different epidemics that ranged in different transmission rates from zero to about 0.5, and then tried to fit them, assuming that the epidemic was created using an SIR model. And we see somewhat okay correspondence between the estimated transmission rate and the true transmission rate. There are some issues here that you actually end up. Here, that you actually end up fitting the SIR model that best explains the data, not the true model. So, for example, I like this one over here, where the solid line is the true SIR model that generated the data. But what you end up fitting, I know the lines kind of all blur here, but the one that you end up fitting is the SIR model that has the smallest distance between the simulated data and the epidemic. Now, I Now, I know that this is all on really, really small trees because, as Olivier pointed out, fitting bigger trees takes a lot of time and we aren't there yet. And so I'm guessing that as I make trees bigger and bigger, that this will become less and less of an issue. But who knows? So hold on to that question. So, of course, there's some limitations here. We've only fit it with an SIR model. An SIR model. In order to make this realistic, we actually have to fit realistic epidemiological models. So we can't just stay within this SIR bubble. We have to go to much more complex models if we want those mechanisms to actually reflect the dynamics that are happening in the real world. So this means that we have to fit models, for example, like this one from Day at All 2020 for COVID, which we saw earlier in this workshop. And this means Workshop and this means fitting multi-type phylodynamic models. So, in order to make a robust phylomechanic framework, we're going to have to go into a much more complex epidemiological space. All right, well, I was super nervous, so I went through way too fast. But in general, we developed the six-step model for deriving the phylogenetic. The phylogenetic likelihood. This isn't particularly novel, but hopefully it helps us understand the assumptions and the connections between existing models so people that are trying to apply these methods can use the appropriate ones. It helps us understand this whole class of models and understand that from this whole class of models, you can't directly infer birth rates and death rates or transmission and recovery rates. Finally, it helps us go the next step and go from implicit. The next step and go from implicitly fitting compartmental models to explicitly fitting compartmental models, and hopefully toward resolving this issue of identifiability. So, thank you. Thank you, Eileen. So, we've got, because you are so very good. It's your extremely good stewardship of time. So, do we have any questions from anyone in the room? Do we have any questions from anyone in the room or anyone on the Zoom session? We have a bit of time for discussion. Well, maybe I can ask a question. So if you could go back to the slide that showed the sort of schematic, yeah, this one. Yeah. So I was, if I understand the workflow correctly, that's implied by this, right? So you've got a stochastic. You've got a stochastic compartmental model that produces stochastic trajectory. So, any given realization of it has a trajectory. What's the relationship then between that stochastic trajectory and the deterministic dynamics? Oh, so those are just two alternatives. Yeah, so you're trying to. You're trying to fit individuals. Oh, I see, there's an inference step there. And then, and then the diversification model is the model of the actual tree, right? So my question is, conditional. So it seems like the tree that you generate is independent of the stochasticity in the epidemic, conditional on the deterministic dynamics that are fit. So, when we simulate the stochastic epidemic, we simultaneously fit or simulate a tree that corresponds exactly to those that epidemic. And then we try to fit a deterministic model. So, this is a cool test of identifiability because we're not fitting the exact model. If we were fitting the exact model, then we would know. Exact model, then we would know then that our constrained model would intersect the congruence class. But by not exactly fitting the stochastic model, but instead fitting a deterministic one, we're only guaranteed to get close, not to get exact, to exactly hit the congruence class. So it lets us test like how far away can I get from the true model before I no longer can identify the parameters. Right, right. But I guess I'm just wondering about the conditional. Just wondering about the conditional dependence relationships, conditional independence relationships amongst these different things. You've got a stochastic epidemic model, you've got a stochastic tree, and then you've got this deterministic model. So the deterministic model is completely independent. I'm just fitting that. Right. But the likelihood of the tree that you generate is computed using the deterministic model trajectory. So conditional on the deterministic dynamical model, conditional on that. Model conditional on that, the stochasticity in the epidemic in the top figure there, the stochastic process is independent of the tree structure. No, I think I'll have to change. Okay, okay, well, yeah, no, it's a complicated question, so sorry. Yeah, are there any other, we'll talk more. We have plenty of time. Sorry. Other questions? There's the true deterministic dynamics, but what you're showing here is the inferred deterministic dynamics. And as you pointed out, if by chance there happened to be an infection early on that spread a little bit more early on, then that's going to lead to a misleading deterministic trajectory. Exactly. So there's a lot of simulation. One that corresponds to exactly the same parameters I put into the stochastic one. So if I had the same parameter. So if I had the same parameters I used in the stochastic one, but then have the deterministic trajectory. Yes, because there's the same parameters. So you could have the same numerical parameters that correspond between the two. That's a projection, right? And like I showed, that doesn't necessarily, this isn't necessarily a reasonable one. So sometimes the deterministic one is not actually the one that. Actually, the one that reduces the distance between the stochastics. It looked like it grew faster just because it started a little early by chance. Yeah. So there's going to be some fun things to do where it's like you fit the parameters and then you try to say, okay, let me project into the future using those parameters. How far off am I? So maybe if I fit the epidemic parameters and I get a really, really bad fit because the tree just happens. Really bad fit because the tree just happened to be really, really small, that will correspond to a large amount of error in prediction. And so I think predicting into the future is actually going to be a lot of my measure of how good my fit is. But that kind of stochastic error, you're going to get no matter how big your tree, because it's early on events, for example. Yeah. And there's always going to be statistical error, right? So, but so why not use the, if you, if you like this project? The if you, if you like this projection, yeah, where you just keep the parameters constant and you somehow turn off the noise, yeah, then why not use that deterministic trajectory to compute the probability of your of your tree? Sorry, I said that one more. So you so you there's this projection that you like, which is to keep the parameters constant, turn off the noise. Yeah, that gives you a deterministic trajectory. With the deterministic trajectory, you can compute the likelihood of your tree, no matter where you get your tree from. Why not use that instead of the estimator? Why not use that instead of the estimated one? Because I don't know what that is in the real world, right? If I had an actual data set, I wouldn't know what parameters I used to simulate it. But you could do it for any set of parameters and then choose the ones that give you the highest likelihood. Yeah, I think, I mean, there's lots of things that could be compared, like the one that best fits it, the one that best fits the case data, the one, you know, there's a lot of cool comparisons you could do. Exactly. Sorry. David? Sorry. David, go ahead. Oh, yeah. Aline, that was a great talk. I love both sort of the generalized first-death formulization and the work on identifiability. But in terms of the identifiability stuff, I have to admit that I've always had a bit of a hard time wrapping ahead around this idea of these congruence classes. But I think one of your slides maybe gave me a new insight on how I should think about those congruence classes. Think about those congruence classes, but I just want to make sure that my reasoning is correct. Can we say, or is one way we can think about these congruence classes that all models, regardless of the exact trajectory of the birth rates and death rates through time, that give the same sort of expected lineage through time plot is in the same congruence class. Exactly, exactly. Okay, that actually is really too. Yeah, no, it's one of these things, it's kind of weird to get to it, but once you're. It's kind of weird to get to it, but once you're there, it's like, oh, yeah, I really do only have one piece of information and I'm trying to infer two. So anything that creates the same, any combination of two things that creates the same logistic time plot gives me the same likelihood. Yeah, I like the way that Matt put it in the original, was that a science or nature paper? I forget, but he said, you know, you only have one line. Why do you think you can get two independent lines out of one? Exactly. I always thought that was pretty funny. Funny