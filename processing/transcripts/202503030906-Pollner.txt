To be able to kick off this amazing workshop. I'm going to start by explaining what I mean by this title and the part about prophets and philosophers for those of you who haven't seen that before. And then I'm going to tell you about two new results in this area. So I'm going to explain this profit versus philosopher distinction via this representative problem of online stochastic bipartisan matching. So in this problem, you're trying to build some maps. In this problem, you're trying to build some matching in this weighted bipartite graph, where one side consists of offline nodes that are fully known up front, one side consists of online nodes that only show up with some arrival probability. So you know all these edge weights in advance, you know all these arrival probabilities in advance, and when, you know, if, if an online node shows up, you can make some decision about how to match it, and you want to build a large matching. You'll also know the arrival order. You'll also know the arrival order. So I'm denoting these online nodes by some letter little t, which goes from one up to capital T. And as an example, in this case, the first online node arrives with probability one, so he's guaranteed to show up. We have to decide how to match him. So let's say we match along this top edge, we get reward one. Maybe on this sample path, the second offline note doesn't show up. She was only going to come with probabilities of 0.2. So there's no decision. Weight two. So there's no decision for us to make. And maybe this final node does show up, and we can pick either edge to match. So in this case, we've got a matching of weight 6. All right. So if you think about this for a second, it's not hard to observe that there's some dynamic program that you can write to tell you the optimal decision to take at each step in expectations. So the exact form isn't so important, but this is just some basic. But this is just some basically like some value-to-go function. For each possible state of your system, which is like how much time has elapsed, what S here denotes what subset of offline nodes are available, I can solve some dynamic program to compute that value to go from the ground up. So in particular, if this online node T doesn't arrive, I'm left with the same set of offline nodes S that's available, and the time has moved out by one. If this online node T does arrive, so this happens. Online node t does arrive, so this happens with probability pt, I can use this dynamic program to compute the best possible matching decision. And what you might not like about this dynamic program is when I've written it in this way, it requires exponential time because there's exponentially many states. I'm keeping track of every possible subset of offline modes that I could apply to. So the main questions of this talk, which I'm gonna tell you about today, is. I'm going to tell you about today is: you know, you might ask, what is the computational complexity of this optimal online algorithm? And in particular, if you want to, you know, have some algorithm that is efficient in polynomial time, how well can you approximate this object? So I'll contrast this quickly to the more classical perspective on this problem, which is through something that's usually called profit inequalities. And these are sort of algorithms that compare to the performance of the optimum offline. Performance of the optimum offline. Optimum offline algorithm works by seeing all of the arrivals in the graph at once on the online side, still from the same distribution, and then computing the maximum weight matching in that graph. And basically, a number of half-competitive algorithms are known for that problem that I introduced on the first slide. All this means is that an expectation, you'll get half of the expectation of this profit. And of course, it's not a coincidence. This profit. And of course, it's not a coincidence that there are three different algorithms that get one half. It's actually like the best possible competitive ratio for that problem. Okay, and I'll just briefly say it's like a very, very dominant paradigm. It's very widely studied for all sorts of matching problems and beyond. And this is just some tiny list of the examples. Okay, so now you can hopefully see where the title of my talk comes from. The optimal offline is often. You know, optimal offline is often called this profit character because the optimal offline can kind of see into the future, see all of the arrivals that are going to happen while making its earlier matching decisions. So the corresponding character for the optimal online policy, in some sense, seems to be a philosopher, because the optimal online can't see into the future, but it has unbounded time to compute what decision to make at each step. So, in some sense, it can think really hard about each. Think really hard about each decision that it has to make. Okay, so this was as recently as 2016, identified as some benchmark of interest. There's this quote from Carlin and Kutsupias from this survey article in this book, Beyond the Worst Case Analysis of Algorithms. They said, Although using the optimal online as a benchmark makes perfect sense in stochastic settings, it is not so common in the literature, largely because we do not have many techniques for getting a handle. We do not have many techniques for getting a handle on it for comparing arbitrary online algorithms. And now, almost 10 years later, this is not really true anymore. In particular, in the last two or three years, there's been a bunch of work about understanding this benchmark, which has resulted in a lot of new techniques and new approximation ratios for some problems, like this matching problem that I started with, that were considered perhaps solved. Okay, so for example, for this online stochastic matching problem that I told you about at the start of the talk, there's been quite a bit of progress. So given that we're in banff, it actually feels very appropriate to represent this online as like the peak of some snow-capped mountain, put this philosopher character on the top of it, representing this goal we'd like to achieve. And I have as this baseline is 0.5. As this baseline, a 0.5 approximation because there are 0.5 competitive algorithms. And so that's, if it's 0.5 competitive, it also will be 0.5 against this piece of algorithm. And now, so in 2021, we showed that this benchmark is piecepace hard to approximate within some constant less than one. And this really justified, I guess, the search for better constant factor approximations. It really rules out that there could be a key task for. Rules out that there could be in two tasks, but it's a problem. And in that same paper in 2021, we gave some very small. So, instead of 0.5, we showed, okay, you can do 0.51. And then since then, there's been quite a bit of work, 0.52, 1 minus 1 over e, that's about 0.63, 0.65, and then finally this 0.67 is like currently the best. Numbers are not so important, but today I'd like to tell you about. But today I'd like to tell you about the techniques that we use to come up with this new approximation for this online stochastic matching problem. I'd like to also tell you about how we beat 1 minus 1 over e for some continuous time version of this problem, where we can sort of analyze, instead of how an algorithm does over some known time horizon, we think about some steady state distribution and the connections between those two. And then whatever time I have remaining, I'll tell you about some extensions and problems. Problems. Okay. So, all of the works that have approximated this online policy for the matching problem have used the same LP relaxation. So, it has some variables xit for each edge, and it's representing just the probability that the online algorithm wants to match along that edge. So, this is the objective: maximize the weight of the edges that you match. There are these two natural constraints. There are these two natural constraints which actually hold for the optimal offline as well. You match each online node with at most its arrival probability, PT. You match each offline node at most once. And there's also this constraint that holds only for online outputs. So to parse this constraint, this is saying the probability you match some nodes I and T, you know, matching those two nodes should require the following two events to happen. First of all, The following two events to happen. First of all, this node T should actually show up. And second of all, this offline node I should be free. It should be available when T arrives. Otherwise, you can't match it. And the observation is that these are independent for online algorithms. They're independent events because you can't make your decisions from 1 up to t minus 1 knowing what's going to happen at time t if you're an online algorithm. It's actually not true for an offline algorithm. So this constraint is sort. Algorithm. So this constraint is sort of crucial for getting some extra boost in these approximations. And I'll tell you briefly about this pretty simple 1 minus 1 over E approximation. This was in a paper by Mark Braverman, Masa Durakshan, and Antonio Mulina. And what they suggested is this algorithm. So for each online node, if it arrives, you consider the off. You'll consider the offline nodes to propose with some probabilities which are given by the LP. So the form that those probabilities take is like the LP weight between i and t, so this x i t. And then you scale by the arrival probability. And essentially, you can think of this 1 minus the fractional degree term as the probability that that node is actually still free. So if you're scaling by the arrival probability and the chance that node is still free, And the chance that node is still free. Roughly speaking, you're proposing with probability xit overall when you're actually able to get matched. And then just do a greedy among the proposing nodes, match to the highest way. And this gets a 1 minus 1 over E. Why does it get a 1 minus 1 over E? It's pretty simple to explain the intuition. So I already said, you know, the chance that online note is free, roughly speaking, it's this, you know, 1 minus the chance it was matched to some previous. It was matched to some previous node. That could maybe be an inequality if you don't match exactly what the LP is telling you, but the inequality is going to point at the right direction. It's free with at least that chance. And then this red term is just our proposal probability. So the chance you're free and actually propose is just xi t over t. Now you can work out, you know, what's the chance that t is matched? Well, if the probability t arrives times the chance trip trip trip t T arrives times the chance you get at least one proposal. And in an unweighted graph, all you care about when analyzing algorithms is what's the chance that you match this node. For simplicity, I'm just going to show the argument for an unweighted graph, but it extends pretty easily. Okay, so now in this step, I'm going to cheat a tiny bit. What actually could happen is that these proposal events could be correlated, could cause some complications in the analysis. Analysis, and you know, I'm gonna return to this point. You do have to justify this step. But I'm just gonna say for now, if these were independent events, if each node proposed with probability x i t over gt, then you can just write out exactly this product for the chance that there's no proposal. And then this is like some very standard sort of like high school algebra to show that this gets 1 minus 1 over. You can replace 1 minus x with e to the minus x and then use the And then use the concavity of this function to lower bound it by some line. So you can trust me, those calculations are quite easy. This is showing that you get a 1 minus 1 over e for each online node t. Okay, so now let me tell you about what are the main ingredients we did in this work to sort of beat this 1 minus 1 over e. So we used this pivotal sampling routine to Pivotal sampling routine to correlate the proposals from the different offline nodes. We showed that these offline nodes actually become negatively correlated if you do some careful discarding, which along the way actually lets us justify that inequality where I cheated in a kind of very simple way. And our analysis uses some of these new tail expectation balances. And I'll show you what I mean by that. Okay. So to correlate these proposals, we use this pivotal sampling subregion. We use this pivotal sampling subroutine. And what does this do? So it takes some proposal probabilities, let's call them R1, R2, up to Rn, and it decides which of these nodes are actually going to propose in some correlated way. So it matches the marginals each i proposes with the probability RI that you put in. And then it has this like prefix correlation property. So this is kind of like, you know, the way you should parse this, the probability S intersects this set is like the chance you get. S intersects this set is like the chance you get at least one proposal out of the first K nodes. By the union bound, it's certainly at most the sum of all of those marginal probabilities. If the sum of those marginal probabilities is less than one, this is saying match the union bound exactly. So like if you have n, you know, n proposal probabilities that are one over n, this is saying like have someone propose with probability exactly one. And you know, if the sum is And you know, if the sum is bigger than one, you're just going to propose with one, which is essentially like you're going to have one of them proposed with probability one. It's, of course, like the best thing we can do. Question? So, so an online node arrives? Yeah. And then the offline proposal? Yeah, yeah. Correct. So when the online nodes arrive, the offline nodes are each going to make some proposal and you're going to pick the highest weight one too much. And you're going to pick the highest weight one to match. Yeah. Correct. Yeah, so this pivotal sampling has some prefix negative correlation property. And actually, our change to the algorithm is super simple to say. Basically, we just replace independent sampling with pivotal sampling. So we look at this vector of proposal probabilities and we look And we only look at the nodes that are actually still free. So I use this random variable fit to denote that this offline node i is still free at time t. We look at this vector in decreasing order of edge weight. We put it into pivotal sampling to get our set of proposers, and again we just match to the highest weight one. So it's some simple way to correlate the proposals. And now, like, in order to analyze this, Like, in order to analyze this, we show that you can achieve a sort of negative correlation of the offline nodes as this algorithm progresses. So, what do I mean by this? I mean, the algorithm is going to stochastically dominate some case where those FITs, those indicators for the offline nodes being free, they're roughly independent or better. So, formally, what I mean is this condition with the marginal probabilities. For the experts in the audience, it's sometimes called negative cylinder dependence. Sometimes called negative cylinder dependence, but we can just think of it as independent or better. And it justifies the sort of 1 minus 1 over e calculation where I cheated by assuming independence earlier. And to prove this, we do some discards. We show the stochastic dominance by considering an algorithm that actually occasionally will sort of throw away offline nodes, which seems very wasteful, but it sort of shows in the But it sort of shows in the analysis that this is going to be the worst equals. And once we have this negative correlation, we're well on our way to this 0.67 approximation. There's this additional step where we sort of re-weight the LP solution, which has also been done in prior work, where in like the hard case where there's a low chance some offline node is available, we actually boost its LP mass. And to pay for that, when there's a high probability, For that, when there's like a high probability it's available, we decrease its LP mass. I'm not going to spend too much time worrying about that. I kind of want to give you some sense of the main technical contribution, which is these tail expectation bounds on the sum of negatively correlated weighted vertices. So what do I mean by that? Well, again, let's just look at the unweighted problem and try to see how does the analysis change if I now have pulls. So the probability I match this node t is the arrival probability times the chance. Probability times the chance I get at least one proposal. So now that's basically like this, you know, the output of pivotal sampling, the set of proposers that it gives me should be non-empty. So now, if you recall this like prefixed property, this is basically saying like, you know, the probability it's non-empty is the minimum of one and the sum of those marginal probabilities. And what makes this algorithm, you know, difficult to analyze is that the sum of those marginal probabilities Sum of those marginal probabilities is going to be a random variable, right? Because it depends on who's free at a certain time. And that's going to depend on both the randomness in the arrivals and the randomness in our algorithm early. So we basically, our main contribution is to give some new tools for analyzing terms like this to basically get the provable approximation guarantee. You know, these terms actually show up in a lot of online matching problems. We have some. Problems. We have some, you know, like, you know, ongoing work where it seems like these bounds could be useful. Maybe they'll be useful in some matching problems you look at. So it's at least now you know where to look if you see some term like this come up. Okay, so I'm going to switch gears a little bit and just tell you about some of the ideas for the stationary matching problem. Okay, so this is motivated by the fact that in many applications By the fact that in many applications, we don't sort of know the offline nodes of the graph in advance. It's sort of dynamically changing. So, for example, maybe these offline nodes are like drivers for some ride-sharing company, and they're coming and going, you know? And then maybe when some online node arrives, the online node probably has much more limited patience in this case than the offline node. The writer wants to get a The writer wants to get a ride match pretty quickly, otherwise, he'll go to some other app. So, once this online node arrives, we have the chance to match it. Maybe we pick this edge to an offline node, and both the rider and the driver depart the system. And this sort of process might keep on going. Maybe now this online node arrives, but there's no one to match her to, so we can't do anything. So, we model this by assuming the offline nodes arrive according to some Poisson process and have, you know. And have, you know, not, they don't like stick around forever. They have some wait time that's distributed like an exponential random variable. And the online nodes similarly arrive according to some Poisson process, but they're very impatient. They don't stick around and we need to match them quickly. So it's sort of like a continuous time analog of the problem I started with. And this sort of problem, we kind of assume an infinite time horizon, and we want to maximize. And we want to maximize, you know, taking it over a very large time span zero to t, the reward we get in that time divided by t. So we call this, you know, a stationary reward because it sort of depends on what the distribution of the state looks like in the limit, in like the steady state of the steady state analysis of the number of online and offline builds analysis. Number of online and offline builds on the system. And some prior work showed that you can get a 1 minus 1 over E approximation to optimum online. In this work, we beat this 1 minus 1 over E. And the ingredients were a tightened LP relaxation. Unlike the one I showed you before, this one has exponential sides. But we argue you can still solve it efficiently. We give a simpler proof of 1 minus 1 over E. I don't know how many of you in the audience have maybe read this earlier. 1 minus 1 over e. Earlier, uh, one minus one over E proof, but those of you who have will know it's like definitely somewhat uh involved and take some work. So, we first gave a much simpler way to see this one minus one over d using the ideas from the discrete problem. We again used pivotal sampling, and we had this one extra ingredient of weakly correlated cues, which I'll give you the intuition for. Okay, so I'm not going to state the whole LP. I'm just going to point out that, you know, in this LP, That you know, in this LP, the natural thing for the variables is going to be the rate of matching two types instead of like the probability two nodes get matched. And our algorithm is really similar. It's going to have the offline nodes propose with probabilities computed via the LP whenever online nodes craft. Okay, like our discrete proposal probabilities took this form, our stationary proposal probabilities will take a different form. The exact expression is not so important. The exact expression is not so important, but I just want you to sort of pattern match these. So x at t is in the numerator of both. This pt arrival probability got replaced with some arrival rate. So sort of pattern matches. And recall this 1 minus the fractional degree term we kind of thought of as the probability that this node was free. It turns out that this more complicated expression in the stationary case is roughly speaking exactly the same thing. There's this additional step. The same thing. There's this additional step which I'm kind of sweeping under the rug where we split offline types into many copies. So you can ask me about that later if you're interested, but morally speaking, it takes exactly the same form as the discrete problem. Via this sort of stochastic dominance argument that first appeared in prior work, we can assume that these offline types stay independent, kind of like how we assumed in the discrete problem that the offline nodes were independent or better. Independent or better. And then the same argument that I showed you before, the same calculation, it also gets 1 minus 1 over E. And then to beat 1 minus 1 over E, our first step is to correlate the proposals with pivotal sampling, just like before. But the stationary problem has sort of one additional twist, which is that we need to do something beyond just looking at independent offline nodes. The sort of like independent The sort of like independent or better guarantee we gave for the discrete problem will not apply here to beat 1 minus 1 over e. So we look at this thing called weakly correlated Qs. So we notice if you look at the number of offline nodes of some type in the system, you know, it's kind of changing according to some Q stochastic process. At each time, it's always increasing at some rate, just given by the parameter lambda i of the Poisson process for that. That I have the Poisson process for that type. And when it's decreasing, you know, there's two things that can cause this Q to go down. There's like a departure rate because each thing in this Q has some limited patience. And there's a match rate. This Q can get used up because the, like an online node can match to someone in it. The departure rate is really easy to understand. It's just this exponential parameter for each car in the queue. The queue, the match rate ends up being much more complicated. It depends on the state of the queues for the other offline nodes. Because, roughly speaking, if everyone else is available, maybe these online nodes are going to want to match to them instead of match to me. If no one else is available, I'm the only person in the system, I might expect to have a higher batch rate. So that creates a bit of a complication in this, you know, in analyzing this. And analyzing this Q. And if you try to write down the expression for the exact match rate, as far as we know, analyzing what happens in steady state is just too complex. These Q's could be correlated in some very complicated way, and we don't have any good way to get a handle on it. One idea you can do is you can kind of take an upper bound on the match rate by just saying, well, the highest match rate would be if everyone else is happy. There's sort of no competition. There's sort of no competition. Everyone is going to want a match to me. That's sort of like going to be the biggest possible number I could put for the match rate. It turns out, you know, I didn't put any details, but the Q's are going to be independent. They don't kind of depend on what's going on with the other things once I replace them with this upper bound. So it's very tractable, but you can't be 1 minus 1 for Q. It's totally stuck at 1 minus 1. So we need this idea that's sort of in between the two. And this is what we call weakly correlated keys. So for half of the types. So, for half of the types, we use this independent upper bound. And for the remaining types, we actually consider some sort of correlated evolution of those cues, where we actually enforce that the evolution depends on the state of those independent times. So it's something, it's still quite complicated, and we don't know how to explicitly write down what happens in the stationary distribution, but it's tractable enough that we can show that you beat 1 minus 1. Okay, and I'll just briefly mention at 3:30 today, there's going to be a talk about the same stationary bipartite matching problem in the case where there's a small number of offline types. And in this case, Ali Reza, Amin Saberi, and Ali Awad showed that you can get a p-tas. You can get a 1 minus epsilon approximation if it's a problem. It's a problem. So see you at 3:30 for more details. Okay, so we started a little bit late, so I might just not say much about these extensions. You can ask me after. We consider some insights when the online nodes have some capacities. Roughly speaking, what's the takeaway from this? From profit inequalities, this problem actually looks exactly the same as the unit capacity version that I started with. It turns out, like, It turns out, like, you can just run the same algorithm, you still get 0.5 competitive. It doesn't seem like it's any harder. When looking at the optimum online, we basically were able to show that this problem is harder. Like, there's this key difference where offline nodes cannot be negatively correlated or independent, like in these arguments I've been showing for the unit capacity case. Another example is you can ask some questions about mechanism design. We have kind of assumed all these edge weights are just given to you up front. View upfront. What if they're reported by some agents, like some buyers who are interested in each getting like one house? So for the matching problem I presented to you, the informal statement is that the results extend. There's still some open problems in the more combinatorial case. So for example, when you have capacities, we kind of need this assumption that the capacities are constants to make it tractable. So open what you can. Still open what you can do if those capacities might be large. Okay, so let me wrap up. So I want to conclude by going back to this quote from the start of the talk, which roughly said that optimal online is a nice benchmark, but we don't have many techniques for dealing with it. And hopefully I've convinced you today that this is no longer true. So we saw that you can use this pivotal sampling technique for both discrete and continuous time matching problems. And we saw this technique of weakly correlated cues to help. Weakly correlated cues to help us deal with the unknown or infinite time horizon in the continuous time problem. In the future, I think, I mean, there's a big list of problems where this benchmark hasn't really been studied yet and would be of interest. I've just listed two where, you know, there's some partial results. So there's progress on both of these settings, combinatorial auctions, made trade constraints, but we don't yet understand sort of the full picture. But don't let this be an exclusion. But don't let this be an exclusive list. Like whatever problem you're interested in, think about maybe whether this optimal online interest is better. Okay, so that's all I have. Thank you. So when you can't talk about the patterns, well, instead of the tax aspect. Question. So comparing the stage period case versus the difference between these two points. So the first case we said they are it's one a lot for the It's got apart support. They have a negative result. The station in the case, I don't see why you can't get the optimum. Is that what Ali Reza are talking about? Well, Ali Reza is, so we're still wanting to have an addition policy involved at the time. You can compute some dynamic program again to get the off, but it might be.