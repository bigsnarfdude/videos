Great so far. So my talk today is, as mentioned, is going to focus on imaging genetics actually. But I think the connection that I'll make to the focus of the workshop is via the application. So the application is to Alzheimer's disease. And for the studies that we've been working with, this is a multi-state progressive process that's subject to panel observation. So they're censoring. And there are a number of issues that arise. And there are a number of issues that arise with respect to censoring that haven't been taken into account yet, but could be. And so I hope I can generate some discussion on that. So collaborators on this work, I'm collaborating with Michelle Miranda, Cedric Bulak, Jihua, Liang Lang Wang, and Faisal Beg. And we have a number of trainees that have been involved in this work over the last couple of years. Okay, so the main general area is imaging genetics. And these are studies where interest lies in examining and trying to find associations between genetic variations and neuroimaging measures as quantitative traits. And so the idea is that rather than looking just at disease, we look at brain imaging endophenotypes, which provide a more detailed measure of Which provide a more detailed measure of the brain, right, than just simply disease-life histories. And there are many ways you can measure the brain, its structure and function. And today I'm going to talk about measuring the structure of the brain using MRI. And we're going to relate this to genetic data, which in this case is going to be high-throughput SNP data. So, the overall objective of these studies is to better understand the relationship between genetics. Relationship between genetics, brain structure of function, and Alzheimer's disease. And again, in the context of our application, disease is a progressive process and it's intermittently observed over time. So there are sensoring issues that arise. Okay, so the primary statistical problem that I'm going to be addressing today is regressing brain imaging data onto genetic data and dealing with the high-dimensionality of both. So there's basically two aspects. So, there's basically two aspects of my talk. First, is a regression model, where I'm going to focus on a spatial model for this problem. And then it's a regression model where we extract some information from the MRI, usually at regions of interest, and we then regress onto genetic data. But I'm also going to present an alternative approach, where rather than looking at locations in the brain, whether they be regions of interest or voxels, we take the MRI data and we put it in. We take the MRI data and we put it into a neural network and use a supervised approach to reduce the dimension of the data so that the features that we extract are relevant for disease. Then we take those features from the MRI and relate them to genetics using a regression model. So that'll be in the second part of my talk. So the idea of the generative process that we have in mind for this analysis is that genotype has an influence on brain imaging, phenotype. An influence on brain imaging phenotype, which has an influence on disease. Of course, genotype can have an influence on disease directly as well. And again, disease is a longitudinal multi-state process that makes censoring a potential issue when doing a number of things, like considering feature extraction that I'll talk about later. If you want to do joint modeling, models where you want to consider genetics influencing brain imaging and disease simultaneously. These simultaneously, then censoring becomes an issue. But this work is going to just present some results in an initial step that looks at just a cross-sectional analysis. So in this cross-sectional analysis, we just have disease indicators. Okay, so first for the regression model. So I'm going to present a spatial regression model. And the spatial regression model is an extension of a Bayesian multivariate regression model for imaging genetics. Multivariate regression model for imaging genetics that was developed by a former student of mine, Greenlove, that didn't account for spatial correlation. And her paper was motivated by an older paper that developed a sparse estimator, regression estimator, for imaging genetics that is basically like a combination of group lessel penalties. But the approach only provided point estimates, and no easy approach. And no easy approach. The bootstrap tends to perform poorly when applied in a naive fashion to this estimator. So, Greenlaw developed a Bayesian approach where the prior was a shrinkage prior that corresponded to certain penalties, and the prior led to dependence in the coefficients for SNPs within the same gene. So, just a bit of notation. So, our imaging data, our So, our imaging data are denoted by YL, and we have imaging data across C regions of interest. Later on, I'll change this. But we have an MRI, and from the MRI, we've extracted measures of cortical thickness and so on at C regions of interest. We have genetic data, so we have D SNPs where we have the number of minor alleles for each. And our regression model is as follows. So it's a As follows. So it's a mean regression model in this case, where W is a matrix where the ijth element of the matrix relates the i-th SNP to the jth region of interest in the brain. And so our goal is to develop inference for Dublin. So this was the estimator that was developed in the 2012 paper for this. For this type of data. So you've got your, so here you have your imaging data, you've got your genetic data, you have an L2 loss function here, and then you've got two group Lasseau penalties. One group Lasseau penalty groups by SNP. So for every SNP, you have a set of coefficients relating that SNP to all the regions of interest in the brain. And it groups at the SNP level. And then to allow for a broader level of sparsity, Level of sparsity, it also grouped together SNPs by their belonging genes. So you can either group together by gene or by SNP, and the penalty accommodates both of these grouping structures. And so the main drawback of this estimator was there's no, it just produces an estimate without any techniques for formal inference. For formal inference, and bootstrap intervals, when applied naively, anyhow, gave very poor coverage. So, in the Greenlaw paper, we developed a hierarchical model. The first level is very simple here, and this is the naive part of this model that we'll extend. And then the second part of the model, which is where most of the development focused on, was in the prior for the regression coefficients. So, let WK. So let WK be a submatrix of W with rows corresponding to the kth gene. So all the SNPs in the kth gene are grouped together in submatrix W, and we assign conditionally independent priors to each of these WK submatrices. And the prior takes this form here. And so it's formed as a product of multivariate Laplace kernels. And it's specifically chosen to correspond to that penalty in the penalized estimator. In the penalized estimator, so that the posterior mode of this model corresponds to the penalized estimator. But then here we can run a Gibbs sampler and get credible integrals from our M certain C samples. So that model gave us a little bit more than the original paper in getting the posterior distribution. But as I mentioned, it's actually rather naive in how it models the covariance. Rather naive in how it models the covariance of the MRI data. So, you know, like MRI data are spatial data, so there's spatial correlations in neighboring regions of interest. But actually, that feature is there in the data, but there's a much stronger feature in the data, and it's a correlation between the left and right hemispheres. So if you have two hemispheres on the left and the right, measures from both, like for example, the volume of the left hippocampus and the volume of the left. Volume of the left hippocanthus and the volume of the right hippocanthus, you'll find that they can be highly correlated when you look at the data. So, for example, in a data set that I'm going to look at later, we have on each hemisphere of the brain 28 regions. And if we look at across subjects the correlation between corresponding regions on the two hemispheres, we get a set of correlations. And here's the box plot of those correlations, and they range from 0.6 all the way up to close to 1. So you can see. Up to close to one. So you can see that the pairwise correlations between the left and right hemispheres is quite high empirically in the data. And these are scatter plots here of, you know, like individual measures looking at the left and right hemisphere. And the correlations in these three cases, I chose them because they're particularly high, are above 0.9 in all cases. So the two types of correlation that weren't accounted for in the Greenlaw paper are spatial correlation. Our spatial correlation and what I'll call bilateral correlation, which is left and right correlation between the left and right hemispheres. So, to develop an extension of that model, we first, conceptually what we do is we take the two hemispheres of the brain and fold one on top of the other. So they're now co-located. So now you have, in a sense, like the regions of one hemisphere, and you have two observations. Hemisphere, and you have two observations from each region. And then now letting denote the left and right paired measurements from a particular region of interest in the brain. If you collect the data together, grouped by pairs, then we specify a linear model here where the model for the errors now to account for the two different types of correlation we've Two different types of correlation that we see in the data is a bivariate Markov random field. So it's a Markov random field to account for the spatial structure, and it's bivariate to account for the bilateral structure. So we have C over two regions of interest on each hemisphere. You have a known neighborhood matrix. So this will be some type of graph relating the regions together. It could most It could most straightforwardly be, you know, which regions neighbor which, or it can be something more complicated. And then the errors, this Markov random field model, as Markov random field models are, are specified through a set of conditional distributions. So here I'm going to specify the conditional distribution for the ith region, conditional on the errors from all the other regions, and it's going to be bivariate. Regions, and it's going to be bivariate normal. Then, in the conditional mean, there's a smoothing part here, and then there's this covariance matrix that accounts for the pairwise correlation. And so, these conditional distributions are compatible, so they lead to a valid joint distribution, and there are parameters here that characterize the spatial dependence as well as the bilateral dependence. So, here's the main difference between. I mean, here's the main difference between the two models. We have this Markov-Random field model that accounts for the spatial correlation in the data here. So it's a separable spatial model, which means we're assuming that the correlation strength is the same on both hemispheres, but you could generalize that. And then the model is fairly straightforward to fit using an MCMC sampler. However, However, one problem with the sampler is it takes a while to run. So the running time for this on a data set with about 600 subjects is a few days. So we looked into developing variational Bayes approaches, which were much, much faster. And the tuning parameters in the model can be selected using information criteria or cross-validation. And then, given the posterior samples, And then, given the posterior samples or the variational approximation, we do SNP selection either based on looking at the 95% credible intervals or using Bayesian false discovery rates, which give you control over an average posterior probability. If you go back to one slide, both conditional distributions, they both have the mean, they both have the same mean structure. So if we objective. Structure? So, is the objective of updating the covariance matrix to gain efficiency? Well, it's really to avoid an obvious model misspecification. When you look at the data, there's clearly spatial correlation, and there's clearly correlation from left-to-right hemispheres. So, we need a more flexible model. That's the motivation. Thanks. Any further questions? So, yeah, so variational base, the approach is to use optimization to approximate the posterior rather than sampling. And so, we have a posterior distribution here, P of theta given y, that we want to approximate. And we do so by optimizing a lower bound on the log marginal likelihood. So, if q is any distribution having the same support as the posterior, Same support as the posterior. We can write the log margin on likelihood as the sum of two terms here. This first term here is often called the evidence lower bound. And the second term here is the Kobek-Leibler divergence from the approximating distribution Q to the actual posterior P. And this is always non-negative. So this quantity here is always a lower bound for the log marginal likelihood. And so the idea is then to consider some. To consider some family of distributions for Q and optimize the evidence lower bounds within that family. So you can assume like a parametric family, or in this case, we assumed a mean field approximation. And a mean field approximation just assumes that the posterior factorizes over a bunch of its components. So that you're assuming posterior independence in the parameters. But then the way the whole thing is derived links the moments of these distributions together. Of these distributions together. So you have posterior independence, but the moments are all linked in a very non-linear way. So in this case, when we do this, we can get an analytic form where the posterior distribution is a product of Gaussian, reciprocal inverse, Gaussian, and inverse Wishart forms. And then these distributions depend on certain statistics, and we get those statistics by optimizing this evidence lower bound. Evidence lower bound over them. And it runs faster than the MCMC. So for a data set that we'll look at later, where we have 632 subjects, about 500 SNPs, and 56 regions of interest, so there are about 30,000 parameters. It converges on a laptop in about 45 minutes. Here's a plot of convergence. And so it's faster. Unfortunately, as we'll see later, it's time. Unfortunately, as we'll see later, it's not nearly as accurate. So ultimately, what we did is we said, okay, run this, get an initial glance at your data, and then use it to initialize the MCMC, and hopefully that will help it converge faster or better. Okay, so just to look at the data and a simulation study. So we're looking at data from the ADMI-1 study. And the ADNI-1 study, here we have data from Here we have data from 632 subjects. We have about 500 SNPs selected from an Alzheimer's database. They're contained within 33 genes. And we have 28 measures extracted from the MRI on each of the left and right hemispheres of the ring. And so here are the parameters here. And I'm going to simulate in a best case scenario, I'm going to simulate from the model. From the model, and then I'll show you the model works well. And this is just to illustrate that when there is spatial correlation, there's a need to account for it. And I'll simulate from the parameter with the parameters set to the estimates obtained on the real data. So, when we do this, here I have the mean squared error. This is the average mean squared error across all regression coefficients. And here's a comparison of three. And here's a comparison of three approaches. There's the original non-spatial model, the spatial model, and then the approximation. So you can see there's a, when there is spatial correlation in the data, an extent to which is estimated from the real data, so a realistic map, there's a benefit in terms of mean squared error of estimation compared to the non-spatial model. The spatial model with the approximation has a relatively poorer performance. So, both in terms of the estimation and also if we look at the average coverage probability of 95% credible intervals, the approximation undercovers, it's underestimating posterior variability. So, you know, I think this is just useful for initializing the MCMC and maybe quickly taking a look at the results. So, for the real data, have the same form just presented. The same form just presented. So we've got structural MRI, we've got genetic data, there are 632 subjects, and then for the response variables, you know, we use the standard pre-processing pipeline in a program called FreeSurfer. And there are response variables, the MRI variables are adjusted for age, gender, education, headiness, baseline total intracranial volume, potential population stratification, which is an issue in the ADNI study, and Apole genotype. And Apolley genotype. And when we fit the two models, the spatial model and the non-spatial model, and we compare them using the WAIC, there's a rather strong preference for the spatial model. So at least based on this criteria, it appears as though there's an advantage to considering the spatial model. And so there appears to be an advantage both in the case of real data and simulated data. And simulate them. In terms of SNP selection, so here I've got two figures. What I'm doing here is on the x-axis I have the SNPs grouped by genes. On the y-axis, I have the regions of interest. And then the pixel is colored red if Bayesian FDR selects that SNP at a level of alpha of 0.05. And then the two figures correspond to two different values. And then the two figures correspond to two different values of the tuning parameter, 1,000, 10,000. And so as we move from 1,000 to 10,000, all of these, many of these get zeroed out, and then you can kind of identify two particular regions that have this rather broad genetic signal here. So these two regions of interest stand out as having this broad signal. It's not necessarily the strongest signal, but it allows us to see which ones have, if there are any, that have a broad signal. any that have a broad signal. You can look vertically as well. And the two regions are the thickness of the left supramarginal gyrus and the thickness of the left superior temporal gyrus. And here are the regularization paths for these two regions. So these are all the point estimates associated with all the SNPs as we change the tuning parameter. And then we've highlighted the SNPs of potentially most interest here in red. In red. I'll say a bit more about SNPs when I get to the next part of the talk. But overall, I think the spatial model demonstrates some benefit when there is spatial correlation in the data. It's a useful development. But the thing that we started to think about that hadn't been thought of before, as far as we could tell, was: are there any other ways to extract features from the MRI when you want to do imaging genetics? To do imaging genetics. So, like, typically, what's done is you have an atlas, and your atlas has regions of interest, and then you look at summary measures of those regions of interest. Or you do it voxel by voxel. So these are all local summaries. But we thought maybe we could create novel summaries using a neural network that would be relevant for disease. That's basically the idea of this next part. So it has. So it's related to the notion of an autoencoder, which is an unsupervised learning model. We'll go to supervised in a bit, that learns how to decode and encode and decode data. So you compress the data to get a dimension reduction. So here, you know, if you have, you know, if X is your data of dimension D, Z is your lower dimensional code, and your encoder encodes down to a lower dimension, and your decoder encodes back up, and then you train the model to. Close back up, and then you train the model to minimize the error on the input data and the output. Yes? Sorry to interrupt this. I just had a question leading into this, which was: what is the spatial dimension that you're going from? So, like, on the previous, it looked like you have like 50 OROIs, or is that 56. Oh, 56. Okay. I couldn't really tell from the plot. Oh, yeah, it's 56. Okay, so you're trying to go from 56 to something. Well, we're going to use 56 in this as well, but these are. In this as well, but these are going to be like non-local measures, right? They're going to be constructed, like they're going to be, they're not going to be associated with each measure will not be associated with any region or a voxel. It's going to be constructed from the whole MRI. Thanks. Okay, so yeah, so the autoencoder is going to compress and decompress the data so as to get a dimensionality reduction. So here's a figure describing, illustrating. So, here's a figure describing, illustrating the autoencoder. So, the idea right now, before we go to the supervised part, is we want to take this part, like this, these are the features that we want to extract from our MRI and relate those to genetics. And this is a generalization of PCA if both the encoder and the decoder are linear functions. And yeah, you know, we often. And yeah, you know, we optimize using standard software, which uses fat propagation and we use a quadratic reconstruction to train the model. We can add more layers as well, so we can have several layers here. And then we can extract those features and use those features in our regression model. Now, one of the things that we wanted to do is change this a little bit so that we take the Bit so that we take the decoder function and make it a classifier function. That way, the features we extract are relevant for predicting disease. So, the idea is that we make this last layer, Q, a prediction of disease indicator. So, we have neuroimaging, we have genetics, and we have disease. And so now we use the disease data to help extract. Extract a lower-dimensional representation of the MRI. So, advantage is that these, so we'll have 56 here as well. The dimension of these were deliberately set to be the same as the original analysis so we could compare them. But like, so the advantage of these is that they're trained to be accurate for predicting disease. So, whatever SNPs we find related to the response are used. Are potentially useful in that sense. The disadvantage is we've lost the interpretation. We're not looking at any particular locations. In the brain, rather, we're looking at this representation. So it's basically the second to last layer becomes our extracted features, and the last layer is just a logistic regression. And so, in a way, another advantage is it's data-driven. And so, we don't have to rely on specific, like, expertly chosen regions of interest, which are another function. So, this is just trying to learn the function so that it's better at predicting disease. So, the idea here is that our MRI are the input, disease, we're trying to predict disease. We take the last layer here. I think the arrow should be going the other way. Here, I think the arrow should be going the other way, and we relate the extracted data to genetics. So, in our ADNI-1 data, we're going to look at this data where we're going to fit the data to 543 subjects classified as either normal, mild cognitive impairment, or Alzheimer's disease. Two points I want to make here: one is this is a reduced sample from the original sample. Original sample, original sample, so we lost about 89 subjects, and we lost those subjects because we didn't have disease indicators. So, doing a complete case analysis is probably not the best approach here. For example, we could use our neural network to impute the missing disease indicators or use some other approach. But this was our first sort of test run to see how well this would work. So, we did the simplest thing, which I don't think is maybe the best. Don't think it's maybe the best, but anyhow, that's why our number of subjects has been reduced. And the other point is that this is just a cross-sectional analysis, but the data are actually longitudinal and subject to panel observation. So this can all be extended. So what we have then, we have the MRI scans. They're processed and registered using this algorithm FreeSurfer, the FreeSurfer, and FreeSurfer will output about 2,000 variables, or 1,860 variables. And then those will be the input into the neural network. And then those will be the input into the neural network. And then, just for this one test case, we have a simple neural network which has one hidden layer. And it's only trained to predict on the Alzheimer's and normal control subjects. We thought that by only using these subjects and training the neural network in this way, it would give the maximal contrast so as to extract features that are, to more easily extract features that are predictive of. Features that are predictive of disease. Once we extract those features, we use the Bayesian regression model to relate them to genetics. And then both of these models have a number of hyperparameters, and the best way to choose them seems to be cross-validation. The ideal way to choose them would be to assign them hyper priors and sample them, but that tends not to work. Just to show that these responses are useful, I think, when we have the, you look at We look at the neural network extractive features, and using cross-validation, we try to predict disease status on holdout data. And so these are the results for the data on the regions of interest, which are specifically chosen to be relevant to Alzheimer's. And then these are the results for the neural network. And the neural network has quite a reasonably higher prediction accuracy. Reasonably higher prediction accuracy on holdout data. So even though we've lost the interpretation of specific regions in the brain, we have this better predictive ability. And so I think it's useful not in replacement of, but in addition to voxel-wise and region of interest-based analysis. Here's a two-dimensional embedding of the features. So these are the regions of interest and neural network extracted. And neural network extracted features. And then the two colors correspond to Alzheimer's and normal controls. And this plot here is the expert features, like regions of interest. And these are the neural network features. And so if you look, you can see these features, as constructed, separate the two disease groups better. So just another way to see that they're. Another way to see that they're relevant, right? Because you don't really, you might think I don't want to use a neural network if I want to do inference, I'm losing interpretation. But the point of these slides is to show that there's still an interpretation in a sense, because they're predictive of disease. So when we fit the model, here are the top 10 SNPs chosen based on their estimates, scaled by the standard error. And here are the associated genes. And here are the associated genes for those top 10 steps, the chromosome, and then the last two columns. This column here, status is either known or blank. So it's known if we found it in the previous analysis or if we could find it in a previous paper looking at the ADNI data. And it's blank if we didn't find it in our analysis and we haven't found it in any previous papers. And the fifth column is we look at the credible intervals associated with each. Intervals associated with each of these SNPs. And we count the number of the 50 SO features whose credible intervals exclude zero. So in this case, one of them. In this case, 15 of them. So if this column here was all knowns, you might say that using the neural network you didn't find anything novel. If it was all blank, then you might doubt me. So what we end up finding was actually ideal. Maybe there's some, adding data has been analyzed extensively, but still, maybe there's, like with this SNP here, it's related to 15 of the neural network features. And so maybe this can sort of give a useful indication of other SNPs that Other SNPs that might be useful to look at that don't appear in a region of interest type analysis. Okay, so you have this automatic feature extraction approach. I think it's added value, not a replacement value. So I think voxelize analysis is still going to be the standard approach, but I think this adds something to it. It doesn't require any expertise for feature selection. And it's And it's a supervised approach that reduces the dimension of the neuroimaging data based on disease. So we consider this approach to be useful alongside standard approaches. Some extensions. I think an extension that I think would be very interesting would be to consider disease in a multi-state model under panel observation. And so then you can think of, as I mentioned earlier, like As I mentioned earlier, like how that might impact, or if it would impact the feature extraction, and if you actually want to model disease and relate, like have a joint model, it could be interesting to consider how you would specify such a model and fit it. And then, you know, what we end up doing is we have an initial step that takes the MRI and reduces it down to 2, like 1,800 measures. Using a convolutional neural net, Using a convolutional neural net, it could be possible to have as input the entire three-dimensional MRI. So we would avoid that first step. There are three papers associated with this talk. I'd like to thank funding from University of Victoria, CANSI, and Edsburg. Thank you. Thank you, Bert. We have six minutes, plenty of time to ask questions. Questions?