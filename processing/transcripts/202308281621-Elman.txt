Okay, I want to thank the organizers also. I'm very pleased to be here. This talk is a linear algebra talk about PDEs and it's a collaboration with a recently graduated student at the University of Maryland. A student at the University of Maryland, Caleb Davey. So here's an outline. I'll give a very brief picture of the types of TVs I'm interested in, and then a little bit of an overview of reduced order models, and then some discussion of how to compute reduced bases, model order reduction for these problems. Something old and something new in this collection, and then some experimental results. Some experimental results, a little bit of analysis. So, a generic problem statement is that we want to minimize some function of j subject to a constraint b. And all of these, the whole problem will depend on a set of parameters mu. I'll focus on two examples in this talk of somewhat different character. First one is a parameterized control problem. Problem. So the want to minimize a functional that is of this form, including a regularization term, to find a state u and a control F subject to a constraint, in this case, a diffusion equation, which is parameter dependent, where the diffusion coefficient depends on parameters. And there's a target state that we're trying to approximate in the control. Trying to approximate in the control room. The second problem is the Stokes equations, standard problem, except with a parameter-dependent viscosity. And I wrote this minimization problem in a somewhat irregular way. The minimization is written down in the weak form, usually in a finite element setting. The constraint is written also in a weak form. But I want it to look like this, because the linear algebra looks like this. So this is a strong form of So, this is a strong form of the constraints. So, for both problems here, the parameter dependence is in a diffusion coefficient. Okay, so here's, I'll say, I'll describe things in a little more detail for the control problem. Everything carries over in a fairly straightforward way to the Stokes equations. So, here's the control problem written one more time. And after we discretize, we can have a discrete version of the control problem subject to a constraint. Control model subject to a constraint of this form. This is a diffusion operative, a parameterized diffusion operative in the constraint. And if we introduce a discrete Lagrangian and impose the KKT conditions, we get a satellite one problem, which looks like this for the control problem. These two matrices are mass matrices. This is the diffusion operator in the case of the control. So we have a control and a state and a Lagrange multiplier as unknowns. Multiplier as unknowns. In compact form, we might want to group the control and the state together into one variable called the x and write it in 2 by 2 instead of 3 by 3 block form. And the Stokes equations, which I won't go into any detail about, has the same general structure, but parameter dependence appears in a different way from the Stokes equations. So these problems are somewhat different. The Stokes equations has the constraint kind of built into the system. Kind of built into the system. It's the incompressibility constraint. And the control problem has a constraint which depends on what we want to use for the constraint. So I'm going to focus today on the diffusion equation constraint, but any other equation is possible. We have some results for other problems, but I won't say anything about them today. So now, reduced order modeling. If I write the whole problem, whichever one I'm talking about, in a very simple way, is About in a very simple way is G, V equals V, G is the matrix. I'm only looking at linear problems here. G is the matrix, which is parameter independent. The right-hand side is not necessarily parameter dependent, but it can be. The philosophy behind reduced order models is that we want the solution for many parameters mu. And if the discretization is fine, if we're looking at three. Fine if we're looking at 3D examples, which I will not do, but if that's the type of problem you're concerned with, it's going to be expensive to compute a solution for many parameters. So the idea is to compute an approximate solution in a reduced space spanned by, again in linear algebra terms, a matrix Q whose rank will be much smaller than the dimension of the original discrete problem. And this reduced And this reduced basis is obtained using greedy search, which is referred to in this style of work as an offline step. You do this once, it may be expensive, but then you may want to solve the problem for many choices of you over a long time and take advantage of whatever it costs to generate the reduced basis. And the basic approach for doing this is to build the reduced basis using a set of so-called snapshots. So-called snapshot solutions. This is standard in this way of talking about this problem. Compute a set of solutions and try to find a basis such that over all parameters, the basis represents accurate solutions on manifold of the parameter space. One way of doing that is to solve a Galerkin system, to compute the reduced basis. To compute the reduced basis and then compute solutions on the reduced space, which are, say, orthogonal to that same reduced space, and that's equal to philosophy here is that if number of the size of the reduced space is small, this should be much cheaper than solving the full-order problem. Here's a picture of the greedy search. I don't think I'll go into gross detail about this. It's very standard. It's very standard, it's over 20 years old. Choose, so we're working with a training set of parameters, which could be arbitrary or that could come from some experimental design, say using a space-filling curve in the parameter space. We just use random collection of parameters, typically 2,000. So we have 2,000 parameters that are in our so-called learning space, and in addition, there's an error indicator. And in addition, there's an error indicator which gives you an idea of how accurate you are in the course of the construction of the reduced space. And the way the 3D algorithm works is to start with an arbitrary parameter, compute the solution, and then see if, for all the parameters in the training set, how accurate the error indicator is for the solutions of the reduced space. The reduced space. Okay, so compute a reduced solution starting with a given reduced space. If the error indicator is bigger than some user-chosen tolerance now, then find the parameter in the training set that's the largest possible. Compute the true snapshot of that associated with that parameter. Add it to the reuse basis. Add it to the reuse basis and iterate like that until this condition is no longer violated. Some discussion I have to give you, what is the error indicator that we use, what is our reduced model, and some stuff that's technically related to the particular problem, the control problem, both problems. Okay. Well, we are, I'm using just the residual, rather than residual norm as the error indicator. There are other possibilities, but this is what we're using. For the reduced system, we consider the Galerkin system that I already wrote, and we consider a petro-galerpoint system, where the residual is orthogonal to Q times the residual. Q times the times the g times the reduced space. With this error indicator, the latter choice, the Petro-Galerkin method, guarantees positive definiteness of the reduced matrix, and it produces monotone behavior of the error indicator with an increase in basis size. But there may be some conditioning issues which I'll elaborate on. Okay. Okay, here's this is the structure of the full-size matrix that arises from the control problem. We've blocked the two variables, state and control, together into one, and it produces a two by two locks out of one system. And philosophy of generating reduced order models for this For this type of problem, and the same thing applies for Snokes, is that we want the reduced model to also be a saddle point system. That leads to a construction of reduced basis that's a block diagonal form corresponding to the two separate components. And this may be three components, depending on how we look at things. Something surprising about this approach is how influen stability is handled. So you want influence stability to hold for either model. You want this bilinear form to be bounded below by something involving the dual variable, okay, the norm of the dual variable. For doing this with finite elements, it holds. When we discretize these problems by finite elements, These problems by finite elements, we have introduced stability. But when we naively choose the reduced spaces, reduced spaces, it exactly doesn't hold. It completely violates the MSU condition. And that took me a little while to take in. Sometimes when I discuss this stuff in talks, people are mysterious to them. But it turns out it has a simple explanation. When we solve for the snap. When we solve for the snapshot solutions, if we have homogeneous deer-side boundary conditions, then the constraint is zero. That means the constraint which appears here in the IMF suit condition is zero. So it's simply impossible to make the reduced solutions satisfy an impsoup condition. It's the exact opposite situation. So something has to be done about that. So now all of this is kind of standard stuff here, and I'm going to say a few more words about standard stuff, basically describe some work on this idea due to several groups, mostly in Italy. So in order to get rid of this difficulty with MSU stability, the way people have done it is to augment the snapshot systems that you get by adding terms. By adding terms. So there are two terms, there are two techniques that I'll describe. These are some authors of the first one, these are some authors of the second one. Before I say anything more about this, in this paper, the authors say, we could use either of these two ideas. We don't really know how they compare. Let's use this one. And that's what I handed Kayla. That's my first goal in helping a student learn what's going on is to say, well, which one is better? Is to say, well, which one is better? Even if nothing really super exciting comes out of it. She learned the whole business, okay, by going through this exercise. So, the Supremeiser said, this supremizer method, and I'll explain the name in a moment, takes the solutions from snapshots and augments them in the first space, the primal space, the velocity space for Stokes, by solving a system of equations of this type. Of equations of this type. The A is the matrix that appears in the one, one block. Every time you get a snapshot solution, compute an auxiliary variable and augment your basis with those auxiliary variables. That leads to a reduced basis that has twice as many columns in the first or primal variable as in the second. And so the total number of columns in the reduced basis is three times the number of sounds. Spaces is three times the number of snapshots. The alternative is only, to my knowledge, applicable to control problems, and it depends on having a space of state space and Lagrange multiplier spaces being the same, and augmenting these two spaces with the other one. Okay? So build the two spaces to include the components of both. And that gives rise to also. And that gives rise to also augmented reduced basis, which has five times as many columns as the original set of snapshots. The supremizer method has its name because it produces the maximum of this quantity associated with the Msup constant. Some technical points here, I don't want to take them to great detail, but do this with a fully This is with a fully offline computation, it is actually not known to be in soup stable, even though there's a less efficient way of making it soup stable. I don't want to go into the details on that here. The aggregation method, so that's the supreme. The aggregation method depends on having the same state in multiplier spaces, which will depend on the choice of discretization. For the tests, I'm going to describe later the discretization. Describe later the discretization of these spaces is all Q2 bilinear bi-quadratic elements. Again, it's only designed for PDE constraint problems. We don't know how to do it for something like Stokes equations. But it's included. Okay. This is that was all standard stuff in this world of reduced auto models. So Reduced order model. So, the idea we had is to try a different type of reduced basis where we don't block the components of the reduced snapshots, of the snapshots, into separate blocks in the matrix, but just stack them. Generate a snapshot and stack it. State and control and Lagrange multiplier, or in the case of Stokes, velocity and pressure, just stack them together and use that as a. Together and use that as a reduced basis. It's where these things are constructed from the greedy search, but without this extra time of augmentation. It was a mystery to me, actually, why this idea has never been pursued. So I suggested that Camo take a look at this. Okay, one feature of this is that the number of snapshots is equal to the size of the reduced basis. Another feature of it is that if we look at the Lurken system, which is written out like this, okay, it's not unsound. This, okay, it's not a sound point problem anymore. It's just a scalar problem. It's equal in dimension to the size of the reduced basis. So this worry about impsuitability is no longer an issue. Another issue arises, what do we have here? Can this even be used? And the guess is that people actually did try it and found that it was kind of odd in its behavior, which we certainly found, as you'll see in a moment. As you'll see in a moment. Okay. I meant to say something a little while ago. This greedy search. How does it work? You start with a given right-hand side, you do a search, try to generate a reduced space such that on all the training points, the error indicator is bounded by tolerance. Okay? This could depend on what the right-hand side of this original system was. People ignore that. The right-hand side could be parameter dependent itself. People ignore that. If you find a reduced basis that works for one such example, you take that as a reduced basis for the rest of your life. So, what does that mean here? Okay, so here's. Okay, so here's sort of a theorem, a little bit hand-waving in it, which says the following: that if the greedy search succeeds for a tolerance less than one, then the Galerkin method is non-singular for all mutual training sets. This statement is weak in two ways. One is it depends on this last piece of heuristic strategy that I just described. We're assuming this reduced basis is good no matter where we start, and in a Where we start. And in addition, it's really only guaranteed for the parameters in the training set. But we really want to use these for parameters not in the training set. That's the whole point of this exercise. But this is what we can prove. Here's a quick, very brief summary of the proof. Suppose the Galergen system is singular, okay, where without law, it's an eigenvalue problem. Let's take the eigenvector for the singular form, the zero eigenvalue, to have norm one. To have normal. Okay, our assumption on greedy search, this hand wraving thing, says we can guarantee that the reduced solution is equal to set, there exists a solution obtained by solving the reduced problem, which is accurate to within the tolerance, less than the tolerance that we're doing the search with. It turns out, I'm skipping a lot of steps here, the truth. I'm skipping a lot of steps here. The choice, if we take B to be the reduced operator times the eigenvector, then this leads to a condition of this type where P is an orthogonal projection, which in turn leads, I didn't say this, but we always orthogonalize the reduced bases so that the matrices in question that generate that are orthogonal matrices. So if we take the norm of this quantity, it's one, okay. It's one, okay. I'm sorry, it's equal to tau, okay, because the norm of this quantity w is equal is bounded by the norm of these two orthogonal matrices times the error which is bounded by the tolerance. But we made an assumption at the beginning that the norm was one, so there's a contradiction. So the theorem is valid, okay? Modulo, a little bit of hand waving. If you assume a distribution, an underlying distribution for Distribution, underline distribution for real, you sample especially for that distribution. Would you be able to prove a theorem that shows generalization there? Can you repeat the first part of your question? The assumption about the... That mu comes from some distribution. An underlying distribution. Is that of interest in this field or what? I don't know the answer, certainly. So maybe it's something to think about. Okay. Amy now want to discuss. Mainly, now I want to discuss how these ideas work, how they compare to each other. And again, the first two methods that I talked about, using the supremizer and using the aggregation method, have been around for 10 years. And the people who developed them didn't think it was that critical to compare them. I accept that point of view. This was Kayla's first problem to compare them. Howard, can I ask you something before we go to the experiments? Before I go to the experiments, I can see the difference between in practice between getting a snapshot for the whole G matrix or getting the three blocks separately. So the G matrix is a block, is a saddle point operator. Okay? And so let's think of, let's not worry about control and state. Okay, there's two components. It's a two by two button. Components. It's a two by two block matrix, then, okay, just as Stokes would be. And the snapshots are a pair, primal, or for Stokes, velocity and pressure. Okay, but no one until, as far as I know, until now, looked at those snapshots together to produce a reduced operator. They separated them out. A velocity reduced operator and a pressure reduced operator in two by two block form. Operator in two by two block form. Right, but when you said that you put them one below the other, so what is the difference between these and instead getting the snapshots for the whole tree? Isn't this more or less? Well, no, it's so the one if I just look at A, B transpose, B zero, and I solve, so let's say this depends on zero. Solve for solve for UP. These depend on u equals some right-hand side right. And I do this for multiple choices of mu giving multiple solutions. In the one case, my reduced matrix is going to look like u1 through u number of snapshots and p1 through piece number of snapshots. Number of snapshots, orthogonalized, okay? So it's a block structure. We didn't pile them one on top of the other, we pulled them apart. Okay, the second one. But if I don't do that, I mean if I take the whole matrix as one single matrix and I take the start from the solution for the sample of matrix, I get a big matrix that has two blocks. But people never do that. People never did that. I mean, it was never tried. People didn't really look at it the way I just described it with this G being a single matrix. It wasn't done. I think the reason it wasn't done is, I don't know, okay, but I think the reason is because it was desired to have the reduced operator, the Galerkin operator, to also be of sound point structure. And it isn't doing it this way that you're asking about. That you're asking, but it isn't. It's other area. So, the reason I'm asking is that when you build a curse of space for this structure matrix, you build a single current space, that the first block, at the basis, the B base, the first block has information on the velocity, and the second block has information on the pressure, and they are one on top of the other. It agrees with the correct. You're correct. You're correct. But except one thing. There is no Greeloff subspace here. I understand, but in the same idea, right? So you are building a snapshot basis, the way you are building is the Krielov basis. But it's true. What you're saying is correct. But then if you apply the reduced, if you construct the Galurgen form with a reduced matrix, I think this is exactly what you're suggesting. You no longer have a saddle point problem. You have this other thing. You have this other thing. And I think these older authors 10 years ago wanted to have sound point problems because it seems natural to do that. You start with a saddle point problem, you reduce a reduced operator. That thing should mimic the structure of the problem you're talking about. I think. Okay, you'll have to talk to Alfio about this. To be honest, I don't know. Okay. Here are now some details. Here are now some details about the two bench, two or two and a half benchmark problems that we're going to look at. The first is the diffusion control problem, and we're looking at parameterized diffusion coefficient, which corresponds to equally distributed snapshot segments, horizontal segments in a square domain with various Dirichi enormous. With various Dirichlet and Neumann boundary conditions. All these things, all these examples were taken using IFIS, modifying the diffusion coefficient. So this is the control, I mean the constraint for the first example, the diffusion control pattern. And these are the took the same, use the same technique, just divide the domain into Divide the domain into some number of subdomains and allow the parameters, allow the diffusion coefficient to be some variables chosen in this interval. Okay, here's the first example. I don't know how readable this all is. It shows on the left for Galerkin and for For Galerkin and for petrogalerkin, the maximum relative error indicator over the training set as the training takes place until it reaches tolerance, which is 10 to the minus 7 in this example. So this is the maximum relative error indicator over the whole set of training set, the whole set of training parameters of which there are 2,000, okay? Randomly chosen. Randomly chosen. This is the new method, the stacked method. This is the aggregation method in light loop. And this is the supremizer method for Galerica. And something clear to look at here, this kind of volatile behavior of the stacked method. It makes you nervous. Below is the same thing with Petra. By the way, the horizontal axes are not identical. The axes are not identical. This is 180, this is 150. The actual performance is about the same, okay? But maybe Petro-Galurkin is a little bit different. And does the stacked method require to reduce basis here of about size 52 or something like that? The aggregation, perhaps 120, and supremizer, 140. And roughly speaking, the same, except for this volatile behavior of alert and marketing. On the right is the condition number of this reduced system, okay, as we proceed through the iteration. Now, there was this theorem that said basically for the stacked method, the reduced matrix is non-singular. Once we get to the answer, okay, it doesn't say what happens in the first 149 or 49 steps. There's no guarantee, but we just let it run. And this is the condition number. Numbers. So these numbers are about 10 to the 6th, 10 to the 7th, and they're all on the order of 10 to the 5th. For the petrogalergan, they're somewhat higher. 10 to the 11th. Are we afraid of that? Maybe not, because these numbers are still pretty good. Well, the truth is, I am. This is for a control problem. But if you have a... But if you have a subtle point problem, don't we expect that better Galerkin would be better than Galerkin because of the indefiniteness? It's like applying CG and min red versus min rest, right? C G on the top and min rest at the bottom. Am I so quick for so galerk applying galerking is like uh using Applying the lurking is like using conflict gradient on the southern point problem and applying practical lurking. I take your point. And certainly, these are precisely what I'm saying. I understand. I get it. I mean, this is what by CG sample looks like. Okay, but I'm not sure, though, that I feel more confident because of these conditioning issues. Okay? But I did like the Petro-Galerkin results. I'm not criticizing it. I'm just saying that it looks like s similar to what you observe if you run caleric or better coloring to the southern point problem. Your point is correct, but again, there's no this is this is just what the measures are. Okay, there's nothing really related to indefiniteness in any of this. This is what the error indicator looks like. Anyway, let me. Indicator looks like. Anyway, let me carry on because you'll need more questions. Okay, this was for a fixed mesh. We're 32 by 32 grid. And here's some tables. Okay, so I should have said this before. From here on in, we decide the aggregation, for the control problem, the aggregation method is better. I don't need to compare both of them in a way. Compare both of them in all my tables and graphs anymore for this control problem. Aggregation is better. And I'm not going to say anything about the supreme master for the control problem. Having said that, I will reiterate the fact that for the Stokes problem, aggregation is not an option. So the only alternative that I have, besides the new one, is the Supreme Miser. But for the moment, we won't say anything more about the Supremeiser. Okay, so this is a table showing two tables. First one just showing how these counts and errors depend on the mesh size. Earlier I was showing results for NC in IFIS lingo equal 5, 32 by 32 grid. These are the sizes of the bases for the galeria. Of the bases for the Galerkin method for aggregation and for the stack method. And these are the sizes of the bases for the Petro-Galerkin method, for the two choices of reduced bases. So the sizes are comparable. They work about equally well. And the improvements are about a factor of two in the size of the problem. Now, these improvements, of course, we're very happy to see them. We were very happy to see them. These are still small problems: 125 by 125 direct solved versus 64 by 64. So there's some savings, but it's not, you know, it's not, it's not going to lead to the revolution in computing. These are the results for three parameters. Everything I've shown so far is for three parameters. Here's some results with 10 parameters. Just to see the effect of this parameter. To see the effect of the parameter sizes on all of this. And let's look at this rightmost column, okay, which is the size of, by the way, these all asymptote as the meshes you find, these all asymptote to what I believe is the true size of the reduced bases that we need to find. This is for 10 parameters, and we're not quite in the asymptotic regime here, but we're getting closer. So now the size of the reduced basis is somewhat larger, perhaps in the asymptotic limit 200. In the asymptotic limit 200 versus 65. But the comparison between the two methods are pretty comparable. Aggregation and a stack method. So basis of size 300 versus a basis of size 160, something like that. Neither one has reached as asymptotic machine. These sizes are not as small as one would have hoped, okay? Some sensitivity to the numbers of parameters. A little bit of disappointment here, but on the other hand, A little bit of disappointment here, but on the other hand, let me add one more comment here, which is: I had experience with these ideas for the Navier-Stokes equations, with this idea, the aggregation, with the stack method. I had experience with this. No, I'm sorry, not the stack method, the supreme module. I did a study of empirical interpolation methods by Navier Stokes using this approach, and I accepted the Milk. And I accepted the numbers as this size as me winners. But when the student Kayla came back to me with these high numbers, I said, this doesn't look right. She must have wasted three months trying to figure out the bug in her system until we figured out we were misreading my earlier paper on the subject. And in fact, it doesn't perform that great, okay? Despite it, I mean, actually, I could. Where should I put it? If this is a 2 to the 7th by 2 to the 7th grade, if that number changed to 2 to the 20th, these numbers are still going to be about 200. So it is still a winner in the long run. And I didn't realize that from the previous study I had done. Okay. Now I'm turning to the Stokes equation. I don't remember when I started. Anybody? Started. You've got a five to seven minutes. Five to seven minutes. Stokes problem. Lurking results. Okay? This is, I don't expect you to, we looked at both Puizon flow and step problem to see if anything different came out of them. This is the Galerpin method. Again, now only the supremizer is an option on the earlier methods. I don't like this image. The size of these, the size here is 300. The variability is insane. One thing I'll point, I put it up there because of that, okay? So you can see it doesn't work super well. But one thing I'd like to point out is this black curve, which is the behavior both the black and the light blue of the supreme item. And the light blue of the supremeiser, they're also pretty volatile. This is not in the papers of 2013 and 2012, and it wasn't in my paper from, I don't know, 2016. I didn't see this volatile behavior, and I was surprised to see it, because these are established methods, but I never noticed this before, and I don't know if anyone did. I don't know. Okay? I don't like this result. How do we fix it? How do we fix it? That was for Galurgan. We could use Petra Galergan. That's one way of fixing it. And the other is we can regularize the problem using penalization methods. If I have time at the end, I'll say a little bit more about how we came to this decision, but we decided to try it. Okay? One word about the impact of penalization. It's understood. It's understood, this classic results. David has contributed to this literature. The error that you get when you penalize a system, which has a small parameter echelon in front of it, the error is really under control, at least this version of the error, okay? Sort of the H1 semi-norm of the first variable plus the L2 norm of the second variable, is bounded with the appropriate choice of the penalization parameter. Parameter. If you use Q2, Q1 elements, it's bounded by the same thing as in the discretization error. And it's just a completely standard result. You can look it up in textbooks by Gundsberger, Giorgi, Marriar, other places, okay? Which just says the error caused by the penalization is bounded using the triangle inequality by the error, the discretization error, plus the error obtained by penalization. And one of them is. Penalization. And one of them is the discretization error for Q2Q1 is order H squared, and the error for the penalization is order epsilon. So take epsilon equals order H squared, and you don't lose anything, at least in this global measure of the error. And I put it this way for Q2, Q1, because I like to think concretely, but if you have an error of order H, if you have a discretization with H to the S error, which depends on having enough regularity, then you choose epsilon to be of that size, and you don't lose anything. And you don't lose anything. Well, you lose virtually nothing. Okay, the bottom slides, oh, on the left, I didn't say it, on the right were the condition numbers. Okay, I'll say it now. Bottom two images were from the previous slide. This is the messy thing that I didn't like. And these are the results penalized delivering comparing the different methods. And the outcome, the results, are basically the same. The results are basically the same as what we saw earlier. The stack method for both benchmark problems, Puissile and STEP are better. Performance is better. These are the error indicators. This is incomplete. So this goes to 300, this goes to 250, this is down at around 50, this is like 200. Okay? So adding this penalization term does it. It takes care of it. The I didn't say it before. The condition numbers or the systems for this poorly performing method were on the order of 10 to the 20. Okay, so all off. I didn't like this even before mentioning it. Now the condition numbers are. Last thing, I think. This is. Thing, I think. This is second to last. This is what I just showed: penalized alerkman. This is petroquelurgin. No penalty needed here. Okay? The results are comparable, just like Valeria is suggesting. They're better with petroquelurkin. The conditioning is not too bad here. So we can solve this problem now using these ideas. These are three parameters. For three parameters, here are the mesh-dependent results. There are nothing new here to see. It's a different problem. Stokes equations are different from the control problem, but the conclusions are the same. This is the data for 10 parameters. Again, the supremizer had some trouble, which you would not find in the literature until you're looking critically. Whereas the statue. Okay, whereas the stacked method, the numbers are bigger than we would like. Now they seem to be going down to find their isymplicity. We don't understand everything about that. There's no real difference between Puicelle and Flow and Steppel for the Stokes problem. So that's it. Okay, so let me make some concluding remarks. When both are applicable, we answered this question that was posed by This question that was posed by this group saying, which one is better? We don't know, and we don't care, so we now have an answer to that. Okay, this new method appears to work. It's exactly what Larry, you've been asking about. We just take G and take the snapshots that come out of G and call that our reduced basis. I don't think anyone tried that before. It avoids difficulties associated with insertibility. Associated with insert stability. I don't really understand the algebraic character of the reduced matrices. It suffers from its own stability issues, having to do with other volatility. Galercan form exhibits volatile behavior, which to some extent using penalization, where that's applicable. It's penalization I don't know how to do. For the Soap's problem, I don't know how to do it. For the soapstone. I don't have the duper for the control. And Petrif-Galurkin seems to work pretty well. Maybe there's some issues with L-conditioning for your attention. Thank you, Harold. Questions? What? Anyone on Zoom? Oh yeah. Yeah, it's it's uh it's a curiosity. It's a curiosity. So, when you, as far as I remember, when you choose the two subspaces for velocity, pressure, also to have it stable. And there's sometimes this value in the count that you have to be careful because with the P1, P0, that doesn't work. So, you can't choose the constant pressure and doesn't fall velocity. Typically, you augment. You augment the space for the pressure, but you don't need it for the approximation, only for the stability. So, what is a good option here? Because you construct a nice subspace for the velocity, and then in your static version, you take the corresponding pressure from that solution. So, maybe you have a good approximation for the pressure. But can you just then just augment the pressure part? So, you can So, you ignore subspace for the velocity. You say, okay, this is perfect. And you take the pressure part, and then by some magic trick, or I don't know how, you augment the pressure part. So, will that resolve this problem? Or is it some other problem? I'm not sure I completely understand your question, but let me see if I can paraphrase it. So, what I think you're asking, which is, so we're working only with stable elements. Okay, we haven't looked at anything that requires stabilization. That requires stabilization. But I thought you were asking about having an unstable element that can be supplemented with a stabilization term. And does that help? I think that's what you were asking. I was thinking about when you go to the subspace, I mean, the full finite element space, of course, is a sustainable discretization. But when you go to the subspace, could sure, but could it be that you have lost somehow important components of the pressure? And Of the pressure, and you just augment the pressure of the substrate so that you regain that stability. I don't think that's what's happening here. The place where we're augmenting is in the velocity space. The augmentation that's done up to Stokes is coming from velocity terms. So, I may not have really understood exactly what you're asking, and I don't know if I gave a good answer, but that's what I can say right now. I'd be happy to talk later. Let me just say one. Let me just say one more thing, even though the bell is wrong. We came to this idea of penalization because accidentally, Kayla first tried these ideas for Stokes using stabilized Q1, Q1 algorithms, which worked perfectly. And then I said, well, this is not what we really want to do. Well, this is not what we really want to do. We want to use a stable element, Q2, Q1. And then she got these terrible results. I wrote David an email. I said, Does anyone ever do this thing? Use stabilization. Okay, so, okay, my idea was to add a stabilizing term to an existing stable element. Is there any reason to do this? And David basically said no. We said no. And so we thought about this for a while and said, well, and I kind of came to realize and recall, people do do this for stable elements with penalty terms. These penalty terms are, if you look at the literature on that, they were added in large part to make the problem easier to solve. They didn't want to solve the satellite problems. You add this penalty term, and then you can decouple the velocities and pressure. And then you can decouple the velocities and pressures and solve for the velocities by taking the short complement with respect to this penalization term. That seems to be a big motivation for why this was done. And everyone kind of points out, as long as epsilon is not too big, you're not losing anything. This may be pertinent to what you're asking, Ortho. I'm not sure. We, in the end, don't even talk about this kind of intermediate thing where we use stable. Where we used to stabilize element and everything worked. Yeah, I was just wondering why I used this error indicator instead of like an error estimator that I guess should exist for problems. We don't have an error estimator coded in IPhis. So I use what's easy for me. And having been trained myself in linear algebra. In linear odds or first, before learning all of these ideas, I guess I'm lazy. Okay, so before asking you to thank all our speakers again, I'll just say a few things. So this is the last organised event for today. We'll start tomorrow at 8:45 here at Tottenham Ezeburg. So tonight there'll be dinner served between 5:30 and 7. Between 5:30 and 7:30, back in the place we have breakfast and lunch. After that, so at 7:30, we'll go for a drink. Could you remind me of the building? Yeah, so we have special access to this place where we enter the PDC, the Professional Development Centre on the first floor. There's special rooms set aside for drinking and reading. And so, but whoever's interested. And so whoever's interested, it's not going to be a long session. So the room upstairs