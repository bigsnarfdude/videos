There's a button there and the protector on. And like I had a look, I would be on the protector. I just don't mean back. Oh, yeah, so it's a special case thing with PIR. Yeah, so basically, what it is is, you have to change the. So what it ultimately is, in that case. In that case, you take the PI to the M points inside an M minus one-dimensional space. Then you get something which isn't wireless, right? Different portions of points give you different concepts. So the exact same thing is working based on RTM module. So together we can take a lot of points to both standard basal vectors to I part of the add modulo on vectors and then that gives you or it gives you something that's equivalent to Or it gives you something that's equivalent to it's like if I applied like a little bit chapter three. So we're not like ten minutes. I mean you're trying to get like nine. Trying to get like naive function type conversation for valuable data by support functions. But the kind of conversation we didn't end up having is like nice. We got these things and say okay, I don't I don't think any extracts you don't hear now try to make sure. So here, everything works so that's our style. I stole my file from you when I wrote my first file. Hey, welcome back. I'm happy to introduce Jacob Mathler. He's going to talk about calculate polynomials in mature. Yeah, thank you. So this has been a, let me not stand in front of the thing. This has been a nice conference so far. So yeah, so I want to talk about Poincaré polynomials. So, I want to talk about Poincaré polynomials at some point, but first, let me sort of say some things that many people have said before. So, I'm going to, in the end, talk about the Poincaré polynomials of all of these objects that I have on the right. So, given a matroid, I can associate its graded Mobius object. So all these things are some kind of graded object. I can associate its Chow ring, which we've heard before. There's a variation of this called the augmented Chow ring. There's something called the intersection cohomology of. There's something called the intersection cohomology of the module of the matroid, and you can take its stock at the empty flat. It's not important that you know what these objects are for this talk. Okay, I'm going to get to the, don't worry, I'm going to get to the polynomials, and I think everyone will understand. I just want to motivate. Okay, so to motivate, I'm going to at least say, so all of these are definable for any matrix, and I want to say what they are in the realizable case. Okay? Oops. Yeah. So in the realizable case, I start with a vector space and I have a finite collection of. With a vector space, and I have a finite collection of hyperplanes inside of this vector space, and I'm going to take the condition that the intersection of these hyperplanes is the origin. So, here's an example where I have three lines in the plane, and I can write down the lattice of flats. So, I have the vector space, and you look at all subspaces I get by intersecting these hyperplanes, these lines. So, I have three lines, and if I intersect two of the lines, I get the origin. If I intersect three, I still get the origin. These are all the subspaces I can get. This is the lattice of flats of the uniform matrix of rank 2 and 3 elements. Two on three elements. So the next sort of step up in this class is: instead of three lines in the plane, I have four planes in three space. And I didn't draw the hyperplane arrangement, but here's its lattice of flats. Okay, so I have the vector space. I have four planes. If I intersect two of the planes, I can get a line. There's four, juice, two is six mini lines that way. If I intersect more than two planes, I get the origin. Okay, so out of this, I can build something called the Schubert variety of a hyperplanar angle. Variety of a hyperplanar angle. And this is going to be related to all of these objects I said at the beginning. Okay, so I have the vector space that all of my hyperplanes live inside, and I can quotient by any one of these hyperplanes. I consider this quotient map. And now I take the sum of all of these quotient maps, one for each hyperplane. And this is injective because I am assuming that the intersection of all of these hyperplanes is the origin. Okay? Now a hyperplane is something of co-dimension one, so V mod H is an affine line. So I have a Is an affine line. So I have a vector sum of one-dimensional spaces. And now I'm going to add a point at an infinity for each one of my hyperplanes. So I embed this inside of a product of p1s, one for each hyperplane. I'll put the slides up also. So a definition by Ardela and Bucher in 2016, and now it's called the Schubert variety of hyperplane arrangement, is that you take the closure of this vector space inside a product of P1s. Okay? So just to show you in the first example, just a little bit about what this is. Just a little bit about what this is. So, in the neighborhood of the origin, it looks like the vector space that I started with. And in the neighborhood of the most singular point, infinity, infinity, infinity, it looks like the singular affine cone, the reciprocal plane. Okay? So I won't say much more about this. I just wanted to motivate a little bit. So one thing to say, why is it called the Schubert variety? Well, it carries many analogs to the Schubert varieties inside of flag varieties. In particular, it has like a stratification by affluent spaces, and so on. So, why did I introduce? So, why did I introduce this? Well, these objects are all in some sense related to the Schubert variety. Okay? So, in the realizable case. So, if in the realizable case I have a hyperplane arrangement, this graded Mobius algebra is the cohomology of the Schubert variety. The intersection cohomology module is the intersection cohomology of the Schubert variety. And the stock of the empty flat is the local intersection cohomology at the most singular point. Okay? So now I have to tell you about the chowdering and augmented chowdering, which have appeared in some talks before, but I want to relate it to the super. Some talks before, but I want to relate it to the Schubert variety. So it turns out that this singular projective variety, the Schubert variety, has a nice resolution of singularities given by some specific sequence of blow-ups, according to strata labeled by flats. And this we call, the resolution we call the augmented wonderful variety. So the augmented chowering is the cohomology of this augmented wonderful variety. And the chowering is the cohomology of the fiber over the most singular. Cohomology of the fiber over the most singular point, which is the cohomology of the wonderful forget. So I just wanted to say what these are in a realizable case, but you can define them for any matrix. And now I'd like to say, like, why is it useful to study these objects? And this has appeared in many of the talks before, but let me just, it doesn't hurt to say it again. Okay? So, one thing is that there is this conjecture by Haran, Rotte, and Welsh in the 70s that said, Hero and Rota and Welsh in the 70s had said that the absolute values of the coefficients of the characteristic polyvermatroid form a log and k-sequence. So, this was proven by June Kahn in his thesis for matroids realizable with complex numbers, then by June and Eric for realizable matroids, and then by Adi for Sitoka and Katz for all matroids. And the main point is that this requires some Hadrian relations for the Chow ring. Okay? So, this is one motivation to study these. Another motivation comes from certain symmetries of this poset, this lattice of flats. So, here's the second example I showed you. And if I start comparing the number of flats in complementary rank, I see that this postset is what's called top heavy. So, what I mean is that there's one element here and one element here. One is greater than or equal to one. Okay? Then, if I move Okay, then if I move down and up one level, so if I compare six to four, six is greater than or equal to four. So I keep comparing the number of flats in comparisonary ranks, and I get more on top than bottom. So this was a conjecture by Dowling and Wilson in 1974. It was proven by Jun He and Botong Wong for realizable matroids 43 years later. And then for all matroids, we settled this Tom Brain, Jun Hu, myself, Nick Proud for the Boton Wong. Nick Profit and Botanic. And the key point again is some kind of Hodge theory. It's the Hart-Lefschetz theorem for the intersection cohomology module. So here's a third reason to study these kinds of objects. So there's this notion of the Kaushi-Louis polynomial of a matroid, which I think Nick will talk a little bit about tomorrow. So this was introduced by Benelias, Nick, and Max Wakefield in 2016. So it carries many analogies to the sort of Kajana Moustic theory. To the sort of Kajanoustic theory for Coxaler groups and flag varieties. In particular, it's given by some recursive definition, and this recursive definition has, as one of its inputs, the characteristic polynomial of the matrix. And this has some alternating sign, right, some pluses and minuses. So there's no reason to believe that this thing should have non-negative coefficients. But it does. And the key point is that you can show that this thing is actually the Poincaré polynomial of this intercept. Is actually the point-cray polynomial of this intersection cohomology star. So the coefficients are dimensions of something, so they're not negative. Okay. So I want to give these three motivations. And now I have these five objects. Hopefully now you believe that they're interesting to study. And now, if what I said before, you weren't following, it's okay. Now I'm starting fresh. It's a new talk. Okay. So I'm going to take the Point Grade polynomials of all of these. The Poincaré polynomials of all of these objects. And I want to say which properties these Poincaré polynomials may satisfy. So these have names. And I only learned this morning that Mason called this the Whitney polynomial. This is now called the, oops, this is now called the Chow polynomial, augmented Chow polynomial. This is called the Z polynomial, this is called the Causian Loustig polynomial. And I chose, this is sort of non-standard notation, but I wanted to match. Non-standard notation, but I wanted to match as best possible the corresponding rings, except this one I felt like it was too hard-coded. It should be called Professor Lucy Panama. And I didn't want to call it P because, well, that's hard to remember what it is. Okay. Am I correctly remembering that the letter Z is just? I think so. That's real. I don't know any reason for calling this thing. So here's an example. So here's an example. So for the first polynomial, so the coefficients are the number of flats in each degree of the lattice of flats, the Whitney numbers of the second kind. So for my second example, the uniformation of rank 3 on four elements, I had the vector space at the bottom, four planes, four choose two, six lines, and then the origin. These are these coefficients that want to go. So the first property you can So, the first property you can imagine, well, a very strong property, is that these polynomials might be real-rooted. And this was indeed conjectured by lots of people, and this is what my collaborator Louis Brody likes to call the real deal on matrix, this sort of package of real-lutinous conjectures. The one I didn't include was this Whitney polynomial. And in fact, you can see in the example I showed you, if you you compute the roots, it has a pair of complexes. You compute the roots, it has a pair of complex ones. So, what I'd like to do in the remainder of the talk, 10 or 11 minutes, is I'd like to fill in a table where I tell you, so the rows are labeled by these polynomials, these point-grade polynomials, and the columns are labeled by various properties. So, I have non-negativity, unimortality, log concavity, row-ratedness, and top-rootedness. Okay, I want to tell you what what is known as far as I know. What is known as far as I know. Okay? So, so far, let me explain what I've what I've already, I mean, all of the things I've marked in already, we've already talked about. So, the top-heavy conjecture corresponds to this polynomial, this coefficient being top-heavy. So, that's this. I already told you this counterexample for real rootedness. I said the real deal, I don't know any of this, this is a conjecture. I don't know if it makes sense to ask top heaviness about the Kajaloustic polynomial because it's degree. About the Kazan-Lucid polynomial because its degree is sort of a lot smaller than the rank of the matriarch. These non-negativity, well, they're all Poincaré polynomials. Okay, and this one, these were not defined originally as Poincaré polynomials. They were defined by some recursive, some combinatorial definition, and you can show that they are Point-Current polynomials, that's a result. So, what else is normal? Well, in the first row, for the Poincaré polynomial of the gradient Mobius algebra, it's a conjecture. Of the graded Mobius algebra, it's a conjecture by Rote that it's unimodal and by Mason that it's log and cave. I don't know what to say there. And I don't know what to say about a lot of these. So there are lots of question marks about log and cavity and unimorality. But I left out some places, and I do know some things to say there. Okay? And I'll color code just, I think probably everybody realized that, but I'm color coding respected just to tell you who the results were attributed to. Results were attributed to that. Okay. So I'll fill in these white spaces in the table. So there's a theorem that says that these three, the chow, the augmented chow, and the intersection cohomology module satisfy what's called the Kayler package. So I've talked about a couple of these properties before. So it's point-grade duality, hard left sheds, and hard dream on. This means that, well, they behave like the cohomology of a smooth press. Like the cohomology of a smooth projective variety or the intersection cohomology of a singular projective variety. Okay? So, and it turns out that this top heaviness is a consequence of Poincaré duality, right? So, Poincaré duality means for the Poincaré polynomial that it's polynomial. It means the same forward, it reads the same forwards and backwards. So, it's top-heavy trivially, okay? So, we get these. Unimodality is a consequence of point-re-duality and the Hard-Leftshan's theorem. And let me just The Hard Left School theorem. And let me just kind of sketch how this goes in the next slide. So let's just do an example for a ranked 4 matrix where I have intersection cohomology and I've written down the various degrees. So the Hard Lafschet's theorem for us means that there's some nice element I could multiply by enough times where I can go from the bottom to the complementary degree, and this is an injection. And if I have a map that I compose four times, it's an injection. I compose three times, it's still an injection. I compose three times it's still an injection. Two times injection, one time injection. So the dimension of this is smaller than the dimension of this, so this coefficient is smaller than this one in the concrete bottom. Now I can do it again starting here. Complementary degree, injective, point fewer times still injective. So this coefficient smaller than this one is smaller than this one. But now this has point great duality. So hard left says I have to stop at the middle. So I can't say anything about what's going up here. But point perioduality says the dimensions But point-grade duality says the dimensions read the same forward and backwards. So I know that they go up, then they go down. Okay? So this is how you get unimortality. Yeah? What do those two check marks mean? Yeah, they were proving by both. Independently. So I'd like to say something about this column here, the log and cavity column. So, there's not much known to my knowledge. So, for cosmetic polynomials, it's known for uniform H-rays. And this is some computer algebra system proof. I just read the abstract of the paper. By Xi and John. So, I didn't add anything more to my table. Okay, so now all of my, I just want to survey what is known. So, I'll tell you a lot of results. And I won't add anything to my table because it'll be for some classes of known. My table because it'll be for some classes of nitroids rather than for all nitroids. Okay? But, okay. I'm most interested in real-rootedness because it's the strongest property and implies a lot of the other things in my table. So Newton has a result in 1707 that says if you have a real-rooted polynomial, then it's log-concave. And this is beautiful, and you can show this in a calculus class. It's like the mean value theorem and so on. Okay? And then if you're log-concave with a couple other conditions, you're universe as well. With a couple other conditions, you're using Odo as well. So the mantra is real-rooted, this implies log concavity implies unimodality. I'd really like to solve this, but this is the hardest one. In some sense, I feel like unimodality and log concavity, non-negativity, you know, these kinds of things, at least unimodality and log concavity are some kind of geometric thing, it feels. Real rudeness, I have no idea what this has to do with geometry. Let me tell you about what is known for real rudeness. So, for some uniform matrix, when you consider the cosmologistic polynomial or the z polynomial, up to some number of ground set elements and all ranks that make sense, this is real-rooted. And I think they also use the computer and the computer stoplets input. It's known for some matroids, fans, wheels, and whirls. This is mostly about the Kaiseralistic policy. This is mostly about the causalistic polynomial intersection cohomology module. If we take the augmented Chao ring, this point-ray polynomial, then I have some recent work with Louis Ferroni and Matthew Stevens and Lorenzo Vecchi. And if you build on, this is, you can build on this work about hyperplane stress, hyperplane relaxations, and so on, and matroid valuations. My collaborators together with George Nazer and Ben Schroeder, who's here. And you can compute these bulk-grade problems very fast. These bulkway problems are very fast. And you can show it through a root up to the ground set, number of ground set elements up to 40. Which I think the number of sparse paving matroids with 40 elements in the ground set is something approximately like 10 to the 5 trillion or something. So it's quite a lot. So you do it by an exhaustive computer? Very exhausting. Okay, so I hear the computer. Okay, so I hear the thing, but I see I have four minutes. I don't know why that's. Okay, okay. All right, so I would also talk, I want to talk about some connection to sort of to combinatorics. So Eulerian polynomials are something algebraic combinatorics people really like. So in 2019, Haglin and Jung introduced some generalized binomial Eulerian polynomials and showed that they were real-rooted. And show that they were real-rooted. And it turns out that if you look at the augmented showering of the uniform matrix, intake of point grade as well, then you can show that it's one of these. And you know that they're real-rooted, so you get real-rootedness for this class. Okay? Okay, so we still haven't added any more check marks here. This is sort of matrix class of matrix by class of matroid. Of matriarch, great class of matrix. So, I want to say one more thing, and that was sort of combinatoric, so I want to relate to maybe commutative algebra. So, there's this thing called a Kozul algebra in commutative algebra. I won't say what it is, but it has some nice homological properties. And these homological properties of a Kozul algebra restrict what the Poincaré polynomial should be. And Mastroni and McCullough in 2022 showed that the Chao ring and organization. Show that the chowdering and augmented chowdering are examples of Kozul algebras. And if you combine this with work of Reiner and Welker, they say that if you have a Kozwal algebra plus some other properties, then the Poincaré polynomials are real-rooted, and you have enough control for small matroids to do this. If the rank of the matroid becomes too big, you don't have enough control. It goes on property, it's not enough. Okay, so this is a result for all matroids but small rank, rather than a certain class. A certain class. Okay, and the last thing that I want to say is that, well, we've been very unsuccessful with adding any new marks to this. So let's add a new column where we can say something. Okay? And this new column is going to be gamma positivity. And gamma positivity is some property that, so if you're real rooted, then you're gamma positive, and if you're gamma positive, then you're unimodal. So if you have a gamma positive polynomial, it provides sort of more evidence towards these real rooted. It provides sort of more evidence towards these real-rootedness conjectures. So, what is gamma positivity? So, it only makes sense for palindromic polynomials. So, if I have a palindromic polynomial, I can change, I can write it in a new basis, this t to the k times 1 plus t to the d minus 2k, and I can read off the coefficients in this new basis. And if these coefficients are non-negative, then I call my original polynomial gamma positive. Polynomial gamma positive. And as I said, the main point is that I have the sequence of implications. So, what we do, I've added this new column here. And it only makes sense for polydromic polynomials. And I wrote these boxes here since I won't even consider the question. It doesn't make sense because these are not polyndromic polynomials. Okay? But for the other three, it does make sense. And you prove that they're indeed gamma-positive. And the point here is it's really not so bad. The point here is it's really not so bad once you have other results. So we have some. So before the proof of the top-heavy conjecture, there was a first paper about semi-small decompositions. And there it relates the chowering of a matroid or augmented chowering of a matroid to its deletion. And there's some formula like that. If you take point-parade polynomials, you can take gamma polynomials of everything, and this falls out. Here for the z polynomial, you need some. For the z polynomial, you need some kind of formula for the z polynomial, then release the z polynomial and a deletion of the z polynomial for a deletion of an element. And this is worked by Brayden and De Soberitz. So that's it. Thanks. Does anyone have a quick question, Richard? Do you think this conjecture is true or not? Do you think these conjectures are true or not? The real redundance conjectures? In general. I guess what I'm asking is: how optimistic do you think these conjectures are?