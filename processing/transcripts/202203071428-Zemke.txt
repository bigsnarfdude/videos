Yeah, thanks for the organizers. Thanks to the organizers for putting this together and thanks for the invitation to talk. Today we're going to talk about, yeah, hopefully something, hopefully I can get you interested in kind of relating to areas of papered fluorology, bordered fluoropology, I think people are familiar, and also the link surgery formula. So the link surgery formula of analysts with nochewoth. And hopefully by the end of the lecture I can convince you that it's a worthwhile perspective. So what we're interested in are bordered three manifolds, which I'm not going to be overly precise here. All this is is it's a compact-oriented three-manifold which has boundary and I And I just want that the boundary is sort of a parametrized, is parametrized. And you know, when people talk about bordered free manifolds, it might mean a little more than this, but I guess I just have some diffeomorphism with the standard surface to the boundary, or maybe there's multiple boundary components, and I kind of framatrize each boundary component. And so the most important case for our purposes is Purposes is the case where the boundary is a torus, or maybe a union of tori. Maybe a union of some number of tori. And in this case, the parametrization for me is just going to be a choice of an oriented basis of homology. It's just a choice of an oriented basis. I'll call it mu lambda oriented basis of maybe H1 of T2 with respect to the boundary orientation. If you have multiple choroidal components, it's just a parametrization of each boundary component. Okay, so the story, I guess, goes back to the I guess goes back to the program of Lipschitz, Brunhoff, and Thurston. And to a bordered manifold M, bordered, let's say M, boundary is F, they assign an algebra to a. Let's just say A. So there's an algebra, which I'll just write as A. I'm not being very precise here, but it's okay for our purposes. And they assign modules over this algebra. And basically, they're just A infinity module. And there's two, there's CFD hats, which takes the form of a type D module, which is just kind of like a. Which is just kind of like a projective module in the sense of A infinity modules, but it's just a certain type of A infinity module called CFP hat. They also construct a type A module, which is, they call it CFP hat of M. Oops, sorry, I really want the A on the other side. And that's just an A infinity module in the sense, in the normal sense of the word. And they prove a pairing theorem. They prove a pairing theorem. So, the goal is to compute Hagard Floor homology of three manifolds, of closed three manifolds, or that's one of the goals, I guess. And so, what they prove is that they prove a pairing theorem. So, if I glue two bordered manifolds, let's say that I glue them along their surface, consistently with the parametrizations, they prove, let's just say, hf hat of Of M union F glued along F is some sort of A infinity tensor product. Maybe I'll say C I've had. It doesn't really matter. And this is some A infinity tensor product of maybe M. And there's some notion of what this A infinity tensor product is. If you're not familiar with it, it's not overly important for the beginning of the talk. But there's some. Beginning of the talk, but there's some, you know, they have these modules over this algebra A, and there's some special types of modules. We'll talk a little bit more about what these are, type A and type D, but there's some sort of A infinity tensor product between them that gives you the fluorohomology, the glued manifold. And so CF-HAT is sort of this weakest form of Hager fluorhomology, or it maybe contains the least amount of data. It's just basically a It's just basically a vector space over F2 or a chain complex over F2. And, you know, at the moment, they are kind of working on, you know, in progress, they have this program to do the bordered HF minus theory, which they have, you know, produced some papers on already, and they're working on some at the moment. And it computes ZF minus of the glued manifold in terms, in the case of the tutorial. In the case of the two torus, the kind of maybe the simplest algebra or the simplest surface you could think about gluing along. And there's some sort of version that they will write down probably soon. And they have some algebras. They've written a paper on the minus version of the algebra. And so this is kind of where their program is going. But that's in progress, and this is like fairly. But that's in progress, and this is like fairly technical work, even defining the algebra. Even though it's a very rich theory, it's also very technical and fairly challenging to work with. And so I guess today I'm going to tell you about maybe another perspective on how to define a bordered invariant in the case of toradal boundary. And I'll give you some examples and hopefully illustrate the utility and maybe advertise it as something to think about. And so the perspective I want And so, the perspective I want to think about is surgery. And so, you know, before we talk about modules and algebras and stuff, I want to tell you the relation between surgeries and gluing border manifolds. And there sort of is a very basic topological relation or topological description which takes the form of Which takes the form of a description. Here's a topology. And this, let's suppose I have two framed knots in S3. Let's do the simplest possible case. So k and k prime are knots in S3, and let's say they have framings, just integer, integral framings and prime. And what I want to tell you is What I want to tell you is that actually the surgery, maybe this is old news to people, but the surgery on the connected sum of 20, let's say it's the n plus n prime surgery, this is actually the same as gluing the complements of k and k prime together by a particular parameterization or a particular identification of the boundaries. Identification of the boundaries. And the parametrization or the way we glue is we send the meridian of k to the meridian of, oops, this is a k prime here, of k prime, and we send the longitude with respect to these framings to minus the longitude of k prime. And this is actually, you know, this is actually not very mysterious. You can kind of just draw. Mysterious, you can kind of just draw a picture and kind of convince yourself of this pretty quickly. And I would like to do that because it's kind of, I think it's instructive even if it's really basic to understand it. And so, what we're going to do is we're going to start with the complement of the connected sum. And so, let's say. And so let's say I have k over here, and I've kind of drilled out the complement here. And we're going to go over to K prime here. And I've drawn, you know, I'm trying to draw the complement here, and we've taken the connected sum of them. And so most, I think everybody, well, it's very easy to see that this is obtained by gluing, right? By gluing S3 minus the neighborhood of K to S3 minus the neighborhood of K prime in a way that sends the meridian, you glue along an annulus. And so kind of, instead of gluing, maybe it's easier to see in this picture that you can cut this picture along an annulus like this that goes through infinity into intersex. And it intersects kind of the connected sum and two points, or intersects the complement. If I glue it at infinity, I get an annulus. And if I cut along this annulus, I just get the complements of the knots. And so kind of, you know, going backwards, gluing them, you're just gluing the meridian to the meridian. And then you think about what it means to do Dean surgery. And you're going to attach a disc. Attach a disk, a disk that kind of follows maybe the concatenation of lambda prime and lambda. And if you think about what it is to attach a disk, well, that's kind of the same thing. I could, instead of attaching a disk, I could just kind of glue these pieces together. So I'm just gluing the longitudes together, and then all I have left is a three-ball. And then all I have left is a three-ball, and I glue that in. But you know, if you think about it for a moment, you can convince yourself that this is the same thing as just doing exactly this gluing diffeomorphism here. So that's kind of a basic topological manipulation that says that, you know, if you want to understand bordered invariants, maybe it's sufficient to understand invariants or surgery formula. Variants or surgery formulas and how they behave under connected cell. Any questions? And so this, I guess I'm starting to erase it. This, of course, is just for knots, but if you took link complements too, same argument works. If you take the connected sum of links and serge around one component, that's the same as gluing the complements together. Okay, so I guess the new approach that I'm advocating is to use this Manolesco-Oujva and I guess Ojva-Salvo surgery formulas. Maybe I should have switched the order, but surgery formulas. Surgery formulas and understand how they behave under connected sound. And I guess the surprising thing is that you actually just get a border theory when you do this. You get all the sort of things you would hope that a bordered theory would satisfy. And so hopefully I can illustrate the things I've been thinking about and the applications that I have in mind. So I guess, you know, Ojo Al Panzabo proved a not surgery formula, which is proved a not surgery formula which was generalized by Manolesko and Ozvoth. And so given, so I'm going to focus on talking about the Manolesko-Ozhvoff statement of things. But given a link in S3 with the framing, integral framing lambda, what they construct is a chain complex C lambda of L. This is called the link surgery formula, and it has the same And it has the same homology, I guess, as hf minus of this surgery manifold. Sort of a formula that computes the surgery. I mean, maybe that's not that interesting if you know nothing about the theory, because, of course, just the actual complex itself computes that itself. But the practical, the applications or the kind of the importance of this formula is that it has a very, you know, has a very strong, it has a very strong structural relation. It has a very strong structural relation. So, understanding this formula can tell you a lot about the Hingerd fluorhomology of surgeries. And so, this chain complex, I'll say a little bit about it. C lambda L is what we call hypercubic chain complexes. Which just means that it has a filtration by points of the cube. And I guess I'll say it's L-dimensional, well, where L is the number of link components. And that just means that it kind of decomposes. Just means that it kind of decomposes, it has this kind of structural description in terms of a cube. And so if it's one-dimensional, that means I guess I'll put the subscripts here. C0, well, this is the case of a knot, it's kind of just a mapping cone from C0 to C1. So it kind of decomposes into two chain complexes and then a map between them. And if L is two, it has. Up. And if L is 2, it has a sort of stronger, maybe it looks like this. It kind of decomposes over the points of the cube. And you can have maps incrementing as many components as you want, but the arrows can't go backwards in the cube. Like, there's no arrow from here to here. They just kind of increase the cube indices. And what does this actually mean? So, to filtration, basically, the hypercube relations, maybe I'll also indicate, there can be internal differentials to these complexes as well. And the hypercube relations actually just amount to saying that if I sum all the differentials of the complex, then I get a chain complex. Usually people write it a little differently. Write it a little differently. They'll say that if epsilon and epsilon prime are points of the cube, they'll write d epsilon, epsilon prime for the map from c epsilon to c epsilon prime. So they'll write it like this notation, or this is Manela Ska Ousbaup's notation, and that you can that you can decompose, you can rephrase this condition as saying that the sum, kind of over increasing sequences like this, for a fixed, if epsilon is less than epsilon double prime are fixed, then you kind of sum all the ways of breaking the arrow from epsilon to epsilon prime into two arrows, then you get zero. So that that's kind of the structural structure of a hypercube. Okay, so the first thing I want to tell you about before we talk about bordered whatever is just bordered algebras and type D modules and type A modules is just a connected sum formula for the link surgery formula. So before we interpret things as algebras and So before we interpret things as algebras and try to advocate this perspective, let me just state the connected sum formula for the linked surgery formula. And as we described, this could be thought of as a way of gluing complements of manifolds with toriedal boundary. Okay, so maybe before I state the formula, the connected sum formula, I need to tell you a little bit more about. Some formula, I need to tell you a little bit more about what these are for the link surgery, what these complexes are. Maybe, let me just give you a little bit more background just so we can state the link surgery formula. So, C0 of L, so kind of the highest point of the cube, this chain complex is just isomorphic to a version of link florhomology of L. And this version of link florhomology is the one where you take a Hagar diagram. The one where you take a Hagar diagram, sigma alpha, beta, WZ. And so it has two base points for each link component. And what you do is it's kind of the free epidoint U1, V1, UL, VL module given generated. Being uh given uh generated by the intersection points of the alpha and beta toleri. So this is what C0 is, the highest point of the cube. So it's going to finitely generate it over this ring. And then in general, C epsilon of L for a point epsilon that's farther up in the cube, it's going to be a low. To be a localization of CFL L at some of the V variables. So I kind of formally invert these variables to get the higher points in the cube. So that's the chain complex. And before the last thing I need to tell you about before I tell you the About before I tell you the connected sum formula is that the maps, these maps kind of decompose nicely. They have an additional structural relationship. So the differential of the slink surgery formula decomposes over kind of over the cube. It's filtered with respect to the cube, but it also has. Respect to the q, but it also has an additional structural relation. So each d epsilon d epsilon prime decomposes further. So what I can do is I'll say, I'll define a link, I'll define m sub epsilon, epsilon prime. epsilon prime to be a sublink of L consisting of all components which are incremented which are incremented. So each axis dimension each each axis direction corresponds to a link component of L. So if I take two points of the Q, I kind of get a Q, I kind of get a, I can think of, you know, the set of link components which are incremented and going from epsilon to epsilon prime. And then d epsilon epsilon prime decomposes as a sum over the orientations of n epsilon epsilon prime. epsilon epsilon prime. So if you know I increment L, if I increment, let's say k components, then this d epsilon epsilon prime maps is a sum of 2 to the k maps, corresponding to the orientations of the sublink which is incremented. So usually for v and negative maps. Yeah, so like v usually is the positive orientation and h conventionally is the negative orientation. Yeah, so for the non-surfery formula, that's right. Alright, so now I can state the connected sum formula for the link surgery complex. So let's say I have two links with special components K and K prime. So I have a link L and I have a link L prime, and these have And I have a link L prime, and these have framings lambda and lambda prime. And they both live in S3. What I can do, what I'm going to do is I'm going to look at this link surgery formula for L and I'm going to think of the cube, this L dimensional cube, as the Cartesian product of an L minus one dimensional cube in an interval. And so algebraically, this corresponds to viewing this as a mapping cone. Let's say. Let's say C, let me say C lambda 0 L to C 0 lambda L. And this will be, in this notation now, this is going to be an L, each of these will be L minus one dimensional cubes. And this corresponds to the subcube where all of the ind, where, of all points in the cube where the In the cube where the index for k is 0. Oh, oops, this should be a 1. And this is the L minus 1 dimensional cube where all points where the component of K is 1. And I can decompose this map as a sum of two maps. Sum of two maps. And of course, you know, I have some internal differentials as well. And the plus map is the sum over all sublinks which contain k with positive orientation. So I'm kind of ignoring all of the other not components, and I'm just kind of thinking of it in terms of k. And phi minus is the sum over all maps of the cube where the orientation of k is negative. Of k is negative. And then internally to each of these l minus one-dimensional cubes, I'm going to sum all the maps where I don't increment k at all. Okay, and so I can do that also for L prime. I can decompose it as a cone, just doing the same thing. But for L prime, and I'll write that phi plus prime plus phi minus prime. Prime plus C minus prime, sorry, zero, C lambda prime one, L prime. Okay, and so the connected sum formula The connected sum formula is simply that, well, what I'm going to do is I'm going to write c lambda plus lambda prime of the connected sign. So that kind of looks a little strange, but what I need to do Little strange, but what I need to do is to add the framings on K and K prime. I add those framings, they're integers, I just add them. And all the other, those are the special components where I take the connected sum. And on all the other components, I just inherit the framing from either L or L prime, and I don't do anything to them. And so I can also decompose this, you know, as a mapping cone over this special component, k connected sum, k. K connected sum, K prime. And the theorem is that this is the tensor product. It's a cone of the tensor product. I guess I haven't left a lot of room. Maybe I'll write this on the line below. This is cone of C zero lambda L tensor C zero lambda prime. C zero lambda prime L prime going to C one lambda L tensor C one lambda yeah lambda prime L prime and this is just you tensor the plus maps together and you tensor the minus maps together. And these tensor products, this one is over f adjoin UV, and where these are the variables for this special component, and this one I guess is over f adjoin UV V inverse. And so there's kind of and so you tensor these hypercubes together, so when you tensor them, each of these will So when you tensor them, each of these will, this will be maybe L plus L prime minus two dimensional. And so there's kind of multiple things going on in this picture. You know, this whole thing itself is a hypercube, an L plus L prime minus one-dimensional hypercube. And so there's some, you know, to translate this into, you know, more explicit, the differential on this This has an internal differential now, and the internal differential is kind of the external tensor product. Like, there's no interaction between L or L prime in this component. And so basically, it's just, you know, del, maybe I'll write, you know, del tensor, del tensor identity plus identity tensor del. And the same thing is over here. Like, this is, this tensor product is a hypercube. You probably called. You probably call this the external tensor product because there's no interaction between L and L prime here. The interaction between the two links just occurs in this map here. And the relation is you sum the positive and you sum, or sorry, you tensor the positive maps and you tensor the negative maps. Any questions? Could you say Oh, could you say when you localize, like I see how that kills the filtration, in the same way that you're sort of forgetting the filtration and the typical surgery formula, but why does the sort of map, the natural map from the complex to its localization correspond to the inclusion of subcomplexes that and Leskin considered? Yeah, so there's a couple points here. So, yeah, maybe I'll just talk about some Yeah, maybe I'll just, I won't talk about so much what, maybe I'll just, as an example, I'll talk about the Auschwitz-Sabo, the case of knots, because maybe that's a little easier. And so, you know, just as an example, so an example would be like for knots. And so, you know, And so, you know, Uttwald and Zabo, they wrote, and experts are probably very familiar with this. I'm sorry to anybody who's not familiar. But Utwalth and Zalbo proved that the surgery formula, if I wanted to do N surgery on K, this is a mapping cone, and they have two maps, V plus H, and H depends on the framing. And so A is actually, most people think of it as the direct sum or the direct, I'm going to just ignore completions completely. So let's say the direct sum over ASK. But if you're going to ponder this for a moment, this is just the sum over all, you know, each of these is actually, you know, kind of A sub S is isomorphic. actually, you know, kind of A sub S is isomorphic to it's just actually isomorphic to the subcomplex of C of K in Alexander grading S. So then when you take the direct sum of all of them, you just get CFK of K. And B sub B of K is I mean, with respect to this picture, if you translate it to B of K, B of K is kind of a direct sum of modules which don't depend on S basically, but if you ponder them, basically this is just isomorphic to the localization at V of C of K. And kind of, you know, the subcomplex in here at Alexander grading S does depend on S, but just kind of in a trivial way because there's a canonical Trivial way because there's a canonical isomorphism between different Alexander gradients, and that's just multiplying by S. Sorry, what? Multiplying by what? Sorry, sorry, V V. Sorry, multiplying by V or V inverse. Thank you, not S. V or V inverse. So, and the map that just is the inclusion of A S into B is just actually the inclusion of C of K into its localization. That's V, but that's not. That's V, but that's not H. H is a little bit more complicated. And you can also just bet in these terms? Yeah, so H is, it's more complicated, but H, so for H, H is the inclusion into the localization at U followed by some isomorphism. Thanks. And so, you know. And so, you know, kind of the position I'm advocating is, you know, part of this position that I'm advocating, is that we should be thinking of these not surgery formulas in terms of just this total knot floric complex, this one with the curly things on it, denoting the free complex over F adjoint UV, because a lot of algebra can be encoded pretty nicely in this world. So that's the connected sum formula. And And so, this is an important thing. And when you stare at this, you should hopefully think that this, the natural goal is how can we interpret this as an A infinity pair or some sort of tensor product of A infinity modules. And so now I'm going to kind of go in that direction and try to show you how to interpret this as an A infinity pairing. Any questions? Any questions? And so to describe how it's an A infinity pairing, I need to tell you about an algebra. And so this is just an algebra. It's not a DG algebra. It's just an algebra. And I'll call it K with a script font. And so it has two item potents. And so it has two item potents. So it's an algebra over this item potent ring, I0 plus I1. And you should think I0 is basically the A's, and I1 is basically the B's, if you are familiar with the surgery formulas. And so I0, you know, kind of usually we, with these algebra, we'll kind of Kind of usually we, with these algebras, we'll kind of tell you what they are in each item potent. And so the algebra elements which fix this, you know, which preserve the 0, 0 item potent, this is just going to be, you have to join uv with the standard multiplication. And then I impotent, let's say we go from I1, maybe I'll do the most actual thing, I1, K, I,0. So the things that go from 0. So the things that go from item potent 0 to item potent 1, there's kind of two special generators here. So you have these algebra elements, uv inverse, and they can be adjoined with one of two algebraic elements. So I have a sigma algebra element and I have a tau algebraic element. And the special So basically, I'm going to call out these polynomial guys and, you know, polynomials in u and v and now v inverse, but the v inverse has to be on the left side of sigma and tau. And then I also have, I guess I'll say, I1, or going in the opposite direction, there's nothing that goes with item potents reversed. And then finally, I1k I1. I1 is uv V inverse. And now, this is an algebra. I mean, I haven't told you all the relations, but here's some generators for an algebra. And I'll tell you the relations. So the relations in this algebra, I mean, so multiplication in 0, 0, I put in 0, 0 is, you know. 9.00 is, you know, sorry, this is a 1. It's just ordinary multiplication, same as here, but it's kind of interesting in here. And so, you know, I have these two maps, maybe I and T, and they go from these two kind of algebra homomorphisms. And so I is just the inclusion. Is just the inclusion and t is more complicated. So t of u is going to be v inverse and t of v is u v squared. And so the relations in the algorithm. And so the relations in the algebra are just that if I take something, if A is in, you know, let's say K0, oh sorry, sorry, I 0, K I 0, the relations are just that sigma times A is this inclusion times sigma and tau times A is kind of this weird homomorphism T. Homomorphism T of A times tau. And so the weird homomorphism maybe is, you know, maybe these algebra elements should be kind of evocative of the actual surgery formula. So a sigma, you should think of this as being the B algebra element, and this is kind of the H algebra element. Okay, any questions? Come on the and so maybe this formula looks very strange, but it's kind of motivated by the actual H map itself. And so I can draw these as quadrants. So maybe this is like I0, KI0, kind of F adjoin UV, I draw. kind of f adjoin uv I draw those as you know this points in this quadrant and then maybe this is I1 or sorry let's write it this way so I f let's just call this f adjoin uv and then this will be the f adjoin uv the inverse and so kind of you know the way that you get this map t is what you do is you first include you do is you first include f adjoin uv into f adjoin u u inverse u u inverse v. And then, and so that sort of is like this upper half plane. Maybe like this axis is the u direction, this axis is the v direction. So, you know, point here, this might be like v to the one or something. And then this would be like u being here. Like UBR. And so what this homomorphism does is, what T does is it's basically just like the H map. In nuclear homology, you first include this kind of quadrant into the upper half plane. And then what you do is you look at the unique map which kind of preserves Alexander gratings. And this is the unique map which preserves Alexander gradings, preserves Alexander gradings and is an isomorphism of f adjoin U with this kind of different U modules. modules where this new u is just the product of u and v. So this is basically it's just the H map from the not the not surgery formula of Oschloff and so forth. So we have kind of these anyway so that's the algebra. These are the two maps in algebra. Okay, so um I'm gonna Okay, so I'm gonna try to hopefully build up to tell you how to interpret the connected sum formulas in A infinity tensor product. But first, I'll just tell you like the modules, the examples of modules in this. I'll tell you, let's see, I'll tell you what the module for a solid torus is. Way to describe it like a I mean it's not quite the like type D or type A module. Quite the type D or type A module, but basically, yeah, I don't know. I mean, I don't know how to say it's just equal to the invariant of the unknown, but basically it's just that. I mean, if you look at the link surgery picture putting in the picture chocolate, you get that. I mean, it's basically that, but it's not it's not actually equal to it. But it's not actually equal to it. But that's basically what it does. I mean, the module for the unknob looks very similar to the module for the algebra itself. I mean, they're not quite identical. So I'll tell you what, here's the type A module for the solid torus. So here's the type A module for the solid torus. And you know, the solid torus is the complement of an unknown. So it's the same thing as a So it's the same thing as the surgery complex for the unknot. And so let's say N-frame solid torus. So I guess I'll call this F, not T, but F. So Fn, and this will be a left K module, so left type A module over F, and basically module over F. And basically, you know, in item potent 0, F is just isomorphic to F adjoining UV. And in item potent 1, in item potent 1, this is alpha join u, the inverse. And you have an action of the algebra. You have an action of the algebra. And so you have actions of algebra elements which preserve the item potents, and those kind of act in the obvious way, just multiply. But then you also have actions of sigma and tau which change the item potent. And so sigma acts by just the inclusion, and tau acts by v to the n times this map t. And so this is kind of the unknot comp comp. This is kind of like what you call the type A module of the unknown. So it's pretty simple. And I'll tell you how to get the type D module for a NOT, K. Maybe we won't go into all the detail of how to get the type, you know, to do the full, I won't do the full link surgery formula. I won't do the full link surgery formula as an example, but for a not K, let's do type D of a not K. So I'm going to write this as X and K, and it'll be a type D module over K. And what you're going to do is you're just going to pick a free basis X1 through Xn of this. Of, this will be a free basis over F adjoint UV of the not floor homology, or the NotFlur complex of k. And so I have basically delta one of this module, it's basically, it consists of three types of arrows. So I have kind of, I'll say it's the ordinary differential. Of, oh, I forgot to tell you the generators. So, xmk times I0, these are all actually just isomorphic to the vector space spanned by these elements. So, this will just be kind of the span of x1 through xn over f. And the same thing holds in eigenpotent. Important. One is just the both the span of these vectors, but they're disjoint. Like, I1 and I0 are just different copies of this. And so usually I would write, usually what we'll do is we'll write like these will be maybe x10 through xn0 and these will be these copies will be x11 through xn. Through x and y. And so we have the delta 1, this type D structure map has three types of sum in. We have the ordinary differential from C of K. We have an extra sum in, which is like X I 0 maps to X I 1 sensor sigma. And then And then we have another term, which is, or maybe I should say, this has this element in its sum end. And then basically, tau is like the H map. So maybe I'll just write here, like, if UI VJ Y is in the H map, H n is a sum end of H n of X. of h n of x i then you just put a sum end of ui v j tau sorry then y tense oh oops let's say yeah maybe I'll put this x i it's not so good let's do x n and m oh n's already taken let's say s and t then Then, and let me not call this y, let me call this x sub j. So then x j 1 tensor tau u s v t tau is a summand of delta 1. Okay, so that's how you can build a That's how you can build the, and it's that's how you build the type D module for a not. And there's a similar recipe to build the type D module of a length. I'll tell you a little bit more about that. And hopefully at the end, hopefully I can just give you some examples and some more things that I've computed to illustrate what these things look like. But this is the recipe for a knot. And as an example, if one ponds And as an example, if one ponders this for a moment, you can ponder that Boschwatt and Savo is not surgery formula. So Xn, this will be, let's say, this will be their not surgery formula. This is the tensor product of these modules. Let's say x. Let's say X and K tensor box tensor with this module F, and let's give it framing zero. So that's how these are related. So usually the type A modules are large, but the type D modules are small. You know, in this case for the not, the type D modules are just finite vector spaces. And so, I guess, let me just, I'll say this. We won't, so more generally, what you can construct is for a link, there's a type D module X lambda of L. And this is a type D module over the tensor product of L copies of K. So there's a type D module over the tensor product of L copies of K, and it's related to Banelesko-Orshbaugh's links to retreat formula by a tensor product. So So X lambda L tends to rub it. Oops. So L copies of K. Sorry. Let me write it this way. So the original analysis of Ojib King surgery formula is a box tensor product where you tensor in all of these All of the type A modules for solid tori. And let's say we give them framing zero. Oh, no, yeah, A, yeah. So you tensor a tight, torrent, you tensor that module for a solid torus into each of these algebra components. So you do this into each of these. And so that's just how they're related. And this, yeah, so now how do we interpret the connected sum formula as an A infinity tensor product? Well, that's by a new module, which I'll call the, there's a merge module. This is kind of how you talk. This is kind of how you turn a type A module into a type D module. And so, what this takes the form of is it takes the form of a DA by module like this, where you have two K inputs and one K output. And as a vector space, M is just isomorphic to the item potential ring I, or as an I module, I guess. I guess on the left side, you have both. I guess on the left side you have both the eigenpotents for k and k prime act the same way on the on the vector space. I, and you have kind of, you have several, you have a delta 21. So if I take a tensor b and k tensor k and I act on some idepone i in the ring, that just gives me i tensor their product. Are their product if, let's say, A and B are concentrated in one item moment. Sorry, delta two one. So I have one algebra input and one module input. And then there's a delta three one, which there's kind of two special terms. So you could do sigma tensor one, one tensor. tensor one, one tensor sigma. And this sends I0 to I1 tensor sigma. And there's also a delta three one of tau, tensor one, one tensor tau, and it goes to I one tensor tau. And then you know there's some other relations if like you have a sigma multiplied by some algebra. Sigma multiplied by some algebra element a, but these are kind of the fundamental ones which determine the module. And so we can interpret the connected sum formula in another way. So the connected sum formula is another interpretation that it just says that if I want to interpret the interpretation That if I want to take the link surgery of L connected some L prime, and this will be kind of a tensor product over maybe L minus or L plus L prime minus 1. Copies of K, this is isomorphic to a different tensor product. So I can take the link surgery, sorry, the link surgery take D modules. The link surgery take D modules, and they'll just take their external tension product over F. Oops, I've run out of room. But what I'm going to do is I will just box it with this merge module, which has two algebra inputs and one algebra output. And, you know, this merge module does have a topological interpretation. You know, if you go further in the theory, it turns out that it kind of almost topologically turns out to be basically the DA by module for a pair of pants times S1, which is topologically another way to describe kind of taking the connected sum and gluing two complements together. But so that's one perspective. I think I have five minutes left. Left. So, you know, at this point, I'm just going to give you some examples, I think, just to illustrate what these look like. I'll just give you, and, you know, I can't tell you all the examples, but I'll just tell you, like, you know, mostly just some fun examples and then we'll wrap up. So I'm just going to tell you what the solids ori are, and hopefully of all parameterization. Of all parametrizations. And hopefully, like, you know, this can inspire you to, or maybe, maybe this will be at least convincing enough. So, and I'll do the type D modules. You know, I mean, so far this is just totally abstract. But the thing is that, you know, what I'm not really going to have time to do is try to communicate that for a lot of applications, there's a lot of things you can do practically with this. Things you can do practically with this. It's like, although sometimes you have to deal with infinitely generated modules and there's some complications associated to that, often the outputs are very natural algebraically. So if I take an n-frame solid torus, the type D module, the n-frame solid torus is just the complement of an unknot. The type D module has two generators. And I just have two different, I have kind of two terms of the differential. I have kind of two terms of the differential. I have sigma and I have e to the n tau. It's not too complicated. So kind of what you're doing is you're just computing the knot floor complex of this knot. And I'll think of this as like an outgoing component. Another thing that you could do is look at the infinity frame type D module. And if you think about this, this is like you have a non- This is like you have a knot inside of S1 times S2. You have the fiber, I guess of the knot. If you think about the complement of this, this is also a solid torus, but it's like an infinity frame. Like you want the thing that doesn't do anything when you tensor it in. And so you might ponder algebraically, like, how do you transform the not surgery or the link surgery formula to one where you just delete the link completely? And this turns out to be exactly the algebraic thing that you would expect to do. thing that you would expect to do. So basically what you do is you have, so I0 times, I guess we'll call this x. So I'm using the type D module. So okay, let's say if I, in item potent 0, you just don't do anything. It's just 0. And then in item potent 1, you just have two generators. And the differential is just. And the differential is just 1 plus v. So, like, you're just taking, basically, all you're doing is you're forgetting about item potent 0, and then in item potent 1, you're just potentiating by setting v equals 1, which is exactly algebraically what you would expect. And then I can tell you what the p over q frame solid torus is. And it turns out that the p over q frame solid torus is exactly the rational surgery formula of Liz Baukonzavo. And so, all of these things, I guess this one is maybe a little bit more complicated. So, let's see, so this will be like P over Q, which I can think of as like doing zero framed naught component, and then I do like minus Q over P surgery on a meridian. And if you do, the way that you compute this is you like do, you know, you do, well, you compute the Huffleng, which I didn't get taught. Well, you compute the hops length, which I didn't get time to tell you about.