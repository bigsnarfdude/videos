Yeah, thank you so much. Welcome from Cardiff. Thank the organizers for setting this up. It has been a long time, postponed several times, so I'm happy that still it's finally taking place. So today I want to speak about some classical hypersurface theory, namely everything around the Alexandrov constant mean curvature problem. Of constant mean curvature problem. Just as a warm-up, let's recall the behavior of soap bubbles, like pictures that we know from our childhood. If you have a closed soap bubble and you bring it out of shape, then usually it wants to bounce back quickly to a perfectly round shape. And the reason for this, sorry, just a second. Oh, sorry, just a second. There's a rough reason for this. Namely, you can set up like a physical model, like a very, very basic model. The total energy stored in the system is basically given by the surface tension coefficient and times the surface area. So you can treat the surface tension coefficient basically as a constant of the system, like of the ambient space, for example, the air pressure and temperature. For example, the air pressure and temperature, this all will go in there. So, what you in the end want to minimize is the surface area. But you also have unit volume because the soap bubble is closed, so the air which is enclosed by the soap bubble won't change. So, what you're actually solving here is the isoparametric problem that you're trying to find the shape of the closed surface, which minimizes surface area given fixed volume. So, in mathematical terms, we have this. In mathematical terms, we have this ratio R, which is area to 3 over 2, divided by the volume, which is a scaling invariant quantity. And it is minimized precisely by every round sphere in the Euclidean space. And you can show by standard variational methods, this is like an elementary differential geometry exercise, that every minimizer of the isoparametric ratio has constant mean curvature. Has constant mean curvature. And by mean curvature here, I simply mean the trace of the second fundamental form without any take any average averaging. Just the trace of the second fundamental form in this talk is the mean curvature of a surface or hypersurface in ambient space. So once we know this property of minimizer, it is of course natural to ask, can we conclude from this constant mean curvature property? From this constant mean curvature property, what can we conclude from that? And this is like a famous question which was posed like probably, I think, more, at least more than 150 years ago, whether closed embedded CMC hypersurface must be around sphere. And in the 19th century, there has been lots of progress towards this under additional hypothesis. For example, you can impose convexity or star-shapedness. Or star-shapedness or rotational symmetry, and many people have contributed to this problem. But the final solution to this plain question here was given by Alexandrov in the 60s, 1960s, and the answer is yes, and nothing beyond that. It's simply yes, right? And the method by Alexandrov was a very nice combination of PDE techniques with geometric techniques, right? With geometric techniques. So ideally, there was a like in every direction, you put the plane, you start from the tangent plane, move it inwards a little bit towards your, so if here's your domain somehow, you have a tangent plane, you move it inwards, and then you reflect the piece that is on the other side, you reflect it inside until it touches the other end of the boundary. And because the CMC property is And because the CMC property is a geometric invariant, if it touches, it has to be, by the maximum principle, it has to be equal in a neighborhood. And since this is true in every direction, it has to be a sphere. So this is a very nice PDE proof of this result. And today we are going to see a very different, elegant proof by integral methods, which goes back to the 80s and Antonio Ross and the Heinz-Karsh inequality. The Heinz-Causer inequality, but I will come to that later. So, we are going to see another proof today. What I want to talk about actually today is the stability of this problem. Namely, especially in physical experiments or in real life problems, you will never encounter, or almost never encounter, anything that is CMC on the nose, right? It has a pointwise CMC property. So, it is important. So, it is important to relax this condition, and we are going to relax it in the following way: namely, we are assuming that our mean curvature is within the margin delta of a constant, let's say n. Okay, we are always here, we are working in Rn plus one. So, the standard sphere would have mean curvature n, and hence this is our model configuration here. And we assume. Configuration here, and we assume that the mean curvature is within this delta margin of the value n. And we are asking the question whether we can conclude that the surface is closed. So I call this surface here Earth because I used to motivate it with the question whether our Earth is close to a sphere. Whether our Earth is close to a sphere, given that it's not exactly CMC, but almost CMC. So you can imagine we have a bumpy surface of the Earth, and we are asking whether this is close to a round sphere by giving ourselves an error delta. And the estimate to the sphere should be in terms of an error epsilon, which depends on this delta here. Depends on this delta here. And there will be a constant involved, which I will comment on later, which we allow to depend on geometric data of the problem. Okay, so this is the question. And in the plain sentence, the question is now whether a closed, embedded, almost constant mean curvature hypersurface is necessarily close to a sphere. And here, of course, we have to specify. And here, of course, we have to specify what we mean by these terms here: almost and close. So we have to fix some topologies on the curvature side and in Rn, where we are going to use the Hausdorff distance mostly. So here's an answer which was given recently. There are many other contributions, but the result by Magnanini and Poghesi comes closest to what we are going to see today. See today. So I'm simply stating their results. There are many other people like Gierolo Vazzoni, who did the quantitative, the Alexandrovov proof. But here is a proof which is based on integral methods. And the result here says that if you have a sufficiently smooth domain, we are not going to worry about precise regularity assumptions now. But what you can say then, if you have a connected boundary, then this boundary. Boundary, then this boundary must be within an annulus of a certain thickness, which is given by the deviation of the mean curvature to a particular constant, H naught. And this constant can be given in terms of the surface area of the boundary and the n plus one, the n plus one dimensional Libby measure of omega. So, and the distance is measured in L1 on the boundary, which is quite weak, right? Boundary, which is quite weak, right? So you can control this in terms of L1 and L1 deviation. And these constants here, Ï„, is an exponent which can be given explicitly and optimally. But I'm not going to do this today because we are not very interested in this constant. But in their particular problem, Magnanini and Poghesi give really, they give a fraction, like one over 2n or something, depending on the dimension it is. Something depending on the dimension, it is a little bit different, but you can write it down. And the constant C is depending on a few geometric quantities. So, basically the curvature of the boundary, not the local curvature, but basically on interior and exterior ball conditions, which is like a global assumption on the shape of the domain, but at least locally, it can be controlled in terms of the curvature of the boundary. So, these are the ingredients, and this is a nice result. So, we are actually close to a sphere once we are close to a constant with our mean curvature value. And okay, I would like to talk a little bit about the proof of this because, yeah, it is quite quick in comparison to Alexandrov's proof. It is based on integral methods and the On integral methods, and the key idea goes back to some paper by Antonio Ross in 1987, who proved something which was called Heinz-Cash or is called Heinz-Cash inequality by today. And the idea is given based on such an integral identity. So if we have a C2 function f on a domain which is constant at the boundary, then we have this integral identity here where the Here, where the Laplace is involved, and this is the Hilbert-Schmidt norm of the Hessian matrix. And here we have a boundary integral involving the mean curvature and the outward Neumann derivative of f. So nu is, here it doesn't matter, of course, because we have square, but nu is always my divergence theorem normal pointing outwards. Okay. Okay, if we now define the Cauchy-Schwarz deficit, which is basically. The Cauchy-Schwarz deficit, which is basically the norm of the traceless Hessian matrix in these terms here, then we can plug this in to this formula here. So we simply replace the Silber-Schmidt norm here to obtain an identity for the traceless Hessian matrix of F. Okay, and okay, what we are going to do now. And okay, what we are going to do now is to simplify this expression by solving a Diraclet problem. We are going to solve the torsion Diraclet problem, which is basically saying that the Laplace of F is equal to 1 in omega with Diraclet boundary conditions. So this integral here simplifies to a volume term. This is simply the volume of omega. And we continue the computation. Continue the computation by simply writing this in a little bit different way, right? This here is still the volume of omegas, and here we have a square, and then we divide by the volume of omegas. So we have done nothing except plugging in more terms in the nominator and the denominator. The good thing here is now we can apply the divergence theorem, use Heller's inequality to get an area of the boundary and the volume here. The point is now we can come. The point is now we can compare these two integrals. Okay, and this is exactly how you see how the constant h0 comes in. We are simply calling this constant here n over n plus 1 times area divided by volume, we call this h 0, and then we have our nice integral identity. So we have expressed the L2 norm of the traceless Hessian in terms of basically an L1 deviation of H from a constant, right? And this is exactly how it comes. A constant, right? And this is exactly how it comes in. This is how nice we can see how it comes in. And also note that if you are in the CMC case, everything is zero. Okay. And this is the key idea. The key idea is now how to revert this here being zero to the property to the closest to a sphere or to be exactly a sphere. Before I come to that, what Before I come to that, what we are going to do with this inequality, let me just mention that how Magnanini and Poggies continue with their proof. The key observation in their paper is that we have a reference function. This Dirichlet problem here has a canonical solution, which is the squared distance, but well, okay, sorry. No, the interior PDE has a canonical solution, which is the squared distance. Has a canonical solution, which is a squared distance. But of course, the Dirichlet problem forces this f to be different in general from the squared distance. But if you have a ball, if omega is a ball, then the squared distance function is actually the solution. So this Q is our reference function. And the point is that f minus Q is harmonic now, right? So, and for harmonic functions, there's this whole zoo of very good. Whole zoo of very good analytical estimates, like Hardy inequalities and things like this. So, you can really make use of this property and obtain and then get estimates for f minus q. Once you know that f minus q is small, you know that the domain must be close to a ball. And that's how Magnanini-Poghesi continue that proof. What I want to talk about, though, is how you can come directly from the left-hand side to a related. To a relation to a distance to a sphere. I was asking myself: can we, once the left-hand side is small, do we have to be close to a sphere? And here is what I came up with last year. You can do that without knowing much about the function f. Okay, here's the result. It's about one year ago, and we are taking a domain in our n plus one with this connected C2 boundary. With this connected C2 boundary, and we assume that f is a defining function for this domain in the sense that the boundary is a level set, and you have a regularity here, that the gradient is non-zero, so the boundary is actually a hypersurface. And then I can give you a constant C, which depends on absolute values for the function f and its derivatives, such that you can explicitly estimate. Such that you can explicitly estimate the distance of the boundary to a sphere in terms of an ln plus one norm of the trace possession. So this is a direct estimate and as correlally you can immediately see the Alexandrov theorem because if h is constant then this traceless Hessian is zero hence the right hand side here is zero. Hence, the right-hand side here is zero, and the boundary is equal to a sphere. Okay, but that's not the point here. The point is that we have a quantitative version of this with an arrow. And I have to comment a little bit on these ingredients here. Right, so first of all, the constant. We are assuming a bound on the second derivative of f. And this resembles what I said earlier about the interior ball conditions that Magnianini and Foghesi have to assume. And Porghesi have to assume. Because once you control the Hessian, you have a curvature control on the boundary. And you actually do need this, right? There is a simple example which you can imagine. So let's say you have two big spheres with a huge radius, and they are close together, and you just join them by a very thin catenoidal neck. neck um then it is you you can you can make you can configure this in a way such that your curvature is constant almost in one sense but of course the whole thing is not close to a single sphere of course the issue is at the neck you have very large curvature and hence the constant becomes very bad and your estimate becomes very bad so that's that's kind of the counterexample so you need some assumption on the curvature Some assumption on the curvature. So, this is one thing. The other thing is, why does the gradient appear in the denominator? So, the key is here: if your gradient goes to zero, you have almost no control on your level sets, right? If, for example, suppose the worst case, the gradient is equal to zero, then the level set is all over the place, right? There is not even, it's not even a hypersurface anymore. So, we definitely expect this dependence as well. And this is all reflected in this. And this is all reflected in this explicit estimate. So there's nothing to be done about the constants. Of course, we can ask what is the optimal alpha here. So here is a power involved, which might be very small. So in particular, very bad. This can be given to some extent, but in this generality, we will not give any very good value of this alpha, right? Because it applies to many situations. Applies to many situations, this set of assumptions here. Okay, one last comment about this theorem. Note that everything is scaling invariant in every direction. By every direction, I mean you can scale the domain and you will not change any quantity, and you can scale the function f by a scalar. You will not change anything here either. So, of course, this is necessary because the assumptions are scaling variant under dilation of the function. Dilation of the function. So the conclusion should be as well. Okay, that's all I wanted to say about this theorem. Oh no, it's not all. Importantly, which we will use later, it also works in conformally flat remaining manifolds. You don't need to rely on the Euclidean space. You can use any conformally flat thing, but then the constant C will also depend on the conformal factor. Okay, some more remarks. So as I already said. Some more remarks. So, as I already said, the constant might be given explicitly, but it will not be as good as Magnanini-Pogesi's constant because they have a very particular problem and we don't. On the plus side, you can actually make very good generalizations of this level sets of you can use this theorem in a wide set. A wide set of situations, which we are going to do actually later today. And this is actually because f is not assumed to solve any PDE. So we don't have very strong assumptions on our function f. Okay, and here are some words about the proof of this. It is not too bad. The proof is the idea is straightforward. The technicalities, there are some involvements, but the idea is straightforward. The idea is straightforward. So we can express the curvature of every regular level set in terms of the Hessian, right? There's this simple formula here: the Hessian restricted to the tangent space. Here is a tangent space missing. So this is not the manifold. This is the tangent space of a level set, is expressing the curvature up to a factor of the gradient. So what you also can do by manipulating this algebraically, you can just express You can just express the second fundamental form, the traceless second fundamental form, in terms of the traceless Hessian matrix. So a ring here is my traceless second fundamental form of every level set. So we can control this traceless bit by the full traceless Hessian matrix. And this traceless second fundamental form is a well-known thing, right? We have this classical Dabu theorem. Classical Dabu theorem that says that if it's zero, then M must be a sphere. This is like a standard theorem, and for this, actually, we do have very good stability results. There are many, many works by Delilah Scott. So basically, they go back to the 60s and 70s, like Regetniak and people have done such things for convex hypersurface. But basically, the first result without convexity basically goes back to Delaney-MÃ¼ller. Then Peter Topping has things. Chopping has things, Grojan has some LP estimates, so there are many stability results. So, what we are basically just plugging in those stability results and use the co-area formula to relate the L2 norm of the traceless Hessian with every L2 norm of the traceless second fundamental forms. And then we do some Chebyshev inequality thing, and it's not too bad. The idea is not too bad. And that's basically the And that's basically the key. Okay, I have eight minutes to present the further application that we have started to work on recently. This is with Chao Sha at Chamen University. So we want to do this in warp products in more general ambient spaces. So we are going to look at warped product spaces, which are given by an interval times the round sphere. And our warping factor here is a radial function depending. Function depending no, it's a radial function zeta, which is which is positive, so that the metric is Riemannian, it's smooth, and it satisfies this set of structural conditions. So we assume that theta prime at the origin is zero, which means that the zero slice is a minimal hypersurface in this space. So this is basically, if you think of Schwarzschild space, this would be like the horizon of the many. This would be like the horizon of the manifold. We have this condition theta double prime is positive. This is basically saying that the Ritchie, the Ritchie curvature in the radial direction is negative. And then we have some other things here. What distinguishes this most from the space forms is this property H4, and this plays a crucial role in the classification of CMC hypersurfaces. Because in the Euclidean space, the sphere and the hyperbolic Euclidean space, the sphere, and the hyperbolic space, this is violated, right? The left-hand side would be zero. But we are assuming this is positive. And concerning H3, for those of you who are familiar with this property, this is saying that you have a substatic metric. This is a notion which is important in relativity. So this H3 is equivalent to this inequality here. This inequality here, where Rich is, this is the Ricci tensor. And now I put a bar here to indicate that we have the ambient Levi-Chivita connection. We will also use the connection without a bar. It will be the one on the hypersurfaces. And then the most important example is the Schwarzschild manifolds, where we have this ODE satisfied by the warping factor. Okay, so this. Okay, so this the Siddhartha-Schwarzer manifolds fall in this category. And then we have a famous, by now famous result by Simon Brendler from 2013 who classified CMC hypersurfaces in such ambient spaces. Namely, they are all coordinate slices. And this is actually where this H4 comes into play, right? Because if you have a, in the Euclidean space, for example, if you have a CMC surface, it's not necessary. CMC surface, it's not necessarily a slice around the origin, right? It can be everywhere else, but this property H4 forces it in Schwarzschild space that it's actually a coordinate slice in your ROP product structure, right? This is the difference, and this is where H4 comes in. Okay, so this is a perfectly nice classification result, and the aim of today is to, or the plan of my talk in the last five minutes, is to show you how to get a stability version. To get a stability version of this result by Prendler. And this is joint with Chao Sha. And the idea is in the same spirit as I've given it to you in the introduction for the Euclidean space. All you need is a Rayleigh inequality which accommodates the Jammore general ambient space. And then you have this nasty beast here, which is already simplified because we assume that F is local. simplified because we assume that f is locally constant. So I have already got away, got rid of the final line which would have gradients of f on the boundary. So this is an integral identity with what Purdue to Junfeng Li and Chao Sha from three years ago or so. They designed it exactly to give an integral proof of Brandless result. So that's what was their main application. And we are going to use this to quickly We are going to use this to get the stability. We are going to do the same spirit here as we did before. We are going to solve a Dirichlet problem to get rid of this Laplace term here under the integral, right? We solve this torsion type Dirichlet problem. Note that now we possibly have two boundary components, right? Because we also have the horizon here. If the boundary of omega is null-homologous, Null homologous, then we can just ignore this thing here. But in any case, we are solving the stereoclake problem. Plug everything in, and then in this exactly the same way as in Euclidean space, it's just more complicated to calculate. But you get an estimate of the traceless version of this quantity here in terms of this, you can delete this one. This is simply H, right? H minus H0. Minus H0. So we have a deviation estimate in L1 for this traceless thing here. And similar as before, H0 is given by a constant depending on ambient data. So V here is for abbreviation, V is theta prime. So this is the derivative of the warping factor. And well, right, once we have that, Right, once we have that, we are applying my level set stability thing. Note that we have a tiny problem here because the level set was only in terms of the traceless hessian of F. Now we have this distortion term here. But f is zero on the boundary, so you can basically discuss it away by some further estimates. So it's possible to get a refined version of the stability theorem. Version of the stability theorem with such an error term here. But then we get the same thing, we get closeness to a sphere by my stability result. And in detail, just to give you the full theorem, which is not an archive yet, it's still under construction, but it's correct and we have checked everything, but we have to write it up. We need one more structure condition on the warping factor because we have to solve a directly problem, right? have to solve a directly problem right so we we need some we need some way to to do shauder estimates here so we need some holder assumption but that's that's the only addition and then we can get an explicit estimate of the distance of our boundary component to a to a radial slice in terms of an L1 deviation of h from a constant right and with some exponent alpha in L1 norm Exponent alpha in L1 norm. And that's an explicit estimate where C depends again, depends on an interior ball condition. Okay, that's the main result. And I'm perfectly on time. Jolchen Bauer, thank you very much, and I'm happy to take questions. Okay, thank you. Questions, please? Okay, somebody raised a hand. Go ahead, please, Danielle. Yeah, what happens if you try to relax the smoothness assumptions? The smoothness seems to be entering the constants, right? Yes. So, what you definitely need is the interior ball condition. Condition. In this theorem, you need, or we need some C2 alpha. This can probably be relaxed, but I don't think you will go beyond. You mean smoothness for the boundary, right? Not for the function f. Yeah. Well, you need the interior ball condition because there are counterexamples if you don't have them. In convexity, you can state the uniqueness result and also stability results in terms of curvature measures. So if they are probably. Measures, so if they are proportional to the boundary measure, and then you don't need such a condition. So somehow there seems to be, you have to give some input, either convexity or some other conditions or these ball conditions, but you don't get it in complete generality, I guess. So, are there counter examples? Do you know anything? Yeah, right. So, for this interior ball condition, of course, the thing is non-convex, otherwise, your Otherwise, what you mentioned would apply. So, for the interior ball condition, it's again, it's a stumble with a small catenoidal neck where you don't have, where you violate the interior ball condition at the neck. This is definitely a counterexample in the Euclidean space even. So there you don't have anything. But certainly, this is not convex. So that's fine. As you mentioned, the convex case. In the convex case, the alpha is The alpha is, I think the alpha can be can be made equal to one actually. So this would be the optimal. I mean, I'm not sure in this theorem, but in the Euclidean case, I think you can put the alpha equal to one in the convex case. So this is the optimal setting. This is basically due to there is a paper by Leichtweiss where we have such a stability result for convex bodies where you have Where you have in three space, right? In three space, yes. Um, where you have, but I think it's also true in higher dimensions, um, where we have the constant equal to one. Um, if we're in higher dimensions, I think this is more recent, this result, but but um yeah, at least you can you can optimize the constant and this constant that the Leischweiss constant goes exactly into the proof here. So, this carries over to what I said to the CMC problem. So, in the convex case, we have much more. So in the convex case we have much more much better results of course. And the Lennis Miller result is this in general dimensions or was this also for three space? This was also for three space but there are generalizations for L P so De Lellis Muller is an L2 estimate. If you put P here then and you are in the subcritical case P greater than N, then you also have higher dimensional results. You also have higher-dimensional results like this. This is a PhD student of De Latis. He was called Daniel Perez. He has an LP version for this in higher dimensions. And since we are assuming curvature bounds anyway, we can put any P, right? So it is really a stability result once you have controlled curvature. So this P is not of great importance here. Thanks. I think that's probably a very stupid question. So if you consider some other curvature, not mean curvature, but case symmetric, is it much harder because it's non-linear or what's going on? Just to check whether I understood your question, if you replace the mean curvature by other curvature functions, yeah, you can do that. You can do that, but the proof will be, it will be slightly different because here in this original argument, everything pretty much depends on the divergence structure of H. Of course, if you do the elementary symmetric polynomials, they also have a divergence structure, but there will be more error terms. So the results will look slightly different, but you can't definitely do things like this. But the results will be a little bit worse. But the results will be a little bit weaker because you have to rely more on the maximum principle instead of integral methods. So, to cut it short, yes, there are results, but they are a little bit less explicit and nice. Would Alexander of theorem be correct? Oh, yes, this is correct. Yeah, definitely. Unless, well, for special cases, let me be careful here. Here. You need further convexity assumptions. So, if, for example, if you have the scalar curve sigma2, the second elementary symmetric polynomial, it will not be perfectly valid in all generality. You need the ellipticity of the linearized operator for that. Or constant Gauss curvature will only be possible for convex hypersurfaces because the linearized operator has to be elliptic. Operator has to be elliptic, and this is only true if your curvature is arranged in a cone, which makes this elliptic. The mean curvature operator is always elliptic, but the Gauss curvature is only elliptic on the convex cone. So you have to make restrictions here. But there are versions of this, definitely. So it's not, there are results, but it's not as nice as in the mean curvature case. Those are questions okay, then let's thank the speaker again. And the next 