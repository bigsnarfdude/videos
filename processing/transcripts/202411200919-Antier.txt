And so for multi-messenger observation, as we discussed over the last two days, we need different expertise that match together to understand better the neutron star and black hole collision. And for that, there is a need on having first having instruments, so GW detector, but also a space and ground instrument for the electromagnetic modeling on each side. So on one side, GW for side TW for understanding the dynamic, the progenitor, and on the other side modeling on the different ejecta, the early hemonora. So in my talk here I present my collaborator so that you know which I work with. But we also needed to have also a connection with chemical evolution and air process and nuclear physics process method at all, less related to astrophysical or pH effects and so forth. Call of VH vector and so on and so forth. So, with all this bubble, I will more focus on this leak, EM instrument, how to detect the GW counterpart and how IA would facilitate repetition. So, in my presentation, that's why you need to pop it fast, but IA can help maybe in follow-up decision making how to have the best strategy of follow-up in multi-bank mostly work in. I mostly work in optical and ground description, so please be biased that we could be allowed that. Then there is once you have observation and you have image, how you can tell that there was a source in this image that we can use also IA. And if you see the evolution of this source, how can it be associated to GW? This is another thing that we need to tackle. It's not only observation very strong. And for all that, you have data from the optical You have data from the optical to try to go into this scheme and to better understand the neutron star. So, first one is decision making and follow-up. So, when us are LIBON, we send out an alert or bottle into the sea, then you know our job is done. But there are so much to do on the electromagnetic side. So, first, as an astronomer, because sorry I must say that uh I am a must say that uh I am a typical French position which is astronomer is like equivalent a professor associate. So as an astronomer you need to wake up if you don't have a rotar 24 hour shift and or if this you don't have automatic processes and then focus to understand if you will go or no go activate observation. And so the shifter needs to understand Needs to understand if it is important, urgent, important, not urgent. Think like this. And if the people on shift, so usually it's not a big bus, people are always on shift, right? Can I serve it myself? One of the things. So to serve it myself, either it is based on automatic criteria, so there is no shifter, no no one to be wake up. Either you can help on read uh on big documentation. On big documentation, and we have our level zero for ETW. And when it is not in the process, then it is a bit difficult. Either you have more experience, you say, oh, it seems like similar K than the other one, and you can solve it. But sometimes you don't know, and this is a big problem for managers, is because then you have calls, oh no, but I don't know what I do with this alert. And it's a nightmare because, I mean, as a manager, it's always to be like a crate. Like a crack. So, to solve that, this is why I built in 2018, Arctic 17, these telescopes networks that involve 20 countries, including Antarctica, so quite happy, 40 institutes, 100 members, and 77 telescopes with different allocation time. So, GROMA is for global admits, advanced routing networks, 702 messenger admits. See Messenger edit. What is good is like it's a worldwide collaboration. So people can be on shift 24 hours. So basically we separate in six hours and usually people do two weeks on shift per trimester. So I don't know in LIGO how many shifts we do per two months, but typically this is how it goes. And we choose to train this advocate to respond and quickly activate the Telescope documentation with the decision tree. With the decision tree at Lego Pirgo, and also to train, because it is a question of training. We have intensively our impact now on YouTube, so we become a YouTuber to practice, because when you have a lot of shifters to train, it's not good to set up 6 a.m. to all lunch, so it's good to have asynchronous tutorials, and this is what we try to do. And so, of course, we have our experience because we fill out more than 90% of the Because we fill out more than 90% of the event to remote. So, with all these ideal, let's say, ingredients, does it work smoothly? Eva, no. Because we have also helped with significant development of tools. So, it's not only AI, it's not about humans. It's also to have tools that do this follow-up strategy. So, here I talk about Roma, but of course, in all the collaborations, there have been massive, massive development. There have been massive, massive development on two. And here about SkyPortal. So, in SkyPortal, you have the alert coming, it's already flagging you if it is a BVH or not, you have indication about if it is astrophysical or not, and you can see which telescope, for example, can already point into the sky. So it's helping me, not only just I will look at red dividing what I do. So it can work mostly for GW. You see, one shifter says, okay, GW candidate, I follow the process. Candidate, I follow the procedure, it is BBH, it is not well localized, the distance is over 200 megaparsec, no follow-up. But another example, so this is, we also follow PRB, that is more complicated because someone says, oh, we need to follow up. The other one says, no, but there is no optical concept. So this is how it's confusing. And you lose a lot of time to try to observe. So again, it's Damon's tool. Instrument tools. So, once you have decided to go there, you need to know where to point your telescopes and which telescopes to use, which filters. If it is further away, maybe you need to point your telescope for long-term exposure on one side and then another. So, it's not the same. So, you need to organize all of that. And for this, we use a tool developed by Meinfel, who is the founder, and that is largely used by the collaboration. Really used by the collaboration. And when you have automatic telescopes like TARO in NIST, that I am working in NIST, so it's easy automatic TW coming, criteria, timing, TARO points, and dynamic. But this is not the majority of the telescopes. The majority of the telescopes are not prototype. Why? Because on one hand, you have big aperture telescopes with very limited time. For example, for a Time. For example, for 4 meters, 8 meters, you just have 8 hours of observation during 6 months. So you cannot say, oh no, maybe I agree, maybe I don't know. And national telescopes is so highly demanding. So you need to have someone that says, okay, I validate. On the other side, you have PI telescopes that we have in Roma, actually. So then you have more time. So you can have more use more for More use more for other opportunistic alert like PBH who are localized, etc. But their test cup, as I saw in the slides, there are handmade telescopes, it's not clear, sometimes you need to put some formula, sometimes you just rechat with your colleagues, you know, so it's even not automatic because it's in the question of PI test. So you have all this question and for your observational strategy, I must say that sometimes it is cloudy, in fact, so even you say no. In fact, so even you say, no, this is where we need to observe the TW. Finally, in fact, this level. So it's not happening smoothly. So even with the best organization, we don't have the best optimization for strategy. And so now, look at my time. So, what the community have done with all these ingredients, so I talk about Roma, but of course the same for the others. For O4. For O4. Okay, so for O4, we don't have the NS allele, so I talk about the NSVH candidate. And so I took two examples, one from last year, 23, 06, 27C, and the other one that I just talked about, that trigger a lot of observation. So I don't talk about if it is astrophysical or not here, I wish to understand if the observation from the whole community is optimal. So for that, Mario, let this. So, for that, Mario let this work. So, she looks at all information from Treasure Map and contact some telescopes team at last to grab what they have done. And so, you can have the zero, so trigger time of TW. And then one day, two days, three days, so this is the observation in color, four different optical long. And this curve represents, in fact, the peak time of a culonova. Peak time of a kilonova population. So, this kilonova population is based on a Bula ruke. So, which means that here at peak, like 1.2 days, it means that most of the kilonova peak at 1.2 days past G0. So, if you have a day's coming, you say, here, I just go as fast as possible and then just image 30 minutes, because you remember you just have eight hours for six months. But it is not great. Well, you will not catch the maximum. will not catch the the maximum piece of the quinoa. So this is how the community worked for example for 2070. So the image before the maximum were the all the quinoa pitch effects of nothing. Whereas for 22ED the community image better. So for example for 22ED was very very highly popular and they cover not all the time but also The time, but also all the localization. So then you can tell you: okay, they have observed grade over time from zero to eight days past T0, they cover where it should be localized by the schema, but will they attain a certain sensitivity? Because we need to compare the QNOVA with the distance of the TW. And so for that, we generate LICO at the distance of the Curve at the distance of suppose 24 or 42020, okay, and we look if these observations, so for example it is TCAN, they are enough deep to constrain if there was a kilonova or not. Because if they are too shallow, then you don't detect the kilonova, but it doesn't mean that there was a kilova. So for 22 ED, good news is that the community efforts, so everyone, except the one that Except the one that didn't want to give me the observation. Okay, so everyone, the community of Point showed that the sensitivity was inert, that we can rule out all kilonoba signals after this search. So it's good because if it is not astrophysical, it's reassuring. Whereas for 230529, we have observation from Observation from CTF ATLAS, for example, and you see ATLAS covers largely 23 or 529. But using 23 or 529, we have information because it is public, right, on the masses, on the viewing angle, etc. So we can constrain that there is only a subset of this kinema population that can fit a 230529 NSPS measure. And so even if the community larger If the community largely observed, we cannot say that there was a kilonova, that this kilonova was present or not because the observation was too shallow. So, this, for example, strategy does not come. So, in conclusion, because NSBH and DNS merger are very rare events, in fact, for the follow-up community, it's very hard only to have one program focused on that. And so we need to have And so we need to have side projects to feed this follow-up collaboration and it is hard to maintain in fact all this knowledge and to boost for optimizing this follow-up. Secondly, as all collaboration, in fact you have your collaboration and students come and go. This is what we discussed I think yesterday. And so sometimes they have the knowledge and they go out on your bubble of your collaboration with the knowledge. So this is difficult to handle. So this is difficult to handle, in fact, as follows with Common Co students. And finally, because tools are done by some people and operation shifts are done by the others, sometimes there is a mismatch between tools that able so fastly and the other one and there is a cross-clash between make them learning but the tool has already evolved. Okay. So what I propose for all this follow-up is to use IA, maybe to replace the shifter with uh arch. Shifter with or to replace or to accomplish a shifter with a chat GPT IA generative A that can be learned from different factors. So one is documentation procedure, the other one is the reporting for each event. So based on Slack, Matterhorse, etc. The third ingredient is a metric, like a TW skinnette, you know, to train your decision. And then the community feedback is important. The community feedback is important, for example, for GCN. We have experience not only from your own collaboration, but from all the collaborations. So this bot can learn from that. And then about tech story of experts that are there for a year. No, but me, I knew because I am expert. And so just make them record it to have that the I can not for instance. Uh how many six minutes. Six minutes. Okay. So part number two. So, part number two, I know you are mostly Lego people, but after, let's say that you have optimized your collab strategy, your convicts will have high, the problem is like once there is an image, is there is a source or not? Because I said the observation told that there was no kineto, but me, myself, I didn't see the image. I am sure that there was no new source detected. This is the question. So, in optical, we have exactly the same problem as everyone. Exactly, the same problem as everyone about the trigger. And for example, this is an image from a TRB, show TRB, and this is a reference image. But here, Gemini claimed that there was a source. So if you just look by eyes, you don't see anything, but it measures the source measurement. And this is what we will use, in fact, for example, if it is a cumulative, in the model. We will give this data to the theoretician. To the theoretician on modeling, and they will think that it is trustable. So, here there is an error and very tough problem on the community is because the astronomers are not in a big collaboration on China. So, maybe with one software they detect the things, with another software they detect the things. Some people just look by eyes, obviously. So, there is an internality between the data and software. Data and so, for example, to solve this problem, one solution is to look if you have an image in another feature. For example, this happened here, and so we can say maybe it is convincing, maybe this is mismeasurement. And so, here I help to understand, maybe learn from different image, from different telescopes, homogeneous, to help into the detection and measurement. Okay, so I go on my third slide to talk a bit about. Slide to talk a bit about the offline. So imagine that you have solved your problem of fooler, you have data, you have solved your problem to have data from different because you unify them with machine learning. And now you are at the stage when you want to have the global picture, right? And you're going to provide your backup to Bellevue in France using GW. Kilonova, GRB, etc. So, as we discussed, I think yesterday, in fact, to do all this analysis, we need to find the best model. And so, that's why there is this use of surrogate models. And so, I am working with the NNMA team. And to have this surrogate model, we use either the traditional way, either using surrogate magic, irritating from machine learning. And so, what the team has done is to check. Has done is to check that this sub-aggregate model with machine learning are traceable. For example, they check by filter if we can recover the same sub-aggregate model with traditional. So, this is a way to explore with IAM. The second one is about having extracting the source properties from the whole JW can and Germany. And Germany. And so I would like to pay your attention and I finish my talk about that. It's about 17017. So, for all of you, I think it's done, we have known everything about 17017, we know the source properties, the ejecta mass, and so on. But with my students, we look back at the data. And this is why I have a chat with you. Because if we just use kilonova model, actually views, and we extract And we extract, for example, the genemio-college mass, the wind mass, the inclination, and the distance. With skinned over only, we don't recover the distance provided by TW. So to have only TW plus Kinanova plus GRB, in fact TW constrain you the distance, so constrain you all the parameters. So about the question if Kinanova alone can distance Alone can be standardizable, standardized label, and things like this, it is tough to answer, and so that's why I pay your attention that really GW gives another indicator to extract your properties. Without TW is more difficult. Yes. So, to understand where this error comes from, this is why you can use IA to scale up your study. Example, make Study. Example: Maybe you don't recover the same parameter GW plus QNOVA or QNOVA only. Maybe because you have a problem about the like of maybe there are too many points in R and less in J. So maybe the best fitting model is going to that because it's creating a source of error. Maybe it's simply the model of Kimonova. Maybe they are not enough accurate. Maybe they don't describe where the first day. First day. Maybe your choice is a numerical problem. Maybe the choice of the way to use machine learning and self-model is not optimal. So there are many, many sources of propagation to make, in fact, to have this proponent externally. And so this is why I think IA can help in the offline. So in conclusion, I hope that I have convincing you for IA in different fields, starting from when Starting from when we have an alert from like a VRO about decision making for the Go and the no-go, and how to observe which test curves, which features, how many room is it, and also something that I did not tackle, but when do we stop, which is also a question. On the optical front, if we detect a source or not in our image and if it is related to GW or not, so I didn't talk about all classification, but About all classification, but I'm happy to talk about the broken classification. And then we need to provide this measurement to a framework, right? And to understand the extract physical property of the source. And here there is I think also IA that can help. And of course, for these three parts, there are different experts, in fact. So you need to bring all together to make progress on this field. So thank you. So thank you. Questions? Hi, it's a very interesting talk. I have a question, but it's not an already something. I can think that if you want to apply AI to the data that you have, and there's different like astronomers that we have, there will be a problem of AI Of how the data is. Maybe different itself, they have different formatting of the data, different solutions. And I guess my question is if you could elaborate on how it can handle from a perspective, AI perspective. So the interoperability is a subject for years. I think we won't be sold in the next five years. There is also a question about filter to use. As I said, About shifted to use, as I said. So, more traffic, more Asia, they use, for example, Johnson's filter that's one broad expected to have in flux, whereas more America use Sloan and Europe uses Peter. So, this is why it's creating uh Likers that are heteromogeneous. So, for me the solution is uh of course to jump on, but Shogun that it's a network of stelescope, but I won't have the photos. So then it's just a question of operability, but it should be fixed step by step. I also think that the solution is also golden tools. If people use the same tools, there will be inputs and outputs from people. And so this is why I think we need to get out from TCM, for example, when it is a text and everyone does their life in a non-form uh format. Non-form uh formatable format, and so yeah, try to extend data with uh some tools that push people to have the same format. And also, my follow-up question is about agent setting here as well. Having a DA you've got all the information that you provide to the AI tool and then like Tool and then like so, in my mind, for we don't we won't use ChatGPT, we reach create an answer generated IA for that. Yes, and then you have places for it to place how exactly do you make your follow-up decisions? You know, do you use as and ask for what you use? Do you use as an S or whatnot? Does any of that change for NSBH versus a possible DNS? So, since the rate of NSVH candidates is so low, like at New York, since one year, we just have a cut-up on the distance, median distance, less than two hundred megaparsec, and the coverage, less than two hundred degrees per. Because to extract physics on upper limit, you need to have a large coverage. You need to have a large corporation. So it is more interesting, you see, than as remote. Of course, adrenaline for us means you need to wake up the manager. Last question. Could you talk a little bit more about the network of telescopes you have and whether you're taking these spectrums across? Yes, we have a collaboration with SORT in South Africa. A salt in South Africa, and so it is a formation in yeah. This is a spectra, but I didn't show that the spectra is always difficult to have. That's why I'm mostly working on like a thank one more time.