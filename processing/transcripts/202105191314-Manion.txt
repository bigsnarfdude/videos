One and e, but actually, it's going to need to have objects for like e squared and e cubed and stuff, because those are only really going to be zero, sort of up to homotopy. And how you get them to be zero is, well, I throw in a null homotopy of the identity map on E squared. Let's call that tau. So I require d of tau equals one. That's the null homotopy condition. And then these other conditions are natural as well. And so this thing, if I look at the growth and weak group, well, Growth indeed group. Well, if I look at the object E squared, you know, that's going to be the same as the zero object in the growth indeed group because the identity on that is zero. So, or is homotopic to zero. So, this thing categorifies a very simple universal enveloping algebra, just half of, you know, this somehow C of E mod E squared still needs to be viewed as super. That's the one complicated thing about this otherwise two-dimensional simple beast. Is that to be a hot. Simple beast does that to be a hop algebra, it's actually a super algebra, okay? Just like GL11 is super, okay. But this is some monoidal category. The monoidal operation takes E and it, you know, E and E cubed and sends it to E to the fourth, if you want. And similarly, it acts on the morphisms. There's a diagrammatic interpretation of the morphisms. And now I can look at, just like representations of the quantum group, I can look at two representations of this category. I can look at two representations of this category five quantum group. Okay. And I want to look at, instead of a representation on a vector space, I want to look at a two-representation on, in this case, a DG category. Or we could say differential because I'm not going to talk about gradings in this talk. But what would be such a thing? What would be a two representation of this? Well, it would be a, just like in the representation case, it's a algebra homomorphism from the algebra into endomorphisms of the vector space here instead of algebra homomorphism, it's monoidal function. Of algebra homomorphism, it's monoidal functor into endomorphisms of my DG category, as in like functors and natural transformations with the monoidal aberration given by composition. Okay, so concretely, what that amounts to is like, well, if I have an object here, like 1EE squared, these are going to have to go to objects here, which are endo functors of v. But really, it's got, you know, my functor, my correspondence here has to preserve the monoidal structure. So all I do have to do is specify. Structure. So all I do have to do is specify one endo functor for like the object E of U, the generating object with respect to the monoidal structure. And then, you know, E squared is going to go to E composed with itself. E cubed is going to go to E composed with self-choice, et cetera. And this is then, okay, this is what it means sort of on objects to have a two-representation, but you need a little bit more data because you have these two morphisms. Data because you have these two morphisms in u. So, this is like the extra layer that you have in higher representation theory: is this sort of endomorphism here of E squared? That's got to get sent to some endomorphism of the bimodule E squared. Okay, so a true representation of u on, or sorry, I said bimodule, I meant functor. Um, so some natural endomorphism tau of the functor E squared. This is a dg functor on a dg category, so it makes sense to talk. On a D2 category, so it makes sense to talk about D of tau, and you need D of tau equals the identity. Okay, so similarly, I can phrase this for algebras. Hopefully, I'm not saying this too unclearly, but what does it mean to have a two representation of this thing on a DG algebra? Well, it means I have a DG algebra A, and then I have a DG bimodule E over it, and then I have an endomorphism tau of E tensor E, and certain relations have to be satisfied, and D of tau needs to be the identity. And D of tau needs to be the identity endomorphism on E. Okay, so this is just like saying what does it mean to be a representation of a quantum group, but this is a two representation of this particular category for the quantum group, okay? Supergroup. And so we will, in this talk, sketch a version of tensor product in both of these settings. So representations are categories or algebras, but the algebra one is actually going to look closest to what Douglas Manleski wrote down. The category one looks closest to what Roukier wrote down. One looks closest to what Rukier writes down in his more general constructions. Okay, so first let's talk about the category thing. Let's say we have this DG monoidal category U. It's acting on two different DG categories. So it's acting on V1 and it's acting on V2. So these are two representations of U. Okay. And instead of telling you or discussing how we're going to define the tensor product first, I want to say, well, how would I define a related thing, an internal A related thing, an internal HOM between these, which is itself a two-representation of you. And to think about how I would define an internal HOM, I want to first think about how I would just define HAM over U, which is a different thing. Okay, so how would I define if these are the sort of structures we talked about on the last slide, V1 and V2 have these functors and these endomorphisms of the squares of these functors, then how should I define what? Should I define what should be like a morphism of two representations from v1 to v2? Well, a morphism should be some functor from v1 to v2 that commutes with the action. Okay. But just like we built in the fact that e squared equals zero by a higher map, we're going to build in this, we don't want to just say it's f such that we have an isomorphism like this. We want to say an object of this hum over u thing is like a pair. hum over you thing is like a pair f comma pi where pi is a choice of i i i don't want to be too strict either about what i say what type of you know isomorphism or equivalence this pi has to be this is for this doc just motivational um but this is a reasonable way to get at the idea of morphisms between two representations and then i could talk about um well that would be an object of hom over u and then i could talk about morphisms between such pairs f comma pi. Such pairs, f, pi, and that would be another thing to define. This reasonable thing. And okay, so now this would not be the sort of internal HOM. This is more like that first type of tensor product that eats up the action that we were talking about. This is the HOM that eats up the action. Okay, but how would that be related to the HOM that doesn't eat up the action, the sort of internal HOM in the category of representations of a Hopf algebra? So just HAM over the ground field. So we're just looking at, say, ordinary representations. Looking at say ordinary representations of the Growth and D group of this thing. Sorry, I have barking dogs, they're not mine, um, neighbor's dogs. But so anyway, we could look at morphisms of representations from V1 to V2, linear maps that commute with the action, or I could just look at all C linear maps, and then I have an action on the space of C linear maps and explicitly here. I mean, in general, it involves like the antipode and stuff and the coproduct on this POP algebra. Product on this Hopf algebra, but this is what it is explicitly here. Here's how my, if I have phi is like a morphism, then here's how E acts on a morphism, E being my generator of this, this some stand-in for a quantum group here. Okay. And but the point is that how are these two things related, HAM over H versus the internal HOM, is that if I take, well, you know, the things in the internal HOM such that E of it vanishes here. E of it vanishes here, that's going to give me the hum over h because e of it is going to, you know, the difference between the two things you would get to make a commute that would need to be equal to make a commute, okay? Um, so let's try to lift this idea a little bit to the categorified level. We sort of know what we want at some sense to be this home over h thing. That's what we talked about on the previous slide. What categorifies that? That's sort of this objects are this f, pi. Okay, how about home over c? Well, that should. Okay, how about Hum over C? Well, that should be something where objects are also maybe an f pi, something like that. But then, you know, maybe you want some action of E then, that you can take E of F comma pi, and you want that to be zero in some sense, if and only if your F pi is actually the sort of thing we talked about on the last slide. Something in this hom over U between your two representations. Okay, one way to sort of arrange this is you take. Of arrange this is you take f pi, but you don't require, you just let pi be any map at all, it doesn't have to be any sort of equivalence or anything. But now, what I'm going to do is going to define e of f pi to be, well, the first part, and I should have said f prime instead of m prime, this is the typo, f prime m prime, where f prime is the mapping cone of pi. So it's like m prime is like EF plus. Uh EF plus sorry, F just F doesn't mean the F in the quantum group. We have E only. Okay, so E F direct sum with F E with the differential between them given by pi. So the idea is that if pi is an isomorphism, that thing is going to be contractible so that it's, at least roughly speaking, you just laxify the pi in the definition of the sort of hom over u, and you're going to try to get something like internal hom. So we're going to. Internal hom. So we're going to take objects of this internal hom over u to be like, I guess really internal hom over the ground field or something to be these f pi's where pi has no conditions. And then E of such a thing, well, at least the F prime part is a mapping cone. And then you can define what the, there's a natural sort of two by two matrix that defines the pi prime on such a thing. And you can complete the definition then. You need to say how this E acts on morphisms. You need to say what morphisms are. Morphisms are f pi to f prime pi prime, you know, like f morphisms between f pi's, and you need to say how e acts on them. And then you need the tau endomorphism of e squared. So you can define all these things. It's sort of a little bit less enlightening, in my opinion, than this idea of the relationship to the Hom over U. Okay, so we want to use the same idea to get the tensor product because these are sort of related in the same way. This tensor product of representations of a Hop algebra, that in Of a hop algebra, that in it seems like it's kind of related to the sort of tensor product that eats up the algebra in a similar way. So we want to get this tensor product using the same idea, basically. And one way to do it is, well, we'll just generalize. And then the generalization will also apply to tensor products. So instead of saying we have like v1 and v2 that get acted on by this, you know, categorified quantum group, we instead have. Group, we instead have just one category, and they may be thinking the tensor product of these two things, okay? And/or maybe it's Homs between them, but I have one category that has two actions of the categorified quantum group. So you have E1 and E2 acting on the same thing, and then you have your tau i endomorphisms of, you know, E1 squared, you have tau1, and E2 squared, you have tau2. They satisfy the usual relations. And then you put in, you require, you have an additional map that's sort of. Map that sort of encodes the commutativity. So you have two commuting actions of this U thing on a DG category, W, say, okay. And then you require some equation for that commutativity map sigma. You require it to be an isomorphism in this case as well. And then I can build something that generalizes the previous construction. It's sort of W with, rather than two actions, it's sort of W with the diagonal action. We don't really have a co-product, a categorified co-product. Really, have a co-product, a categorified co-product on this U, but we have this construction of a diagonal action as follows. It's basically the same. This is where the M came from. So to build this delta sigma w gadget, well, the objects of that are going to be pairs m comma pi rather than f pi from the previous slide. And m is going to be an object of, well, I'm going to want mapping cones. W is just some dg category. Okay. And so. Category okay, and so this should be script W by the way. Um, but so I'm gonna take the pre-triangulated closure of W because I want to be able to take the mapping cone on stuff, and just for fun, I'll take the item potent completion as well, okay? And then now it makes sense, it will make sense on the next slide to take the mapping cone of a map pi from E. So E2 and E1, they're endofunctors just of W, but they extend to endo functors of W bar I. Okay, so I can talk. Okay, so I can talk about E2 of m and e1 of m, and I can require it as part of the data of an object of this delta sigma thing is that I have this pi, this morphism between e2m, or from e2m to e1 of m. Okay. And now I just like in the previous slide, I define e of m pi to be m prime pi prime, where m prime is the mapping cone of pi. And then you have to trust me, there's some natural definition of pi prime that makes sense. Okay, so this is, I'm trying to move. Okay, so this is. I'm trying to motivate this because just by analogy to the previous one, that this is just works the same way. It's not any harder to prove things in this setting than the previous one. But now I can say, okay, if I want to get the previous setting, I'll take W to be dg functors from V1 to V2. And then I have two commuting actions by pre and post composition with the like E's that act on V1 and V2 respectively. And this, so if I take this setup, then the So, if I take this setup, then the previous slide generalizes that internal hom thing that we said. We build this internal hom. Whereas now I can also use this to get the tensor product. And so now I'll take w to be v1 tensor v2. And I still have basically two commuting actions by e1 tensor the identity and identity tensor e2. And so the construction on the previous page. The construction on the previous page applied to this case gives you a tensor product that, um, following Raphael, I write with this sort of double tensor product symbol. Um, so I think this is due to him originally, but that's that's supposed to be the name for these higher tensor products as you draw the little double tensor product thing. Um, so this is what I wanted to say about the categories version, okay? And this doesn't look like Douglas Manelescu yet, if you're familiar with the algebra of cornered floor homology. The algebra of cornered floor homology, but the next version will. Next version will look more like this. Okay, so I want a similar thing, I want something related to the previous construction, but now it's going to tensor together. Instead of taking two, you know, DG categories with actions of u, it's going to give you two dg algebras with bimodule actions of u. Okay, so I have bimodules e1 and e2 over dg algebras a1 and a2. A1 and A2. And then I'll have the tau i on the squares of those bi modules. And I want to tensor those together and make a new thing of the same sort, okay? Another two representation on a DG algebra. Okay, well, so this, let's aim for the general version because then we can apply that to get the tensor product. So let's suppose instead of the W from the previous slides, now we have a DG algebra, let's call it B, and we have DG by. And we have dg bi-modules E1 and E2 over that with tau i on the square of ei. And then you have this commutation isomorphism that e1 tensor e2 is isomorphic to e2 tensor e1, and we're given an isomorphism, and it satisfies certain relations with tau i. And so now, okay, one thing I could do is I could just take B mod. That's a DG category, and now I have the sort of, that's W. Have the sort of that's W. And I can do the previous construction. I can form delta sigma of W using the previous slides. Okay, that's what I know how to do. Now, what I want is an algebra level version of that. So I want to be able to take delta sigma of B rather than of B mod, such that then if I then go take mod of that, so delta sigma of B in parentheses, and then mod, I want that to be naturally identified with the delta sigma applied to the module category delta. Applied to the module category W, okay, that we just talked about previously. Okay, so that's how we want to define delta sigma of B such that that is true. Okay, and so, well, what do we know about the previous construction? Delta sigma of W, where W is B mod. An object of that would be a pair M, pi. Well, B mod is already, and by which I mean DG modules over a DG algebra, and that's already pre-triangulated, idempotent, complete. pre-triangulated idempotent complete i don't have to worry about that um a pair uh m comma pi so m would be a module over b a b module and then pi would be you know from e2 e2 tensor m to e1 tensor m pi would be um just a map not not an isomorphism or anything just just a map okay um and we want that that's that's an object of the thing on the left so we want that to be the same data as So, we want that to be the same data as a module over this DG algebra we want to build. Okay. So, how do we do that? So, m pi is supposed to be the same data as, so m gets acted on b, but we want m pi to be the same data as something getting acted on by delta sigma of b. Or sorry, we want we want delta of sigma of b such that that's true. Okay, so um, m is a module over b. So, if I have m pi, that's, you know, if I M pi, that's, you know, if I have what I want to be a delta sigma of b module, that in particular gives me m, so it gives me a b module. So what I'm thinking is maybe this dg algebra delta sigma of b is is bigger than b, so that if, you know, if delta sigma of b acts on something, then b acts. Okay, so let's try to build it like that. So can we sort of say delta sigma of b is b plus something more, okay, such that, you know, if m is a module over b, then the data. B, then the data m pi, the extra pi data, is equivalent to the action of like the something more in the algebra delta sigma of b. Okay. And well, pi, what would that be from E2 tensor m to e1 tensor m? Now we're going to assume this doesn't quite look like something acting on m yet, but if we assume e1 has a left adjoint, then it is. So we're going to make that assumption, and we can do that. Assumption, and we can do that by making some algebraic assumption on the bimodule. So, but basically, if E1 has a left adjoint, then a pi from E2 tensor M to E1 tensor M should just be the same thing as some other map from like E1 dual tensor E2 tensor M, and then just mapping to M. Okay, so maybe I'll call that Zeta. So, assuming that we have this dual, then the X. That we have this dual, then the extra pi data is the same as this extra data. And now this looks like something acting on M. Like we have a map from that something tensor m into m. Okay, so it's like we want this to be the extra stuff in delta sigma of b on top of what was in b. Okay, um, well, the problem is that you don't have a multiplication on this, you know, if I have two things in that, I can't multiply it. So, why don't we just throw in the whole thing? So, why don't we just throw in the whole tensor algebra of that thing? Tensor algebra of E1 dual, tensor E2, that has a multiplication. And it contains, you know, if I just have this linear map, you know, this thing, tensor M into M, then I just naturally get a module structure over the tensor algebra just by letting some tensor act by doing that map a bunch of times. Okay, so what our definition in the algebra case is going to be, it's going to be some quotient of the tensor. To be some quotient of the tensor algebra, and like the zeroth tensor power is b. So, this algebra contains b. The first tensor power is this thing that like sort of looked like the extra data pi that we had, and then all the higher ones are generated by those. Okay, um, so and I just want to say what the extra quotient is in the case not where we're doing delta sigma of b for a general b with commuting actions, but just when we're taking now the case when b is the tensor product of, say, a1. B is the tensor product of, say, A1 and A2 as DG algebras. So if I have DG algebras A1 and A2, and say they get acted on by these bimodules, E and tau and stuff, well, I could just take the tensor product of A1 and A2 as DG algebras, but I'm trying to form a bigger type of tensor product. It's going to contain that as a sub-algebra, but it's not going to be everything. Okay, so in this case, though, we're going to define this big algebra. So, we're going to define this big algebra as a quotient of this tensor algebra. And so, let's look at this case. B is this ordinary tensor product of DG algebras. We have these, and I said end of functors, but I should have said bimodules because we're in the bimodule case. Sorry for the typos. But so if I have this, well, we made some technical assumption that I might have slid by on a previous slide. Have slid by on a previous slide. We assumed a certain map is an isomorphism so that we can sort of commute anytime I see an E1 dual and an E2, I can commute those past each other. E1 dual commutes with E2 as well as E1 commutes with E2. So this means if I have a tensor of a bunch of like E1 dual, E2, E1 dual, E2, E1 dual, E2, I can just put all the E1s to one side and the E2s to the other side. And then there's nothing more I really, you know, then tensoring over this algebra. Then tensoring over this algebra B actually does nothing here. So, this is going to give me this sort of tensor product. And it's not that it does nothing. It just goes into this E1 to the M. That's like a tensor product over the algebra A1. Okay, and here E2 to the M is a tensor product over A2. So that's where the tensor over B went. But now in this case, we define the relation ideal. So remember, we wanted this delta sigma. Remember, we wanted this delta sigma of b, which in this case is going to be this tensor product of like two representations on dg algebras. This is going to be the following quotient. It's going to be whatever quotient of this thing right here makes the tensor product B over this algebra, HM, also known as NCM, the Nilkoxeter algebra. This is the endomorphisms of like E to the M in our monoidal category U. So it's a diagrammatic algebra with like Diagrammatic algebra with like crossings, no dots, and D of a crossing resolves that crossing, and a crossing squared equals zero. Okay, so that's this algebra HM. And so this is the sketch I want to give of this definition of A1 tensor A2. If A1 and A2 are like DG algebras acted on by this U thing, then now if you're familiar with Douglas Manelescu, this formula may look familiar, but we're going to define But we're going to define this A1 tensor A2 so that this is the definition. It turns out that this is very compatible with the category level definition. So like in the category level definition, we looked at when we looked at f comma pi, well, I didn't emphasize it too much, but pi had to satisfy a certain compatibility condition with the tau maps that you had. That's equivalent to saying. Equivalent to saying that I have a module over this quotient thing, not just a module over this tensor algebra, but a module that descends to something over this quotient. Okay, so that in the end, what is true is that a module over this quotient of the tensor algebra, this delta sigma of b, in this case, this a1 tensor a2, it is the same data as the m, pi, the data of an object of this delta sigma applied to the category. Okay, so that these constructions. Okay, so that these constructions are compatible. So, okay, we can use that idea in a sneaky way to define the bimodule E. I don't want to spend too much time over this because I want to get to the strands bit in the last 20 minutes. But so I defined right A1 tensor A2, but I said, right, I had E1 acting on A1, I had E2 acting on A2. What's the E acting on the tensor product? I still need to define. On the tensor product, I still need to define that, right? Or at least say something about it. Well, here's what I can say about it. I'm looking at this double tensor product thing. That's a module over itself. But we said that modules over this thing, any module over this thing, can be encoded as some m pi, where m is going to be a module over the ordinary tensor product. In this case, the m is just this big tensor product thing as like a left module over the ordinary tensor product. A left module over the ordinary tensor product, which is a sub-algebra of it. Okay, so now here's how I'm going to define right the e was supposed to be the mapping cone of pi in some sense, and that's exactly how it's defined here. In this case, if you translate through the definitions, this is what you're going to get is that I sort of take E tensor M, and this is my M here, and that's mapping by this pi that I had up here. By this pi that I had up here into E1 tensor M, and I take the mapping cone on that, that's my bimodule E over this tensor product. And then there's a natural way to define the endomorphism tau of E squared. So this is just my little bit of saying vague things to indicate that, yes, the construction closes so that given, you know, A1, E1, tau1, and A2, E2, tau2, we don't just produce A, but we produce A, E, tau. Okay, another to represent. Okay, another two representation that then we can start tensoring more stuff on. That's the benefit of you know making something that's of the same sort of you know thing that we started with is we can make you know higher and higher iterates of this construction. All right, so that is what I wanted to say about the algebra of this construction. Now, in the last 19 minutes, I wanted to talk about the relationship with Hagard fluor homology and with these explicit algebras that, by work of Aru, discovered. That by work of Aru describe partially wrapped Foucault categories of symmetric products. Okay, and these are these so-called strands algebras written A of Z, and I'll say a little bit about what these things are. There's different versions of these, and it turns out that this project favors one of the versions, the Zarev bordered sutured version of this, over the LOT pointed match circle version. That's so hopefully I'll try to indicate why I think that's the case in the next 19 minutes. In the next 19 minutes. So, for us, we're going to say, okay, these algebras, what are they? They are some DG algebra that's associated to a piece of combinatorial data, which is in the bordered sutra framework, it's called an arc diagram. So it's just going to be a bunch of intervals, or Zarev doesn't allow this, but you can. You can allow closed circles as well. And then they're going to be matched. Okay. So there's going to be finitely many points in these circles or the interior. In these circles, or the interiors of the intervals that are matched in pairs. And so I'm going to draw the matched points by drawing a red arc between them. So here, unfortunately, this is a little bit small, but this is a single interval. And then we have two pairs of matched points that sort of interleave each other. And on the other hand, we have an arc diagram that's not considered by Tsarevin because this has circles in it as well. So then this point on the interval is matched to. On the interval is matched to this point on the circle, and then we have another matching down there. Okay, um, and now these are kind of weird diagrams, but what you can view them as is sort of parametrizations or combinatorial representations of surfaces. And then the surfaces are supposed to get assigned categories, and it's going to be the you know derived category of this algebra. Okay. And I don't want to, if you don't, if you haven't seen how you're supposed to get like this surface with extra structure from these things, just Extra structure from these things. Just believe me, there's this way of building a surface. You sort of thicken up the black parts of this diagram, and then you glue on handles for the red parts. So like right here, I guess I got to move my. Well, okay, you can see kind of this one over here that I can't actually move my cursor further, but hopefully it's clear enough how you get that from here. And then the surface has this extra boundary structure, which is actually very important, but I don't want to talk about it in. Actually, very important, but I don't want to talk about it in this talk so much. But it's this sutured surface business, as Zara refers to it. And I just want to contrast with the LOT perspective where, you know, these algebras, you'd assign the same algebra to a different but related type of combinatorial gadget. It would just sort of recover the one interval case of Zarev's story. And instead of drawing the interval, though, you would draw a circle with the base point. So the translation between Point. So the translation between these stories is that given the LOT pointed match circle, you cut open at the base point to get a single interval, and then you're in Zarev land. And vice versa, given like one of these Zarev single interval arc diagrams, you just self-glue it and put a base point there to get the LOT story. Okay. So the LOT story is, in some sense, more widely known in the literature, although the Tsarev story is also very widely appealed. Also, very widely appears in the literature, but um, okay, I guess my uh my slides tell me I'm supposed to say a bit about this algebra in 16 minutes. I think that's reasonable. Um, so before I get into what you know what this looks like when you start doing this cornered floor and how the tensor product comes up, I want to say a little bit about this algebra that you would associate. So, say I have one of these Z's, and we're going to take this, this one that I'm highlighting right now. This, this one that I'm highlighting right now, uh, this sort of torus matching that's called, um, as our example for this slide. So, I'm going to make some algebra, and I'm going to specify the algebra by saying what's its basis. It's going to be algebra over F2, my favorite field, F2, because there's no plus and minus signs. So that's always very nice. And so, the algebra I'm going to give a basis over F2 is going to be certain types of pictures, and the pictures are always of. And the pictures are always of upwards veering strands diagrams. Upwards is with respect to some orientation that you always have on these z. Okay. And well, there can be solid lines and dotted lines. And the idea is that all the lines have to be solid except for just a horizontal line, one that doesn't upward veer at all. Those are treated differently. Those have to be dotted. And that's just a notational convention, but they have to come in matched pairs. We have this. We have this line matched to this line, okay? And you can't have one without the other. And then when I multiply them, I can take this picture. Well, I can't really actually multiply this by this one, but say I didn't have the moving strand on the left, then I could multiply these two pictures just by concatenating. And the only subtlety comes when I have, you know, a pair of dotted lines. I'm allowed to, you know, make a multiplication that chooses one of them. A multiplication that chooses one of them that then solidifies in this case the bottom line, and the top dotted line gets erased. If I were to multiply this thing minus the moving strand with this thing, okay, so that's and then also if I have a double crossing that's that's zero, that's similar to the last talk. And if I have then one of these circles in my arc diagram that Zarev doesn't allow, I can still make the same definition. I can still make the same definition. I'm just going to have infinite dimensional algebras because I can wrap infinitely many times around cylinders. Okay, so this is just a description kind of you give a basis of these pictures and you say how to multiply them and then the differential resolves crossings, including with like a dotted line, the differential of this, it would just resolve this crossing by solidifying this top dotted line, and correspondingly it would erase the bottom one and then it would resolve the crossing. One and then it would resolve the crossing. Okay, so that's a sketch kind of of how these algebras are defined. So here's a picture: like if I'm trying to concatenate and the ends don't line up, the multiplication is supposed to be zero. But then here's how I'm supposed to treat the dotted lines, the solidify and erase type of business. Differential resolves crossings, differential of this. I mean, all ways of resolving crossings, including if you want both possible parts of a dotted line pair, could contribute to the different. Line pair could contribute to the differential, like in this picture. Okay, and then by work of Aru, these explicit diagrams describe the endomorphism algebra of certain Lagrangians in the Foucault category, partially at Foucault category, which generate. And this sort of extra structure on the surfaces I was drawing here, this sutured structure, that directly gives you this data of stops that you need for the partial wrapping in a rooster. So it's very natural from that point. In a roost story, so it's very natural from that point of view, and in my opinion, from other points of view as well. Okay, so right. So now that we know a little bit about these algebras, then in 12 minutes, we can look a little bit about the cornered floor approach to decomposing these algebras into smaller pieces and gluing together an algebra. Say for this thing in LOT's story, it's sort of like two copies of this story. It's sort of like two copies of this torus matching. And it's going to represent, instead of a torus, it's going to represent a genus 2 surface. And you can ask, well, can I get that by gluing together? Well, I want to sort of cut this diagram somehow. And in this language, it's going to look like I'm cutting this pointed match circle into two half-pointed matched arcs or something. And then I want to know how I would recover the algebra of this big circle from something that I associate to each of these pieces. That I associate to each of these pieces individually. Okay, and the answer that they give algebraically is very reasonable and ends up being equivalent to this tensor product thing that we do is you take for each of these pieces, you say for the top piece, I'm going to define some sort of thing, new type of algebraic gadget, using the same type of pictures that were used to define the algebra, but I'm going to let some strands sort of Let some strands sort of emerge from the bottom of this interval that I was dealing with. Even in the, by the way, even in LOT story, the strands pictures are always drawn in an interval, not in a circle. Okay. And so for the bottom piece, then they define some other gadget that's based on these type of pictures. And then there's a very natural way to describe the glued together algebra. And that is, it's Algebra. And that is, it's a direct sum over, you know, if I have some piece like this, and I'm allowing M strands to emerge from the bottom, I can tensor that over this nil-Coxeter algebra or nil-hecca algebra with a differential, this HM thing. I can tensor these two things, and I'm going to get a picture that looks like this, where a crossing can pass above or below that green line. Okay. And just diagrammatically, it's pretty clear that. Grammatically, it's pretty clear that a formula like this will give you together the algebra of the glued together diagram. Now, the question is: how do you interpret this? And a related question is, what if I had the genus 3 surface with three of these little matching patterns? How would I build that algebra? Well, I could do one of these cuts, but if I did two of the cuts, it's like, you know, how am I, how do I know this bottom cup piece? I know this bottom cup piece for a genus 2 matching? That's not what this story tells me. It only tells me a closed piece for a genus 2 matching. Okay, so it's not something a priori that I can apply for more than one cut in this way of thinking about it. What I'm claiming is that the exact same algebra can be applied to do it more than one time, except that you need to elaborate. You don't want to just define the algebra. You also need to define the e and tau on the algebra. Tau on the algebra, and that's the idea. And this makes sense in the Zara framework instead. So, um, so I want to ask what happens if I look at this story instead, but I cut open at the base point of point and match circles. So, I'm in Zarev world, and now it looks like I'm trying to recover the algebra of this thing from the algebras of these two things. So, this is already just diagrammatically different in character from the previous slide, just because all three of these pictures are the same. All three of these pictures are the same sort of thing. So that you would expect one of them has extra structure from like strands going down, strands going up, if and only if all three of them have this extra structure. In other words, this sort of extra structure that in Douglas Manelescu's story looks like it arose when you had a weird type of diagram like this only, okay, that you would only consider this when you're considering this. When you're considering this, well, in the Tsarov picture, it looks different. In the Tsarov picture, it looks like you're always supposed to consider this, right? Even if you're not like looking at, you know, even for the glued together thing, as well as the two pieces. So this, by the way, is like saying on a tensor product, you know, the second type that we were talking about, you take two representations and on the glued thing, you still, that's still a representation. That's the same type of distinction here. Of distinction here, okay. So, so if we do the Zarev style thing, then the gluing looks very simple. You just end glue these, and so how we view the Douglas Manilescu construction then is that anytime I have one of these arc diagrams and I pick a distinguished interval. So, in particular, if it's like one of these LOT ones that I'm drawing, the whole arc diagram is just a matched interval. So, that's the distinguished interval. Okay. And if I have two of these arc diagrams, And if I have two of these arc diagrams with a well, sorry, if I have one of these arc diagrams with a distinguished interval, then by what I was just saying, that should carry some structure coming from these type of pictures with strands going down, strands going up. And that is actually what is going to be the structure of a two representation of this U DG monoidal category as bimodule and bimodule endomorphism over my DGL. Morphism over my dg algebra A of Z. Okay, so we're going to use pictures with strands going up, one strand going up. This picture I can sort of multiply on the left or right with things with zero strands going up, and I'll still get something with one strand going up. And so that means pictures like this are going to give me a bimodule over the strands algebra. And now, if I start taking tensor product with this bimodule with itself a bunch of times, I'm going to get that describable by a basis. That is describable by a basis where M strands go up. And that's the sort of M strand thing that appears in Douglas Menelescu. Now, that strands going up, how about the strands going down thing? Well, if I look at this bimodule, okay, and this is just what I said, if I tensor it with itself a bunch of times, it's M strands up. But I also wanted to look at the left adjoint of this bimodule, and that's actually not so hard to compute here. You can identify that with the things with strands emerging from the bottom. With strands emerging from the bottom. So that, you know, similarly, if one strand emerges from the bottom, I multiply on the left and right by stuff where zero strands emerges from the bottom, then I'll get another thing of this form. So pictures like this give me another bimodule over my strands algebra, and that's the dual of E. Okay, so then what would this formula? Okay, well, I guess I gotta, before looking at the tensor product formula, you know, to have a two representation of u on this strands algebra, Of u on this strands algebra, I need an endomorphism tau of e squared. Well, if e squared is just two strands going up, how does tau act? Well, it can act on, you know, just by sticking on top where I have those two strands going up, I stick a crossing on top. So if they didn't cross before, now they do. If they did cross before, I have a double crossing, and that's zero. Okay, so on this strands construction, given this distinguished interval of my arc diagram, I naturally have. Arc diagram, I naturally have not just the A, but the AE tau. Okay, and now I can ask what happens if I have two of these things, I glue them together end to end, and the Douglas Manilescu formula says, basically, just translating it directly, says that the algebra of the glued together thing is the tensor product of the two pieces. Okay, as DG algebras. So if you just say as DG algebras, then the result doesn't tell you that. Then the result doesn't tell you the E-by module over the glued together thing. So then, if I want to glue something else on, I don't know how to do it yet. But so if you, and this elaboration involves ideas similar to Douglas Menelescu, but which extend what they're doing and aren't covered in that paper. But so, what's true, and Raphael and I proved, is that if I have this definition of tensor product, Have this definition of tensor product, higher tensor product. So, this does build an E-by module on the right-hand side. And on the other hand, in the Zarev interpretation, I have an E-by module on the left-hand side. And these also agree, not just that the algebras are isomorphic, but the E's and also the taus agree so that now I can keep tensoring on and keep applying this theorem over and over because it always at every stage builds all of the structure on the glued together algebra that I need to then glue that to other things. To then glue that to other things. Okay, so, and we prove also a more involved version of this that lets you sort of self-glue an interval into one of these circles that Zarev doesn't allow. And that's another can of worms. That's maybe the hardest part of the paper. I don't want to say anything about that here. I just wanted to say in three minutes, one final remark, or I guess two final remarks. One is about what does this look like topologically? Because we talked about this end-to-end gluing of these. About this end-to-end gluing of these surface representatives, these combinatorial things that represent surfaces, but how about the surfaces themselves? What sort of surface gluings does this tensor product correspond to? And it is related to the sort of sutured structure. You need to take the sutured structure on these surfaces into account. But one way to view it is just sort of gluing along an interval in the boundary of these surfaces. It's not like gluing two surfaces along a common circle boundary. It's like taking an interval component. Taking an interval component or taking an interval little piece of the boundary of one, and so it's like a boundary connected sum or something. Um, I think that's what it's called. Um, another way to view it is, you know, if I, you know, well, this is basically the same. I'm gluing an interval component in the boundary. It's just I'm viewing it differently with respect to the sutra structure. Let's not dwell on that. Let's let me just say that there's this other way of viewing the same operation, and that is, you know, instead of gluing an inner. Is you know, instead of gluing an interval here in the boundary of one surface to the to an interval in the boundary of the other, here's how I can think of that. I have this sort of open pair of pants, it's like a pair of pants, but only half of it. And so I can, yes, interval, interval, interval, and then the rest of its boundary is also three intervals, but I can like, if I want to characterize what this operation is doing in something that sort of looks related to the ordinary interpretation for tensor products. Interpretation for tensor products of algebras over or modules over Hopf algebra, which is like pair of pants style stuff. I can look at this open pair of pants. And this produces the same gluing that we're getting from our operation that our gluing theorem recovers algebraically. Okay, so it's like this. So I just wanted to compare with it. Usually, the closed pair of pants, usually, I think if I have some representation of the quantum group that's associated to the circle, and then I have another one associated to another circle, and then the Associated to another circle. And then the pair of pants gives me that tensor product operation. So if I glue, you know, maybe here I have a representation, here I have a representation, then glue in the pair of pants, I'll get the tensor product where the quantum group is acting by the co-product. Here, it's similar, except one, it's intervals instead of circles, and two, it's GL11 plus instead of GL11. These seem related, but that's the story I want to come to eventually. I don't think I can say anything. Eventually, I don't think I can say anything intelligent about that right now. On the final side, I just wanted to make one slight advertisement for a paper I put out a few months ago is that if you're wondering, if you know about these Auja-Salbo algebras that have recently been used for this purpose of computing HFK with tangle decompositions, you might wonder: are these things tensor products? Are these algebra tensor products? Well, no, they're not, but you can do a version that is. Can do a version that is well, the algebra of this type of diagram does arise as a tensor product, and it's derived equivalent to the algebra of this diagram. You can try doing a variant of Vaucheral Ensemble theory over this. There's actually some very nice things that happen when you try to do that. But that is for another time. I am thankfully only zero minutes over. So, thank you very much. And I'm happy to answer any questions that anyone has or try to answer. So try to answer. Thanks, Andy. Questions? Andy, I have a motivational question. If you don't have taus, you just have me, like you say, if you have two functors, E182, acting on two categories, can you define the trans product? Yes. Right. What do you need to do that? Well, so you need. Well, so you need like definitely the tau because, in part of the thing that I didn't say when I said like f, pi, and then e of that is going to be mapping cone of pi, then this pi prime. Pi prime is going to be specified by some like two by two matrix. Like it's going to be some endomorphism of, or it's going to be some map from like E1 of the mapping cone to E2 of the mapping cone. And in there, you're going to have like E1. Squared and E2 squared terms. You don't have tau, right? You don't, if you don't have tau, then you don't have any relation on the square of the functions. It's not even that, it's that you can't build the function. Yeah, yeah, I mean, that's right for the factors. And then on the tensor product, it's sort of even worse. If you don't have tau on the factors, then you can't even build the e functor or in all. E functor or and also you can't even build like the L okay on the DG algebra level, you can't even build the algebra. On the category level, what you can't build is the by module E. Are you saying that to define categorical commodiplication, you always need some kind of self-crossing? That's what it, I mean, that's what it seems like, although I don't want to commit to that in that general. Although I don't want to commit to that in that generality, because I'm thinking of it appearing in this relatively technical part, like you need this term in this matrix to be to make sense, and it's like tau or like tau one and tau two. And so like you need, but more generally than that, could you do things in a different way? I'm not sure. So is there a pictorial way to explain why you need a self-crossing to be able to define kiquadical commodiplication? Is that a diagrammatical explanation? Because I don't understand. Explanation because I don't understand when you explain it like that. It's possible, but I also, right? I, yeah, so I that would be good to have, but I also don't understand, or like I don't know how to do that. Um, I agree. The yeah, I don't know. More questions? Okay, Dan Cooper? Hi, Andy. Can you also construct the algebras that Ina and Vera produced in their work, which they used to study the Hagard floored knot homology? So these are sort of like these Aujasabo ones. They should be cozul-dual to certain instances of the Aujasabo ones, or at least certain variants of the At least certain variants of the invert ones should be, and these cannot be. These sort of are related to canonical bases or crystal bases for the underlying representation, whereas this type of diagram is related to standard tensor project bases. But what can be is the algebra. So Yin Tian has this paper on categorification of, I think, what he calls UT of SL11 and its tensor product representations. There's this algebra appearing in there that can be built as a tensor product. You can kind of guess because. You can kind of guess because his things, you know, his and decomposable item potents over his algebra categorify standard basis elements, not like some canonical basis or something like that. So no for EPV, but yes for TM. And these sort of all fit into like a square of different diagrams. So a quick follow-up. Can you choose a representation, a two representation, so that the whatever you want to call it? The whatever you want to call it to R matrix is compatible with the braiding that's studied over these algebras? Well, yeah, it depends on. So different algebras, you can look at different braids. For instance, EPV have a braiding. Yeah, so Oja Sabo have a braiding. I have a braiding over these things. And the braidings are in general morphisms of two representations, although that hasn't been. That hasn't been established in all cases. I think, for instance, the Oja Sabo case, I don't think that's in the literature, but it's relatively simple. Is that, sorry, was that what you were asking? I don't know if I entirely. Well, your first few slides were about how you get the Alexander polynomial from GL11. And here you've categorified this monoidal category. So potentially you could choose an object in this. Choose an object in this categorified monoidal category to maybe you need more structure to get the full knot invariant, but maybe you get the braid group action by commuting two representations. And I'm wondering if that's known that this braid group action commuting two representations for some fixed two representation is compatible with. Is compatible with one that has been studied by people studying this slightly, you know, bordered Hagar floor construction. I am not sure I understand the question. So there are braidings and they're the ones that people have studied and they're compatible with the two representation structure, but I that's not what are you asking is compatible? So, like, it's not this, this, this story is. It's not this story is kind of general, it can be applied to all of the different things in the literature on this topic. Um, it is a little bit more tautological in a case maybe like Ojoa Sabo or EPV than it is in a case like this diagram here, where it's really built from a tensor product. And this tensor product theory is like really key to understanding what's going on. Whereas here, it's like this is not built from a tensor product, the two representations. Tensor product. The two representation structure is very simple because, like, this is it, sort of only has to do with this one little interval here. It doesn't interact with all of the other arcs. Okay, so that E squared is actually zero on the nose. You don't need a tau, that sort of thing. But yeah, it's all of these, all of these different things that have been studied. It's not like I'm proposing here a new thing that hasn't been studied in the literature other than this one. This thing is new. This thing is new. And then, yes, I do have a braiding on here, and not full results, but preliminary, you know, say for like just two strands where I don't extend out by the identity on other side, then yes, I can say my braiding is, then I've change of basis bimodules between this thing and the Augeva-Sabo algebra such that my braiding by module corresponds to theirs. But that's the only sense I think right now in which I have like. Now, in which I have like a new instance of these types of tangle constructions for HFK, that then you can ask, is it related to the literature? What I was describing in this talk is a little bit more like a general properties and facts about these things that you can think about in any of the cases that appear in the literature, and they can be more or less useful to think about in various ones of these cases. Okay. Okay. So is it known that the two tensor product gives rise to a braid group representation? Abstractly, no, I don't think so. Like that, that would be really great. All the braidings I know, I've got by thinking about Hagride diagrams. Okay, thank you. And I think that's something that Raphael has been thinking about, especially in general cases and stuff. And that's something we'd eventually like to, you know, have some theorem along those lines. You know, have some theorem along those lines. Like there's a general rating on the two representation two categories such that these Hager diagram things are related to it. Okay, I understand. Thank you. And Jay, what's next? So if I give you sort of a true representation of this categorified nilheck algebra, say corresponding to a genus one surface, so just like the little diagram you are considering. Diagram, you are considering in your talk. Then, of course, I can get by your tensor product construction things for every genus. So, do you know that sort of Hagard fluorhomology is the unique one that gives you an actual TQFT that gives you invariance of three manifolds and four manifolds? Like, if I started with a different one, can you see that? One, can you see that I would get something that's not an invariant? Well, I mean, I guess I don't have enough of like a well-developed theory that stretches to three and four dimensions to really allow me to like answer that. I mean, this, it will build you some algebra, but it's not then going to like, so then with some creativity, you could try to. With some creativity, you could try to see whether or not you can fit that into something with three and four-dimensional ramifications, and then maybe discover that Hagard floor or things like it are, you know, I would guess, you know, you could do variants that are, you know, it's not like you could build different versions of Hagard floor by, you know, cutting along similar types of surfaces, but then the three manifolds are different or something. But yeah, I don't like so far the dimensions three plus in this stuff has been kind of. In this stuff has been kind of what you need to do if you really want to make that interact with this stuff. What you'd really like is to have like a tensor product formula for gluing together A infinity bimodules from Hagar diagrams, just like I glued together these arc diagrams. Now suppose I have Hagar diagrams. Now suddenly I have to describe the A infinity structure, A infinity action of this tensor product algebra. That I would really like to answer that question, and then you could start pushing this. You could start pushing this farther into the, but like right now, all I know, like, I can't really get to not invariance or anything. It's not like I can't talk about three dimensions or four dimensions. It's just that I just have to do the local things and talk about for like two strands and have point group by modules commuting with that and then hope that eventually I can define this A infinity, you know, extension out by the identity type of operation. Maybe so I guess it's related. So, I guess it's related to what Ben was asking. Somehow, when I do this operation to get the thing associated to, say, the genus G surface from the thing associated to the genus 1 surface, is there any way that you can recover the action of the mapping class group on the thing associated to the genus G surface from the action of the mapping? From the action of the mapping class group on the thing associated to the genus 1 surface? That, again, that's the sort of thing that would be great. That's certainly like not the sort of thing we talk about in this paper, at least. So maybe that's desire. It's not like I'm saying I don't, you know, I definitely think that would be great. I think the more we can start pushing, I sort of view those things as a goal of this project that we haven't quite achieved. Of this project that we haven't quite achieved or gotten. Okay, yeah. I mean, you know, my memory, it's been a while since I thought about it, but I mean, my memory was that sort of if you believed that you knew what the categories for genus, you know, a surface of genus G and the action of the mapping class group on a surface of genus G were. G were, then, you know, and you believe that it did extend to, you know, a whole TQFT, then there was, you know, then there's an essentially unique way that it does. So, you know, and I guess, yeah, I mean, I guess maybe the stopping point is this action of the map. Like, I mean, you know, I think if you knew how to understand the action of the mapping class group from the tensor product, then From the tensor product, then you'd be pretty close to being in a rigid situation where everything was determined by the genus 1 surface in some sense. Yeah, I mean, I agree, except that it seems to me that, like, based on the whole Zara philosophy and everything, like, I'm not actually going to want to be looking at TQFTs that assign things to closed three manifolds or to close. To closed three manifolds or to closed surfaces. It's all going to be this things with boundary that you have to think about in some particular way. And what I am especially hoping is true as a variant of this is that you're not looking at like that you are looking at eventually at the invariant of a very simple thing. You want to look at the invariant of a point. You want to say something like the following. The point gets assigned. So if I take this two representation two category of u, that's a two category, but we have Category, but we have a monoidal operation, this higher tensor product, at least on objects, okay? And you'd really want it on like suitably A infinity morphisms, et cetera, but at least on objects. So you could hope that this gives you a monoidal two category and thus kind of a three category. That's sort of what you want to get us on to a point. And I'm trying to write up a paper that talks about: okay, now what that's going to be really hard to study, but if we decategorify and try to do this in three dimensions, This in three dimensions are by three to three-dimensional TQRFT, but still only looking at dimension 0, 1, 2, but and then trying to get up to 3. But this is how I want to describe, I mean, I want everything in the end to go all the way down to a point and to come from the invariant of a point. So I think that would be a really nice answer for like, what is this higher tensor product doing? If it is actually saying, like, oh, it's related to the Haggard form of a point. I almost like want that to be true. So, but I think that. Like, I want that to be true. So, but I think there is evidence for it. You know, I think that we'll see. Okay, thanks. Nice talk. Thank you. I think it was Mina's hand, but now I see Matt's. I don't know. Okay, Matt. Matt, you're muted. Sorry about that. So, do I understand that the algebra That the algebra or the sort of arc algebra, the chord algebra associated to an open line segment, is a sort of algebra bimodule in some sense. The question that I want to ask is, what's the relationship between this algebra and the algebra associated to a circle? Is there some Hochschule domology operation that produces? Are you meaning some matchings, or what do you mean? Just one of these Z algebraas associated. Use Z algebra is associated to chord diagrams. Okay, yep, yep. And you're taking a specific chord diagram or just sure. Well, something I want to take a specific chord diagram kind of supported on an interval. And I'm wondering what's the relationship between the guy with the interval and the guy where you where I self-view. Yeah. Okay, yeah, yeah. So that's, that's the hard, that's, I would say, is like the hardest results in our paper. Do you give it a. Hardest results in our paper do give a description of that in terms of a sort of lax elaboration of the tensor product operation. So there's this delta sigma thing that we're talking about. Okay, that's like the kind of easier version than them, but to do the self-bluing, we needed to do this more sort of elaborate version where things get laxified in certain places. And then we have this theorem that tells. So I probably won't be able to accurately. To accurately talk about that right now. But that, yes, there is. I mean, you get this algebra, and now it can be infinite dimensional because I can have things wrapping around. The idea is when I do this tensor product, E1 dual, you know, like tensor algebra of like E1 dual tensor over B with E2. Like in the case we were talking about, I can put all the E1 duals on one side, all the E2 duals on the other. But in this case, you can't. In this case, I can have like E1 or like E2 and then E. Or, like E2 and then E1 dual, E2 and E1 dual. And that's sort of how I get things wrapping a bunch of times around the cylinder. And you can't just make that like a bunch of stuff going up and then coming on this, like has to go up, down, up, down, up, down. You know, so it's the combinatorics involved in proving the gluing result become more difficult. And that's one reason why the paper came out later than maybe it would have otherwise. But I'm glad that we do have this result in the end, but it is complicated. Got a big one. Cool, thanks. Any more questions? I was actually one way. I'm sorry, I just wanted to follow up. Maybe I missed something to Jake's question about gluing from Genus1 surfaces. So I understand how you get the mapping cost go back to an unusual 2 plus 1 dimensional TQFT, but if you have this two-category, is there a framework for doing this? Is there a framework for doing this for getting action on the high genus surfaces from just genus one? Getting the mapping class group action? I mean, no, not that I'm aware of yet. Although I would hope that as I mean, that to me seems like an essential part of the TQFT structure when I'm looking at combordisms between 2D surfaces. And it is true that what I know about the TQFT structure. About the TQFT structure, or I'm guessing at the TQFT structure so far is mostly like dimension 0, 1, 2. That's that's just like one reason, you know, it's, I feel like this talk is just a little bit different in character than some of the other talks in this conference, just because, like, I know three is three and four are like interesting, and I do want to think about them eventually. But to my point of view, it's like hard if you're, you know, if you're trying to get three, but you also want that in the same room as zero. That in the same room as zero, that's like it's sort of a harder goal to go for, and so I don't know at the moment, but I do think these are very important things to eventually work out or try to work out. Okay, well, thanks very much. Let's thank Andy again.