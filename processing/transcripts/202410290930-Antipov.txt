So that is continuation of my work that I presented in Cambridge in the summer. And conclusions, I mentioned that that method I discussed could be extended, hopefully, to elastic contact and fracture problems. Contact and fracture problems. And that time I thought about some kind of numerical Wigner-Hof problem, meaning that the matrix would be defined numerically. I knew that it would be discontinuous and there was no hope that it would be solved in a constructive way. But in fact, it was my just prediction in Just you know, prediction in reality was much better, and the solution actually found in closed form, and it's what I'm going to discuss now. So, previous results, I don't want to spend much time on results by other people. I just mention two papers that directly relates to what I'm going to. Relates to what I'm going to discuss. First, in the paper that was published, in the first paper, I used Archnitsky Rostovs model that is popular in contact mechanics since 1964. It is used in many papers. But that model gives only prediction of. Gives only prediction of stresses of contact stresses or tractions under the stamp, and there was no way to extend it, and so on. So, when I use that model for fracture, so basically it was similar. So, in the vicinity of the crack, and just in a very close neighborhood of the crack itself, it was. It was, you know, the solution could give some numerical results, some prediction, but you cannot extend it further. Then second paper, it's what I discussed in Cambridge, and I will not talk about it. So, what results needed, I will mention them in this talk. So, our main model concerns. Model concerns the two-dimensional elasticity. So, the dynamic problem, we have momentum balance equations and also stress-strain relations. If Lamech coefficients and density are just constants, that is a standard problem. Semi-infinite crack propagates in either interfacial crack or in homogeneous plane, both problems. Homogeneous plane, both problems are solved and known in the literature. But what is new here is that Lome coefficients in the density itself are functions of depth. We assume that all functions of depth have the same exponent, nu. Also, to simplify the model, we assume that the loading is running with the crack at the same speed. So, in other words, we consider state. Other words, we consider steady-state problem. So, since, yeah, and we can, of course, introduce instead of x minus vt, we introduce a new variable ψ, and along that variable, we can apply along the x ψ, we can apply the Fourier transform, and then the problem becomes. And then the problem becomes one-dimensional. But because of the power law function for Lame coefficients and density, we will have variable coefficients that when we use momentum equations and implement all derivatives, we will have. Derivatives, we will have governing equations with variable coefficients in terms of displacements. Now, another thing is the boundary conditions. The boundary conditions here also unusual because if we look at the stress-strain relations and we want both structures to be defined and constant. And since lambda and mu vanish at the boundary, so by definition, if not only displacement but also normal derivative bounded, then fractions always equal zero. And there is no way to prescribe them as a non-zero function. So that is why, at the same time, if lambda goes, I mean, if I mean, if y goes to zero, new positive, so displacement should also bound it. So that term needs to be sacrificed and zero. And only one hope is that the normal derivative have a singularity the same as in order to neutralize the zero of the Lame coefficients. So, and that. So, and that is why we have these boundary conditions. Now, how to proceed? We apply the Mellian transform. So, normally Mellian transform is adjusted to polar coordinates. They always, you know, if you have a sector or something, then describing polar coordinates, then Millian transform is anomaly is the best. But here we have Is the best, but here we have the Cartesian coordinates and we apply Millian transform with respect to y for positive y is the standard for negative slightly modified the formula because we have no positive negative half a plane. So then the class of solutions. So since we want displacement apparently to be bounded and at infinity should be decaying and that gives us, we don't fix the beta. We don't fix the beta, it should be only positive and the smallest possible. In other words, we don't want to make our class of solutions narrow. It wants to be as wide as possible. And then, of course, the problem gives us what is beta. All right, so the displacement of the Mellian transform with respect to S is holomorphic in the strip, zero, beta. Then we want to continue because we need to deal with derivative. Continue because we need to deal with derivatives, we need to integrate bypass. We continue analytically, in fact, monomorphically, to the left. And definitely we have a pole at s equals zero because displacement are bounded. And also we will have a need to accept the pole, I mean, the singularity of order one minus nu, because then we have a derivative of the order. Derivative of the order that will make our boundary conditions sensible. All right. Before I formulate the problem, I introduce the shear and wave speeds. By the way, that is the same as in a homogeneous plane, homogeneous case. And since they share the same exponent, so that we can write it in terms of original Lamek constant or. Lamek constant or a new one. And we also need some auxiliary parameters. And we consider only subsonic regime. Also, there are some results already for transonic, but subsonic regime is good because beta one, beta two positive, and it is some sense easier to solve all these problems. Now, when we apply Mellian transform, we deal with derivatives, integrate by. Derivatives integrate by parts, at the standard, we will have shifts. Like we can solve, for instance, Basel equation by using Meiling transform and reduce Turieman problem. And that problem can be solved immediately. And we have, instead of Rabinho's series, the same series from an integral representation, by the way, from Millian transform. So it was similar, and we have two unknown functions, two shifts. Unknown functions, two shifts. What counts, of course, left and right shifts. That is some kind of regular shift, but still it interferes and makes properties unique of the problem, of the solution. Now, since we have polynomials, so we don't need to factorize in terms of integrals. It's good because we will have less complicated expression. So we can factorize this function in terms of gamma functions and introduce a new function. introduce a new function two new functions phi one and phi two and now that function has um infinity at the point nu minus one and that is why one of the poles of that function at the point nu minus one is removed but the pole at the point s0 survives and needs to be considered so the problem after this factorization becomes becomes simpler. We have phi 1s, phi 1s minus 2. So it could be considered like difference equations with variable coefficients, of course, but since we have holomorphicity and so on, at the same time, it could be considered as a classical problem by Carleman for a strip. It's not really classical because we have here shifts more than just one. Just one. The functions g1, g2 doesn't have alpha. Only one place where alpha actually is is in the middle term. So we had it for year transform parameter and it's on its presence doesn't affect very much the problem. So that is also good. So we can write the presentation of solution. The presentation of solution of Kariman problem. Only write it in the interior of the strip. Don't write Sakhotsky-type problem formulas for the boundaries because for our purposes we need only interior, at least for the presentation. And then we can invert the Merlin transform. Of course, it doesn't mean that we solve the problem. We have just representation because unknown functions inside. Unknown functions inside. But what is good is that the unknown functions in theory. So then later we let s be p minus one, and then we have integral equations for the unknown function on the line imaginary part equals whatever for for this contour k minus one or something. K minus one or something. Anyway, it will be a shift of the contour omega that is parallel to imaginary axis. So now we can invert the Mellian transform, use Cauchy's theorem and theory of residues, and find the first two terms. We don't need the other terms, at least at this stage. But what's interesting, we have a first term is constant. Constant. I mean, it's, yeah. And the second one has the asymptotics we need. Now we can satisfy the boundary conditions, the boundary conditions for the normal, for the derivative respect to y. So that term disappears. And here, when we take the limit, we will have exactly that term. And that term has to be exactly as the Fourier transform of the boundary. Of the boundary functions on the boundary conditions. So now the boundary conditions are written in terms of functions phi1, phi2, which are still unknown. Remember, we need to solve the integral equations to fix them. And yes, and we had also an arbitrary constant or functions of alpha here because of the pole. So because of periodicity and the pole, we have the And the pole, we have the assignment and so on. And now we can fix using two boundary conditions, we can fix these two arbitrary constants or functions, inspect to assay constants. And in order to remove arbitrary functions or constants from the integral system, we can represent our unknown in the integral equations as a sum or linear combination. As a sum or linear combination of two functions, which are free of C1 and C2. So now we have two equations, in fact, four equations, because we have a system of two, J1, J2, and then M1, M2, because for each index upper subscript 1, M2. And so they independent on C. We can solve them and then find C1, C2. Find C1, C2 from the boundary conditions, just like two equations, a linear system of two equations. All right, so we find C1 and C2 through those auxiliary functions, which are defined from integral equations, from system for integral equations, free of any unknowns. And assume at this moment that we know them. And in fact, you see that C1, C2 are expressed only through the values of those unknowns, or only at a particular point u minus. Of only at particular point nu minus one. All right, so delta also expressed through this. It's basically Kramer rule. But what's interesting is that C1, C2 is basically, we're just one step before the vector Riemann-Hilbert problem. Because that is C1 and C2 is written if we look back to the representation of displacements. So when we find When we find the jump of the displacement on the upper side and the lower side of the card, it disappears, and we have only C1 and C2. And by the way, all formulas that I present so far is only for the upper half plane. For the lower half plane, we'll be have similar, of course, different constants and so on, but also minus. It's a nature of the Mellian transform for the lower half plane. form for the lower half plane. So that is why they will not cancel, even if we have a homogeneous, I mean the constant will be the same. And yes, we are here. All right, so that gives us a displacement on the upper and lower side of the interface or a crack and also a crack. A crack and also a continuation of the interface. So that is a load that initially was a Fourier transform from minus to plus infinity. Half of that is prescribed. It's where the load is running at the h1 minus or h2 minus. And that is unknown. So basically, the function with plus, it's the function that we normally write in Winnierhoff problem, upper half plane, with respect to alpha. Half plane with spectral alpha. And this, when we subtract them, plus in my plus, it's the upper half plane and this lower side of the cut, because on the continuation of the crack, they zero, so we will have a function. I mean, the integral will be only from minus infinity to zero. So they function analytic in a low-half plane. So, and then we will have a vector Riemann-Hilbert problem. And so, this is written here. So, it is written here. The entries of this vector layman hero problem are quite interesting. First of all, because we had only signum and we analyze everything and turn out that the diagonal elements of that matrix are continuous at the point alpha equals zero. So it means that there is no discontinuity from alpha negative to positive. From alpha negative to positive. The same of diagonal elements, yeah, and they're real and they're positive always for any parameters which look. I mean, I looked at. And all diagonal elements pure imaginary and they change their sign, but always their product always negative. It's also good. So, and so basically, this problem has only one point of discontinuity. One point of discontinuity, a piecewise constant. Of course, that problem is solvable in explicit form. And before I proceed with the solution of that problem, I want to mention how we actually find the entries of the matrix, because the entries, this constant, are the solution of those system which are associated with. Associated with Karl Demand problems. So we go. Oh, by the way, before I go, this was one slide more. That is already mentioned that diagonal elements positive of diagonal elements pure imaginary change the sign and their product k1 and k2 not even written. Not even written negative written a1 a2 a21 always negative. Yes, and also that relates to the next slide that in order to find because we need to solve current problem that associated with the lower half plane and the upper half plane. But it turns out we need just to solve only for one of the planes, say for upper half plane, and then because of the structure for low. Uh, for low half plane, Carlyman probably for low half plane. We need only to change the sign in the solution of the upper half plane, and of course, the parameters. So, in other words, they're not just automatically here, when J and I mean lower upper indices are the same, we will take only change the parameters. So, it's had some kind of Um, yeah, anyway, correspondence relations. There is a diffraction problem, uh, diffraction theory, they like reciprocal, reciprocal relations, something like that. Um, so now integral equations free of alpha. So we have that integral equation, but in fact, we have But in fact, we have here, as I said, it's a system of two equations. J could be one and two. So if we have one, then we have expressed through two. And if we have two, that express through one. And then we have also index M, but index M only relates to the right-hand side. Then it's of course nice written, but how to solve? And it's a point or parallel to imaginary axis. Cos of course behaves nicely, but when p approaches s then disappears and there is no contribution, exponential contribution from this function. So how and JP oscillates, so it's better to have a better contour. So first we go. A better contour. So, first we go to real axis that is apparent substitution and have hyperbolic coach. And then we have another substitution that maps the whole contour to the contour 0, 1. But then we split the function into two and then we have contour 0, 1. Now, I say each Integral equations have kernels with a fixed singularity, no Cashi kernel, and that is regular. And that is not nice. First of all, they oscillate. The behavior of this function will be next slide. But anyway, so they oscillate, they change sign, lots of things. But the presence of y plus x in the bottom, so it's also. In the bottom, so it's also not so welcome for numerical computations. So, present properties of that function j that I removed from, so initially it was in the integral, right? So, I rename it and put it aside. So, basically, it's just a matter of taste, of course. So, that function j1 and j2 have oscillating singularity at the point zero. It's exactly. Singularity at the point zero is exactly where we have fixed singularity in the kernel. And otherwise, they bound it but oscillate. And in order to remove, yeah, and see here there is no oscillation, right, in the kernel. That is regular, that is monotonic, but here we have oscillation in the G. So that is why we are enforced to have oscillation on the solution. Otherwise, it will be. It will be everything contradict each other. So we prescribe a selecting factor for the solution at the point zero, then analyze again by Mellian transform, by the way, as this integral in order to find the symptotics. And then that is more or less standard in the system of single integral equations, especially with fixed singularities where it wants to find a singularity. So analyze behavior of all parts at the point zero. Of all parts at the point zero, and in order to remove oscillating factor, we will arrive at the specific characteristic equation for the unknown deltas. And we find they're quite symmetric, have these formulas. So that is now we know the behavior, selecting behavior of the solution. And of course, we need to do some numerics. We use quadrato formula, but of course, it should not be standard. So, that is a quandary form quadrato formula for single integral with oscillating weight. And actually, when I wrote the quote, it was quite stable. I couldn't increase accuracy of computation indefinitely, but to tend to the Definitely, but to 10 to the minus 4, in some cases, minus 5, it was plausible. But next, if I go further, it's not because of delta, because we basically use a quadrature formula. We have a full system of linear equations. And then, in order to increase, for each change of parameter, we need to introduce a scale factor. To introduce a scale factor, that is quite tedious work and so on. But again, 10 to the minus 4 was good. Now, the structure of the matrix, also nice. We have each block is 4 by n. So we have diagonally blocks, then four blocks, zeros, and this block symmetric. And that is how our system just wrote a half. Is how the system just wrote a half so computations were quite accurate. So, there's also some symmetry property of the solution they described here, and that's how I actually realized that accuracy was 10 to the minus 4, because some real formulas need to be real, some imaginary, and normally the undesirable imaginarity was 10 to the minus 4, or vice versa. So, and then was more. So, and then was more or less steady convergence of the main part real, and so. All right, so we're done with Kerr-Mann solve systems. You go to vector problems. As I said, it's quite standard, nice diagonalization, transformation matrix, eigenvalues, also nice. Then we factorize factorization in explicit form, so we need to factorize two functions. That one, quite standard, through. That one quite standard through branches of multivariate function, and that one so factorized, and we found the solution. So, the behavior also similar to what we have in fracture mechanics, but of course, instead of minus one, half we have stresses, for instance, nu minus one, and here displacement. But oscillation here, different delta, delta expressed through this curly man. Model one problem: no oscillation, solved explain. Solved explicitly, very simple, some straight and some characteristic traditional for fraction mechanics, like stress intensity, straight energy change when the crack precede by delta L and then Griffith style criterion that we designed according to the solution. So the two graphs in the finish. So that shows straight energy for a mode. Straight energy for mode one. Oh, by the way, there is no release waves here and no that trap zone when the crack can propagate beyond release field. But we don't have surface here anyway. But all other ways are here. Mode two and my conclusions. I will probably stop. 