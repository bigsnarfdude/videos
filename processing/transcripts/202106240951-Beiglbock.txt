I would say these are the main contributors, but honestly, this is not a complete list. Okay, so I hope I should be more complete when I actually code the results. So, what are we trying to do? Yeah, so our basic role model is Role model is classical optimal transport, and the way that the classical Wasserstland distance provides a very nice way of creating an ambient space for the set of probability measures. I mean, by now we are very familiar with this, but I think it's a really interesting step. That usually you look at probabilities very much in isolation and then And then, based on all these spectacular advancements in optimal transport in the last maybe 25 years, there is this idea that you should look at probabilities as a geometric space. And you can perform all these wonderful geometric operations between them. You can look at natural interpolations between them. You have this gradient flow structures. You can form barycenters, etc. And yeah, so what I question that I've been very interested in in recent years is: is there something similar for stochastic processes? So, can we find a nice ambient space which plays a similar role for stochastic processes? And I mean, even though stochastic processes themselves are very classical thing, it turns out that there is really not that much. That there is really not that much done in this direction, or known in this direction. And I mean, I want to emphasize that storage processes for storastic processes, there is so little done that this is a relatively long program. So you would kind of like to start to understand what is the right topology to measure distance between to measure when strastic processes are similar. And then, of course, you hope there is some natural kind of metric. And finally, you would be. And finally, you would be extremely happy if you can find a geometric structure that is behaving in a similar way as the geometric structure on the Bassels Brand space of probability measures is behaving. And maybe as further motivation. So I think in general, this is very natural questions. I mean, whenever you use, so in applied maps, if you use a stochastic process to model whatever type Process to model whatever type of phenomenon, you will never think that your model is totally right. So, you would always like to have some continuity or stability. And it turns out that it's actually not trivial to identify good topologies that guarantee such stability or continuity results. So, the first topologies you would pick, you just don't do it. So, I think already this very simple part of this goal is actually something which is quite interesting. Which is something which is quite interesting from an applied perspective. Sorry. Okay, so the basic question I start with is this question about topology. When should we consider stochastic processes to be similar? Yeah, and during most of the During most of this talk, I will just look at processes in infinite discrete time, and my state space will be just a real line, but it's not important. You can take whatever polar space as usual. And what we start by doing, what we start with is when we look at the stochastic process, a natural way to look at it could be look just at the distribution of this process. Look at it. This gives you a problem. Look at this, gives you a probability on Rn, and then on Rn, of course, our favorite distance is some type of Wasserstein distance, okay? And I mean, of course, I would rather use some Wasserstein 2 or Wasserstein P distance, but I mean, I'm suppressing this for most of my talk, and it doesn't matter, yeah. So the capital N here is the number of time steps? Exactly. Yeah, very, very good. Yeah. Yeah, and I mean, we could make, we could look at Rn times Rk, Rr to the power of n times K. If we want to have a different state space, but it's not important here. Okay, so this is called attempt zero. And the reason is that this approach doesn't work so well. And what I want to do first is I want to discuss what's the actual problem with this approach. And I want to, for this, we draw a Draw a supposedly very simple picture where we have a stochastic process with two time steps, and at time one it is splitting up and down. And at time one, it's already separated by some little number epsilon. And we compare this with a second process that is still together at time one and then it's Together at time one, and then it's splitting. Sorry, what's the difference? Oh, the difference is the epsilon separation in time one? Yes, so the difference is exactly this epsilon separation, yeah? Okay, so first question is, what is the Baselstein distance of these two processes? Roughly. So maybe you can use the chat for questions. Use the chat for questions. Maybe you can put suggestions in the chat. Yeah, or we can have it as a question for the open problem session. I don't know. Okay. So both processes start from the same initial point, right? Yeah, both courses start in the same initial point, or if you want, there is no time zero. So, no time zero. Yeah, so this is to double-check definitions. Yeah, very well. So, we have some very smart people who answered this in the chat, and the distance is just epsilon as it's supposed to be. Yeah, so if we put Wassersten distance here, then it looks like these two processes are extremely close to each other. Yeah. However, a typical question when you look However, a typical question when you look at stochastic processes would be look at some optimization problem. Look at, yeah, the simplest thing you can look at is some optimal stopping problem. Yeah, you take a supremum over stopping times and you evaluate the process at this time and then you take the expectation. Yeah, so the rule with stopping times is you have to decide when you want to pick your payoff and you are not allowed to look into the future. You are not allowed to look into the future. Yeah? So the question is: what is the value of such an optimal stopping problem for the process X? And what is the value of such an optimal stopping problem for the process Y? Yeah, so let's call this. Let's call the first question A. Let's call the second question B. And of course, we can see if we can have some answers to this in the chat. And I mean, okay, so this is very probabilistic questions, but I hope you're roughly familiar with what optimal stopping is doing. You're following the path, and at every time I ask you, based on the information you have right now, do you want to stop here and pick what you have? Do you want to stop here and pick what you have here, or do you want to continue? Yeah, and I mean, let's zoom in on this first question. Suppose we are here on our stochastic process. Do we want to take what we have, which is roughly at level one? Or do we want to continue the path and take what's in the end? What's in the end? I'm sorry that I'm spending so much time on this. I think it's important because this is really, I think, at the very basis of a probabilistic question that is different. So Leonard Wong is already solving this. So what's happening? Solving this. So, what's happening with process one is if we are on the lower path, we know that in the future we will only go down and so we want to stop immediately. Yeah, so if we are here, then we want to stop and then we get a payoff of roughly one. If we are here, we know that our future is looking very bright, we will go up and in the end we will have a higher gain. We will have a higher gain, yeah. So, if this reaches level two in the end, then the average of one and two is 1.5. And the problem is with the second process, I cannot do anything like this. If I'm at this level, then I have no idea about the future, and it doesn't matter if I stop now or if I stop later. On average, I will always have the same playoffs. On average, I will always have the same payoff, okay? So, with the second one, we would get an payoff of one, yeah. And I mean, probabilistically for the process Y is a so-called martingale. So at every time point, the current value is the best estimator for the future. And for such processes, the values for optimal stopping problems are always just the initial value. And yeah, so somehow. And yeah, so somehow martingales are really random processes. This process is really deterministic. So already at time one, you know everything about this process. So what this problem is kind of showing you is these processes are very different from a probabilistic perspective, but a classic Wasserstein distance cannot see this. And the reason is that information about the time doesn't enter in the classic Wasterstein. The time doesn't enter in the classic Watson distance. So, somehow, this is exactly the point where you want to do something. To see what we can do here, what I want to do is I want to rewrite this condition in a way that looks a bit more probabilistically. Realistically. Yeah. So the mapping T is a mapping from Rn to Rn. So this we can write as a mapping T1, which depends on the X process. And so on, many mappings like this, and then a mapping Tn which depends on the X process. And this Transport condition corresponds to saying that this distribution is supposed to have this to be the same as the distribution of the Y process. Now, if you're a probabilist and you look at this guy, then this looks strange in a way. The reason is what you do here is you want to determine something about y1, but you look into the entire future of your Look into the entire future of your process, X. Yeah, so from a probabilistic perspective, this is where you are cheating. This is where you are looking into the future of the path. And this is exactly what you shouldn't be allowed to do. Yeah, so if we want to do this probabilistically, maybe we want to replace this by T1 of X1. And at the second step, we want to have T2, and T2 is supposed to be. T2 and T2 is supposed to depend only on X1, X2, and so on. Yeah, and the typical way of expressing this in probability would be to say that we can interpret the process T as process TT and what we would say is that And what we would say is that this has to be an adapted process. Yeah, adapted or non-anticipative. So, this means we don't look into the future. Okay, and I want, I mean, we really, really want to say that, I mean, from the probability perspective, that's exactly what you should do. You should not allow for arbitrary mappings, T, but you should look only at mappings which correspond to these adapted processes, because these are going to. Yeah, because these are going to correctly take information into account. So my second attempt here is look at Wassersten distance where T is adapted. And this is a topic which we discussed already yesterday when Schumik had a question here. When Schumik had a question here, you want to make this symmetric, yeah? So, what you want to do is you want to have t and also the inverse of t to be adapted, yeah. And then, I mean, of course, this is a definition which works very well if these processes, if these laws are continuous, if they are not continuous, then you want to have formulation with couplings. Yeah, I mean, as in classical transport, it's fine to restrict to mappings if you have. It's fine to restrict to mappings if you have regular things. And then to build a theory, of course, you would go to a counter-Rowbridge formulation. But yeah, I will not discuss it here. Yeah, and it turns out that actually this solves many problems. So for instance, if you use this definition, then you get continuity for optimal stopping. Or if you're close to a martingale, then you're behaved like a martingale. And in mathematical. Martingale. And in mathematical finance, if two models are close in this sense, then everything you calculate with respect to such a distance is going to be similar. So you have continuity of the usual things you would do with models. So importantly, we are certainly not the first ones to recognize that there is a problem and that you should both use topology and that you should do something about it. That you should do something about it, yeah? So there is actually a super long list of people who realize that the usual weak topology or convergence and vast distance is not the right thing to look at with stochastic processes, but you want to have extensions. Okay, what I find very interesting is that there is this is really popping up in different communities independently. Communities independently. Yeah, and I mean, the first reference I'm aware of is David Eldos, coming from Stochastic Analysis, who gives a refinement of this extended weak topology. In economics, Helvig defines, uses a very different definition, again, with the same purpose, refine usually topology. Then, very close to what I've been doing. Then, very close to what I've been doing, so co-authors in Fulebakov and Ramila Saar, what they do is they use a causal version of optimal transport and give a distance based on this. Very much what I've been doing on the previous slide. So, symmetrizing on the level of inverting the map. This is also appearing many times in the literature independently. Yeah, so there is. Authors from really coming from different areas and giving slightly different but very much related definitions, which with exactly the goal of extend the weak topology. Yeah, and you can continue this list. There is people from Logic who are also doing this in their language. Yeah, maybe let me sync out the Maybe let me think about the Knotter-Rosenblood topology, or what I call here Knote-Rosenblood topology. Yeah, I mean, so I assume that many of you have heard about Knoter-Rosenblood couplings. I mean, this is maybe the simplest coupling between measures on the end you can look at in a way. And of course, you can define some costs or some distance based on this Knuter-Osenblood couplings. And obviously, it's not. Obviously, it's not symmetric in the order of the coordinates. It turns out that also this Knotter-Rosenblatt topology gives, in a way, a reasonable topology if you want to look at strastic processes. Yeah, so the first, okay, and then you could also base the topology on this optimal stopping game I've been playing before. Yeah, so the usual leak topology makes conversions of makes Convergence of mix is continuous if you test against continuous functions, and you could define a topology by testing against optimal control problems. Okay, so this could be an also could also give you a weak topology. Yeah, so the first main result I want to mention is that in this simple setting, it turns out that all these definitions are actually equivalent. Yeah, so I think this is something which is which I find extremely reassuring. So there is not just many arbitrary extensions of weak topology to take this into account, but it's really there is a number of people who are working completely ignorant of other groups. And I mean, just totally different fields. And in the end, they come to the same topology. So, I mean, my reading of this would be that. Would be that this is really in a way the canonical topology if you want to take information serious. Yeah, I also want to say that I mean with usual weak topology also have many definitions and it's kind of easy to see that they are very much related. I want to say that, I mean, here we really had to work, so we were struggling a lot. A lot so, specifically, Mano Ada, he has a very strong background in algebra, and we very much relied on this in the proof here. So it turns out that something which somehow the Helwig topology seems very weak and the adapted Wasserstein topology seems very strong. And in the end, you more or less sandwich everything between these two definitions. And yeah, getting from Helvig. Yeah, getting from Helvig to adapted wassten somehow it needed much more algebra than most of us were capable, except for Manuela. Okay, so I think this is a very natural topology, but still there is what do you mean by algebra? I mean what kind of algebra does it need? I mean he's doing universal, he was coming from universal algebra. Yeah, so we think that this is just abstract non- So, as think that this is just abstract nonsense and it will never help you with anything, but then in the end, what you do here is you have many disintegrations and integrations nested into one another. So, somehow you have always end up looking at iterations of Wasserstein space, of Wasserstein space, of Wasserstein space. And I don't know. So, I mean, I was always failing to prove anything there because I couldn't do the bookkeeping. And he developed a really nice language. And he developed a really nice language for exactly this bookkeeping. Yeah, thank you. I want to say, mention some limitations. Okay, before I mention the limitations, I want to also mention that, I mean, by far, my favorite distance here is this adapted Wasserstein distance that I presented on previous slide. So I think it's very natural and it turns out to be really powerful. And it turns out to be really powerful if you want to get control of the typical problems that turn up in optimization or math finance. Still, what you can see as limitations is what we list here. So this space is not complete. And actually, if you use other natural metrics, it's still not complete. So there is really, I think there is a really substantial. I think there is a really substantial reason why this is not complete. Also, you kind of feel like you are some in examples, you feel like you identify geodesics, but it turns out not to be convex. And a third limitation, and I mean, this is mainly a limitation if you work in probability, but I mean, for instance, David Ellis very much emphasizes this is it's very natural in probability that you have filtrations that are generated, not just by the process. It not just by the process, but that you have that you allow for extra information to come in. Yeah, and somehow this is not captured in what I have presented so far. And I mean, yeah, I want to spend some time on explaining where this non-completeness comes from. And for this, I go back to the example we had previously. So we look at the sequence. Yeah, so we look at the sequence of processes which are splitting, say, at the height of one over m. So this is my process Xn. Sorry, a filtration is just a nested sequence of sigma algebras, is that right? Yes, exactly. It's nested. And all these sigma algebras are subsets of F, is that right? Yes, yes, thank you. And somehow the compatibility condition is that XT is F T map. Ft measurable. And this is a probability way of saying that the information in Ft is enough to know X. And what we have been discussing so far is that the filtration is implicitly, we have been pretending that the filtration is the smallest filtration which makes the most building. Yeah. But somehow what this what this is doing is this is allowing to incorporate more information. To incorporate more information. But what is the problem with a general filtration? You still have a conditional, you can still try to couple the conditional distributions as you're moving along in time, but something is breaking down? No, you're totally right, actually. So give me one more slide and then I will say exactly what you say. Okay. I mean, yeah, so right now what I want to emphasize is if we look at this sequence of If we look at this sequence of processes xn, then you realize that this is actually a Cauchy sequence, also in an adapted Wasserstein distance. So for adapted Wasserstein distance, this is Cauchy. So this should have a limit. But as we have seen before, this guy cannot be the limit. Yeah, so the process y is not the limit because the distance is bounded away from zero and yeah, the value of an optimal stopping problem is different for the right-hand side than what it approaches for the left-hand side. So for left-hand side, yeah. So somehow this is not the limit. And then if you think about it, what should happen in the limit in a way is this. In the limit, in a way, is this should converge to a process X where there is just two points which share the same position. So somehow the process looks the same, but the filtration is a little richer. Exactly. Yeah. So this is exactly the point. The process is the same. It's only the filtration which is. Yeah, it remembers where it came from. Yeah. Yeah. Came from. Yeah, yeah, exactly. Okay, so the point here is that in a way, three solves problems one and two. Yeah, so the resolution here is really that what you should be doing is you should be looking at processes that allow for general filtrations. And I mean, as Schumik already Already spoiled, you can just make the same definition as before, and it will give you an extension of this adapted Wasserstein distance to such processes which have a general filtration. Yeah. What does the DC stand for? Coupling DC? Bicausal. So this is somehow adapted in both directions. And it's adapted to the filtrations rather than just to the processes. Yes, exactly. Okay, and then if you would have canonical filtrations, it would be the same as before, but in general, it can be something different. And I mean, something which happens here is because you allow for general state spaces and so on, you create a lot of redundancy. So, what you want to do is you want to identify two processes if they have distance zero. So, this is something which we will do implicitly. Okay, so results which we obtain here. The first result says if we do this, we obtain a complete space, and in fact, here. A complete space, and in fact, we obtain exactly the completion of what we had before. And I think there is actually two nice ways to read this fact. So, one way is to say that we have found a nice object for the completion. So, filter processes, this is what we study all the time in probability. So, we have a good understanding of the completion. Sorry, the P here now is a transport distance exponent, or what is the P? Yeah, exactly. So, I think. P, yeah, exactly. So I think I put the p I start to put the p here because in the next statement, then it suddenly matters, yeah. Um, yeah, so another way of reading this is to say that filtrations are something which is natural. Yeah, so I mean, you can think that maybe it was just a coincidence that Kermogov defined processes filtrations, maybe it was just a convenience, but in a way, this theorem. But in a way, this theorem says it's actually exactly what you would like to define if you want to capture everything that can be approximated with canonical processes. Yeah. The next thing is, yay, the geometry works out. Yeah. So it's a length space and you have geodesics. Yeah. And yeah, let me spend some time. Yeah, let me spend some time on drawing a picture. So we start with this process and we end up with this process. And we can now ask ourselves what is happening at intermediate times. Yeah, so you can start to interpolate between stochastic processes. Yeah, so for instance, in this case. This is the way you would see one process transform into the other one. Yeah, we can mention some things here. So, of course, the first reflex you should have is try to see if you find something which is nice and geodetically convex. So, find something, yeah. So, find something, yeah, and for instance, optimal stopping problems for convex payoffs are something which is convex along geodesics. And you should also, you can also ask yourselves yourself, is this compatible with other structures which we look at for stochastic processes? And this is the case, yeah. So, for instance, the Martin-Gaels form a closed convex subspace. So, whenever you interpolate between two processes, Interpolate between two processes, then which are martingales, everything in between is a martingale. Yeah, so from my finance perspective, this is something which we really want because, yeah, I mean, all our models are marking gates. And if you want to have an average of two models, then it would be very nice if this is again a model. Yeah. Sorry, why is it what happens when p equals one? It's not a geode. It's not a geodesic space anymore? Yeah, so then it's not a geodesic space anymore. That's strange, no? Yeah. It's isomorphic to a classical Wasserstein space. So you can identify a Polish space. Such that if you look at the Wasserstein distance on this Polish space, then our space here is isomorphic to that classical Wasserstein space. Yeah, then it's also what's quite nice is all these operations use sorry, the Polish space which gives you surf when n is finite is the polish. Finite is the polar space which gives you this isomorphism compact or non-compact? Ah, okay. Let me please give me two more minutes and then we talk about compactness, okay? So it's yeah, so I think item second on my list is compactness. Yeah, okay. Yeah, so there is, I mean, all the operations we look at. I mean, all the operations we usually want to look at are continuous. And it turns out, I mean, they are. So, if you have reasonable assumptions that your payoff is Lipschitz, then they are also Lipschitz continuous with respect to such an adaptive Wasserstein distance. And actually, if you so there is other metrics you could look at instead of adapted Wasserstein distance, but it turns out for other metrics, many things go through. Many things go through, but this one is no longer true for other metrics or topologies. So for instance, David Ellers, I think David Ellis had the biggest impact, yeah, concerning putting topologies on the space of stochastic processes. But still, you would not have Not have a continuity of optimal stopping, for instance. And what this item is kind of saying you is that this topology is fine enough to have continuity of all these things. But Matthias, there must be some restriction on what kind of optimal stopping you're looking at, like some continuity on the path or something like that, right? Yes, of course. Yes, of course. Yes, of course. Yes, of course, you're right. I mean, you want to have something which depends continuously on the path. Right, right. Okay. Yeah. It's like, I mean, if you would look at the usual weak topology, you want to put also just continuous functions. If you put a Borel function, you don't want to have weak continuity. Right. Okay. Thanks. Yeah, so this is saying that this is a topology which is quite That this is a topology which is quite fine. The next one says the topology is not too fine. Yeah, it says that you can still approximate every stoastic process with a simple process, with a process that is finitely supported. Or actually, you could also put something like a finite state mark of chain here. So you can find very discrete objects to approximate. The next one is answering or is alluding to Robert's question. Question: It's there is a good criterion for when something is compact. Yeah, I mean, usual weak topology in probability, it's so convenient because we have such a nice characterization of compact sets. By Prohor's theorem, if everything is bounded within some region, essentially bounded within some region, then you have compactness. And actually, this carries over here. Actually, this carries over here. So, if you have a set of such processes with filtration, it is compact if and only if, I should say, sorry, this is pre-compact. Pre-compact if and only if the laws are pre-compact. So, essentially, this is saying, or for instance, this is guaranteeing you, if you look at processes on a compact state space. at processes on a compact state space then they are automatically compact yeah if a sequence is has a if a sequence has a weakly convergent subsequence then it also has a weakly convergent subsequence with respect to this stronger topology yeah and it i mean it turns out that i mean this is extremely useful and i mean in in i mean you see it in all this appears in all the proofs this uh this result This result. Actually, also a consequence of this result is that we have existence of barycenters. So this is something which I quite like that, I mean, maybe you have five experts suggesting different models and you can then define an average model of what their guidance is. And actually, this is also my last slide. I want to put here. I want to put here such a barycenter, which Stefan Eckstein was calculating for us or implementing for us. And he was, of course, somewhere inside using synchronous algorithms. So we have some entropic regularization at the end of this talk. Thank you for your attention. Thank you very much. Okay, any questions for Matthias? Matthias, Christian. What about the stability of Markov processes? Since you have this closeness of martingale, how does it behave with, for instance, special martingale problems? Special mounting problems? Okay, so well, Microsoft is not closed. I want to say everything I'm doing here is discrete time. Yeah. So I mean, I'm very much working on continuous time, or we are all working on continuous time. Some things there are fine, some things are really much harder. What I'm trying to draw here is, this is saying that being Markov somehow has no reason to be continuous. somehow has no reason to be continuous. Okay, okay, I see. Yes. Yeah, I mean, what you want to do is you want to have some uniform, you have to be uniformly Markov. So there is some Arcela-Ascoli theorem which tells you very much, there is an Arcela-Ascoli theorem which tells you exactly when you are closed. Okay. Thank you. Can I have a questions? Can I have questions about your yeah, you said this in the discrete About your yeah, you said it is in the discrete time. Is there any hope for extending to the continuous time? Yes, I very much hope so. I mean, it's so I think in continuous time there is a relatively blunt. So, okay, so this is very speculative, yeah. So there is a relatively blunt extension to continuous time where you look at all processes and you look at some way of Some way of adapted Mausofstrain distance, which can also wiggle in time. But if you look at all processes, then I think you will not have something which is geodesic. So if you restrict to martingales, then I'm quite optimistic that you can get something which is geodesic. Okay, what I would really like to do, which is really open in my mind, is have it geodesic on the level. Have it geodesic on the level, have some nice geodesic space for semi-martin gaze. Okay, thank you. Sorry, what if, before we get to continuous time, what if we let n go to infinity? So you can kind of, so for finance questions, what you will certainly want to avoid is that constants are exploding. Constants are exploding only because you add many more time steps. So, this is something which would be very silly. And then, what you do is you define this distance slightly differently, and you define it based on the semi-martingale decomposition. Then you can pass to infinity, and if you have nice processes in continuous time, you have nice stability results, even if you look at infinitely many time steps. Infinitely many time steps. So, actually, there is so I think we don't properly understand this situation, but we have some conclusions. For instance, when we say we have stability in my finance, it means we have Lipschitz constants. And it turns out that the inequalities which we have, they are almost almost sharp for like standard Black Scholars model and standard call options. I mean, with almost sharp, I mean, we don't have optimal, we don't get, so our standard. Optimal, we don't get so our general inequalities don't give the optimal constants for Black School's model and a very simple option. But what you get is that you're only off by a constant of like two pi. Yeah. So it means that you're somehow not totally missing the scale of everything, but you get the right scale of the mistakes. And sorry, what's Sammy Martinel? A marking gale is something which is nice because it's totally random. And a process which has finite total variation is also nice because it's almost a deterministic process. And the sum of these two is the semi-martin gate. And for some reason, it's a nice class. So it's closed under many operations. And yeah, so I think most of the reasonable processes we look at are semi-marking it. Look at our semi-marking gates. And I asked: Is the construction by tree constructive? Or do you have an algorithm to approximate a given process by trees, say? Yeah, so you can do something very blunt. I mean, you can, with the process, you can replace, you can just fix the grid and round to the grid. Round to the grid. Yeah, so if you have any such path, then you would replace this by maybe this path, which only jumps to elements in the grid. And this is doing the job. Yeah, so you can have the most basic approximation. It's just actually not trivial to show that this approximation works. I mean, okay, so this is actually, I think this is a super good question. So we wanted to prove that this, so this was the starting point. So this project which says that all topologies are equivalent, this was started by exactly this question: that is this very naive approximation by trees? Is this, does it work? And what you end up doing when you prove it is you prove that. You prove it, is you prove that this Helmig distance and the depth wasten distance are the same. The answer is yes, and it looks trivial, but actually, it was relatively gave us half a year of trouble. And you mentioned the problem of the filtration. So does this automatically take care of the filtration somehow? Because here you have, let's say, the barycent, and you said that the in the And you said that in your simple example, the limit has a different filtration. So how does it work there? Yeah, so the limit has to be allowed to have a different filtration. Also, you need these filtrations in order, so you can easily construct two processes where the bar center, two processes with canonical filtrations where the bar center has a different filtration or needs to have a different filtration. So you need to have to put filtrations. need to have to put filtrations in order to to get very centers or yeah displacement convexity so in a given in a given application let's say in math finance do these filtrations the extent filtrations have have financial meanings um okay so there is a whole theory of um enlargement of filtrations which is dealing with this so i think in So, I think in this context, the way I would understand it is: I mean, it's the right way of completing something. I mean, most numbers you ever see are rational numbers, but still it doesn't make sense to look at a set of rational numbers. You need to look at the set of reals. I think the same is true here, that you can approximate every model with some very sophisticated filtration by other models. By other models which have only canonical filtrations. But still, you want to have these models with non-trivial filtrations in order to get a nice complete space, which is nicely convex. So perhaps a related question is maybe I have a given source of randomness that can be used as the extra randomness, and then I can maybe extend my given filtration by using these randomness. By using these randomness, and then I can do this kind of very centers or limiting processes. So you will not see this. Yeah. So when you identify two processes when there is just some extra totally independent notion of randomness. Okay, thank you. And I have one more question about this figure. I see it. Disfigured. I see. I know that you have this figure in also in your paper, but in that paper, you have not further discussed about this. What this figure is about. Can I see? How can I know what this figure is about? I mean, the detail about this very center of three models, something like that. I'm sorry. So, the question is: whether we have more about how this is done? Yeah, yes. I'm questioning about how. Yeah, yes. I'm not sure about how this is done. Yeah. Yeah, so we have. So I think in our paper, we have put this picture. I mean, so I think there will be a separate paper about the numerics of this together with Stefan Eckstein. I mean, essentially, what he has done is he has implemented a Karkamin and then he has done some checking that this Karkamin is actually. Is actually really the first shaming in this case. So, you think you say there's another paper, or you are saying that you are planning to have another paper about the numbers? Maybe a group without me would have a paper dedicated to the numerics of this. Okay. Yeah. And I mean, yeah, I want to, I mean, yeah. Stefan Eckstein, I mean, he Stefan Eckstein, I mean, he is really, he's super, he's a super good mathematician, but he's also so incredibly fast with implementations. I mean, we contacted him and discussed with him that it would be nice to have more numerics for this. And then he tells us, yeah, let's discuss this in detail next week. And next week, he already has all these implementations. He's really amazing. Wow, really. Very good. Very good. Thank you. Okay, great. So maybe we should prefer for the next talk. So, okay, let us thank Matthias again for all the nice answers. Thank you very much.