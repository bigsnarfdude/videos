So I go back to this old top. This uh work was done when I was a graduate student at Cornell and my bible was Lobo Street Cuts. She helped me a lot. So I gave this talk here a memorial of you. First, let's have a quick review of the standards of Inky Cargo. So we focus on standards today. We start with a today. We start with a rectangle and we divide it into k square, small rectang uh squares, and we keep some of them defined by s and then define cell stimulus set. The cell stimulus set is called cell in the cupid. First it is connected and it has all the symmetry of a square. And also we have all the four boundary lines included in the curve. Boundary lines included in the protocol. And finally, there is a technical assumption called non-diagonal, which means there is no local cut point. Actually, on planet cases, it enjoy this condition, we will see later. And here's some history. In 1989, Banlo and Bus constructed the localism metric diffusion process first on copies. And Kuskan and And Kuska and Joe gave another construction that gives similar future forms, and it was proved in 2010 that these two constructions are equivalent. Higher-dimensional cases are more complicated because the diffusion process is transient. There is some difference between transient case and a strong recurrent case. So today I just focus on strongly recurrent cases. Current basis. And we have the sub-Gaussian heat kernel estimate. And this is a slightly larger class of rectals than the title. We call it Selminsky target light rectals. So here we start from some IFS and here rho i are the contraction ratios that we do not uh have additional assumptions. Additional assumptions, but we still have some assumptions, of course. So, first, we want the fractal to be connected, it is metric, and we want it to look like a carpet. So, we include all the four bordering lines. Then it looks like a carpet. And finally, we have this non overlapping uh assumption, which means two cells, they cannot intersect with a positive measure. With a positive measure. They intersect only on the borderline. And the question we are interested in is whether there is a noise cohesion process that has subgravient difficultness rate. So here we just consider the Euclidean metric and the standard host of measure. So we do not change metric in measures. So it's a name of the question. So it's a name question. And actually, unfortunately, there do not always exist such a definition. We found this example. So the idea is if we look at this middle part, if we look at side to side, this middle part, it's very strongly connected. And so we expect it to behave like the planner R2 case. And so the work. And so the walk dimension minus host dimension should be close to one, or close to zero, just like the panel case. And if we look at corner to corner, you see this long interval structure. So we expect the host of work dimension minus host of dimension to be close to one. So anyway, it we get we can find some uh contradiction. Some contradiction if there is subconscious in this transition kernel. This is a county example. And today I am going to give you some examples of surface key carpet light fractals with subclausing components. On the known x distance. You just think about the fixed weight, or there is no diffusion or any weight. You can put the defined weight. Yeah, yeah, yeah, yeah, I know this is. I do not know the answer for that question. So so the weight matches the diameter. Oh and and I forgot to mention that Jink Kami will give a talk tomorrow about Servinsky chips and process. He considers some technologies of it. And it's also interesting work. Um okay, so unconstrained copy to Unconstrained cupup is Sylvinsky-like fractal with fixed contraction ratio. So we have nice structure near the boundary. And the theory is we have a nice self-similar due to form and we have a sub-Gaussian heat kernel estimate. So the idea comes from Kusuka and Joe. The strategy So the strategy is we define some kind of cell graph energy. So given a function f, we consider, for example, on this level one graph, we consider the average function of a cell. And two cells are said to be linked if their intersection is not void. And we take the summation on square and to get a discrete energy. And here, so we want to find And here the so we want to find some good renormalization factor such that CMDM converges, such that at least have some nice sub-sequential limit. And at least we want the limit to be irreducible and regular. So Kutzburn Joe gave some candidates of such a normalization factor. Normalization factors. The first one is called Pancuri constant. The Pancuri constant is actually the reverse of the first non-zero eigenvalue of the disproof form. So if you put the energy to the left side and take some kind of gamma limit, gamma subsequential limit, you would expect that the energy to be to control the norm. To norm. So you expect the subsequential limit to be irreducible. Another one is called resistance constants. So here we want a lot of cutoff functions in the domain of energy domain. So here each cube here is a copy of a level M graph and we look at its neighborhood. we look at its neighborhood of the two neighborhoods of its middle cell. And we consider the energy of cutoff function that is one in the middle and zero outside this neighborhood. And we take some kind of interval to get this resistant constants. And again, you expect if we use the resistance constant as a Constant as a renormalization factor, the final limit will contain a lot of nice functions in the domain. So the inferior isn't the denominator, but it's it's not in the theorem, right? Uh it it's h uh it's here. It's not in the denominator. Uh we we want more energy. Yeah, we we we consider the largest pos I I mean I mean we we need to consider all the cases. So the a worst case is it's its energy is large. I mean we want to want to have every cutoff function domain. Um and now the question is whether uh Whether Rm and lambda m they match. And in fact, in Khuska-Jo's paper, they already have this some kind of general estimates already. And they introduced actually four classes of normalization factors, but we kept three of them. The last one is named sigma m. It tells you that how It tells you that how the local energy on the two cells controls the difference of average functions on these two cells. And if we look at one, we see that sigma m is the largest one, and Rm is the smallest one. So we want to prove that Rm is greater than sigma m. Then we can show Then we can show that all these re-normalization constants have this R to the negative M ratio. And we are looking at the strongly recurrent case, so they become larger and larger as M becomes larger. So let me briefly talk about the proof here. So we use strong recurrence here. So the first observation is that if Is that if the function is small, other energy of the function is small, then you have some holder continuity of the function. So the idea is to use the Poincaré constants. You will get some point-to-point resistance estimate using the Poincaré constants. And next, we can use that quote continuity to show a side to side. Show a side-to-side resistance estimate. We want to find a function that is zero on one side, one on the other side, and the energy is more. And so here the strategy is to use stronger currents. So we start with a function that reaches this sigma n. So it's a function that is defined on the union of two cells and the difference of average on these two cells is one and the energy is sigma m inverse and then we can choose one point by symmetry near the boundary that has a value approximately one as zero and another point and another point inside this cell that has value approximately a half. And we next we look closer into this cell. We divide it further to use uh strong uh to use the holder continuity. So we divide into uh some n cells. Then the oscillation of the function on each n cell Of the function on each n-cell is smaller. So on this whole cell, it's about a half, and on this whole cell, it's about zero. And we can find, there's a finite many cells link these two cells. So we can find like this structure, two points on the side of one n-cell that has different values only below. On it below the difference. And then we use some chain rule resistance to get the side-to-side resistance. And by doing this, of course, we lower the level down of, we get a few levels down, but it doesn't hurt. It's a fixed level. So we get this other estimate. And finally, we use some trace zeroing strategies. I'm not going to talk about too much detail here. We use some trace zeroing argument to get a function that is zero on one side, one on the other side, and behaves like a linear function on the other two boundary lines. So we get a function. So we get a function that behaves like a linear function on all the four boundary lines. And we can now glue these kind of functions together to get a cut function. On the boundary of each cell, it looks like a linear function. Inside, it's complicated. And we get a cutoff function that has small energy. So we finally get. So we finally get the estimate about these Poincaré constants. And then we can show that this renormalized discrete form gamma converges to some duty form. And it's not yet a self-similar form. So we use another subsequence to get a self-similar form. So it's a standard technique by So it's a standard technique by Kush Hanitor also. And finally we also we actually have all the nice resistance estimates. So we get the pit kernel estimate immediately. And there is another more complicated rectal. This this one is more difficult and it is called holo LSC. So here the contraction ratios are different. Contraction ratios are different, but we have the condition that all the cells, all the level 1 cells, are attached to the boundary. So it's hollow inside. Unfortunately, we do not get the four-syll ring. We need another geometric condition. That is, we look at one corner level one cell, and the cell cells are cell. And the cell next to it, we need the assumption that row 1 is greater than to row 2. So this cell is at most a half of this 1. And under this assumption, we can show that there is a nice g2 form with subgausing it complex. This is mostly what I want to say today, and recently what And recently, Hua Chu and I gave some results about high-dimensional case. In R3, we can also construct nice rich forms on unconstrained components. And we haven't made it published, but we have written some. And also Huzen models and shimmerism also have some nice results about PNG on. Well, yeah, semi-system doesn't work. Similar bucket, okay? Yeah. So so I had said you have some ni nice P energy forms also. Noteing uh strongly recurrent case. Yes, yeah, for these hard enough. Just for the standard carpet. Yeah, but I will use some probability here, so I I think your your idea is will be different. Second speaker. Speaker, time for anybody has any questions. So, would you mind if I asked you, well, what class of three-dimensional specific perfect you have been able to treat? Well, I mean in in your last reference, where you said, well, you you have been able to treat three-dimensional species. Oh, three dimensions. So w what what what kind of class of topics? Uh Yes, so let me go back to the maybe I'll go to it here. So our assumption is as follows. So first the fractal contains all the six boundary phases because we do not want the interception of two cells to be very bad. So so the so the whole boundary of the cube is currently. Yeah, four bones of the cube is contained and uh we uh do not have local cut point here because it's high dimension. Yeah, that's also the assumption. Uh also symmetry of course. Yeah, yeah, yeah. Yeah, that's also assumption. Yeah, okay, fine. Questions? Apart. Because we actually want the work dimension minus host of dimension. Host of dimension minus walk dimension smallest. So this is the condition that you use. Any more questions? All right, let's thank the speaker again. A few minutes until the next speaker starts. I think it's supposed to start at five minutes, right? I'm not sure which mentioned that we were going to stream, but it doesn't work. We were referring to that great picture. So for the legacy point result, I mean we wanted to legalize that is fine. But maybe it would require different friends. I don't have any audience just. So it's not as famous something that's not open, but I think you relaunch this.  That's what the people are. Yeah, this is actually one. I think it's a special guy, so I'm not sure. All right, I think I need to buy the path. Please, everybody, let's welcome Saja Kablayev, who's going to give us a preliminary report on the fine structure of the new functional practice. Thank you very much for the introduction. It's a great pleasure to speak here, a very nice meeting. But I started to prepare relatively recently because just a few days ago Just a few days ago, putting the schedule, so I started to reuse slides from three years ago and realized that three years ago I also conference. Unfortunately, Friedman Fearnet and Pop Strike has said he passed away in December. So we held this conference in June 2022, but it was Memorial conference for Paul. Because my time is short, I'm not going to give an introduction. I will just go straight to this part about P functions and decimal functions. Of course, my talk is a direct continuation of talk of Fatalis, but also it it's connected to this previous talk because Jerkinski Karakin is uh one of main examples. So we have a large programme to study PV functions on different data spaces. What we will What I will talk about today includes mostly fractals with hit current listeners. So it's a very similar setup as in the previous talk. But in other papers, we consider it more general setup. For instance, in the first paper, we considered general genetic deforms without informal estimates, but we considered weak estimates like national inequalities and the hopeless inequalities. inequalities and parapolis inequalities. This second papers denote the two case which is Gaussian. This is most familiar to most of the audience here. Third paper is about hectals or with sub-Caussian term of estimates, which here we investigated how subordination was How subtination works with EV functions. And actually, this paper is very heavily devised. You can see that this paper Senate Brussels paper some years ago, but this paper is devised very heavily. In particular, we discovered that the V functions for non-local diffusions are actually the same as for local. So one of the reasons for diffusions. So what then? So, then mostly we will speak about this paper, but it's also the place. And Fabrice mentioned that there are several more papers written Maurice's and Fabrice explain. Oh. So, this is sub-Gaussian fictional estimates, which appeared many times here already. Most important features that distance scales like a time to some power, and this power is Some power, and this power is denoted. It is sometimes denoted as gamma, and sometimes it is denoted as one of the important idea. And there is some universal theory for which Marx and Takash and some others were responsible. Particularly, these estimates are standard stable under absometries. And also, there are three parameters here, but we're not independent. Here, but we're not independent. There is one very component of the region. Those are dimensions that are dimension. So, in a lot of my results, two parameters I intend, but typically I say we use these two parameters, but actual dimensions depend. This is the picture of Sierpinski Gasket, and uh I wanted in one slide to illustrate how this Slide illustrates how these dimensions are connected. So, lowest dimension is one, it's topological dimension, which is very easy to compute than the mathematical dimension, which is μ. This is the L. Then the next larger dimension is actually a new dimension. It's a bit unusual, it's called topological housdorf. It will explain later. It has this precise way of the world actually look like. Next is spectral dimension. Next is spectral dimension. It is unique, but it does not evolve very popular. Next is usual host of dimension block 8 or block 3. 2 is dimension of Rambian space. And what dimension is equal to dimensions, so the important thing. And this practically everything was introduced here by Parlopas in. I think I could maybe be wrong here. I think here we say I understand except this dimension actually introduced much. So one of the discoveries which you made, and it was a bit surprising for us, is that it is well known. Was that it is well known that on all these rectals there are many functions of 30% signals. But one question which was apparently overlooked is that what is the best possible exponent? And there is actually a very nice theory which follows from this Barlow-Bas theory, but best presentation is given in these notes by Marx. And it gives a very general result that under the Very general result that under Hyptorian estimates, the harmonic function has eased for the constant points, double-minded. But when we started as a corollary, we started to understand that on Shakinski architecture, we felt a pinskin which