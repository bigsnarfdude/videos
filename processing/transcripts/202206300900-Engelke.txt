So, yeah, this is joint work with people from ETH, Marlos Matus and two students of hers, David and Jinjou. And yeah, so in this conference, we've seen several talks about causality, about extremes and climate. And I think this topic of extremes and causality is still at the very beginning. And even definitions of what we really would like to look at and how we define causality in extremes. Define causality in extremes. Yeah, there are plenty of open questions. And people have started to work on this and started to define what they mean with causality for extremes. And so one problem that we have, and Limbu has given a very nice introduction for this, is that if we have several variables like here in this graph, we might be interested in detecting which variables cause which. So this would call a causal discovery. Call a causal discovery, and in extremes, in particular, we might be interested in finding out if those variables are extreme at the same time, what is the causal structure between the extremes of these variables. And this kind of causal discovery in extreme variables has been studied in several papers that I cited here. And we've already seen talks by Claudia and by Mario Carlios also. Also, and yeah, there's also another project that will actually present just afterwards by Nicola, where we looked at causal discovery in heavy-tailed models. So, now in this talk, I look at a somewhat more classical setup of causality in terms of potential outcomes and treatment effects. We were not so much interested in finding out the causal structure of the extremes, but rather to find the size of the causal effect related to extremes. So, I will explain what this means. Extremes. So I will explain what this means in a bit. And yeah, this paper that I present is down here. It's already on archive. And especially for the theory, I will refer to this because I won't have too much time to explain all the details of this, but I would rather like to give the main idea of it. Okay, so I've it's okay. I think I can just use this. So I've drawn here. Drawn here a graph, and I will explain what this graph will mean. But as if you've seen the introduction by Lindbo, basically, this will represent our outcome y, a treatment d, and then some confounders x. And yeah, we will be interested in looking at extreme values of this variables y and find out what is the effect of the treatment on this variable y. But yeah, I'll give a bit more details on this on this definition. More details on these definitions. So, here we'll look at binary treatments only. So, you can think of this as no climate change and climate change. So, this has been, we've seen already in several talks from different people that looked at these probabilities P0 and P1, which represented a probability under a world without human forcings and a world with climate change, so with this anthropogenic forcing. So, with these anthropogenic forcings, and in climate change, people look at the change in these probabilities, at the ratio or the difference of these probabilities. And this framework is a potential outcome framework where actually we have these variables y1 and y0 that represent the outcome in that world that has been treated, so with climate change, or that the world that has not been treated, so where we wouldn't have anthropogenic forcings. And the problem, as Lindbo said, And the problem, as Lindbo said in his introduction, is really that we cannot observe both of them, but it is a missing value problem. And then in the classical causal inference theory, people often look at this average treatment effect. So they just look at the average, the difference of the averages of these potential outcome distributions and define this as the treatment effect. But now in extremes, but also in other But now, in extremes, but also in other fields, people are often interested in changes in other parts of the distribution, not only in the average, but in say quantiles. And then they define the quantile treatment effect at a particular level, tau, as the difference of the potential, the quantiles of the potential outcome distributions. Okay, because you can imagine that a certain treatment might have different changes, different things in the average. So, climate change maybe will not change the overall precipitation on average, but it might change. Precipitation on average, but it might change actually that there might be more extreme precipitation events. And this we can only detect if we look at a treatment effect that is concentrated on a quantile. And so there are many questions related to these quantile treatment effects. So for example, if we have an education program, we can ask ourselves, how much will this education program actually increase the wage of the 0.1% poorest people? Poorest people, portion of the poorest people. Or we could ask in the climate setting: if we look at a one in a hundred-year heat wave or flood and we were now to double the CO2 concentration in the atmosphere or do some other intervention in the climate system, what would be the causal effect on this impact of the heat wave or the flood? Okay, so there are many very natural questions, and there are also many questions where this tau here, the level of the quanta we're interested in. Level of the quanta we're interested in is actually very close to one or very close to zero, so that we're actually looking at extreme changes of extreme events. So, as in those two cases here, there's also a nice paper by Johanna and co-authors who look at a generalization of this quantile treatment effect or the weighted quantile treatment effect. And okay, so this graph is kind of a simplified version where I only have a treatment and the outcome. And the outcome. And if I have a simulation model, then I actually only need this because I can randomize the experiment and really intervene on this D. But in reality, if I have observational data, I will actually rather have a graph like this, where I have additional confounding factors that will change the probability of getting treatment or not. And thus, I can no longer just use regression to get the effect of. Effect of D on Y, and I have to use different methods, other methods from causal inference. So, yeah, this X will be this additional confounding vector. And really, in this talk, I will assume kind of the simplest case where we say we observe all of these, Y, D, and X, and we would like to define what we mean with the extremal causal treatment effect. Effect. And you can think of an example for those. This I will come back to this example later in the application, where Y might be the salary, D might be a treatment, which is whether a person went to college or not. And then what would be the confounding factors that could be socioeconomic factors that influence both the probability of going to college and the salary of the person. So, for example, the status of Um, the status of your parents, uh, what is their income, and other factors that influence both of those. And they, as Limbo explained very nicely, um, this makes actually the problem harder because we can no longer just regress d on y, y on d. And what people do in order to correct for this or to adjust the estimator, they use kind of an adjusted estimator. An adjusted estimator using the propensity score. And the propensity score is nothing else than the probability that a person gets treatment given the confounding factors X or the covariate X. And this is really just a conditional probability that can be estimated by different methods, can be estimated parametrically or non-parametrically. And Lindbo also talked about this. So this is one way of kind of including or adjusting for this presence of this. Adjusting for this presence of these confounding factors to not only get the regression coefficient but to get the causal effect from d to y. And well, there are many methods again we will here use without discussing further here the sieve method, which is a non-parametric method. So we don't need an additional parametric assumption here. However, as Limbo also discussed, we need assumptions to make this work. And these are kind of these notorious assumptions that we cannot test, but people Cannot test, but people make them in causal inference and kind of argue why they hold. So, the one important assumption is the unconfoundedness assumption, assuming that given this vector x, actually the treatment and the potential outcomes distributions are independent, meaning that basically we capture, we've observed all of the confounding factors. And then a more technical assumption is that this propensity. Technical assumption is that its propensity score is bounded away from zero and one. These are kind of standard assumptions. In causal inference, I won't discuss them here more, but I would like to concentrate more on the extremes part of the problem. Okay, so now the situation will be we have observational data, so we don't have this luxury of having a model where we can intervene on the treatment, but we actually only have observational data and we have confirming factors X. And we have confounding factors x. And suppose we observe IID copies of this triplet of the outcome Y, the treatment D, and the cobrate vector X. And now in 2007, Philpo has introduced estimators for these quantiles Qj tau. So these are the quantiles of the potential outcome distributions. So the quantiles of YJ. And so I've defined them here. So basically, what this is, is we solve the usual. What this is, is we solve the usual quantile loss. So, this is basically if you forget about this term here, this is just the usual quantile loss. But what we now have to do, we have to adjust for the presence of these confounding factors. And we can do this by using the estimate propensity score and this kind of indicator whether you have been treated or not. And yeah, they show that these estimators are actually adjusted estimators that take into account. Estimators that take into account, that estimate the potential outcome distribution, taking into account the presence of these covariate or confounding vector x. And well, then an estimator for the quantal treatment effect is, of course, just the difference between those two estimators. So here I write one minus tau because I want to consider tau being close to zero. That means the quantal of interest being close to one. This will be more. interest being close to one, this will be more convenient in the SQL. Okay, so now when does this actually work? This works if we look at a fixed probability level tau. So this is the classical case where we get more and more data and we want to estimate at for fixed level tau the quanta treatment effect. And they show this estimator of delta hat is actually then asymptotic normal. However, in extremes, what typically In extremes, what typically happens is that we're interested in estimating something that gets more and more extreme. The more samples we get, we would like to estimate more extreme quantals. That means in the asymptotic theoretical setting that our tau n, actually tau will depend on the sample size n, and tau n will tend to zero, so that one minus tau n tends to one. And we look really at extreme quantities. But there are different scenarios that can happen. So the first one is what we call Can happen. So, the first one is what we call the intermediate case, where tau n goes to zero. So, we're looking at extreme contours, but n times tau n goes to infinity. So, what is n times tau n? n times tau n is the expected number of exceedances that we see in a sample of size n over this quantile related to the tau n. Okay, so n times tau n goes to infinity means that we see in the limit infinitely many exceedances. So, essentially, it means we can do usual. Essentially, it means we can use these usual empirical estimators here and still get asymptotically normal results. Okay, this will look differently now if we, and this, okay, this regime somehow where we get infinitely many exceedances is not really what we'd consider as an extreme scenario, because there we estimate a quantile that lies within the range of the data. Within the range of the data. In extremes, we're often interested in quantas that lie outside of the range of the data. So, for example, if we estimate the probability of a one and a hundred year heat wave and we only have 50 years of data, then this would be a quantile where this n times tau n would be smaller than one and would actually go to zero in the asymptotics. Okay, so there we can expect that something else happens, and actually, something else happens because these empirical estimators will no longer make. Will estimators will no longer make sense. So, kind of in a moderately extreme case, they considered in Zhang and Al is this case where n times Pn, and now I call it Pm and Pn instead of tau n because I want to distinguish it from this intermediate case. So where n times Pn goes to some positive constant D. And in this case, actually, something different happens now. The limit is the asymptotic. Limit is the asymptotic distribution is no longer Gaussian, but has some other kind of strange distribution that comes from the fact that they are actually using this empirical estimators in a case where maybe it would be better to already use extrapolation. And then what we usually consider as extreme in our community is when n times pn goes to zero. So the expected number of exceedance actually goes to zero. That means we really have to use extrapolation. Otherwise, Extrapolation, otherwise, these empirical estimators here will no longer make sense because we no longer have exceedances over this lab. And just to illustrate this, we can look here. This doesn't have to do anything with causality. It's just an IID Univrate example where we estimate the quantile based on 1000 data points, IID sampled from a Frochet distribution, and we Crochet distribution, and we compare the empirical estimator, or basically the bias of the empirical estimator that you see here, this red line, compared to an estimator that is based on extrapolation, so extreme value theory. And you can see compared to the true value of the quantile, starting from this level where we have one or less exceedances over this level, there's a huge bias. And this extrapolation actually makes sure that we can still estimate correctly these quantum. These quantum. Okay, so I haven't told you how we do this extrapolation. Here, we do it with the Hill estimator, and in the causal setting, we'll actually also use an adjusted Hill estimator to go to higher quantile treatment effects, so extreme quantile treatment effects. So the setup that we considered in this paper is that our potential outcome distributions y0 and y1 are heavy-tailed. That means their tail. Their tail behaves polynomially with some coefficient minus one over gamma j, and this coefficient can be different for the different potential outcome distributions. There's also a slowly varying function, but this will not matter so much here in this extrapolation. So, and then, okay, if we just play a bit with this formula, we can actually show that if we want to estimate a quantile at an extreme level, so this one minus pn. level so this one minus pn we can go back to a less extreme level this one minus tau n this we can estimate empirically because it's an intermediate level and there is theory for the empirical estimators but we have to multiply now with the correction factor somehow this extrapolation factor that involves these probabilities but also involves the tail index from this survival function okay so this is really where extreme value theory kicks in Is really where extreme value theory kicks in. We use the tail index to extrapolate from an intermediate quantile to an extreme quantile. And then for the extremal quantile treatment effect, what we can do obviously is just looking at the difference between the extreme quantiles of the potential outcome distributions, and we use the extrapolations for. And we use the extrapolations for both of them. And this will be our approximation of the extreme quantile treatment effect. So the only thing we have to do now to estimate this extreme quantile treatment effect is to estimate the intermediate quantiles and to estimate this Hill estimators that are defined on the potential outcome distributions. Okay, so for this. Okay, so for this, this is basically what I'm seeing here. Our extremal quantile treatment effect will be estimated by using here for the intermediate quantile simply the empirical estimator because we know it's asymptotically normal for this one. But we won't have to extrapolate, so we need an estimator for these tail indices, gamma one hat and gamma zero hat. And okay, and usually what we do to And okay, and usually what we do to choose this tau and this intermediate level, we actually choose this as k over n, where k is the number of exceedances. And we will require so that this is an intermediate level. So this k, which is equal to n times tau n, should go to infinity, meaning that we can actually use empirical methods to use to estimate these intermediate quantiles. And we will exactly use this adjusted quantile estimator that I've shown you before from. Estimator that I've shown you before from Philbook. Now, for these estimators of the extreme value index, we use a Hill-type estimator. And we call this a causal Hill estimator because we now define an adjusted version of the Hill estimator so that we can actually estimate in each of the potential outcome distributions this factor of extrapolation. And this is very similar to. And this is very similar to the usual Hill estimator, which would be defined as this sum here without this correction factor. But now, in order to make this actually work in this causal framework, we have to correct for the presence of these confounding covariates. And we do this by using this estimate propensity score. So similar to what has been done for the empirical quantiles, we define these causal Hill estimators by this adjustment. Hill estimators by this adjustment factor. Okay, and then one can ask: does this actually work? Is there now better properties in the extreme case than we obtain if we just use the empirical estimators? And indeed, there is, because this now this extrapolation from extreme body theory helps us to get asymptotically normal estimators. So the first thing we show is that the estimators of The estimators of the causal tail heaviness of the causal extreme value indices are actually jointly asymptotically normal. Then we also show that using now this causal Hill estimator to estimate causal extremal treatment effects, so this estimated QTEs are now also asymptotically normal in this extreme. Asymptotically normal in this extreme setup, where we look at estimation of quantile treatment effects for probabilities that go beyond the range of the data. And we provide also an estimator of the asymptotic variance of this QTE so that we can actually do inference on real data sets. And yeah, I'm skipping all the details of this theory. Again, I refer you to the paper that I cited before. To the paper that I cited before, if you want to see more details. Instead, I would quickly talk about the application that we considered in this paper. So this was now in this framework of the impact of college education on large salaries. And why is this important or interesting? Because there is evidence that actually college education has an inhomogeneous. Has an inhomogeneous effect on the wage distribution. So that means that the effect on the average will not be the same as the effect on very high wages. And so the treatment in this case or the response in this case would be the wage at age 30 in dollars per hour. The treatment is whether a person went to college or not. And covariates, as I mentioned before, would be socio-economic factors. So, for example, the region of residence. Example, the region of residence, whether your parents are married, how much the parents earn, and so on. Because you can imagine that these factors will determine or will influence whether you go to college or not, and they will also influence your salary at age 30. So it's important to correct for them or just for them using, for example, such a propensity score method. Okay, so I just very quickly show you. Just very quickly show you some results. So, we estimate the quantile treatment effect at different from kind of more intermediate to extreme quantiles. And we can see that let's sit maybe at this one, that over a different range of this tuning parameter k. So I didn't mention this, but this k of course is a tuning parameter because we can choose, we kind of have to choose this intermediate sequence tau n to determine what we consider. Tau n to determine what we consider as the threshold. So, yeah, we should look at this as a function of k and select this k. But we can see that over a range of tuning parameters, there is a clearly positive effect of college education on the highest salaries. And this holds true for different levels of quantum treatment, in fact. Okay, so I'd like to give a little outlook. So, I have what I've covered here in this talk is really kind of the maybe most basic setup in causal inference where we have a treatment, binary treatment, where we have a response Y and we have a covert vector X that is fully observed. Now, in terms of applications, first, there are, I think, many interesting other applications, especially. Many interesting other applications, especially in climate. We have here looked at this education application, but I think really application in climate could be very promising. Now, maybe my questions for climate scientists would be, for observational data, what would be interesting setups here for this model? Lindberg already mentioned something with air pollution and maybe impacts on health. That could be one setup that is of interest, but I guess there are other. Of interest, but I guess there are other configurations, maybe also related to climate change, that could be seen as such a causal problem with observational data. So there might be other problems like cycles in climate because things can influence the variable y, but then y could back influence the treatment or the axis. So there might be cycles in this graph. One could think about time series and Granger-Cozellis. Think about time series and Granger causality. So, yeah, I think there are different challenges in climate that could be interesting to discuss here. But also, in terms of kind of just the theory of causal inference, I think there are many extensions of this. So, for example, Leo presented the instrumental variable approach. So, again, one can think here of extending this to instrumental variables. Think about whether instruments are actually different for extreme values because there might be For extreme values, because there might be links that no longer appear in the graph, even though they appeared in graphs if you do treatment effects for averages. So, yeah, there might be some interesting things to investigate here. And then, of course, we only used the sieve method and a particular method for the propensity store. So, there might be other methods that work better. And I think there are plenty of things to. Of things to investigate. So, again, this is the archive paper. So, especially for the more theoretical parts, you can have a look there. And otherwise, thank you for your time.