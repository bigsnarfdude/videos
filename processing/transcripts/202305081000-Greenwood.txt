And there isn't time for them, please feel free to get in touch by email. I'd be happy to answer questions. So I'm going to talk about the work of a former PhD student, Kai Chong Zhao. She did some really fabulous work on this and has just been hired as an assistant professor at U.S. Hired as an assistant professor at York University in Toronto, which is really great. So, I'm going to be talking about a quasi-binomial model with random effects and then adding sparsity to estimate SNP effects. And I'll be using some data on anti-citrulinated protein antibodies, which is a biomarker that goes high prior to a diagnosis of rheumatoid arthritis in many cases. So, we're asking a really simple question, right? So, we're asking a really simple question, right? We're asking whether methylation patterns in whole blood samples are associated with levels of this ACPA protein antibody. And we're trying to see if we can adjust for any potential confounders and covariates. And some of the ones that are really important are the cell type composition because we're working with bulk samples here. But another one that's really important is the genetic variation, which does have an influence on. Which you know does have an influence on methylation data, and often analysis of this kind is done in two steps. As in, first, you might find an association between methylation and your phenotype of interest. And then you might say, okay, well, let me see if there was a SNP close by that might have explained that association, whether it's mediation or whether it's just another factor that influences methylation at that place. So, here I'm going to talk about And here, I'm going to talk about a solution that we've been thinking about for that near the end of the talk. So, a little bit about where the data comes from. We're looking at people who have either high or low levels of this protein antibody, ACPA. And basically, how they were obtained is we took a sample from Cartogen, which is a population biobank in the province of Quebec in Canada, and measured the ACP. And measured the ACPA levels in about 3,600 people, and then sub-sampled people who had high or low levels, not very many, just 50 or 60 high and 50 or 60 low, and then did methylation with bisulfite sequencing in the stored samples from those people who had been selected because of the cost, really. So, the bisulfite sequencing gives. So the bisulfite sequencing gives count data. So we have counts at each position. We have the methylated count and the unmethylated count or the total count. A little bit of notation. I'm going to be using y for a methylated count and x for the total count or the read depth. And methylation is usually measured as the proportion y over x. Of course, if the denominator is small, those counts are pretty imprecise. And the data is such that there are. And the data is such that there are a lot of places where those counts are small, and there are also some places where the count is zero in some people, but you might have nice data in other people. So you have a problem with sort of variable data quality and a lot of missingness if you were just going to treat the counts naively. This particular study was done using a custom capture library. So they were focusing on specific regions in the genome that were thought to be of interest. There are about 400,000 regions in the data that we're looking at and about 5 million CPGs across those regions. And so we really wanted to look at an approach that would use the regional information. So here's one region, just to sort of set the stage. Each dot at a At a particular vertical position, corresponds to one person. So, if you look on the left, you have a lot of dots with very high levels of methylation. The yellows are the people who have high ACP levels. The blues are the low ACP levels. And then, of course, you have a number of positions across this region of the genome. Methylation generally decreases as you go from left to right. There's a lot of variability. There's a lot of variability, and the people who have low levels of ACPA were seeing methylation levels that seem higher. But there's a ton of variability. I'll be focusing here on what's called data set two, the 2019 data set, where we had 60 people with high levels and 60 people with low levels of ACPA, 4.2 million CPGs. 2 million CPGs. And when we group things into regions, I'll be looking at 12,900 or so regions that have had at least 50 sites in them. And I'm interested in nine covariates. Of course, the ACP status. Also, cell type composition measured by four covariates, age and sex, and smoking. And smoking is coded as two covariates. I've seen those merging hands. So speaking from a statistical point of view, Speaking from a statistical point of view, we were looking at the challenges associated with this read depth variability, the confounding by cell type mixture, the fact that the data was regional, the interest in the SNPs that could affect cis-methylation, really looking at cis-methylation particularly, and also the possibility that some of the reads actually just could be errors. So when something is read as methylated, it may actually not be methylated and vice versa. Actually, not be methylated, and vice versa. So, we developed a model. I'm going to go through some of the assumptions behind that model, hopefully without belaboring it too much. So, first of all, we started by saying that we want to incorporate errors. Okay, so we have two parameters, P0 and P1, which basically allow for the sequencing reads that we see to be wrong. Reads that we see to be wrong. These actual parameters, you could choose them or you could estimate them from some external sources, which is sort of what we did, is we estimated them from external sources. The second thing we did is we assumed that the true methylation status follows a nice binomial distribution, where that depends on the parameter pi is going to vary smoothly. Pi is going to vary smoothly across any one of those regions that we are interested in analyzing. So we have pi, the binomial proportion, which is a function of position t, and your covariates z. And of course, then we put in some phenalization to make things smooth. The problem with that first assumption that we made is that the dispersion we actually have in the data violates the binomial assumption. Violates the binomial assumptions. So, here, if you just look at all the positions in this region I showed earlier, and you just calculate a measure of dispersion at each position, you can see that the dispersion rises up to a peak of about 20 and is generally much, much higher than what you would assume under the binomial distribution, which is represented by the dashed line at the very bottom. So, it's not only higher than the binomial distribution. So, it's not only higher than the binomial, it's also position-dependent and variable across positions. So, if you do an analysis naively, assuming a binomial distribution, you will get p-values that are too small. So, we then modified the original proposal to add in two different terms to cope with the over-dispersion. The first one is a multiplicative dispersion term. So, we're going into a quasi-bino. So we're going into a quasi-binomial with the addition of phi, which I've put in red here. And we also added an additive dispersion term, so like a subject-specific random effect, which I've termed U. And where, of course, we still keep the smoothness parameters to penalize, to make it relatively smooth curves. Why did we add two different types of dispersion parameters? Dispersion parameters. And the thing is, we needed both. We went back and forth on this, sort of looking at what happened in the data set and the behavior of our tests of significance. And this little diagram here shows what happens if we only have one of the two parameters at a time. So top left, if we don't have any over-dispersion parameter, then the dispersion doesn't bear any resemblance to reality. If we only have the multiplicative. If we only have the multiplicative quasi-binomial parameter, you get a constant rate of dispersion across the region. If we have a subject-level random effect, we do get regional variation, but it's not variable enough. So we needed both of them in order to basically get realistic-looking patterns of dispersion. I won't spend very long on estimation because it's quite complex. Because it's quite complex. We have a lot of parameters. We have to do some tricks in order to get the estimating equations to work. It's not linear in the unknown methylated counts. And so the end of the day, we're looking at a relatively complex estimation involving a hybrid expectation solving algorithm. We do, however, have a regional However, have a regional level test of significance for each covariate at the end of the day. So, in comparison to some of the other tools, you know, we can deal with, this is on the bottom here, the one that's called Desomnimus. You know, we're reading, we can adjust for variable read depth, we can adjust for confounding, we get a regional level inference, we can adjust for sequencing error, and we have non-constant dispersion. We did do simulations. I'll show you a little bit of the simulation results, but of course, when you do simulations, sometimes things always look more beautiful than they do when you go back to the real data. So here I'm showing that under that the red line is the true parameters that we simulated and the gray lines are the estimated results. And so the estimates that we get are generally unbiased. Generally unbiased. You can see, you know, like 100 lines here all plotted on top of each other from a simple simulation. And here, perhaps a little bit more interesting, is we can really see that we needed both of those dispersion parameters. So the top left graph, if you simulate data that follows a binomial distribution, then things are fine and the regional p-values that we end up with follow the diagonal line quite nicely. But if we simulate data that But if we simulate data that has multiplicative and additive over-dispersion, which would be down here in the bottom right, for example, if you only put in one of the over-dispersion parameters, the behavior is terrible. And you need both of them in order to get the green line, which follows the line of expectation. We also looked at power by essentially comparing one curve to another curve and varying the maximum. Varying the maximum difference between the curves. So, this is the same layout as the null hypothesis scenarios, where on the bottom right here we have large multiplicative dispersion and large additive dispersion. And again, you can see the power is quite good. Here, the x-axis is the difference between the curves, the largest difference between the two curves or the power. And that other methods. And that other methods are not capturing anything at all here. When there is a binomial assumption in the top left of this graph, then there are a number of methods that do quite well. But as soon as we get over dispersion relative to the binomial distribution, the picture really changes dramatically. So, now going back to the actual data set and the 12,000 regions that we analyzed. 12,000 regions that we analyzed. The first thing I want to say is that both kinds of dispersion were present in the data. So, here, one dot is one region with a little bit of color, you know, to show when they're plotted on top of each other. You can see that on the horizontal axis, this is the quasi-binomial parameter, and most of them are much greater than one. The vertical axis is the variance associated with the additive dispersion on the log scale. And again, we have lots of regions where we have more than you would expect. A variance of zero would be none. And so these points that are sort of in the lower cloud might be estimates of variance that are close to zero. But the majority of the regions that we analyzed had. That we analyzed had extra variability. And then this is a QQ plot of the regional level p-value, so one p-value per region for high versus low ACPA levels. And again, the green is the model I've been talking about, which has a p-values that are sort of closest to the diagonal line which you would expect under the null. Yes, this. Yes, this curve is a little bit inflated. I feel like there's extra sources of dispersion we still haven't characterized. But certainly, this is much closer to the diagonal than these other curves, which either have no corrections for dispersion or have only one of the dispersion parameters included. If you compare with other methods, on the top two panels, the top left and the top middle, you see. Left and the top middle, you see our results when we assume that there's no sequencing error on the left, and in the middle, when we do allow for sequencing error. And then the other four panels are other methods. And I think what really strikes me here is the fact that there's really nothing popping out of the tail of the distribution for the other methods, whereas we see quite a significant tail. And of course, one could debate whether we are finding spurious results or not, but. Spurious results or not, but I think we are finding things that are very interesting here. I'm going to show you one example region to give you a bit of an idea. This is near a long non-coding RNA. And here's the ACPA covariate. So these are plots, one plot for covariate, and the second from the left on the top is for the ACPA covariate. This is a pointwise estimate. This is a pointwise estimate and confidence interval, and you can see that that estimate is greater than zero on the right-hand side of the region with a regional p-value of 10 to the minus 21. If we actually look at the data, the raw data by ACPA status, ACPA negative on the top, ACPA positive in the middle, and the medians superimposed in the bottom panel. You can see that there is a See that there is a small difference between those two groups, but that small difference is quite consistent for a large number of CPG positions. So here, each box plot is one CPG position. We can do some pathway analysis on the things that come out, and they are reasonably reasonable for reasonably reasonable. They seem to be quite reasonable for an auto. To be quite reasonable for an autoimmune disorder like rheumatoid arthritis. So, I had said at the beginning I would talk about the SNPs and local influence. So, the next thing we wanted to do was to try and allow or to create the ability to put SNPs in as covariates. I mean, if there was just one SNP, sure, we could put it in as a covariate. But when you have thousands of them in a nearby region, you would either have to do some You would either have to do some LD pruning to get them down to a small number, or we want a variable selection approach that will actually pick out which NIPs are the ones that are most important. And that's what we're trying to do here. So we have a region that we're interested in, illustrated by the box. We have CPG sites in that region. And then we have probably hundreds or thousands of SNPs that are nearby, depending on the size of the window you want to look at. And that's much larger. And that's much larger than the sample size that we had in this data set. So we put in here a new penalty, a sparsity smoothness penalty, has two terms in it. One of them is a sort of an L2 penalty, the parameters. And the other one is a penalty. And the other one is a penalty on the second derivative to enforce a smoothness. And by putting this in, you need, of course, other steps need to be added into the estimation process. So there's some proxical gradient descent and backtracking things that came in. So in a small simulation, this works well. You know, you could put in 100 SNPs and find five that And find five that had the correct influence. Of course, you need to do some cross-validation in order to find the best hyperparameter tuning. And this is also available on GitHub, as is the other software package I was talking about earlier. Comparing results, if we take those 12,000 regions and analyze them twice, there are 886 regions where at least one SNP was retained and where therefore And where, therefore, the p-value will change quite substantially, the p-value for ACPA, which is our primary interest, will change quite substantially between the two analyses. So I rushed a little bit through this, but I'm going to stop here. We have a software package that can do nice regional analysis. We can add in SNPs and do a sparse estimation. And, like I said at the beginning, And, like I said at the beginning, the idea and methods could be applied and extended to other kinds of count data, and I'm hoping to do that. I would like to recognize Kai Chong Zhao, who did this work during her PhD, and many colleagues who are involved, and shamelessly finished for a plug for a graduate program at the Gill, which where I'm the graduate program director. So, thank you very much. And I do have time for like, you know. Have time for like you know one or two quick questions any questions Welcome back.