Speaker now is Benoit Posader from Brown Elibois. He's going to talk on long-time existence for the oil and Coriolis system. Thanks very much for the introduction. Thanks to the organizers, Alex, Howe, Jacob, and Sasha. It's really a really wonderful conference. So I feel very honored to be part of it. And so I'm going to talk. And so I'm going to talk about joint work with Yan Guo, Chun Yan Wong, and Klaus Woodmeier on the long-term assistant for the Euler-Coriolis system. So what is the equation? It's really close to the usual incompressible Euler equation in three dimensions, except that we're going to add a Coriolis force here. And for us, the Coriolis force is going to be fixed. Force is going to be fixed. So from now on, omega is just a unit vector pointing upward. And we're going to consider axisymmetric data and show that for those data, we have small data, long-time existence. And what does long-time existence means? Well, we can get any polynomial time provided you adjust the norm accordingly. Okay, so maybe, or at least for Maybe, or at least for me, the first time I thought about that, there was some red flags because I would not necessarily expect to have long-term existence, small data long-term existence for the Euler equation. And now the Euler-Coriolis system is slightly different, but it's really only exactly the incompressible Euler equation if you are in a frame that is rotating. In a frame that is rotating at a constant velocity. So, in that frame, you would satisfy the honest-to-god incompressible Euler equation. And then in the laboratory frame that doesn't rotate, then you satisfy the Euler-Coriolis system. But so, these are really solutions to the Euler equation. And yet, you may think that maybe they should blow up in finite time. Finite time. And at least this is not going to be the case here. And so you can suspect that there is something fishy, but there is nothing wrong with the equation. What happens is that we're going to perturb something different. Usually when you think of Euler, you're perturbing something which is a fluid which is quiescent at infinity. Whereas here, if our fluid is quiescent at infinity, then in the fluid Crescent at infinity, then in the frame that is rotating, the one where it satisfies the usual incompressible Euler equation, then your fluid has a constant angular velocity. And so it is absolutely not present at infinity. The kinetic equation is infinite, but it has some kind of rigid body motion. And now this is at infinity, it's not going to really affect what happens close to the axis of rotation, sure. Sure. But on the other hand, Euler equations are non-local. And so it is at least plausible that if you have a big behavior at infinity that is forced, then this is really going to have non-trivial consequences. And in this case, it's going to lead to some stabilization. Okay, so at least this makes it possible that you could have a long-time existence for the Euler equation in this setting. In this setting. Now, the next question that you could do is: why would you want to do that? Why would you want to take your aquarium and give it a constant angular, rotate it about a fixed axis at constant angular velocities? Well, turns out that this kind of problem really occur very naturally the moment you start thinking of fluids on a fairly large scale, because you're going to be in your laboratory frame if it's sufficiently large and it's in the earth. And it's in the Earth, then it's going to be, you're going to feel the rotation of the Earth, which so this, and it would give you exactly this if you're at the North Pole. But even if you're at a lower latitude, then you're going to feel a different or a smaller Coriolis force, but still you should still feel its effect. And of course, then you're And of course, then you're not in R3, you're on the sphere, but there is a sweet spot where you're on scale that is sufficiently large that you need to take into account the Coriolis effect, but not so large that you cannot assume that you're in R3. Or, for example, that you can assume that the speed of rotation is uniform instead of if it was on the sphere, it would depend on the latitude. Now, of course, the next thing that you would Of course, the next thing that you would probably say is that, okay, but if I'm really looking at geofluids, if I'm looking at the atmosphere, then I need to add a ton more physics, I need to have temperature, stratification, etc. And okay, this is true, but one thing at a time, you would just make your life more complicated. Let's try to first deal with the Euler equation and see what we can do in this case. And so that's our program here. Now, that was it. Now, that was it for the physical motivation of these equations. Now, on the mathematical side, there are two lines of work that are very related to what I'm going to present. And in both cases, they look at the effect of rotation and they look at, in fact, the effect of fast rotation. The first line of work is, as so, has been worked out by Babin Mahalov and Nikolenko, but there are also a lot of Nikolenko, but there are also a lot of nice works by Emmanuel Ponier and others. And what they do is they consider a generic three-dimensional torus. And they show that in this case, if you can take any solution to the Euler equation, you can decompose it into three components. A first component is just solving a nonlinear, is related to a 2D solution to the Euler equation. Solution to the Euler equation. So, this is still complicated and quite non-linear, but at least it's to the Euler. And that is, so, for example, you know that you have global existence and you can say a lot more. The second component obeys a linear equation, the Poincaré equation. And so, okay, in this case, you certainly do have global existence and you know what happens to the norm. You can describe your solution explicitly. And then there is a remaining. And then there is a reminder here that you can't really say too much about it, except that, well, it is small, at least for a long time, if you rotate fast enough. So this is the first line of work. There is a second line of work. So the numerology I'm going to present is from the paper of Curley and Percada, but I think this was started by Judy Foi, and there were subsequent work by one. And there were a subsequent work by Juan Chen and Angrio Castillo Ferreira. And what they do, they consider the Euler-Coriolis system on R3. And in this case, for general initial data, they show that even of low regularity, and in particular, so not necessarily axisymmetric, they show that if you fix any time, if you fix the time and you rotate fast enough, then you can have existence. You can have existence all the way to this time. And now, once you see those two results for the same equation, then this really is reminiscent of, or you can see that there is probably a strong dispersive framework or effect behind, because those are the two whole marks of dispersion. The fact that if you're in a big domain, then you can use the dispersive decay to try to Decay to try to delay the effective effect of influence of the nonlinearity. And for example, in this case, through Strickland's estimates, or that if you're in a generic torus, then you can make sure that you destroy all of the unwanted resonances and integrate your system to first order to write it as linear plus something which evolves more slowly. And in this case, this is what it would be. This case, this is what it would be. And you also know that you cannot always do that. There could be a resonance system that would be an obstruction to integrate it, but it would typically be a lot simpler. And this is what happens in this case. Your resonance system happens to be the 2D Euler equation. So in a nutshell, this is really what we're going to try to do. We're going to take in Going to take advantage of those two effects and try to say that as much of the equation as we can, we're going to try to integrate it through normal forms. And then when we cannot, we're going to use the decay to make sure that we can still control the solution. Okay, so those were the main works for the Euler-Coriolis system. Now, sorry, let me Me go, yeah. Now, as I discussed, usually the or the Curlie's effect is unavoidable when you go to atmos geofluids. And so, in this case, when you start to add more physics, you really have a ton more work. And I'm not going to do too much with this, but you have worked on free boundary with viscosity, you have worked a lot of work on the primitive equations, equatorial waves. Equatorial waves. And you have some work from Elgin D. and Widmeyer and Poussati and Widmeyer that are for the beta plane equation, which is another equation related to the so a 2D version in some sense of the Euler-Coriolis system. But what so but on the other hand, so those are for different equations. So, those are for different equations. Maybe something to keep in mind about those different equations. So, one of the work on the previous page was by Ibrahim, Lynn, and Titig, but building on previous work with Nakalishi and Sao. It's not quite for the Euler-Coriolis system, of course, but it's for a related equation, the isothermal primitive equation with no viscosity and Coriolis effect, which is this equation. It has a fairly similar structure to what we are going to consider, except that you have cancelled the dynamics on the third component of your velocity, and instead you have this. But for this equation, they do produce finite time blow-up for the solution. So, current effect is not by itself enough to prevent that. And the same thing, axis symmetry. And the same thing, axis symmetry is certainly a big simplification. At least, even for the Euler equation, and those have been referred to before, you can produce solutions that blow up in finite time for the Euler equation. So at least it shows that these are not directly the same equation, and in particular, in both cases, you are in a non-dispersive setup, but you have to be quite careful with the structure of the equation that you work with. Okay, so as a result, you really need to understand something to understand the properties, the refined properties of this Euler Coriolis system. So let's try to do it now. The first thing that you can easily check is do I have vector fields? So is there a way to upgrade the energy estimates to give me control on some Control on some good derivatives that would really help me essentially compactify the dynamic. So this is possible because the Euler equation being so geometric has a lot of symmetries and you can see what remains of those symmetries. So the Euler equation, you have a two-parameter family of symmetries based on the fact that you can rescale the velocity. The fact that you can rescale the velocity, the space, and the time, and they have to satisfy one relation. But in our case, we've also fixed the speed of angular velocity. So we have one more relation, but that still leaves us with one scaling family of symmetry. Same thing for the Euler equation, you have invariance under all rotations. Now, in our case, we want to fix the axis of rotation, so we want the z-axis to be fixed. Axis to be fixed, but it still gives us all the symmetries about the z-axis. So another one-parameter family of symmetries. And once you have those, you can just look at the lead derivative, and it's going to give you a vector field that commutes with your equation, at least with the linearized section of your equation. And so in this case, this is the scaling vector field and this rotation vector field. Now, that's pretty good. That gives you two vector fields in your equation. Fields in your equation. However, we're in dimension three, so this is not going to be enough to give me regularity in the tangent space, which is, yeah, because it's only two vector fields. And so in some sense, you can think of this as a continuation of a series of work for dispersive equations where you have some vector fields, but these are not enough. And then you have to add some more dispersive analysis to really push your control on the equations. Push your control on the equation all the way. And so this was done for the earlier Maxwell system or for the gravity capillary water waves. And so this, so we worked on this a lot with Xu Dang, Alex Yonescu, and Fabio Pusateri as well. But at least one thing that we can see right away is that it makes our axisymmetric assumption plausible because if you start axisymmetric, you're in the kernel of this vector field and you're going to remain in the kernel of this vector field. You're going to remain in the kernel of this vector field for all time. So, in other words, axis symmetry is preserved along the flow. Now, this is maybe something for later when we go more to the more precise description of the proof. But so because we only so we will try to propagate some smallness or some decay of our solutions, and to do this, we need to do some nonlinear version of the stationary. Nonlinear version of the stationary phase. So we need to be able to integrate by parts in the phase in the Fourier space. And we can only do that in two directions, the directions of the vector field. So we will need to add control in one more direction that we get to choose so long as this would be enough to span the whole space. And the direction that we're going to choose is this epsilon. So it comes from this. So it comes from this simple fact that the two vector fields that we have, they are the two first vector fields of the spherical coordinate basis. So the scaling is just the radial vector field, the omega is just d by d theta, and so we're going to add this new vector field epsilon, which is just the third vector field in the circle, the circle, the circle coordinate basis. Why do exactly spherical coordinates are not? Do exactly spherical coordinates and not cylindrical coordinates is something I find a bit bizarre. But at least in the estimate, this really makes your life a lot easier. And in particular, if you do this, then you have this basis is reasonably nice. All of the Poisson brackets are going to cancel. They span the space at every point. But of course, this last direction, epsilon, does not commute with your equation. With your equation, or even at the linear level. And so we will have to propagate it by brute force. And this is where the bulk of the work is going to come in. But okay, so if the vector fields by themselves are not enough to control our solutions, then the ma most natural thing to do is to try to understand better the linearized system. System. And for us, this is so it's easy to get the linear system. You just drop the u gradu and this is what you get. And maybe you have to squint a little hard, but after you massage it, you can reduce it to a scalar dispersive equation with this dispersion relation, C3 over absolute value of C. Now this is a funny dispersion relation. Somehow it seems to pop up in different problems in fluid dynamics. Problems in fluid dynamics. For example, not exactly this one, but a very related one appears when you consider stratified fluids, as in the work I think of Saint-Raymond and Colin de Verdière. And this is something I don't quite understand. As far as I can see, these are just unrelated, but they happen to have a fairly similar dispersion relation. But okay, let's look a bit more at this dispersion relation because it is zero. Relation, because it is zero homogeneous, you have this funky fact that the group velocity is always perpendicular to the frequency. So the frequency always propagates in a direction that is perpendicular to where they are pointing, which makes it a little less intuitive. But on the other hand, everything is so explicit, you can really compute the gradient, and then you can compute the Hessian, which is maybe more important for the analysis. The analysis. And if you express it in cylindrical coordinates, you see that it is reasonably nice. And in particular, once you have this explicit function lambda, you can really do, you can compute the determinant of this Hessian. And once you do this, you have this pleasant surprise that this is something that you understand everywhere. And it is positive most of the time. And you understand exactly where it vanishes. And it only vanishes for the plane. only vanishes for the plane z equals zero and for the z axis. So that's good. And on top of this, then you can also see that in all situations, no sorry, not this one, but in all situations, you will be able to find a 2x2 minor that is non-degenerate. So depending on where you are, it can be one of several 2x2 minors, but there is always one whose determinant is one or two. One whose determinant is one or bounded below. And so that's good because by stationary phase analysis, then you can push that to one over T dk. And because at most point, you're going to have much faster decay. You're in dimension three, so you would expect it to be minus three half decay, then you would really hope that you should get better than one over two decay everywhere by because maybe not quite optimal decay, but at least something in between. But at least something in between. And that would be great because once you have that, then you can hope to propagate it to nonlinear solutions. And if your nonlinear solutions have integrable L infinity norm, then by the algebra property, all of the nonlinearities are going to be integrable in time. And so at least so long as you can overcome the loss of derivatives, you should be in a good spot to get global control for your solutions. So, you can look for, but unfortunately, this is where your luck has run out. And if you take radial initial data, you can do some explicit computation, and you see that at least when you evaluate it at zero, your solutions are not going to decay any faster than one over t. So you're stuck with this, and yeah, we'll have to deal with that. But on the other hand, one over t decay is still consistent with Still consistent with long-time existence, and this is what we'll prove. Okay, so now that we understand it as a dispersive perturbation of a dispersive equation, or now that we understand the linearization as a dispersive equation, we can go back to these previous works on the Euler-Coriolis system that I mentioned before and try to compare a bit more our results with what they do. And to do this, let's try to normalize. And to do this, let's try to normalize, let's normalize the speed of rotation. So we introduce epsilon, which is just one over the speed of rotation. And we can divide our equation by epsilon, and this is what we get. Now, you see, this is almost the same equation as the Euler-Caulish system, except that now you have epsilon in front of the nominality, but this you can easily absorb if you rename v epsilon times u, and then you this allows. And then you this allows you to cancel this epsilon. And what you gain is that your initial data is now epsilon times the first initial data. So even if you started with initial data of unit size, now you are talking about small initial data. So that's one thing that you gain. But even when you do this, then you realize that what you're perturbing is Euler Coriolis, but it's Euler Coriolis in fast time, T over epsilon. And if you believe that, And if you believe that this person was pushing waves to infinity at a certain speed, then if you do this much faster, then you're really going to push the wave very fast to infinity and you should really not see them for a very long time. And so you can really hope to use this mechanism. And you can easily, there is a way to do this, which is that from the stationary phase analysis that we discussed. Phase analysis that we discussed, you can just obtain Strickard's estimate when epsilon is one, and then you can just rescale those Strickarts estimate from T to T over epsilon. And just by the change of variable, it's going to give you 1 over T a small parameter in front of your streakout s norm for the equation in fast time. And once you have that, then you have a small parameter in front of your non-linearity. Small parameter in front of your nonlinearity, and then you can hope to prove that you can have extend your solution for a longer time because it's closer to being linear. And this is more or less what is done by BT Foi, Cody, and Pakada, etc. Except that, of course, in their case, this is a bit more complicated because the dispersion loses you a ton of derivatives. And on top of this, the Euler equation is quasi-linear. So, by treating Is quasi-linear, so by treating this term purely perturbatively, you've got another loss of derivatives. So you need to couple this with energy estimates, and this is why when the dust settles, you end up with a logarithmic time instead of what would be suggestive from this, which you would think there should be a polynomial time. But then there were later improvements. If you accept to look at other slightly different spaces, you can recover. Slightly different spaces, you can recover some polynomial time, but then it's a fixed polynomial. Whereas in our case, we get any power of epsilon. Now, of course, there is one big difference, which is that we have to assume axis symmetry. And I'll come back to this later, but there is really a strong reason for that. If you want to go too very long, time. And now we can also understand. We can also understand the work of Labin Mahalov and Nikolai Ko in the same way, because in this case, instead of using dispersion estimates, you use normal forms, which is at least at the level of homogeneity, the same thing as dividing by your time derivative. But now you should be dividing by your time derivative in fast time. So when you do that, you naturally pop up an epsilon in front of it. Or you can think that now you're the distance. The distances between all your resonances or the phase has been multiplied by one over epsilon. And so, either way, once anytime you do a normal form, now you gain this power of epsilon. So, okay, this is to compare it with the previous works. But for us, so we go to So we go to arbitrary polynomial, but we have to assume axisymmetric data. And now let's try to understand the reason for it. Oh, but maybe before, let me just say one more thing, which is that you can also this work. So, one of the my interests for this kind of problem is that it also follows some work on quasi-linear dispersive equations. And so far, this. And so far, these equations have been studied a lot, but always for radial dispersion relation. And of course, this is most of the most natural equations have radial dispersion relation, and these are certainly the first thing you should try. But really, this comes with a cost in generality. For one thing, so once you, in this case, all of the rotation vector fields are going to commute with your linearized equation. With your linearized equation. But more importantly, when you start to go deeper into the quasi-linear analysis, you need to introduce certain functions that really capture the properties of your bilinear interactions. And by the very the very assumptions, all of the place where you will have degeneracy will only be on spheres because at the linear level everything is radially symmetric. Everything is radially symmetric. So, this is good. So, you're looking at the zero locus of a function, it's co-dimension one, it's a sphere. But it becomes more important when you start to look at two conditions being satisfied at the same time. So, for example, you want to have space-time resonances and that the non-linear hessian be non-degenerate or be degenerate if you want to look at the bad case. So, that's two functions that have to vanish. And if they both vanish on spheres, If they both vanish on spheres, then you will have that either those surfaces are going to be disjoint or they will be maximally the same, or they will be the same. And so instead of having the intersection of two codimension one objects is again of co-dimension one, and you can't really, so this is not really what you would expect in general. And in fact, Bernico and Germa some time ago had looked at what happens for the first iterate of general dispersion relation. Of general dispersion relations, and they had some conditions that were always satisfied if you had radial functions. So this is one way to try to understand this, not for radial function, not for radial dispersion relation, but the next simplest thing, which is axisymmetric dispersion relations. Okay, but now I would like to explain why To explain why it is important for us to have or why we require the axis symmetry. And this is because in our equation, we can find a bunch of what you would think of pre-dispersive almost solutions. And they come from the fact that you have a lot of exact solutions to your equations that are trivial but have some trace. One first such example would be Such example would be a trivial solution to the Euler equation in 3D in the non-rotating frame. And those trivial solutions would be a function which is always, the velocity field is always planar and it only depends on the z direction. So then it's a static solution, but in the rotating frame, it's going to do some rigid body motion. And now clearly this is quite far from an L2 function, so this is not going to be in the So, this is not going to be in the function space of perturbation for us. But once you have this exact solution, then you can just cut off, multiplied by your cutoff function, and then you produce an almost solution that has a behavior that is quite far from a dispersive behavior for at least some time until it starts to see the fact that it was not an exact solution. Now, this particular example is maybe a bit too trivial and interesting. Is maybe a bit too trivial, and indeed for us, it doesn't really matter because those equations do exist, but they would have a large norm in the norm that we control. So we don't really have to face that, except that the non-linearity has a structure to allow it. But what is a lot more problematic for us, and was already seen in the resonance system of Babylon, Mahaloff and Nikolaiko, is this family of 2D Euler solutions. To the Euler solutions. And indeed, you can construct another exact solution of the Euler-Corioli system if you look at vector fields, which this time do not depend on the z direction. And then in this case, what you see is that the third component of the velocity is just passively advected. But then the first two components of the velocity, they satisfy a closed system. And this closed system, system and this cross system is just a 2D Euler equation because if you're a 2D vector field which is divergence free then you're a grad perp and now you take another perp so this is a pure gradient you can absorb it in the pressure and now this is just Euler equation and again so this is going to evolve and it's going to evolve in a way that is very different from a dispersive dynamic now again this is not Now, again, this is not going to be a perturbation that is admissible for us, but you can multiply it by a smooth cutoff function to keep it one on a big ball and then let it drift off. And then you obtain a fairly good almost solution. And then this time it can start with small initial data in our norm. And this is something that we can't really allow because to the Euler. Because the 2D Euler evolution is just very different from the 2D dispersive equation. And now, on top of this, their corresponding nonlinearity would really mess things too much. And this is why we assume axisymmetry, because in this case, it would correspond to a regularly symmetric solution to the Euler, and does do not evolve. So at least we don't really have to face this, but Really, we have to face this bad additional dynamic that we would have to do otherwise. Okay, so this is for the presentation of the main difficulties. Now, I'll try to say a few words about the proof, but the broad line of the proof is not too surprising. It's consistent with how you treat a How you treat a quasi-linear dispersive equation. The first big challenge is to find a good formulation of your equation to get a good parametrization of your unknown where you can really understand the linear problem and also try to see the possible nonlinear structure that you have. Then the second step is to get a precise analysis on your dispersion relations. Relations, so because this is what is going to come when you want to do nonlinear stationary phase analysis. Then the next step is energy estimates. So you need to overcome the loss of derivative. And we also use this to propagate a lot of the vector field, a lot of derivative along the vector fields in L2. And in some sense, after this, you need some extra amount of Amount of work, and this is where we do, this is where the dispersive analysis kicks in. And it comes up for us in two steps. The first step is to try to obtain a stronger control on the good derivatives, the derivatives along vector field. And for this, the first step is to upgrade this L2 control of on derivatives along those vector fields to a control of maybe fewer derivatives, but in a stronger norm. Derivatives, but in a stronger norm, and a norm that behaves more or less like the Fourier transform in L infinity, which is something that is a bit better adapted to the stationary phase picture where you look at what happens in Fourier space. And then the second step is what I mentioned before, that up until now, this was good to control two derivatives in Two derivatives in the tangent space, but we need to have control of all the derivatives. So we really need to provide by brute force one additional derivative in Fourier space that does not really commute with our equation. And this is the second step in the inspirative analysis. So what we're going to do is now we can only do L2 and but we're going to propagate L2 norm of this epsilon derivative. Of this epsilon derivative that I mentioned before. All right, so let me first say a few words about the parametrization of our unknown, because of course, what happens is that you're talking about a three-dimensional vector field. So this corresponds to three scalar degrees of freedom, but it has to be divergence-free. So you really only have two scalar degrees of freedom. And the question is how to pin them down. Is how to pin them down correctly. There is, in the axisymmetric case, there is a reasonably canonical way to do this, the wheel string formulation. That is quite good because it nicely shows or decomposes the kinetic equation along those two components, but it doesn't really behave so well under the Fourier transform. And so instead, what we do is we look at is we look at we use a Hodge decomposition of the horizontal velocities to get our decomposition and this is partly inspired by looking at the linear picture for long enough and then realizing that the linear so the the linear part of our equation can be understood in terms of just two unknowns this Unknowns, this horizontal curve of the horizontal velocity and the third component of the velocities. And well, you want to make them to normalize them with Fourier multipliers to make them at the same level as you. And once you do this, you get these two unknown A and C. And this is a good parametrization in the sense that once you know U, you can, of course, get A and C explicitly. But once you know A and C, you can recover your vector field in a... Recover your vector field in a relatively smooth way, and by this, I mean by only introducing Fourier multipliers that are never infinite. So that would be a relatively smooth. So you have a nice reconstruction of your vector field. And not only this, but once again, the kinetic equation, the kinetic energy, which is really the main driver, decomposes nicely along those two modes. Decomposes nicely along those two modes. They each pick up half of it. And on top of this, this decomposition commutes with your vector fields. So same thing, the norm of the vector field is also decomposed in the same way. And yes. And so once you have this, and from this fact that you can recover you in a relatively smooth way, then you can, so this you will be able to express nicely. This you will be able to express nicely in terms of your new unknowns. And now you can plug this equation into the nonlinearity and see what you get. And you get a fairly big mess that would take the full slides, maybe if I were to write them, but they're not so important. After you stare at them long enough, then you can see that you can put all of the terms in the non-linearity into three buckets. The first bucket is just terms that are bucket is just terms that are that are the best of both words, so I'll just won't mention them. And then there is another bucket which is reasonably good, which corresponds to nonlinearities that always involve a Fourier multiplier that vanishes where your dispersion relation becomes less powerful, where you only get the one over T decay. Now the unfortunate fact is that Unfortunate fact is that so you have a copy of something that is zero on either the z-plane or on the z-axis. However, you only have one copy and it's distributed basically randomly into any of the two inputs or of the output. So it is a fairly weak condition, but at least it is some kind of null form that tells you that at the worst places your non-linearity is not as bad as you would expect. Not as bad as you would expect it. And this is true for almost all of the terms, except for one term or for two terms that at least are explicit and they're written here. And this, to some extent, we have already seen them. And indeed, you can look at what happens for the part in the case when your solution is really close to being resonant. Really close to being resonant. So, if you look at solutions that are almost independent of Z, then this Fourier multiplier vanishes, so you can remove this term and this term. And now, if you do this, then you see that you will get a closed system in terms of A. And in fact, even better, if you introduce omega, which is this renormalization of A, then you will realize that this is nothing but the 2D incompressible Euler equation. Incompressible Euler equation in vorticity formulation. And so this certainly is not going to give you to have a very nice structure. This is a way to see that it is the resonant system because this is where you would be resonant. And those terms, if we really had to face them head-on, they would really introduce a new dynamic that is not so compatible. And so what we do, and this is why we have to assume axis symmetry. And this is why we have to assume axisymmetry. On the plus side, when you're axisymmetric, then things are good because this is a gradient of a radial function. This is another gradient of a radial function, and you're taking their determinant. So this vanishes. And so this term is absent. And for the same reason, this term is also absent because in this case, this derivative you can distribute it here and you have the same picture. So, okay, so this is why we introduced the axis symmetry, and then we and from now on, then the analysis boils down to a more classical small data long-time existence for this quasi-linear dispersive system. And to do those, then what you need to do is to first diagonalize your linear operator, and this is done. Our operator, and this is quite easy in our case. And then you try, so you look at those two eigenvectors and you try to express them as superposition of linear waves. And then the bulk of the analysis is to try to control this superposition function v plus and minus and in particular to control its smoothness because when it is smooth then you can do the stationary phase analysis and try Do the stationary phase analysis and try to say that the smooth superposition of linear waves is going to typically be localized at the pace where you would expect it. Okay, so maybe I should try to finish soon. So let me at least present the idea. So the dispersive analysis, a big part of it is to find the right norms that will work for you. And for us, because we need to track down the page. Because we need to track down the pace where the dispersion relation becomes less potent, we introduce, we localize not just in terms of the strength of the loss of derivative, but also in terms of the so if you want, this is the angle that the frequency does with the North Pole. So this is, well, it turns out to be the dispersion relation, so X3 over Xi, but you can think of this as Of this as a measure to how far our frequency is going to be horizontal, and this is how far the frequency is going to be purely vertical. And so we decompose, so we give a size to each of those quantities, and then we define our normal this way. So we have three norms. The first one is the one from the energy estimate, and it is what you would expect. Estimate, and it is what you would expect. So it says that we are going to control a lot of derivatives of our solution in Hn or a lot of derivatives along vector fields of our solution in L2. And then we have to make it a bit more complicated. So for one thing, because it's zero homogeneous, when the frequency is small, the group velocity is very big. So it's good to try to also control negative frequencies. But this you can always do with Euler, because Euler, you can write a non-linearity as. Earlier, you can write the norm in Eric as divergence of you cancel you. So, this is basically for free. The maybe most interesting thing is this norm, which is controlling, which behaves like L infinity, but it behaves like L infinity, like the Fourier. Yeah, it behaves. So, remember, V is somehow the Fourier transform of our solution. And so, this term behaves like L infinity once. like L infinity once, except that you measure, except that, well, it's an L2 norm that scales like L infinity once you've decided on the scale of your angle with the z-axis. And so if you're far away from the place where your dispersion relation is degenerates, then you expect to have a much better speed of decay, t to the minus three-half. And then this is not so powerful as an information. As an information is just L2 information. But once you get close to the places where the dispersion relation they generate, then this starts to kick in and give you extra smallness. And then finally, the norm for the last dispersive analysis component is just an L2 norm, but of the derivative in the wrong direction. And okay, I'll okay, so maybe let me ask you quick. So, maybe let me quickly. So, the energy estimate is just what you would think. And then, after this, you need to write down your equation. So, you write your linear, or you write your solution as a superposition of plane waves, and then you write your nonlinear, so the non-linear interaction as this double integral of involving the density of pen waves. And this is the trace of the. And this is the trace of the bilinear interaction, and then you try to massage this term using the fact that you had some null form, which is that your multiplier always involves one copy of those good Fourier multipliers, except that it's in a random choice of the input or output. And then you have to look at structural assumptions, or you have to look at the structural properties of the corresponding phase. Properties of the corresponding phase. And one thing that is quite nice is that only the two directions in which you can derive, you're already almost guaranteed that your phase, your quadratic phase is going to be non-stationary in the sense that you can bound it from below by a quantity that you can understand quite well. And so, using this and the fact that this is going to decay or to be small only on a tiny set, then this is already almost. And this is already almost good enough to bootstrap the control of the vector field from L2 norm to this B norm. And then for the second part of the dispersion analysis, you need to work a bit more. And in this case, you use the fact that you can do normal forms and this somewhat really nice property that either you can do normal forms or you have some. Have some bound from below for this thing, which was the gradient of the phase in the good directions. And this bound from below is already matched at least to some amount by the smallness of the multiplier. And then after that, you need to turn the crunch. And because you have now introduced a lot of parameters, you start to have a lot of case-by-case analysis. But eventually, Analysis, but eventually you can close it. And so let me just mention two or three nice directions that this work really begs to answer or really makes quite natural. The first one is we have almost global solutions, essentially, so not exponential lifespan, but polynomial lifespan. Can you push that to global existence? You push that to global existence. Now, that would be really nice because then you really have something which is very different from the previous results, and you would have global solutions for Euler. So this is something that we're quite optimistic. And well, okay, but let me not say more. But then something that I think would be really interesting would be to try to analyze this. To analyze this in a case where you do have a non-trivial effect of the resonant system. So, you really have to couple it with the Euler mode and see if there is some regime where you can really produce this solution that would be a superposition of a dispersive component and a 2D Euler component into your equation. But that seems quite challenging. And then, of course, so as I mentioned, So, as I mentioned, the addition of the Coriolis force is just but one example of more important cases where you have this axisymmetry or the effect of rotation that stabilizes systems. And so, hopefully, this can really add in some new allow us to treat a lot more problems. And okay, I thank you for your attention. 