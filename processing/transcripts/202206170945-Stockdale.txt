Yeah, thanks for inviting me to come and speak today. Yeah, I wanted to give a bit of a genomic EPI perspective to some of the issues that we've been talking about during this week in kind of challenges and opportunities, particularly in kind of methods development, I guess, for the next pandemic. And yeah, I'm going to speak about this in the context of a project that I've been leading recently, trying to develop a new method for estimating serial intervals using pathogen genomic sequences. This has been in collaboration with Been in collaboration with other folks in the Magpie Research Group at SFU, as well as collaborators at the Microbiological Diagnostic Unit at the University of Melbourne and the Victorian Department of Health. And as you'll see towards the end of the talk, we've been applying this method to COVID-19 data from Victoria, Australia. So, as a little bit of an introduction, what do I mean when I say genomic epidemiology? Well, usually it means that we're going to use pathogen sequences to try. That we're going to use pathogen sequences to try and understand something about transmission. And of course, transmission there can mean many different things. We can be thinking at a global scale. But in the kind of perspective of today, I'm going to be thinking more about figuring out person-to-person, person-to-person transmission. Genomic EPI has become much more popular in recent years, in part because of the hugely exponentially increasing availability of genomic data. So, I've included a plot here just showing the number of sequencing projects in one database, the gold database, which is primarily for bacteria. And you can see kind of how things have taken off recently. The case is the same for viral pathogens and other things like that as well. I think there are now something like over 6 million COVID samples on GizAid. And so, yeah, we have this massively increasing pool of data to work with. The increasing pool of data to work with. And I guess along with that, the data is also being collected at kind of larger scales. So, you know, we've all seen that for COVID, population genomic sequencing of, you know, PCR tests when people, you know, get a test for COVID. So how can we kind of utilize that growing basic data, I suppose, is the question. I've kind of, before we begin with the Begin with the new stuff that I've been working on. I kind of highlighted a couple of particular what, sorry, what I see as particular areas for research or challenges with genomic EPI that we particularly try to focus on in this project. So one challenge I think is linking genomic and epidemiological data. In my experience, these are often collected by different groups, particularly in public health laboratories. You've got your epidemiologists, your genomic specialists, and Your genomic specialists, and sometimes it could be a little bit hard to, you know, link these two together. And it also means that the data are being collected for sometimes different purposes, different sampling regimes and things like that. And yeah, so that adds to this kind of challenge of linking the two together. Something else I think we need, and these second two points kind of link together, are more methods for both lower diversity outbreaks. So, by this, I mean, well, I guess this has become. Well, I guess this has become more of a problem under COVID. I mean, outbreaks where mutations happen slowly relative to the speed of transmission. So we often see clusters of COVID cases where there's only one or two SNPs mutations between people in the cluster. And a lot of our classic methods for outbreak reconstruction, for example, don't work so well in that in those settings. Yeah, and then related to that as well, less densely sampled outbreaks. So, as I said, you know, a lot of our They said, you know, a lot of our reconstruction transmission reconstruction methods are kind of designed for when we have a relatively high sampling rate among people in an outbreak. You know, we've done a detailed study, we've followed up with secondary cases. But now that we've got, you know, not just in COVID, but for things like TB where people are doing regular sequencing, I think we need methods that kind of work in, and I've kind of drawn a little figure here, in this kind of middle area. Kind of middle area between our kind of phylogenetic methods at one end, which act at this big population scale, stuff like phylogeography, for example, where we know the locations of our tips and then try and infer back through time, like where in the world the pathogen has been. So we've kind of got that on this big global end of the scale. And then on the other end is our transmission reconstruction in a particular outbreak, working out who exactly infected who. And we do have things in the middle. And we do have things in the middle, but I kind of think we need more of it personally, in my opinion. So that's part of what we set out to do with this project. Though I'm not saying that ours is the only way to do that, of course. So to go off in a different direction for a second before I bring everything back together, as I said, we focused on estimation of the serial interval in this work. And I just wanted to kind of define that so we're all on the same page. So the serial interval is the length of time. The serial interval is the length of time between successive cases in a chain of transmission, and specifically today, I'm going to be defining that as the length of time between symptom onset in an infector or an infectee. So in my little diagram here, if we've got a case A who infected a case B, you know, time moves from left to right. If A got symptoms at this time here, sometime later they infected case B, who eventually got symptoms here, then the serial interval is given by this length of time. Interval is given by this length of time. Sorry, the mouse comes up very slow on the screen. Why do we care about estimating this quantity? Well, first off, it tells us about the speed of transmission. So we can combine that with an estimate of R0 to try and make predictions about the size of outbreaks. Of course, knowing about the speed of transmission can inform our surveillance or case finding efforts, you know, when we're trying to work out who someone might. We're trying to work out who someone might have infected. But also, kind of from a modeling perspective, I suppose it has a lot of downstream impacts on other estimates. It's used can be a background kind of parameter in calculating things like R0, RT, and it can be related to the generation time, incubation periods. For example, we know that the difference between the incubation period and the serial interval tells us how much transmission is occurring before symptoms show. Is occurring before symptoms show. So, kind of having a good understanding of a serial interval has all these kind of downstream impacts. And I'll speak a little bit more about this as we go through, but one thing we wanted to try and do in particular was to come up with cluster or lineage or time-specific estimates of the serial interval to kind of track how that's changing. So, there are a whole range of methods that already. A whole range of methods that already exist for estimating the serial interval, but the majority of these rely upon or assume that you're directly observing transmission pairs, infectors and infectees. And there are a couple of ways that you can get at these, but most involve using some kind of contact tracing data or contact trace pairs. So we can look retrospectively, for example, by when we identify a case, trying to look backwards and find who infected them and thereby. And thereby get a set of pairs like this. I've just made up some people. We decide that A infected B, E infected F, and so on. And you can also do this prospectively, for example, by monitoring your population for index cases and then following up with people in their household or otherwise to try and find these pairs of infectors and infectees. And then I've included an example here. Once you've got all those pairs of cases, as I did in this paper by Cases as it did in this paper by Duodal for COVID, you can plot the distribution of all your serial interval pairs, so the symptom onset time, kind of difference between all of these pairs, and fit your favorite distribution or however you want to estimate the serial interval. But as I said, most of these existing methods require this kind of detailed contact data. We need to actually be able to find pairs, and they often generally assume. Pairs and they often generally assume that we do fully observe the you know that the pairs that we get are true transmission between A and B or E and F. This can be hard to get to do this contact tracing. It also often means that estimates end up being collected from particular settings like households. And of course, household studies are super useful. But if we think that transmission maybe is acting slightly differently in households, we might get a slightly biased view. We might get a slightly biased view of the serial interval. You know, maybe transmission generally takes longer outside of the household, and so we're not kind of building up that picture of what's really happening at a population level. Because it's difficult to do contact tracing, estimates can be not updated often. So as I said, the serial interval going into downstream estimates of other parameters, you know, we might be using a bit of an outdated serial interval estimate. And also, there's privacy concerns, and this is something. And also there's privacy concerns, and this is something I've come across when trying to build this method is that it can be really hard to share contact data, right? It, you know, has is detailed information about people. And so the ethics of that can be challenging. And so this motivated, as I say, what we set out to do. But before I move on to that, one other kind of existing method for serial interval estimation, which kind of partly motivated what we Of partly motivated what we did here was this paper by Wink et al. in 2014. And so they did take this idea of undersampling that we don't necessarily see true transmission pairs into account. So their method was designed mainly for still kind of small outbreak settings, houses, school outbreaks. And what they do is this take this index case to case approach to estimating the serial interval. So they take the index case in their So, they take the index case in their, whatever their small outbreak setting is, a household, let's say, and they look at the difference in serial symptom onset time between that index case and everyone else in the cluster. So A to D, A to B, A to C in this example. And they then consider that each of those pairs might represent direct transmission. This is what they call primary, secondary. So the people in the little circle here, this is from their paper, are this is like R A and R B, for example. RA and RB, for example. So there was direct transmission from A to B. They consider that also that there could have been an unsampled case, well, or somebody else in your household configuration who was in between A and B. So you could have had one missing case in between. They also considered that there could have been two other cases in between your pair. Or lastly, that there could have been one person outside of the poster who infected both of the cases. So actually two initial cases in. Two initial cases in the cluster. And they kind of, by considering each of these four methods, they use a mixture model to estimate the serial interval, which I've included here, they assume to be normal. Yeah. I was just going to ask about that. Yeah, so they and we, you'll see in a minute, do assume positive. We'll see in a minute. Do assume positive serial intervals. Yeah, obviously, you can have negative ones if, yeah, the what is it? The infectee gets symptoms before the infector. I think it's mostly a convenience mathematically type thing, but yeah, I would like to. Oh, oh, yes, sorry. I'm getting mixed up. Yes. Sorry, I've got it the wrong way around. Sorry, I've got it the wrong way around. Yes, so you can have negative serial intervals if, yes, if the incubation period is highly variable, and then, yes, your infect D gets symptoms before your infector. But yeah, should in most cases would be relatively unlikely unless, yeah, you have a super variable incubation period. Yeah, sorry, got that. Yeah, generally. Yeah, generally. Yeah. Sorry, I forgot where I was. Yes. Yes. So as I say, well, you'll see in a minute that this kind of inspired some of the decisions that we made in our approach, though we're not going to use this kind of index case-to-case setting. So, as I say, we set out to take a new approach using genomic data. So, there are kind of two. Genomic data. So there are kind of two main goals or key new aspects of this, which are the ones I've marked with red stars. So we want to avoid the issues of using maybe expensive or resource-intensive contact data whilst harnessing what whole genome sequence data can tell us about who infected who. In doing this, we're going to try and incorporate under sampling that we might not fully observe all of the cases in a given cluster. And as part of the And as part of that, try and set up a method which is intended for larger clusters than households. So, you know, any kind of, I guess, we're thinking in a kind of intermediate regime where we have a good idea of what's going on. Let's say like a school outbreak or a workplace outbreak, but we're not seeing, you know, we may be seeing 50% of cases or less. And we're going to try and, again, use this approach to make cluster-specific estimates. So can we compare estimates of the serial interval? Estimates of the serial interval in different settings or through time under different COVID-19 variants, for example. So, here's a kind of schematic view of our method, and I'll take us through each of the different stages. The first two, sequencing and clustering, are kind of preparatory stages, I suppose, and I'll review those briefly. But I'm going to spend more time on the second half of this diagram, where we're going to do some sampling of transmission networks. Some sampling of transmission networks. So that's where we're using this genomic information as a proxy for contact data. And then, given that, trying to do an estimation of the serial interval. So, as I say, first, if we want to use whole genome sequencing, we're going to need some sequences. And yeah, I guess I've touched on a lot of the ideas of this already, but the idea is that instead of using contact data, differences in our sequences are going to tell us how closely related people's infections are. How closely related people's infections are, and therefore who might have infected who. So we can track these patterns of variation in different sequences in a cluster to see the kind of more likely transmission pairs. And as I said, this method is kind of currently targeted at this intermediate level, moderately dense level of sampling, something more like routine COVID-19 sequencing than doing a detailed outbreak study where we follow up with every single person. And that's not to say that the method wouldn't work if we weren't. Not to say that the method wouldn't work if we do have detailed data, but more that we also want it to work when we don't. So again, if we want cluster-specific estimates, we need to do some clustering. And I'll just review this briefly. This is kind of a, there's one main point I wanted to bring up here, which has been something we've seen, which is the challenge of doing genomic clustering, particularly for COVID-19. Clustering, particularly for COVID-19 sequences. So, the normal approach, and we have done this, would be: you know, we have a set of sequences, we build a maximum likelihood phylogeny, and then we use some cluster tools, such as clustering tools, such as cluster picker we used here, to essentially, if you look at my little diagram here, create clusters of cases. But as I said, we're seeing a lot of low diversity, well, clusters in Well, clusters in COVID-19. So, something we found when we did this, particularly for, you know, in, as I say, we're doing, I'm going to talk about an application to Australia where they didn't have a lot of COVID in the kind of early outbreaks there where things were, you know, there was an introduction and then a burst of cases, we found it quite easy to do this clustering. But once you kind of progress to more community spread, I suppose, it can be harder to distinguish these from one another. And we kind of end up From one another, and we kind of end up with one huge cluster of thousands of people. So, something we explored doing as part of that was doing what we've called exposure site clustering. So, we did want to avoid using any contact detailed contact data in this method, but our kind of minimal amount of that that we decided to use was clustering cases by those associated with particular sites of interest to public health. So, we don't know who met who and when, but we do know, you know. But we do know, you know, this person attended this school at some point, this person attended this healthcare site at some point, and then clustering by that. And yeah, I'll come and touch back on this at the end. Clustering by location or some kind of external variable that has nothing to do with this people. No, no. And ideally, I would like to do some kind of combination of the two. Ben Sopkoiak, who's another postdoc in our group, has been working on a method to do that. Working on a method to do that. But yeah, we haven't, he's still developing it. So we haven't tested out on this data. So we've got our sequences, we've got our clusters, and now we can go on to do the actual serial interval analysis. And the first step is using our sequences as our proxy for contact data. So building a network of who infected who, given our sequences. And as I mentioned here, I think. And as I mentioned here, I think because we are aiming this at a more sparsely data situation, our kind of idea here is that we don't need to exactly reconstruct the one true transmission tree. We want to kind of build some general idea of who might have infected who, but incorporating the wide uncertainty that we're going to have. So we do this by a kind of two-step process. So for a given cluster, first we want to essentially make ourselves First, we want to essentially make ourselves a big list of all of the possible transmission pairs that we define as plausible, and we call this a transmission cloud. So, you can imagine it as we want to build this big bubble of all plausible pairs in a cluster. And what do we mean by plausible? Well, we say that this is any pair A, B in the same cluster who have sufficiently close sequences. So, in practice, we do a kind of SNP threshold here. So, they have to have pairwise genomic distance. So they have to have pairwise genomic distance less than or equal to some G SNPs, where we're pretty strong cutoff here. So we say that because, well, for COVID-19, for example, we know that mutation occurs slowly, we do a pretty sharp cutoff, something like one or two SNPs, but you would change this for whichever pathogen you were dealing with. And then we also say that those people have to have realistic timing of their symptom onsets. So in practice, again, Symptom onsets. So, in practice, again, we say that they have to have a difference in symptom onset date less than or equal to some T days, but we're much more generous with this, essentially, to try and not bias our estimation too much. And yeah, we do specifically, so this relates back to Ebna's question, we do say that the A has to have showed symptoms first. So, we're going to restrict ourselves to positive only serial intervals, which may not always be the case for COVID, but you'll, well, essentially. Um, but you'll well, essentially, this comes out because we're going to be using gamma distributions and we couldn't find a way to make it work otherwise. Um, but it is something I'd like to think about. Um, however, we shouldn't shouldn't see uh negative serial intervals too often, so I hope for a first kind of pass that this is a reasonable assumption. So, at this point, we've got this big cloud of plausible pairs, and what we do is sample plausible transmission networks from that cloud. So, I think of like picking pairs. I think of like picking pairs out of the cloud, gluing them together until we have what we're calling a plausible transmission network. And we can do this sampling, you can imagine, in various ways. You could just randomly select. So we do it by selecting one infector for each infectee. So that assumes that we, everyone ends up in this sampled network. You could do this completely at random. You could do it by preferentially sampling close genome sequences. Or what we do is both preferentially samples close. Both preferentially samples, close genome sequences, and people who are close together in time. This is arguable whether you want to include the time aspects, I suppose, but we had conversations with epidemiologists and contact tracers, and the impression we got from speaking to them is that that is the decision-making process they would take. The closer people were in time, the more likely they would determine them to be a pair. And instead of doing this just once, you can imagine that our Of doing this just once, you can imagine that after we do that, the sampling from the cloud, we end up with a transmission network that looks something like this. We actually do that some big number n times. So that's building in that we don't really know who infected who, but we try and get this kind of distribution over who's more likely to have infected who. And what we're going to do is estimate the serial interval in each of these networks independently and then kind of join everything together at the end to do an averaging across the space of networks that we see. The space of networks that we sampled. So at this point, we're ready to estimate the serial interval. And as I said, we're going to do this in each of those networks independently. And again, if you've got multiple clusters, you're doing that, repeating that whole process again in each cluster. And we take a similar kind of approach to the Vincatal paper that I presented earlier in that we consider these three different pathways of transmission. But as I say, we don't take that index case-to-case approach that they Index case-to-case approach that they did, we just work through every single pair in our sample transmission networks and consider that each one might have represented one of these three different transmission pathways. So by this, I mean that we could have had direct transmission between our pair, A infected B. It could have been indirect, there could have been cases that we missed in between. And in extension to what Binkatel did, we consider that there's a potentially infinite number of missing cases. Of missing cases in between. I mean, in practice, we wouldn't really want there to be an infinite number, but you know, we could have one, two, three cases, you know, as many as you want in here. And then lastly, we consider this co-primary transmission. So again, that's the idea that there was somebody outside of the cluster who we didn't sample who infected both of our cases, A and B. And similarly, we do for a mixture model to incorporate this idea. So for each pair in our tree, we have the mixture of these three pathways, and then we sum up over all the pairs in our tree. And then we sum up over all the pairs in our tree. So, mathematically, what does this look like? Well, we assume that the true zero interval, as I say, has a gamma distribution, which we parametrized in terms of a mean and standard deviation just for ease of having a mean out at the end. And so, as I say, if we have direct transmission between a pair A and B, then the observed interval, let's call it TAB, so the difference between A's symptom onset and B's symptom onset is going to be a true. Symptom onset is going to be a true serial interval and therefore it's gamma mu sigma. If we have indirect transmission, then we note that the observed time interval we see between A and B is actually m plus one serial intervals if we have m missing people in the middle. So you imagine if we had one missing person in the middle, we've got two serial intervals between A and question mark and between question mark and B. And then so on as we get more people in the middle. But the problem is that we don't know how many people there are, this number M, and so we add a couple of. Are this number m and so we add a kind of uh hyperparameter, I guess, for that, uh, where we say that m must be geometric with some rate pi, where pi is kind of a sampling rate, right? It's you know something like the proportion of cases that we're missing. I'm sorry, that we're finding. And it turns out that the, you know, the sum of gammas is gamma. And if you take into account this geometric hyperparameter, then the distribution of the observed Then, the distribution of the observed time we see between A and B is a compound geometric gamma distribution, which has a nice form we can write down. And as I say, we're going to fit this in a mixture model. And overall, we assume that a proportion W, which we're going to estimate, of all pairs in our tree are of this type. And you can see that the direct transmission is actually a special case of indirect when M is zero. So that's we kind of compress that all into one category. One category. Then we've got our co-primary transmission where our person externally infects both cases. And hopefully, I convince you here that this turns out to be a folded gamma difference distribution. So let's take, if I take you through my little diagram again here, so we've got time going from left to right, and we've got some person question mark who we know infected both A and B. So person question mark showed symptoms here. Am I going to pen? Yeah. So, our question mark person showed symptoms here and later on went to infect both A and B. So, we've got two true serial intervals in this diagram. There's the one between question mark symptoms and A's symptoms. And there's another one, I'm going to write all over this, sorry, between question mark symptoms and B's symptoms, which is about here. Sorry, my drawings are really bad. And then if we think. And then, if we think about how that relates to what we actually see, which is the difference between the symptom onset of A and B, we can see that that is the difference of those two serial intervals. It exactly lines up. So that gives us our gamma difference distribution, which also had a nice form. I've included the paper up the top here if you're interested. And it ends up being folded because of that assumption we made that A had to show symptoms before B. Yes, and there we have it. So that's. And there we have it. So that's our kind of model for what this co-primary transmission looks like. And we assume that in our mixture model, the remaining proportion, 1 minus W, of transmissions are of this type. And did I keep it on the next page? Yes. So we end up with a log likelihood that looks a little bit something like this. So as I say, we're going to consider these transmission paths, these possible pathways over each pair in our tree. So we have a sum out of the front over every. So, we have a sum out the front over every single of the pairs in our network or our tree. And then we have, yeah, the proportion W that are of that compound geometric gamma type and a proportion one minus w that are of the coprimary type. And we could maximize this likelihood directly, but in practice, what we do is actually use maximum a posteriori approximation by putting priors on those parameters w and pi. So these both kind of are related to sampling. Of are related to sampling, it's not exactly a sampling rate, but um, in coprimary transmission, we've missed a case, right? The person who infected both A and B. And of course, pi tells us about missing cases as well. Yeah. When you average over all different average of the data, we don't weight anything weight by likelihood. Um, I haven't thought about it actually. We, yeah, we just do a About it actually, we yeah, we just do a general average, though. I mean, some trees it's definitely possible that we get the same tree more than once if there's not many options. So, in that way, I guess it would be weighted if you sample one tree more often, but yeah, otherwise not. But yeah, I hadn't thought about it. It's an interesting idea. Yeah. Yes, and then as we said at the end, yeah, we average over all of our networks to get our whole cluster estimate. So, in reality, we should count, right? Because you're not evaluating what exactly. Not about the way exactly. Um, yeah, I guess if you had a small enough uh network where you thought you could do them all, you could do that, but yeah, we just sample. Uh, I mean, it's fast, 100,000, however, 100 or 1,000, however many you want. Have I got anything to say before I move on? Yeah, I guess I can move on to our data application given time as well. So, as I say, we have some transmission clusters from Victoria in Australia. Transmission clusters from Victoria in Australia that we used to apply this to in collaboration with our Melbourne colleagues. So we had data from them from the first two waves of COVID in Victoria, just roughly January to April 2020 and then June to October. And to set the scene a little bit, yeah, they had very limited community spread in that first wave and then a lot more in the second wave. And we primarily worked with 10 different clusters of cases per wave. Essentially, we picked those clusters. Essentially, we picked those clusters which had at least 15 cases were finished by the end of the study period. And for wave two, there were a lot more we could choose between. So we kind of picked some key clusters that they were interested in learning more about. So just to touch back on the clustering issues I spoke about earlier, I've included here some figures of the phylogeny for the wave one and the wave two data. So in this first Two data. So, in this first wave, we did use genomic clustering, and you can see that we end up. So, each of our clusters here are coloured on the phylogeny, and you can see that generally the clusters do look quite neat on the tree, right? There's like a burst, you know, a relatively long branch and then a burst of cases that forms a cluster. But the wave 2 phylogeny, which we ended up doing that exposure-site clustering, you can see that we have this like long backbone of the tree and then very low diversity among it. And so, when we did the genomic clustering, It and so when we did the genomic clustering on this tree, whoops, I didn't need to draw. Uh, well, it kind of works. You see, all of these cases end up kind of being clustered together because of that, that low diversity. So, we found that doing the exposure site clustering gave us a bit more resolution. In general, like sometimes that aligns well with the tree. This yellow cluster you can see up the top, which was related to an aged care facility, does align well genomically. But this also. But this also allowed us to do that comparison of, you know, do our serial intervals longer or shorter in certain kinds of settings. So here are our estimates of the serial interval in each of those 10 clusters per wave. So to just explain what you're seeing here, on the left, wave one at the top and wave two at the bottom, we have the estimates of the mean serial interval and a 95% confidence interval. 95% confidence intervals for in each of our 10 clusters, as well as they did a kind of pooled analysis where I put them all together to get a whole wave estimate. And on the right, given the mean of the means and our estimate of the standard deviation, the sigma of the serial interval, I've just plotted basically what we get for our serial interval distribution. And then again, the bottom for the second wave. So, in general, we're not getting super huge estimates, particularly. Super huge estimates, particularly within WAVE, but there is some differentiation between them. Particularly, you know, we get these two. Oh, you can't see my counter, can you, my mouse, but here in the second wave, we get these two clusters where the confidence intervals completely don't overlap. And I'm trying to come up with a good way at the moment to think about, you know, just because the confidence intervals overlap doesn't mean there's not a significant difference. Not a significant difference. I'm trying to think of a good way to summarize this given that we have estimates of the mean with confidence intervals and the standard deviation with confidence intervals. But anyway, we're seeing a bit of a difference. And in general, these are in line with other early published estimates for wild-type SARS-CoV-2. But yeah, with some kind of variation starting to show. One thing we did was then to bring in some more of those wave 2. To bring in some more of those wave two clusters, so we focused on the 10 initial ones, but we extended to looking at a whole set of about 90 wave two clusters where we're able to categorize by these exposure type settings. And so here I've plotted, this is those 94 different clusters, and I've ranked them by increasing mean serial interval and just tried to get some visual idea of if certain settings have longer or shorter serial intervals. And I mean, this isn't super conclusive yet, but. This isn't super conclusive yet, but I think that generally, the which ones is it? The orange color, which is packing and meat processing plants, and schools, which is the brown ones. There's not so many. But I don't know how to rub that out. Well, it might. The schools tend to also tend to be in the lower ones. So these are kind of settings where people tend to attend for not very long. Whereas settings such as aged care facilities and healthcare facilities. Aged care facilities and healthcare facilities where people are staying for longer times, as well as housing, are kind of more towards the top of our serial intervals. So I would like to look at this on an even bigger scale, ideally, but it's proving a little bit, it's kind of hard to get data. But yeah, I don't know. I guess it's some early signs that there's differentiation in serial interval in different settings. And the last thing I'll talk about is that, as I said, estimates of the serial interval are. Estimates of the serial interval are input when we want to estimate the real-time reproduction number RT. So, something we did was do a little comparison of how different RT looks if we use our cluster-specific serial intervals in each of these outbreaks, which are shown in colour here, compared to a literature estimate of the serial intervals. This was published by B et al, and they used a gamma distribution also with mean 6.3. And yeah, so sometimes you can't really see the gray very well on these diagrams. So I'm sorry. See the gray very well on these diagrams. So, I'm sorry if you can't see that. You, you know, in general, for some of these outbreaks, it doesn't make much of a difference because we estimated a serial interval that was close to six. But in a couple of outbreaks, it can make a bit of a significant difference. This cluster A8 at the beginning, we're seeing a difference of two and about three in our estimate of RT. And also, particularly in this cluster A10, you can see at the very end, this last one here, that just changing the underlying serial interval, something we normally kind of assume is the difference. We normally kind of assume is the difference between RT less than one and bigger than one at the end of our sample cases in that cluster. So, you know, this literature-based estimate here was for wild type SARS-CoV-2, as is our estimates. I think that this is indication maybe that if we were to use a serial interval estimate from 2020 for Omicron, then we might see a bigger difference in these serial intervals. And that's something we're looking to check now. And that's something we're looking to check now. So I'm just gonna finish off with some specific and more general thoughts about future pandemics and outbreaks. So specific to this project, I think, well, in my opinion, what this is starting to show that we need to make sure that we're updating estimates regularly, particularly when they're impacting these downstream analyses. I haven't seen so many estimates of quantities like serial intervals for the later variants as I did. For the later variants, as I did originally, I mean, they exist, of course, but I think it's something important to keep in mind. More widely, I think there's a question of what else we can learn from genomic data where we're not working on this global level, but we're not working on a super detailed person-to-person resolution. Like, what else is there in the middle? Yeah, how can we better combine genomic and FE info? And then, we'd like to do this for this project too, like, as I said, in the clustering, but also in that. Clustering, but also in that tree sampling. I think if we could combine the information we're getting from the genomes with any known contact pairs or household contacts, that would really improve things. And even more widely, this is like a super broad idea that I wanted to finish on that I would really like if we could use genomic epidemiology more in prediction settings than just estimation. And this is something I've been thinking about with other folks that in the Magpie group at the moment. Group at the moment. And yeah, I guess I don't, I'm out of time, but I just thought I'd finish on that as a more perspective point. Yeah. Oh, and I'll finish off by thanking everyone else who was involved in this project. In particular, Konia Susfidasari at SFU did a lot of the building of the model here, along with Paul Tupper. And then, yeah, our collaborators in Melbourne and the Victorian Department of Health. And lastly, you can read our preprint if you're interested, which is all about. Our preprint, if you're interested, which is all about the stuff I've spoken about today. Thanks.