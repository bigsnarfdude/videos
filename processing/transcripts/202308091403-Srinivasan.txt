The invitation to speak and for moving my talk before the hike. I actually enjoy it. So, yeah, this talks about rational points in terror. So, probably on the algebraic side, but I hope to show you how p-adic geometry can help you find rational points. So, we heard from Denzel we need to start talks with making controversial statements. So, I've heard of the controversial statements of the goal of the number theory. Statements that the goal of the number theorist, at least the field of number theorists I hang out with, is to find darshan points in nice curves. So you're given, and this is a technical term, so smooth, projected geometrically integral. So you have a bunch of equations with a few coefficients. I'm going to assume that my curve has genus at least true. So this is a sufficiently complicated curve, and the goal. Complicated curve, and the goal, not of maybe every number, but a lot of them, is to compute the set of rational solutions, the set of rational points. So one of the landmark theorems in arithmetic geometry is the curves that are sufficiently complex, geometrically complex, so gene is at least two, this set of solutions is actually finite. So this is, if you can, we'll be clear. If you can make more clear with voltage from 1983, this is a finite set. So you actually want to know what are these finitely many solutions, what is the finite set of rational points. So unfortunately, Fauden's theorem does not give you a way to find this finite set. Maybe the solutions have billions of digits. It doesn't give you a good way to compute this finite set. To compute this finite set of points on the curve. So, today we're going to use p-adic geometry. We're going to try to locate this finite set of points inside a set of p-adic points on the curve. So, we're going to look for rational points inside the periodic points. And what we are hoping for is that the rational points lie on some, they're constrained in some way, and where they can be inside the set of plateau points. Like we said, we'll play it. So we want, for instance, there might be special analytic functions that vanish on the set of rational points. So we want constraints, like a certain analytic function vanishing on the set of rational points. And we want these to be explicit things that you can write down, you can compute, right? Explicitly computable constraints on the set of astronomers. On the second rational points. Okay, so what's special about that the rational points are inside the P-iadic points, and why should we even expect such a thing? So let me start with a little bit of history of periodic methods for finding rational points. So there's a precursor way before Faultins proved there are finitely many solutions. There's this early apiatic method due to shabby, which was later made. Which was later made effective by Kohlman, gave bounds on the number of rational points, which are quite often sharp. So this is a way of locating the rational points inside the piano points. And the idea is you embed, so where do such functions come from? So you embed your curve, as we've been doing all weekly, embed, embed the curve. It made the curve inside the Jacobian, inside this lattice space, and maybe the rational points inside the Jacobian line up nicely along some hypersurface. So you have this piadic lead group, the piadic points in the Jacobian, and we have this nice analytic curve. We hope that you can find some constraints. We hope that the rational points line up along some nice hypersurface. So in that curve, here. Uh so in that curve here so um one um one or one obvious location where you can hope to find rational points is inside the rational points of the Jacobian. And let's say they take this closure and you want to take such functions, functions that cut out this closure. Functions that cut out this closure and restrict them. Okay, and hope that it's explicit enough that you can actually describe what this is. And as a reminder, please come to the comm session. So if you want to do this, you should first do a sanity check. Like any direct stock, you should check that this is actually a smaller dimensional space, right? So there are some dimensions. Dimensional space, right? So there are some dimension constraints. So if this is to work, we need the dimension of this closure. I mean, it would be a problem if this fills up the whole space. The only function you'd be able to write down is a zero function. That really is not a constraint. So you want the dimension of this to be less than the ambient dimension, dimension of J. And this is something you can control in many situations if we can control. In many situations, if we can control this group of rational points. So, in the low-rank situation, another theory is this group, the set of rational points in the Jacobian, is a finitely generated group, has a well defined rank. And whenever the rank is less than the genus, you will find interesting functions that vanish on this location. Functions that vanish on this locus. This is strictly smaller. You wouldn't intersect a hypersurface with the curve and expect a finite number of points. So this is a heuristic for when you can expect constraints on the rational points. But if you want to actually write this down, Coleman actually helps Coleman and others that tell you that you can actually describe these functions by nothing on the rational points rather than explicitly. Exclusively, what you need when you restrict to the curve is you need a set of differential form on your curve. And if you're close enough to a point, it's actually what we teach at people in calculus. Write down the power series expansion for your differential form, integrate term by term, set it equal to zero, and solve. But actually, you need to be a bit careful. Like, this works close enough, in a small enough p-adic neighborhood above any point, you have gifted images. About any point, you have good convergence. But if you want to actually make sense of entangles on all of the pairic points, you know, the topology of the pairs is rather weird. There is no good notion of paths, right? And so this is why I put this in votes. There's more than one way to make sense of an integral. One of the insights of tropical geometry is to clarify the relationship between different ways to integrate a differential form. A differential form. There are two popular methods. So, like Eric, Eric here was involved in these comparison theorems. So, it was also Eric Gatz, Joe Rabanov, David Zurich-Brown. And it led to some fantastic uniformity results on the number of flash move points many years ago. So, this is a strategy, but this works. It crucially needs this dimension hypothesis. We need the rank of the Jacobian to be less than the genus. Jacobian to be less than the genus. You can ask how often, how likely is it you will be able to use the sphereic method? If you write down a random equation over the rational numbers, it's very likely this holds. Most of the time you expect the round to be 0 or 1, the lead will probability. So for random curves, this method will quite likely work and it's actually pretty successful. But I think we'd all agree that not all curves are the same, like not all algebraic varieties are the same, especially this one. Algebraic varieties are the same. Especially this audience, people favor modularized faces more in best rank than other varieties. So in number theory, there are certain curves that we like more than others, so-called modular curves. And modular curves, so these are curves that parameterize elliptic curves with certain extra level structure. These tend to have high line. So this hypothesis, this star doesn't hold. So you want other methods, other places to look for functions vanishing on the rational points. So in the last, let's say, 10, 15 years or so, there is this recent breakthrough. It was an extension of the An extension of the Chevrolet method, the Chevroleti Kohmanikin method. And what it lets you do is that it's actually been quite successful. It's, for instance, helped us find rational points on certain modular curves where the rank equals the genus. And you don't get in You don't get anything with I43, you need an additional geometric input. So what do you do when the right size in the shape of D-correl? The extra geometric input is the data of a line bundle of the decorum. So if you are you understand. So if you are you have to set up that the rank rank q equals the genus, but you have additional neurons of every rank the Jacobin to play with. More precisely what the Schubert-Jacobin kin method uses is a line bundle on the Jacobian that cannot be deformed. That cannot be deformed to zero algebraically on the Jacobian, but when you pull it back to the curve, we do get the trivial bundle. So if the Neurons are very of the Jacobian slank at least 2, you can find such line bundles. And the Chauvini-Coleman-Kip method uses such line bundles to produce new analytic functions vanishing or dashing points. Let me first tell you what these Points. Let me first tell you what they look like. So, the new constraints on the rational points, they have the shape of certain quadratic functions. So, they look like products of single intangals. Like the single intangers like a linear function of the Jacobian. So, the things that show up here look like quadratic functions. G of Q, so you have a nice basis of that coming from integrals of the transform, so the natural is the genus, minus certain iterative integrals that we have in calculus. You look for zeros of functions that you get by integrating differential forms, but where does Differential forms, but where does this really come from? You start out with some straightforward geometric inputs, this theta of a lung bundle, but to from there to get to this explicit analytic function vanishing on the rational points is quite a bit of heavy technical machinery along the way. So the first time that people observed such a thing was possible, that you could use line bundles on J. 9 bundles of J to produce functions vanishing the Jacobinus is due to work of Jennifer Balaprishnan and Neitan Lugar. So they were inspired by many of Kim's non-obelient shabby method. And the idea is rather comological. So you if it It uses a heavy technical machinery. Number theory uses a lot of PRICOT theory, but the idea is pass this line bundle into this black box machine, it does some black magic, and then it uses the line bundle to embed the curve into a space that's larger than the Jacobian. So when the land equals the genus, you no longer, I mean, this closure of G of Q fills up the whole space, the Jacobian is too small, but you can use the full geometry of the fundamental group of the curve. So, in some sense, the Chaboty-Permin method only sees the abelianization of the fundamental group, but if you use the full fundamental group, you can embed your curve. Fundamental group, you can enter your curve into larger spaces and try to hope that the rational points in the curve line up along special sub-varieties in this larger space. So that's morely what they do. But to go from here, to start with the line bundle, you need to pass through all this short speoretic machinery before you end up with this very explicit analytic function. So the starting point. For us and many other people, was given that you start with very explicit geometric information, is there a way to directly use this geometry to describe where these extra functions, new functions come from? So there's a new approach, a new more geometric take what I shall repeat. This is a different team of people. So can I just ask this hypothesis that the neurons very rank is regular models? That's true for all of these modular curves? It's true for modular curves have lots of extra correspondences. There's the HECA action, so it's a good place to look for curves with extra correspondence. But it's not the case that the first thing implies the second thing. No, no, no. This is true for many modular curves, but the gender framework is. But the gender framework is you need this and you need this extra information. I was very simple. Excellent, American number one, and anyway. A very naive question. Please ask who this analytic function, what space is it defined on? If it were analytic on the whole Jacobian, it seems like Daga would tell us that it is algebraic or Tell us that it is algebraic to be different. So these functions have the shape that they're locally given by integrating differential forms. You start with an algebraic differential form and you integrate it, you actually end up with something on a multi-committee on the neighborhood of a point. Oh, the neighborhood of a point is actually given by power series expansions. You write down your differential expand your differential form in a uniformized planet, and you would degree 10 by 10. A global intersection of some buttons. But globally, it's a section of some button. Globally, omega is the section of algebraic, it's a section of holomorphic differential, but you integrate it, you end up with something on the differential. You don't have a global integral. You don't have a global integral. This is some collection of open sets that cover a cover. Yes, in each residue disk, so you look at piano cords in the curve. Yeah, you look at p-adic points in the curve, they especially in the neighborhood. You look at the p-image of a point, a p-point, you get a nice residue disk. In each residue disk, there emits a nice power series expansion, which you can write down by integrating term by term. But globally, it's not happen sets that don't cover the whole curve, but they do cover the rationale. Yeah, so it's something called Kohlman analytic. So it's locally analytic with an additional condition that's kind of hard to. Condition that's kind of hard to phrase, but is some compatibility given by for weakness. Yeah. If you're thinking close enough to a neighborhood of a point, you should just think like you do in calculus. You have a differential form, it has an expansion, and then you need to be. Yeah, it's an additional constraint if you wanted to actually be analytic in like global how do you piece together these local integrals across residue disks? Integrals across residue disks, so you need some global analytic condition that lets you pass between residue disks. The topologies we are, there's no. But even then, this global thing will not be a function. It will be a certain kind of analytic function, is what Eric's saying. A Koolean analytic function. A certain subset of analytic functions on an apiadic graph. And in in in a small enough neighborhood of any point, it's it has it has nice convergent power series that you can look at. Empowers in these study things. Just a terminology question. What's the rank of the end of the group when you say NSO general? Oh, yes, sorry. Yeah. We need line bundles that cannot be deformed to. Need line bundles that cannot be deformed to the trivial bundle on the Jacobian, but when you respect to the curve, it does deform to the trivial bundle. So, yeah, so to go from line bundle to these explicit functions that, I mean, if you sit down and write them down, it's integrating differential forms. There's a lot of work that goes on in between, and the original approach due to And the original approach, due to Bhadakrishnan and Jograha, used a lot of heavy watch-theoretic machinery. But I mean, line bundles come with a lot of additional geometric structures. So you want to directly use geometry to describe where these extra functions come from. So what Eric Hoven and Hero observed is when you have such a nice line bundle, a line button not Non-trivial eigenbunda with restrictions to the trivial bundle in the curve. This lets you embed the Jacobian is too small, but you have the total space of the line bundle on the Jacobian and you get an embedding of your curve into the total space of this line bundle. So this has just one extra dimension, but that's good enough. Inside this larger space, the rational Inside this larger space, the rational points do line up in some sub-variety. For carrying this out in practice, what they actually need to do is they work with explicit formal coordinates on this g plus one-dimensional space. We need to do explicit, if you want to write down these functions directly, you need formal coordinates on the total space of line number. The total space of line bundle, you need to parameterize this map. So, okay, so this again, I mean, it actually works in patterns, they have examples. But at the end of the day, you don't care about these larger spaces very empathically. All you care about is describing these functions when you restrict them to x of qp, right? And at the end of the day, both of these the wrote down very explicit functions that can be described in terms of integrals of the 12th. Of the 12th. So today I want to present to you the third take. This is everything I say today is joint work with our professor and Stephanie MÃ¼ller. We want to give a new theoretic perspective on where these functions are Inditional functions come from, and to us, it's no accident that you see functions of this specific shape showing up. So what we do is in our setting, okay, so here's the back to working with the Japanese, you have. Now, instead of looking for the rational points on a single hypersurface, we're going to look for rational points along finitely many hypersurfaces. These are level sets for some nice analytic functions. So, and these analytic functions come from vetrized line bundles and the theory of fines. Trice line bundles and the theory of fights. So I described, I mean, part of my talk is to describe what these functions are, but you look for rational points along finitely many level sets for some explicit analytic functions. So these, so what we need for our setup, we need to build a new theory of a dielectric metrized line model. A dialectic metrized line bundles and an associated height functions. So this h sub l is an example of something called a canonical height function associated to the line bundle. And those are quadratic functions on the Jacobian. Functions on the Jacobian. So each of these pieces match up. So this term here lines up with this function here. So this is a global height. It's a quadratic function. And this here, the local height of p is naturally described by a multimeter integral. So it's not accidental. It's not accidental that such functions show up. So that's what we do. What are some advantages? So why we do identify the new framework for something that already exists. There are a few advantages. advantages of this third method A over one and two and so I'll reiterate this once again these the functions that cut out the rational points are directly described by iterating the titles on the curve You don't have to work with these larger spaces or go through Hodge theoretic machinery. The main input is geometric data that has to do with the line funnel, things like the churn class of the line funnel. And particularly, it avoids the machinery of previous two methods. I'm going to say another big challenge, if you want to really use this powerful new technique, quadratic shape, you can apply it to your favorite class of cash that satisfy this hypothesis. One thing you need to be able to do ahead of time is know which, know what this finite set P is. What is this finite set P is? Know on which level sets you expect to see any rational points. So that's a computational challenge in implementing this method. So, okay, how do you get your hands on the set T? And previously, what people did, so in the first instances of quadratic jupiter, Instances of quadratic jeopardy, people just restricted themselves to curves where you could control the speed ahead of time. So you impose conditions on your curve x that force the rational points to lie on a single level set, the vanishing locus of this function. So the kind of condition that they impose is on the reduction of this prime. So for instance, Of this prime. So, for instance, if your curve x has potential good reduction at all places, this invariant t happens to be zero. More generally, The level sets where you look for rational points, this collection of values t has something to do with the bad reduction of this curve at different places. So you have natural functions that factor through the dual graph of the curve. So if your curve has potential good reduction at all nascents, the dual graph is a point and these functions and there's at least one component where this difference vanishes. This difference vanishes. So you end up having to look at the single-level set where the difference is zero. So, one thing that comes out of this new take on quadratic shippers, we can work more generally this is the work in progress from the SNIC, which doesn't tighten this up. Tiding this up. You can compute psi t more generally, and you end up having to understand certain piecewise polynomial functions on the reduction graph of the curve. So the key input for this, is where insight from tropical geometry comes in, is some comparison between different integration theories. Different integration theories, between integration on the Belkovich space and Belkovich-Kuhlmann integration and Orowetzki integration there. Now for iterated integrals, not just single integrals. The comparison for single integrals already appeared in KLCB, but the comparison between integrated integral integral integrations The comparison between integration theories for iterated integrals is the very recent by very cats in Barbett. So that you can use explicit comparison with these different integration theories to tease out this finite set of values. The hope is to expand the collection of curves where you can run this one addiction method and keep And key here is the certain harmonicity formula for the child. Yes? So if I have like a good, if I wanted to fix good plan, then I know that methods one and two give slightly different subsets of the rational, they cut out slightly different subsets of the parent points. So is your subset the same as one of the rationales? Ours is the same thing as what Jen and you don't get the rest of that. So what did you do? So one reason you might want to be able to work with clients that aren't affected by reduction is to get like maybe like better balanced. Right, right. So that's something that we're working on. One thing that was very helpful in these uniformity results was being able to work with primes of bad reduction for the curve. So the previous approach is assumed P is a good prime. For us, it makes no difference. The theory would set up words equally well for bad primes. But if you want to tease it out to get some kind of, you know, And now to get some kind of uniformity result, this is things that we just started thinking about the last few weeks. You need to be able to bound zeros of these integrator integrals on anuli. So maybe. Another complication in quadratic shipperty is you need conditions on the reduction type at all primes p. So it's So, it's not going to give uniformity results as good as the ones you see in regular Shevoti because, like, once you fix a prime T, you don't care about what the reduction type looks like at other primes. But here, how large the set T is, how many level sets you need to look at, depends on the reduction type at other primes. So, if you want to control how bad this gets, you might want to work with curves which have bad reduction over. Curves which have bound reduction only at a small set of times, but like modular curves do fit that framework. You can control where many places you have bound reduction. So maybe, with thinking about this, it's definitely one thing that we can do now we couldn't do before. Use bad practice. So that was actually next to my list of advantages I wasn't going to write down. I wasn't going to write down, but yeah, you can work with that primes p. One thing that I like about this method is that it puts padic heights on an equal fitting with real value heights. So in Podwood's talk, you're going to hear a lot about classical real-value heights and applications. But the various constructions of piardic heights in the literature, and they all look very different, and they look very different from the construction of real-value heights. This, I should say, constructions of Zarhin, Schneider, Colmes, Maser and Tape, Coleman and Gross, Nekoard. I mean, I don't know, I think we're building constructions of PRD kites, but they all look rather different. So one thing that our approach does is, I mean, embrace this general framework in Eric Law theory that you should not have a favorite place, you should treat all places equally, just like you should have a favorite child. You should treat all crimes out. I'll put them on an equal footing. So that's another thing that's nice about this new approach. So, okay. That's all I wanted to say for motivation, but maybe I should actually say what these questions are, where they come from. So, sorry, can I just ask? Yes. So, the total space of the line bundle that showed up in this Alexander. Is that gone now? You're back just on your photo? At the end of the day, At the end of the day, I mean, it's still there secretly hiding behind the scenes, but what they needed to parametrize, they needed to write down coordinates on the store space and pull back functions along a parametrization, write down how x embeds in this big space. And at the end of the day, to tease out explicit functions, they had to work with this larger space. Our functions also secretly come from the total space of the line bundle, but at the end of the day, when you restrict them to the curve, you know they come from these exposure. To the third, we know they come from these exposure levels. So you don't have to pass to this latter step. And it's in these latter two as opposed to the original stuff? Is there anything non-aged less? I mean, secretly, I mean, secretly, I mean, these functions are coming from non-abelian shepherds. This line bundle lets you probe a certain non-abelian piece of the fundamental group and a second non non-abelian quotient. The second non-abelian quotient, but that's like rather too big to work with. And you work with smaller quotients of the fundamental group that you construct out of that. But you need to go through some machinery. I mean, see where it comes from. So the goal of the second and third approaches was to sidestep all of this complicated heavy machinery and directly use the geometry of the line model. Thank you. So let me. So, let me tell you what these functions are, these so-called height functions. I describe a canonical height function on an ability variety. This will also show up in Ford Wood's talk. So, I think for all of this week we've been using line bundles to embed our varieties in projective space. But if you ask a number theorist, there are other things that line bundles are good for. Are other things that line bundles are good for, and the things that line bundles are good for is for producing height functions. So, if you have, say, an abelian variety over, say, over the rational numbers more generally, over a number field. And if you give yourself a line bundle in this package, you get something called, I mean, classically, this is like. This is like work due to the normal date. It goes back to the fifties. You get something called a canonical height associated to the height model. So this is a way to take a rational point on a Ruby variety and measure how complex it is. And this, I mean, I think certain people in the audience have wrote PhD thesis on how this can be quite difficult to compute. And how this can be quite difficult to compute. But today we want to focus on not the usual real-value height, but study a paik analog. So one thing that we do is construct canonical QP value heights. Replace the target R by QP, but for doing this, you need a light. And like the rib I think case, you need to make some additional choices. You need to pick something for the curvature form for the line bundle. Oh, so need. You need to give yourself a curvature form of the line bundle. This is an explicit cohomology class. It's very closely related to the Churn class of the line bundle. But this lives in global holomorphic differentials concerned with Gramp homology. So this is a certain refinement, if you want, of the germ class. So if you there's a cut product map from this tensor product to wedge 2. Product to wedge 2. The germ class left in the wedge 2, and we said you're picking a left under this product map. These exist for a VITs. But if you give yourself this additional geometric data, this curvature form, you can produce something called a canonical height. This. This is the curvature form associated. This is the curvature form associated to the line bundle. It's a certain cohomology class, saying where it lives for now. It lives in global holomorphic differentials tensored with each one belong of the ability writing. Okay, so it corresponds to splitting the Hodge filtration. Huh? Is this like a churn bay form type thing? Yeah, it's the left of the churn class. Yeah, it's a lift of the churn class. So the churn class of the line bundle is something that lives in wedge two of each under arm. Right? H2 of the Jacobian is wedge two of each under arm. This is the lift of this twin spencer product. It's an explicit cohomology class. You describe this using differential forms on the abelian righteous or back on the graph. You can build this height function, but what makes it canonical? But what makes it canonical? There are lots of height functions out there, and I think there'll be several that show up in Farwood's talk. But for abelian varieties, there's one that's preferred, the so-called canonical height function, because of the way it interacts with the group law of the curve. So what makes this height canonical is you can relate the height of 2 times the point back to the height of the original point. Back to the height of the original point. So the height scales, if you start out with, depending on the type of line model you start out with, so if you start out with a symmetric line model of devium lighting, so light model that's isomorphic to the pullback by minus 1, the height scales, the height of m times t is m squared times the height of p. If you have an unisymmetric line bundle, so m inverse is Is isomorphic to the pullback by minus one, then the height is linear. That's what makes this canonical. And in general, if you choose an arbitrary line bundle on an abelian IT, its square decomposes as a symmetric piece and an anti-symmetric piece, and the heights correspondingly add. So, this is the key property we're looking at. Property we're looking for for a height function. And the definition of this should not be very different from the definition of canonical heights, canonical real value heights. And the fact that this is a quadratic function is what's responsible for those products of single integrals that we saw before. So, what is this function? So, like I told you. So, like I told you, the total space of the line bundle doesn't completely disappear. So, these are functions that are pulled back from the total space of the line bundle. So, here I'm going to draw picture. So, that you work place by place. So, look at the original variety base change to give you, and say you want to evaluate the high. You want to evaluate the height at a point x, what you do is you at each place you choose a section of the line bundle, which you can do, say, even before this. Choose a section of the line bundle that you can choose any section you want that passes through some point above x. And to evaluate the height. To evaluate the height at the point on the base, you sum certain local height functions that are defined on the total space of a New Belium value. So these, HLDs, these are functions that are really functions on the total space of the line bundle, which they know is the zeros function. QP value functions. So there's one for each case, and you pick your favorite section about this point, say it doesn't have a zero or a point, and you can evaluate these local height functions at this point and some of them will have. The end result, based on how you package these together, it turns out to be independent. The joys of section you start with. And ultimately, the product formula, the independence? For real-valued heights, it is the product formula. For defining theatric heights, you have to choose an identical class character. So a homomorphism from the product Q plus, but it vanishes from Q plus. So if you scale. So, if you scale the height doesn't the fact that it is characterized, but like, yeah, I'm sweeping a lot of that under the right. Can I ask? So, your HL cam on the left one doesn't have a curvature form, and then on the right one it had a curvature form? It will, so it should good catch. But let me say, but what these local functions are and the local p is at p, you will see the curvature form. But it's the curvature form only gives. But is the curvature form only using the decomposition into local heights, or do you really need it to define the global height? Sorry, say that again? Are you using the curvature form? I use the curvature form to define the local thing. Right, but the global thing is then well-defined without the choice. No, it depends on the choice. It depends on the choice of the curvature board. In theory, you can start with one line part of if you have. You can write down different curvature forms for it and produce in theory different height functions. And we'll try and lose all of that. So, yeah, absolutely right. I should put these dependencies out here. So these local functions, like I said, you do use the total space of the line bundle hasn't completely gone away. And these local functions, they're not completely arbitrary. So at places that are depth, so the pressure Places that are different, so the time P is special for us. At places away from P, the VRI topology and the P-addic topology are kind of incompatible, right? So if you want these, so if P is different from P, you want these HLVs to be functions that are Q-valued inside QP. And in your head, you should be thinking they come from some intersection theory, something like a model. Some intersection theory, something like a model management. So, here are the matrix line bundles showing up. Line bundles QP usually come with some kind of integral structure that you can use to measure sizes of sections. So it's a model metric at almost all places. The place above T is where you get some interesting reactions. You get some interesting reaction, there is the curvature form shows up. So, if you want to describe, what we really want is to describe what these functions look like when you compose with a section. So I'll give you a formula for this composition. And if your curvature form, I told you it's an explicit homology class, and it lives. And it lives in omega 1 tensor each on the round. So there are differential forms, holomorphic differentials, forms of second kind that show up in this description. And the curvature form, the local height at P just integrates these forms that show up in the curvature. Except you should also correct for this section. And the section itself might have zeros of poles somewhere, so there's a certain correction form for the singularities of the section. You can find one explicitly in solving the Diemann drop problem. You know what kind of residues you want this differential form to have, and you know that the way you set it up, the sum of residues will be zero. Us will be 0. So the local height at P, at least when you compose the section, is given, is defined to be a certain iterative. And the factor is PLI comes only from contribution at P, right? Yeah, this is, yeah, this is local. The curvature form is only used at P? Yeah, it's a splitting of the construction at P. And away from P, it's more or less. Away from fee, it's more of a term of the class. Yeah, it's the same thing that shows up in with an algorithm type. There's essentially only one if you demand that for symmetric line bundles you get this kind of scaling behavior. So describe what these functions look like when you compose with a section. Cases away from P, on the fibers, the fibers are giang, it's just a copy of K plus. copy of k cross, places away from p, these functions behave like evaluation on fibers, and at p, it behaves like a logarithm. We have a logger alpha. So this sort of essentially knowing what it is on the section pins down what the function is of the entire space. So this is all I'm going to say for a definition thing. And what you have here is you use have here is we use a Bologotski diagram to construct this, but on our application to quadratic tremendous you choose you need the right kind of line bundle. You want a line bundle that's non-zero in a non-severity. So this is so that you actually write down interesting functions. Interesting functions that vanish on the rationale. You don't want to write down the zero function, so that's guaranteed by this. So your line bundle pulls back to the trivial bundle, then the set of rational points, it's contained in the union. So the functions that you use is the difference of the global height at each, so the sum over all places. Sum over all places minus the local contribution at p. This, okay, this is not quite a function on a JFTP, but you compose there's a canonical section one, right? The line model pulls back in the trivial bundle. You can pick your favorite non-vanishing section. So this is an analytic function on x of qp. On x of qp, and by its very nature, the fact that this is the quadratic function means it can be described in terms of products of single integrals, and which by definition on the curve is given by this sort of iterative integral. And one of the results, one of the things that we showed in the paper is for rational points, the heights away from P. The heights away from P factored through the dual graph. The values that you need are controlled by where the point specializes in the dual graph would be. So when you write integral here, this is like a path independent? This is the path independent Polaroidsky integral. But the other one is path independent. The other one is path-independent. That's the one you can actually compute with. So this is morally where these functions come from. But one nice thing about this is these functions, if you're able to do one-what skin titles, are actually quite computable. And the surprising thing for us is that we could use That we could use these local contributions at P, these p-iadic integrals, to say something about the contributions away from P. So clearly, if you want to compute these p-adic heights, you don't need intersection clearly. All you need to be able to do is do p-adic integrals. So I like to say all you need is one curvature form to do them all. Scurvature form controls the contributions at all places. That was actually in the original draft of the Tolkien book. They changed the book. So you can use these p-iadic injectors to cook up these local heights away from peace. So you need to produce a Away from P. So you need to produce something that looks like a valuation that places away from P. So what we show is if you define this new function, what we call a Volowatsky valuation, so defining these integrals along the way somewhere you have to Along the way, somewhere you have to integrate something that looks like a DZ over C. So you need to make a choice of the piadic longer come. If you don't want to pick a specific number, you work with a universal branch and just let that vary as a parameter. And these integrals look like some kind of quadratic function in the choice of dot p. But then you can study the dependence on this value. So you can look at the derivative of Of this canonical height with respect to log b. So pick up the coefficient of the linear term. And turns out that this is actually a valuation. It's a q valued. So this actually factors through q and actually factors through the reduction graph. And it's the same thing with a P is And the no-fuel contribution to the La Ronti type. So, this is a pi-artic analytic way to compute something that shows up in real value heights. So, all you really need to be able to do is compute these p-adic integrals. Say all in quotes. I mean, these Vologotsky entitles are rather mysterious. The one, at the beginning of the talk, I said, like, you know, write down power series expansions of differentials integrate term by term. That kind of works well in residue disk, but it's hard to figure out how what these integrals look. out how what these integrals look like locally. So okay, this might seem like a way to get your hands on these contributions away from P, but how do you actually compute this thing? This is still rather mysterious. So I want to end with this. So this is where tropical geometry comes in. So these functions are not random, they satisfy Satisfied a nice quantum formula. So, and that's something that's actually useful for computations. So, and work in progress. So, if you look at so pick pick the kind of land model that shows up in Guernadi Chi. Shows up in quantity of t. Then this Woliwatski valuation, this thing that you get by differentiating the local height of p. This is a function that factors through the dual graph and you have an explicit formula for Have an explicit formula for its Laplacian, graph-theoretic Laplacian that can be described from this curvature. So now I'm viewing this local height as a function of the dual graph. The partial of this function, this is something that's This is something that can be read off actually from the churn class of the line bundle. So you should, there is a version of this that already shows up in Gugler and Kunemil's work when they were interested in studying or computing. They don't take heights and well I don't quite I don't fully understand all All the forms and currents and so on that show up in that word. But I can describe for you what the Laplacian of this valuation is rather explicitly from the term class. What was leather in front of term? Huh? What letter on the right one side? Oh, the evaluation evaluated at the section one. On the right side. So, this is a map that I'm about to define that takes us input the churn class. It's a function, this whole thing, this is going to be a function on the vertices of the row graph. And let me tell you what it does. So, you're going to apply this to the churn class of the line bundle product, and you work, generally, you take and define this as a function on batch 2 of each one of the. Wedge 2 of each one of the round two functions. Qp value function of v. So if you take a wedge of two forms, okay, I'll describe this when x has totally degenerate deduction, but as additional correction terms. So this here is something that involves, so if you want to evaluate this at the vertex p. At the vertex V of your dual graph, what you need is the residues of these differential forms along amnuli. So vertex in the dual graph corresponds to, let's say, example here, vertex in the dual graph corresponds to a component and its and its the neighboring vertices are connected by anguli in So, for each edge in the dual graph, you get an angulus, and you can expand these differential forms in the Laurent series, the parameter for the angulus, and you get these residues. So, this here sees the residue of these differential forms, and also another co-cycle on the dual graph. A co-cycle on the dual graph, which has to do with the difference. This is the difference in the volume of skin factor for the two sides of the anubis. This is a harmonic co-chain of the duo graph. You also have the residue co-chain. is locally expanding expand and I mean take the coefficient of E Z over C and you take the difference you need something that's anti-symmetric it's very sum um and okay so this this is a formula for so this is what you get when you evaluate this Get when you evaluate this homomorphism on a wedge of two forms, but in general, you're going to apply this to the term class of the line bundle. If instead of the one section, you choose some other section of I upper starl, there's a direction corresponding to the divisor of the section on the geograph and so on. But this function I might look as complicated as computing Bolivotski entangles, but actually you can get away with far less. You don't need Bolivar's game titles on your noise. So, could you just say again? What exactly is the relationship between the churn? I mean, that's just like the regular old churn class. Chern class of the line bundle. So, the churn, where does this live? The churn class of the line bundle lives in H2 deram of the code here. So, that's badge 2 of H1 deram of the curve. So, it's a sum of badges of differential forms on the curve. And this This map here, this is a map defined more generally on all of each two of H1 and R. So, to evaluate the right-hand side, you ask what this does to the chunk class. This is extended, maybe, from the pledges. So, yeah, you have two different ways of producing harmonic co-chains in the dual graph. One is by taking differences of Wolvertzkin titles on the two sides of an annualist, and the other is by evaluating these densities. Manualism and the others by evaluating these residues. And the Daplacian for these Bolivotsk evaluations have to do with that, do with both of these harmonic co-chains, but put together in this nice way. And this is actually something that you can compute. It's in harmonic co-chain. Meaning with that coefficients are like harmonic functions. Yeah, on the global graph. Qp value harmonic functions on the positive graph. QP value will have lot of functions on the function as well. Oh, sorry, that's okay. On each edge, you look at this. This difference on the two sides. And yeah, you can recover the difference of, I mean, if you write down the chunk class in the correct way, you can actually extract. You don't need to evaluate these co-chains in arbitrary differential forms. Chains and arbitrary differential forms. You only need them for things that live in certain subcases, and you can actually compute them by just doing cop product computations. I mean, okay, sorry, I said a lot of details, but the upshot is this is something that's actually computable. It's not as hard as throwing whatever that's going to buttons. I definitely deal with that, so I'll stop there. Are there any further questions? So, with the definition of the quadratic function that comes out, a set containing the rational points, you had the canonical theater height. But how is that defined on a non-rational point? Okay, so I didn't tell you at all how to construct the canonical theodic, right? So, you first, like you said, all you need is to Is that all you need is to know the local contribution at P. You can make. Sorry, but was it the global or the local height that we can map for the quadratic quality function? The global height, it's defined on the rational points of the Jacobian, but you can extend it. You have a nice basis, it's a quadratic function on the rational points, and you have a nice basis for quadratic, qp-vat and quadratic functions on the rational points given by the single integers. And those make sense on all of you. So I definitely get that. So I definitely get that. Thanks for asking. I think that's a big question. Yes. So La function of a rationally valued function is rational. But I see that the right-hand side here seems to be a p-addic value. Both of these are QP valued functions. So this is a function. You can compute up there, you use certain factors for Q. Oh, um I could catch. So I was trying to hide this error class character that shows up in these formulas. But there's a constant, PRD constant, that shows up. So if one was interested in studying rational points on things like symmetric powers of curves and stuff like that, is there any interaction between these ideas? Because there's some cold. Because there are some common integration ideas. Wasn't this like Jen Park's? Jen Park's thesis, and it involved solving, looking for common zeros of multivariate p-adic power series. And if I remember correctly, there was some technical condition, but one still doesn't know if it's true. So yeah, so I'm sure Lean Dad. Yeah, so I I'm I'm solely in the realm of single single univated power CPU. But like is there any role of these more complicated uh integration theories in those kinds of questions? Sorry, that's probably that's probably kind of like quadratic shabberty for like for quadratic points in the curve. I haven't thought about this, but maybe, I don't know. I think solving for common zeros of many, maybe power series scares me a bit, but maybe it can be done. But maybe, maybe can be done. I don't know. If there are no further questions, let's thank Patmegen.