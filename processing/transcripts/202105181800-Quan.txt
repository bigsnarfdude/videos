So, hopefully, we're all so we're all on the same page. So, you know, I sort of threw complex and a parenthetical because to do this, it would be sort of helpful to think first about asymptotically real hyperbolic manifolds. So, this is a class of non-compact Riemannian manifolds with compact. You know, compact boundary and embedded so that we can make some choice of a boundary defining function. So the boundary is going to be cut out as the zero locus of some function. And say in a neighborhood of the boundary, we impose this requirement that the metric is of the form one over rho squared of some other complete Riemannian metric. So it sort of gives you a nice cheat to say that the, you know, To say that the boundary is somehow far away because you've divided by your vanishing locus of it. Just this condition says that it's a so-called conformally compact manifold. And imposing this extra condition for the differential of the defining function requires that near infinity, the metric is negatively curved. Negatively curved. So, one way that you can think about this sort of structure is that having fixed this metric on the boundary, it induces a conformal class of metrics on the boundary. Excuse me, just a second. So, I'm going to move the water dish of the dog. Sorry. Sorry. Hopefully, it's not too distracting, but please let me know. Right, so we have a conformal class of Riemannian metrics on the boundary, so you can think. Of Riemannian metrics on the boundary, so you can think of it as this sort of compact part, you know, just restrict it to your boundary. And the kind of heuristic that's helpful to keep in mind is that this Riemannian geometry in the interior is inducing some conformal boundary geometry. So it's helpful to just keep in mind something that, you know, near its boundary looks like real hyperbolic space. And I'm allowing myself to maybe sort of mess with the metric in the interior as long as it's sort of uniformly. Sort of uniformly constant, negatively curved at infinity. So, some motivation for this coming from physics. You know, going back to this heuristic of relating the interior and boundary geometry is the so-called anti-de Sitter conformal field theory correspondence, which goes back, I believe, at least to Maldo Setta and has been developed by many, many people since then. And the idea is that sort of And the idea is that sort of there's something like a gravity theory in the interior, and this should be related to a conformal string theory on the boundary. What's really wonderful about physics, though, is that it can give you a lot of really wonderful mathematical conjectures that you can try and prove. So just kind of a sampler of some of the problems in geometric analysis that have come out of this include trying to study either Einstein metrics or minimal surfaces. Once you fix some sort of prescribed boundary geometry, Some sort of prescribed boundary geometry. Questions related to the renormalized volume of the interior. So, you know, the volume is non-compact, but physicists love to try and extract finite quantities out of infinite things. Questions related to sort of scattering and inverse scattering. And the very vague idea is that this sort of boundary manifold is supposed to support some kind of conformal field theory, where the partition function of this field theory, assuming that This field theory, assuming that we're in some region of space where we're under the vacuum Einstein equations, the partition function is given by summing over all the different representatives of this fixed conformal class of some exponential of the Einstein-Hilbert action. So, this is, I think, the extent to the physics. And let's get back to the geometry now. So, one kind of One kind of nice geometric picture, which is going to make an appearance later in a complexified version, is kind of a different way of obtaining hyperbolic space from a compactification of Minkowski space. So the idea is you can sort of start with Minkowski space with its Lorentzian metric and choose some radial compactification using this defining function, at which point restricting the original Lorentzian metric to these different components of Minkowski. To these different components of Minkowski space in this radial compactification, sort of naturally give you either hyperbolic space on these sort of spherical caps or a copy of de Sitter space on this equatorial belt. And so the idea is that, you know, in this geometric model, there's a kind of a geometric duality between hyperbolic space and desider space in this way, you know, and sort of with the light cone in the interior. So, you know, this is. So, you know, this is going to appear again a bit. So, now trying to talk about asymptotically complex hyperbolic geometry, let's sort of try and complexify the picture we had originally had. So, you know, what should it mean to be asymptotically complex hyperbolic? You know, if we want to think about just what should be the complex Poincaré metric, this is given by the Bergman metric. So, you know, on the complex disk, we're now of complex dimension two. Dimension two and the sort of unique metric of constant complex curvature minus one has sort of this form. So one thing that we start to see already is that there are kind of different speeds at which our metric can blow up at infinity. You know, depending on whether you have some tangential velocity that you're measuring only in some of the vectors, in some of the directions versus others, you'll have sort of different rates of blow-up. Have sort of different rates of blow-up at your boundary metric. And so, you know, we can sort of try and think of what should be the geometric structure that can generalize in that sense. In the case of the complex two-disk, its boundary is going to be the sphere with its round metric. And so in this case, you know, sort of this term in the metric, we can write it as something like dr squared plus theta squared. So dr was the sort of direction, you know. Which is measuring tangential length normal to our boundary. And we have now sort of something extra, this one-form theta, which turns out to be a contact one-form. So let's see what this looks like on the round three sphere. So S3, you know, it has this really nice structure where it participates in this Hoff vibration. There's a map from S3 down to S2, and the five. S3 down to S2, and the fibers of this map are all circles. So, this one-form theta that was showing up in our metric, it turns out to measure the lengths of tangent vectors, which are sort of tangent to those S1 directions. So, there's sort of a few different pictures here that you can think about it, which is, you know, this one-form theta on this three-manifold, its kernel gives you a collection of two planes, and then Two planes, and then you know, normal to those two planes are these S1 fibers. So, you know, we had sort of two different tangential directions which were diverging faster at our boundary. There's sort of also an issue of smoothness, which is addressed if you replace your defining function with its square root. So, I'm going to call that rho as the square root of r. And when you make that coordinate change, now only this z theta direction, which is tangent. Z theta direction, which is tangent to these circle fibers, is blowing up at this kind of fastest speed. So we'll take that to be our sort of general model for what an asymptotically complex hyperbolic manifold should be. So again, you know, you say that in some neighborhood of the boundary, which is cut out by this fixed function rho, your metric has sort of this form, where again, there's something that kind of looks like the asymptotically hyperbolic metric, with the exception of tangent vectors. Exception of tangent vectors in the direction of this one form theta, and I want those to you know sort of diverge at a greater speed. This theta is a contact one form on the boundary, so it satisfies this sort of non-integrability condition, which says that just starting with this one form, you can build a volume form on that boundary manifold. Once I fix this data, I'm completely free to make some choices. Completely free to make some choice of an almost complex structure. So, you know, on the kernel of that one form, it should act something like multiplication by I. And when I hook in d theta, which is going to be a symplectic form on the kernel of that one form, I now have a smoothly varying family of positive definite bilinear forms. So, you know, sort of this gives us something like almost a metric. Almost a metric, except for the one-form direction. And this is sort of the form of our metric in this neighborhood of the boundary. So there's a bit more structure on the boundary, but it's still something like a conformal class of these structures. And this is what we'll call a conformal pseudo-CR contact manifold, which is a bit of a mouthful. And these manifolds, I'll refer to them as ACH again, just to save. Refer to them as ACH, again, just to save syllables. An important additional hypothesis, which I'll additionally, I'll occasionally impose, is this condition used by Guillarmoux and Sabareto, and building off of a definition of Guillarmoux in the real hyperbolic setting, which is that we'll say such an ACH metric is even if the dual metric from our Riemannian metric, which is not. metric which is not normal to the boundary has an even Taylor expansion in the defining function rho. So you know you can say that this metric is even if the sort of metric which it induces on the boundary has an even Taylor expansion in your defining function. So I'll stop for a second and sort of say are there any questions about this kind of geometric setup before I move on? I know that this problem I know that this probably is a bit dense for people that are new to it. Okay. Yeah, so if there aren't any questions, I'll just maybe make a brief mention, which is in some sense, this is kind of a nice generalization of asymptotically complex hyperbolic, because, for example, if you were to start with just complex hyperbolic space and take some nice quotient of a discrete subgroup of its isometry group, say. Subgroup of its isometry group, say, you know, such that the quotient doesn't have any cusps but is non-compact, it will have a metric of this form. You know, if you start deforming it in the interior, that'll still be the case. So it's sort of good for analytic purposes. So let's talk about now some of the tools that we're going to use to prove things about these spaces. And first, I'll just sort of have a super quick crash course, which on pseudo-differential operators. This is probably going to be familiar to a lot of you. Be familiar to a lot of you, but just to you know get some of our notation fixed. Um, you know, when I refer to something as kind of micro-local, the general idea is you know, it's sort of local in phase space, which is going to be our cotangent bundle of our underlying manifold. And, you know, we're sort of interested in pseudo-differential operators, which locally look like quantizations of certain functions on the potangent bundle, where these functions that I'll refer to. These functions that I'll refer to as symbols, you know, you want to think of them as being asymptotically homogeneous of degree L, which is going to be sort of the order of the operator. And the sort of idea is that analytic properties of these operators will be related to the Hamiltonian dynamics of its principal symbol, which will be some function actually on the cotangent bundle by the Hamiltonian flow of the symbol, right? So I have some operator, I'll have a way of turning it into a function. I'll have a way of turning it into a function on the cotangent bundle. And then I can look at the Hamilton vector field of that function, and the dynamics of this vector field will tell me something about this operator. So just, you know, sort of for an example, if we have an Lth order differential operator with some representation in a choice of local coordinates, its symbol will have this form where I just take the highest order derivatives and I replace them with fiber coordinates of Fiber coordinates of the cotangent bundle. So this differential operator looks like something like a fiber polynomial smoothly varying in the base. So, you know, just really briefly. So, you know, one very basic property of this symbol function is is it, you know, vanishing or is it non-vanishing everywhere? Is it non-vanishing only on the zero section? So, you know, we'll say that an operator is elliptic if its symbol is. An operator is elliptic if its symbol is non-vanishing except possibly at the zero section of the cotangent bundle. One thing that's sort of nice about this condition is that if you have an operator whose symbol is real valued, you know, being elliptic tells me immediately that my dual operator was elliptic because the symbol of the dual operator will be the complex conjugate. So I'll sort of get ellipticity for free. So just being elliptic will tell me that I have an estimate of this type. An estimate of this type for some choice of n and for every sort of Sobolev order s. You know, I lose l derivatives, how you can think of it. And then similarly, its dual operator being elliptic immediately gives me sort of a dual estimate. And these two combined are sufficient to conclude that my operator P was Fredholm. At least, you know, provided that sort of these Sobolev spaces are dual in some appropriate sense. And we'll see a version of. And we'll see a version of those pairs of estimates later when we're talking about a more specific operator. And so now let's really talk about the dynamics, right? So we have propagation phenomena that we can consider, right? What if your operator wasn't elliptic? What this tells you is that if you're non-elliptic, then the symbol has to vanish somewhere outside of the zero section. So I'll say that the elliptic set is going to be everywhere the symbol was non-vanishing. Everywhere the symbol was non-vanishing, and on its complement called the characteristic set, assuming sort of this mild condition that the symbol is non-radial, i.e. where it vanishes, the Hamilton vector field of the symbol is linearly independent with this sort of radial vector field, which is the infinitesimal generator of dilations on the fibers. Assuming this condition, I can prove kind of a nice estimate which depends. A nice estimate which depends on a dynamical statement. And so the idea is that sort of if I'm trying to prove some estimate which I have, you know, micro-localized by some operator A, if I can sort of connect the region where the symbol of A is supported by the bi-characteristic flow of my symbol to some region which I'm micro-localizing by B, while sort of remaining in some broader region controlled by G. Controlled by G, I can kind of bound the operator norm in terms of, you know, the norms of these other operators. So the actual sort of explicit statement is the following. So I'll say sort of, you know, my I have this statement of my operator A being backward controlled. You know, so in other words, somewhere where I'm kind of interested in A, if I can connect the wavefront side of A by some By some integral curve of the Hamilton vector field, at least for some finite time, then I have sort of the following estimate. So you should think of this as being something like the elliptic estimate. You know, this somehow, if I didn't have this B term, this would almost be the elliptic estimate on the nose, kind of micro-localized by the operator G. And in this case, I have something which is almost as good, which is I have this. Is I have this B that's sort of compensating in this way. One thing that's really good about this condition is that it's sort of, there's a kind of time symmetry for the flow, which is that I have almost an identical estimate if I replace sort of being backwards controlled, where some point which I'm localizing by A, I flow backwards along the flow. Similarly, if I were to place Similarly, if I were to place t with minus t, the same estimate will hold. This isn't the case if I change my operator slightly. So now we can look at sort of slightly more interesting propagation phenomena when I have what's called complex absorption. So in this case, all I've done is I've changed my operator. I'm still trying to sort of get a similar estimate, but I'm adding on this what's called a complex absorbing potential Q. Absorbing potential Q. So now, you know, Q has sort of a definite sign, and this estimate is really only going to hold sort of one direction in time. So in this case, if Q is positive, then an operator of this form will still have the propagation estimate if A is backwards controlled by B. On the other hand, if I were to change the sine of Q, then I need it to be forward controlled. So I just replace all my T's with minus T's. With minus t's. Okay, so finally, you know, sort of what if you were radial? I was kind of assuming that in the background all at once. That's sort of an issue because, you know, propagation of singularities doesn't help you very much. You're sort of remaining in one fiber if you are, you know, parallel to the dilation, the generator for the dilation action on a fiber. But what's sort of nice is that when you have such a radial When you have such a radial point for the flow of your symbol, your dynamics are now sort of more closely to sort of a source or a sink. And you have, again, a slightly weaker version of your propagation statement. In this case, there's now an additional hypothesis you have to add, which is sort of you'll have an estimate as long as you are looking. As long as you are looking at some Sobolev order, which is above or below a sort of threshold. So the idea is, you know, sort of, you know, if I'm remaining in some dilation orbit, my flow will act like sort of a source or a sink. And the sort of source or sink points, I'll have an estimate of the type where I can sort of propagate an estimate into this source or sink if I'm kind of above my threshold and I'm can propagate sort of. Can propagate sort of out of it if I'm below this threshold. Sorry, I have this reversed. That's a bit of a typo. Sorry about that. So the idea is that you can propagate regularity out of this source or sink if you sort of have, if you're above the threshold, and you can propagate regularity into the source or sink if you're below the threshold. And the threshold parameter, it will depend on a kind of subject. It will depend on a kind of sub-principal term. So, you know, if our operator P was of order R, I'm now interested in the behavior of this sort of R minus one term. Okay, and so finally, you know, stepping away briefly from pseudo-differential operators, we'll have sort of briefly Fourier integral operators making kind of a brief appearance to talk about constructing the wave trace, which is something else in the title. So, in this case, sort of the ideas. So, in this case, sort of the idea is: if we're interested in constructing the fundamental solution to the wave equation, we can sort of we, you know, sort of by spectral theory, hope that it'll have something like this form if we had discrete spectrum. But in general, you know, we want to think of the solution to the wave equation as some integral operator, and we'll hope to construct the Schwartz kernel for this solution operator. For this solution operator through a paramatrix, right? So we'll construct an approximate solution operator. Rather than solving the wave equation on the nose, I'm willing to accept some error term provided that I can sort of remove that error later. So the idea, you know, very roughly is that we'll start with some kind of approximate guess for what the wave pair, what the wave equation solution propagator should be. And I'm going to sort of iteratively And I'm going to sort of iteratively improve that guess based on the form of the Euclidean wave equation. And so, you know, if you construct this iteratively, I end up getting something which is going to be smooth except along the light cone, i.e. the time t flow out of the geodesic flow. So that'll be the symbol of this operator. And so the sort of takeaway from this is you should think of this as giving you a reasonable approximation. A reasonable approximation to the true wave propagator, at least for very small time. What I'm going to end up getting is that, you know, just looking at sort of the form of this integral operator, this has a slightly different expression than our pseudo-differential operators, right? Those complex exponentials had a very particular form. So in this case, you know, this will no longer be a pseudo-differential operator, but it'll be a Fourier integral operator because I'm allowing a slightly more general form. Allowing a slightly more general form of my phase function for this kind of local model for the algebra of operators that I'm constructing the parametrix in. Okay, so let's actually get into what we've proven. So I'll just sort of quickly review kind of what's known about asymptotically complex hyperbolic manifolds. So remember again, we had this sort of collection of our data, right? We had our manifold, its metric. Our manifold, its metric, and this sort of conformal class of a one-form and an almost complex structure associated to it. So, manifolds in this level of generality were first studied by Epstein, Mendoza, and Melrose, many of whom are at this conference. And what they were able to prove, assuming this kind of extra condition, which was pointed out by Guillermoun and Sabareto later, that the metric is even, is that That the metric is even is that the Laplacian of these manifolds has sort of this spectrum. So it has some absolutely continuous spectrum which starts at n plus 1 squared over fourth, you know, kind of similar to real hyperbolic space, where our manifold is of real dimension 2n plus 2, just to make that explicit. And it has possibly some finite collection of discrete spectrum between zero and the bottom of the continuum. Zero and the bottom of the continuous spectrum. And so, you know, they were able to prove these facts about the spectrum by studying the resolvent, right? The inverse of this operator, where they proved that it exists and it's a bounded operator for certain left half, right, half plane of the complex plane and showed that it admits a meromorphic continuation to the whole complex plane. And the way that they proved this was by constructing a sort of particular algebra of Particular algebra of pseudo-differential operators, which they called the theta calculus, that had been kind of adapted to the geometry of our non-compact manifold. And what they're able to show is that the resolvent exists and is an element of this algebra of operators and is the inverse to the Laplacian with this spectral parameter in that algebra. And you get a whole host of other results for free knowing that. One issue with this is that it doesn't tell you much more about sort of the structure of the poles for this operator, right? So we still don't know much about the discrete spectrum, and we're particularly interested in resonances of this operator. So not the poles lambda squared, but how are the values lambda, which are poles of this operator, distributed in the whole complex plane? So, you know, that was for me at least one motivation for trying to think about some of this. So, you know, kind of a different approach to this proof, which is very strongly inspired by work of Vashi in the real hyperbolic setting, uses this kind of geometric duality that I'd mentioned previously. So the idea is, you know, sort of take your initial eigenvalue equation, at least on real hyperbolic space, and try and extend it into the desider region along the row equation. Region along the row equals zero boundary, right? So that's given here. And so in this case, you know, at least on an asymptotically complex hyperbolic manifold, which is even, you should have a way of trying to make this extension in a smooth fashion. So, you know, in this case, right, take your initial sort of eigenvalue equation, make some choice of boundary defining function, and conjugate by. function and conjugate by an appropriate power of the defining function, you'll end up getting to factor out a copy of R. You'll now have some new operator which depends on lambda and has sort of this leading structure. So it looks something like rho times del rho squared plus sort of something like a Laplacian of the boundary metric, at least for a fixed representative of it. So in this case, you know, the sort of So, in this case, the sort of conjugated extended operator now has this principal symbol. So, this is sort of where this is really where Vashi's method, I think, gets interesting. The idea is that, you know, remember that our boundary defining function told you that the boundary was given by, you know, rho equals zero here. If you extend into the desider region, you're now in a region where You're now in a region where your defining function is allowed to be negative. And so, as a bilinear form, this changes signature. So, the idea is that because rho is showing up here as a coefficient at the level of the principal symbol, when rho is positive, this is an elliptic symbol. And when it becomes negative, it now has signature m minus 2, 2, where m was the real dimension. The real dimension. So the idea is that in the sort of extended region, the conjugated operator, after you factor off this extra copy of rho, it's ultra-hyperbolic. You know, it looks something like sort of a wave equation with two time variables because you have minus there in both cases. And because it now is sort of an operator of a different form, you can try and exploit the structure of the dynamics of its Hamilton flow to be able to prove. Flow to be able to prove something about the original operator. So I'll state the theorem quickly and then sort of try and give a sketch of how we proved it based on this conjugation idea. So, you know, this sort of first part is essentially the result of Epstein, Mendoza, and Melrose. I mean, it's slightly less precise because it doesn't tell you anything about the mapping properties of the resolvent, but you know, it does tell you that. Resolvent. But it does tell you that the resolvent exists and it acts similarly to how you'd expect as the inverse of your sort of Laplacian. Remember again that you need to assume that it has an even metric, but what we can show is that starting from some initial region in the complex plane, it admits a meromorphic extension to the whole complex plane with finite order poles. The sort of benefit, and this is where we start to see some new results, is that you have this slight Is that you have this slightly sharper mapping statement, which tells you precisely what the decay of the resolvent is in terms of the powers of the defining function. And if you consider data which is supported strictly in the interior, you get actually a gain of sort of two orders. It's not just minus one, but minus two. And finally, we have a non-trapping statement. So if you assume that you're, you know, asymptote. Assume that your asymptotically complex hyperbolic metric is non-trapping, i.e., in the interior, sort of any geodesic arc extends to the boundary. So you have no closed geodesics in the interior. Then you have an estimate which is actually uniform in some strip containing the real axis. In this case, you can sort of prove a statement like this for fixed values of lambda. And here you have. Fixed values of lambda, and here you have an estimate which is actually going to hold for all lambda in some strip. In this case, the sort of width of the strip is going to depend on the initial domain that you fixed to sort of start your Meromorphic extension. And I can say more about how you get this constant if there are sort of any questions, but it's not very complicated. So what are some things you can do with this non-trapping estimate? With this non-trapping estimate, one thing that's really nice about it is it immediately tells you about the long-time decay of waves for the wave equation. So, if I look at the wave equation for my ACH manifold, I can take its Fourier transform in the time parameter and get something like the eigenvalue equation. So, what that tells me is I can write my solution to the wave equation in terms of this integral transform of the resolvent acting on my inhomogeneous term. My inhomogeneous term. And because of my non-trapping estimate, if my manifold has this, satisfies this non-trapping condition, I can take that sort of initial value where I've computed this inverse Fourier transform, and I can shift the contour down to some fixed constant imaginary part of lambda equal to c line. And what I get is that this becomes. And what I get is that this becomes, this starts to give me some exponential decay, you know, modulo any poles that might have occurred when I shifted that contour. So, what this tells me is that as a function of t, my solution to the wave equation says up to some residues, it's exponentially decaying, given this sort of mount-trapping estimate. Sort of in future work, one thing I'd like to try and do is establish also a sort of vial asymptotic for these. Symptotic for these residues of the, you know, for these, for these poles of the Resolvin, trying to build off of work of Dachev and Dyatlov, which, you know, I think would be sort of interesting because, you know, remember again that this is in a setting where our manifold is non-compact. So there's comparatively much less known about these poles of the resolvent rather than, say, eigenvalues. And so to sort of just give a very brief sketch of the idea of the proof. Just give a very brief sketch of the idea of the proof. You know, it's much as like occurred in the real hyperbolic setting using the sort of conjugation and extension trick. So we take our original operator and we're going to look at it instead the sort of extended operator in the region where I've allowed my defining function to be negative. I want to try and prove Fredholm estimates for the extended operator, look at the inverse of that, and then restrict. The inverse of that and then restrict the inverse back to the original region and sort of undo my conjugation. You can prove Fredholm estimates for the extended operator just by sort of combining different micro-local estimates, which you can, you know, which I've alluded to already. So, just based on the sort of how the symbol of the extended operator propagates in the sort of extended region. There's sort of a slight There's sort of a slight subtlety, which is that you need to use actually variable-order Sobolev spaces to prove these estimates. So it's not enough to sort of have a fixed Sobolev order. But once you do that, you have your Fedholm estimates for P, you look at its inverse, and then you sort of undo your conjugation. So I'll come back to this, but I want to try and give you a sketch of the picture, a picture which kind of gives you a sketch of the proof for this. This, you know, for the dynamics. So, in this case, you know, what you should think of is that this coordinate is our defining function. You know, so this line is where the initial boundary of our manifold was. And then everything here is the kind of extended region where we've allowed the defining function to be negative. The sort of extended operator, it has the structure where it's the flow of its symbol. The flow of its symbol has the structure of a source and a sink along the conormal bundle of the boundary. So, you know, this direction on our picture is going to be the defining function rho. And you should think of this as being like c over one plus Japanese bracket of c, where c was the dual coordinate to rho. So, you know, the To rho. So, you know, this is sort of you should think of as taking place at fiber infinity, you know, where one of the fiber coordinates was strictly positive and one was strictly negative. And so the idea is that the characteristic set of our extended operator in this extended region, it's connected. So you have bi-characteristic trajectories which go from the source to the sink. At the source, we sort of fix our We sort of fix our variable orders, you know, Sobolev order to be very, very high so that we can have the sort of radial propagation estimate and propagate our high regularity out of the source into regions where we may not have as much regularity. At the sink, we allow our Sobolev order to have reduced such that it's below the threshold and we can kind of propagate regularity into the sink. Into the sink. At some kind of fixed negative distance in the defining function ρ, we fix our complex absorbing potential to have some definite sign. So we have something like elliptic estimates for trajectories that are emanating from it. And we can sort of combine all of these, you know, on different kinds of micro-local patches of our phase space. What's nice about this is that you have sort of a very similar picture for the Sort of a very similar picture for the dual operator, which is, you know, the dual operator, its trajectories still flow in the same direction, but the sign of your potential has switched. And so now you're now propagating regularity out of the sink backwards in time and into the source backwards in time. So, you know, in this way, things sort of work out really nicely for you. But this also kind of hints at why you needed to allow your Sobolev order to vary. Sobolev order to vary, which is, you know, I had some fixed threshold for my Sobolev order where certain estimates would have applied at the source of the sink. And I needed to be above the threshold at, you know, one value and I needed to be below the threshold the other. So if I'm connected by a bi-characteristic, I better allow that Sogelov order to vary. Okay. So, you know, that's sort of the very rough idea for how you prove an estimate of the type I was just describing. Of the type I was just describing. So, you know, what can we say about the wave trace and how do we say it? In this case, a sort of nice takeaway: we saw already that I could relate solutions of the wave equation by some integral transform of the resolvent. So we should think about what the structure of the resolvent can tell us about the wave kernel. In this case, Epstein, Mendoza, and Melrose, again, they constructed the resolvent. The resolvent as an element of this special pseudo-differential algebra. In other words, it was, you know, its Schwarzkernel was some distribution on a slightly modified version of the product. They sort of took the initial product and they blew up the corner that arises in that product. So the idea is that, you know, X was a manifold with boundary. So now if you take its product with itself, there's going to be a corner. And they, you know, constructed a particular. You know, constructed a particular blow-up of that corner, which sort of played very nicely with the boundary, uh, the geometry infinity. And so, our sort of idea is going to be: well, okay, if the resolvent was, you know, had Schwartz kernel on this blown up product, maybe the wave kernel should have Schwartz kernel, you know, as some distribution on that modified product. In this case, the way that Epsom, Windows, and Melrose did their And Melrose did their theta blow-up was a modification of the sort of usual homogeneous blow-up of a submanifold inside of an ambient manifold. So in that case, typically, I have some embedded submanifold inside of a larger manifold, and I remove that embedded sub-manifold and I replace it with its inward-pointing spherical normal bundle. We're almost going to do that, right? So this theta blow-up is given by: I'm going to blow up the I'm going to blow up the boundary diagonal inside the product and replace it with something like its spherical normal bundle. But I want to have a slightly modified spherical normal bundle, which is somehow remembering that my one form had different asymptotics of the metric. So, how do I actually phrase that? Well, my contact one form, it induces a line field. So, you know, I have on this product. On this product, two different projections. I can sort of project onto the left or the right copy of my manifold. So take theta and pull it back by those two projections. I get now, you know, a section of some line field inside of the larger co-normal bundle. And so, given that line field, this induces the structure of a splitting on the original normal bundle of the boundary diagonal. So, you know, given that splitting, So, you know, given that splitting, you know, H here is going to be the annihilator of that line field. And I'll say that the parabolic blowup is going to be, you know, just precisely that structure. So in other words, you know, I take my normal bundle and I quotient it out by a certain scaling action. Because I have this splitting induced by my choice of one form theta, I'm going to scale with slightly different homogeneities. With slightly different homogeneities. So, in other words, two vectors are going to be related under this relation if there's some dilation in which I'm scaling the vectors which are dual to theta, you know, sort of twice as fast as any of the others. And that should sort of that should square with our intuition from the metric. So now I'll show you a picture of the blow up. It's somewhat unintuitive because I can't draw. Somewhat unintuitive because I can't draw all the dimensions to kind of show you these different parabolic directions. But you can think of it as just taking the usual boundary diagonal and blowing it up parabolically in this way. And in so doing this, I can construct a sort of algebra of what are called theta Fourier integral operators. So in this case, these are going to be kind of similar to regular Fourier integral operators, which had that. integral operators which had that kind of local form I described with the extra sort of requirement that these operators will have, I'm going to require that their canonical relations intersect the cotangent bundle of this kind of blown up face transversely. What this gives me is kind of a second notion of a principal symbol. So, you know, a regular algebra of FIOs will already have some notion of principal symbol in the interior and just restricting Restricting my symbol to that boundary function, to that bound, that new boundary face I've induced is going to be what I'll call the normal operator. So what we can prove sort of having constructed this algebra of FIOs is an analog of the Poisson relation for a closed manifold. So in this case, you know, I guess I already spoiled this, but the wave kernel exists. But the wave kernel exists. It admits a sort of renormalized trace. And the singular support of the wave trace, it's a subset of the periods of closed geodesics on my manifold. So this is again giving you some relationship between kind of closed geodesics and the wave group. Further, the leading term in the expansion of the wave tracer. Expansion of the wave trace or the renormalized wave trace turns out to be the renormalized volume, which the physicists are sort of interested in. So, in other words, the wave trace emits this asymptotic expansion and its leading term is this quantity, which we refer to as the renormalized volume. So, the idea is that your volume of your manifold is infinite. And so, the way a physicist might try Way a physicist might try and kind of renormalize that is to say, okay, well, I already had this defining function, so I'm going to, you know, just look at what's the volume up to some distance from the boundary, and then I'll let that limit go to zero. And so it has some kind of well-defined finite part. You know, there's this sort of expansion in terms of the epsilon parameter, but it only depends on the defining function you had initially chosen. So, you know, this to me was sort of really interesting because it's telling you that this kind of gadget that initially the physicists sort of only introduced to try and make sense of partition functions, it's really related to the spectrum of the ACH manifold in kind of an interesting way. So, the sort of general ideas for how you would prove these two facts is to again start with how you constructed the wave parametrize. How you constructed the wave parametrix, at least on a closed manifold. However, you would have done that in the interior, continue to do so, and sort of only concern yourself with how does the canonical relation of this FIO approach the corner in the boundary. And so the idea is, you know, my flow out of the symbol of my Laplacian, you know, in other words, the sort of the light cone in phase. Sort of the light cone in phase space that I was describing. It is a Lagrangian with respect to the kind of the canonical symplectic form on this product of cotangent bundles. And in this case, you have a slightly modified symplectic form after you've done this sort of theta blow-up. And the wave group that you're hoping to construct, it is a theta Fourier. It is a theta Fourier integral operator with respect to this canonical relation. So, the sort of the idea is that you know these theta FIOs they're kind of modeled very heavily on the theta pseudo-differential operators, and they allow you to kind of iteratively improve your wave parametrics. Remember that this kind of guess for what the true wave kernel should be, we had some kind of remainder term, and the normal operator associated to this theta algebra, this theta. This theta algebra, this theta calculus of FIOs, it induces a sort of series of model problems just by taking sort of whatever your remainder term was, looking at the normal operator associated to this calculus, and then trying to solve it to slightly higher order in powers of the defining function. So, you know, in that sense, it feels very similar to many other kinds of iterative constructions you might, you know, you might do already. You know, you might do already. Okay, with that, I think I'm done. So I'll stop and thank you very much. Sorry about that. Great, thanks so much, Adrian. Excellent. Just imagine the rousing sound of everybody clapping. And. And I definitely have a few questions, but I'll open it up. Does anybody want to start? Well, I guess it's first it's a remark, but I was confused initially. So the Hamilton vector field you're talking about is actually the Hamilton. Well, okay, I guess I am still confused. So the On the space in which you cross over the boundary at infinity and do this conjugation to make an operator which is smooth across infinity. There it makes sense to me what the Hamilton vector field you're looking at is because it's just the Hamilton vector field of this conjugated operator. But on the double space you made, Double space you made, I'm just confused about. I mean, you're okay, so you have this canonical relation. Oh, maybe the point is you don't actually have to look at the rescaled Hamilton flow on the double space. You just know what the canonical relation is. It extends smoothly up to the boundary on this blown-up, or not maybe not smoothly, but in some ways. Or not, maybe not smoothly, but in some way with yeah, so that is some that that is something you have to prove, which is that the sort of the kind of the theta Hamilton flow, which is going to be different than the usual Hamilton flow, that extends and intersects the corner transversely in the front face. So, the idea is that, you know, I guess one thing is that. idea is that you know i guess one thing is that that that might be confusing is there there are several different constructions at play uh in the case of the sort of blow-up um when you when you uh blow up the boundary corner you you know that that'll induce a new uh canonical symplectic form on the uh on the cotangent bundle you know you you replace the cotangent bundle with your theta cotangent bundle and with respect to the Respect to that new symplectic form, you want to look at the Hamilton flow of symbols with respect to the new form. And that is what will extend smoothly. That's what will allow your canonical relations to be smooth in this theta FIO algebra. I don't know if that makes sense. Yeah, that helps. We've got a question from Antonio. Why don't you go ahead, Antonio? Can you say anything? Can you say anything about the scattering operator from this? You know what happens when these things really take the limit? You mean the scattering operator associated to the extended problem? I mean, because you mentioned the wave group, right? Yes. The limit as time goes to infinity? No, I haven't had. I haven't had a chance to think about that at all yet. I do think that's a very natural next step. I know that I believe you and Yiran Wong thought about this in the case of the asymptotically hyperbolic setting for the zero calculus, yes? Yeah. Yeah, so at present, I can't say anything, and I'd be very interested to look into that. Yes, we just have to unmute myself in the process and remember that. So when you did this extended version, so you get, of course, a very nice Fred Home problem as you put it. What you didn't say is relating this to the original one. I mean, in terms of the inverse you get for this threat home problem being the inverse you actually want. uh yes that's true so i guess you're you're saying you know does this does this really restrict is that your question yeah uh does this really give you the the correct yeah the correct inverse uh yes um i think the yeah i'm trying to think about how to put it um so i mean i i think that it it it depends as i was saying on um the the kind of the initial domain Kind of the initial domain that you pick for your sort of Meromorphic continuation. But, you know, and so that's sort of why the non-trapping estimate depends on this. So I'll maybe just say this quickly. So for your variable order, Sobolev space, you need to sort of pick what you know sort of pick what you need to pick what the um what what are what are the sort of threshold values for the extended operator or sorry i'm i'm uh stumbling um for for your order function for the variable order sobo of space you you have to sort of pick its uh supin inf and that dictates actually the the width of the The width of the sort of initial region that you can complete the meromorphic continuation in. You know, sort of the idea is that kind of the width will be dominated by one half minus, you know, whichever is one half minus either the super the inf, kind of whatever is smaller. But you do end up getting the sort of inverse of this. Inverse of this after kind of undoing your conjugation and restricting in that way. You sort of get the inverse on the kind of coisotropic variable order sobo of spaces you've constructed. Sorry, I guess I'm not sure if that answers your question. Yeah, I think I'll ask you later because I need some more questions. Yeah, thank you. Yeah, yeah, sorry. Just can always talk and gather, Todd. Yeah. Let's hear Anthony. Yeah. Let's hear Andrew's question and then, or Antonio, do you? Well, okay. Andrew's. Okay, your hand's still up. Anyway, let's hear. Okay. Hi, Adrian. Adrian. My question is: as I understand it, when you are doing the resolvent result, you're extending across the boundary and using commutator estimates. Uh, commutator estimates, but when you look at the wave trace, it's a parametrics construction, and you remain within the space, you don't cross the boundary. Is that correct? Yes, yes, precisely. So, yeah, yes. Thanks. Okay, I think let's just maybe we'll just be grateful that everything is going on time and take a full And take a four-minute