First speaker of today, Artis Redoff. Yes, thank you. And good morning, everybody. And I hope everybody had a nice afternoon yesterday and could relax. And we are approaching the second part of the conference and maybe we are all a bit tired already, but A bit tired already, but I hope at least you get also some interesting ideas. So what I would like to tell about is an operator analysis of a differential algebraic, a partial differential algebraic equation. And first of all, I would like to start with some. With some PDAE examples and applications, why we are really interested in such systems, where are they coming from? And second time, I would like to formulate these partial differential algebraic equations in the form of operator differential algebraic equations, and then go to some existence results for. Existence results for the solutions of PVAE. So I'm restricting here clearly to the analysis and not I'm not telling something about the Nomega analysis, NOMEGA methods today. And finally, I would like to pose some open questions. They are more general ones and not particular ones, but yeah, let's see it later. And first, have a look onto such a Such a little Gaz network. It is called GASIV 11. It can be downloaded from the GAS library or also from our collaboration project here. We have also some transient data for transient simulations of such gas networks as benchmark uploaded there. And what do we have here? We have 11 types and three sources. And three source nodes, one here, one here, and here. Three demand nodes here, here, and over there, as well as two compressors here and here. So there the gas is compressed. And as one example, also a valve. This will have in such gas networks also elements like valves. And how can we model the basic Can we model the behaviour or the transport of the gas to such a network? What do we have here? It's usually a pipe model, a PVE model for pipes. And here it's a little bit a simplified version of the Euler equations. And here at the height of this function f, we have the The friction term. This is a non-linear one. And usually you have the Euler equations in terms of the density and the velocity. Here we have it in terms of the fluxes Q, the mass fluxes Q and the pressure speed. And the row density, the density is a function of the pressure. Is a function of the pressure. If you have an ideal gas, then it's just a linear constant linear function, depending on P. And in general, there is behind a non-linear function, and I call it here rho. And how are these, yeah, and what are the other relations? So these are the So, these are the relations. We have a PDE order on each pipe. And additionally, we have some, I call them algebraic equations here for the compressors. And in general, you have the pressure on the right end, it's compressing from left end to right end here, as a function of the left pressure. In general, this is. In general, this is given by an implicit equation system, but just for simplicity and in order to have in mind what is behind, I wrote here this as a function. And additionally, we have for the value also some kind of model, and one model where we do it like that. The theta might be a constant parameter or Constant parameter, or actually, it is a piecewise constant, or depending on the value, also continuous function, depending on the meaning. But the important cases are one, theta is equal to one, then we have just but cancels out, then we just have p right is equal to p left. That means in the uh case the valve is open. The valve is open. And in the other case, if Î¸ is equal to 0, then we end up with Q equal to 0. That means we do not have any flow through the valve. And in that case, the valve is closed. And additionally, as we heard already from Zah on Tuesday, he has. Say we have some boundary conditions where all these elements are connected at the nodes. And at the input nodes here, usually a certain pressure is given. So there we know the gas is put or pressed into the pipe system with a certain pressure. So this is a given one. And here the This is a given one. And here the psi function or psi function should only indicate that it is at a special node. So p node should be the vector of all nodes and then the vector the corresponding node, which has this relation here. And similarly for the demand nodes, usually one takes out a certain amount of flow and then we have here Then we have here the Q as a mass flow living on the pipes and evaluating it at a particular node here, at the demand nodes, then we end up here also with the function qz here. And finally, we have these junctions, so the intermediate nodes, and there on one On one hand, we have the relation between the pressure functions living on the pipes and on the boundary we have here the global nodes I would say, the global nodes only. And here is the pressure of the nodes and at certain places, X nodes I call it boundary nodes. Boundary modes, yeah, just pressure between here on the pipes is equal to the vote here on that end, and that is this voltage. And additionally, we have that the sum, the mass balance, that the sum of all flows in each node is equal to zero. And I just wrote it down like that. And yeah, here always you have to Always, you have to take one of these junctions. And all together, what we see now, we have a system of pds and of algebraic equations and boundary conditions, which have also somehow kind of algebraic equation. And what we do in our projects is First, to discretize such partial disputes in an appropriate way, either I could say we do it in a way such that the resulting system is then somehow called nicely the idea of index one, or we developed some approach in order to find an index one. Find an index one DAE at the end. And what we get is actually we have the spatially discretized PDE here. So I didn't give exactly which kind, but we indicate that QH and TH are now the spatial discretizations of P and Q. And then we have more than ODE, what each pipe, together with these algebraic relations and all together it's a differential algebraic relationship. And then another example from a circuit simulation that we also deal with coupled with partial differential algebraic equations. At the beginning, let's have a look onto such a NAL gate model. Here we have Gate model. Here we have some voltage sources and some transistors. And together with these two transistors here are the two input functions of the NOR gate and over the flow capacitance. We have the output function. And this transistor here acts only as a nonlinear resistor, but from the production point of view, it is much easier. You, it is much easier to have a transistor than normal resistor. And then, what in circuit simulation is done usually or formal time was done, that you replace these transistor models. You an example of a MOSFET of a metal oxide field effect transistor. And we have here the source Here the source and lane, so mainly the flow is from source to drain, depending on the applied voltages the gate this channel here opens or not. And here we have SGDB, so to speak, and here it's a little bit difficult to see properly from your side, but here it's S G D V to have some connections and. And using such an equivalent circuit model, we have here only resistances, simple diode models, some control sources in between. And all together we can describe this with the differential Dubai equation. Because here we have only lumped element descriptions. And yeah, together with Kirchhoff's law and the nodes and relations for this capacity. Donations for this capacitor C, for example, the whole system is a DA. However, with the shrinking dimensions, we have the problem that sometimes the different elements on such a chip adopt each other. For example, some kind of Some kind of cross-stroking over when you have some lines on the chip quite close together. And that's why we were interested also in another kind of model, not to use equivalent models, but to use semiconductor equations and also later on Maxwell equations. I don't want to explain the equation. I don't want to explain here the Baxter case, because I just would like to explain how it is PDEs or PDAEs come from. And now we are looking for a description semiconductor partial differential equation. And that can be done, and we submit the Kirchhoff's equation in general in the following form. Following form. It's a bit messy, the next slide, but the only thing I would like to say here. Here, we have a description of our circuit systems, where the elements that we describe by a semiconductor description are inside the system, and here the red variables are the socket variables. And one little thing. And yeah, one little thing that is usually not so obvious for everybody or not so common, we have the differential algebraic equation where we have here the derivative, inside the derivative of the actual QC. Behind this is a charge of the capacitances and of course if it is differentiable then we Differentiable, then we can use a chain rule and then put it in normal form of the DAE. But from the maker point of view and also from the analytic point of view, it has some advantages to keep it here and why I keep it also here in this way. And on the other hand, we have here the description of the semiconductor equations where we have conductor equations where we have the whole and electron density as well as the potential phi and I called it here phi h because it is already a homogenized version of the semiconductor equations and but just a little notion regarding these equations here behind. Regarding these equations here behind. It is a simple drift diffusion model written down here. The names that we have on one hand a diffusion part here behind and because if you plug it in you have difficult and on the other hand here we have the drift part. The drift part. And what I wanted to say, ah, yeah, here, as I said, it is a homogenized version and the original potential phi, the function of the space, of course, or a semiconductor device, MT and on the boundary it It should satisfy some back here in order to explain it. Oh. On here on the boundaries, source, gate, drain, and bulk, and at the boundaries, data hit article. The potential here in this semiconductor depends on the boundary of the voltages of our circuit here. So these are voltage modes. And here the loaded potential is in the circuit, and that's why we have selected. That's why we have here inside a DDCL condition depending on the nodal potential of our circuit E. And in a homogenized version, yeah, you can write it like that. And here fx and g are suitable functions that put in the right order of the semiconductor. And because of this, our electricity. Our electrostatic potential at the nodes of the circuit come into here into play and also here into play. And on the other hand, we have a connection regarding the currents, the current through the transponding varieties, and the current is given by here by the current of the electrons at holes. And additionally, this. Um additionally, just um essentially just a little yeah, a bit of carpet here we might but okay. Uh but anyway, what we see the correct connection between both uh type of equations is the one hit by a such a boundary. Hand by such a boundary integral, but the other hand by boundary conditions. And now the question is how can we treat such systems? And in order to have a look onto this, I would like to formulate these partial differential algebraic equations in an abstract form. And let's look the following way. The following way, as I have explained before, sometimes we are interested also in having an operator here inside the time derivative that is called by D. And then we need appropriate function spaces. So we look for normal as on here and neural spaces and u should live in X or yeah. Yeah, an x, or yeah, essentially a function of a time interval into x, and then our d is mapping into a live space z. And yeah, depending on the approach, I will explain a little bit later, whether it's a solution approach or not, we have our time derivative should live then in z bar and the different space could be the same, but uh generally it's a different space. generally it's a different space and then the map the map A maps from Z bar to Y and our B maps directly from X to Y and in general our operative E is only defined dense in X and the natural solution space now for those kind of equations is then given by By our functions, maybe time to our Hibbot space X, but there should be a time derivative existing for D of U, and this should belong to the one. And let's have a look, a little example. It's a bit more, yeah, it's Bit more, yeah, it's not so practical, but it's close to that one that I showed you before from the structural point of view. And let's have a look here. General is a deer E, we have here only an ODE for the moment, and not just have too many equations here. Then a little Poisson equation, then one of the variables that was current there. There through the semiconductor contacts, the semicolon or some function of our PDE. And on the other hand, we have a boundary condition, a directory boundary condition for our PDE variable depending on our DAE or in this case PE. And in that case, we can write this in the form that This in a form like I described before. And here we see the D should only take from the U, only the first variable. Because only for the first variable, we really need the time derivative. We don't need them from the others. The other solution components. And then the A is just blowing it up. These are all. Up the whole equation. System I see here one zero is fitting. So four kinds of equations because I put the boundary equation equations as a different equation here. And yeah, and then the operator B is given like that. Here, it's a bit trickier just to note it as B integral, as this operation. Operator comes from this integral here. And here I write an R because this is only a condition on the boundary, it's not a section for a boundary. And in that case, so what we usually have, we have here our Laplace operator, if you write it like that, our B is an unbounded operator. And yeah, this all Yeah, it's all on one hand interesting also for the community here, but on the other hand it's quite difficult to get existence results or solutions of such systems. And we could write the same system also in variational form and just integrating here all the really here by parts. Or the VE by part, and taking then the corresponding H10 space. And in order to use this H10 space, one should again homogenize. And here I have behind the homogenized version. So U22 is a homogenized part of U2 and then Two, and then we can, yeah, we don't need the extra boundary condition anymore, we can write it like that. And finally, the advantage of this variation form big description is that now our operator really is bounded. And what can we show in general for such a kind of systems, in which cases we have existence of solutions? We have the existence of solutions. And so, first, I would like to present you some results for PDEs with monotone operators. So, quite nice case. And what we use is also the literature approach that we learned yesterday. And here Here, what do we need in order to F or to show the existence of solutions, at uniqueness? Our D operator should be surjective. In practice, at least I do not see any problems with this assumption so far for the practical applications that we have in mind. But what is the restriction in order to get really results here from our perspective is that the A is not a general I will come to it later. First of all, it should be an operator from that start to the restart and B of T then from V to restart all T in pi. And then in the natural solution space. Then the natural solution space is given as follows for the big solutions, solution time also. U should be an L2. And yeah, I knew because it's already quite long here. I took zero t interval as interval notation basically here. And then the time derivative look should live in the two space um uh over the time integration at a valid values at z star. Values and zuck. And yeah, I call this W12, but depending on two spaces here on the V space, where the T is coming from and the Z space where the T is projected over mapping it. And so for as long as B is As long as B is constant and all these functions are linear, an existence result is given in my PhD student Michel Ratis extended the results also to a time-dependent case B of T and B can be also non-linear in this case. But of course not for all of this. For all of these functions. So we have unique solutions in the space as I described before for the following cases. For A is equal to the dual of D. So that is really a restriction here that we need. And V of T should be strongly monitored, hemicontinuous, and satisfy a certain The model satisfy a certain global condition. It is also known for and the right hand side should live here also in the entry space. And in that case, if we state the initial condition, and as we see here, we have only time derivatives for the d u component in this description. Description of the surjective defines exactly which part of the solution should have an initial value of the collision. This is given here. And in this dimensionally approach, it should be our space H. And yeah, in this, for such general cases, we could show uniqueness of. Cases we could show uniqueness of solutions, but there is, of course, there are some limits. Ah, no, first on the limits, let me give a shorter description of our proof. And what did we do? Yeah, the classical one, we use a Galerkin approach and describe our solution in terms of linear Linear combinations of spatial basis functions with time-dependent coefficients. Should be an idea or something. And then there's one thing important in order to approach goes around. These basis functions should be chosen in such a way that on one hand, the null space of D. The last base of D is spanned, and one of its complements. Which one is not important? But at least the basis should give us also splitting of X into the space of D and as soon as we use such basis functions, then we control our unix probability of Our unit solvability of the Galiokin equations, and the Galiokin equations that arise up there are dms. General, even without the additional assumptions, these would be different territorial equations. But with our particular assumptions on that A is equal to the star to the joint, and additionally the monotonicity assumption regarding the operator B. We know, or we can show that these are all. Or we can show that these are always DAs of the next one. And yeah, how can we show this? That has to show some upholi estimates of the differential performance. Then we show the low-bus availability for the algebraic components inside using some properties. And finally, solve the inner and only issue. Solve the inherent only is by the theory of Cara Simu Dovi. And yeah, the tricky part behind is special part of the essentially this is needed here at the last part when we would like to show the conversions of the Gareken of the DAE solution. The DAE solutions to the PDA solution. And additionally, somehow it is exploited in order to have a DLE of index one. As long as you have a monotone, it's only monotone operator B, then from the DLE point of view, it is not completely necessary, but But for this convergence, at least we needed it. But there's also another tricky part before showing that the Galochian solution to the DAEs really converged to the original solution of the PDAE. And as long as we are in the media case, there's no yeah, there's constant coefficients, there's no big deal regarding uh the timer devi. Regarding the time interval. But in the nonlinear case of B is time dependent, then usually we only know that the solution is given on a special close to our initial value. And then the problem is if we would like to do the convergence proof to go to the limit. To the go to the limit of the solution, then it might be that our solution space goes to zero. Our domain, solution domain goes to zero. And that is the TV part here behind to show that we always find at least a compact parameter while that is not going to zero in the interview at all. And yeah, this is just the theory behind. Theory behind this theory is, but as I said already, when we look at our applications, in particular the applications I have shown at the beginning, strong monotonicity of P is often not clear. We quite often have monotonicity on certain subspaces or for parts of the operator B. That is the door back here. And there's one open question and one extent, this approach that is described there. The operators being strongly monotone of properly chosen subspaces. What do you mean by strong monotonicity? Ah, it's a just that. California should be or they should be scaled differences of vectors for non-linear ones to use the differences of course yeah you have To use the differences, of course, yeah, you are right, and yeah, and luckily there are already some results for certain classes, and I would like to present some results that we didn't see so far here in the audience. And one comes from Belsibio, and Bensibion and he considered so-called, yeah, well you could then the second point, partial differential algebraic equations. These are systems of the following form, where they are coming from flexible multi-body dynamical systems. The finite dimensional case we described in his talk already. And here we are looking for the infinite dimensional case Infinite dimensional case, yeah, where we have flexible forces inside the system, and yeah, and signal ensured that one can write to them as long as the forces are in a linear form. It's a linear representation. That one can describe such systems in such a form. And essentially, usually, here is also a mass. Last one of the second derivative of u, I skipped it here and put it also into the other of what it is. And I just did the actual simple description. And we have two relations and two different spaces. This is again a big formulation here. And that's why here we have the scalar product. So we test the size. Scala product to test with some function in our function space B. This should be also Hilbert spaces here. And we are looking for a solution u in this Hilbert space together with my plan U in another space. In this case, it is given the H1 of omega in the three-dimensional space to the power of 3, and here the corresponding boundary space. Space given to the directly boundary conditions. And what he assumes here, also for certain applications inside these flexible multiple system dynamics, is that A and B should be continuous and continuous lighting at once. L and M should live in the corresponding space. And yeah, here we have if we have a look onto this, we see this is somehow the adjoint operator. It's a thing of V, regarding here the operator V of the multiplier mu. And in the final dimensional case, it is exactly the Dylan multiplier or the longitudinal dynamics. Multitudinal dynamics. And what he could show is that some kind of systems have also unique solutions under the following assumptions. So here we have already what I asked before somehow, the operator A should be zero. B0 elliptic, so it means subspace only of space B, and the subspace is essentially the kernel of this operator B here. And additionally, this is the sort of zero point condition, the L G B uh condition we find for the operator V, as soon as we have such a constant. If you have such a constant, then one can burn a control that this has a unique solution. And he did most of the work already in his thesis in 2000, but the description is given in his book, Computationally Flexibility in the Different General Microphone. In the differential microphone 13. Does this format also work for, say, compressible fluid flows? Wait a moment, and probably the details you should ask Robert. Let me come to the next slide. So, Robert Edmann also, I mean, this was also somehow happened. Hyperbolic type, but particular description from the multi-galactic systems, and here Robert Edmann and HD student sorry, but also yeah. But also, yeah, several other co-writers he considered several applications and also fluid atomic applications that I refer to over. And you could show that some of them fill into this class here. And it's a little extension, and what you could see, I mean, if you would write the system that we had before. Before is the first order system. Here, introducing u dot equal to another variable, then we end up also with a system like that, but this is a bit more than considered before. And uh here also uh they control uh the existence of uh mild in weak solutions. My in big solutions for yeah, what do they need? They also they need some properties of the operators here, and A and all the operators here A, A should be also a color graphic, K and B the same. Sorry. All of them should be linear and bounded. And the D operator here is The here elliptic. Behind this is also because they also considered the lipid case with the paramodic case epsilon equal to zero. And B that we had before should, yeah, we see here the saddle point relation behind again should satisfy the LBB condition again. And then they need also some. They need also some additional properties of the operator K here. They should be restricted from below by a constant K on the kernel would be. And here the assumptions on the right-hand side came mainly from the different applications that they considered. And I also have chosen here only two publications, but of course there are. Complications, but of course, they are similar on these topics in particular, mainly also Robert considered the nominal discretization of such systems that I don't explain here. But yeah, I've given here Cesar's and also a new paper together with Christopher Simmer on the circular educational results on systems here. And yeah. Yeah, that's actually already more or less what I wanted to tell you from the analytic point of view, what is known for special classes. And now let's come to the question of normal forms because there Timo, already in his thesis, showed, as we had heard already by Bergenstark on Monday, also that a normal form exists for such linear operator operator form under the condition that E is a bounded Is a bounded and we are considering here again several Hilbert spaces. And additionally, what is needed in order to get such a normal norm, and we will put later, this is some regularity of the potential of E and A. And this definition, this j is based on is based on the matrix chain that we have a detectability index concept for the finite dimensional case. And who is familiar with this? Everybody or those of you know that one needs certain or uses certain projectors, certain subspaces and this One needs to assume that these projections exist also in the infinite dimensional case. And yeah, this is the limit, so to speak, behind this approach because it's always not so difficult, not so easy to find or to decide whether these projections exist. But Timo did it. Exist, but Timo did it in particular in his thesis in applications for circuit simulation, and there he described it in more detail. Yeah, I showed that for such systems one can do it, or quite often do it, and there are really conditions that are getting usually infected. And let's have a look into the long form here. As long as we As long as we neglect this last line here, then it's essentially the having k equal to zero, then we would with a Kronecker-Weilstrass form that we know from the finite dimension. And in the infinite dimensional case, yeah, as a general, it is not possible to get here, zero, and this mainly comes. And this mainly comes from this additional part that we have here that I have described before. So in the PDE case, we usually have additional boundary conditions. And we can somehow interpret this additional part here as a reflection of the boundary conditions of our PDA systems. And they have incorporated to the system, and then also that's why when we Oh, that's why one needs to also hear an operator K in general. And yeah, now some open questions. Not really particular problem, but more from the general point of view. One thing I'm interested in: do we have under which conditions do we also have? Under which conditions do we also have these unique solutions for bottom-meltonian DNAs? Because they also have a particular structure and how can be exploited in order to show the existence of solutions. But I believe one also needs some additional conditions. And another thing, what can we learn from index concepts for partial differential algebra? For partial differential algebraic equations. It goes also to the direction: how should we extend existence approaches for in the finite dimensional case for the index to PBAEs? But yeah, it's a question. One question from the nomadic point of view is as I explained at the beginning, As I explained at the beginning, after spatial discretization, we end up with a differential algebraic equation. And from the numerical point of view, we would be interested in good solvable DAEs. Good solvable DAEs would be of index one. And so that's why, yeah, let's come to this question below. Is it possible for special? Spectral defined other spectral representations of media systems of higher index, as sure as we have a good definition for this, that lead to index one DAEs, but and provide solutions that converge to the original solution of the PDAE. Even so, the PDAE system has a higher indexes. Or is it some Is it somehow that would potential if our PDE index would be say mu? Should we look for special discretizations also of index mu in order to better describe the behavior, the solution behavior behind that? But this is still an open question to me. It is more also philosophical one, but for particular class. Philosophical one, but for particular classes, maybe one can find some answers. And that brings me to another question, in a general case, what kind of classification concept we should looking for in case of PDAEs? Because usually, at least I'm a nomadical analyst. I'm a numerical analyst, and we were interested in the index for the DAEs in order to apply a good numerical method to the corresponding system. Or actually, later on, more or less, I move to the case that we should have a look onto our model system and describe our model in such a way that we end up with a well-posed system that means only with an index one system. X1 system. But nevertheless, the index in the finite dimensional case reflects somehow the numerical difficulty that we have at solving these theories. And from the PDE point of view, we have actually for the numerical difficulties or the question to treat them from the discrimination point differently, or the classification for two elliptic, parabolic, and Yeah, elliptic, parabolic, and uh hyperbolic problems. And when looking for PDAEs, I think one should glue those concepts somehow together for a good classification and from the numerical point of view. And yeah, but the question is: how could these concepts of PDEs incorporate into a good index concept for PDAs? And yeah, I learned something here during this conference. I'm really thankful also for the invitation. There are several interesting results regarding the solvent approaches. And can we derive a suitable classification from the solvent approaches? Behind that is also a little bit I'm not so familiar with this for PDEs. Can this, for example, elliptic parabolic and hyperbolic system description reflected somehow in the operators regarding the dissolvent approaches. And what I also would like to have a look on is I presented. Look, I presented here some special classes where we know that we have a unique solution. But can we see some particular properties of the resolvents of such systems? And yeah, finally on the Agra Bay line around, an existent result yeah, an existent uh results for special DAE classes also help a bit. Classes also help a bit to find sufficient conditions for the existence of the metal bottom stream. And yeah, those are my questions and at the end of my talk.