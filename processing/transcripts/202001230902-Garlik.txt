The reputation is data which is just another name for the formula which we have seen in Aberstog and Witerstalk. I'm going to talk about the original formation of the formula. It's encoded in unary and it's not relativized. It's in a sense the weakest of the formulas I know or we have seen which Know or we have seen, which expresses this fact that a formula F has a resolution of length V. So the fact that it is weak isn't very natural is the reason why I looked at it. And also because low bounds for it were mentioned as a log. For it were mentioned as an open question in the paper of Albert and Moritz. So this is a theorem, actually. And in this talk, I will try to give some ideas how to prove it. It is an exponential lower bound. Should lower bound on resolution refutation of this formula provided f is unsatisfiable and it works for any unsatisfiable f and all large enough v's. V is the main parameter, it appears in the exponent. From this fo from this low bound it is uh not hard to uh infer uh low bounds for um a reflection principle. A reflection principle, or Rubans for resumption for reputations of the negation of the reflection principle, which contains the formula F here. This, sorry, it's a mistake. It should be N and R, not an F, because F is not fixed in this formulation, like here. For this formula, For this formula, low bounds were known, but they were not exponential, they were not that strong due to at serious bonent. So we propose exponential low bounds, this. And the third consequence we may not have time to discuss is also easy to get. And we can use the formula in a way that if you have some family of formulas. If you have a subfamily of formulas and you know that they are hard for resolution, but we are not quite sure whether REST2 refuses them or not, we can modify them in an easy way such that they stay hard. It's potentially hard for resolution, but they will be very easy for REST II. But as I said, it's just an easy consequence. So what we will actually do is Plug in some zeros and ones for some variables to the original formula in order to talk about it in a smoother manner. It will be very much easier to talk about it and it will come with a natural class of random restrictions which we will apply in our low-bound argument. So, of course, restricting the formula only makes the low-bound task for us harder. The low-bound for the original formula would follow immediately. Formula would follow immediately if we prove one for this formula. So, what we do basically is prevent some premises which are in the original formulation, which remember the clauses are ordered, which are too far. We want only this premises to come from the previous level. So, maybe a picture. Maybe a picture. So we have F, forma F, these clauses, these are fixed. This is our playground. This is some nodes which important is the index. And this index will this pair, index pair will index all the other variables. For example, here we have variables D1TLB. D1TLB, so one is for the first level, is T is the last cause, and L is for the number of the literal, we have N many variables, sorry, variable, and B is to give the polarity to take the variable positively or negatively. So, if this variable is true, then the meaning is that the formula clause D12 contains the Close D12 contains the variable XL with the polarity B. Similarly, we will introduce variables to point to axioms. We can do an axiom download to the first level only. And as I said, it's in unary. So this means that we have a separate variable for every pair. For example, here one, three, and For example, here 1, 3, and some number of the clause from F. Similarly, we want to talk about the left premise of a clause in the derivation. So, notice that it comes always from the previous level because we prevented, for example, it coming from this level by plugging zero for the corresponding variable in the formula of The formula of Alsiras-Miller. We have the for the right premise the same. And we also need to specify for the resolution rule by which the clauses are supposed to be inferred, what variable is the result variable. So for example, here for clause three, six, it will be a variable L prime R. Um eventually we want to write out some axioms. Going to write out some axioms which enforce this functionality so that, for example, write premises only one arrow, one variable from D33, L variable assign one, and all the other zeros. We want to enforce this by axioms. We will like to see that the last cause is empty, which is nothing else than writing down the negation of this little. Writing down the negation of this literal which negation of this variable, which exactly says that the last clause does not contain the, for example, here, variable x1 positively. And we also want to describe the resolution rule that would be two axioms. For example, here we would like to say that if if we know that the right premise of d 2t was d12n, uh we this the Uh we this the x five was the uh result variable. We want the x five to appear uh negatively in the right premise, let's say, uh convention. So this is what I just said, an example of an action saying that the last cause is empty and saying the last thing I said about the result variables. And similarly, we write down clauses which says that little Uh clauses which say that literals which are not resolved are transferred from the premises to the uh to the conclusion of the rule. So here is a more precise version of of the result now written for this formula RFFST. Well SST is the rectangle, it's our playground. And so it says that for each epsilon there is delta and t is zero, such that if n r s t are integers satisfying T are integers satisfying some natural condition, and F is an unsatisfiable C and F, which has R clauses and is an variables. Then any resolution refutation of this formula has length greater than 2 to the t to the delta. So maybe let's have a look. This epsilon is not really needed. You can imagine plugging one for it because it only appears here, it only rests. Here, it only restricts some lower values of this parameter t, where t is the main parameter. So, s is like the height of the proof, as we saw, and t is actually actually the actual length of the proof. So, yeah, I hope it doesn't cause much confusion with a previous formulation where we used s for length. Okay, so for example, this one, the number of clauses has to be at least the number of. This has to be at least a number of variables. It's quite natural. And we do interesting formulas which violate it. And here we again have that HPT is the main parameter is greater than number of variables or the height. Okay. To now I'll dedicate I think the rest of the time to to give some ideas how to Uh to give some ideas how to go about the the proof of this formula, of the lower bound. So it's by contraction. We assume uh given some epsilon and assume that for all delta and t0 there are some these numbers and a formula f which satisfy the conditions of the theorem and there is also a short refutation pi of f of st. Our task will be, it follows from some calculation based on the improved technique to find delta and t0 and prove that the above cannot happen, which we do in the following two steps. It's a classical framework as we are used to prove resolution lower bounds. Just the defin definitions of of weights and the adversary arguments will have to be much more refined. Much more refined. But it's a very familiar framework. So, the reason of applying the random restriction is to reduce the width of the formula, of the proof, provided it's small. I put it into quotes because it's not really going to be a width, it's not going to be some To be some index width or block width. We will have to go to something more refined. And the direction basically, the main idea is if the clause is wide, the restriction will satisfy with high probability. The second step would be to run an unversary argument against such reduced refutations. Refutations to show that they cannot exist. Notice that compared to formals where we previously rativized the formal composed with something, here our job will be a little bit harder because it will not really be clear what it is if we restrict our nicely, neatly written formula by some random restriction. We would have to talk about its properties by about it, what happens after restriction, just by knowing the properties of rho. Just by knowing the properties of rho. So we have to be careful to ensure all the properties of rho, we will need. So an adversary argument we will see in more detail, but basically it's showing such a proof with its small width doesn't exist, but propagated some kind of partial assignment. Usually, the assignment assigns, I mean, usually if you... Assigns, I mean, usually if we proving easy row bounds for resolution, it will falsify every clause. It will start with the empty clause, end of the proof, and we will have some procedure how to find the premise, how to go from conclusion of the root to the premise, always falsifying the current clause and do it in a way such that we don't falsify an axiom. So this means that we can go forever, and this means that such a proof does not exist. Now we look at some ingredients for this particular formula. We have to really listen carefully what the formula is saying in order to design these things. So first problem I mentioned is this functionality, which is another axioms which are part of the formula, which I didn't mention before, or I mentioned them in words, but I didn't write them, which basically say that, for example, L variable gives the points to the left. Level variable gives the points to the left premise. So we would like to say that at least one clause from the previous level is a left premise of the clause at ij. And also, there are no two left premises, there's just one. This kind of limits our restriction because our restriction will have to respect this. And this means that, for example, positively occurring literal, this one, we won't have a good chance to satisfy. Have a good chance to satisfy basically, probability will be something like this. We either hit it or we falsify it because we hit someone else, some different J double prime, which means we have to evaluate to zero this literal, so we didn't satisfy it. So this notation means just the set of variables, L variables, which share this index ij. Index ij. So it's for a set of variables. By setting it, I really mean we set one of them to one and the rest to zero. Okay, but we also notice that, however, if we have a negative recurrent internal like this one, the chance to satisfy this is very good, even much more than we need. We we would be happy with one half because we would like to argue that if it's one half and we have uh more literals in the clause, then it's mu multiplies. Uh It multiplies, and so it's even too good, which multiplies the following definitions of important pair or L-important pair. We will have to distinguish the sorts. We have five sorts of variables, and we have to define all the notions like importance for each of the sorts separately. It will be similar for the sort L, R, L and V. It will be different for sort D, as we write it here. So it is also known thing. It is also no known thing. This actually comes from the notion of pigeon being good in Proofs and Games paper by Pavel Purlak. So we look at the clause E, which occurs in our alleged short proof, and we call this pair unimportant if E contains a negative reteral of a variable from this set, or E contains at least T half positive returns. So why T half? Because as I said, So y t half? Because as I said we would like to satisfy also with a probability t half if not no negative literal occurs but only positive literals. So that's why t half. We sample the random restriction by the following experiment process. Now this p, the probability will occur in all the steps. So let's first read the steps to understand it and we can look at p we We basically each pair which occurs, we have these S times D Mary pairs, we include or not with probability P into some set A B and then for those which were included, we independently sum to complete closed D, which means for every literal it will be either there or its negation very variable. Okay, step two, we want to also kill those variables which point to x. kill those variables which point to axioms. So we also do the similar thing on the first level. We sample some set Ai in independently with probability P for each one pair one J separate and then we also can afford to avoid those which were already chosen to A D. This will not go much, this will just factor P times 1 minus P will occur there. And And we randomly choose M and set IJ, this is a set of variables to M. The notion of setting this set of variables we already explained. Then this will be easier. There is no danger like before. We want to sample in a similar way the variables on which we resolve. So again, if it's probability P, we choose a repair ij, and it's there, we sample out of this n variables. out of these n variables, one of them. And the last thing is we, this is the most complicated, we want to sample these left and right premises for each level. So we do it again by selecting some subset, by selecting each point for the p, and then those which were selected for each level we build a one to injection to i minus one. The cases where this this fails are very Fails are very have very small probabilities, so it will work. And we set corresponding literals. Okay, so now we look at some properties of the row we just built. Maybe this is a very careful choice here of this P. It depends on T. T was the main parameter, the length. This A must uh fall basically it depends on epsilon, but basically in in some small in interval. Um interval. If P is too high, we will most likely falsify some axiom. If P is too small, the restriction would not be useful. So this is just to say that at each level our sets, first step we always include elements in a set, we didn't use much of each layer. Then what we need to show in order to be able to say that we did not Say, be able to say that we did not falsify an axiom with high probability, there will be a lemma with not difficult proof saying that we need to look at connected components, because where something can break with the axioms, it's actually connected components. And the lemma will say that basically these shapes can appear as a maximum connected component of rho, but no But it's always only two labels. Here we have other two labels here also. This is kind of compulsory label because we assume that there are edges, so it has to be chosen. And some other label can appear either here or there. So there are more of these kinds, but always two labels only. And this is s singular case singular case because both of these have to have a label L L R and I say that with And I say that with high probability we can pick rows such that no third label will appear at such shapes. So I will not do the computation. Then we have in dilemma how actually what the restriction does with the proof, with the pi, so with clauses of E. So this is a lemma which says that after the restriction, number of Restriction: number of Z-important pairs for any Z out of these will be small. The proof is: if it were not, we would satisfy the clause. But the proof is long and a lot of computations, but not difficult. Okay, and the last thing is how to run this adversary argument. Because we have this notion of important pairs, as I said before, when we are trying to propagate some partial assignment, we only be. partial assignment, we will only be able to falsify variables, literals appearing in the clause, which have an important index. There can be many other variables of which we don't have any control. We just know that their index pairs are not important. This will make a lot of problems, but we cannot overcome them. So most important thing is maintaining these two properties of our assignment, partial assignment. Properties of our assignment, partial assignment. It will be chosen from some class of admissible assignment, which have a nice shape and don't falsify any axiom. And basically, anytime this assignment for when we are in the current clause of the restricted proof, pi restricted to rho, anytime we assign some variable, sorry, Sorry, all the variables which have an important index in E will be assigned. Maybe there will be some more assigned. There will actually have to be because we require some closure properties of this admissible assignment. And second, whenever we actually assign, evaluate some variable, the literal in the clause will be falsified. The same way, just don't falsify everything, but just these. Okay, so wrap up in a minute. In a minute, we proceed as follows. We know the width of this clauses is small, width in the sense that for, as we have it, that the number of important pairs for every kind of sort of variables is small. This means we have to show this, but we can find the premise of a current clause. If you are the current clause, Of a kernel clause, if you are the kernel closer and it's a partial assignment, it's an extreme assignment, we will be able to find where to go to left to right premise, and we will be able to do this and never satisfy an axiom of ref. Here is the most difficult case because we are traversing the proof. So, in the proof, pi restricted to rho. So, in this proof, these are the variables which occur there. So, and this is the most difficult. So, and this is the most difficult question, a query. What was we need to decide what to do, provided we have not already assigned this variable. If it's in the domain of our assignment, we are fine. We just look whether it is falsified and we go there. But if it's not, we have to argue, or the way to argue is to basically to go to some pristine untouched clause, which is does not is not Is not touched by any edge we have built before, either by row or by the restriction we are building. So we need to show that there is enough space on each level. There will be some restrictions like sets which we want to avoid. Some of them are those which are touched by our row, which was the remember. Which was the remember, this was the very first restriction we sampled. But then we applied some closure properties and propagated some sigma. So we can control both rho, that was from the properties of rho, and the difference between rho and the thing we are propagating, because the difference depends on the number of important indices in the clause which we reduced, so it's small. There is also th w thing that we thing that we these variables occurring positive positively can be there we want to avoid them because we don't want to satisfy them but because we assuming that ij is not important why it's not important because we if it were important the the variable would be set so because it's not not important there is only at most t half of them and summing everything up we get Summing everything up, we get a root of space. We have the whole thing is t uh size t, each level is size t, and we have something smaller. Uh so we are fine. The problem with this is that there are two more fine details, what the proof or what can happen in the proof, which gives rise to another two kinds of sets which you want to avoid, but these are technical details, I will not talk about them. So, thank you. Questions? So it looks like you in the hypothesis you have optimized the constants, right? But in the conclusion with the one? Like the t2 dotted is dotted? No, no, it's not that. No. No, but uh I included this statement with this uh This statement with this epsilons and this target because that's what the technique gives you. And the other day there were questions like how low we can go. The comment is that this is what the method gives. But if you actually had the first, first I had the proof for binary encoding, where you this all these pointers you encode them in binary. And then this can be completely omitted. So the for binary. Moreover, these two special Moreover, these two special cases which I didn't discuss will not occur for binary case at all. This is something which pertains to this unary world. So this will be dropped, so you can go pretty low with this T provided to encode in binary. Depends on your application what you want to do. Could you at least very briefly say what are the new examples separating best and resolution? Ah, sure. So basically, yeah, I haven't written it on. So you have those formulas, which you know are familiar formulas, which you know are, let's say, require exponential size to refute in the resolution. And so for the formula, if it's from formula A, you make a conjunction of A with a ref of A in resolution and with the parameter which is the Parameter, which is the polynomial in the number of variables of f. So, this is what enables the REST2 to quickly refute this. But it stays hard for resolution because the proof splits into two, and on one side you will have basically if I if I plug in or let's plug in basically on one one side I will have a refutation of your hard formula in resolution uh which we assume to be Which we assume to be to have to be big, or on this other side, I will have a refutation of ref, which also we know have to be big. So it works for resolution, but not for stronger proof systems. Any questions? 