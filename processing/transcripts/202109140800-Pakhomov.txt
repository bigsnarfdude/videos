Let me introduce. So it's a pleasure to introduce Fyodor Pakomov. And so he works at the Steklov Institute in Moscow and also at Ghent University. And he has a, I think, a quite prestigious grant from the Flemish Science Foundation. And he's going to talk about dilator analysis of AC. Talk about dilator analysis of ACA0, please. Um, okay, uh, thank you, Michael. Uh, so actually, do you do you see me? Uh, because yeah, we can. I'm sorry, yes. Uh, okay, so okay, but okay, now we should. Yeah, um, okay, yeah, so, yeah, so I want to thank the organizer for inviting me to this conference. And actually, since I haven't sent this my announcement. This uh my my announcement of in time so that they have allowed me to actually still um present this uh workshop. Uh, okay, but okay, let me start. So today I'll talk about uh my uh joint talk with uh Juan Guildiera. Um uh yeah and so let let me get started. Uh oh fine. Uh sorry. Uh uh okay. Okay. Yeah. So let me start this discussion of the latest. Of course, it's a short talk about the latest today. So people probably already heard quite a lot, but nonetheless. So now I want us to talk about... No, no, I want us to talk about some very concrete dilators, and actually, this talk will be mostly about concrete dilators. Okay, so this is, I think, probably the most important example of the dilemma, namely the dilator omega 2x. So, okay, so basically, for a linear order A, we always could do so the natural. We always could naturally define the linear order omega to A, where elements of the order omega to A are this formal counter-normal forms where powers are from the order A. So we have this formal counter-normal max with natural conditions on coefficients. On coefficients, and then we basically then we just compare them as you would compare a counter-normal force. Okay, and of course this is so basically for any linear order A, omega to A else is a linear order. And if A was well ordered, then of course omega to A will be a well order of the order type omega to the order type of A. The order type of A. And so, and so also, what is important is this conception that, in fact, this transformation was factorial. So, namely, we could put that for function f, so for strictly increasing function from a linear order A to a linear order B, we put omega F to be to be. f to be to be this function from omega a to omega b that yeah that maps cantonormal form uh like this uh to this cantonormal form okay this is uh most example of a dilate so now let's go to the general definition okay so of course we heard today about this uh functor preserving uh Pullbacks and add co-limits over the directed diagrams. Okay, so this is one way to define the latest. Other way is to so other way is to define them in terms of the notation systems. Okay, so actually we also see denotation systems today, but systems today but that's what me uh remind you so um okay so the uh so basically the national system is a special kind of functor uh from linear orders to linear orders where we have a set of key that that is called um the set of denotations. We assign RTs to each told denotation. So this function S is this RT assignment function. is IFT assignment function and okay so basically and each order n of a should be should consist of all elements like this so we have this tuple we have C and then it's C applies to elements of A given in increasing order and so naturally We define how n acts on functions. And of course, we generalize the construction of omega x from the previous slides. Okay, so these are annotation systems. And so this is there is this result of Gerard that delayed this in this abstract sense, so this functor preserving pullbacks and directed collides. And directed collimates are precisely the same thing as functions that are initially isomorphing to denotation systems. Okay. Yeah. So basically this is essentially, of course, the trivial direction is to show that net systems are apprecio uh are the latest and uh so the important so the harder direction is the reverse one. The harder direction is the reverse one. And that is called normal form. So basically, we put the alright into its normal form up to just make it some naturally isomorphic function. Okay, and so one nice property of the energy system, at least defined as I turned here, is that they preserve substructure relation. So if you have, if A is the If you have if A is the suborder of B, then N of A will be a suborder of N of B. And also, of course, it's N resources identity. Sorry, except time to be so difficult. Yeah, uh okay, so now okay. Yeah. Now it should be okay. Yeah, okay. So now let's talk about embeddings of the latest. So yeah, since the latest are functions, the natural notion of embedding is a natural transformation. So yeah, so basically for people that are of course the standard thing. So but for people that are less familiar with Girls here, let me. Familiar with Ktigurcio, let me remind you. So, basically, a national transformation is a family of embeddings. So, at A, from F of A to G of A, side Z, for any F from A to B, we have the following diagram commutes. So, yeah, this is just national transformation. Yeah, but but so but on the level of denotation systems, we of course uh have this natural notion of embedding of denotation systems as structures. So, of course, so basically denotation system is so you could consider that it has its say the set of all denotations as its domain, so the set C. And then basically we have we have some additional structure on it, but yet we basically yeah we want to preserve it. So yeah, so basically this Yeah, so basically we say that variant detection is this map from CF to CJ, such as pursuit of IT and basically if you make this substitution of denotations according to this function e then it always gives us embedding of linear order. So this is the notion of the Yeah, so this is the notion of embedding denotations. And in fact, embedding denotations and national transformations are the same thing. So essentially it's a part of a general normal form theorem. So Okay, so now let me discuss the connection between embedding of dilators and functions from ordnance to ordinance. Okay, so here we actually are getting to this say yeah so to Yeah, so to to to the point w what is special about this embaying. Okay, so first of all, so of course any diletta induces a function from ordinals to ordinals, namely the function that maps an ordinal alpha to the ordinal or the type of d of alpha. And it's very easy to see that if a dilator f embeds into the latitude g, then this corresponding function the The corresponding function, the function corresponding to f is point once y is smaller or equal to the function corresponding to j. Yeah, this is very trivial because of course basically f of a embeds into j of a for each a and from this you get an equality of on order time. So it's trivial. However, so inverse inequality does not hold. So okay so it's quite so okay it's quite It's quite so, okay. It's quite easy to give an example. So I give it here. So let's F be the identity deletor. So identity deletery is just this, so this function that maps each A to A and the level of denotation systems. This corresponds to denotation where we have the only denotation and basically it's have IVT1 and it's have basically natural comparison. And let's be a different dentation system, namely, we have one denotation of IRAT0, so one constant, and one denotation of IRAT2. And also, so basically, there's some natural way to how you define the comparison so that it would be dilated. And so it's easy to see that basically, so as function on ordinance, they are like this. So f, of course, is just a dentif function. Of course, it just had empty function and g is this function. It's okay. It's not maybe it doesn't look extremely natural, but yeah, so but yeah, no, no, no, so as functional is this thing. And it's easy to see that in fact j is 0. or equal than f. Uh however uh it's also easy to see that f isn't embeddable to g. That f isn't embeddable to J. And the reason for this is that, in fact, yeah, so basically, if you look at this denotations, not as national transpiration version, but this embeddings of denotations, then it's easy to see that basically here we have one denotation of IIT1, and here we only have denotations of IIT0 and IIT2. 0 and I 82, and we couldn't map the notation of IRT1 anyway. So f couldn't be embedded. So, yeah, in a sense, there's embeddability in this more refined notion than just extensional comparison as ordinal functions. Okay. Okay, so now let's move to the discussion of the latest in second order instruction. Okay, so there are so particularly in So particularly in this talk I will present the latest in arithmetic beer denotation systems and so and the point is that okay, so so far I did not d define the certain kind of functor, but Functor, but in reality, so the way how it acts on all linear orders could be determined by comparison rules. So basically for each two denotations, C and T from Cm, we just need to define the way how we compare two tuples like this, given pairwise comparisons of X1, X. Pair wise comparisons of x1, xs, c and y-wise. Basically, so for given C and D, it's just some finite table of contexts. So yeah, so this is how we determine dilated by finite information. And of course, we this is so basically that system are showing kind of structures. So, and over RCS here, we could talk about this. Talk about this countable structures of this type that are included by set of nations. So it's pretty standard thing. And RCAC, it's quite natural to talk about the latest. And in the form of denotation systems. And yeah, and there is this classical result of JRA. So that the fact that omega x is delayed is equivalent to AC0 over recursive comprehension. Okay. Okay, so this was, I think, this is the most well-known result connecting AC0 and the latest. But today I'll talk about a bit final result of this kind. Okay, namely, okay, let's go to slightly the main result finally. Yeah, Yeah, so okay, so okay, so of course we have this delayed lambda x x plus one. This is just very natural thing. So we map A to this order A with one additional element, where this element top is just greater than any element of A. So this is So, this is natural way defines this. And then, so combining this dilator omega x and this dilator x plus 1, we could define this dilator xx lambda x map omega n to x plus 1. So basically, n is just basically what it means: that we have this tower of exponential of the high n. So, we basically iterate omega x n times, and then we compose it to be x plus 1. Yeah. Yeah, and so one could, of course, give a direct definition as just denotation system. So, namely, omega n to x plus one is simply this dilator that maps x to this depth and counter normal form, where its points on the very top level are either elements of A or just this top element. Okay, so yeah, so here we have this. Yeah, so here we have this first classical result about non-linear of AC0. And actually, probably I'm not that sure about the history of this. I probably saw Jensen himself have promoted this for AC0. And yeah, so this, but I'm not sure who exactly was first. But of course, Jensen have done the ordinal analysis of BA. So and here we this ordinal analysis of AC0 is kind of Of AC0 is kind of trivial consequence of ordinal analysis of PA. So, yeah, so let me attribute this to Jensen. Yeah, anyway. So, but basically, okay, let's formulate this. So, one way of formulating one of the ordinalized results for AC0 says that if for some reasonably represented linear order A, AC0 proves that A is a well-ordered. zero proves that a is a valid then a is embeddable into omega n for some n okay and so and okay usually one state that it's less than epsilon zero but it's the same thing of course and and so and our assumption is is that if AC0 proves If AC0 proves that D is a deletor, then D is embeddable into lambda x, omega and 2x plus 1 for some L. And so going back to the talk by Juan, so of course Juan could interpret this as a result about the calculation of the proof stating the latest of AC0. Of ACU, namely this would be the dilator epsilon plus. So epsilon plus is this dilator that maps x to the sum of omega n x plus 1 over all natural number n's. And this is a proof-serving dilator of AC0. So this is this embeddability least delayed such that any AC00 probable dilate is embeddable in this. So let me comment on this result. So of course it's very easy to conjecture that such something like this holds. So because yeah, it's so because it's basically just more by a more standard technique, one could easily show that so if you have here AC0 plus plus you add to it some statement that something is a balloon. Statement that something is a beloved, then the ordinal some A is below, then the ordinal of the theory will be epsilon plus from of the order type of this beloved A. So this is so basically if you just look at this extension, so if you say just look at the question, so gi gi given so yeah so w w how how How AC0 so basically, if you consider AC0, this operator that map perloaders to prove CD coordinates of the series AC0 plus the sync is veloaded, then of course this will be this corresponding function or noise will be epsilon plus and this could be shown by the more standard technique. However, what we I have here is more as we discussed in this slide about this connection between delayed Connection between delayed between embedding of delayed and ordinal functions. In fact, this result here is final one. So here we actually talk about not just this extensional characterization of this AC0, but it's more refined classification. So basically, we fully classify all probable dialysis of Okay. But yeah, well, the result is so as one would expect. And in fact, I think the main contribution of this work is the development of the new techniques that allowed us to prove this. So this is what I actually want to talk about today. So may I ask a question? So why do you need this x plus one? X plus one. Ah, cool. It's very simple. It's very simple. Imagine that X is an epsilon number. Yeah. Okay, first of all, imagine that X is an epsilon number, and you notice that without this, you basically don't move to the right order, right? And second, if you don't add plus one, then you. You don't add plus one, then you get a normal dilator. And basically, if you want to specify all dilators and not just normal dilators, that by necessity we need to break normality because the things that are compatible with normal dilators are just normal dilators. Okay, very good. Okay. Yeah. So, okay, in part, the m way how we prove uh this result about compatibility is kind of a more refined version of uh the usual ordinal analysis of AC0. So let me remind how usually the ordinal analysis of AC0 is done. So okay so basically okay so here here what we want to prove. So we are given some arithmetical linear order A such that AC0 proves that A is well founded. That AC0 proves that A is well-founded. And then we want to show that A is embedded into omega n for some n. Okay. So first we have this consideration result between AC0 and theory P of X, where P of X is just remote device version of P, where we have this additional free unary predicate letter. Free unary predicate letter something is an M element of X. Okay, so this consideration is that so if AC0 proves that for X Phi of X, where phi has no second-order quantifier, then this theory PA of X proves phi. So it's a very simple conservation result that one can prove by very simple model CAD Kartman. Okay, so then basically when you apply a Basically, when you appl appl apply apply apply this conservation for the particular statements, A is well founded, what you get is this probability of the set. So if X is progressive set, then all elements of A are actually elements of X. And so progressivity means that basically just premise of transferant induction. So basically, X satisfies the premise. So basically, x satisfies the premise of transferant induction. Okay. Away. Okay, so this is basically what we get from this probability for an HCL. So the next step is embedding of P of X into omega logic. So the embedding process, so if phi is provable in the pair of Is provable in the pa of x. Then we say basically what we get is that phi is provable by an infinite omega proof such that its trunk is rather small, so it's just omega times two. And the cut trunks are bounded by n. And so basically this is done just by giving explicit infinity proof for all the axioms of Infinity proof for all the axioms of P of X and then just say combining them by and then you have a finite proof figure in P of X of phi and then you just from the axioms and then you just transform it to this to the same figure in omega logic and combine this with proofs of axioms. And this is how you get this now. Okay, so then there is this cut elimination for omega logic. Oming the logic. So basically, trade off one level of cuts by one expensation. Okay, thus, so basically when we iteratively apply this thing, we get something like this. So actually here I even forgot there was two and replace two with omega, but it doesn't matter. But it doesn't matter. Yeah, so we have a probability of the same as your inomic logic by now by a catch-re-proof. And there is this important fact about a probability of this kind of statement with omega-logic, known as boundless lemma. The state that if you basically, if you have this cut-free proof of the founders, so and this is a cut-free proof of the founders, or Of some linear order, then this linear order is in fact embeddable in the rank of the proof of those valves. Okay, so this is more basically standard thing. So, okay, so now let's discuss what we need to modify in this roof. And this is actually, I think, basically more or less all the status steps, but this, I think, just But I think basically the general plan will be still the same. Okay, so first we will need a replacement for the theory P of X and the replacement for the theory P of X will be the theory KPU OX. And so what is it? So basically it will be a variant of KPU. Okay, so we have the theory and the language of KPU and basically we consider your elements to be Consider your elements to be some kind of linear order. So basically, we have this in addition to membership, particularly between sets, we have this less than relation between your elements and so and else and so as in the case of PFX, we actually add this free predicate letter x and actually it will be there for the same per more or less the same purpose. The same per more or less the same purpose. So we have the spirit x and okay. And the actions are the action of KPU, axioms that less than this linear order on your elements. And finally, we want to state that actually it's not just linear order, but that it's a velo ring of your elements. And this is stated in the b best possible way in the setting, so by stating the scheme of transfine induction or or or or over your elements. Or or over your elements and the order less than. So yeah, so this is our theory. Yeah, and of course not so sometimes people include into the crypto part theory axiom of infinity and we don't do that here and in fact we explicitly don't be interested in the situation. Be interested in the situation where all sets are finite. So basically, here basically GPU stands just for some reasonable theory of finite sets and could have been other choices. And basically, the only reason why they use it is because it's, I think, most well-known theory and doesn't do what we need. Okay. Okay, so now now we are going to this uh step of going from AC0 to KPU. Uh okay, but uh okay, so actually we'll do it in two steps and uh here what's important i i i in is is that we actu we extend KPU, uh version that we had before. The version we had before by addition by additional binary relation E. And the axiom that E, so basically E is a graph of an ejection from Euro elements to the class of national. So basically, we explicitly state that the class of your elements is at most countable. Okay, so basically you have Okay, so basically we have this kind of modified version of the story KPU. And then the connection that we have is that if AC0 proves that some arithmetical D is a dilator, then basically inside this modified Q, we could internally prove that D of O is a dilator, and so O here is simple. Later, and so O here is simply this, so basically, just this order on your elements. So, O is ordered on your elements, and so basically, yeah, and so, of course, then d of O is this inter, of course, it's internally definable thinking in this invariant of KPU. So, basically, of course, basically, we represent the denotations that are in this D of O as appropriate sets with zero elements. So, basically, if you remember the denotation, the denotation, so application denotations. So, application denotation system to some order order denotation, and all other components are elements of the order. So, in this case, these elements of the order are just your element, the denotation is some natural number. And of course, we could represent this kind of tuple in the theory QPU. Okay, so then of course we can talk about this D of O and then basically. G of O, and then basically, what we have here is that we state that it's G of O is so well founded with respect to this fresh predicate letter X. Okay, so basically we do more or less the same thing as before in the case of P of X. So, yeah. But now instead of just linear order A, we go from dilated D to this linear order D of O and now it is the thing that is. And now it is the thing that is probably founders. Okay. Yeah, okay. So now you can consider the model QPU provides this premise. So okay, this would be progressive, not some problem. Anyway, yeah, so it's just PLG. Okay, so yeah, so basically we have a model of we can see the sub model. We consider some model of KPU, and then we go to essentially go to model zero as follows. Namely, we so the first order part of the model will be this natural numbers in the sense of the model of TPU, and the sets will be just m definable subsets of naturals. And of course, so now since Of course, so now, uh, since so, and here, of course, was important to add this countability assumption. So, because if we have explicit our fine our say function written in countability of humor element, then of course all is just projected into natural numbers by our function E. And hence, all is simply internally isomorphic to just some order on nationals, and of course, because it was. And of course, because it was O in turn was satisfied with the transfine induction schemata into this model with definable sets, it will be blurred in the sense of this model. And here, here, and seeing the model of model of AC0, and we know that this is AC0 blue ball dilator, here the application of D to the sort is also internally beloved. And okay, since basically this gives us our claim that it is so that it is X. So it's X below with respect to particular definable set X. Okay. And so. And so this is basically this way by this model the conception you prove this connection. Okay, so now but yeah but in fact we don't want compatibility it's so it's not what we w sorry it will be we wouldn't be able to embed our system if Able to embed our system with this additional accountability assumption, so we need to get rid of this. And we get rid of the accountability using forcing. So, this is, of course, something that one didn't need to do in the case of ordinal analysis of user ordinal analysis of IC 0, but now we need to do this. And yeah, and so by it's very simple. So, what we want to do is kind of forcing. So basically, uh forcing here is not the forcing in the sense of set theory, so we don't want to che change our set structure. Basically, we use forcing simply to define additional functional symbols. Okay, in the case in this case, it will be just binary validation and basically our first thing we completely preserve all this CPU of uh or extraction. Of extraction and simply do something non-trivial only for additional fun, additional binary predicate ek. Okay, so our forcing conditions are finite sequences of your elements and extent as and the order of them just extension order. Okay, so you preserve atomic hormones and basically we consider this. If you consider this fine sequence of arguments, this is basically an initial part of our function, right? So basically, so we say we think that if basically you know that as it is as i is some your element, then we map this your element to the natural number i. To the natural number i. So, this is how we treat our forcing condition. And okay, and this is basically different to this natural forcing. Okay, and so I do it away negative fragment. So, basically, forcing relation will be classical. Yeah. And yeah, and it's else because you don't do anything about other predicates than it will be short there is no. Okay, and one could show that this forcing relation forces all axioms of the theory with contability. And hence, basically, due to this result, in fact, we could improve the lemma from the previous slide to the lemma about the theory results. Slide to the lemma about the theory without countability assumption. Okay. Okay, so now we need to go to infinity proofs. In our case, our infinitary proofs will be this proofs in HFA logic. And so HFA logic is simply this infinitary logic, buttons basically instead of national numbers. Our structure will be the structure of hereditary finite sets. Her desired finite sets over a given linear order A. But otherwise, the same thing. So it's not much to discuss here. And yeah, so basically we derive this sequence that are just sentences with the concept from HF of A. So we have usual interaction rules and the interaction rules for universal quantifier is simply is simply this okay so it's under direct and local omega rule so just now it's not omega rule but it's a hf a rule okay so smaller standard thing and you have of course we have uh cut rule okay okay so it's uh okay yeah this shouldn't be here because we are working it's a mistake so there's no additional can you Mistake, so there are no additional conditions. Okay, um, okay, so just usual cut rule, nothing special about it, and uh okay, and so basically, so you HFA proofs are just well-founded proof trees in this logic, and if done require proof tree to be well-founded, that it will be a pre-proof. Yeah, okay, so now. Okay, so now what are beta proofs? And beta proofs, of course, are simply and we can see the beta proofs in this HFA logic. Okay, so basically the beta proofs will be this uniform families of proofs over all X. Yeah. Okay, so basically we were that is very rational, so we That is very national, so we basically if you want a bit of proof, some proofs that's the families of proofs PA for all linear orders A such that they agree well with the morphism. So, what this means is basically you have this for any morphism A to B, you could naturally define what this image of a proof under this. Image of a proof under this function. So basically, what does this image do? It just simply replace all your elements with other your elements and keep all the other structures the same. And of course, in principle, this map could break the proof, namely it doesn't work well with this introduction of universal quantifier. However, what we want is just kind of so that we always, this F always map. Always this F always maps a proof PA to a sub-tree of PB. So, this is what it means for a proof, this family of proofs to agree with each other. Okay, and so finally, so because so we want to connect proofs with particular concrete dilators, we actually want to have bit to proof that it's where we have ranks bitness by elements of particular diletta. Okay, so basically a ranked bit to pre-proof this P F rho is this following structure. So we have here F is summed alight and basically it just and rho is this assignment of rank. So basically what we want is that we want to have this family of proofs and we want to have to have this unif to have this assignment of ranks in F of A. Yeah, and yeah, and of course we want to again we want to that course we want to again we want that simulus to to be this nice sign that so computes with all more things that yeah so all the standard stuff so basically basically now it's more or less usual infinity family of this usual affinity proof we have explicit information about this ranks in particular nodes and okay so and then we write something that's so basically And then we write something that's so basically write that gamma is beta f and provable if there is this rank pre-proof pf raw. Yeah, okay. And so of course it's bit to provable if we have probability for some delatinism. Where the rank is a delator. Okay, this is this is your bit to proofs. And yeah, by more or less standard technique, you could embed says system keep you in. KPU in beta proofs. Yeah. Okay, there's some particular bound, namely this ordinal. Okay, this is deleted. And yeah. Yeah, okay, so basically, basically it's most okay, nothing special happening here. So basically, just need to take good axioms to verify. Take good axioms to verify, and the good axioms are this one. So instead of verifying the QPU, which we have a lot of axioms that are not that easy to verify in infinity logic, we take the other system where we have axioms that are easy to verify in infinity logic. So namely, axiom of empty set, axiom of adduction. So for any A and X, we could add element X to a set A. And then we have adduction induction. So yeah, somebody This uh some very classical way of talking about um uh um structures of hereditary finite sets. Um so yeah so basically just induction for this uh so basically where we progress over adductions um okay and yeah but basically this is uh since we prove a lot of using this basically when we have this adduction for arbitrary formulas we could prove a lot of things Foremost, we could prove a lot of things about these hereditary finite sets. And in particular, we could verify all the actions of KPU. And of course, so basically, this is kind of strongly theory because it forces the sets to be finite. And then it's very easy to verify these actions in this infinitary proof. And then it's basically when you do it the natural way, actually, this proofs will say they will be functorial families of proofs, that everything could be fine. That everything could be fine. Okay, so this is how embedded works. Then we need to do cut elimination of in bit to process. And again, nothing special about this. It's more or less a standard cut elimination. One just needs to be careful what exactly does it mean. So, because of course, now we want to talk, naturally, we want to talk not about just bit of rules but a bit pre-proofs yeah so one should be careful but basically the so the point point is that so cut limit so you could so of course probably the more more easiest way to think about calculation is from axiom so basically do some transformation from the axiom by this complicated transformation but other way to think about it that actually we transform Actually, we start we transform proof from its hex. So basically, we start with the conclusion and start to do something from this root root, and then yeah, and then somehow transformation moves upwards in the proof tree. And okay, so this is more formally one could think about the pre-proofs as a co-inductive data type, and so we define that cat elimination by correcion. Yeah, but basically it's more than the standard thing. Yeah, but basically it's more than the standard thing, so uh nothing uh um interesting really happens here. Okay, so I think uh so most say uh probably the most interesting so progress in this um uh so in the whole whole proof was this proof of um this bit about miss lemma. Okay, so what it does it say? So it says the following. Uh so consider okay, so can see again this arithmetical denotation system G. Denotation system D. Okay, and now basically we want, since arithmetical, we basically could just consider this to be considered to be atomic formulas in the structure of HF of A. And so now what you show is that basically if you have this bitter proof of well-foundness of DO4. And f is dilator, then b is embeddable into slightly more complicated dilator, namely this one: omega plus omega square time f of x. Yeah, okay, so how it processes. So, uh yeah, so ba b b basically the point is that uh uh view Is that so? We need this notion of simulation. So basically, simulation of one order, another one is basically people can basically this notion is mission from theory of transition systems. But anyway, so basically simulation is as bad. So basically it's kind of in the terms of overlords. Of you know, we have a lot of things that like basically for each element A in A, we assign the set of embedding candidates inside B. What this means is that for any A, we have at least one B, such that B is an embedding candidate. And basically, if we have some A and some smaller, some smaller meant A prime, and there was embedding candidate B for A, that there is an embedding candidate B prime for A prime, such that. B prime for A prime, such that B prime is smaller than B. And basically, if B was ever lower, then we could, so a simulation gives us an embedding. Yeah, so basically this mu R is this embedding. So basically, we map any HA to the least possible embedding candidate. Yeah? And then we have this functor of basically this functorial families of simulations. So basically, the simulation of prior lattice. So basically this is a simulation of prior lattice, this functor is final simulations over all linear orders A. And basically it doesn't require just requires this commutation with the directed collimits. Okay, in general, basically if you do, the problem is that if you generally do this minimization, you don't to the structural theory of simulation, you don't get natural transformation. However, basically, if you go to this Uh however basically if you go to this again go to slightly larger dilator actually you do. So what this holds is that uh if you have f and j dilators uh oh no sorry this is the type of so basically this mu so basically we apply this dilator omega plus omega time sample. So basically what I should write here is that it's not at is not transformation from f to g but it's transformation from all formation from omega plus omega f to omega plus omega g so basically uh yeah so basically we go from transformation we still go from the simulation to the natural transformation but it's not of the original element but slightly large one but it will not matter and so now okay and so and okay so and that uh why we needed this net uh natural transfer um uh National transforming in the simulation was that basically a careful inspection of the usual proof and boundaries, lemma gives simulation. So we don't get an embedding of the latest, but however we get the simulation of a dilator d in the dilator lambda x, omega times f of x. And okay, and so combining this lambda, And so, combining this lemma with this factor about simulation from this slide, we actually could get to our original boundaries. Yeah, so this is basically where this transformation of coming from. Okay, and now finally proof our main theorem. Okay, so basically, okay, so our theorem is so if D was actually zero proof of the later. Then basically should contain D. Then D is embeddable into this iterative omega tower of X plus one. Okay, so basically we do like this. So basically as we prove, so the probability that d the delta C0 implies probability in QPU or X of this internal of the U.S. Of this internal actual orderness of D of O, then we embed KPU proofs into a beta proof and then we embed so then we do cat elimination and then we do then from cat elimination we get an embedding as we discussed. As we discussed, oh, oh, sorry, okay, it's again a typer, so it should have been just the last technique should have been the embedding that we actually need. Okay, okay, so this is how the proof goes. So, as you could see it, kind of modification of this standard proof plan. Yeah, okay, and so again, so to get so about I could again. Okay, so about I could again comment about this comment of Michael in the end of Hansdork. So again, I guess, of course, so if you consider some much strongest, you will say something like KPI. And then you, of course, you have this indeed kind of this natural dilemma that it corresponds to AC0, to this KPI in the same sense that epsilon plus corresponds to AC0. So I am more or less sure that. I'm more or less sh uh sure that basically it will be appreciated later in this in in uh in in this sense, but of course one will somehow to combine the techniques that uh yeah, so we used here to these standard techniques of theories like KPI to really uh get this kind of results. So some by some one will need to say have a more refined version of this original analysis. A more refined version of this original analysis. Okay, so it's more or less everything that I wanted to say. Alright, thank you, Theodore.