This is me, it's my talk. Okay, so you know, I've observed some similarities, or at least, you know, synergies between blockchain and data science. You know, both of them have, I would say, interdisciplinary perspectives. Sometimes, you know, when you talk to people, they're like, you know, what's new about blockchain? It's distributed systems, right? An electrical engineer might say, or, you know, an economist might say, oh, it's just Austrian economics as a network, right? But I think all those perspectives are very, very important to actually fully understand. Are very, very important to actually fully understand what's going on there. And data science is certainly like that as well, incorporating machine learning, computer science, statistics, domain knowledge, tremendously important in data science, all these good things. Another sort of important thing to note is I would say both blockchain and data science have, I would say, a focus on the practical aspects. They both, I would say, originated from outside of academia, although ultimately. Outside of academia, although ultimately based on theories that are in academia, certainly Bitcoin came from outside. Data science, I would say, has been brought in through observing what occurs in business environments and then the study of that. So that's, I sort of, you know, sort of said this already, that interest in both of these topics has been driven by observing what is worked in practice rather than starting. What is work in practice rather than starting with a theory? Although, you know, I guess both do have theoretical foundations as well. So, what are the two perspectives that I'm going to talk about? You know, one perspective is using blockchain for improving the practice of data science, specifically the integrity of the data science process. And I'll sort of talk about what the importance is there in a moment. And then, you know, sort of flipping it around, right, to say applying data science now to blockchains, which I suspect. Science now to blockchains, which I suspect is, you know, I mean, we had a very good talk earlier about that, about the analysis of, you know, on-chain transactions. So I'll be talking a little bit about both, mostly the first one, because I think that that's possibly new to some folks here. So yeah, first we'll talk about using blockchain to improve the integrity of the data science process. So why is this interesting? Why is this relevant? What do we need to fix about data science and perhaps more broadly? Data science and perhaps more broadly science in general. You know, this is a little op-ed in Nature a little while back talking about this sort of a disconnect in trust between scientists, decision makers. We're definitely seeing this now. You'll see there's a lot of parts of this talk that are kind of very topical. Although, most of this material I did about two years ago, or sorry, three years ago, when nobody cared about epidemiology or academics or pandemic, it was sort of a low-point interest. Interesting as. It was sort of a low-point interest, interesting as for the back. Anyway, you know, according to some surveys, up to 33% of scientists admit to questionable research practices. I mean, I'm sure you've been aware of colleagues that have sort of pushed this envelope. And this sort of thing can be tremendously damaging to society, right, when it occurs, especially in the health field. There's a widely perceived, I guess, let's call it a, this truism that, well, not a truism, but certainly. Not a truism, but you know, certainly there's a rumor, let's call it, that vaccines cause autism, it's done a tremendous amount of damage. There's diseases out there that should have been eradicated, which now aren't because people are afraid. And it remains to be seen, you know, with coronavirus, I'm extremely curious whether people will be more afraid of the virus or the vaccine. So that's, I've got, let me eat popcorn to watch that one. So, you know, you know, there's a multitude of reasons why a lot of experiments are not reproducible, right? Are not reproducible, right? I'm not saying that certainly what I'm going to talk about today will magically make all experiments reproducible, but perhaps it'll address some aspects of why they're not. What are the implications for data science and evidence-based decision-making in general? So we'll be talking about those things. So, this is a group, I feel, as a group of experts on blockchain. I'm not going to spend a lot of time on this, right? I'm just going to talk about blocks. Usually typically, there's a header, a data route. Header, a data root, meaning here's sort of the payload down here. The data root is essentially a pointer to that, oftentimes a hash, and then there's also some kind of reference here, again, usually a hash to another block. So we can extend this to be a chain of blocks. This is the newer blocks here. They're added to the tip of the chain. Older blocks are going to be to the left. I'm going to stay with that consistency throughout these slides. So how, you know, perhaps the most Perhaps the most obvious way that a blockchain could be used to improve the integrity of a data science process would be to commit data and different artifacts that are generated throughout a data science project and commit those to a blockchain. Commit those, you know, so an example would be starting with raw data being collected, a data set being collected, right? A stakeholder, these could be different stakeholders. They could all be the same stakeholder, right? They would do Holder, right, they would hash that data, create a unique fingerprint of that data, and digitally sign a transaction and put it inside a block. Later on, somebody may create a model, create some model and analytics with that data. And again, whoever's doing this can do the same thing, hash that code, hash the model, put the data up there, sorry, put the model up there. And what I'm trying to note here, though, There and what I'm trying to note here, though, right, is you know, if this was like a public multi-use blockchain that's not exclusively for this data science study, there may be different data that appears in these payloads, so it's often important to also have some sort of reference back to the previous data payload that was there, right, so that somebody could look to the eventual output here. So, here I'm talking about having meeting recordings and having things like at the end the evidence and the recommendation. Like at the end, the evidence and the recommendations, which is perhaps a report, something else. And what somebody could do is go backwards from the report and go back all the way and see how the whole process kind of unfolded. So that's sort of perhaps kind of an obvious idea. However, one thing to note is there's been a tool. I don't know how many of you are kind of programmers or familiar with Git, almost every sort of GitHub. Almost every sort of GitHub, right? GitHub is sort of like a, you know, kind of a Facebook for coders, right? But any, what Git actually is, is a decentralized protocol, much like a blockchain, where very much so you're able to, you know, create a fingerprint of whatever blob you have, whether it's code, data, text, whatever it is, and you can do the same thing, hash, and put it into sort of new commits in this Git chain, right? And going from the final commit, which is And going from the final commit, which is the end state, all the way back to the beginning. So, a question like this is maybe it's not too early to give the group a quiz, right? What value would a blockchain add to this? Because we don't need a, we don't, sorry, blockchain network. I'm sorry, I should have been missing a word here. They should say blockchain network, right? Which is this network of computers. What value would that add here? That's not, if I was just committing stuff to my Git requirements. Committing stuff to my Git repo. Oh no, that's very close to it. Yeah, yeah, actually, let's go with that, right? If I didn't have this blockchain network, what I could do is I could actually go ahead and create multiple histories in parallel without revealing them, right? And then one day later on, I can then publish the result that suits me post hoc, right? Forget about this one, and publish this one, right? And then, you know, it shows the chain going backwards. Chain going backwards. But what a blockchain network does actually is the blockchain network, the network of computers, the value add there is it provides consensus on time. And each of these entries is actually time-stamped. And everybody agrees on when these commitments were made. So by being time-stamped, it's very difficult to sort of undo this process or unline this process. I have a pedantic comment that. I have a pedantic comment that all the times are the same here. It could be the same time on different days. It's a coincidence, right? Those are different days. Same time on different days. So why is it difficult to achieve this in GitHub? Because in GitHub, right, or Git, forget about GitHub. GitHub's a little bit different. Git simply, right, what I could do is I could create any number of these histories and then only reveal one because Reveal one because they're not published in general. Okay, so the problem is it's not published, so we can only approve the successful one. So the problem is resolved as long as it is published to the. Yeah, and I can still go ahead and very much pick and choose results of simulations to tell but also in Git you can change the history. Or start a new history, right? Or who knows what happened to modify it here, you cannot. Perhaps you can modify it here, you cannot. Well, in Git, so going back, right, I mean, this is virtually the same thing as Git, right? Let's start here. Git does have references back using hashes, right? So one can follow from the other, but I could go ahead and start over again as many times as I want. That's the trouble. Yeah, yeah, and again, I don't want to dive too deep. I just assume you're not actually storing the actual data. No, just a reference, a hash. Blockchains are not good general purpose data. Blockchains are not good general purpose data. This is what we're also doing, and the other element besides the provenance, I think the ability to manage, to have access control and add over. Those are like higher order features that could be added on here. This is just talking basic, certainly. I think they were on the same page. The only thing which again, with the time, it's a delicate issue. It very much depends on the consensus algorithm and other Consensus algorithm and other things. Typically, when it's research data, you wouldn't have a problem, but we do know that depending on the consensus algorithms, malicious miners can suppress for a certain time certain things. But I don't think this applies here. Yeah, certainly we could do this with a public blockchain, right? And then we're assuming that somebody's, let's say, bribing Bitcoin miners large amounts of money to sort of fiddle with this. But that's, you know, we could always see a reason. With this, but that's, you know, we can always see a reorg, right? We can always see a chain reorganization where somebody wrote a different history there, right? So that would be, it would be evident, right? Which is sort of. But again, especially the management features you can build on top of them, they are going to be key in all data science things because as soon as you deal with personalized data, personal data. Yeah, I mean, that's sort of, I would say that's a partially orthogonal issue, and that often perhaps, right, perhaps if you're dealing with medical data, which is going to be my sort of use case here eventually. Of use case here eventually. You don't want to publish the raw data, right, which could include medical forms that are unredacted. That's technically raw data, right? Like, you know, the processing almost always occurs, right, between the point of data, actual, the raw data and Saskatchewan, for example, is a big issue is with indigenous communities. So how do we ensure the NCERC rules that every, so even if you have consent for So even if you have consent from individuals, there will be still the First Nation or the Métis community which can override things. And here it's very, very nice, especially if you, as you said, have just references. I can cancel, I can control, I can grant override features, right? Absolutely. So again, you know, quiz number two, what could go wrong with this? This seems all great, right? What's the, you know, you know, maybe a blockchain, one of the interdisciplinary features or disciplines that goes into it. Or disciplines that go into it is cybersecurity, right? Which involves adversarial thinking. That's sort of a clue as to what could go wrong here. What can an adversary kind of do here to mess with the system? Well, one thing I'm interested in always is suspicious transactions because I have fundamental problems basing the whole security model on a public-private key principle and assuming that the private key can never be lost. Or we're touching on it. I don't want to belabor this. We're touching on it. I don't want to belabor this, right? Or coercion, right? Which, you know, I mean, even if we had this system in place, right, going with this pandemic scenario, there could be pressure here from people with guns or something to say, write this data to the blockchain and sign it, right? And what's this person to do, right? They'll probably comply, right? Compromise the platform, right? Your mobile app or your other platform, and that's the problem. That's a possibility, too, right? Yeah, that's a good point, too. That's a good point, too. So, where does this wrench attack? This is a little bit just taking things on a lighter side for the moment, right? Why did I have a wrench there? This is sort of a famous comic in cybersecurity. I'll just still give people a moment to read. I won't try to read it out. Yeah, so the idea, right, is there's always a way around, right? That's where adversarial thinking comes in, right? There's always a way around through the side door, right? In this case, the notion is that you would just, you know. The notion is that you would just, you know, threaten or otherwise coerce someone into doing something with their keys revealing or signing things. So I've been building up to this idea, right? You know, with this sort of, I will call it a framework I've sort of presented, we can achieve what something is called radical transparency. And if you can actually Google this term, it's a relatively new term. And the folks that are coming up with this, they're sort of, you know, these. Coming up with this, they're sort of, you know, these are blockchain network designers, right? And it's sort of a different paradigm, right? Where you know, the idea is that they want to be maximally transparent about what they're doing. So there's a lot of insight into the project, are funds being spent correctly, what's being done, all these things. So I'm going to talk about this idea of radical transparency. I've sort of shown it there earlier with this idea that all of the data, as much as possible, including things like meeting minutes and Like meeting minutes and recordings, and basically anything you can, you put up there to make it available. And that's this notion of radical transparency. So, the way I'm going to frame it, actually, is talking first about evidence-based decision-making, right? You know, when we talk about data science, what's data science for? Sometimes in academia, we think it's well to write papers, right? But, you know, again, this stuff comes from the business world, the practical side, and it's actually used for evidence-based decision-making. For evidence-based decision-making. And this is perhaps a canonical loop, or at least one that we use in the public health decision-making space that I've seen. So beginning with data, what you can do is take that data, upgrade it. They call it the new oil. You upgrade it and you generate knowledge and evidence from that data. You make a decision based on that knowledge and evidence, take some action, and collect more data. And collect more data. It's a loop, right? You collect more data based on what actions you took, and it really never ends. It's sort of a, you know, we mentioned complex adaptive systems before, right? This is definitely what we're going to dive into. Then there's also, you know, in data science, right, there's also this notion of descriptive models, right, where you have a model that can sort of accurately store and retrieve different information about a system. Then there's what we talked about earlier, which are predictive models, right? Earlier, which are predictive models, right? Using machine learning, statistics, other things, you can predict the future. Is the price going up? Is the price going down? Is this different kind of predictions? And at the highest level, the stuff that's actually often used for evidence-based decision-making is in fact prescriptive models, a model that suggests a course of action or allows somebody to explore a whole host of possible outcomes from choices and being able to. From choices, and you know, being able to perhaps choose the best of those. So, yeah, we're so what I'm going to be talking about is this part of the decision-making loop. Not going to be talking about action, like the actuation of these decisions is sort of left outside of the scope for the moment. And I will be focusing also on prescriptive type models for this particular example. So, I'll just sort of zoom into this quickly, right? I don't want to spend a ton of time on complexity. I don't want to spend a ton of time on complex adaptive systems, but the motivation is that many social systems, including healthcare systems, the spread of infectious disease, these are often characterized as complex adaptive systems. Classically, in engineering, if you have an engineering background, you might have heard them referred to as dynamical systems. And often, these can be analyzed using systems of differential equations to solve for the behavior of such systems. However, Such systems. However, past a, I would say, a small level of complexity for very small systems, it's possible to treat them analytically, but oftentimes you have to create computational models or machine learning models or other types of models to handle complex adaptive systems beyond sort of trivial ones. Sorry, I think I missed the slide. Yeah, so complex adaptive systems. Yeah, so complex adaptive systems have some features that are common to most of them. There's path dependence, which means that history is very important. There's sensitivity to initial conditions, emergent behavior, memory in the system, which has to do with path dependence. Features a lot of non-linear relationships there. There's often feedback loops, which lead to generally difficult to predict systems. Systems. So the way that oftentimes complex adaptive systems are approached is through simulation. So that I see as being a big contribution of simulation in general to data science, getting further to the right of that sort of progression to create prescriptive models. You really have to have a good picture of the system. So for that, Picture of the system, right? So for that, oftentimes you're creating a fusion or you're combining different models that you've created in the earlier steps of the data science process and also combining different data sets that you've brought in. So these models are often called integrative models in that they're integrating different parts and components. And when you create such a model, you basically get a good idea of whether or not you have a coherent picture to hold, right? If you've got one sub-model telling you this thing, another sub-model is telling you this thing. Another submodel is telling you this thing, those don't reconcile, or those don't work together. That really tells you that you probably don't understand something, right? Or that the data is bad or something. You need to go back to the drawing board and revisit that stuff. So this lets us investigate causal relationships, which often different methods, other methods have trouble handling causality. What-if analyses, identification of gaps in knowledge, like I just described, if your models don't make sense together. You know, I see. I see simulation as sort of being complementary or a dual to machine learning methods. Oftentimes, machine learning methods have predictive power, they're very good at predicting, but we don't really understand why that prediction is successful. It's sort of prediction without insight. These models are different, right? There's a lot of insight that goes into them. So my case study, as I mentioned, it's very sort of timely now. This work's about three years old. Now, this work's about three years old to be honest. So, you know, I'm going to talk a little bit about basic epidemiology here, right? Which is perhaps again very topical. The classic model in epidemiology, which is the Kermack-McKendrick model that came out at the turn of last century, is a differential Lagasian model with three compartments. There's a susceptible compartment, which means these are people, individuals that have not had the disease, and they are susceptible to catching the disease and becoming... Catching the disease and becoming infectious after that, affected/slash infectious. In this very simple model, which is also called SIR model, based on susceptible infectious recovered, you know, these infectious individuals, if they come into contact with other susceptible individuals, can probabilistically infect them. That's what this beta is here, as the probability of transmission. Sorry, you shouldn't say it's a probability. You shouldn't say it's a probability, it's a coefficient. And then, so once some time elapses for that infectious individual, there's oftentimes an infectious period, which is an epidemiological term. Usually, once that elapses, the individual goes into the recovered state, at which point they cannot be infected again because they have a built-up immunity to whatever the disease is. Clearly, in the real world, these states are sometimes often fuzzy. These states are sometimes often fuzzy, right? Oftentimes, recovered individuals can catch the disease again or a different strain or these different things. Also, you know, with this coronavirus, this novel coronavirus that's going around, there's also something called an asymptomatic period here, where the individual can infect others but doesn't have any symptoms yet. So there's all kinds of different elaborations on this model. But the basics are there. Does anybody have any questions about this basic formulation of a disease model? Okay, the idea, again, is, you know, there's not just one individual in this system, right? Clearly, there's many individuals interacting with each other. So, how does that look? So, I sort of showed the differential equation model, right? But, how do we approach this with sort of modern data science eyes? Eyes, right? Actually, bring it with me. I brought one with me in case you want to see it. I brought an IoT device called a sociometric badge. And this is an open source, open design that I didn't create. It's called Open Beacon, actually, if you want to Google it. I think these things are still available for purchase. And it's sort of a coin-operated, sorry, coin-battery cell-operated little printed circuit board that has Bluetooth on it, right? And when you come within a few meters of somebody, Within a few meters of somebody else, approximately actually, interestingly, the infectious distance they're thinking for many transmissible diseases, including coronavirus, these devices will read each other's Bluetooth and generate sort of a connection and a graph, if you will, that you sort of collect over real time. Certainly, this kind of simulation approach leverages Internet of Things, I would say, cellular automata-type models, type simulation models. Automata type models, type simulation models like that with discrete states rather than being numerical models purely. And also, this involves Monte Carlo simulation where clearly one realization isn't enough. You want to really understand the behavior of the system under a number of initial conditions. We talk about R0s, but this actually is not the reproduction numbers and things like that. Maybe we can take offline if people are curious, but it's not really that relevant to this talk. So, the specific kind of modeling approach we Kind of modeling approach we will demonstrate here or show is the agent-based modeling approach, which basically models individuals in the system as agents, which are decision-making entities that have rules that relate them to other agents as well as the environment. So this is sort of taking an expert systems approach where data or information about how people behave is impacted. About how people behave is imputed to a certain extent, and any IoT data is used to sort of parameterize those behaviors as opposed to prescribing those behaviors. We can get into why that is perhaps offline. So, yeah, I mentioned this already. So interestingly, these models, these agent-based models, are both expert knowledge and data-driven, a combination of those two things, which I think is kind of interesting. So I feel I should explain these a little bit. This is where the cellular automata kind of This is where the cellular automata kind of analogy, if you will, or comes across. This is actually a simulation of a northern Manitoba community that I did a few years back just to show as an example. It does resemble a cellular automata. Each cell here represents a location with one or more individuals. So some of you may be able to see if you squint, there's a couple dots in this square here, that's basically showing multiple individuals in common. You know, multiple individuals in contact at that location. So, I'm just trying to give a bit of a flavor as to what these models are like. So, this is where the blockchain actually fits in here. So, I created something a few years back. This is actually for a hackathon, and I got this, you know, a brief paper published in this simulation conference. The idea being, so, again, this is that decision-making loop: data, knowledge, decision, and actions. You'll notice there's not a lot going on down here. There's not a lot going on down here, right? I didn't really want to suggest that we put blockchains directly, or sorry, simulations on blockchains directly in charge of anything in a direct way. So it's just decoupled from the action a little bit. The idea being that data being put into the system, much like I was showing earlier, is getting written onto the blockchain, coming from the web, mobile devices, IoT, they all interact through blockchain network clients, and the data can be written or collected at some point. Collected at some point in the future in a smart contract. In this case, what I'll show is a smart contract that implements an agent-based model. We can then sort of turn the crank and perform simulations using the data combined with the model and visualize the output in a couple ways, in traditional ways, graphs and charts. You can read the logs off the blockchain, just create tables just like you normally do, except the data that you're getting. Except the data that you're getting is sort of verifiably on-chain, or at least the simulation results are verifiable on-chain. And also, I wanted to show how this can be used in practice for decision-making by demoing, if you will, a virtual reality decision table, which, you know, given the way things are going, could be the way that people meet in the future, right? In the near future. Just a little bit on implementation. I thought this was interesting. I won't spend a lot of time on this. Did I use the word Turing complete? Here, I did not use the word Turing complete. So, this is an interesting bit. This is the bit of code I'll talk about here. At the time, this was actually very interesting. The Solidity language had just gotten bit-wise operations, which let me implement a linear feedback shift register to do random number generation. Certainly not sufficient for gambling or anything like that, but for some very simple demonstration, this was. You know, this was sufficient. So that was, I think that was kind of cool. That was my code slide. So just skip over that. So, in terms of knowledge translation, right, out the back end of that data science program, process, I should say, you know, you can get traditional graphs and charts out of there. Simulations carried out on the blockchain through the smart contract. The results and logs are stored on the blockchain directly, and they can be extracted from the blocks using a web interface for convenience. So, I want to show a little bit about how. So, I want to show a little bit about how this decision table might look or work in practice. Interestingly, I have the VR kit with me. Does anybody know here what the term bitrod is? Yes, this gentleman knows about bitrod. That's where seemingly your program has gone rotten and stopped working, even though the bits are the same. But that's because everything around your program changes, right? So, since I wrote this in 2017, it's got delisted from the Google PlayStation. Got delisted from the Google Play Store because I didn't fill up some forms two years later. They were changing their policy, and I couldn't revive this, right? But I'll show as best I can sort of what that looks like. Give people an idea. Oh, that's the wrong page. Sorry, this is not showing up here. Over here. Okay, so. So the idea being that. So, the idea being that, you know, in this first version, it's, you know, again, this is not significant in any way, just showing, I couldn't revive the full version that has the simulation in it. That's where I got stuck. But, you know, it gives you an idea here, right? Like, multiple people can sort of get around and stand around this table in virtual space and they can have a meeting, right, discussing the simulation. We were actually going to, at our old lab back in Europe, we were going to buy a physical table like this, but it was 20. A physical table like this, but it was $20,000 to buy a table with a display on it, right? And people be able to touch it and interact with it. This is sort of like a much cheaper version of that, if you can imagine, right? Because this uses off-the-shelf smartphone hardware to implement this. But just to give you an idea of what this would be like if I was able to piece it back together after three years, that's a to-do for me. Get that working again. Let's close this. Yeah, that used to work on on on Daydream. Is that my time? Yeah, it's the all the SDKs have changed. Google's deprecated Daydream, and so yeah, things just stopped. The first thing I discovered with the Pixel 4 is that the goggles and everything I have no longer worked. Yeah, so it's the same kit, right? So you get it, yeah. So, you know, that's that's software, right? But now you get the kind of idea where this goes, right? Where this goes, right, and you know, certainly, certainly, if you know, if we're trying to get the public, right, everybody in the world to buy into something like you need to stay home for the next month or six months or whatever kind of extreme decisions required, you know, telling somebody that, you know, bulletin, you must do this and showing them some graphs and differential equations, they might be like, hmm, I don't really get this, right? But, you know, some of this is definitely storytelling, right? To people, right? So that they feel that they're involved in a process, they feel like an understanding. They're involved in a process, they feel they can understand it, they can watch this a few times. It's a communication tool at the end of the day. So, we're sort of reaching the end of this section. My second part is going to be a lot shorter, right? So, I think other people have that covered very well. So, what is the impact or interest in this? I sort of took this to the extreme, right? I took this to the extreme where the simulation is actually carried out on the blockchain, right, using Ethereum. So, let's talk about that a little bit, right? So let's talk about that a little bit, right? The analytics source code is open. The results of the computation are open, you know, both in open, published on a blockchain. The provenance of the data is clear, which data was used in the model. It's all there in the blockchain. I didn't really dive into this, right? But there's the potential there, which is interesting. Using, you know, because on blockchains we can always transfer value tokens, right? ERC-20, Tether, whatever it is, Bitcoin. There's a possibility to pay compensation to people that provided the data. That provided the data, and also other stakeholders, such as people that perform the data science. So, you can actually, what I'm getting at here is you can actually approach a decentralized data science process that is sort of coordinated by a blockchain, which is an interesting idea to me. One I'd love to explore after all the talks. What we can do is we can verify that the claimed code was used with the claimed data to produce the claimed results, right? Which is something that's perhaps, I would call it an advancement in a sense. I would call it an advancement in a sense. Certainly, there's challenges there. Challenges include blockchain scalability and the cost of using a public network. We had an interesting chat earlier about what's Turing complete really mean when you're that resource constrained. Just to give a bit of background, I ran a simulation with, I think, six agents in it, meaning six individuals, sort of much like us in a room, right, hanging out and sort of coming into contact. And I was able to do And I was able to do 12 time steps in one Ethereum block for six ages. So now imagine, you know, let's simulate a population in Canada, right, for six months, right? Certainly, you know, there's things that you don't want to do directly on the blockchain. You know, there's tremendous costs there. So I guess to tie that off, though, right, in some extreme cases, which perhaps we're living through right now, the benefits of trust and openness. The benefits of trust and openness may actually outweigh the costs, right? So that's that's more of a takeaway, right? That's something to think about when you're going to fall asleep. Thank so the second piece, right, looking at the other way around, which I think is going to be the style of most of the presentations today, right, which are creating tools, right, tools, models, techniques to understand, and also design blockchain networks. So I'll be talking about the design of blockchain networks. Many of you, I think, will be talking about. Talking about their understanding, understanding the transactions. So, in data science, has anybody heard of the CRISP model in data science? It's sort of a canonical model. You can definitely Google it. It's very Googleable. CRISP model for data, CRISP model for data science. This is from some, I would say, current work actually of mine, which was to try to map the CRISP model into, sorry, it's the other way around, map the Sorry, it's the other way around, map the blockchain token economic design into the CRISP model. And so there's this inner loop here, if you see this inner loop, this is before a blockchain is launched. This is sort of design time. So if you saw, you know, years ago, right, the token economics and the functioning of blockchains was kind of more or less written on a napkin, right? Somebody sketched it out and said, let's put this into production. I mean, certainly. It out and said, let's put this into production. I mean, certainly I'm exaggerating, right? But a lot of networks that have failed over the last few years, certainly they could have used more thought put into that, right? Certainly. So in this inner loop, we're in pre-launch mode. We're still designing and simulating the behavior of the network to understand its characteristics and performance. We use a simulation to generate data. To generate data, right? All the data in this case is generated by a simulation. So, first, you begin with understanding what the purpose of your blockchain network is. That's the analysis phase. You're doing like a business analysis of it. What's the purpose of the blockchain, et cetera, et cetera. Then what you do is you create a model. This could be a token economic model, it could be a network model, it could be a computer network model, actually, all those things. In a complete model, you'd want to model. In a complete model, you'd want to model all of those things in the technology stack. You evaluate your model to understand the characteristics of the model that we've created consistent with our goals, with our business understanding. And so this iterates on this inner loop. The designers improve their model of the token economics each time. Of the token economics each time. And then at some point, at some point, they launched the network, in which case, the model they've produced here is actually implemented in a real computer network, in a real computer blockchain network. And there's many blockchains out there. Example would be the Steam blockchain or Steemit blockchain. No, I'm thinking Steam blockchain. There's a lot of, it's in the news lately, actually, right? Because there was almost like a hostile takeover of it. It's actually gone through 20. It's actually gone through 22 hard forks over the last couple years or since its inception. A lot of those were to tune the parameters in the token economy, right? A lot of those forks. So certainly, you know, once blockchains are alive, the evolution doesn't stop, right? Evolution doesn't stop there, at which point, what's interesting here, right, is the same model that we've developed here, which can be thought of as a digital twin of the actual network, now you've got a digital twin of the live-running network. Of the live running network, and post-launch, what you can do is you can take the live network state, right? Other things too, you know, your chain analysis, you can do, you know, you can look at active addresses, all these different things, and parameterize your model with real live working data. So that's actually what's interesting here. This process, you know, certainly I would say the practice of design. Would say the practice of designing blockchain networks is improving a lot lately, right? So, this is sort of, I would say, becoming a norm now rather than an exception. Since it's so nascent, though, I'm not aware yet of this occurring all the way through, meaning that we started with a model, we created the digital twin first, and then based on that digital twin. Based on that digital twin, launched the network and then collect a database on that network to back to parametrized the modeling. And that so that there hasn't been enough time gone by yet to actually observe that, but this is ongoing right now. This is occurring right now. Almost all the way through here. I'm just going to zoom through these last ones. There's a company I've been working with lately, a very brilliant scientist there named Michael Zargum. He's sort of, I would say, you know, as a small Of, I would say, you know, as some economists here, right, you can check out his work. It's really redesigning economics from the bottom up, from a computational perspective, right, rather than these sort of top-down models with a lot of assumptions about people. And there's a tool, an actual tool that can be used to model these economic systems. It's called CADCAD. You can go to CADCAD.org and check it out. And it's actually, you know, computer people often have kind of senses of humor about names, right? Of senses of humor about names, right? CADCAD stands for Computer-Aided Design for Complex Adaptive Systems, right? So it's just sort of a cute name. So CADCAD relies on sort of backed by a system dynamics model. I think there's updates to this, but the idea being that there's rules of the technological system, which means that computers implement these rules. means that computers implement these rules. This would be the code that runs the node. Then what happens is this updates state, there's the global state here. Individual computer states all flow into a full system state, which is a collection of all the computers in the system. Then what we do is we take that and we have the observable system state. The observable system state, right? Because in this notion of agents, there's versus the environment, there's things that are observable, things that are not observable. So this model delineates between those things. There's things that people cannot see in the model, which is a very good feature. From there,