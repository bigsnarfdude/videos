Me to this time for me in Banth, and I'm enjoying a lot. So, I'm new in neural network, and well, this conference has been very inspiring to me up to now. I'm collecting a lot of information, I'm learning, and hopefully, one day I will be able to produce new results of this learning. And I think it's very interesting sometimes to attend conferences which are related but not so strong. Confluence which are related, but not so strongly related to the field. I'm coming from technetic theory, and well, because you can see well, you can learn and see more ideas, and maybe you can use them thereafter in your field. To tell you a story, when I started my PhD, they told me that solving both one equations with numerical methods was almost impossible because, well, for the course of dimensionality, for the Dimensionality for all these cases which are related to the solution of this kind of model. And well, then we started reading some literature and we found that there exists this IMEX idea, implicit, explicit Rungekupta scheme. And starting from that paper, we started to develop an entire new field which is related to asymptotic processes. Field which is related to asymptotic preserving uh schemes are uh well in my community are uh are very very uh used uh and uh considered very interesting and two of the people that did this research are present in uh in this room and so I hope that will be also this week useful as uh as uh this paper has been uh in the past for for our community so well now I will So well, now I'll enter a little bit into the detail. So this is an ongoing research with some colleagues. Jacques Mar is in Verona, Deca is a postman of mine, and Olesto Pareski now is in Hedim. Well, since when I'm not in Europe, they always ask me where is Ferrara? So here, so Ferrara is located here, is in Italy. So then it's a little bit well one hour now. Is a little bit one hour north, Veroni is there. Also, Veroni is very close, is one hour distance, so we are travel here and okay. So, Ferrara is a small city of Renaissance. We have a castle and the university is quite old, it's been f founded in the fourteenth century by Pope Boniface Main. This is a basis of uh uh my uh universe. My universe. So, well, after this, this is the Diamante is very logical, and this is now I can enter maybe a little bit into So, okay, now I can enter a bit into the details. So, well, I would like to discuss about plasma and our numerical method related to this problem. So, what is plasma? It's an electrical conducting fluid, but the temperature is very high, and so electrons are separated by the atoms and are free to move in this fluid. In this three. So it's considered the fourth state of matter, and most of the universe is in this state, like stars, for instance. And well, what people are trying to do since 30 or 40 years is to try to reproduce what happens into the star inside some device. And the principle of this magnetic fusion is exactly this one. So we want to confine plasma in such a way that the nuclei of deuterium and tritium, that are two results of That are two results of hydrogen are able to join together, and joining together can release energy. So, these are two examples of devices that are trying to develop in order to realize this fusion here on the Earth. The problem are many. One is related to the high temperature which are generated by the plasma, and so this means that it has to be must. It has to be, it must be isolated from the wall of the device. Otherwise, if they touch the device, it damages it for design temperature and cannot work. So, the idea is to realize to the scope of this external magnetic field that you see here, the magnets, is to achieve exactly these goals. So, to keep the plasma far from the walls. So, from the mathematical point of view, there exist really many, many different There exists really many, many different models that have been used to characterize what happens inside this kind of device, or in general, in a plasma. You can have fluid models like magnetic hydrodynamics, you can have also B-fluid models, or you can, if you relax the hypothesis of thermodynamical equilibrium, you can describe the plasma by means of the kinetic equation. And that collision from kinetic equation you can also then pass again to the Foul Leader. So, and when you want to solve this model, you have to design also some other numerical methods because there are different scales, there's the course of dimensionality, there are many, many different features. And so, to solve this kind of problem is some sort of nightmare. And this is the huge detail to do about numerical methods for. Numerical method for kinetic equation applied to plasma. There are many research groups here in Canada, United States, Europe, France, Germany, Italy, Spain, UK, but also in China, Russia, and Japan. So there are really a lot of people working on this subject because there's a lot of interest around fusion. But surprisingly, from the point of view of the control, there are not many results yet. So, if I just well, here there are some references about the control in plasmas, and apart from the first one, which we discuss about control from where the borders are of fluid dynamics type, well, from the kinetic point of view, there are not many results. What is listed here is almost everything that exists about control in uh plasmas using uh plasmas using uh using uh kinetic equations. So there's a lot of work to do and as I will show you there's uh many menu requests on that. So what yeah so let's uh enter again into a little bit of detail. So well here is one model that is uh very often used to to describe plasmas is a kinetic type of equation. F represents uh this F represents the distribution function, so it's a point of view, it's a little bit a point of view, a probabilistic point of view. It describes the probability of finding an atom or an electrons in a given position x with a given velocity v at a given time t. And these electrons or ions move into the space, this term describes the motion of this particle, and are subjected to some force, which can be. Some force, which can be, you can have an electric field, which you typically recover it from solving a Poisson equation for the electric potential phi, or you can have also a magnetic field. Just to add, so just to clarify all the term here, rho is the density, so the number of particles that. Is the densities, so the number of particles that you have in a given position, and here I wrote plus zero, which is some sort of neutralizing background. So typically, you can describe one species, like let's say the electrons, imagining that ions remain, they don't move because they have a larger mass, or you may be interested to describe both of them as we have a couple of these equations to solve. So, compared to classical fluid model, here we have Fued model, here we have an additional variable which lives in F3 also. So the problem is seven-dimensional. So you have really a problem of course of dimensionality solving this kind of equation. And if you add also, well, unsynthetic quantification, the problem becomes even more complicated to be solved. So, well, this is a Razov-Maxwell model if the magnetic field and the The magnetic field, and but if you want to be more realistic, you can also solve Maxwell equation. Here are the Maxwell equation because a magnetic field induces a magnetic field, and magnetic field induces a magnetic field. So, you would like to solve the entire problem. But if you start to couple Brasov equation with Maxwell equation, here you have also the speed of light, and well, it becomes very, very complicated. So, typically, to avoid all this complication, in the device that I showed you before, this talk. I showed you before, this Pok√©mon, for instance, the model that is chosen is like: okay, you have a self-induced electric field which is obtained by solving the electric potential, and then you have a magnetic field which is external, which is the one to do so by the coil, which is exactly the scope to the scope is to confine the plasma in some bit. So, this is the model that I will use from now on. So, the idea is: well, we want to find the control, so we want to find an external magnetic field which is obtained as a solution of the optimal principle, which I would say to minimize the mass or the energy or the thermal energy close to the walls. And well, here we have the first problem, because since the magnetic field can be very large, we can have very fast in time and short in space spine dynamics, and so also the numerical methods. And so, also, the numerical methods we design in such a way that they are able to treat this kind of problem. So, in the following, I will use some kind of semi-implicit time discretization to face this problem. So, the general form of the function that we want to solve is written here. So, you have some running cost, and then you have epinalization, because you want the magnetic field to be as small as possible. So, we have the eponymization on the intensity. Penalization on the intensity of the magnetic field. And the running cost, here is an example of what you have. So, this shape that is written here, you have F h is a target distribution, meaning that, for instance, you look to steer the moment of the distribution function towards the design states. So, the case psi equal to 1 corresponds exactly to say that I want the density of the plasma to be as close as possible to a given configuration, while if you choose. A given configuration, while if you choose, for instance, psi equal to v, means that you want the mean velocity of the particle of the plasma to have a desired configuration. So, for instance, they move far from the body. So, the counter problem that you want to study takes this form. So, you search for a minimum of the functional subject to the fact that you want to solve this equation. So, the Lazov equation, the Blazov equation, Equation. So the Lasov equation, the Lasov equation with the external magnetic field. And well, so the setting is the following. Okay, you have a torus, so we simplify it a bit, the problem will pass through a two-dimensional setting for now on, and the external magnetic field also is just orthogonal to the plane. And here I will introduce a discretization, but be careful because this discretization is not a numerical, it's not there for numerical purposes. Therefore, it's just there for physical purposes. Because, as you have seen at the beginning, well, you have these coils that produce a magnetic field, but you cannot imagine that this magnetic field, which is produced by this coil, can take any kind of value in any point of the space. So, just to try to be a little bit more realistic, we introduce this grid saying that the magnetic field takes constant value in each point of the Point of this partiability. Of course, if you relax this situation and you suppose that P can take any value, then the control becomes more simple. So this situation makes the problem a little bit more complicated. Another word which is important here is that the control, typically when you have a control problem, you have a force term which tells you that, for instance, the particle, well, you move the particle thanks to the force term. But here, the the forcing term. The forcing term, so the control term, is a vector product. So, what is the effect of this external magnetic field to make particle rotate? So, particles start to rotate around the magnetic field line. So, you want to reach the confinement by the fact that particles are just rotating. Which is not so obvious that you are able to do it. So, well, the problem, I think. So well the problem at the continuous level becomes now a problem at a discrete level in the sense that B has different constant value in each part of this device and you won't see that the rest of the equation was defined. So here is a little bit of detail of what you can ask to the running cost if you can ask the position x to have a so to the particle in average to have a given position x given position so an average given a position, so an average position, or you can ask the particle to have an average velocity, but this is not sufficient in general. Because if you ask the moment of the distribution to have some given value, you still have the problem with the tail. So because some particles which are very fast, which reducing the tail of the distribution function, may escape from this control and reach the wall. So you can add a control to a values. To avoid also a request, just to avoid that the tail of distribution, the particle which belongs to this tail escape. And so you ask also to the control to concentrate around this mean value. From another point of view, you can see that this term just asks to reduce the variance around this mean value. So for instance, reduce the temperature. So, for instance, reduce the temperature of the gas. Okay. How can we solve this problem? Well, the strategy that we adopted is just to replace our distribution function f by a finite set of particle n. And so it's well known that when n goes to infinity, this can approach the solution of. The solution of your Lazov equation at the very beginning. So it's a sum of delta functions, delta omega is just the weight of the pattern. And so your original problem is transformed in a set of second order ODE with a given, and that you have to solve. So from the point of view of the solution, now the problem is simplified, and now we have to solve to find a suitable time in spatialization for this problem. And as I said before. This problem. And as I said before, we rely on some sort of semi-implicit discretization. Why we choose that? Because B can be very large compared to the other term in general. So you want the time step not to be related to the size of this B. And this kind of semi-implicit scheme, which is a combination of an A-stable scheme and an M method, the one that I presented here, is able to. Is able to solve this problem, so it gives a very large stability area. And moreover, in the limit in which B becomes very large compared to the other term, this scheme is consistent with another model containing this limit, which is the classical model in plasma physics. So it's also consistent with the unit model. So the main problem here is to find. So but the but the main problem here is to find the the magnetic field bit. So how we can find the magnetic field bit? So this is the setting now. So we have a physics so the we have a grid which is related the larger grid is related to the physics of the problem while the smallest one is related to the level of resolution so to the numerical expectation. And so here this is the setting so if this macro cell B is constant and well and power. And well, and particle about everything. So, to determine this magnetic field, we just divide the interval of the simulation into small intervals and we try to solve a sub-optimal control problem. So, a series of sub-optimal control problems. So, how can we do it? The idea is quite simple. So, the scheme is implicit, and so we cannot solve the control problem. The control problem, even for a small time step, analytically. So, we do an approximation, we change for a while our time step integrator, we solve the problem for this simplified scheme, and we derive some optimal feedback control. And then we plug the magnetic field that we have found into the original scheme. So, at the end, what we have to show me is. End, what we have to solve is this minimum intension problem related to the fact that particle position and velocity has to respect the law that you see here. You can prove that a control exists where P is just a projection of an interval minus Mn, meaning that you don't want to fix a limit for the intensity of this magnetic field. And this is the expression that you get for your Expression that you get for your control. And then you send the H to zero, so the time step to zero, and you get an instantaneous formware for your control that you plug into the scheme and you realize your control. So let's see if it works or not. So here we have the initial density, we have just uh directly two streams, so we have two bumps of density, we have a given electric field, and at the very beginning the particle uh pushed the to the bumper. Are pushed to the boundary. Here we have periodic boundary condition, here we have a reflection because they are the wall of the device. And so you want to avoid the particle to touch the boundary and to destroy it. So if you just keep B constant, what is going on is that you particle goes to the boundary, they are bulging back, and then they spread all over. And here you have the battery. And here you have, you see the density of the boundary, you have some sort of ways of the density of the boundary, and it's something that you want to avoid. And if you do the control case, you see that at the very beginning already, particles are pushed into the center and remain to the center for all times. Yeah, the final time is very large, is 100 compared to x k, which is 10 to the minus 3. So it's really able to keep the plasma. To keep the plasma confined. And if you look at the density of the boundary, well, here you reach 10 to the minus 4. So there are still particles that touch the boundary, the fastest one, but most of them remain far. Okay, so then you can run another type of test, because this one was very regular, so it's quite simple to control this kind of system. System, you can try to run some instability in which the fluid is more complex and try to see what happens. And also, in this case, okay, here are some vertices that form and touch the boundary. This is the uncontrolled case. And the control case, you see that you keep the instability close to the center of this domain. So you are able to reach a really good control. Here is the thermal energy at the bottom. Terminal energy at the boundary, which is five close to zero. Ten to the minus fifty. Okay, so this is the first part, but then I want to discuss about, I have still something, not the uncertainty, which is the part which is related to neural network. So as you have seen, the model related to plasma is very complex. Of related to plasma is very complicated. So, you have really to take into account many, many different phenomena. And so, typically, there's something that you cannot take into account. So, you have some uncertainty in your system. You don't know exactly the microscope interaction, you don't know exactly the boundary condition, what happens at the boundary. You don't know, for instance, the initial state. There are no ways to know exactly where particles are located at the beginning, so you don't have any type of So, you don't have any type of information about that. So, but what you want, you want to control the system anyway. You want to avoid the worst-case scenario in which you don't know whether your plasma touches, for instance, the boundary. So, if you add this uncertainty to the system, well, already was a seven-dimensional problem, as I said before, now the problem becomes even eight, nine, ten, uh mixing nine, ten dimensional, okay, depending on the dimension of Depending on the dimension of there are no messages that introduce. So it's very, very time consuming, and to be honest, well, it's difficult to run simulation with this situation. So, well, there's a lot of research in this direction for kinetic equations. There are many, many results from this term. Jimei, she did a lot of work on that in the past. But I want to discuss about an idea which is related to multiple. An idea which is related to multi fidelity. Yeah, so well, let's introduce some notation. So, now here we have to think no more in terms of deterministic fashion, but in a probabilistic one. So, you have to think about expectation, so what we expect the solution to be, and in terms of variance, what you expect to be the solution far from this expectation. So, the expectation is just the integral of f with respect to. The integral of f with respect to the random input z multiplied by the probability density function when you know it of the random input. If you don't know it, well, you compute it from data. So, these are the quantities that you want to compute, so expectation typically and values. And well, one method that works very well, but has many drawbacks also, is the standard multi-country. The standard Monte Carlo. So, how a standard Monte Carlo works for uncertainty modification? Well, you can imagine that we are having some uncertainty in the initial data. You don't know exactly the position of your atoms, of your electrons, or your ions. So, what you do, you just sample some, let's say, n identically distributed sample. So, from the data that you have, or from the distribution function that you suppose to have in terms of that, you term of that, you solve your problem for all these different samples, so and you have different M realization, and then the expectation is just the arithmetic average of your solution. So it's very, very simple and permits to compute well, the uncertainty EOS system this. So let's see what are the advantages and the drawback. So there are no interactions between the sample. So, there are no interactions between the sample, so everything is you can use your code to compute your problem, you just have different realizations. So, the scheme is not intrusive, you can parallelize it, it's very, very simple. But the error estimate that you get is, well, the central limiter tells you that the error goes with the square root of the number of samples multiplied by the bias. Bias and the other two terms are the error of the standard discretization. So it means that okay, it works very well, but you commit a very large error. So the question is, can you improve somehow this estimation? And the idea is to use this multi-fidelity approach by neural network at the game. So if you know that there are some reduced model, are some reduced model that I call F infinity. So F is your unknown. And you know that you can describe your problem with a different model, which is reduced in the sense that the cost to compute your reduced model is much lower. And so you can afford a lot of simulation for your reduced model. And you can compute, for instance, the expectation of F infinity almost exactly. Exactly, or with an negligible error. And if this reduced model is close enough to your original model, well, you can write your unknown as a sum of the reduced model plus a perturbation, which is the difference between the two. And so the expectation of all other quantities of interest in terms of probability can be computed by just separating the two integrals and say, okay, I compute the expectation of. I compute the expectation of this model and plus the expectation of the perturbation. And if you give a look to, well, again, to the central limit theorem, you have that the error goes with the square root of n multiplied by the variance of your original problem. And here, instead, you have the variance of the perturbation multiplied by n. So with them, there's nothing that you can do. There's a theorem that tells you that. is a there's a theorem that tells you that is a is the evolution of the error. But if g is small enough, this term here is very small and so the error, so you get really a reduction of your error as I will show you later. But you can generalize this idea instead of doing just this decomposition, F infinity plus perturbation, you can generalize by introducing a new random variable. A new random variable f lambda, in which lambda is a new parameter that you can determine by trying to reduce the error that you are committing by doing this separation. So thus you can prove some theoretical result that tells you that you can find an optimal lambda which minimizes the errors that you are committing. And if you see this. And if you see this result, it tells you that this rho is the co-initial coefficient. So if the two modes are close enough, rho is close to one, and the error that they are committing is zero. So basically, you are computing an exact solution modulus the fact that you are able to compute F infinity exactly. But as I told you, since F infinity is a reduced model, you expect to compute it in a very fast way. So, and again, you can generalize this. So, and again, you can generalize this idea to many low-fidelity models. So, introduce a new variable which depends on a combination of your original problem with many low-fidelity models. And you can try to find the lambda, in this case the L, L, capital L lambda, which minimize your error. So, what is the idea here? It's just okay, now we come back to the Vasov equation, this uncertainty, and here you see that you have, I have added. That you have, I have added the variable Z, and well, and we want to consider different low-fidelity models. What is interesting is to consider low-fidelity models which are based on neural networks. So the idea here is so we you imagine that you have F or some moments of F, so like let's say the density, the temperature of your plasma, is your arc fidelity solution. Is your act fidelity solution obtained by solving your original problem. These are computed by some particle scheme, some deterministic method, whatever you want. Then you train, for instance, a neural network with some given data depending on what the certainty parameter, and you construct a surrogate model of your neural network, or you can do something more since you know the physics. Do something more since you know the physics of the problem here. The physics is very well known. We can try to construct a neural network which is also satisfying the loss function, the physics of the project. And so take into account the discrepancy between the surrogate and the differential operator, which are related to your original problem. And okay, so let's see some results now. So let's see some result now. Here we have a standard problem in plasma physics, which is the Landau dumping. Here we have the result. So you see a dumping of the energy in time. On the left you have the solution computed with the particle. On the right is definite volume. The shaded area represents the confidence band around the expectation, which is the continuous line. So what you want to do when you What you want to do when you pass to the control problem is to avoid that this confidence band tells you that you are touching, for instance, the wall of your device. And then you can consider, as a low-fidelity model, the solution generated by training neural network with a particle or a finite volume scheme. And what you get is uh the following. So here is the standard Monte Carlo. You see the arrow goes from ten to the minus two to ten to the minus three. To the minus 2 to 10 to the minus 3. And here is what you get by using this idea of combining the solution of your problem with the neural network for peak or with the finite point. And you see that you have a reduction of the error of two order of magnitude. Of course, here you have the number of samples. It remains that the error scale is the square root of n. There's nothing that you can do, but you gain a couple of... But you gain a couple of money to do even more. And well, you can do something more. So you combine two different low-fidelity models. One, for instance, constructing is the neural network based on particle, the other one based on fire volume. And well, here again, the red one is the standard Monte Carlo, and the blue one is And the blue one is the this combination of two surrogate models, or federated models based on Ernest. And this optimal number tells you the quantity of one model and the quantity of the other model that you take in order to reduce additionally the error. You see that here you go around ten to the minus six, while here the error was ten to the minus three round, more or less. So there's a lot of gain doing this kind of strategy. doing this kind of strategy. And well the message is that you don't need the neural network to compute exactly your solution. You just need it to reduce the error that you are committing in computing your solution with the original model. Let's go to the conclusion. So what we have done is just well, the first part was uh studying uh this instantaneous control strategy to try to steer the plasma. To steer the plasma in a direction thanks to this external magnetic field. But the idea is to derive the control, you discretize your cost function, and you solve the control problem over a single time step, and then you pass to the limit of time step close to zero, and then you plug this in your original equation. The second part, we have explored We have explored a complementary thing which is related to add to this system uncertainty quantification. So to add all the information that you don't have with the system because these are not possible to be quantified or they are too difficult in some sense. And the idea is to use this multi-fidelity using, for instance, as a low-fidelity model, some neural network based on, for instance, or physics-informed neural network. Or physics-informed neural network or other idea to try to reduce the error that you are committing by solving the problem directly. There are many extensions, for instance, what I heard yesterday is when some neural networks preserve some structural property of the equation could be very interesting and can be explored. So, thanks a lot. Any questions for this one? So have you done any uh experiments where you are not where you are controlling the state equation with uncertainty quantification? I think that there must have been your motivation to look into this. No, no, I don't have it, but of course we did it. When you add the uncertainty quantification, the problem is much more complicated because you don't know exactly. So the standard scenario is what we have seen, okay? But there are many more But there are many scenarios which are worse. In the case in which the initial data are such that, for instance, the particles are much faster, the control of the system is much more difficult. So that's the real problem. And that was probably your motivation to look into these surrogates, right? The motivation to do the surrogate is to reduce the computational effort. The computational effort. Because here the problem is uh you have a a big problem of course of dimensionality. So this is why you use Monte Carlo, because they are fast, but they are not precise. So if you use this surrogate, based on what we did in the past, we was to use surrogate which were based on the physics. You know that some orders are close to the other. And in this way you can reduce the variance. Now what we are exploring is to use a surrogate neural network. Neural network. But you want to use these surrogates in the control problem. Yes, at the end, yes. But do you need to somehow adapt the analysis that it's used in the control problem, right? Because there you do not, I mean, you do not need, potentially don't need high accuracy, but you need you need like the type of output that minimizes the error in the control that you're computing. And the control that you're computing, right? I mean, it's a different objective, right? So you're trying to surrogate that replicates the control rather than the surrogate that replicates the solution. Yeah, I agree. I'm agreeing. So it's a direction that Valis pointed right now. But I'm agreeing with the different algebra. Question, so it's since you use some kind of control variant uh type of Kind of control-variant type of approach, right? Do you think it makes sense to try to do it in? Yes, we also try multi-level, but I think the advantages that you can have using multi-fidelity are larger in some sense. Because if you find a model which is very close to your model, and with neural network you can construct really models which are very close, the the the gain that you get The the gain that you get, I I believe that is much larger than using multilevels. Yeah, multilevel Monte Carlo. Multilevel Monte Carlo based more on uh different grid. So let's say I was thinking about you know little park and then you have to figure out it's a different part to do, yeah. Yeah, you maybe use model instead of building Just out of curiosity, how long does it take to train? It's quite fast with particle itself, it's fast, I think. I have to ask one day, something like that is not so long. But we have to think to this kind of simulation, which are very, very expensive. The point is that it has been well known since many years that solving the full Bosnian equation. That solving the the full Bosman equation in seven dimensions is almost impossible in some sense. So you are starting from this point of view. So it's already similar to the slope of the thoughts of the paper that's saying you know getting speed up. You're on the floor to then be able to get this speed up at the end. I think at the end it's worth it, I was just curious. No, no, but it's interesting the point is the point is how robust is your How robust is your neural network that you can adapt also to other situations? That's the point. Of course, you have to train it, but you have to train it with a given randomness in uncertainty, but you want to use it with another randomness. Otherwise, it's straightforward. Of course, it will involve you. So you have to use it in a different uh setting also. That's with a different uh uh randomness uh in uh in your operations. The question is uh if it's uh robust enough, Is that if it's robust enough, then you can pay to wait a little compute your simulation. Otherwise, no. I was wondering if there is some structure in the ODEs that you are looking in your ODE. Yeah, here we lose it, because typically energy is per served, but with the same implicit discrepancies, but you need to do it like a we prefer this direction. We prefer this direction because this way we are able to integrate without problem when B is matched. But again, at this price is very new these things. So we are thinking about what is better to do. If it's better to possibly energy, it pays something in terms of time step or or not. It's a Poisson system uh this three. I I just looked it because you have this uh cross product. Yeah. Cross project? Yeah. The the system then uh the simplified system and the discrete version. So the point is here the control act making the particle rotate. So it's quite difficult because you don't know exactly what you ask to the particle because they want them to stay there. But the maximum that you can do is to add a force which makes them rotate. So it's not obvious that the So it's not obvious that you can control with this term. That is what the engineer is doing since 20 years, try to control with magnetic field. I had a quick one, if you wanted. What's the sampler that you use to generate? Okay, there are different things that you can do. Here you just choose a given distribution. Well, a given distribution, okay, it's uniform and that's what you want. But in reality, typically, maybe you have data. Okay, so you don't have a really probability distribution function, but just data. And so this is why Monte Carlo are very interesting, because they work with data. While if you use other strategies, L time T B, you can use them only if you know the probability distribution function. While here you can use also L terms. You don't need the Okay. Questions? Uh, let's thank the speaker again and