Okay, brilliant. Okay, great. So to conclude our day, number one, Marilyn Brennis will talk. Also from U of T. Yeah, thank you very much. Thank you very much for coming. I realized it's the last session of the day, so that counts a lot. I really appreciate it. To repay your kindness, what I've done is I tried to make my presentation as light as I could, whether or not Whether or not I succeeded, I guess you'd be the judge of that. What I want to talk about is about fluctuations, charge statistics in mass-scale conductors. I say charge statistics because in principle from the approach that I'll be proposing, you can get the entire charge distribution. However, I'll be focusing more on the fluctuations. The way I usually like to introduce talks is by Introduce stocks is by raising your attention to a recent experiment. So, this is the one that I selected. It was published last year. Basically, what we have is a layer of graphene coupled to metallic leads. And crucially, there's no induced chemical bias between these metallic plates. So, there's charge transfer being induced by the action of these pulses, these light pulses. Pulses, these light pulses, which are non-periodic. They have these Gaussian envelopes, and there's a relative phase between the pulse that generates certain charge transfer between one side and the other. The idea of this experiment was twofold. First, they wanted to understand the mechanism of charge being transferred from one side to the other, depending on this relative phase of the pulse. Phase of the pulse, and another one was to study some logic gates that he can use from this construction. The only reason I wanted to raise this experiment to you is that this non-periodic modulation is now experimentally realizable, okay? And there might be some highly known Markovian effects that are happening, especially if you consider strong system and environment coupling. So, at the level of theory, fluctuations, okay, in general, will tell you a lot of information. Particularly near equilibrium, there's fluctuation-dissipation relations that you would like to understand for a more general class of problems. And more generally, fluctuation theorems and TORs away from equilibrium. But even at the level of the experiment, understanding fluctuations is very important. The experiment I raised to your attention before was just. I raised to your attention before was just one example. Nowadays, there's even experiments that using this light modulation, you can generate transitions of single electrons happening in these junctions. They call them single electron guns, if you're familiar with them. And these fluctuations tell you a lot about the regimes of operation, how to optimize for efficiency, so on and so forth. Okay? Before I get into the actual protocol that I Before I get into the actual protocol that I want to introduce, first I would like to start with some definitions about charge fluctuations, particularly when you have driven fields. The type of configuration that I'll be interested in is a central system coupled to, say, two reservoirs, one on the left, one on the right. And the name of the game here is non-perturbative. I want to make no assumptions about the energy. Assumptions about the energy scales of this coupling, and I want to make no assumptions about anything related to the system. It could be highly non-interactive, it could contain like strong interactions, say non-quadratic interactions in the Fermian language, so on and so forth. I want to make no assumptions either about the temperature of these reservoirs. So, in part, this talk will be about how to tame this beast. In particularly, for Particularly when I look at systems that depend on time, I'll be interested in the stochastic accumulated charge, which very importantly depends on two times. The time at which I started doing my measurement, the time that I'm interested in. And the charge being transferred is just going to be the integral of that. Average current, on the other hand, is instantaneous. It depends only on the time which you want to measure. And charge variance, crucially, will. And charge variance crucially will also depend on two times, and it's defined in such a way. Some of you might be more familiar with this type of definition here, which is the integrated quantity between the current current correlation function in time. These are the current current correlation functions in time that appear, for instance, in fluctuation, dissipation relation, so on and so forth. The trick here is that even though the accumulated charge depends only on two times, Charge depends only on two times, it's additive. If I want to consider several time periods, for instance, and if I want to study what's the charge that flew from one side to the other, I can just add them together and everything will be fine. Variance, on the other hand, is non-additive, as you know, okay? So it's very important to decide what are the relevant times in which you're doing your measurements. In which you're doing your measurements. Now, this is completely irrelevant if you consider only autonomous systems. Why is that? Well, that's because in autonomous systems you'll typically relax to a steady state in which the current is not being periodically modulated. It reaches a steady state, and you can very easily define what the charge variance would be as a function of time. But in driven systems, for instance, in But in triple systems, for instance, and what I'm showing you here is: well, this is supposed to be periodic, but even in periodic systems, if you consider, for instance, the variance over this, what I'm pointing at here, the variance of charge being transferred over this period, will be different depending on the time period that I select. Now, I'm going to be facing two problems. If I want to address Facing two problems if I want to address charge statistics in the type of configurations that I was showing. The first one is: how do I address the dynamics of a system that's strongly coupled to the reservoir without making any perturbative approximation? That's the first one. The second is, how do I actually address the charge statistics? Now, for the first problem, what I'd like to introduce is this approach that some of you may know about. It's not a new idea. It's not a new idea. And it is when you have a reservoir which is strongly coupled to a system, what you can do is that, as opposed to considering this untamable animal, is that you consider a set of fermionic modes, each of which is coupled to its own thermal dissipation. So, what I have is several fermionic modes, and each of them is And each of them is coupled to its own independent thermal reservoir. Far so good? Yeah? Well, what you can show analytically is that if I make the assumption that the spectral function of each of these small reservoirs onto the single fermionic site, if that's a flat spectral function, then I can generate any effective spectral function that I want as a sum of Lorentzians, okay? As a sum of Lorentzians. And maybe it's very easy to some of you to see how you can actually show that. You can do it iteratively. So if you consider just the one mode coupled to a single reservoir, you can show that if the spectral function of this object that I'm selecting here is flat, then the effective spectral function that the blue system will see, it's a single Lorentzian. So if I do it iteratively in such a way, I can generate any spectral function that I want. Generate any spectral function that I want by using a sum of Lorentzians. Now, crucially, the aspect here is that, okay, I've somehow extended this system to be coupled to these set of modes. And if I don't even have to assume this can be done in the general case, okay? Each of these couplings, Each of these couplings, as I increase the number of modes, will keep decreasing in value, okay, in energy scale. So this is always, okay, you can guarantee, the smallest energy scale of the problem. What I'm trying to tell you is that the entire dynamics of this system and the lead modes that I call can be understood. Its dynamics, you can understand them from a Limbladmaster equation that we copy. At this point, you might be asking. At this point, you might be asking, okay, what do you gain? It seems that you've made something very complicated, right? Now I have a system which can be very, very complicated, and now you've extended it by these number of Romanic modes. The idea is that the fact that now your reservoir is finite and your dissipation is local allows you to play a lot of games. Say, for instance, tensor networks, so on and so forth, with local dissipation. And it allows And it allows the problem to be tractable without really any approximation other than the fact that maybe you're using an MPS for your state. Now, the currents, okay, if I want to look at currents, for instance, mean values of charge transfer, I can do so by just looking at continuity equations. I write down a continuity equation for the system, and I can just plug out what Just plug out what the current operators would be, even microscopically, compute the expectation values, and that's it. Now, we want to take this beyond to study fluctuations and the statistics of charge transfer. So, how do you do that? Well, what we did was introduce the full counting statistics onto this mapping that I just described to you. I don't want to say much about full counting statistics other than the fact that it relies on a tool measurement protocol, you have to be very careful about. Measurement protocol, you have to be very careful about that, mainly because you have to make the initial assumption that system and environment is in a product state. Otherwise, when you do the first projective measurement of the two measurement protocols, will kill any coherences that you originally had. But being careful about that, you can then basically put on top of the master equation that I showed you before. The master equation that I showed you before, the full counting statistics. The idea is that the generating function, the characteristic function, which is the most important to address the chart statistics, will then be given by the trace of this row top here, system plus environment. And this is the entire dynamics of the entire universe, system plus environment. Under weak coupling approximations, Born-Markov, you can reach a Limblad-Masseur equation. You can reach a Limblet master equation that it's sometimes called a generalized master equation. The idea is that I can use the same procedure now, since my master equation, even though it could be of highly normal covariant type because I'm keeping track of the degrees of freedom of system plus environment, the dynamics of that in turn is Limblarrier, okay? I hope I'm being clear. And then you can address the higher order cumulants just by looking at the characteristic function. Just by looking at the characteristic function. Now, so that's what we did. We just basically what we did was employ the full counting statistics after we do the mapping, and then what you get them again is this generalized master equation, in which dissipation is local, and crucially, the counting fields do not appear in dissipation, which is not typically the case, for instance, when you look at generalized master equations of the local type. Typically, you get counting fields. Typically, you get counting fields acting on dissipation. In our case, everything gets included into the coherent part of the evolution, okay? And this is a result of the mapping. Okay, so so far I've made no assumptions about the system itself. Okay, it could be It could be highly interacting, it could be whatever. But now I'm going to make the assumption that the Hamiltonian is quadratic. It can have any time dependence, though. It could be periodic, non-periodic, it can be whatever you want. But let's assume it's quadratic. So we can maybe attempt to get some equations that dictate the dynamics of the current, the noise in those types of configurations. Now, what you can show is that the dynamics of a correlation. The dynamics of a correlation matrix in this case, since the system is Gaussian, then the evolution will be Gaussian as well. And you will get a dynamical equation that dictates the correlation matrix as a function of time. And through that, you can get the currents. So very nicely, if you only are interested in the current, then all you have to do is solve an equation of the Lyapunov type for Gaussian systems. Now, if you want to take that beyond, just say, look at the second order QM. To say, look at the second-order queue and what you have to do for Gaussian systems is basically just plug in your correlation matrix to the second-order moment. And then what you end up getting is also an equation of the Lyapunov type. But now the force term depends on your actual state. And through the dynamics of this auxiliary Lyapunov equation, you can understand the dynamics. Yeah, put another question, you can understand the dynamics of the novice. That would really depend. That would really depend on the form of the Hamiltonian. If it's right, but what happens if you have a Hamiltonian with Coustaging dependence? It's something very complicated. I don't think that's it. Well, how do you find this transformation that diagonalizes the Diagonalizes them. There's an exact result for that dependent. I can tell earlier. Basically, it's an extension of non-equilibrium wait function. Time dependence. But with NTF, if you have time dependence, if it's not periodic, you're gonna have to do a few year expansion. A four-year expansion on the Uh a full year expansion on the on the frequency terms. Well, that's only if you want uh but for a two-time uh correlation function. From generalized two-time correlation functions, you can get the same without making any assumptions between the system and reservoir topics. Can you get the entire dynamics? The dynamics of the generating function. The dynamics of the generating function. Okay. We should talk about that. Thank you very much. Okay, so using this approach, I'd just like to finish with an example. So it's just two fermionic sites with some time modulation. And for this particular example, I just picked a periodic modulation just to point out the importance of keeping track of these times over which time periods you're doing the integration for the noise. Periods you're doing the integration for the noise. So, if you look at the dynamics of the current, okay, after a certain, you can start with any initial state that you want, okay, and after a certain time you're going to reach what we call the limit cycle condition, okay, in which the state becomes periodic. But now I ask the question, for instance, I want to look at the fluctuations over a single time period, the charge fluctuations over a single time period after Period after I've reached the limit cycle. And if I do that, all I have to do is look at the dynamics of the noise. And what you can see is that the noise itself does not become periodic until you reach very long times. So what we did is that you can define this other quantity here, which we think is experimentally more relevant than this quantity, which is known as the zero frequency noise. Okay? So say you're an experimenter. So, say you're an experimentalist and I have a way to measure the current. I wait until the limit cycle, and then I say, okay, I start at the beginning of the limit cycle, I end at the beginning of the limit cycle, and I want to see what the fluctuations of the current are only in that period. If you do that, you'll obtain the integrated quantity over this period of time that I'm showing you here, in light gray. Now, if you wait very long, though, and decide Though and decide to do your measure still over one period but waiting very long, you're gonna get the zero frequency noise. This zero frequency noise is a more complicated object because it contains all the statistical correlation, the covariance terms between the previous time periods. In fact, if you do that for, say for instance in this case as a function of the driving field, what you'll see is that these definitions of the noids can be can be very different, okay? Can be very different. So, in red is the fluctuations in the limit cycle, what I call. And the blue one is the zero frequency noise in the sense that people say, for instance, defining in the condensed matter sense. And in the low driving frequency regime, these two quantities are equivalent. This case is basically, this regime here is basically where you're not driving the system, right? So it's basically autonomous. System, right? So it's basically autonomous, and then in that regime, you don't have this subtlety arise. Okay, so just a little bit of summary. These average fluctuations, they contain correlations between different time periods, even in driven systems. You have to be careful about that. We've introduced this flexible approach to address normal covariance dynamics for both the current and the noise. In particular, for any spectral function, that's maybe something we could discuss. That's maybe something we could discuss. And the higher-order moments follow from the dynamics dictated by the generalized master equation. So related to this work, something that I would like to do, so non-periodic modulation, this is completely defined, right? You just plug in your time-dependent Hamiltonian. But something that I would like to address is another case where you have a non-periodic modulation or something very complicated, time-dependent. Complicated time-dependent, but something like non-quadratic fermionic interactions, right? That would be nice, right? Because then you could address the entire statistics of systems which are very strongly interacting. And there's a way to do it that I know, but I'm facing one problem of which I have no solution. Yeah, so the idea is that I didn't want to talk about this, but maybe some of you would know how to do it. So I'm trying to maybe get the answer for some of you. Um look at the choices. Here. If you look at the form of the characteristic function, so in our case, it's obviously not going to be the trace of the entire system plus environment state, but only the state of this system plus fermionic lead. System plus fermionic need nodes. Now, any method that allows me to study the dynamics of that object, say for instance tensor networks, will depend on the algorithms of which you do the evolution, say for instance time-evolving block decimation or time-dependent density matrix renormalization group. I need to take the trace though, but it's known that those methods rely on you after each step renormalization. On you after each step, renormalizing it. Okay? So if I need to renormalize, I won't be able to see how the trace is being lost as a function of time. You do. You do have that. Otherwise, how do you satisfy positivity from your algorithm? We should not. Because what you have a counting field where dynamics are not I fully agree. I fully agree. But when you're looking at any method that relies on tensor networks, okay, the contraction is killing the norm as well. So if you could somehow fix that problem, then you're in business. Maybe we'll hike. Maybe we'll hike up the mountains and we'll find the solution. That was the last thing I wanted to say. Oh, sorry. I just wanted to say that this was the result of a beautiful collaboration between my wonderful PI, Denver Sengala, the EOFT, Gabriel Landi, the man himself, Jens Eiser, who you may know, and my two friends, Arcek. He used to be in Denmark, now he's, I think, he's starting as a professor in India, and Giacomo, who's in Berlin. Thank you very much for your. Thank you very much for your questions for Marlon? Yeah. So maybe not a question or a comment. I don't know how to solve your problem, but if we solve it with simplicity benchmarks, I want the problem as well for this bench. But this is for the case where you have a small error. That's good to know. For weak interaction strength. Interaction strength. No, that's a hybridization extraction. So it's actually a better and strong interaction. But it's numerical stuff. Ah, that's good to know. The problem is it's not a long chain. This is like a change. But a benchmark would be wonderful. Yeah. Regardless. Questions. Anybody still online wanting to ask questions? Pardon again. Thank you.