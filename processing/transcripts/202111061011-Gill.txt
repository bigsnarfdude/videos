Second talk of the conference. So, the next speaker is also from the University of Albuquerque, Brandon Gill. He's a master's student as of, I guess, last fall, like very recent, right? A PhD student. A PhD student. I don't know what's in master's. And he's working with Cherry Gannon in number theory and mathematical physics. And did I understand it right that in a previous life he was a hydrologist? A what? Hydrologist, a what? Oh, so I must have. I was someone else. So, um, yes, and he will speak to us today about a pandemic-friendly handshake with multi-vectored checkouts. Yes, thank you for the introduction, Renata. So, as she said, my name is Brandon Gill. I'm a PhD student at the University of Alberta, working with Terry Gannon. So, today I would like to talk to you about multi-vector Ducobi forms. So, first Forms. So, first off, we're going to go through some general philosophy. I will go through some preliminary definitions: so, vector-valued modular forms, Jacobi forms, a definition of a multi-vector Jacobi form, and then sort of some current results as well as future and ongoing work related to those. So, first off, we're going to start with sort of the general philosophy behind the talk and some of the motivation that goes into studying these objects. These objects. So, first off, I would definitely like us to get to a definition of what a multi-vector Jacobi form is, and in an ideal world, in a way that you would hopefully care about why you would define such an object. So, we're going to do that through some motivated definitions, lots of examples. I'm going to directly compare the definitions of some of these objects, and then I'm going to talk. And then I'm going to talk about some early results that surround them. So, the overarching motivation for why one might choose to study these so-called multi-vector Dacobi forms has to do with a conjecture that's called reconstruction. So, essentially, it's the process by which you would attempt to rebuild a vertex operator algebra from a pre-prescribed From a pre-prescribed category of representations. In other words, it is conjectured by Gannon and others that if someone comes up to you on the street and hands you a modular tensor category, you can find a vertex operator algebra that has that category as its category of representations. So if you're unfamiliar with vertex operator algebras, it's entirely reasonable and you don't Entirely reasonable, and you don't really need to know what they are, but they are objects that are cared about by a number of people within various math and physics communities. So this is sort of the broad reason for why one might choose to look into these objects. Because right now, the process we have for attempting this reconstruction is terrible. We do it in pieces and snapshots. It in pieces and snapshots, and it's very ad hoc. You build up a number of restrictions until you eventually come to a vertex operator algebra because you had no other choice. So the goal of these multi-vector Jacobi forms is to rebuild the entire classical part of a VOA all in one shot. But in order to do that, we're going to need to build up to what one of those are. What one of those are. So, to start, I'm going to talk about vector-valued modular forms because the multi-vector Jacobi forms are sort of a mashup of these two much more well-understood objects. So, I'm going to start off with the definition of a weakly holomorphic vector-valued modular form. Okay, so I'm assuming everyone in this room is at least vaguely familiar with what a modular form is. So, a vector-valued modular form is more or less exactly what you would hope it would be. What you would hope it would be. It's a complex-valued function that goes through D copies of the complex numbers and it obeys a very similar transformation law as regular modular forms would. The key differences being, number one, here, your output is vector-valued, hence the name, and you have this extra piece that you're picking up that's called a multiplier. So this multiplier is So, this multiplier is a representation of SL2Z, and essentially what it does is it creates, it's the reason why the notion of vector-valued modular forms are non-trivial and not just a stack of modular forms that have the same weight. This representation tells you how the various components of your output interact with one another. So it's actually a very, very key piece. So it's actually a very, very key piece. And there's some additional small technical assumptions about growth conditions and whatnot, but I'm not going to get too far into the weeds on most of that for the purposes of this talk. So a quick example of such a vector-valued modular form. You're very classical, Jacobi theta functions, theta 2, 3, and 4. If you stack them up one on top of one another, they form a vector-valued model. A vector-valued modular form. And they have weight negative 1/2, rank 3, and a multiplier which is at least consistent with the transformation law I have there. There's another piece to the multiplier, obviously, to get a full representation of SL2Z, but that's one such transformation law that it obeys. As you notice here, the weight can be rational. Can be rational, it can be negative. As far as regular modular forms go and vector-value modular forms go, the weight can be all the way up to a complex number or more complicated things. The main differences are that the group SL2Z becomes insufficient to deal with some of the transformations that you get. But again, we're going to sort of ignore some of those pesky details in this particular case. In this particular case. And then we have the rank, which again is just the dimension of the output. Okay? So fairly familiar set of examples here. The next thing I want to talk about are Jacobi forms. So these objects are very slightly more complicated, although not considerably so. So a weakly holomorphic Jacobi form, it's also going to have Form, it's also going to have a weight. We're going to introduce an additional parameter called the index, and that in our case is going to almost always be an integer. And then we have a map here from the upper half plane cross C to C. So it's a scalar-valued function, just like good old wholesome regular modular forms are. You gain C your Mobius transformation here, and this is how your elements of SL2Z. Elements of SL2Z act on the shifting component, the lattice component. And then you'll notice the transformation law for the modular part is very similar. We have this same f tau plus g factor. And we have an additional factor here that deals with the translation component. And you'll notice, again, we have an absence of that representation because we are dealing with only a scalar. We are dealing with only a scalar-valued function, it's not necessary. You can define a generalization of these with such things in there. They're called with characters and all that good whatnot, but again, not particularly relevant to this story. And because we have introduced an additional variable, we also have introduced an additional symmetry in the inputs. So this is an additional translational symmetry, and it must obey this lovely little transformation law. This lovely little transformation law there. And again, there's a few small technical assumptions that get added. Make sure nothing blows up where it's not supposed to. But we will again sweep those under the rug. So questions before we leap? Oh, sorry. I do have an example of such functions. Now, obviously, this room is going to be much more familiar with examples of these than a lot of other rooms, but one that I like is the VirestrasPay function. It's a very nice little. A function. It's a very nice little vector, or nice little Jacobi form. It's going to have weight 2 and index 0, and it's defined on this lattice right there. And it turns out to obey all of the necessary conditions to be a Jacobi form. So any questions before we dive right into multi-vector Jacobiforms? All of this is sort of mostly background type stuff, but please feel free to interrupt me. Please feel free to interrupt me along the way. Okay, so the main part of our talk here: multi-vector Jacobiforms. So, in order to define these, we're going to start off with a couple of small preliminaries. First off, we're going to let M be some positive definite lattice of rank R. We're going to define the complexification of M, and we're going to define this Jacobi group. Okay, so similarly to the Similarly to the Jacobi forms mentioned above, they obey a symmetry of SL2Z and Z squared. These new multi-vector Jacobi forms obey a symmetry with respect to this Jacobi group. So this is going to be the same SL2Z, and in this case, we're going to take the semi-direct product with our lattice squared rather than Z squared. And lastly, we're going to define R, and it's going to be a unitary. R, and it's going to be a unitary representation of this Jacobi group on our output space C to the D, where we assume T, that being the T that comes from the representation of SL2Z. We're going to assume that T is diagonal. A lot of these assumptions here are not necessary for the purposes of having some sort of theory, but they are incredibly necessary for making that theory convenient and nice in most cases. In most cases. So that would be things like unitarity using SL2Z here rather than, say, the metaplectic group or the braid group, and with keeping T diagonal. So again, these are all mostly quality of life assumptions for these purposes. So which leads us to the actual definition of a weakly holomorphic multivectored Jacobi form X. So it's going to have index. X. So it's going to have index m, weight k, rank r, multiplier r, all that good whatnot. It's going to be a map from the upper half plane cross V rather than c. And we're going to go to this c to the d. Now, the main things I want to draw your attention to, this transformation law, which if we compare that with the transformation law for Jacobi forms, is very similar. It's as if we rewrote it but replaced all of the necessary Z. Z individual Z's with these Z vectors that we now have. So the key generalization that a multi-vector Jacobi form makes beyond just smashing the two together is you're now taking not only an input vector of Z's as compared to a single Z vector for your Covey forms, you're also dealing with vector output. Okay? So this is a very key piece of the puzzle, and it allows you to collect a lot more information into one of these multi-vector Jacobi forms as compared to collecting all of this information into, say, lots of vector-value modular forms or lots of Jacobi forms. So, yes, this second transfer, this first transformation law is effectively real. Law is effectively rewritten, but with all of the vector changes that accompany going to this generalization. We notice that we pick up this representation again. This is again to deal with the vector output. This teaches the function how to interact with each component. And we again have a second transformation law because we have a second set of variables. Set of variables. And this second transformation law is also incredibly similar to our original one. With, again, the necessary dot products replacing regular multiplication. And here too, because we have a vector output, similarly to vector-valued modular forms, we have to have a representation, in this case, of the Jacobi group we defined here. Cobi group we defined here. We have to have this representation to tell the output vector, or the output vector, how each component interacts with one another. And again, similarly, small technical assumptions to make sure nothing blows up when it's not supposed to. So yes, it draws a lot of similarities to these pieces. Now, the only other thing that I really want to mention about these that's really distinctly different. Really distinctly different from multi-vector or from vector-valued modular forms and Jacobi forms is that M, capital M, is now replacing the index. So if you look back at our Jacobi forms, this little M was an integer index. We now have an index that is given by a lattice. So that's probably the most uniquely different piece of input information as compared to As compared to regular old Jacobian farms. So we can square that away by dealing with a couple of examples. First off, it's important to realize that this is truly a generalization of both Jacobi forms and vector-valued modular forms. And we can see that directly because a vector-valued modular form is just a multi-vector Jacobi form where the z variables are set to Z variables are set to zero. It all collapses right back down exactly as you hope it would. And even more interestingly, Jacobi forms are also examples of multi-vector Jacobi forms, where you set all the representations to the identity, the dimension, meaning the size of the output in this case, is set to 1, and you take capital M to be the square root of 2mz, where m is the Z, where m is the index of the original Jacobi form, the integer index thereof. So very, very key to see that these are truly generalizations of the functions we want them to generalize. Now, as far as a, oh, there we go. As far as perhaps a less trivial example or a less obvious example, if you take this positive definite lattice M, Take this positive definite lattice M of rank R, then the lattice theta functions, or the collection of all of them, if you stack them up, which are given component-wise by this formula here, they form a multi-vector Ducobi form. So this is a huge class of examples that are really nice and relate to characters of Katz-Moody algebras, and they relate to a number of other areas that we care about with respect to these functions. About with respect to these functions. And in this case, we're going to see that we have index capital M as one would expect. These are going to be weight 0 because they're re-normalized by the eta function. They're going to be given rank R, that's the dimension of the lattice. The multiplier, I'll spell out on the next slide. And the dimension, interestingly enough, is actually the number of postets in M star mod M. So it's just a very nice, neat little feature that shows up on its own. That shows up on its own. As for the multiplier, so again, this is the rho and rho prime that we use in the original definition, which together form a representation of the Jacobi group, is given by this guy here. What's M star? M star? At the dual lattice. Yeah. Yes, so they're given here. So for the translational. Translational variables, the multiplier, so the representation that tells the output vectors how to interact with one another. This is given by a permutation lattice, or pardon me, a permutation matrix there. A nice, very little exponential there. And then, for those of you who are familiar, this will look Of you who are familiar, this will look very, very similar to the vial representation. So it's going to be, in fact, a very natural generalization thereof, where this extra little root of unity coming in just has to deal with the fact that we renormalized. So that is sort of the first major non-trivial example of what a multi-vector Jacobi form is. And you can And you can go through all the very explicit computations to verify all of this, but they're painful, unenlightening, and truly awful to do. So, yeah, that is very briefly what a multi-vector Jacobi form is. So, let's talk maybe a little bit about what the current results we have about these functions are. So, things that we have already proven include the fact that the characters of vertical The characters of vertex operator algebras are in fact multi-vector Ducobi forms. So, this was the whole impetus for choosing to study these objects to begin with. Is that the important example that we care about is in fact an example. So, this does turn out to be true. Secondly, there are. Yes. So, do you have to assume something about the vertex out? Rational vertex out. Rational vertex operator algebras. Yes, I could be wrong about the name, but yeah, rational vertex operator algebras, their characters do get these. So we do have the existence of some appropriate notions of a direct sum of these multi-vector Jacobi forms, tensor products thereof. We also have the existence of very nice, natural, appropriate notions of. Nice, natural, appropriate notions of the restriction of a multi-vector Jacobi form as well as a sub-form. So you can independently restrict both the inputs and the outputs and still have completely nice and well-defined notions of a multi-vector Jacobi form, which I think is very nice. And lastly, we have something that we've coined the bridging theorem. So to give you a little more So, to give you a little more light about what the bridging theorem is, we have to go back to regular old Jacobi forms. So, these were studied mostly by Eichler and Sagier in 1985. And I believe it's theorem 5.2 or something like that in their book, states that there exists an isomorphism between the space of Jacobi forms of weight k and index m and the space of vector-valued modular forms, which will be Valued modular forms which obey certain properties that they outline within that theorem. So essentially, they describe with this theorem a bridge from regular old Jacobi forms to vector-valued modular forms. And they do this by making use of this second transformation law down here. Play around with that. Play around with that notion enough that you can eventually remove the dependence on Z by including many additional output components. So this was the real inspiration for what we've called the bridging theorem. And we have an almost exactly analogous result for multi-vector Jacobi forms, and that being that. Multi-vector Jacobi forms, and that being that there exists an isomorphism between the space of weakly holomorphic multi-vector Jacobi forms of index m and weight k and the space of vector-valued modular forms of weight k satisfying ekans of technical conditions that we outline. So, this is really remarkable. This is exactly what we would want to come out of this. We go about a very similar process to To try and find and describe this periodicity relation that occurs with the second transformation law. And we get that you can, in fact, reduce all of those z variables by just adding more and more components. And this is really a very nice result. And the main reason why this is nice is because the Is because the theory of vector-valued modular forms is well studied, it's well understood. So, this gives us, at the bare minimum, a theoretical tool to work through any problems we have with multi-vector Jacobi forms by, at worst, translating it to vector-valued modular forms, doing the process over there, and translating it back. This also tells us that any of the very nice properties and Very nice properties and very nice theorems and results that come from vector-valued modular forms should have some sort of analog in our world as well, which gives a huge list of things for us to do. So lastly, I want to talk about some future work that pertains to these objects as well as some ongoing work. And that's at this point that I'll check the time to make sure I haven't gone too far over. So, in particular, So, in particular, some of the things that we would like, our sort of wish list, if you will. Finding some differential operators on the spaces of multi-vector Jacobi forms. This is a phenomenon that occurs very naturally with both Jacobi forms and vector-valued modular forms, and so we should have some notion of that in our space. We'd like to find lots of little corollaries and results that just Little corollaries and results that just sort of follow from these more major theorems along the way. We'd like to sort of spell out in a little more painstaking detail some of these more non-trivial examples, especially the ones that relate to vertex operator algebras. And lastly, we'd love to establish a module structure on the space of multi-vector June Covie forms. Multi-vector Jacobi forms. Vector-valued modular forms, as well as regular old Jacobi forms, have very nice natural structures on the spaces of them collectively. So we'd love to see something more about that in this world as well. As well as, of course, a laundry list of other results from vector-valued modular form land. How am I doing for time? I don't know when you. When you started it with that. So, perhaps the last thing I'll talk about here, I'm going to zoom in on this last point here and sort of express why we think we should have something like this and really zoom in on what's in those parentheses there. Because that's a very interesting thing that I'm currently working on, sort of on a day-to-day basis. So, very briefly, So, very briefly, outlining what the tensor product of two multi-vector Jacobi forms is, it is as natural as you can possibly make it. You take the tensor product of the input spaces, you go to the direct, or the product of their output spaces up there, you can define them component-wise, and they're given by the very natural formula that you would expect there. That you would expect there. You split up this new z vector that you get into its constituent pieces, you feed it into each piece of your regular old multi-vector Jacobiform, and you use the orthogonal direct sum of the lattice indexes. And it's component-wise, spits out exactly as you would expect a tensor product would, thus allowing row 1, row 2, or row 1 tensor. Row 2, or row 1 tensor, row 2, and row 1 prime tensor, row 2 prime to act as the representation that you're using for your COVID group. What's really interesting here is that the output space of this tensor product is C to the D1 times D2. So this output space is as large as possible. Large as possible. However, Eichler and Zegier define a product on regular old Jacobic forms, and their product, when you translate it to our language, gives you a multiplication, a tensor product, if you will, where the output space is as small as possible. You take the diagonal of D1 and D2, I believe it is. And D2, I believe it is. So that is as condensed an output space as you can possibly find. And what's truly remarkable is that in principle, we should have some notion of multiplication for every meaningful group between them. And that should then lead to a different module structure for multi-vector Jacobi forms depending on your choice of multiplication. Multiplication. So that to me is incredibly interesting, and I very much hope that we get some sort of result like that. So yeah, that's very roughly what I wanted to say. So any questions?