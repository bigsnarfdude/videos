Explains all the current laboratory and astronomical observations. But there are some things which GIA cannot explain, and for example, plaque information loss, space-time similarities, cosmological constant, and there is also not a viable way of integrating GR with quantum gravity to make a theory of everything. So, the general consensus is that GR is at best incomplete, it is, it might be. It might be an approximate version of a more complete theory of gravity. So, with this understanding, we would expect GR to break down at some point of time when we don't know. And that's why we are testing GR with whatever way we can. Of course, before the detection of gravitational wave, it has been tested with the binary pulsar and solar system. But now, since we have gravitational waves, we can. Reflection ways we can test it in more in a strong field regime. So we do a plethora of tests using gravitational waves and means I think the last time I counted there were 20 tests we do at the moment with gravitational wave within LBK. All these tests broadly can be categorized into three broad groups. One is One is where we exploit the dynamics of compact binary and test whether the dynamics is as predicted by GR or the space-time around the binary is as predicted by GR and so on. So in this category of sources, in this category of test, we have the parameterized test of post-Newtonian theory and we Such a post-nutrient theory, and we also check the consistency between the inspire emergency and bring down of the same signal. We also try to constrain the type of radiation in strong field regime, etc. The second group of test is the propagation, where we see whether the propagation from the source to the detector has any effect of the space-time between the source and the observer. And see whether how different it is from the GR prediction. For example, we test the local Lorentz invariance and we check for the dispersion of gravitational wave because in GR gravitational wave don't disperse within the space time in the spacetime between the source and the observer. And when we do this dispersion test, we are also able to constrain the gravity on mass because some of the parameters. Mass, because some of the parameters directly relate to the gravity and mass. And we also try to constrain the number of space-time direction and also the speed of gravity. Because if the source emits gravitational wave and it reaches the observer, if it observes, it reaches at the same speed as light, then we can also constrain the speed of production wave. The third one is where we are checking. Checking the polarization content of gravitation wave. As we know, in GR, we have two independent polarization states, H and H. But in a generic music theory of gravity, there could be up to six polarization states. So by checking or counting those number of correlation states, we can also test TR. So by constraining any alternative correlation test. So with these number of parameter tests and Number of param tests and using the rubric of data, LIGO, Ardupagra collaboration have performed tests on the events observed in GRM TC3. There are about 49 events on which the tests have been performed because these are the events which are very high significant. For testoster we only use events where the false lump rate is less than one in 1000 per year and with And of course, different tests also have their own selection criteria. So, not all events being analyzed by each of those tests. So, but the 49 is the total number of events, but different tests have their own number of events on which the test is applied. So, after doing all these tests, the one-line summary of that paper is that there is no deviation of GR has been found from LBK in the data, but In that data, but there are certain things we should take a closer look. So, in the third catalog, the GWTC3 catalog, we did this modified dispersion relation. If you remember, we check the dispersion of gravitational wave from the source to the observer. And this is called modified dispersion relation test, where we have a parameter called A alpha, which is the phenomenological parameter. So, if A alpha is 0. So, if A alpha is 0, the gravitational wave is not dispersed. So, everything is as predicted by G R. But if we get a non-zero value of A alpha for any value of alpha, which is our phenological parameter, so if we get a non-zero value of A alpha, that hint towards the dispersion of gravitational wave. So, this is the following plot we get after analyzing all the actually for this test we analyzed forty-three events. Test: We analyzed 43 events, and the red one is from the GWTC3. And we see that for some values of alpha, for example, alpha is equal to 1 and alpha is equal to 1.5, the 0 value, which is the GR value, is not encompassed by the 90% federal interval. So we basically exclude the GR value in this test for this value of alpha and the two values of alpha. Is of a loss, so that there is some tension here. But if we exclude these two events, GW200219 and GW200225 from the list and we combine the result again, we get this blue volume, which now encompasses the GR value within the 90% critical interval for all values of alpha. And also, kind of is consistent with the previous catalog result from GWTC2. From GWTC2, more low than the increase of number of events we got from GWTC2 to GWTC3. So, in the collaboration paper, we just wrote that this is verbatim from the paper, we say that these two events require detailed analysis to understand the reason for observed deviation, which we leave for follow-up work. So, we really don't know what is happening with these two events. The only thing we can say is that they got the lowest. They got the lowest residual SNR in the residual test. But other than that, it's like we also check the data quality issue, etc. But of course, the follow-up work is required to understand better what was happening with these fuel lines. So we have the result for modified disprogeneration. And then the other group from outside the UK reanalyzed this event, GW20029. GW200219, but this is different than the other GW29, which I showed in the previous slide. This is the event which has been claimed to be precession. Relativistic precision has been found in this event, but this is also the event which have shown that the precession we are seeing is because maybe some data quality issue. So, anyways, this event has been analyzed by groups outside the collaboration. Groups outside the collaboration, and this is the test they perform. This is a plunge merger test they perform using an aligned spin model. And it's another aligned spin IMR model which they apply and try to look for deviation in the amplitude of gravitational wave in the post-plunge signal. And this is what they found. So, this is the result they got it for their real data. Their real data. And they also did some injections from SUVNR we form in zero noise and Gaussian noise. And this is kind of again some tension here because if you analyze the data, you find that it is not encompassing the zero, so the GR value. So the question is: we use a line spin model, so and this signal is also. This signal is also claimed to be processing. So, is this something some kind of waveform systematic? Or the groups have claimed that there is some data quality issue is happening. So, maybe there is some, we have not been able to mitigate the glitch properly. So, these are all open questions for this event. So, what is happening for so that we are getting this GR del mission in this test? Then, very recently, we have Very recently, we have this event, GW230529, which is from the O4A observation. This is the only event we have public at the moment. And this is an event where one of the objects is in the lower mass gap. And people performed again test of GR on that. So on the x-axis, we have different GR deviation parameters. So any of these values, if we found to be non-zero, that found to be non-zero that hints towards some GR deviation. So we see that for phi naught which is a zero pian deviation parameter, we see that the volumes are all excluding zero. Whatever waveform model you use, all the volumes are excluding the zero, which is the GR value. So again we are scratching our heads and say what is happening here. A couple of things to note down, this was A couple of things to note down. This was a well-known thing: is that there is a correlation between the chirp mass and the zero Pn term, and because of that correlation, one can so is like if your chirp mass is higher, your delta phi naught is also higher. So that would be one reason. But again, if it is correlated, then it shouldn't exclude zero, it's just that it should be a long tail, including zero value. Including zero value. It is also a single detector event. So if we have any noise in the data, we would not be able to kind of cross-check it with other noise in the other detector. So if even if there is any subtle noise which we have not been able to find, that could also cause this deletion. And of course, there is some prior choices we have made in the analysis. For example, we choose. For example, we choose uniform in component masses. So, and that prefers higher sharp mass, and higher shared mass means higher value of delta phi naught. So, that kind of the shift you are getting is might be because of our prior choices in the patient analysis or some sort of sampling issue in our parameter estimation. So, these are all kind of the possibilities were noted by the authors in this paper. Noted by the authors in this paper, but all these examples which I've shown you is hinting that there's something going on in the data which is not poetically indicating towards the GR consistency. So how should we do a precision test of GR in strong gravity with these kind of caveats? So the first thing is that we have to assess false causes of TR abbreviation or TR abolitions. Or GR violations because we know that our waveform models and our analysis techniques are not on par ideal. So before we talk about the precision test of GR, we have to deal with and understand these causes which can lead to GR volation. These are occurrent GR volation, and this is I've been thinking for last couple of years. So, how do we deal with these things before we? Do we deal with these things before we can claim any deviation in GR from directional data? So, the first step is to enumerate the list of possible causes of GR violation. And for that, this summer we put up a review article where we try to list all possible causes of GR false GR violation which we can think of. Of course, if there are more, if there are any other causes, you know. Causes you are, you know, please let us know. We can include that in this paper. So, in this paper, we try to categorize all the causes which we know of into three categories. Of course, it is not a strict categorization. Some of the causes may belong to some other category or not. But just to make the discussion current, we had three categories where we say that if we find some tension in which we are in data, what could be the issue? The problem, what could be the issue? One is maybe our noise in the data. So, the assumption we have in our data analysis is that the noise is stationary and Gaussian and it is also free of glitches. But of course, this is not 100% true. There are, of course, some data quality issue. So, anything related to data or non-Gaussianity is in this category. Like, we also have data. Like we also have data gaps and detector calibration, which is not problematic at the moment, but in future they might be. The second category is the waveform systematics, where we know that we do not account for all known physics in our waveform models, which we use for test of GR. For example, eccentricity and tidal effects, viscosity, or peaks, etc. So, this is all anything which is missing in the waveform model or not accurate. In waveform model or not accurate waveform model goes into this category. And then there are astrophysical causes, for example, gravitational lensing, which I did talk about. The binary or the signal which we are looking for could be in an environment which also affect the signal. And if we don't account for that, that would also lead to some of the GR volition. And there could be mistaken source class. And of course, I'm going to talk about some of them in detail, but not all of them. In detail, but not all of them. Maybe we can discuss that tomorrow in the morning session. So I'll save some of the discussion for tomorrow. So let's talk about some of them in more detail and what we know currently, what could cause the upper GR volition. So as I said, in all our data analysis, we assume that for the chunk of the data we are analyzing, we assume that the data is non-stationary, that means it doesn't change over time. Change over time and it is also non-Gaussian, that means it is free of glitches, etc. So, these are some commonly occurring glitches we know from the data. And the most famous one is the glitch we got around the time of CL217 or 17. But, of course, the signal was too loud and visible in the data. We were able, and of course, the glitch was also loud and visible, so that we were able to subtract it and then reanalyze the data. It and then reanalyze the data. So, glitches are there in the data, we know that, and we try to mitigate them, we try to filter them out, but the filtering is not always gives you the desirable results. And any non-stationarity and non-gaussianity in the data can affect actually all your analyses. For example, it affects the searches, parameter estimation, astrophysical population inference and. Astrophysical population inference and cosmological parameter inference, etc. But of course, the test of general relativity people have shown that if you have some signal and you have an overlapping glitch, even if you subtract that glitch, the residual data or the residual of the glitch can give you GR deviation. So, this is the result from Prop Edel in 2022, where they show that if you have an unmitigated data, which is the shaded Unmitigated data, which is a shaded region, and even if you try and remove that glitch using different methods like bank passport cleaning or glitch subtracted method or impainted method, and then you do parameter estimation, sorry, then you do test of GR, then you even then you get some GR volition because as you see that true value of chug mass is here and your chop mass which you have info is. Your chug mass, which you have info, is very biased. And here you are getting basically this 54 parameter, which is the 2pm deviation parameter, you are getting a deviation in that. So even if you mitigate your glitches, that can also give you GR variation, upper GR variation. The next one is missing physics. I noted down some of the things. Some that list is again here. One of the main thing which we are missing currently in our WEFO model is. are missing currently in our before model is eccentricity and we know that the finding eccentricity is not large eccentricity is not we know that we will not find large eccentricities but there will be some eccentric signal in our in our catalog so if any of these happen to be eccentric and you analyze it with your poisircular templates they may show up as real deletion and Up as GR irradiation. And of course, the tidal effects, if you have neutron star in the binary, then the modeling of tidal effects in the waveform model is not very, I would say, mature at the moment because the numerical retrieval simulations we use to calibrate our waveform models is not as mature as the binary black hole numerical simulations. So, there's some improvement we need. And of course, there are effects which we use. There are effects which we account in your ring-down signal because you also do ring-down test of GR. So, if you miss some things, that can also give you devision in your test of GR. And of course, kick-induced effects, these are small effects, not problematic at the moment, but of course, in future, whenever detectors become more sensitive, these can also lead to some biases. So, talking about eccentricity. So, talking about eccentricity, there have been many studies have done, and they found that if your signal is eccentric and you perform your test of GR using, which uses coicircular waveform model, you would end up having GR deviation. So, this is an example from the paper which read by my student. If you inject an aquas circular NR waveform, let's say, and you perform test. Way form, let's say, and you perform test of GR, which is this parameterized test of gr, all your volumes are consistent with the zero line, so everything is fine, it's all gr but if you have an eccentric signal where the eccentricity is 0.05 at 17 hertz, then you see that the volumes are now shifting away from zero line. It is showing that it is there is some GR deviation, and if you increase your centricity even more, the deviation is even more. The deviation is even more. So, if your signal is eccentric in the LIGO Virgo Karbra band and you do the test of GR, the usual test of GR, you will find GR delivery in your test. Talking about the inaccurate modeling of known physics. So, these are the effects, the eccentricity and the tidal effects are, we know that we have not accounted for those physical effects. But even though, if you account for some physical effects, Though, if you account for some physical effects, those physical effects are not accurate because the waveform models we use in our analysis are all phenomenological models. They based on some approximation and they are also heavily calibrated against the NR simulation and we know that NR simulations themselves have some numerical error. So, there is always some truncation error or numerical error you will have in your wafer model, no matter if you have. No matter if you have incorporated all physics, so because of that truncation error, you can also get some biases in your analysis. And of course, none of the waveform models currently we apply use memory, incorporate memory effects, so that can also lead to some biases. So, this is a kind of old study, which showed that if you don't account for higher-order modes in your waveform model and your signal has In your waveform model, and your signal has higher remorse, then it can give you GR deviation. But of course, it's an either said old study, but now I think the waveform model, whatever waveform model we are using, they have all higher order modes in them. So that at least we have got rid of this issue here. Then the astrophysical effect, as Ajit talked about gravitational lensing, so it also talked about different types of lensing. He also talked about different types of lensing: strong lensing and weak lensing and microlensing. So, if you have strong lensing, strong lensing are of three types: type 1, type 2, and type 3. And type 2 lensing actually gives you a GR, gives you a waveform which is very much different than the GR waveform you would expect. And I'm going to show some results from that. So, we can also get some apparent GR violation due to astrophysical aspects, for example, neurosystem. Aspects, for example, your signal can be lensed, or your signal can be, or your source could be in an environment like gas as environment or AGN disk, or your source is not the one you are thinking of. It could be a black hole mimicker, or it could not be a CBC event, a compact battery coalescence, or it just could be a parabolic or hyperbolic encounter, just like we found that for GREPLU150921, it was. It was called anything you like. It could be also a head-on collision. So, if you have a different source model altogether and you are trying to analyze that with your CVC waveform model, then that can also give you some GR division. So, just to show some results, we have for the strong lensing again led by my student Punima Narayan. So, here we have strongly lensed. Have strongly lensed binary black hole signals, and these are type II lens signals. And actually, the waveform or the signal you get is different than what would you expect from GR because strong lensing shifts your waveform by pi by 2 for each higher order mode. And if you have all the modes combined, it will not be a trivial shift in just phase. So you will get some non-trivial modulation. Trivial modulation in the phase, so that will lead to some non-GR effects. So, if you analyze your lensed signal with an unlensed test of GR, you will also get some deviation. So, here the result we are showing for binary which has mass ratio 5. And as you increase the spin of the signal, the deviation become more. So, for highly asymmetric systems and highly spinning systems, And highly spinning systems, we will get deviations in GR if the signal is strongly mixed. So, talking about the future, so whatever the causes we have listed in our paper, they are not all problematic or we don't have to worry about them at the moment. There are some effects which are more important than others. Which are more important than others. So, moving forward, of course, we are in currently in O4, and in three years' time, we'll enter the O5 era. And then we have A sharp and Voyager and then 13 inch detectors. So, given that the sensitivity of our detectors will be 10 times more, so all the events which we have listed in the paper can actually be problematic, at least when we go. Be problematic at least when we go to the third generation detector. So, this is kind of a crude way of showing which of these effects we should worry about at the moment and we should not worry about at the moment. So, the process means for a given sensitivity, this is not an issue. So, we should not worry too much about them. And the check marks means we should be worrying about them. For example, the non-stationary and the non-gausionity in the data is present all the time. Is present all the time. So it's a problem anytime. But for example, let's talk about memory. So memory is not an issue, not a problem for O4 and O5, but in A sharp and 3G, it could be, we should take into account otherwise it would be reverse biases. So now you see that in the HGLR, which is for the third-generation detector, all these effects have check mark, and it's again, it's our from our And it's again, it's from our current understanding. We don't know exactly quantitatively if they are problematic, but we have to test and see if they are making any difference or not. So with this, I'll summarize. So the parent waveform model used in our test of GR analysis are not perfect. That can lead to false GR evolution in many scenarios. And we need to make our waveform models and also the test more robust. Also, the test more robust. The effect of false causes of G-Reporation needs to be assessed because, whatever table I showed you last time here, it's all based on our prude understanding of the rates and the results we have. But I think each of these need to be qualitatively assessed, and that means we need to kind of do some injection campaign and try to see if any of these effects are any of. Are any of these checks and crosses are indeed correct or not? So basically, we have to build a community-wise consensus on this list and also the framework to deal with in the event of if we do get any false any GR deviation in the data, say in O4 or O5, what should we do? What should we tell the community that do we have a GR deviation or it is because of all these things we have discussed? Because of all these things we have listed in this paper, but if it is because of those, which of those effects are kind of causing the problem? So I'll just stop. Thank you. There's a question on Zoom. Please go ahead. I have a very nice question. So let's say you have one event which sort of violates here for one of the tests, but it doesn't violate GR for the other set. But it doesn't violate GR for the other set of tests. Will you call it the violating GR or is it just it was systematics in the test itself? The second question that I have is like, when can confidently say that it's a GR violation? Meaning that if you say CR deviation, Form 0, are you going to say it's a violation of GR or are you just going to wait and see a 5 sigma deviation from 0 to claim our GR virus 0? Yes, sir. My first question first. Yes, sir. My first question first. So I think you say when we get GR deviation from one pipeline and not from other pipeline. Yeah, so that's kind of the thing we have to think about. So we have to kind of develop a framework when we kind of call any GR deviation serious GR deviation. So if one pipeline is giving you a very large deviation, like five sigma type of GR deviation, I think that's a clear indication. That's a clear indication, but of course, it could be due to the waveform systematic, as you mentioned. So, we have to kind of investigate it further and see whether this deviation we are finding is indeed because of that cause. Of course, when we