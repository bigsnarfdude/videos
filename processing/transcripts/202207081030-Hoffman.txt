Thank you for the opportunity to speak here. It's been a wonderful conference. So I think we should thank our organizers for bringing us to this beautiful spot here. My talk begins about 15 years ago in another math institute in a setting almost as beautiful as this. Beautiful as this. I was in Rio Vidy visiting Vladis Surovicius at IMPA, and he was all excited, as he always was, about some new problem. And the problem was one that we've heard about today, or we've heard about it earlier this week, activated random walk and a corresponding model called the stochastic sandbox model. So you take your favorite graph. My favorite graph is Z. The physicist. My favorite graph is Z, the physicist's favorite graph is Z squared, but everything here will be, that I'll talk about today pretty much will be on Z. And we want to, so I take the nearest neighbor graph on Z and then I have particles, and I have two types of particles. So I have So I have particles like this, which we'll call awake and the circles are particles that are asleep. So the awake particles do simple random walk with rig one. This leaving particles stay hood until an particle arrives. So, this right here is. So this right here is the fraud model that we started off the conference with, but with one more thing, my OA particles will move with rate one and with rate lambda. If this guy here chooses to fall asleep and goes like this, then there's an awake particle there and it immediately gets woken back up. So it's only the individual awake particles which can go to sleep. And then if this particle here decides to move here, then we would move to a configuration like this. So this is activated random walk and Walk and the stochastic sample file, which I won't say very much about, is going to be very similar, except these particles fall asleep with rate infinity. So they fall asleep immediately. immediately now this is ideal a but we're going to have um we're going to have one other thing so so paired so particles so sites with multiple particles Are automatically awake. And the movement is going to be pairs of particles move at a time. So I take a site where there are two or more particles, and then those two particles will each do an independent simple random extra. So I have some situation like this here, where these two particles, maybe they both decide to Maybe they both decide to move here. And that will wake up this particle here. And now these, I have two sites again that have more than two particles. And maybe now, so I move two of them. This time I'll move them in opposite directions. And then they go to site square or something. And then they instantly. Where there's nothing, and then they instantly fall asleep. And the remaining one also instantly falls asleep. The remaining one also falls asleep as well. So this is the stochastic sandpile model. And this is the model. So Vladis was talking with a physicist, Dickwin, and this was the model that he was extremely interested in. And Vladimis thought that activated random walk was a model that had a lot of the same characteristics and was much easier. And Vladis usually had a very good intuition. In this case, he did. So it is generally believed that the stochastic sandpile model behaves in exactly the same way that activated random walk does. Active random walk does, and it's just quickly computationally hardware. So the sorts of behaviors that we're looking for, right now we're having enough problems finding them in accurate random walk. And the stochastic sandpile model, probably the same technique for just a lot more technical details that you may not want to see. And I want to see. So the question, so first, are the bottles clear? Okay, so the questions that Vladis was really interested in. So my initial configuration It's going to be ID on view articles at every site and so then so one. So one for any lambda, zero between zero and infinity activated random walk as a value. Volu mu C and mu below mu C the system stabilizes almost surely and mu greater than mu C it does not stabilize. So stabilize means each particle moves only quite a many times, or equivalently, each particle, each site has particles arrive violently often and not stabilizing as particles arrive infinitely. Okay, so I wrote this down. I didn't get this conjecture quite right because this is This is actually right here is pretty clear. The part that is conjectured is that this critical value is strictly between zero and one. It's easy to see that with no particles, the system is stable. And if I have on average one or more particles, Have on average one or more particles per site, then the system is never going to stabilize. And then the other conjecture is that the same thing holds. Is that the same thing holds true for the Segaxi signal? This was a question that Laos is really nice. And so do we get an eraser? So, one tool that we have, and basically the only tool that allows us, gives us any hope, is the abelian property. So when I started off with my picture and I said, okay, we've got two particles here. Okay, we've got two particles here. These ones will move. I didn't worry. I had multiple choices for which particles, which site with multiple particles, I could take a pair and move them for the stochastic sand file. Or I also, in the activated random walk picture, I had multiple sites that had an active particle. And I didn't really tell you why I chose one rather than the other. Why I chose one rather than the other. And the answer is that it doesn't matter what order that I do this. So the abelian property says if we have a set of instructions at every so we have lots of instructions. At every site. Then, so what does that mean? That means, so here for activated random walk, my instructions can either be the particle that's above that, the particle. Particle moves to the left, the particle moves to the right, or the particle falls asleep. So I vision this as for each site, I have something that looks something left, right, sleep, sleep, right, right, left. And I've got this sequence of instructions here. And the way that I do it is I just take the lowest one on my list that I haven't used, and if I choose to use it, I use it. And if I choose to move a particle at zero, I just take the lowest unused instruction on my list and I do that. And then I, so I move my particle, my weight particle goes from zero to left to minus one. And then I cross that off the list. So I've got this set of instructions in the final configuration. Is independent of the order of the moves. So, this is one thing that is really, really helpful. And more helpful than this fact here is the fact. Here is the fact that the odometer, the number of instructions used at each site, which I will call use of I, I'll call that the odometer at I is also. It is also I can say always work with the leftmost particle, choose the leftmost particle and move that until it stabilizes or doesn't become the leftmost particle and move on to another one. Or I can choose either. One or I can choose any way that I want, and I'm going to get the same thing. And importantly, the number of instructions that I use will be the same. This is really the only thing that gives us any hope of analyzing this file. So um, I mean I mean, anyone who ever visited Blattis knows that he would be really excited and he would tell you something like this, and then he would also be super busy and he would go off on all his meetings. And so I just thought about this problem. And when I finally got a chance to talk to him again, I said, well, I don't really have any thoughts on this problem, but there is one problem that I can't. Problem that I can't cause. And so there's one aspect of activated random walk, which is quite simple. And that is if I do directed activated random walk. So my only two instructions are going to be either the particles move to the right or they fall asleep. And I said, in this case, we can figure out exactly what the. Out exactly what the critical value is. So, and this is kind of a nice example of it being improperly. Nice example of the behavior property. So let's assume that I got one particle, one active particle at the origin, and then I've got these other particles here. I've got some configuration like this. I want to say that this system, I want to decide whether or not, based on the two parameters, mu and lambda, the rate of falling asleep and the density of particles, I want to see whether the system is going to continue on forever and the particles are going to move infinitely many times, or whether it's going to stabilize all of them. Stabilize the lunch. I can do that. So, and what I'm going to do is, since I have the abelian property, I can choose to move the particles in whatever order I choose. So I'm going to first move all the particles I can from zero to one, and then all the particles I can from one to two, and then all the particles I can from two to three, and so on. So let's put some notation here. So xi is the number initially at i and this is IID Pass on you. And then I'm going to have, I said that I was going to move the particles from left to right, starting at zero. Sorry, you sense Z or you want C plus? Well, it doesn't really matter. So I'm on Z plus right now. It's not too hard. Once we analyze it, I'm. not too hard once we analyze it on Z plus to start analyzing it again on C. So Yi is the number of particles that And ZI are going to be equal to the number of particles. Behind I behind and I. So after I move all the particles from Y Z1 is after I move all the particles from one to two. Then maybe there's a particle left behind. Maybe there's so conditioned on YIB. On YI being positive, these guys are independent, Bernoulli. So these guys here are IID. So, what's the chance that one gets left behind? They get behind, left, told to fall asleep with rate lambda. And the possible instructions, they move with rate one. So the chance that it falls asleep before it moves is lambda over one plus one. Initially, you take one particle to be active. It doesn't, it doesn't matter. Matter all I need is one active particle. So I'll start with one active particle at George. Okay, but I could take them all active. Of course, but I was supposed to. I could take them all active. I could take all of one to be asleep. And once we do the analysis, it will become clear that it doesn't really matter. But if making them all active makes you happy. Active makes you happy for just the sake of definiteness, then we can start with a model active. Okay, so it doesn't change because the particles you leave behind at E doesn't have a term of the number of particles that reach E? No, so say at three, say all these guys make. Three, say all these guys make it to three. And so here, then I get that E3 is equal to four. Then what happens? The first three, the instructions, I could get sleep instructions, but if I get a sleep instruction, they immediately get woken up. So the first three are going to move here. Here, wake this guy up, and like this. So, eventually, I've got to get some sleep instructions. I can ignore those because it will immediately get woken up until I get down to one awake particle. And now this particle has, will fall asleep with rate lambda, it will move to the right with rate one, so it has probability lambda over one plus lambda of falling asleep. And that's independent of everything that I've seen in the past. So, all I really care about is the one sleep instruction or the one instruction that I see after I get down to one article again. That's the only thing that happens. Is this clear? Yes. Okay, great. So now what do I see here? I see that I see that so what's the so I get that y i plus one is equal to what it's equal to Y i, the number of particles that get to i minus one. So all the particles that make it to three will make it to four except possibly one, plus the number that are at i plus one initially and now. And then, do I want to, and then the number that fall asleep. So let's so y i write i either and then minus zi. So zi is either zero or one. So either zero or one of the particles get left behind that. So this is, I can write down this if. So this is, I can write down this equation and then I can rearrange this and get yi plus one minus yi is equal to xi plus one minus so what's happening to yi so yeah yi is now particles that arrive or that are at i so the number of particles well the number the number of particles well the number of particles the at okay so yeah so it should be the number of particles at i when i start moving so then the z i are iodi bernoulli conditioned on yi strictly larger than x i this is not what when you set it to z i or i d vernodi it's conditioned on condition conditioned on y i v Conditioned on Yi being at least one. At least one or at least Xi. What? At least one or at least Xi. I was thinking that at Xi originally there were only sleeping particles. If Xi is zero, then Yi is at least zero. It could be zero. No, but I'm not sure about this conditioning. The Zi Arber Nulli, if you know that you. Bernoulli, if you know that you right, that you have some. I can think of the ZIs as being Bernoulli, and they just tell me if one particle makes it to I in this procedure, then this is the, at least one particle is at I initially or makes it to I in this procedure. This is the number that gets left behind. So it's the last instruction, okay. It's just the last instruction. Okay. Okay. So what's happening here to YI? It's doing a random walk. And so these guys, this is an independent sequence, and this is an independent sequence. And so what is the expected value of this here? The expected value of this. The expected value of this. So the expected value of yi plus one minus yi is the expected value of this, xi plus one. So that is mu minus the expected value of zi, which is lambda. is lambda over one plus lambda. So now if mu is bigger than lambda over one plus lambda, then this random walk is going to have a positive drift and it is almost surely going to, with positive probability, it will never hit zero. And then and then I don't need to worry about it. And then I don't need to worry about any conditioning because all the eyes will get visited. And I don't need to worry about Christina's question about whether they started asleep or awake because they will all get visited. So they will all turn flight. Okay, and now back to Laura's question about whether I'm working on Z plus or Z. So I have been working on Z plus. So I have been working on Z plus, but I can pretty easily use this to conclude that if mu is larger than this, then the system does not stabilize. And if mu is smaller than this value, then it's pretty easy to use this random walk here to see that the system does stabilize almost surely. So So this right here, we can see that Vc is equal to lambda over 1 plus. So this is kind of one example of how you can use the abelian property to actually analyze this system. So are there any questions about this? Now, so now I can replace this conjecture with a theorem. So various parts of this are due to various people. All these mu C's being All these mu c's being greater than zero are due to roller and survives. And how do they prove this? They prove this by using an argument fairly similar to the directed case. The particles they're finding, they're finding at some random place, and they want to say that they're deposed or they're deposited at some faster rate. At some faster rate. So they find a very clever way to deposit particles. Here I just deposit a particle by saying, well, we got down to one and either we left that one behind or we didn't leave that point behind. They have some very creative way of depositing particles, but they basically do the same argument here that we didn't really do when you see when the density of particles. When the density of particles is less than the critical density, lambda over one plus lambda, then they're able to say that the system stayed plus. So Rula and Senator Vitrus showed that that was less than one with Reedy and one of our absentee organizers, Shoshindu. Sure should do. We prove that when lambda is small, that the critical value is less than one with Jacob and Leo. We prove this for all Lambda. And then in hopefully soon, forthcoming work with my student Ethiop, my former student Jacob, and Grizzolo. We are So we are proved that BC is less than one for the stochastic sampling model. So are there and then this has also been extended as Vittoria said. So the rest of my talk is going to be some combination of the things that Vittoria was talking about and then some and the things. And then some comments, and the things that in a multi-scale argument. We haven't had a multi-scale argument today, so I will try and throw one in. Are there any questions about what we've seen so far? I understand correctly. The missing result is just mu C larger than zero for stochastic. Oh, oh, this is Roland Center emissions as well. Yeah. So conjectures were theorems. Yeah. conjectures wet theorems yeah so so all all that for z uh unfortunately the z2 uh much less is dope okay so now i want to give you some sense of why this is true when lambda is small and and then do a multi-scale argument and then sketch a multi-scale And then sketch a multi-scale argument to say that we can extend it to all values in the math. Okay, so I said before that the thing that we really can use is the abelian property. Is the abelian property, and I haven't used the part of the abelian property about the odometer being if the system fixates, then the odometer is well defined no matter how you stabilize it. You'll use the same number of steps in each at each setting. So So my initial configuration now is going to be the same one that we told you was talking about. So I'll do activated random wall. And now I claim that if this, so this is my initial configuration, and the question I want to ask is, does this stabilize? All particles in the interval from minus n or no particle ever moving outside of minus n. And I claim that, so I gotta. So I gotta claim two things. First, if lambda is small, if lambda is small, then it's gonna be extremely unlikely that it does stabilize here. And then we could use that fact to say that if lambda is small, the system does not fix. So I will not, that second thing that will not that second thing that if the problem if this probability is small the system does not fixate i'm going to just let that let you verify that on your own and i'll just work on this statement but is the statement uh clear so unlike some of the fancy techniques that we've seen Techniques that we've seen throughout the week, I'm going to use a very simple technique, which is the union value. So, and what am I going to take a union over? All possible O values. So, I know that if this stabilizes, so if this stabilizes in this interval, then we get. Then we get and O'Donnell U minus in through U in. So I have some set of instructions. If it stabilizes, I can say. If it stabilizes, I can say how many times was an instruction at three, how many times was an instruction at minus k. And I want to take a union over all possible. Now, this is problematic because, well, there are infinitely many possible adoptions. So I want to do two things. First, I want to show, I want to say that. So I want to say that the set of ogometers is really essentially finite. The probability that the ogometer is very large and it stabilizes in this interval is going to be very, very small. I don't understand. But if it's a Virantis, we can also have to use a destruction from outside. So by stabilize, I wanted to stabilize with the particles. To stabilize with the particles never leaving the ah, with the particles never leaving the interval. Yeah, there's not a lot of difference between those two things, but yes, I do want it so stabilized in here, and I want no particle ever leaves minus any. Sorry, maybe it's a stupid question, but are the instructions independent from the LED function? Once you know how many instructions were used. No, no. The instructions, the dollar function is a random function that depends on the instructions. So you choose the set of instructions independent at every spot, and then we stabilize, and we'll get. And we will get a function, but if it chooses a different set of instructions, we'll get a different function. So, yes, make sure that what I mean is conditioning to the number of instruction used. Are the instruction like still no, no, no. So I want to count the number of I want to say that if If the sum i goes from minus n to n of mu n is at least into the fourth and this event here is automatic. So, why is that true? This is true because, well, if I take, if I do into the fourth instructions, then I'm probably going to do constant times into the fourth steps. And I've got in particles. So some particle has done a constant times in cubed steps. And the steps that this particle take are just going to be simple random walk. It's going to be simple random walk. So it's going to be exponentially smaller in the probability that a given particle does in cube steps without leaving the interval. So I've restricted this from an infinite set of odometer sequences that I need to consider to a finite set. So that's some progress. So that's some progress. But we have, so now we have something on the order of how many odometer sequences do we need to consider? We still have something on the order of exponential into the four. And the probability that I, for a given odometer sequence, the probability that the last The probability that the last, the top term on at least n of them is asleep is going to be exponentially small again. So we still have to reduce the number of plausible odometer sequences further. And we can do that using the following. So now I want to fix two things. It's the dominant zero and the number The number of particles possibly greater than zero. And I claim that this tells me: so if I me so if i know use zero i know the number of moves from zero to one because i know i know how many instructions i used to zero i've got a list of instructions i can see how many of them told me to move a particle from zero to one so for the number of passing that you have you can eat them on the exact number or just on the credit d zero zero just just i i i fix these numbers this is a million and Numbers. This is a million, and this is 500. Something like that. And now I so if I subtract off the number of particles that go from one to zero, this tells me the this is This is equal to the number that fall asleep to the right of zero. Because initially, there are no particles to the right of zero. And then I just, every time I move a particle, every time I move a particle to zero from zero to one, that increases the number of particles that are in positions greater than zero. Every time I move a particle. Than zero. Every time I move a particle back from one to zero, it decreases the number, and so nothing else can change it. So that tells me the number that falls asleep greater than zero. So is this clear? Now, this almost Tells me the odometer at one because I've got this list of instructions at one, and I know that I use 100 instructions move to the left. So I just go up my list, and I see where the 100th instruction of moving to the left is, and the odometer has got to be at least that. And the odometer has got to be at least that high in the list. And I see what the 101st instruction moving to the left is, and it can't be that high. So say this is two, and my instructions look like left, right, sleep, left, right, left here. So this is the first left instruction. This is the second left instruction. And this is the third. The only two possible. the third the only two possible values for the other dominator are one two three four or five so there are only in this case two possible choices for what the odometer could be and this is so now for any choice of the ogometer then I also know the number of particles Also, I know the number of particles that fell asleep greater than one. And so I can repeat this same argument, and I can say that really the number of odometer functions that I need to consider is going to be exponent, is only going to be kind of exponentially large rather than exponentially large units of the four. And so this gets me down to where x plots. Down to where it's plausible that I could use a universe. And there are some technicalities that go into this, but at each stage, I kind of get this tree of possible odometer sequences. At each stage, I can add on some random number of possible. So if I know the odometer at 0, 1, 2, 3, I have some number of possibilities for what the odometer is at 4. For what the odometer is at four, but it's how many choices am I going to get? I'm really going to get, on average, only a little more than two choices for what the odometer is. Because after here, I want to know how many steps do I get before the next left instruction. And a left instruction has probability just slightly less than one half, because slightly less than one half left, slightly less than one half right. Uh, slightly less than one half right, and a very small sweep of quad. So, I really have roughly kind of two-to-dn choices for what the odometer function could be once I've fixed u zero, which has to be less than n to the fourth, and this number, which has to be less than. So, it's something which is exponential in n math. But there is some dependence between U0 and this number, right? So you fix U0 and the part of the follow-up slip to the right, then you won't have one half probability to get R or L at one, right? I just choose a number here. So yes, if I know, if I know, so all I'm going to do is I'm. All I'm going to do is, I'm going to just take some number which is between zero and n to the fourth. And we got to say, and some number here, which is between zero and n. And then I'll just look up on this list here. And that gives me some number of instructions here. And then I say, well, the only possible dominant function. The only possible odometer functions that could match are some here. So I'm not conditioning on this is actually the odometer, but I'm just taking some number and saying, if this were the odometer, then there could only be certain other choices. And that gives me the end of the. So that's an important thing to notice, to note, and I should have said that properly, but I just fixed this number. I just fix this number, and for any given choice here, then this sequence is independent of that number. And therefore, the number of possible ways to extend it is independent. So I'm not conditioning on what B0 is and what the number of particles is. It's just take two numbers. And for those two numbers, I want to say. I want to see how many sequences, odometer sequences, are consistent with that, whether or not they're the actual odometer. I'm sorry, you may have said this before, but here are you. So you know you of zero and you get sort of, say, two choices for you of one. Why do you not get sort of four choices for you of two and eight for you of three? So I get a tree. So for each choice, So for each choice, so now I know what my value of u of one is. And now I know also how many fall asleep to the right of one. So then that tells me how many particles move from two to one. If you knew you would, but I thought you don't quite know you will, right? Yes, but for each, for each choice of for each. For each choice of, for each possible value from u over 1. Yes, yeah, sure. I guess what I'm saying is if you have two, sort of one choice at the top, then two to the choice at the point. Yeah, yeah, so I get exponential. Okay, but then if you add that up, don't you get sort of two to the n squared instead of two to the m? Maybe I'm not jumping. No, no, so I get some sequence, mu zero, mu1, mu2. And each time, and say I've got a hundred of these sequences. 100 of these sequences, and now I want to extend it for each of these sequences. I have a couple of choices for how to extend it on average, slightly more than two. So the number of possible sequences is going to be exponential in the length. It's going to be two plus epsilon to the to be and then I can say for any given sequence the For any given sequence, the chance that I find a lot of sleep instructions is going to be exponentially small. And I can make that exponent as small as I want. And therefore, I can win this union battle. So is that clear? And now I see I've got about three minutes left. About three minutes left to try and sketch a multi-scale argument. But what I want to do is I want to so here this picture is going to be round to small and so here I had sites And edges. And here I'm going to map these down to a site. It's going to be mapped down to a region here. I will call a block. And the edge is going to be mapped down to what we call a transit region. And I want my system here, where lambda is large, to behave kind of like it did here. So there is no possibility a particle could ever be stuck between two sites. So in here, I've got a new pull. So I want there to be no possibility that there's ever a particle stuck in a transit region. Stuck in a transit region. Well, how can I do that? The only way that I can do that is I can put a particle at every site in the transit region. Sites could be either be empty, they could be occupied by a sleeping particle, or they could be occupied by a wake particle. So here, So here, now this isn't very good, putting a particle everywhere isn't very good for getting density less than one. But so here, my density, I'm either going to put a particle everywhere, or there will be one spot where there's a particle missing. And then, so I will have down here configurations of particles that. That are the analogs of sleeping configurations of active particles or empty things here. So I'll kind of say all the possible things that I can have in this plot correspond either with an empty site, a site with one sleeping particle, or a site with active particles. And so I can write that down, and then I can say. And then I can say, well, the chance that this whole system falls asleep now is not really, not this really large value, but the chance that all these things fall asleep is now really, really small. And I can't really say more than that in the 20 seconds I have remaining. So I think this is a good place to quote that.