In the PRIA, about differentiation simulativating operators for the pair GLN and GLN minus. So, please. Okay, thank you very much for the introduction. And I would like to thank the organizer for this very nice conference and the invitation. So, yeah, today I'm going to talk about results that we have together with Jonathan Ditlefsson and Jan Fram from Ors University. Fram from Ors University about an explicit construction of differential symmetry breaking operators. So for the pair GLN plus one, GLNR. Okay. So thanks to Professor Kobaeshi and Professor Kubo who gave some nice lecture. I don't really have to introduce a lot of notion here. Notion here because they clearly define very well symmetry breaking and they talked a lot about also the F method that I will not mention too much, but like that you have a background on this kind of branching problem. So thanks to you. And so yeah, I will start with a classical consideration. So we choose the pair GLN plus 1. The pair G Ln plus 1 G Ln R, okay, where H is embedded as using the left upper block on the diagonal embedding. And our goal is to construct explicitly some differential symmetry breaking operators between two principal series representations, so which are induced from a minimal parabolic subgroup. Okay, so. Okay, so for this kind of problem, that would be natural, and I mean, we tried a bit to use the F method, so developed by Professor Kobayashi, Professor Bevner, and that has been used a lot since then. However, here we faced some problems in solving the equations and we used them. We used then a different method, which is called the source operator method, and which, as far as I know, was introduced by Jean-Lucler. And that's what I'm going to explain and show what kind of results we can get with it. So I didn't set it, but it's still a work in progress. So of course, I'm going to present the work that we are sure about. That we are sure about, but in the end, I will quickly talk about questions and comments that we are kind of stuck on. Okay, so quickly, let's see what are the principal series representation, just to recall the notations and so on. So, we choose the minimal parabolic subgroup of GLN with the Langlands decomposition MAN, so with very classical notation. So, A, with B. So A with B diagonal matrices with positive entries, M is diagonal matrices with plus and minus one, and N is unipotent upper triangular matrices. And also we use a classical n-bar for the transpose conjugate. And so we start with a weight in Cn, a representation of M, which is just a character here because since it's abelian. Since it's abelian. And then the principal series representation acts on smooth function on g, which satisfies some equivalence property. So very, I mean, that's the classical definition for this representation. And of course, rho is also the half sum of the positive roots here. Okay, I just put some index, some. Put some index, some exponent n here, because I will have to distinguish between representation of gln plus one and gln. So that's pretty much it for that. And so to summarize the setting, we have H inside G. The parabolic subgroup of H is also inside the parabolic subgroup of G. So it's a very nice setting to start with for this kind of branching problem. This kind of branching problem, and it also implies that h mod ph will be naturally embedded into g mod pgs. Very nice situation in terms of geometry here. And so I recall that the goal is to construct symmetry breaking operators, which are differential operators for two different principal series. So one of H and one of G. Okay, so now. Now, a last ingredient that we need is the Napstein intertwining operators. So, if you take an element inside the value group, which here is just permutations, you use this integral operator here, and it's well defined for some range on the lambda, it's absolutely convergent. Lambda, it's absolutely convergent. And then it will intertwine the principal series. So for GLN, one with psi and lambda, and the one with W psi and W lambda. So where the parameters are just permutated, permuted. Anyway, it's not a problem. So then it is known that it admits a mirror. It is known that it admits a Meromorphic extension to all Cn. Okay, no, it's just a small definition that we say that lambda is generic if the difference of the lambdas is not an integer. And for this kind of parameters, why is it good is because the principal series are irreducible and also the Napstein operators are invertible. Operators are invertible. That's my classical results about the Napstein operators and principal series. I just wanted to recall that so that we have everything in mind before we get started on this source operator method. Okay, so the first, I will sketch how it works. It's not like I will comment that we are not going to do that exactly, but that's mainly the idea. That's a rough idea on how it works. So, the first remark is that the restriction of function is actually H intertwining. So, you take a function on G on the left here, and you restrict to H this function, and you get a function on H, and that operation is H intertwining. Um, yeah, I don't. I'm not very precise about the parameters, that's not what matters here. I will be more precise later. So, once you know that, you will search for polynomials P such that the multiplication map by P, so it's polynomials on G. Maybe I should have written that. And you search for them such that P is 18 to 20. So, you have a multiplication map which. So you have a multiplication map which goes from xi lambda to pi xi prime lambda prime and I want to insist that it's still on function on g here everything stays on function on g and then I restrict and I get to principal series of h okay so like that I can build if such polymers exist and then there will be some There will be some. I can build my first symmetry breaking operator like that, but I can do more using the Napstein operators. So I can conjugate this multiplication map with the Napstein operators, and I get an operator D here. Since the Napstein are G intertwining, so the whole composition will be Position will be H intertwined because MP is just H intertwined. That's how I wanted it to be. Okay, and then I can compose D with the restriction. And clearly, it's a symmetry breaking operator. And there are two questions because I want to construct the one which are differential. So is it differential and is it non-zero? Because I mean, if I get zero, it's not interesting. That's. Zero, it's not interesting. That's clear. I want to insist that it's clearly far from obvious that it should be differential because Napstein operators are not local. So there are no, at least for us, there are no, and for now, there are no reason for it to be differential. And then to be non-zero, that's also not really trivial. That's also not really trivial, but it's more at least the proof we have is more just technical. Okay, and to conclude, so I want to go for a theorem which of course will be more precise, but for these generic parameters where the definition is recalled below, this method will allow to construct all the differential symmetries. Construct all the differential symmetry breaking operators. Okay. And that's, I mean, up to some small precision and small changes. First, I will look at the restriction and see if there is, because I choose this one because it's uh like it's well known that it's H intertwining. But is there other are there other possibility here? Possibility here, and we will find that yes. Also, the multiplication map. I will explain which polynomials we should use. And finally, for the map style, I mean, I have a choice on the file group element that I choose. And also, I will precise that part. But in the end, it will turn. It will turn out to construct a differential symmetry breaking operator. And thanks to already known results, we are able to say that it constructs everything in that setting. So for generic parameters. Okay. So I recall even if it has already been, I mean, people already talked a bit about that, but I recall what I mean by I recall what I mean by differential operators. So here we have two, I mean, we have functions or sections between two different vector bundles. So for us, it's just a line bundle in that case, but the general definition can go for vector bundles. And so, how do we define a differential operator in that situation? It's just a map which goes from A space of smooth section on X, smooth to smooth section on Y, and it should satisfy some locality property. And so if I take a map, smooth map, which goes from Y to X, then T should restrict the support of functions, but I mean, you cannot But, I mean, you cannot compare the support of Tf with the support of F, so you have to pull back. Yeah, let's say pull back the support of Tf inside X using the map P. Okay. And so if you compare, it's just some generalization. I mean, it's just some generalization of a possible definition of differential operator using the support. Okay? So in our context, So, in our context, we have so X will be G mod P G, Y will be H mod P H. And the vector bundle is actually just a line bundle, either coming with an action of G or with an action of H. And differential symmetry breaking operator will then be. Operator will then be a p-differential operator which intertwines the h action for so for some smooth map p. Okay, and so for p we know we have an obvious candidate which is the injection of h mod pH into g mod pg but there is a natural question is for what p are there some Are there some differential intertwining operators? That's a question I want to answer now, and it's just one proposition here. So if I want to have a non-zero p-differential operator, so the I mean, it kind of makes sense, but the p must be h intertwining, okay? And moreover, we should have, it's explicitly given by multiplication on the Given by multiplication on the right by these permutation matrices. So, okay, how do we see that? It's not that complicated if you remember or if you know that when looking at the support of the no, you look at the distribution kernel of your operator and then it. kernel of your operator and then its support should be in bijection with the singular point in a singular orbit into G mod P G mod P H. Okay, that's what I mean Professor Kobayashi mentioned it on Monday, but basically the support is only one point and so you just search for what kind of point you want. Of point you want, and you find these matrices, and so you have different possibilities for p and i want to clarify that it's totally equivalent to change the starting I mean the embedding of H into G that we start with started with okay so that's why we have also n plus one possibility so you could start by embedding H differently H differently, and that's yeah, that's equivalent to having different p. Okay, but here the good thing is I have a uniform way to define this first example of differential symmetry breaking operator, which is one of the bricks that we need. I call that the shifted restriction because you take a function on g and you restrict it to a. And you restrict it to H, but with a shift. Shifted restriction sounds nice. And we know explicitly for which parameters it intertwines. Okay, and that's our first step is to understand what we could put instead of the restriction. And that's the other map that we can have. Okay, so the second step was to talk about. Was to talk about polynomials, so the invariant polynomials that we want. So, I mean, in the work of Jean-Louis Claire, there is no real recipe on how to apply the method. So, meaning there is no real way to find for, I mean, to search for the polynomial. So, we just, I mean, it's something just very natural that we. Something just very natural that we propose here. So, the first property is that they should, I mean, they satisfy some equivariance property here, but it's clearly very natural because it means that you go from a principal series representation to another one. That comes from that condition. And the second, we want the multiplication by P to be H intertwining, and that gives you more or less. More or less this equivalence property up to this character of H that we put here, and that I mean in the first place we forgot about this character, but it turned out that we don't get a lot of stuff that way. I mean, we get only half of the story, so we had to put the character to get everything in the end. In the end, okay, and now what are the possible polynomials? Then is so it's given in this proposition that we proved. So it's generated by first the determinant of on GLN plus one and the following two polynomials. So the first one, psi, phi, is just the left lower coefficient. Lower coefficient, lower left coefficient, and psi is the principal minor of size n. So first I will make a comment that we don't really need the determinant of gl n plus 1 because this one is actually not only h intertwining but also g intertwining. I mean the multiplication map is g intertwining. So by changing just the By changing just the starting parameter, we can get rid of the determinant if we add one. So this one is not really interesting for what we want to do. So we will focus on these two generators here. And then finally, the multiplication map, as expected, it will go from one principal series of G to another one. Introduced here. It's okay because I had um so uh occasionally that you your voice uh uh interrupted so could you okay yeah can you hear me nicely now or yeah no no no you you we can hear okay okay sorry about that i mean i don't know why but today i had some issue with the internet so uh okay i will continue Uh okay, I will continue. Uh, so remember we had this map, and now we will conjugate by the lapstein operators. And it turned out that for all other Ditlefsson and Fran already did it in some paper that they put on archive this year. And so you take your multiplication multiplic multiplication map oh sorry multiplication map by five first you by Napstein so here you see you have to choose the similar thing for psi but this time with the permutation But this time with the permutation i n plus one okay and one of the results uh is that some differential you're on mute on mute. Mute on mute so now it is muted so I we cannot hear you can you hear me or yeah no no yeah no no fine. Yeah, no, no, fine. Okay, because I got kicked off the Zoom session. Okay. So if that's fine, I will just put the full screen again. Okay, where was I? So, yeah, So, yeah, basically, we can define these two families of operators, and they turn out to be differential operators. And as I said previously, it's not that obvious. And that's what we call the source operators, okay, because there will be building blocks for the other intertwining operators that we want to have. Okay, let's jump into it. So, how do we come? So, how do we construct now the differential symmetry breaking operator? It's just by composing the DI that we just produced and the FIs. You can compose them several times, so that's why we have power. And then you restrict using the shifted restriction. Okay, and I don't give, I mean, you can chase the parameters while you are doing that. While you are doing that, so you start with xi lambda and you get into xi prime lambda prime, and that's the result is that it's non-zero, which is non-I mean, it's not really hard to see, you just have to look at the highest degree term. It's quite technical to be fair, but not that complicated to understand. And from the constructions, clearly the From the construction, it's clearly a symmetry breaking operator, and the fact that it's differential comes from DKFs and from the result. Okay, and then the final parameter that you get in is also easy to chase. That's not the problem. So, the question was: at that point, does it give everything or not? And it turns out that you can use the That you can use the duality that approved by Kobe and Bevsner between differential symmetry breaking operator, Verma morphism between Wehrmacht modules. And then you use another result by Professor Kobayashi, which tells you what is the branching law for Dharma module in the generic case. So for generic lambda. Lambda and you will see that then the dimension of symmetry differential symmetry breaking operator is one and so that's why we have everything here and since we know explicitly is the branching law we know exactly for explicitly for which parameters there could be some differential symmetry breaking operator and that's exactly this one so using this duality and what we know already on the derma module side Know already on the Dharma module side, we can deduce that it gives everything. So that's why we like the method, even if there are a lot of things that we don't know. The first question is: What about non-generic conduct? And that's a bit tricky. In that case, the thing is. In that case, the thing is there might exist differential intertwining operators on the G-level. For example, given by the residue operator of the NAPSH time. And so you can compose what we just built with this kind of operator, if you're lucky. I mean, you have to check that every all the parameters that we are talking about, everything is working nicely. And then you can get another differential symmetry breaking operator. A differential symmetry breaking operator. So that's one way to do it. And so for we by hand, we did the G the n equals two case, so from GL3 to GL2. And it seems to give everything. There is just one case that we are not really sure about. That's what we want to talk. So is that everything? And that part we really don't know, let's be honest. For n equal 2, we found some cases for which For which dimension of the space of differential symmetry breaking operator is bigger than one, actually, is two. And we did that with the basically, it's the F method that we applied here. And yeah, so we don't know if the construction with like differential intertwining operators on the Operators on the G or H level is enough to get the two of them. Because we don't really know if it's, we get a lot of operators and we don't know which one are the same, which are zero or not. But we still have a bit of work to do there. But for general N, I don't think we have any clue to answer that. And one last question that I would like to have the answer is: what's the link? To have the answer is what's the link with the F-metric? Because it does sound very related, because the kind of equation that we have to solve is not far away. It's a bit simpler, I would say, in the computational side. Like the differential equations that we have to solve are simpler, that's for sure. Then we have other problems. And it's like And it's like the Knapstein operator seems to act a bit like a Fourier transform. But I mean, we have no real idea on why it works that way. So that's a good question that I would like at least deal with soon. Okay, and that's all for me. So thank you for your attention. And if you have any question, of course, feel free to ask. Question: Of course, it's free to ask. Thank you very much, Cantini. So, are there any questions, comments? Yes, Michelle. I have one question. Can you hear Michelle's voice? Maybe you may hear me. Yeah, I can hear him. Yes, so thank you very much, Pontan, for your talk. One question about the source optimizator construction. Source optimator construction. So, if I remember correctly, in the original work by Jean-Louis Blair, there was a family of special polynomials appearing in his construction, a kind of generalization of Jacobi polynomials, related Jacobi in the sense of the existence of a kind of Rodriguez formula. Rodriguez formula that controls the braking operators. Do you have some similar phenomena here for JLN? I don't think so. Because so if I remember correctly, I mean, his work, he first worked with principal series, and then in the second time, he looks at the case, I mean. At the case, I mean, he looks at the ranking point bracket in some sense, but not in the SL2 case. So then he goes to discrete series, and that's when he has this orthogonal family of polynomials, which is defined with this Gekenbauer type. Yeah, it's Jacobi type polynomial. But here I don't see. But here I don't think you I don't think you should expect some orthogonal polynomial family behind it because you I mean you're not in the unitary situation so I'm not so sure about that because the decomposition will not be discrete also so yeah I don't know if that answers your question but I mean to answer your question Question, but I mean, to answer your question honestly, it's uh, I mean, no, we don't have that, but I think there are good reasons for not having them. Okay, any other questions? Yes, I want to ask about the geometry behind SOAS. Uh XK are completely A complete representative of orbital decomposition of H spherical air spherical variety G mode PG. Yeah. Oh, I see. Yes, I think if I understood correctly, because the sun was not very good, but yeah, the idea is to look, to get them is to look at the support of the distributional kernel. Distributional kernel. And you know that it should be singular supported inside G mod PG mod PH. And then you just look at what are the possible singular orbits inside that space. So it's more or less what we learn. Does that answer your question or Any other questions? So from representation theoretic viewpoints, that interesting cases when free specific representations is not irreducible. Not irreducible, so namely non-genetic cases. And then, also, viewpoint of the operators that also sometimes are very interesting and the geometric operator shows up as differential simulator-based operators. And do you have some idea? So, you talked about when n equals two case, but for general case, how to capture all operators when parameters. us when parameter is integral yeah so i mean what um what we tried and what we are still trying is to try to use the f method um i mean that's i mean that should give the answer if we manage to solve the equation as but we face a problem that i mean we feel like there are two less equations Feel like they have two less equations because it's not abelian. I mean, the neural radical is not abelian, and so it feels like we have two less equation. And so, I mean, right now we are not able when n is not equal to two, because n equal to two is a bit too small to see the problem. And when you start to do n equals three, I mean, we are a bit lost in the. I mean, we are a bit lost in solving this equation because we also have a third-order differential equation inside it. And yeah, it's like, to be honest, it's like very messy for us. It's still very messy. So we don't really know. Okay. So it's a future problem. Yeah. Okay. So any other questions? No? No, so then let's thank you away. So, thank you very much.