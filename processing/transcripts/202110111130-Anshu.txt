From Berkeley, and he's going to tell us about an aerial of 2D frustration-free systems. Thanks, Larson. Thanks so much for the invitation. And I'm very excited to be here online. Sorry about the bad quality of the video. Well, luckily, the slides are good and the sun doesn't affect the slides. So that's nice. So I'll talk about this not so. This not so old work with Itai Yarad and David Gossett that we put out in March this year. So, this talk is going to be about two concepts. First, that all of you will be very familiar with, which is that of 2D spin systems. A 2D spin system, for the purpose of this talk, we'll think of it as a collection of a collection of particles which are arranged on a Which are arranged on a nice lattice. So, for example, a 2D lattice, a square lattice. And these are locally interacting. So, we'll imagine each of these particles to be a qubit of constant dimension, for example. Now, the Hamiltonian that acts on this system will be local, which means that we'll assume that each interaction, let's say Hij, only acts on a constant number of particles. So, let's say here, one interaction acts on four particles. And then it's our Four particles and then it's RNT everywhere else. I'll be assuming for technical reasons that these h high j's, these global interactions are bounded between one or zero. That's just choice of scaling. And the very important quantity of interest for this talk will be ground states of this Hamiltonian. So the ground states, these are the states which minimize the energy and there is an associated spectral gap, which is the difference between Difference between excited energy minus the crown energy. So, the spectral gap is something that we'll be talking about a lot. So, for these systems, there are some very natural questions that one can ask. So, we can ask, for example, what is the correlation length in the ground state? That's a question that one can ask. We can ask, what is the entanglement in the ground state? Another question is, is there a nice Is there a nice tensor network representation? So, there are all sorts of physically motivated questions we can ask about these systems. Now, on the other end of this talk, we'll concern concepts from something from a slightly different world, which is that of polynomial approximations. So, what are the kind of questions people are interested in polynomial approximation? Well, in this field, one is given a complicated function. Let's say one is given A complicated function, let's say one is given something like an exponential function or a point function, which I've drawn in blue. So that's f, and the goal is to approximate this function in a nice way. So here, for example, we would like to approximate the exponential or the point function using a polynomial so that so the function is well approximated by the polynomial up to a smaller than epsilon in certain range. So, in this figure, for example, the approximation by these green polynomials. By these green polynomials, would work well in this region or in this region. So, polynomial approximations are very, very well studied in mathematics. And there's a very clear theory out there which tries to understand how to approximate a complicated looking function using polynomials. And Chevyshan-based approximations are usually one of the popular and one of the powerful toolkits there. And usually, they're optimal in many cases. In many cases. By optimal, I mean the goal here would be to minimize the degree of the polynomial because less the degree, better it is. So optimality refers to having lower degree. Now, in the context of many body systems, there have been lots of results which have connected polynomial approximations and spin systems in a very non-trivial way and in a really fundamental way. So these are the A really fundamental way. So, these are the inspirations for the work I will talk, I'm going to talk about in the remaining slides. So, I thought I'll go over that. So, there has been some demonstration of the power of Chebyshev approximation that I showed you earlier. And here are two examples, which are quite striking in terms of how effective they are. So, here's one example. So, let's consider what is known as a frustration-free system, which concerns the systems where each Hamiltonian has Where each Hamiltonian has the ground state as its own ground state. So the ground state satisfies each local interaction. So the precision-free systems, one can ask what is the correlation length of the ground state? And prior works by Hastings and Bruno and Robert Sims, they showed that the correlation length scales as one over the spectral gap of the Hamiltonian. But more recently, using the technology of Chebyshev approximation, Technology of Chebyshev approximation, Gosett and Huang improved this quadratically to one of root gap, and surprisingly, that was optimal. And it's quite that the Chebyshev polynomials captured this right dependence on the gap. Another example is that of area laws in 1D system, where imagine the analog of the picture I showed you, which is a collection of 1D particles arranged on a line. And here we have given a ground state, and our goal is to understand what's the entanglement. Is to understand what's the entanglement between the two parts in the ground state. Now, in this case, Hastings famously showed in 2008 that the entropy scales as exponentially one over the gap of the system using tools from manufacturing physics. And a few years later, these authors improved this exponential to one-hour gap using the machinery of Chebyshev polynomials and so on. JV shift polynomials and so on. So here's some examples. And in fact, these results were clear motivation for us. And our interest was in entanglement entropy in two-dimensional systems. So the picture is back again of the two-dimensional lattice that I showed you earlier. In this picture, let's take our lattice and let's divide it into two parts. So one is A and one is A complement. It's the orthogonal to A. And these are divided by To A, and these are divided by this yellow line, which I'll call the boundary of A. So, in general, we can ask the question: well, if you're given a quantum state on these particles, how does the entropy, which well, I'm sure this would be very familiar to everyone, but just thought to write it down that this would be trace log 1 over psi A times psi A. So, what is the entropy of the marginal of the ground of any state in the region? any state in the region what does that look like or in other terms how does the entanglement so this is also known as the entanglement entropy how does the entanglement entropy scale as a function of number of particles so if psi was a random quantum state that was literally that had no structure then it's very easy to argue that the entropy scales extensively it scales as the number of particles in the region this is known as a volume law behavior but it is conjectured uh in um that's the In that's the area of conjecture that if you have a unique gap ground state of a Hamiltonian, then in that case, the entropy scales as the length of the boundary, which has much few, in the 2D, it has much few number of particles. And instead of the volume, that's the number of particles in the bulk. So this is the area of conjecture that the entropy of a gap during ground state scales in this manner. So in this talk, our main In this talk, our main result will be the following, which let me go through this summer story, which is that unique ground state of a locally gapped frustration-free Hamiltonian in 2D satisfies an area law across the vertical cut. And the area law takes the form, it's the length of the boundary times a tiny correction, which we didn't work hard to improve, but that should be improved. So, let me quickly click. So let me quickly clarify what these terms are. Well, frustration-free, I showed you earlier, that's the case where the ground state satisfies each local term. So that's frustration-free. Locally gap refers in our case to the assumption that instead of a global gap for the whole system, we are also assuming that if you look at any rectangle of this form on the lattice, here's the cut. And any rectangle of this form, it also has a spectral gap. Or it also has a spectral gap. And assuming these two properties, we can establish this result. Unique is not necessary. And if you don't have a unique ground state, then you can prove single results using an additive log than dimension of the ground space with this addition. And this cannot be improved. So if the ground space is too large, then there will be states which have very, very high entanglement. So that's unavoidable. So this is the main result. So, this is the main disease. And I think I should excuse me very briefly. What are the boundary conditions you take for all of these assumptions here also on these rectangles? Right, so in this case, I'm assuming, well, I guess it's a square lattice, and this is the end of the lattice in the sense that there are some Hamiltonians acting everywhere. So, I'm not sure what boundary condition. What would boundary condition refer to here? So you just take all the Hamiltonian terms that are strictly within these big rectangle, or if you look at the black rectangle, there's nothing special at the boundary. You don't add anything. It's just the terms that are inside, completely inside. Oh, yeah, exactly. There's nothing to be added in the boundary. In fact, we don't even have to assume translation invariance or anything like that. It's just a collection of local terms. Local terms, and if they satisfy these conditions, then they have this property. Thanks. Right, I understand the boundary conditions are important in these discussions, but I guess they don't really show up in the proof in any crucial manner, I believe. Maybe they show up under these assumptions. All right. So, well, I'd like to give some an outline of the proof and a very brief outline before. A very brief outline before delving deeper into it. And before getting into our proof methods, let's look back at why people believe that Array Law should hold in the first place. And the inspiration for Area Law comes from what I mentioned earlier: that the correlation in the ground state is limited, that if the ground state is gapped, then the correlation does not go too far. So, for example, recall this is the Recall, this is the boundary, this is a yellow, yellow, yellow cut. And we have this region A on one side of the cut. Now, usually, now because there's a decay of correlation in the ground state, so it is expected on intuitive grounds that this part of the region should only be correlated with a certain limited region away from the boundary, and that's roughly of the length of one hour gap. So, if so, this would suggest morely that, well, the intro. Suggest morely that well, the entropy of this region only is limited to this whole region, or in fact, to this region. And this entropy gives us the size of the green region, that is totally boundary times one over gamf. So that's the boundary. So the fact that the entanglement is very limited would suggest that the area law should hold because, well, there's no correlation between here and these regions far away. So the whole region would be purified over here. Would be purified over here in symptoms. But this statement, this intuition is not really correct. And in fact, formally establishing it in one dimension required much more non-trivial considerations. And as far as we know, the idea that exponential decay of correlation implies area law holds in one dimension between Brandau and Herodiki, but there's no proof. But there's no proof beyond. Like, it's not clear why decay of correlation should imply a draw at all in higher dimensions. So, our view will be slightly different from this view, but along similar lines. So, correlation in some sense captures, a decay of correlations captures a locality in the region. So, what you're saying here is that, well, if you look around the boundary, there's a sense of locality and system is local due to the Hamiltonian. So, our view will be to So, our view will be to translate this language into the language of polynomials. And what we roughly basically show is that if you have certain optimal polynomial approximation that I will describe in details in the coming slides, which can be viewed as a notion of locality for the ground state around the cut. So, if there is an optimal polynomial approximation around the boundary, the yellow boundary, then it implies error law, which sort of implies error law, which sort of again is the same picture that locality implies error law, but in a different language of polynomials. And that's the high-level message that I would like to sort of pitch here. And our proof, in fact, does exactly what this high-level view would say. So we first understand the polynomial approximation for one-dimensional systems because, well, the boundary of a 2D is a 1D system. It's clearly a 1D system. So, first step thing with the thing that we do is that we try to understand, well, well, understand how the approximation theory for ground states look like in 1D, and then we lift it to 2D via some construction. So, these are the two main steps in the proof. And again, this might have been standard decryptic because I didn't even describe what polynomial approximation is and so on in details, but I'll be doing. In details, but I'll be doing all of that in the coming slides. But that's a high-level view, right? So I have to keep that in mind. All right. So let me end this overview subsection with acknowledging some several parallel works. So for example, ARA law has been established under several assumptions in the past. So if there are a small number of low-energy excited states, then Hastings and Massanis approved area laws. And Massanis that proved area was in 2D and beyond. If you have a spin half lattice, there are qubits and there is a nearest neighbor interaction, then using Bravi's exact representation of ground state, it was shown that area law holds for these systems. Under some adiabatic assumptions and also under some specific heat assumptions, area laws have been shown. But these don't refer to spectral gap assumptions. So that's what we are concerned about, about gap. Concerned about gapped about gapped systems. And it turns out very interesting that if you go to very high dimensions or on general graphs, the area law is violated. Which again which comes from some very interesting thoughts on why the decay of correlation doesn't imply a yellow law. I mean, that line of argument can, in fact, helps prove that a yellow law doesn't hold any very high dimension, but I won't go into the details of this talk. But I won't go into the details of this topic. All right. So now what does high mean? Sorry, a high dimension would basically mean that it's an expanded graph. So this is. Thank you. Yeah. Okay. So this is a construction on expanding graphs, I think. Yeah. But to be clear, in any finite dimension, there's no counterexample that's known. Is that right? In the finite dimension, there's no counterexample to be added. I'm sorry, my screenshot installed. All right. So I'll spend some time trying to discuss how does one really bound entanglement in the series of works that I'm interested in. So bounding the entire to the ground state amounts to constructing certain operator, K. This operator acts on the whole lattice. It acts on A and A complement. It acts on A and A complement, the whole system, and it has a property that it has low Schmidt rank. So, what is Schmidt rank? Well, Schmidt rank is just the best way I can decompose my operator K as a sum of left and the right operators. So this operator only acts on the region A, this operator only acts on the region A complement. And Schmidt rank is the smallest number D such that I can indeed decompose my operator in this manner. So the goal of bonding intact. Goal of bonding entanglement is quite, you know, well, it's simple to write. It is that find an operator can, which is as small Schmidt rank as possible, that well approximates the gram state. Now, there could be two kind of, there could be several ways to approximate the ground state. And in literature so far, two versions have been considered. So first version is that, well, maybe you approximate the ground state in L1 node. So in the sense that, you know, well, in the sense of L1 norm. And here's an example of what this could look like. Example of what this could look like. So, if you have a Gibbs state, for example, if K was basically a Gibbs state up to some truncation, I mean, I don't really take the Gibbs state, but I take it, take some high power of Gibbs state and so on. And if there were some low energy, low number of eigenstates assumption, then this condition would be satisfied. But this condition is very hard to satisfy. Satisfied, but this condition is very hard to satisfy in general, and in the kind of setup we are interested in, it's very hard to really find an operator K that approximates the ground state in L10. But this would be very nice. But unfortunately, this doesn't work. So the next strategy, which is a much weaker version, is to approximate the ground state in L infinity naught. And this is often what we'll adopt in our In this talk. And this is what is the most useful notion of approximation in all the results. So here's an example of how one would try to approximate the ground state in L infinity. So one example is, well, I just take my Hamiltonian divided by the maximum number of terms that was L times L for the lattice, and I take it to a large power. If the power is large enough, then this operator essentially approximates. Operated, it essentially approximates the ground stating value for any, and that's one thing I mean. Now, this is called the approximate ground state projector on AGSP, which basically is an operator which approximates the ground state operator epsilon. And the estimated rank is bounded by some number capital D. So one can ask, well, how good an approximation. What, how good an approximation I need to be able to prove AI laws and so on. I don't have L1 approximation, that's very rare. So, well, L-infinity approximation, like, how should it look like? So, let's take an example. Let's say put epsilon 1 over 10 and D 1000 suffice, D 100 suffice. So, it would seem like D being 100 is pretty good because that's a constant Schmidt rank. And you would expect on intuitive grounds that, well, Said, well, that is a pretty very low number in terms of amount of entanglement that K has. But turns out that, quite remarkably, turns out that this is really not the right regime we should be looking at. So this would not suffice. And the reason is that it was shown in this work that I briefly mentioned, which is Aharanov et al., that you can have, for example, You can have, for example, quantum states, for example, a maximally entangled state between the left and the right regions on all the particles, which has a lot of entanglement. So if you have an EPR state on the lattice, basically which kind of goes, you know, it's like an EPR which connects, you know, all the particles, it has too much entanglement. It has volume entanglement. But you can approximate this EPR state using an operator which has Schmidt rank. Operator, which has Schmidt rank very small constant, like 10 or 15, and approximation 1 over 10. So it is possible to, in fact, approximate very entangled states using such operator scale with very small error, like some constant error and constant straight map. So to be able to prove area, we have to go much, much beyond that. We have to get an approximation that is much better than what these factors would give. These factors would give. And this is what we will do. We'll use the theorem of Arad Landau Uzrani from 2012, which says that if epsilon is really small, like epsilon is roughly 1 over 2d instead of a constant, then we are able to bound the entanglement by some number that depends on the thing. And that's the key challenge that one has to overcome. So just to give an intuition, if epsilon was zero, let's say, then k was equal to the ground state. Then k was equal to the ground state and Schmidt rank and Schmidt rank of k would be the entanglement introduction. And so that's that's for zero. And this result is a robust version of the case when epsilon is zero. That's the reason that we'll try to capture. Okay, so now let me go back to polynomial approximations. So as I mentioned earlier, one way Approximations. So, as I mentioned earlier, one way to construct this operator k, which was an approximate approximation to the ground state, was to take the Hamiltonian in some nice normalized manner and take a large power. And this is a polynomial of the ground state. Sorry, it's a polynomial of the Hamiltonian. And we are interested in polynomials of this form. Not exactly this, but something like this. And the overall philosophy is: well, we want to minimize the degree because small degree corresponds to. Because small degree corresponds to Loschmatric and roughly, can you remind us what is n and l? Oh, sorry, I should have emphasized it earlier. So this was my lattice. N was this and L was this. It was the length of the, you know, n was the vertical length and L was the horizontal length. So the Hamiltonian H, its largest eigenvalue is always at most nl, and eigenvalue could be zero. So this over. Eigenvalue could be zero. So, this operator has eigenvalues between zero and one. So, when I take a large power, only the zero eigenvalue survives, and any other eigenvalue it gets killed. So, that's a way to approximate the ground state because ground state is the zero eigenvalue. So, the overall philosophy is that: well, smaller the degree, better it is, and low degree. And low degree corresponds to low Schmidt rank. And roughly, just to keep in mind for everyone that one should think of Schmidt rank as exponential in degree, roughly. And well, so as I mentioned earlier, in the theory of polynomial approximation, it's very well known that the Chebyshev polynomials are the best thing for this job. We should not be using this polynomial. This is not the best. Chebyshev are the best. So why not just use that? So let me quickly show how I'd want to try to use that. Well, here's a graph about the spectrum of. Here's a graph about the spectrum of the Hamiltonian. So here's the ground energy, this is zero. There's the gap, and there's the maximum possible energy, which was n times l in this picture. So here's the spectrum. How does my ground state look like? Well, the ground state is represented by this function f, which peaks at zero and is zero everywhere else. So if you feed in the Hamiltonian in this function, you would basically output the ground state because every other diagonal will be killed. By this, I mean the matrix way to take functions of matrices. Functions of matrices. And g would be my polynomial, which basically would approximate the ground state. Now, I don't really care what happens here because there's no eigenstate here. So I would only try to approximate the function starting from zero and all the way in this region where the spectrum of the Hamiltonian lies. So Chebyshev polynomial would be the best thing for this job. And what would they achieve? So if epsilon was, let's say, one over 10, a constant, the degree would roughly look like The degree would roughly look like maybe I can just tell how it looks like as a function of epsilon, that'd be easier. So, the degree would look like square root of the norm of the Hamiltonian, that's the regime I'm interested in, times log one over epsilon. So, this would be how the degree would look like of a Chebyshev polynomial. On the other hand, if you're trying to use this approach, my degree would be the norm of the Hamiltonian. be the norm of the Hamiltonian times raw one r epsilon so there's a quality improvement here compared to compared to this this using this this an obvious construct handicap so Chevysha polymers are good at this job and these polymers are exactly what are used in 1D ideal laws to get very good approximations and very good results in one manner but there is a problem in trying to apply Chebyshev polynomials in the 2D case and here is a way to summarize this And here is a way to summarize this issue. And the issue is that: well, let's look back again our system. And if you recall, I had mentioned that our interest would be in this region around the cut. That's where we care about approximating the ground state. And that's what we'll do anyway in the end. So let's look at this region. The number of particles here are roughly the area of the region. If this is constant, if this is a constant. If this is a constant width, so we want an AGSPK of degree certainty and error epsilon, and roughly the Schmidt rank would look like and Schmidt rank would be e to the d roughly. Now the Chebyshev polynomial, it achieves an error epsilon with a degree at best we can hope for square root of the number of particles here, which is roughly the boundary, length of the boundary. It could be worse because I may have to consider other particles too, but Have to consider other particles too, but let's assume that I don't have to, just for the most hopeful way to try to prove this. So, I would try to use this, try to somehow use the Hamilton within this region. So, degree would be square root of the boundary times power naught epsilon. That's the overall approximation error. But this is too high because Schmidt rank is exponential in degree, which roughly looks like, if I just quickly take logs on the top, it looks like one or a. On the top, it looks like one over epsilon to the power square root of a. What I wanted was Schmidt rank, sorry, Schmidt rank, which was my number d, sorry, capital D times epsilon to be less than one, less than half. But this is too large. This Schmidt rank is too large for our purpose because this boundary is too large. And I cannot possibly use the Chebyshev approximation. So this leads to a trouble because, well, I just A trouble because well, uh, I just showed you earlier that the Chebyshev polynomial is optimal, and this is a clear bottleneck because Chebyshev polynomials are optimal. This line of attack on Eridos seems to be really, in some sense, hopeless because I can't beat Chebyshev in terms of approximation of the Hamiltonian. And at the same time, the parameters of the Chebyshev polynomial are not good enough to prove the to satisfy this condition, which would give us here. Which would give us head. So that's the problem. And the resolution to this problem that is the content of our work is to observe the commuting case, which is a very special kind of local Hamiltonian system in which all the terms commute on the lattice. So not just terms which are far away, but also neighboring local terms commute. So if you look at this. So, if you look at these terms, this set of Hamiltonians, then Ariel law always holds. And in fact, it's easy to prove Ariel law using some other techniques. But then you can ask, well, why doesn't the Chebyshev approximation work here? Simply because, well, I mean, there should be a unified picture on how we prove area laws. So Chebyshev approximation seems to fail in 2D, as I tried to outline in this slide. But we know there is an area law for commuting case. Commuting case. So, maybe, so is there a unifying picture that we can build? So, it turns out that interestingly, when the terms of the Hamiltonian commute, the Hamiltonian has a very nice spectrum. And the spectrum looks like this. It's essentially, here's the ground energy that's zero. And every other spectrum is integer, one, two, three, four, and so on, up to the largest eigenvalue. Now, in this case, Now, in this case, several works many, many years ago had shown that one can improve upon Chebyshev approximation by a significant magnitude. In fact, one can take a degree to be roughly square root of area times log 1 epsilon in comparison to Chebyshev, which was square root and log 1 epsilon outside. One can bring the log of 1 epsilon inside for every error epsilon. So now, if I take my error to be large enough, little I take my error to be large enough, a little bit more than two to the minus the area, then degree will be pretty small. Degree will be quite large, but not that large. And Schmidt rank will be exponential in degree. And then by choosing the parameter here properly, I can make sure that Schmidt rank is smaller than one over error. And that's exactly what I would want to satisfy, to prove error law, which I would want to satisfy. Schmidt rank times epsilon is less than half. And that seems to come out naturally once I have. Seems to come out naturally once I have if I have this sort of behavior. Unfortunately, it's not clear at all how to use this because we are interested in non-commuting Hamiltonians and this nice spectrum of non-commuting Hamiltonian, like non-commuting Hamiltonians do not have this nice spectrum. Their spectrum will be all over the place. And it feels as if we'll be back to this picture, where we have to approximate the Hamiltonian everywhere, approximate the ground state. Approximately downstate by accounting for a whole range of spectrum where Chebyshev is out. So, the resolution for us is given in this technical theorem that we prove. And I will try to kind of clarify how do we resolve the Chebyshev issue and so on. So, what we essentially show as the main technical result is that if you are looking at one-dimensional locally gapped Hamiltonians, which are frustration-free, and if you recall And if you recall, one dimension comes in because the boundary of a 2D is a 1D region. So that's what we are actually interested in. So we show that if you have a ground space, any ground space, it doesn't have to be unique ground space. It can be very large too. But if you have a ground space of a 1D frustration-free Hamiltonian with a constant local gap, and this is my Hamiltonian, then there is a polynomial which is a multivariate polynomial of these Hamiltonians. Hamiltonians. So it's not a polynomial of H itself, but rather it really looks into each local term. It's a polynomial of these Hamiltonians, such that this polynomial well approximates the ground space up to a very small error. So what does this error look like? If I set this to epsilon, then I get degree to be square root n log over epsilon. Think of n, n is the norm of the Hamiltonian that I've been showing. Of the Hamiltonian that I've been showing in the previous slides. Sorry, this goes here, right? And log 1 or epsilon is well inside, as was happening in the commuting case. But here, we can also show that wherein the non-commuting case under local gap, the log 1 or epsilon is also inside the square root. That's exactly what we would want for this behavior to satisfy. So a short answer to what... So, a short answer to how does one get around the Chebyshev bottleneck? Well, one essentially constructs multivariate polynomials. And Chebyshev was optimal for a univariate polynomial, like of the Hamiltonian itself. So, this was a polynomial of H. This is optimal and it doesn't help, but once we go into the multivariate regime, we start seeing better approximations. So, well, now how do we lift this to 2D? Starting, so this is a result about 1D system. Uh, starting so this is a result about 1D systems, but how does it relate to 2D? Well, one has to look at the as I mentioned earlier, what we essentially do is we look at the cut and we try to try to confine our interest in the region around the cut, a constant region around the cut. So, how do we do that? We use this trick, a very nice trick that was introduced in this work, which proved the 1D area law, like the best 1D area law of one-hour gap. Of one over gap. So there's a trick of using truncation, which was to take this big Hamiltonian acting on the 1D chain and truncate everything away from the cut. And that's what we do here as well. We look at row by row and we write my full Hamiltonian. We modify the full Hamiltonian into H prime, which is a sum of local Hamiltonians that goes along the cut. So I goes from one to the boundary. Sorry, let me just, this was N. Let me just. This was n, and also n is a boundary, right? And h prime is no longer the Hamiltonian, the local Hamiltonian, which was acting in this row, rather, it's a truncation, truncated version of the Hamiltonian that was acting in this row. So this effectively creates a 1D system for me. And each S prime has small ln because of truncation. So essentially, our proof takes this Hamiltonian, feeds into this construction. Feeds into this construction and the polynomial comes out. I didn't have time to go into the details of how does this look like, but one of the key steps that are important here, which are also also, which kind of decided also there in Martingale method, you know, and techniques to bound lower, yeah, to bound the spectral gear, is that of merge condition, which basically says that if I have a ground space. Uh, if I have a ground space on a certain block of rectangle which might be sitting over here, and another block of rectangle which might be sitting sitting a little bit above with certain overlap, then this approximates the full block. And this is the key property that we need, which is ensured by local gap, and that's the merge condition. And that sort of plays a key role in trying to build these polymers. All right, so as everyone can observe, this is the last slide over here. Everyone can observe this is the last slide over here. So, let me end this with some open questions. So, first open question that seems to be, in my opinion, most tractable would be to try to prove the area law in 3D, which by the same principle that, well, we are interested in the boundary. A boundary of a 3D is a 2D region. So, what we really need is to construct optimal polynomial approximations for 2D systems. That will be the analog of the theoretical. That was the analog of the theorem that I showed you in the 1D system. In here, the current methods probably break down, or sorry, not provably, they just break. We don't have proof that they break. And we can only show suboptimal polynomials, which we hope to be able to improve. Next, a very exciting question is to try to prove frustrated area law, which should apply to all systems, which is the big open question. Systems, which is the big open question that would be great to resolve. Third would be: can we replace the local gap assumption with the gap assumption itself, which might be key to solving this problem? We don't know. And in fact, the local gap assumption is violated in what are known as edge states, which all of you will be familiar with. And the previous talk discussed a lot about edge states. So, an example from the work. From the work from 2015 was a system like this, in which these regions this was a gap system on the full lattice, but these tilted rectangles did not have gaps, gap within the system. So that's that's a consequence of edge states. This would be a problem if we try to prove error law across diagonal cuts. We can still get around it because to prove the error law across diagonal cut, we can. Diagonal cut, we can tile the diagonal cut with rectangles and prove the area of a rectangle that avoids the edge state problem, but it's sort of a circular way of getting to it. So if you get to really not have the local assumption, and another, probably the most tractable question in this list would be to try to prove that ARA law and the polynomial approximation implies a Pepsi representation for the 2D ground states, which Not states, which is a very exciting question. So, with that, thanks for your attention. And thanks, Anorak. This was a bit shorter than you had, but no problem. Thank you very much. I'll tap here.