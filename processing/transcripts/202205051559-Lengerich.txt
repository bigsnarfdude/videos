This is theoretical options for complex diseases. So, thank you, Ben. Thank you. So, I'm going to start off with a really easy topic that we all agree about. Uh, interpretability matters. We all agree on this, but these examples are just too fun not to share. So, I'm going to show a couple of couple examples. So, I wanted to show a couple of examples. This is work with Rich and Mark at NYU and Manolis at 118. We call this death by our own numbers. So, creatinine is an indicator of kidney failure. And so, we expect that with high creatinine levels, there's going to be high levels of mortality. And so, maybe when we fit a model to the medical records, it'll look something like that. Maybe there's a saturating behavior where about two Where above too far, it's not that bad. But in reality, when we look at the model, the real data looks like this. And we have these points at 3 and 5, where there's really strange behaviors in data. And for really high levels of creatinine, people are actually surviving really, really well. And this is strange. A blind AI system might say, let's put everybody in renal failure, and then they get placed on CRRT, and they survive really well. But we don't want that to happen. But we don't want that to happen. Also, there's this concavity and changes at round numbers three and five suggest there's important things going on. That's just one fun example. We can go through a ton of other examples here. So for instance, with the blood urea nitrogen, as Rich was telling us on Monday, this is actually the same data set. The risk jumps and then flattens at 35. But if we look even in finer detail, we see that for Look even in finer detail, we see that for men, really elevated BUN doesn't actually seem that bad, but for women, it does. So, there's some difference in the treatment there. We can see that severe tachycardia or racing heart is actually good for you. Again, these are counter-causal things that probably we don't want our AI model to then go apply to the clinic. Similarly, elevated graduate seems really good for you. Seems really good for you. And a ton of comorbidities, like a history of chest pain, asthma, chronic lung disease, things that make people show up at the hospital quickly and request really urgent care actually look like they would do better. So we basically think that interpretability can turn these problems, these compounding problems, into opportunities. So we look at the, we can say, we look at these shapes of the curves, we say something weird is happening, but not just our models. Our models are inefficient, but also it tells us we can change something about the treatment code. Okay, so all of that was based on the generalized additive models, the idea that we can make glass box models by ignoring interaction effects. Just focus on additive effects, and this will be very interpretable, and then we can do things with those glass box models. But what if we're in the case where interactions actually don't happen? So a lot of people would say, okay, well, let's fit a larger model, right? Fit a larger model, right? And that makes sense. Maybe we have some non-linear decision surface represented by this cloud. And then if we want to interpret this black box model, maybe we'll fit a locally linear or locally interpretable models. And of course, Marco Rivero's paper online started a whole bunch of avenues of estimating local models that can tell us about the local behavior of this globally black holes. And this makes a ton of sense because local. Because locally linear models seem to almost sacrifice nothing. We know that reloaded neural networks are piecewise linear, and reload neural networks are universal approximators. So in some sense, piecewise linear functions are all equal. Of course, there are reasons we don't want to use them all the time, but in some sense, they sacrifice nothing. And in that case, what's really the point of black box on the phone? Suppose we only had a collection of Had a collection of local explanations or of locally linear or locally explainable models. What would we have sacrificed if we got rid of the black box model? For the most part, we might have sacrificed our generating strategy for these locally linear models. Oftentimes, when we're generating locally linear models, we do this implicitly by fitting this black box model and then explaining. But I want to say that alternatively, we could just fit a meta-model. We could just fit a meta-model to produce local models. And if we do this, then we can be explicit about how much we care about this meta-model being a black box or a glass box. And we can use all our tools that we have on this meta-model to decide how much we want to understand where the model explanations are coming from. So, what are these local models? Well, maybe there's three philosophies here. The first is Here. The first is the philosophy of noise or of error or of insufficient samples. And this says that local models are incorrect because they're obscured by what we are observing in this local area. So here we have a dog or a tiger. It looks like a target, a tiger from far away. Maybe we label it as a tiger in our computer vision algorithm. Then we see there's a fence there, and we say, okay, actually, it's a dog, but there's a context that we're missing that. That we're missing that made it look a little bit better. So, the solution here is to subtract out the influence of unseen context factors. And we might think about using mixed effects models here. Another philosophy might be that local models are true, but only for a local view of a global phenomenon. So, this is the person with the one screen, they see the tusks, they're accurately identifying the tusks, but Identifying the tusks, but they don't know that it's an elephant. They just think it's whatever is there. And so the solution here might be to take these context-specific models and reconstruct them into a global model. A third philosophy might be that these local models are accurate reflections of local effects. So here we have a pizza either on a plate or on the street, and the meaning of this pizza is different in the different contexts. Pizza is different in a different context. And so we can't just subtract out the street with plate and get a true understanding of a pizza. The true meaning of a pizza actually changes. And so in this case, you probably want to use context-specific models and understand them as context-specific effects. So we made a package called Contextualize that focuses on these last two philosophies. Now, like all good things in statistical machine learning, Trevor Hastie and Rob Tipscher. Machine learning, Trevor Hastie and Rob Cipsirani got here in 1993. So they have the varying coefficients linear model. So they say, in a linear regression, we can, instead of just using one population beta, let's have beta be a function of some context variables. And this was back in the 90s when we cared about closed form solutions and analytical solutions. And I want to ask the question, what if we can put land? What if we could put linear varying coefficients on ML steroids? What could we do there? The challenge, of course, is that as we expand the parameter generating function to be deep nets or to be something like that, we have learnability problems, we have interpretability problems. But if we can solve those, then formulating these with back propagation, we could probably estimate most model classes to be contextualized. To be contextualized. Yeah, so aside another way, our view is that we have some latent systems that generate context observations and generate model parameters. And the model parameters gives us observations. Of course, we don't observe either the latent system or the model parameters. But if we build a meta-model to link context observations to model parameters and train by a loss-owned observations, By a loss-owned observations, then we can estimate these in a reasonable way. And the way we solve those ML problems that I was talking about earlier is by a variety of different tricks. So the first one is this idea of constraining the model parameters. And one good strategy we found to do that is to build archetypes and subtypes. So within the model, the sample specific model parameters. The sample specific model parameters, we have a set of archetypal models. And then each sample has a latent subtype, and so the subtype gives it a convex combination of the archetypes. And so this constrains your sample-sloven model parameters to lie in a lower-dimensional manifold under high-dimensional fairness. So this idea is from Maron Australius, Alexevi Vati, and Anthony Plutanius. And Anthony Plutanius, who I was lucky enough to know at CMU. So I got to hear their talks and incorporate that in this framework. And then another way of handling the challenge of estimating these flexible metamodels is through constraining the metamodel, like for instance with a neural additive model. So this gives us an additivity that we can understand what's happening, but it has flexibility and that it's not directed to the outcome. And that it's not direct to the outcome, it's forgetting modeling the others. And then, of course, we use a bunch of regularization on the matter model once more. So, here's a toy example. I'm sure lots of people, there are lots of frameworks for estimating heterogeneous treatment effects, but let's consider it in this setting here. So, we have a context, which is the risk factors, on which is the treatment effects, and observations are the response. And in this toy example, we're going to And in this toy example, we're going to assume that we have these five dark blue batches of observed patients, and they lie on some manifold of real patients. We're going to ask what happens at inference time for two patients, Jamie and Joe. Joe is near a cluster of observed patients, and Jamie is far away. So the challenge, of course, if we learn a population model, this doesn't have any heterogeneity and does pretty poorly. And it does pretty poorly with both. If we learn cluster models, it does okay, but for Jamie, it can't extrapolate on the manifold. It hasn't learned anything about the latent structure of this phenomenon. We could train a deep neural network that takes in both the context and the predictors, and then we estimate the local models as the derivative or some other method of getting locally explainable models from the Models from the deep neural network, but since we haven't really told the model what this latent structure should look like in any way, it just has to learn it from predictions, it ends up doing okay, but being pretty disorderless. If instead we build a context encoder that directly predicts the effect from the context, then we can get structure, and this even generalizes a little bit. Of course, this is a toy example, so it should work. In the worst case, we just recapitulate the dockage. So, again, this is a package that's the short link is contextualized.ml. It's in active production, so please let me know if you have use cases. I'm more than happy to implement stuff to get this working for you. But in general, it's built in PyTorch with a SK Learn-like interface. So you just make it some dexterized regressor and then fit it. Make a context-size regressor and fit it with common keywords. And then we can predict things like normal, or we can predict parameters. And so, of course, the predict function takes in both the context and the predictors, whereas the predict parameter function takes in just the context. Pretty fast. So, now I'll show you some examples of using this framework on. Some examples of using this framework on disease subtyping. So, this is an example with our lab at MIT doing Alzheimer's disease subtyping. And the data we have are 430 patients of a single-cell RNA-seq, post-mortem brain samples. I think Susmita was asking earlier good points about sparsity and stuff with single cell data. In this example, we actually avoided that problem by just aggregating the single cell into pseudo-cell sorted data. So we have cell type specific information. And then we also aggregate it in this preliminary analysis so that each patient has a different feature for each cell type and the average expression within. Type and the average expression within that cell type. This was pretty nicely pre-processed for quality control. And we have context of demographics and clinical factors. And then we're going to predict either Alzheimer's or healthy status. So of course, just doing a PC of the gene expression doesn't cleanly separate AD or healthy patients. But we can build models to predict one of the other. And we do see in this case that allowing heterogeneity can. In this case, that allowing heterogeneity, any markers for predicting AD status improves the predictive performance on help-out samples. And then, what we can do is we can ask why does this happen? What is the heterogeneity in the samples that leads to different predictors being important for different patients? So, for instance, in this figure, we've colored the plot, colored the points by whether or not they have a thyroid dysregulation at the baseline. At the baseline. And we see a really neat clustering separation between patients that had thyroid dysregulation and patients that didn't. And what we're visualizing here are the model parameters, are the sample-specific model parameters. And so what this is telling us is that for patients with thyroid dysregulation, they have different markers of AD than patients without thyroid dysregulation. This makes sense because there's some hormonal. Hormonal and immune response things that are crucial in AD. Another interesting set of hydrogen AD is the APOE4 factor. So APOE4 is a genetic variance that's associated with AD. And typically we think about APOE4 increasing the likelihood of somebody acquiring AD. But in this analysis, we're saying that because the markers of AD cluster with Of AD cluster with respect to APOE4 status, that suggests that the type of AD or the markers of AD are different for patients with APOE4 or without APOE4. Not just that it's changing their risk, but it's also changing how the AD looks in those patients. We can test things like male-female. In this case, there's actually not strong clustering here, so maybe there are similar markers in males and females. In males and females. And we also have some information on drugs, and we actually don't see that much difference in the markers versus different patients. So now going on to another example of how to use these sorts of contextualized models, and this is personalized pre-mit benefit in COVID print. So the main challenge here that we're showing with this example. That we're showing with this example is that we can easily deploy contextualized regression in isolation, but maybe we want to learn it alongside some other model. So for instance, EVMs are amazing. Their tree-based algorithm is really good for capturing discontinuities in mortality in healthcare data. So we'd like to use that. But we also want them to be differentiable because we want to fit them in. Because we want to fit them in this contextualized machine learning framework where the parameters change and we train right back propagation. So, how do we fit a tree-based model into a differentiable framework? So, our solution is basically to train them side by side. So, what we do is we first train this EVM to predict the outcome, and this captures all the discontinuities in healthcare data. And then we train the neural additive model. The neural additive model to predict untreated mortality risks. And alongside it, we train another neural additive model to predict treatment benefits. So the idea here is that the EBM has captured a whole bunch of real effects in the medical data, and it's captured them with the tree-based thing. But we can't really update the tree-based model with backdrop. So we train the neural attitude model. So, we train the neural additive model to correct what the EBM has learned incorrectly as a homogeneous risk factor and instead encode it as treatment benefits. So in this way, we are estimating latent treatment benefits after correcting for untreated mortality risk, and we're including these discontinuities from the EVM model that's reasonably. And when we apply this to about four About 4,000 COVID patients from New York, we see pretty reasonable evidence that treatment effectiveness changes based on inflammation and thrombosis factors. So in particular, what we're showing here are the neutrophil nymphocyte ratio, a marker of inflammation, and a marker of COVID-19 severity. And we see that the first three treatment effectiveness goes down with respect to increasing inflammation. Inflammation, the others basically stay constant. There's some indication along with this in a follow-up study that shows that glucocorticoids, which produce inflammation, are most effective for patients that have reasonable levels of inflammation and not markers for thrombosis. So, example number three is a Is about discriminative subtyping of lung cancer. And the main takeaway from this one is that we can use a deep learning model like CompNet as a context encoder. So the motivation is that we can often describe cancers in terms of molecular subtypes, but it's really hard to know if the molecular subtype is optimal. And we never really observe the truth. The truth. So we propose to use something called a discriminative subtype, which is just what I've been talking about throughout this whole thing: the latent subtype that generates mixing parameters for archetypal models. And in particular, we choose to combine histopathology images and transferctomic data in this framework. So we take context data as an image of the tumor to predict the subtype. To predict the subtype of the tumor, this subtype mixes archetypal transcriptomic patterns to predict the most important genes for predicting things about this tumor. So we can think about this kind of as attention that's driven by an image. The only difference between attention and this is that attention typically changes the importance of features, but this could also change the sign or do something else in a more generalized model. So, we apply this to the TCGA data set of lung cancer. We're trying to predict three different types: lung adenocarcinoma, lung mosquemous cell carcinoma, or healthy tissue. And of course, this model outperforms other models for this sort of task, otherwise, I wouldn't be showing it. But more than that, the transcript archetypes, which are learned at the same time, everything's transcripted. Same time, everything's trained by backdrop, the chance of coming archetypes choose to focus on biologically relevant processes. So these are just logistic regression models, and so we can feed the coefficients through traditional process enrichment filters. And we see that most of the archetypes choose to focus on processes, that's just models. And then because we've done this, And then, because we've done this with joint imaging and transfectomics, we can look up the samples for the images that most activated these subtypes. So we can say, what are the morphological patterns that look like these genetic subtypes? And I'm not a very good pathologist, so I'm not very good at summarizing these, but I think it's a promising direction to connect imaging with the latent subtypes, and we can label the latent subtypes in terms of the genomics. Okay, and one final example here, and this is about inferring networks. So network inference. So Bayesian networks, of course, are directed acyclic graphs, or DAGs, which factorize joint distributions into sets of parent and children nodes. And suppose we want to ask me. And suppose we want to ask context-specific Bayesian networks. Well, then we're going to allow W, which are the parameters of the network, to change with context C. So in the same framework that we used before, we're going to assume a conditional independence so that we can build a model from C to a latent subtype C. The latent subtype C will generate. The latent subtitle C will generate Bayesian network parameters W, and Bayesian network parameters W define a likelihood on X. So that's pretty typical for Bayesian network fitting. We have parameters W that define a likelihood on X. We can update that. The difference here is that W is generated by a metamodel that takes in C. Of course, the question is, networks are big. How do we actually define tractable functions to output network matrices? Network matrices and subtypes. So, our solution is the same thing: to model these context-specific Bayesian networks as output of a smooth function. But the question is, how do we make sure this smooth function actually outputs Bayesian networks? And this is difficult because Bayesian networks are acyclic, which is a global property of the entire network. How do we make a smooth function output something that satisfies a global property? Property. Well, luckily, my friend Shun found in 2018 that diagnos can be encoded as a smooth function. So the trace of the matrix exponential tells you how many cycles are included in the matrix W. So he showed that we can use this trace of the matrix exponential to estimate population pH network. So I heard him talk about this, and I realized, hey, if we have a smooth function that tells us. A smooth function that tells us how DAG-like we are, we can use this as a regularizer on our outline to encourage us to always be predicting DAGs. So we called it, oh, so he called that no tiers, which is kind of a backronym. The idea is it's easy to fit. We call it our method not mad. So it's no tiers optimized. And the idea said the same way. Said the same way as the other frameworks have been: is that from the context, we predict a subtype. There are K archetype networks. The archetype networks are trained at the same time as everything else by a backdrop. And we can do a mixing of these archetype networks to generate a sample-specific Asian network. This gives us the full optimization where we have three terms. The first is the standard Asian network fitting likelihood squared error. And the second is the DAGNIS, which is the Is the DAGness, which is the no-tiers loss, and the third is the archetype sparse attempt. So we want sparse archetypal DAGs because then we can combine them and still be DAG-like. Or they will actually be DAGs. If we have dense DAGs, it's unlikely that we can combine two dense DAGs and still be acyclic. But if the archetypes are themselves pretty sparse, then we can combine them. So, graphically, it looks like this: where we take in, say, patient covariance and we feed it through. We like to use the absent model again, where we can look at the influence of each patient factor on the patient subtype. Patient subtype governs mixing of archetypal networks. And in this example, we're using gene expression networks. So, we have some archetypal gene expression networks. Patient subtype governs the mixing of. Patient subtype governs the mixing of them, and that gives us a personalized gene expression network. Because the no-tiers loss is differentiable and the not-mad loss is differentiable, we can train this end-to-end just based on the patient gene expression data and the patient covariance. We don't have to know anything about the archetypal networks to start with. So, we apply this again to TCGA using patient demographics and immune cell proportions infiltrates. Proportions infiltrates as context, and we estimate gene expression networks. In TCGA, it's bulk RNA-seq, so it's a little less noisy. And what we're plotting here are the samples grouped by the cancer tissue origin. You can see the number of samples that we had in the training set here. And of course, lower mean squared error is better. Oh, yes, and of course, these are held-out patients. So, the idea is that the meta-specific. Patients. So the idea is that the meta-model is generalizing from the patients that we saw in the training set to generate gene expression networks. And now it can generate gene expression networks for all patients. So one of the interesting things about this result is that not only are the orange bars lower than the blue, which is why I'm showing it, of course, the contextualized models are doing better, but actually the tissue average models are not that much worse than the personalized models. That much worse than the personalized models. So, this is suggesting that a lot of the benefit here is not actually from personalized networks, it's from tissue-specific networks. But we don't have any way to share statistical power between patient networks unless we use a meta-model or some other framework to share power between these patient networks. We do see that as the number of samples increases from the lymph nodes to the eye to the lung, there is some benefit to using personalized networks beyond just a tissue-specific. Networks beyond just a tissue-specific network that's trained in a multitask fashion. But I think this emphasizes the point that even if there isn't that much personalization, if it's just a multitask benefit, formulating it as a meta-model can have benefits. So then, of course, we can take these networks, these gene expression networks that we've learned, and we can embed them, just like we might embed the actual expression values. And we can look for clustering of these patients. Of these patients. So we did this in a pan-cancer setting. The previous slide was just showing the MSE from a couple of different tissue types. But this embedding is showing a bunch of different tissue types. And of course, the networks cluster with respect to the tissue. That makes sense. One interesting thing is that this recovers the split between lung adenocarcinoma and squamous cell carcinoma. I was talking about this earlier. We use images to predict. We use images to predict important genes here. But here we're just going from patient covariates to predict gene expression networks, and we see that there might be different gene expression networks for these two subtypes of cancer. There is, however, a subset of screen cell carcinomas that look molecular, very similar to the adenar carcinomas. And also there are two clusters of colon adenar carcinomas, which cluster quite distinctly. Cluster quite distinctly in the network embedding space. And then we can go just manually go look up the images because TCJ has images associated with samples, and we can see some clusters of morphologically distinct images. Yeah, so that's all done under this toolkit, contextualized ML. A short link is there. But it's, of course, in active development, so please talk to me. And I'm happy to implement. Talk to me, and I'm happy to implement stuff for you if you have a use case. Thank you. So I have to write down three questions first. Okay, so the first one was about this, I don't remember, it was at the beginning when you were showing this neural additive generalized model. Uh generalized model where you were showing that you actually by introducing the context you were predicting much better the two examples and my question was like you've shown uh binary classification examples but so like does it also go towards multi-class like can we just yeah yeah yeah transform it into a multi-class institution Transform into a multi-class sense of an HTML? Yeah. So, yeah, we have written classifiers and regressors for this. And I didn't talk about this at all, but there's a lot of multitask tricks that can be done that actually benefit from using a meta-model. So you can have multiple outputs happening at the same time. So that would be the way to go. Would be for predicting multiple classes where you won't be having multiple tasks. That mean multiple tasks? So, as written right now, it can just handle an output that is multiple, that's a matrix rather than the vector. The code can handle that. Okay. And then about the other model that you were presenting, so the one I noted down slide 29, but yeah, so here essentially are doing back propagation, and only for the last two could distinguish. But for the last two, for the single task and multitask, that's right. Yeah, yeah, yeah. Okay. Don't do it for the EVM because it can help anyways. Exactly. Yeah, so our solution to that problem is to say, well, let's freeze that model and build another model that's going to correct for anything that learned wrong. And is she saying it's going to correct just some kind of bias that you're trying to introduce? That's what's happening, right? That's the only way you can... Because you're taking the average at the end. From what I see, you take the average of the three outputs. Of the three outputs? Yeah, I don't think I explained this clearly. The difference is that this thing that's estimating the treatment benefit also has access. So once we estimate the treatment benefit, then we get to access the actual treatments that are received. So for assuming you do a double product between each of them? Yeah, between the estimated treatment benefit and the vector of treatments that are received. So this gives you a That are received. So, this gives you a scalar treatment benefit for the patient, and that corrects your naive estimation of risk for that patient. I didn't explain it clearly. So, the EBM, while that could also take in the treatment benefits, it's hard to encode this interaction between the patient benefits and this latent variable. The best way to estimate the latent variables is by back obligation. Variables by back propagation, so we separate that out and freeze the EVM server. And my last question is about your model that is connecting histology and transcriptomics, because I'm kind of working on the same thing, so I really think we should talk. Now I really think we should talk. And I was wondering, like, so I had multiple questions, but I think one of my main ones is: if so, you're predicting from the images. If so, you're predicting from the images the gene expressions, if I understood correctly? Basically, we're predicting the influence of the gene expression. So, we're predicting a model that can be applied to the gene expression to then predict something else. Yeah, I struggle to understand how this works, honestly, and maybe I need to read the paper. I was wondering, like, how do you know? So, how do you know how? How do you know how it all depends on how well your model is doing, right? So if you don't have a measure for your model performance, it's difficult then to conclude what that the inferences you got are actually correct. Right, right. So that was my question, and that's why I was asking, like, if you were predicting gene expressions, how well were you predicting those? And my question is, how do you estimate how well you're doing the task? Yeah, yeah. Yeah. So overall, you know, we can get accuracy of the labels for this entire. Accuracy of the labels for this entire model. And that gives us some indication that we're predicting the label well. The question is: are we doing everything well in the intermediate steps? And right now, our best way to evaluate that is by interpretation of what it's learned. And those are reasonable, but no way to know it's actually correct. Unless you have, like, I guess you could link it to genetic mutations, and that would be really interesting, but I haven't done that. Because the labels are from, at least from what I could see, they seem from the osology. see the scene from the histology itself. So from the histology appearance you can see whether it's quamulous or not molecular labels. So I thought that would be the case as well but deep neural networks actually just trained on the histology don't do very well. So you can see like this one is just looking at histology and it gets much worse accuracy. And this was this is reasonable to say the art that was published in like nature medicine. I follow up on this part. Can you go um how do you generate the archetypes? Is it like backpropagated through as well or do you have some kind of regularization there? Because I guess you want that to be different, right? Okay, yeah, so the main regularization is just sparsity. Okay. We have played around with ideas of entropy. We have played around with ideas of entropy to induce the archetypes to be different from one another, but we found that's more complicated than helpful. Are there other questions? Otherwise, I have another one, like very practical. Like the part where we regularize the uh the trace of the exponential. So I I played around with exponential, I guess, uh with in Python. With in PyTorch. This doesn't scale very, very well, right? So, do you have a trick to compute the trace on the exponential, or is it you just apply it and you just don't use it on very big networks? So, I guess it depends on what you mean by it doesn't scale very well. Because for example, if I if you have like a big protein-protein interaction network. Yeah. Right? And So okay, so we definitely have problems with scaling. Okay, so we definitely have problems with scaling. And if it's 10,000 or 10,000 protein interactions, this would be really difficult. But I've actually found more of the problems are due to the statistical instability of estimating these really large networks rather than the computational actually calculating the trace. Because it's instability radiant through the double. Basically, because when you're doing this summation of archetypal Bayesian networks, you really easily run off the manifold. You really easily run off the manifold of patient networks, and so that can mess up your training. So, in practice, you know, this doesn't scale to very large networks. I think there are a lot of interesting directions of how to learn models of networks, because these networks probably don't rewire along that many axes of differentiation. So, we could learn to compress networks first, and then we could work in a compressed space. But that's, yeah. Uh but that's yeah, that's open work. Uh oh go ahead. No, it's okay, go ahead. Okay. Now again on slide 29, just some curiosity actually. In the first day Rich was showing how EDMs can be editable by dockers. So I was wondering whether once you correct, you make this correction through the names. To make this correction through NANS, if the final results is in agreement with what a doctor would do with these edits, I don't know if you have the opportunity to check this, but maybe you have some cases that you can actually check. Yeah, I guess actually we haven't done that much with editing with the COVID-19 data. So I don't know what it would look like. Okay, because this is COVID-19, right? He was showing different data sets, if I remember right. If I remember, but yeah, yeah, yeah. Yeah, I'm not sure. Okay, okay, yeah, it was just a reason. Yeah, thank you. So it's a nice question. So what are you feeding to your model? Just gene expressions and patient profiles and lots of other co-parates and then you're at the end you are getting the disease class like. The disease class, like every personal in terms of cancer, how is it working? So, in this example? Yeah, okay. So, we take in two inputs. The first is the histopathology, and the second is the gene expression. And this is bulk RNA-seq because it's from TC2I.