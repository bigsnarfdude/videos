Yes, sir. Okay. Starting now. So the second session on mathematics part. So our speaker will be Andrew Sandu and he will talk about where Shannon focus on inference. Please. Hello, everybody. I would like to thank Risha and organizers for putting this Organizers for putting this workshop together. My marching orders from which are going to talk about the mathematics of data assimilation. So the current work is about variational pocket planting planning and it is joint work with my students Tami, B, Eugene. The COVID data estimation is to estimate the true state of a system. We call it X2. We put together information from three different sources. The background or the prime, described by this background probability distribution. It can also list the current orange. Adrian, you can't see that slide, just fill it on the title slide. Yeah. Okay, so can you repeat? Is there any adjustment? Can you repeat? Is there any adjustment that we need to make? It's just a bit slow, so it's everything is okay. You might want to say the full screen. That might make it easier with the transitions. This is the full screen and I don't see the window that you have micro screen or micro screen. So let's see. Oh, I use the port. Do you still have to think about me? Yes. Hey, how about now? Is it still there? Yep. It's good? Yeah. Okay. Yeah? Okay. Okay, so introduction to data simulation slash introduction to the notation that I miss in the talk. We have the background for the parameter described by the PB probability distribution. We have information from the model which encapsulates our knowledge about the physical models that cover the evolution of the system. We have observations which are noisy snaps of reality. Which are noisy snapshots of reality available at discrete times. And we want to build a bio-serial posterior, a biographical analysis that describes the improved understanding of the true state of the system. Somewhat popular approaches are ensemble-canner filters, when it actually can be impedance, particle filters, another entire technical methods, and variational filtering, variational filters. Radiational filtering, radiational smoothing, for ER, which is another thing in itself. Of course, there are also high-pred methods that bring ideas from different families into a single algorithm. Monte Carlo methods. Adrian, sorry to interrupt again. So we're what we're seeing right now is your first slide with uh bullet one. With bullet one, background prior, and that's all that we're seeing. So yes. So I think from our perspective, what we're seeing is your PDF browser with the talk as one tab, but it's not really full screen. I switch back the control screen to just PDF screen. So you have a little bit of additional borders here, but. Okay, sorry. Hopefully what you see is what I see. Okay. Sorry, thanks. Go ahead. Okay, so multi-coupled data simulation methods use a sample-based approach, an ensemble of states, an ensemble of parameters, describe To describe the underlying probability distributions. Asample Camoufl filters have been a huge success in data assimilation. Ansible Camouse Moogers also total success, perhaps rather than used as the filters. The disadvantage of a sample camera authenticity is that it is based on inner consistent theory. It works well in practice. However, it is not consistent, probably not consistent. Probably nothing, or non-linear problems among Gaussian distributions. Particle filters, particle smoothers are very general friendly. They use important sampling to describe probability distributions. So we have empirical approximations of distributions as weighted sum of delta functions. In sequential importance, In sequential importance, which is 17, so the classical particle filtering, one needs very large numbers of particles to avoid the collapse of the waste. Some newer developments include a sample transform particle filter, which is a transformer approach, particularly transform participant filter, and also there is a good amount of work in localizing particle filters, which give hope. which give hope for converting it without collapsing over a relatively small number of particles. The other terminal methods that is widely used are variational methods. In 4D bar we compute the mode of the posterior distribution basically by minimizing negative rho of the posterior which according to Bayef. Which, according to BAFE, is the negative log of the background minus the log of the likelihood of observations. In case of a time-evolving model, in order to carry out this minimization, we need the gradient of this function with respect to the initial conditions. And this is done by running in the forward model, laying checkpoints, running backwards, the atroc model, each forward backwards. Each oral record pressure is one function and one gradient evaluation. Then we have an optimization loop that iterates over this. And here is our minimization. It is very positive, it is a non-linear method, but perhaps the main disadvantage of Ordivar is that, without additional work, we only have one point estimate of the true state. Of the true state. That is the model of the posterior distribution. Without additional work, we don't have a representation of the posterior uncertainty, uncertainty estimate. Today I'll talk about a newer idea, namely particle flow filters. They can be regarded as particle filters, they can be regarded as a metric of probabilities. But here, Probabilities. But here is the idea. We start with a bunch of particles that sample the bigger mod probability solution. We use a dynamical system approach in state space to transform the samples in this synthetic time into samples from a posterior distribution. The particle movement from centering the prior to centering the posterior The selling the posterior is done under the flow of a spochastic differential equation. So, this is a cartoon that shows the workings of the regional particle for filter. We have the body of particles sampling the posterior. We have some observation and the corresponding posterior, sorry, we start with particles and the trial. We build this special. Build this special differential equation that moves the particles such that at the end of the process we have a sample of the positive. Particle flow filters started with a paper in 98 that discusses some mathematical aspects of the forward cloud equation. The forward cloud equation. Then, in 2016, in the machine learning community, an article in IC News proposed the spine-variation of granular center. This is essentially the precursor of all the following methods in particle filtering and particle smoking. Or Doe took on the idea and developed the webbing particle filter and the particle flow. Particle filter and the particle flow filter, which localize current functions. A number of theoretical works that appears in 2020-2021, where people study interactive large-file diffusions and interacting systems of particles. So, here I'll talk about an approach that is general, that subsumes everything that has been done, and basically provides a framework for carrying out data assimilation in the non-definition. In the nonlinear Mangausian case. Okay, so what is the idea behind a behavioral forward random approach? We start with particles that sample the prior distribution. Q will be the probability distribution of the particles, that is, they move in state space, and a time zero, or synthetic time zero, the distribution of the particles. The distribution of the particles is the label. Particles move in artificial time under the dynamics of a stochastic differential equation. Because these terms depend on the probability distribution of the particles, this equation is a Machine-Blasso-decon process. We have a deterministic path or a derived curve and we have a random noise multiplied by a random rate. Multiplied by a diffusion matrix. So, except for this dependency on Q. This is a typical etor stochastic differential equation. X represents the state of a particle. In this view, we have infinitely many particles, so for every value of X, there is a hypothetical particle. Corresponding to that motion of particles, the particle PDF The particle PDF evolves in time according to the Fokker-Plan-Blasso equation. So, again, this dependency on the probability distribution itself changes the equation a little bit. So, our goal is the following. We build these particle dynamics, the drift term and the diffusion term, such as to ensure that the probability distribution of the particles approaches the posterior. Approaches the posterior as the synthetic time goes to infinity and the samples of the particle sample approach a sample of the posterior again as time goes to infinity. We make several assumptions, namely we make an assumption of smoothness for developing the mathematical machinery in order to quantify how far Quantify how far the current probability distribution of the particles is from the target, from the posterior, we use the clear divergence between current distribution of particles and the posterior. So this is the expected value with respect to Q or float Q over P, just the standard formula. The goal is to select the drift term and perhaps the diffusion term such that the Term such that the Kn divergence between the current distribution of particles and the posterior approaches zero. This means that probabilistically, Î”ta approaches the posterior. This is an example of a variational Oker-Plan filter in action. We have these bimodal distributions. This is the prime. You see is the observation. This is the observation likelihood, and this is the posterior in the yellow. We start with the number of particles assembling the prior, and the particles cluster above the modes of the triangle. Thus, the differential equation involves the particle position supporting time, and this is the reconstructive distribution, at time tau1, reconstructive distribution of tau time two from the particles. The particles and for a very large time, the particles span the tumult by the tumult of the posterior distribution. We see that the particles collapse in this example, and I will talk about ways to avoid this later on in the talk. But the fact that the distributions are crazy, distributions are multimodal, and so on, is no abstract because we'll be able to show theoretically that the Theoretically, that the particles always converge towards an irony symbol of the posterior. Okay, for the mathematical machinery, we define a certain dot product that measures how quickly the K array decreases along the trajectory. So we have the following feedback, right? Our job is to find the differential equation that describes the motion of the particles from posterior, from trial, toward the posterior. The optimal cliff that maximizes the rate of decrease of the tail divergence between the current distribution and the posterior. Here. Could be optimal drift. Looks like this. When we say it maximizes the rate of decrease, we have to measure the rate of decrease in some degree. And the purpose of this scalar product is to provide a metric for that. So, the drift, the force that pushes the particles, consists of several points. The first point depends on the current density of particles and also depends on the target, on the posterior. The posterior. Second term depends upon the current distribution, also depends on the diffusion, the stochastic terms. And A, the metric, can be thought of as a randomization recognition in the main. Okay, so the stochastic process, the most of particles, looks like this. We have the Optimal brief term times d tau, and we have a rejuvenation term. The first term of the force, which is the current rate, S T D, toward the post T. The second term, do or it controlled by the socaster and finally the last. And finally, the last term has noise at every step of the particle moving and can be top of the definition turning the classical particle filtering view. With this populate, the corresponding evolution of the probability density of the particles looks like this. We see that it doesn't depend directly on the diffusion term, so On the diffusion term. So, however, we choose the diffusion term, the rejuvenation term, these diffusion compensates from E1, so that the evolution or the probability distribution of the particles is the same no matter how we choose C1. Now with this optimal choice of the drifter, we can establish the following design. We can establish the following design. The probability distribution of the particles evolves toward the unique steady state, which is the posterior, regardless of the starting configuration, regardless of the initial condition using. And the progress of steps first of all establish that the Fokker-Blan-Blassov equation is a remaining radio flow. This means that the KL dipotence decreases. The KL divergence decreases along this trajectory. This means, because the KL divergence is always non-negative and decreasing, bound to begin decreasing, it must have a steady state. The diffusion must have a steady state. And then, in step two, we show that the steady state of the distribution is usually the positive. So, we want So, we want to come to this screen machinery of building a special stochastic equation that moves the particles in state space. The corresponding evolution of the probability density of the particles approaches when the synthetic time goes to infinity a steady state that is exactly the posterior. The way we build the optimal drift ensures that wherever we start, That wherever we start, the particles will assemble the most here. Now, how do we choose the metric A theta, the precondition? We can choose it to be identical. We can choose it to be proportional to the current distribution, and this leads to the stein variation of radiation descent from 2016. We can choose We can choose it to be the covariance of the current distribution, and this leads to larger validities. How do we choose the diffusion term? Well, the diffusion term involves rejuvenation of the particles along the trajectory in synthetic time. Now, the way we choose the diffusion term doesn't impact the evolution of the other light. The evolution of the underlying probability distribution. Because of our special choice, quantitative term, we compensate the anti-diffusion molecule here. However, in practice, the choice of this diffusion term will matter because we work with a finite number of particles. The simplest choice is to take sigma to zero and have a deterministic dynamics, in which case the equation for moving the particles The equation for moving the particles looks like this, right? Minus a tau the gradient of q over p. In general, this rejuvenation, the retal noise, teleton dynamics, maintains particle spread and alleviates particle collapse. So when we lose a finite number of particles, this term will play a role and an important role. Okay, now how do we implement this theoretical optimal tree? In practice, we have a finite number of particles. We can start with a sample of the regular mobility distribution. We move the particles in synthetic time and the term is interdependent tau. We have an assembly of particles. Particles that describe the distribution Q now. To build the optimal leaf, we need gradients of the logarithms, of the probabilities distribution, the current one, and the posterior one. How can we do this? How can we estimate the negative gradient of the distribution, negative gradient log posterior, using Stimulator using all these samples. There are techniques for the direct evaluation of the gradient of density terms, or we can take a moiler that is reconstruct from the ensemble the colour distribution and reconstruct the posterior using some parametric similar distributions and the gradients of that. So things that we can. So things that we consider are parameters, parameters many of probability distributions that can be Gaussian, kernel distributions, Mixture distributions, Laplace, Cooper, Cauchy. On each of them, we fit the parameters of the distribution from the cardinal sample and we compute the gradient analytically, which is everything that we need to implement the algorithm. Was there a question? Okay, so when we implement the optimal grid using a parameterized distribution, all these probability distributions will depend on different ensembles of parameters, because these ensembles will be the distribution, the parameters of the distributions. Of the distributions. B, E posterior will depend on the Beckham ensemble. A, D, and tau will all depend on the current ensemble. Because of this, because every ensemble network impacts the evolution of every other ensemble member. Of every other ensemble number. The correct way to look at the dynamics of the particles is as a system of not one particle, discretized, but as a system of interactive particles. So we have a dynamics that looks like this, where the drift depends on all the particles, sigma depends on all the particles, the other parameterizations. All the particles infect the dynamics of the current particle E. We make the theoretical observation that particles are exchangeable random variables at any synthetic time. This means that renumbering the particles doesn't change the joint probability distribution. So, putting different numbers of different particles doesn't change the joint behavior of the system of particles. Because Because they are exchangeable, the marginal probability distribution of each individual particle is the same. However, the n particles, they have a joint probability distribution in the big ensemble space, and this probability distribution is covered by the Karm dynamics. We apply the machinery that we develop. The machinery that we developed, and we compute the optimal width for the coupled system of particles. We compute the optimal width, not for one particle under ideal conditions, but we compute it for the coupled system of particles under the realistic condition that we use parameter flight distributions. If we define the covering term as the ratio of the general probability distribution of The general volume distribution of the n particles divided by the product of n particles. Okay, so this R is one if the particles represent independent separate, but in general this is not one because the particles get coupled to this common dynamics of the system. We see that the optimal drift looks like this. The optimal drift in the case where we evolve the unasampled particles together. Are a sum of particles we have. It's the theoretical optimal grid that we derive from one particle. Last, the gradient of this coupling term, this is a force that matches the particles, our integer. And we have some case couples coming from the derivatives of the parameterizations that we use, for example, for the current distribution. The current distribution or for the covariance in the case of large-by dynamics. Now, the important term is this force. When we evolve not one particle, but we evolve n particles together, and we use parameterizations of the current distribution, the particles interact. This interaction of the particles leads to a trend probability distribution that is different. Mobility distribution that is different than the relatable marginals. This coupling term needs to be included in the optimal list so that the particles are matched towards the independence. In the case, for example, where the joint distribution is multivariate Gaussian, each particle has a distribution, a Gaussian distribution with mean x star, x bar. X dump, X bar, and covariance P, but we have these off-diagonal terms for the 20 PDF. Because the particles are exchangeable, where these off-diagonal terms are equal to each other. The gradient of the logarithm, of the coupling term, looks like this, right? Some matrix times the force that pushes each particle away from the ensemble beam, plus another matrix that That penalizes essentially the difference between the empirical mean and the exertion. So essentially, this is a force that penalizes the sampling error of the unsambled mean. Okay, now in general, we cannot compute, we cannot estimate the general probability distribution of n. The general probability distribution of n particles moving through state space. So we have to do other things, regularize the particle flow. We have to replace this force, napla x or r, that pushes the particles, total independence. We have to model it somehow and replace it by things that are feasible to compute. First idea is to regularize the particle flow. Regularize the particle flow using the mutual information between two distinct particles. The mutual information is the clear divergence between the joint distribution and the product of marginals. If we change the cost function and add a regularization term that includes the mutual information between two distinct particles, we look as the set of particle evolves not only to push not only to push the margin of each particle toward the posterior, but we also look minimize the mutual information between particles. And this is the term bushes particles toward the terms. Andrew, excuse me, could you wrap up in five minutes? Because the time is up. Okay, we will do that in five. Okay, so this regularization. For fixed obvious regularization using mutual information adds what essentially is a recurring force between particles which so the particles evolve are the optimal pushes things toward the posterior and then there is an additional force coming from the visualization that pushes the particles away from each other. This is an example of four different cases where a number of particles evolves under variational particle flow without any regularization of diffusion with regularization. The regularization pushes particles apart, so we get these low discrepancy sequences with very symmetric. Sequences very symmetrically distributed. If we use post-ifusion and regularization, then we get samples that look very reasonable. The samples are positive. We produce the leaf. What is the product diffusion coefficients increasing from left to right? And by diffusion, I mean the amount of stochastic machine. The amount of stochastic waste agreement and different regularizations, stronger regularization is done. We see that there is a heavy medium between diffusion and regularization that leads to rentive programs that are close to uniform. Okay, so uh I would like to talk a little bit about the essential forty bar, coming from uh the relational focal plan smoother. Ogap smoother. Again, we consider the smoothing. We consider first a perfect model. Our variables are the initial states. The posterior distribution under Gaussian assumptions is the 4D bar function that we have done. The gradient of this 4D bar function is the gradient of the background plus. Background plus a sum of the gradients of the observation likelihoods, each of them multiplied by the model object. Now, if we do 4P pi, we just minimize log PA, negative log PA, using this radio. If we apply the variational focal plan by inference with a set of particles that sample the Baylor distribution, the time step. So we start with an initial set of particles, we sample the PB, the time zero. We see that the particles move on the platform's vocabulary. And I wrote it in discrete form here with Delta Tao, who made the algorithm The analogy with 4D bar more clear. If we just do 4D bar, we basically change the state from one iteration to the next by moving along the gradient of the log DA. Perhaps we use some regularization of this gradient. In the case of DLGS, this regularization is some casual inverse approximation built by the quasi-dominant. If we apply the variation We apply the variation of focal plant ideas, then we get some additional terms. And these additional terms involve the trend distribution of the particles, involves the interaction of the particles, and can involve the addition of a stochastic term, that is the rejuvenation of the particles. Okay, so 4qR by itself computes the mode of the posterior distribution. Distribution. People might use the ensemble of 40 parts, so we sample errors in box equations and we compute a mode for each of those probabilities. But if you want to really sample a posterior distribution, we have to go to this variational forker plant inference idea and run a sample of 40 bars that are coupled to each other. How is the coupling between the 40 bars realized? Well, it is. Well, it is given by the variation of overplane machinery that I just discussed. The same idea can be applied to weaken strain working part. The difference is that no particles are entire trajectories. We have to account for the probability distribution of the model levels, of course. But in general, we can say what we generalize is to an ensemble of coupling. An ensemble of calculated for devices calculations. Okay, so conclusions, the variational Fokker plan is an approach that mostly transports particles from sub-samples, typically of the prior, into samples of the posterior. We have to choose the equation that moves particles in ensemble space that it's going. We have to choose it such that the particles are pushed. It such that the particles are pushed toward the posterior, and we have to choose it such that the particles stay away from each other, such that after many iterations, in the long term rigid, they become an IoT sample of the posterior. There are many aspects of the implementation, because we have to always work with a finite dimensional sample that lead to some approximations in order to obtain, but I'm modeling about the errors of this. Of these modulo-gier approximations, we have guaranteed always come up with a semi-poster. Okay, thank you. I'll stop here. So, questions? So, let me just make a comment. Comment. Again, much important to talk about something mathematical. But the comment is that everything that we use today was Kamal filters, stable Kamal filters, variation of spartical filters, everything start as a mathematical idea, as mathematical algorithms, and then they develop into the very useful algorithms that we used to be. So I believe that the variation of black inference has the potential to grow from these mathematical ideas. To grow from these mathematical ideas into some traditional techniques. So great. So, i great, um, it's a nice framework. I'm just wondering about the feasibility, so that's one. And then I've done something about artificial dye, and the equation became stiff, and then it was a little bit difficult to deal with. So, if you can make comments on that, that would be great. May I ask somebody to repeat the question? Because it goes to the speakers in the room and then through the mic and I cannot hear very well. Sorry, I hope. But moderator TV. Number one is feasibility of disaggregation. It is a nice formula, but can we use it for clinical data sooners or something hardenous or non-linear or non-linear geometry? That's number one. Just remember well, can you hear me? So the formulas involve computing gradients of low probability distributions, right? We have to parametrize the probability distributions and then compute the gradients of them. We have liberty to choose these parametrizations and we can use it in both And we can use it in both filtering and the smoothing approach. So if it's variational for the bar, you can use it to numerical weather prediction. Can you use this for numerical weather prediction, for example, high-dimensional system? What's the feasibility of this method? Difficulties, um maybe what you're here?