So what I'll tell you about is the joint work with Tali Kaufman. Maybe I'll start with the message of this talk, which is the connection to arithmetic groups. And it's that if there exists, it's going to have to be arithmetic, but like there exists an arithmetic group that can act. The camera acting freely co-compactly on sufficiently thick defined building. So if the dimension is three, it has to be arithmetic. And a representation of gamma into modular representation over the field with two elements such that this curious condition holds. So the cup product for H1, I should say the kernel of the cup product Of the coproduct, it has a dimension. The coproduct goes from the gamma F2 tensor H1 gamma rho to H2 gamma rho. That thing is very, very injective. So it's less than the dimension of H naught. Also, the space of fixed vectors, then, okay, and Okay, and uh there exist a top uh subgroups. So this is gamma, this is gamma one, gamma two, gamma three, such that the index of tribute to index attributes of group is two. Then modulo, uh a very reasonable conjecture, there exists locally testable codes. Codes by which with two query faster. So I don't know if such so it's modulo a very reasonable conjecture, which was confirmed by computations, but I don't know if such a thing exists, but what I'll tell you. Just just can you explain? What what is M, G L M F two? Uh j Uh g the group of M by M maximum. No, no, I know what is the group G L M. What is it? How M is related to the thickness or to the group? No, it's just summer. Some M. Just it doesn't have to be a convex quotient, just abstract map to G and M F to group of quotes. And then this is what the U map is the cop product. This is the cup product. The dimension should be less than the dimension of the fixed vectors. So this is the fixed vectors. So I mean this is essentially the dimension of V rho gamma. So if it's one dimensional, this should be one to one. Say. And what you need that will exist gamma one is a list of index two sequences. A list of index two subgroups. Each one is of index two in the next one, starting with gamma. In the actual how many do you need? Infinitely many of those, yes. So it's just for. Yeah, this is a trivial action. So I want to say that I will. When you celebrate this for code, you mean. But I will explain what these are, but I should say I would have liked I would have liked. Okay, so this project spans two preprints with several dozens of pages. And I hope, I don't know if I would be able to give you the whole journey of how we get to this, but I will try and we'll see where we get to. Okay, so my goal now is going to be to explain the things in the tile, which are locally testable codes in sheaves. What's the connection between them? And I will say something. Between them, and I will say something on how we get to this. So, let me start. This is a math conference, so I should explain a little about locally testimonial code, which I will review to LTCs. So the idea of coding theory is that, okay, so let's say we have a finite alpha net. So, usually it's 0, 1, but I will care about. One, but I will care about very large alphabets today, so it's going to be a huge alphabet in what I've gotten. And the idea of curing theory is that we have an M-letter word that we wish to transmit across a noisy channel. And that noisy channel, it means that somebody flips letters, a small fraction of letters at random. So, what do we do? We just identify sigma to the m with a subset of With a subset of some longer words. Those are called code words. This is called the codes. The elements here are called code words. This is going to be transmitted across a members and channel. So what this means is some, so I have some word here and some, so few letters are flipped and I get my word. I don't know, so I get a different word. And so I get a different, possibly different word, omega prime, and I need to recover omega, my original omega. And because n is typically bigger than m, the question is how to design this set of code words so that it would be possible. And let's see, just coding codes are the efficiency of codes that is measured by a few parameters. The first one is the distance of the code. Of the code that is all denoted by just this of C. By this I mean the minimum of the distance between any two words in the codes of W1, W2 and C and are distinct and And this means, so I count how many indices are different. And I normalize by the length of the word. Okay, so that's called the normalized Hamming distance. And this is a number between 0 and 1. And notice that if less than 1 If less than one half of the distance the letters are corrupted or flipped and I can recover an F omega from, I'm sorry, W from W prime. So this is one parameter that we care about when we do coding theory. Another parameter is the efficiency. Is the efficiency of a transmission that is called rate the rate of the code. So, this is essentially the efficiency of the transmission. So, it's the number of letters which I want to send, modulo, the number of letters which I actually send. And if that number is small, then I'm not wrong. And if that number is small, then I'm not very efficient. If it's large, then I'm pretty efficient. You can also, it's the same. You don't need to appeal this thing. It's the same as the logarithm and RC to basis the size of sigma to the n. And what computer scientists care about is constructing sigma, not sigma. Sigma to the n. Oh, sigma. Oh, silly. No. This is normalized when you're running. I should say this is often called relative distance. I mean. Okay, so computer scientists care about good codes, which means just an infinite family of codes. So typically it goes by the natural numbers such that Such that, okay, so the ni's go to infinity, so the length of the block that I send goes to infinity, and the distance of all these codes is the interim is greater than zero, and the interim of the rate. Let me denote that by R of C. Of C is also positive. So it means that I'm increasing my message by a constant fraction, and I can recover my original word if a constant fraction of errors occurred. Okay, so it doesn't matter how big the message is. And what about the stability? So what is look at the stability? So let me say we say Let me say, let me say it in a few words. So the recovering of W from W prime, while in theory, I mean, we know that it's possible if only a few errors occurred, but it might be an expensive operation. So we want to know that if, let's say, I don't know, there was a huge communication glitch and all the letters got corrupted, or 80%, some huge number of letters got corrupted. We got corrupted. We want to know about that quickly so that we don't try to decode. So we want to know quickly if there was a huge corruption of large number of letters. So the idea of model testability is that we want, so I said we want to know quickly if the word was significantly Quickly, the word was significantly corrupted. But what this means informally is that we want a randomized algorithm which takes some lambda prime, not in the code, but some word. And what it has to do is the And what it has to do is the following. It accepts that word if it's in colludden. So it accepts all core words. And the probability of rejecting, so that the algorithm either accepts or rejects, the probability that I reject that word is at least epsilon times the distance. Times the distance of that word from the code. And the last case is that the algorithm probes only, let's say, L letters from track, so it only looks at, let's say, ten letters. And based on that, L is a constant independent L. Yeah, so L is not dependent. Yeah, so L is not dependent on this on you usually like to let this n go to infinity and that those two so here L is some fixed natural number and epsilon is some somewhere between 0 and 1 and you don't want to depend on this n. But we are letting n goes with yes. So okay, I should say we call this fixed, yeah, it's got a family of all of the tests. So I call this an L query epsilon tester. And notice that, I mean, if I only prove 10 letters out of, I don't know, 1,000, then most chances I won't even reach the corrupted letters, right? So the best I could hope for for is to be proportional to the distance of that word from the code. Okay, so this is why you see epsilon times the distance from the code. The distance from the code. So, this is the best we could talk about. And a family of LTCs. So, you're assuming that you can see for the purpose of testing, you can see both. No, you don't know. Omega is not known. You only see omega prime, and you have to guess. You have to guess if you got to guess what is, you have to find what is omega, and if significant. And if significant what we want to know is that there was some too many letters were corrupted, and we don't want to attempt decoding, so we just ask for retransmission in that case. By the way, and if that probability is very small, we can just perform this test many times, right? To increase the probability that we detect very corrupt anodes. And I should say, but everything is independent of the size of. Everything is independent of the size of sigma, right? Yeah, so by a family of locally testable codes, I mean really a family of codes like that and all admitting an L-query epsilon gesture, and it's the function. And the point is that the same epsilon and the same L for all basic, it's the same ones. And it has been an open problem, and so the major open problem in computer science are there good LTCs. There are an infinite family. Is there an infinite family which is both good? So the rate is bounded away from zero, the transmission rate, the distance is bounded away from zero, and we can detect significant corruption. And okay, there is a long history for that. Let me know, forgive me for not going into it. So I guess if you take any code on, I don't know, V text. It takes letters and colours made seven letters. And you just concatenate. So I could, you mean, just repeat the word several times? No, so if you have a longer message, just cut it into chunks of three letters and one of them. Will will that not be locally disciples? I mean I can really a random block. I think not. I don't think so. I think not. I don't think so. But let let go. I need to t let's I don't want to go into that right away, but that doesn't work. The suggestion was to just take, I mean, that code would not have good distance because It's not the rest of the world. Yes. Let me go on. Okay, so let me give you the state of the art on this and that the main breakthroughs came in late 2021 and 2022. And so there were two works which actually solved this problem. So yes, and this is due to lots of names here, the new work of Ra. Here at the new Levna Lubotsky Moses and independently Mentelev and Kalachev Kalachev. So this is very recent. So, this is very recent. In their case, the number of queries you have to do is, I believe it is large, very large, I guess. What I want to tell you about today is I want to focus on two query codes. So, you just probe two letters. So, the alphabet size is going to be pretty large. And two letter, two query codes, and they are important to computer scientists for other purposes, which I will not go into. Not going to. I'm not an expert either. Okay, so that's coding theory. So today we're going to look for L equals 2, and sigma is going to be, the alphabet is going to be very large. So it's still some kind of ball. Kind of a handbook project. So how do we do this? So we're going to entirely different room and I'm going to introduce she's fine as spatial complexes. So just to uh make sure that everybody Sure, that everybody knows. So it's influential complex to me on a vertex on a vertex set to Vx is just a subset of our set of the vertices and such that. And such that, well, the singletons are in X, they're in vertex. And if I have some member in X and it has a subset, then that subset is also in X. And you should think of it of the vertices as, well, being vertices as the two element sets being edges and three element sets. And three elements at the same triangles, and so forth. Okay, so this is very standard. And just a piece of notation xk will denote the k faces of x, which is just all those sets in x of cardinality, k plus 1. There is also an empty face of dimension negative 1. And let f be a field. Be a field. So, definition. Definition is the following. So a sheaf, I should call this an F sheaf because it's a sheaf of vector spaces for F, but an F sheaf on a simplical complex X. X consists of the following data. So one, it's an F. It's an F vector space curly F, okay, the sheaf, I will name it curly F, a vector space f of X for every face in X, but non-empty, every non-empty face. And second, a linear transformation, which I call restriction. Which I call restriction from y to x. And it goes from fx to fy for every, whenever x is contained in y and x is non- And it has to be subject to the following condition. Subject condition that the restrictions maps are compatible. So the restriction from Are compatible. So the restriction from C to Y composed on the restriction from Y to X is the restriction from X to Z. The map is going up. They go up, yeah. And it's still calling to a strip ship. Yes, so I will explain that so okay, I should say I b I believe many of you know sheets on topological spaces and this is completely different. Spaces, and this is completely different. So, this notion can be realized as sheaves on an honest topological space. There are other notions of sheaves on graphs by Joel Friedman. There are local systems on Posets. Let me not go too much into the history of this notion, but yeah, they go up. And you should think of these as, okay, so each face. Each face kind of represents its immediate simplicial neighborhood. So if I have a vertex V here and I have an edge, let's say the edge, this is an edge in the center here. I have a vertex V. So when I say that F of V goes to F of E, then what I really mean is that, so that V kind of represents This neighborhood, this neighborhood. And I go to the simplicial neighborhood of that edge. So here is that simple. So it's really a restriction of from one open set to another open set. So you should think of. set to another open set. So you should think of each phase as representing its immediate simplicial neighborhood. So this is why it goes up. So you're not asking that identity of yeah you should I should have that I just do this and then you can define that the restriction of from X to itself is the identity but I usually just Is the identity, but I usually just save myself time and assume that x and y are different. Why is this not a fresh sheaf? So because, okay, on that, so I let me not go into this now. These can be realized as sheaves on some topological space. These cat this is a cat this is an abelian category, and this is equivalent to the ability to some abelian category of sheaves on some topological space. On some topological space. I mean, sheaves appreciative, just. She's not pre-sheaves. She's. Actual sheaves appreciative. It's a pre-sheaf. I know that it looks like it, but it's not. So just trust me on that. So this is a very, very nice and easy case of sheaf theory. And I'm hiding the topological space. And everything that you can do with sheaves, you can do with these sheaves. You can do with these sheaves. And it's just kind of simpler and nicer. And in particular, you have sheaf. Okay, let me give a few examples. How much time do I have? Okay. Just a few examples. So we have a notion of a constant sheaf. So if v is some, I'm going to do just vector spaces. So if v is some vector space, then you just take f of x to be v. f of x to be v for every non-empty phase, and you take the restriction maps to be the identity. And that's the constant G. And I will usually denote it by simply as v, this is common in algebraic topology and algebraic geometry. And something a little more interesting is that the representations of the fundamental group of my complex The fundamental group of my complex, if it's connected, they give rise to sheaves on X with one-to-one restriction maps. These are called local constant sheaves or local systems. I should say this generalizes the local systems on graphs by a Germanic machine. So this is technically only. So, this is, I think, the only special case that I know of in the literature. And you can have many sheaves on graphs because this condition is actually vacuous for graphs. You will never find three faces, three non-empty faces like that. So on graphs, you have many, many, many sheaves. And you can also take subsheaves of those two examples, and you can take quotient sheaves. There is a very immediate notion of quotient sheaves and sub-sheaves. Sheaves and sub sheaves. So, this is the main source of examples. These are the main sources of examples. Sub-quotients of a notion of sheaf cohomology. And it's, so let's forgot, to make the definition easier, I'm going to fix a linear ordering on the set of vertices. And I'm going to put ci xf to be just the product of all the f-axis as x goes over the high-dimensional faces. So let's see i. And there is a homology theory in the usual sense much much Just much, much easier than shift cohomology on topological spaces. We have di, the icon boundary map going from ci to ci plus one, which is defined by, I take these are called, the elements of this set are called cosycles. If they evaluate it at some phase, then I just go over. Then I just go over the subfaces of dimension Li. This is an i plus 1 face. So I would like to write here f of y, but, I'm sorry, f of x, but this thing lives in this space and not in f of not in curly f of y. So what I have to do, I have to apply the restriction. The restriction and then I have to add a sign. And the sign is it usually tells me that this is negative 1 to the s plus 1 if x is obtained from y by removing vertex number x. This is why I need the order meeting. Yeah, so I quickly with the red, this doesn't show up well. So in the future, it's okay this once, but in the future, yeah, use it. I will, okay, so sorry. I don't know how many colors there are, but yeah, red was not. Okay, okay, sorry. But this is a standard sign choice in cohomology. So and we have the, if I compose it twice, then it is zero, so I actually get a cochain complex, and this induces And this induces common bunch of groups, which are denoted h i x with coefficients. Then I have co-cycles and co-boundaries, the whole usual thing. And just for example, if I just take f to be the constant sheaf of this vector space. This vector space. And what I have defined here is the same as the singular cohomology of the topological realization of x. So this is the singular cohomology of the sites. And in general, you can get more interesting stuff. Okay, so And maybe I should say H0, what is that? And if you think about it, so it's all of those, what am I looking at? I'm looking at zero to second, so those are F choices of F, B, and D. Is a vertex such that the restriction, if I restrict my vertex, And very swiftly from some vertex to an edge. This is the same. This for every edge E, which is the union of two vertices. So it's just a choice of, oh, sorry, this should be F V. This should be F V. I just choose something on every vertex and they have to agree on the edges. And here you see kind of. Kind of some kind of connection to property testing. Okay, just a quick remark is that I excluded the empty face. And you can actually repeat the construction of the sheaves on X, but allow the The empty face. So, what do I mean by that? I mean that this is defined and everything else is the same. And this is called, those are called augmented chips. And I don't know if they have. And I don't know if they have a good topological analog. This is something which we do not see in topology, but we do see it in the theory here in a natural way. So they have, I mean, they have, I can define C, the negative one cochins. It's just f of the empty set. And I can even define the negative one cohomology. So this is kind of where I depart from. So this is kind of where I depart from ordinary cosmology theory. And just an example. There are two important examples are the constant augmented sheaf, which is, again, choose f of x to be the same vector space all the time. So it's denoted And if I take its cohomology, I'm going to get the reduced singular cohomology instead of the coh. So it's actually, we see it a little bit with topology, it gives us the reduced singular cohomology. And perhaps a more important example is that let z be some non-interface of x. So the link, we can form the following sequential complex, which is the number of x. Calling sequential complex, which is the number x. It's known as the link of x. So that's all those faces x in x such that x cop z, x means z in x, and x does not meet z. And this is called the link of x and z. And if you want a picture, I don't know, sorry, if that I don't know, so if that is this if this is X and this is my vertex Z, then the link would look something like just this hexagon without the interior. That's that, this is X. And if I have a question for usual sheaves, the value on the empty set is usually the final object. In this case, the zero space. Initial, I guess. Initial. Yeah. Yes, initial. Yes. I could define it to be the zero object and then I would get a shift, if that's your question. So it's an extension of the concept of. The XM of sheafs, in the usual sense, forces this to be. It doesn't have to be zero. I mean, for instance, if I take everything to be the same vector space, then I could choose that to be the vector space. And this is what I do when I talk about the constant augmentation. Actually, choose that to be that vector space too. And it's going to kill the zero. And it's going to kill the zero of, and I'm going to get boundaries in dimension zero coming from that. And it's going to kill the zero of cohomology. And this is why you get the reduced cohomology instead of the ordinary cohomology. Okay. So if I have this link, so I can restrict. My sheaf F to an augmented sheaf on the link. So it's simply by defining, so I'm going to name that, I'm going to call it FZ, and it's defined by, well, I just do this, and as for the restriction maps, I will just do what Just do what is what makes sense. And we'll just define the restriction not with f, but with y cop z coming from x cup z. And here you see this is defined for the empty set as well, right? Even if it's because z is non-empty. So sheaves naturally gave rise to augmented sheaves at the links. So this is a natural notion to consider. And okay, so what does this have to do with coding? With coding theory. Any questions so far? Okay, so the relation to coding theory is that the space of cocycles could serve as a code, so cucycle codes. And it also leads to the notion of an expanding sheaf. So you know that there are expander graphs and high-dimensional expanders, and I want to promote the notion. And I want to promote the notion of an expanding sheaf, which I don't think has any analog in topology. So the idea is the following: so let's say that f is the sheaf on x. And let's say I have some number k between 0 and the dimension of x. And suppose that there exists some natural number m. Natural number m such that if I evaluate f at some face, I get f to them, but for every k-dimensional face. So on the k-dimensional faces, I see the same vector space all the time. And let me call that thing, let me call that sigma. So I'm creating expectations here. Expectations here. Okay, so what can we do? Then CKXF, what is this? This is just a product of all the k fix. All the k faces at x, which is just the product of all the k. I mean, this is the same as sigma to the x k, because I assumed that each of these is sigma. Right? So I can think of C K as a code inside a C list. And it doesn't have to be a good code, it doesn't have to be testable, but it does have. So we can, it does have a way to, there is a way to test, oh, I'm sorry. ZK, I'm sorry. ZK, I'm sorry. Yes, thank you. I said cosycles. I meant this. I can think of the cosycles as a code inside this set. There is a very natural way to test. Way to test. So we can test with k plus two queries if we have some f in zk is contested in k plus two queries if it's in zk. I'm going to just choose some k plus one face at random, uniformly at random. And accept if, well, I just compute a co-boundary and I evaluate at y. And if this is 0, then I exit. And right? And I need to probe k plus 2 k phases to compute that. Right? Sorry. So this doesn't have to be a very efficient tester, but it is. Have to be a very efficient tester, but it is a tester. And okay, so maybe the question is: so, when is this a good tester? So, this is an epsilon tester if the following, well, what does it mean for this to be an epsilon tester? It means that for every k co-chain f, the probability The probability that f is rejected. So this thing accepts every cocycle, right? This thing accepts every cocycle. And the probability that I reject something, I want it to be greater than epsilon times the distance of f from CK. And this probability is precisely, if you think about it, it's the number of y's. Think about it, it's the number of y's for which this thing would be non-zero divided by this number. So that's exactly the Heminghorn of And what about the distance in the next board? So this can set the scope. Well, typically bad or typically small if I have coboundaries. Coboundaries. Coboundaries are typically small because if I take some, I don't know, I can just take something which is supported on one k minus one phase, and then it would be supported on a very small area. It's co-boundary is going to be something very small here, but it's typically small if this is non-zero. But for instance, if k equals zero, then this will be zero. The best we could hope for, the best we could hope for is Is the following and that's for every f which is not for every f which is in the code that is not a codometry, the Hamming norm of this is greater than, say, some delta. That's greater than or equal to sum for some delta. And that's the best we could hope for. And let me call this condition. We call this condition one. This I want to hold for every f in CK. We call this condition two. And definition xf is called a an epsilon delta cosystolic standard if one of the equations. If one and two. And this is going to be a two-part definition. If something more happens, if this is called an epsilon co-boundary expender, that's called histolic, and that's co-boundary is moreover. Moreover, the cohomology group, the K homology group, if moreover BK is CK, it is CK, or equivalently HK branches. Yes, you have to define it consistorically spander at level K in dimension K. Whoops, yeah, in dimension K, I'm sorry. Whoops, yeah, n dimension K, I'm sorry. N dimension K. Oh no. Let me go five more minutes and then I will stop. Okay? Sorry, this is uh. Okay, so these are two notions that have been considered in literature. This has some history. And I will say that Cobander expansion uh was originated in the works of Lin Yellen Schulang in Romov from two thousand nine to twenty ten. 2009, 2010, and they considered only this case of constant sheaves or constant elemented sheaves. And they wanted to tell it, they used it for the topological overlapping property. And this was introduced later in the works of Karlman Koster and Dubotsky and Dotterell and Karlman Wagner. Wagner all around 2015. And mainly for the so this was kind of known or considered for this chief, the constant chief with this. But also we consider here some general version. And the moral of this, what this means is that That if we want to get a locally testable code is the following. So just the moral is that if an achieves with large systolic extension. Co-systolic expansion in dimension zero give rise co-systolic expansion. What? Cosystolic expansion, this abbreviation. So if I apply this definition with k equals zero, and this is going to be zero, so they give rise to, okay, with, I don't know, with, let me be specific with With epsilon developer cosyston expansion, they give rise to locally testable codes which are, okay, they give rise to codes with distance which is greater than or equal to delta and the two query epsilon plus two. So that's the connection of all of this, and so this relates. That's how this relates. And let me give you the main result now. And with that, I would like to finish. And we call this the tower paradigm, but it's just a name. And it means that from a finite set of data, you can actually produce an infinite family. You can actually produce an infinite family of such sheaves. And the way it works is the following. So suppose that X is a pure simple complex of dimension greater than or equal to and let And let F be an F t sheet on X and suppose that if I evaluate it on a vertex, I get F to P B M for every vertex, and it's the same M for all. And suppose that the following conditions are met. Uh, that the following conditions are met. So I'm going to write these conditions in four. So the first condition is there exists an infinite tower of double. Of double coverings. And this kind of connects to the beginning of the lecture. So x, which x is covered by x1, x2, and so on. There are so-called local expansion conditions. So for every z in x which is not In X, which is non-empty. I will not write down the precise conditions, but X, C, and F C is a good coboundary expander in some dimensions and X itself is the underlying graph of this is an expander. The underlying graph of this is an expander, is a good expander. Let me not specify in the interest of everything what are the precise constants. And the third part is that the dimension of the topology is greater than or equal to the dimension of the first homology. Then there exists an infinite family. Family of good two query LPCs. And I'm essentially out of time, so I cannot, I will tell you what is the family briefly. So the family is that, let me denote the, so I have x x r goes to dot dot dot, goes to xy. goes to dot dot dot goes to x1 goes to x so that's a morphism and i said those are sheaves so there is a pullback there is a pullback sheaf so it gives rise to a pullback sheaf u upper star f u r upper star f on x r. So I can do everything that I have with normal sheaves, I can do with these sheaves, and I have a full app sheaf. And I have a full website, and it gives me the code. It gives a code, a zero cosycle code on SR. And that's how I get the camera. I'm out of time. So we need to start pumping. Start punctually our last talk by Rama and Tarimala at 4:30, but maybe there's time for one or two quick questions. Obviously, there are some alphabetic groups in the background. Yeah, so there is a question of how do I construct something satisfying these three conditions? We have some way. Actually, we had this a year ago, and then we were struggling about constructing this. And if you can find an arithmetic group with the drawing, An arithmetic group with the properties of the beginning and some other maps. Basically, the problem is only with one and two is the work of the combo expander, which from the yes, this is the main issue. But I should say the highlight is that these two conditions can be checked with a finite computation. I didn't say that. So that's what I said. So why don't you check T3 by? Why don't you check T3 by computer? That's pretty tough. What? That's very difficult. We have computational limitations. We cannot compute. It's so large. We can't compute anything. The thickness that you need for the building is huge. This is the true magic of this, that you only need this one miracle and it gives you a good rate. And now the team one which shift are you taking now? So that's I I don't I will have I can tell you later, but it will take me more time. So but the next the next step is to construct something that satisfies this and this is still open, but we have some ideas. But the space is the quotient of some building where the Yes, it's going to be the quotient of an affine growth. The x that we're going to choose is going to be the quotient of some affine growth. It's building by some groups. Index to subgroups are going to give rise to these guys. We're going to choose a shift that comes from a representation and we're going to modify it so that this actually happens. So I didn't say that by taking quotients and sub-quotients, you can actually play in contrast with ordinary shield on topological. In contrast with ordinary shoot on topological spaces, you can actually play with this quite a lot. But like I said, how do you what is the magic that you