So here's his title. So, Tobias? Thank you. So let's see if I can move. Yeah, I can move. So the goal of this talk is to connect homology, in particular Homphyl homology, to curve counting in the resolved conifold. And that's, of course, I'm not the first person who. I'm not the first person who made that connection, but there is maybe some news towards the end about that. And the talk will, however, start from connecting curve counting to the sort of unrefined Homefley homology, just Homefley polynomial and in symmetric colours. So that's an old insight of maybe Uguri in Waffa. Huguri in Wafa. But there has been some progress over the last few years in understanding somehow in mathematics how you actually do that a little bit more rigorously. And it's somehow a new way of treating open Gromovitan invariants. They have values in the skein module of the Lagrangian on which they end. And so I will go over that and that will be once some. And that will be also somehow the main starting point for relating this to not homology. So let me just start and tell you about this somehow curve counting in general and what is the new perspective. And so we have the standard set up. So there is a three-dimensional Calabio. Calabio and it's not going to be super fancy, so it will be C3 or T star S3 or the resolved conifold. So these are all friends. And we will have a mass loss zero Lagrangian in this Graviao. And also these people will be well known. So they will be the toric brain and conormals of knots in S3, both in T star S3 and Both in T star S3 and in resolved conifold. And also, there will be the zero section in T star S3 around. And then there will be also some kind of maybe a little bit of outlook into other three manifolds and what would happen there. But anyway, so what we do is we take an almost complex structure on this Calabio, and then, of course, a holomorphic map is. A holomorphic map is a map from a Riemann surface into this space, and it takes the boundary to the Lagrangian, which solves the Cauchy-Riemann equation. And now that equation is a Fredholm equation, that means that its linearization is a Fredholm operator. And therefore, the index of this Fredholm operator is the expected dimension of the moduli space. And here we see this. And here we see this nice property of three-dimensional Calabielos that the dimension the dimension formula is somehow the complex dimension of our space minus three times all the characteristic of the surface. And then there is a relative, in this case, Chern-class term, which drops out if you're in a Calabiau and if you have Mass Law serial Lagrangian. So somehow the second term drops out in Term drops out in Calabios and Mass of zero, and the first term drops when the dimension is three. So that means that in these spaces, whatever holomorphic curve you see, it will naturally have formal dimension zero. And in particular, one would then guess that after perturbation, this space of holomorphic maps is a zero-dimensional manifold, or perhaps better, zero-dimensional. Or perhaps better, zero-dimensional orbifold because there's some group action or something like that. And so one should be able to count the solutions to the equation and hopefully do so in an invariant way. So in the case of no Lagrangian, when we just take closed curves and perturb, then indeed this is true. And the main point making Roma-Witten invariance invariant. Witten invariance invariant is that when you deform, say, the complex structure or something like that, then the curves may move, but the singularities in this space is in codimension two. So when you meet the nodal curve, there is somehow a codimension two locus because you have a stretching parameter. I mean, it's like xy is equal to epsilon, where epsilon is. Epsilon, where epsilon is a complex constant. So it's somehow codimension two to go to the origin, and this codimension two is manifest in neck stretching, and there is a twist in this neck as well. So that's the two parameters near the nodal curve. But when we have open curves with boundary, then the twist in this stretching is gone, and therefore there is a codimension one low. There is a codimension one locus of nodal curves in the space of in this in the moduli space. And in some sense, one should then not expect that there is an invariant way of counting these curves. So here is the here's the basic problem, and that's somehow here on the left-hand side you have two boundaries of two holomorphic discs. So the black board is not the This is so the blackboard is not the blackboard, but the paper sheet is somehow the three-dimensional manifold. So I'm drawing just the boundaries of two curves. Here they are, and they happen to link. And maybe then as I deform the complex structure, the curves start moving. And at some point, the boundaries intersect. So then I'm in this co-dimension one wall. And when I come out the other direction, of course, the two discs, the two separate disks, they can just make. Separate discs, they can just maybe go or curves can go on. So I have two the two curves that I did have, but on top of that, I could glue the two curves to a new curve, which is sort of twice the size of what it was. It's splicing here, and I get sort of three curves on this side. And indeed, there is in no way the case that two curves, if I count them naively on this side, is equal to the three curves that I have on the other side. Three curves that I have on the other side. And then that sort of presents a problem. But as we will see, you can resolve this problem provided you count the curves in an appropriate way in the skein module of the Lagrangian. So that's what I want to explain. And in general, we'll use the Homphyl skein. And for kind of illustrative purposes, we'll also use a little bit of the Kaufmann skein because when we have Because when we have a Lagrangian which is fixed by some involution, because in that case, you can actually define more ordinary curve counts and you can compare the sort of skein curve count to the ordinary curve count and see the difference. So, but our main player here will be this Homphley scan. Okay, so what is the Homphley scan? Well, the Homphley scan associates a module over a ring of Over a ring of two two variable ring, Laurent polynomials in variables A and Z and to a three manifold and the module is generated by all isotopic classes of framed links in this manifold. So you think of a link, so that's an embedding of S1, but somehow you fatten this S1 to a small infinitesimal band, right? So you have a kind of framing along the naught. Framing a naught. And that's a huge module, but we quotient it by certain relations. So there is the following three relations for the Homfiskey. So what it means is that you take your link and in some little ball, your link may look like this overcrossing. And then you can replace the overcrossing by an undercrossing and Z times the spliced. times the spliced the result of splicing so somehow you relate the value of this link in the scan module with two other links and there is some kind of normalization condition that tells you that the unknot costs a minus a inverse over z and finally there is this somehow framing framing condition that says that a little kink with an over crossing can be replaced by an a times the sort of frame The sort of framing changed link. And so this is some module, and in particular, for example, if you have the three-sphere, then this module is generated by the empty link, in fact. So that's why there is the Homfley polynomial. So if you take a link, you draw it, you apply all these relations, eventually you come back to a bunch of unnodes and some polynomial. And that polynomial is the Homphyl polynomial. Is the Holmfree polynomial and somehow, well, one has to check that this is invariant, otherwise, we talk about what it is. So, for the Kaufman, on the Kaufman side, there are very similar relations. Here, the links are unoriented, still framed, and the first relation turns into from three to four terms. So, there is two ways of splicing the crossing, and we take C times that. And we take c times that. The normalization for the unnaught is slightly different, but it's important that there are four terms here, just like here, as we will see. And the last term is somehow this framing change. It's the same. Here, one might wonder, how do you do framing when you don't have orientation? But regardless of which orientation you pick on, a little kink, it has the same sign. So that's how you define this A array inverse. So this. So, this skein module has been and can be computed for many three manifolds. The S3 was very simple. For the solid toruds, it's a free commutative algebra on somehow countably many generators, which is basically what you think. So somehow you take a connected m times around naught, both positively or negatively, and the algebra structure is obtained by Obtained by stacking, you can think of this as an annulus times R, and you stack them from outside. Okay, so that's where our invariants will take values. And the curves that we count will be slightly different from the ordinary curves in Gromo-Witten theory. So we will count only. Only what we call bare curves. So these bare curves are curves for which all component, all non-constant components, or sorry, all components. So a curve is in general like has a nodal domain. And we will care only about those maps which have positive area on all their components. So that's a kind of bare curve. A kind of bare curve, and it's not super easy. I will tell you in a while how to actually set up the machinery for counting only bare curves, and there's something you have to prove in order to do that. And I'll talk a little bit about that. But anyway, so for generic perturbation, these bare curves will be embedded and in particular, their boundaries will be embedded curves in the three manifold. Embedded curves in the three-manifold, and we will count them by their values in the skein module of the manifold. In order to do that, we need to say something about this framing, and the framing will be, as in scan theory, very much related to this A variable in the scale. And how do we actually deal with the framing? Well, we pick some additional geometric data. Additional geometric data, which is just a we can take it to be actually generic is enough, but take it for sanity's sake to be a non-vanishing vector field along L and this vector field will we will also pick a four chain, a four-dimensional chain in the six-dimensional space, which has boundary on L, actually on twice L, and it will start on out. And it will start on out, it starts out on j times this vector field and minus j times the vector field. So in the basic case of say S3 in T star S3, you pick a non-managing vector field and this chain that you get is just somehow the graph of that vector field in the cotenant bundle in the positive direction and in the negative direction. And you orient the pieces so that both of them have boundary equal to. boundary equal to L. So in the resolved conifold, maybe you have to construct this. It's a homological condition, but you can do it. Okay, now we will use this four chain to define a certain linking number between a holomorphic curve with boundary on L and L itself. And it will also be used to define a framing of the boundary of the curve. So basically for generic data now, our holomorphic. Data now are holomorphic curves, will have an embedded boundary and it will nowhere be tangent to this ψ. So, xi and the tangent of our curve determines, you know, there is a normal vector on that plane from that plane. And we'll use that as a framing vector for our naught. And we will use it in a slightly different way also. So we take the boundary and near the boundary, we shift the holomorphic. And near the boundary, we shift the holomorphic curve along j times this normal vector field ν. So, note that when we do that, we shift, of course, the curve off of the Lagrangian, but also since the four chain starts out in direction j times psi, which lies in this plane, these vectors are sort of perpendicular, we shift the boundary of the curve off of the four chain. Of the curve off of the four chain as well, right? So now we have a two chain which is the curve and a four chain with disjoint boundaries, and we define the linking number of the curve and L to be the intersection number of those two chains. Okay, so it's somehow, of course, this may depend on the vector field. I mean, if you pick another vector field new here, it's determined by our data, but if we pick another one, it may. Data, but if we pick another one, it may change. So it may be intersections here. But anyway, this is what we do, and we call it the link. And then with all this extra data, we are somehow ready to explain how we count the curves in the scale. And the way we count them is that, as you remember, these bare curves, we have some generic perturbations. So it's actually a manifold, possibly orbifold. So this point. This point, which is the curve, has some weight. So it's maybe you can think one or minus one, but maybe sometimes some group action. So it's maybe a rational number. Okay. Then we take the variable z and raise it to the negative of the Eulie characteristic of our curve. So depending on the topology of the curve, we get different kind of contributions. And then we take the A variable to the linking between Linking between L and the curve. So there was somehow this shifting off and four-chain intersection. So that's the exponent of A out here. And finally, we take the boundary of the curve framed by the vector nu and consider it as an element in the scale of L, right? So this rational number times Z variable times A variable times some polynomial in A and C. Polynomial in A and C, if this was S3. But in general, somehow, this, of course, this is element in scale, and that time C and L also element in scale. So that's the contribution from one curve. Okay, so the main point with this skain-valued invariant is that it is actually invariant under deformation. So this skein-valued invariant, as I'll discuss briefly, resolves these two. Resolves this two is equal to three problem in a nice way. And maybe I should say one word for those with some sort of technical interests. How do you actually carry this out in terms of holomorphic curve counting? Well, what you do is, of course, you naturally need to have some space where not all curves are bare. So, in general, if you have a holomorphic map in the Calabia, In the Claudia L3, then you can attach any old constant map from any old domain and build a nodal curve along that curve, right? And we need to build the space where we have all those objects in there, but then prove that somehow we can neglect them. And the way we do it is that we attach a big weight on almost broken components. So when you have a component, So, when you have a component that is about to break off, so here's the local situation in R6, then you redefine the weight on the functional analytic space where you look at the debar problem in order that it's sort of growing with the size of the gluing neck. So, this is a short story version, so it's somehow you need to first do that in direct. somehow you need to first do that inductively in in in r6 and then you put that story everywhere where a bubble is forming so you you somehow define such a space and the key point is maybe that when you do that and you rescale things the debar operator the use the kind of debar operator that we have is converging to the linearization of the debar operator on vector fields over the constant curve so in some sense this weight This weight is not as dramatic as it seems. It's more or less like some rather complicated blow-up where you try to keep all these constants. So this is the thing that you have to carry out, and you have to prove that there exist perturbations here. And the main point is you have to prove that bare curves and somehow live an isolated life. And I'll try and tell you how that goes. So, so one has to define suitable perturbation data, which I'm not going to go into. But after that has been done, the following steps are needed. So, first is by somehow general Fredholm theory and some evaluation maps, and it's not so very hard. One shows these statements that I made that a generic. Made that a generic solution to this equation is transversely cut out and everywhere boundary linearly independent from psi and maybe transverse to this four chain. So this is just general position sorts male thing. But then there is a new ingredient and that's a very important, the most important ingredient for this bear curve counting. For this bear curve counting. And that's that, you know, if we try to count bear curves, here is on the left-hand side, here's a bear curve, it has some kind of genus one and boundary. And now, you know, we count it. And the worst case scenario, this bare curve would converge in the limit when we deform, say, complex structure to something which is a new bare curve part of it and a complex. Curve part of it and a constant attached. Okay, so then of course our bear curve count would have no chance of being invariant. Here there would be some Euler characteristic to the whatever and here would be some other Euler characteristic and somehow the bear curves actually change. But the point is that these cannot happen for generic data. So that's somehow the upshot of the story that when you have a constant Have a constant curve bubbling off somewhere, you see that you see a trace of it on the curve from which you bubbled off. Namely here, there would have to be a singularity in the curve. So you use this, you prove that if you have solutions, these weighted things that you add on in the strange space of bare curves or configuration space for them, it actually decays that fast. Actually, it decays that fast. And when you zoom in, you see that the curve would have to have a singularity. And by the previous step, it's kind of inductive ingenious in order characteristic. There are no such solutions. So this is sort of the key step for counting bear curves. But once we know that these objects actually bubble off in codimension two, then we can look at what And then we can look at whatever happens in generic one-parameter families. And here is somehow the picture of that. So on the left, we have the Homfley picture, on the right, there is the Kaufman picture. But let's do the Homphley first. So if we have a family of curves which the boundary goes through and crosses, then at exactly this point, since we have only bare solutions, there Have only bare solutions. There will be an identification between this crossing curve and the nodal curve one genus up. So, right at this crossing point, there is a new moduli space beginning, and it starts like that. So, you can even write down a local model and show that this is the local model that governs this. But now you see that, so if I now add all these ends of moduli spaces, I find that this curve my This curve minus that curve, if this count should be invariant, this curve minus that curve has to be equal to this curve. But that curve is obtained from the nodal curve by increasing, right? I mean, it increases the Euler characteristic by one. So you see that this invariance under this type of real crossing is exactly the first skein move, skein relation. Scane relation. What about the second thing that can happen in one parameter family? Well, the second thing that can happen is you can have a holomorphic curve flying around and it's a two-dimensional object. So at isolated points, it can come in and intersect the Lagrangian. And at that intersection, it can go straight through or it can open up a boundary component. And opening up a boundary component decreases the Euler characteristic by one. But if you remember, our But if you remember, our four-chain was somehow oriented positively in some sense on one side, will go on negatively on the other. So here is one four-chain positive intersection minus four-chain negative intersection has to be equal to z times the boundary of this curve in the scale, right? So this is computing for us. If our curve count should be invariant, this relation has to be imposed. And so this, in some sense, computes for us the The Homphy of the unknown. Okay. And now, about the real case, I'm not going to say. So, permanent, the main difference is that if I have an involution in my space, then any curve I see, I can swatch reflect. So I have kind of two curves nearby. And so I have two gluings. I can either glue, you know, upper part of these to lower part of. Upper part of these to lower part of that, or upper to upper, and I have somehow two splicings, therefore. And this moduli space that previously just ended here now actually goes continues as a double curve. And that transforms the scan relation to that. And here you see the corresponding elliptic story and transforms the scan relation to this. But there is a kind of one other important observation here is that. Important observation here is that, unlike in the Homphyl case, the open case, where we actually have walls in our moduli space, there is another way to not view walls. Namely, we just go here. The boundaries here, they kind of cancel out. And that means that here, you see, in this relation, we are relating curves of certain Euler characteristic to curves of Euler characteristic one below. But we could also fix the Euler characteristic and just All the characteristic and just count ends in the moduli space here. And that's what's done in real grommo-Witten theory. So somehow here we want, I mean, it's smarter actually to do the Kaufman thing, but we didn't really have to. We could count it in the classical way because we see no walls in the more classical. Okay. This is the final move that explains this. That explains this slightly strange choice, maybe, of two copies of the four-chain. So, of course, in generic one-parameter families, the curve, boundary curve, could at some point be tangent to this psi. And when that happens, because the curve is complex, the tangent plane of the curve is tangent, the curve, the whole curve, is tangent to the four chain. So, as you move on, you see that there is a sort of four chain. Move on, you see that there is a sort of four-chain intersection born here if the curve is upward going, but if it's downward going, it's born here. And now there is a sign check that this intersection point between the four chain and the curve actually has the same sign as this crossing point, but that's not so hard to check in a local model. So we get the last part of this frame-skin relation. Okay, so. Okay, so so what we found was that this count in the scale is actually invariant, and um I have a couple of remarks here, but I think maybe I can skip skip some of them, but this one is a little bit important. So this C variable is, of course, the Euler characteristic variable. And if we would like to connect our curve counts to more traditional ones, then we should replace C by Q. And replace C by Q minus Q inverse, where Q maybe is this e to the GS. And the famous Guppa-Kombovaffey formula for contributions of an embedded curve with the right normal bundle to the Gromo-Witten theory looks like this. It's the exponential of whatever homology class to the power D for default covers. And then over D, n times this Q to the D minus Q to the minus D. Q to the d minus q to the minus d to the Euler characteristic. And you see that our curves, the bear curves, is basically corresponding to the first, not multiple cover of this formula, just d is equal one, right? So we are saying that at d equals one, we take the curve, it's embedded and ice, and there is these contributions from constants attached to the curve. So in some sense, comparing to Gupa-Kumawafa, what we're doing is we're perturbing things out. Now every Curving things out, now every curve is embedded, and it's only the first term in this formula that matters. Okay. So, anyway, I'd like to explain how this thing actually leads to a proof of large n duality. So, here we relate Homphy polynomial and curve counting in the resolved conifold. So, we start from a naught in the 3-sphere. From a knot in the three-sphere, we take its Lagrangian conormal and we shift it off the zero section by sort of shifting it along the dual of its tangent vector. So that's a kind of non-exact but still Lagrangian. So it's now off of the zero section. And then we can view the t star s3 as this conic where we put a little real epsilon on that side. On that side, we go to the cone point and we blow up and blow down, do the small resolution, and then we get this resolved conifold. But in some sense, if we do it with a small area of the CP1, then outside of the S3 where a conormal lifts, it lives, it's not so much affected by this transition. So you can think of the co-normal as also sitting inside this X. Okay, and then the Oguravafa. The Auguravafa large n result says that the partition function of counting holomorphic curves ending on this Lagrangian-the resolved conifold is equal to the colored Homphly. So the nth colored, symmetrically colored Homephili is the same as counting curves that goes homologically n times around, and A here is identified with the error. identified with the area with the homology class of the P1. And this is the homology class of the boundary. So let me tell you now how this skein counting leads to a proof of that result. It combines with the symplectic field theory stretching. So what we do is we start in S3 and I will, I mean, part of what I'm going to tell you about later will lead to approved. To tell you about later, we need to approve of many times around things, but for now, let me focus on ones around things and just maybe assume it can be argued that you can normalize one such curve. So they're basically along some standard curve here in the LK, or very close to it. But anyway, so if I start my argument, I shift off my Lagrangian conormal and off of S3, very small. Of S3, a very small distance. And when I do that, I find that in this homology class, going once around, I find a unique holomorphic cylinder going between the conormal and the zero section. So that somehow it's easily checked there is only one. And what are we learning from this gain-valued count? Well, what we learn is that we should count this unique annulus by Annulus by C2, whatever the Euler characteristic is zero, times the boundary of the annulus in the scan of S3, right? But the value of this boundary of the annulus is K itself. So in the scan, it's equal to the Homphyl polynomial. So somehow, whatever our count is, after some deformation, something, it's always equal to the Homphyl polynomial of K. Okay. And now we're going to deform. And the way we're going to deform. Going to deform, and the way we're going to deform is the following: we take a tiny neighborhood of this S3, epsilon distance, and we do SFT stretching, which means that symplectically we insert a very longer and longer and longer and longer and longer neck in here. And there is a compactness result in SFT. It tells you that under this stretching, when I take the stretching to infinity, the curve has to converge to some curve on. Has to converge to some curve on the outside asymptotic to rave orbits in the boundary of t star s3 here and then maybe some curve in between and finally from rave orbits down to the zero section. But if I put on s3 a round metric, then the geodesics on the round metric has index two. And that's also their Conley-Sender index, which means that their dimension input is minus two here. Input is minus two here. So the curve on the outside would have dimension, if it has any rave orbit, at most minus two. And that means that generically it's not there. So therefore, when I do the stretching, what I learn is that eventually all the curves will leave this little neighborhood and they will just sit outside the neighborhood and have boundary on LK. And when they're there, I can now just feel a little bit in the middle. Now, just fill a little bit in the middle and put it in the resolved conifone, and the curve count does not change. So, they are far away from this deformation region. And so, therefore, we learn that, you know, when I stretch, nothing changes. So, the Homeflow polynomial of this counts all these curves and we get this Uguriva result. So, relating Homphyl polynomial and curve counts. Okay, so. Okay, so maybe let me comment briefly on what's different in this setup from ordinary curve counting. So, for example, if you would take the standard unknot in S3 and this kind of cylinder, and now you start stretching, it's safe to believe that this boundary shrinks, shrinks, shrinks, and at some point goes away. Point goes away and then it lifts off. Okay, but at that point, we know from this moduli space that there has to be two disks crossing the Lagrangian. So at some earlier time, those two disks has to be created. So it's somehow one is plus one and one is minus one. And then at this point, they move across, and they're the a minus a inverse over q minus q inverse for the unknown unknown. Unknown Homphyl polynomial. And so, somehow, what we're seeing in this new theory is that this moment has to have happened before that moment, and that would not be visible in sort of the standard theory. And in particular, if we do this real Gromow-Witten count, where we can actually count things, then for any knot, this basic cylinder that we saw, you have to double it, but it's counted by one. And that's it somehow. So, if you don't, And that's it somehow. So, if you don't, in some sense, in the real Gromo-Witten theory, this crossing is invisible and so on. So, the invariant would become one. But if you count in the scan, you would get the Kaufmann polynomial of any node. So, it's a sort of more refined way of counting, in some sense, corresponding to counting curves in the complement of S in the O serial section in T store S3. Okay, maybe just very briefly, a word. Very briefly, a word about what happens for other three manifolds. So, if instead of S3 we have a man of three manifold M, then the main difference is that there are non-contracts, I mean there are index zero geodesics for any metric on this manifold. And therefore, pieces of the curve can actually get stuck. And that means that for such manifolds, there is some sort of universal Gromo-Witten-Skein invariant, which And scan invariant, which takes any collection of ray bo orbits and counts all the curves that go down to the zero section. So, let me not, I want to kind of get to the end of my notes. I'm going to skip this differential operator. It's some sort of SFT. This count of curves is not completely invariant. So, we need to correct it by some SFT story. Okay. So, I want to show you another. So, this is You and so, this is of course a great application of this skein count, but sorry to interrupt you, but um, that what's the interpretation for this general three manifold, you will still have some large n interpretation or what? Yes, so so if you so somehow if I go back to the actual argument, so you see, let's let's do this and replace S3 by m. So then I have this cylinder, I count it by the Have this cylinder, I count it by the scale, and it should remain invariant. When I stretch here in S3, since I have no rave orbits of index zero, everybody leaves. So that means that I also know that I have a dual for t star s3, which is this resolved conifold. If I was in another three manifold, there may be, and the only thing that can happen is that some piece here inside could still be inside. Here inside could still be inside. Okay. So the curves wouldn't close off, they would leave some little ray borbits here and go down to the zero section. And therefore, and what I'm saying is that that package that's left off is a standard package which has nothing to do with the co-normal. Everything that you possibly could attach to, I call this universal ground-width invariant. So maybe for a concrete application, you know, if you take You know, if you take RP3 here, then in T star RP3, there is one geodesic, so there would be one such curve going from this orbit down to the zero section. And the curves on the outside would have holes. So when you do the large and dual, then there are two Kayla parameters in local P1 times P1, right? But before you try. P1, right? But before you transition, this orbit here basically plays the role of one of these dual parameters, the other one, and the first Hill parameter is the empty orbit in some sense. That's the one for S3, and then this one is the other one. But if I took something like your three-manifold M to be like a three-taurus, so pure closed grammar widthen of the Large and Dual should not exist or should be something very, very simple. Yeah, it's too big. Yeah, yeah, it's too big. So you would have to have infinitely many Kayla parameters or something like that. So you don't have a geometric large and dual space where you close off everything. But in some sense, this T star s T3 with all these orbits, which would be any home topic class, and the corresponding knots on the zero section, is some kind of replacement for the large endurance. Replacement for the large endurance. So, somehow the T3 wouldn't go away, but it would stay there in a very specific way. Is it okay? Thank you. Okay, so I'd like to explain how you can use these to actually count curves. Curves from infinity, and I'll illustrate that by looking at the toric brain. So there is one other type of curve which one might consider, which is of dimension one. So in our manifold, say that this the resolved conifold, let's say, or here we'll actually take C3, there are There are the Lagrangian is infinite and goes off to infinity and ends there in the Leschandrian. And that Leschandrian has certain Rabe chords. So they kind of flow through the Rave field, flow lines, which begins and ends on this boundary of L, kind of ideal boundary. And now there are some moduli spaces of dimension one, which have a positive asymptotic at this rave orbit, rave chords. So we can. Rave chord. So we can look at such curves that you know has positive asymptotic. There, it looks like a strip over the over this ray chord. They go down, they follow L, they go back up. So this has dimension one. And if we consider the whole moduli space of curves with this dimension one, you know, this positive orbit, then by our deformation invariance, so somehow the moduli space involved. The moduli space involved, the boundary of that moduli space has to be zero in the scale. So somehow this is some closed one manifold, which maybe ends when curves become R invariant. But we have a one-dimensional manifold with ends, and those ends have to cancel out by invariance. And the ends correspond to curves at infinity, and we did curves inside. So if we knew the curves at infinity, The curves at infinity, we would know that if we take these curves at infinity and multiply them in the skein with the curves inside, we get zero. And this turns out to be a way of determining the curves inside in the skein, which is a horrible problem in subset. I mean, you have to take account curves and so on. You can just determine them by looking at the exterior curves, which are sometimes very easy to find. For example, for the toric brain, and let me not give the Me not give the equations more than these. So here we have a Lagrangian, it's the standard toric Lagrangian in C3, which in coordinates C1, C2, C3 is given by this expression and drawn here as L1. So there is an kind of S1, there is an S1 action here, so it's easy to see that somehow all the holomorphic curves in this symmetric complex structure that exist. Complex structure that exists actually lie in this plane. So, it's somehow I draw them here as a red line. So, there is this basic disk attaching there, but of course, there is all the multiple covers and whatnot, right? And so now we would like to understand if I perturb, what kind of element in the skein do I get? And the idea here is to look at infinity and see what curves are there at infinity. Curves are there at infinity. And at infinity, if we scale, we find that this is somehow just a clifford torus in CP2, and it's a classical object. We have complete control. And let me skip the details, but let me just say this thing, that at infinity, there is one rave chord, the one we drew in the previous picture, and there are three disks: one going around the meridian, one going along. Meridian, one going along around the longitude of the torus, and one is a little one kind of contractible arc. So, so basically, these three curves, meridian, longitude, and little naught, has to, in the scale, annihilate whatever comes out of this basic disk. So, we get if psi counts in the skein, all these curves in the basic disk coming from the basic disk, then this operator. Coming from basic this, then this operator unnaut minus meridian minus longitude has to annihilate it. And as it turns out, you know, you can write in the scale some eigenvectors of these operators and just solve the thing. And the solution is this. So somehow you get a bunch of curves, and it's how we'll see, we'll see the See, we'll see the more down-to-earth way of writing this in a second. But basically, what I'm saying is that we basically determine here elements in the scan corresponding to all the Homphyl polynomials, all the representations by this simple equation in the scale. So somehow, instead of finding all these things, you can find the three curves at infinity and the fact that they act, you know, and this is very powerful, so you can somehow determine. Very powerful, so you can somehow determine all the curves. So, here is another interpretation of this equation. In fact, you don't have to close them off. So, you can think of here sits this boundary of the basic disk, and there is a moving holomorphic curve here. It crosses through, and of course, there happens all these kinds of scanning, scanning, scanning. But this equation tells you that the only effect of this heavy red thing with all the multiple covers and everything is that if I come here. Everything is that if I come here and I go out here, I picked up one longitude, I picked up one thin line along the red guy. So that's the nature of this skein relation. So in some sense, we know how this basic disk deforms the skein theory for curves moving there. So, in order to come to this home flee homology, etc., I would Etc., I would like to simplify the counts a little bit. So I will count what I call generalized curves. So that's a specialization where we take the brain to have to do U1 scan theory. So A is equal to Q. Now this is the A of the remaining brain, not the A, which is the area of the thing in the conifold, but this is the A of the L K. And so that's just Q. And this C we replace by the And this C we replace by the Q minus Q inverse, and then we project this thing to homology, and it's easy to see that the U1 skein works well with that. So basically, it's homology plus linking. And then for such curves, the recursion relation for the scain is more kind of familiar to everybody. It's this one, one minus longitude minus meridian acting on this function counting all the curves. Counting all the curves is zero, and so we can compute the coefficient here, and it's indeed this Hookamer symbol. Okay, so these, since we now understand how these basic disks behave when we attach them to Lagrangian, it ties up, turns out, to ties up with some quiver story. So it was observed in what's called the Knott's quiver's correspondence. What's called the Notes-Quivers correspondence that the colored Homefley polynomial can be written as a kind of quiver partition function. So the quiver has some nodes, I'll draw pictures in a bit, and there's some arrows between them, and you can write a partition function. So this perspective that we have here gives a geometric view on these quivers, and the view is the following: that you start with your Lagrangian, it has a neighborhood which is T star L, and then you can. And then you can attach to it one of these basic disks, just like you're building basically this C3 situation by taking a S1 times R2 and attach a disk to it. And then you pretend that all the holomorphic curves live in a neighborhood of this attached disk and the cotangent bundle. And then you can show that the total count of all these disks in the U1 scale needs to keep track of the linking between them and the count. Between them and the count is the following according to this kind of quiver partition function. So this is the denominator we had before, and I'm sort of unfortunately switching Q to Q squared, but that's unavoidable. Anyway, so the thing that we need to keep track of are the mutual linking between the disks attached and the self-linking kind of framing of this disk, which goes into this formula. Okay. Okay, so the picture of these curves when you stretch the complex structure around the torus is that on the inside, you know, everybody here, we take disks that go once around the generator, just the simplest discs. So they would go into this basic cylinder ending on a ray board, a ray board, and on the outside sits somehow embedded. The outside sits somehow embedded sphere with puncture attached as this rayboard. And then the linking, so the quiver variables have the following interpretation that this Q charge here is the number of four chain intersection on the inside. And the A charge, somehow the A is the homology class of this curve. And all these CIJs, how they link, the curves link. And how they link the curves link or the link with themselves is some kind of framing data along this basic curve which comes from the sphere attached. So for the count, it's essential that if we don't really go all the way to the break-in, but we see this almost broken disk, then its neighborhood should look like the neighborhood of a standard disk on the toric brain. So somehow you can either say that it should be. You can either say that it should be like that, or that you track down its boundary condition as a minus pi rotation in each C, which if you trivialize this one. Okay, so now, for example, for the unknot, we can see this basically maybe the only knot where we can see all the disks, and we see them here. So, here's one disk, it's somehow the A2 disk, and here's a one disk. So, we're normalizing the So we're normalizing the homeflow a little bit differently. And one can hope that for other nodes, you also find these disks by basically taking the conormal very close to here and degenerating somehow. But let me not go there. And then somehow I should also say that the further we go down the torque, and say at this point, the more conjectural the torque becomes. So for this gain-valued counting, it's actually pretty rigorous. It's actually pretty rigorous. Now it's not. So some parts of it are, but it's a lot of guesswork here. So, and much of this guesswork, maybe from the holomorphic curve side is mine, but there was a lot of developments about this not squiver's correspondence that I'm just borrowing. Anyway, for the unknown, the quiver looks like this. So there is one disk, the small one, which has no self-linking. They don't link in between each other. And this one has self-linking. Each other, and this one has self-linking unit one for the trefoil. There is some kind of quiver with six nodes, and red arrows here are linking between the boundaries, and the orange things are self-linking. And here you see the sort of area and four-chain intersections of the disks. Okay, so I should first remark that somehow these quivers are not. These quivers are not unique. So, there are other quivers that give rise to the same partition function. So, there is a they could be canceling pairs. So, it's somehow the only difference is that you have a self-linking here and a four-chain intersection of opposite signs. So, you can imagine that they could cancel and then they cancel. You can also take two such curves and cross them and build two, you change the linking and you build a new guy. The linking, and you build a new guy which now goes twice around. If this one goes once around, once around, this one goes twice around. And those are somehow the only moves we found so far. But now to kind of relate to not homology, what I would like to say is that there is some way coming from this M-theory picture, and maybe Bukov Schwarzwaffer wrote. Book of Schwarzwaffe wrote the paper in that spirit where you can refine this quiver partition function. So basically, it's a very simple refinement in the sense that you're upgrading this self-linking to a new variable t. And when you do that, you get a new partition function. And say the first time, first term of this, the linear term in the x is the, in example, then the Poincaré polynomial of. Example then the Poincaré polynomial of Homefley homology. So, for example, for the unknown, you have this denominator which indicates there are two disks. One is just the disk, and the other one is the disk with area A squared and one unit of self-linking. So, in some sense, if you look at the quiver, you need to encode also the t variables here. And note that this second, this move does not change the first level. So, two guys. First level, so two guys can maybe collide, linking is changing between them, but self-linking is not, and so on. This is not so good for this, and indeed it's the refined partition function not well, not invariant under that change. Just a basic observation of how the refinement enters. Is a self-linking number? Presumably, that's an examples, or like which class of examples, or is it known in some generality? Or is it known in some generality? No, it's not. I mean, I don't know. I can relate it in this twisting T-plane, Q-plane, so picture. But in all the examples, when you have a quiver and you put these self-linking numbers, you do get the for the right quiver, you do get the refined hopefully. But very often, of course, it's guesswork. I mean, you know, this expression, and you say that you have this. And you say that you have these linkings, and then you check with maybe what effect it has for Homeflip homology and so on, Homeflip polynomial, and it works. So in some sense, at least it's consistent, but we have no way of finding this geometrically. So, okay, maybe I'll postpone answering that question a little bit. But in some sense, there are very few examples where we can actually find the disks and actually. Where we can actually find the disks and actually do the calculations, or backwards engineering. Okay, but let me press on for a little bit. So, for simple notes, you can actually compute a lot of this colored Homefley homology in this way. So, you take the partition function, you take the k-times around things, and the corresponding polynomial, if you take out this denominator, is the Homefley avoidant. Is the Homeflow void, and that means geometrically that we somehow decide to express things on level two, for example, as if everything came from double covers of level one guys. So that's what this denominator means. And so somehow not every object will have a geometric, direct geometric interpretation, but when you have two disks, they don't link, their product still has to be expressed in terms of these to get. Has to be expressed in terms of these to get the whole thing. Okay, I'm rushing a little bit because I want to come to the last examples, which are the main news in this talk. So for notes, so very simple notes, you cannot do this. So you have a level one quiver, all kind of quiver nodes, this going once around, you should think. And then you try to somehow generate, you take this refined partition function, you ask, do you get the super polynomial or the Poincaré polynomial? Or the Poincaré polynomial of Homphy homology. And for the first note, I think where this doesn't work is this 942, it's here. And there you find that if you take the first level, you find the quiver that matches the refined, homefly, and the refined homeflow is here. And then you take the second level of whatever it generates on level two. Then you see that it can absolutely not be the case. That it can absolutely not be the case that everything on level two comes from level one, because if you just look at the a powers, a powers would be, you know, minimum would be minus four, because you take two such guys and multiply. But these guys start at minus six. So this indicates that we need to have new generators. And here's a conjectural picture of those generators. So basically, to be a little bit quick here. To be a little bit quick here, what they look like is that on the inside, when we stretch, it's a default cover, default covered cylinder, but on the outside is somehow a sphere which still embedded but asymptotic to this default covered cylinder attached. So it's a little bit degenerate holomorphic object in this stretch picture. And when we count the contribution to Gromo-Witten theory or this partition function, it Or this partition function, it looks exactly like the old contribution. Just substitute q with q to the d and x with x to the d, or you know, d times around. And here's some kind of explanation of why the d goes in what you would expect. It's somehow breaking some symmetry. So it's okay. If you want to write the corresponding recursion relation, it looks just like the old one, but it's this operator to power d. Okay. So now here's somehow the even more conjectural. Somehow, the even more conjectural story. So, the conjectural story is that these things also generate homefully homology, but they generate in a new way. So, if maybe I'll do that twice around, so forget about the rest. So, for twice around, we have to correct the denominator. This one comes with one over one minus q fourth, like a double cover, which has no single cover before. And in refinement, there will be a factor of one plus t to the power one or. t to the power one or minus one times q squared over one minus q squared. So you see that classically or whatever unrefined t is minus one and then it's just this one over one minus q4. So somehow each such guy twice around gives rise to two generators in homphymology and the sign here is related to some trivialization. Okay you can write partition function. Let me go fast and come to the last story. The last story. So, what would this tell us? Well, it tells us that the super polynomial, the part of the super polynomial that does not come from level one guys, should actually be divisible by either this factor or either one of these two. So, here is, and this I should thank Marcos Storschis, who is somewhere here, who did this calculation of for 9.4. Calculation of for 942, the super polynomial in second symmetric representation. Here it is. Okay. And then you take this thing and you subtract off whatever comes from level one. You have this quiver on level one. You subtract it off and this is what remains. And you see that everywhere there is somehow that it's possible in all these terms to factor out this or that factor. Somehow, unfortunately, we are not at the stage where this factorization is unique. So you could look. This factorization is unique, so you could do something else, maybe some other way, but at least it exists in this example. And just to give the numerology, what happens here is that, you know, here are the number of generators that you need for the Homefly homology in level two. And these are the numbers that come from level one. So there are some kind of numbers coming from level one. And you see that quite a few of the new generators. So these are sort of easy to. Generators. So these are sort of easy to spot. They have to exist because they're extremal. There are six of those. But you see here inside at the other eight degrees, there are also quite a lot of these generators. And then somehow this next case is this 10,132. And there I think that this super polynomial is maybe a little bit more conjectural, but anyway, modulo that it still checks out. So you see. It still checks out. So you see, there are even more generators. And you can also check this partition function on more on unrefined levels. If you have this generator, you can see what it would do for the colored Homphyli, and indeed it checks out. So just to round off, I would like to say what is sort of the main goal and how to achieve it, I don't know, but one would guess that maybe there is somehow. But one would guess that maybe there is somehow for any not this finite collection of basic disks and not equally basic disks, some number around, so that this refined partition function you can write down actually explains this whole Homefly homology. And maybe last version is somehow I don't really know how to do the refined version of that, but in the unrefined versions, one should probably be able to also upgrade. So here we To also upgrade. So, here we used one brain on LK, but we can probably use more brain. And then these quiver-like things should be thought of as in the scale of LK. So, I will stop at this. I'm sorry I'm over time. Thank you so much for listening. Thank you, Tobias. Do we have a question? Yeah, I had a question. So, in the usual way of constructing ophthalmology, you need to restrict to braid presentations of your links. I was wondering if this sort of restriction plays a role in your story. I mean, so I should say this is not quite the definition. So, in that sense, it doesn't play a role. That sense it doesn't play a role. I mean, I should say that I don't know how to get the conormal in a nice enough position so that you actually express all these things through basic disks. So it's sort of not a definition, but it's some picture that at least gives you maybe some interpretation of this and how you have to put the co-normal and so on, you don't know. But the, I mean, the you know, you can imagine. Know you can imagine that if you have a braid and you degenerate these things onto the unknot, you could see that not so much worse holomorphic objects should appear than these disks. But this is also a very conjectural picture, so there is no definition really in there. Let's see, who's next? Sergei? Yeah, thank you for bringing. Yeah, thank you for a very nice talk. I wonder if this level structure that you described toward the end has connection to homological data of the non-homology, namely, for example, if you can comment on spectral sequences degenerating or non-degenerating being related to that. Yeah, I don't know. So somehow I think that one would maybe like to view these strange factors as some kind of different. Strange factors, some kind of differential or something like that, right? But it looks to me as if this is a, if there is some homological structure, it's some homology of a relative complex. So that you, in some sense, what this is about is you take the whole, everything that's on the second level, and you sort of subtract off that which comes from the first level. And on the thing that remains, there is some kind of difference. That remains, there is some kind of differential, right? So that's the kind of structure. And I don't know if there was something like that observed in the for the for the actual homology somehow. But that's the flavor, at least my understanding of it, something like that. So it's more like not on the whole complex, but on maybe a quotient, something like that. Yeah, so you gave quiver, you gave sort of unreduced quivers in your examples with size twice as big as the determinant of the knot. Is there also, I mean, can you see a reduced quiver in this formulation with size? Yeah, yeah. So what it looks like. What it looks like, what it looks like for the quivers, maybe I even have, let's see, I cheated a little bit. No, I didn't. Sorry. So what it looks like is that, you know, remember this kind of this move. So you have some kind of disk there and some other disk linking it, and you go through and you create three new disks. Three new disks in some sense. So it looks like going from redose to unredosed is that something like this: that you have a reduced version with pivot nodes. And for the unredosed, there is a little guy linking this reduced pivot person. It has like some kind of A squared charge. And when you do the unlinking, it comes like an unknown pair. So that looks like that. And somehow this SL1 differential also looks like. Differential also looks like that, but for another little disk. So it's as if this nice division by things actually has some life like that, that there is really like a reduced quiver, and you can get to the unredosed by adding some tiny little thing which homologically zero boundary, do the unlinking, you throw it away. So it looks like this kind of redosed unredosed comes from the closed sector in some sense. Sector in some sense. So, in some sense, these last formulas are about the reduced people. There would be twice as many terms, four times as many terms, if not. But it really works. They sit very tightly. And so, there's no way to compute these basic disks. Compute these basic disks, even for like the two-end torus knots or something like that? I know, I don't know. I mean, I'm actually thinking about it. I don't know yet, but you know, Trefoil is very tempting to say that there are three crossings, there are six basic disks, but somehow it's not, yeah, I don't know. I wish I had something better to say, but not really. And it could be that their life. And it could be that their life is somehow more about the exterior of this not complement in the resolved. I mean, it could be sitting pretty complicated. Although the negative end is simple, that the manifold is not. So I unfortunately don't have. I mean, I think maybe.