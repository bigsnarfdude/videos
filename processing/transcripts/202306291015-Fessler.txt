Okay. Thank you very much for the introduction. Thank you for the invitation from the organizers to participate in this really nice workshop. Yes, this is work that was inspired by a former PhD student of mine that actually turned out to be less trivial than I thought. And so my colleague Raj, who's a random matrix theory expert, helped me with some of the initial math. And then Rodrigo is a postdoc who helped dig up more math. And Javier's helped. More math, and Javier's helped with that as well, is probably all the results that I'm going to show you. And whereas many of the talks here might have been advertisement, well, describing some recent work, work that you can go read about, none of this has been submitted archive yet or whatever. So it's very much hot off the press. I spoke about it at the SIAM optimization conference a couple of weeks ago. And this is not advancing for some reason. Okay. And this, and some of the results came in a couple of days before. Came in a couple days before that conference. So that's how recent it is. Okay, so I'm going to talk a little bit about what dynamic imaging is, just to give a warm-up. And then I'm really interested in locally low-ranked models, but I'm going to start with the globally low-ranked case, which doesn't really need additional solutions, as you'll see, but just it's less summations, easier to describe the main ideas in that setting. But the locally low-ranked case is what I'm really after and similar problems. All right, so let's talk about dynamic imaging with some pictures first. So when you get out your Some pictures first. So, when you get out your cell phone and take a video, we're taking pictures as a function of space and time. And at any point in time, it's a reasonable model to say we capture all the spatial samples simultaneously. And then we have a sequence of those images as a function of time, and that makes a video. In magnetic resonance imaging, we don't sample in space, we sample in K-space, reciprocal space. And what we wish an MRI scanner would do is that some An MRI scanner would do is at some instant in time collect a whole bunch of points in k-space, and then at a later instant in time collect another whole bunch of points in k-space, and then we would make we do inverse Fourier transforms more or less, and then we'd have a video from MRI. But that is not how MRI actually works. That's just a fantasy of how it works, a fantasy that is presented in many, many publications. This is the reality of how it works. Every point that you collect in case space takes time in MRI. And so as you're collecting data, time is collected. And so, as you're collecting data, time is marching on. And so, really, what you have is, we call this KT sampling. So, K-space on one axis, time on the other. And we would really like this to be a full grid, right? We'd like to have fine temporal resolution and lots of K-space samples so we can get good spatial resolution. But we can never get that in dynamic or MRI because of the fact that time is marching on as we collect data. So, you could think of this if we had a single coil MRI. Think of this if we had a single coil MRI scanner as a matrix completion problem where we're missing a lot of data in a very structured way that doesn't satisfy any of the standard properties from compressed sensing for matrix completion. And this is one of the reasons dynamic MRI is slow, or MRI is slow as well, because it takes time to collect these data points. And so you end up with, if you kind of collect all points in K-space corresponding to a given image resolution, you end up with kind of slow, you know. You know, poor temporal resolution. So, one way to try to improve temporal resolution is to collect fewer points per time interval. The points here are still spaced in time the same amount. You can't make the MRI scanner go any faster in terms of the A to D converter that's collecting these points. But we can collect fewer of them. And then instead of grouping in this example, you could, you could, what, okay, let me just tell you what happens clinically in MRI most of the time right now is you take these, in this case, eight samples. You take these, in this case, eight samples, and you pretend they all came from the same point in time. You group them together, you do an inverse fft. And so you get an image that, of course, has some blur in it, temporal blur, right? Because you're taking different points in time and pretending they didn't come from different points in time. So we can make that pretending a little more reasonable by taking fewer points in time and grouping them together. So here I'm taking six points in time and grouping them together and make a single frame. And make a single frame. So now I have better tempo resolution, right? Because the elapsed time to collect six points is less than the elapsed time to collect eight. But now, so I have better tempo resolution, but I have understandable case space, right? Because each of these blocks only has six points in it, and my image has eight pixels in this tiny example here. This is the picture here illustrates how we typically do this, which is we preferentially sample the center of case space because that's where Sample the center of case space because that's where most of the signal-to-noise ratio is. And so you'll notice every time frame I'm collecting, in this case, the four points near the center, and then randomly collecting points near the edges of case space each time. It's still an undersampled problem, right? Still a matrix completion problem, if you want to think about that, with another form of structured sampling that won't satisfy any of those nice conditions from compressed sensing theory. All right, so that's it in pictures. Now let me describe it in mathematical models. So for each of those, describe it in mathematical models. So for each of those points that we choose, groups of points that we choose to group together, which could be as few as one point, but in practice, it's many more than one, that will be a vector y sub t. And we'll have from t equals one to t such vectors. And for each one of those time points, groups of time points, we'll have a latent image x. It's a 2D or 3D array that I vect into a latent image here, x. And then there is a forward model, A sub t that maps from the latent image into the data. From the latent image into the data, and we know that what that matrix is from the physics MRI scanner, we don't actually store as a matrix, it's an operator that we write as a subroutine with its adjoint and so on, but on paper it's a matrix. And if I take all that data and stack it together, accounting for the noise and so on, then we finally get a model of the form y equals ax plus noise. But the x here I want to point out to you is a matrix here, because I'm going to take the latent image at each point in time and arrange. Time and arrange those in a matrix that has number of spatial positions by number of dynamic frames, number of time points, because this is a dynamic reconstruction problem. So, I really don't want to vect the whole thing. I want to keep time separate from space. So, the goal in this problem will be to reconstruct that latent space-time matrix X from the case-space data. And as the pictures I showed you earlier, this is always an underdetermined problem. So, some form of regularization, some sort of model assumptions is necessary. Necessary. All right, so I'm going to start by talking about global low-rank methods to introduce the key ideas, but I'm really interested in locally low-rank methods. All right, so one reasonable model is to assume that the matrix that we're trying to estimate is globally low-rank. So why would that be a reasonable model? So let's say we inject a contrast agent into a patient. Then that conjure agent is going to wash into the kidneys and wash out. Maybe it's going to wash into the heart and wash out and pick. Wash out. And pixels that are near each other in the heart are going to have similar time curves, similar for the kidney. We're made up of, you know, fat, muscle, and different ingredients. And so it's reasonable to assume that that matrix, space-time matrix, is low-ranked because a lot of pixels have similar time properties. All right, so if you buy that as a model, then it's reasonably set up this inverse problem with a constraint on the rank of that matrix, or if you're not sure what the actual rank is, which in practice you probably know. Actual rank is, which in practice you're probably not. You could set it up as a regularizer instead. And if the operator A here was the identity or a unitary operator, then by Eckert Young-Mirsky, there's a simple, even though it's a non-convex problem, there is a simple closed-form solution involving the SVD of the data. But we don't have those properties in dynamic MRI. And so what we instead would have with either of these is a challenging non-convex optimization problem. Now, this is a Now, this is a conference on data-driven, so I just have to say something here about data-driven. If we knew the temporal basis in advance, we could write this matrix X as a product of an unknown spatial image times an outer product, unknown spatial image, and then whatever the temporal bases we needed were. And then it would be a simple least squares problem, but that wouldn't be data-driven, right? So here we're learning the temporal basis as we're performing the inverse problem. So that's the sense in which it's data-driven, even though there's The sense in which it's data-driven, even though there's no training data. So, I guess in the machine learning language, this would be zero-shot or self-supervised or something like that. All right, so what's commonly done since rank is a non-convex function is to replace that with a nuclear norm and then solve an optimization problem like this that has a data misfit term and a nuclear norm that encourages the solution to be low rank. Or that might be too strong assumption, especially. might be too strong assumption, especially the low, the low rank assumption might be too strong, especially in the presence of motion. So there's also models that assume that the image is sum of a low rank part, L, plus a temporally sparse part. So now your data fit term involves the sum of those two components, and then a nuclear norm on the regular, on the low rank part, and a some sort of one norm, if you want to be convex, on the temporally sparse part. So you have some apply some Apply some temporally sparsifying transform t and then apply a one norm to that. Now these are both convex optimization problems that are easily solved by something called the proximal optimized gradient method, which I don't think is well known as FISTA. So I want to spend a minute on that. It's been around for six years now, but anytime in an audience that does mathematical, maybe some people do optimization, I want to promote this method from Adrian Taylor et al. We did a small variation of it, including We did a small variation of it, including something called adaptive restart that helps it converge faster in practice. But the original contribution really comes from Adrian Taylor. We've applied it to MRI before, and I'm going to show you some results. So I'm going to talk about this in general and for composite cost functions, where here we have a smooth data misfit term and then a prox-friendly nuclear norm non-smooth term. And in this case, we know the Lipschitz constant of the smooth term. And so you could apply proximal gradient methods. So you could apply proximal gradient method to this, also known as iterative self-thresholding algorithm, that takes a step in the direction of the gradient of the smooth term and then applies the proximal mapping of the non-smooth term. And for the nuclear norm, the proximal mapping, which I didn't give the definition here, I just gave the result, turns out just to be take the S V D of your image, whatever your argument of the proximal mapping is here, X, and then take all the singular values and subtract. Take all the singular values and subtract a constant from them. And if any of those go negative, set them to zero. So you get a low-rank sort of behavior because you're setting some singular values to zero and shrinking other singular values. So that's the basic idea of proximal gradient method. So FISTA, also known as the fast proximal gradient method or accelerated proximal gradient method, has a faster convergence rate than that. And it has the optimal convergence rate from a big PRIGO point of view, but does not have the optimal constants. So the proximal optimized gradient method, POGM. Optimized gradient method, POGM, reduces the constant to the optimal constant. And these constants that I'm talking about and these optimal things are all worst case analysis. But despite being worst case analysis, I consistently find in practical medical imaging applications that you get the benefits predicted by the worst case analysis. So here's, by the way, a screenshot from Adrian Taylor's paper of the proximal optimized gradient method. If you're using FIST, I encourage you to throw it away and look at this paper. I encourage you to throw it away and look at this paper instead because it's almost, it's like one-line modification of your code. So here's the gradient step. Here's the momentum term that you have already in your FIST implementation that you get from Nestor Off-like Momentum. And then this additional term comes from the optimized gradient method, which a former student of mine, Dong Wong Kim, developed. And then the proximal optimized gradient method has an additional component to the momentum term, as well as, of course, the proximal mapping sum. Of course, the proximal mapping somewhere in it. For those of you who have implemented anything with Nestoroff, these magical square root of four, whatever, will look familiar to you and remain mysterious to this day. Okay, so let me, so that's the, and this paper has a numeric computer-assisted proof that you get this factor of two improvement in the constant that is we now know is the is the optimal constant. And here it is. Constant. And here it is in practice on some actual perfusion MRI data. This is the reconstruction from the fully sampled data here. We've retrospectively undersampled this by 10-fold under sampling, and that's the image obtained by running a low-rank plus sparse reconstruction. Of course, you can see it looks a little bit noisier because it has 10 times less data than the fully sampled data. And then we've compared a whole bunch of different algorithms. The green and the pink or the magenta here are two. Pink and magenta here are two splitting-based methods, augmented Lagrangian kind of methods. And then the blue curve here is the first order, the ISTA algorithm. Well, they're all first order. And then this is FISTA. So you can see it's converging much faster. This is time on this axis and then convergence of the cost function on the vertical axis. And then this, the one going down the fastest is the proximal optimized gradient method. And I've consistently found that kind of improvement. Consistently found that kind of improvements from using POGM. This is just looking at it. That's from the, that was low rank and sparse. Here it is applied to just a low rank cost function. And I'm comparing up here sub-gradient descent. So that's even slower. And then, okay, proximal gradient descent, accelerated, proximated descent, and POGM. Both plot. Both plotting it in terms of the cost function versus iteration and plotting in terms of normalized root mean squared error compared to the fully sampled image. Both plotting it versus iterations here and versus time. And every way you look at it, POGM is consistently converging faster than all these other first order methods. Okay, that's my promotion for POGM. And so I'd say if that's what you're interested in, is globally low rank or globally low rank. You're interested in is globally low rank or globally low rank disparse, use POGM, end of story. But I'm working my way towards locally low rank, and that's a harder optimization problem, as I'll describe later. So when we get there, as a motivation for getting me there, let me remind you why we're using these first order methods here. It's because the nuclear norm is a non-smooth function. It is just the sum of the singular values, which looks innocuous enough. But in case you're not familiar, if you think about what's the singular value of a one-by-one matrix, it's the absolute value of the element of that matrix. And that's Of the element of that matrix, and that's a non-smooth function. So there's a proof that it's a non-smooth function. And that's why it requires these more complicated algorithms like proximal gradient methods or ADMM, which others in this room, as well as my group, we've had lots of fun writing down and playing with these complicated algorithms. But let's not forget that the nuclear norm itself is not a holy entity. It's something that's a relaxation of rank. So why not relax further and consider a smooth function and maybe make our A smooth function and maybe make our life easier. All right, so I'm going to be spending the rest of this talk talking about smooth regularizers, where instead of just adding up the singular values, I'm going to be adding up some function of the singular values. And I'm specifically going to focus on functions that satisfies Huber's conditions from his book on robust estimation, robust statistics. They're symmetric, differentiable. And this weighting function that is the derivative of the potential function divided by its argument is. Divided by its argument is bounded, which is a sufficient condition to show that the derivative is Lipschitz. And the canonical example is a hyperbola that's often used in sort of corner rounding approximations to total variation, but here we're dealing with singular values, not with pixel values. And once we've done this, now we can apply gradient-based methods, like quasi-Newton methods, that potentially could give us a faster rate of convergence. These first-order methods have convergence. These first-order methods have convergence rates of like order one over k squared or whatever, whereas quasi-Newton methods can have linear convergence rates, right? So there's the potential for faster convergence, but that's not my only motivation, as you'll see when we get to the locally low-rank case. Also, in the long run, I won't have results in this talk. I'm interested in approaching non-convexity in a graduated non-convexity way, but maybe still doing it with smooth functions so that I can apply gradient-based methods. So I know I'm going. Gradient-based method. So I know I'm going backwards in terms of sort of optimization sophistication here, but I'm a practical engineer and I want to get results faster. Okay, so let me just say this is a math conference, right? Let me say a little bit about the math. So we've defined a function here that is the some function, sum of some functions of the singular values. And there's known results in the literature already that say if that function is convex, then this particular object here is a convex function of the elements of the matrix argument x. The matrix argument x. That's from the literature. And also, it's differentiable as well. If this function here is differentiable, whereas the singular values themselves are not differentiable functions of the matrix element, if you put a differentiable function as the argument here, like we have, then this becomes a differentiable function of the matrix elements. And specifically, the gradient of it is in terms of the S V D of the argument. So if X Of the argument. So if x has got this singular value decomposition, then the gradient of the regularizer evaluate that matrix has this form here. It depends on the same right and left singular vectors, and it depends on the derivatives of the potential function evaluate the singular values. And let me point out there's two dots here. So the dot upstairs, that's the derivative. The dot downstairs, that's my use of Julia notation. Julia, if you put a dot after a function, it means apply the function element-wise to the argument. To the argument. And I think this is something that math should inherit from Julia. Julia's got a lot of stuff that comes from math, but this is a really convenient notation, I think, to say I've got a function, scalar-valued function, and I'm applying element-wise to a vector. Anyway, that's what the downstairs dot means there. Okay, so that's known results from the literature about convexity and ingredients. You can actually work out, I don't have the proof here, but you can work out what the Lipschitz constant. So this is differentiable and smooth. Differentiable and smooth, you can work out the Lipschitz constant of the gradient of this regularizer that I'm advocating here. And the regularizer turns out to be that Huber weighting function evaluated at zero, which is the second derivative of the potential function at zero under the conditions I've given you here. All right, so that's extremely easy. Lipschitz constant to compute. It's typically one, the way I normalize my potential functions. Okay, so now I can apply gradient. Okay, so now I can apply gradient methods to this globally low-ranked kind of cost function where I have a data mismatch term and this regularizer involving this smooth, the sum of smooth functions, the singular values. Here's the gradient for the whole thing. And in the process applying gradient methods, it's likely I'm going to need to compute a line search at some point. And so I'll have this one-dimensional line search function, which you can write down what its derivative is, depends on Frobenius norm, for Frobenius inner product between some things that we know how to compute. That we know how to compute. And that derivative itself is a smooth function. I mean, the function is smooth, and its derivative has a Lipschitz constant that depends on the system operator part plus this Lipschitz constant we got from the regularizer. So that can be helpful, I think. We haven't actually used this. We've derived the theory of it, which I don't think I, yeah, I skipped the derivation of that, but that could be helpful. But that could be helpful because when you do say a backtracking line search, what do you do? You start with a value one and backtrack. This gives you a value that you know you can use as a step size that will get you in the right direction with the right units and so on. Okay, so now I've got this smooth approximation to the nuclear norm. I can apply a quasi-Newton method to it, and we can compare that to POGM for the globally low-ranked model that we didn't really need a new solution for, but let's just see how the smooth But let's just see how the smooth one works. So, what I'm actually plotting here is the non-smooth cost function. I'm imagining that's still the one we care about. And I'm running the optimized gradient method. And the proxy, so ignore the green one, it's not important. The proximal, just compare the approximal optimized gradient method to this actual quasi-Newton method, limited memory quasi-Newton method. And you can see whether I plot, let's see here. I've got, let me see. Let me see here. What are the difference? I don't remember what the difference between these two plots are at the moment. They look identical. So I'll just focus on this. Oh, no. Oh, I've plotted both cost functions. I plotted both the, my student plotted both the non-smooth and the smooth cost functions. I've done such a small amount of, even with a delta of one, the corner rounding is such a small effect. You can see the cost functions are virtually identical. And POGM and the quasi-Newton method are converging basically at the same rate. And you can plot that. The same rate, and you can plot that in terms of root mean squared error as well. And then you can look at the singular values. This is the singular values of the original fully sampled data, which means it's not all that low rank. It's actually pretty noisy data. And so this is on a log scale, but you can still see that the singular values aren't maybe going to zero as much as I would like. I think it's because all the noise in that data, or because there is some motion, it's not really that low rank. But both POGM and the quasi-Newton methods, depending on how you choose to round. Depending on how you choose to round the corner of the cost function, have the effect of shrinking the smaller singular values, which is what you want in a method that promotes low rankness. And there's images, the root mean squared errors, I would ignore anything after the decimal place, right? So they're basically the same, the original POGM and the quasi-Newton method. As you'd expect, we're making a small approximation to the regularizer here. All right, let's move on to the locally low rank. Let's move on to the locally low rank, which is really the motivation for this work. That was just to get us warmed up. So, when I described the motivation for globally low rank, I said, well, the kidney might have this behavior and the heart might have this behavior. So if you throw all that in a big matrix, if the kidney and heart have different behaviors, you're going to need a higher rank than if you just look at patches in the kidney or patches in the heart, right? Those different regions should have a lower rank because those pixels presumably have similar time behaviors. Similar time behaviors. And so I'm not the first to invent this. Lots of people have thought of this idea. And so they said, let's extract patches from our image and then apply a nuclear norm to the patch. So these are space-time patches. I've tried to draw in here. And I think this is probably a more reasonable model in the presence of motion or even in the absence of motion. Just a little additional notation, right? Because now we're summing over patches. And I cited a dozen applications here in MRI, and there's many beyond MRI as well, where people have used this. MRI as well, where people have used this sort of local low-rank assumption. All right, so if you do this with non-overlapping patches, as I've kind of shown in this diagram here, this, yeah, sure, please. Yeah, no, please do. I was going to say, I don't mind being interrupted. I'm just yeah, but this matrix X, I arrange space. Matrix X, I arrange space on the column along and then time along the row. So I'm taking, so a patch here really means a group of rows of that matrix. Right. That's the way I'm going to do it in all the experiments I'm going to show you here. In the presence of motion, you might actually want to take sort of rectangles out of that space-time matrix because there might be kind of big changes in time. But the perfusion data set I'm showing you has doesn't have too much motion in it. And so Too much motion in it. And so I'm choosing, but the math is general enough. The piece and piece can be whatever you want. But I'm thinking about it, talking about it, and showing results only where I've partitioned in space. Oh, yeah. So when I said space-time, I mean there are patches that have a spatial component and a time component, but I haven't chopped it up in time for anything I'm showing you. So if the path in this picture, I've got red, green, yellow, and blue or whatever patches, and they're disjoint. And so that turns out to be. And so that turns out to be, even though it's a more complicated-looking regularizer, that is still proximal-friendly. Basically, you, when you want to apply the proximal operator for that sum, you just work on each patch independently and apply the singular value soft thresholding algorithm to it. And so then you can still apply proximal optimized gradient method or your favorite if you have a different favorite proximal method for that. Unfortunately, when you do that, though, you're going to end up with blocking artifacts. Though you're going to end up with blocking artifacts at the boundaries between patches, and so you'd really prefer, I think, to use overlapping patches, all right? Patches that have a stride smaller than the patch size. In fact, I'd really like a stride of one pixel, because then I have shift invariance to my regularizer. But unfortunately, in that case, there is no known proximal operator, and I don't think one exists. All right, so now what do you do? All right, so now what do you do? You have to make some choices here. You could apply sub-gradient descent. It's still sub-differentiable, convex sub-differentiable, but boy, will that be slow. So I don't think anybody does that. So the most common thing I think people do are something called cycle spinning, where each iteration, you just take one random shift of your image, which is like taking one term out of this sum over all the possible shifts of your image, and making an update based on that. Update based on that, which you could think of as kind of a stochastic version of proximal gradient. Or you do what's called proximal averaging, where you say, well, I have a sum of a bunch of terms, each of which is prox-friendly. So I'm going to pretend that the prox of the sum is the sum of the proxes, which is not, but you can pretend that, and implement your algorithm that way. Or you could apply ADMM, but you would need a lot of auxiliary variables here because let's say IIx eight patches and you Let's say I have eight by eight patches, and you want to do a stride of one. I would need 64 eight squared auxiliary variables, at least as I know how to implement that. And in a 3D plus time dynamic MRI, that's enormously expensive. And so I don't think I've seen anybody do that. The most common is to do this cycle spending, which I'm spoiler alert seems to work remarkably well. So here's an example of applying POGM to the case of non-GM. To the case of non-overlapping patches. So that's the easy case. All right. And so the cost function goes down as it should. And I've, let me stinky. Oh, this is for two different regularization parameters. And if you, especially for the larger regularization parameter, I hope even in the lighting in this room, you can see the blocky artifacts there that you get when you use non-overlapping patches. So I'm going to talk about overlapping patches for the rest of the talk. Going to talk about overlapping patches the rest of the talk because nobody wants that kind of blocking artifacts. So now I'm talking about POGM up with some of these ad hoc modifications. So the cycle spinning or the proximal average. So interestingly, I've already alluded to the cost function goes downhill. Now, we don't know what the minimizer of this cost function is. We only know what the lowest value of the cost function is, but it's descending. Now, if you zoom in here, zoom in on this axis, you can see that the cycle spinning method, the cost function. Cycle spinning method, the cost function is warbling, right? Because you're choosing a random sub random shift of your image every time instead of considering all the shifts. The proximal averaging considers all the shifts, but it's just making this approximation. So we don't know anything about the convergence theory. In fact, I predicted this would work much worse than it actually is because POGM, you saw it had those three momentum terms. So it's kind of aggressive from a momentum point of view. That's what makes it fast. And so if you put all this momentum in there, And so if you put all this momentum in there that's designed for convex cost function, and now you're like changing the rules of the game by taking the proximal average, I just kind of expected it might diverge. But remarkably, it's converging to something, right? I don't know what it is converging to. So there's for some mathematician, that might be an interesting thing to understand what's actually happening. Why is it working as well as it does? And you get better looking images. All right, so the root mean squared error. Lower the root mean squared error with POGM with this proximal averaging. The images look pretty good, and the root mean squared error is lower than what you saw in the globally low-rank case. But convergence theory, we don't know anything about it, right? It's just a recipe now, right? We're taking this one algorithm and modifying a step, replacing the proximal operator with the proximal average. Who knows what it's doing? So from a principle point of view, I would rather write down a cost function and have an algorithm that I know actually minimizes that cost function. That I know actually minimizes that cost function. So, this is really the motivation. This is the point at which I'm going to put in my smooth approximation of the nuclear norm. All right, so instead of the nuclear norm, for each patch, I'm going to have the sum of some functions of the singular values from these patches extracted from my image. And now, I don't mind if they're overlapping patches because that's just a bigger sum, and I can still apply gradient-based methods to this. You can write down what the gradient is, it's going to involve. What is the gradient? It's going to involve lots and lots of singular value decompositions of patches and the same kind of derivatives that I showed you earlier in the globally low-rank case. And I know what the Lipschitz constant is for this cost function as well. Now, we are doing some corner rounding here, so we have to make a choice about how much to round the corner. So, my student experimented that a little bit by trying different values of the. Of the approximation parameter there. And of course, if you make the parameter way too very small, then it converges very slowly because the curvature is higher. And if you make it too big, then you're not getting as much of the shrinkage effect that you would like. And the normalized root mean squared error doesn't go down as low as you like. But if you make it a reasonable value, then you can get reasonably fast convergence to a low root mean squared error value. Low root mean square error value. Not surprisingly. Okay, so now I can apply the quasi-Newton method to the smooth cost function, but I'll actually plot the original non-smooth cost function anyway. So we're applying POGM with proximal average here and quasi-Newton to the smooth cost function. But I'm plotting the non-smooth cost function just because that was the original problem, if you will. And they're behaving remarkably. They're behaving remarkably similarly. So that's interesting that proximal averaging is working that well. Don't know what it's converging to, but it is. I mean, I can't, it appears to be converging. I can't say anything theoretically. I'm doing out of time here. Probably going to be early. All right. And when you run both of these algorithms, I don't think I talked earlier. This is the fully sampled reference. This is if you just take the collected data. This is if you just take the collected data, the eight or tenfold undersampled data, and just do an inverse Fourier transform of it, you get this terribly blurry image. And you can see that you know to the first couple decimal places again. First of all, the digits before the decimal place, the proximal optimized gradient method with proximal averaging and the quasi-Newton method are producing essentially the same image. All right, it's much faster than I expected. So, in summary, Than I expected. So, in summary, what I focused on today is a smooth approximation of the nuclear norm that leads to similar image reconstruction results to using the non-smooth one, but enables us to do gradient-based optimization methods where we know what it's converging to. Now, as I've already said, POGM with either cycle spinning or proximal averaging works better than I thought it was going to. So, if anybody has an explanation for that, theoretically or intuitively, I'd be interested in your thoughts about it. And so, there's a lot of And so there's a lot of things I want to do with this in the future. As I already alluded to, I would like to look at non-convex potential functions because I really think we would like probably to get closer to the original rank function. We probably don't really know what the rank is, but we probably have a guess. If I take my patches small enough, probably most patches have a background in them, and then maybe one temporally varied component, the part of the heart or the kidney or whatever organ you're in. So my guess would. Whatever organ you're in. So, my guess would be most patches have a rank of like two or so. So, why not penalize just the singular values that are passed to, penalize singular values three and beyond? That's non-convex. It's a different form of non-convexity. Even if I put a square or whatever for the potential function here, the fact that you're penalizing the tail of the singular values turns out to be a non-convex function. But it's a logical one to use. And I can still, if I put a smooth function here, I can. Put a smooth function here. I can smoothly penalize the tail of the singular values, avoid shrinking at all the first couple components that I'm pretty sure probably have real signal in them. So that's something we plan to investigate. I would really like to have a quadratic majorizer. If the singular values were a linear function of the matrix, I would know how to get a quadratic majorizer for this, which would let me do the line search more efficiently. And this is important because I'm doing. And this is important because I'm doing lots of little singular value decompositions for every time I take a line search step. So, if I had anything that would let me do that line search more efficiently, that will reduce the numbers of SVDs that have to be done. The code, I didn't show you plots versus time because this is a very crude initial implementation. There's a lot of opportunity for parallelism, right? You're doing all of these patch SVDs in parallel, and we haven't exploited any of that in our code so far. I've seen recent patches. Far. I've seen recent paper that sort of somehow intertwined Newton-based methods and proximal methods. I need to take a closer look at that. Some kind of graduated non-convexity things where we adjust regularization parameters as a function of iterations probably needed. And then just at the SIAM optimization conference, I learned about an alternative to POGM called Opt-ISTA, Optimize ISTA. Whereas I mentioned that POGM has a numerically assisted proof. Numerically assisted proof of, or really a numerical proof that it has the optimal constant. This new algorithm, Optista, that comes from Ernest Rue at in Korea, forget which university, he has now an analytical proof. The algorithm is slightly different, but it's again got that same optimal constant, which is two times better than ISTA. So, and I'd like to do, you know, so that they both have the same theoretical worst case bound, even to the constant, but who knows practically how it'll perform. But who knows practically how it'll perform and my real-world application. So I plan to do that comparison. And with that, I'll say thank you for your attention. Thanks, Jeff, for your talk. I would have a question. So, when you compared in the first part of your talk the POGM with LBFG, LBFGS, you know, you could also apply LBFJS to the original formulation. Oh, really? Even though it's not differentiable? What you do, it works if you have quadratic plus non-smooth. Yeah. What you do is you add a quadratic Moreau envelope term in the right metric that cancels the linear operator. And then basically you get a gradient of the Moreau envelope in a metric, in a different, then this you can just pass plug and play to LPFJS. Okay. LPFJS. Okay, I'm not familiar with that. I'd like to get a reference. Yeah, I'd love to do that comparison. So, when you say more envelope, is that what I would think of as a quadratic majorizer basically? No, no, it's a minorizer. Oh, okay. But that shares the same optimum. Okay. It's a more envelope. So it's an infimural convolution. So you convert with a quadratic function with the infimal convolution. You get a lower envelope with the same minimum, but which is continuous. But which is continuously differentiable and you know the Lipschitz constant and you can just put this to LBFG as the gradient. So is there a parameter you need to pick there, like what the smoothing parameter or no? No, it's fixed because it's related to the Lipschitz constant of your quadratic term, of the gradient of your quadratic term. Okay, so now would that also apply to the locally low-ranked case with overlapping patches? If you know how to compute the prox map. Oh, no, I don't. That's the whole point. That's the point, yeah. Yeah, so okay. So So, okay, so what you're saying would, and the first problem was just a warm-up to just kind of introduce the idea. So, I'd like to do it just for the fun of it, but that won't, if it won't solve the second problem, then I'm maybe you can have an iterative algorithm to compute a prox map. Okay, that sounds more complicated than just taking a derivative of something that I know how to take a derivative of, but uh, an iterative algorithm. Oh, oh, which is fast, usually. Let's see here. I wouldn't know how to do that. See here, I wouldn't know how to do that. Well, like ADMM, I would know, but that would be a huge number splitting variables. So, what iterative algorithm would you use to compute this proxy map? I would love to know. I would love to know. Yeah, it's something that, you know, you have a quadratic term plus this term. It's strongly convex, so it has linear convergence at least. So it should be very fast. You can do warm starting. So I don't think it's too demanding. But what algorithm? I don't still don't know what iterative. Suppose A was identity. So this is basically. Yeah, when A is the identity, this basically is the. Yeah, when A is the identity, this basically is the proximal map, right? So, again, I'd love to know what you would use to compute that, because I don't know how to do it. Where there's this house at court of Gabriel Peret did this with a sum of non-smooth terms where it cycling through the prox. Oh, okay. Rand prox? Maybe it's related to what you have been using here, I think. Yeah, you mean the prox. You mean the proximal averaging or something? Yeah, yeah, yeah, yeah, exactly. It might be. Or you use the Dijkstra algorithm, not that for shortest path, but that one that computes the intersection of projection onto convex sets, which works for prox maps. It's a dual algorithm. Oh, is that? Okay. I'd like to do that comparison. I don't know that algorithm, so I'll love to get the reference from you and do that comparison. Okay. Dual algorithm for this, even with overlapping paths. For this, even with overlapping patches, yeah, I suppose, yeah. Then in the tool, they separate, yeah, okay, okay, that would, yeah, and then and then it'll probably come down to compute time issues, right? So, as right, and so yeah, no freelance. Okay, I'm an engineer, I'm happy to compare compute times. Thanks for the comments. Thanks for a very nice talk. So, I just curiosity, could you use your method to like separate the movement and like correct movements? Like correct movements, and I don't know. Correcting movement would involve more terms. And I was talking to somebody over dinner at some point. So let's see, where's the right place to, I don't think it's really so easy to show in any of these equations. But even if I go, well, I'm going to go back to the globally low rank case. You know, in the presence of motion, this matrix. Presence of motion, this matrix is not going to be as low rank. So, yeah, it's not so easy to write this way. But I have a bunch of columns. And if I could somehow estimate the motion, I would apply some, well, some warping operator like we just heard about in Andreas's talk to the columns to try to get them to line up and then apply the nuclear norm or something after that. Yep, see, Tom, thanks for coming. Have a good flight. And so there definitely is work out there where you're. So, there definitely is work out there where you're jointly reconstructing the image and estimating these warpings that you need. Interesting. I don't know if I've seen people put that inside of a nuclear norm. In the papers that I'm thinking about done that, they tend to use more like finite differences across time. Maybe it's just a lot to have both those nonlinear warps and the SVDs needed in a nuclear norm regularizer. But what I've described here, I would not say it's going to do anything special about correcting for motion. I think you would need a Correcting promotion. I think you would need additional terms in your cost function to deal with that. Okay. Thanks. Thank you for a very interesting talk as well. And I have two questions that go more into the start of the talk. So, first is, do you know of any unrolled version of the POGM already? That's funny. That's funny. So, I had a PhD student who was working on that, and then he decided to go get a job in industry and make a lot of money. So, that didn't get, so I know a little bit, but it hasn't been published or completed yet. So, let me tell you what the catch is. Oh, so the algorithm as given here is unrollable, you know, and suitable for differential auto-differentiation and so on. The version that with adaptive restart. So, let me tell you what adaptive restart is if you don't know. Me tell you what adaptive restart is if you don't know. So, all of these momentum methods, right? You have your gradient, and then you're adding to that some momentum. So, something about previous directions. And if the current gradient and the momentum from previous directions starts to point more than nine degrees apart, that's probably a bad thing. And so, and empirically, we find that any that it's better. And some Udanahu and Candice found this for FISTA, and we extended it to POGM. So we have in this in the code a condition that if those In the code, a condition that if those vectors are more than 90 degrees apart, we restart, go back to the first iteration, is basically like gradient descent. Now, that step is not differentiable. So, my student was working on replacing that sort of binary, like, oh, if it's bigger than 90 degrees, make a switch to something that has a smooth thing. And then he left. And so, that version would be unrollable. Okay, you need some some you need to replace that step function with some smooth function, and it can be done. Um, it's funny that you asked. It's funny that you asked because virtually every iterative algorithm out there has been unrolled. To my knowledge, POGM has not yet, but it's waiting for you to do it, Max. Go for it. Happy to work with you on it if you'd like. And the second thing is a more practical question. If you go to your motivation of like how you pick these six points then in the MRI: six points, six points. Where you take in time, like it's basically the fourth slide or something. Basically, the fourth slide, or something like that. I was wondering whether it would not be easier to get a negative time evolution of the case-based data in the different and then basically align them in time. I mean, we can collect these points in any order, but and by the way, for those of you who know MRI, this is in the phase and code direction. This is in the phase encode direction. The readout is coming out of the plane, right? So, this is Cartesian sampling. So, there's also another direction coming out of the plane. So, ask your question again now that I've not in MRI at all, but I was wondering whether if you take these case-based data points in a time, like in a diagonal, in a time-evolved manner, if not, it would be easier to take later points and try what would have looked and try like what would have looked what would this measurement have looked like if we evolve it back in time and then after doing this pre-processing uh doing the uh assumption of like well they've been all taken at the same time point um uh so perhaps you're saying like take these four points here and try to predict from that what this would have been at that point in time so actually that's funny they're in in functional mri where you collect one slice of MRI where you collect one slice at a time. There is something called time alignment where they do exactly that, but they do it in the space domain, not in K-space domain. I mean, whatever model you use to make this prediction, I would rather build that model into my cost function. So if you don't like the nuclear norm, if you have some other idea about how things are related in time, I would rather describe that in terms of my latent object rather than doing some, because the reason for that. Because the reason for that is that this two-norm is because in MRI, the data really is additive Gaussian noise. So it's statistically justified. As soon as we start fiddling with the data, pre-processing in some ways that destroys that, we can still put a two-norm here, but it doesn't have the same statistical justification. So my personal preference, and I think where the field largely is, is to try to capture those either here or in a neural network and learn it, right? You can replace this math with something totally data-driven with a neural network, but historically, But historically in the field, there is something that's called keyhole imaging or whatever, they're data sharing where they do exactly that. So, I guess it's probably better illustrated on the next slide where you say, well, I don't have this point here, so I'll just take the nearest one and I'll put it here. And I guess here, I'll put this here, and I'll group those together and do an inverse FFT. The simplest version, the zeroth order version, what you described, is already being, is already out there for decades, actually. But we're trying to do something better than that. We're trying to do something better than that. That would have been an interesting comparison to have that as a like, what if we just did that to this data? Should have done that, should have done a data sharing comparison. Because that would be a better straw, man. Because what I showed you instead was the zero filled image somewhere, right? Yeah. That doesn't make any sense because you don't want to go from like, oh, this is the worst choice that you can make. Exactly. Putting zero there is much dumber than putting the nearest point in time. And it would be a much better image. And it would be a much better image. And I'm actually, you motivated me to definitely replace that in the slides next time. It'll be worse. I mean, it'll be better than zero. It won't be as good as our fancy stuff, right? But it'll be more, that's a better straw, man. Exactly. Absolutely. Yep. I think a more realistic. Absolutely. Especially since so much of the object's not changing. I don't have any videos here, but it's mainly the heart that's changing here. And so you could. Great question. Let me question just about. I mean, maybe I have a music. Uh, I mean, maybe I have a misunderstanding of the OMRI is used, but uh, can you do this on volumetric data? Oh, yes, absolutely. Sorry, because just this is the what I have in mind, because you mentioned repeatedly about using SVD and working on patches. But if you work on spatial temporal patches, then you go to the 4D, where unless you do vectorization, you cannot use the SVD, right? I mean, you will have to use tensor-like versions. So, even here, I've already done vectorization. So, even here, I've got. So, even here, I've got two spatial dimensions. That's vect into one column of x, and then the next point in time. So, even in 2D plus time, I've already taken what's really a tensor. And so that's what you're saying, right? It really should be, you know, x by y by time. And my students and other people have worked on tensor low-rank methods. This was exactly my point because you mentioned the single RSVD, but whenever you go into tensor, things get trickier. Go into tensor, things get trickier. Exactly, that's right. Okay, um, yep. The alternatives would be to use like sparsity norms rather than low-ranked norms. All right, one attempt. Well, that's absolutely. Yep. Yeah, sure. Can you go back to okay, training? Training. Yeah. Right, so so So, I think I'll explain try to explain it here. So, here I've got four non-overlapping patches. So, I would also like to have this patch right here and this patch right here and so on, right? All the shifted versions of the patches. But a different way of accomplishing the same thing is to take the image and do a cirque shift of the image and then take these four patches. So, that's so this shift operation. That's so this shift operation is a cirque shift, circular shift on the spatial direction. And so, if I do all possible circ shifts and extract all the patches, this turns out to be a shift invariant function of my spatially shift invariant function of my image, which is what I really would prefer to have from a, so that I don't get any blocky artifacts. Thank you. Okay, you're welcome. Thank you, speaker. All right, thank you. Thank the speaker. All right, thank you all very much.