Okay, so welcome everyone. My name is Emilia Huerta Sanchez, and Sally Otto and I are co-organizing the software series, which is part of the hybrid thematic program on modeling and theory in population biology. And all of this is made possible by the Banff International Research Station. And so, before I introduce our speaker, Before I introduce our speaker, I want to remind you that we have another event next Tuesday at the same time, and it'll be an interview with Montgomery Slatkin. Okay, so let's start. So today, I am delighted to introduce our speaker, Dr. Jerome Kelleher, who is well known for having developed MS Prime. Currently, he is a Robertson Fellow and a group leader in biomedical data science at University of Oxford. At the University of Oxford. He and his group specialized in developing advanced algorithms and software designed to address challenging issues in large-scale genomics. Jerome's academic journey began at University College Cork in Ireland, where he received his PhD in computer science. And before assuming his current role, Dr. Kelleher was a senior statistical programmer in Gild McVean's group at Oxford. McVean's group at Oxford. And before that, he postdoc at the University of Edinburgh's Institute of Evolutionary Biology and the Department of Statistics at the University of Oxford. And so personally, I'm grateful to Jerome for figuring out how to make coalescent simulations computationally faster and for developing software that is powerful, practical, flexible, and makes, I think, our lives easier. And I just want to say that not only And I just want to say that not only is MS Primes, not only has MS Primes become the simulation tool for generating genetic data under various demographic histories, which can of course be used to benchmark new methods, to test hypotheses, and to develop intuition. But it also has inspired new methods development to leverage tree sequence data. And so, in my lab, I know that we use MS Prime all the time, and I was just teaching before this. And I was just teaching before this, and we were using MS Prime there too. So it's also a great teaching tool. So, with that, Jerome, thank you for being here. And the floor is yours. Well, thank you, Yes. Let me just get my slides shared. Okay, can everyone see my screen? Yeah. Fantastic. Well, thank you, Mary. Fantastic. Well, thank you very much for such a lovely introduction. It's a real pleasure to be here, and thanks to the organizers for giving me this opportunity to talk about MS Prime. So the goals of the talk today, I'd like to give people a high-level sort of overview of the features of MS Prime. Overview of the features of MS Prime and to highlight how to use these tools and how to provide and provide some examples of their effective use. And with this in mind, I want to provide a few canonical examples of how you do sort of key things in MS Prime and how you integrate with the wider Python data science ecosystem using things like Jupyter, NumPy, Matplotlib, etc. And I also want to just And I also want to just point out a few common pitfalls for people who are just getting started with MS Prime or have been doing it for a while and may not be kind of structuring their code in the optimum way. So some non-goals. I'm not going to give an introduction into coalescent simulation because I think you can't really do this without giving an introduction to coalescent theory. And I think that's beyond the scope of this talk. Of this talk, and I'm not going to even attempt to be comprehensive about all of the things that MS Prime and TSKit can do. I'm just going to sort of select a few things here and there that I think give a flavor of the possibilities. So, an important question to sort of address before we even talk about doing coalescent simulations is: you know, when should you use coalescent simulations and when? And when should you use forwards time simulations? So, the downsides of coalescent simulations are that they are much less flexible than forwards time simulations. So, forward-time simulations can accommodate essentially any evolutionary process that you can dream up. And there are some incredibly powerful and flexible simulators out there. And in particular, see the upcoming SLIM workshop. The upcoming Slim workshop from Ben Haller. Slim is an amazing piece of software. The pros of coalescent simulations, though, is that they are very fast. So in the cases that you can model things, the things that you're interested in, in a coalescent framework, so you can think about things as being neutral or nearly neutral, then coalescent simulations are often several orders of magnitude faster than running. Of magnitude faster than running forward time simulations. So, I think a good rule of thumb for whether you should use a forward-time simulator or coalescent simulations is you should probably use coalescent simulators whatever you can, because you'll save yourself a lot of time and some electricity. Another thing that I want to sort of address at the outset is that. Address at the outset is that it's probably not obvious to people kind of coming in reasonably fresh to this, but MS Prime isn't a monolith. It's a component in a wider ecosystem of interacting and interoperating pieces of software that we've sort of been putting into place over the last almost a decade now. So these interacting bits of software include forward time. Interacting bits of software include forward time simulators, so slim and forward pi 11 are very important parts of that. There's the software for thinking about demographic models, such as Deems and Standard Popson that I'm going to talk about later. And then sort of the glue that's holding all of this together is the tree sequence toolkit, TS kit. So as a kind of a first approximation, the way to think about it is MS Prime is running your simulations. Prime is running your simulations and TSGit is doing your analysis. So, as soon as you get a result out of MS Prime, now you're in TSGit doing your analysis. So, jumping in, the main thing that we're interested in with a coalescent simulator is simulating ancestral processes, right? So, the coalescent is a backwards in time model, and kind of by construction, it Kind of by construction, it decouples mutational processes from the ancestral processes. And this means that, you know, and through the way we do things in MS Prime as well, we completely separate the idea of simulating mutations from simulating the ancestral trees or the representation of the realized ancestral history that we get back. So, there's a lot of kind of confusing terminology lying around. Terminology lying around. So we can call the simulated ancestry an ancestor recombination graph. We're not going to get into what we mean by an ancestor recombination graph here, but I'm basically going to use the term arg, trees, tree sequence more or less interchangeably throughout here. Essentially, it's the realized history of your sample. So we're going to do a bunch of these examples. Of these examples. So, I want to show how you can do MS Prime simulations in a Jupyter notebook and how you can use the available sort of visualization and introspection tools to effectively run your simulations and to understand what they're doing. So, we're starting off with a very simple simulation here. We import MS Prime into our kernel and we run MS Prime sim ancestry. We have a sample of size two. We have a sample of size two. I'll come back to what that means in a minute. And we specify an effective population size, NE, of 10,000. So we're simulating a very, you know, very rough approximation of humans. And to make this example deterministic, I'm putting in a random seed. And then we get back our answer. This is the simulated ancestry that MS Prime has produced, TS. That MS Prime is produced, TS, and then we use this really, really powerful and handy draw SVG operation on the tree sequence object to visualize it. So we say draw the tree sequence that we got back from MSTRIME. And here, it's a single tree. We can see that we've got four sample nodes at the bottom. We've two, three coalescence events. One happened at time 15. One happened at time 1500 generations ago. The other one happened at 2900. And then they reached their most recent common ancestor at node 6 at time 21,000 generations ago, whatever it is. So this result object is a TS-Kit tree sequence, as I said. So this is a separate library from MS Prime. I'm not going to even attempt to talk about all the things that TS-Kit can do, but. Can do, but essentially, anytime we're doing analysis here, we're using the functionality in TSKit. If you want to find out more about TSKit, we've got a sort of website at tskit.dev, which tries to bring all of the different resources that are available together in a sort of easy-to-understand format. So, there are different ways of looking at this tree sequence object. One is to just look at the actual Just look at the actual thing itself in the notebook, and that gives you back this nice summary of what's in it. And the view has been slightly mangled here by the slides operation, but basically it's just telling us that we've got one tree, our time user generations, and telling us how many nodes and individuals and so on are in the trees. Another way of looking at it is this tab. This tabular representation. This is the underlying representation of the ancestry that actually produced and that's moved around. So these are the nodes, and we can see that these nodes correspond to the samples that we specified at the present. And then we can see that the more ancient nodes here are, these are the times that these coalescence events occurred. And then the actual topology. And then the actual topology of the tree is defined by this edges table. And that just says that there is an edge joining a parent child zero to parent four over a particular genomic integral. So it's very, very straightforward and simple representation of the ancestry. So a detail I brushed over a second ago is what we mean by a sample. A sample. So by default, MS Prime simulates diploids. And this means that if we take two sample individuals, we have got four sample nodes because each individual is composed of two genomes or ploids or various things that people call them. And these are represented by nodes in the TS-GIP model. And so we've got four nodes in total to represent two sample individuals. Individuals. So to illustrate this, we can simulate other ploidies. So here we simulate a triploid. And here we say we still have two sample individuals, but now they each have ploidy three. And so they correspond to three nodes, three sample nodes at the bottom of the tree. And to demonstrate how these nodes and individuals sort of relate to each other. Individuals sort of relate to each other. I've set up some labels for the three nodes. So we're labeling by I individual ID N node ID. And so we can see that individual zero here has node zero, node one, and node two. And then individual one is composed of nodes four, five, and three. Under the hood setting, Ploydy, it doesn't actually do very much. Um, it doesn't actually do very much, it just changes the time scale that the coalescence is happening at. But it's it's just trying to make these things easy to do, um, rather than sort of forcing the user to think about what the coalescent time scales are when you've got these tricky ideas of different ploidy levels and so on. Okay. So, a key thing that we're doing when we're running coalescent simulations is we're Running coalescent simulations is we're you know we're sampling from a random distribution of trees or tree sequences or arcs or however you want to put it and this random distribution is is defined by parameters that we supply to sim ancestry so in in the the examples before i used this random seed argument to to make the examples deterministic but usually this is exactly what we don't want to do we want to to generate We want to generate random samples from our distributions so that we know that we're truly sampling from this distribution and we're doing it in a reproducible way. So, MS Prime works really quite hard to get you good randomness. And I think the basic message here is that you should trust us. Should trust it. So, just to illustrate what I mean by, you know, drawing different random samples, we've running the same simulation again here without the random seed arguments. And we can see we get two completely different realizations. And that's all we mean by sampling from this. So the flip side of wanting to get lots of random samples is that we're going to need to do lots of replication in order to. Lots of replication in order to get at these distributions that we're interested in. So a single replicate or a single draw from a random process with high variance doesn't tell you an awful lot. So we need to do lots of replicates. And MS Prime offers some specific machinery to make doing replicate simulations as efficient as we can. I'm just going to demonstrate that there. So the So, the sort of canonical example that can be used as a way to build up your own sort of simulation analysis pipelines is computing the mean and the variance of the time to the most recent common ancestor of a sample using a thousand replicate simulations. And this is very straightforward. So, we use NumPy here. So, I definitely recommend using NumPy wherever you can. Recommend using NumPy wherever you can. It's a very powerful numerical library. It's sort of the foundation stone of the Python data science ecosystem. And we're going to do a thousand replicates of our simulation. And we're going to use a NumPy array of length 1000 to represent the summaries of each of those replicate simulations. And the way we do replication then in Replication, then, in sort of an efficient way, is to pass this numReplicates arguments to MS Prime, some ancestry. So, keep the rest of the parameters the same and pass this extra num replicates. And then we get back this reps value. And then we, in a for loop, iterate over these replicates. So, this enumerate function here is basically just giving us a way to index. Just giving us a way to index the replicate ID. So it's not important that we understand everything that's happening here, but using this as a template for your own analyses is a good way to make sure that your simulation code is nice and efficient. And so for each replicate, we grab a tree. There's no recombination here, so we only have one tree. We get the time of the root, we put that into the jth slot of the Into the jth slot of the NumPy array. And then when we're finished this loop, we output the mean and the variance of that array using NumPy. And this turns out to be a mean of 30,000 generations and a variance that's big. So I'm emphasizing this here because it's something that people That people slip up on quite a bit, and their code ends up being quite a lot less efficient than it needs to be. I think it's a pretty common gotchas. So to illustrate this, we've done the kind of canonical example here in a timeout. And it takes 126 milliseconds to run these thousand replicate simulations when we do it in the sort of recommended way. But if we do it in But if we do it in the, you know, in the same in distribution, so you know, you get correct results by doing this, but it's 10 times slower. So the sort of obvious thing to do here if you're doing replication is to call sim ancestry a thousand times in a loop. But it turns out that that's much slower than using this num replicates example. And it doesn't make much difference here. Example and it doesn't make much difference here, it's only a second, but this does scale. So, if you've got a complicated demographic model and you've got lots of parsing going on inside Python, this can easily totally dominate the actual time to take the simulation and it can be many times slower than it needs to be. The second kind of common gotcha here when people are doing this is that they store the replicate simulations in a link. Or the replicate simulations in a list. And this is a sort of natural thing to think about, especially if you're coming from a language like OR, where everything is a sort of explicit list. And you're not really used to thinking about these Python structures that represent implicit iterations. And so what happens here is, you know, you get the same answer, and it's more or less more of It's more or less more of takes more or less the same time, but it uses a thousand times as much memory as it needs to because it's storing all of these replicate simulations in memory at once instead of looking at them one by one by one as is done with the sort of the recommended approach. I've tried to illustrate this here with looking at these objects in the notebook. You know, the first three elements of Replis, they're all tree sequence objects. They're all tree sequence objects, whereas the original reps variable that we had a minute ago, that's a generator object, which is this Python tool for doing implicit iteration over a set. So takeaways here, MS Prime is good at randomness. Really don't bother generating random seeds and so on unless you genuinely need to. There's a lot of work behind the scenes. There's a lot of work behind the scenes to make sure that we're doing this well, and we're pretty sure it's doing it well now at this point. And for small simulations, using num replicates and doing structuring analysis in a certain way can make a big difference to your CPU time and memory usage. So I'm primarily interested in talking about ancestry simulations. About ancestry simulations here today, but I think it would be incomplete if we didn't talk about mutation simulations a little bit. So, MS Prime is also actually a very powerful mutation simulation engine, and we can simulate mutations under many different well-known models. We added microsats recently, actually. And it can take any given tree. And it can take any given tree sequence and impose a set of mutations on that. So it doesn't have to be something that's generated with MS Prime, it could be, you know, something inferred with relator or TSInfer or anything. It doesn't matter. It'll impose mutations on that given the branch likes and the parameters that you provide. So to illustrate this, we've run another ancestry simulation, same as before. Simulation, same as before, two diploids. This time we've said that the sequence length is 20 kb. So we're simulating 20 kB of non-recombining non-recombining genome. And then we throw down mutations on that simulated ancestry at a rate of 10 to the minus 8 per generation, per site per generation. And then to visualize this, we And then to visualize this, we throw this into the trusty draw SVG. And we can see then that we've got some mutations sort of drawn on top of our tree. And this is showing us the positions along the genome where the mutations occur. And then we've got the corresponding positions, sort of the on the branches, where those mutations occur in the history. So it's a nice way of. History. So it's a nice way of sort of quickly seeing where your mutations are happening and so on. So if you, so there are lots of ways of analyzing sequence data in TSGit, but I just want to emphasize that you can get your data out in standard formats if that's what you need. So you can output to VCF and then VCF can be basically consumed by. Can be basically consumed by whatever tool you want. I'll say there's lots of functionality already in TSKit. So you may find that you can do what you need to in there, and that'll be much more efficient. But there's always the option of exporting to VCF and other formats if you need it. Okay, so population structure. We've assumed so far that we're simulating Far that we're simulating from a single pangmictic population that has had a constant population size for an infinite period of time. And this isn't particularly realistic. I don't think there are very many species that follow this. So, usually, what we're interested in doing is providing some more complex demographic models that That will sort of summarize, or at least reflect some details of the history of a particular species. So MS Prime supports a pretty flexible model for demography. We've got essentially any number of discrete populations which have sizes that can change over time and migration rates between them. And it should efficiently manage. And it should efficiently manage pretty large numbers of teams. And rather than talking about MS Prime's sort of interface for defining populations, I'm actually going to focus here on a tool called Deems, which is intended to be a standard for defining demographic models. Demographic models. So there's a paper in genetics in 2022, if you're interested in finding out more details. But basically, DEAMS is a declarative structure, which defines a set of populations, their time existences, and their relations to each other in terms of ancestry and also migration rates between them. And the key idea is. And the key idea is that if we have this single definition of what a demography is, then this definition can be used by the programs that are inferring these demographic models. And then we can transfer those inferred models directly into our simulators to simulate under them. And so DEAMS is supported by quite a few different programs now at this point. And I think it's a really great. It's a really great, it's got some really nice tools for working with populations as well. So, I'm not going to talk about how Deems is structured, but basically, we have three names populations here, A, B, and C. And we'll see what they look like in a minute when we use some of the nice tools that are available. So, we want to define our demographic model. We do that here by importing Deems and then sort of defining this. Sort of defining this YAML from the model that was in the previous page. So normally we'd just use a file. I'm putting it into a string here for convenience. And then we load up that model into Deems using Deems.loads. So that parses this demographic model, makes sure it all makes sense, and then returns you some object which represents that demographic. Represents that demographic model. And then we can do some really nice things with it. So, one of the things we can do is use this lovely Deemstrawl package, which lets us actually visualize the demographic model. So, Deemstrawl has this tubes function, which lets us do one particular type of visualization. So, now we can immediately see that we've got two contemporary populations, A and B. B is smaller than A, and both of them merge into Into a single ancestral population C a thousand generations ago. And you know, this picture is worth a thousand words of trying to describe what a population or a demographic model actually is. So coming back to MS Prime, how do we use this information? Well, MS Prime has its own demography API, and that supports Deems as a sort of import format. Of import format. And the way we do it is we've got this method msprime.demography.from Deems. That takes in the Deems model that we loaded up a minute ago, and that turns that into an MS Prime demography class. And the demography object then has a bunch of features by itself. And one of the things it can do is provide these sort of introspection features when you're in a notebook. Features when you're in a notebook. So, when I'm in a notebook, I look at the demography. It tells me I've got these three populations called A, B, and C, tells me their population sizes, tells me about events that happened in the history of these populations. So our population split here is telling us that populations A and B were derived from C at that time. So Now that we're working with a demography, there's another thing that we need to do, and that's specify where our samples came from. So now we're calling some ancestry with this demography object, which captures all of the complexity of a demographic model. And now we need to tell MS Prime where do we take our samples from? And the best way to do this is to use this form where we say we give the population. We give the population name as the key in its dictionary, and the value then is the number of samples. So we're taking two samples from population A, one sample from population B. And again, we draw out this tree to see what it looks like. So this tree is handy. It looks, you know, it tells us some basic stuff about what has happened in the past of our simulation, but it's not giving a lot of insights into, you know. Like insights into where events occurred. And we can use the information that's inside in the TS-Kit tree sequence model to allow us to get at that. So the TS-Kit tree sequence does complain complete information about our populations. And it starts with this populations table. So these are the populations that were defined in the original DEAMS model, and they've come through as. Original Deems model, and they've come through as having names A, B, and C. And then the nodes themselves are associated with each of these populations. And there's various different ways you can get at this information, but I've just shown the nodes population array here. So this is saying that the first four nodes are from population one, you know, name equals A. Second two nodes are from population two, which is name is B, and the rest then are from population. Then are from population zero, which is C. And then we can bring this information together so that we can improve our visualization. So now we can set up our visualization so that the node labels reflect the population in which the event actually occurred. And we can map that back to the metadata that was provided as part of the original Deanus model. So now we can see. So now we can see that all of our coalescences happened in the ancestral population, which isn't surprising because it's such a small population. But still, we've got four samples coming from A, two samples from B, and then all of the ancestral nodes are occurring in population C. So the takeaways here are that there are some really, really good tools now for working with demographic models. For working with demographic models, you know, way better than was available even a few years ago. So, if you're still working with MS Prime 0.x demography models, then I'd really encourage you to make the switch over to the new demography APIs or even move over to using Teams as your sort of primary way of working with demographic. Of working with demographic history. I haven't talked about standard POPSI here, but basically, if you're interested in simulating a particular species and that species has been added to the standard POPSIM catalog, then that's the go straight to standard Popsim and use Standard Popsim to simulate your species because it's using MS Prime under the hood or Slim. And it's trying to bring together. You know, it's trying to bring together all of these tedious details about estimated parameters from the literature into one place to make it easy to simulate a particular species. So, when should you use DEAMS or when should you use the MS Prime tomography API? Well, I think basically DEAMS is really good for empirically estimated models. So, when we're looking at these like big complicated models that people are estimating for humans, for example. For humans, for example, Deems is ideal for that. Whereas, if you were working with simpler, more theoretical-based models, then actually MS Prime's demography API is probably a bit more convenient. There's also a bunch of, I think, underutilized tools in MS Prime's tomography API. So, we've got, for example, numerical methods for calculating coalescence rate trajectory for a given For a given demographic model. And we can do really powerful things with this. I think there's really some really cool features in there that may not be used as much as they might be. Okay, so moving on from demography. Up to this point, we've basically been simulating the ancestry of a single base of sequence, right? We're assuming that. Base of sequence, right? We're assuming that no recombination can occur, so we only ever get a single tree, and most of the time, that's not what we're interested in doing. So to make things a bit more realistic, we need to define two more parameters, sort of at a minimum. And these are the sequence length. So that's the length of the sequence that we're interested in simulating. The length of the sequence that we're interested in simulating and the recombination rate between base pairs along that sequence. So, here we're simulating 5 kb at the human sort of rate of 10 to the minus 8. And when we do that in this example, we get two trees. So, recombination has occurred at position 6, 601, and that's resulted in two distinct trees here, one tree to the left of 601. Here, one tree to the left of 601 and one to the right. So, I'm not going to go into the details of what all that means. Essentially, we've got these two trees, and now we need to do something with them. So, visualization is very handy. It really helps us build intuition about what our simulations are doing, but of course, it doesn't scale. So, we can only really visualize these sequences of trees with very short regions. Regions. So, to illustrate here, I've expanded this simulation to just be a megabase. And even there, we get 600 trees, which there's no way you can visualize. So, we need to do something a bit more quantitative. So a very common pattern for this is to compute a statistic for each tree and to move along tree by tree. And TS-Kit has some very powerful ways of doing that. So the canonical. That. So the canonical example again of doing this is essentially to allocate an UMPy array, one for each, one slot for each tree to contain the thing that you're measuring about that tree. And here we're looking at the MRCA along the genome for each tree. And we go through the trees in this loop, and then at the end, we output the MRCA of. output the MRCA of that and the maximum of that for some reason. And so here that takes a millisecond to do for whatever 600 trees, which it's a small example, but it's still reasonably quick. And that tells us that our mean MRCA was 40,000 generations. So I'm not going to go into as much detail here, but there's To as much detail here, but there's another common gotcha here, which kind of results from people storing lists instead of using the iterators in the standard way. You get these confusing error messages, but basically don't take a list of the trees. You're just going to end up getting the wrong answer. So, just trying to illustrate that again. And then, one final example, just showing a nice way. Just showing a nice way we can integrate with Matplotlib in order to get a plot of something. This is the MRCA along the genome and the tree boundaries shown in grey. And we can do this with very little code directly from the trees. So takeaways here, there's lots and lots of features in MS Prime for this sort of stuff. In MS Prime for this sort of stuff, we've gene conversion, genetic maps, multiple chromosomes. You know, the documentation is pretty complete on that. A thing to remember, and it's important to point out, is that MS Prime is fast for sort of low to intermediate levels of recombination. So, you know, human chromosomes are fine, we can simulate them, but for very high recombination rates, it's actually very slow. So, try. Actually, very slow. So, trying to simulate a whole Drosophila chromosome currently isn't actually feasible. So, if you're doing that, you're actually better off with a simulator like Scream or something like that, which uses the SMC. We're hoping to fix that soon, but at the moment, very high recombination rates do make MS Prime quite slow. Again, using TS-Kit effectively, you know, following these sort of standard patterns can make a dramatic difference in how. Can make a dramatic difference in how efficient your analyses are. And also, there's a whole bunch of population genetic statistics in TSCIT, in case you get the impression that you've got to build up these sort of statistics yourself by iterating over trees. Most of the time, you don't. Okay, so I've got one more big chunk of functionality I want to talk about. I'm going to go through that fairly quickly as I'm a small bit behind time. The most exciting feature that's happened in MS-RAM in the last couple of years is the ability to simulate trees conditioned on an input pedigree. And the idea there is that rather than simulating this kind of completely unconstrained process where we're using the coalescent model as a way of determining which lineages coalesce and recombine. Ages coalesce and recombine, we use this input pedigree as sort of tubes which the genetic ancestry gets shoved down and minced up and stuck back together. And the beauty of this is that the pedigree can capture the intricate details of history that are just impossible to model in a probabilistic way. Probabilistic way. So, the models that are sort of appropriate on a continental level, it's very difficult to scale those down to the population genetic processes that happen at a village level. And if we have observed pedigrees that are large and sort of detailed enough, then we can do just this. And that's the sort of thing that's demonstrated in this paper from last year where we introduced this feature. Where we introduced this feature, and it's some very, very nice results on that, I think. So, quickly to show how this works: here's a pedigree. It's, you know, pedigree more or less like you find in various programs. We import this into MS Prime with this paras pedigree function. And then I'm showing the example pedigree just so we can visualize this. This function is defined in the MS Prime document. This function is defined in the MS Prime docs. It's using network X. What we get back is a TSCIT3 sequence that has the pedigree information encoded within it in its individuals table. So here we can see individual zero has parents four and five. We skip back here, we can see individual zero has parents four and parents five, right? So it's very straightforward encoding of the pedigree. Encoding of the pedigree information within the overall structure. And then the node table also then shows how the different notes for each individual relate back to these individuals. It's our standard stuff. Okay, so we then run this simulation with a slightly different pattern. We don't specify any samples, but instead we specify this initial state. This initial state. So the initial state, this input tree sequence, which contains the pedigree information plus the nodes for the representing the genomes of the individuals in that pedigree. And the initial sampling conditions are taken out of that tree sequence by MS Prime and used as the way to set up the structure. The model then is the fixed pedigree. So when we do these two things, The fixed pedigree. So, when we do these two things, we've got an appropriate input pedigree and we say model equals fixed pedigree, then we simulate condition down that pedigree upwards through it. So, again, we want to show what happens when we run this simulation and there's with these labels. So, we can see these individual zero has nodes zero and one, and in this case, individual zeros Individual zeros genomes or nodes, they coalesce back in individual nine at node 18. That's one thing to notice. The second thing to notice is that this ancestry stops at generation four, right? So our pedigree only contains four generations of information. And what we do when we get to the top of that pedigree is we just stop. Stop. So these trees are incomplete. We have two different trees, and both of those trees have two roots. And the roots are the two nodes of individual 11. They're the same on both sides. The third thing to notice about this is that the history actually is incomplete. So looking again at the branch between zero and Branch between 0 and 18. This has gone through the pedigree, right? It's after going through three generations of individuals and three generations of nodes. Now, no coalescence has happened, so we don't put in any nodes to represent that coalescence, but still, we have passed through known nodes. And actually, leaving those out sometimes is a disadvantage. Sometimes we want to know the Advantage. Sometimes we want to know the precise path with which the genetic material has traversed through the pedigree. But we can fix that now with these new features that have been added in version 1.3, these two new parameters called additional nodes and coalescing segments only. With those two, we've got a very flexible way of specifying exactly what combinations of events. What combinations of events are recorded by adding nodes on these sort of on these long branches? So, doing that here, we've got basically the same simulation, except we add these two new parameters, additional nodes and coalescing segments. And we're interested in basically everything here. So, we're saying record all recombinant nodes, record all pass-through nodes, record all common ancestor nodes. And now, when we do that, we can look at our branch between 0 and 18 again. And now we can see that we're after passing through nodes 11 and 12, individuals 5 and 6, on our way through to pass through here. So we now have complete information about how genetic material has passed through the pedigree. And these arguments aren't only for the fixed pedigree model. Only for the fixed pedigree model, you can do this with the Hudson coalescence, DTWF, or any other model. And it gives you this information about where nodes have gone through branches where coalescences have not necessarily occurred. I think there's some really interesting work to be done in this area where we reason about what information is in these unary nodes and whether they can be detected from real data. The final thing to note about this is that the pedigree simulation just stopped at the founders. And usually, we'd like to simulate back to the most recent common ancestor of our samples. So, MS Prime has got very powerful sort of mechanisms for doing this. And essentially, we can add on an extra simulation on top of the simulation we've already done, telling it to complete it to ancestry. To ancestry. So, this is the same method that we use for what we call recapitating forward stem simulations. And there's a pair of papers here if you're interested in that or interest, more details there. So, here, our final tree sequence is the output of our previous simulation. We're using the GGWF model here, which seems more appropriate. And then we coalesce to a We coalesce to a most recent common ancestor of everybody six generations ago. Okay, so the fixed pedigree model is very powerful. I think there's lots of exciting possibilities to explore there over the next few years, particularly when we combine with these large empirical pedigrees. And the ability to combine these multiple simulation types, you know, even across different simulators is a really, really powerful tool, which is well worth figuring out how to do. Right, so that's all I want to talk about. Thanks for listening. I just want to acknowledge my collaborators and the really big community of enthusiastic and fantastic developers that have sort of grown up around MS Prime and TS Git. So these are the contributors from GitHub for MS Prime, and I want to thank all of them for their contributions. For their contributions. We have, we're a friendly community. So, if any, if you want to join our Slack or if you have any questions, please just do jump up on GitHub and post a question to the discussions board. We're always happy to help if we can. There's a bunch of publications. If you want to get more details about any of these ideas that are in here. In here. So these are where the ideas were sort of originally set out. And there's quite a lot of online resources as well. I guess the main thing really is to use the TSKit dev website, which has lots of links and information. And it's trying to put together these resources in a way that's handy to use. With that, I'm going to thank you all for listening. Thank you all for listening and stop sharing my screen. Thank you. Thank you, Jerome. That was great. I guess we have some time for questions if anybody has questions. Let's see. What's the protocol for asking questions here? All right. I think anybody can speak. I think David Pety has one, and then Ellen Baki. Sorry if I mispronounced your name. Hey John, thanks for the nice overview talk again. I guess I hadn't known that you could simulate multiple chromosomes and going. Multiple chromosomes and going off of that, what is the best practices for trying to simulate like autosomes and like a sex chromosome concurrently? Yeah, that's a great question. I don't think there is a best practice right now for the sex chromosomes. That's tricky. I think we haven't really figured out the right way to scale parameters and so on to do it properly. It's something we're Properly. It's something we've talked about quite a bit in standard POPSI, but I'm not sure that was ever a proper solution. Yeah, doing the multiple chromosomes thing is a bit fiddly. You have to do a few things manually, which you can do it, and it's documented in the documentation. Awesome. Thank you. Just to say, you could do that in Slim. You could do that in Slim if you wanted to, but of course, it's not going to be as fast as doing it with a coalescent. Yeah, okay. Thanks, Jaram. I'd just like to ask whether there are any plans to extend to including selection, so things as things such as the ancestral selection graph. So there is limited support for For selective sweeps at the moment. So we have the basic machinery in there for doing the structured coalescence. But we're sort of, there's a few people are interested in extending that to make it more flexible so that we can kind of provide arbitrary allele frequency trajectories as the background in which you do the structure coalescing on. So I'm hoping. Lesson on. So I'm hoping that we will have sort of much better structured coalescent support in the, you know, over the next year or so. For the ASG, I'm not sure. I'd have to scratch my head quite hard about that one, to be honest. That's tricky. It's quite a different story because you have to add branching events. And so. Yeah, yeah, yeah. Yeah, yeah, yeah. Thank you. Thank you. Jasips? Hi. Hello. Yeah, thank you for the talk. I'm very interested since MS Prime is being used by so many people for so many different purposes, there must be a lot of thought, or it's like a very important decision what the default arguments are. So I wanted to ask you about what was the thought process behind? What was the thought process behind making the discrete genome option being set to true the default option for the simulations? It was essentially through experience. So from the original, the original defaults, the thought process was, let's do what MS does because it's MS. And over the years of sort of working Years of sort of working with people and seeing what they wanted to do and what they typically got confused by, that most of the time people actually seem to just want to simulate discrete genomes. You know, most of the time they want to be able to think about their study species, kind of simulate that as directly as they can without having to sort of, you know, twist coordinate spaces. Twist coordinate spaces and things around in their heads through, you know, for any or whatever. So there was a conscious attempt with the 1.0 API to make things as simple as possible from that perspective. So, you know, just do all of the coalescence, time scale manipulations and so on behind the scenes so that the users didn't have to. I see. Thank you. I see. Thank you. Nice question. Moira? Hi. Yes. Thank you. And thank you for a very nice talk. My question is, so I had to simulate short tandem repeats before, so SDRs surrounded by SNPs. And I know the way I did it was very, very slow. And I'm wondering if there is a better and faster way to do it. If there is a better and faster way to do it, so basically, what I did was, you know, I gave the chromosome size that I wanted for the SNPs, and then I needed the STR like exactly in the middle, and then another set of SNPs. But when simulating the STRs, it created one STR per position. And so that means I had to go through the whole generator to get the specific SDR that I needed. So is there any way or a way of working on that? A way of working on that that would make it maybe faster? I don't really know off the top of my head where I'd need to look at the details. But if you want to open a question on the GitHub discussions forum for MS Prime, I'd be happy to sort of go back and forth a bit on that. Okay, sounds good. Thank you. I have a question. Please speak up if you have a question because I can't see everybody on my screen here. Emilia, I was just pointing out that there was a request on the chat to if we could potentially get access to your slides, Jerome. Well, I'll give whoever the slides, but I don't know what mechanism that will happen by. Okay, so we will. Okay. So we will figure out how to post that maybe on the Sasanji website. Yeah. And I've just put a link in there. Or if you have it now, you can add it in the chat, Jerome, whichever. Tasarbian, like it, Bilgy, Sally. You can email them to me, Jerome, and then I can post them on the web. I can send them to Noah to post on the website. Great. I think there's another question. I think there's another question by Walid. Yeah, hi. Can you hear me? Yep. Yeah. Hi, Jerome. How are you? Quick question. Very exciting, the work that you're doing with integrating empirical pedigrees. I'm just interested in picking your brain on what future directions you're kind of thinking about, because there's a lot of pedigreed wild pot. A lot of pedigreed wild populations out there, so I think it'd be very interesting to get those ecologists to kind of consider using MS Prime in that way. So, what do you think? Yeah, that's a great question. I think it gives us a way to, as I say, model this like this level of population structure that isn't really captured by the large-scale. Scale, you know, thousands of generations scale models that we usually think about. And it's a way of looking at the recent past and capturing the vagaries of the recent past, I guess, you know, because when things are that detailed, the actual history matters, and the actual history is directly reflected in the pedigree. So if you go through this, like. So, if you go through this arbitrary bottleneck three generations ago, that's just there. It happens. So, I'm not sure what the immediate application is. I guess that's not really my forte, but I think it's a new thing that people can do that wasn't really possible to do before to simulate genetic ancestry. You know, genetic ancestry, and get out your full tree sequence, or whatever you want to call us, conditioned on this pedigree, and then examine what are the effects of, say, running multiple simulations through this particular pedigree. How constrained is the history by this pedigree, or how much variation is there around that? I think in the human context, In the human context, you know, looking at things like how important is this super fine-grained population structure on things like GWAS, you know, there's a unique opportunity to do that now, I think. So I think there's some cool applications. Well, we are, it's one p.m. here. It's 1 p.m. here. It's been an hour. Let's thank Jerome again for a wonderful talk. And I hope you join us next week for the next event. And so thank you for coming. And thank you, Jerome, for giving a nice presentation. Thanks, Emilian, for the invitation. And thanks to everybody for coming.