Okay, hello, hello. I don't know. It's the end of our crypto. Can you hear me now? Hi. Hi. Hello, everybody. Okay, so Peter says that the volume should be they say that they can hear Peter, but the volume needs to be very low. Can we push up the volume? Should I try again? Hello, everybody. Can you hear me? I know you can hear Keeper who tried to adjust the real Dickie's microphone. Is that better? Okay, wonderful. All right, so I think that now we are perfectly on time. It is 9:30 here, so we're gonna start. I just want to mention to the speakers that the camera is To the speakers, that the camera is essentially going from one side or it's not going too far off the screen, so if you're in front of the computer, people online cannot see you, just so you know. All right, so it is my pleasure to be here with you and introduce Peter Monk. Peter has had some great contributions to not only the world of FREX methods, but also computational wave in general. And because it's a small conference, I want to say that I am particularly glad to introduce him. Particularly glad to introduce him because he has had a great influence on my life, both professional and personal. And so I can tell you how I met Peter when I was a graduate student. I contacted him to come visit him and spend a few months at the University of Delaware. And he very gladly welcomed me. And so that's the, it was in 2012, a long time ago. But this visit has been really excellent for many different. For many different ways. He was a great help in my research. He had some great suggestions of things to look at that came into, that later took the form of a paper that won the prize later. So that was really great. And only later, at the beginning, I was still unhappy that you didn't want to be a co-author with me on that paper. But you said that you your contribution were not big enough that you didn't want didn't want to be a co-author. Then we finally wrote a paper later when I was a postdoc, but that's essentially Later, when I was a postdoc, but that's essentially after this visit is essentially what led me to go on to a postdoc in the US and then be a professor in the US later. So, a great influence, not only scientifically, but also on the personal side. So, I'm very happy that we have here, Peter, for the first talk today. And so, the microphone is yours. Thank you very much, Lisa Marie. And gosh, what a mistake not to have your name on a prize-winning paper. Well, I don't know. But anyway, yeah. But anyway, yeah, certainly. That was very nice to start the collaboration. 2002, did you say? 12. 12. Okay. Yes. So thank you, Lise Marie, Virginia, Helene, and of course, Hilaria for organizing this and for allowing me to speak. And so I do apologize a little bit. This talk was intended for Thursday. Was intended for Thursday when I assumed you would have heard 10 times everything. And so it's a little bit, it may be a little bit vague in places. My goal was to introduce this Bruno Dupre's ultra-weak variational formulation for Maxwell's equations and tell you about our efforts really to not so much mathematical efforts, really, but Much mathematical efforts, really, but more sort of some of the things we've done to try and make the code a little bit more useful to our industrial partner. So this is joint work with Himo La Hivara, and he will talk on Thursday, I think, and really give some numerical examples of this from our work. And I will just sort of set the scene. That was the idea. Sort of set the scene. That was the idea that I would do that. So, anyway, by the way, it's very nice to be in Mexico. I've never been to Mexico before. I've lived in the US for quite a long time. So, it's really nice to finally get the southern neighbor. Okay, so yes, so this is ultra-weak variational formulation for Maxwell's equations. And we have received some grant support for this in the past. Um, and and I guess currently, in fact, um, so let's see, not so much. So, I'm going to sort of dive out of sight every now and again, press the down button, and uh, I'll start with uh sort of an introduction. Um, and uh, so yes, so well, um, it's no surprise I'm talking about a Treft's method, um, and it's due to CÃ©sanin Dupre. So, it would have been nice, very nice to have Bruno here. It would have been nice, very nice to have Bruno here to speak first. And this goes back a long way to Olivier's 1996 paper. And at that time, or thesis, I should say, at that time, I was trying to solve, I needed to solve Maxwell's equations because I work on inverse problems and we needed synthetic data to put into the inverse solver. And we couldn't afford the commercial codes. The commercial codes. So I was looking for a way to solve Maxwell's equations. And so, yeah, so we started using this in 1998. And really, yes, that's where we go. So currently, we're working to develop this ultra-weak in an industrial setting and in particular for electromagnetic antenna simulation. Electromagnetic antenna simulations. Some of the things that we've done to the code, I mean, besides writing it and parallelizing it and stuff like that, you know, there's quite a lot of, oh, worked. So sometimes good things happen. So our recent paper here, by the way, you might have noticed a typo. My file was labeled Max. Was labeled Maxwell 2023. This is really a new talk. So, anyway, so this is, yes, so this is our sort of latest work with our industrial colleagues showing some of the things we can do. And I'll comment on that more later. Yeah, so what they want to do is solve. They want to do is solve antenna radiation problems, or and in particular, they're interested, or at the time when we started, they're interested in solving scattering problems from or understanding how, sorry about this, I will learn, so how to predict the electromagnetic radiation from a Magnetic radiation from maybe different antennas. The point is that this is a large object, and the antennas are relatively small. So there can be several of them. And what they want to do is mesh up this aircraft and then solve the scattering problem or the antenna source problem and predict the so-called And predict the so-called far-field pattern. So the far-field pattern is a functional of the near field. So obviously, if we're going to do Treft's type method, we're only going to be solving on a finite region of space. And then we have to go to the far field. And there's an integral you have to evaluate. There's a functional you have to evaluate. And you get the far field pattern. And this is a fairly old 2015. Fairly old 2015 example of sort of meshing and then predicting the far-field pattern, which looks a bit like that, apparently. Okay, so I want to run through really Olivier's thesis from all these years ago and try to tell you how this works. Tell you how this works. And then, yes, I'm going to give one set of, really, one set of numerical, two sets of numerical results. One is just a comparison to finite element methods, which we were forced to do by the reviewer of our paper, which was actually a good thing because it made us think about several things. And yeah, so we're, as usual with draft methods, we're solving a linear. Solving a linear problem, Maxwell's equations, with no source term. The sources have to be built in some other way. And here, epsilon and mu are the electromagnetic parameters, and they can vary spatially. They can be matrices with certain properties, like, well, mostly they have a positive real. Mostly they have a positive real part, let's say, or positive definite real part, but not always. And so then there's this odd-looking boundary condition, and this comes from, well, sessionosthesis, but really it's a sort of incoming to outgoing radiation. Actually, yes, incoming to outgoing radiation. Yes, incoming to outgoing radiation condition. And it's a convenient way to write boundary conditions for this method. And the most important, well, there's two important ones for us. Q equals one, Q equals one, you take this to the other side, you get E tangent is proportional to some function. And that's called a perfect electric conducting boundary condition. And it's the analog of the Dirichlet boundary condition. Dirichlet boundary condition for the Helmholtz equation. Then, on the other hand, if you take q equals zero, you get a simple absorbing boundary condition, it's like an outgoing radiation condition that we used for a long time. And a q equals minus one doesn't occur really in nature, but on the other hand, it's useful because it's a symmetry boundary condition. So sometimes it's you if you have a lot if you have. Sometimes if you have, say, a cylindrical object and a wave coming in, you could split it in half or into quarters and put suitable symmetry boundary conditions. So we use all three, but the important ones are q equals one and q equals zero. And then, of course, because it's Trev's method, somehow once you have the electric field, you can just evaluate the magnetic field, which you might do. Which we might do. Okay, so we want to solve this problem. This is the data, boundary data on some boundary of omega. And what else do I need to say? Z is a quantity that has a physical meaning in some instances, but it's a parameter, positive real parameter, that is defined on all the, it's going to be defined on every face in the mesh. Defined on every face in the mesh. So it's defined on the outer boundary by physics, but on the rest, it's just going to be a positive scalar quantity, and there's a canonical choice for that, namely one. So we go. So yeah, so the classical Cessena method, and since I was writing the code in 1998. Writing the code in 1998, that was really the work of the state of the art then, I guess, is to use plane wave solutions of Maxwell's equations on a finite element mesh. And then there's some variational technique, some variational equation that you write down to penalize the jumps. To penalize the jumps in the Cauchy data, so it's the tangential electric and magnetic fields across interfaces. We want them to be continuous. And of course, we have the well-known limit that plane wave solutions imply that the materials are piecewise constant. And mostly that's not really a huge problem for our applications. For our applications. But there are cases where you have functionally graded materials where the epsilon particularly may vary smoothly from, or you can think of it as smoothly, from one place to another. And those we need some other technique. I'll mention that a little bit later. And usually the mesh is tetrahedral and K is going to And k is going to denote an element in the mesh. So the derivation of the ultra-reak, this is perhaps a little faster than I would have put if I were planning the first talk, but you take Maxwell's equations. Maxwell's equations on an element. This must hold on an element. And then you integrate by parts. When you integrate by parts, the curl moves over to the test function and becomes a curl, stays a curl, I should say, and throws out some term. And you can see that this is the nu cross H, which is roughly nu cross H, which is the magnetic. Which is the magnetic field, and this is the reason for sort of saying this is a Neumann-type boundary condition. And then you integrate again, and all the derivatives come onto the test function, and you get this term. So, and now we can see, and this is where the Treft comes in, right? Is that so? Yeah, sorry, this E sub T here, where does that occur in this formula? Oh, there's a T down here and here. Oh, there's a t down here and here. This e sub t is the tangential trace of the electric field. So then you see that if this test function satisfies not Maxwell's equations, but the adjoint Maxwell's equations, namely there's a bar here, complex conjugate on here, if it satisfies the adjoint Maxwell system, then this term goes away and we get, and I think Fokash has called this fundamental identity. has called this fundamental identity which connects the the the the the Neumann and Diracle well this is not quite what I said was Diraclet data but this is rotated Diraclet data on on on the on the back on the boundaries of the element okay now if you now if you Now, if you so now we can use this, or Cessna could use this, to go to the next slide. And well, so if you to then I can go to the next slide, but I don't want to. So, so to connect, to write this, which is called the isometry lemma some places. So, um, Some places. So here you'll see that sort of impedance trace, if you like, or this impedance type condition. And the same thing here with a complex conjugate. And if you just multiply all this out, you get this with this. But this is zero. But this is zero. And so you just get this equals this. And so now you see that this is with one sign, and this is with the change sign. And so now if we consider an arbitrary element in the mesh, well, you see that across a boundary, we want continuity of this term here. So if we're on one element, the E. The E tangent should equal the E tangent on the other element, next door element, and this guy, well, nu cross H should be new cross H on the other side, but because we've got normals that point out of the elements, there's a minus sign comes in. But this is very good, because so you get this. You get this. This is the neighboring element. This is a neighboring element, and you get minus the normal there, and you get just the same thing here, except all of a sudden, omega has changed to K. And I do apologize for that. This is because our code is actually rather schizophrenic about what is omega and what is k. Sort of varies from place to place. But anyway, but it's a mistake. And it should be kappa. But it's a mistake. And it should be kappa because it should be kappa because, and it probably should be kappa here because it was kappa here. Sorry, I do apologize about that. That's the wave number. And anyway, so now if you add these guys, ah, that's bad. If you add these guys over all the element, then you get this quantity here. And on the boundary, well, this is exactly. Well, this is exactly what the boundary condition gave you as Q times the other thing. So this is all nice. And okay, so now this is where I think Cessinander Pre did a clever thing here. Well, many clever things, but this is one of them. They said, okay, well, let's let the, let's, this is, this is connecting these unknown. In sort of impedance traces on neighboring elements. And so they defined, you'd think I could learn, but old dogs and new tricks are not easy to. So anyway, here is, they define the new unknown for the ultra-weak problem as being this combination of the fields and a new test. Of the fields and a new test function, which is the same combination. You notice, of course, that this is the same as this. And this is Y. So, and then there's a slight, well, not problem, but you see that here you need the impedance trace with the plus sign, and here you need the sign and here you need the impedance trace with the minus sign and so they define this operator f by which just flips solves the solves max the adjoint Maxwell system with the given boundary data here and converts it actually into the corresponding with the opposite side race with the opposite side okay and then we have some sort of boundary space Sort of boundary spaces on all the elements in the mesh. And we're looking for a solution now in this product space. And we have the Cessenand and DePrey's classical formulation of the ultra-weak variational formulation. And it satisfies this kind of cute equations. And yeah, this is. This is sort of how it's programmed. You choose some basis functions here. That tells you what you put here and actually what you put here, because we're going to take the same spaces for these two. So this one is reading off from the basis, and this one is just, well, these things are dense in L2, so that's the same. So we don't, yeah, so we get a A there's some bars missing here. Oh, yo, yoi. You know, I went through this last night, but unfortunately, Lise Marie took us out to a Mezcal restaurant, and I blame this all on her. Lise Marie and Donnie, too, I should say. So, anyway, this is it. And then, well, then you can, so then you have. So then you have to choose the basis functions, and the basis functions have to be solutions of the adjoint Maxwell equation. So they are plane waves, but slipped in here are epsilon bar and mu bar. And it's important to center these somewhere in the element because when we have absorbing medium or PML, then we have exponential decay or exponential increase, depending, and it's easy to And it's easy to overwhelm the system with if the, say, the PML is far from the origin, you're going to get large exponentials, which would cancel with small exponentials, but it's good to have that extra little piece there, but it really makes no difference to the formulation. And we, yes, let's see. I should have probably written this on the slide, but to be solution. On the slide, but to be solutions of Maxwell's equations, you need that dot A is zero to ensure a divergence-free field. And that means that for every D, for every direction D, for every direction D here in the plane wave basis, there's two A's. And you get to, I mean, they just. And you get to, I mean, they just have to be orthogonal. Well, they don't even have to be orthogonal, I guess, but they just have to be two, they just have to span the space of solutions of that equation. And yeah, so these are plane waves, these are plane waves moving in a direction D, and you get to choose the D's, and you get to choose how many of them you want. And then, well, so there's Ralph in his, Ralph Elizabeth. Ralph Ilaria and Andrea have in their paper a set of directions which they use to prove convergence of the method. We don't actually use them because they're not sort of, you can't just increase by one. It's my understanding, so Ralph can correct me, but you can't just increase by one direction. So we want to have five directions on this element, six directions on this one, 27 on that one. We want to be able to. On that one, we want to be able to move them around. So, we actually use these Hammersley points for no particular reason except these guys provided software to compute them. So, we use between one and I think 1,200 directions, depending on, but maybe it's 1,500. Anyway, it's a reasonably large number of directions. Okay, so the number of basis functions varies from element to element. Varies from element to element. And as I'm going to summarize in a couple of seconds, the convergence theory says that as thought of as an H method, that is decreasing mesh size to get convergence, the ultra-weak variational formulation should converge at a certain rate and the order is roughly proportional to the square root of the number of directions. Of the number of directions. In three dimensions. Yes, this is all three dimensions. Yes, yes, yes. That's correct, in three dimensions. So, yeah, you can assemble over integrals on faces only. And if you have a flat face, then you can just use a formula for the integral. So that makes it relatively quick to assemble. In fact, assembly is usually a vanishingly small part of our overall computer. Part of our overall computation because the matrices are sparse, that's good, but often very ill-conditioned. So, generally, we have to control this. That is what we always do is we pick P on an element as large as we can without destroying biconjugate gradients, which we use to solve the problem. And so, provided you don't choose these number of directions too large. Choose these number of directions too large. Biconjugate gradients. I don't know if you've ever watched, I've watched thousands of times biconjugate gradient convergent, and it goes. And it's always very nerve-wracking when it goes up, then it usually comes down. And if it doesn't come down, well, then after a while, you just hit control C. So anyway, so this converges if the condition number's not too large. The condition number is not too large. And we, Timo might say more about this, but I think it's a sort of probably not very interesting. What we do is we just kind of just take a random, I mean, take an element, and we just figured out how many plane waves gives a condition number of like 10 to the ninth. I mean, these are big condition numbers, right? 10 to the 12th, something like this. And then we developed a little formula, which has got no... We developed a little formula, which has got no real theoretical validity. And we use that formula based on the size of the element to predict the number of directions. And, you know, we should all be talking about artificial intelligence, right? So I always thought that, well, this would be a good place to do, but I would love to know from you how would I train my AI to pick PK? I mean, if we could do that, then funding. That, then funding would be assured for the, well, anyway, yeah, forever. And of course, you can extend this to other systems. So Helmholtz equation, of course, and fluid-solid interaction problem, you know, elasticity, well, infinitesimal elasticity. Yeah, and I think also. So what is it? Acoustics? Aeroacoustics? So, you know, there are some, yes, some systems here that can be solved. Okay. Okay, so for a long time, there was a convergence proof in Cessna's thesis, which said that on the boundary, certain things, well, there was a uniqueness proof saying. Things well, there was a uniqueness proof saying, Well, okay, there exists a solution, and then a convergence proof which says on the boundary the method converges. And it took a little while, long while actually, until I think Ralph and to some extent Annalisa Bufa and I, Ralph and his co-workers, realized that really ultra-weak is a Treft's DG method. Once you have Trefts, Method. Once you have TrefsDG, then you have all the machinery of Trefs-DG to get stability. And then you use duality, you can get convergence. So it's important to kind of compare ultra-weak to Trefs-DG. And if epsilon and mu are real, so the Trefs-DG method for Maxwell's equation is equivalent in certain case, in one certain case, to the... To the ultra-weak. And I'm sure we're going to see a lot more about Trefs-DG. So, in the Trefs-DG method, so assume epsilon and mu are real. The reason for doing that is then the space or the solutions of the adjoint problem are also solutions of the original problem. So then you can say, okay, I'll use, I call this prim up here, primary problem. Primary problem. These are the plane waves without the conjugation. You can look for a solution in this primary space. So plane waves, solutions to the primary problem with pK directions on each element K. And then these following the usual IPDG type approach. IPDG type approach, you can obtain a Maxwell equation, a Treft DG method, which where the solution satisfies some system, which is not a Petrov-Galerkin, it's a Galerkin method, which both of these are in the primary space. Okay? So, so the sec. So the sequ sesque, I'll just put this up here. So the sesquilinear form is really developed in a very similar way to what I showed before. You take the solution of Maxwell system, multiply by a test function, integrate by parts, but then you start adding penalization terms and so on to So on to guarantee the jumps in the electric field are controlled. And the variational formulation looks quite a lot different. It involves jumps, average values, and jumps in the fields. And, well, it looks like this. So there are terms which you can imagine, well, you can see they came from integration by parts. There's E times H, or. H or and H times E, and then some other terms, which are perhaps a bit more mysterious. This FI, I didn't really find all this because I thought probably this would all have been defined earlier. I'm sorry. Fi are the faces in the interior of the mesh. So they're not boundary faces. Boundary faces have to be handled slightly differently, as you saw with the queue operator before. And then there are. And then there are some stabilization terms that are usually added to the IPDG. And I put scale here. That was a note to me to scale these equations, which I did, but I didn't remove the scale comet. So, mezcal. So, this is, so you see that there are some alphas and betas here and a delta, and these parameters can be chosen. Can be chosen according to your whim. Although I think that for the HP method, Ralph and his co-workers suggest choosing them proportional to the inverse of the mesh size on a particular element or on that face. But you can also choose them to be just constants. And if you choose them to be alpha, beta, and delta to be a half, To be a half, then algebraically you get exactly the, well, with an overall constant, but this is proportional to the ultra-weak variational formulation. So yeah, these are, this is equivalent. So then, yeah, so then that's very nice because you can then, it took a lot of work, but if you can then prove convergence of the method, because you have all the techniques. Of the method because you have all the techniques available to you for IPDG type stuff. And so Hipmey, Moriola, and Perugia, in this very solid work here, proved convergence of, well, I would say they proved convergence of the ultra-weak, but actually they proved convergence of TRESTD. So what did they need for these proofs? They needed something called a Morowitz type. Something called Amorowitz-type estimate, which is a very nice continuity band, very explicit continuity band for the solution of the problem. That in turn meant that they have to be on a star-shaped domain, and so that imposes certain requirements, but this actually, to my mind, was the big breakthrough. big was the big breakthrough because this is these were known these Morowitz estimates are known for well since Morowitz for for the Helmholtz equation but were not known for for for for Maxwell until until well this is this is not really quite the paper but but they had a paper which is referenced here on that then they needed um estimates for for the approximation properties of hell of plane waves Of plane waves and the magic name there's Vecwa, who studies long ago. And it was long thought, at least by the people I talked to, that these methods didn't work in 3D, but they do. So they got estimates for that. And then they used a DG theory to give stability. And you can do duality and so on and so forth. So very nice convergence proof. And that I'm I'm not really doing this justice at all, but I'm just going to say that there are some measures. There's definitely some constraints on all this, but they proved that with epsilon and mu constant, if you have sufficient regularity in the, you have high regularity in the solution, and so this is r is the regularity, and then you take enough directions. Take enough directions, but you see why I said that pk is roughly q well it's pk squared pk is roughly square root of pk is roughly q and q is related to r and r is the convergence rate here or r minus three halves. So increasing the number of directions gives you higher and higher order and that and they have also looked I think at HP methods as well. As well. I hope I did this computation correctly. It seemed I needed 169 directions to get fourth-order convergence, but that's actually a lot more than we find in practice. But here's something that was very useful to us, namely general element shapes are allowed. So the elements making up the mesh have to be Lipschitz, star-shaped, regular. You have to look in their paper for an exact statement. But what it means is. But what it means is that we can, in our code, use tetrahedra, yes, of course, prisms, yes, cubes, and what's the third one? Oh, pyramids. So we can use all those, and they're very, very useful for filling out space in certain practical situations. So that's well, for that proof, you need to do. proof you did you you needed also the domain to be starlike but that um but for for the elements yes i think there was a restriction on um special type of starlike domain and but i mean for finite element or for any but it is interesting and and so this is a nice thing okay now the problem is with absorbing media which we which we see um and in the pml maybe uh the pm PML, maybe. PML is a bit, oh, sorry, what's PML? Perfectly matched layer. That's an absorbing boundary sort of absorbing condition that we use to make the waves outgoing, scattered waves outgoing. And that's built into the scheme or into our method. But it does produce, or it does involve epsilons and mus that are complex. So in any case, for absorbing medium, forget the PML. Absorbing medium, forget the PML, absorbing media means epsilon or mu or both have a non-zero imaginary part. And then the ultra-weak and the TrefsDG are not equivalent because, well, the ultra-weak solution is not computed, right? We don't compute that. We compute this X thing on the boundary. If we want to get E, we have to solve using the primary basis functions a local problem. A local problem, usually with least squares, but it's only on one element. But the Tref's DG method doesn't apply because they require the same space for the equation and for the adjoint variable. If you do this, if you require this, then the fundamental inequality or fundamental equality kicks out. kicks out this type of term. And again, I hope I've got the slides right, but it kicks out a term where you get a difference between mu and mu bar, epsilon and epsilon bar. And that's not a problem. And in fact, in view of, what did I say? Why was it in view of something? Oh, in view of needing to use this sort of post-processing, we. We probably will go to using this fundamental inequality. It kicks out this volume integral term, which is no problem on a tetrahedron, going to be a true tetrahedron or any other object with planar faces. But we will have to think about numerical integration, I guess, particularly for this term. Term. But so if we put this in, and if perhaps DG puts this in, then again, we're the same. And we haven't really done enough on this to know if it's really useful or anything. So, yeah. Comparison, I apologize for these slides, which are far too full. So we were told you must compare to finite elements. Compare to finite elements. And that was a very good thing to do. So we used NGS Py and NetGen. I know we have an expert here, or two experts, possibly, or more than two experts. I don't know. A multiplicity of experts on NetGen. And that has edge finite elements, which are the standard elements for finite element analysis for Maxwell's equations. They're available in principle at all orders, but in... In principle, at all orders, but in any rate, for the orders we want. And we chose a problem where we knew that ultra-weak would work better than finite elements. Of course, otherwise, when we were trying to publish a paper on ultra-weak, so namely a penetrable sphere with a complex epsilon chosen at random, essentially. There's a thing called the Mie series, which allows you to predict the far-field pattern using. Pattern using Hankel functions and stuff like that. And we used tetrahedral mesh, so the two methods would be the same sort of thing. But the main bad thing we did was to use the direct sparse solver from NGS Py. And so that limited us to about, on my computer, about 1.2 million or 1.3 million degrees of freedom. And then the computational domain. the computational domain is is we're using the units unit the unit uh unit unit size cube as the scatterer on the unit sphere I'm sorry and we put the PML a little bit away from the from the NetGen has PML so we put the PML a little bit away from the object here are the parameters Parmax is our code and so we And so we decided to use Melank and Sauter's sort of choice of parameters, namely as we change lambda zero, that's the wavelength. So the request was what happens with different wavelengths. And we choose h, the mesh size for ngs pi, to be like this. And we just vary p, which is what they say to do to increase. To keep a roughly uniform error. And about 1% in the computed RCS. So here's what happens. This is the error. This is 1%. And well, ParMax is usually a little higher, but sometimes not NGS. I mean, this depends on the relative choices as you vary. As we vary F, Parma. As we vary f, Parmax is moving, is choosing different numbers of plane waves on elements. As we vary f, net gen is choosing different numbers of basis functions, different orders of basis functions. Fortunately for us, the curves crossed. Here's, what is this? Number of degrees of freedom. So this is the number of degrees of freedom with Parmax, and it is going up, this dispersion error. Dispersion error. But NetGen finally started going up faster. I mean, it does go up faster. You have an element, right? The element needs n cubed, p cubed, and we only need p squared. So we know that this is going to happen, but fortunately it happened before we ran out of computer room. So, and the computer time is here. This was using an old version of ParMax. So we claimed that we would be actually less than. We claim that we would be actually less than this if we did it today just because of some technical problem. And below this, at 10 to the minus 3 gigahertz, so the sphere is one meter, whatever that means. And the gigahertz tell you the wavelength. So this is very long wavelength for us. We always think of Parmax as being a higher frequency solve. Frequency solver, but not high, but higher. And anyway, 10 to the minus 3 Parmax fails. Of course, finite elements, perfectly happy. And that's something we'd like to figure out. And I'd love to talk to somebody about how to get around that. I mean, frankly, for us, it's not a problem. We're not ever asked to solve that problem, but it's great sort of that we can't go lower. What's sort of interesting is that you get a far field pattern that looks like it's for a much bigger object. I mean, it all converges, everything's fine, but it's for a bigger object. Then you look at the solution near the sphere, that's where the very small tetrahedra are, or smaller tetrahedra. It's all random. And it sort of fills out a sphere, roughly, in space. Roughly in space, and that's the far field. You get a far field pattern for this sort of bad area, which that's bad. It's a bad result, actually, for many reasons. Because you want, I mean, it'd be much better if it just failed and refused to converge, right? You don't really want to have it converging and giving the wrong answer. Okay, so just to very quickly, well, not very quickly, maybe minutes. So we noticed in 2D and certainly in 3D, very strongly in 3D, Certainly in 3D, very strongly in 3D, the company pointed out to us that in certain cases we get the wrong answers. And they're important cases. So in particular for patch antenna. Patch antenna is modeled as a perfect electric conducting sheet. So it has no volume. It's just a portion of a plane or circle or sphere, I mean, or something like that. But you see this in 2D as well. Like that, but you see this in 2D as well. So, so I'm going to switch very briefly to the Helmholtz equation. Here's the model problem. The wave is coming in this way, and it should, obviously there's something, there's a strong singularity here. Finite elements doesn't really notice. And in a way, UltraWeak is working well as well. It's hard to see on these pictures, unfortunately, due to These pictures, unfortunately, due to we should have changed the color map differently. But in the error, so this is the, this is, oh, Comsol is, of course, the finite element library that you can use. I would now use NetGen because it's free. But anyway, you can do this easily enough. And here, and on this one, you don't really see it, but the difference between these two solutions, the ultra-weak result. Ultra-weak result is not symmetric around this result. There's a little yellow area here showing that there's more error above than below, and there's the same sort of thing at the back end. It's not behaving right. So, and we can look at the absolute value of the console minus ultra-weak. Again, at the very tips, we're not seeing the right field. And so, what we did is, well, what we did is switch to using finite elements in this. Using finite elements in this region, and based on the condition number of a certain matrix in the ultra-weak system. And so, because we're refining heavily around here, you get this big condition number because ultra-weak conditioning gets worse with these smaller elements. And then we put finite elements in there. And now the two fields are. Fields are looking much better. There's no, I mean, of course, it's error, but there's no sort of preference, there's no strange behavior around the points, around the edges there. And we wanted to do this in 3D. And this is another area where I would really very much like help. So I'll tell you what we did. And in private, I'll tell you what the drawback is. What the drawback is. No, I might admit it on recording. So sometimes we see poor performance of plane wave ultra weak. Now I'm using a new thing, plane wave ultra weak, near sharp edges. And we to resolve the field there, we need small elements. Once you have small elements, you have conditioning issues. You get back into this 0.01, I mean this 0.101 gigahertz type of element size compared to the wavelength. Element size compared to the wavelength. And so we wanted, we decided, and also I should say that antenna people want to put strange sources in there, and it's hard to do that with ultra-weak. So we wanted to be able to use finite elements in small parts of the grid. And we would like to maintain the structure of the plane wave ultra weak. We want to continue to use by CG. So my I'm allowed to tell the story. No, I mean why did I start using this strange method? I was actually working on finite elements. I mean I wrote papers on finite elements and so on and so forth. The answer is I could not solve the finite elements. In 1998, I could not solve a big finite element system on a convenient computer that I could get access. I could have probably applied for something on a cray, whatever it was then, and whatever, but that was just like far too much work. But that was just like far too much work. So, but with UltraWeak or Trefts in general, I think, you can use this really simple YCG algorithm. I mean, you know, the code is sort of, even in Fortran, it's not long. So, oh, and that makes it easy to parallel too, because all you have to do is matrix multiply, and you can program parallel matrix multiply. Program parallel matrix multiply. So by CG, we wanted to use by CG, and we wanted, and I should mention at this stage that another approach is, of course, generalized plane waves, which is not what we're doing. And there are other approaches, I think, which I'm hoping I'm going to learn about here. But yeah, this is after conversations with Lise Marie. But what we But what we actually did is the following. We just approximated this map, this impedance to impedance map, by finite elements. So we defined earlier, given boundary data, impedance boundary data, and the adjoint Maxwell system, then we can redefine the map FK to be whatever you got here, but with a minus sign. Got here, but with a minus sign. So it just is the impedance data. And so we decided, okay, we can just approximate this by finite elements. So if you're given some, I haven't defined what these are yet, I will. If you're given some finite element function on the boundary, some discrete function on the boundary, because remember we're function on the boundary, because remember we want to connect to ultra-weak in a simple way. So we're going to use the same fluxes on the, or these same unknowns on the boundary. If you're given those, we want to solve in the volume finite element space on an element with this boundary data, and it turns out that this is the simple variational formulation for that. This is, again, with the finite element space. With the finite element space in the interior of the element. And so we want to define, so then we would like to define FKHY to be this, but this is not ideologically sound in the mathematical sense because we're using finite elements in H curl, and we can't, officially, we can't evaluate that. Of course, you can. Evaluate that. Of course, you can, because it's finite, because it's a polynomial. But so instead, what we did is say, well, okay, the y includes the nasty term. So we'll just rewrite, and this is probably where we get the trouble, Frank. We'll just replace this data here by the Y, but then we have to subtract off a bit more here. So this is the new mapping. This is the new mapping. And then for the continuous problem, we have this isometry lemma, which somehow I thought was useful, and it would be useful. And to have the same property for the finite element ultra-weak, we would need that this and this are equal, but we get these sort of slush terms. So these have to cancel, and that means the p has. And that means the P has to go away. And so, one possibility, and I think this is where we make a possible mistake, is, or not mistake, but I think I didn't choose the right thing here. If Z is constant on each face, which we'll choose, and if we have this flux, this trace condition here, then the finite elements are also given isometry. Given isometry. So then, so here's what I think I'm going to show you this one. So this is just using pthort and netlec edge elements on each element, discontinuous. And then, did I say what I was, oh, and then Ravia Toma of element P, size P on each face, so discontinuous across. So discontinuous across the edges. And we could, I've tried also the full elements, full polynomial degree, but I didn't try very hard, but it didn't seem to work very well. So anyway, so now our finite element method. Our finite element method is now this. We have the Raviatoma on the boundaries. We compute this with edge elements, and then we confidently expected glory. So here's what actually happens. Well, here's what, no, I'm not going to show you what actually happened. Here's what happens. This did actually happen. So there's a lot of things here. I wish I could read what they are. There's sure that we're using. That we're using Q minus 1, 0, aha, 0.99. I said 1 was PEC. That doesn't work. 1 gives us instability. So we use a small change from 1 here. So that's one thing where you can see that there's some issue. I mean, the results for 0.99 and 1 are probably going to be within discretization error, but nevertheless, that's an unpleasant thing. An unpleasant thing. And then we use, so each of these is three lines. And we're using just a plane wave on a cube, making sure we're not in the direction of the plane waves in the basis, right? So we don't want to be there. And I'm going to redo this slide, I guess. I'm going to redo this slide, I guess. If the owner can't see which is what, okay. I think, yes. This one here is this is, no, I don't know what it is. One of them is finite elements. Gosh. Yeah, I think that's. Oh, no, no. One of them is pure ultra-weak. That's with 15 directions. I remember I said I had 169 I thought I needed. With 15 directions, you get this fourth order convergence. And so it's very nice. This is with finite elements, pure finite elements, with, I think, one. One, order one, maybe order two and order three. So you can see, you know, as you increase the polynomial order, you get good convergence. With three, you get fourth order convergence. You can see here the bad things are happening. They're starting to diverge. That's due to conditioning problems. But so that's good, right? This is the this is the Number of iterations by CG for various different cases. And we ran this with the credit card problem. The credit card problem is exactly as it says, a credit card modeled as a completely as a surface in the mesh. And I'm told that this credit card, sacred to me, this credit card. Sacred to me. This credit card is metal, actually. So, this is a PEC credit card. Anyway, this is, you can see we have small elements around the edge. We put big elements everywhere else. We have a certain number of directions. So we have finite elements in this sort of layer around the outside. This only went up to 28 direct in the rest of the grid. And this is a different. And this is a deficient picture because it shows an RCS, a radar cross-section, but it doesn't show you what we would have got had we just used plane waves by themselves. We would have to, and I apologize about that. So, yeah, so I don't know what the takeaways really are. For, I mean, this is for finite element ultra-weak biceps. Week. By CG slows down, particularly in this, in this, very badly, in this important case. And I guess a better preconditioner is needed, or maybe a better choice of boundary space. We don't have any convergence theory for our finite element method. And this is out of left field. You don't see this one coming. They didn't mention it. But our user, we have one user, and our user wants to model antennas and to model antennas. Antennas and to model an antenna, you need to excite the antenna. And to excite the antenna is something that I hope to learn from Igor how to do that. But because this is sort of in the arcana of electrical engineering, they just say they use blah, blah, blah method for doing that. And it's not quite clear to me anyway what that is, but we need to do it. And Timo will talk on Thursday, originally straight after me, but talk on Thursday to give some. On Thursday, to give some, when I say real numerical results, what I mean is some results. And in particular, just as an advertisement for the future, we solved a problem like the one that I showed you at the beginning, an aircraft at a sort of interesting frequency, a few hundred, maybe 400 wavelengths long. Long. He solved that on a civilian supercomputer in Finland. I mean, when you see how many resources were used, you'll say, okay, that's not going to happen in your living room. But it's possible with just a sort of an amateur code like, well, you know, code like this to actually solve very, very, very, very large problems. And And please. So that's the end. Thank you. So thank you very much for your talk. And I guess I'm monitoring the chat as well. So if there's questions online, please raise your hand or write in the chat. And you can unmute and talk as well. We can hear you. But maybe we can start with questions in the room. Questions in the room? Wait a second. I'm going to give you the microphone so that people online can hear your questions. Yeah, yeah. You say there was initially some doubt about the 3D case, the proof for the 3D case, and then some additional tricks were applied to handle that as well. Well, it's not, I mean, the proof of the 3D case required, I would say. required, I would say, two technical but interesting developments. Namely, one was this refined sort of continuity estimate, which had not up till that point been proved. So Morowitz was done for Helmholtz a long time ago. It resisted, unfortunately, for a long time until they managed to do that. And the other. that and uh the other are these uh vequa type estimates some some sort of some sort of error estimates for for polynomials uh for for for for um plane waves on on uh on on on tetrahedral and so on um i guess that in in cessana's thesis there is information there is a convergence theory there but it's uh yeah i mean there is a convergence theory there too so the the main thing was really this morowitz thing i think yeah Well, thank you, Peter. Maybe I'm mid-fast. Sorry if I missed it. But there's always this renders issue of the null space of the kernel operator. So how do you deal with that? Well, because we're, you know, yeah, that's a good question. And actually in Ralph's paper, they, well, I'll tell you what, I'll tell you what we didn't do. We didn't do anything. We didn't do, we didn't do anything because we have plane waves, so they set it, so the field has zero divergence. And so it's local, yes, exactly. So what they proved, they looked at, and now I'm digging rather deep, but they looked at the dual space of HDIV and they proved convergence in that, which is in some way like. Way like saying that you're controlling the divergence very weakly. So they were able to do that. Yeah, that's so. So we don't, practically we don't do anything. Theoretically, there is this convergence result. But it's in a weak norm. One very quick thing. Is there any number that goes down? We don't do adaptive refinement in our code. There's at least two papers that I, well, there's two papers I know, so I say there are at least two papers. One is by Paul Houston. Unfortunately, I don't remember his co-authors. They looked at adaptive approach to TREFS-DG. One interesting thing that's in that paper, and it's also an experience. And it's also an experience we've had just recently with Virginia that taking a mesh-dependent weighting on the faces doesn't seem to have very much, doesn't really change things very much. This is what we experience. So we still use a half as the weight. But where was I going with this? Oh, yes, Paul Houston says it's a nice paper. We tried. It's a nice paper. We tried with Tim Warburton a long time ago to do adaptive methods as well. But, you know, there's the problem of conditioning. So, I mean, in the end, it seemed to us that it was just best to use the biggest space you could have. And then, you know, on a particular grid. We published papers on it, but I wouldn't say that we didn't really. That we didn't really have a good answer to that. Yeah, that definitely needs more. Okay, we have two questions online. I see you, Ralph. Ralph, you raise your hand. Is it my turn? Well, I cannot hear your voice very well. Lise Marie. Okay, so let me ask my question. Hi, Peter. Great to be able to hear, listen to your voice. To be able to listen to your talk again after a long time. A question concerning this coupling of ultra weak. He's asking, for the antenna problem, are there any dimensional models where point of domain would be in higher dimension? Definitely. Yes, definitely. So there's what we can do model. So there are models of antennas, one-dimensional antennas. I can't say. I can't say. And I think people do use that, although we would probably want to mesh around it because the singularities might cause us trouble. But yes, definitely. Thank you. And so, Ralph, do you want to unmute yourself and ask your question? Can you hear me? We can hear Ralph. Groshing, we cannot hear you. If you were trying to talk, we couldn't hear you. You were trying to talk, we couldn't hear you. Yeah, I was not talking, but Ralph has talked for a minute already. Okay, so we could not hear Ralph before, but now we could just right now. So, Ralph, do you want to go ahead? So, can you hear me now? Yes. All right. Okay. So, then again, Peter, it was great to be able to listen to your presentation after I had not listened to you for quite some time. Thanks for the. Thanks for the talk. My question concerns this final element: ultra-weak coupling. In the case of non-absorbing media, can this be understood in the Treft DG framework as using plane waves in a subdomain and using conventional polynomials? Conventional polynomials in another subdomain? Yes, yes, I think so. Although I admit that I haven't really looked too much. Well, certainly it's finite elements in one subdomain, plane waves in another. And thank you for listening, by the way. The actual method seems a little difficult. Seems a little difficult for me to relate to a standard finite element method, I would say. Yeah, that's all I would say. But I mean, it is a finite element method, whether it's what that's sort of what the problem is that we're having, is it's not a very standard finite element method, so developing preconditioners and so on is hard. Mm-hmm. My point would be that once you can fit the method into this DreftDG framework, this can pave the way for more or less rigorous analysis because then you have all the tools available. Yes, indeed. And so, yeah, we certainly thought about doing an IPDG or TreftsDG. Doing an IPDG or TreftsDG method for Maxwell, of course, and that's well known, I think, in the finite element part. But then I think you'd need, I mean, we also thought about just using conforming finite elements in the finite element part. That would work, that would, well, I say that would work, I don't know, but that's an obvious thing to do. But in both those cases, I think you would be needing some sort of preconditioner. Some sort of preconditioner which sort of would foil the simple use of By CG. Our idea was to do as little work as possible and use By CG. But we did play with subspace preconditioners for edge elements and decided not to go ahead with that. Okay, then the main challenge is the solver. Surely. Okay, thank you. I think. If not, I propose that we wrap up here. We can thank Peter again and then we're going to have a coffee break and we'll get restarted in 20 minutes. 