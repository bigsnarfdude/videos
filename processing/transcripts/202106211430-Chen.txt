And its applications. Thanks. Good afternoon, everybody. And thanks for the invitation. And thanks, Robert, for the introduction. Today, I would like to share some of our recent work in the intersection between optimal transport or multi-marginal optimal transport and graphical models. So, this is joint work with Dr. Johan Carson's group. So, it's a collaboration between two groups. Group. So I prepared an introduction to optimal transport. I don't think this is necessary anymore. So I would skim through this just to warm up. So optimal transport had several formulations. So the original formulation is the modest formulation and the optimization variable is a optimal transport map T. Okay, you want to minimize this cost. Then another formulation which is easier to handle is the cantology. Is easier to handle is the cantology formulation and c here is the transportation cost of moving unit mass from x to y and the cantology formulation is a is a linear programming and the optimization variable is the joint probability between the given two marginals. And when this cost is the is basically the Euclidean distance to the power p, then this induced Watchstein distance. The watches time distance, and uh, yes, and uh, yeah, and uh, there are also other than this module formulation and the cantotic formulation, these are known as the static formulation of optimal transport. There is also a dynamic perspective of the optimal transport. Most famously is this Banamou-Brinier fluid dynamic formulation. And this in this formulation, you can just imagine you have a body of fluid and compressed. And compressible, so the density can change. And the goal is to choose a velocity field to drive this fluid flow initial distribution to a terminal distribution. And you want to do this in such a way that this action integral is minimized. And similarly, induced for just you can see directly from this fluid dynamic formulation to see how to formulate this. To see how to formulate this stochastic control formulation, basically, in this static stochastic control formulation, you can view that you have a trivial dynamic system and you have some uncertainty in the state. And the initial state has this marginal distribution. And you want to find a feedback control strategy to drive this dynamic system to a target state, which has this prescribed distribution. So, this is the stock. Distribution. So, this is the stochastic control formulation. And optimal transport is very useful due to many reasons. And one important reason is the beautiful geometry it induced. And one aspect of this is the metric. And this is the slides I like to use very often. It's basically to show you this Washstar metric has the weak continuity, which is a very important property. Which is a very important properties for actually, I mean, it's very important in many other aspects, but it's also very important in engineering applications, especially for single processing, because the distance between in this underlying space actually has some physical meaning. For instance, if we view this three PDF as the power spectrum of three signals, then this mode basically represents the frequency of the signal. Frequency of the signal. So, if you use other metric to compare, then you cannot see that these two signals are closer to each other because they are closer in terms of frequency. But if you use the Washington metric, you can actually tell this is the case. And another important property of the Washington geometry is that the displacement interpolation or the geodesic actually has some very nice property. Some very nice property. For instance, here, if we have this 2D distribution, if these are the two marginals, if we use the naive Euclidean interpolation geodesic, this is what you get. It has this fade-in, fade-out phenomena, which is not nice in application. But if you use the wash scan geodesic, then actually you see the movement of the mode. And this is very useful in re-applications. And useful in real applications. None of this, what I have discussed, is going to be used in this talk. So, this is just an introduction. So, sorry. So, this talk is basically going to be more on the discrete optimal transport. So, in the discrete setting, basically, you no longer have these continuous distributions. What you have is basically you have a bunch of points. And this point, so these are the support of these marginals. Support of these marginals. So, this probability distributions, the marginals, they become probability vectors. Okay. So, basically, the data we have for this problem is basically two probability vectors, mu1 and mu2. They basically tell you the distribution of the mass of this initial and targeted distribution, but on finite support. And the optimization variable now is really a joint probability matrix, is a distribution, but it's a matrix now. Distribution, but it's a matrix now of this size d1, d2, and the c here is the transport cost. Each entry of this tells you the transport cost from moving from one point to another point. So this problem can also be viewed as a network flow problem or bipartite graph. But this is basically the problem we care about in this code. So it's a very standard linear programming problem. Nowadays, actually, most famous algorithm for this, I think, is this called a single algorithm. It's also equivalent to the, I mean, it coincides with the Schrodinger-bridge problem. So in this problem, basically, you just introduce an entropy term to regularize this. So initially, you have two linear constraints and one convexity constraint, and you have a linear cost. Now, if you add a entropy cost. Entropy cost here. Then, this becomes a strictly convex optimization problem. And this is one advantage of this, but I think the structure of this problem makes it this is not the only advantage. What makes it special is that it induced this single iteration. So, basically, if you consider this problem, if you do the Lagolangelo analysis, basically, you replay. Lagrange analysis: basically, you replace this constraint by a Lagrangian multiplier, then you see immediately the optimum solution to this problem becomes this. Okay, and this k here is basically e to the power minus c, and c is the transport cost matrix is a given, okay. And you just need to the goal is to look for two vector positive vector u1, u2, such that U1, U2, such that this B, which is written in this way, would minimize this. Question? No? Okay. So this is the optimal solution. And the way to find these two factors, U1, U2, is also very simple. Is use the single iterations. Basically, what you do is you start from maybe one vector that you want to be one vector. To be one vector, then you do this operation to get u2. Okay, so this is a matrix vector multiplication, and this is a point-wise division. Then, after you get u2, you do the next step, very similar, then you get u1, then iteratively doing this, and eventually you will converge to the optimal solution, the u1, u2, you want, and you get the optimal solution to this problem. And this algorithm is very simple. This algorithm is very simple. It's very easy to implement because it only involves matrix multiplication and pointwise operation, which is very simple. And that makes this algorithm really popular these days. Also, this algorithm has linear convergence property. And this can be established by using the Hilbert metric. Okay. What we consider in this paper is the multi-marginal optimote. The multi-marginal optimal transport problem. So, in this setting, we would have a bunch of probability vectors: mu1, mu2, and more than two, let's say. And this is the marginal constraint. So, what we are looking for is a joint distribution of all the marginals. Okay, therefore, it's a tensor. It's actually a G-dimensional tensor. Okay, and we want to minimize. And we want to minimize this cost. So, this is the cantology formulation of the multi-marginal optimal transport. I think what Luke had discussed this morning is more like the model formulation. So, this is the cantology formulation of optimal transport, multi-marginal optimal transport. I want to emphasize a few differences here. The most important one is that now we no longer need to have access to other. Longer need to have access to other marginals. So, here we actually assume only a sub, so the problem has a J dimension. Okay, so the optimization variable is a J dimensional tensor, but we assume only part of these marginals are given. So, you don't necessarily have all the marginal to be given. You just need some of them to be given. That's how far open. Okay, we have some background noise. So here, this problem is a standard linear programming problem, but computationally is very expensive. The main reason is that here, the B, the optimization variable, is a J-dimensional tensor. And the number of variables, as you can see, is D to the power J. And this is really not good, especially when J is large. If D is equal to plus. But if d is equal to let's say 100, then you can never go up to let's say j is equal to 10, then you are screwed. There's no way. So this is not good. So, but fortunately, in many applications, in many applications, what we have, so you see, the only data we have for this problem are these marginals, and then is this a cost matrix, cost tensor C. Fortunately, in many applications, I would say in majority of. Applications, I would say, in majority of applications involving multi-marginal optimal transport, the C has a structure. It's not just a general tensor C. It has a structure. For instance, the famous Washington Berry Center problem, the cost tensor actually can be written as a pairwise summation between your marginal and the barycenter you want to calculate. So it really has some structure. So, it really has a sound structure there. This is one type of graphical structures, and there are many other structures you can explore. For instance, you can talk about the low-length structure, you can talk about the sparsity, maybe there are more. But in this talk, we would just focus on the graphical structure of the cost. So, this is what we, the real problem we would study. So, it is a special case of multi-marginal optimal. Of multi-marginal optimal transport, discrete multi-marginal optimal transport. Okay, and you are given a bunch of marginals, and the goal is to look for a cost, to look for a joint probability tensor to minimize this cost. We assume this cost tensor here, okay, is a J-dimensional tensor, but it can be decomposed according to a graph. Okay, it's a graphical cost. So, this is one example here. So, in this example, Example here. So, in this example, the problem dimension is six. So, J is equal to six. Okay, so this C is actually six-dimensional tensor, but we assume the Cx actually can be decomposed according to this graph, which means it's equal to the summation of a lot of factors, and each of this C alpha corresponds to one edge of this graph. And and each edge because it only involves two nodes. So this is much better than the node structure C. I mean, the general C can always be decomposed according to a graph, but it's a complete graph. But here we can see the graph which is not complete. So we have some advantage. And there are many examples of this type of problem. Of this type of problem. I'm a little confused. I don't understand why the general C can always be decomposed as a graph. Because here, for instance, let's forget about X3 and X6. So we only have four nodes. So any C can be decomposed in this way. So you're saying any function of four variables can be written as a sum of functions of two variables? Sorry, I think. Good point. So, here, actually, first of all, I think yes, we can, but here, actually, here we consider this as a factors. So, I think maybe we can. So, I think maybe we cannot always decompose according to the edge, but we can decompose according to the full graph. So, here, the whole thing, if you have a complete graph, we view this as a clique. Okay, it's a complete graph. So, actually, let me take this back. Not always as edge, but you can decompose this according to a graph. But if you have a complete graph, basically, this Cx is equal to C alpha X. There is only one alpha. There is only one alpha. Okay. But in general, if you have some structure, for instance, here for this specific graph, there are several ways to decompose this. You can decompose this according to every single edge, but you can also decompose this into this is one factor, this is another factor, and then the whole thing, this part is another factor. That is the same. Okay, yes, thanks. Um, so this are several. I um sorry, I still don't get to uh how you answer Robert's question. In general, are you considering clicks of graphs? Are you considering hypergraphs? Because, in general, of course, you cannot write a function of four variables as sums of twos. So, are you considering like in general, you can consider hypergraphs, or perhaps you look into clicks? No, we actually consider the original graph, but Original graph, but uh so here the x alpha alpha alpha doesn't have to be a set of two entries. Okay, so it doesn't have to be a set of just edges. It could be like hypergraphs, it could be something. So it's a hypergraph if that's the terminology, yes. Okay, all right, thank you. Sorry about this because the originally what we did is we did everything in the factor graph, so we can see the factor directly, but I feel it's a bit complicated. But I feel it's a bit complicated to use factor graph language in a talk, so I just use this right. Okay, thanks. Uh, so there are several examples, for instance, the washing sign very center problem. The four marginals are given, and your goal is to calculate the average of the right. So, here we create a new node x1. So, the cost function actually is equal to the summation of this four of them. So, this is the very simple problem. Very simple problem. And the geodesic problem also similarly. I mean, this is the discrete geodesic. So if it you can put many more there, but basically what you care is the summation of this consecutive node, the cost. Another interesting example is what we call the Wascherstein spline. So in this problem, what we are trying to do is given a sequence of distributions, how do you Of distributions, how do you interpolate them in a smooth manner? And if you use geodesic interpolation, then you can basically see some linear piecewise interpolation. But how do you make them even smoother? So we borrowed the idea of the cubic spline and developed this notion of a cubic spline in Washington space. And it turns out this problem can also be written as a multi-marginal optimal transport problem where the Transport problem where the C can be decomposed in as this graph. So this X are the given marginals and the V are the, I would say, the hidden variables, the velocity, which you don't see. But if you want the smooth interpolation, you have to model it because you need the smooth transition in the velocity to, you need a continuous transition in the velocity to ensure smooth transition in the. Smooth in transition in the space. So, this is there are many other examples. Actually, one of the very first multi-marginal optimal transport problem, the incompressible Euler flow problem, can also be decomposed as a graph. So the question is, how do we utilize this structure and to help us to solve this problem more efficiently? So, this is the main topic of this talk. The main topic of this talk. So let's just come back to this matter and margin optimal transport. And as you can imagine, you can just also use entropy lynchation. There's no problem with this. Okay, so here we just add the entropy lyricalization. And also you use the Lagrangian analysis. You can solve this problem very easy, at least formally. And again, the solution is equal to the optimum. The optimal solution is equal to the k is equal to this is a tensor, then multiply another tensor, and this tensor is a rank one tensor. And this u1, u2, uj are basically your Lagrange multipliers. And actually, this lambda are the Laglange multipliers because you only have constraint when J belongs to this set, gamma. Therefore, you only have Lambda there for the other place. Have lambda there for the other places, you don't you have a trivial lambda, so it doesn't really matter. So the optimal solution looks like this. And after you do this, after you lay down the dual problem in terms of u and as well as the lambda, they are the same. Then this is what the dual problem looks like. This is a standard. And in this problem, you try to maximize the lambda j, the like language multiplier. j the like language multiplier and this is the cost function okay u is a function of lambda so this is a this is the dual problem it turns out you can also do the sinkhole algorithm on this and this is basically the this dual problem if you do the block descent no actually the is a maximum is a block ascent algorithm for this then you recover the sinkhole algorithm i think this is also a well-known fact so this is what the algorithm So, this is what the algorithm looks like. So, you have this u1, u2 up to uj, you need to calculate. Okay. Then, for one step of this thing algorithm, you just fix all the other lambda and try to update one of the lambda. And because it's a block ascent, which means you just maximize this lambda and fix the others, if you do this, due to the very special structure of this problem, you can actually solve this. You can actually solve this. So, this is the sequence iteration. So, you just update this UJ according to this equation here. And as you can see, the operation here looks very simple. K is given, U is what you want to calculate, and this is the projection operator. That is this just a point-wise multiplication and the division. So, it looks very simple, okay? And this algorithm also has a linear convergence guarantee. A linear convergence guarantee, and is also very easy to parallelize. So it looks everything is fine. Then we don't need a structure anymore. You can just solve this. But this is not the case because the complexity of this problem is hidden, of this algorithm is hidden in this operation, PJ, Ku. So remember, this is the tensor, it's a J-dimensional tensor. If you want to calculate the projection PJ, it's actually very expensive. It's actually very expensive. If you don't have any other structure, it's super expensive. It's basically d to the power j because you have a huge tensor, you want to calculate one of the marginals. This is not a very easy task. So, how do we utilize the structure of the cost tensor C to accelerate the calculation of PJ? So, it turns out. Of PJ. So it turns out if the C has some good graphical structure, we can accelerate this. And this is basically the main contribution of this work. So in order to do this, we are going to take a detour to a very different topic called the probabilistic graphic model. Oops. Yes. So this is a different topic. It's the probabilistic graphic model. And here we will study the undirected probabilistic graph. undirected probabilistic graph models. People also call this Merkle random field. It's basically one way to represent high-dimensional probability distributions. And basically, if you have a J-dimensional probability random variables, you can write down the probability distribution or the probability density in this way. And if this can be decomposed, we say that if you can decompose the distribution. We say that if you can decompose according to a structure like this, then this is much easier to handle. So, this is the Markov random field. So, this phi and the pai here are the code of factors. Okay. And the pai basically capture the interaction between the node. And sometimes we also use the phi to capture some local potential, local, but very often this is absorbed. Very often, this is absorbed into this, but we just keep both because we need both in our late, it's just easier. And this is just one example of this. And actually, you see, this is the same graph we have earlier. So we say we have a graphical model or Markov random field according to this graph. What we mean is that we have a random probability, we have a random vector of six dimension. vector of six dimension over here and this uh they the joint distribution of them has this structure okay so normally this is a six-dimensional tensor but now we have more structure we say okay because it's a graphic model it can be actually decomposed into this way and here we have many factors here we use the the factor graph representation there Graph representation, therefore, we have one factor here, one factor here, one factor here, one factor here, and the whole click as another factor. So we have three factors. And you can also include some local factors for each of the individual nodes. Okay, so this is a macro random field. And this is a very popular way to model a high-dimensional probability vector. And excuse me. When I say the variables x alpha1, x alpha2, x alpha3, in the example I see that those represents sort of the vertices of the maximum clicks in that graph. So I wonder if in general that is the case or only in this. In general, you can always do this. In general, you can always represent as a The maximum click. So, one thing about this probabilistic graphical model is that this decomposition is not unique. It doesn't have to be unique. So you can always assign probability, assign this factor into the click. That is one of the more optimal ways of doing this, but there are many other ways. For instance, here, we can also use the We can also use the edge. So each edge represents one factor. That is also fine. Does this answer your question? Okay. So this is the probabilistic graph model. And so one of the most important questions in this domain, probabilistic graphic model, is called the Bayesian inference. The Bayesian inference. So basically, if you have a model px, what do you want to know is the basically the marginal distribution of some specific node. Okay, this is the most important questions in this domain. And of course, you can just calculate this by definition. It's doable, it's expensive. You just need to take the summation, a lot of summation to be done. But you can do this, but there are more efficient ways of. But there are more efficient ways of doing this that for instance, like variable elimination, belief propagation. So there are many efficient algorithms to calculate this marginal inference. So that is exactly what we would use. So this is the detour to probabilistic graphic model. So let's come back to our problem. So we have a multi-marginal optimal transformation. Multi-marginal optimal transport problem, and we have this single algorithm for this. And the bottleneck for this algorithm is this: this PJ, okay, this operation over here. And K is this U to the power minus C, and U is whatever we have here, correspond to the Lagrange multiplier. Okay, so if we view this as a graphical model, so when C can be decomposed as a graph. Be decomposed as a graph. Then, this k u, I mean, it's a joint probability. If we view this as a probability, joint probability, then this can be written in this way, right? So what I did is I just write down uj and I just replaced the c by the graphical structure c. Okay, if you write everything in this way, then Everything in this way, that it's easy to see that this is a probabilistic graphic model. Okay, so this C alpha represents the phi, no pi alpha of the graphic model. And this uj, the Laglange multiplier you have, basically corresponds to the local potentials. Okay, if you view this k. k multiply u in this way then what we need to calculate is the p j k u is the projection of this tensor is nothing but the j marginal of this probabilistic graphic model okay so this is basically the key of this framework and this in general this projection is difficult to do but in Projection is difficult to do, but if it has some graphical structure, we can view this as a Bayesian marginal inference problem. And by doing this, we can take advantage of many efficient algorithms in probabilistic graphical model literature to help us accelerate this calculation. And this is exactly what we are doing. So, let's go, let's move forward. So, in order to show, in order. order to show in order to see more explicitly how this can help us i'm going to present a special case called a tree structured optimal transport okay it's a very special case but it can deliver the idea so this is again is an optimal transport problem multi-marginal optimal transport problem and we assume the cost tensor can be decomposed as a tree okay As a tree, okay. A tree is just a graph with no loop. And in this problem, we assume we have three marginals are given, all the other marginals are not given. Okay, the C can be decomposed as this graph. And for trees, if we want to calculate this PJ, it's actually very simple. So, first of all, you see K is can be decomposed as a tree, and this And this even if you add this u, this at the local local potential, it doesn't change the graphical structure. So you would still have a tree structure. So for tree structural probabilistic graphic models, one of the most useful algorithms to calculate the marginals is called the brief propagation. So here, so this is the just an algorithm for marginal inference in the brief propagation in the probabilistic graph. Probably in the probabilistic graphic model literature. So, suppose we have a tree-structured graphic model like this, and we want to calculate marginals of one node or other node. Okay, how do we do this? You can just view this as a agent and they communicate the belief. Okay, so this is how the algorithm works. It just can be written in one line. So the note X. The node X1 node would send a message to its neighbors. But what is this message M62, for instance? Basically, what you do is you collect all the incoming message. So in this case, you only have M426, and then you combine with this, your local or the you combine this with the other factors that is relevant to X6. Then you do a matrix modification. Then you do a matrix modification, then you can calculate this message you want to send out. If you do this in a specific order, you can actually make sure that the algorithm converge in finite steps. And the number of steps you need is basically the size of the graph, which is a very efficient algorithm. And once everything converges, you can calculate the marginals in this way. Okay, so now every this. So now every this MKJ is a vector, and this is a vector. So, and this is a matrix, this is a vector. So, it only involves matrix vector multiplication and vector vector multiplication. And compared with the brute force projection, which in which case you need the tensor multiplication, which is very complicated. So, this is much easier. And if we combine this brief propagation algorithm with the synchron algorithm. Algorithm with the sinkhole algorithm and to solve multi-marginal optimal transport problem. And this is what we will see. And we call this algorithm sinkhole brief propagation. It's basically applied brief propagation to compute the pg in this problem. If you combine these two, this is the algorithm you will see. It's very similar to the standard bleed propagation algorithm. Actually, this step is basically the same. Basically, the same. This is the second step is basically the same, but it has an actual step. And this step corresponds to the single iteration. Basically, here you have the mu at the marginals. And I think this next slide is more intuitive. So it has two type of messengers. One type of messenger is exactly the same as the brief predation. As the bifurcation, it just sends to your neighbors. Another type of messenger is we call this bouncing back messenger. Basically, if you send the messenger from six to two, because X2 has a constraint, so you can view this as a wall, then whatever message you send there is going to bounce back. And you just need to calculate this using this operation here. This is basically the single iteration, but pictorially. Pictorially, what you see is just this messenger you send to the constraint node, it's going to bounce back. Okay, so this is the single vocation. And for the rest of the talk, let me see how much time I have. For the rest of the talk, I would just go over several examples. So this basically shows you how to do this for the two very simple examples, very simple. Simple examples, very center and geodesic. And a more interesting example is this application. So a more interesting example is this, what we call the aggregate inference problem. And for this problem, basically what you do is normally for inference or for filtering problem, let's say you have a bird, you want to track the bird, you have some measurement, you can track the bird. You have some measurement, you can check the birds, and this is a standard filtering problem. So, what we mean by aggregate filtering problem is that you want to check, let's say, 1000 birds simultaneously. And I mean, of course, you don't want to check every single of them. You want to check the group behavior of them. Okay. And what you can measure is basically, let's say every other second, you can take a picture, then you can basically see some of the. Can basically see some of the configurations of the birds. So, mathematically, what you see is this. So, we have a lot of, we have, let's say, a large number of dynamic systems. Their dynamics are the same. All of them, they can model as this hidden Markov model. The X are the hidden state, which you cannot see, and the O are the observations. Okay. And in the standard filtering problem, what you do is Standard filtering problem, what you do is you have a dynamic system like this, then you observe O1, O2, O3, up to OT, then you want to infer maybe the distribution of the state or the most likely trajectories. Okay. But here, because we have too many of them and we observe them simultaneously, and due to many reasons, we cannot measure, because if you take a picture of 1000 birds, there's no way you know which point corresponds to which bird. Point corresponds to which birth. And so that's why the measurement we have are basically a bunch of probability vectors. These are the empirical distributions of this system. So what we have is basically we have observed a probability vector at O1, observed a probability vector at O2, and the same thing for O3, OT. And our goal is to find out the distribution of the state, which you cannot see directly. This can be This can be viewed. This is the goal to estimate the posterior distribution of the XD. Okay. And it turns out this problem can be modeled as an entropy regularized multi-marginal optimal transport problem when the cost tensor can be decomposed as this hidden marker model. Okay, so you can use the single-home brief predication algorithm we have there to calculate this. To calculate this, and this is how the algorithm goes. This basically, the yeah, I think this basically tells you the how the message would pass through the system. So you would go forward. Okay, then until the very end, then you bounce everything back, you would go backward. So if you are familiar with the filtering literature, then you would see this is very similar to the standard. Is very similar to the standard forward-backward algorithms in field three, and this is indeed the case. So, here, because each observation we have with a PDF is a probability vector, if we consider once, if we specialize this to a like one individuals, then at every point, what you see is a Dirac function. Okay, it's a special case. If you use this special case, then this algorithm would actually reduce. Would actually reduce to the standard forward backward algorithm, which is the filtering algorithms for one individual. So, this is a strictly generalization of this filtering algorithm. Young Shin, can I ask a question? What is the cost function? Is it the log likelihood or something? What are you trying to optimize? Oh, yeah, sorry. Yes, this is the log likelihood. The log likelihood, okay. Yes, this is the log likelihood basically. Um, how do I say this? So the here, okay, I think this is this model. So we have the cost tensor can be decomposed according to this graph, right? So in this graph, basically we have this edge-wise cost. So from x1 to x2, the cost is basically the log p minus log p, sorry, minus. Minus log P, sorry, minus log P X two given X one. And for this type of H is basically the minus log O T given X T y this is basically this is actually very similar to the very similar to the shooting a bridge problem and it's just that we have more marginals and we have some note we Note that we cannot observe directly, but it has the same physical meanings of if you want to cook up a Schrodinger's thought experiment, you can do the same thing. Suppose you have like 1 million particles, okay, then you let them go, then you observe this O1, O2, the distributions at the sequence of point. Then you ask the question, what's the most likely trajectory they travel and what's the most likely distributions they have? Distributions they have, then this is what we are solving here. It basically has the same physical meaning as the Schrodinger bridge problem. And this is a discrete problem, but it has the same physical meaning. But the Schrodinger bridge also comes with a parameter, which is the temperature, which I guess here is arbitrary. You just take it to be one or something. Yes, yeah, it can be arbitrary because we actually don't fully agree. You see the shooting. You see, the Schrodinger bridge problem, the reason you have the temperature is artificial is when people use the shorting bridge problem to solve occupant transport problem, you need a temperature. But in the original Schödinger bridge problem, you don't have a temperature because it doesn't exist. The temperature basically tells you the temperature of the dynamics. It's not the real temperature. For instance, everything is captured. So if you want to see a temperature, So, if you want to see a temperature, the temperature is already captured in the dynamics. If the temperature is low, then we can say this one. It's more lazy, they are lazy Markov chain. If the temperature is high, then what we mean is this Markov chain, then mixed faster. So, it doesn't have to have a temperature. I see. Thank you. So, this is just one example, I think. Uh, one example: I think what we do is uh suppose you have a uh this many tense sensors, okay. So, this cross are sensors, and suppose you have a I don't know how many we use, suppose you have 1000 dynamic systems, let's say birds, okay, they travel. So, these are the ground truths of the distribution of the birds, and these are the observation. So, each sensor can basically detect how many birds are in that neighborhood. Many birds are in that neighborhood. Okay, so this is what you see from the census, and this is what you can recover from these algorithms. And this algorithm becomes better and better when you have more and more agents. Because due to the larger deviation, the more agent you have, the more unlikely you would observe something weird. So this is also justified by the Classified by the theory of large deviation. So I see, I have two more minutes. So I would just quickly discuss another example is the mean field again. So the mean field again. I think you actually have more than that. I do. I think you have about seven minutes. No. Okay. Okay. Thanks. So maybe I'm wrong. Sorry. No, I'm wrong. Sorry, I'm no, I'm wrong. I'm wrong. Sorry, you don't have okay. I will just uh go through this quickly. And this is the mere field game problem. Basically, is the game involved a large number of homogeneous systems. And so if we assume individual dynamics of each agent is modeled by this SDE over here, okay, so it's a non-linear system, but the noise enters the system in some specific way. And it turns out. And it turns out this problem, the mean field gain problem, I would skip the background of mean field gain, but it can be modeled as a when the when the cost in the mean field gain satisfy the monotonicity assumption, then it can be modeled by this density control from problem. Okay, so it this is optimization. Basically, what you are trying to optimize is the density flow and also the control feedback policy. So this is capture basically. So this capture basically the this is the Fokker-Planck equation captures the group behavior and this is the initial distribution and what you are trying to minimize is some penalty and some other cost functions. Okay and for this problem it turns out you can change of value you can do change of variable so instead of model instead of viewing the optimization variable as low and v you can view the optimization variable You can view the optimization variable as the distribution over the trajectories. So, what we call this is the PV here. Okay, if you do this, then you can use the Stanov theorem. I mean, this is basically the standard thing we would use in the Schrodinger bridge problem to equalize the K-divergence and the control energy. Okay, that if you do this, then this is the reformulation of the mean field gain problem. And this actually was. Again, problem, and this actually was studied by Banamu quite a long time ago. I don't remember when actually. So, this is what you see. The optimization variable is this distribution over the trajectories, and this is the cost. It has two terms. One turn is this, and another turn is this KR divergence. And Pv means the distribution you want to optimize. P0 means the distribution of the trajectories when there is no control, so zero control. Control, so zero control. So, if you discretize this over space and time, this is what you see. You would have a bunch of constraints. The optimization variable is a J-dimensional probability tensor, and this is your cost, and you actually naturally have an entropy recognization over here. It's not artificial, it's actually there all the time. And the difference between this and the problem we discussed is that you have some non-linear terms, but it turns out. Nonlinear terms. But it turns out this algorithm can be generalized to this by using this, what we call the generalized single algorithms. So it's not very difficult. So therefore, this is actually the mean field gain problem can be reformulated after thisization as this multi-marginal optimal transport. And actually, the cost function here can be decomposed in this very line graph, which is really the same. Graph, which is really the simple graph, okay. And the same thing can be done for if you have multiple species, so you would have a similar formulation. And again, you can reformulate this as a multimarginal optimal transport problem. I'm a bit faster here, but this is the graphical structure for the multimarginal optimal transport problem. If you have multiple species, if you only have one species, then you don't have this mu minus one, no. If we have multiple species, Note. If we have multiple species, then you have this artificial node, which basically tells you how many agents you have at each single species. Okay. So this is example. Actually, I would skip the example. It just shows the algorithm works. Okay. So a few takeaway from this talk is the graphical structure for MOT is great. And there are some. Is great. And there are some fundamental connections between MOT and the probabilistic graphic models. And these are very two different research areas. And there are plenty of applications. And I will stop here. Happy to answer any questions. Okay, thanks a lot. Thanks. So let's see. I'm afraid I lost track of time. And so we only have two minutes until the next talk. So I'm thinking maybe to ask you to hold your questions till the end of the next session. Your questions till the end of the next session or to communicate them privately to Yangxin. But I do note that there are a couple of people who joined the audience: Jason Altschuler and Henrique Box, who are PhD students at MIT and have studied the computational complexity of optimal transport. So I think you and they may have interesting things to talk about. Yes, yes. Also, I want to add that we are going to have this gather town for social interaction. For social interactions, if you want to have more in-depth discussion with the speaker, yeah. So, this is on this is on Wednesday, so there's also other opportunities to further discussion. Yes. All right. Thanks. So I'm going to stop sharing that. Sounds great. Thanks so much for your talk, Sanchez. Thanks. Okay, I think our next speaker is Adolfo Vargas Jimenez. Maybe he wants to try sharing his slides. Um sharing his slides. Yes, give me a second. Now, do you hear me well? Yeah, we can see you. When I hear you, it's with a bit of an echo, but yeah, it's not too bad. Okay. So this short talk is maybe we can just give people one minute to