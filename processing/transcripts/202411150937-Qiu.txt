Thank you very much for the introduction and thank you so much for the kind invitation and having me here and also thank everyone for being here. Okay, so today I'm going to talk about a conscious approach based on particle systems for meaning-mixed problems. Problems. So, in this chapter, we first review this kind of approach for optimal problems. And then we come back to discuss the approach for games or min-max problems. We can also generalize it to bi-level problems, StackBrook equivalent problem over there. This is joint work with Voki and Huang. Let's have a look at the background of this map. The background of this method is based on the SWAM intelligence. And the idea over there is that we can use the collective behavior of simple agents, but they just interact with each other or with the environment. And this simple system, particle system, can lead to the emergence of complex structure that is intelligent and sometimes cancelled to the problem solving capacities. And there's no centralized uh control or external management. The control or external management. So, this is the basic idea based on Swami Targans. And then you can apply the Swami intelligence to the optimization problem. And the idea over there is based on the fascinating capacities of Swami intelligence. The largest systems of interacting particles can be used as a tool to solving the challenging problem like the following one. We want to minimize the cost functional in some way. And this objective function here. And this objective function here can possibly be non-convex or non-smokes. A particular one is given this way. It's just you can see there are many specs and it's not convex and in some point it cannot make the differentiation over there. A particular method is this one, consistent-based optimization. It's a recent work by Juno Tizo and Jose Del Group. And was their group, and they proposed this consensus-based optimization problem. And it focused on the instantations, deterministic, and stochastic decisions in order to establish consensus around the points so that the location of global minimal could be approximated by the consensus points. So I will introduce the following system right here. It is a stochastic differential equation system by using the stochastic differential equations. So I will slow down here. So, this is the particle system, and XI denotes the particle, the ice particle with the partition X. And in the SKE, there are the drift part and diffusion part, right? The drift part is corresponding to the deterministic alignment. Basically, we give a force here and to make the particles communicate with each other, and then they are dragged back to the contest point. And the diffusion part is corresponding to the stochastic exploration, like the gate in GAS, or any other optimization methods. So the key point is that the cassette point should be, if the cassette point is close to the optimum point, right, this will be small. And this one is also small. So the exploration will be stopped somewhere. So this is the difference from the Langevin method where you have a sigma as constant. You have constantly volatility. Constantly qualitative. So, here in this theater, the bright motions normally chosen independent for different particles, they have independent noise denoted by the winner process B. And now, the question is asked in how to get to the consistent point. This one is a suitable global estimate for the minimizer of the objective function. We want to find the minimizer objective function, right? And this will be a Matter objective function, right? And this will be an approximation for that. That's the only idea about consent-based optimization problem. So if you have any question, please let me know. Just let me know. Okay, so if you use this one, and if this is successful, I realize that over there, there's no derivative happening. You don't need to click derivative, only need the evaluation of the objective function over there. Okay, so sometimes we lack the zero derivative because it's not differentiable, right? One way. But you can replace the derivative with the error by some pseudo-derivative, nano. But there are other cases that the derivative is difficult to compute. And this is happening when we are doing the projects with NAMR curving calibration problems, where the likelihood function is very complicated. If you want to compute the derivative with respect to the parameter of the With respect to the parameter over there, you get a system. You need to solve iterative equations. So it's complicated. Okay, so now let's have a look at the consensus point. The consensus point is not complicated here. An example is here. This is just an example. You can use other consensus points. So the following one is based on the Laplace principle. It's given this way. So for each, for each So for each particle, for each, there are n, suppose we have n particles, right? For each time t, there are n positions over there. So you explore the position, basically, you compute the value function at its position, and you put a weight over there. Okay, if the value ex is very big, you have a very big alpha, alpha is a big number, positive, then this will be very small. Okay, so if your x is relatively small, close to the minimizer, Small, close to the minimal, this one is relatively big. And this is corresponding to the weight over there. So if the X is close to the minimal point in some way, in the sense of evaluation, it will have a very big or huge weight over there. And we can expect that this expectation here is close to the minimizer. This is an intuitive understanding. But you could also understand in other ways, like the weight is chosen, you know. Other ways, like the weight is chosen in a way, like Burzman principle, or it's corresponding to a very rational problem. But here, we just introduce the intuitive basis, the idea. Take the weight, take the average, you get the consistent point. And here, this one is the empirical measure. It's just using the sum of the mirrors. So effectively it's a Gibbs measure with loss function. Yeah, yeah, that's good. So now, yeah, you're right. So now, yeah, you're right. Some people say this is, I see this is called the Laplace principle, but also some people say this is corresponding to the Burnsman principle, GPS. So the Laplace principle actually implies that this consensus point is close to the minimum point where the objective function is minimized over these finite positions at time t. Positions at time t generated from particle system. So, this is the idea over there. Any question about the constant on here? Yeah. So, we'll use it later for min-max problems. Yeah. I mean, this is true once you have the large division principle, right? Yeah, this is a large principle. Yeah. I have talked different places on. I have talked to different places. Some people come to me and say, Brozaman principle, but it's a Laplace principle, why do you choose both the drift and diffusion term only up to the only difference? Sorry, after the same, it's here. This one is a difference between the consistent point and the position. Drift is a lambda and the diffusion part is a sigma. And the diffusion power is a sigma. Sigma is constant. So lambda sigma is constant. So it's green, right? Maybe you cannot. There is also an absolute value. You could take an absolute value. You could also take a quantum value. Let's have a look at it later. So this is a particle system. So how to study the convergence? You want to consider that? The particle will be converging to a point. Particle will be converging to a point, and this point is expected to be the minimizer. So, the mathematical way that let n goes to infinity, don't consider the n-particle coupled system complicated, high-dimensional. Let n goes to infinity, you only need to observe one particle, that is the falling on Mikhail-Velassov system. And the density over there is falling is certified falling PD for plant equation. So, this idea by by So this is the idea by Hussein and their group. They studied this PDE and then they studied the last time behavior of the PDE solution. Then found that PDE is blowing up. It's not but it's blowing up, converting to a black mael. And the support darken mare is minimized. So this is the idea for the PDE measure. So if you look at this is the convergent analysis, right? The only missing there is that they don't consider, they don't prove the They don't consider, they don't prove the mean field the limiting process. So what do you mean by the X bar? It's close to the global minimizer. X bar? So X turns close. Close to the global minimizer is meaning that there's a distance between the vacuum air and the rho T. You can use in the water stand distance. You can use the water stand distance to measure it. They have an estimate over there. But x q d is also close to the true minimize. So it's not the exact unhole minimized? It's not exact. Actually, this is a whole problem is about approximation. So the touched point is approximating of the touched point. Okay, so the only meeting is the theory is almost complete. The theory is almost complete if you prove the mean field limit theory, right? And we did this with Swan in 2012. And even recently, Hoffman and Gerber and Basti, they also got a quantitative analysis on the mean field convergence over there. Okay, this is a concept-based optimization for the minimization problem, right? Yeah. So our question, of course, is how to extend this. Question: Of course, is how to extend this to the min-max problems. So, there are two motivations. The first one is that, so for the minimization problem, you can compare the CBO and the SDG, like SGG. People say they have a comparable performance in some way. Some people prefer this one. So, there are arguments over there. So, we want to get away from them argument to have a look at this method, maybe have better outperformance in the games problems. Games problems, like min-max problems. This first one, the second one is that the min-max problem is actually very important, right? In GANS, machine learning, we will see some background for that. So it's also known as saddle point problem. And the classical min-max problem is studied, for example, in the context of zero-sum games. So the goal there is like we know that is the mean max. So you first take the minimax maximum respect to y for given x and then take a minimum of the maximum objective function over there. So that's the problem. The next problem is simple. So first we have a look at the Nazi group point over there. So for the Nazi group point basically the x star, one star, or x and y they are symmetric to each other. Well, X and Y, they are symmetric to each other. Don't know which one is going first, which one after one. So, X star, Y star is not equivalent. Let's review. Okay, let's have record definition. So, given Y star, X star is the mean minor. Given X star, Y star is maximum point with respect to Y, right? So, this other rules you can also conduct this one. So, for the convex concave ones, you can use variance of gradient descent. For gradient descent ascent algorithm. It's called GDA. Basically, convex concave means it is convex respect to X for the minimization and concave with respect to Y for the maximization problem. So if you don't have this kind of convex or concave, it's MP hard problem over there. So this is the Nash problem. So let's have a look at the gradient-based method, like GDA, okay. Based method like TDA. So, this is the example here is a review paper, the very recent review paper. So, study this very simple example: x times y. Take a min max and max minimum. If you take a maximum with respect to y, depends on x. x equals 0, what's any? I see posit number y positive infinity. While negative number, y is negative infinity, right? There will be positive infinity or 0. Minimize with x. Minimize with the value x, if we choose x equals 0. So the minimize min max for one will be 0 for any arbitrary value of y. Conversely, we take max minimum, so it will be 0, r, 0 for y, and r for any value for x. So the natural problem will be 0 and 0, right? Origin point is not equivalent. But if you use the Griden-based method, we found that starting from any point close to 0, they will be as the deterrent. They will be as the iteration going on, they will be uh go moving far away from the original point. So that's the problem over there. So that means solving the min-max problem. So the previous example is convex, concave, actually, right? So the challenge is not just lying in the non-convex, non-concave, but it's also lying in the problem itself. Even for some concave or concave. Even for some concave or convex problems. So, we have studied the non-convex, unconcave, the mean-max of computation. And this is the background, actually, that advanced machine learning or many other. I don't know all of them, but you can refer to the review paper about background for Emacs problems. So, let's move on for Max. So, what I want to say here is that there's a need for the method to effectively address the MIMEX problem. So, we actually have proposed a zero-order CDO method for Natchez Prime Point, and we studied both two-player game and the multiplayer games over there. That's what we are not talking about today. What I'm going to talk about today is about just actually if you Talk about today is about just actually if you study the GANs, in some cases GANS is described as a Natchez freebon problem. But in most cases, people prefer like it's a min-max problem or max-minimum problem. It's not a Natchez quantum problem. Actually, Natchez cannot exist. Refer to this paper here. We have a study and gas. So have a look at this example. It's very simple. The mean max part is zero and accurate value of y. Actually, value of y with a point value that is zero. But the maximum minimum point is negative one and zero. So they are now considering each other, right? So there's no nash equipment point. And this is the this is happening the same in the in the guts trainings. So then we consider the sequential game, means x and y has order. We can first take a maximization with respect to y and then Respect to y, and then study the minimization with respect to x. So it's defined this way. So I'll just review over there. So for each x, take a maximum, you get a value, function value, which is epsilon bar x. Then you minimize this epsilon bar x, you got x star. And from this x star, you can also get y star. And this is called the global min-max solution. We define it here. So now we have a question. If you study this problem, so which problem so which which suppose that this is a simple problem you want to study the x star y star so which which one would you like would you like to find first x star first or y star first it's a question we've got study the uh this one suppose it's a simple one you can compute it out so we for the x star y star which one would you like to find it first y star y star is Y star. Y star is y star is a function. Okay? Let's have a look. Basically, you can first find y, y bars corresponding to x, right? But then finally, it becomes this problem. So you need to first fix x star, actually. It's like a leader-follower problem. You first find the leaders TC, and then you can make an authentication kind of follower TC. So there's a sequence order. See, there's a sequence R. But let's have a look at this and uh uh to see the algorithm over there. So, the difference between this kind of problem and the next problem is that x and y two particle system, they are they are not symmetric to each other actually. Okay, so let's have a look at I. Maybe you feel like familiar with it. It's like the CBO, right? Lambda, sigma, and this is the power. And this is the consensus point, consistent point, and this is the y. So the idea is that how to design this consensus point and to incorporate the order, x and y. So let's have a look at the discussion. There's no absolute value now in the diffusive term. No, yeah. So there's a but we have a t, t is a positive between positives. Oh, t is a function. Diagonal. Diagonal. Diagonal. Yeah, diagonal. You have a vector, you put the vector in the diagonal. You can choose, that's two different ways. I will mention it later. Good point. And so the initial value is ID and B invented round emotions. So let's have a look at X and Y. So X is sensible in X alpha. Y is the sense of Y beta. And so for Y, So, for y, it is for any given x particle, and y should explore the landscape for the maximizing. So, for given x, this guy looks for the consensus point around different given x particle body. But for the x, x observed the consensus point of y. So, x has more, leader has more information about y. Has more information about what Y is doing them. What's the optimal why for that? So that's the idea. They are not the same, they are not following the same formula, so they are not symmetric to each other. So if you let alpha beta goes to infinity, basically y is doing a maximization for every x. Follow X is doing the optimization for the optimum value Y. So X will be determined actually first, and then Y is the follower. We will see this in the numerical experiments. So you want to have a look at the system. The drift term is trying to direct the particle towards the consensus point. The consistent point is the point we can design, right? And this is the diffusion term. It has this form. It injects some randomness for the exploration. There are two different kinds of diffusion design here. You can use isotopic, like we said, absolute value. We can also like using direct. Follow this point. So the consensus point will be somehow, or you expect that we receive the middle of the upper battery. That the receiver would increase the upper value and the lower value to gain static gain. Or where it would be his statistics? What is the meaning of the consistency pawn, right? Is this your question? Yeah, I mean point somehow will reflect who is playing first and second. And you can pause the symmetric problem with the max-mean problem, so you will have both the the So the the the other extreme value of the gain. So um so for instance so the particles here are not players particles X group X group Y they are not players just particles in the landscape okay fine but somehow somehow you will need to Alright, where you start marking? For now we have no x star, y star. But if you use the Lagrang principle, this guy will convert it to the optimal value of y given x position, right? Yeah. This guy will be converting to the x star, close to x star, but it's Close to x star, but uh it's based on the distribution of the particle partitions, right? Yeah. The convergence here, though, is point six on point omega point, click, it's point faster. So it's a point, like uh when yeah, so what sense does it converge to make the max or the argument? Okay, we would talk about in a thing with this license. In that sense, aren't you doing the y first and then the max? That's the here. If it go to infinity, y is not doing for us. Y is actually corresponding to a value relying on x. Given x, we find optimal, right? But this one, we're trying to get the, but we're trying to get the optimal point. Yeah, or yeah. We will see this later on. Okay, this is the intuitive idea over there, background. Okay, um Okay, so still, if we want to study the convergence, let n goes infinity. So we want to study a simple system like here. It's a coupled system, x, y, and Mikim Branasov, X and Y, X alpha, beta, and Y beta is giving, is a contingent form of the Laplace principle, right? But I think we don't need to repeat it. The the difference of them is also clear between X and Y for the concept part. And y for the concept part. And if rho is a joint distribution function, rho y and rho x are the marginal ones. Okay, if you want to use the PDE, you can also, you can propose the PDE for distribution, for joint distribution G here. But here we don't use the PDE method to study the convergence. What does the convergence mean? So it's about the global convergence. That's the mass power. That's the math part. So it's not easy, straightforward to study the convergence. We need some assumptions. So today I post the assumptions here. Let's have a look at it one by one. It's not so. So first one is saying that the object function is bounded. So if you are doing meaning max problem, if it's not bounded, you can use a hyperbolic touch, right? Put outside, and the problem doesn't change. The mean-main pulse is the same. You can always make. Is the same. You can always make the problem to be abandoned. The first one is natural. The second one is about local continuous. Also, standard, right? Only the third one. Third one is that we want to study the convergence rate over there. So y bar is given x, we find the optimal value for y bar. So it's a function. Y bar is the function depending on x. We assume that this y bar is mixed and debunded. And the bandit. This is restrictive in some way, but in numerical stuff, you don't need this one. Okay, it's just for sure. This third one. And the remaining four, five, six, seven, they are standard in the CBO method. Okay, basically, they want to say that the x star, y star is a unique mean max point. Okay, I will go over them quickly. Maybe you may be worried about okay, so many assumptions in an example. Actually, constructing an example like this one here is not difficult. Okay, yeah. Bunding is one like, you take maximum with respect to y, y is equal to this one, right? This part will be zero. I take minimum with respect to x, x should be zero. Come back, okay, y is also zero. So the mean max point for this problem is the origin point. So this is an example satisfying all the conditions. All the conditions and uh it's not convex con concave, it is uh not differentiable at certain points. Okay, this is the assumption and for the convergence you need, so this is the Mikhail-Blashov system. So, we use the generalized Leapton functional method. We can use the Leapton function, like you can say it is a variance function vx, vy. It may Vx Vy, it measures the distance between X star and X bar. Okay, let's move on quickly. Okay, so this is the distance between X star and X bar. So there are some parameter assumption formula here, and we can prove that the mirror distance will be decreasing exponentially. Will be decreasing exponentially first to a certain abstream level. So there are some assumptions like here, it's complicated, but this can be easily satisfied if initiate the x0, y0, like with Gaussian distributions. So there'll be no problem. This is the convergence there. It was decaying very fast. We will show that. So if you see the proof, consider this energy. The proof consider this energy, measure distance between x star value and the particle position. Take a little formula, you get an energy infinity. And you need to estimate each term, like here and here. Okay? And if you look here and here, technical estimates, you can get the convergence over there. So let's choose some examples. So this is the example as beginning, okay? Let's come back to the example. Okay, let's come back to the example, the first one. So, in the grid-based example, it's divergence over there, but here we can see that it's converging. And you can also see that this is X, this is Y. X will be converging to the optimal point faster than Y. And the black point here is the initial value, initial at some points. And the blue one is the mean position of the particles. It's converging to the optimal point. Converged into the optimal point over there, rubble one. And we also found some interesting things, like in this work, they studied this problem complicated, but they found that their gradient-dependent method is converging to this point. But actually, this point is not the mean-max solution. And our method found that the mean-max solution should be this one, and we check that this bit. Okay, we are closing one minute. And we have other examples like the next one. Still compared with the existing examples and the next one. So I want to... So maybe you are concerned. So the problem over there is one-dimensional. You can also consider like a. We also applied it to like data poisoning and tech over the problem. The problem over data can be formulated as a min-max problem. The min-max problem, but we don't have time to introduce this problem over there. But it's a high-dimensional setting, okay? And we always check it with the most advanced region-based method. We compare them. If the parallel algorithm is used, the CPU method here shows that it could be an effective and efficient method. If you want to, you can refer to more details about this work in the keyboard. Then stop here. Thank you very much for the time. Thank you, Visit, for this interesting talk. So we still have time for a couple of questions. Thanks for the nice talk. So I thought that when you introduced the assumption, you are making assumptions in there is a unique minimizer, and you said this is a standard assumption in this CPO literature. But basically, the last three items here assumption is assuming there is a unique minimizer. Yeah, there are basically two streams of measures. It depends on the measure. So in the Nazi frame point, it will use another measure. In that case, you do not need anything unique. It will converge into a point, and you verify this point will be an approximate Nazi frame point. But for this kind of measure here, we need it to be unique. I mean for the convergence you depends right but for the applying of this method we don't need for the numerical stuff we don't need uh unit you can just study right but for the convergent theoretical result you need you need so if there are for them there are two uh there are two minimum minimal points we studied like PSO and CO We studied like PSOSEO. Sometimes it converges to one of them. Sometimes it converges to a certain point between these two points. Yeah. That's the numerical stuff. Do you have any idea how the initial distribution of the particles plays a role in the convergence? That's a good point. In this method, actually, no. It's just we just need that the We just need that the initial distribution has a support in the whole space. Yeah, yeah, I saw that. If you locate it in the compact support and it's far away from the point, it's not efficient. That's right. So that's what I was wondering whether or not somehow the distribution of the particles shows up in the convergence rate, but it doesn't. And if you want to refer to this complicated requirement and then you. Complicated requirement on the initial distribution. But this could be immediately satisfied. You can say x0 by 0 has continuous and postpone if I are no questions. Let's thank Junior again. So, well, this is obviously the end of the work. 