We have seen prior work that has focused on sampling-based techniques, such as the RRT star algorithm, which require no explicit description of the configuration space and can also guarantee probabilistic optimality when facing a known environment. But at the same time, something-based methods suffer from narrow passage problems. And in the presence of unknown environments, they require constant replanning, which usually comes with no convergence guarantees. Convergence guarantees. Now, more recently, we have seen deep learning methods that have gained significant attention because they require no need for any environment or robot model for navigation. But at the same time, deep learning methods are known to suffer from overfeeding problems to specific environments used in training and also come with no collision avoidance or target convergence guarantees. So, instead, as Dan described, our work focuses on reactive vector field-based methods that provide observations. Based methods that provide obstacle avoidance and convergence guarantees, while at the same time solving the kinodynamic problem of finding appropriate inputs to the robot. Now, despite their advantages, these methods usually require significant offline tuning of potential functions or are limited to simple unknown environments with only convex obstacles. And our work tries to provide solutions for these two problems. So, just to give some background, let's focus first on the Background, let's focus first on the problem of navigating to a target X star from almost any point in the workspace while avoiding all a priori unknown but convex obstacles. For this task, we can use previous work from our lab, which basically defines a convex local workspace around the robot as the intersection of half spaces. Technically, this local workspace is a Boronois cell, with each edge that defines the cell being a separating hyperplane halfway between the robot and each obstacle. And each obstacle, and at the same time, orthogonal to the robot obstacle distance. Now, by eroding this local workspace by a ball of radius equal to the robot radius, we can define the local free space, which is a collision-free neighborhood of the robot. And we can then project the target position x star onto the local free space to find the local goal, which is x bar star here. Now, this is a convex optimization problem, which can be solved efficiently in real time. And based on that, we command the robot. And based on that, we command the robot to basically follow that projected local goal. And because of its simplicity, this algorithm can guarantee target convergence and obstacle avoidance at the same time with a very simple Dyapuna function that is just the distance of the robot to the goal. Now, what is more important to us is that this algorithm is doubly reactive in the sense that both the trajectory and the vector field are generated online during execution time. So that's all nice for. So that's all nice for unknown and convex obstacles. But on the other hand, we have prior work on navigation functions, which has been shown to solve the problem of navigating to a desired target from almost any point in the configuration space, but in a priori known environments. So the obvious next step, and this is the focus of my research, is to attempt to combine the two approaches to solve the same problem in geometrically complicated and at the same time unknown environments. So to do this, So, to do this, we will assume that the robot possesses a sensor of fixed range capable of recognizing familiar objects in the environment, as well as measuring range to nearby obstacles. And for our hardware experiments, this sensor is realized with a combination of a LiDAR and an RGB camera. We also assume that any non-convex obstacle in the environment is familiar in the sense of having a recognizable polygonal geometry, and all unknown but convex obstacles are well separated from all other obstacles in the environment. Obstacles in the environment. But apart from these assumptions, all obstacles are initially unknown and are discovered online during execution time. So the goal is then to find a controller that probably guides the robot to a possibly moving target while avoiding all obstacles in the environment. And to do this, the basic idea of our reactive controller is to construct increasingly simple but topologically equivalent environments. Find a map that is a diffeomorphism from the original environment to a model environment where all of To a model environment where all obstacles are convex, apply a doubly reactive navigation strategy similar to what I described before in the model environment, and finally pull back the resulting vector field to the original environment. So here, more specifically, except for the physical space that the robot discovers as it navigates to its goal, we also use a semantic space that includes all recognized familiar obstacles and the observable portions of all unknown obstacles. The mapped space where all overlap The map space, where all overlapping obstacles in the semantic space are consolidated in real time, and finally, through a series of intermediate spaces, the model space, where all map space obstacles are either deformed to disks or merge the workspace boundary to form a convex environment. So the main focus is then to find this map H between the map and the model space. And to do this, we will first consider the simpler problem of the transformation of star-shaped obstacles into this. Transformation of star-shaped obstacles into disks. And for such obstacles, we can show that based on smooth but non-analytic functions, we can construct smooth switches that vary between zero away from the obstacle and one on the obstacle boundary, as well as deforming factors that map the boundary of the obstacle to that of a topologically equivalent disk. We then combine these two, the smooth switches and the deforming factors to form the map H between the mapped, sorry, the free space. Between the mapped, sorry, the free space in the mapped space and the free space in the model space. And we can show that this map is a C-infinity diffeomorphism. And also, with the use of small switches that limit the effect of this diffeomorphism away from the obstacle, no unknown obstacles are used in the construction. So we then extend this construction to consider arbitrarily shaped planar obstacles. So given a specific non-convex obstacle, we first perform either triangulation. Perform either triangulation or convex decomposition of this obstacle and build a connectivity tree that is based on the dual graph of this decomposition. So then the goal is to successfully purge this leaf of that tree. And to do that, we first find an anchor point in the leaf spawn. We identify two polygonal colors, one for the leaf itself and one that defines the neighborhood around it. And for each of these colors, we construct implicit functions that basically define them. Functions that basically define them. So, using these functions, we construct a smooth switch that varies between zero on the boundary of the external polygonal polar and one on the boundary of the leaf itself. And we then construct similar deforming factors that map either the boundary of the leaf to the boundary of its parent or the boundary of the root of the tree to the boundary of an equivalent disk. And so then we can write down the map between the map and the model space for each leaf purging, as I described before for the case of star-shaped obstacles. One important One important thing here is that if the obstacle intersects the workspace boundary, we simply merge it there by treating the root of the tree as an additional leaf that needs to be merged. So here are some examples that demonstrate how the algorithm works with convex decomposition and by successively performing leaf purging, as I described before. Any non-convex obstacle can be eventually mapped to an equivalent disk, no matter how many non-convex fingers it has. And we also efficiently implement this algorithm. Also, efficiently implement this algorithm in C, which allows for real-time performance on robot hardware. So, our reactive controller then for fully actuated particles is just a push forward of the same double reactive navigation strategy in the model space through the inverse of this constructed diffeomorphism. So, to be more specific, our strategy in the model space is to just follow the projection of the goal YD here onto a local free space around the robot position Y, with Y being the position. Y, with y being the position of the robot in the model space and yd the position of the goblin in the model space. So, so far we have just considered the motion of fully actuated particles, but it turns out that we can extend this construction to differential drive robots as well. And so, here we consider the standard non-polonomic differential drive robot dynamics, which are defined in SC2. And we can show that an augmented version of the same map H with an angle component C here that is just the angle. See here that is just the angle of the push forward of the robot direction unit vector is again a C-infinity diffeomorphism between the mapped space in SC2 and the model space in SC2. And the idea of the reactive controller remains the same. So first we push forward the differential drive robodynamics through this modified diffeomorphism in order to find equivalent differential drive dynamics in the model space. And then we find reference inputs in the model space according to the same W reaction. According to the same double-reactive navigation strategy. And once again, we use the Jacobian of the diffeomorphism H-bar to find the actual inputs in the physical space. So to formally prove target convergence in a changing semantic world, we employ a hybrid systems formulation where each mode is defined by the subset of already localized familiar obstacles. So the controller in each mode is the push forward of the double reactive strategy as I described before through the inverse of the DPM. The inverse of the dupeomorphism for the given subset of localized familiar obstacles. The guards describe the perceptual updates where a previously unexplored obstacle is discovered, and the resets are just the identity in the physical space with possibly discrete jumps in the mobile space. So here's an example where the robot starts navigating to a predefined target in an unexplored environment and successfully localizes familiar obstacles and explores the nodes and edges of the corresponding navigation. Edges of the corresponding navigational hybrid systems graph. So, based on this description, we can guarantee convergence to a specific target by using the Lyapunov function for each mode, which is just the distance to the target in the model space. And to be more specific, we use a theorem from a famous paper by Michael Braneke about the convergence of hybrid systems. And to see how the theorem works, this figure plots the value of two Lyapunov functions over time with respect to the same equilibrium point. And each function is associated. Point and each function is associated with a different mode of the hybrid system. So here solid lines show when the corresponding modes are active basically. So based on this description, the theorem basically says that the hybrid system will eventually converge to the target if the Lyapunov function candidate for any mode is non-increasing when that mode is active. And also the value of each function when the system enters the corresponding mode is less than or equal to the value of the function of the previous reset to the same mode. So if both of these conditions are So, if both of these conditions are satisfied, we say that the Lyapunov function candidates are Lyapunov-like. So, since we have a finite number of obstacles, in our case, we only have a finite number of resets when the robot identifies a previously unexplored obstacle. And at the same time, memory can only be incremental, which means that the robot cannot forget any previously encountered obstacle. So, that means that our job here is easier since we can have no reset to prior mode of the hybrid system. And the fact that I And the fact that our reactive controller guarantees that the distance of the target position in the model space always decreases in each separate mode of the system is enough to ensure that our LabNov function candidates are Labunov-like. So we can also extend our formal guarantees to moving targets such as humans. We assume that the target is friendly in the sense that its model space velocity is such that the target either approaches the robot or slows down when the robot gets too close to the obstacles or when the robot gets too close to the target. Or when the robot gets too close to the target itself. And with these conservative assumptions, we can guarantee that the model space distance of the robot to the target in each mode of the hybrid system will never increase. So overall, our work presents a variety of formal guarantees. First, we show that the constructed map is a infinite diffeomorphism where it forms sharp corners. The reactive controller in each mode guarantees collision avoidance and convergence to designate the target. And also, the overall hybrid reactive controller is a well-behaved hybrid system. Controller is a well-behaved hybrid system, generates a piecewise smooth flow and always guides the robot to the designated target. And finally, we can guarantee tracking of moving non-adversarial targets given some sufficient conditions on their behavior. So with that, I would like to move on to the experimental results. So in the first set of experiments, we considered tracking of a static or moving target. So here the robot is commanded to navigate to a predefined goal location, shown here as a purple dot. Location shown here as a purple dot in the semantic map at the top right. And notice how the robot detects objects and geometric features in the bottom first-person view screens and then localizes obstacles in the semantic map in real time and successfully avoids them. Then in the second experimental run, we command the robot to move to the same predefined location unless it sees a human. And in that case, it is commanded to follow the human while avoiding all obstacles in the environment. And again, the robot manages to. And again, the robot manages to do that by localizing all familiar obstacles, avoiding any unknown obstacles, and successfully following the human. Then we can use the same strategy on a different robotic platform and different environments. So here one of our legged platforms, the Ghost Spirit, is capable of following a human while avoiding familiar and unknown obstacles in different configurations, environments, and lighting conditions, both indoors and outdoors. And then in the second set of experiments, And then in the second set of experiments, we also consider the use of semantic feedback and human mesh extraction to perform experiments with predefined logic. So here, the robot follows the human in the voids of obstacles until it recognizes a stop signal in the form of a raised hand. And I think it's somewhere over here. So here, yeah. And then we command it to autonomously navigate back to its starting location. And it manages to do that again by localizing all. Do that again by localizing all unexplored, previously unexplored obstacles in the environment. So, with that, we can also use this reactive navigation strategy along with a low-level gate layer, as Dan described before, to perform more interesting tasks with our legged robots. So, here the robot is commanded to move to a predefined target unless it sees and localizes a cart. And in that case, we command it to navigate in front of the cart, align itself with it, and then jump to grab it. Grab it. So here the robot has seen the cart, it tries to align, and then it will perform this dynamic maneuver to jump and mount the cart. And the hope is that with this, looking forward, we can couple this W reactive navigation strategy with a high level deliberative planner to perform more interesting tasks with legged robots, such as the example shown here, where we command the robot to swap the positions of two objects in the environment. Positions of two objects in the environment. So, in summary, our work presents a reactive controller with provable guarantees of collision avoidance and tracking of fixed and non-adversarial moving targets in unexplored semantic environments. And shows how the integration of reactive planning with state-of-the-art perception affords semantic planning in various unknown environments. So, I would like to point out that our tools are also publicly available if you want to play with them. And with that, I would like to conclude the talk. And with that, I would like to conclude the talk, and thank you for your attention. So, hand over to Paul. Stop sharing.