Hi, I'm Francesco and I'd like first to thank the organizers for inviting me to this conference and I'm sorry of not being there physically with you. I am indeed talking about some models that I worked on with Joel and Ishban during the early days of the epidemic. And I am going to summarize the work of my three papers that I have on COVID from early 2020 to early 2020. From early 2020 to early 2021. And these are basically the bulk of my PhD thesis. And so, but the title of the workshop is Preparing for the Next Pandemic. So how do we reconcile these two facts? The thing is that I think that looking back at history is always a great teacher and seeing what were the kind of public discourse and the public opinions back at the beginning and at different phases of the first pandemic waves is. The first pandemic waves is quite important to try and get prepared for the next. So, indeed, this talk will be divided into three parts. The first part is something that has happened at the very beginning of the epidemic when we realized as people that things were going out of control and the main late motive was lockdowns and restrictions because we wanted to preserve the health care system but also get a grasp of what. System, but also get a grasp of what this new virus was like and if we could find some cure. And so the very first work was indeed done at the very beginning of the epidemic around March, April 2020, when about the time where the UK government announced the first lockdown. But then after the restrictions were finally lifted at the end of the first way in the summer of 2020, then the 2020, then the public opinion, let's say, changed a little bit, or at least that was my impression by staying on Twitter and reading papers. And the famous word, herd immunity, was introduced in the public discourse. And there is a very nice paper by Tom Britton and others about this idea of disease-induced herd immunity that was somehow already explained by Gabrielle in the By Gabrielle in a previous talk. So I'd like here to talk a little bit about our work in this direction, which is quite interesting, I think. And eventually we discovered that variants were a thing and we had new waves and the herd immunity discourse kind of paved the way to change. And we went back into lockdowns and eventually we started thinking about how to learn to live with the virus. How to learn to live with the viruses. So, these are three distinct phases of the epidemic. They both relate to periods where we didn't have widespread vaccination available and we needed to address the problems on flattening the curve and all the, let's say, slogans that we have heard during the year. So, let's start with the very first bit. That comes from the first paper that I had with Joel. Have with Joel and Ishban on the subject of its optimal timing of one-shot intervention. And I hear, I think we should talk about the ambiguity, I think, that was widespread at the very early days when we were talking about lockdowns, because many people thought that, you know, we go into lockdown, we kill the epidemic early on, and we eradicate the virus at least locally, and then we live happily ever. And then we live happily ever after, COVID-free forever. But actually, I mean, I think none of us who know a bit about infectious disease thought that with lockdowns we would have solved the problem unless we would have acted globally and very decisively. But however, there is still value in having early lockdowns when you think that the epidemics is going out of control. However, you need to However, you need to be clear about which policies you have in mind, because different policies might imply different ways of thinking about lockdowns. And in this paper, we have focused basically on three questions or three strategies, like do you want to delay the epidemic or do you want to reach the immunity as soon as possible and try to minimize the overshoot? Or do you want to minimize the peak incidence if you have in mind the stress on the healthcare system? Know the stress on the alt care system. And how did we model this? Of course, here we do not want to have super realistic models because, I mean, we were quite a small group and we didn't have too many resources, but we wanted to understand at least conceptually what's the idea behind these lockdowns. So we started with the simplest model of them all, that is the SIR, with a slight modification that is basically changing the infectious. Changing the infectious rate beta in such a way that it becomes dependent on time. And you get eventually, if you model lockdown in the simplest possible way, you can think of it about reducing the beta value after a certain period by a certain quantity that we call 1 minus C. And this means that you are effectively reducing the contact between the infected and the susceptible. Contact between the infected and the susceptible, and you maintain this intervention for a certain duration. And after that, you go up again to the normal levels because that was like a one-shot intervention where everything goes back to normality after its end. And now you can play when you fix some of the parameters. Now, again, we are not really super interested in the actual value of the parameters, but just in the conceptual-like way that the concept they are. That the concept, the ideas that we can get out of this. So, you can look at some statistics, for instance, the number of susceptibles or the prevalence or the cumulative incidence. And here I plot a few curves. The black ones are the ones where you do not have any control, so you never intervene on the curve. Whereas the various colored ones are interventions that are made at different times of the epidemics. And you can see that depending on what you want to do, if you want. On what you want to do, if you want, for instance, to minimize the attack rate, then you cannot really intervene quite early because otherwise, the only effect that you have is that you stop the epidemic for a while, but then eventually it goes back to full epidemic and you have so many susceptibles that you are basically getting a normal wave. But if instead you are late during the growth phase, and here this is represented by the blue curve, you can indeed minimize You can indeed minimize the overshoot, provided that you reach the herd immunity thresholds that in this model is one over are not at the end of your lockdown. And this means that if you want to minimize the global burden, you need to act very late on the growing stage. But if instead your question is about minimizing the maximum peak Maximum peak of the epidemic in terms of the number of infected people, then this doesn't hold true anymore. And you need to intervene not too early because of the same problems as before, not so late because you are too close to the peak and therefore you won't have a rebound. So the sweet spot is in kind of in a middle ground where you are basically observing two different peaks that are more or less at the same height. That are more or less at the same height and are represented here by the pink curve. And eventually, if you have another problem that is delaying the epidemic so that the average time to infection is as high as possible, then it makes sense to intervene early. If you think that you're very close to discover a cure or if you want to buy some time to understand better what's going on, then early interventions are well served. Conventions are well suited for that. So, of course, to understand why, I think the most interesting bit is the minimizing of herd immunity. And I think the best way to understanding is looking at a face portrait approach. Like here we can plot the SR curve, and you immediately identify the diagonal that is the place where S plus R is equal to the whole population, that is one. Equal to the whole population, that is one. And this is an absorbing state in the sense that as soon as you reach one of the points on this line, then the epidemic is over. Now, of course, if you instead you are below that line, then the epidemic still goes on and eventually reaches a point that needs to be after the herd immunity threshold. So, no matter where you start, you will end up You will end up in a place that is above the immunity threshold point. And this means that when you intervene early, you can conceptually think about intervention as follows. So you start with an epidemic, say that you take a point that is close to zero in the R axis and close to one in the S axis, and you follow one of the trajectories if you don't. Of the trajectories, if you don't control the epidemic until you reach the attack rate or the final size. But imagine that you have an idealized situation in which lockdowns simply kill all the contacts between infected and susceptibles. And therefore, during your lockdown, you're just waiting for infected people to become R. This is equivalent to basically move horizontally to the right because the number of susceptible remains the same, but Of susceptible remains the same, but the number of recovered increases while the number of infected goes down. But eventually, unless you reach exactly total elimination, then when you start over, and you can see he turned on the right, when you start over and you go from A to A prime, then you are forced to go down after the immunity threshold. Whereas when you intervene late, you are basically preventing many, many more. Preventing many, many more infections. And this allows you to just go slightly above the immunity threshold so that when you lift the intervention, you basically have no more infected and no possibilities for a new wave to happen. That's the idea about why intervening late is better to minimize the overall burden. Now, of course. Now, of course, in the paper we explored a lot of different assumptions about the timings, about the strength of the intervention, about what changes if you have a different or not. And we have also extended results to metapopulation models because we were interested into looking at how different countries should cooperate to reach the same global goal. However, I think the very However, I think the very important message of our paper is about how timings of intervention change depending on the policy that you have in mind. So if you want to delay the epidemic, you need to implement lockdowns immediately. Whereas if you want to minimize the peak, you need to implement them during the growth phase. And if you instead want to minimize the attack rate, you just need to implement it just before the peak. Now, this one. Now, this was kind of a nice idea, but after the first restrictions were lifted, we were talking about herd immunity. And there is this paper by Tom Britton that is on science and it's very well known that defined somehow the concept of disease-induced immunity. Now, the idea is that real populations are heterogeneous and therefore. Heterogeneous. And therefore, if you model a lockdown as something that is not so harsh that it kills completely the heterogeneities of the population, but allows the epidemic to spread, then you can exploit the fact that the epidemic acts like a targeted vaccine, preferentially targeting people who are highly exposed, that is, the most active or the most susceptible people, if you want. So the main finding is. So, the main finding is depending on aging activity levels, you have various subpopulations that suffer different attack rates, but the lower herd immunity threshold is reached way earlier than you would expect with mass action models. So, we were really intrigued by this kind of works and we wanted to explore a bit what would happen if you do some model error or model misspecification, because we thought that it was an interesting way to look at the same problem. Way to look at the same problem. So, I need to talk very briefly about this finding by Britton because our work kind of stems from that. So, he basically considered a multipopulation as CIR with different rates of contacts between different types of persons. And the only difference between a normal SIR, SCIR, and its model is. SCIR and its model is this and this alpha coefficient that is the contact rates reduction coefficient. And his idea was indeed to look at lockdowns and to decide the strength of the intervention based on the minimizing the cumulative incidence. And indeed, exploiting this heterogeneity, he found out that the herding, the disease-inducer, the immunity threshold, is indeed much. Threshold is indeed much lower than what you would expect from a mass action model or a normal epidemic on an SIR. So, our idea was to be a bit more explicit about the contact structure of the population and more vary, doing some nature-based simulations or fully, but we soon realized that they were quite expensive to simulate, inform, and analyze. So, eventually, we decided to pick. So, eventually, we decided to pick MIMFID-like models that still describe the network, but in a much more tractable way. So, we consider a few models, mainly the degree-based heterogeneous mean field and the heterogeneous pairwise and an age-based compact mental model, but we have also extended the results to an age structure SCIR that was informed by the polymod studies. So, we have tested these findings on different models. Findings on different models. So let's start talking about the network that we have chosen. So we needed to specify a degree distribution, and we have chosen a negative binomial because basically we were ensured that we could vary the variance but keeping the average number of contacts fixed to 10 in this case. And you can see three different degree distributions that we obtained by varying the shape parameter. The shape parameter. And the interesting bit is that these three different degree distributions have very different heterogeneity. And the one on the left is basically a delta-like degree distribution, where almost all the nodes have degree 10, whereas the one on the far right is much more heterogeneous ones, and there are a few nodes who have more than 200 contacts. And then we went. And then we went on to describe our heterogeneous models. I don't want to go too much into the details, but the idea behind mean field models is that when you try to describe the evolution of the compartment, say the S compartment, you soon realize by looking at, if you want at the SIR model, that you need to describe it in terms of the number of births susceptible infected. So if you want the equation for So if you want the equation for S, you need somehow to leave the equation for SI on a network. And this is the pair level. And if you want instead to go one step further, then you're considering pairwise model where you try to give out equation for the pairs as well, but they depend on the triples instead. So basically, at some point, you discover that either you stop at some level of depth into the network, or you have to go until Or you have to go until the full network. And depending on where you stop, you call your models differently. In the heterogeneous mean field, basically you stop at the level of the singles and then you look at the pads and you say, okay, if you have a susceptible node and you look around and the probability or an infected node and you look around its neighbors, then the probability that one of the nodes Then, the probability that one of the nodes is infected is simply the total number of infected nodes over the total number of nodes. That's basically the prevalence. And this we know it's not true, because if you are infected, you are more likely to be neighbor of an infected node. So there are correlations that we are killing when we stop at the mean field level. And the same holds for the heterogeneous pairwise when we look at the triples. We have also considering the heterogeneous instead. The heterogeneous instead is because the various compartments are described in terms of the total number of susceptible nodes or infected nodes or recovered nodes that have exactly K-links. So we are not considering the average infected, but we are considering the average infected that has exactly K-links. Then we also put in some clustering because it was the straightforward implementation because it acted directly on the triple closure. Directly on the triple closure in the manner that you see on the bottom of the screen. And clustering coefficient is simply the total number of triangles over the total number of triplets that you have on the network. So now the idea is to see how this kind of strategy works out with different models. And we see that indeed, increasing the variance drastically reduces. The variance drastically reduces disease-induced immunity, confirming us that the work from Britain. However, we can see how different models give you very different estimates. They can vary by quite a while, like 5 to 10 percent, I'd say. However, the claim remains true, and so we just confirmed on many different network models. But we weren't fully fully uh you know fully convinced by this and the reason you can see back here in the in the motor population scir from from britain's paper that you have a contact rates reduction coefficient attacks on the whole network like at the same time so if you have an heterogeneous network to start with well once you do your intervention you still have an heterogeneous network uh it's simply that the rates go down uh Go down. However, in a more kind of realistic situation, you can think that there are a few types of contacts that you can really act upon and other essential contacts, for instance, household contacts, are not that easy to break down. So here we developed an edge-based compartmental model and the budgets behind is a bit involved to be described in this talk, but it's written down in. It's written down in the paper, and it's quite nice and interesting. But you can think a bit about this model as a multiplex network where you have two levels, the household levels and the community level. We consider households of size only four in which everybody is connected to everybody. And then each node is connected to the community through a degree distribution that is the negative binomial that we studied so far. We studied so far. Now, the interventions here can easily kill the community contacts, but they would keep the household contact intact because you cannot go into households and tell people to stop seeing each other. So what did we discover here? We discovered that basically, if you do a global intervention, just as we did before, indeed you find that the disease-inducer immunity gets really low. Gets really low. However, if you instead intervene only on the community, then these effects are greatly reduced. We are talking about 75% to 40% in the global intervention case to 75% to 55% in the community intervention case. So this means that modeling essential Essential context that cannot be disrupted is essential to get this immunity threshold right. But why does this happen? Well, the reason is that basically when you heal the network, removing community contacts, which are the more heterogeneous ones, you are not allowing the epidemic to exploit the heterogeneities in the communities. So all nodes become more or less equal in terms of the contacts they have. Less equal in terms of the contacts they have. And therefore, the epidemic doesn't preferentially target like a targeted vaccine the more active people. But then when the restrictions are lifted, then you get an epidemic that indeed now can target everyone according to their activity level. And this is why the early immunity threshold gets bigger. Of course, here in this paper, I think we. course here in this paper I think we we kind of demonstrated how network heterogeneities indeed reduce a third immunity threshold level and we tested a bunch of models to to see that this is kind of general of course we also showed that how you model intervention has a dramatic impact because if you consider some heterogeneities that you cannot maintain and others that you can then you get very different results and finally in in the third and final part In the third and final part of my talk, we were thinking about the flatten the curve issue. The starting point here is the hardworlding data. That it's a nice website that collects all sorts of statistics about many things, among which COVID. And you can look at the government response stringency index that is basically a measure based on various indicators on how strict government restrictions are in different. Restrictions are in different places. And you can see that basically nobody did a one-shot intervention, actually. And the reason is that there was somehow a feedback mechanism, but it's really understandable. Whereas where we had policymakers looking at the situation and then taking decisions on which restriction maintain, which restriction lift, and how to regulate the response. And so in late 2020, And so, in late 2020, we got the idea of modeling this kind of feedback mechanism that we see using tools from control theory. And this goes directly to feedback control loop models, where we had the following idea. We have, say, a network model. We have chosen a stochastic CIR on an urban shrinking network with many nodes. With many nodes, and you want to control how the epidemic is spreading into this network. But you also want to give people as much freedom as possible while at the same time ensuring that you do not put at risk the hospitals and the health care system in general. So, you have in mind an optimal curve that you would like to achieve, that it's not full elimination, but it's rather a curve that is gender. It's rather a curve that is gentle enough to not be too much disruptive. And now you have to somehow use your optimal or ideal solution to act on the network. But also, when you observe things on the network, you need to have a trajectory, tracking control that tells you, wait, we are not on the right trajectory. We should tune the control parameter that changes the government response. Changes the government response, let's say. Now, how did we achieve this? Again, we are using low-dimensional simple models and keep in, and also like notice that there is model error here because the high-dimensional system is an SEIRD, whereas our optimal solution is given by an SIR model in which the coefficient, the beta coefficient, so the rate of inflation. Coefficient, so the rate of infection is subject to variation depending on what we want. So, first thing is: let's define an optimal curve. The optimal curve is, of course, the one that has a peak that is below or at the very worst, at exactly at our threshold that we can fix thinking about the hospitals. So, we can solve the SIR so that we can find the beta that produces exactly that curve. And now, That curve. And now, if you look instead at the high-dimensional system, you can extract some statistics of it. We were thinking about, you know, how many people were infected, how many people were recovered, but eventually it's simpler to think in terms of number of infected and number of susceptibles. And then, you know, you can put the statistics that you get from the network into your controller and say, wait, we want the controller to act in such a way that if you are on the optimal trajectory, If you are on the optimal trajectory, then the controller tells you to stay exactly on the beta that you should aim for. But if you are away from it, then you need to act on the system. And the strength that you act on the system depends on the difference between the infected curve and the optimal infected curve, and the susceptible curve and the optimal susceptible curve. So, this tells you basically how. So this tells you basically how to modify beta in the real low dimensional system to get it back on the right track. However, we need a way to translate this into the high-dimensional system. And we have used basically a mean field approach where we have that we know that on a network, if you write down the mean field model on a network, you get equations that are quite similar to the SIR, but now instead of beta, you have this. Instead of beta, you have this beta times average number of neighbors of a node. So we thought, okay, then the map between the low-dimensional system and the high-dimensional system is basically, you know, putting this beta equal to the beta hat over average K into the network. And therefore, this is our map of how the controller works, and we can test how How the epidemics look like when you are in the best possible case. The best possible case is simply when you have an epidemic that for which you can get online estimates that are without any delay or any noise or any error. So you know everything that's going on on your network. You know everything that's going on on your network, and you can see here on the black curve, the black dotted curve is the optimal solution, whereas the three colored curves are three different approaches. Okay, the red one is simply the epidemic without control. The yellow one is the epidemic that you would get if you were using the model from the optimal control case. From the optimal control case. And the blue one is what you get when you use your feedback loop. And you see that when there is basically no model error, no, sorry, when there is basically no noise or delays, then what happens is that if you start a little bit higher than the optimal curve, the system already acknowledges it, goes into full lockdown. But when you are back on track, then it starts reopening and eventually it gets to the desired beta and stays there forever. Stays there forever. Of course, this is not a realistic kind of situation because, in general, you do not have good estimates of the number of infected or the number of susceptible people in your population when you try to extract statistics. You know that they come with some delay because you need to test people, then you need to collect the samples and you need to analyze them. Samples, and you need to analyze them, and so on. And it can take you know, three days, but also, in some cases, a week or two weeks, if you are particularly unlucky in an unlucky stage of the epidemic. But also, when you try to infer the total number of infected people from the tests that you've made, you of course have a kind of noise into that estimate that is, of course, proportional to the incidence because the more people are infected, the more you expect to be. infected the more you expect to be to be far from from from the truth also here in the ideal cases we can tune the this beta control parameter like as much as we want in a continuous fashion without any problem however we know that in in real life uh in real life you can say you know to people you know wear a mask or you know go into curfew after a certain hour or stuff or stuff like that but you cannot Or stuff, or stuff like that, but you cannot expect to be super fine-tuning your control. So, this should be discretized. Also, when you go into full lockdown, you cannot achieve exactly eta equals zero because some infections will happen no matter what. So, there is also minimum value for your control. And finally, you cannot change in time your control because you cannot tell people continuously how to behave. And so, we considered And so we considered a model where you can update policies every 20 days. So basically, we tried to stress out this feedback loop mechanism to see if it was still worth it. And what we have found is basically the same curve as before. Now the yellow one is a bit different because it's a 60 days lockdown followed by full openings. And we also consider the fact that every month. The fact that every moment that you are above the optimal curve, then it means that your healthcare system is in distress and you expect the mortality to rise up by a certain coefficient, that it's because simply people cannot get treatment in time. And so we have done exactly the same as before, but now you can see how all these delays change dramatically how things are shaped. Shaped. Like, for instance, at the very beginning, the controller doesn't realize that we are far away from the optimal solution. When it does, it goes into full lockdown as much as it can. And then when it finally realized with some delay that is below the optimal curve, it accepts for some reopenings. And on average, that is the dashed line, you get nice kind of results that do. That are more or less below the optimal solution, but of course, the variability dramatically can increase the more noise you add. So what we wanted to say in our paper is that you can use control loop feedback control to model epidemics. Even if you have a simple model, you can kind of get away with. You can kind of get away with murder because the feedback control takes care of that because even model error can somehow be used by the model to act on the real system. Of course, then we were aware that we were using some idealized model, and the reality is much more complicated than that. So we tried our best to put some errors on our model and show. On our model and showcase that non-ideal behaviors have an impact. However, we think that the main point remains valid, that if you think about continuously looking at the system and apply control over it, then you get some better results. Actually, the best results that you can get possibly. So, in conclusion, I talked about very quickly and briefly about three papers. Briefly about three papers, I surely overlooked a lot of interesting stuff that we discussed in those papers. But I wanted to get directly into the points that we were trying to make back in 2020. And I think the main take-home message here should be that the model error is a thing. So when you develop theoretical model to show something that you think is true, then you should also kind of be aware of what happens when the reality. Happens when the reality doesn't behave like your model. And this is something that I think everybody is aware now, at least listening to all the previous talks, but still, I think it's important even for purely theoretical people. Another important aspect that I think it needs to be stressed is that simple theoretical models are still useful because they help us conceptually understanding the fundamental mechanisms behind what. Mechanism behind what we observe. And even if they are not super realistic, they still lay out a conceptual framework to work with. Then there is an important point that I think its network models should still have their place in the infectious disease community, because I think they are still used today, for instance, to inform more complicated models such as ABM or individual-based models. Know individual-based models, but they have their own right of existence, and you can learn a lot by studying epidemics on networks still. And then the final remark is that, of course, giving out numerical estimates should be done with caution because it might be quite problematic if you're wrong. And this is more or less what I wanted to tell you about today. And thanks.