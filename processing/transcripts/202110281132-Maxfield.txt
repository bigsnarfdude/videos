To join you in Banff. I've been googling pictures of what it looks like where you are today, and I'm a little bit jealous. But hopefully, sometime before long, I'll be able to join you all somewhere beautiful like that. But for today, I'm going to talk about some work in progress that hopefully will appear on the archive soon, which is inspired by Inspired by very simplified pared-down models of black holes as collections of qubits that have been useful in the past. And I wanted to. So a lot of this was motivated by conversations, for example, with Samir Mateur. So there's some, he's got some credit for this line of thinking as to exactly how replicable humiles fit into that sort of picture. I've got a sort of perfect gas of comments. Perfect gas of comments at the end, which will expand or contract to fit the space available to them. So, everyone should feel free to interrupt at any time. There are various points where I've been sort of deliberately brief, but if people want me to expand on certain things, then I can do that. And if I don't say everything that's in my slides, then that's absolutely fine. So, please do interrupt at any time. Good. So, yeah, as I've said. Yeah, as I've said, previous discussions of quantum black holes has been useful to think about some of these very simple models where we don't worry about all the details of gravitational dynamics and the sort of exact state of Hawking radiation, all these sorts of things that are, of course, very important if you want to do detailed things. But if you strip those away, there's still the essence of the sort of usual old confusions we have about. Sort of usual old confusions we have about black holes are still there in sort of a context where we can really calculate everything and get our hands dirty and play with ideas in an extremely concrete and calculable setting. So I think that this was probably pioneered by Samir Tur. He's got a beautiful review of the information problem from the early 2000s that introduced these sorts of things. He used a little by Steve Giddings and Giddings and Xi to talk about sort of the model. And she to talk about sort of models of how you might produce unitary Hawking radiation. And also, Joe Potinsky's nice review of the information paradox in the late 2000s discusses these nicely as well. So by their references that I'd recommend, if you'd like to know more details. And one particular aspect of here, which was sort of the heart of the MAMPS paradox, Mater Amiri. Mathur Amiri, Mirof Polchinski, and Sully was this idea that you can't take the Hawking process of production of particle pairs near the event horizon, which is producing entanglement between the interior and the exterior. If you'd like to go from that picture, which is this red curve that we've all become sort of very familiar with, and turn that into the green curve is what we'd expect from unitarity. Unitarity and the Beginson-Hawking formula counting states, then you can't just make small corrections to that radiation production process, but you need to do something a little bit more dramatic. So that's, in this context, is a very concrete sort of no-go theorem that we'd like to see how we evade that in replicable models. So that's the idea for today. Replicable wormholes. So that's the idea today: to review these models and put replicable wormholes in, and then that gives us a very concrete setting where we can play and ask various different questions. So first of all, I should warn you the kind of model I'm going to come up with. It's in some sense extremely conservative. I just, we've learned that replicable wormholes are doing something very nice for us recently. And the models I And the models I come up with are going to be what you get by staring at a rectangle wormhole. This is a particular sort of geometry and very directly interpreting that in gravitational language. So I think this is a very reasonable definition of what we mean by low energy gravity. So it's just taking the laws of nature that we've seen, experimentally tested, we know and love, and making a reasonable extrapolation for what that theory should look like sort of in a more complete way. Sort of in a more complete version without introducing more speculative ingredients, strings and brains, and so forth. And I think if I talked about given this talk in 1995, I think there's an alternate history where that could have happened, then I think that it would have been taken as fairly conservative and following various developments that were happening at that time. But now I think it's regarded as very radical because we've already had various talks about, so for example, from Alex. Talks about, so for example, from Alex this morning about ensemble duality and so forth, is this sort of picture is going to give fits into that paradigm of ensembles in ADS-CFT language, which is, of course, in conflict with the top-down stringy constructions that we have from ADS-CFT. So it's a departure from things we think we've learned in the last 20 years from that point of view. So to say that more, a little bit more concretely, we're going. Concretely, we're going to be constructing a Hilbert space of several black holes. But despite the fact we're thinking of these black holes as being in distant parts of the universe and very far apart and prepared in independent ways, that Hilbert space is going to involve these black holes talking to one another. So the inner product is going to be mixing on that Hilbert space, is going to be mixing up these black holes. So this is a sort of in technical language is a violation of cluster decomposition. It tells me that physics over here and Decomposition tells me that physics over here and physics over here doesn't straightforwardly separate. And the resolution to that picture, as pointed out in the late 80s and early 90s, is that the Hilbert space splits up into different superselection sectors labeled by some discrete or continuous parameters alpha. And on the right-hand side, in each of these individual sectors, you do have this cluster decomposition and physics in different black holes independent. Physics in different black holes is independent, but once you add them all together, that mixes things up. So, again, in the ADS-CFT language, these super selection sectors would correspond to the dual Hilbert spaces of individual members of the ensemble. And this direct sum over different sectors is telling me that I'm considering an ensemble of CFTs. But there is a way of, the way I've reasoned I've written it in this way is to remove us from the context of ADS CFT. The context of ADS CFT, and to emphasize that this is really just something we're very familiar with in quantum mechanics, is it's not sort of a modification of quantum mechanics. Everything lives in a Hilbert space. It's just that the algebra of operators you have access to don't act irreducibly on your Hilbert space. So it's, in other words, you have an algebra of operators, which are those accessible to asymptotic observers. And once you Observers. And once you have a state that lives in one of these super selection sectors, it can't move you into a different one. So they all act within each sector. And this is something that happens in even just something as mundane as spontaneously broken global symmetries. Okay, so there's you then might ask the question as to why we're studying this model that involves all these selection sectors. This model that involves all these selection sectors, if we believe in ADS-CFT and these stringy constructions, where those things are absent, maybe that we're just taking these too seriously. So, the hope or speculation and why I think this is a worthwhile direction to pursue is that if you take some of these models that do have super selection sectors, you take the gravitational language very seriously in those models, you can start to narrow down the ensemble again, the idea of CF2. Again, the ADSCFT language and concentrate on a single superselection sector within those models. And then the hope is that the physics within a single super selection sector is going to resemble what the physics would have looked like in something like the dual of any plus four. So that's a sort of broad motivation for taking these things seriously and really exploring the consequences of these kinds of models. Okay. Okay. If there are any questions on the general overview, then I'll jump into reviewing the bit models, first of all, without replicable models. So this will be more or less following the discussion of Mateur, for example, that I mentioned before. And if you'd like more details, then that paper is a great reference. Okay, so let's start off by talking about the states that we're modeling and the Hilbert space that we're modeling. So we're going to take That we're modeling. So, we're going to take the very simplest context. There's lots of ways you can generalize this and play with this, but I'm going to take the simplest context I can, which is think of a black hole that we're going to form from collapse with some specific initial pure state, and I'm never going to change that state. So it's just think of one particular way of forming a black hole. And then we're going to just allow it to freely evaporate. So we're not going to throw anything else in. So just leave it alone. It's the simplest possible thing we can do. Simplest possible thing we can do. Now, given that, there are still lots of internal states that our black hole could have. The reason it has different internal states is because as it evaporates, you have the Hawking process at the horizon. Some radiation escapes, and that escapes at some time with some wave function and some polarizations, and it produces a Hawking partner that is an excitation inside the horizon that has some corresponding wave function and polarization states and so forth. So, there's some internal states that. There's some internal states that live in the interior of the black hole. So you can think of these living on some Cauchy slice that I've labeled sigma k here. And we're going to describe the degrees of freedom for those interior excitations with some set of bits, C. So the first bit of Hawking radiation is emitted, and there's some Hawking partner that is in two states labeled by the value of C1. Then there's some other second emission of. Second emission of forking quanta, and there's a corresponding partner with states labeled by C2. And at some particular time, Tk, there'll be K of these bits inside the black hole. And as time goes on, this label K will grow to roughly linearly in time. So K will increase by one once every thermal time, roughly. Okay, so we've got these two to the power of K states labeled by the Hawking part. States labeled by the hockey parts. Okay, so that's the states. I'd also like to have some model of the evolution. So one of the reasons to introduce this model is to get a handle on really what's going on at the horizon where I'm producing Hawking radiation and understand sort of the process of infalling observer. So for that, I really need some kind of picture that dynamics that takes me from one slice to the next. That takes me from one slice to the next. So I'll just say this slice sigma k, I've taken it to be sort of nearly null outside the black hole, and that's so that this slice doesn't include the state of the Hawking radiation that's already escaped. It's really a state that's describing just the interior of a black hole, and there's no sort of matter excitations crossing it because I've decided that I'm not going to throw anything else into the black hole. Okay, so now we want to introduce this evolution, which is going to take us from a slice sigma k minus one up to some slice sigma k, which is waiting for one more Hawking quantum to be emitted. So to make this a sort of unitary time evolution, this Cauchy surface or partial Cauchy surface sigma k minus one is not quite equivalent to sigma k because you need to add To sigma k because you need to add in a little chunk of scry plus. And that little chunk of scry plus is just enough time that it contains the kth bit of Hawking radiation. So that means that the Hilbert space hk minus one, describing the states on sigma k minus one, is going to evolve with some unitary to a Hilbert space describing both sigma k and a bit of Hawking radiation. A bit of Hawking radiation. And it'll be an evolution that looks like this. So this operator UK, which is producing some excitation in the interior and some piece of Hawking radiation. And what this does is it leaves the first K minus one bits as they were, and it just produces this new bit, which is going to be in some maximally entangled state. Going to be in some maximally entangled state. So if you like, you could just pull this psi as one over the square root of two times delta BKCK. If you like, I've left it as an arbitrary state psi because it's just useful to distinguish the B's. These are Hawking's B modes that escape to Scribe Plus from the C modes that are inside the black hole. So it just makes it a bit clearer where all these states are living. But okay, that's the basic evolution. Sorry, can I ask a quick question? Can I ask a quick question? Please, Mark, yeah. Just so the U here is an isometry, I guess, or just confused about the dimensions of the Hilbert spaces here. Yeah, so technically, UK here is not a unitary, but it's an isometry. So, there's the reason for that is that, yeah, I really only want UK to describe how the state. Want UK to describe how the states change under forward evolution. If you imagine I started with a generic state on sigma k along with the radiation that wasn't entangled and I evolved that back in time, then that would produce some shockwave at the horizon and it sort of moves me to some different part of Hilbert space without a smooth horizon. I'm just for now, I'm describing the piece of Hilbert space that has a smooth horizon. And then, so that, and that is not, it's the usual thing. And that is not, it's the usual thing that it's if you start with a generic state near the horizon and evolve forward, it becomes smooth on the horizon. But if you start with the generic state and evolve backwards, it becomes very singular. So yeah, so this is an important technical point. You should keep an eye out. And if I ever use UK to evolve backwards in time, you should be suspicious for exactly this point. But I'm only ever going to use it to evolve forwards. So it's fine that it's an isometry. That's a feature of that. Yeah. Thanks for that comment, Mark. Thanks for that comment, Mark. Okay, so yeah, one very one specific slice here that we'll find useful is when this label k, the sort of discrete time label, reaches the very end of evaporation, which is our maximal value, capital K. And in that case, this slice, this Cauchy slice, sigma capital K becomes the entire black hole interior. Black hole interior. And you might think of this as some closed universe. Okay, there's maybe some quantum gravity stuff going on in the very final moments of evaporation. So there's something mysterious going on on the very right-hand side of this slice. But modulo that, it's just some sort of closed universe that, in a traditional description of information loss, is sort of splits off from our parent space-time and is forever lost. Time and is forever lost. And in particular, we can compute the final state on this final slice sigma k along with scry plus and its sort of maximally entangled state on capital K bits, which is an intensive product of the black hole interior and the radiation. So this is okay. So this is one particular time that'll be useful, actually. Okay, so I've given you the set of states, I've given you a thing for a rule for evolving forward into the future, and now I need to describe the inner product. And the answer I'm going to give is probably one you're all thinking of implicitly anyway, which is just that this bit basis that I guy gave you is actually orthonormal. So it's if I were to think about how I would compute this in gravity, this is a little. Gravity, this is a little bit overkill from this point of view. It's just sort of quantum of fields within some weakly gravitating region on some particular slice. So this is a little bit overkill. But in principle, what I would do to calculate this inner product between two states on sigma k is compute the path integral, the gravitational path integral bounded by these two Cauchy surfaces, sigma k. And I'd sum over all the geometries, and this would involve. This would involve the sort of two contour in-in geometries, where on the left-hand side, I've indicated the sort of bra that describes the state C prime, on the right-hand side, a ket that involves C. And this pink surface, I've indicated the region over which I might be doing a path integral. So the geometry that's relevant here is the piece between the green surface, sigma k, and the pink surface, which is basically arbitrary. So that's sort of forward time evolution. That's sort of forward time evolution on the right-hand side on this kept C, and there's a matching backward time evolution on the bra C primed. And this is how in gravity we would impose the Hamiltonian constraints would be in principle in the path integral language by this sort of evolution. Yeah, so then the right-hand side would be a path integral weighted by e to the plus is, and the left side would be. E to the plus is, and the left side would be a sort of complex conjugate weighted by e to the minus is with some time reversible or CBT. Okay, the only reason I emphasize that is that that'll become more important later when we introduce the replicable works. But it's just the principle of how one computes inner products of gravity, and that's what we're modeling here. Okay, so as I said before, this, as described so far, is a conventional model of information. So far, is a conventional model of information loss, more or less. So, if you want to work out just the state of radiation, that means we should trace out the black hole interior. So, that means we take something like this state that I've drawn here. We have two copies of this state. Maybe I should just say something about the notation here. I've used this bold letters bold B or bold C to denote some string of bits, because otherwise the notation is going to get really out of control. Hopefully, that's not going to cause any confusion. But if it does, please interrupt and I'll try to clarify. Okay, yeah, so we take two copies of this sort of state on interior and exterior, and then we trace out the interior, which means that we're computing some inner product on the interior. So the C prime C inner product. And this is basically just a chronic deltas. And what we end up with when everything is properly normalized is really a maximum. Properly normalized is really a maximally mixed state of radiation with an entropy that is just the number of bits we have that you can think of as increasing linearly with time. It's the sort of red curve I had in the page curve before, and this is information loss. And say Mateur's small correction theorem, for example, various other results in the essence of the AMPS paradox is that you can't make some small tweaks to this inner product or small tweaks to this. Product or small tweaks to this evolution that will fix this. It needs something more dramatic. And okay, I won't use the very precise version of those theorems, but this is some precise version of what is meant by a small correction, but it's relatively close to what you might intuitively think. Okay, any questions on this sort of initial model before I throw a replica worm away? Wormhole. Okay, good. So let's add a replica wormhole. So, first of all, I should say, what is a replica wormhole? And I'm going to draw them all in Lorentzian signature. So it may be a little bit less familiar. But in the end, a replica wormhole is just the geometry that joins together multiple replica black holes. So I take several of these black holes that I can. Of these black holes that I can think of as living in different universes or very far apart in the same universe, or one very far in the future of the other, or as long as they're well separated. And gravity allows the geometry to become connected between these things, despite the fact that they're very far apart in the sort of ambient space. And if we really directly interpret these geometries, then These geometries, then these things should be contributing to the inner product on a Hilbert space, not of a single black hole, which is this CC primed inner product that we introduced here, but on the Hilbert space of multiple black holes. So we take n black holes, and because there's some connection, we're going to be mixing up the inner products here. We're going to be mixing up the different, the separate replicas in the inner product. Inner product. So here, the replicas I'm really thinking of as being physical but identical black holes. So we often think of the replicas in the replica trick as being sort of mathematical fictions that are useful for our calculations. Or in some recent language, the replicas are thought of as different quantum computers simulating our gravity system. These are all reasonable perspectives, but from my point of view, I really want to think. But from my point of view, I really want to think of them as actual physical copies of my system that are well separated. And I'll explain this picture in, yeah, well, now, I guess. So this picture is asking how these geometries are, what these geometries look like in contributing to the computation of an inner product on two black holes. So this is the n equals. On two black holes. So, this is the n equals to two example. So, that means that my states, so the basis of states I'm going to take is still these collections of bits on each black hole. The only thing we're going to be modifying here is the inner product. Keep the same states, we'll keep the same unitary evolution from one slice to the next. The thing we're going to be changing is the inner product. And we've got the same rules to compute the inner product as before, where we take the two. Uh, the two well, we've now got for this n equals two example, we now have uh four slices in general, two n uh boundaries for our um for our path integral. We've got n copies of sigma k that live in the kets. So that's producing the state C1 and C2. So there are boundary conditions on these green slices that are defining the states we're interested in. Then we've got n copies on the primed guys, C1 prime, C2 primed. These are second. two prime these are second copies of sigma k that live in these sort of complex conjugated space-times the second branch of the inin contour and then we join them in any way we like and the novelty of a replica wormhole is that they get joined with some new and interesting topology so before we had these sort of pink fuchsia arrows that were just joining together copy one with copy one or copy two with copy two the novelty of a replica wormhole is that we join The novelty of a replicable whelm hole is that we join them together with this sort of permutation, in this case, with a swap on some region of this final Cauchy slice, and that's the region that we'll call the island. So what this path integral does, what this particular geometry contributes to the inner product, is something like I've written here. So this sigma hat of Scry, this curly eye of the island. This curly eye is the island, and sigma hat is the operator that enacts a permutation on this island. I think in Jan's talk, we had some similar operators. But okay, so this is the swap operator that literally acts on a tensor product Hilbert space, just exchanges the two factors. So that is something we can think of as acting on the matter degrees of freedom, if you like. And then we've got this pre-factor that. Factor, this lambda thing, and that comes from the gravitational action. There's actually something funny going on where these fuchsia surfaces meet these yellow or blue surfaces, where there's some weird topology going on. And there's some very old discussion going back to the 90s, work of Sorkin and others, and more recently, motivating the fact that these should have some finite contribution to the action. Contribution to the action, but it's not infinite. So, you know, often these sorts of singularities we might exclude because they've got infinite action, but this one has some finite action. And it's proportional to the transverse area of this surface where they drop. And perhaps won't go into the details of this here. And there's also a contribution from how complicated the topology of this rep. From how complicated the topology of this wormhole is, which is coming from some property of this permutation, which I can explain if people are interested. But it's not too important. The important thing is only that this action contributes a finite piece that tends to suppress things by the exponential of the area. Okay. Now I should. I've said here that this sigma hat of the island. That this sigma hat of the island I'm thinking of as a Heisenberg operator. So that means that actually the time it acts at, or the Cauchy slice that it acts on, is not necessarily the same as the Cauchy slice where we're defining the states. So there's a little bit of forward time evolution to get to the island, then we enact the operator, and then we evolve back again. So there's the sort of U-dagger swap U going on that we're used to from Heisenberg evolution. So in practice, this means that This means that we should, as I've written on the right-hand side here, this tau2 operator involves acting with this u operator to evolve it for some number of steps. So there's some step, sigma k is where we started, and sigma k island is some Cauchy slice where the island lives. So we have to evolve by k island minus k steps into the future, and the same into the past. Past and is a relatively straightforward calculation that is that tells you that this extra Heisenberg evolution and the production of Hawking radiation gives an extra suppression. And the extra suppression is given by basically the exponential of the number of bits of Hawking radiation that happen in that evolution. So these pictures on the left look a little complicated. You can pare them down and write them as a sort of circuit diagram. Down and write them as a sort of circuit diagram, as on the right-hand side. So these psi's are the state of Hawking radiation, is the state that's produced on the interior and the exterior by the Hawking process. And then we've got these purple lines. The purple lines indicate where the escaping Hawking radiation goes. And that just gets traced out. So we just straightforwardly identify it. And then the blue lines and the yellow lines indicate the production of these Hawking partners, which we're swapping. Partners, which we're swapping. And you can follow around these sort of closed loops that connect the psi up. And there's just one big closed loop. And that roughly is where this extra suppression comes from. The calculations are not too difficult, but the essence of it is hopefully you've got some feel for where that's coming from. And once you've combined this geometric piece, the lambda, with this extra. With this extra piece from the production of Hawking radiation, that is like a matter entropy. And these combine into some combination that looks like area over 4G plus entropy of matter. So you get something that's like e to the minus the generalized entropy. But that sort of that combination comes out sort of fairly automatically in this simple model of bits. Okay. Good. Yeah, so this model is. Unfortunately, the notation gets a little bit out of hand because you've got each black hole has k bits, and then you've got n black holes, and it all gets a little bit confusing. So yeah, everything looks a little bit complicated at the moment, but I hope that I've got the essence of the idea and that really the model is relatively simple. You just take k black holes and there's some piece of the Holes, and there's some piece of the inner product that involves permutations of parts of those subsets of those bits weighted by some factors. But I'll pause for questions. How am I doing on time? I'm not sure what I've said. You have about five more minutes. Five minutes. Perfect. Any questions or clarifications at this point? Okay, so because it's all a little bit overwhelming and confusing with all the islands and it's you know the notation is a little bit out of hand, I'm going to make a just discuss a slightly more pared-down version of the model that is the very simplest version, which is basically what it follows from something that a paper of Polchinski and Strominger in the mid-90s. Polchinskik and Strominger in the mid-90s, which you can think of as an early version of the island rule, where they didn't know about quantum extremal surfaces, but they thought in modern language, what would happen if we allow an island to cover the entire black hole interior? So that means we're just going to allow the only thing, the only correction to our owner product we're going to allow is this permutation on the very final slice, which is this. Final slice, which is this baby universe, sigma capital K. And we're not going to include an area suppression factor. It just makes life simplest. So one way to think about this is that you have a conventional picture of information loss where you create your black hole, it evaporates, and eventually the black hole has disappeared completely, leaving you just with the radiation. Completely, leaving you just with the radiation. And then the black hole interior becomes its own closed baby universe that lives off in the void. And the idea of this model is just to say, hey, we should treat these universes as bosons. One universe in state psi one and another universe in state psi two should be the same state as one universe in state psi two and a second universe in state psi one. The wave function. State psi1. The wave functions, if you like, should be permutation invariant. And I think that's an extremely conservative idea that no one would find controversial. So take that seriously. You now compute this inner product. And for the reasons I said before, you include these permutations. So these are now the inner product on some slice at a finite time. So to compute the inner product on the slice at a finite time, you should evolve to the very end point of evaporation on the slice sigma capital K, then introduce. Then introduce permutations and then evolve back. Oh, okay. Maybe it's better to say you evolve both the bra slice forward and the ket slice forward and introduce permutations. And that, as sort of comes from this sort of circuit diagram picture, gives you these suppressions both from the number of bits that have been that are to be evaporated and the number of bits of Hawking quanta yet to come. So it's just the model is you simply take The model is you simply take n collections, each of k bits, and you introduce an inner product that includes permutations weighted by these specific factors. And these things come out naturally from this sort of circuit diagram. So in particular, with this inner product, this U that we introduced to do time evolution from one slice to the next is unitary or more technically an isometry, as Art pointed out. Summitry, as Mark pointed out. I mean, the reason it's a unitary is really by construction. We define the inner product by evolving forward in time. So automatically, that evolution itself is going to keep the inner product fixed. In particular, also the corrections to this inner product are exponentially small. So they all come with this, if we're far from the end of evaporation, so the black hole is still macroscopic, means that capital K, final time, is much. K, final time is much bigger than little k, the current time. So there's an exponential suppression of all the non-trivial terms here. So that's one way of saying that there's a smooth horizon, that we still have the usual sort of unitary production of Hawking radiation, and the inner product isn't doing anything too wild at early times. There's these exponentially small pieces. But nonetheless, when you make observations of radiation, you get the page curve. Okay. Okay, so let's very briefly. I'll maybe I won't explain in detail why that is, so I can make some comments at the end. But yeah, so in the end, we get some expressions now for the state of the first k-bits of Hawking radiation that again look quite similar to things that Jan wrote down in his talk, but coming from a rather different context, where the density matrix. Where the density matrix itself is not just maximally mixed, that is the identity, but it's a sum of permutation operators. So the n equals two version involves one piece that's the identity operator and another piece that's the swap operator. And if you compute the von Neumann entropy of this density matrix on, say, two black holes, it's very, very close to maximum. So maximal would be k log two, but you said there are two black holes, so it becomes two k log. That there are two black holes, so it becomes 2k log 2, and the corrections are really tiny. So, this was actually guaranteed by this small corrections theorem. We haven't done anything too dramatic, so the von Neumann entropy doesn't change very much. But the important point is that the von Eumann entropy is not something you ever observe. It's not something linear in a density matrix. And instead, if you wanted to work out the von Eumann entropy from some experiment, you would need to do something. You would need to do something cleverer, and really you would need to produce multiple copies of the system. But in gravity, because of these wormholes, you can't make these copies independent. And the really physical thing is something like the expectation value of a swap operator. So tau2 here is the operator that exchanges two copies of the radiation. And there's this quantity paid with Don from last year. We call this the swap entropy. This is the entropy. Swap entropy. This is the entropy that you would deduce by actually making physical observations on copies of the system if you were to imagine that they were uncorrelated. And this quantity gives you a page curve. So it gives you not just k log two, as in the number of bits of Hawking radiation that have been emitted, but the minimum of the number of bits that have been emitted and the number of bits that are yet to be emitted. So that goes up for a while, then when the black hole is halfway evaporated, it comes back down. So that's the version of this. It comes back down. So that's the version of this page curve in this very simple way. Okay, so I think I'm out of time. So I will just briefly flash up the sort of ideas of where to go with this. So far, apart from a sort of concrete explanation of how these replica wormholes avoid these small corrections theorems and so forth, there's nothing particularly novel in here. But I think there's a lot. But I think there's a lot to do with this model that will give a bit more insight because it's such an easy place to actually do calculations. And the interesting things really happen when the number of black holes becomes very large. So far, I've just been talking about having two or three copies of the system to do things like this swap entropy. But when n becomes large, then very interesting things start happening. And in particular, when n becomes exponentially large in the entropy. So one feature in particular that I think is interesting to explore. I think it's interesting to explore is how we approach a single super selection sector in this sort of model. So you imagine making many black holes, measure the radiation, and how that creates the state of many baby universes. And in the end, this should be something that looks like the final state proposal of Horowitz and Meldersena, except we've never actually modified quantum mechanics in getting there. And that's interesting to understand in more detail exactly how that works. Detail exactly how that works. Another question that's work in progress is to ask how we count states of black holes in this model. So, if we just had a naive set of k bits that are maximally entangled bits that describe the black hole interior, it looks like there are two to the n k states. We have n copies. So, that's like the too large entropy that is giving us the information problem. And in this model, if And in this model, if the number of copies becomes very large, then eventually we actually should get a much smaller Hilbert space, and that's coming from these permutations. And there's a very interesting story about how that works that I won't have time to go into today. But that's work in progress as to how this topology-changing processes are actually enough to get the right state counting, a sort of truncation of the Hilbert space of black holes. And the last point is it gives. It gives some idea of how to explain a canonical formulation of replicable wormholes that perhaps I won't go into because of time, but let me just finish with sort of a general maybe comment about gravity is that it's giving us lots of surprising results that perhaps it didn't have any right to know. It knows about the microscopic skate counting of black holes from Becca Stein Hawking. We now know it knows about the page. We now know it knows about the page curve and gives detailed things about the statistics of the spectral microstates and so forth, and perhaps lots of other things. And I hear a lot that people ascribe this to the magic of Euclidean gravity path integrals. The only first, this page curve calculations really don't require any Euclidean piece. There's technical reasons to include Euclidean. Technical reasons to include Euclidean calculations where things are simpler. But really, these are Lorentzian calculations describing processes in real time. And you can describe everything in terms of a Lorentzian path integral. So I don't think that Euclidean word is very necessary. And also, there should be a language of the canonical formalism to describe this as well. So really, this is just gravity doing work for us when we have the proper definition. But with that, I'll invite any more. Uh, invite any more questions. Maybe uh, time for a couple quick questions. We have any from the in-house audience. Okay. Okay. How about the virtual audience? I actually see hands up from Henry, could you actually say more about the canonical interpretation of your toy model? Yeah. Okay, so it's certainly not a complete picture at the moment. Moment, the speculation is roughly as follows. So, first of all, the first thing is to set up the canonical formalism in a theory with constraints in a form that's going to be most useful for the closest approach. So, in the sort of traditional algebraic way of quantizing a theory with constraints, we have some algebra of constraints. We have some algebra of constraints. With the Dirac procedure, it's not actually much instruction for how you construct an inner product on your Hulbert space. He tells you how to construct an algebra, but you're left to fend for yourself for an inner product. There's one way of doing this, which is to, first of all, quantize the theory without constraints, and then you later design, and that gives you a sort of kinematic Hilbert space, and you later impose. Space and you later impose constraints on top of that just by roughly speaking inserting a delta function of the constraints. It's slightly more complicated when you have a non-abelian algebra of constraints, but this has been developed in great detail in the 90s in the context of, you know, motivated by gravity and is equivalent to BVB RST and all these kinds of things. And one way of imposing that delta function is to write it as an integral over a group of constraints. So if the algebra of constraints So, if the algebra of constraints is the Lie algebra of some group, then you can write this delta function as an integral over that group. And that's one nice way of defining an inner product. You can think of these group elements as being quantum, sort of quantum versions of gauge transformations, and the physical Hilbert space is a coset that's where you identify states that are equivalent under one of these gauge transformations. So, that once you've got that picture, so this is just a perhaps unfamiliar way of doing theories in a product on theories with. Doing theories inner products on theories with constraints, this integral over some group or a sum over some group looks a lot like our island inner product, where we quantum gauge transformations are permutations on islands. So the proposal here is that you should be gauging these permutations of islands. That's the basic idea. There's lots of technical details to work out and things that I don't want to take all the time to say, but that's the essence. That's the essence of the idea. Yeah, just a quick question on that. So, presumably, you're defining the constraints on some like single time slice on. I mean, usually you define the constraints on some time slice on a fixed background, but here you have topology changing configuration. So, how do you actually define what? Yeah, so we're used to composing constraints on a single time slice because we only really need to impose them. We only really need to impose them perturbatively. So you have some small change to the Hamiltonian, some small change to the lattice function, or that moves your slice a little bit, and that imposes the Hamiltonian constraints, for example. But if you're sometimes the sort of detailed topology of this group of constraints is important, and this is such a case. So this is why I had to introduce this group. Had to introduce this group averaging formalism. Why I had to use this unfamiliar language. But yeah, really, the constraints in GR in the path integral language are coming from integrating over some non-trivial geometries that involve time evolution forwards and backwards. And really, we usually only care about the infinitesimal time evolution. And then you just say, okay, it replaces by a delta function because you integrate over any amount of time. But now, because we've got these. But now, because we've got these islands, you have to integrate for a finite amount of time, do a permutation, and then integrate back again. So that's why it's different and looks a little unfamiliar, and why this is a proposal with details to be worked out. Cool. Thank you. All right, thank you. Unfortunately, we're out of time, so let's save the remaining questions for a discussion session. Yes, thank our speaker. And we'll reconvene at two after lunch. Thanks, Henry. I could say hello. I'm responsible for health as Christian friends.