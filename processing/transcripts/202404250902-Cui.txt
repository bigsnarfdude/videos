Smooth potentials. So we can derive this very classical Hamiltonian OD system as follows. Now, if we change a little bit on the initial values, we assume that the initial value x0 is random and satisfies some distribution mu0. And keep v0 is fixed. And then as time goes by, the xt should be a random variable. Now, if we look at the evolution of this density of xt. Density of Xt. We denote this density as Zot Xt. Then, along this time evolutions, actually, one can check the evolution of the densities. It should satisfy this continuity equations. And along this Hamiltonian OD system, we transform the total differential into partial differential, and we can get to the PDs for the velocity as well. In some situations, like the control areas. Situation like the control areas, the velocities also have some original functions such that v equals to gradient s. Due to these properties, in this particular situation, after a function of the tan, we can change, we can rewrite the equation true as the equation of the rho and s. So s is the original function of the v. So by this rewriting the equations, actually we can understand. Actually, we can understand what the structures of these density evolutions. Indeed, we can rewrite this orange equation here into this following kinetic form of the infinite dimensional Hamiltonian system. So here mathematical H is the average energies. So this average of the kinetic energy plus small plus the smooth potential. And here, this is a very kinetical formulation because Formulation because as you can see, partial rho partial t equals to the function derivative with respect to s, and the partial s partial t equals to minus functional derives with respect to rho. And since this zho, this is the densities living in the one density space, and s is the dual variable of the velocity. So we call this system as the Wattenstein Hamiltonian flow, because this is the Because this is the equation evolving on the density manifold. Okay, so that's our short derivations for the Hamiltonian-Wass-Stan system we are going to consider. So to make a short summaries, what we just do is starting from ODE system, input some randomness into the initial data, then the density of the Hamiltonian ODE in the sample space will behave again like a will behave again like a Hamiltonian system in the density manifold. And actually, this viewpoint can also, you can also think in the back world. So you think about your patterns, you are solving some high-dimension Hamiltonian Jacobi equations or high-dimension continuity equations. Actually, you can use the ODE version to trace it back. Then it may give you new ideas to solving high-dimension problems as well. But today we may need folks. But today we mainly focus on this Watson-Hamilton system directly. Okay, so let me first introduce some examples. First examples is the Wassenstein geodesic equations, which is the Hamiltonian and his energies, his energy is purely the kinetics. And if you're substituting these energies and you can derive the corresponding Hamiltonian system, is the Hamiltonian system is this standard continuity equations and plus this first order Hamiltonian Jacobi equations. This equation is called the Watson geodesic equations because it's the sidel points of the well-known formula, is the Banner-Mobrinier formula. It is a dynamic version of optimal transport patterns. So it tells about a story moving the initial densities mu zero to the Densities mu0 to the dark to the dark target density mu1. And during the transportations, we want to keep the mass is preserved is preserved. So we need to satisfy this continuity equations. During the transportation, the goal is to minimize the average chemical energies. And the minimizers of the cost actually will give you the Wassestan metric between. between mu0 and mu1. Okay, that's the reason why this why this equation is also called the Wassen geodesic because it gives you a characterization about the saddle points of the Ballambo-Brinier formula. The connections between these two systems and this Wasserstan metric patterns is that the energy of this Wasserstan Is that the energy of this Wassenstan system Hamiltonian flow is actually equals to the Wassestan distance taken square? This is the first examples. The second examples is the well-known Schroding questions. And actually, Schrodinger equation can be derived from the Mydenome systems. And in this situation, we take the Hamiltonian as the kineties plus the clinical energies plus the this feature information here. Beta is a small parameters. Facial information is defined as the gradient log and row squares and the times zh do the integrations. As a result, we can derive the corresponding Hamiltonian system. First equation is similar to the geodesic one and the second equation is different because this is the standard Hamiltonian part, Hamiltonian Jacobi part and we will plus this And we will plus this feature information take the functional derivative. Okay, this question is a coupled system, depends on the SD is depending on Joe. If we using this Madden transformations, we define this complex variable, u equals to this, the power coordinate. And then actually we can derive the Schrodinger equations as follows. It's a standard linear Schroding equations. So there's So there is a deep relationship between this Madeline systems and the Schrodinger equations. As we can see, the Schrodinger equations has this following Watts-Stan-Hamiltonian flow versions. Actually, it also tells you this Watson-Hamilton system can be derived from this optimal density control patterns. So it's slightly different from the geodesic equations. The geodesic equations different from the OT patterns. So, this is the pattern about transportations. I want to transport initial mu0 to mu1, and the cost functions is minimize the kinetic energy minus the fission information. The center point of this fibrillance will produce this Boss-Stan-Hamiltonian system. Okay, this is just two motivating examples. So, to make summaries, So, to make summaries, in the following optimal density control patterns, if we want to minimize some average Lagrangian functions and finish the transport target, then we often end up with a Hamiltonian system on the density manifold. So in other words, if we want to solve the problem nine, actually we can looking at the sidel points. So the side points will satisfy this Wassestan-Hamiltonian system. System. And now, actually, we are looking for the control variable is S0 or grading of S0 such that the transportation satisfies this PDE system and finish this transportation goals. And this actually gives you some ideas to design the structure preserving methods in space directions, in spatial directions. So, the main ideas for us to look Ideas for us to look at the numerical part is first understand the Washington Hamiltonian flow from the initial value problems viewpoint. And then we look at the boundary value problems, such as the control problems. The main tools we are going to use is the optimal metric on discrete graph. So the central goals is structure preserving numerical skins. So let me talk about these main tools we are going to use. main tools we are going to use first is the why we need to use need it need why we need it the this is the because that the common linear discreditations will often pro broken some structures uh so here is examples if we're looking at this following linear shooting questions with the random input so this is the with the random input as the driving forces this is the round Forces. This is the round input in the inhomogeneous medians when you talk about wave propagations in opticals. So this is two famous linear version models in Stochastic case. If you apply the E-ten chain rules, actually you can verify the plane waves for this two-ninear systems also exist. As long as the classical dispersion relationship holds, you can verify this. Holes, you can verify this is a plane wave solution of this one, and this is the plane wave solution of this one. However, when we talk about numerical discreditation, if we want to preserve this kind of plane wave solutions for the original models, even in the determinist case, meaning if sigma equals to zero, it's also very hard to find out the structure preserving scheme, which preserves the plane wave solutions and the other. Wave solutions and other quantities at the same time. It has been reported, this phenomenon has been reported in these papers. Then in 2019, this papers reported tools is based on the optimal transport and graph to design algorithms in space directions to preserve this dispersion relationship. So actually, the mentor is inspired by these papers. These papers. So, thanks to these tools, actually, we can design algorithms which could preserve structure, preserve the properties of the original patterns as much as possible. So, let's look at the detailed setting for the graph discretizations. So, first, we think about we are working on the graph setting directly. So, consider an undirected. Consider an undirected connect graph G. So it has three elements. First one is the vertex set, second one is the edge set, and the edge weight set. So omega ij defines the weight on the each edge from i to j. And nj is the neighborhood of j nodes as long as the you have the is in the neighborhoods, as long as a oj belongs to this edge set. Belongs to this edge set. Okay, so the second requirement is that we do normalizations such that for different nodes, the density on different nodes weighed together is one. This is the density space we will work on. And zo zero g is the interior of the density space. Okay, the materials is the OT metric and graph. Matrix and graph. And this idea is indeed proposed around 2011 by three different groups. And we want to extend a little bit on this automatic such that we can contain some more mathematical models. So we are going to do our minimization problems and the goal is to transport mu0 to mu1 and every And every element here are sitting on the graph. So we will define the discrete energies, the chemical energies on the graph. And V is the corresponding discrete needle potential, and W is the interaction potential, and beta I is the discrete facial information. And so to preserve the mass during the transportations, we need to also define a discrete version of So, define a discrete version of the continuity equations. And this setting has a lot of freedoms because if all this potential disappears, we just recover the OT metric and graph. So if beta is smaller than zeros, well, then we are doing Schrodinger-bridge patterns. If beta is larger than zeros, then we are just doing the Schrodinger equations on graph. Okay, so let me introduce the notation. So, the first notation we are going to use is the inner product on the graph. And the u and v are the vectors on the graph. So, since it's undirect graph, so every velocity is unh, we are counting twice. So, that's the reason why we do the inner product. We need to divide by two. And the seer here, sigma. And here sigma j AO is the probability weight functions between this node zhoj and zho AO. So this is the main contribution of the OT metric and graph. So it gives you more freedoms on designing the numerical methods from the structure preserving viewpoints. The basic requirement for the probability weight functions is that you satisfy the maximum principles. The typical choice The typical choice for the probability weight functions is also inspired by some classical numerical methods. For example, we can define the upwind probability weight. If the potential SJ larger than Si, then the probability weight is defined by ZOI. We can also introduce the average, simple average probability weight is just the average of the two nodes. The average of the two nodes divided by two. And we also have the other choice, depends on the probability of width functions, depends on the choice of the average. Okay. And to define this continuity equations, actually we need to define the discrete divergence operators. So thanks to the structure of the inner product, actually we can define the divergence operator such that the integration by Such that the integration by path formula is hold, such that we can preserve the mass. So, this is how we define the divergence operators. And the leader potential interaction potential is standard, is quite standard. The last point is about discrete facial informations. To give you more freedom choice for discrete version of facial information, we define a new edge weight. H weight is omega delta, and a new probability weight function is a zeta deltas. Okay, so this is the main settings. Now the minimization problem is clear. Then we can study sidel points. And when we study side points, we end up with the following Hamiltonian system on the densities, on the discrete density space. Okay, there should be some remarks on the systems. Be some remarks on the systems because we are introduced this non-linear discreditation for the probability weight functions. So it gives you different properties compared with the continuous versions. So the first difference is that let's look at the geodesic equations. For the geodesic equations, actually in principle, we can solve S equation at first, then solving ZO equations. Than solving those equations. But for the Wassenstein-Hamilton angular graph, we cannot do it because the probability weight functions, actually, if you choose the non-linear weight approximations, this S equations will depend on the row. So it's fully coupled system. So this is the one big difference between Watson's Hamiltonian flow and graph and its continuous versions. There are also other differences. There are also other different plays between the continuous problems and the discrete problems. For example, if you remember that how we designed the how we designed the Washington Hamiltonian flow in continuous case, we start off with our OD system, input some randomness, then we can construct the PDEs. Okay, but if we start in the inverse directions for the graph, we have the Wasser-Stan-Hamiltonian system on graph. Stand-Hamiltonian system on graph already. But if you ask whether you can define a stochastic process such that its stochastic behaviors is exactly these equations, the answer is maybe not. It's very hard to define a stochastic process, especially jump process, to fulfill this optimal transport. And the second technical properties, problems, is that since you are using graph discretion, Since you are using graph discreditations, so nodes has neighborhood structures, it will give you some technical issues when you do the numerical analysis. And this difference will produce the main challenges is about the singularity of the Wasserstein-Hamiltonian flow. So let's still using the geodesic equations, the OT patterns as examples. So in this time, beta equals to zero, there's no fission information. If we're using the If we're using the upwind weights or the average weight, actually one can prove that the singularity of the one-sister Hamiltonian flow always happens. So the singularity means that either the density goes to negative numbers or the S blows up. So it's very hard to avoid these singularities. If we're looking at the properties of the optimum metric patterns and graph directly, Patterns and graph directly. So it's surprising that the minimizers of the optic patterns could even touch the boundary of the density manifold. So this property is totally different from the continuous versions. So our idea is to overcoming the singularity of the WAS system Hamiltonian flow is based on facial informations. So if your original system does not have the facial information, we want to add a facial information. Informations we want to add feature information such that your patterns use the wheelpost for all that for all the time. So, this is our central ideas. And our main results for this was standard Hamiltonian flow on graph is as follows. So, for general Hamiltonian system on graph, there exists a blow-up sun, t-star, such that before the tans, everything is nice. You can preserve the mass structures, energy structures. Structures, energy structures, as well as some physical property, like your solution is time reversible with respect to time, and it's a time-transversal environment with respect to the linear potentials. And the last properties is our main ideas. So, if you contain the fission information in your systems and the probability weight functions for fiscal information satisfying the maximal principles. Satisfying the maximum principles, then you can always prove that the solution always stays in the interior of the density manifold. So for any time you can do it. So this is our central ideas. And thanks to this regularization properties, and actually it allows us to do some time discretizations. So our logic to design the time integrators is as follows. Is as follows. So, first, we check the singularity of the Hamiltonian system. If it have some ters like facial information, actually, we will be happy because we can use the existing simplerity integrators directly. So, if beta equals to zeros, like the optimal control patterns or geodesic equations, it has singularity. So, we can add numerical, we can add a small fission information as a regular addition, so we get a modified energy. Addition so we get modified energies. With this modified energies, we can obtain a modified Wassey Hamiltonian flow, which has which is well posed. Then we can design simple activity integrators to that models. Okay, let's look at the concrete examples. We apply the simple actic Rungo Kuda method, which satisfies this simple actic condition directly to this our logic. And as a Logic and as a result, we can obtain a lot of the structure-preserving properties like mass structures, simplex structures, as well as the other two physical properties. And since we are using simplex integrator directly, so unfortunately we cannot preserve the Hamiltonians, we can only preserve that, prove that the Hamiltonian is preserved up to our polynomial time. And here r is the orders of the simply. Is the orders of the stempolyactic methods? Okay, so due to time limitations, so let's talk about some numerical behaviors instead of the details approved. So the first numerical examples we are going to illustrate is the geodesic equations, so which is a sidel point for the optimal transporter carbons. And as we emphasized before, a popular proof. Before, a popular approach to solving this geodesic equation is as follows. We just add, since the Hamiltonian-Jacob equations may produce some singular behaviors at some times, so a popular approach is that I add a numerical viscosity at here. Then I can solve S equation at first. Then everything is smooth, it's nice. Then, once we solve S equations, I can solve those equations. So, this method is a called numerical. Is a called numerical methods with numerical viscosity to solving these problems. This is an existing approach. And our approach is that since this does not contain feature information, so why not add a small parameter times the feature information into the system? Then we apply the simplex integrators. So this is our skins. And here is a comparison between the two skins. First line is the numerical. First line is the numerical methods with viscosity. As you can see, this is a transportation pattern. I want to transport the uniform distribution into data measures. And if you look at the behavior of the density, slabs, step nodes, everything is good, it's smooth transportations. But if you look at the energy level, you will say the energy is decreasing as time goes by. But as we emphasized before, the energy level is the same as the decrease. As we emphasized before, the energy for the Wassenstein-Hamiltonian system for the oriented model measures the Wassenstein metric between uniform distributions and delta measures. So this should be a fixed numbers instead of decreasing. And our free share information actually schemes, regulatory schemes is much better until the energy level. So as you say, during the transportation, the energy is The energy is preserved good. But on the density level, if you look at the graph of the density evolutions, it will, in the medium process, it will produce some oscillating behaviors. So this is the disadvantages of our approach. This is the first examples. And the second example is the Schrodinger questions. And you can say, Schrodinger questions in the Myanmar. Say shooting equations in the Mylan system transformations, it already contains the fishing information. So there is no need to do the regularization. So we can just apply the simple integrators into it directly. And now as a result, it preserves a work good as time goes by. So after a very long time, the mass is preserved. And so that's the energy is conserved after a very long time. Conserved after a very long time. The last examples we want to show you is the OT patterns. I want to transport one Gaussian into a Gaussian mixtures of two Gaussians. And here we're using our simplexity integrators as well as some multiple shooting strategies such that we can compute the time density evolution as time goes by. So, as you see, So, as you say, this transportation is like this. I first go a straight line because I know the target is here. So, I go to the straight lines and then I split the mass a little bit in the median process. And then we to go at the final steps, I will go to the two directions at the finals. Okay, so that's all the examples I want to show you today. So, to make a short summaries, what we will do. Summaries, what we will do is constructing Watson-Hamiltonian system and graph, and then we talk about some structure-preserving property for time discreditation and spatial discreditations. In the futures, we want to report the application of Wasser-Stan-Hamiltonian flow and computing high-dimension Hamiltonian Jacobic equation in the futures. Okay, that's all my talk. Thank you. Thank you. Thank you. Give me time for one or two questions. Okay, I have a question. So the Hamiltonian departs from the solution, which ends one can expect. But do you have any sort of backward analysis for that? Yeah, yeah, yeah, yeah, yeah. Yeah, that's very good questions. Actually, it's very technical problems. I hear so here we have, I just omitted the technical assumptions and the details. If you want to prove this kind of results, you need to using the backward analysis. Actually, you need to analyze the lower bound of the densities. Since you have contains, for example, you contain special informations and you take. Fisher informations and you're taking derivative actually is singular near the boundary of density manifold. So you should do a very careful analysis on it such that you can up to a polynomial non-times the density, you have exactly density lower bound. So it's very technical proofs here based on the backward analysis. Okay. Okay. If there are no further questions. No further questions. Thank you again. Yeah, thank you. And we'll move soon to our text talk. Yes. Don't forget us. I'm not sure how we do it because I'm losing my voice.