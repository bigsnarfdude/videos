Yes, what I want to present is a work starts with a joint work I wrote with Chris Klaus on infinite dimensional partial differential algebraic equations with a focus on disinfectivity. And as we just heard, we want to have a discussion on current research and open problems. At the end, I will also have At the end I will also have a couple of slides on current research and there are also T MORIs and climate involved. But we just arrived also, let's start slowly. This is finite dimensional situation. It's somehow a little bit shifted. So if you could see the whole slide, that would be great. I should say that So, I should say that everything here will be linear, so also for the finite dimensional situation, I focus myself to finite dimension. Okay, so E and A are just square matrices, and I also focus myself to the regular situation. So, in general, you could also assume that. So in general you could also assume that both matrices will have each other. And someone broke the pointer last week. My session should have a pointer. Luckily I have one. Just take this one. This is maybe also reasonable. Okay. So if someone broke it, it can be this one. So those matrices in the general situation, of course, can be regular matrices, but when I focus myself to the regular situation, that means Radio situation, that means I want to have some point in the complex field such as this matrix is invertible, then of course I focus to square matrices, and here I want to focus myself to the regular situation. And one thing we are always, if you go for normal forms, we restrict ourselves to chaos. Pairs T and A, which are somehow related, and I call them related if there exist two invertible matrices such that I can transform the E to E tilde in the same way as I transform the A to A tilde. Then it's well known that we can rewrite every pair V A, every regular. P A, every regular pair I have to to mention equivalently in such a pair of matrices. Whether P is just the identity, N is a mere potent matrix and J, well can be, J stands here for Jordan blocks or Jordan matrix, but it just combines. And as I said earlier, I want to focus myself to dissipativity. Here also Here, I also want to already introduce notions of decipitivity. What do I mean by decipitivity? That if I take a solution and the solution of a DAE, I think of the term Ex. So Ex of T, that's my solution. And if I take the derivative of the norm, this should be, well, the norm should not increase, which is equivalent to the fact that the derivative Is equivalent to the fact that the derivative is less or equal to zero. And if you just differentiate this Euclidean norm, this is equivalent to the fact that the real part of the inner product of Ex and Ax is supposed to be. So, this we somehow should be in mind because this term we will me occasionally also later on in the infinite dimensional situation. Situation. There's a finite dimensional situation that is well studied. I cannot mention all the names involved here, so I thought I just choose some books. So this is a book by you all should know or know maybe by Kunkel and Mehrmann on DAEs. And these are some of the books where Timo is involved with Achim Illichmann. I did not put all the surveys there. So there are more books and more with. So there are more books and more results available. These are just some placeholders for the whole theory. But in those survey books you find all the theory and also the non-linear situation. Okay, so this is a finite dimensional situation and now let's move to the infinite dimensional situation and let's start myself with some example. I start with one example, relatively easy example, the piece of A relatively easy example is a piezoelectric beam. Here I adjust V, so I just have a one-dimensional interval, let's say from A to B. I didn't write down boundary conditions, so you won't see the A and B. But the C involved on the interval AB. So V is just the displacement and P is just the electric charge and then alpha gamma beta rho and beta, rho, and mu are the material constants. They can depend on C, but just for simplicity, I've chosen them here to be constant. So these are somehow two coupled wave equations. And we can rewrite them, that they somehow also look in this form with an E and A. I choose this set of state variables, just somehow motivated by the Hamiltonian. By the Hamiltonian, the energy variables. If I choose to state C, then this is equivalent to the following system. So here you have now a matrix D, I should say operator A, which is somehow the first derivative. You have a block matrix with block operator because these are identities. Because these are identities, and you see directly this is somehow, this is not really the idea. Because if we assume, and that is the case, and here at the moment I would like to assume it, that my constants are all positive, then of course this matrix here is invertible, and we just have a usual quotient problem. And it's then easy to see that the system is well posed in the sense that Is well posed in the sense that we have existence and uniqueness of solutions. But let's assume that somehow the mu is zero. That this material constant tends to zero and if it's very small then you may change it to the choice of mu is zero. But if mu is zero then you have actually here a problem. Then one of the I go to the wrong side. But then here one of the variables, one of the states here one of the variables one of the state variables C4 is just the zero function just zero so you can kick out the fourth variable and if you do this so mu tends to zero and I choose it zero then the state z has only three components and it's equivalent to this set of equations but now additionally you see if you Additionally, you see if you look at the third row, the third row here is just zero. And also on the other side, you have the third row in the identity multiplied with the fourth row. This is zero as well. So the third row is just the zero. You can also eliminate that. You can also remove it and you end up with this equivalent. Equivalent system of locations. And if you have a close look on this one, the A still looks like a partial differential operator on some, but I didn't write down phases and domains, yes? I just have a silly question. So the gamma only appears as far as gamma beta, absolutely. If beta is zero, then the gamma beta must be zero, too. Is that the only reason why it's Reason why it's written by some product like that? Or by an anthologist's former, I guess. Okay, okay. Okay. I mean, it has the effect that beta is zero and the gamma, but also the gamma. Good point. No. So but now if we assume beta and gamma are not zero and here we had our choice mu is zero, then here we now have a singular matrix. And it's somehow the invertible part. It's actually somehow already in a kind of normal form. So you have somehow an identity, you can of course just You can, of course, just get rig by the square root of rho by multiplying everything by one over the square root of rho. So you could have somehow the form identity simple for z. And of course, this is somehow modern form of normal. So this is one example of a partial differential equation. Other examples are hybrid equations coupled with elliptic equations. We have just written down Written down one of those, just on an integral again, and here I also have written down some boundary conditions. But you can also think of more general domain, but general parabolic ecliptic equation of structure form, but of course, plus boundary conditions. Again, you have somehow the identity and a zero. Here you have somehow the identity. Here you have some of the identity with the W and the zero inform of the derivative set. And of course those examples appear quite often in applications. Quite often you have something coupled with a human thing. There are also other situations where you somehow would not really call them partial Really, we call them partial differential algebraic equations, maybe more singular differential algebraic equations, because also the E is unbounded. And here I have one example. So the E somehow is now this partial differential operator. So on former former talks, so those of you who have heard my talk in either Kiel or Le Mini or have read our paper, or have read our paper, may notice that there we call this example Drexter equation. And if you look in the literature, then you find a lot of papers on Drexter's equation, then you find this equation. But unfortunately, if you trace it back, and this we found only after our paper was published, if you trace it back to the original paper of Drexter, then the the sign there is different. The sign there is different. And some signs really, whether or not an operator is invertible or has a kernel. Signs, yeah. So vexed equation, if we really go back to the original work, is not in DAE. Now it's a nice equation. So that's the reason I just call it now example with an unbounded E, and don't call it Waxler. So this. I mean you said that signs matter but also boundary conditions here. Yeah, boundary conditions matter as well. So they are coming next. Exactly. So what I present here, and I only call it an example, is what a lot of people call Drexter equation and also with those particular boundary conditions and also spaces, which are now noticeable. So we just look at everything on the interval. So we just look at everything on the integral 0Ï€, we choose Dirichly boundary conditions and also those of the second derivative, and we choose the following spaces. So in the final dimensional situation, the E and A matrices, they were square, so they were going from Rn to Rn. In the infinite dimensional, if the dimension is the same, the spaces of course don't need to be the same, so for that, I choose two spaces. So for Z I choose two spaces, Z and X and one is L2 and X is just H2. Intersection is H10. So somehow X is embedded in Z. And I can view E as a linear bounded operator from X to Z. And A I can also view or consider as an operator from X to Z. Consider as an operator from x to z, but this operator will be unbound because here, of course, I have four derivatives. E only has second derivatives and A has four derivatives. So E is then the operator identity. So X, second derivative, and A, second derivative, plus twice, fourth derivative. And the boundary conditions are Conditions are partially in the space X, and the other boundary conditions, those defined here in the topic. And as Marcus mentioned already, the choice of the boundary conditions and the spaces, this is important whether or not the operator E is invertible. And here you can easily see that the sine function is actually in the kernel of E. So you have kernel of E. So you have a singular j. That's not nice, not directly nicely written in such a block operator matrices with the zero and ziant. But those examples we should also have in mind. So what's my general setup? What I want to study is infinite dimensional Infinite-dimensional DAEs of this form, which somehow have lived on Hilbert spaces, X and Z. They don't need to be the same. B is a linear bounded operator from X to Z. A is a possibly unbounded operator from X to Z. And again, I want to restrict myself to the regular situation, so there should exist So there should be single a complex number such that this operator is bounded invertible. Okay, so what's known? Of course, we are not the first looking at those, but quite some literature. And Kirsten I we spent a researching pair not in Benf, it was in over Wolfer, and unfortunately it was in hybrid form, which is for researching pair a strange concept. A strange concept. So, I was in Warwolf when Kirsten was at home. But, nevertheless, he used this time, or I in particular used the time to get into all this literature. So, there is a lot of existence and also on bias first in all the forms. And here I only mention some of them. So, if I forgotten one of the names, in particular one of the names in the audience, I apologize for this. So, assistance of solutions. So, assistance of solutions, quite often you have finders subspace, and on the subspace, you have then a C0C group and so on. And there are also papers which try to find a concept for the system of a kind of Ayashba's canonical form. There are paper by Tala and Tala. They somehow use the splitting of the spaces of a loop splitting. Splitting, then there's this book by Siegel Duck and Idiorhoff from 2003. They work in arbitrary banner spaces, but actually they were able to find a canonical form. And this book actually was the basis for our work. And using Gilbert spaces, actually separable Vana spaces would be enough. We could simplify a lot of Could simplify a lot of their results. They had somehow conditions you had to satisfy, which are, I think, not so easy to understand, and in particular to prove. So restricting ourselves to separable banner spaces helped a lot. Of course, I also should mention Timor at this point, in particular his PhD thesis, where he also had a biased canonical form, if there exists. If there exist certain projections. Which was, by the way, on the basis of what Carvin and Was Vita and Lee did. That's true. Yes. Carvin, I also should mention you. But you are mentioned also here. That's real. But somehow your idea was more too general. This is also our idea, but you were closer. Our idea, but you were closer to the final dimensional situation and trying somehow to generalize those concepts. So, what's the aim of this talk? We want to characterize differential algebraic equations and we want on one hand have solutions and we want to have dissipativity. This will be our main aim at the end. Characterization, when do we have? When do we have dissipative solutions? And we also would like to have characterizations when normal forms exist. So I present those results. I again like to step a little bit back and summarize some results on infinite dimensional ordinary differential equations. Most of you know this probably, but with one of those Probably, but with one of those very first talks, you never know what the audience exactly knows. So if you feel bored, you can also tell me. Otherwise, you can relax. This is maybe also fine. So let's for a moment assume that E is the identity or E is invertible. Then of course you can reduce it to this. Yeah, I just assume I have one limited space then of course, because the identity goes from Px to X. The operator A should be densely defined and closed, and I want to have at least one resolving setting. That's just again the vectority. And then we have two concepts of solutions. We want to study that are classical solutions. So what is the classical solution? The solution should be at least continuously differentiable and has to satisfy our equation. Satisfy our equation. The initial condition has to be satisfied, so in particular the solution has to map into the domain of A, otherwise this term is not well defined. And the weaker concept of solutions is the concept of mild solutions. And I call the solution a mild solution if the solution is at least continuous and satisfies the equivalent integral. The equivalent integral equation. And here, of course, I have not of course. It's very important to mention that the A is in front of the integral. Because I don't assume that X maps into the domain of A. It's not just that they interchange easily with the interval A is an unbounded operator. And of course we know every classical solution is a is a mild solution. Is a mild solution and the following two assertions are actually equivalent. Of course, now you may wonder: are we really interested in mild solutions or are we interested in classical solutions? What is the best concept we should aim for? But under the assumption, and this is important, that I have regularity, it's equivalent that if for every initial condition in X, I have a unique mild solution. I have a unique mild solution. It's equivalent to the fact that if I only study or consider initial conditions in the domain of A, I have a unique classical solution. So this is really, really equivalent. And here the regularity is really essential. So how to characterize existence of solutions? There are two main results. So you can use Sheeta's theory and the theory. Theory and the theorem of Lumer Phillips. So Helios Schider characterizes the existence of unique bounded solutions. This bounded is not really necessary, but then you have to make this a little bit more involved. I had to choose here. I chose your bounded, of course, but here I have the zero. So if you start from another point, then you shift everything, but somehow without loss of generality, I can here start. Here, I can hear stand boundedness, otherwise, you shift everything. So, what do you have to check? Well, you have to check that the whole interval is in the resolvent set. So, as identity minus a is bounded to invertible, and it is really hard sometimes to prove that all those resolvents, and not only the resolvent, but also all the powers n, so this is the resolvent. n, so this is the result to the power n is bounded by a constant k, which is not dependent on n. Otherwise it would be easy, because we would only do it for n is 1 and then take to the power n, that would be too easy. So it's really important that this constant k is independent. So this is an equivalent characterization, but from my point of view, not really useful for Really useful for applications. And in particular, when it comes to dissipativity, then the Luma-Phillips theorem is much more useful. So what the Luma-Phillips theorem tells us, it says the following assertions are equivalent. Uniqueness of mild solutions with non-increasing war, this is just what we meant by distributivity, is equivalent to the following conditions. So you To the following conditions. So you could either test that the range operator is surjective, it's of course much weaker than showing that all those points are in the solvent set. And we need some disputivity inequality. This usually is also relatively easy to show. You have this operator A and it's a partial differential operator than what you usually Operator, then what you usually do, some integration by parts and choosing, taking care of the boundary conditions, and then hopefully you have the right boundary conditions so that it works. So the harder part is this one, but if you want to avoid it, there's also a good answer. You can replace the selectivity by another integration of parts inequality, taking not only the operator A, but also the operator A. Operator A, but also the operator A star, the joint of A. But then, of course, you have to calculate the operator A star. So, this is the other characterization. And our aim is to generalize this result to the DA situation. So, taking care of singular operators D. Exactly, and as I mentioned already, so this real part we also had on the very first. real part we also had on the very first slide in the finite dimension situation if then you had chosen the E to be the identity then we actually had this inequality. So this inequality, this distributivity is also called, implies that the derivative is less than equal to zero. Okay, so let's start with this book I mentioned earlier. book I mentioned earlier, and they already introduced somehow for general Banner spaces a wide contact. And they called it miradiality. I don't know whether radiality really is a wide notion, but somehow we still use it because they use this. So the generalized resolvent set just those complex numbers where these operators are invertible and then we have the wide And then we have the right and the left resolvent. So we take the resolvent. Here the R stands for right. So I multiply the resolvent from the right with V. The left resolvent I just mean multiplying the resolvent from the left with E. So that somehow easy notation. And then we need two concepts. That's the concept of weakly iradial and E radial and E radial or radiality. And it looks a little bit like the Helioshida conditions. That was also the reason I mentioned them. So Helioshida condition, and then you should look at the E radiality. If you replace the white resolvent just by the resolvent, and E is identity, then this is just the resolvent S. You had this power n, and here you had constant divided by s to the n. So, what we now need is we replace the resolvent by the right resolvent and the left. So, one is bounded, the other one is somehow bounded, but not with the same bound. So, we need them both and also towers. And the difference between evaluality and VTE value is that here we only have That here we only have to check it for N is one. So here we don't have the powers. So clearly, e-radiality implies weak e-radiality and the other implication only holds if, for example, the K is the idea is one. Now if K is one, then you can just repeat it. And now we choose the following of A. We choose the follow or they chose the following spaces. So let's fix one point in this resultant set. You can choose those spaces x0, x1, z0 and z1. You can just define them. x0 is relatively easy, it's just the kernel of E. And those spaces have nice properties. I think they also come on the next slide, but one I can also The next slide, but one I can also mention here. Actually, the definition of those spaces is independent of the choice of alpha. I fix one alpha, but if I choose another alpha here in the set, I get the same space. So what else do we need? Yes? I don't know if it's is it easy to s get some intuition why these powers of these resolve and Powers of these resolvents come in quite important. You mean in Hiyoshida already? Yeah, I guess it's a problem. I think here you need it because you need it in the Cauchy problem situation. The Hiyoshida theory needs it. And there you have this Hiyoshida approximation, and it's really in the theory. So without, it's actually not true. So there are examples where you only have the condition satisfied with... Have the condition satisfied if n is one, and that's not sufficient. So you really need all those powers. Because you all need all the powers in your Schider theory at a certain point when it really comes to solutions to existence of C0 semi-groups, we also need here radiality and regional radiality is not sufficient. So it's somehow inherited by the Cauchy problem situation. Can I also ask something? Can I also ask something? So in the slide before, so does it make sense to multiply E from the left and from the right, from just from the spaces? Yes, because I mean E goes from X to Z and the other one goes back. Yes, and the other one? Yeah, but they they live at the end. So so this one lives goes from X to X and this one goes from Z to X. From Z to X. You start in Z, you go to X, and you go back to Z with the left one. So the resolve goes in the other direction. And it forget the A or the D. A goes for the people at home, I have to stand. Okay, okay, here. Okay, okay here. So these are again the definitions. So what is known? And now I only assume the really radiality. So forget about the powers for the moment. Then and here actually Hilbert spaces are necessary or separable Banner spaces would do. We know that the direct sum, it's not an octogenal sum, but this direct sum actually asks the whole spaces. The whole spaces, and you can define some operators, first of all. Those operators you can define with reality. These are actually near bounded operators and they are projections. And the P is a projection on X1. And I can do it similarly. So with P I use the right insolvent dissolvent, with Q the left dissolvent. Otherwise, I use the Otherwise, I do the same calculations. The Q is a projection on Z1 and the P is a projection on X1, along the one along X0, the other one along Z0. What's now the nice thing with those projections? They somehow, in quotation mass, commute with A and B. They cannot really commute because the spaces are not the same. The spaces are not the same. But if I have a P on the right side, and I want to put it on the other side, then I have to go for the Q. So E P is Q E. EP, QE, and the same, at least if I the domain of A, then AP is QA. So if I commute it, if I want to interchange the P, then at the other side I have the Q. Other side, I have the cube. I know that's all. Why does a limit exist? This is exactly due to the definition of immediality. Because this one is just then you really need it otherwise, well, not otherwise we'll not Otherwise it would not so now we can use those projections to split the operator. We find those p tilde, q tilde, and then we can equivalently write our differential algebraic equations by multiplying them from the left and to the right, and those p tilde and q tilde are actually invertible equivalently in such a block of music. Block of loose forms. So we have somehow splitted the differential algebraic equation in one part evolving from x0 to z0 and the other one from x1 to z1 with the following properties. So E0 here is actually just zero, our assumption that because we have got a higher index, E1 is a linear boundary. E1 is a linear bounded operator. The A0 and A1 are both densely defined and closed. And A0 actually can be shown to be boundedly invertible. So this one is boundedly invertible, so I can get put here an identity. Here I have a symbol. So what I still would like to have is here, it's probably nice. Here it's probably an identity. This would be if I think of a normal form, then this would be one A to have here the identity. But in order to get there an identity, I need an extra assumption. I need that E has closed range, because then I can also show that E one is boundedly in good. So this gives us the splitting. So this gives us the splitting, but now once we have the splitting, then we have somehow separated the algebraic equation from the differential part. And this differential part, of course, we now would like to have existence of solutions. In the final dimensional situation, it's just a linear ordinary system of differential equations, and of course you have existence. But in the infinite dimensional situation, this Infinite dimensional situation, this is linked to the generation of C0 semi-groups. And this is the place where I need now instead of weekly E radiality, E radiality. And here I also shifted things a little bit, so you can also explore this alpha if you like. But I alre was only working with bounded solutions, and if I want to include some groups, I can generalize my conclusions. Can generalize in EI assumes closed range. Then we get the first main result. So there exists two invertible matrices such that I have this normal form and the reduced system, so this one belonging to this identity and this operator has unit-bound solutions and they satisfy a certain bound. So this k. Certain bound. So this k is a constant we find in the definition of evaluity, and the alpha is just the constant here. So if we go back and alpha is just zero, then we are back to bounded solutions. This is the first one, yes. We'll have some potential to grow by choosing a positive alpha. By choosing a positive or exactly exponential work. Just shifting the A well, not with the identity, as you do with Cauchy problems, then you shift it with alternative. I'm thinking of transient growth potential, where you might grow initially but then exponentially decay. No, this is more the long-term. This gives you more information about the long-term behavior. Here is the one. K is the one from the red land. It could be possible that's a red land. Yes, K comes from the definition of ideas. And if you want to have something information in between, then you want to have the information of K. Choose X one. X1 for the decay, so the last formula. So this is not the second we have X0. They are called X0X1. Does that help? That helps, that helps completely. We somehow follow the notation of the blocking. So X1 is the second component. But the next slide is for you as. But the next slide is for you as well as you move. Of course, I hear already your question: what about higher indices? No? I thought so. Because so far, this was implemented in our definition of evidentiality. We had that the n is zero. So we have somehow an index of zero and one. And of course, they did it already much more general. And you can define concepts of p. Concepts of PE radiality and weekly PE radiality, and still coming back if you want to would like to see them. At least I want to show them shortly. And now you maybe understand that I'm not directly started with those definitions. Of course, then you have to. So if P is one, then of course you can forget about this product. That's what we had before, then we only had one result. Before that we only had one resolvent and now you have to go for products. Then you put big points S0 to Sp. This you can do again with the powers n or without the powers n. And depending whether you consider the powers n, you get radiality, and without if you just choose n to be one, then you have weak e radiality. So this is somehow a canonical generalization. Generalization of the concept of one e-radiality which we have before. If you work with those definitions, and here I only have chosen generalized, so the only difference here in the assumptions is here there's a P for Ashcroft market in red. So the P there, and if you put a P there, then we actually get this result, which also looks similar. Which also looks similar. More work to do. So the only difference now is here we have the n, and the n is a real potent operator, so n to the p is just simple. But otherwise, well, the proofs are more involved, but otherwise more or less. Okay. Welcome. Welcome to the trickle tea. Let's see. One slide or two slides on coupled systems. Someone at two minutes? Yeah, yeah? You have a choice. Coupled systems or distributivity? I'm just enforcing that I don't know. Both? Okay, okay, I go on. Okay, okay, I go on. I go on. And I'm not going to 25, so that's fine. So this is if I start with a couple system of forehead, so let's assume somehow we had already an E of this form identity 0, 0, 0, which we had, for example, in this example of coupled parabolic elliptic equations, then we have, of course, more information. And now we split the block operator matrix. So block operator matrix in a similar manner. So we need some assumptions on our single operators AB as a domain. Then we have examples. We can have the following result. So again we need some assumptions on the domain and the most restrictive assumption here is that we assume that the operator A4, A4 is A4, A4 is the one here in the lower right corner, is invertible. So if this one is invertible, then we know that at least the closure of A, I assume that A is closed, I must have assumed this, because it's closurable, that the closure is evadial, if I shift it a little bit. And the other nice advantage is that you Is that we also have particular forms of the projections. So here we really have some more formulas. Well, really is good. You have to make sure that you can calculate those operators. This is easy, but here you have to take closure. But then you have the projections and you really can write down those little bits. So in the finite dimensional case, this is what we call a sure complement approach. Yeah, exactly, exactly. This is a sure complement. Exactly, exactly. This is a shortcut we make. Our systems are called this crime reduction. Exactly, this is what is hidden. This is a shortcut to make. Can one hope for anything with A4 not invertible? I mean, well, looking at the system is like, well, if it wasn't invertible, then what would we do? I mean, it's an algebraic constraint. I cannot really think of something here, like the result of the setting. Yeah, exactly. Yeah, exactly. Yeah, so even in the final dimensional case, I would expect that if all somehow it's got to be invertible. The irregularity implies it already. Is that what you suggest? If I just look at the top equation there and I'm being very naive and think, well, I want to somehow invert this, the bottom right corner needs to be invertible. But I'm pretty sure in finite dimensions, I can write down an example. I can write down an example where A4 is not a so you can construct rather simple examples. Just a one-dimensional physical example. You think about the capacitor, or if you prefer mechanics, think about a mass or spring. And if you write down the model, you exactly get something where E is a 2 by 2 matrix of this form. Let's assume that the capacitance is 1. Let's assume that the capacitance is one. And A1 is and A1 and A4 are both zero. And you have this matrix on the upper right and the lower left as a one and a minus one. And that's something which is regular. So this invertibility of the A4 is a feature, as you just said. As you just said, it's equivalent to the index being less or equal to one. So the world is full of such examples. Yeah, yeah, but here we, as I just precisely Okay, then I come to dissipativity at least to say a little bit about my title. My title. Somehow, we want to make the result a little bit more the direction of Luma Phillips. So at the moment, we were more in the flavor of Here's Yoshida for the generalized situation and now I want to be more in the direction of Luma Phillips. So formally, so what we are interested in, dissipativity, you remember, I interpreted as a, oh, that this derivative is less or equal to zero. This is somehow what. Or equal to zero. This is somehow what my notion of dissipativity is. And if I just formally differentiate this along classical solutions, of course, then I get this expression. I can make an easy calculation. Well, let's just have a look at this term. And if you look at this inequality and you square it, so S is positive. If you square it, then this one is easy. And this one you just this one you just take apart and then you easily see that you go those three terms. This first one here is the same as this one so you can just eliminate and then you bring this part to the other side and divide by s and I guess I forgot two. This should not be a problem. This two I just ignored. Don't worry. But it's equivalent to this But it's equivalent to this this inequality. And now you see I've chosen arbitrary s. So if I have this inequality for every s, I could just take here as the limit to infinity, which is equivalent to the fact that the real part is less or equal to zero. And so this is somehow the motivation or the Somehow, the motivation or the proof for the following result. So let's assume that the positive real axis is a result instead of the operator pencil, then the following three conditions are equivalent. You have a kind of distributivity. So this one is less than equal to zero. If and only if this inequality holds for every S. And since I assumed that And since I assumed that invertibility, I get this inequality. And this term we have seen before. Now I can use the notation of left resolvent, but this is a left resolvent. So the left resolvent is bounded by 1 over s, which is half of the weak radiality with k is 1. Timo, you had a question? So it reminds me a lot of maximal disciplines. For these operators, you have something like a weaker assumption that only a positive point is in the resolvent, and then you can imply that every point. It's here the same. Maybe I've even written it. Yeah, I even have written it here in this form. So this is now our main result. So assumptions, B is linear bounded with close range. A is densified closed. And now we have one lambda for some lambda. Because if you have it for one, then you actually can show that it holds for everything. And again, the idea of the proof is somehow similar. And you have. Similar. And you have those two inequalities. Looks a little bit like Louis-Phillips before, where we had the disapproval for A and for A star. And then we have the following main results. So under those assumptions, we know the existing vertical operators bringing our operator pencil EA into normal form. And the differential part is generated by a Is generated by a contraction syndicate, which means for every initial condition, I have a unit biot solution, and we have written that this one is here dissipativity I've written because we need when everything is dissipative. So, these are now somehow a Lumber-Phillips theory for infinite-dimensional differential algebraic suspects. And as an example, Systems. And as an example, this I can make easily skip. We again calculated it for this example we had with an unbounded E. But you have to test, you have to integrate those terms. And then you usually see you need some zombullat embeddings, but somehow it works out nicely. But a little bit, this was easy. The calculation, a little bit more work was More work was calculating the A star, the joint operator, and in particular, but this was maybe only my problem: calculating the A star of an operator which is not working between the same butter space, which somehow goes from an H2 to L2 and then goes the other way around. So, this was maybe a little bit a problem, but otherwise the calculations then was similar. Now, this brings me Now this brings me to the end of this paper. So, what we have shown somehow in the Man-Phillips theorem of infinite-dimensional differential algebraic equations. And we characterize well-positions in particular of coupling systems. If you want to read more of it, results are published in these papers. And, well, this depends if you give me another five minutes, because this is nice. Minutes because this is my stop here if you like, but as you requested, some more discussions. I have still four slides on two problems or work in progress. But we can also first discuss this, what you prefer. I'm maybe okay, Helbert has more questions so far and then we can introduce and you introduce the questions. Then you introduce your questions. Okay, that's time as that. Okay, so questions so far, and can you speak really loudly so that they can hear from that speaker over there? Well, I have a question that some of the feelings were passed and asked about some. Yeah, in terms of linear relations or multi-valued operators, if you think about this last part of dissipative operators, there's this work by Miadeva from the nineties on non-linear semiconductors. Can you look at this linearly? It's not, can look at this linearly. And then A somehow there, this is not your A, but this would be somehow E versus A, but seen as a linear relation. They have curved, he has characterized this activity as well. I was wondering, I think it is equivalent to your definition. And is there any difference in that work? Because I I think this is a s if this is not complete the same situation, but this is one thing and the other thing is this works by Baskakov on Ukraine. UK, who has also looked at these things through the eyes of linear relations? The second one, I don't know at all, so maybe we should discuss this later on. So, my question to Jan Schorton is: is there any use of looking at this real ICBK relations, or is this more or less the same? My feeling is this more or less the same. I take it. I did it. I think we have. I mean you have the algebraic thing is the algebraic part of the PBA gets off in a different direction. I think maybe a little bit equations. I mean the structure is better in one shape. But then maybe that these abstract things hold in this other viewpoint and iron knows something. I mean for example I think this is much easier because you don't have to invert E in some set. I mean looking at relations in practical examples I think it's less. I think not inverting E is like really helpful. Along those lines of not inverting E, your condition on decipitivity looks a lot like a numerical range condition. Where in the standard problem you might say the numerical range condition in the left half. Yeah, that's equivalent. And in a kind of a naive way of approaching, at least the invertible E case. At least the invertible E case is to make a requirement, say, of the numerical range of a B1 inverse A or A inverse. But your condition is filtered through not looking at the norm of X, but looking at the norm of EX. Yes. Right? And so that changes kind of the domain over which you test the numerical range. So you end up with something more like the numerical range of E star A instead of say E inverse A, A E inverse. Because in my reality, Because in my real products the inner product of E, X, and A, and it can bring the E to the other psi, and then you have numerical range of E psi. This is second. Does that end up being nicer? In other words, looking at the norm of Ex versus the norm of X. Is it easier to control the norm of EX, for example? Well, EX is more the solution. What is the solution? I mean, that was the solution of the DAEs, and we wanted information about the solution. Of course, if you can get back to really information on X, that would also be fine, but that's much what you can definitely simply if you assume that E has a closed range. So then I have split your space into part which is where X is 0 and the double part. Double part the idea is on two hands, yeah. You can reconstruct this as one festival. Your example was this one with Rayleigh's beam is invertible. So we have to. Which beam you mean? The beam? You mean the piezoelastic? Exactly. You mean the first example or the last? I didn't understand. The last. But the last was the one with the unbounded E. It's invertible. No, the E was not invertible. It had a kernel. From EFA, it's an unbounded inverting operator. No, no, the E has a kernel. The sine function is in the kernel. E of sine functions. So the one-dimensional kernel. So it's a one-dimensional kernel. Okay, of course, using the theory you can split it. You can split off somehow this one-dimensional kernel. And then you end up with an E and this E is invertible. So I was thinking to an only example I think given by FEMO or the Stokes equation. That's your file, your Shira theory applied to the evolution of Stokes. The evolutionary Stokes system. Stokes? Stokes is. Oh, Stokes is that's where I think A4 is zero. Yes. So it's strictly stand. This is a good question. We know it's well always playing other patterns, right? Virtual screen is only a S2 with the loss and the question. Yes, but you can rewrite it. I think that it's. I think that it is yeah we did we we did actually we did some uh we used the M of projection for for a decoupling which results into a mesh versus canonical form in another language yeah so but that's but that's really a nice example since since uh there there are ones that can be enough ones A4 and G4 of the perturbative. I think there are plenty of questions and reflections. This is maybe a good, maybe this will be more of the discussion topics, but I saw other people have questions and she also something that is probably obvious. I give you this coordinate parameter to zero in the beginning. The parameter to zero in the beginning of the talk. Is it obvious that the solutions also can converge to solutions with mu to zero? So if you solve the equation with mu non-zero, will they converge to the solutions from mu to zero or there is something? So it's not a theory of dynamic piezoelectric beams, and then when it comes to zero, we get a quantized value beam as well. Yeah, I like your character. characterization of the EL ideality questions of the E this index one in terms of participativity. And did you have also look in the characterization for the higher order terms? So but I think that's already a problem with ordinary differential equation situation, but it was also Helioshida. I mean Was also Hiyoshidai. I mean, automatically has somehow this sensitivity. So, higher order, I don't really see. It's interesting, but I have no idea how to, of course, all those products in there, how to characterize it. We have not looked at it, I think. No, but one could try to do it by looking at the Looking at the dissipativity conditions, you're part of the inner conditions of the ENA, but for the subspace, it's one that tries to create such a respectability condition only on the subspace of that signal. That a very closeness for sub-equation with the E1 and A1 AO and E1 is more. So if you claim to like dissect activity on the sum itself, then it should be possible. Okay, but I was also thinking about not only disruptivity, but just some further maybe some dissipativity, but similar relations for operators that are Yeah, exactly. I think I don't know how it is of email or inside. But I agree with you on the subspace, it's possible to actually go now more for the subspace because the evadiality condition looks quite nice, but it's always applied to everything and sometimes a little bit strong. So if we can be Strong. So if we can weaken it a little bit, this is another problems. Exactly. Sorry. I only see those and you. Sorry, okay. I don't know which order. I think we spoke, so we will let Allah. Okay, Allah first. Thank you for the nice talk. Actually, I just wanted to confirm one point. If you assume that the Asian. If you assume that the initial conditions are consistent with people? Yes, yes. Because later I always said solutions I have for initial conditions in the subspace. This is of course equivalent to saying I have consistent initial conditions. Of course for the algebraic part of course there are some automatically consistent, right? Yeah, yeah, yeah. Initialize the division. Yeah, the exact thing, exactly, exactly. In the main example with the E unbounded, the structure of the problem didn't go back. So those operators, they are just the same operator always happening there, right? So this d zeta squared, d zeta squared on the right and left hand sides, and d zeta to. And left hand sides, and D sided to the four is also the same operator, the same boundary condition. So it's so my question is: how sensible is this, or how sensitive is your approach to the boundary conditions you put on these things? Because I mean, this is a very, very symmetric situation where there's operators, but I mean, there's only two operators, time derivative and the Daplacian with theoretical boundary conditions. Have not checked the sensitivity, so you just worked out. So, you mean if I just replace other colours? But the boundary conditions just the same. You have to make sure that you do those integrations by heart, so they have to have not checked under boundary conditions. Not checked under boundary conditions. So I cannot, because you could then say, okay, I have an operator with compact resolvent with a self-adjoint, and then I just take a spectral point of this. And this is my one on there on the left-hand side. And then I just have this operator and the square of it. And then. I agree, one could easily generate a more general theory model. Yes, a class of systems. No, no. I'm just saying that it fits so perfectly symmetrically in this situation, so that I was wondering whether one has something different here. So maybe the Norman boundary conditions for the third derivative, I think, could already be problematic because it's not a square root anymore. I've not checked. I'm not. I guess it should work but um what has to do with the calculations but there was one Amy Carson and then also she had some questions yeah but I can move well my questions are not well I'd like to pose it at some point but I can also move them yeah we may have to say more about them after we have We may have you say more about them after we have our sort of set up for the problem session because you could maybe give us a preview now of the discussion. Yeah. So, just shortly, okay, we do it shortly. So, one thing is, and then you can already think about it. This is all very good. Indices. Notion of indices. If you look at linear, finite dimensional situations, then somehow they're different indices of DAEs and they are all equivalent. And in the infinite dimensional situation, I can define a lot. I can define a lot. I first of all introduce the radiality index and then you have the resolvent index. And here I only have written it down like a real resolvent index. You can also think of a complex one by testing it for complex numbers. I put in the real part. Then I have another chain index. When we somehow look at chains, they satisfy this equation as long as this somehow. This equation as long as this somehow is possible. And another one is the Neil potency index. If you assume you have Unich Weierstrass form, and of course you have other notions like the differentiability index or the perturbation index. I can define a whole zone on indices. So one question would be which one is the best one? And another one is how are they related? So maybe we have some relations. Have some relations with my old show. These are those. So, this is somehow the first point of discussion, I think, which would be nice. What is the right notion of indices and how are they related? And I can go through the definitions if you like, later at another occasion more closely. And another thing is for Hamiltonian system. What Hamiltonian systems. What Hamiltonian systems have an even more special structure. So there you have this A written as an AQ and the A, just the A is dissipative, which means satisfies this equation. B again assume closed range, the Q invertible, but also I assume that B star Q is Star Q is greater than equal to zero. And then it is already known in a finite dimensional situation that the index cannot be too high. And we also have a first result in this direction that at least the result of an index we can say a little bit. The result of an index, if you look at the real axis, is at most. Is at most two. And if you look at complex numbers into account, then it's at most three. And that's what I mean by the complex resolvent index. This is actually based on an old work by Goldberg. And actually, Timo and I, we had a palm paper, Timo, yes? From two thousand seven, yeah, I know, it's it's really old. Really old, but there we already discovered somehow this result. And then now the question further would be what can we use this structure to get again, like this, somehow combine it, this Luma-Phillips results together with the Ford Hamiltonian structure to get even more easily applicable conditions. So these are some of the So these are some of the other the two open problems I find adapted because of the time I asked later. Thank you very much for the very