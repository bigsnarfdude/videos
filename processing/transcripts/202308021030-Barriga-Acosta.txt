Around with this H such that f alpha is unbounded over these functions Rotman called. Rodman called these functions semiconduct. And one time, Michael defined this property as being totally unbounded, something like that. So call it whatever you want. This is image. We don't say that for the LB for HR. Not H alpha H alpha no no first observation here the length of this sequence this kappa has to be at most D because you cannot plug in a dominating family beyond beyond D to satisfy this property, right? So if you think about it a little bit, D equals C implies equals C implies m H you just enumerate the functions and start capturing more and more with models so this is due to Royman just an observation that we're gonna show right now which is not difficult that there are p points and this follows the same proof follows the same proof as Kettlin under the equal C. So let me just review that proof quickly. So under D over here with pictures under D equals C, this implies the existence of the points. And this is an induction of line C and you begin by Of length C, and you begin by, I don't know, just consider an initial filter, the frechet filter. And you're going to extend this over and over. So suppose you have constructed the filter F alpha, satisfying that any sequence, decreasing sequence has a pseudo-intersection within the filter. And then in the next step, of course, at limit the stages, you just take the union. And then for successors, And then for successors, you're gonna take this filter and extend it to something else. That something else is gonna take care of the alpha member of decreasing sequences of natural numbers. So beforehand, we have, I guess, defined or labeled this family of decreasing sequences. S alpha what is this increasing sequence infinite steps right so you encounter the S alpha vector and you want to plug in a pseudo intersection as long intersection as long as the all members of this sequence belong to the filter F alpha. That means, you know, the fair condition at this stage. So you have here S alpha vector, and this looks like something like this, a recursion sequence. And you want to find a C. Find a single intersection that's easy in general, but that single intersection has to have infinite intersection with every member of the filter, right? So every member of the filter, because each of these, let's say this is S alpha of zero, and this is S alpha of N, all of them have infinite intersection with every member of the filter. So here we have a member of the filter. Member of the filter. Let me call this A. And this element can define a function easily. For example, for the first ring, we take the first element in this intersection. And for the second ring, we take the first two elements, new over there, and so on. So over here, we take three elements, and this creates a follow-up. And this creates a function, right? F alpha. In the process, you just take care that these filters have size less than d. Then you'll have less than d many functions. And there's something that is not bounded, right? So there's going to be a function that wins infinitely many times, like that. And just in those times where you are winning to a function. Where you are going into a function, you know that you are capturing more and more elements. And just take the initial segments over here, and that's going to be your pseudo-intersection, P alpha. And you extend it with that as a generator, right? At the end, you reach this point and you just extend with an ultra filter. That's going to be a P point. Filter that's going to be a P point. All right. So over there with MH, this is very similar, but now we have this increasing sequence of models, H0, H alpha. And you begin again with F zero, well, not as a element there. not as a lem element there well we just begin with f0 a maximal filter over h zero we don't know we where this as element lies in this sequence but we're gonna extend this filter with you know same property for example after we have constructed f alpha we're gonna have here f alpha that is unbounded over this Alpha that is unbounded over this model. So, at this step, you don't take care only on one sequence of this at a time. You're going to take care of a lot of sequences there. So, let's say over here, there was S vector alpha. Well, S. And there is another S prime vector, etc. So, you're going to extend it with a whole family of. With a whole family of things P S in H alpha. The only new thing over here is that each of these are going to have infinite intersection with every element in the filter. And you just want to prove that this has the finite intersection property. Section property. So if you said F0 is eventually a member of said H alpha, I think you probably don't want H omega one at the beginning, right? Because then you don't trap your F alphas. You don't need to trap the F alphas. But this just talks about hereditary countable sets. Oh, sorry. You mean these F alphabets? No, the F. You mean these f alphabs? No, the filter f alpha. So we construct it that way. It's not hereditary functions, it can function at some point. These are as subsets of the some H alphas, but they don't have to live there. And yeah, probably they don't live in the whole union. F0 is a subset of H0. Yes, probably doesn't appear anywhere as well. Anywhere, but the sequence is appearing. Right. So finite intersection property with these things? Doesn't the sequence depend on H alpha? You have to know H alpha to get the sequence. Yeah, right. Right, it's the sequences that are elements of H alpha. The sequences that are elements of H alpha that he deals with. All right, so if you have S, for example, S zero, S1, another one, S2 vectors here. So here we have S zero of zero, S zero of one, S zero of two, etc., and S one zero, right? S two of zero, etc. So notice that this is an element of the filter, F alpha, element, element. So we go vertically, and this small intersection, Si of zero, is an element of the filter. And so this row is basically one sequence. Let me call it S bar. S bar prime that lives in the model H alpha, but we took care beforehand, right? Among all of those. So that's a proof. You didn't actually use F alpha at all. You could have done the sequences for all sets, regardless of where they came from. And then you just used F alpha. And then you just use that alpha as you were constructing. You could have done the whole construction with the f's and then choose the f alphas by induction. Because you don't know what f alpha is at stage alpha. Each stage chooses. Yeah, yeah, but the s's don't actually have to come from the f alpha. Because you don't know what f alpha is, so you can isolate them, and they have to be subsets back. We just select those that come from the f alpha. Otherwise, we don't have to worry about them. Don't have to worry about them. You won't expect you won't, but you could have dominated all of them. Yeah, okay, okay, and then you just that's even stronger. What if there's too many of them? What's important, right? That's the hypothesis says you can normally do everything. Yeah, yeah, without having to hypothesize that there's too few of them. Yeah, yeah. Yes. How do you know that they are if you add them all that they still generate the welfare that they don't compete one with the other? Yes, precisely this, right? So that's how you can say, Oh, I see, I see. Yeah, yeah, yeah. Okay, if you just open the door and the whole thing, you don't know what you know, but it's just one single detector, one thing that might be. Everybody has a different proof. All right. Observation MH MH does not imply there are two points. And this is due to Miller, who proved that in the labor model, there are no two points and D equals C. Okay, one more aspect of this MH is that mh fails in The Sachs model. So here we're taking the side-by-side product of LF2 Many Sachs Reels. And it is known, Van Gartner and Labor proved that in this model, there are P points and even selective ultra filters. We're going to sketch the. We're going to sketch the proof of this. Yeah, I think I have a product or the oscillator side by side product. I'm thinking yes, but I don't have the proof. So, maybe after the sketch of this, it'll be clearer. So, in the SACS model, we have d equals omega 1. So, that sequence, this sequence of models have outmost length omega 1. So, over here, we have the ground model. Over here, this is extension B let me. Let me just attach a filter, and assuming that you have a sequence like this of length omega one, let me direct picture like this. This is H zero, H H alpha, H alpha plasma. All right, so these are the elements of the sequence, and the alphas witnessing also the statement, I can find the alphas in the ground model because this forcing this omega-omega bounding. So all the alphas live there over here. F alphas. Do you know that B is contained in H0? H is theoretically both set of a class. No, it's not because the A and F alphas are. No, but how do you know that the H alphas start with P? No, they do not. Green. Green is different than green. You don't start from P, but they are. I think P was below H0 from the green stuff. Yeah, okay. Yeah, in my head, up and horizontal. Yeah, right. In my head, I'm just picturing a sequence in the extension. Okay. Okay, so okay, you can get a whole sequence of conditions. Add three, well, another condition in the sex, omega two, three in the sex, just one alpha, satisfying, you know, by thinning out and pressing down lemma. This P alpha restricted to gamma is the P bar delta system with the supports. With the supports. The p gamma at gamma is this tree. So we're fixing this tree for a lot of gammas, omega too many. They have the information that the X gamma, the gamma sex real is going to be captured in this H alpha. That's probably a stationary set of gamma. That's probably a stationary setting now, it's not all the magnitude. Right, sorry, it's stationary, stationary many. Am I missing something? Right, and you know the supports are disjoint after the support of P bar. Ada or disjoint So there's a bunch of sax reels over here like that make sure it's there around Okay, now this tree is going to be super important. And the property is that we have so many sex reals that are kind of independent from each other that we'll be able to manage that the next function f alpha is not going to. Alpha is not going to be unbounded over the previous model. So they carry among everybody, they carry much information to contradict that property. Okay, for that, over here I'm going to picture the tree T. So this is a SACS tree T, T as in Tule. Three single hacks. Three single Oaxaca grow downwards and it branches over here, right? And then over here, he branches again. He branches again. And over here, too. Okay, I'm going to keep track of these branching nodes. They have a name. So, I'm going to capture this node and this node. And I'm just going to consider an isomorphism with the Cantor tree. Like this. So basically collapse this stem and collapse this stem and collapse these stems to have an isomorphism there. Let me picture the kind of tree over here. One more. All right. So now, what I'm gonna do is. What I'm gonna do is all these sax reels are a branch of this tree. It's just a single tree. This tree lives in the ground module. So we have many branches. So let's say the gamma sacrile passes through this branch. Or maybe passing through forcing extension containing. Say it again. We might be passing to the forcing extension containing p-bar. Yes, a gamma that is sufficiently large. Also taking a generic over the first gamma, maybe the gamma zero, maybe iteration. Well, maybe not. I don't know. I don't get it. Okay, so this is going to be SAC Frill, like that. It's just a branch through this element. If I take the pullback, meaning let's declare y gamma. This is going to be the inverse image of the SACS real. So I'm just taking the pullback over here. Back over here. So I began going to the right and then going to the left and then going to the right and something else, right? So this is going to be the Y gamma. It's just the same sex real view in the country tree. Take the inverse image of one and this One, and this is an infinite set. Let's call it i gamma. And so I'm doing a little bit more things in the extension. Let me capture this by a condition. So let's extend this guy, the p bar, with a condition q bar so that everything is captured there. So the q bar forces that, I guess, the I guess this phi lives in another model, H beta, beta greater than alpha. But let's just assume it's the next model. No, H beta is right. So everything so far, if I extend all these guys with Q bar, they're going to still have all the information. So everything is capped. All the information so everything is captured in H alpha. So phi is right there. Say it again. H beta. Thank you. All right. Now we're almost done. So for this H beta, we have the witness F beta, right, which is unbounded over this model. And from this function, And from this function, just take a subset of omega seeing that behavior of the grow of f beta. So for Marieli students, from this function, give me a set that is describing the behavior of f beta. This question for you. Yeah, right. For example, then take, let's say, the maximum of those partitions, right? Or take simply take the nth. Let me call it. It's going to be the nth element is above f beta of n, right? Just something that describes a faster behavior than. A faster behavior than f beta. Okay, and from a subset of omega, you can create this tree that only branches at A. So over here, for example, A contains this level and also contains this level and contains this level. So we're going to branch one and then we branch both. Both right here. So this n lives in A. This n prime also lives in A. We also branch here and branch here, but this M doesn't live in M, so just go just go right. And over here, M prime lives in A. Uh, right, okay. So, forget about that. I take it back. Branch left if nothing is happening. If the natural number is in A, branch both. I think my picture is already messy. So basically, this Y, when it branches one, one, this capital I is going to be contained in A. And that behavior is going to be pulled again by this phi or phi, phi. So what we found is that if we take the condition P gamma concatenated with the Q bar concatenated with this This condition in the gamma coordinate. These three that I created with A, let me call it T so A. But notice that I'm just sending notes over here. This is not a tree yet. I have to close it downwards or upwards to make it a tree. So let me just. To make it a tree, so let me just use this notation. This is a tree, and this is an extension of capital T. This is a sub-tree over there. And these forces that capital I gamma is contained in A for a gamma that doesn't interfere with the support over here. You can choose a gamma far enough. All right, and that's the proof. And that's the proof, right? So a function coming from capital A that describes the behavioral, just take the h of n equals the nth element of capital I is going to win to this function. All right, so that was a little bit surprising, and already these two results solved some problems. Solved some problems of Reuman. Reuman asked whether MH is true in CFC at even more delta. This already answers that question. All right. So I'm going to stop with Delta right now. I'm going to go ahead with, I'm sorry, MH, and I'm going to go ahead with Delta. Yeah, right. Yeah, right, just since then. Right. Actually, yeah, so there are no people in the Chelan, no P point model, and in the silver model with David and P. The existence of people doesn't imply image. This is what we prove over here. Okay. Okay, Delta. So, just one annotation: I'm gonna describe. I'm going to describe the note partials of the verse space to be the partial functions from n to omega, just partial functions with infinite co-infinite domain. Okay, these are like the silver conditions, and then delta is the cobinateral statement. Is the cobinatorial statement that exists a family of total functions indexed by the partial functions so that for every given two partial functions satisfying these two conditions x minus y Y is infinite, as well as y minus x. The second condition says that in the overlap of the support or the domains, they differ at most final many times. So the n, and let me denote this that the x is the domain of x, intersect the domain of y, where x of Where x of n is different than y of n, this is finite. Rush rule that then could partial functions satisfy that. If they satisfy that, if my walls, then thank you. Thank you. If they satisfy one and two, then the differences are not bigger than the corresponding HY. So HY is going to win to this part of X infinitely many times or the symmetric HX.  If they satisfy this, then this happens. Okay, the picture I'll always probably you've memorized this picture before. So here we have a partial function x and here is y so these. So, this difference right here has to be infinite by one. This other difference, which is y minus x, has to be infinite. And in the overlap, they almost coincide. This overlap can be almost empty, doesn't matter. Okay, and the conclusion says that the attached, the associated h is going to win infinitely many times over here to this part of x. And we can add the condition that if follows y in its domain, it doesn't matter. Whatever happens here, it doesn't matter. This happens, this is h sub y, or the same metric, we follow x and over here it wins infinitely many times, h sub x. The domain of the partial functions. Okay. So let me share with you the map so far. D equals C implies MH. Royman proved that this implies delta. It's not difficult to see. You just declare for every partial function, declare the minimum label where h alpha caches. where h alpha captures the x and just define h sub x to be the f alpha, the next f alpha. The rest, you can prove it. D equals b, what am I saying? Usually we say b equals d implies delta and this implies that the box product Is normal, is paracompact. Okay, being delta the weaker, the weakest statement known that implies the part compactness of the box product. So notice that if the continuum is at most LF2. Then delta holds, right? That means that delta holds in the Sachs model. And that was a question of Royman: whether delta implies MH. So in this model, we answer in the negative. But it's not really, it's because cardinal arithmetic, right? It's not really about the properties itself. Properties itself. That's followed from what you said, right? Well, we need the LTS against the SDS. So yeah, I forgot what I was saying. Anyway. All right, so I'm going to go. Maybe I should say this. So, delta seems like a very weird statement. And how is this related to proving something like this, right? Well, the thing is that when you try to separate elements in this space, let me just give a sketch. Elements in here that are total functions. Total functions are isolated points. Elements over there that hit the infinity and then they become partial functions, they are accumulated points. And I mean, infinite co-infinite domain. And the other option is that they're almost the limit point, and then just a finite partial function there. So these elements. So, these elements and total functions are easy to handle in order to separate things because power compactness talks about like kind of separating elements. And basically, delta is uncovering the most problematic scenario for points to be separated, which are points that satisfy one and two. So, this is So, this is enough tools to make this happen. Okay, I was planning to present that proof, but I don't think it's there's something more important to say. Okay, so the continuum being small implies delta, and it was unknown that, for example, the simplest model. For example, the simplest model where we have B equals omega 1 less than D equals omega 2 less than C equals omega 3. For example, this can be achieved by adding omega 2 many coin reels and then omega 3 many random reels. It was unknown in 2015 that whether delta holds in this model and in the coin. In the coin by the random. So we start exploring finite support iterations, or in general, CCC forcing extensions. Like, is it true that delta holds in any CCC forcing extension? And the answer is yes. Not yet. What in the snowball draw? What you assume of the drawing? GCH? We can assume GCH. Yeah. By not yet, I mean there is an assumption that we're unclear how to prove it, but we think it must be true. If not, please share your thoughts. And I'm going to try to let me state this more precisely. More precisely model of GCH and B a complete Boolean algebra That is CCC If G is B generic then B of G and don't believe this yet. This is the hope. I don't want to rephrase I don't want to rephrase this that, oh, we need an extra assumption. Along the proof, I'm going to get there, and probably I'm going to stop there too. So the proof of this should go as follows. All right, again, here we have the ground model. Have the ground model. This is the extension. And we're going to begin by considering a dominating family F alpha alpha less than D. The value of D is unknown with this forcing. And I'm going to have a sequence of models, sequence of models. Sequence of models in the extension. And let me call this capital F. So I required capital F to be in the first of these models contained in M1, etc., up to the union of M alphas, alpha less than D. Let me call this model M. Just take an M in the extension, a model that is capturing. That is capturing partly f along the way, and the size of these models are less than t also because we're assuming GCH, this is, and every model in this sequence is close under sequences. So declare P to be the Boolean algebra. To be the Boolean algebra intercept M. So this P becomes CCC by M being closed under sequences. So actually this extension, this extension, no, actually this B can be expressed as P iterated with Q dot, with Q Q dot is the tail of this forcing. The tail of this forcing. And since I'm capturing the dominating family in M, this Q dot is omega omega boundary, CCC and omega omega boundary. In the ground model. Well, I think these tabs are indeed these models are in being used containing more and more names for the tabs that are not. Yes, yes. M is in V. These functions are functions over there. Yeah, I should put dots. Every function as the whole collection, I put it in the first model is omega omega bounded. Okay. Correct, correct. There's nothing to prove. Yeah, kind of the thing is that after M, after beyond this M, there has to be other reals, right? Be other reals, right? If there are no more reels to capture, then basically we're in that situation. Right. Okay, let me shorten this. So over here, we have the sequence of the M's, M0, M one, M alpha, M, right? What we don't know is that the whole set of partial functions is contained in this M. We cannot guarantee that, right? I mean, it could be, it could happen, but that'll be a trivial case. You have to somehow distinguish between names and objects. Okay, let me think of a better picture. Also, only names are traced or something. Because otherwise, with the Flow, I usually find that the whole sequence, yeah, they're not transitive, they're elementary models. But I should do this. Over here is V, and let me picture the models over here this way. All right, and the And the forcing, okay, maybe the forcing is doing this, this is B. What else? Okay, so we start by kind of capturing partial functions. If this is a partial function over here, if Michael Michael is speaking. So, this is a partial function over here. The name is going to be over there. It could be over here, right? Or it could be not in M. Could be over there or not in M. Typically, it's not going to be covered by M. But then for each of these X's, let me. Let me rearrange my picture for each of these x's. Maybe the x dot is not in m. Let me consider another sequence of elementary submodels that is capturing m and is bigger than this one in the following sense. So the picture is going to look like this, which is purple. Okay. This model, I'm gonna call it M for the pens of X, and it's gonna have just like that. That model, I'm gonna declare that it contains The first element I can split that model that contains that element is increasing like that, also of length B X. And I'm calling this model MX. Yeah. Right, right. Right, right. Um, how can I see how to do just the sequence of the M alphas alpha less than B is also here. Also, the capital F is there. Yeah, by what George said, this is what is going to happen, right? It's going to capture like an initial segment of the original sequence of models, and then it's going to branch out. But the thing is, the But the thing is, the important thing is that we are considering the x over there. This one? Nope. I can call it D. No. Yeah, you're loading up one of the amounts of staff, so it should be a little bit and you're starting with the change called stack. Yeah, okay. So I think my picture is partial, but it's gonna come back and capture everything far beyond. I think the picture that I'm describing right now is what is gonna happen in the next. Okay, the idea is. Okay, the idea is I don't have like this statement mh. Notice that we're kind of describing instances of mh, right? But mh is very linear. And that not necessarily is happening here. Like I can have a sequence of models for this x, and if I another y, that's going to be another sequence of models. All right. So note that if I take mx, there's going to be a lambda x where m x intersect D is lambda x. Subscript, what do you have? Mdx subscript lambda x, the mistake was right, sorry, sorry. Lambda x. There you go. Thank you. And there are going to be cofinal many of these lambda x in D satisfying this property. I can't object those programs in all. Right, and it's technically they have size omega one and they're growing, yes, right? Otherwise, yeah, okay, this implies we can call it a claim that if I take m x, now this m x, and intercept it with m. M this gives me m lambda x right huh and I think this is what I was thinking over here. This guy that I'm picturing is M X lambda X. M X lambda X. So kind of this is telling you, okay, even though these models branch out potentially for any given X and Y, somehow you can control a little bit with these Lambda X's and the Lambda Y and just compare them linearly. So Lambda X is gonna be less. Lambda x is going to be less equal than lambda y or vice versa. Okay, so just finally, I'm going to draw the assumption. The rest are more details. Okay, the assumption over here. So, by using that, notice that M X lambda X is close under omega sequences. So, if we intersect it with this, here we have a complete embedding. Fleet embedding. And moreover, if we take this guy and we intersect it with M close under omega sequences, this is a complete embedding of V intersect M X lambda X. But notice that this intersection was precisely m lambda x, right? This is v intersect m lambda x from the original sequence. Now, I didn't define here, well, I discussed p, the first iterant was b intersect this m, right? And we can even define we can even define P alpha to be B intersect the M alpha. So over here, we are saying we can actually split this guy as a two-step iteration where the first one is already known, p lambda x, with another q x lambda x, right? All right, so the assumption is let me say some words over here. This P lambda X is going to have the information about the dominating family. Under the eyes of this model, this model MX Lambda X X, the family is dominating, meaning P lambda X forces that capital F is dominating. And that tells you that this forcing is omega omega bounding again. Also, this point X dot is going to be this forcing name because, you know, we put this as a name on this sequence. As a name on this sequence, and everything that describes x dot is going to be from this forcing. Okay, and this is a complete embedding of the Boolean algebra. So let me describe these things: one p lambda x star q lambda x x dot it's a complete. X dot is a complete embedding of B two X dot is a P lambda X star Q lambda X X dot name three P lambda X forces X forces u lambda X X dot is omega omega boundary. This is true at this stage lambda X, but the assumption, I'm not stating the assumption yet, the assumption says that for every alpha greater than this lambda X, all of this is going to happen. Alpha, let me say this, exist. This exists q alpha x dot the existence of q lambda x x dot was based on that complete embedding. But for larger alphas, I'm saying, okay, there has to be someone satisfying these three properties. Still have some of the donies in this provide the donkeys. No, the models can see more and more of the dominating family, but under their eyes, this guy is going to be omega-Omega boundary. Okay, well, this is where I wanted to stop and emphasize this. If we assume this, we can go along the proof, which is more detailed, but we can prove that delta holds. The main ingredient here from the assumption is that, okay, this x dot branch out, right, from this sequence. Branch out right from this sequence, but then because property number three, there is a function that wins to x dot and that function can be described with this model. So there's a way that even though we're branching out, we can come back to this sequence and describe things. To this sequence and describe things. That was like the main thing from this assumption. Coin omega 2 star random omega 3 is one of those. And precisely what is happening here. And precisely what is happening here is let me begin with my weird pictures again. So, if this extension is a two-step iteration like that, over here you have the intermediate extension. Let me say this with a coin, right? And the rest is the random reels. And these models are capturing information partly from this extension, right? Let's say that information is captured that. Information is captured that step. But the rest of these q alphas x alpha dots are parts of the random portion. Those models are not seeing anymore this part. They're looking at further. But we know that this is just the random model, is uh satisfies this. In a sense, it's something because going and then randomly. It'll be something similar because where the randomness sort of first order omega mega boundary correct correct um yeah so that means that answers the question though about that delta holds in that far almost um oh yeah delta Oh, yeah, delta holds over here. That is true. That means that that box product. In this model. Was that also open, whether or not the box product? Royman asked in the survey that she published with Scott Williams in the paper that they talk about uniform box topologies too. She stated that it is unknown here. But well, this is what I wanted to share. And more than this, if this is true, if the assumption is true, then assumption is true then it is significantly that we cover ccc extensions right and the rest would be okay what happens with other parts other type of iterations but to get these inequalities it's kind of difficult to do it with non-CCC finite support iterations so we should be exploring maybe in the problem session I can continue with the questions here really interested whether or not this is an additional Whether or not this is an additional assumption, or yeah, the focus is right now is on Q it is known that you cannot have an analog of this UM for the MH, and it is not only on test for this. Well, is I would assume MH in this image holds here, MH holds here. Holds here, MH holds here in this model. Right, right. MH holds here. It's hard to decide. Yeah. Yeah, P points. In this model. And actually, you prove that in this model there are P points. Model that are p points. Okay. Okay. There are results that if you have a rich enough ground model and you iterate and you add random reals, you might have p points. And it kind of looks like mH is going to hold too in those types of models. So but that also means we still don't have a model where image fails, which is obtained by CCC. Do you know anything about the model? No. That's another question that I can dig in later. This property that mh fails, it wasn't because we noticed something about delta. There's no relationship there, right? And especially delta holds here. And especially delta holds here. But what happens in the models where delta fails, it should happen that mH fails more drastically, right? It should be more evident that in these models, this tells you something about delta 2, or at least that's the direction where we're going of this consistent with this? Delta fields? No, that's the. Delta fields? No, that's uh, that's the big question. Yes, yeah, yeah, that's the big question. The equivalence that power compactus implies, Delta, because the power compactus proof, the proof that you get paracompactus usually involves non-linear sort of groups of nominating families and average products and we can flow for it. So it seems very similar to the doubt that you tried to do that. Is there some options? It's a big question. It's a big question by Royman. She asked whether this me paracompath implies delta. Yeah, and we this box product is related to something that they call the Navla product, which is a quotient mod finite. And it is a result by Kuhnen that if the factors are compact, countably many, they have Many, they have the same paracompactness. This is paracompact if and only if this is paracompact. Marian Lynn Rudin was the only person under CH proving directly that the box of production is paracompact, but the rest of the people prove with the NABLA product. With Polgar side, we found that delta is equivalent that the NABLA product of this space is monotonically normal. Normal. And we also prove that Nabla products of matrizable factors, such that the Nabla product is monotonically normal, then the space is hereditarily pra-compact. So monotonically normal in these spaces is super strong, becomes super strong. It is a question whether the part or if there is another combinatorial statement, delta-like equivalent. Delta-like equivalent to the power compactness either of this NABLA or the box product, but that's unknown. Those are different questions. Well, we'll miss copy if we don't have it. Should we start online? I don't think we are. In case there are people on the eye,