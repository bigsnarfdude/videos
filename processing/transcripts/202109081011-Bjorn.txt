She is going to speak about fine potential theory via analysis on metric spaces. Please, Jana. Thank you, Andrea. So, yeah, I will try to tell you something about why analysis on metric spaces can be useful also for treating things and problems in RN. And this is based on some. Is based on some results together with Andr√© Bjarn, Visala Twala, and Jan Mali, who, as we heard yesterday already, unfortunately passed away just less than two weeks ago, which is really sad. I only have one paper with Jan, but he has been involved in more of our joint results with Andersch and Riesa. With Anders, and we saw through various discussions, he has initiated several problems and results that we then later studied. So, let's start with some kind of motivation for the fine potential theory and for analysis on metric spaces. So, the whole problem is solving in the record. Problem is solving the Richlab problem on an open bounded set in Rn, and so well, everybody knows what that means. You are trying to find a p harmonic function in omega with boundary data that are prescribed on the boundary in some sense. And the p harmonic function means that u is a solution to the p-laplacian, which P-Laplacian, which is defined through the divergence of a certain power of the gradient, and here p will always be between one and infinity. And as you know, solutions to the P-Laplace equations are p-harmonic functions. We know that they are held to continuous in omega. They are actually even better than that. And for p equal to two, the equation. To two, the equation just becomes the classical Laplace equation with harmonic functions that are solutions. And an old question, more than 100 years old, was that if we have continuous boundary data, does that mean that the solution is also attaining this continuous boundary data? On the boundary, this has been solved. And that's not what I'm going to talk about. And it's known. Talk about, and it's known that this need not be the case. And the Anmali has actually been involved in characterizing which points have the property that the solution would be continuous at those boundary points. So I give you an old example, which kind of gives you the flavor of what can go wrong with the boundary points and continuity. At the boundary, At the boundary. So consider the Lebesgue spine in R3. P is equal to 2. And well, the Lebesgue spine is obtained by rotating this curve, which is the exponential of quickly decreasing type. You rotate it, and then this gives you the complement of the. This gives you the complement of the set omega at the origin. And then, if you solve the reflect problem in this set, then it can happen that the limit at the origin here, it actually does not exist, even if you have very nice boundary data F. So, that the level sets will look something like this, and the limit does not. And the limit does not exist. So, this tells us that this boundary point is an irregular boundary point, and in a way, it behaves more like an interior point, because its value at the origin is not really caring about the boundary data, but it's more determined by the values of the function inside. Of the function inside in omega. And in the language of fine potential theory and fine topology, this means that we can add this origin, the boundary point zero, to omega, and the union will be a finely open set. So, in a way, it is a fine interior point. So, even though the limit So, even though the limit at the origin does not exist, the fine limit exists because it does not see those bad level sets that I draw here in the picture. So, what is defined topology, and what are finally open sets? So, the definition is through the notion of thinness and the second. Of thinness, and the set G is finely open if the complement of this set is thin at every point in the set G. So that means that this integral here of linear type converges. So we can see in the picture here what actually happened: that you take the complex. Happen that you take the complement of the set here in, that's what this term tells us, and you calculate its peak capacity. And then you compare the capacity with the capacity of this whole ball here. So that's what they have here. And then a magic exponent. And if this integral converges, the set. The set, this complement here is called to be seen at this point. So some examples of this, if the set is open, then for small radii, this part here, this complement will be empty, so the integral will. So, the integral will trivially converge, and that means that every open set is finely open. And in the Lebesgue spine, because of how it looks like, it is thin at the origins of certain piece in dimensions. And another typical example of a finely open set is if you take an honest open set and remove a set of capacity zero, for example, the rational numbers in a Numbers in a unit square, then the set of capacity zero does not really have an influence on the capacity. And so this set with the set of capacity zero removed will be finally open. And if you remove, for example, the rational, then you get a set that is finely open, but its interior is empty. So there's a big difference between open and finally open sets. And finally, open sets. So these finally open sets, they define a fine topology. It's been studied since the 1940s for P equal to 2 in the linear case. And the theory has been later studied by many people and is reasonably well developed. The non-linear case for P not equal to 2 is much younger and it's been studied by Adams and Fuglede. Adams and Fuglede, and also the Finnish school, into which I would also include Jan Mali for all his collaborations with the Finnish people. And the Finnish school and Yanmali, they have been studying Dirichlet problems for non-linear PDs and, in particular, for the P-Laplacian on such finely open sets. Finally, open sets. And relatively recently, also eigenvalue problems for the Pilar Blushen have been studied on such sets by Fusco, Moherji and Jang. So if you have a finely open set, which is not open, and you would like to study, say, the P-Laplace equation on it, what would you need? I mean, one thing, one ingredient that's needed is that you need some kind of test functions, and those shouldn't hear you anymore.  Probably her connection is lost. I don't know how to contact her. I wonder if she accidentally hit the mute button because she's muted. Is she? Sorry, Andrea, this is Veronica from Beerce. I'm just in touch with her, but she is not muted actually. Something is wrong with her connection. Maybe, yeah, I'm just trying to see if she can maybe log off and log back again. Yeah, we can hear it. But I don't see how to get in touch with her. I'm texting her. You can text her as well. But I'm not sure if she is looking at the chat. If you can hear us, Jana, you can give us a thumbs up so we know you are there and you can hear us, and it's only us. Only us no if she lost her connection proper, she cannot see the chat as well, I'm afraid. She's right there, but probably her connection is not there. Jana, if you can hear us, you're well, she's not even moving her slice. So she is, I think she probably got stopped. She is, I think, she probably got stuck. Her computer got stuck. I hope that she realizes that she is not online. Mark is not answering my text as well. Just one recommendation. We can wait for her, but don't stop the recording because if she comes back, we won't be able. Because if she comes back, we won't be able to get the recording back. So we can leave it open. Thanks for reminding me. In fact, the first day we did it wrongly and we had to record it using Zoom after all. But now we know it. Thanks. Okay. So you can see me. Oh, I think she's gone now. She left. Did she? Yeah, I think her, yeah, because she stopped her. Her, uh, yeah, because she stopped her. Uh, no, we don't have a um a pause option, not in live stream. It's just a one-time start button. And if you stop it, somebody's asking, if you stop it, it's for the system, it's like you are over and you're done with that recording. Jana, do you hear? Hello, I guess I lost connection. Yes, yes, apparently. Yes, yes, apparently. Did it happen recently or did it happen a long time ago? Something like five minutes ago. Oh, I see. Does anybody know which slide it was? If you go back to the slides, maybe we can find it back. Okay, I will start sharing again then. I don't know why that happened. It may always happen. Yeah. So, I guess this one was not the same. You can go ahead. And I think it was this one. Yeah, okay. So, I was talking that about that there have been earlier approaches, different approaches to defining Sobolev spaces and gradients on finally open sets. And the idea of The idea of analysis on metric spaces is then, or one of the possibilities it gives, is to define these directly rather than having to go outside of finely open sets. Because that's what the earlier two approaches were doing. They were either taking globally restrictions of global subolef functions, or they were approximating by sub-olef functions on large. Functions on larger sets. So, before I give you some introduction into how to define sub-LF spaces on metric spaces, I would like to give you a few ideas why one would like to look at finely open sets. And one of the reasons might be that the standard P-superharmonic functions are Harmonic functions are finely continuous, so that superlevel sets are finely open sets. Another reason is that if you look at Sobolef functions, they are finely continuous at quasi-every point. So that means outside of a set of capacity zero. And this brings us also to the fact that Sobolev functions are quasi-functions. Sobole F functions are quasi-continuous, and that means that their level super-level sets are quasi-open. Quasi-open sets are close relatives of finely open sets, one could say. Namely, a set is quasi-open if and only if it differs from a finely open set in a set of capacity. Of capacity zero. And a good reason for studying quasi-open sets is, and thus also finely open sets, is that quasi-open sets appear naturally as minimizers in certain shape optimization problems. So, how to define gradients and how to define subolev spaces. How to define subolev spaces and how to solve Dirichlet problem for the P Laplace equation on metric spaces. So, for that, recall that in Rn, the P Laplace operator is just equivalent to this minimization problem here of the P energy. And so, if you want to do a similar thing on a general set. On a general set or a general metric space, you would like to define certain Sobolev spaces on such a set. So we take an arbitrary set E, for example, a measurable set in Rn, and we want to define a suball F space on that. And for that, you need a gradient and you need a measure. So, the assumption for defining Sobola spaces is that you take a metric space with a metric D and a Borel regular measure on it. So, in particular, if you don't want to think of metric spaces, you can just think of measurable subsets of Rn. And to define a gradient, then this definition goes. This definition goes back to the 90s due to Heinon and Kuscala. And a function g is called an upper gradient of a function u on a metric space if its integral controls the difference of u in two points along every curve that connects two points x and y. Points x and y. I guess many people have probably seen this definition. So it's simply a way of controlling the differences of the function u along curves. And it was also shown then that among all the possible upper gradient, because it is not unique, if you add a positive, something positive to g, then you still have the inequality here. I define. Defining it. And so anything that's larger than G will also be an upper gradient. But among them, you can find one that is minimal. It's not really an upper gradient. It is only P weak upper gradient because the defining inequality can fail for a small family of curves. But it is minimal both in the L P norm and it's In the LP norm, and it is also minimal point-wise almost everywhere. And so, this gives us a notion of gradient or minimal upper gradient for an arbitrary function on a metric space, on a general metric space. So, having gradients, we can now define so-called Newtonian bases. Well, in the usual Well, in the usual way, Lp norm of the function and L P norm of the gradient, and it should be finite. And the nice thing with this is that since X as a metric space was allowed to be totally arbitrary, this gives a natural definition of a Sobolev space for any measurable set E. Totally. Totally arbitrary measurable set. So, does this have any connection with the world in Rn and the Sobola spaces that we are used to? Well, yes, it does. In Rn, the gradient, the minimal gradient is equal to the absolute value of the standard gradient. And on open sets, This Sobolev-Newtonian space defined by the upper gradients is the same as the standard Sobolev space. On the other hand, if you take a very bad metric space, or it doesn't have to be that bad, but if it does not have rectifiable curves, or it has very few of them, then zero function will be an upper gradient. Be an upper gradient for any function u, and so the Newtons of a left space reduces just to the Lp space, which is maybe not very interesting for solving differential equations. One can also define the space, the Sobolev space, Newton-Sobolev space with zero boundary values simply by taking global Newtonian functions. Global Newtonian functions and requiring that they vanish outside of the set E. And this will serve as test functions in the boundary value problems. So one can then try to solve the boundary value problem, the Dirichlet problem on such a measurable set in the usual way. You simply You simply find a function. Sorry, this is not. So you simply have boundary data f here. And you are looking for a function that has these boundary values and it minimizes the energy like here. And this can be shown to be uniquely solvable under rather general assumptions. Rather general assumptions of Poanca inequality and the doubling measure. I don't go into that because those are automatically satisfied in Rn. So you can solve such a Dirichlet problem on any measurable set in Rn, which sounds good, but there is a catch. If the measurable set that you have The measurable set that you have is such that the space of functions, of Sobolev functions with zero boundary values, is just the zero function. That means that there are really no test functions to have. Then the solution of the Dirichlet problem will be just the boundary data. And that's not very interesting. So, what we did was that we looked at for which and characterized which sets Which sets have a non-trivial set of test functions. And it turns out that this happens if and only if the set has non-empty fine interior. And in that case, it's also true that the set of test functions for a set E and the set of test functions for its fine integer. Test functions for its fine interior are exactly the same. So, in other words, when solving the Dirichlet problem on a set, you may as well be solving a Dirichlet problem on its fine interior, which justifies why these problems have been earlier studied on finely open or on quasi-open sets. Quasi-open sets. It doesn't really make sense to study it in a lot more general sets than finely open or quasi-open sets. Another issue here to look at is actually the gradient depends on with respect to which set you define it. So it is not completely clear that the minimal upper gradient that you are considering in the Dirichlet. In the Dirichlet problem, it is the same for the set E and for its fine interior. So I will look at it a little bit later, but now I want to give you an example of a finely open set, which is actually suitable for solving a Dirichlet problem for p-harmonic functions on that set. Functions on that set. So take a unit cube or unit square, and you remove balls from it, which are placed at the dyadic points, and they have radii, small radii given by this formula. And alpha here is greater than n over n minus p. P is less than n. Less than n. And then you get, if you take, if you remove all these balls, you get a compact set, which has empty standard interior. So it's equal to its boundary. It has positive measure, but the fine interior is actually almost all of this set. The fine interior would be obtained by removing the closed balls. Obtained by removing the closed balls from the unit cube. So we could call this a Swiss cheese. And then since the fine interior is non-empty, there is plenty of Sobolef functions with zero boundary values on this set. So There is plenty of test functions for the Dirichlet problem as well. And so one can solve and find a unique solution of the Dirichlet problem for the P-Laplace equation on this set with any boundary data f that belong to a Sobolev space on this set. And since the set of test functions is non-trivial, this gives us a solution. This gives us a solution that is, in general, not equal to the boundary data. So, if I come now back to the question of whether the gradients on E and its fine interior are the same, so why is this an issue? Remember that the sub-life spaces on E. Sober life spaces on E is defined using the gradients that are defined using curves taken through that set E. Whereas the subolev space on X is defined using curves and the gradient from X. So since on E we have less curves than on X, we have this inequality. We have this inequality, but it could be strict. For example, if E does not have any curves, then again, the gradient with respect to E would be zero, whereas the surrounding space may have plenty of curves. And so, like here in Rn, the gradient would be equal to the standard gradient. So, then we have to have a gradient. Gradient. So then we have a strict inequality here. So when would these two be the same? And there are two sufficient conditions in the space of N1P0 functions with zero boundary values. This is never a problem. That's fine for any set E. And if you do. And if you do not require zero boundary values for the function, it's just a sobola function, then these two gradients would be the same if E is a so-called p-path, open set, which means that almost any curves hit this set in a relatively open set. Relatively open set. And using this, then we can say that for finely open sets, the two gradients will be the same. Namely, I mentioned already earlier result by Fugleda, is that finely open sets are quasi-open. Finely open sets are quasi-open, and it was shown by Shelmu Gallingam that quasi-open sets are p-pass-open. So they have the property that gradients with respect to those sets will be the same as gradients with respect to the whole space. And as a matter of fact, together with Ian Mali, we showed also the other implication. So every p-bus open set is actually. Set is actually ways I open. So these two notions turn out to be the same under the assumptions of Bohn-Karre inequality and the doubling condition. So a corollary of these observations is that if you have a measurable set E and you study a Dirichlet or obstacle problem on that set, you may as well study it on the five. It on the fine interior, and moreover, it's not only the solution that will be the same, but also the gradients for these functions coincide whether they are taken with respect to E or whether they are taken with respect to the fine interior. So, how does this relate to the work of Mali and Kilpalainen and the Finnish school in the 90s when they were studying sobolar spaces and differential equations on quasi-open sets? And another result together with Visa Latvala is that I've been talking. I have been now talking about these Newton sobolite spaces on metric spaces. So it's not completely clear that they give exactly the same thing as what Kilpelin and Mali and Zeemer studied in Rn. But they could show that if you have a finely or quasi-open set in Rn, then the definition of the Newtonian Sobolev space is actually exactly the same as the Sobolev space. As the Sobolev space defined by Kirtalan and Mali and Zeemer. And also the gradient corresponds to the gradient that they defined. And the advantage of the Sobala spaces on metric spaces is that all of these definitions can be done within the set itself. You do not have to go outside of it to take restrictions from the underlying space. From the underlying space, so you do not have to take slightly larger open sets. You can simply define the gradient and subolev spaces directly, just within the set, the finely open or quasi-open set. And I guess we have one minute or so the solutions exist to the Dirichli problem in this situation. The Dirichli problem in this situation, and one might also like to study their regularity. And this is largely open. Well, one step is that every Shabole function is already known to be finely continuous, quasi everywhere in say quasi-open or finely. It's a quasi-open or finely open set, but not much more. So, this is true for any sombol function. If you have a solution to the Dirichlet problem, then you can say a little bit more, but not much. If the boundary data are in the Sobolev space, then it can be shown that the solution is finely continuous. Finely continuous at every point inside where the data are continuous. So, in particular, for boundary data that are continuous on the whole set G, the solution of the Dirichlet problem would be finely continuous everywhere in the set G. In Rn and for globally continuous functions, this was proved already in the 90s by Kilpel Leinen and By Kilpelinen and Mali. And we have managed to localize this to sort of just one-point situation. We don't need continuity everywhere, but just at one point if needed. And so we managed to do this in metric spaces. So since my time is over now, I think I skip the last two. Skip the last two slides about uniqueness for functions with zero upper gradients. I wanted to show you a short proof of a uniqueness result that was initiated by Nicola Fuska. But I think I don't have time for that. So thank you for your attention. Thank you, Jana, for your nice talk. For your night's talk, are there any questions or comments? So So, apparently, there is no question. So, we can thank Jana again. Thank you. I stopped the recording and there is a break now.