Alright, so last but not least, Nicol Rafael Enerkaus. And we're going to be hearing about persistence modules, our representations of species. Yes, so thanks for the introduction, and thank you for inviting me to talk. Thank you for organizing. Thank you for organising. I've also got a final slide because more than I've forgotten anything else that will remind me. The brief I was giving was quite fairly vague, but it gave me flexibility to basically talk what I wanted to talk what I wanted to. And what I was discussing with people at lunch was that TDA seems about 20, 25 years. Twenty, twenty-five years old, and representation in theory seems about fifty, sixty years old. And so there is a chance that people in TDA have not been looking at things that happened earlier in representation theory. There have been lots of things happening in representation theory in the last 30 years, or what happened before then. So I thought I'd just like to double-check that we haven't missed anything essentially, as a first point. As a second point, there were As a second point, there were lots of people asking about how to deal with representations that weren't over algebraic closed field. And also, TDA people seemed interested in post-epresentations. And so, with all those things in mind, I chose species. So, there's a concept of species that was developed by mainly by Ringel and Vlab back in the 70s. Sorry, Ringle and Vlab, D-L-A-L. Blab. D-L-A-B. Yeah. You'll see their names on the screen in a moment. The point is this. In Siri's talk, we saw that there are path algebras of quivers, and you can ask when do they have a finite representation type. Well, it's when the underlying graph of your quiver looks like a n, b n, e6, e7, or e8. I've labeled these with a capital I. That's the kind of fine. I. That's the kind of finite representation type case for an algebraically closed field. There's the Tain case as well for a path algebra, which is these extended or Euclidean Lincoln diagrams. So they're just a little different from those ones over there labeled with an I. And that's the same case, and we didn't really discuss it, but that's when you have infinitely many indecomposables that you can still describe them. That you can still describe them in a nice way. There was debate on what Tang really meant, and I don't want to go over it at all. But I just want to keep in mind that these are for the describable but still infinite case. The rest of the diagrams are called the Dinkin diagrams. These are the usual Dinkin diagrams, all of them together. These are the extended or Euclidean Dinkin diagrams, all of them together. They're valued graphs. So you see how on BN I've got a 1, 2. Now, on BN, I've got a 1-2 here and a 2-1 here. Where I don't have a value, that's it. The value is 1-1, so it's not really worth writing to save everyone's eyes, including mine. And the point of species seems to be... I only... What does 1-2 mean? 1-2 is the value of that edge in the graph. So it's more information than a graph. It's a graph where each edge has a value, a pair of integers assigned to it. It and these will come up later. Yeah, we'll see how they appear. And from my perspective, the point of species, one good thing about species is that over a perfect field, and not necessarily algebraically closed, over a perfect field, you can access all of the thinking diagrams in finite representation type case and in tame representation type case. So let me try and explain that story. I also then read a paper of simple. I also then read a paper of Simpson, again we'll see it later, who dealt with species, but allowed the species to be infinite, whatever that means, and that really corresponds to the poset being infinite. So I thought it was worth presenting that here, because now I can tell my story while saying something consistent about your story, which is persistent modules. And we'll see how persistent modules... Well, I hope I'll try and explain how persistent modules are represented in the basis. We'll see how it goes. So this is the overview. There was a joke here. B R I S is the acronym. I'm from Britain, so we're obsessed with acronyms, so I thought, yeah. So that's the overview for the talk. We'll see how far I get. B-I-L-L-S. B-I-R-S. Oh, oh, oh. Yeah, good point. I tried my best, but then the talk wouldn't make any sense. I tried my best, but then the talk wouldn't make any sense if my presentation came after my illustration later. So the background is filtered and factored representation. So classically, people cared about representations of postsets, but they really cared about something else. So this is just reminding you what a representation of a postset is. I put a vector space for each element of my postset, and I put a linear map for each pair that I compare. For each pair that are comparable in that way. I've written it in a strange way because I'm going to keep rewriting the same thing, and that will be, it will look like a representation of species later. So that's why I'm writing it in a fairly strange way. You need these conditions so that it actually becomes a functor. And a morphism of representations is a natural transformation. So there's your naturality condition. And such a representation is filtered, or you can consider factors, but I'll show you later. Can consider factors, but I'll show you later how it's the same. If each of these maps are injective, so that's quite peculiar, that's not really something that you've been dealing with, or at least it's quite a special case of what people have been dealing with. But this is where close up representations really, the study started. And you can consider the category of filtered or factored representations with point-wise finite dimension. And this work of Kleiner and Nazarova Reuter from 1970. And now they're over Reuter from 1972. So that's why it was my first plug, but it's an old paper from 1972. It described a finite poset P where this category of filtered representations has finitely many indicators. That was their job when they did their job. And I'd like to just, part of the background, I want to explain how that job was done. I thought it might be nice. I certainly hadn't thought about it for a long time. I don't think many people in the Rep Theory community even know how it was done. Theory community even know how it was done. So let's see how it's done. It was done really with this process of differentiation. Oh, dear. Oh, yeah, here we are. So I'm going to assume P is finite. I'm going to remind you what anti-chains are. They're subsets of your postet of completely incomparable elements. The width is the maximal possible anti-chain, the size of the maximal possible anti-chain. The size of the maximum possible anti-chain. Now, differentiation. I'm going to write it and then I'm actually just going to run the algorithm and really see what's going on. I start with a maximal element in my postset. That's where keeping finite comes into play. And I define a new postet, P of Z. So I delete my maximal element. This might be running out of battery. I delete my maximal element. I'll just go the old-fashioned way. Go the old-fashioned way, yeah. And then, what do I do? I look at all the things, all the pairs x and y that are not comparable to each other, because they're in an anti-chain, and z is not comparable to either of them. Quite a horrible sentence to say and symbol to look at. Let me try and explain it with an algorithm. The point of this differentiation procedure was that Glen and Adrobe Leuter showed that a poset, finite poset, is representation finite. Is representation finite? Thank you. Amazing. Such good organization. This category of filtered representations has finitely many indecomposables, if and only if the width of the postet is at most three, and the differential, I'll just keep going with this. The differential yields the empty set eventually. So if you keep taking your So if you keep taking your maximal element and deleting it, but adding some maybe new elements in and some new relations, then eventually you yield the entertainment. Let's see how it goes. This was in Bruce's talk, the grid. This is the grid. Yeah, that's the grid. And I started with my maximum element here, and I thought I I just wanted to firstly point out the category of all representations of this poster is wild. Representations of this coset is wild. But the category of filtered representations of this coset is finite. So there's subtleties going on. The former thing I said is part of work that I'm going to mention later, and the latter is as follows. There's a maximal element. That's the maximal element. Everything is comparable to it. It's globally maximal. So the set. So, the set of pairs which are incomparable to this probably maximum is empty. So, when that's true, I just delete it. And actually, if the set of elements that were now let me look again, these are the set of elements that are comparable to Z. The ones that remain are in a chain. So the pair of them can't possibly fit in an anti-chain. Fit in an anti-train. If I take Z, X, and Y, there is no anti-train. So I just delete it. So you think, oh, this is simple, so far, nothing's happening. That's interesting. Then I take Z. Again, everything incomparable to Z forms a chain, so I delete it. Pretty boring. Now I take Z. Everything incomparable to Z is this, this, and this. Don't form a chain. So something interesting should happen here. So, something interesting should happen here. There are my X and Y. And I delete Z, I add in a join of X and Y, like that. By the way, when you say deleting, I mean they store the information of the budget with any composable setup. At the end of the day, the algorithm can compute more composable statements. Yes, but the the storage that's going on is the The storage that's going on is that the number of indecomposable representations of fill of this concept is smaller than the previous one, but it's finite if and only if the previous one was finite. I find these last two steps quite interesting because you had two maximal elements. Yes. You chose to remove one. Yes. And somehow this procedure tells you, wait, now we're going back to what you had before. This you could have achieved also by simply selecting the other maximal element. It would make for more complication. It would make for more complicated things if I chose this one here. No, maybe go back one step, one more step. And now you could also remove Z instead of Z, you could also have chosen the one on the bottom, and basically you made this other choice, but the procedure leads you back to that choice you didn't make. It leads me back to something where I've deleted one. This is exactly the same thing as you would get if you had chosen the. Yes, it wasn't a good choice. Yeah, so that's kind of curious, right? You don't get sparkly that much. Yeah, that's you, but it's kind of funny that you get that. There are different ways of getting to the same place using the hardware. And now I just want to run it. Can I clarify also to leave it? if if deleted um differently. So there you had you had an anti-chain of elements that were incomparable to to the choices that we proposed, but they already had a common upper ground. Yes. So would this say just don't do anything since you already have a common upper ground? Yes. The choices I made, the choices I made, were on the plane here. So it may not have been good, but the beauty of the thing. Have been good, but the beauty of the theory is it doesn't matter which ends you chose. If you eventually yield the intercept, you'll be good. And I want to now convince you that I'm going to yield the intercept because I'm definitely going to run out of time if I spend much more time on this. I delete that one. Here's another one. There's some incomparable things. W and X are comparable, but W is not comparable with Y and X is not comparable with Y. So I've got to get some complicated things going on here. If I relabel. Now, if I re relabel Z, I delete that. Delete that by adding that. And you just keep going. And it gets pretty nice, but you can see how it slowly cuts down. I don't want to go over this. But you see how it's slowly cutting down to the empty set. Is it true that there's a systematic order that would actually never include anything new if I? Actually, never include anything new if I just cleared the bottom row, then cleared the sounds. I think what you're doing is making things more comparable by adding in joins and deleting other maximal elements that weren't comparable. But remember, this finishes all. But but remember, this finishes only if if if it's finite. The the point the point I'd like to make is this. So does the choices matter? For a different choice, would it never terminate? No, I think it doesn't matter which choice you make. I don't think it matters which choice you make. It should be that you can keep making choices, and it doesn't matter which ones you're choosing. ones you're choosing. But if you eventually get down to something that's representation wild, it'll never work. And if you get down to the empty set, it definitely did work. So it's really about does this process terminate or not? And if it does, then you're good. And if you get down to something that seems like it'll be impossible to terminate because it's representation infinite, then it won't terminate. Yeah. Yeah, now I'm on the 20-minute mark, and I should have been further through the talk. So I'm going to skip over extension, but the idea is I talked about factored representations as well, which are ones where the maps aren't injective but surjective. And there's a trick where you can define an equivalence between factored and filtered representations. But I want to skip over this and waste in the time. That was in a time. But there is some equivalence between factored and built representations. In for exam there's a there's a paper you have with Bot Botman, Opperman and Steen where the factored representations turn up. This algorithm together with this equivalence tells you that that problem is representation finite, which is consistent with these quotients. I didn't want to go over that because I thought I'd be told off at the end of the month. So I'm still in the background. Still in the background. This is Gabriel's theorem. And what did Gabriel do? Gabriel described the quivers such that the path algebra, so now for me, this whole talk, Q will be a quiver, not a poset. So KQ is not the incidence algebra, it's the path algebra. Of course, there are cases where they coincide, but I care about the path algebra. The underlying graph should be thinking type A, D, or E, so that's not. Or E? So that's not these, but these. These ones, yeah. A, D, or E. And we've seen the incidence algebra, so I'm going to skip over this fairly quickly. But you can describe the incidence algebra as the quotient of a path algebra by relations. This was in Ezra's talk, so I won't go over it too much detail. And there's his work of Lupians. And there's this work of Lupians. So, this is where general representations were studied, not just filtered representations. Lupians described the posets, finite posets P, where the incidence algebra is representation finite. We have finitely many intercomposable. So, this is not quite Nazarova Reuters' work. It's looking at all representations, not just filtered representations. And then a year later, Dlav and Ringel looked. Year later, Dlab and Ringel looked at something called a K structure. Now, I don't want to go over this in detail at all because I'm going to generalize it almost immediately. But a K structure is, instead of just putting... Okay, so for the incidence algebra, the incidence algebra, I really get a copy of K for each element of my postet. The vertices in the quiver are the elements of P. So I put a copy of K at each vertex. I put a copy of K at each element of the postet. Here I'm putting a Each element of the postset. Here I'm putting a skew field extension for each element of the postset. So it's quite strange. And I don't want to go over examples because I'm going to see an example later in the context of species, which is what I want to get to. And you want some condition on containment of these skew fields relative to the poset. So there's some compatibility between the skew fields and the poset here. It can't just be chosen arbitrarily. And Lab and Wrinkle. And Lab and Ringel, they defined filtered representations of a structure, a k structure of a p. And they described the p, where this category of filtered representations is finite, there's finitely many indecomposables. And it generalizes this work of Kleiner as he's open Reuters. So Klein and Ringel were thinking that there's other things you can do where you involve skew field extensions. Skew field is a possibly non-connected thing. Skew field is a possibly non-connected sequel. Final? Yes, you want you want when I say extend, there's many details that I'm going to gloss over, but these extensions need to be finite. There's many details that I'm going to miss today. So representation theories, please complain, but I'll probably submit immediately and then move on. But the point here is that instead of having just a field, I'm including field extensions. So I could have started with. Extensions. So I could have started with the real numbers and put the complex numbers as a field extension in places. And that was a fun game to play, and you could still classify. You could still describe when this category had finitely many indices. And it fit in nicely with the previous work. So now I'm on reconciliation. I want to try and combine all of these things together. There's quivers, quiver representations, there's posets. Representations, there's posets and poset representations, there's these structures where you involve field extensions. This is very complicated, and it's better to have overriding language that can describe all of it simultaneously. And then we can speak that. And it'll be complicated, but we avoid having to go between different worlds. Just talk about everything in a in a unified way. In a unified way. Yeah, so now I'm just going to list off what I said. I want to adapt Gabriel's work to access all the Dinkin diagrams. So I want to include these ones and these ones and these ones outside these green boxes. I want to think of a theory of representations that includes all of the Dinket diagrams. All of the Dinkit diagrams. That would be nice. I want to encompass representations of structures of posets. I want to involve possible field extensions. Not just have the incidence algebra, but something more general that recovers these structures. And following Simpson, I want to allow for infinite quivers and poseets. So that's where persistence, that's why the idea for this talk came, that persistence. For this talk came, that there's not so much kind of thing. Wouldn't you have the line out of it or allowing that talk? Um I think I'm allowing anything. Anything, very quick. The real line will work. The real line is not locally finite. Between 0 and 1, there are infinite many numbers. And the reason I want to do this is because I want to, as an illustrative example, I want to look at work of people. Well I want to look at work if you could use the rough sort of rough sorry when you say infinitely the idea with the real line is that you you have far too Is that you have far too many arrows? You have an arrow from zero to a half, from a half to one, and an arrow from zero to one. And that's too many arrows, because the real line you want representations where all of those maps, the composition of those maps, gives you the third point. Yes, yes, yes. I I'm I'm alla I'm allowing for any quiver. I'm not putting any finalness conditions on my quiver. Putting any final misconditions on my quiddown. Yeah. So this was the beauty of Simpson's work. This whole talk is really a plug for go and read this paper from Simpson. So I'll get there. So let I be a possibly infinite set. Just I is an infinite set. And I want to think about I as the elements of a postet or the vertices of the clip. So it allows for the real line. Allows for the real line, depending on how you want to look at it. So, what's a species? A species over i. So, for each pair of elements in my set, what am I going to have? I'm going to start with a skew, just think of it as a field. It could be non-commutative. The reason I want to allow it to be non-commutative is so that I can access all of these thinking languages. And I want a bimodule for every pair. So instead of just considering a linear map from one vector space overfield to another, I choose a bimodule. It's quite strange. But each arrow I'm considering bimodule. I'll give you an example in a moment. Maybe it's a bit more concrete. And I want some compatibility. So it's a horrific isomorphism of home spaces, but th this is this is useful for the theory. But th this is this is useful for the theory. This this third point is really so that I get fewer complaints from the regular crowd. So what's an example? One, two, three. Okay, it's not infinite, I know, but I'm going to deal with an infinite one later. F one will be the real numbers, f two will be the complex numbers, and f three will be the the quaternions. And F3 will be the quaternions. But this is something strange going on already. Non-commutative fields. But they're all fit. You know, I've already noticed that this is a chain of field extensions that respects the order of 1, 2, and 3. So what I'm really going to describe is a structure. The complex numbers can be considered as a module over the complex numbers, a vector space. Numbers, a vector space. But they can also be considered as a module over the real numbers. The complex numbers are a real vector space, is what I'm saying. Also, the quaternions are a complex module, not a vector space, but a module. They're not a vector space, but a module. And they're a module over themselves. Quaternions can be considered as a module over themselves or over the complex numbers. And otherwise, I'm going to take the zero byte. And otherwise, I'm going to take the zero bimodule. So, yeah, Hedge is the quaternions. And there's a valued graph you can define for each species. So, this is where we had this question about what these pairs of numbers are doing. I'm going to define a valued graph, this is a valued graph, using this language. I have edges, undirected edges between i and j, and I give them a value depending on the dimension. Value depending on the dimension of this bimodule as a vector space over the different fields. So I could put j equal 3 here and i equal 2 here and then I'd be looking at the dimension of the quaternions, but over H or over C. That gives you different numbers. Actually gives you the numbers one and two. It actually gives you the numbers one and two. So but then okay the pair the this pair is uh is ordered. This pair is ordered. But the edge is not the edge is not ordered. You are choosing a direction. If there's no difference in the dimension then you're going to get you're you're not going to get some order. So sometimes it's ordered. I mean that in general it is ordered, yeah. In general it is ordered, yeah. Yeah. Yeah, yeah. Uh I'm going to I'm going to recover the usual definition of a path algebra from all this nonsense in a moment. And there you'll have no order, everything will be 1, 1. And if you have 1, 1, there's no point in labeling it. And if I don't label this at all, I have the Dinkin diagram A3. So the path algorithm. So the path algebra gives you A3. So you see how this kind of pushes the world of path algebras over algebraic enclosed fields. But this is slightly different. This is 1, 2, 1, 2. In fact, this is B C 2 tilde. 1, 2, and then nothing in between, 1, 2. So this really is the Deacon diagram. Is the Dinkin diagram, the extended Tinken diagram of like BC2 tilde? So it cannot be accessed using the theory of alpha algebras over algebraic and closed fields. People were asking how do you do things over non-algebraically closed fields? What happens? This is what happens. If you're in TDA and you don't like this answer, then the information to glean is that it was the wrong question. There's something called the tensor ring. This is going to generalize the path algebra of equivalent. So I had a species before that was a collection of skew fields and a collection of bimodules. If I take all the skew fields together, I can take the product of them and define a ring. R times C times the quaternions. And if I take all those bimodules, I can take their direct term, I can take their tensor product. Can take their tensor product. They can keep taking their tensor product. This you can consider as the vector space spanned by all the trivial paths in your quiva. This is the vector space spanned by all the arrows. This is the vector space spanned by all the paths of length 2. And in general, paths of length n, the n voltage product. So this is the tensor ring. This is a very general construction from ring theory. There's lots of work on this. There's lots of work on this. It goes back very, very far. Colon, I think, is my favourite reference. But you can do it here. And you want some kind of multiplication here. And how do you multiply things? Well, if I have something in the field here, and then I'm considering something in the bimodule here, well, nothing should happen. It should be zero. The multiplication should be zero. As an example, you take a quiver whose set of vertices is i, and the tensor algebra gives you the path algebra using these specifications. Yes, here things are finite, but I thought the example would be nice as a sum of the check. I've got finitely many arrows here. But of course, I could just take the direct sum over all the possible arrows between i and j. To 9j. I just thought it would be nicer to put it as a number. This is some case where I have a locally finite quival. But I didn't need to do it. I just thought it'd be... There's lots of general nonsense on the board. I thought I'd give you a break. But we'll see later that I didn't have to. So there are these theorems of Vlad Ringl and Joel Skirachenko, and I think they're amazing. They're amazing. That's why the reason I'm giving this talk on this topic is because I love this theorem so much. I'm in the world of a finite set, I'm afraid. But from representation theory perspective, this is where this is motivated. So you can look at the tensor ring of your species. I'm leaning over details here, it should be a K-species, so sorry, the representation things we have. But this thing is finite or tame if and only if the graph of the species is one of these or one of these respectively. You access all of them. So this really is for me the better version of the theory because where did all the Dinkin diagrams go? They were here all along. So that was the work of Drad and Ringel. Quite amazing. Quite amazing. Something that George Kirishenko realized is that if you take a perfect field, any characteristic zero field will do. So the real numbers will do to answer people's questions about the real numbers. Any basic K algebra has the form of a quotient. This is awful notation. That should be an admissible ideal. It's nothing to do with the set. My apologies. My apologies. The statement here is that it case perfect. The the statement here is that if k is perfect, any basic k algebra is a quotient of the tensor wave. And a nice quotient at that. So the point is if you have a basic finite dimensional, maybe it's extended because of the world of persistence, but if you have a basic finite dimensional algebra over a perfect field, it lives in the world of species. If your field was algebraically closed, it lives in the world of path algebra over clips. Ever quick, but if it's not, if it's only perfect, finite fields are perfect. F2, if you want to deal with F2, this is another way of dealing with it. So that seems to be of interest, but I don't know if this is answering the question of every species has a graph. Yes. And then you're saying that finite and tame only depends on the graph. Yes. Yes. But the tame and financing of the tensor ring. Of the tensor ring. Dealing with quotients of the tensor ring is ridiculous. I mean, very difficult, and still unknown. But if you're just looking at the path algebra, or generally the tensor ring of a species, then you take this valued graph and you check if it's one of those or one of these and respectively, then that tells you if your if your number in your possibilities was finite or infinite, but still deal with some Then the second statement has a form uh has that form for some g and some i? Yes, yes. There exists a species and there exists an ideal, not i, i prime, whatever you like, such that such that that basic k algebra is isomorphic to that. I mean, uh you'd say merito equivalent, but but we saw that merito equivalence is actually isomorphic for basic algebras, so. For basic algebras. So for a statement like this, do you need the generality of species or can't you do this already with the students? I don't think you can get these unboxed Lincoln diagrams if your field isn't algebraically closed. Okay, so that's the point, right? That's the point. That's the point. If I take K to be algebraically closed, I didn't need any of this. Close, I didn't need any of this. If I take k to be the real numbers, to be f2, to be any perfect field, for the second point, I did need it. And if I, for the first point, if I wanted to access all of the thinking diagrams, you done, then I needed this language these things. So for me, this is very very nice theory. I haven't till 11:30. Sorry, in the so if you do so, if if things are you just take. So if if things are you just take the same field everywhere and then the same result, then what do you get? Like this tensor algebra, but it is like products of polynomial things? If you take the same field everywhere and you do like it like quivers, no, and you're a species. I think it should just be a path algebra of a of a quiver. If you take if you take the same field uh if you're should be the path algebra, but I'm trying to think not the temperature space is not. I don't know. No, sorry, sorry. No, it's a good question. I think the answer is that if I take Fi to be equal just to a field everywhere, then the tensor ring gives you the path algebra over that field. Whatever the field. But the point here is the following. If I start with a perfect field and I take any basic biomedimensional k algebra over that field, it might not be the path algebra of a quiz over that field. You have to define a species. The argument goes as follows. If it's basic and finite dimensional, I mean it's a semi-perfect ring. The quotient by its radical is a semi-simple ring. A semi-simple ring, and if it's basic, that actually means it's a product of division rings. If I take a basic finite-dimensional algebra over any field, that modulo, its radical, is a product of division rings. Those are the division rings you take for FI's. You have a collection of division rings in your hands when you take a basic. If your field was out of breakthrough closed, all of those division rings are actually your field. Are actually your field. But in general, they're not. I can take the complex numbers as an algebra over the real numbers. That is definitely basic. It's definitely finite-dimensional over the real numbers. Its radical is zero, so the complex numbers over the radical is zero. And now I have left in my hands a division ring, the complex numbers, but it's not the real numbers. Complex numbers, but it's not the real numbers. So you end up with a division ring extension of your field. No, I guess I am not because when you get the tensor algebra over up to dimensional vector space, you get the fracture. So something, so there is some subtilities in your Q and a structure vectors. When you take the tensor algebra over a two-dimensional vector space. On the zeta basis? No, actually, no. It's a basis, no, actually, no, and it's really hard to know. This is presumably what you're doing is taking the graph will give you a loop or something. Yes, yes, yes, that corresponds to notes. Yeah, probably. If you want to take the tensor product over just Interproduct over just one, over just your field, then you have one vertex. And if you're taking a two-dimensional vector space, you're taking A to be K2, you're taking just your field to be K. And that will give you a polynomial ring. It's a complaint. So, for example, for F2, we still have to look at people that are looking at. We still have to look at, you know, there are lots of ideas have to vision to make this right. Algebra extension of algebra. The subtlety that I haven't put here is that you want your division rings to be finite extensions of a ground. So finite feed or something? You you take F two or F four? Yeah, the uh so the finite finite division is the better would you Division print is the better one prints are things. So hopefully your complaint is resolved. I'm going to move on because I have 18 minutes left. There's no problem. This is really the main point of giving a talk on this topic. It's that it's complicated, but it's it. Complicated, but it gets you everything. I think it's great. And now I define to you what a representation is. There's a notion of a representation of a species. It gives you the same thing as a module over the tensor ring. So what's a module over the tensor ring? You start with a, at each element of i, at each vertex in your quiver, at each element of your poset, you put a vector space, but over the skew field. But over the skew field at that place. And then you have to adjust. Then you have to adjust. For your path algebra, this is just K. For your postet, this is just K. But this does nothing. This is really just a map from one vector space to another. I won't go over the details of this because I don't think you need to know it. But the point of this slide is that there is a notion of The point of this slide is that there is a notion of a representation of a species, and it is the same thing as a module over the tensor ring. And there's a morphism of those as well. And you just, what you have to do, you just have to adjust for the fact that you're dealing with bimodules and different division rings. So remember, this is an FIFJ bimodule. This thing is an FIFJ bimodule. This is an FI module. This is an Fi module, this is an Fj module. So, how do I go from Mi to Mj? A tensor with this I module? This is now a left Fj module. This is a left AJ Fj module. So, I can ask for this Fj there. It's complicated, I know. I'm going to move on so I can point out the work of people in the audience. So, this is still reconciliation. Remember, we had the incidence algebra of Poset. And recall that the path algebra is the tensor ring of the species given by the pivot. I want to generalise this the these relations so that it works for an infinite poset. And this is where this is this was the genius of this. This was the genius of Simpson. So, really, this paper of Simpson, I really think it's something amazing and it kind of is dealing with infinite posets, but simultaneously is still being consistent with this representation theory that deals with all thinking graphs. And Dinkin Simpson noticed that you needed the appropriate notion of associativity. Notion of associativity. To generalize R, remember R consisted of saying that if I go along one path in my quiver, or if I go along another path, if I want that to be a positive representation, they need to be equal. I need to have a relation that makes one path the same as the other. I want parallel paths. This is dealing with parallel paths. What you do is you think about, okay, what's the analog of composing to analog? Composing two arrows. How do I go from one arrow and another arrow and compose them to get another arrow? You have maps like this. Imagine, take this as an arrow from H to I, this is an arrow from I to J, and I want to compose them to get a path from H to J. So you introduce binary. Introduce bimodal homomorphisms. And again, the point here is there is an analog. I don't want to discuss the details because I'm running low on time. But there are associativity maps. You have to choose a particular subset of your indexing set. What what what per set representation theory people want to do is take the whole of i x i x i. You want all of your relations to commute. Of your relations to commune. You want that wherever you start and wherever you end, that's always the same, no matter which way you go around. I'll reconcile this in a moment. But the condition is this. This is the condition. Some compatibility condition between these maps. This should not be understandable. You should trust me that I've checked Simpson's. Simpson's work, and that this really does yield what you want. If I take a representation, I can ask that it satisfies this commutativity condition. How do I do it? I impose that all of these equations hold. Maybe I'll just write something about this. Maybe I'll just try to write something about this. I just want to convince you that this is this somehow makes sense. It somehow makes sense. You've seen these before, so it's evident. So on the one hand, I'm going to look at this map, H I J. Hij, I take A A H I I tensor it with With this, and then I'm tensoring this is H, with MH. And there's two ways I can deal with this. I can firstly just consider composing these two arrows and considering CJIH tensor the identity on this and get down to J A H tensor. H, sensor mh. I can also just ignore this and act on mh with this. So then I then I go to this. If I hit that with one on A, this is one on M sensor I mu H. This is the maximum. H. This map is coming from your representation. This map is coming from your commutativity condition. But now I can act on this with my representation map. And I can act on this with my representation map. And I get to mj. And I want that diagram to move. That's what this equation is saying. So it's kind of the right thing. So, it's kind of the right thing to be doing. So, your modules over your incidence algebra satisfy this because they're really modules over that path algebra that satisfy the relations R. A module over this is actually just a KQ module such that that module satisfies the relations R. Analogously, I want Analogously, I want my module over my species, the tensor ring of my species, to satisfy these kinds of relations. For a poset and a field, I'm going to consider that species and a commutativity condition. At every vertex of my poset, I take the field. Whenever I've got i less than or equal to j, I take k. Otherwise, I take zero. And these commutativity conditions, well, when you have any possible h less than or equal to i less than or equal to j, this is k tensored over k with k, and I want to go to k. Well there's an isomorphism. Well, there's an isomorphism. There's the obvious isomorphism. Lambda tends to lambda prime goes to lambda times lambda prime, the multiplication map. So this is really just the multiplication map. If I take a tree quiver, that's a quiver, say a finite one. Any of these that don't have values, it's a quiver, but it's also. It's a quiver, but it's also a poset. So I can consider it as a posset and look at my example, or I can consider it as a quiver. Now, I want to make sure that I get the same thing. Whenever I have an arrow from i to j, I'm going to take k. But this is creating an issue because I don't have. Let me look at this. Let me look at this. For an, for a3. For a n, for a3, for a3, I've got two arrows. I don't have an arrow from here to here. But as a poset, I take k. As a quiver, I take zero. So there's something going on here. The difference is, I don't have any commutativity relations for my quiver, but I impose commutativity relations for my poset. So, considered as a poset, you have. Considered as a postet, you have far too many bimodules A, A, J, I, but then you impose some commutativity conditions to get back to what you started with. This is the analogue of the motivation. The incidence algebra is really you take a path algebra, but then you have to kill out by some relations. And the categories of representations are isomorphic. So that's the sanity check. Sanity check. Take a tree quiver, consider it as a quiver, consider it as a poset, it doesn't matter. Unify these two worlds with species. And this example, by the way, has nothing to do with the size of the post-sector. So persistence modules are representations of species. That's the title. I had to say it at one point, you know, like I'm just going to. So that's why I thought this was a nice topic. I like it from a representation theoretical perspective, and Simpson's work gives you what you want. Now I want to illustrate the work with the Gusa-Rock-Kodorov representations, also known as representations of a continuous quiver of type the real line, a continuous A-type quiver. So, what I had before, I'm just going to give it, it's just an example of a poset. But you can have weird posets on the real line. So, it's not the normal order on the real line, it's that. This is just an example. They deal with many, many more complicated situations. But I thought I'd just deal with something non-trivial. Trivial, but still fairly nice. So now everything between minus one and zero, the order is swapped. And everything between one and infinity, the order is swapped, but otherwise the order is the same. So just to see what was happening earlier, I'm taking the real line. I take the species where I put K everywhere and A, J, R. And aji to be k when i is less than or equal to k in this weird order. So now the order is really mattering. Let me think. In this order, a third, sorry, minus two thirds is bigger. Minus two thirds is bigger than minus a third. Is bigger than minus a third. Strange. But because of that, because of that, minus two-thirds A minus a third is K. And on the other hand, it's actually strictly bigger. And so minus one-third A minus two-thirds is zero. That's zero. So, so kind of weird. So, the signs that you put are in their inequalities right here. Yes, yes. They're not arrowed. Yes, yes, sorry, they're inequalities, yeah, yeah. But you can, you can you know, there's there's an analogue here, which is if I replace all of these numbers and infinity by vertices, it's kind of a type A equivalent. Type A equipment. But yes, it's in order. Talking about order, not equipment. The associativity, it's just like before. Representations that satisfy C. Okay, so now the CJIH condition is pretty simple. It's just asking that it's multiplication. Where you can do multiplication. So actually, just take a vector space, a k vector space of each number on the real line. Number on the real line. And I note that if I tensor by k, the vector space by k would be nothing. And then I just take k linear maps. Usually it would be an fi linear map for that vertex i, but they're all the same, they're all k, so I just take a k linear map. And I ask that these maps compose that was the condition of satisfying the commutativity, this associativity condition. It's associativity condition with C, and that M satisfies C is this equation here. So it really does give you what you want. Cordana can tell me off now if I've described. This is a representation of that? Yeah. So this is really a representation of interference. The work of the use of further on. And the morphisms are what you'd expect. Wherever you can go around a diagram, the diagram should be like a morphism of representations of quids. Yeah, and they had a lovely theorem. Many lovely theorems. But I just thought I'd tell you something about the theorems. Interval representations are indecomposable. And those are all the indecomposables. And there's a description about when outside the writing sequences exist. If you take a simple, which for me is what you're really doing is taking a vector space at one vertex, supported at one vertex and nowhere else. There are no outside of writing sequences ending or starting, in fact. Very strange. Usually, in the representation theory of quibbas of A n, that's how you get the. That's how you get note of them. This talk of Sira, Sira had this talk and drew the Alzheimer's writing quiver of type AN and it looked like this. And these were simple, and these were Alzheimer's writing sequences. So it's completely at odds to the classical situation. I thought that was. The classical situation. I thought that was very lovely. Thanks for doing such nice maths. And now this is specialization. This is where you talk about your own research in the last 60 seconds of the hour talk now. I just want to give you an example of what I've been looking at. I firstly give you some ring theory setup. You can take a polynomial ring, as you usually know, but you can skew it. Ring is usually known, but you can skew it by an automorphism. So that's what the polynomial ring usually looks like. It's a vector space given by the powers of your indeterminant. But I haven't told you what the multiplication is. It's the same as usual, the way you skew it. So if I want to multiply a variable on the right by a scalar, I have to pass through an automobile. Very strange. But it's a great language. But it's a great language to know if you want to deal with division rates. Let me take the complex numbers, the complex conjugation. We're all happy so far. Here's some isomorphisms and Merito equivalences of rings. If I take my skew polynomial ring and I kill out my x squared minus 1, as usual that factors is x minus 1, x plus 1. So this is So, this is this is there's nilpotum elements in this ring. Elements that square to zero and so on. It's the two by two matrices over the real numbers. But as we saw in Baptiste's talk the notion of Marisa equivalence, which is not when you have an isomorphism of rings, but where their module categories are the same. The module category of M to R is the same as vector spaces over R. R. This is quite a strange isomorphism. This is a really weird thing. x squared plus 1 is your standard example that you tell your undergrad students. This is an irreducible polynomial over the real line. In the complex plane, it's not irreducible. It should factor as x minus i, x plus i. Minus i x plus i. In the skew polynomial ring, it is irreducible. I thought that was, it blew my mind the first time I saw it. I thought it was great. You have something that's irreducible over R, not irreducible over C, but skew irreducible over C with respect to complex conjugation. Because you get the quaternions, that's a non-conjunctive ring. I thought that was great. So you noticed that I started with C. So you notice that I started with C, and I've got the real numbers and the quaternions using this language. Why am I doing this? Earlier, I pointed out an example of a species of type BC2 tilde. I had the real numbers, the complex numbers, and the quaternions. There's a generalization of this called the semi-linear path algebra. I'm not going to define it. To define it. That's assigned that I should. It's complicated. It's complicated. There's an example of the semilinear path algebra. What it's doing is as follows. If Q is the loop of one vertex, the semilinear path algebra is the spirit of the loop. So the semi-linear path algebra is the x-ray. So it's the semi-linear path algebra is unifying skew polynomial rings in one variable and path algebra equivalents. What's the example? Same as before. Take this weird quiver. Kind of reminds you of BC2 tilde. I've got three vertices and two edges. I've got some loops. I've got some loops. This is the equation I want to explain, if I can have a minute. I think the semi-linear path algebra, I kill out by s squared minus e1. So doing this path twice is the lazy path. Doing x, multiplying x twice is the same as 1. So there's an analogy going on here. Going on here between these two expressions. And similarly, t squared is supposed to be the same as minus e3 to here. Because of these relations that I'm killing out by, I get the 2 by 2 matrices over the reals, and I get the quaternions. And actually, this whole thing is Merito equivalent to this ring. It's a ring of matrices with entries in the appropriate. Matrices with entries in the appropriate places. That thing on the right-hand side is the tensor ring of the species I gave you, BC2 tilde. So this language of semi-linear path algebras is something quite interesting that I'm exploring. I'll just end by saying that I'm doing some work with Rock, one of the collaborators called called Dynamo Andrew. Cardano on the previous slide. We're trying to use this approach for new types of thinking diagrams, infinite types, like BN. So I've got a natural number. I've got the set of vertices in correspondence with the natural numbers. But it's a weighted graph of type B. Thank you for listening and for organizing and for assisting. I have a question. When you mentioned that these representations of R in the sense of inclusive form an abelian category or a an abelian category or a category uh i i think it should be the category of representations of that species should be abelian quite sure yeah it would it if you look at if you're asking for things that are pointwise finite dimensional which is which is usually the case of course it won't be grothendie because you won't have products so you have to be careful what kind of abelian category you want but i think To be careful what kind of a reading category you want, but I think it will be a really Rodana's better answer. I think so. I've got a lot of stuff. Did you do anything with the child rock, taking a real line, so continuous composite, and then like have one piece representations over C and then the other piece representations over R. It's my favourite. I promise you that there was no conferring with Gordana before the talk. It's my favourite question ever. We're still working on it. We're still working on it. Please. Please. There's something fun that we want to do. You can index, what can you do? You can take two real numbers, you can take their difference, and you can consider that as a rotation. And there's an automorphism of the. And there's an automorphism of the quaternions given by something called spatial rotation. You conjugate by a quaternion number. We want to somehow have persistence modules that index spatial rotation. The intervals will index spatial rotation. Yeah, it's ongoing, so I shouldn't say too much, but Daisy Rock was happy with me mentioning something at the end and not anything confident. The end and not anything concrete. It's all I'm caring about. Please join. That would be great. Oh, yeah, sorry, sorry, sorry. Yeah, so in Emerson's talk, he talked about live paths, which were representations of the which is still on the board. And so, but we want to take vector spaces over finite field and save characteristics to F2, sorry. So, what is the tensor ring and what is the ring? The tensor ring, and what are the associated so if you take if you take F2 everywhere, then what you're really going to be dealing with is just the path algebra over F2 of a quiver whose underlying graph is a n tilde. One of the points of this, this is now maybe not answering your question, but maybe it does. One of the theorems I mentioned. One of the theorems I mentioned, this one of Charles Takirichenko, says that if I take any F2 algebra that's basic and finite dimensional, it will be the tensor ring of a species. And that's the quotient of a tensor ring of a species. And the valued graph that you get of that species might be this. It might be this. But if you take the species, If you take the species where you take F2 for each of your skew fields, and all of the bimodules that you want are just F2 is an F2F2 bimodule, you'll recover the path algebra over F2. That's saying that we kind of get the same representation theory for F2? Yes. The reason I boxed these is actually that if you take a path, I mean if you take a Path, I mean, if you take any field and you take the tensor ring of a species, you recover these things, but you don't get these values. You don't suddenly get these new values. If you're looking for A n tilde, you won't really get much new. That's the summary of my answer to your question. If you're looking for C n tilde, you'll definitely need something new. Can't just look at this as a path algebra. Can't just look at this as a path algebra. Centering of this might be a path algebra. But they can take extension of another final extension. I mean the skew fields are where I the skew polynomials are where finite fields are. Oh, you said you think you might want to take a uh uh F two, like a F2, like a like F4 at a vertex, or do you want to just take F2 at a vertex? If you want to take just F2 at a vertex, this language only recovers the usual language. There won't be anything useful in my talk, probably. Well, but it says that the representation theory is still the same, that it doesn't study any finite. This is tame, but not finite. And the representation theory doesn't change. Representation theory doesn't change. Presentation for the doesn't change. That was flab wrinkle. Really, Gabriel, but flabb wrinkle. But it's just a remark that you said often the right sequences between symbols when you consider the real line. But this reflects the fact that there are also no arrows in the quiver. I mean, if I would like to start the gap will quiver off the real line, but no real number is in the immediate census. Yeah, I know errors. The quiver of all the alignment is no point. And in the same way, yeah, I know error mode. The way it's such a good comment. If I take this simple, I can take a projective cover, which is this. But this kernel is not projective over the real line. You can do this projective cover over the real line. But the kernel is not, it's an open thing. You you don't include that point. But then you can't just. But then you can't just for a finite quiver, that's just starting at the next vertex. And there is no next vertex over the real line. Still freaky, though. Still like it. I thought it was worth finding out. Weird stuff. Yeah. And very similar to the Very similar to the process of elimination, in delta elimination of different natures.