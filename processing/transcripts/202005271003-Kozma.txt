Minute at the same time, so I apologize to everyone that I didn't reply to. It's not because I don't love you, I love you all. Okay, but let's get to the to the to the talk. So today's talk is we are moving out of the chat. If there are questions, please put in the public chat. Okay, so today we'll be moving out of the 80s and getting to this decade, even though this particular argument is also from the 80s. And let's let's but it has some ramification, important ramifications from this decade. But let's start by describing what this argument is about. And I'm going to start with a very, very basic idea, which is using exploration. Which is using exploration for percolation. An extremely useful idea, which, even if you don't get anything from this mini course, except that you can do exploration. I did my job. I can go home happy. Okay, so what is what I'm going to demonstrate the idea of exploration with a very, very simple lemma. Okay, so let's see what this lemma is. I remind you that C of zero is the cluster of zero, the connected component. Of zero, the connected component of zero, all the points which are connected to zero by some set edges, by open edges. So it has some open edges, some number of them, the number that connect them, and there is also closed edges, edges which have been deleted, which are basically the boundary of the cluster. Okay, because the cluster extends. Okay, because the cluster extends to everywhere where you have open edges. And okay, lambda is some number, don't worry about that. And here is the statement of the lemma. This part is not so important. I want you to concentrate on this part. On this piece of the formula that I've highlighted, it says that one minus p. 1 minus p times the number of open edges minus p times the closed edges, number of closed edges, is very small. Basically, it's square root of the size of the cluster. The formulation of the lemma is correct, but what I'm saying is not completely precise. So the probability for Gambler that it's bigger than 10 times square root is already e to minus 100, because it's extremely small. It's extremely small. And so on. It's true for any lambda. So for lambda, we'll often use it for lambda logarithmic or square root log so that the probability here becomes negligible. Okay, so if you find this confusing, think about it in p equal to half. In p equal to half, it means that you have more or less equal number of open and closed edges. Edges okay, and in P which is not half, you have to weight them a little bit, okay? So, let's see how to how to prove the lemma. The lemma is proved by a process called exploration. So, let's understand what this means. Okay, we are going to define a sequence of sets of edges. Okay, the first set of edge, this first set has zero edges, then the next one. Set has zero edges, then the next one has one edge, two edges, and so on until n, not more. And here's how we do it. So assume at step I, there exists some E, some edge E, which is not in Si, but there is an open path in Si from zero to one of the vertices of E. So maybe I should have prepared a picture, but I didn't, so you have to imagine. Picture, but I didn't, so you have to imagine it. There is SI is some set of edges, some of which are open, some of which are closed. We are only interested in paths in SI composed of open edges in SI if we can find some and I assume that we can find some edge which is not in SI, but which has a path leading to one of its edges. Leading to one of its heads. And if such ethics, of course, there could be many. If there are many, we choose one of them in some arbitrary way. If you don't like the word arbitrarily, then you could, for example, choose the first one in lexicographic ordering or in any other way that you love. And define Si plus one equal to just add E to this S, to S. And if not, just fix it. Okay, but what happens? So what is the Happens, so what is the process? This process doing it's really exposing the cluster one edge at a time. Okay, you start with no edges, but you are at zero. So, zero has 2D edges surrounding it. So, you, for example, take the first edge. If it's open and you add it to SI. Open or closed, you don't care. You add it to SI. Then you take, for example, the second edge. Open or closed, you don't care. You add it to SI. Open or close, you don't care. You add it to SI. After you finished all the edges surrounding zero, for example, then you see, well, okay, are any of them open? Well, if not, then that's it. That's the cluster. The cluster contains only zero, and we can go home. The process stops. But if some of them are open, then you can continue to explore edges which are connected to these new vertices, which we know, which we now know are. Which we now know are in the cluster. So we are really finding out what is the cluster of zero step by step. Okay, I hope this explanation was clear. Let's go on. Now, to this process of set, we associate the process of numbers xi, which is just the appropriate numbers that you can guess 1 minus p times. Numbers that you can guess: one minus p times the open edges, exactly like the term we have here, and the p times the set of closed edges, exactly like we have here, minus. Okay, so in the end, we will get the x at xn will be exactly this quantity. And here comes the most crucial point of the argument, basically the whole argument. Of the argument, basically, the whole argument. Xi is a martingale. I hope everyone knows what is a martingale, but let me define it just in case. A martingale is a process such that if you condition on it at time n and look what is added for, or i, and look what is added for time i plus one, the expectation of the addition is zero. This is exactly what. This is exactly what is happening here. Why? Let's compare xi to xi plus 1. xi, si plus 1 is just si union 1 edge. This edge is new. We don't know anything about it before we added it to the set. So if it's just some arbitrary edge, and we know it has p probability to be open, and y minus p probability to be open. Y minus p probability to be closed. So, what's the expectation? It's one minus p times the probability that it's open, which is p plus, sorry, minus p times the probability that it's closed, one minus p. So you get p times one minus p minus p times one minus p. So it's just zero. And this is exactly what it means to be a multi-game. Another proof. Another proof that follows immediately by Azuma hefting inequality formatting. So, okay, so let's see if some of the questions. So a couple of comments on the chat. Yes. Okay, let's see. Where is now? Ah, here is the chat. Let me see. Yes, in the boundary exactly means touching the cluster. Exactly means touching the cluster, having one vertex in the cluster O2. Okay, the yes, this is somebody asked if this is intentional, this is independent of n. Yes, it's independent of n. It's exactly like it's some kind of, it's like asking what is the probability, for example, that there's some. probability for example that the sum of n random variables is taking for example plus minus is bigger than square root n and lambda square root n this is independent of this as an estimate independent of n so there's certainly a so you should compare the left hand side to a sum of independent variables which are compared to square root n I see that I see that. No, I don't care about which order the edges are chosen. It doesn't matter at all for the argument. I see that somebody asked, or I see some people have already answered some questions. Okay. Okay. So let's do it just a little more. Let's do just a little poll like we did last time. Raise your hands, people who want to see the statement of a Zuma inequality. So, just a comment to address Leo's question. So, Leo was asking whether you can look at the whole cluster and then choose the edges. And then choose the edges. Yeah, whether you can look at the whole cluster and then choose the edge. No, it's important that at every step. It's no. No, no, you cannot do that. It's important that at every step, the edge, you have no information on it. Okay, I see that there is, there are some people who want to see the statement, so let me show it. It's not very complicated. It says, suppose Xi is a martin, and suppose. Martin. And suppose it has differences smaller than mi. Mi in our case is just one. Well, okay, if you want, even maximum of p and one minus p, but certainly smaller than one. Then the probability that this martingale, okay, here I'm in the usual formulation you have to subtract x0, but x0 is 0 in our case. So the probability that it went bigger than m is x. went bigger than m is x square exponentially small in m okay so this is an extremely useful inequality so i should probably i should move the chat window from my uh from my main window i i keep forgetting that okay okay so i i hope i hope the statement is is clear let's say let it let it go so let let's say understand a little So let's understand a little bit more about this, talk a little bit more about this argument before we apply it. So it's really flexible. You can, here what I did was to start from zero, but you can start from an arbitrary set of vertices. You can put all kinds of complicated stopping conditions. Here I stopped once I had n edges. I didn't go any further in order to have to have. Have to have a statement, but I can stop by some geometric condition or any condition which is a stopping condition can be used. So there are really lots and lots of variation. I will just show one, which is a bit closer to how we will use it in the next part of the statement. So suppose, okay, I remind you this notation, this is a notation for a cube. For example, from minus n to n in Z D. I remind the people who have. The people who had too much fun in the last two days that all this course is about Z D and percolation in Z D, and that this is a cube in Z D. So let S be the set of vertices connected to the boundary. And again, we define E, the set of open and B the set of closed. And we again define X in this way. X in this way, then again this n to the d half is the volume of the box, n to the d is the volume of the box, and half is the square root. Remember, we have a square root here, right? So this is actually square root of the volume of the box. There should be a constant here, but it's not, sorry forgetting. Okay, so this and this is exactly the same way. You do expression, but you do it in sus. You do expression, but you do it starting from the boundary and then examining the edges inside the box, one after the other, in an arbitrary order, until I discover all vertices which are connected to the boundary by open paths. So, let me not, you know, discuss this any further. Okay, questions before I make this whole transparency. A transparency disappear. If I have a reference, I need to think about it, but certainly this whole talk is all contained in the paper of SERF from 2015. So that would be a good reference. But probably exploration should be. Should have some more canonical reference, I think, if I not. Okay, so this is enough for the generalities, and now we want to go to more specific application of this idea. And what we will study is these events. So, I have to introduce here a new notation, which is, by the way, not a standard notation. Which is, by the way, not a standard notation, is especially for this talk. I had to write a special latter code for these double arrows. It wasn't many people, there are many people raising their hands. So, I don't know if these people have questions. Raising the people are there are people who want to ask questions. Okay, let's let's take perhaps. So okay, I see that let's let's uh maybe I will take a question a bit later. Okay, I I want to uh to get to at least the main point before starting taking starting taking questions more seriously. Okay, so we are really just uh so if something is so if something is unclear getting to the main point of this error For the moment, asking the chat please still answer. I will take questions in maybe 10 minutes or so. Omar, do you want to say something? Yes. Okay. No, no, go on. Okay, so let's understand what is this notation. Okay, so we have some subset E in. Some subset E in Z D, usually it will be a box, and we have two subsets of E. And I am making this beautiful notation that A is doubly connected to B. What do I mean? There are two disjoint clusters in E which intersect both A and B. Now, be very careful that this is not the same as having two. As having two disjoint paths, we discussed that this two days ago, this event, and there was this BK inequality and so on. This is something slightly different. It's a stronger requirement. Okay? We are asking that there are two, A, that there are two paths, two open paths from A to B, but that they do not connect not only are the paths disjoint, but they cannot be connected by some bridge that goes between them. By some bridge that goes between them, they are really two disjoint clusters. I don't think I prepared a picture, which maybe is a pity, but I think I can draw here. No? No, I don't have it. It somehow disappeared. It should have been here at some point, but it disappeared. Okay. So be careful about this distinction. I'm going to estimate. I'm going to estimate this probability. I cannot estimate it without the requirement that the clusters are disjoint. This is very important. Keep it in mind. Okay, so our presentation is clear. And very often we will have this again, usually for a box. And in this case, I will not write in which. In which space this is. So I will write it this way: if A has two connections to the boundary of E, and the connections are in E, of course, and the cluster are disjoint in E also. So I hope this notation is clear. And let's get to the statement of the theorem. Okay, so again I remind you, this is an end by N box. You, this is an n by n box, n by n by n, okay, d times box. And let's examine the event that just x, y, there are just two neighbors, two vertices which are a neighbor, which are neighbors. And let me, since I've already made the definition disappear, let me repeat it. What does it mean, this double arrow? It means that they are connected to a To the boundary of the box by two clusters in the box which are disjoint in the box. In particular, if they are disjoint, then if x belongs to one of them and y belongs to the other one, then x cannot connect to y. So this notation and the okay, sorry, and this sentence are equivalent. Sorry, you don't want, I want just this sentence. Want just this sentence, not the top that insists on being selected as well. Okay, so x is connected, both x and y are connected to the boundary, but they are not connected among themselves. So it's exactly the same thing. Then the statement of the theorem of Isa Mannkestern is the expectation of this set is smaller than n to d minus half square root of d. Okay, so. Look. Okay, so let me take a few questions now, and people can stare a bit at the statement of the theory and make sure that they understand exactly what is it. Okay. Okay, so, so, so, so, so. Yes, so I see that there was the following question. Can the clusters meet each other outside Lambda? Yes, I'm not forbidding that. I'm not forbidding that. This is important here that they are not connected in lambda n. It's possible that x is connected to the boundary, y is connected to the boundary, and afterwards, outside the box, the clusters continue and continue and connect. This is not a problem for our event. So I'm only requiring that X does not connect to Y inside the box. Acts outside the box, they're allowed to continue and connect. Okay, let me see if there are any. See if there are any other questions, which are okay. I don't see any new questions. Were there any questions from before in the chat that I should answer? Did one of the moderators notice a question which you think is interesting for no other questions in the chat? Okay. Okay, so let's start. Let's let's start the proof of the theorem. I think after that, we'll have our break. Okay, the proof I'm giving here is due to Gandalfi, Grimett and Russo. They simplify the argument of Eisenman, Kestan, and Newman incredibly. This paper is just four pages. By the way, that's another very, very nice reference. People asked for reference. So, this paper is probably from a So, this paper is probably from 87 or something like that, but anyway, you will not have a problem to find it. And it explains this very nicely, four-pages paper. Okay, so let's see what how let's see how the proof goes. So, we define xs, you won't be surprised by this definition at this point, is one minus for some arbitrary set of vertices to be one minus c times the number of open edges between vertices, minus p times the number of closed edges. Now, be careful, okay. Now, be careful. Okay, we need one vertex and x and both vertices in the box. So there is some issue here near the boundary. I've written it properly, but it's not actually important. So I hope the definition of x is clear. It's certainly written quite clearly. Now let C1, C2, and so on be all the clusters in lambda n. So, okay, clusters again is a set of vertices which are connected and all connected in lambda n. So a cluster. In Lambda n. So a cluster in Lambda n means that the connections are in Lambda n. Things which are connected outside are not considered the same cluster in Lambda n that touch the boundary. So clusters which are just some cluster in the middle, I don't care about it. I care just about clusters which touch the boundary of lambda n. Then, okay, this is the proof. So this form This formula is the essence of the proof. So let's make sure we understand it perfectly. Let's see what we have here. We take all these clusters, we calculate the x's and sum. We take the union and calculate x of this union as a set. It's a set. All of these are sets of edges. The union is a set of edges for a set of vertices. Did I say edges? Okay. Okay. These are all sets of vertices. The union is a set of vertices. And you can apply x to it. And this is an equality. This is not so you can understand that argument is probably simple, but confusing. So let's see why this is correct. Let's see what an open edge contributes to this difference. If it's open, then it's necessary. If it's open, then it's necessarily in one cluster. An open edge cannot belong to two clusters. It's all and it doesn't belong to boundaries, certainly. So it contributes one here at the cluster at which, not one, one minus p, sorry, contributes one minus p here at the cluster at which it's contained, and contributes one minus p here because it's contained in the union. Because it's contained in the union, so its contributions cancel out completely. Now, let's see what you get from a closed edge, which belongs to the boundary of exactly one cluster. So, it's closed, and one vertex of it belongs to a cluster that touches the boundary, and the other edge can belong. And the other edge can belong to the same vertex, to the same cluster, or can belong to a cluster which doesn't touch the boundary. I don't care. In both cases, contributes one here. Well, okay, P here and P here. And again, the contribution cancel. So what doesn't cancel? What is left? What is left is exactly this event. Because if X, if the edge X, Y, is closed. Y is closed and x is connected to the boundary, and y is connected to the boundary, and these are different clusters, then it appears once here and twice here. So, you understand that I made a mistake. There should be a minus here. Okay, so I apologize for the missing minus, but uh, no, actually, there's no missing minus because this is it, because actually, I didn't make a mistake, it's a minus contributes. It's a minus constributes minus p here and two p here. So it's actually correct as it. Questions about this equality? Yes, everything is clear. So let's continue. Now we apply the exploration argument. The exploration argument tells us that x of Of each one is smaller than square root log n. I warn you that we will have lots of logs. This is because I don't want to, you know, these logs sometimes can be avoided, but once you allow only a square root log n with some constant, then this means that the probability you can make it like n to minus 100, then you don't care about these events. So that's always the So that's always the probabilistic cheap way out is to put a square root log and have the probability negligible. So I'm using this exploration argument. Maybe let's look at it just for a second again. With lambda equal to square root log. And then here you get e to minus some constant log n. So the probability is polynomial in n okay, I'm back. Okay, I'm back here. So allowing the square root logs, and I know that with high probability, meaning say with probability minus 100, both are bounded by the square roots of their size. Here I did a quick job and just bounded it by the square root of the volume of the whole box. Okay, so. Okay, so this transparency is the same as the previous one. I just compressed some formulas to have more space. You don't have to read it again if you followed the last transparency carefully. Now let's use Chrisishwarts. Right, we need to estimate this sum of the x's. And each x is bounded by square root ci. Okay, sum of square root log. So we need to understand the sum of the The sum of the squares of the clusters touching the boundary. So I apply Cauchy Schwartz, I write it as sum of this times one, and then I get sum of the squares, okay, square root, and some of the ones, square root. Now, the first term, this, I can simply bound it by the volume of the whole box, which is n to the b. So these are just. D. So this is just the first time I just bound by the square by square root and D. The second term I bound, recall that we are interested in clusters that touch the boundary. I don't have any luck with selection today, touch the boundary. Okay, so how many clusters can touch the boundary? Certainly, each cluster Cluster can relate to at most one boundary point. So the number of clusters that touch the boundary cannot be bigger than the size of the boundary. So you can bound it quite trivially by n to d minus one. So what did we get eventually? And this is the end of the proof. Okay? We know that what We know that what we are interested in, this guy V, is equal to this contribution with high probability this is smaller than even much has a much better estimate, n to d half, not n to d minus half. And this sum has this estimate, and those are the square root logs n. So you get exactly this. And the last sentence here just says that, okay, everything happened with high probability. Thing happened with high probability. Let's say that this with high probability is with probability 1 minus n to minus 100, and then whatever contribution you get with probability n to minus 100, you don't care about it. It will be negligible compared to the other quantities. So that's the whole proof. And I certainly think you deserve a break. So let's take a five minutes break, and after that, A five-minute break, and after that, I will take questions, and then we'll have some other entertaining stuff to fill the rest of the hour. Okay, so five minutes a week. Okay, thank you. So if there are any questions, please post them on the chat and we will resolve them as soon as possible. As soon as Gary can't the first question, I believe from yes, so uh Yes, so there is a question here whether the bound on the number of clusters can be improved. Right now, only very slightly. I hope to I will return to this question in the end of the talk. I think this today's talk is going exactly as planned. So I think I will. So if it continues this way, I will answer this question. Continues this work, I will answer this question in more detail. So, the question, but again, let me repeat: the question: the question was: can we improve this bound? And I will answer, I will refer to this question at the end of it. So what was the main result in the Gandalfi Grimett Russo paper? Is this the main uh is this part the main objective? I I let let me check the paper, but uh Check the paper, but that's that's what I remember why can't I find that okay just a second You don't see my my window now, do you? Just a slide. Just a slide? Just a slide. Good. So, Sarah has posted a link to the Gandhalfi paper on the chat, by the way. Okay, good. Don't seem to have this paper downloaded. That's weird. So, maybe there are a couple more questions. couple more questions. So Inon was asking whether the bound of n to the minus half square root log yes so Inon was asking whether the n to the minus half square root log n can be shown for a single edge in the back as opposed to the sum of the log. Yes, I will get to that in a second. And Dior is asking that shouldn't the DOV should the DOV. Should the D over is certainly a smaller error, right? Look, our D's are at least, okay, at least two, let's say. It's an integer and it's at least two, because one-dimensional percolation is not so exciting. So, in this case, this term n to d half is certainly smaller than n to d minus half, and it's it's a To d minus half, and it's a negligible quantity. Oh, oh, yeah. Okay, yes, this is d minus half. There is no, there are no parentheses here. It's just, you know, it's not d minus one divided by two, just d minus half. Maybe I should have used a more clear. Clearer, but then I wouldn't have place for the whole proof. Okay, I think the five minutes break is over, so people who haven't been back with the coffee can only blame themselves, themselves. Let's Yes, there was yes, but yes, but this is also true about Eisenman's Newman. Eisenhum proved that the infinite cluster and unique, maybe, I think maybe Gandalfi Grimet and Russo simply gave a shorter proof. Okay, okay, so, but let's get to a quarrel that was already asked in the chat. You can get from this estimate on the number of edges an estimate for a single edge. Why? Because if this probability you have to play here a bit with n and 2n. There is some, by the way, could you hear me now? I got a message. Okay, you have to play a bit with n and 2n. n here should be 2n. Should be 2n compared if you want to use the to conclude the corollary from the theorem. So, how do you get the corollary from the theorem? You use the theorem if 2n, but then oh sorry, if n half, but then if some edge is connected to distance to n, then in particular it will satisfy this. So, the probability of that, so it just It just follows from that from replacing n and 2n and dividing. It's a very straightforward thing to do. And a few more corollaries of the theorem before we continue. First of all, that's also a reasonably flexible argument, and people have been doing variations on it quite successfully. Here is one that I particularly like for no object. Particularly like for no obvious reason, if you take a box and take L to be okay, and you do the exploration from the left, you do the exploration from the right, and you take the union and then do this substructure, then you learn something about edges which are connected to the left and to the right. Let me not explain exactly what there are some this version has more subtleties than Version has more subtleties than the version that I showed you. And Tom, I guess Tom said he was teaching, so it won't come today, but he has a version where he does the exploration, not from the boundary of some set, but from random points in his favorite setup where you have a non-amenable group. So there are lots of variations on this argument that you can do by exploring forms. That you can do by exploring from various places. Okay. Okay, so as I promised, I want to get today to something from this decade. So I have to take you back to the previous hour. This theorem was proved in the previous hour. I hope people remember. I hope people remember. But let me state it again. So, suppose S is some finite set in Z D, then the sum over all X's in the boundary of the probability that zero is connected to X inside of set S is bigger than one. And this is already true at critical, only at criticality used for this argument that we are at P C. This argument that we are at PC. The argument that I showed you before about doubling connection works in NEP, except at some point I divided by P and didn't make a fastening. So it works on NEP, say, not too close to zero or something. So suddenly it was not restricted to PC, but this argument was restricted to PC. And this we saw in the previous hour, and it has a few applications. It has a few applications. I noted here two: one of myself, Ivas Saf Nahnias, from 2011. I hope you can read the statement. I'm not going to read it out loud. And the second is the lemma that is the second ingredient in this Eisenman-Kester-Neumann self paper, in this paper of self, which uses the Eisenman-Kester-Newman argument. And it says that if you take any two points, That if you take any two points in a box of size n and you then the probability at criticality, this is not a for piece model than pc, then the probability that they are connected in a box of size 2n, you have to increase the box a little bit, it's not the end of the world, is only bigger than some polynomial. And there is a remark here that all constants depend on the dimension, which also holds for what we had before. Holds for what we had before. Okay, so again, this is certainly not true for P smaller than P C. In this case, the probability could decay exponentially. Okay, but it is true at criticality for any dimension. And it's a corollary from this theorem in a way that I'm going to show you now. Okay, so what I want to show you now is the proof of this lambda. Of this lamp. Okay, here it's written again. Let's assume first that x and y are on the same line. So I'm assuming that all the coordinates are except one are identical. And also there is some assumption that the difference is even. That's not so important, but it will make life a little bit easier. Okay, so let's just assume that. Let's see what we do in this case. Now, we know. Now, we know that the sum, okay, we know from the previous theorem that the sum of these probabilities is bigger than one. In particular, there is at least one which is bigger than the number of elements. Number of elements is just the size of the boundary. Okay, so there must be at least one z such that this probability is bigger than this 2d here is a mistake, than the size of the boundary. Than the size of the boundary, some leftover from something old. Okay, so and the size of the boundary is basically K. Okay, yeah, it's K, not N. I'm using the previous theorem in K, where K is this guy, the guy that is the difference between X and Y. So I'm doing this, the difference between X and Y is 2K, and I'm putting a box of size exactly half or not. Exactly, or not size, but okay, of size exactly 2k or but lambda k is from minus k to k. So size is actually k. So the size of actually 2k, yes. So the size of the boundary is k to d minus 1. Sometimes some contents that depends on the dimension. We don't care about that. Okay, now we use the symmetries of the lattice. Okay, the lattice has our lattice has Lattice has you can rotate and you can reflect. And what I'm most interested in is reflection. So I'm going to reflect. So first of all, I'm going to use rotation symmetry to ask that to ask that this D would be in a given phase of the cube. In this case, the phase. Of the cube. In this case, the phase which has, you know, who's that the first coordinate is k, right? Every face of the cube is to choose a phase, you choose one of the coordinates, and then you choose if it's k or minus k. So I'm choosing the face where this is k and positive. Okay, so this is just a definition of so we are allowed to make this requirement because of rotation symmetry now. Now let's reflect through the first coordinate. Okay? So if z is z1 equals up to zd, then z bar would be minus z1. And again, by symmetry of the lattice to reflections, we also have that the probability of zero to connect to z bar is also bigger than c k. It's the same. I'm just just written in a more compact way: k1sd or d. One as d or d over d minus one is the same. Okay, I hope this part is clear. This was just use of reflection and notations. Now translate this thing. We translate the first guy to x and the second guy to y. So you get the probability that instead of 0 connected to z, you get x connected to x plus z. And instead of the connection being in lambda k, it's in x plus lambda k. I remind you that this is an Lambda k. I remind you that this is a notation for translation. X plus lambda k means translate the whole box by x. So this is exactly the same as this. And the other guy, the zero connected to z bar, we translate to y. So instead of zero, you get y, instead of z bar, you get y plus z bar, instead of lambda k, you get y plus lambda k. And both these numbers are bigger than some constant over. Some constant over k d minus 1. But this is the same point. Okay? Notice very carefully. x minus, the difference between x minus y is just 2k 0000. z1 is k, z bar is minus k, and the other coordinates are the same. So x plus z is the same as y plus z bar. Okay? Just by the way they constructed them. Way we constructed them. Okay, again, I'm okay. So, I hope you understood. I kept from the previous slide only this conclusion. And I already replaced y plus z bar by kx plus z because we just said that they are the same point. But everything else is exactly as it was in the previous transparency, including the boxes. The boxes. Okay, now both these boxes are contained in our box lambda 2n. Remember that eventually we are working in this bigger box. This is why we need the 2n. Without the 2n, this is not true. Be careful here. k can be as large as n and x and y can be anywhere in a box of lambda n. So in order to have this box contained in some other box, you must extend. Other box, you must extend that other box. This is exactly where we have 2n. Okay, and the same thing holds for y plus lambda k. So if we replace x plus lambda k plus lambda 2n, of course, the probability is only increased because we added the we increased space, so it's easier to connect if you have more space, right? Okay, and now we are going to use the FKG inequality. Inequality. So, since last time people were not familiar with BK, I will skip the poll and go directly to explain what is the F-K inequality. The F-K inequality, maybe I will put it on, it says that if you have two increasing events, then they are positively correlated. The probability that both occur is bigger than the product of the probabilities. Product of the probabilities. Okay, so let's just go over the definition very quickly. So a function is called increasing. If it increases, so a function, I mean here something that a function on configuration, so a property of the cluster. And any two positive okay, just a minute. Uh okay, just a minute. So, this is uh, so this is positively correlated. So, a replying to Russ asked if I really need FKG here. I don't really need FKG here, but I will need it in the next step. So, I already put it up. But you're right that at this point, I didn't really need FKG yet. Okay, but so just as a practice for what is FKG, these two events, the probability that X is connected to Y. Is certainly bigger than the. Oh, this would still be x plus z. So, okay, but anyway, it's the same, so you don't, you're not, you shouldn't be angry with me. So, because if both occur, then x and y are connected. So, this implies this. So, it's a smaller event, so it's a smaller probability. And then, by using FKG, we know that both of these events are increasing. If you add more edges, then certain and it was connected before, and you open more. It was connected before, and you open more edges, and it's still connected. So, this is an increasing event, and the same is certainly true for y. So, this is bigger than a constant than the product of these two guys. So, some other constants, of course, this c is, of course, not the same as this c, it's the square of it, times k to d 2d minus 2. And this proves the lemma in this case that x minus y are on a line and we. Minus y are on a line and with an even distance. So let's let me not take questions and just finish the lemma before taking questions. So we prove this in this case. And let's taking slightly smaller c, we can also remove the requirement that distance is even. This is easy. You just take a neighbor of y that if x A neighbor of y, that if x minus y is odd, then you take a neighbor of it which is even, and then open one edge, and you can use fkg again. What happens if they are not on a line? If they are not on a line, then I'm going to construct a sequence of points going from x to y by exchanging each time one coordinate. So, x0 is the same as x, and x1, I replace the first coordinate. X1, I replace the first coordinate of X, by the first coordinate of Y. Then in X2, I replace also the second. And in X3, I replace also the third. So I'm replacing one coordinate after the other until I get eventually to Y. Okay? So this process of replacing coordinate by coordinate, each xi, xi plus one differs by exactly one coordinate. So we can use the case. So, we can use the case that we have already established. The case we have already established says that the probability that they are connected in lambda 2n is bigger than n to 22 minus 2d. Okay, and I use here that they are both in lambda n, which is, but this is easy because being in lambda n means that all coordinates are between minus n and n. And so each hybridization of x and y also has this property that all coordinates are between minus n and n. This property that all coordinates are between minus n and n, so all probabilization, all these guys in the middle are also in the box lambda n. So we can use after what happened here after rotation that the probability the case that we have already established. Now we use FKG again, and here we really need FKG, we can't avoid it. The probability that X connects to Y is certainly bigger than the probability that they are all connected, because that's certainly harder. Because that's certainly harder. And now, by using FKG, we get that all these events are increasing. So, this is bigger than the probability, the product of the probabilities, and you get a constant, again, of course, not the same constant as before, but some power of it, divided by 2d square minus 2. Okay, and that's the end of the proof of this lemma. Okay, so Okay, so I think I only have like a minute and a half, something like that, Tomo. So even take a few minutes. Maybe I will make just a few more comments and then take questions in general about the whole talk. So, first comment is that this was improved very recently, just this year. Very recently, just this year, to n to minus d square. There is certainly a lot of interest to improve this value, but minus d square still doesn't have any spectacular corollaries, but improving it enough will be important. So, certainly, this is interesting. An interesting result, the proof uses the bower fixed point. So, that's quite That's quite so that I quite like this paper. Let's go back to where we were. Now, from this theorem, which we already proved, that the probability to have two connections between two points is something like square root n. Is something like square root n and the lemma that I just explained? We can get the theorem of self. I will not certainly not do this last part of the proof because I have 30 seconds or so, but let's just read the statement. So the statement is as follows. Now we are must be at PC. This is no longer true in okay, this is, but not Is but not, but at least the way I had in mind to prove it, it's only two at PC. Now, I okay, maybe I will compare. Let's compare to the corollary before. The corollary before was that the probability that two neighboring points are connected to distance n is smaller than square root n. Now I'm making a much bigger separation. I'm allowing much bigger separation. I'm saying, let's take a box of Saying, let's take a box of size n to power, say, one over 10. It's small, but not, but not two, but not just two points. It's not microscopic, it's kind of, you can call it mesoscopic. It's some kind of intermediate scale box. And to some small power, certainly this constant is smaller than one, it doesn't make sense. Then the probability that it is connected to the boundary of the box by two disjoint clusters is small. Is small. So, and this theorem is proved. The corollary did not need criticality, but this theorem is proved using the lemma that I just proved to you, which does use criticality. Therefore, the theorem is already at least, okay, actually, it's true in NEP, but at least in the most naive way, and certainly in the way Serf proves it. Way self-proves it, it's only to impeace it. Actually, the generalization to arbitrary piece is in our paper, my paper with Hugo and Van San that we put on the archive this year. Okay, so I certainly don't have time for this proof, so let's skip it. But in the end, after the proof, the proof combines these two elements. So, this is the same theorem, except I made the constants explicit. The proof combines, but I will just say in one sentence that this proof uses the lemma to get from the probability that a box is connected to the boundary by two disjoint clusters to the event that two points are connected by two disjoint clusters by an argument that's called the path. By an argument that's called the patching argument, or sometimes it's called an analysis argument. It's not important. Some kind of one of the more or less standard arguments, but you'll have to read it in the paper. I will not do it today. And as I said, the theorem actually holds for all P, but this is not in the paper of CERF, this is uh but it but essentially the proof is the same. But essentially, the proof is the same. Now, I want to answer a question that was asked before I finish. Before I take more questions, let me answer a question that was asked in the chat. And this was the question whether it's possible to improve the bound on the number of clusters. And this was the idea of self. He had a complicated scheme in order to improve the S. In order to improve the estimates. And let's understand the scheme just in a very, very general way. So let's. This is the arrow that I showed you. If you have an estimate on the number of clusters, then you have an estimate on this quantity. The probability the two points are connected to the boundary. And if you have a better estimate on the number of clusters, you get a better estimate for this because. Estimated for this because the sum of the squares of the cluster, the sum on all the clusters, of the squares of the sizes appeared at the crucial point. So a better estimate for the number of clusters would give you a better estimate for this. A better estimate for the probability that two points are connected would give you a better estimate for the probability of a little box because the probability of a little box is doubly connected is small. As I said, it just follows. Is as I said, it just follows from that and a patching argument. Okay, I didn't explain that, but at least you can imagine more or less what is the argument. Once you have a better estimate for that, you can actually get a better estimate for the number of clusters, because if you don't have many boxes that connect to distance, it means that the clusters must be separated by a polynomial factor. And then you can repeat and get better and better estimates in a okay, it actually converges to some. To some estimate, which is better than what we had better than this, and also, and most importantly, this would be better than a half. Okay, I hope you got something from this picture. I understand it's not, but if you want to understand this part of the argument, certainly you can only understand by reading the paper of self. But unfortunately, the end result was a little disease. The end result was a little disappointing. It didn't converge very effectively. And what he got, for example, for this quantity, the probably just the two points are connected by these joint clusters to the boundary, is, for example, in dimension 3, 12 over 23 instead of half. So that's a little bit disappointing, but maybe it will be important. But maybe it will be important. Okay, so I think that's definitely what I wanted to say for today. So let's terminate the talk. I think I'm even a few minutes, yeah, I'm certainly a few minutes over time, and I will now only take questions. Okay, thank you. So we will unmute and everyone to thank Gaddi. And I will unmute just Gaddina. Okay, so I will at this point stop the recording. Stop the recording and we can have more questions. And afterwards, people can join breakout rooms for informal discussions.