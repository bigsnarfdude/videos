Well the plan for today is roughly as follows. Um we'll first discuss how you can start from a quasi-sometry of an HAG and the thing that we want to do is to find some dark magic to produce some P depending on F, which is an automorphism of Of some graph. And roughly, this graph will encode some intersection patterns of maximal dimension, let's say, top dimensional quasi-flat. Quasi-flats, which in a way kind of makes sense. You have a self-quasisometry of your group, whatever it is, and you want to say that this quasisometry will send flats to flats and will preserve some intersection properties of these flats. And you want to encode it into infograph. And the light motif of this talk is that whenever you have a deep understanding, You have a deep understanding of what this graph is, and most importantly, what are the automorphisms of this graph? What you can do is then study what automorphism you get to tell us something about the original quasi-exography. And it's very tiny here. And so, the way we want to do it is through an example is to show that when you take That when you take the Mapping class group of a finite type surface, and let's say you also take some random positions, then this group here is quasi-isometrically rigid. And this is the only part of my talk in which I'll cite Spencer's talk. I'm sorry for not keeping in the Not keeping in the line of the other part. So at least we all know what this means. And if time permits, I also show how from quasi-metric rigidity, one can get other kind of rigidity results, which are more algebraic. In the lines of like some estimates on who the outer automorphism group of G might be. So let us delve into the technical part and a little caveat. Whenever I write Whenever I write this smile face upside down, it means that I don't want questions on this part. So, yeah. You just invited questions. Well, I'm gonna find late, sorry. But like what so like what I don't really understand what you mean by today. It's that's sort of clear. Let's say you know that your group is quite rigid and you also know it's a cylindrically hyperbolic, for example. Then there are some conditions ensuring that the automorphism group, let's say, is finite or trivial. And the idea would be that whenever you have an automorphism of your group, you can see it as an isometry, and in particular, quasi isometry. Then you can run this whole machinery and get some, let's say, some automorphism of the verb that tells you that the original elements that you pick here was actually an inner automorphism. And if we have time, we're gonna delve into it. So let's go to the technical part. So for the rest of the talk, For the rest of the talk, let G be an HG and say this very strange letter, which I never know how to pronounce, is the HHS structure. So it's going to be the collection of all domains and projections to the hyperbolic spaces. We say that a complete support set, which will aggregate by CSS, is some collection of domains inside of our structure which are pairwise orthography. Pairwise orthogonal, and then we ask that it is every element in the complete support set has unbounded coordinate space and And moreover, we also require that this collection that we're taking is maximum with respect to inclusion among all those which have this problem. So what I'm saying is that I'll just take a collection of orthogonal domains, I make it the biggest possible, and I just care of those which have unbounded. And I just care of those which have unbounded coordinate spaces. And possibly also like with non-empty Gorma boundary. But for the definition as it is, we just don't care. I want to say it as a plastic. You want maximal cardinality? Yes. Maximal cardinality? It's maximal over the structure, not maximal over the set. It's not maximal under inclusion, it's maximal under all things. And then you just consider those of maximal. Consider those of maximum cardinality among all of all of the collections which have this property, yes. And why do we care about this? The point is that let's say I have a complete support set which is given by u1, uk, where k is this maximal number. And let's say that And let's say that for every i, I choose, let's say V infinite rain Li inside of the curve graph of the line. Then what I get is Well, the feature that you should have in mind is the following. I have a collection of domains which are paramoids orthogonal. So let's say this is one, let's say this is two, and you have Do when you have your tree here, and there are a horizontal. And in each of these coordinate spaces, I'm choosing a line. So let's say this is L2, this is L3, and this is L1. So when I take the collection of points in the group G, Group G, whose projection lies inside of this light. What I have is that I have the product of these three lines. I should have made it a very small color, maybe. And this so these are defined x and g such that the projection to dy of x stays in Li for every eigen. And this is what I call a standard flat. It's a flat because it will be quasi-sometric to the product of these lines, which are pairwise orthogonal because they live in orthogonal domains. And notice that we chose the complete support set to have the maximal dimension possible. So what I'll see will be that this the flat that I just constructed is of the maximal dimension in our group. Maximal dimension in our group. Because I couldn't fit any other domain in this collection, which I unbuttoned coordinated space, so I couldn't find another orthogonal line to make this square bigger. You have a question? Okay, this is something I should know. Why can you find a value in by? Let's say let's say. Let's say also assume this should work. This should work. So, I have another question. Yes. Why is it important to take lines here instead of seeing like utter sex and UI maybe each product? So the you could do it the same by just choosing uh like array. Like array, just infinite on one side. And instead of having a flat, you would get an orphan. You would get like this product of rays that gives you just this, for example. Okay, what if instead of a ray we say, like instead of a line, it's saying higher directional y. What? Like, so what if instead of a line, it took like entire space y? So the point is that you, as we will see later, what you really want is to be able to talk about what happens to. Be able to talk about what happens to maximal dimensional flats. So copies of R2DN embedded into your space. So the best, let's say, the most natural candidate of flats that you want to find into your HAG are those which actually come from the orthogonal coordinate spaces. You take one line of each of them and you take the product of those. Okay, so I guess we can't say I think we can smother shapes that are URI and I need to give you things they are to ask. Yeah, oh and yes, so uh what else? Okay, this was a general definition and now up to now we just talked about complete support set as sets. Now we want to talk about the single elements of this complete support. These single elements of this complete support set and say if they have nice properties or not. So, for example, I say that an element w inside a complete support set is good if there exist uh two complete support set, you prime, you second prime, which are a complete support set. are the support set such that the intersection of u prime and u second prime is just the domain w that we chose. In other words, what we're saying is that I can select this w, which we call correspond to some lines that I'm choosing in this product by intersecting two collections. Collections. And what you would like to see is that if you have your collection, let's say, if you have the standard flat for the collection u prime, and you have the standard flat for, let's see, let's make it very, ah, this is the square. And you have the standard flat for the collection in second, you can make them overlap just along the line which corresponds to the domain that you chose. And this is very general, and we want to show, we want first to stop and say, okay, what is really happening in a very concrete case. So can u pi multi-double prime be u? They can, but one of them can. They can, but of c like, one of them can, the other must be clearly the case. But yes. So let's see what happens if our group is the market class group of the surface. Just to have in mind what's really happening. From the definition, why can't they be the same? Well, no, I mean. Because they're intersecting a bigger structure. And this is why, let's say, in insight, this is what intersection pattern will mean. Like, there will be some directions which correspond to intersections of these maximal dimensional flats, and I want to be able to recognize them before and after applying this positive model. So, let's see what happens in Mark and Transcribing. So, first of all, the domain set is just the The domain set is just the collection of subsurfaces and one should also add like essential up to isotopy and recall that in this case the orthogonality relation actually corresponds to the subset Actually, correspond to this subsurface being disjoint. So, what is a complete support set? It will be a collection of disjoint subsurfaces of the maximum number possible. And the fact that the coordinate spates are unbounded means that the that the Bonded means that the subsurfaces that you get have to be connected. So, one thing that you could do, for example, is the following. You could have, let's say, a surface of genus 2, and you could take this annulus here, this annulus around this puncture, well, around this. Around this genus, call it B. And you could also have this subsurface here, the one-punctured surface cut out by this A. And this is a complete support set, but you already see that something like no not all of these uh domains are good in that sense. Domains are good in that sense. Because, for example, u is not good. And the problem is that whenever I have a collection that contains u, I can also make some space to fit inside the boundary kernel, which is this analysis A. Because everything which is disjoint from U will also be disjoint from its boundary analyst. From its boundary analysis. So whenever I put U, I also have this A and K in around. While unlike argument. Because for example, if I have this A, I can find another complete support set, for example, this one, in which I have A. A and I have this curve B prime and this let's say curve C and the intersection between this collection and this collection is just A. And it's easy to see that these are this is is really at the comfort of it. Like you are good if and only if you're a non-dolos. Even only, if you're anonymous, and because you can make this kind of stuff. And so this is the setting. And now we want to add some assumptions that make our not yet clear theorem about quasi-sometries actually a bit more clear. So, then you could, if I know if you're an angle, is this like a more general GHG thing? Can you say you put it on the switching to the bottom? Not really. What will be in the general case will be you restrict to the collection of good domains and you suppose they have some properties. And then what you will get is that a quasi-sometry of a space will induce an automorphism of some graph corresponding to these two domains. Maybe let's save it like this. Let's take it as a cure function, which I'll attribute to Jason Bernstock Mark Higgin. And system plus a little refinement by myself. And it says the following. You have your F which is a quasi-zometry from G to G. And what you want to say is that To say is that F induces an automorphism of the graph whose let's call it X where X is the graph whose vertices are good domains. are good domains and you have an an edge between two good domains if and only if they're orthogonal and if something happens that we'll discuss later. But I just want to underline that you started with a quasi-symmetry and you get some way of saying okay Way of saying, okay, the maximal dimensional flats corresponding, which I can obtain by taking orthogonal root domains, putting them together, taking a line for each of them, and looking at their image, are actually kind of preserved. And not only that, but orthogonality between two good domains will be preserved. So if you have, let's say, a two-dimensional flat or Or, in which you choose one line in a good domain and another line in a good domain, what you will get in the end will be another two-dimensional flat along two orthogonal good domains. And here is where the list of hypotheses gets quite long, and we'll try to go through them. So, the first thing you want is that Is that whenever you have two orthogonal good domains? Then you can find two complete support set such that the intersection between the first and second And the second are just w and w prime. In a way, this is like the two-dimensional equivalent of being good. Being good was each of them can be recognized as some intersection of maximum flat. This property is every two-dimensional flat corresponding to good domains can be recognized as intersection of maximum dimensional status. Of maximum dimensional standards and where I generate it. I kind of want to use this well. So the second assumption you really want is that whenever you have w, which is not good, so whenever you have a surface as before, a subsurface as before, with some boundary in some sense. In some sense, you can find some good domains, d1, dk, dl, let's say, and some complete support set u and u prime whose intersection contains w, v one and y l. And yellow. And this is kind of telling you that even if you're not good, so you can't be recognized by this intersection, the best thing you can do is actually find some good domains, which in the analogy of the mapping result will correspond to the boundary curve of your not good surface. And you can recognize this as a whole pack. And the third hypothesis, which one means? I don't remember the third hypothesis. Ah, yeah. Whenever you have U and V, which are good, you can find a W, which is good, such that W is orthogonal to U, but not to the other one. Which kind of means that not only you can recognize each of the refuges as intersection, but you can just look at all other good domains which are orthogonal to you to actually recognize you as a whole. And then there are all the other assumptions. And this is where this minor phase comes. And in a way, there are more small technical assumptions, which really tell you that whatever good means, it should mean that it behaves exactly how per analy in the marketplace group. And And number two, there's no like you don't care how many? No, you don't. No. So, why can't I expect to be distinct then? I mean, what stop you just taking the same set twice? You or like separate things just yeah, as long as these are good, this is fine. As long as you can recognize. As long as you can recognize each of these separately, you're fine. The point is that you don't want to have something which is not good and put together with something else. Yes, yeah, yeah. Like you have some natural notion of boundary. You can make it bigger. But it's still like inside here, there will be whatever the boundary is W. And why do I keep insisting that Why do I keep insisting that all these properties look like what nua in my principles group look like? Because in Maputos group, this theorem tells you that where y array is annual. His theorem tells you that if you have a quasi-sometry of the Markotross group to itself, this induces an automorphism of a graph which has the good domains as points, so curves, and you connect two curves if they're disjoint. So, this is the curve graph. And the funny thing is that now you know by a theorem of Evaron and later expanded by Bartman that the automorphism of the curve is a very important thing to do. The automorphism of the curve graph all come from marking classes. What does it mean? It means that there exists an element G in the marking class group such that G coincides with this automorphism F. And what you can do is with a With a little more faith, you can show that F and G are at finite distances. So you started with a quasi-sometime, which in theory might be as awful as you want, and you just showed that in the end it's just a local deformation. And it's just a local deformation of an isometry, and an isometry that you know really well, because it's just like the left multiplication by an element of the group. And from this, showing that the Mappinclass group is quasi symmetrically rigid in the sense that whenever you have another group which is quasi-symmetric to G, they're actually roughly isomorphic. It's just like a piece of k. It's just like a piece of chip. Almost. How much time do I have? Okay, this is the right time to stop and ask for questions. The graph that you mentioned was defined by the first activity system. Is it hyperbolic? Because you've got the art yeah and the art of the you talked about the graphic. You talked about the graph for the CSA. Yes. And you said we didn't use a an automotive setting that? No. We didn't really study anything about it. But just we, like, let's say we just cared because at this point for Macintosh group, you already know what this is, like one of the nodes. Could also be disconnected, could be very, very bad. Very bad. But at least in this case, you have like what you really care is not what the graph is, but what it's out of office somehow. Because you get to this point and you want to say, okay, I have some combinatorial data now. I have something which is poorly combinatorial and I want to recognize what it is. And if there are no other questions, I might want to move to random questions. So uh let's start by defining what we mean by random. We mean by random. And by random, we mean that we have G, which is from Appleton's group, and we give it some word metric. And we take a random variable x that goes to the K graph of G with some set of generators, some finite set of generators. And we ask that it starts. It starts from the identity element of the group. And whenever you pass from time t to time t plus 1, what you do is that you choose t plus 1 among the neighbors of xt uniformly at random. And so the picture one should have is that let's take a kilograph of the market, which is surely not like this, and you start from the And you start from the identity. You start from the identity, then you choose one of the vertices which are adjacent to the identity, just by flipping a coin as many times as you want, which is one. Then you do the same. You are here, which is where to land. You can go like this, you can go like this, you can backtrack. You can keep going like this. And what is important is that at every step, Is that at every step of this process, what you have is some element of your group. And so instead of just one random guy which is very drunk and like is going along the mummy group, you can say, okay, let's call the whole company of my friends and like let them drink a lot and we'll say, okay, I have I mean if they just step onto multiple groups, like Step on the multiplus group. Like, they might get very far away, but let's say I get x1 and xk, which are independent. So, not only they're drunk, they also don't remember their friends. They just go wherever they like. And so I can consider what I call n of t, which is the normal subgroup generated by x1 at time t, xk at time t. So I let them go for a very, very long time, possibly. I stop them and I look where they are and I take the normal closure of the subgroup generated by the salads here. And so I can look at the Randall. So I can look at the Brando quotient, which I define as G bar, which is the Marketplace group quotiented by this entity. And what you would like to do is, well, say some properties for this quotient hold with a certain probability as you make the probability as you make the time go to infinity. So as you make your friends go for a very very long time and possibly very far away. And K here is an important teaching genus or just saying K. You can take any K, yes. You can take any K as long as you just say that the law, the respect is the same and they don't care about each other. And we get a theorem. We get a tear out. We shall attribute to myself, 243 and abotline. Ying and Rasmussen and I'll say well greater importance in 2024 because not out yet and it says that first of all the group G is an HAG. Is an HAG and satisfies the property And second of all, if you look at the graph X, which has vertices, the good domains, and edges corresponding to orthogonality, this correspond to the graph. Correspond to the corresponding quotient of the curve graph by the action of the random circle. And yeah, the properties that we very conveniently erased. Yes, second new sense. So this graph here, which was the graph whose vertices are good the way Good domain and edges are commonality is actually just the quotient of the curve graph by the circle. So it's literally the same that happened above. And then it's easy to show that the automorphism group of this quotient is, not very surprisingly, just the Mapping class group. Quotiented by nt. And all these properties just all, let's say, weak probability that goes to one ST goes to infinity. So it might not hold for exactly all nt that you get, but as long as you make the time go very long, you can ensure that this property holds with probability actually exponential. With probability actually exponentially decay. Yes? Does any cure depend on carry? No. Okay. Not that I know, let's say. And so, and if all of this is true, then you can run the same game that we ran before. You have a quasi-symmetry of this quotient, you extract an automorphism of this graph. Of this graph, you recognize it as the corresponding quotient of the map of this group, of the curve graph, sorry, and you recognize that the automorphism group of the curve graph are just mapping classes up to this quotient. So you start with f and you get an element of this quotient, and again, as in the previous case, you can show that f and this element are actually at finite distance. And so what you get again is that mapping cost group. First group coefficient by a random subgroup is quasi-somatically reactive. And do I have still more time? Tell us more things, please. What? Tell us some more things. Are there any questions on this? I mean, are I different really good, I guess? There is there's no study in this uh good graph, okay. That is a good graph. No, the point. The point? No, the real point is showing this. As long as you know this and you have a nice understanding of what the HHS structure is, you can show that it satisfies the property and everything follows. Actually, what they should be showing, as far as I know, is that That are, if you take this subgroup here, it's actually hyperbolically embedded. And then you can find a nice enough subgroup, let's say, a finite index of this one, which satisfies all these properties by some small cancellation procedure. Is there a contuition where like a random object should satisfy all these probabilities? No, and that's quite surprising. No, and that's quite surprising. Because, like, this is telling you that whenever you have a quotient of the MapChaus group that you know nothing about, like, you just stumble upon it, what you would expect is that this behaves exactly as the map control scope, which is in a way very surprising. Like, the general quotient, in whatever sense you may make it, of the map control group should behave like the map control script. So, the philosophy is that fancy theory, right? Yes. Yes, and I lost my notes. No, I'm forgetting that theory. Do we know that these random stuff is just one stuff which we want to play? No, not that closer, it's not that it'll be closer. Now I don't know if I want to tell you more about some part of the proof of this or I want to tell you about the the corollaries that one can get from what is omatic rigidity. Yeah, we we can put so Yeah, we we can both so proof. Proofs like hands up for proof? Call to talk for hands. Hands up for other corollaries. Oh crap. I'll go with the corollaries. We can make you tell us about the proof in the discussion section. What? We can make you tell us about the proof in the discussion. Yes. So there is this theorem of me and And system, which is which is actually just make putting together some known parts. So it's not really a terrible system. He did a lot of work in previous work. I mean, he did a lot of work in previous work. I just came and said, oh, it worked. He did. So it says, take G asynchronically hyperbolic. And suppose that G is quasi-zometrically rigid in the precise sense that whenever you have a quasi-zometry, it's actually at a finite distance from an element of the group. And you also add this very And you also add this very technical and annoying requirement that there do not exist finite normal, like finite non-trivial normal subgroup of G. Then what you get Then what you get is that phrase it as the outer automorphism group of G is five is actually trivial. And this is in a way very interesting because you get something poorly algebraic, and in a way it's another kind of rigidity result. Another kind of rigidity result. You start with some automorphism of G, which in theory might be whatever, and you show that it's just a direct striction of a linear automorphism. And how did you prove it? So the point is that we use this hypothesis to show that. To show that if you have an automorphism and you see it as a quasi-symmetry of the group, it's actually within finite distance from the left multiplication by some error. So you start with say You start with your element phi, an automorphism of G. You produce an element G in the map into G, in let's say in G, such that phi and the left multiplication by G are at finite distance. How can you view phi as quadrature? How can you view phi as quite as much? What? So l well, phi, you can see it as an isometry from a kilograph G to a kilographic object because it's an automorphism sending to elements related by so I see. So I see the swoop between the left multiplication by G and applying phi is finite. And now it's easy to show that instead of taking the left multiplication, you can consider the conjugation by this element. Because then you get that the sup of the distance between p of h and And gh minus 1, you can bound it by triangle inequality with this and the distance between gh and gh minus 1, which is just the norm of g minus 1 in the chosen word norm. So you get that this is fine. And at this point, general tricks of cylindrical hyperbolic groups. And cylindrical hyperbolic groups tell you that if is within finite distance from an inner automorphism, then phi actually coincides with this inner automorphism. And this is also where the annoying part of requiring no finite non-trivial normal subgroup, whatever, whatever, of G comes in. Sorry, and that holds in all your random questions. And that holds in all your random questions? Yes, it does. Because the cylindrical hyperbolicity, you just get it because it's an HEG. So you have your action on the main curve graph, which is a cylindrical. And you can show that the main curve graph just does not collapse to a point. It's quasi-metric-regid because of the previous point. And this is a bit annoying, but not much. Like the point is that this is true for Mapico's group again. Is true for mapping close group again, and you kind of work your way around to recognize everything to so even in the even so I mean it it's not true I guess for closed genus genus 2 but but is it still true is it true in closing? It's true in let's say if you start with the mapping group that has these properties so g let's say genus at least three, then you get these properties for the other one. Does it follow do you know if it's true for genus two? For Geos2. We didn't really think of it. Also, because, like, I don't know, we didn't think about it. It might be that the finite don't true about the normal subgroup up there, which is just like the hyperlink involution, stays in the portion. Like, it comes down in the portion and supplies. So, most likely, no? But probably not in some random quotient. I mean, right? I mean, most likely, like, your random quotient will avoid. Most likely, like your random equation will avoid this one. So your finite normal subgroup will survive in the question. But the fun part is that even if you don't have this hypothesis and you have a maximal, like there is a maximum non-trivial normal subgroup of this form, again because of eyelinerity and stuff like that. And instead of having it the autoutomorphism group to be trivial, we just know that it's finite. Well, we just know that it's fired and it will be some subgroup of this. But you'll try to avoid this at all costs. This is a very bad subgroup. It's also like, yeah, it's very good. It's like the subgroup that fixes all the boundary points of the action on the topic of bound space. You really don't want that. Any other questions before we break for discussion? Maybe I'll make a comment in response to what you told out Lou. I mean, I think that, you know, for me, part of what makes these random question theorems cool is that, like, Gromlaw has a theorem about random push and hyperbolic groups being hyperbolic. The fact that, you know, Somehow, the fact that, you know, kind of picked up this seemingly crazy definition, right, and that it holds for random quotients to mapping class groups kind of gives credence to this being the right definition. Yeah. Yeah, you would like the random equation to have the same properties. Meaning that it's an HSG. Yeah, meaning the fact that it's an HSG means that, like, I mean, like, I think probably everyone in this room is sort of convinced that HSG is a reasonable definition, but this is. It's pretty natural. It's a natural definition of the fact that the fact that it has its property. Are there, like, can you give us an example of another theorem with this philosophy first to radical sets that just give it an aspect? You can get a stronger version of this theorem here, saying that if you look at the commensurator of the group G, it's actually just isomorphic to G. So not only in like automorphism of G are in their automorphism, but also when you look at isomorphism between finite in the subgroup of G, they're actually restriction of inner automatism. They're actually prescription of the neurotromatic, and it's still some powered version of this stuff. Yeah, and already the fact that, well, you just pick the a very, like you picked the random subgroup of the mapping as group, you chose to do this quotient here, and you still know exactly the automorphism group of this graph, which possibly, like, I don't know, might be. I don't know, it might be completely different. And not only that, but this is also like a covering map, if you look at the, like, not as just a scrap, but as complex in which you feel, like, the simplices. And this is what we actually use to prove that the automorphism group of this one is the quotient of the automorphism group of this one. Because you have an automorphism and you try to find the automorphism. Can you try to find a way to lift it upstairs because of covering theory? So this room is going to be geometric finiteness. I'm going to talk with Kristen Spencer about geometry finiteness, which you can sit down here. Uh next door will be where they should be and there's two questions that are. I think are the questions started. Yes. I agree with you. The point is that your stuff probably comes out of the paper passport and you can. And they already never already used before. As long as you ensure me that this map is so I can use this very easy and as long as you ensure me that the HHS structure is what you expect it to be so just like you take the original HHS structure, you apply you take the people and The people in this class is by the action of the subgroup, and you can collapse stuff only in the curve graph, but nothing else. As long as you keep menace, then everything follows. And actually, this covering stuff is just saying that the elements of NG have large large translations, so you act freely on as you talk about. Putting the dash together important questions, but not the fact. We didn't say the facts. I want to ask people. Yeah, yeah, but okay, it's all right. I think I'll go for a walk and then maybe at nine or something like that. Where is the one? Like second floor, where there was. Second floor window set. Ah, nice. Okay. I think so, yeah. I'll see you in text. Also, your talk was amazing. Thank you. You speedrun it like very fast, but it was very nice. Nothing more of like this can part of a store. Oh my gosh. Oh, if you ma'am, that's a little bit of a message. And you get another both of them. You finished your paste. So it's the same machinery. Almost. So the point