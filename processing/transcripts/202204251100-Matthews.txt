Thank you so much, and thank you to the organizers for putting this all together. It's so nice to see so many people. It looks like a really good group. So it looks like a great talk week coming up with lots of good ideas coming about in this series. So today I'm going to share with you just a little bit of recent work on fractional decoding. Work on fractional decoding of codes from curves. And the work that I'll be talking about today is joint work with my student Aidan Murphy, who actually just defended his dissertation successfully a few weeks ago, and Wellington Santos, who is a postdoc now at Virginia Tech. So the big idea, what I would like to say the big idea is, is can we do more with less? Because that has kind of a nice ring to it, doesn't it? Kind of a nice ring to it, doesn't it? Um, can we do more with less? So, actually, though, what we're asking is, what can we do with less information? Um, it won't necessarily be more, but can we do error correction using less? You have to be careful in the university. Don't go around saying, can we do more with less? Because they'll take you up. You're so right. I should have whispered that just to this small group. Just to this small group, yes. So, in coding theory, we're always wondering: can we get away with doing more for less in terms of decoding? And so, that's what we're talking about today. Just for decoding, can we do more with less information? And actually, the real question we're asking is, can we perform error correction using less information than we normally would? And we'll see as we go through this. Yes, that is the case for. Yes, that is the case for some codes. And so we'll be considering codes from curves that have this property. And I'll be clear about what we mean by less information and performing error correction in that situation as we go forward. But this is the big idea. So if you were at Dr. Dr. Mo's talk, you already know that using less information from a receive word and doing something with that information is something that. With that information is something that we've been interested in now for some time. And so I want to think about those traditional situations first. So, this is going back to sort of like the beginning of coding theory. And classically speaking, if we have a sent code word, C, and we'll assume we're using a code of length N, dimension K, and minimum distance D over some finite field F. Suppose we have a received word W, just of these N symbols. These n symbols, we know that if all of those symbols are over the finite field that we started with, then this code is capable of correcting the floor of any d minus one over two errors just based on its minimum distance. We also know from basic coding theory that if instead the word has its symbols being either erased or from a finite field, and here when we mean an erasure, we say erasure, we mean We say erasure, we mean that this word is received, and its entries are either the entries of the sent code word or they're erasures, and erasures are denoted by the question mark. And then in this situation where the positions of the erasures are known and there are no errors anywhere else in the receive symbols, we know that this code can correct any D minus one erasures. And of course, when we say these two things, we're thinking about using at We're thinking about using access to all of the received symbols, right? So we capture W, and then with the information from W, we perform either erasure recovery or error correction. And like I said, if you work at Giacomo's talk, then you know that there are codes where we're trying to recover information using fewer symbols. And so those are those locally recoverable codes that he was referring to. That he was referring to. Very nice talk, by the way, very enjoyable. We know that a locally recoverable code with locality R recovers an erasure in a coordinate using only local information. And by local information, we just mean our other symbols of the code word. I'm sorry, the received word. And so these are our other symbols from F. The setting that we're going to be considering. That we're going to be considering, we're going to look at codes over field extensions. And so we'll have this degree L extension of a field of Q, the finite field with Q elements. And we'll typically be thinking about the code. Do you see my little hand on the screen? You see the little cursor? Okay. So we'll be thinking about our alphabets for the codes being this larger field, an extension of FQ of degree L. So in this LRC, our locally recovered. So, in this LRC or locally recoverable code situation, if you think about it, we could have a received word W that has coordinates, either these field elements or the larger field or erasures. And then if the code had locality R, what would that, we would mean that we're covering an erasure from R symbols of the large field FQ to the L. So this means that we're using RL symbols of FQ. Of FQ. And when we use those RL symbols of FQ, if you think about it, they're among the n minus one symbols of FQ to the L that we have access to. So I'm going to make this distinction as we go through. So when we're doing local recovery, we're selecting symbols from this repair group or recovery set and And those are among the symbols of the received word. We can think about how this relates to another idea. Suppose instead, again, we have our code as having an alphabet of this larger field, this degree L extension. If we have a single erasure, then we need Then we know that it's assuming that we have minimum distance at least two, we know that this single erasure can be recovered using the remaining coordinates, which would be L times N minus one symbols of FQ. Something that we won't talk about today, but is closely related to the topic that we will discuss, are codes with linear exact repair schemes. And so all of this is just kind of to place in context this idea of fractional decoding and relate it to. Of fractional decoding and relate it to some things that are in the literature that people might be working on already. So, for codes with linear exact repair, the idea is you want to recover an erasure using fewer symbols of the ground field than the L times N minus one symbols that you normally would. I want to mention, though, and just to be clear, that the symbols that we're using here for linear exact directions. Here for linear exactor pair, the symbols of the ground field Fq, they're not necessarily among the n minus one times L symbols that we would have used before. So there's a slight distinction here between the locally recoverable codes and the information that we're using, which is really like a subset of the small field elements that we had before. And here we're using fewer than L times n minus one symbols of FQ, but they're not necessarily found. Of FQ, but they're not necessarily from among the ones that we started with. So that's coding for linear exact repair. Today, though, we're going to talk about something that's similar to this, but it involves error correction. So consider that we have, again, a received word up here. I know this is a bit repetitive, but you know that that word can be represented using symbols of FQ. We just need L times N of them. And the idea of And the idea of fractional decoding is: can you still perform error correction if you have access to just a fraction of those symbols that you did before? When we say fraction of the symbols, we mean in terms of the number of symbols of FQ that are used, not necessarily a proportion of the symbols that you are thinking of when we think about this, the representation of W here. So, fractional decoding was introduced by Tama Ye and Bark and Tama Yeh and Bark in 2017. And that's the topic that we're going to be considering. So, this idea is sort of like linear exact repair, but for error correction. All right, so we're going to be looking at doing this for codes from curves. And so, these are going to remind us very much of algebraic geometry codes. You could think of them as algebraic geometry codes if you like, though not in the strict sense. In the strict sense. So I thought it would be good to think about what that strict sense is and then build on that to develop the codes that we're studying for fractional decoding. So typically to construct an algebraic geometry code, one would start with a non-singular projective curve over a finite field, and you would choose two things. And these two things are going to be what govern the properties of the codes. You would choose some rational points on the ground field. Rational points on the ground field. So where now we're just working over a finite field F. There's no extension, yet we'll get to that. So for now, just standard algebraic geometric construction. We'll take n rational points over the finite field with coordinates in the finite field. And then we'll collect them in this divisor D. These are the evaluation points. So we have n of them. So that's the first choice we make is the evaluation points. The second choice is the choice. second choice is the choice of divisor G. And I know this is probably a lot of review, but the idea is that this divisor G tells us what functions we evaluate in order to define the code words. And so this Riemann rock space of G, of course, is the collection of functions that have certain properties which are specified by the points in the support of G. Based on the description of G, the function might have to have certain Description of G, the function might have to have certain zeros, and it's only allowed to have certain poles. So, this is all very standard. One thing that we'll do throughout is we're going to always assume that the degree of g is less than n. That way, the evaluation map that you see at the top of the screen is injective. And so the evaluation code is then just the image of this evaluation map. So, that's the traditional algebraic geometry code. When we do this, we get When we do this, we get a code over the alphabet F of length N. Its dimension is just the dimension of the Riemann rock space, and the minimum distance is bounded below. The most commonly studied algebraic geometry codes are, of course, the one-point codes where we take just G to be a multiple of a single rational point. And those are the one-point codes. All right, so what did we do? We chose two things. We chose the set of evaluation points and we The set of evaluation points, and we chose the divisor G, which specified the space of functions. And so, one thing that's been going on for a while now in coding theory is manipulating those two choices in order to get better codes or codes that are more carefully designed with a particular application in mind. And that's what we'll be doing today. So, in particular, we'll be thinking about how can we replace those two things, the space of functions f, The space of functions f that we evaluate in order to define code words, and how can we define the points in such a way that promote fractional decoding. So, notice that if we do this, of course, the choice of points determine the length, provided that we can place V in such a way that we have an injective map, we know the dimension, and then. You know, the dimension, and then again, we get probably if V is much smaller than the Riemann rock space of G, then we might get an improvement to this minimum distance, but we're at least guaranteed that. However, for many applications that we're interested in now, the minimum distance may or may not play the most important role. So the point is the choices of D and V determine the properties. The codes that we're going to be looking at come from the Hermitian curve. Curve. There are other choices for the curve that might also allow for fractional decoding, but we'll stick with this one here. And as we go through, you'll probably see some of the properties that would be convenient for a curve to have in order to perform fraction coding on the related codes. All right, so many of you are familiar already with the Hermesian curve. We'll think about this as a projective curve where the affine Curve where the affine points are the solutions to the equation that we see here. There's q cubed of those when we think about viewing this equation over the field of q squared elements. Right, so for every x value that we plug in over fq squared, we have q different y values that go along with that. So that gives rise to these q cubed rational points. And in addition, we have a single point at infinity. Another important Another important ingredient, again, also review, is the Riemann-Rock space of a multiple of this point at infinity. So I put this here just to remind us that, well, in this case, the Riemann-Roch space has a really nice basis. That's something that we'll be making use of and will be an important ingredient in the fractional decoding idea. And then finally, the definition of the Hermitian one-point code is just the evaluation code that we. Just the evaluation code that we get based on this curve and this particular Riemann Rock space. All right, so that was all background. Now we're going to move into how we're going to take this background and use it to define something new. So now what we'll do is I want to think about a Hermitian code over this large field. So I have a field with Q to the two L elements. I should have said on I should have said on the last slide that the reason we look at the Hermitian curve over Fq squared is that there it's maximal. It has the maximum number of rational points for its genus. And so I might want to look at a Hermitian curve over this larger field. And if we do that, then it's this top equation that we see here. Or we might want to look at that curve over FQ squared, in which case we would have a different curve with a different. Case we would have a different curve with a different equation. So for fractional decoding, remember what we want to do is we want to think about having a code here and then decoding, thinking about the symbols being represented over this smaller field Fq squared. So our goal will be to define a code on this curve so that we can apply fractional decoding using elements of Fq squared. In order to do that, there are some things that we'll need to consider. Remember, we have those two choices to make. We have to choose the evaluation points, and we need to choose the functions that we'll evaluate in order to get code words. Oh, I see something in the chat. Oh, that's not important. I'm sorry. I thought it might be a question. All right. A question. All right. So we think about it. We have to choose the collection of points, the evaluation points, and the set of functions. So, in thinking about the evaluation points, we're going to be motivated by what we see in the Reed-Solomon fractional decoding algorithm provided by Wellington Santos. We're going to see a little bit of that algorithm in just a moment, but I'll tell you that the points, the evaluation points, play an important role in the fractional decoding. And there in the reads, Decoding. And there in the Reed-Solomon case, they're always chosen over the crown field. And so we want to keep that idea in place. You'll see why later. So I'm thinking about the curve over this field, but I want just the points that are rational over this ground field. And so the first thing to notice is that when we do this, if we take the FQ squared rational points over the curve over the large field, then those actually turn out to be. This actually turned out to be just the FQ squared rational points of this curve if L is odd. If L is even, we don't get as many points, right? Because in this case, we get Q cubed points. If L is even, depending on the characteristic of the field, we get either just these points where x is zero. So there's just going to be q squared of those, not q cubed like we saw here. Not Q cubed like we saw here. Or in this situation, we get something that looks at first a little more interesting, but again, we just get Q squared of them. So if we're thinking about designing codes with these FQ squared rational points of this curve as evaluation points, then to get a longer code, it would be natural to choose odd L. And that's exactly what we do. So what we're going to do then is we're going to take L. We're going to do then is we're going to take L to be odd throughout, and so L will never be even, we'll always be taking odd-degree extensions from this point on. And we'll take D, that divisor that captures the evaluation points, to be the sum of those FQ squared rational points over this, the curve over the larger field. And again, the intention is to define the longer code of the choices that we have here. So we're thinking about defining the code over the larger. We're thinking about defining the code over the larger field, but using evaluation points that just have coordinates that come from the smaller field. All right, so we have the evaluation points in mind, and now we're going to move on to thinking about what functions should we evaluate. So we have some choices to make, right? We have the curve over the large field. We have a curve over a smaller field. There's some interplay, of course, between the two. If I was thinking about a one-point code, Thinking about a one-point code, I would think about taking a multiple of the point at infinity. Just it's a nice point to choose, though it doesn't actually matter what point. It's just the one that's typically chosen. So when we do this, if I consider this to be a divisor on the curve over the smaller field, just xq given by that y to the q plus y is x to the q plus one, then we know that the Riemann-Rach space of this device. Riemann rock space of this divisor would be defined as shown here. So it's this nice, these basis elements have this nice form, and we can see that their powers are restricted by beta, as shown here. When we do that, we get polynomials over FQ squared in the variables X and Y. Of course, if I'm thinking about defining a code over the larger field, then maybe it makes sense to instead consider the Riemann-Rock space of Monroe space of this same divisor, but now as a divisor on the curve, this other curve, the one defined by xq to the L. If we do that, of course, we get a Riemann rock space that has a similar form, but you can see that we're going to have many more functions here, right? Because before where we saw Q, now we see a Q to the L showing up. Again, we're still restricted based on theta. But these are functions that have what? They depend on Q to the L now, and their coefficients. To the L now, and their coefficients are going to come from the field of q squared elements. So we have these choices to make. In this case, we have, like I said, many more functions. But when we're trying to do more, again, I want to say do more with less, but we're not actually doing more with less. We're trying to get by using less, like in the case of locally recoverable codes. One thing that we notice is that Notice is that we often have to decrease the dimension of the codes in order to get the local recovery. And so here we'll see something similar in that this large space of functions here is too big for us to apply fractional decoding for a code based on the evaluation of this set. So instead, we're going to take this hybrid form. Okay, so what do I mean by hybrid form? Well, take a look at the functions. The functions have the same form that they did before. form that they did before. They're really the set of functions that we see here in the Riemann-Mach space of beta p infinity considered as a divisor on the smaller curve. But we're going to allow their coefficients to come from this larger field. So ultimately we have a subset of functions of this Riemann-Rock space. And so this is the situation that we're looking at. So we're going to call this So we're going to call this L of beta P infinity prime. And it's going to be a collection of functions that remind us very much of these two Riemann rock spaces, but are actually neither one of them. And these functions are over at the field with Q squared. I'm sorry, Q to the two L elements. All right, so these functions have this form, and that form is going to be important. Well, I say this form, I should be careful. What we'd like to do is we would like to create a family of these functions. A family of these functions. So if I were to take R and replace it with Q, we would see just the Riemann Rock space that we were just referring to, this L of beta prime. But again, remember that we have to think about the dimension. If we have too many code words, too many functions to evaluate, then we might not be able to achieve our local goals. And here, local, I actually mean local, meaning like over using information from the smaller field. From the smaller field, not in terms of the locality sense. All right, so what are we going to do? So we'll fix an integer r, and rather than allowing all of these linear combinations of these powers of x and powers of y going up to the exponent on y is no longer allowed to go up to q minus one, it goes up to r. But in this way, we get a nice collection of functions. And those are the functions that are used to define one of these r Hermitian codes. One of these R Hermitian codes. And so an R Hermitian code is a lot like an algebraic geometry code. It's a lot like a one-point algebraic geometry code. However, it has some special properties. The evaluation points come from our rational over the ground field. The functions that we evaluate, they're functions over the ground field. There aren't as many, I'm sorry, they're functions over the large field, but there aren't as many of them as if we just took the Riemann rock space over the same divisor over the large field. Over the large field. All right, so these are the codes that we're going to consider fractional decoding for. And again, a lot of our motivation comes from what we saw for the Reed-Solomon codes and fractional decoding, which was introduced by Wellington Santos. And so there's two reasons that we're talking about now fractional decoding of Reed-Solomon codes. One, because we're going to use it in our fractional decoding for Hermitian codes. O fraction decoding for Hermitian codes. And two, it really provides some justification as to the choices that we just made. So, you know, typically to define a Reed-Solman code, one would fix the size of the field Q, and then integers K and N, where K is at most N and N is at most Q. And then we would, what, enumerate the field elements, and then we would select polynomials of fixed degree to or bounded degree to generate the code words. And so here we're going to. To generate the code words, and so here we're going to do something like we just saw in the Hermitian case. Again, this is the motivation right here. So, this came first. So, what we'll do is we have the same restriction on K and N that we normally see. We'll enumerate the elements of FQ. We'll call those gamma 1 through gamma Q. So, this is like the choice of points that we made before when we were choosing the FQ squared rational points on the large curve. The second The second thing we'll do is choose the collection of functions. So these functions are going to be functions over a larger field, a field extension of degree L, but the degree is bounded by k minus 1. That gives rise to the Reed-Solomon codes that we see here, just using the standard evaluation map. So this Reed-Solomon code has a lot of parameters used to describe it. The Q squared means that I'm considering it as a Reed-Solid. The Q squared means that I'm considering it as a Reed-Solomon code over a field with Q to the L elements. The length of the code is N, coming from the number of gammas that we've used. K is the restriction on the degree of the polynomials. And gamma is actually the vector of evaluation points. So, when we consider one of these read-soloman codes, we are considering it over this larger field. And so And so, if we have a received word over using this code, then it has coordinates coming from this larger field. And of course, the goal here is to perform decoding as best we can using a fraction of the elements of FQ. One of the main ingredients used to do that is probably no surprise. It's the trace function, right? So you can imagine that we're going to be doing a lot of this. We're going to be doing a lot of taking an element. A lot of taking an element over the large field and projecting it down using the trace map, and then we're going to want to try to reconstruct using the information from the traces. Another tool that comes up a lot, if you're thinking about linear exact repair, for instance, and other related topics is the use of this basis of the field extension. So I'll consider. So I'll consider FQ to the L as an extension of FQ and think about this as a basis for the vector space of FQ to the L over FQ. And we'll also take a dual basis. Of course, we know that if we start with an element in the large field, that that has a representation as a linear combination of basis elements. And of course, what's really nice when we have this basis in a dual is that we know the exact coefficients that give rise to Exact coefficients that give rise to that representation. And they come just from the trace map. One thing that Santos uses in, and Wellington here is here, by the way, I believe. I saw him earlier. One thing that Santos uses in his work is this idea of taking a polynomial. So I have a function that's going to define a code word. That function lives over, has coefficients coming from the large field. I'd like to relate it to some. Large field. I'd like to relate it to something with coefficients from the ground field. And of course, you're thinking, okay, so here I have this, the polynomial written out. And you could just take the trace of every coefficient. And that would be a way of going from the coefficients being upstairs and taking them downstairs. Of course, you'll notice that this map is a little more subtle. Instead of taking just the trace of all of the coefficients or traces of the coefficients, instead, we index this with i, where i index this with i, where i is something between 0 and l minus 1. And i tells us to pull the ith basis element from up here, and we get a representation of a polynomial in this way with coefficients over fq. So the degree doesn't change necessarily, but it certainly, I should say the bound on the degree doesn't change, but the polynomial does. And so we can notice that the polynomial H can be That the polynomial H can be recovered from these H sub i's as follows. So, right, the polynomial H, this is the typical representation, but each of these coefficients can be rewritten using the trace map using the fact here. Once we do that, of course, you can regroup, and you can see that the polynomial H is really just a linear combination of these H sub i's. So, the idea is. So, the idea is if you had access to all of these H sub i's, these polynomials of coefficients over the smaller field, you could actually reconstruct H. And that's the kind of game we want to play as we move ahead. All right, so a few other ingredients that are important. How do we actually use this for decoding? So, remember that the gammas came from FQ. We're going to set lambda to be To set lambda to be m over l. So m is going to be some value that's at most q, and it's going to tell you the number of parts of a partition that, so you're going to take a partition of FQ into several sets, all of the same size, and n will be the number of those sets. Once we have this partition, we use that partition to define annihilator polynomials, as you see here. Polynomials, as you see here, you can notice that the degrees of these polynomials are given by the cardinality of the a sub j's. And these are polynomials over FQ. So there's just one other ingredient that we need in order to do this, fractional decoding. So another associated polynomial. So I start with a polynomial that I would evaluate to give rise to a code word in this read Solomon code. Code word in this read Solomon code. We're going to take that polynomial and project it in another way to get a polynomial that has coefficients and FQ. So we can notice that, well, this expression is maybe not overly pleasing to the eyes, but the important point is that the degree of this polynomial is at most. The degree of this polynomial is at most case of j. And case of j depends on the sizes of those parts of the partition, as well as some of the parameter choices that we made earlier. This is going to be important to us later on, even when we're talking about fractional decoding for the Hermitian codes. What this means, though, is that because these polynomials, these t sub j polynomials have bounded degree, bounded by k sub j minus one, they give rise to Reed-Solomon curve. They give rise to Reed Solomon code words now over FQ. So remember, this is the field of definition. So starting with a polynomial H with coefficients over FQ to the L, we're able to evaluate this polynomial to get something with coefficients over FQ, which gives rise then to this weed seldom encode over FQ. Can you see the bottom of my screen? I think that's much better. So, the idea is that when we evaluate H, that would have given us a Reed-Solomon code word over FQ to the L. But associated with that H are these Read-Solomon code words that live over FQ instead. And notice that they have varying degrees starting with from the same initial value K. All right, so the projections of these Reed-Solomon. The projections of these Reed-Solomon code words then can be put together in an array. And so we end up with an array of code words, all these over FQ. So the idea is we started with a polynomial that we would evaluate to get a Reed-Solomon code word in this Reed-Solomon code. Now we've taken that and written information from that codeword as an array of field elements over FQ. Field elements over FQ of size m by n. Of course, this is what we do with a code word. We want to perform decoding here, so we're not always going to be capturing code words and then just expressing them over FQ. We instead want to be able to take as input a received word, take that received word, and write it in terms of FQ in some way. And that's what this virtual projection is. So here I take as input. I take as input some received word using this same read-solmen code over FQ to the L. And then, just like we saw on the last slide, we can project it onto FQ using an M by N matrix. The entries of this matrix here have a similar form to those polynomials, those T sub J polynomials that we saw before. But of course, we don't know that W comes from a function. And so the description is slightly different, but still strongly inspired by. Strongly inspired by the polynomials, the T sub J's. And the good news is, when we do this, if we were to start with a code word, in other words, C being the evaluation of some polynomial over FQ to the L of degree of most K minus 1, if we took that and projected it using the pi map that we saw on the previous slide, this one, which has all these D sub IJs. Which has all these d sub ij, we actually would end up with that array of Reed-Solomon code words that we saw before coming from the polynomial H. So that's good news for us. And that's actually the method that Santos uses in his work to provide fractional decoding of the Reed-Solomon codes that we've defined here. So there's a lot of details that we won't go into, but we will be making use of this. Into, but we will be making use of this algorithm. So I just want to mention a bit about it. So we have a receive word using this Reed-Solomon code over FQ to VL. We take pi of W, and that's going to give us the M by N array over FQ. And then from there, there are some details that we won't go into in the interest of time. Won't go into in the interest of time, but from there, error correction is performed. And the result is that this procedure can correct up to tau sub lambda errors, where tau sub lambda is as shown the floor of n minus k over lambda over 2. And remember, the important point is we're trying to do error correction using less information. Error correction using less information. And this information, we're sort of keeping track of it as elements of FQ, the ground field. So remember that there's a typo that should be pi of w. The received word is taken as input, and we use pi of w, pi of the received word. That's represented using m times m elements of fq, which is lambda times ln. So there we see the lambda showing up when we're talking about. Showing up, we're talking about the fraction of symbols that we would normally use. All right, so with that in mind, let's talk about decoding these new R formation codes in a fractional way. So remember that these are codes over the larger field. Here, n is going to be q cubed, and that's because, remember, we're taking the fq squared rational points on the curve, and those fq squared r r r r r r r r r r On the curve. And those FQ squared rational points on this curve turn out to be exactly the same as the FQ squared rational points on the curve over X, the curve X sub Q, the standard Hermitian curve. And of course, we're assuming odd L in order to be able to say that. So as we do this, it's going to be important for us to organize our points. And so I want to introduce this set gamma. Introduce this set gamma sub A, which has been used in the literature a lot with Hermitian codes, and particularly thinking about them locally. So we can notice that if we fix an FQ squared element, call it A, then as I mentioned earlier in the talk, for that particular value of A, we have various choices that we can take that satisfy the equation that defines the Hermitian curve. There are actually Q of them, no matter what A is. And so, if we wanted to, we could take some function from a Riemann rock space, say, a multiple of the point at infinity, and we could evaluate that function at just the points that have y coordinates in gamma sub A. So, here this F should be A comma. F should be a, b1, and so forth. So here we're evaluating f at the points that are associated with the values that appear in gamma sub A. So remember that the functions that we want to evaluate in order to get the code words, they have this form. Remember that this R is the specifies the upper bound on the degree for the Y variable. For the y variable. So, if we were to take one of these functions like we see here and take a value coming from the ground field, substitute it in for x, that's going to give us a polynomial in just y. And that polynomial is going to have degree at most r minus 1 in y. And we can also remember that these are polynomials over fq squared. And so we're going to. over fq squared and so we're going to use this notation it's like a um an a in front of the f to denote that we've plugged in x equals a into the function f that we see here all right so with this in mind if we have such an f, then we can take f, restrict it to only considering points that have an x value of a. Points that have an x value of a and evaluate the function there. And if we do that and we evaluate just at the points, the b values and a, we get a code word of a read-Solomon code over fq to the 2l. So it's a read-Solomon code word over this alphabet because remember that's where the functions live. The length of the code would be q because we have that Because we have that the cardinality of gamma sub A is Q and the bound on the degree we see here. So I mentioned that some organization is necessary. So we're going to collect the points of the evaluation points that we're using in such a way that they're grouped by X values, as shown here. Which means that a code word has this form. So I can think about a code word from this R Hermitian code. Our Hermitian code is divided up into chunks, where the first chunk comes from evaluating functions where x is set equal to a, one, then x is equal to a, two, and so forth. Of course, we can see that this is going to give us what, a code word that lives in this product of Reed-Solomon codes. We can notice that when we do this, that these Reed-Solomon codes all live over the larger field. They all have Live over the larger field. They all have length Q. The bound on the degree is the same. What's different is the set of evaluation points. So here's how we use this setup for fractional decoding. So I'm going to mention three different approaches to fractional decoding. And each one will let me just say we'll start with the most basic one. That's probably the best way to say it. So we'll start with the most basic one, but they all have some similar elements. The most basic one, but they all have some similar elements. So, um, we'll do something very motivated by what we saw in the Reed-Solomon case. So, what we'll do is we'll take the ground field. Here, the ground field is FQ squared. We're going to take the ground field and we're going to partition some of it in such a way that gamma sub A i lives in this partition. Notice that the partition has m elements. And then, with each one of those, we'll associate an annihilator polynomial. The annihilator polynomial is just in the variable y. And with that in mind, if we have a function from our Riemann-Rock-like space that remember is comes from beta P infinity along with the parameter R. We can define a projection of sorts. Projection of sorts. This projection of sorts comes about in the following way. You might recognize the form. It's similar to what we saw in the Reed-Solomon case. It's not as obvious, just glancing at this, though, that this polynomial has coefficients over FQ squared, but certainly the annihilator polynomials do, because remember the A sub ij are subsets of FQ squared. And also when we restrict the polynomial F and we take Polynomial f, and we take a projection of that called f sub u, that gives us a polynomial over fq squared as well. These polynomials have degrees that depend on the cardinality of a sub ij and the other parameters that we've chosen. This allows us to define the projection of a function from this Riemann-Rock-like space. So we started off with a function that has coefficients over the larger field. Coefficients over the larger field. We project it using the ideas that we've just talked about to get an array that is of size n by n. And the elements of this array are over FQ squared. To let me back up. Remember in the Reed-Solomon case, when we talked about this, we talked about the projection of a function. And then we said, well, actually, though, our decoding algorithms, they take as Our decoding algorithms, they take as input not necessarily code words themselves. In other words, they don't necessarily take as input functions, they take as input received words, which may or may not have come from functions. And so we need to have an analog of this for words over FQ to the 2L that's not dependent on representing that word as the evaluation of a function. So to do that, we need to look a little more closely at these sets. Little more closely at these sets, these gammas of AIs. All of this is kind of like technical and maybe not super interesting, but the important thing is we can use this to set up a situation where we take as a receiver w and we can, from that w, we can write down an analog of what we just saw for the function. So, what this means is that ultimately we're going to be able to create an array which has Which has as its coordinates elements of just fq squared, and the size of this matrix is m by q. And of course, it's important that when we project a code word, we actually get the same thing as the projection of the defining function. And we see that here. All right, so how do we use this to actually perform fractional decoding? So, like I said, we'll have three different algorithms that we'll talk about today. That we'll talk about today. And this first one is the most basic. So, what it does is it takes a received word using with the idea that you're using a code over this larger field, one of these R Formation codes, and it's going to download the entries of the projection of that code word. When it does that, remember that the projection of this code word is that m by n matrix that's divided up into chunks. Divided up into chunks. Each chunk was called D sub something. So we have each chunk represents a Reed-Solomon piece, and we can apply fractional decoding to that Reed-Solomon piece. And so if you think about it, we have these Q squared chunks, D1 through D sub Q squared. And for each one of those, we're going to apply Santos' algorithm for fractional decoding. If we're successful and in doing so, then we'll be able to have access to what each of those points. But if any step, if any one of those chunks gives us a decoding failure, meaning it has too many errors, then we're just out of luck. And so that's how this first decoding algorithm works. But it still does something. But it still does something. What does it do? It corrects the floor of half of Q minus R over lambda errors. Remember, Lambda was that fraction, that M over L that we selected earlier. So L remembers the degree of the extension. M was the number of parts of the partition. So we have some control over how many errors we correct based on the setup. And it's using element. And it's using elements of fq squared, and it's only using lambda times ln of them. So that's something. This is actually the first step, I believe, in terms of fractional decoding for codes from curves of positive genus, even if the result itself isn't as many errors as we would like. In particular, so remember, this is a code of length qq. Of length q cubed, and this is the number of errors we're able to correct in this fractional fashion. But this is a code over a large field as well. This code has entries in FQ to the 2L. And we're able to correct some of those using a proportion of the information, a proper proportion of the information that one might normally use. Okay. If we think about it, though, if imagine if when you think about the projection of a received word, Projection of a received word coming about in those read-solomon chunks. If the errors are well distributed, so there aren't too many errors in any single block, then we can actually do much better. And so in that scenario, the algorithm we just described corrects Q squared times the value that we just saw, which I think is more respectable than what we had before. So again, that's if the errors are well distributed. So I mentioned that I would share. So, I mentioned that I would share three different approaches. And the next one depends on something that you might have been wondering why we haven't talked about already, and that's interlead read-solomon codes. So if you think about it, when we were looking at one of those projections, we were saying we really had just an array of Reed-Solomon codes. And so we'll use this notion of interleaved Reed-Solomon codes to get improved fractional decoding. Get improved fractional decoding. So, the parameters here: Q is the size of the field where the evaluation points are chosen from. N is the length of the code coming from the number of evaluation points. K is a collection of integers that define the or specify the degrees of each of these f sub j's. And then m is the number of rows. M is the number of rows. And so this is our notation for an interleaved read-Solman code. And there might be times when, if they're all the same, that could be helpful. And so we'll have an algorithm that makes use of a homogeneous situation for interleaved reads all of them and codes. And then we'll have another algorithm that takes into account the capabilities of having potentially different values in the set K. So when we write K this way, K is really a more We write K this way, K is really a multi-set, so I hope you'll forgive me for the notation here. All right, so the main idea is that we want to make use of collaborative decoding for interleaved read selenomen codes within the structure that we were thinking about before with some adjustments that are necessary. So in 2009, Schmidt, Sidorenko, and Vossert determined a collaborative decoding. Determined a collaborative decoding algorithm for these Reed-Solomon codes that could correct up to T errors where T is bounded above as shown. However, there is some failure probability, and so that's described as you see here. So, if you think back to our algorithm one, that kind of basic idea, it turns out that these projections of the These projections of these polynomials F really are innerly Reed-Solomon codes, right? And we pointed out actually at that time that what they were, each one of these rows was a code word in a Reed-Solomon code, and it came from a polynomial of the same bounded degree. And so, in this way, we get each of these projections gives rise to a homogeneous interlavriate solvent code. Encode. And so we have this virtual projection. And now the idea is that a received word of one of these Archimitian codes can be treated as a corrupted version of some homogeneous interleaved retolen code. And that's really the idea behind algorithm two. So we take as input some received word using this same R Hermation code we've been. Same R Hermitian code we've been talking about the whole time. We download the m times n entries that are over fq of the projection as shown here. Now, each chunk of the projection, we now apply the collaborative decoding algorithm for homogeneous interleaved read-Solomon codes. If we're successful at each stage, this allows us to recover the Hermitian code word. And of course, there's a chance that one of these chunks will fail to decode properly, in which case we declare a failure. So this gives us what I think is a nice improvement over algorithm one, because you can see how many errors we can correct. Of course, there is some failure probability that we can write down, but this is still superior to what we saw in algorithm one. To what we saw in algorithm one, which was instead of m over n plus one, it was a half. And of course, the same idea of the errors being well distributed, leading to improved error correcting capability holds. And then we can also think a little more carefully and partition things a little more finely in such a way that if we control the sizes of the size of these partitions, then These partitions, then I'm running short on time, so I'll just say that we can write down a more sophisticated projection, you might say, that now is no longer a homogeneous interleaved read-Solomon code. Because here, each of these polynomials depends, its degree depends on the sizes of the a sub ij. The AC of IJs. The good news is that after we do this, we're actually able to take a received word, write down a modification of this projection that makes sense for it, and now apply the same technique that we saw before. And we can actually correct. It's a different number of errors. We have a result that describes when. Describes when algorithm two is better than algorithm three and vice versa. But it's the same idea. If the errors are well distributed, then we can correct many more of them. And the whole point of this is we're doing this using symbols of FQ squared. And, you know, not so many of them. How many of them depends on the choice of lambda? In other words, the choice of the ratio and the number of parts of the partitions and L, the degree of the field extension. So that's actually all I have. So that's actually all I have. So I hope that this has been interesting to you, and I'll share some references. And just remind everyone to come to Access. Feliche is going, oh, does she really have to say that every time? Yes, I do. So if you don't know about the Access seminar, it's the first and third Tuesdays of each month. Thank you. Thank you, Gretchen. There is time maybe for one. Maybe for one question or two very quick questions No questions Okay, so I guess since it's almost um We can start to move on to the next speaker, and before we thank Gretchen again, thank you. Thank you. And so we have a couple of minutes for the next speaker to share their sights.