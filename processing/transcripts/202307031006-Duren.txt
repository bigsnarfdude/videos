When we do differential gene expression analysis between two groups of samples, like healthy and delete, in addition to the differential expression analysis, we also can do differential regulatory activity test to see which factor is really driver of the disease or the between the two conditions. So I'm going to show a method can do this. The first I introduce the background and talk about Introduce the background and talk about method and validation, and last one is application. So we start a question: what the biologists are thinking. My thinking, like in developmental biologists, are considering there are many different cells in human tissue. The whole DR becomes specialized by expressing a certain set of proteins, even though they all have the same DNA. And genetics are introduced. And geneticists are interested in how a genetic warrant in non-coding region could cause a disease. And medical health researchers are studying how cells are responding to environmental signals and how they transform from healthy to disease standards. So all these questions is actually can be done by turning on or off certain genes. So there's a mechanism to control that, and this mechanism is called gene regulatory level. Gene regularity level. That is a so fundamental thing in biology. So, in gene regulation, if you look at one gene, here this gene is the target gene, we use TG to represent that. It's typically regulated by cis and trans-regulatory animal. The cis, including like enhancer, promoter, insulator things, we call them RE, and trans is mostly transcription factors. So, transcription factor binds to the enhancer and make a loop. The enhancer and make a local promoter and deregulate gene expression. Here, the TF and TG could be profiled by gene expression A, and the RE inventor promoter could be profiled by ATEX data. And the study of gene regulation is many studies, and from the microarray data available, people start to study gene regularity network. And previously, the idea had two main challenges. So, the non-coding region is involved in gene regulation, it's a major part, but it's not observed in gene expression. And another one is tissue, it's a mixture of different cell types. This project is now, we think, is mostly in thou because we have single-cell multi-on data, have paired gene expression and chromatine accessibility on the same cells. So non coding and mixture of cell type is not a big issue anymore. Is not a big issue anymore. But we need a method, of course. And another thing is the system, the gene regular connector system, is so complex, this has many genes and interactions and this context band that is changing. So this requires a very large sample, large data to fit that. And this is one challenge. And another thing is we have many knowledge from gene regulation like transcription factor and DNA binding. Those are DNA binding, those are knowledge we know how to correctly incorporate them in your model. So, this is another tip. To work on that, we can introduce the method. Before talking about the method, there's very old things that people typically use in a linear regression model to model gene regulation. So, here just start with the so for all these different genes, so if people regress them then people regress them their expression by expression of transcription factors. So one gene, they build one linear regression model to see which transcription factor is important here. So the advantage of this model, of course, interpretation is really good. But the limitation is two things. One is it cannot capture non-linear relation. Another is the non-coding region are not considered. And of course, when we talk about linear or non-linear, the first thing is to think about new. The first thing is talk about think about neural network. So we can do it by neural network, of course. So here's something we are trying. So for the output is one gene. We want to express one gene's expression here. Then the input is have transcription factor expression and the nearby regulators accessibility from APAC payment. Then the first layer is like we call them a regulatory module, which is a combination of Module, which is a combination of different transcription factors and different enhancers, like regularity elements. And in this module, we can add the knowledge of transcription factor and DNA binding. For example, we say these transcription factor's motifs are enriched in the set of REs. This is something a module of network things. You can consider them by adding manifest regularization based on the MAPLATE matrix of the TF and RE binding. F and RE binding. But adding that, okay, Maxim ST is, you know, each module is the real module, not random things. And third layer is a combination of those modules. And then last layer is, of course, the gene expression. Then we can fit the gene expression by a non-linear model and using those knowledge. We can fit them across different tissues like brain, heart, lung, muscle, many different conditions. Conditions, and there's diverse conditions, so it's good potential to fit the very complex system. But now let's move to single cell. So when we look at the single cell data, we have many cells, but all those cells, many of them is really independent and not independent. So the real number of conditions is very low. Is very low. There are just dependent things. But now the structure is the same as the bulk data. Bulk data will be across different tissues, single cell data across different cells from one tissue. Then how we can transfer the knowledge learned in the bulk data to single cell data. So this is, we talked about a lifelong neural network model. It's a lifelong learning. It's one type of transfer learning. But one type of transfer learning strategy. So, first we learn this relation in bulk data. Then, we learn them in single-cell data. But when we learned it in single-cell data, we just add elastic weight consolidation on the loss function to make sure that the solution of the true model is not totally different. Something we should share. And which one is shared is depend on the feature information. The feature information, it's a second-order directory information from the first neural network in bulk data. So, from the first neural network, the feature information is very high for one parameter, which means this parameter is really important for the model. It's better to not change it. Then, for some parameters, the feature information is low. That means this parameter is not that important. If you want to change, you can change it. So, you can add this loss. So, we can add this loss to the loss function. But here, instead of the standard elastic rate consolidation using the Auchelian distance, here we're using cosine distance, which is because the single-cell data and bulk data, the scales are totally different. So we cannot use the Auchelian distance. Then the output of the model is we use a Shape value to interpret the results. So by calculating Shape value, we know By calculating Shape value we know which input is important, more important for the outputs. Then for transcription factor, Shape P value represents the trans-regulation from TF to gene. And enhancer Shape value represents the importance of which enhancer is regulating the gene. And we also can do from the first layer, we know TF and REs, if they are activated in the same module, that means they are working together. So based on this, we can. Working together. So, based on this, we can infer transcription factor binding. All these three outputs are a general gene regular gene is not self-type dependent. Then we can make it self-type specific by using a feature engineering method. So now we already know these coefficients and combine them with gene expression, ACAP, and transcription factor expression. Let's say if transcription factor is not expressed in this file type, of course. Expressed in this cell type, of course, it's not working. So, by combining them, you can get the cell type level gene regular together. Okay, this is the method. And let's see the validation part if it is good. So, first thing is we ask, because in a regression-based method, once we can regress the gene expression better, then it means it's a better understanding of the mechanism. So, the network is typically good. So, first easy things we can check. Easy things we can check if our model can better fit the gene expression by using the external or bulk data from ENCODE projects. Here is we use the PBMC single-cell matrix data. And the result is no, it didn't improve at all. By adding external data, we cannot improve the gene expression prediction. So see the result I'm so disappointed. But then again, you say, oh, okay, since our goal is gene regularity network, Goal is gene regularity network. Why not we just check if the network improves? Then we see, oh, yes, the network part is really significantly improved. It improved a lot. Then here is we using the chipsy data scratch. Then the information here is previously people do based on regression. If you can better fitting the gene excursion, which means network is good. If the fitting is bad, like the network is bad. But from this data, we see even the regression is not. Even the regression is not improved, but the network is improved a lot. The reason is because bulk and single cell not always agree with each other because bulk data is across diverse contexts. So some correlation is consistent part, it makes the signal more stronger and it is better validated. Some non-consistent part is the signal is dispared and those one may be noise. So the natural part is given to but the graph. But the regression is not. Then we talk about the accuracy of the gene regularity network. The gene network has been studied many years, and what is the accuracy now? So here we use the AUPR ratio. So most of the methods, the AUPR ratio by using the chipsy data screen choose is about 1.2 to 1.3, which means that your prediction is compared to a totally random predictor. Totally random predictor, you are more accurate, 20 to 30 percent more accurate than the totally random things. This is the current situation of gene regular network study. We also have many benchmarking people talk about that. That is the current accuracy. But now, after we adding a text sheet and adding uh external data and using the neural network, we can do uh two point three, two to two to three volts more accurate than random things. For it's more accurately and random things. It's a huge improvement in the gene regularity network. Both TF and RE binding and TFG binding prediction all look crazy. That is only one transcription factor. Here we collected all 10 transcription factors which have chipsy data available on TBMC and we test all of them. Overall all increased. So on average it about in TF2. This binding part we have about threefold compared to random adding Compared to random and in target gene identification, we can do two-fold. And now it's the last one. Once we have the network, so what we can do is, in the beginning I talked about we can do regulator activity testing. So here the input is we have a gene regulatory network we just studied, and now imagine you have many gene expression data, either single cell or bulk from many patients. From many patients. So the network here is you only need a reference network here. And for different individuals, you have gene expression data, single cell outblock. Then output is we can calculate the regular activity for each transcription factor in each individual. Here regular activity is based on relative expression of the gene in the regular. A regular is one transcription factor and it's their target gene. If a regular means active, that means the transcript. If a regulator is active, that means the transcription factor is really working here. Then we can test if the regulator is different between two groups or not. This helps us to identify the drivers. I have two examples. The one is in AML and leukemia data. Here is we using the microarray data bulk and 38 healthy and 26 patients. Now we already have the PVMC network. Then combining them together, we can see. Together, we can see VOX-N1 is a tumor suppressor regulator. So they already have a problem that overexpression of this gene expresses cell growth and cancer. But if you look at the expression of FOX N1, there's no difference in microarray data. But if you look at the activity, then we find, oh, in healthy, it's much higher, and D-V is lower activity. But means this gene is really protecting from cancer. And we can do the same thing in TCGA in TCA. In TCGA in TCGA that detected the activity and zero, the higher activity one had a much higher survival rate. Then it operates with validation of the process. And the second example is if we look at the TCR stimulation in TV4 T cells, then these two markers are not significantly expression no significant change in expression in zero hour and eight hours. But Zero hours and eight hours. But if you look at the activity, it's significantly changed. Then again, this is validated by protein data, like whole protein data and possible proteon data. So we know if there's protein is already changing, but there's no changing expression. This one, there's no way to be directly detected from the TF expression itself, but we combine with the network and we can infer the activity and we find the activity is changing. Okay. Okay, then it's the summary. We talked about network modeling and we talked about consistency, inconsistency between expression fitness and accuracy. And we validate network and talk about activity, healthy and disease case, or all stimulation. And this is many of the work is done by the postdoc from my group, Jo Yuan Yuan, and with funding is from NIH Cobra Grant. Thank you all. Yeah, very nice talk. So gene-referenced network inference is obviously very, very hard because I've been working on it for a long time and it's exciting to see that you made some headway here. So I think one, two, two hard thing about gene-referenced networks is that finally does not imply regulation. And second is that the RNA expression in the TF does not imply that it would have strong activity. So how in your network, though, do you assume that the TF's RNA expression is related? TF's RN expression is related to its activity? Yes, so here we are assuming using a TF expression to feed that. But in the end, after in the end, based on the whole, based on target gene, we can find the better estimate of the activity. Yes, so then one morning you want to take the activity and bring it back to the model to use that as the effort. You didn't try that. Really good idea. Thank you. So you understand, or do we have understanding? Or do we have understanding about the biology behind the phenomenon that a TS expression doesn't change much, but the targeted downstream chain expression changes a lot? Yes, yes. We have a very good understanding of this part. Typically, the transcription factor protein is in the cytoplasm, not in the nucleus. When they're expression high, that maybe means there's a lot of protein, but it's not necessary to go into nucleus and bind to DNA. For example, nuclear receptors mostly just outside. Nuclear receptors mostly just outside. And once they receive some ligand or some information there, they go into the nuclear and bind the DNA and regulate the nucleus. Those are the typical meaning of transcription factor activity. I mean, another mechanism that that happens by is if you've got cofactors that are actually in the nucleus that need to be presented by conditional regulations. So the transcription factor alone isn't enough to activate anything in the factor. Not to activate anything about it. Have you considered extending your models to deal with those conditional regulatory relationships to try and model the joint activity of co-activators that bind to the transcription factor? Yeah, it's a combinational regulation of the transcription factory itself. Yes, I'm working on one of these projects and And so my collaborator will be talking about this this afternoon. Combinational requirements. How does the sparsity in the single-cell FCD declare affect this? Because a lot of the genes cannot be captured. Yeah, so in this data, it's like almost 90% of them are zero, right? So it's okay, but but Okay, but if one gene is, of course, not detected at all, there's no way to get the information. If there's some signals there, based on the bulk, we can improve that, but not guarantee that all this very small count thing is detected. And in terms of why petrol effectively coat, why it might not have the same impact on downstream gene? Impact on downstream gene. Do you also consider chromatin accessibility or whether it's in the model, like whether it is actually accessible, even? Pardon, I didn't really get the points. Okay, so for example, like why a transcription factor is expressed in two different cells if it has the same targeting in cell number one? The same target gene in cell number one and cell number two, that gene may or may not be expressed. Like one reason I think there's a cell factor matching it. Another could be the DNA of that target gene in cell one and two are just totally different congregationally. One is available for like any ultraviolet, and one is not. So, what are your thoughts about integrating that kind of model? Yeah, so um Yeah, so um in different cell type, like maybe in some cases the transcription factor is both expressed in the two conditions, but the target gene is expressed in one and not expressed in others. Those rethink is a combinational things. Sometimes the inheritor they needed is not open in the other context, then the transmission factor is not finding that that may be. Another one is they may need other call factors that is also not expressed. Also, not express if possible. But the core factor part, so we are not considering them in this paper, but in previous data, we talked about some core factors, the chromatin, the modeling factor, some general things. Those work this transcription factor by a protein-protein interaction. We evolve that and uh to fit the model. Then the model become be more complex, but uh indeed can improve and Indeed, it can improve and better explanation of the gene expression change. Thank you. I think you'll go into the coffee army now.