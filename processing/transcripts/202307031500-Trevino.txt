And I will give, well, in particular, an explicit one. So just a brief history. So let chi be a character, non-principal character. And then let's just, for simplicity, let's say it's modulo prime. Some of these things work for non-prime, some don't. So I'll just point out which things can be extended to non-primes. So historically, one of the first inequalities for character sums was Polyvinogrado, proved in 1918, and they proved separately that if you add chi of n, Of n for numbers between one and capital N, this is bounded by square root of p log p. So this one you can generalize to modulus that are non-prime. If you want to keep the one here, so we're talking about explicit number theory, you want to keep the one there, you might need the character to be permitted. You might need the character to be primitive. It might, I think, you can still get the one, even if it's not primitive, but I'm not sure. I think you might have like a four over square root of six, something like that. Anyways, Vinograda proved it, and he proved it explicitly in the case of primes. Polya, I don't know what he did, but he also proved something enough to get his name on it. Okay, so that's a Polyvinogradov. So that's the point of integrator. If you assume GRH, you can get the impressive improvement. I guess here I should put balance where you can get changing log for log log. So not much. All right. So that's what that's before Burgess. So I want to point out a few things. Let's like, what is the truth? What is the truth? All right, so we can't prove whatever is the truth, but how big can this be? Okay, so Vinograto already had a very nice conjecture for this, and Vinogratov's conjecture is that this is bounded by square root of n times. Square root of n times p to the epsilon. Okay, so why would someone conjecture this? So if you think of a Dirichlet character mod p, then one thing that should come to mind is that the values of the character are always in the unit circle. So we kind of think of the character behaving someone randomly. Someone randomly. So if you're in the unit circle and you pick random things and then you add them up, it should average to like around zero and the error will be like the standard deviation, right? So the error should be like square root of n. So that's what they're square root of n. And then Vinogreto thought, okay, well, that's not going to precisely work. So let's have something depending on the modulus in there, but something tiny. So they just. But something tiny. So they just tacked on the p to the epsilon. Okay. But basically, we think that it behaves like square root of n and poly-minogrado is kind of better than this bound if n is large with respect to p. So the trivial bound is that the sum of chi of n is at most n because all of these are bounded by one. All of these are bounded by one. So this is the trivial bound. This thing beats the trivial bound if n is large enough, right? So polyvintegrative beats trivial if n is bigger than square root of p log p. Okay, in particular, one of the important things we want to know sometimes is how big can N be and get this thing. All right, so how big can we make n and get an inequality that beats the trivial bound by a lot wide margin? I think we're all familiar with little lo, but just in case we're not, little o of f of x means that what is it? The limit as x goes to infinity of f of x over g of x is zero, right? So g of x is little of f of x is the other way around, right? Uh, the other way around, right? So, this would be much smaller than n. If you divide by n, the limit would be zero. Okay, so that's little of n so polym integrative gives us pb implies that n equals p to the one-half plus epsilon. That one half plus epsilon is good enough. Okay, all right. So that was kind of the best we had for some time. And then Burgess in 1958, I guess it depends how you count. If you're only interested in primes, then 1958. If you're interested in more stuff, then keep kept publishing. Of publishing actually for decades, but what he proved was: let R be a positive integer, then the sum of chi of n when n is less than n is bounded by n to the 1 minus 1 over r times p to the r plus 1 over 4r squared plus epsilon. Okay, so this was what Burgess proved. And one of the exercises and the activities for tomorrow is show that this implies that you can take n to be p to the one quarter plus something and get that little o of n over there. So it kind of be polyvintegral. Be poly of integrative by a square root factor. So instead of p to the one-half, you just need p to the one-quarter. Still not great, but in particular, you can kind of see also the connection with this conjecture. When you pick r equals 2, you get the inequality square root of n times p to the 316 plus epsilon. 16s plus epsilon. Ours. Yeah. Okay. So not quite the conjecture with square root of n times p to the epsilon. We have this annoying three, p to the three sixteenths in there, but that's what we can prove. If you let r equals three, you get n to the two-thirds times p to the something. What, one-ninth? One night. Right. So the larger the R is, the less P contributes, but the closer you are to the trivial bound. Although if you want to get this one fourth plus delta, you will let R go to infinity for that proof. Okay, so that's the Burgess inequality. The goal is for today is kind of try to give the idea. Of try to give the ideas of how you prove an explicit purges inequality. So it builds on work on lots of people. So just a few names of people that have worked on problems like this or that led to things we needed. So Andre Vay, Erd≈ës, Davenport, obviously Burgess. I think I. I think I there's also work by Schmidt I use. Ah, stuff by Norton. Who else comes into play? McGown? More recently, Francis. Me. Oh, Booker. Booker did some cool stuff that we'll use. So in the proof I'll use, I'll give you, I'm trying to simplify a lot of items. I'm trying to simplify a lot of ideas, but I'm simplifying ideas that came from a long list of mathematicians that worked on this problem. If you're interested in kind of like making this epsilon explicit and putting a constant there, then there's a lot of flavors of making verges explicit. You can put n in a certain per like range, and then what's the best constant? Range and then what's the best constant you get in that range, or we can try out a theorem that just works in any range. For example, a theorem that works in any range would look something like this, or p greater than 10 to the 7. This is a theorem of mine. Then the Burgess inequality you can put this constant in front of it. And you can make that epsilon look like log p to the one over r. This is kind of, if you don't restrict things, this is kind of the best one so far. If you restrict to ranges, then the records are, if it's a quadratic character, the record Booker has it. And if it's not a quadratic character, then Francis has the record. Than Francis has the record. What else should I say here? Ah, what about this one over R? The record and making this as small as possible. It's so crazy that Burgess had epsilon. Then even Burgess himself had log P to the one over R back in the 60s. And in the last 60 years, the improvements we've had on the asymptotic bounds. Had of the asymptotic bounds is that instead of one over r, we can now do one over four r, and that's a paper of Kerr, Schwarlinski, and uh sorry yeah, so So, this one over R can be changed to one over FR. There are some restrictions on the range, but that's basically the improvements on verges. If you think asymptotically, if you think in terms of explicit bounds, then we're just improving constants. And hopefully, Tim convince you that it's worthwhile work to do this kind of thing. Okay, so what we're going to do today is not prove this one, I'll prove. Prove this one. I'll prove a slightly simpler thing. So simplified. And I will skip, I will still skip steps, but I will try to prove instead of 2.74, I'll have 5. And instead of log p to the 1 over r, I'll have log p to the 3 over 2. To the three over two r and the proof will be a little simpler by doing those two changes. I will still need to skip several steps, but I think the big idea is I can communicate them. I uploaded to Dropbox the paper where I have this proof. This was written with Kevin McGown. Was written with Kevin McGown, and the paper is Lee's quadratic non-residue. It's in the Dropbox and it's by McGown and here that was a survey paper we wrote a few years ago with sort of the state of the art and the problem the least quadratic on. Of the art in the problem, the least quadratic non-residue, and we try to make everything self-contained. So we have a proof of polyvinogradov there, a proof of Burgess there, and we have like a proof of the best thing you can do if you assume Riemann hypothesis. So that's not in the Dropbox if you're interested in reading that. But in particular, for here, it's only like the four pages that deal with that fruit. Through okay, so let's try to attack this problem, and we're going to use an idea. I think it's due some more names to add here. I think the idea is actually from Ivaniets and Friedlander. It's, I think it's Friedlander, but it appears in the book Ivaniets and Kowalski. They credit Friedlander, and there is a paper of Friedlander that has an idea very similar to this. So the idea is the following. So, the idea is the following. Instead of just focusing on this, we're going to deal with a larger, well, where the consecutive terms don't have to be the first n, they can be just anywhere. So we're going to deal with the sum in, say, an interval from n to n plus h. So our goal is prove. This is at most 5h to the 1 minus 1 over r times p to the r plus 1 over 4r squared times log p to the 3 over 2r. So that's going to be the goal. And we're going to try using induction. So this is how did Friedlander and Evanians do this induction idea? Well, the idea is that they didn't shift. So consider. So consider moving n to n plus h. So this doesn't seem that useful, but let's see what happens. Okay, so if you have this sum and you want to shift everything to n plus h, then this will be the same as the sum of n plus h. But then But then, because things shifted, there were some things you forgot to put in. And there were some things that you put in that you should not have put in. I guess it's from I guess it's from n plus h minus h to n plus h. Right? So I guess let h be a positive integer. So if you shift everything by h, like if you instead of starting at five, you start at eight, then you excluded five, six, seven, but then you added like things at the end, right? You added three things at the end. You added three things at the end. So, this has length h, and this has length h. So, the idea is that we can use induction in these guys. These are sums of smaller length. As long as you pick this h to be smaller than that capital H, then you can apply induction there. So, that's one idea. That's one idea. And then, why do we do this? That's where it gets pretty weird. So, the idea is to consider H as a product of two things. So, then you have N plus AB, but then you could factor an A and write it as A inverse times. A inverse times n plus b but then this n will move through similar residues. So you now consider this like a number x. That's kind of the idea. And because chi is multiplicative, then you can pull out a chi of a. Okay, so let's write So let's write it out. So, I guess the key thing is characters are totally multiplicative. So, we want to find a way to use this to our advantage. So, by shifting things and then thinking of this as a product, we can factor things out and then we can work with that. That's the idea. Let's see, where do we have this? Let's see, when do we have this? Okay, so let's see. So this is the sum of chi of n plus h, where n is in that interval, and then I'm going to And then I'm going to say plus two theta h of e h. So this is like error that depends on the length of h. And this theta is some complex number with absolute value of most one. So that's the part where we're going to use induction. Okay. So what we're going to do is So, what we're going to do is we're going to consider let A be some positive integer. And now consider, let A prime be the set of primes that are less than A. And then we're going to let b be some other positive integer. So, what we're going to do is we're going to consider different shiftings. So, we're going to shift by age. For any h of the form a times b with this in a prime and this in b that's the idea. Mostly you can make it work with this idea to get this theorem. We have to make a slight adjustment, but I will tell you the adjustment later. I just want to give you the big idea now. Later. I just want to give you the big idea now. Okay, so the idea is you're going to make this shift and you're going to sum over all those shifts. Okay. And because of this, because it's written in this way, all these lengths will be at most. Okay. All right. So we need some inequalities. So we need, we want. So we need, we want A times B to be smaller than H over D and bigger than H over D plus 1. We're going to make the choices of this capital A and capital B to satisfy that inequality. This way, when you pick any of these H's, when you plug it into this, the length of it will be strictly smaller than. It will be strictly smaller than age, so you can apply induction to it. That's the idea. We want to apply induction. Okay. Let's just look at this bit here. So we're summing over all the H. Summing over all the H's, it can be written as A times B with A and A prime and B and B. Sorry, B less than or equal to B. We're going to add over all of those and we're going to consider the sum of this. Okay, we're going to also do that to these guys. Also, do that to these guys, but when we do that averaging out, they're all bounded by some error that's bounded by this. So all of these guys are bounded by an error that looks like h over d times, say, some constant times two, and then maybe times theta, where theta is, well, actually. we need to divide here by pi of a times b and now theta will be at n so why am i why am i dividing by pi of a times b so the idea is that you're averaging out so i'm considering shifting by h where h is the product of these two things and i'm considering all the products between primes less than or equal to a and numbers less than or equal to b and for all And for all of those, I'm averaging out. So, how many of those do we have? We have pi of a times b, so we'll divide by that term. When you're averaging out with the error terms, the constant just goes away. Yeah. This is some integer that we'll pick later. Yeah. I think we'll pick 10, but yeah. 10, but it's an integer, it's just it just gives us freedom, and then at the end we pick it. Okay, so you do this. All right, now the idea is, so h is a times b, so chi of n plus h will be chi of a times chi of a inverse n plus b. So now let V A of X being the number of A's number of ways. Number of ways we can write the number of a's such that a inverse n is conjured to x mod p. So, by considering this set, we can kind of group these guys by whenever this is x. And because chi of a satisfies that chi of a is at most one, then we can have this bound where if you put absolute values and you do absolute values and you bound it, then here you have one over pi of a. Over pi of A times B times the sum over all X modulo P of V A of X times the sum of chi of X plus P. Okay. So this multiplicative thing allowed us to change it to this. And then you can use Holder's inequality to prove that that thing is bounded by Let's see. What happens with the errors? Oh, I'm just ignoring it. I'm just working with this. The error term is this, and we'll forget it until the end. But that's already controlled. So, yeah, so I guess if I'm writing absolute value at the beginning, then here you still have. Then here you still have you'd have somebody like that okay. Okay, so yeah, now we apply holders inequality and we get that. Again, I'm just going to ignore the error term. I'm just going to look at this guy that is bounded by one over pi of eight. One over pi of A times B times the sum of V of A raised to the one minus one over R times the sum of V of A squared minus one over two to the R times the sum of over x sum over b of chi of x plus b to the two r to the one over two r so you have this product and you want to bound it you're going to use folder's inequality there is an absolute Yeah, I can see you're right because VA is already positive. So this, this is again, if you want to convince yourself, to me, it always takes a few minutes, sometimes not so few, but I have to redo this. Like, oh, how does folders work? So this is due to. Holders work. So, this is due to holders' inequality. And again, it's one of the going from here to here is one of the things that I put in the activities for tomorrow. If you're very comfortable with folder, it's immediate. If you're not, then look up folder, see how it works, and then see where that implies this. Okay, so we have this. So now all of a sudden, the problem of bounding Burgess boils down to calculus. Down to calculating this, bounding this, and bounding this. Okay, calculating this is very easy. This is just I of A times B. That's because B of A is counting all the A's that satisfy this inequality. If you're going over all the remainders mod P, then you're basically. mod p then you're basically just finding pairs a and b that have this so there's pi of a a's and there's b b's so that's where you get the pi of a times b bounding this is tricky i'll leave it for later bounding this is harder but there are some deep theorems in mathematics But there are some deep theorems in mathematics that allow us to do it. So there's something known as the Bay inequality. And the Bay inequality says the following. Okay, let chi be a theorem non-principal character mod P of order n. So the order of a character is to what power you have to raise it to get the identity. T and let f of x be a polynomial with coefficients in fp and suppose it has oh let me think about it okay let's okay i'll just copy it the way i have it before Way I have it before. So let f be a polynomial with integer coefficients with m distinct roots. And the algebraic geometers can correct me if I mess this up. And suppose f is not an nth power when viewed. Well, I'll just write mod p. So if you view it. So, if you view it, the polynomial mod p and it's not a nth power, then when you add up chi of f of x over all remainders mod p, this will be bounded by m minus one times square root of p. Okay. Okay. This is a very powerful indeed theorem. All right, so we're going to use this theorem to balance this. This thing click on the, there might be a type of V A of X, I think, is counting where it curves A and N. Is counting ordered curves a and n rather than a and b, so maybe it should be pi of a times h instead of pi of a times capital P over there. Let me think. Oh, yeah, maybe. Yes, you're right. Thank you. Yeah, it's A and M. Thank you. Yeah. Yeah. So I guess here I should add So it's pairs A and N satisfy that coherence. Thank you. Okay. Yeah. Now it makes more sense why the part where we were summing over n disappeared, right? were summing over n disappeared right like what happened to it it's here all right so we want to bound the sum over all remainders mod p of the sum of chi of x plus b when we let b range from one to capital b and we raise this to the 2r. So this is what we want to bound. The bound. Okay, so step one is: well, let's figure out what happens when you square this. When you square it, that's the same as the sum times the conjugate of the sum, right? That's the same as the sum of chi times the conjugate. It looks something like that, where now you have two things moving, b1 and b2. Okay, so if we square it, now all of a sudden we can break it apart as the product of something and its and the con and well, something and conjugate. Something and conjugate of something else. So when you raise the 2r, then it'll look like the sum over b1, v2, dot dot dot, vr, br plus 1, the dot b2r of chi of x plus b1 times chi of x plus b two times chi of x. times chi of x plus vr times chi bar of x plus vr plus one dot the dot chi bar of x plus v two r okay so this is just like unfolding things out for every choice of b one b two dotted dot b r this will appear when you unroll that product You unrolled that product. Okay, but then the next observation is: well, the conjugate satisfies that chi times chi conjugate of the identity, right? So in other words, you could think of chi conjugate as chi of n to the p minus 2. I guess we can pull it out. I guess we can pull it out because the order is a divisor of p minus one, so the inverse is when you raise it to the p minus two power. Or you could also view it one over chi of n if you want. Once we count, for me, it's easier to view it this way. But if you view it this way, then it's easier to see, okay, we have a polynomial where we can apply by. Polynomial where you can apply y. So that sum over there, if you write it down here, it's the sum of chi of a polynomial, right? It's this polynomial. So then we just apply Bayesian equality, and if An equality, and if the polynomial takes a while to write out if this polynomial is not an nth power, then Then this sum is bounded by well, then you change the order of summation. So you have you have sum of x and then you have all the d's. So you exchange the order, you put x inside, and now you're adding up over all the x's, and you can use bay. Can use they. And how many roots do we have? Well, we have two r roots. So then you're bounding by 2r minus 1 times square root of p. But then you have b1, b2r basically free. They're all between 1 and b. So you have each one of them has b choices. You get b to the 2r. So you get this bound. Bound if f is not an nth power. Sorry, I'm probably writing too low for you to read, but hopefully you can see this part. And so that, if it's not an nth power, so then the annoying part is: okay, how could it be an nth power? Right, so let's first do the q. Right, so let's first do the case n equals two. So the idea is if B one B two to the dot B two R yields F as not an F power We get that inequality. So, for those two pools, we get that inequality. If B1, B2R yields F as an nth power, we can just bound it by the trivial bound. The sum is bounded by, as if they were all ones. As if they were all ones. So that's p. So if this thing is good, you get this bound. If it's bad, you get that bound. So the whole summary This is bounded by the good B's times 2r minus 1 square root of p plus the bad b's times p. It's a little tricky to count these precisely. Count these precisely so we can just assume that, well, we can just bound them. So we can just bound how many good bees can there be. Well, what if they were all good? That's if all the tuples are good. And then we have to figure out how many bad tuples we have. All right, so now we want to bound this. So let's bound. So let's bound it in the case when n is 2. So when n is 2, again, the function looks like x plus b 1 times x plus b 2 times x plus b r times x plus b r plus 1 times x plus b two r because if the order is two. Because if the order is two, the inverse of something is itself. So the inverse of this guy is itself. So you can just write them all here. And how do you get a square? It's just the number of ways you can pair things up. So we just have to count number of pairs. Right? So you choose B1. There's B ways of choosing B1. And then you choose its pair. And then you choose its pair. There's two r minus one ways of choosing whoever is paired with b1. And then you choose the next thing you haven't chosen. And then you pair them up. There's two r minus three things left. And you keep going like that. So you get b to the r times two r minus r. 2r minus 1 double factorial. Double factorial means that you just go every two. So factorial, you descend one by one, double factorial, you descend in steps of two. So this is also known as, you can write this as two r factorial divided by two to the r times r factorial. So if n were two, we could bound it this way, and we get That the sum of chi of x plus b to the 2r be less than or equal to b sum over x. So if the order is 2, we get the bound 2r minus 1 square root of p times b to the 2r. of p times b to the 2r plus 2r factorial over 2 to the r times r factorial p times b to the r. So that's the bound we get. Again, this is in the case of quadratic characters. If you read some of these papers, sometimes it's like they assume that they're quadratic characters. If you read, say, the If you read, say, the proof of the Burgess inequality in Ivanius Nkowalski's book, but they don't actually prove that the quadratic case is the worst case, but you could prove that. It takes some effort. So it turns out the n equals two case is the worst case. And that's in the exercises to do tomorrow. For that, I give you like a list of things you can do to prove it. It might not be the best way to prove it, but it's how I know to prove it. Okay. So now we have this nice bound. And this And this bound, I mean, not exactly with these terms here is because I want to make things explicit, but in terms of something times square root of p times b to the 2r plus something times b to the r, that's the key part in why Burgess was able to prove the Burgess inequality. Without this, you cannot prove it. So, this is like the heart of the proof. Okay, but for the explicit. Okay, but for the explicit, then we need to work hard on other parts of it. Sorry, okay. So what we're left with bounding is the sum of VA squared, right? So we have that the sum of VA is pi of A times H, and we bounded this guy. I won't write it again. We have it right here. So the thing we now need to bound of BA squared of X. Okay, and we're summing over all residues mod P. So basically, this is the same. This is the same as the size of S, where S is the set of all quadruples A1, A2, N1, N2, such that what is it? A1 and 1 is N1 and 2 is congruent to A2N1 mod P. Again, I will. Again, I will let you figure this one out. So you okay, we need more conditions. A1, A2 are in P prime, and N1, N2 are N. R n capital N to n plus h and their integers. So you want to find the quadruples that satisfy that a1 times n2 is congruent to a2 times n1 mod p, where a1 and a2 are prime numbers less than or equal to a, and n1 and 2 are in that range we're adding for the Burgess inequality. So it turns out that we're going to be able to do So it turns out that this sum is the same as that thing. So now we want to count this thing. And what we're going to do is we're going to split it into two cases. So one case is a1 equals a2, and the other case will be a1 is not a2. Okay, so if a1 Okay, so if A1 equals A2, this one's pretty easy. If A1 equals A2, then N1 is congruent to N2 mod P. But this, like the length of this interval is smaller than P. So N1 has to be N2. So once you pick A1, A1, then everything else. Well, once you pick A1 and N1, things are fixed, right? So that bounds how many you can have. So there are I of A times H such quadruples. Quadruples. Okay. I guess I didn't say that H was less than P, but it's first of all, it's easier proof. And second of all, if you couldn't get H less than P, then what are you even doing with Burgess? Because the trivial bound would already beat you. Okay, so what if A1 is not A2? What if A1 is not A2? So this thing here yields that A1N2 minus A2N1 is some multiple of P. So a nice exercise is show that once A1 and A2 are chosen, then K is also fixed. That K is also fixed. This is a good exercise. I'll leave that up to you. Okay, so once you have that, that is fixed. Another exercise is now shown. That there are at most h over the max of a1 and a2 plus one choices or n1 and n2. So both of these exercises are relatively easy. Yeah, pretty straightforward. So I'll leave them to you, but. I'll leave them to you, but I mean, they're fun, fun problems. So if A1 and A2 are fixed, then K is also fixed. And once A1, A2, and K are fixed, then you can show that the number of pairs N1 and 2 in this interval is bounded above by that. And that this is actually quite easy to show. Basically, we just look at things, module something, and then it pops up. And then it pops out. Okay. So this tells us that the size of S is bounded above by pi of A times H plus the sum over A one and A two Of h over the max of a1 and a2 plus 1, right? Because we said that when, well, I guess here we should also say not equal. So when a1 is not equal to a2, then for each choice of a1 and a2, you have at most h over the max of a1 and a2 plus one ways of adding this. So then what you do is you can write this as. is you can write this as, so that's pi of A times H plus two times the sum. So I guess you fix the big one and then you add over the small one and then we said that the big one is a one and I multiplied by two because I impose an order so By two, because I impose an order, so I can switch the order. Okay, but this A1 is fixed, right? So it's pi A times A plus two times the sum of A. Here we have one over A times, oh, H is also fixed. So it's just the number of terms, it's just pi. Of terms, which is pi of a. Oh, it's pi of a minus one because it's smaller than a one. I guess I should just put a ones here so that it's more obvious. So the number of terms less than a one that are primes. So if you counted all the way up to a one, you'd have pi of a one, but you're not a one, so you subtract one. That's pi of a one minus one. And then this plus one business. This plus one business, you get another pi of A1 minus one. So you have something like that. Okay. So this is five A times H plus two H 2H times the sum of pi of A minus 1 over A plus 2 times the sum of pi of A minus 1. You get this sum, and we're going to back. Then we're going to bound a few things. So, this bound is pretty straightforward. This is smaller than pi of capital A squared because each one of these terms is at most pi of capital A. Remember, this is a's are smaller than capital A. So, if you make this as big as possible, that would be pi of cap. Big as possible, that would be pi of capital A. And how many terms of we're summing up? That would be pi of capital A. So you get pi of capital A squared. That bounds pretty straightforward for this one. If you're now dividing by A, that's a little trickier. So the strategy is, well, I won't tell you the strategy, but I will tell you what to prove. So, prove this is bounded by pi of A over 3. We need a little playing a little with explicit estimates of prime numbers. And once you collect all of Once you collect all of these things together, you will get that the sum of the squared of x is bounded above by pi of A times H times five thirds plus two pi of A over H. Okay, so now we have all the ingredients to finish up the proof. We've added V of A, we added V of A squared, and we bounded that other thing. So all together, I think we'll need a big board. Okay, so what do we have? All right, so what was it like we had that our bound that we cared about was bounded by By one over pi of A times B times the sum of V A of X raised to the one minus one over R times the sum of V A squared of X is one over two to the R times the sum of the sum of chi of X plus B raised to the 2R. This is the 2r and when all of that was some error have something like that. Okay. So this thing, if we choose things nicely, this is going to be less than 2œÄ of a prime. Okay, good. Okay, this is five-thirds, and we can make pi of a over h times two be less than one-third. We choose a such that 2 pi of a over h is less than 1. Okay. All right, so that's 2 pi of a h. The plug. A H. We plug things in here. We have one over pi of A times B times this was pi of A times H, all of that to the one minus one over R. This we can replace with two pi of A H, all of that to the one over two R. This thing here, so what was the bound for this? It was like Like, let's see if I can remember. I think it was 2r factorial over 2 to the r times r factorial times p times b to the r plus 2r minus 1 times square root of p times b to the 2r. Okay, so if we pick b nicely, then Let's see. So let B equals the ceiling of 2 over D times P of the 1 over 2R times log squared P. So if you choose that B, then How can we simply? Well, I guess we can just see what happens. So we choose this B, let's plug it in here and see what happens. All right, so we have two. I mean, I'm going to take some shortcuts. Otherwise, we'll be here forever. So we're raising V to the R, right? So this is 2 to the R, and then P to the one-half in block to be 2R. And then when we plug it in here, you get 2R minus 1, which is the other one half. You raise this with 2R, you have 2 over D to the 2R. E times log to the 2i. So that's like e to the three halves take logs of the 2i and stop. Let's see, what do we got? 2r factorial over 2 to the r times r factorial plus 2 over d to the r times 2r minus. The r so it's two r minus one there's a log somewhere. What was it? We lose a log somewhere in the second one, but here the paras and logs won't match they don't one of them will have two r and one will have four yeah yeah thank you and then this thing here we can use This thing here, we can use Derling. This is less than square root of two times two R over e to the something. So the R So, I guess another 2 to the r can pop out. And this is actually, this is up to the 1 over 2r. Okay, so the simplification is that this thing, if you choose that, I'll just, I mean, you could write things out in terms of p's and logs, and that is useful. But I guess it's a little cleaner if you just do this part. This part and then plug that in here. So you have 2r to the 1 over 2r times b times p to the 1 over 4r. So, ah, and then we have that arrow over there, and that is bounded by this. So this error is at worst 2c over d to the 1 minus 1 over r times e of h. So that's like pulling out the d from using induction. I'm skipping that step, but basically this transforms into this. So we have this inequality. Okay, and then the pi of a's kind of go away. The pi of a's kind of go away, right? They don't quite go away because when you multiply these out, you get 1 minus 1 over 2r. And when you divide by pi over a, you get, well, you basically have pi over a to the 1 over 2r. And then the b's do cancel out. And then we have p to the 1 over 4r, which is not exactly what we want. want we have 2 to the 1 over 2r and then so this times this is 4r to the 1 over 2r and we have h to the let's say 1 minus 1 over r times h to the 1 over 2r okay okay so the idea is that now we can combine these Is that now we can combine these two? We get this expression, and now we can use how we created H to bound this part. So that work I was kind of doing with the P's over there. So roughly, H over D is approximately A times B. So H is approximately D times A times B. D times A times B. So if you do H over pi of A, that is roughly DAB over, sorry, DB times log of A, right? Something like that. But B is this thing. And when you raise B to the one over two R, you The one over two r, you get p to the one over four r squared, so you're going to get p to the one over four r, and here you get a p over one over four r squared. If you do the math, you get p to the r plus one over four r squared, which is what we want. Now, if you look at the log, log of two log squared p to the one over two r is uh Is log p to the one over r, we want it three over two r, which is slightly worse. That comes from the fact that we have this pesky log a that we have to get rid of. So if you analyze this h over pi of a and you go through the details, you can then bound this by the following expression. By analyzing A B D R, which were all parameters we could play around with. Then you can get pi of A over A. Pi of A over H, sorry, the other way around. You can get that H over pi of A is bounded by something. And then you get that S chi of H is going to be, let's see. So we have E of H times. 4.04 r times d plus 1 over d to the 1 over 2r plus 2c over d to the 1 minus 1 over r and then the key is that you can make this less than c for c at least by so that's how you end up doing all of that things all of those things All of that things, all of those things. Okay, so I think I guess we ended up a little early. Yeah. Am I right in thinking that the sort of purpose of thinking A prime is to enable the factorization? What factorization? Like to count B A squared? Yeah. Well, so that when we pull the character apart, you only from U. pull the character apart you only permutes the like a a bar and the so we permute it um you don't need so like if you look at the paper where i proved it i let a and b be free and you didn't have to move over primes okay so yeah so you don't like for example if you read the original paper where i proved a 2.7 for the best i could do Or the best I could do. I didn't restrict to primes, but so it has some advantages and some disadvantages. One of the disadvantages is that then calculating a bound for BA squared, when we're doing this part, if you don't restrict over primes, it's more complicated. But one of the advantages is that then you don't need bounds on primes. You're adding over A all the time. You're adding over all the time, and those sums are easier to control. And when I tried putting in primes to me, it didn't seem like it helped my results that much. It just made some things converge faster. But when you're trying to write the simplest argument, my co-author Miguel does think that using primes was easier. So he prefers using primes. They do give an advantage over also when you try to get. Also, when you try to get the best power of log, like if you want one over two r, it does have to go over primes. For A and A and B, you can do some wave. Yes, but it's done instead of five, you could have high wave, yes, and maybe it could give you better income. So instead of moving over primes, move over like you mean psi of x like the smooth numbers or yeah sh functions. Yes, yes. Okay. Oh, I see what you mean. Yeah. And then you get much better instead of li of a, you have Something to try. Yeah, I haven't seen that tried for the explicit estimates, but that's a good idea. Simplified version of those types, if you use all co-primes up to a step, the same pooling a part trick should work, right? work right co-prim with what uh co-prim with b so so that the when you pull the character apart when you pull it out chi of a bar and then second boss chi a bar and plus h you mean co-primes to p yeah oh but yeah that way you make the so yeah so for the for the breaking apart that's that's not an issue at all but so where it simplifies using prime So, where it simplifies using primes is when you're trying to count these things, this is easier if A1 and A2 are prime. But I'm thinking for them to be something. But the part where you do this chi of A times A button. Yeah, so for this part, you only need A to have an inverse. That's all you need for that part, yeah. For that part, yeah. I mean, I think you're gaining some type of a little bit of a logarithmic factor once you're averaging things out. I think that's what's going on. When I did the calculations to me, it just seemed that the constant was converging faster, and that's all the gain I saw. But Kevin McGown tells me that if you want that log P. If you want that log p instead of to the one over r, if you want it to the one over two r, then this change helps. I do have an explicit estimate to one over two r without using this, so I'm not exactly sure. But it does seem like you can just use a to be all integers and things still work. Are there any other questions or comments? Are there any other questions or comments? Jen? Uh, and Ricky, whenever we were counting the number, to go back to the two thousand uh using the V bound, I guess, for the sums of chi raised to the power of two r. Yes. You're counting the number of good ones and the number of bad ones. Yes. Is it the case that the number of good ones plus the number of bad ones equals the number of total ones? Yes. But we're going to play the number of good ones. We were going to play a number of good ones who were upper bounding with the total number. Yes. And then the number of bad ones, we did some kind of funky argument and got some challenge. If we write the number of good bounds as the total ones minus the number of bad ones, yeah, and then we have the number of bad ones, and we should have something that's increasing in the number of bad ones. Increasing in the number of band ones, and then if we get another band on that, that might lead to a slightly better small saving. And I was trying to figure it out, but it looked like we'd be a saving of, say, like square root P when we get a saving of quarter P. You think that big a saving? Well, I agree with my own notes now, but I don't think it would be very big, but there would be a saving. There's another trick you can do, which Booker does. And the trick is what we're using. And the trick is, well, we're using the Bay bound, and we're saying there's two R distinct roots, but sometimes you don't get that many roots, right? You get less roots. So he actually goes over, well, what if you have these many repetitions and he just has with less roots and he gets a better bound. But he was trying to calculate some class number of something. So there was like some goal at the end. Like some goal at the end, and he knew how much he needed to save to get there. So he's like, Let's do every trick in the book. Booker is the one that introduced the trick of summing over primes because things converge a little faster. If you want that class number, it helps. And he had that trick of, well, let's not assume that just there's two R roots. But when I try to implement that, there were other tricks that Booker did that I couldn't quite follow. So if it's a quadratic. So if it's a quadratic character, you kind of can, instead of m minus one, you can kind of do m minus two. Apparently, you can change this m minus one to m minus two, but that's something that I would need to be more comfortable with algebraic geometry to believe. Landstra tells me it's valid, so it's probably valid, but Booker did that. Balant. But Booker did that kind of thing to get extra savings that I was not comfortable using in my own papers. Any other questions or comments from anyone here? For composite moduli, there's this one paper you're citing. Is that the only result now? Are you talking about the paper, Jane, Sharma, Cali, and Luke? There's one by Norton, it's not bad, it's not fully explicit. Okay, what very long? Sorry? Very notable. 98. Like, yeah. Yeah, I guess by now it counts as very long. The 90s still feel like recent to me, but yeah. Yeah, I mean, the result is older. He proved it in the 70s, but. is older. He proved it in the 70s, but didn't publish it until 98 when a grad student in Georgia convinced him, like, hey, you need to publish this. But he had been out of academia for decades at the time. So the Burgess inequality works for the modulus Q when Q is cube free. And Norton has a way to make Burgess work for arbitrary Q, but there's a cost. You have to multiply by something that depends on the divisor. Something that depends on the divisors of view. So I think if one wants an explicit one for arbitrary moduli, then you would need to combine Norton with this funny trick. Let's see. Thank you, Richard, for the Okay, so in six minutes, it will be 4:30. So, in six minutes, if you could be somewhere on Zoom, then I will meet you on Zoom and give you instructions for the second half of the ice project. Okay.