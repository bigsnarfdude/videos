Picture, but here I won't have many because I'm trying to do everything in Huber spaces. So I thought it would be nice to start with this introduction, which also gives a bit of context about why I'm talking about this thing. So, this was me, say, in the PhD. I was the PhD about approximation, in particular, interpolation for operators in Binax spaces. Now, shortly, I will explain what that means exactly. Yes, thanks. You just click on it and move it from here. You just click on it somewhere, you can move it and put it in some place here. Which one? The plane. You can move it and put it away. Yeah, that would be lucky. You can even turn it off. Okay. Okay. Okay. Okay. So uh So, this was at the end of the PhD. So, I was very, as is often the case, very enthusiastic about keeping doing the research about what I did. I thought it was very important, very nice. But, you know, of course, things change. I quickly almost forgot about this, but it was somehow always in the back of my mind somewhere. So at some point recently, I said, okay, it's time to go back and thinking again about it, check if it's really worth doing something. And yeah, so that's why I'm talking about this now. But I hope this also sets the tone for the talk, which should be about Should be about taking you a bit through the thoughts that I have about this topic. So it's very much a work in progress. And okay, so first of all, I would give you some serious motivation besides the romantic side of the thing for me about why this could be interesting. could be could could be interesting uh i will have some also preliminary uh uh recalls of some basic stuff so i apologize in advance for that but i need to to have highlight some aspects that we we need to to to see what we can do in this setting okay so let's start from from the beginning again from from that problem that i mentioned before which Mentioned before, which is approximation in Banach spaces. Here we restrict ourselves to Hilbert spaces, which is already general enough. So I mean just the generalization of what we do normally for say functions from Rn into R. So instead of a function to be approximated, I have an operator between two Between two Hilbert spaces, I have a certain number of data, say scatter dot, it doesn't matter here. So an element in X and the corresponding image to the function f. And I want to construct an operator, phi, between these two same spaces approximating the function. Okay, so in some norm, I would like those two operators to be close enough. Operators to be close enough or closer than a set tolerance. And okay, in particular, for example, you can think of the interpolation problem. So not just approximating, but you want to exactly match the data. For example, just to give you a flavor of what that could mean, it could be very simple in some cases. In some cases. For example, this is one of the objects I was studying, which is an interplant using so-called cardinal operators or functionals here, because they are from Hilbert spaces to R. And they can be defined, for example, in this way. If you're familiar with this, maybe you would recommend. With this, maybe you will recognize Shepherd's functions because this is essentially the norm of the difference raised to a certain power. And they are cardinal in the sense that they satisfy this simple property. They are zero at all the data points except one. So clearly, if I use those to do a combination. Use those to do a combination of the values to be interpolated, ideal to the interpolant, right? Okay. Okay, so why I'm talking about this? I'm talking about this because this is a first example of, say, application. Why would I want to construct this kind of Say functions, spline functions, as I said in the title. Well, this is a first reason. I could use those for approximation. So, this is a problem which classically can be addressed with splines. As far as I know, it hasn't been done yet in the setting of Hilbert spaces or Larax spaces. So, this could be a first motivation. And in the same direction, I also want to mention another application where classically we often use splines, which is differential equations. So here I'm considering functional differential equations, which, okay, roughly speaking, is again a generalization. So, of course, we are not talking about derivatives in the classical sense. Derivatives in the classical sense, we are talking about gator derivatives. So, as a quick reminder, they work exactly in the same way. This is, I would say, the most basic definition. So, the only major difference I always keep in mind is that the result is a linear operator. So, if you evaluate a guttural derivative. Evaluate Gatto derivative at some point, at one point of a Hilbert space, the result is a linear operator. Okay. And so with that in mind, I can define a functional differential equation, which is, as the name says, a differential equation where the, well, there might be also traditional derivatives involved, but derivatives in the Derivatives in the gatto sense are involved. So, for example, in this one, there is so the unknown is a functional, so depending not just on points in a shield space, but also in time. So, also a derivative of time appears, and the ghetto derivatives are hidden inside certain linear functional that we have here. We have initial condition. We have initial condition. So, this is an FD and more, let's say, more concrete example. For example, here I put a functional advection equation. And here you can better see that here we have that kind of capital derivative I was mentioning. Mentioning. There are many examples of different kinds of equations that have this form. Here I have a very short list for a longer list and details, more deep examples. I suggest to read this nice paper if you're interested. And why am I considering this kind of problem? Because This kind of problem because again, we can take from the classical theory also the approaches about how to solve it. So we can choose a Galerkin-like approach. That is, we want to approximate the exact solution with an approximate one belonging to a space of functions with a certain basis. We replace the exact solution in the equation with this. Exact solution in the equation with this approximation, we get the residual expression, and then we say, Okay, I compute approximation by imposing that these inner products with the elements of the basis of the approximation space is zero. Okay. So, overall, as I said, two As I said, two problems which classically can be addressed with splines. So the idea is why can't we try and do the same thing here? So to do that, I need to define somehow splines in this context. So spline functionals. So the first step to do this, my opinion, is let's My opinion is let's be more precise about what do we mean about even before splines, what is a polynomial here. So as I said, I will focus on the case of functions. So the second Hilbert space is just R. Short comment on the notation: x to the power k means Cartesian. Cartesian product of k times the Hilbert space. Then, when I consider a k linear operator on x, so it will have k entries. If I write l x to the power k, this means that all the k entries are all equal to x. And yeah, this way it should be clear. It should be clear that when I write this, I mean that I have n plus one k-linear operator, so one which is constant, one linear, and so on. And their combination is what I call a polynomial of degree of degree n here. Okay, so I'm just taking. So I'm just taking combinations of multilinear operators. Okay, so this is the polynomial example again in the let's say in the context of approximation so that we can take a look at what such an object could be. This was This was a polynomial interpolant for the interpolation in Hilbert spaces, very old example. It's, by the way, a generalization of classical Lagrange interpolation. In fact, you can check that it reduces to Lagrange polynomials if the space is one of real numbers. And so in this way, it becomes. In this way, it becomes easy again to define the terrible plant. Okay, but I show this not just to give you an example of a polynomial defined on a Hilbert space, but also to highlight that we inherit from the classical method. Methods, also the drawbacks because if I try to use this interpolant here to interpolate this functional, this simple functional, you see from the table where I applied this interpolant and then I evaluate the interpolant at different points than the data ones and I check the error. And I check the error, you see that as I increase the number of points, of interpolation points, the error gets worse and worse. So this is what we know and that happens with polynomial interpolation. And it's still true here. So this is to stress that going for splines is maybe a good idea. Maybe not the only idea. And in fact, I want to mention course. Want to mention, of course, this is not going for splines, is not the only solution. For example, one can extend to Hilbert spaces other classical tools like radial basis functions, which is also an option. And it's, by the way, very natural since they are defined using norms. But of course, again, they have the same features, advantages, and disadvantages. For example, Disadvantages, for example, the behavior when you derive them or when you integrate, because they are, of course, not polynomial. In the best case, they are rational. Okay, so what can we say about these polynomials? Maybe an intuitive, simple thing, which I anyway try to formalize. I anyway, try to formalize here is that in one sentence that we can handle this component by component in a sense. So I mean this, if the Hilbert space is separable, that is, if there is a countable orthonormal basis, if I consider a k-linear operator. The a k-linear operator L, then when I compute, say, the corresponding monomial, so L to the power k, this can be expressed in this way. So as sum of polynomials of total degree k. Okay, so this means, I mean, it can be easily checked starting from the Easily checked, starting from the fact that we know that for k equals one for linear operators, we can use the risk theorem. And so we can write that as the linear product. Okay. And so if you iterate that, you see that basically fix all the arguments but one and you iterate. But one, and you iterate that, and you see that you end up with this. So, I and I care about this because, say, the consequence is any of the polynomials that I want to have and glue together to have a spline then can be expressed in that way. So, I have essentially polynomials. Polynomials in the components of X. Components with respect to the basis. Okay, so these are the polynomials. Now I want to have piecewise polynomial functions. So I have somehow to choose or at least control the subdomains on which. The subdomains on which I want to have these functionals. And of course, the other ingredient is taking care of the regularity. But I would say, first of all, the major problem is subdomains, subdomains, okay? Because otherwise, we don't even know what we're talking about. So a couple of simple first approaches. First approaches. As I said, this is work in progress. But so the first one is really, in a sense, going component by component. So I say the way I choose, I construct my subdomains is probably not the possible option, but say I give a set of points. Okay. I set a degree. Set a degree and then what I do is essentially constructing operators which generalize the truncated power basis. Okay, so for each point, I construct this set of operators where these are essentially the polynomials, polynomials of degree m actually I did a mistake, I should have Actually, I did a mistake. I should have not affixed n, but this should be k, yeah, from zero to n. Okay, sorry. Polynomial in this direction. So these directions. So for each, xi is fixed and I take all the j's, so all the other points. And so I have polynomials in all these other directions. And these are. And these are the truncated powers. Truncated powers again in the same directions. And here, essentially, I am this is, of course, the midpoint between xi and xj. So that's where I have my boundary between the two subdomains. Between the two subdomains, right? Okay, so what this means that collecting all these functions, what the space that I'm spanning is one of, say, spline operators or functionals of degree m defined on these subdomains, or I call them here hypercells. them here hypercells which have this kind of structure actually here not just should be greater than or less than basically you you are you have hyperplanes passing through this point you split the space into semi-spaces and you are intersecting Are intersecting this. So you have, I call them hypercells because they are cells which are bounded in certain directions and unbounded in all the other directions. Kind of sure, exactly. Do you mind doing a picture in 2D? In two-dimensional case? You can use a picture in two-dimensional. Sorry. Yes, thanks for that mind. So, say we start from we start from this point. So, what I have to do is I consider all the other points. For each of them, I take the middle point, and there will be. And there will be the hyperplane going here, and then what I'm doing is that I am defining and so there is this semi-space, this semi-space, I'm defining just the splines along this direction, okay, and then I do the same, the same. So the same in the other uh directions. What else? Yeah, of course if the directions, this just generates the space. If the directions are linearly independent Linearly independent, I have a basis as well. So, this was a choice I'm talking about, the choice of not defining, not starting from, say, the directions, not starting from the basis of the Hilbert space and choosing the directions and defining cells here. Instead, I opted for Opted for, let's say, just give, I call it the centroid of the cell. So that's how I try to control what is going on here. Okay, the other option is this one. Let's say I started from generalizing another thing, which are these. Thing which are these Lobachevsky splines defined like in this way with this recursive integral expression. Why I consider those? Because if you fix the parameter A here, if you fix I, that is the order of the spline, and you say shift suitably this spline. Suitably, this spline, you realize that those are essentially the BISC lines, okay? Up to a multiplicative factor. And yeah, in fact, in 2D, the divided version looks exactly like this. So, and it looked to be at first a good idea because, okay. because, okay, to start the recursion, I just need something piecewise constant, which is this. Then we replace the Lebesgue integral with Bochner integral, which is exactly the generalization to Himber spaces. Okay, and if you follow the formula, yes, the resulting FI's should be. Resulting Fi's should be piecewise polynomials of degree I minus one, except that it doesn't work because little detail, there are several requirements. The main one which is not met is that the ball should have a fine measure, which is not the case if the Hilbert space is infinite dimensional. Space is infinite dimensional. So I stick to something more simple. Let's say I make the compromise. I say, okay, let's just try to define something with some of the properties that I would like, something compactly supportive, supported, positive, and have in mind the application to To the approximation point-based. So here I won't have something, say, similar to cells. I will just associate to the points that I give one or more functions. So what I'm doing is something really, really basic, for sure, not ideal. I define this again: truncated power, but But in this way, so here I have the norm of x minus xi over a certain radius. So in this way, I can build something which at least somehow reminds us that these plans and which is piecewise polynomial in all directions, in a sense. Okay, I can. I can construct a whole set of these operators, all centered at the points, considering a finite set of radiuses, which I can suitably choose. Of course, here, as I said, this is piecewise polynomial on these sets. This set okay, plus what's outside where everything is zero, it's non-negative. I don't want to have this, I had to take okay, good Let's say it was Spire in Spire.  Okay, sorry. I was saying, yeah, it's so point-based that I could go completely to an approach in the style of radial basis function, that is, I can have only one function associated to each point in this way, keeping the essentially the same properties and. The same properties, and in this way, for example, if I choose properly the radius data, of course, I can simply solve the interpolation problem, for example. Okay. All right. This doesn't move anymore, but okay. So to summarize, this is just a first approach to show that. To show that something can be done, and at least application-wise, it could make some sense. The two approaches, the first is, let's say, in the direction of generalizing the concept of cells, and we do things component by component. In the second one, In the second one, it's different. As I said, it's point-based with this problem about the degree. And of course, there are a lot of open questions which one could ask. The first, of course, is if there are any other construction. I'm sure there are. If an homological approach can be useful here. And then, of course, going back to motivation, so really try to apply this kind of tool to solve those problems. And then if all this makes any sense and it works, then why not thinking bigger and go to Thinking bigger and go to black spaces. And that's all. Thank you. Thank you, Chederi, for the nice talk. Questions, comments from the audience? Well, I have say a comment, or I don't know if it is a question, comment, whatever. If you go to the working point twice approach. Point twice approach, then somehow you have this point speed on this xi, yes. Yes, say what is the effect on, I mean, say this n function that you construct, they form a basis or because your basis functions also say can can you ensure something about the interplay or or or just no, of course the Of course, that's one of the key points of this approach: the choice of the points and the choice of the radioxies. And actually, what I'm thinking now is that about this, one should try and say something about it being a basis and positive definitions. Because that's what you want. I mean, you can use it. I mean if you if you're very very uh conservative okay you can just uh keep things separate but that's not really useful because then in the middle you have gaps so yeah that's one of the for sure it's one of the questions thank you um other comments no okay so then um let's thank Jerry and And then we resume as well.