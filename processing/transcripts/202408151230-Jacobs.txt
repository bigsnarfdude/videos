Lucha Libre guy called Mathematico and I bought his shirt. So, yeah, if any of you guys have extra time, I highly recommend Lucha Libre. It was super fun. Okay, so today I'm going to be talking about generative modeling and then sort of the math content of this is going to be trying to construct Lagrangian. To be trying to construct Lagrangian solutions to diffusion equations. And I'll explain how these two things sort of fit together. This is joint work with a whole bunch of people. For the sake of time, I won't keep writing all of the other names, but you can look at some of our papers. This is my most important collaborator on this project. Okay, so lately when I've been giving this talk, it's been to like very machine learning. It's been to like very machine learning type audiences. So I usually don't have to do any introduction on generative modeling, but I think that is not quite this audience. So let me talk about generative modeling, which is sort of one of the, I don't know, really hot topics in machine learning right now. So in general, a really important task in machine learning, and we saw this in Matias' talk, is I have some. I have some sort of unknown probability distribution. And what I want to do is, I want to find a map that's going to push a very nice probability distribution into this unknown distribution. Okay, so I want to find some map that I'm going to call y. And this is going to be something that's essentially going from like a nice probability distribution. So you could think of this, for example, as a Gaussian. Was a Gaussian. So, Gaussian. And it's going to take this to some kind of like unknown probability distribution. And this unknown distribution is something that's very high-dimensional. It's interesting. It has lots of complicated structure that. It has lots of complicated structure that we can't really understand. But we want to sort of try to construct this map Y so that we have a way of converting something that is very easy to sample from to something that is very hard to sample. Okay, and so this is like an unknown probability distribution in high dimensions. So really, this is a map from Really, this is a map from RD to RD. B is really, really big. And again, I want it to essentially push something nice to something not very nice. Okay. Same D. Yeah. I mean, okay, it doesn't have to be, but for the purposes of this talk, it'll be the same D. Okay. But what do I know or like? What do I know, or like, I mean, I have to know something about this unknown probability distribution. It can't just be a huge question mark, otherwise, obviously, there's nothing that we can do at all. And so what I usually have from this unknown probability distribution are some samples. Okay. And so one thing you could think about is maybe my unknown probability distribution is every possible image of a cat. Okay. And so there's some probability distribution on this crazy high-dimensional. On this crazy high-dimensional space of CAT images, right, which are probably millions of pixels. So, you know, D is something like a million. And what I want to do is I want to, you know, take a whole bunch of pictures of cats, maybe from the internet, and I want to try to construct some map Y. And then what I want to do is I should be able to take samples from this nice probability distribution, push them through this map Y. Push them through this map Y and get new cats that I've never seen before. Okay, so that's really the goal of these sort of generative models, right? I want to take some data that I have, I want to try to learn a map, and then I want to hope that this map can create new things that I have not seen before. Okay. So, really, all we have here are just Really, all we have here are just a bunch of samples. Okay, well, right, this is an optimal transport workshop, right? We know we have something that we love to do in terms of constructing maps between probability distributions, but again, the whole point. But again, the whole point of doing this is I want to create new things that I haven't seen before here. Okay. And so for instance, if I just tried to construct, sorry, if I just tried to make Y the optimal transport map that goes from this nice probability distribution to the empirical distribution on the samples that I have, this is useless because I'm never going to create new things. I'm just concentrating. Create new things. I'm just concentrating on all of the data that I have. Okay. And so when you do this generative modeling, you want to come up with some map Y that you can sort of interpolate. You want this somehow to be doing an interpolation of your data. All right. There have been a lot of ideas. A lot of ideas of how to do things like this. Again, we saw this in Matthias's talk with the Wasserstein games. And what I'm going to talk about is this method that has become recently very popular, which is called generative diffusion modeling or score matching. All of these things are sort of synonyms. And when you first see it, it will seem like a completely crazy idea. Like a completely crazy idea, but it actually sort of does work. Okay. Let me just fix some notation. So I'm going to actually call this unknown probability distribution row zero. And we will see why in a second. And I'm actually going to call this nice probability distribution that I want to create this map. That I want to create this map to find them actually going to call this thing row infinity. Okay. All right. So here is how these sort of generative modeling, score matching, diffusion models work. Okay, so I'm going to choose a diffusion equation. It's almost always a Fokker-Planck equation. I'm going to choose a diffusion equation that has this probability distribution as its stationary state. And that's why I'm calling this thing rho infinity, because if I run this diffusion equation on any data, then On any data, then after I run it for infinite time, then this is what I should converge to. Okay, and so I sort of have this forward process that I get by running a diffusion equation. And I should mention that this original paper is due to Song at I believe that this appeared in 2019. Okay, so I run a diffusion equation from row zero to row infinity. And again, I've chosen this diffusion equation so that my Gaussian or whatever nice thing. Gaussian, or whatever nice thing I want to get, is the stationary state of this equation. Great. So I've run this equation. Then this is not really giving me the thing that I want. Okay, this is giving me a map that goes from the unknown thing to the known thing. But I want a map that's going the other way. And so how do you get this map that goes the other way? Well, Well, you just try to reverse this process and go the other way. Now, of course, if I try to run a diffusion equation backwards, this is a disaster. And so this is not what you do. When you run this diffusion equation, you're going to be observing a velocity field that your density is evolving. Density is evolving along. And what people do is they train a neural net to learn that velocity field. And then to go backwards and construct this map Y, I'm just going to solve a continuity equation along that velocity. Okay. And actually, that's not quite what people do. So, what people actually do when they run this backwards. When they run this backwards, is they actually also do something stochastic backwards because if you just work with a continuity equation, that is hyperbolic and that is very, very methyl, right? Okay, so let me just say what is the standard thing that people are doing here. So the standard thing. So, we are going to first one, we're going to run the equation dt rho minus divergence of actually let me just write it this. Of actually, let me just write it this way minus Laplacian rho minus divergence of rho x equals zero. Okay, the stationary state of this thing is some nice Gaussian. So we run this equation starting from our initial data. Okay, we observe a velocity field, V, we train a neural net. We train a neural net that is going to try to learn this velocity field up to some error. So let's say step two. So the true object row zero is unknown. What I have are samples from row zero. You're running the samples forward, and they're basically doing this with some kind of stochastic method. With some kind of stochastic method that that's going to run the sample spell. Yeah. There's a ton of things you could say about these implementation details. And unsurprisingly, people have to tune a lot of things to really make this work extremely well. But when it does, right, all of these things you see like DALI that are generating these crazy AI images, they're being Crazy AI images, they're basically all using these kinds of ideas. All right, so we run this equation forwards. We're going to learn and approximate velocity field. Field that I'm going to call V epsilon. And what you should think about V epsilon is that V epsilon satisfies something like this. And actually, let me just say one more thing about this first step. You can't run this for time infinity because you actually have to do this on a computer. Because you actually have to do this on a computer. So you're going to run it for some long time capital. Okay. So this is for just write this here. So this is four time capital T okay. And the property that this V epsilon that you're learning should have is you're essentially going to train your neural net so that So that the true velocity minus this learned velocity, let's say that this in L2 is something like epsilon squared. Okay, so you're going to train your neural net until this happens. And again, this V, which is sort of the true velocity field, you get to observe this V as you are running the process. Okay, but again, Process. Okay, but again, right, when you actually implement this, you know, this is, and sorry, I'm also integrating this in space. When you actually implement this, of course, this thing is going to be some kind of discrete sum that is along the samples that you are sending forwards. Okay, so this is my neural net. This is the thing that I'm observing. Yeah. So the V the V is this equation has some velocity. So I can also just write this equation as dt rho minus divergence of rho v is zero. Or I could write it like that, right? So it's just v yeah. So v, right, v for this equation is gradient of row. Gradient of rho over rho. Okay, I guess I'm writing plus, so this is minus and then minus 6. So you know it. So again, when you're implementing this, this thing is going to be some kind of a discrete sum. And you know this on SIM. And actually, the reason that this method got super popular in this paper by Song. In this paper by Song, is that when you have this special structure of grad row over row, you have some sort of nice cancellation here because of this row. And it turns out that you get something that you can implement very well on a computer. Yeah, so again, you can really say a lot about the implementation details of this thing. Of this thing. But I want to try not to get too much into the weeds of that because that's sort of not the point of what I want to say today. But of course, I guess one thing that I should say is, right, when you only know this V on samples, okay, it's just discrete data. And the whole reason that you're training a neural net is that this V epsilon is a function that is defined everywhere. Okay, and so that means that this v epsilon is something that I can just flow arbitrary things along if I want to go in either direction. Okay, so this is one important implementation thing to say. So let me just say this, right? When implementing V is only known on data points but the neural net neural net the epsilon is everywhere defined. And right, that's the whole reason that you can expect to potentially create things that you have not seen before. Okay, because if I choose some point in row infinity that doesn't get hit by this forward process, I can still run that. I can still run that point backwards along this vector field d epsilon that I've learned. And this is what's actually giving us potentially a way to generate new samples from this unknown distribution. Yeah. So when I actually implement this, I'm going to have access to basically some sort of empirical distribution of row zero, right? Distribution of row zero, right? I have n samples, and so what I'm really using as the initial data for this equation is something more like I could call it row zero n hat, which is an empirical distribution like this. Well, what's going to happen in the way that this is typically implemented is you're doing some kind of like Langevin. Like Langevin diffusion type algorithm. And so you actually don't really like the way that you diffuse these particles is you do some kind of time stepping where some of the time steps are run this particle along Brownian motion. That's one of the parts of the, yeah. Okay. Well, I had this feed epsilon. And now what I want to do is I want to learn this map Y by flowing backwards. Okay. And so the most obvious thing to do would be to just say, well, I just flipped the sign. I just flip the sign in this equation and I run it backwards, but with v epsilon instead of v. Okay, but again, right, continuity equations are bad. They're, right, they're not, they're not very stable. They're very hard to analyze if you don't have some extra structure. And so, in practice, what people do to learn this map Y or to push samples through this map Y. Through this map, Y is we're going to run things backwards. So we're going to generate data by running the equation. Let's see, what is the least confusing way to say this? All right, let me just write something down. And there is a strong chance that I will screw up the signs here. This thing should either be a plus or minus. Let's see. Let's see. Let's just hope it is a minus. And what I want to do here is essentially something like this. So here we go. And so I'm running this equation backwards starting at row infinity. And again, I may have a sign error. An error. Okay. So, and actually, let me call this object rho epsilon because I am technically flowing a long different equation because of my v epsilon over here. And so I don't necessarily know that I'm recovering the same thing as before. Okay, so what is happening here? Um, we are not directly reversing this equation. What we're doing is we're still going to give ourselves some diffusion, but we're essentially trying to cancel out that diffusion through this extra alpha times the velocity field. Okay, if this was the exact velocity field v, then these two things would cancel out. Okay, and so if Okay, and so if I've done a good job of learning v, then somehow this equation should be doing a reasonable job of inverting this one. And again, the nice thing here is that this is not just a continuity equation. It really is a backwards heat equation where this thing has the sign that you like. Okay. So this is the standard thing that people do, these three steps. These three steps. And again, the implementation details of this are, there's a ton of things that you can think about, but this is the very basic. And so what you would really want to know, well, there's actually a huge number of questions that you would really want to know. But one of the most basic things that you would want to know is, well, as this parameter epsilon goes to zero, do I really recover? Do I really recover this unknown distribution when I send things through this map? Okay, so as this error goes to zero, am I going to get back row zero? But really, you want to analyze that question in the joint limit where the number of particles are also going to infinity. Because it turns out that if I keep this fixed. If I keep this fixed as just an empirical distribution of samples from this unknown thing, and I do a better, better, better, and better job of training, and epsilon goes to zero, what happens? You just recover the empirical distribution. Everything will just go back to the empirical distribution. This is this mode collapse phenomena where you don't learn anything new and you don't want that to happen. Okay, so the ideal thing that you would like to analyze in this case is something. Is some kind of joint limit where epsilon and n are jointly going to zero and infinity, respectively. Okay, that's very hard. There's basically no analysis like that out there, almost none. And so what people usually do is they give up. They say, all right, let's just assume that n has gotten sent to infinity. So I'm actually doing this process where I really have this thing row zero. This thing row zero. And then they're just asking the question: if I really have that thing row zero, when I send epsilon to zero here, am I truly recovering this row zero in this backwards process? Are there any questions about that? No, not necessarily, because if this is really v, then regardless of the value of alpha, these two things should cancel each other. Cancel each other. What am I doing? Oh boy. Okay. What do you mean? Like in this training process, I mean, people can add whatever different things they're like, this is another implementation detail that I don't even want to think about, which is just, you know, these machine learning people have some great way of generating this neural net v epsilon that has this property. Yeah. Ah, yeah. I mean, yes, there. So you can also, yes, the things like that are relevant. Yeah. Okay. So this is the standard thing that people do. But I don't remember what the optimal thing to do is, but you definitely want to play with your choice of alpha. You can even make alpha depend on time. And you often want to do things like make alpha depend on time. This is what I really like. There are a million different implementation issues that you can think about for this thing. And hardcore machine learning people do all of these different things. They tune a million different parameters and they get amazing results, but you have to do a lot. But you have to do a lot. Yeah. Okay. Let me mention a few drawbacks about this standard approach. First of all, what you should kind of imagine is that this row zero is very likely singular. I mean, we tend to think that real data is concentrated on low-dimensional manifolds in some very high-dimensional space. So row zero is singular. So, row zero is singular. And in addition, it's probably compactly supported. So, again, if you think about images of cats, pixel values are just between zero and one. And so this thing would live in zero, one to the D for some very large. Okay. So what is going to happen is something horrible is happening at initial time. Okay. You have a very, very singular. You have a very, very singular measure, and you are applying a diffusion equation to it, and so you should expect something kind of crazy to happen. And, in particular, with the heat equation, you have something that is compactly supported. Heat equation doesn't like compactly supported things. It's going to instantaneously send some amount of mass arbitrarily far away. Okay, so again, bad things happen at initial time, and that should worry you when you. Worry you when you are trying to reverse this thing and you start getting close to initial time. Okay, the other thing that's not so satisfying is how do you implement this equation? You again just do some kind of stochastic particle method. So you're also sort of going to be running particles along this velocity field, but to do this part of it, you're doing some Brownian motion. Okay. Okay, and what that means is that this is not a deterministic method. And so people can give some guarantees about how will this behave in the bulk. But again, it's not deterministic. And so there's always a possibility that you have some bad luck. And even if this thing should converge when you send epsilon to zero, right, maybe you get a bad instance and you produce a sample that has nothing. You produce a sample that has nothing to do with your original distribution. It's unlikely, but it could happen. And so there is interest in trying to do this more deterministically. And this would be especially important if you are trying to do this in some kind of application where safety is critical, safety, security, things like this. Okay, this example with CAT images, you know, that's just fun. You know, that's just fun. It doesn't really matter if we end up generating a dog instead. But people are even using these kinds of things to solve optimal control problems. And if you have an optimal control problem that you are applying to something really important, like, you know, I don't know, a self-driving car that you don't want to crash, then probably you would like deterministic guarantees on how you're going to do. And And not these sort of things that are stochastic. Okay, so there's sort of like two things that you should be worried about, right? So perhaps I should really say two big things, because, as I've kind of been saying, there's a million small implementation. There's a million small implementation details that matter. But these two big things that you should care about are: one, you have very bad behavior at initial time for real data and two. Um, this method is stochastic not deterministic. And so we could ask what happens if we try to change things a little bit so that we don't have to deal with these issues. Okay, and so essentially, how do we deal with this second point? We will just simply always have alpha equal zero so that this thing really is a continuity equation. But this means that we are going to have to deal with the fact. That we are going to have to deal with the fact that we have a continuity equation. And that's going to make our convergence analysis a lot harder. And for this first thing, one thing that I've been thinking about with my collaborator Kartik and some of his collaborators at UC Riverside is: well, okay, we know that weird things definitely are happening at initial time. This is a fact of life for any diffusion equation because diffusion is just not. Diffusion equation because diffusion is just not going to like a singular measure with compact support. But you can try to do different things with other kinds of diffusion equations. You can try to design your diffusion to potentially have better behavior. Okay, so what I'm going to talk about in the rest of this talk, rest of however small amount of time I have left. Is we are going to replace this Fokker-Planck equation with just a more general diffusion equation. So we are going to work. So just say so. So this is a more deterministic approach. Let's say a deterministic approach with equation flexibility. And so, what we're going to do instead is we are going to, let's call this maybe one prime. We're going to run the equation. We're going to run the equation. dt rho minus divergence of rho grad p plus x equals zero. And here, what is this p this is going to be part of my velocity field. So in the case of So, in the case of the heat equation, P would be the logarithm of rho. But for more general diffusion equations, you would say that P is F prime of rho for some convex function F. And the most other common choice besides the logarithm is some kind of power function. And when you do power functions, Function and when you do power functions, this is the porous media equation. Okay, so basically, you should just have in mind those cases, but you could potentially do more. Okay, so let me just say that again. So F prime equals log rho. This is heat equation. And F prime of rho equals rho. Equals rho to the m minus one. This is porous media. All right. So we're just replacing step one with step one prime. And for instance, again, if I choose f to be log, f prime to be log, then I'm doing the same. Okay. Step two prime is going to be the same. And then in step three, And then in step three, I am just saying that I'm going to learn this velocity field, and I'm going to explicitly force this parameter alpha to be zero. And that forces me to be deterministic because I'm just flowing backwards along this continuity equation. And so we're going to flow backwards. And I guess what I should mention is the rho infinity for this problem is potentially different, but it is something that we can compute explicitly and also easily sample in high dimensions because it will always be radially symmetric. All right. Any questions about this sort of deterministic, flexible setup? So it turns out m less than one causes some problems with the analysis that I'm about to write down. So actually, we were looking at we were initially looking at m larger than one. And so if you choose m larger than one, If you choose m larger than one, then you sort of fix this problem of immediately sending things out to infinity. Because of course, the media equation has, you know, is fine with things that have compact support. But if your m is now larger than one, actually you want to dissipate your singular measure faster. And so you would expect, okay, maybe I fixed one problem, but I potentially introduced another one. And I think actually what is the ideal thing to. Is the ideal thing to do here is to kind of choose some profile that's going to like interpolate between behaviors. But of course, one thing that I should mention is as soon as this is not the heat equation, running this step one becomes a lot more expensive to do on a computer because you will have to do some kind of density estimation. So actually, the magic of this Of this paper of Isang et al. is they showed that you can learn this velocity field without having to do density estimation of your row that's flowing along the thing. Okay, but as soon as you have something nonlinear, which is essentially what we want to talk about here, you have to do some density estimation. And that's going to make this step one prime more expensive. But this is training that you do once. Okay, and so if you can solve it, then you can just use these methods. Then you can just use these methods. Yeah. If it's non-linear, though, you can't do like Lagrangian, right? You can. And so that's the thing I want to talk about is how do we actually, oh, and sorry, I should call this. How do we now check that this will do the right thing? I'm flowing backwards along a continuity equation. And the nice thing about what's happening over here. What's happening over here is because this is a parabolic equation, I can use parabolic PDE theory to tell me something about how stable this equation is when I make errors of order epsilon in my velocity. Okay, here I have no parabolic theory to fall back on. Well, okay, this is not quite true. The parabolic theory that I have to fall back on is that this V epsilon. That this V epsilon is approximating a velocity field that is coming from a diffusion equation. And that's the thing that I have to hope will work. Okay, so how am I doing on time? Okay, before questions or just before. Okay. Well, I don't want to keep people from lunch. That is a good question that I don't know the answer to. Statistics and probability tend to break my brain. So if I can't write it in terms of an integral, I'm very unhappy. I thought the advantage of like this, like low-range, advantage of like this like logarithm thing is that like you can use bias pool kind of simplify when you want to try to get oh i mean that's this that's this trick that allows you to do the training fast i think get a cut that is great versus just ah okay okay um i have not thought about that but yeah i think that's a good question Okay. But I would presume that if you stick with the heat equation, but you still want to say that you're doing something deterministic, then you should still be able to do that part of it, I would imagine. But yeah, I don't know what would happen once you have a nonlinear equation. Okay, so how do I check that this works? Well, what I want to know is Is row? I guess I probably should have put my epsilons up here. So is row epsilon zero approximating row zero and what I can do. And what I can do is, if I am able to construct the Lagrangian flow maps that are associated to these equations, so what I can say is let y epsilon be flow map epsilon v epsilon. Along v epsilon and let y, I'm sorry, I should say backwards. All right, this is the same thing. So just along V. I can answer this question of how well is rho zero epsilon approximating rho zero by just asking, well, how? By just asking, well, how well is this flow map approximating? Okay, so we can reduce this to does y epsilon approximate y. And in fact, in a sense, maybe this doesn't even make sense because constructing Lagrangian. Constructing Lagrangian flows along velocity fields is very, very delicate. What you need is you need some differentiability of your velocity field, right? So you have classic Cauchy-Lipschitz theory that says if your velocity field is Lipschitz, then you have a well-posedness theory for Lagrangian flows. Then you have these improvements first by De Perna and Lyons and then by Ambrosio that say, And then by Ambrosio, that says, okay, you still need a full derivative, but you don't need it in L infinity. It's good enough if you can get it in LP. And in fact, Ambrosio showed that if your velocity field is BV in space, that is good enough. All right. Well, we kind of want to do something global here. And so the awkward thing with the heat equation is that as you go further and further out towards infinity, your velocity. out towards infinity, your velocity field is getting nastier and nastier. And with the porous media equation, in some sense, the situation is even worse. So For PME and dimensions be greater than or equal to 2 compactly supported initial data. This implies that the LaPro. The Laplacian of your pressure is a singular matrix. And in fact, this means that you cannot, well, okay, no, you can't. You can actually construct these velocity fields. Oh, sorry, these flows, but you cannot use standard theory because this actually falls outside of standard Lagrangian flow theory. Theory. So, in this case, standard well-posed in this theory fails. Okay, but what can you control? It turns out that you can control the following thing. You can control this integral provided that you stay away from time zero. So, this will be some kind of quantity that is potentially blowing up with this small time parameter tau. This small time parameter tau. And this f star is the convex conjugate of this f. And so I first saw a version of this calculation in a paper by Pratam and David. And this is a slightly different version of this calculation. Their calculation, you can only sort of get bounds like this for certain x. For certain exponents m, and this bound will hold for the heat equation and for all m strictly large energy. So no, you have to do more complicated things, which I'm probably out of time to explain. But what is the issue here? Let me just say what the issue is, and there are ways to get around this, and then I'll stop. So the problem is that I don't actually control. Oh, and sorry, there is a square here. Oh, and sorry, there is a square here. Um, when the pressure is really small, this goes to zero. Um, and actually, it's going to zero precisely where this thing is a singular measure, because it has to be canceling out some singularity for this thing to be controlled in general, because this is actually true at all times. And so, what I can do is I can sort of construct Lagrangian flows as long as I know. Flows as long as I know that an individual particle is not going near places where this thing is going to vanish. Because if I stay away from those places, then essentially I know that this sort of thing is controlled, which is actually the Hessian of the velocity. And it's squared. And so then I could use standard theory. And so what it turns out is you need to do more analysis on this thing. But it turns out that actually when you flow backwards, you When you flow backwards, you can show that if you started somewhere where this was not very small, then actually you will not be small throughout the entire evolution. So you get some kind of Gronwald control. And you combine those ingredients with this other Lagrangian flow theory by Creepa and Delelis. And this actually gives you some explicit convergence rates in terms of your parameter epsilon. But what I will say is for these determinists, Will say is for these deterministic things, we get way worse rates than the stochastic people get, which is you know not surprising, and we would like to improve them, but we have tried for a long time, and I think we will just finally put this paper out there in the world. So, should be out soon, and I apologize if I went over, and I'll stop there. What a great talk. I just have a follow-up question. The last sentence you said. How much worse is this? Oh, a lot worse. Yeah, yeah. Like, so they're getting things that are maybe they're even getting the error rate as something like epsilon squared or epsilon. I mean, it's like epsilon to the power that's not crazy. On to a power that's not crazy. And what this is going to give you is it is going to converge at the rate. Let me make sure I write this correctly: one over log one plus one over epsilon, what would show up here? I think maybe a four. Okay, so this is really bad. That is a very, very slow convergence rate. That is a very, very slow convergence rate as epsilon goes to zero. So, when we actually run it, we get very nice results. So, in one of the papers that's out there with Kartik and some of these other people, we get nice results on MNIST and CIFAR, but of course, those are still small to machine learning people. To machine learning people. But for those, we seem to actually see nicer things than you would get from running diffusion models. But of course, you know, like we're not Google, we're not Facebook. They're, you know, they've optimized the hell out of these methods. We tried to do the most fair job we could of trying to optimize both of the things that we were running. So, yeah, I mean, right now, I think the theory is very far away from what we observe in practice. Yeah, it's okay. Here's what I think this is a good question because it reveals something that is quite interesting, which is this. So, what I should say is, right, this will have some dependence on. Right, this will have some dependence on the dimension and on m. And if you want this thing to not have a horrible dependence on the dimension, you want it to not be exponential with respect to the dimension, then what it turns out is that you want to choose m to look something like this. So one plus alpha over d. And then you will get something that is scaling like this parameter alpha. But I think Alpha, but I think this alpha may be showing up in an exponential. And that's why you really want to do this. Otherwise, you have horrible dependence on the dimension, right? You have cursive dimensionality. And so, right, what it's saying is, okay, if you want to get rid of the heat equation, then you don't want to go too far away, especially as you go into higher and higher dimensions. And this is related to this fact that if you This fact that if you start with something singular and you have a large exponent, you are going to diffuse super, super fast. And so you have this horrible velocity field near initial time. But what is possible is that this is the scaling behavior you would want for large values, but for small values, you could potentially do something. But yeah, for probably for this first paper. For probably for this first paper, we're just going to stick to proving things for PME and heat equation. Because it obviously, as you make this app more complicated, the analysis gets more complicated. So just I mean, kind of a different like more cool proposal. So instead of considering this like nonlinear equation we thought of like changing the detail. like changing the like sort of taking a different power of the flash is that because that would help with the sort of less singularity of the oh you mean just like instead of second order you do some kind of higher order oh okay yeah I mean that's that's also certainly possible yeah I haven't thought about that About that. Any other questions? Okay, let's thank our speaker again and yeah, there is one event on the schedule. So there's this job search panel. 