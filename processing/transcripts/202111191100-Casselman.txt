So, first of all, I want to thank everybody involved in this thing, especially Tasha, who did most of the organizing, and all of the speakers, and even the people in the audience. It's really been a very pleasant week for me. Couldn't imagine something better, in fact. What I want to talk about today is Arthur's truncation operator. I'm not going to say very much that's new, but there are some neglected parts of the subject. There are some neglected parts of the subject which I want to bring to your attention. So, for most of us, so let me explain one thing. This text is not for you to read necessarily. It's for me to use in the paper I'm writing subsequently. So, I will skip over large chunks of text. Otherwise, I'll never get through. The important message starts in the second paragraph here. So, for most of us, the truncation operator of Arthur is. The truncation operator of Arthur's is a black box, which people don't investigate very carefully. But it actually has some surprising features to it. And I've been thinking about this for over 30 years now. In fact, my thinking about it began in Lumini when I was giving lectures that Patrick DeLorme has already referred to. What puzzled me at first sight and really stymied me for many, many years was the definition. I just couldn't understand quite where the definition of Arthur's truncation came from. Of Arthur's truncation came from. And in fact, I learned very recently that I was in very good company because gymnasts told me that Delene and Corvallis also expressed some surprise. It's just somehow a non-intuitive definition. That's an understatement, actually, to what he actually said. What did he say, Jim? He thought it was wrong, and he didn't think the conversation should be pursued further. Wow. So I have to tell you. Well, maybe that's not. So I have to tell you. Maybe that's not fair. Maybe that's not fair. So usually when Delene says he doesn't understand something, it means that you don't understand something. Right, that's right. So you seem to have been one of the few counterexamples to that statement. Well, it is very non-intuitive. So I have two goals in this lecture. One is to make it slightly more intuitive, if not explain completely what's going on. And the other is to raise some new features, which are even more surprising, maybe than the definition. Even more surprising, maybe, than the definition of the gyms. And I'll begin with a little history and then go through some origin, some questions about the history of the subject. I should say that some of what I'm going to tell you is known only for a few groups. These few groups include GLN and SLN, and a few other classical groups, and maybe more. It's not so clear. I'll explain what happens later. When I started to prepare this talk, I wanted, it's something I've been. This talk, I wanted, it's something I've been thinking about for a long time as an excuse to think about this material. And I had a number of conjectures which turned out to be false, but I haven't been able to verify exactly what is the case. So this is a report on work in progress. I do have some ultimate goals in mind. One of them is to construct Eisenstein series in a new way. And well, there are a few more as well. So the history begins with Hans Maas. Hans Maas, who defined a kind of truncation operator for SL2Z. And he did this in order to estimate the dimension of certain spaces. However, the version we use today for SL2 at least is exactly the one stated by Selberg in his 1962 talk. Let me recall what the basic geometry of this situation is. We have two groups. We have the group gamma SL2Z, and we also have gamma intersected with the upper parabolic subgroup. Subgroup. And the fundamental domains for these groups are well known. One of them is very trivial, and the other is rather more complicated. The one for gamma comes in two parts, a simple part and a complicated part. The complicated part is compact, and the simple part actually retracts off onto infinity in a very nice way. But what's important is that the simple part is part of the complex, excuse me, the simple part of the The simple part of the fundamental domain for SL2Z is actually part of the fundamental domain for P. And so you basically have a nice, really, really nice part of the fundamental domain plus something more complicated. It's also important that for y greater than 1, the image of the upper half plane above y is a manifold with boundary. I don't have much intuition, but I think of the interval I infinity as... Of the interval i infinity as something like the fiber of the tangent bundle at the cusp. It's very hard to phrase in normal mathematical terminology. So the upshot is the points of the upper half plane come in two different kinds. One are the nice parts and one of the complicated, one of the simple parts and one of the complicated parts. And when you divide this up for all the parabolics, you get the picture on the left. There's a very nice way which I'll come back. There's a very nice way, which I'll come back to later, explaining this by Stuller and Grayson. They introduced something called the canonical plot, and for SL2Z, it's very simple. The upper half-plane parametrizes lattices in two dimensions. And you divide the lattices into two kinds, basically, those which have very short vectors and those which don't. And very short in this case just means that, well, first of all, you normalize the lattice so as to have volume one. So, as to have volume one, and then the short ones are the ones where the shortest vector is less than has length less than one, and the other parts which are called the semi-stable parts are those for which the shortest vector is greater than or equal to one. And so you get something called the canonical plot. By plotting all the lengths of vectors, as you do in the two pictures here and here, you get what Grayson and Schuller called the canonical plot. For other groups, this is an extremely interesting idea, which I'll talk about later. Extremely interesting idea, which I'll talk about later. I just remind you what truncation does in this case. We look at the constant term, which I call c of y, that's the constant term above y, capital Y, and then we subtract off that from F, and we get a function which is kind of a little bit hollow, so to speak, above Y. And then we have a decomposition of my function as F plus, well, it's the truncation is what I get when I subtract. It's the truncation is what I get when I subtract off. And the f, my then my function f is lambda y plus c of y, and that's an orthogonal decomposition, which I write down here. The second part, the c of y of f, is in red because there are two ways of doing this. This is, on the one hand, this is the volume, this is the metric of f on the entire quotient, and on the other hand, it's on the special quotient. And those agree in this case. It's a very, it's a useful fact, which makes The useful fact which makes everything work. There are other properties of the truncation which do it, but I'll not refer to that. I'm interested really in the geometry. And there's a motivation for doing this. One of the basic facts, one of the basic applications of the truncation is the so-called Maas-Silver formula, which is so-called by Harish Chandra. And the point is that when you truncate Eisenstein series, you get something which You get something which is square integrable, and you can actually give an explicit formula for what the length of that truncated Eisenstein series is. And this formula is actually rather interesting. I've written it in the form down here in the integral. Formally, it's a very simple formula. When you write it out, it becomes more complicated because the constant term is more complicated. And there are reasons why this works out. Some sort of regularization process gives a very simple. Sort of regularization process gives a very simple explanation for that. And this again will play a role later on in the subject. For groups of higher rank, so for SL2, it's very simple and essentially due to Silberg. And for groups of higher rank, the subject starts with Langland's work on Eisenstein series. And I think, I'm not quite sure, I haven't read the book on Eisenstein series completely. And I think the subject, his use of Maas Selberg, starts with his Boulder talk, which is a little bit different. Boulder talk, which is a little bit different. And he has a somewhat complicated generalization of the Maas-Tilberg formula for arbitrary reductive groups. And he has a truncation operator, but it's designed specifically for Eisenstein series. It's not a general truncation operator. It's a very strange formula, an enigmatic formula, as I say here. So these can be found in two sections of the written version of his Boulder talk, which probably many of you are familiar with. Of you are familiar with. The most puzzling aspect of Langland's Eisensei series talk is that he uses, he refers to, in fact, ordered set partitions, which are rather a strange notion. I don't think it occurs anywhere else in automorphic forms. And just recently, actually, LeBesse and I have taken this up, and we think we now understand almost all parts of Langland's talk in those two sections. One curious feature is that his treatment is only very, very weakly related to root systems. Somehow, the ordered set partitions play a very crucial role. It's very hard to understand exactly why he does that. I couldn't resist putting a scan of his Boulder talk in here. If I were giving a talk to a live audience, I'd ask all those who have looked at these two sections to raise their hands, but I guess I can't do that here. The point is that it's a Is that he refers to a very pleasant exercise, but I'm not sure exactly who's carried out this exercise. It's very strange. There are some other amusing aspects, for example, referring to L2 as the bed of Procrestes. I don't know, I'm not going to tell you exactly what the legend of Procreates is, but it has something to do with a man who chops off heads and feet to measure accordingly. And I couldn't resist putting in a picture. Procrestes was eventually killed by the Greek hero Theseus. Eventually killed by the Greek hero Theseus, and this is a picture of Theseus killing Procostes. Percostes is on his bed there and about to be truncated. In his Corvallis lectures, this where the modern story starts, Jim defined truncation in very general terms and simplified considerably Langman's version of Maas Silberg, which was crucial in his work. And this is Arthur's version that survived. Arthur is rather modest in the way he writes. He said, by a slight modification of Langman's version He said, by a slight modification of Langlands, we arrive at the following. But actually, Jim has really rewritten the subject quite extensively. Langland's version was not really usable in a very general way. I mention here that there's not much material. There's not many people who have looked into the black box. There's an extremely long, verbose paper by Scott Osborne and Garth Warner. And then there are lecture notes from the And then there are lecture notes from the Friday morning seminar at the Institute. There's a set of rough notes by Le Bes and Langlands in the original typing version. And then there's a very detailed book Le Bes and Balswerde, which is really the canonical reference these days. The accounts are not very different from Arthur's original accounts. They fill in some gaps and simplify things. There are a few small errors on Jim's papers, but otherwise it's basically okay. But now I want to look at the general case. But now I want to look at the general case. So, my original page of notation, I had two pages of notation. This is imitating Jim's lectures at Corvallis, where he gave an extremely long lecture on notation, criticized by Sarah, as I remember. I just want to point out the unusual features. So, first of all, G I take to be a split group with simply connected derived group. There's a reason for that, but I won't mention why. I fix a minimal rational parabolic. I fix a minimal rational parabolic, and basically I fix an epane galage of the nilpotent roots. And I just want to be sure you understand: sigma in my notation is always the roots, and delta the simple roots. Sometimes this is reversed. There's no canonical choice of these. And when I put a bar around a torus, that's always its connected real component. I fix, fixing the data that I've done here gives a canonical involution, which on classical groups. Evolution, which on classical groups just takes it into the transpose inverse. And I fix my maximal compact and I pick gamma. Now, it's an interesting point, and I think underappreciated, that for split groups, choosing the canonical involution is essentially equivalent to choosing both the real compact subgroup and the integral structure on the group. This is because of Chevrolet's approach to split groups. This plays a role implicit in almost everything I do as far as I know. On almost everything I do, as far as I can see, I have two things that are like symmetric spaces. First of all, I have my x, which is the real symmetric space. I divide out by the center of g, but it's also convenient to just have g mod k, which for reductive groups is not necessarily a symmetric space. It has a central component. The group acts discretely on both x and y. And because of my assumptions, we can identify this is because of class number one and Of class number one and strong approximation, we can identify my quotient of x by gamma with the idelic quotient. The reason I do this is because at some point when I was preparing this lecture, I was interested in computation, and computing with the ideals is almost impossible. But there turns out to be some nice algorithms where you can transfer computations to work with gamma instead. And as I mentioned here, it's significant that the canonical involution gives rise to both. Involution gives rise to both K and G of Z. Now, in this business, if I work with the Adele groups, it's things that are sort of hidden. But if I work with the real groups and the integral points, then it's not quite clear. But there's a difference in the parabolic subgroup. Some parabolic subgroups are just not as good as other parabolic subgroups. This is measured. It's some kind of DF. This is measured, it's some kind of Diophantine measure in some sense, so that the rational numbers can be measured by Diophantine height. And there's something similar that goes on here. So the choice of sigma, of theta rather, and integral structure distinguishes them. The P sub theta, which are the parabolic subgroups containing my given minimal parabolic, are very special. That's because they somehow inherit a really good integral structure, no ramification involved. And in fact, it'll become clear. I use subset notation often. Often I refer to these just by theta rather than by p theta. And again, in this case, because of class number one and so on, the gamma acts transitively on the parabolic, on the Grassmannians. And as I say, I was interested originally in some algorithm that I was able to compute with these. So actually I'm able, one result of this is that I'm able in some sense to compute. This is that I'm able in some sense to compute Eisenstein series for arbitrary groups. It was fun, but it didn't actually work out to very much in the end. And I'm not going to work with G mod gamma. I'm going to work with the spaces modulo gamma. And that's because this enables me to avoid a lot of reference to induced spaces. Are there any questions? Would you be willing at the end to say something about the simple variant of the Euclidean algorithm? Simple variant of the Euclidean algorithm? No, I cannot. All right. Yeah, I wish I could have done that, but no, it's too inaccessible. It's on some other computer. I can't do that. I can say only that you have to know how to do computations on an arbitrary split group. Group and the group rather than the Lie algebra. So there's a whole hierarchy of algorithms dealing with structure constants on the Lie algebra and doing explicit computations and nilpotent and unipotent and the unipotent groups and so on. And it just extrapolates on those. I don't know. Not many people have tried to do computations on arbitrary split groups, but there is a large literature on it. Bill, would you mind repeating your hypothesis? So, would you mind repeating your hypotheses on G? It's split, and its derived group is simply connected, and it's over Z, over Q, rather, but I give it an integral structure. Does that answer your question? Absolutely. Thank you. Okay. You can see where they're not necessary. In the long run, all of these will be unnecessary, except for split. Split is somehow extremely important for what I'm talking about, and although there are, I'm sure there's. I'm sure there's some expansion to other groups, but at the moment, split is very important. So here's one way in which the PÎ¸, the standard parabolic subgroups, are important. P acts transitively, every P acts transitively on these, and the Iwasawa decomposition says that. But if I choose my P equals one of the standard ones, then I get a real analytic map from the symmetric space to AP. The symmetric space to AP and then to AP modulo at center. Actually, that's not quite correct. And then I get a homomorphism which is invariant under this and into the little A, the center of P, MP. And the important point is that if I choose my P other than a standard parabolic or some vial transform of it, then there's also a matter. There's also a map onto its center of m, but it's it's somehow not quite the right one. We want something, in this case, the k interacts with the integral structure in such a way that things get messed up. So I define my sigma p for non-standard parabolics to be just an integral transform of the one I get for the corresponding standard parabolic. So as I say here, this maps to a theta, not to AP. So this is an extremely pointed. This is this is an extremely point. It's hidden in the idyllic treatment because you just automatically choose all these things and it falls out without actually. So this is not a democracy of parabolics. I think there's some interesting arithmetic to be investigated here, but I can't do it. So my A theta is a, it's basically the center of m theta. And in there I have an obtuse cone and an acute cone. And these can be described very explicitly. And these can be described very explicitly and very simply in two lines. If I take the minimal parabolic, and I introduce this notation, which is not Jim's notation, I find that if I read Jim's papers, it always takes me about two seconds to transform between Tawhat and Taw. And this causes me a lot of trouble, so I decided to just obey my whims and put in some graphical device. So this is the acute, and this is the obtuse. Very simple. Yeah, those two. Um, yeah, those two seconds are always very annoying. I have to reI have to haul stuff up from my hard disk and visualize this or visualize that. So I decided to make the visualization explicit. And those give me functions on every parabolic quotient of y and x. So that's pretty much notation. Now, the secret of, at least in far as I can see, the secret of understanding the truncation. The truncation is to begin with some toy models. So, I want to explain, I chose the word toy from Peter Sarnik's talk. And so, I want to explain what those toy models are, but I'm going to begin with a very general fact which automatically motivates Jim's definition. So, let me tell you a very wonderful fact. Suppose I have an arbitrary convex polytope in Rn, and suppose it's defined by affine inequalities, fi less than or equal to zero. Less than or equal to zero. And then if I take a face of C, it will be the intersection of places where F is equal to zero. And so I define the exterior of that face to be the place where f of i is greater than zero for the ones which are zero on f. So here's a picture of the exterior of one face, and here's a picture of the exterior of one of the vertices. And if you look at the definition, you realize immediately that the exterior of C is just all of Rn. So these are not quite arbitrary. Not quite arbitrary polytopes, but even infinite ones, as long as they have some locally finite criteria. And the theorem is, it's very wonderful, it's a truncation formula for the Euclidean geometry, which is that the characteristic function of C in this case is an alternating sum of the characteristic functions of its exteriors. And this is really the basic motivation for Jim's definition, although I don't think Jim had any idea that this was. Think Jim had any idea that this was involved. But if you sort of look around, this makes it entirely plausible that his definition is the right one. I think Delene would be happy with this observation. So the proof is actually not very complicated. It's a question of calculating Euler characteristics. And in the cases we're interested in, we're really interested in only two cases. One is where C is a simplicial cone. CSS and Polishelkone. This is what Opdom would call the Kasselman region over here. It's not the anti-Kasselman region, but the Kasselman region. I was pleased to see that his diagram is exactly my diagram. So that one case is where we take a simplicial cone, and the other is where C is the convex hull of a Weyl group orbit. Those are my simple models, and they are both very instructive. So in case one, where I look at the simplicial cone, we're looking at the tideline. The simplicial cone, we're looking at the tiling by coordinate oxons. And then it's actually trivial to prove what I call the truncation formula. It's just a question of the binomial theorem. This is less than 1.1 in one of Jim's papers. And then there's a second tiling, which is also very interesting and not referred to explicitly, I think, in Jim as such. But if I have a convex region, I can parametrize, well, I can partition the Well, I can partition the space according to what the nearest point is. So, in this case, here's my region, and then I have the points here, the nearest point of the region of the convex of C is on this face, and here is on this face. So I partition off the space according to nearest points. And now, this is very nice in this case. Even for the case of a simplicial cone, it leads to a not quite trivial result. Not quite trivial result. We can apply the truncation formula to each cylinder over a face. So here's a face, and the cylinder over the face extends infinitely far in both directions. And I apply the truncation formula to that. That's a convex polytope, although infinite in dimension. And then I sort of look at all of these together, and then I can construct some associated. Regions by the following, I take the conical span of certain combinations of roots and co-roots and fundamental weights. So here are the weights and here are the roots, and I take various combinations of the spans of those. And I take an alternating sum of the combinatorial lemma, which is usually these days called Langland's combinatorial lemma, but it's actually due to Arthur, significantly different from Langland's own combinatorial lemma. Its own combinatorial lemma is that the alternating sum of these things is equal to zero, except when delta is actually empty itself. And that's a very, very valuable and elementary observation. It gets you a long way. I've actually proved it here. So I claim that what it is, it's a link. This combinatorial lemma is a link in a chain between the nearest phase partition and the coordinate tiling. And I've explained that here. And I've explained that here in two dimensions in a very simple way. Running across the top, we have the partition according to nearest points. So here's the full space here. And then now under each one here, I give the corresponding coordinate partition. So this breaks up into an alternating sum. This is the characteristic function of this cone. And I break that up into an alternating sum here. And I break this up into an alternating sum. And I break this up. Up into an opening sum, and I break this up into on. And it turns out there's a very simple way to get cancellations. And what you're left with is sum of plus this, minus this, minus this, plus this, and it gives you zero. And that's what the fundamental limit states. In two dimensions, it's a rather trivial fact, but already in three dimensions, it's somewhat non-intuitive. I could draw a picture of it, but I won't. It's not worth the time now. So the second simple model I have is now. The second simple model I have is now instead of taking just a simplicial cone, I take the vial convex hull of an orbit of a point. And again, I get several, well, I get the nearest point partition, the nearest face partition. And then the truncation formula becomes an Eisenstein series. So the point is that the faces of this convex hull correspond to what are called the parabolic subgroups of the Weyl group. And so when I take a sum over all faces of certain dimensions, Faces of certain dimensions, that corresponds to looking at an Eigen size series of some kind. And when I, the truncation formula then becomes that the characteristic function of the convex hull is an alternating sum over faces, over standard faces, which would be this one and this one, of certain Eisenstein series, finite Eisenstein series of the obtuse characteristic functions. This is working with the vial invariant functions. With the vile invariant functions is a nice model for automorphic forms. It sometimes prevents you from making very stupid mistakes. I recommend it highly. What's interesting now, however, is that this picture is a number of things, but one thing this picture of is the compactification of the torus. What's going on here in those terms is that if I travel off to infinity, I get orbits of the A acting on, as I spread T out, this becomes wider and wider. out this becomes wider and wider and I get eventually eventually approximate A orbits on some compactification. I'll refer to that mildly later on. So now I call this the truncation formula. It's well known in classical geometry, but I learned it from a paper of Michel Brion. It has an active life in some sense these days, but not necessarily for this case, but for lattice convex. But for lattice convex, convex lattice regions instead. But Michel Brayon uses to find a very striking formula for the Fourier transform of polyhedra in terms of tangent cones and vertices. What's striking about this is that you don't have to worry about faces other than the vertices. Somehow, a number of things cancel out by some regularization process. What's striking for us is that Bruno's formula is actually Maas-Silberg in a different guise. This has been elaborated. Eyes. This has been elaborated on in papers by Jacquet and Lepid and Rogovsky and others. It's a curious formula. I don't really understand it in some sense. It's not, I mean, now that you know it, you know it, but it's somehow I didn't anticipate, one doesn't anticipate it. Deline didn't apparently not anticipate it, for example. I do have a question, which it just might make it a little more intuitive. If I take any smooth convex polytope, I say polytope at any smooth convex region. Is the limit of ones with a finite number of faces? Is there some kind of limiting theorem that explains what's going on? Some kind of analysis? I do not know. Now, the key to understanding truncation for the arithmetic quotients is basically depends on the partition, which is well known in some sense, but I wanted to tell you that there's really an optimal way to partition arithmetic quotients. Partition arithmetic quotients. And this can be found in the work of Stuller, Grayson, and Harder. Sort of, I'll explain the sum problem with the exposition. So it gives you a reduction theory for arithmetic groups. It doesn't use Eagle sets, which I find extremely satisfactory. At the moment, this theory of these people seems to be complete only for some cases. It's not quite clear to me which cases work and which cases don't. There's some open work to be done. In which case, it's done. There's some open work to be done, it's an awkward situation. Anyway, I can explain the basic idea. As I've already explained, if I look at GLN modulo O and it parametrizes positive definite quadratic forms, and then if I have a lattice, I take L equals Zn, for example, then I can associate to that something we've seen before for SL2, namely its canonical plot and its canonical profile. So I scale my lattice, given a metric. Given a metric, I scale the metric so that the volume becomes one. I say scale L, but I'm actually scaling the metric so the volumes become one. And then we're looking, the symmetric space parametrizes lattice's modulus similarity. And if I have any sub-lattice, not of the same dimension, but of some smaller dimension, I associate a point in R2, namely m is the x value, and the log value of volume of m is the y value. Is the y value. And by convention, the point zero has volume one, and by assumption, the lattice itself has volume one. So this gives me a plot. Here's a plot for SL2, some point in the upper half plane. And here's a plot for SL3. So I've taken some arbitrary points and I've scaled them. So the parallelo piped they span has volume one. And I get that. And this is this thing here. This thing here, this blue line here is what's called, what Grayson calls the canonical plot. Stuller and Grayson differ very little. Grayson made a coordinate change to logs instead of multiplicative. It made it a good deal clearer. This is actually a fascinating diagram, but I don't have time to explain it. Almost every phenomenon you see here has some interesting explanation. There is a real theorem in this subject, which is highly non-trivial. Here are some sample canonical plots. There's a real theorem in the subject, which is a Stulet. Theorem in the subject, which is a Stuller and a proof made very transparent by Grayson, which is I get this plot, this profile, and the vertices of the profile, they come from lattices of sub-lattices of different dimension in Zn. And the point is that these vertices of the profile come from a flag. So they're actually, you get L1 included in L2 and so on and so on. It's a highly non-trivial and very beautiful theorem, actually. And that's the crucial fact. Actually, and that's the crucial fact in the Gratian-Stuller-Harder method of parametrizing, of describing the upper half, well, the symmetric spaces. So the point is that its stabilizer is a rational parallel subgroup. So for every point in the symmetric space, we attach canonically a rational parabolic P. And so we have a partition parametrized by rational parabolic P. It agrees with the classical. P. It agrees with the classical one in case we take SL2. And well, it's just a beautiful thing, I think. If I take my gamma and GLNZ, then these regions are, well, they're compatible. So these things are compatible with the action of gamma. And that's the point. Somehow, my AP is not the natural, excuse me. It satisfies this. And so this is a gamma invariant for. And so this is a gamma invariant partition, which is extremely nice. And this region is stable under NP and it's also stable under that. And well, so now we have exactly what we had for SL2. We have regions which embed both into the quotient by gamma and the quotient by gamma intersect P. Sorry, which G's does this apply? Which to what? For which G's? Because you know, Siegel introduced Ziegel sets because he wasn't able to prove. Because he wasn't able to prove, for example, the finiteness of volume of the quotient without introducing. I mean, when he introduced Ziegel sets, it was a major development for him. He could do, of course, Minkowski did DLNZ. So I'm asking which Gs, this theory you're describing, which I'm not familiar with, it works for which Gs? Ah, well, that's a good question. I'll answer your question now and say more about it. Question now and say more about it later on. So the answer is: I don't think anybody knows. That's the short answer. There is a theory due to Grayson, Stuller, and well, due to Stuller for GLN and SLN. And then Grayson extended this to classical groups in a first paper. And then in a subsequent paper, and this theory for the classical groups that Grayson looks at is extremely precise. He tells you exactly what happens. What happens is that for split groups, That for split groups, somehow you don't have to worry very much. The obvious thing is true. For other groups, you have to choose some parameter t in the positive file chamber. And that's sort of a minimal value of t. This value of t is probably one determined by Arthur in one of his papers as well. There's a very simple characterization in Arthur, and that's probably the one that Grayson chose, although I haven't investigated. Now, suppose, however, Now, suppose, however, if you go away from the classical groups, split classical groups, in fact, then life becomes a little complicated. And there's a theory due to Kyberend, which is good for groups over function fields. Chi-Berend doesn't use lattices, he uses something he calls the complementary polyhedron. Gratian and Stuller and Harder have applied Behrendt's ideas to arithmetic groups, but there's some ambiguity somewhere. Some ambiguity somewhere. I'm just confused. I've written to Stuller and Harder and gotten no reply. It's just not clear to me for which groups. In principle, for groups where the Dinkin diagram is simply laced, everything in Harder and Stueler works. But if there are multiple links in the Dinkin diagram, then there's some confusion, which I don't know if it's real confusion or if it's my confusion. It's something to be investigated, but it's awkward because you have this. But it's awkward because you have this half-baked work by Stuller and Harder, which it would be nice to see finished completely. But it hasn't been. I don't know what more to say. What's really interesting is, I can't resist this because this is one of my favorite topics of incomplete mathematics. What's really interesting is that which value of t you choose is not only by Arthur gives a very simple characterization, but in harder. Characterization. But in harder, in Grayson's work, it becomes clear that it has something to do with ramification of the group. And that somehow your reduction theory depends and a very should depend in a very precise way on the ramification of the group involved. In Harder and Stuller's work, this becomes a little more apparent because they work with a building, and in principle, they work with arbitrary compact subgroups of the Adele group. But in practice, it doesn't seem to be. Um, but in practice, it doesn't seem to be so clear. It's a very interesting domain of investigation, I think. I think bare random construction doesn't require the hello. I think bare end construction doesn't require G to be split. I'm sorry, I can't understand you, Joe. I was saying that bare end construction, the complementary polyhedral does not require G to be split. No, it doesn't require it to be split. No, it doesn't require it to be split, but the question of Dinkin diagrams is a little funny. We can talk about this some other time, actually. I'd be interested. If you've looked at their papers and understand it, I'd like to know, but certainly don't assume it to be split. Split, for split, it's almost, I'm not even sure what happens for quasi-split groups, but for split groups at least, your value of t is zero. And for other groups, you get some other value of t. The one, the one in Arthur's paper almost certainly. And Arthur's paper almost certainly. Okay. Any other questions? So for SL2, we just get the usual thing. So here you can see that what you get is somehow... So the good parabolic subgroups are the ones that are hit by this line. There are exactly two of them. So in general, probably what's true is that for split groups, it's just the Weil group transforms of the standard parabolics, for which you don't have to worry about delivering. Have to worry about Diophantine heights. So I get this assignment of P. So I get this partition of a group and then, well, it's related to the boundary components and the Satake compactification, which I won't say more about. But we get projections from X of G onto a boundary component and the Satake compactification. And I also have this AP. This is actually a misprint here. AP. This is actually a misprint here. This should be A theta. As I said before, this should be A theta instead of AP. And then here I'm a little more precise. If I choose this, then so then my very explicit description, which is certainly everybody in the literature has something like this. In this case, again, it's a little more precise. In some sense, you know exactly what this domain attached to P is in terms of what happens on the boundary. In terms of what happens on the boundary, so the interesting group is the interesting part of the partition is associated to G itself, which Harder and Stuller and Grayson call the stable semi-stable points. And so you have a description by induction, so to speak, of how things work. So what happens is that you can see that you can make some definition by induction. It's not as useful as it might be, but it's very useful. So the stable, the semi-stable parts of the The stable, the semi-stable parts are the part which don't belong to anything else, and you can make the definition by induction along those lines. So, right, so I mentioned Diophantine height here. It's an interesting business. Anyway, so I have for every p, I have a function sigma p. So the theorem, yes, the theorem is this, but I won't. Is this, but I won't say anything more about it. I will say something. So it depends on the fact that you can explicitly compute what the canonical profile is on the A orbit, and that somehow determines what happens on the wrist. It's a very, very nice description. So it's a very precise version of reduction theory in principle. And well, I do this for the t not equal to for t equal to zero is very. not equal to for t equal to zero is very simple and then excuse me let me drink some water so then I can actually look at what happens when I look at this partition on the orbit of a minimal parabolic and then you get a picture like this so as I said these are related to satake compactifications and what's nice is that we get what I call the finite model So we get what I call the finite model of what's going on. So the finite model, that is to say, the Weyl group, the hull under the Weil group is actually somehow occurs as a submodel of arithmetic quotients. And in fact, in my calculations, I actually did some calculations of Eisenstein's series of truncations, and somehow the Weyl group keeps occurring over and over and over again in the computation. It's some strange thing which I don't really understand very well. Which I don't really understand very well, but may not be important. So, inspiration for syllabus construction comes from results of Harder and R. Simon, which classifies vector bundles. And as I say, you describe the semi-stable sets by excluding all the rest of them. And well, what's useful about the lattice theory of Grayson as opposed to the Grayson, as opposed to the complementary polyhedra of Harder and Stuller, is that you get something called p-profiles as well. This is probably okay for complementary polyhedra, but I haven't worked it out yet. And that turns out to be extremely important in understanding how truncation works. I won't say anything more about that, except that I'll refer to it simply later. The P profile gives somehow a minimal bound on the G profile. So So, as I say, the situation for SLN and GLN is ideal. Grayson extended this in a very beautiful paper, actually, where he does explicit computations. He also extended his technique to lattices and the Lie algebra, but there he has some trouble, and it's just not very precise. One would speculate that you can generalize his second paper where he deals with the Lie algebra for split groups to prove a good result, but that's not obvious at all. At all. His techniques don't seem to do that. And then I mentioned Chai Marant and Schiller. And some confusion. It may be my confusion or it may be their confusion. I'm just not. But as I say, they haven't. It's strange that they haven't actually published anything. They just keep producing more and more lecture notes, which you can find around on the web. They started with some lectures in Trieste, where they're very ambitious. There's some confusion. Okay, so I have a little bit more time. Let me explain what I have to say about truncation because there's not much. So the partition of X gives rise to... Hello? Hello? No, somebody said something. The partition of X gives a crude cluncation. You just multiply it by characteristic functions. And there's a very And there's a very obvious if you if you follow you apply the combinatorial lemma you get a very simple definition along the lines which I mentioned here. This is it. So this is what I call the true the crude truncation on the symmetric space. And it just applies to the function I multiply by the characteristic function of the characteristic functions of the different pieces. And this is exactly mirrors, this is another simple model, if you want, for Arthur's trunk. Model, if you want, for Arthur's truncation. But now you can realize Arthur's truncation is almost exactly the same, except that where I have f in this equation, I'm going to replace it by a constant term with respect to p. And that's exactly Arthur's. So the theorem of Brillon somehow gives you context for understanding what the definition of Arthur's truncation should be. I won't give all the different I won't give all the different things here, but you can see what the definition is. So, Arthur's truncation is now lambda gg as opposed to omega gg. And this is what the definition becomes. And you understand it better because you have these simple models which seem to work out very well. So, again, you can introduce a parameter t in the truncation, and then you get thing. And then what's very nice is a very simple application of the notion of p-profiles. Of p-profiles is that outside if so, if I take a parameter t, that gives me a region of semi-stable, relatively t semi-stable lattices. And that gives me a region in the symmetric space. And what happens is that Arthur's truncation agrees with it, but it doesn't modify F inside the semi-stable points. And so as you take T off to infinity, you get more and more, a better and better approximation to F. And more, a better and better approximation to have. Of course, you can make similar definitions for each Levy factor. And then you can carry out the analog, and you can make projections associated to parabolic subgroups as well. And you get a definition. And then you apply, in this case, we start with a definition by the truncation formula. And if we apply the combinatorial lemma, we then get a truncation decomposition analogous to the nearest face decomposition. And that's a very simple thing. And that's a very simple thing. And that's, well, I'm not quite sure exactly how that's used in the literature, but it is very common. So, the number of open questions which I want to pose. So, what happens is that Arthur's truncation is an orthogonal projection. And that comes from a calculation of constant terms, which is very simple, actually, and very nice. And my definition is the proof works exactly the same here. The proof works exactly the same here as it does in the classical case using Ziegel sets, or almost exactly the same. And so the truncation with respect to G is a nice orthogonal projection. And however, what you want to know is, you know that for all the other truncations that we have, all these simple models, the different pieces corresponding to P also give you orthogonal projections. And so that's my first question. Is Arthur's truncation? Is Arthur's truncation applied to P also an orthogonal projection? This must be known to somebody, but I haven't seen it in the literature. The answer almost certainly to question A is yes. There are a number of examples. It looks to me, after doing some examples by computer, it looks to me like it's a simple, I just have to get my bile group combinatorics right. But that leads to a more interesting question. So, suppose that we do have an arthritruncian orthogonal projection, what is the Projection. What is the formula for the norm of those, the L2 norm of those projections? And for this, I have an extremely radical equation which I don't completely believe, which is that in spite of the fact that Arthur's truncation is not local on Satake compactifications, it looks to me like it behaves as if it were, in the sense in which the L2 norm on gamma quotient is the same as the L2 norm on the gamma intersect P quotient. On the gamma-intersect p-quotient. And there's some evidence for that coming from the Maas-Silberg formula. But I don't understand what's going on. It's a puzzle to me. You might wonder why. So the literature is quite nice. There are lots of good applications of Arthur's truncation already, but there are some which would be much nicer if you knew that the second conjecture B was actually true. Or in some version, some version of it. Or in some version, some version of it, some version of it has to be true, but which exactly I don't know. Anyway, there'd be lots of derivations, but the main application I have in mind is a new construction of Eisenheim series associated to square integral homomorphic forms as opposed to just cus forms. And there's also in the back of my mind as a version of the trace formula hinted at by work of Sakhalarides for GL2, which I think would be very nice to see. I have a lot of references, I won't say anything about that. References, I won't say anything about that. All I will say is, thank you very much.