Experimental tests on quantum causality. Over to you. Thank you for the invitation, Sedge, being here. It's not easy to be the speaker after Marcus, so I will try to remove Marcus. So we go to photons and we try to discuss a bit about quantum causality. And I would like to show you a bit of perspective on the experiments that we've been doing in these specific topics in the last few years. Topics in the last few years. So it's really a real pleasure. It's a picture of being in Barnes, but it's the pleasure of sharing with you this session. So, my goal would like to be to introduce the concept of causal structure briefly. This is a powerful tool that allows us to properly investigate the boundary between quantum and classical correlations. So then, we like to briefly review some of the basic concepts. Some of the basic concepts, such as the inequalities. And then I would like finally to move on some tests that we have been recently performing on complex quantum networks. So let me only try to provide you with the big picture. We want to carry out causal inference, and the aim is to decide which causal models are compatible with observed data. You may have some very simple cause and effect structure, you may have some more complex. We have some more complex ones where the causal explanation between the observed data and what is behind is more complex. But then the key point is always to take data and according to the data, you can see which causal explanation is compatible or not with your experimental observation. We have seen a strong growing interest in quantum causality in the last few years, even if you have some difficult. Years, even if you have some different subfields, I would say. We have seen indefinite causal structure, and we mentioned the works by Chaslav, Bruckneff, by the experimental work by Phil Walter. This is not what we're going to discuss today. Then we have another research line, which is on non-classicality in the causal framework, where you try to investigate whether you may have some quantum advantage on infering. Advantage on infering a causal structure. And this was specifically the research line undertaken by Kevin Resch and Rob Speckens. What we would like to see today is to briefly introduce the concept of directed acidic graph and see how this can provide us a powerful tool to try to investigate in which scenario you have a departure between classical and quantum correlations. And quantum correlations. This is a well-known concept, but let me very briefly introduce the notation I'm going to use. We talk about the rig acidic graph. We have some nodes. The nodes are the variables which are causally connected in the DAG. We have some arrows which identify a causal connection between variables. And if you have an arrow connecting xj with x, xe with xj, this means that you have a Xj, this means that I would have direct causal influence from XE to XJ. Then you can introduce the concept of parents of a variable, which have all the nodes that can directly influence the variables. You may have some Markov condition where you see all the variables, how the evolution on the different events is happening, and then you have an acidicity because otherwise it will be some kind of you are influencing your father and so on. Influencing your father and so on in some kind of loop. And so, what you have is that you can write down a DAG which describes your experiment. And depending on the DAG, which describes your experiment, this causal structure can impose some constraints among the variables you are observing. For instance, when we have this very simple structure, which is, for instance, the one that we're using on the clinical trial. We're using on the clinical trials. You have a medication, a placebo that you give as a treatment. This has an influence on the recovery. And you ask yourself, is there any latent factor which somehow is correlating treatment and recovery? Then you can move this very simple investigation scenario to a causal structure, which is written on the right side, which is a so-called instrumental test. And according to this data, And according to this tag, if you consider only classical variables, you will find some causal constraints on the observed statistics. Such a framework, and then what we can infer from causal constraint. From the experiment, we take some statistical data and we can see whether our data we carry out a causal infinity. We carry out the causal inference, and the data can lead us to validate some causal constraints. So, from the statistical data, you can exclude some causal structure. This is what's happening for bad inequalities, for instance. So, you have some data, you have a causal structure, and you may find that your causal structure give you some constraints, but that your data are violating, and so they're incompatible with the causal structure you are assuming. And then you can use. And then you can use this ingredient when you combine statistical data with a causal structure. You can combine these two ingredients to develop some kind of certification of non-classicality. This means you believe in a causal structure. You have some statistical data. And then combining these tools, you can then identify some new tools to certify the non-classicality of physical systems. Of physical systems. This is somehow the big picture which is behind today, my today's contribution. The most standard scenario that we can analyze when we talk about quantum foundation is the best scenario, which is now pretty easy to formulate as a DAG scheme. When you have a best scenario, you have two parties, Eddie's and Bob, as shown on the DAG structure on the left. On the left, you have the measurement input x and ypsion. When you do a bail scenario, you assume that the two observers are independent. Then x is not influencing epsilon and vice versa. X and Ypsion can only influence the accessible variables A and B, which are your observables. Then, when you do a standard bell test, you assume that you have an eigenvariable, the local eigenvariable. The local eigenvariables, which is connecting A and B. So, this is a data structure that we are assuming. You can take this data structure, you can then see which kind of constraint you obtain on the different probability, and all this constraint will then lead to the CHSH inequality. So, the CHSH inequality is somehow a constraint on the observables which arise from the DAG structure. The dark structure which corresponds to the best scenario. And we know that you can violate all this inequality. So now when you combine the violation and you combine this together with the physical structures that you believe to have realized, you can then certify entanglement between the two systems. This is what happens when you consider a bell scenario, but you can also But you can also move this to a so-called prepare and measure scenario, a time scenario, where you again have now two different parties, which they actually prepare quantum state, send quantum state, and measure quantum states. Now you can take this experiment, refresh it as a dungeon structure, you will have measurement inputs, you will have accessible variables. You will have accessible variables, you will have likened variables. And then again, your DAG will imply a kind of constraint on the observable data. And then if you combine this now with a dimensionality assumption, all these structures can lead to a dimension weakness. So when does this then imply? This then imply when you achieve a certification of non-classicality, you assume a power of the experiment, and in this specific case, you add a dimensional assumption and you see that you get some constraint. If you validate your constraint and you believe in your data structure, you can then use this to certify the dimensionality. So, this was a bit a way to rephrase pretty simple. Pretty simply, what you can tell about two standard scenarios: the PAM, the prepared measure scenario, and the inequalities. And then, what I've been doing is this is a strong collaboration with Rafael Chavez in the last few years. You can move now this approach to investigate other scenarios where you have dug structure and you use the DAG structure to find some constraint and you ask whether you can violate this constraint using part two resources. Called create using part two resources. A first one, on which I'm not focusing, but only want to cite it, is the instrumental scenario I've shown you before, which is shown here and which was deeply used by deeply investigated by Judy Pearl, where you have the following scenario. You can ask yourself, may I identify an inequality for this instrumental scenario? May I violate Mario, may I violate it if I have a quantum resources? And we prove it that indeed this is possible in 2017, in 2017, 18 using entanglement. So we realized this scenario here, Lambda was a quantum resources. And indeed, by using the quantum resources, we could show that you can indeed validate the inequality that you can derive from. That you can derive from an instrumental scenario. If you want, this is a way to show that you may have a classical to quantum departure, even in a scenario which is simple than the best scenario. Because while in the best scenario, Alice and Bob cannot communicate, in this instrumental test scenario, you have a direct arrow which connects Alice and Bob. So this was a bit to provide you. This was a bit to provide you the framework. And now one can ask, can I use now these tools to investigate more complex data structures such as quantum networks? And this was a bit now the research line on which I would like to provide you some hints on our last results. So you start from a base scenario. A best scenario is a pretty simple scenario because we know it. We know it since a long time. And moreover, in the best scenario, you have only a single Lambda model. This means that the local set of distribution allowed classically is convex. So it's pretty simple to characterize the set of correlations. Now, one can try to move to more complex scenario, such as the one I've shown on the right side. And now in this complex scenario, you may investigate this. You may investigate different nodes, different sources, different observables, different measurement stations. And this is what we want to investigate now. So in particular, we are interested to investigate some complex scenarios where you have independent sources. So where you have independent Lambda model, where you associate a Lambda model to each individual source. Individual source. So, while you have, in the best scenario, only one source that you would like to investigate to certify the quantumness, in these independent source context scenarios, you may have many, many sources and you want to certify that indeed you are observing some kind of quantum correlation, which emerge from your scenario. So, what can be the interest? So, you will have to demonstrate monolocality in complex quantum networks, and the goal may be. And the goal may be to certify quantum mass and then to exploit it to carry out quantum cryography, but also you can use it as a different approach to certify randomness using a quantum resource. The first scheme that has been investigated is the so-called bilocal model. And this model was already investigated years ago by Cyril and Co-Ort. Ago, by Cyril and co-workers, not even that approach, but the approach obviously perfectly coincide. And so, on the upper level, you have what is a standard GZ experiment where you have three partners, Alice, Bob, and Charlie, and a single lambda model that you would like to disrupt. Instead, when you carry out an experiment on the locality, as shown on the lower side, you have two different. Other side, you have two different sources, lambda one and lambda two. And now your goal is to show that what you observe is not compatible with this tag structure. So you can take this tag structure where you have two sources, lambda one and lambda two, three partners, Alice, Bob and Charlie, three measurement settings, X, Y, and Z. You can derive an inequality which characterizes the set of correlate relations that would be known in Commerce. That would be known in converts, and then you would have to see whether you are able to violate this set of correlations. So, this is a bit the summary of what has been done using this bilocality scenario. We did the first experiment in parallel with the group by Jeff Fried. So, this was in 2017, where we implemented this violation in this bilocal network. And then this experiment. And then this experiment was later on replicated with more complex scenarios. So our experiment, which is from the left, then in 2019, the experiment was repeated by the group of January Bank, where they could, while we carried out the proof of principle experiment, they could somehow use almost loopholes implementations, where they already had a long distance separation between the two different sources. Between the two different sources. And what is why this can be an interesting resource because this can be interesting to have a device-independent approach to certifying general quantum networks. I repeat, the key ingredient is that you take your structure of an experiment, you derive the correlation, and then you try to observe that your experimental data Of experimental data are incompatible with the correlations that you can predict starting from the data. I would like now to briefly show you the last two experiments that we have done along this direction. The first one was to implement the star quantum network scheme, which is now reported on the right side. It's a scheme where we have now four sources, which are distributed according to a star shape. Shape. You have four different sources, you have five different sites. This is a picture of all my collaborators. Again, this was a joint collaboration with Rafael Chavez from Nadal. And these were the causal structures that we were interested to investigate. This, in our case, was a star net with overall five nodes, a central one, and four. A central one and for satellites, but you can also have in mind to extend this to a higher number of nodes. Now you can use this data structure, this causal structure, and you can identify which is a set of correlation that must be fulfilled if you use classical correlations. And this is inequalities that you can derive here. Can derive here. And now, what we implemented in this experiment was really to have this star network Dolinza lab, where we could have four independent sources. Some were passing, some were continuous solving, there are some technicalities, but the key points that were really four independent labs, four independent lasers on the same floor, but completely disconnected apart from the energy consumption. Then you can connect all the stuff. Then you can connect all the stars using fiber and so on. And then you may say, okay, I have the following scheme. Are my data compatible with the classical description or not? But obviously, when you increase the complexity of your structure, the number of alternative models that you would like to rule out increase a lot. So, why it's simple when you have a CH inequality? To say I'm not compatible with this, when you consider these scenarios, you may have many more alternative structures that you would like to exclude. So, this was a bit a picture of the lab I worked. I don't want to discuss now was the experimental case, it was a different subs. We are different inequalities. So, obviously, in this inequality, you could increase the number of possible measurement settings for each partner. So, you could go from the standard tool to more measurement settings for each partner. But I would like somehow to show you now a bit more what is the physics that you can obtain. So, what is shown here, you have any. Is shown here. You have n equals to 2, 3, 4, and 5. And this shows how many nodes you have in your star network. So n equals to 2 is the standard bill inequality, only two nodes. Then you go to 3, 4, and to 5. And what you can see, we can start from the case n equals to 2. This straight line here that you observe is fully equivalent to a bell inequality. To a value inequality. If you are below the orange line, you are compatible with CHSH, local, classical correlation. If you are above, you can exclude this causal model. And this is the standard. Then you can go to n equal to 3 and you see different boundary. And depending on whether you are in your boundary, you can exclude or not some causal structure. For instance, Structure. For instance, you can see in EPA23 where we have, you can see that we can exclude the model with two sources, the so-called bilocal model, but you cannot exclude the single Lambda model, which is a big peculiarity because when you consider to have two independent sources, you are using some information on your structure, and this allows you to observe some quantum violation. To observe some quantum violation, even in a scenario where you could not observe violation, if you had not this extra conformation on how is your on your structure inside. That's 20 minutes. 20 minutes, Javier. Thanks a lot. Then you can go 20 equal to 4 and you see it becoming more complex. But this is always to show you each time you are in some part in your subspace of your correlations, you can. Of your correlations, you can be compatible with some dark structure and not compatible with other ones. And this is the goal of what we did. This is a bit of summary where you can see the different number of sources, the number of settings, the classical bound, where you can see violation. So, this was a bit a way really to show how you can start addressing more complex scenarios, but how addressing more complex scenarios. But our addressing more complex scenarios opens much more questions that you would like to answer. And I would like now to spend the last few minutes to discuss our last results, which concerns the triangle network scenario, which has been a scenario of some theoretical interest in the last, I would say, couple of years, because it has been shown that the triangle scenario can show some. Show some genuine quantum correlation that you cannot observe with all their schemes. So, in this triangle scenario, we assume to have this A, B, and C, Anis and Bob and Charlie. You have three different sources, and you ask now to see which kind of correlation we have. And there are some also some experiments where you are not using measurement input coming from. Input coming from outside the triangle, but it's the experiment itself which is producing the measurement setting for the other partners in the triangle. I'm short of time, so I only would like to show you the overview. So we have carried out two experiments. We implemented the triangle network scenario where we have two independent sources as shown here and we investigated And we investigated which correlation characterizes the triangle. And we have done this from two different perspectives. The first perspective was very similar to the previous one. We have a triangle network scenario. We would have to characterize the correlation and we would like to exclude some other models. You may have a Svetlichny scenario where you have a single lambda model. You may have a relaxed scenario. You may have a relaxed betici scenario where you allow, for instance, direct communication between different nodes. So, you see, you can modify your causal structure, also allowing communication between the different nodes. And each of these relaxation of the causal constraint will imply new causal bounds. Since so, we get out two different tests. So, we first say, okay, we have six nodes. first say okay we have these three nodes we want to to you would like to certify if all the correlates the bipartite correlations are genuinely quantum and this is the first step that we implemented which is the following one where we could find out we could measure simultaneously by inequalities between all the different parties in size and triangle and by observing a simultaneous violation we could certify we could certify simultaneously that all the sort of correlations were at the same time truly quantum. Then we can also now try to do some more fancy tests. For instance, this one, where you will have to exclude that one of the parties is directly influencing another one. So this kind of retitchy models. Models, and this is what we implemented in the following scenario. Where again, we could for each of these tags, we could identify the bound and then we could show that we have the violation of the bound. Since I'm short of time, also what we implemented, and this is the final part of the story, we used this triangle scenario to investigate the so-called three. To investigate the so-called Fritz distribution, which was suggested by Fritz really a few years ago, where you tried to, where Fritz showed that you could have in the triangle a distribution which is truly quantum and not classical. And this is a joint experiment also with Rob Speck and Ellie Wolf. I'm a bit short of time, so I can leave this out, but we're using this triangle scenario. This triangle scenario, and this, and we experimentally investigated this frequency distribution. These are the experimental results where you could find on the left what was the theoretical prediction, and on the right side the theoretical experimental results. And then by using some different machine learning approach and also some inflation techniques, I'm really jumping to the results. And really jumping to the results, we find a way to guarantee the agreement between our experiment and the theoretical prediction, also working in a noisy environment. But I'm a bit quoting short here because I'm out of time. So I would like to thank you for your attention. My goal was to show you how powerful can be also from an experimental perspective, this drug structure, because it allows you. Because it allows you to precisely describe what's going on in the lab and also to precisely identify which is the model that you have each time you're ruling out according to your experimental data. And thank you so much for your attention. Great stuff. That's loads of exciting stuff there. Thanks, Fabio. Thank you. I have lots of questions again. Does anybody else want to? Does anybody else want to go first? I think you're too slow. Okay, so Fabio, what's more interesting then, looking ahead to having, you know, doing these tests using 50 qubits in a superconducting quantum computer? Or is it more interesting to think about the Philip Valfa direction and sending the photons up? And sending the photons up high to different gravitational potential. Then we see if you, from my opinion, this can become interesting when you get to more complex quantum network scenario. So now, what, for instance, what we are also doing, we are working locally. This is a picture. We are now all the prime sections. Are now all the previous experiments have shown you were done using the same lab. Now we are connected with other labs inside the campus. And so there is to have some sort of simple quantum networks and to see how this sort of quantum networks allow us to realize different parts. If you consider now moving also to investigate effect of gravitational field. Effect of gravitational field, then one should see how you can translate this in a dark structure. So our experiments now are not mature to go in some direction, but I guess that's the kind of tools that you develop may be useful because at least what is the idea that allows you to define properly what you are testing. So as many sub tests, if you are able to often, this was a case of loophole, if you Case of loophole, if you analyze which condition you are really fulfilling in your experiment and you translate in a dark structure, it's then easy to see which kind of correlation must be fulfilling. So I guess also this new form of experiment, it can be a precise framework to see exactly which sort of correlation, which kind of correlation you are testing. Yeah, great. And Lucian was next. We've got lots of hands. Lucian was next. We've got lots of hands now. Yeah, thanks. It's very nice to hear all this. Just an experimental question. So you have these independent sources of entangled photons, like I think in one case you had three sources. I think they don't interact at a quantum level. I think that's right. But nevertheless, there must be a timing issue because you want to consider measurement outcomes. Measurement outcomes on these different settings on these different sources, sort of at the same time, so to speak. How do you manage to do that? Is it some sort of clever coincidence technology, or how do you do that? Thank you for the question, because I still exist sort of details which are critical. Indeed, you are fully quite in the sense that the measurements are independent measurements. You are not measuring the different photons on bad basis. On bed basis. You are not doing, you are the triangle structure in this case. You measure the photon one for one. So it's not like a sloping measurement. Each photon is measured individually. So in this case, we could even go to a larger number of photons. We could also use some pretty large coincidence window in the sense that our experience is not too. Our experiment is not triple free in the sense that Ellis, Bob, and Jari are not spatially separated. So, what we could do is identify coincidence within a window tile, which is even a bit long, the sense that this experiment was not duple-free from the spatial independence between the different partners. So, what you have now is that. What you have now is that most of compared to years ago, now everyone uses a time-to-digital converter. You have a time flag which identifies all your photons. In this case, we have three different labs. So we detect the photons in different place. We have also time flag of all the detection, and then we can elaborate the data afterward. Okay, thanks. Okay, good. So we've got two more questions, but I guess we need to take a break now. I guess we need to take a break now. And I guess Cheslav and Jeremy will have to save those questions for the discussion session. So, what should we do, Lominia? Should we meet back in five minutes at 10 past the hour? Yeah, that's fine. Thanks. Great. Okay. See you in the gather town then.