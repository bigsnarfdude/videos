This was most heavily considered in the fifties, sixties and seventies and this whole method of using these observations to create your model is called data simulation. So what happened is data simulation kind of fell into two camps. It fell into a continuous data simulation camp. So this is what's called nudging. It was invented by Hope and Ananthes in the 1970s. And then it fell into statistical data simulation, which is Collin Filter, 3B, and 40 bar in the 1960s. So these are kind of the people behind it. Kind of the people behind it. So because statistical data simulation was more readily amenable, or more readily directly addressing the real-world applications, this sort of took off and this kind of fell away. So the idea between the two frameworks is they kind of have three different perspectives. The continuous data simulation idea is we have some sort of truth given by some sort of Newton's second law. Force equals mass times acceleration, like Avi Stokes, for example. Acceleration, like Avi-Stokes, for example. And then we have some observations of that truth. And the idea is to use a feedback control term on the differential equation to kind of nudge the system dynamically towards the truth. But the problem here is that you're assuming, you're expecting the system to compensate for any potential errors because you're not taking them into account. So this is where statistical data simulation came into a bit more of a kind of like the basis of all data simulation in use today. Data simulation in use today. The idea is we have a truth, a model, and observations of that truth. So we're even putting in some sort of lack of knowledge of what the model might be. So if there's incorrect parameters or incorrect forcing or our boundary is not, is too smooth or whatever, how can we best account for that? And we do so statistically. So the idea is to statistically optimally weight the model and the observations to get some knowledge of the truth. To get some knowledge of the truth. So it's like a three-pronged approach versus a two-pronged approach. But the assumptions here is that you're going to be working in a stochastic land. So you have error between observations and truth is unbiased and normally distributed if you want to do much. And the error between the model solution and truth is unbiased and normally distributed. To save some time, I'm going to skip this part because it's not super relevant. But why care about continuous data simulation? Because that's where I live. I live back in the CDA nudging type land. Nudging type LAN. So most of those data simulation methods have been developed to minimize the error in statistics for a given system. But the problem is they make a lot of assumptions about the linearity of the model. Proving things in a stochastic land for nonlinear models is quite difficult because nonlinear models mess up your Gaussian distributions. It's really bad. So because our models are getting more accurate, we're getting higher resolution in, say, ocean modeling, for example. Ocean modeling, for example. A lot of these gaussianity and linearity assumptions are becoming more and more infeasible, leading to fully Beiging methods, in particular, particle filter, and another look in some sense at continuous data simulation because they're more theoretically amenable and more theoretically strong. They have fewer assumptions and they're lying on data and all sorts of things. You can talk to lots of people, they'll have lots of different perspectives on here, but this is one story assimilation people will tell you. Simulation people will tell you. So, but the idea here is: I haven't said anything about the governing equations. All these methods are developed agnostic to the physics of the problem. I'm going to skip that for now. So, I want to show that if I go back to nudging, I can actually say, hey, if I use the physics, I can tell you how effective data simulation is at root. And we can actually, I can, I will state this, but I will not explain it. The nudging and continuous data simulation is actually the fundamental under. Simulation is actually the fundamental underpinning of all the data simulation algorithms. They all use some sort of feedback control, they just do it differently. So, here we're going to define mu to be the solution to a decipitative dynamical system. Hold that decipitive in your mind briefly as we go through. I'll bring it back later. So, this is Newton's second law. Think Navier-Stokes since this is the Navier-Stokes crowd. And we don't know the initial condition, right? That's our first fundamental problem with dealing with rural models. We don't know the initial condition. Dealing with real remotes. We don't know the initial condition. Other things are wrong, but that's problem number one. So, how do we deal with problem number one? Alright, so I want to describe mathematically what my observations need to be. So, I'm going to take, I'm going to go over here for a second here. In 1D, say I'm observing velocity or pressure or something at these blue points, right? So, if I'm working in a continuous setting, I would like to have a continuous representation of these discrete observations. Discrete observations. So I interpolate them using maybe a linear interpolant or something like this. If you're working in a nice Fourier space land, maybe just looking at low Fourier modes. So I'm going to call this IH of U. So I'm observing the full continuous solution at those blue points, and then the IH of U is just the continuous representative given by interpolation. Okay? So with that, I am now going to construct a new system. To construct a new system, I'm going to evolve it dynamically with f in the same way, but then I'm going to add on my feedback control term. This mu here is a positive constant. I'm going to look at the difference of these two terms, and I'll explain that on the next slide. And I'm going to give it any initial condition. Doesn't matter what it is, as long as it's regular. Regular enough. So, what is this feedback control term doing? Well, if I'm at a snapshot in time, I have this IHMU that I described, and I have some solution. Described, and I have some solution to this system. Assuming that it exists, we have to prove this. And so the solution to this system is going to be this green curve. And the idea is that I would like to dynamically nudge the solution of this guy towards my truth, my U solution. So the idea is to compare V and U. So I want to penalize this PPE dynamically, continuously in time, with this feedback control turn. So if V is higher than U. Control turn. So if V is higher than U, I want to push V down at the next time step. That's the idea. So here, V is above U, I would like to push it towards U. And the reason we have to do IH of V here is we have to compare apples to apples, right? So if I just did V minus Ih of U and V was eventually converging to U, this would become a source of error rather than actually going to zero. So it's very cheap to do this compared to the other methods. I won't go into why, that's not the purpose of this talk. Go into why, that's not the purpose of this talk. And then the interpolants have to obey certain finite element bounds. I really don't care. I usually work mostly in with Fourier projections as my interpolant because I'm working in the idealized setting. So we'll just focus on that. Assume IH is Fourier, low Fourier truncation. So I'm going to work with two different equations, but the original paper was set in 2D incompressible Navier-Stokes land. We're on the torus. So there's torus in 2D, so it's really nice. Taurus in 2D, so it's really nice. Everything's very straightforward. So here's our standard Navius equations, and then we're going to do with some unknown initial condition. So this is a black box to me. And then I'm going to look at this guy, and IH term here. 4Hruncation, this is linear. So I can do IH of V minus IH is IH of V minus V. So in 2014, Azawani, Oson, and TT proved that if I Proved that if I observe enough low forwarding modes and I push the system hard enough, i.e., my mu is very, very large, then I will have the solution of the second system converges to the solution of the first system exponentially fast in time once we're within the absorbing ball. For you. And this can be proven both in L2 and H1. Okay, questions so far? Mu was the Basically, mu is discussable. Mu is the discussible. Oh, mu? No, mu is this penalization size, right? This penalization, it's this emphasis term. So it basically makes it work, makes that term more important. Yeah, it overwhelms non-linearity. It overwhelms nonlinearity. So if you think about it, in some sense, if it's too large, none of the other terms matter. Which is, it seems kind of dumb, but it's actually kind of relaxing of synchronization. If you know about synchronization from Strogatz, like you read chapter 9 of Strogatz, it talks a little bit about. Chapter 9 of Strogatz talks a little bit about synchronization from Cora and Carol in 1990. So, yeah. So, from here, we also want to look at computational testing, right? We want to see how sharp these theorems are. So, the idea here is, as I mentioned, we're going to generate the truth with a fine-scale simulation. And then, in a separate script, we would like to simulate the V model. And take an initial condition. We're just going to often take zero. So, I'm going to explain briefly, we're going to have this simulation here. Because we have to work with adsorbing ball estimates, mu has to be very, very large in theory, and h has to be very, very small. They're kind of reciprocal, reciprocally related. I think mu is mu times h squared times constant is bounded by the viscosity. So, the idea here is that we don't need a lot of observations, actually. So, with mu being very small, 24, and Grashof being 5 million, we take the true solution here. We take the true solution here. This is the plot of the vorticity. We take piecewise constant observations here, we feed them into the V solution, and then this is just the image of the difference of these two. So as it goes black, it's just going to 10 to the minus 16. I mean, machine precision. So even with only 49 observation points being observed continuously in time, with mu very small compared to a Grashof number of 5 million, we have convergence of the two solutions to each other. And this is a non-traditional. The two solutions to each other. And this was a non-trivial force set. So this kind of spawned over the last nine years, actually, over 150 works on continuous data simulation. The idea, why this works is that if I'm looking at low-mode forcing, right, the fundamental idea is we have determining modes in nodes theory. So if we have a, if we observe enough modes, then in large time, our solutions will match up. That's the idea. Match up. That's the idea. So if you try to apply this to a system that's not decipitative, you're kind of screwed and you can even test this computationally. I don't think anybody's proved it yet. We need to, because there are some people who just do data simulation on any system and it doesn't work. So again, this addresses the, okay, which systems does it work for? Okay, we can address the initial condition problem pretty quickly with just this feedback control nudging, but what happens when we introduce other error? The whole point. When we introduced other error, the whole point of the other data simulation methods was to account for error, like observation error, noisy error. So there's been a very little bit of work in this direction with stochastic noisy data in these two papers here. But there's also a lot of other errors that need to be taken into consideration. We could be observing solutions discrete, or observations discreetly in time. So, how does that affect the solution? Turns out it doesn't if you observe often enough, and it's going to If you observe often enough, and it's going to be system-dependent, of course. I'm going to skip over this one. But what's really cool, and what I'm going to talk a little bit about here, and what Acio was going to talk about in particular, was forcing recovery. So it turns out, in machine learning and biblical data simulation algorithms, you kind of like try and find missing terms and correct incorrect parameters. If your viscosity is maybe a little off in your Navier-Stokes system, or you've guessed there's a term in the system that's actually not there, how can you correct? Actually, not there, how can you correct for that? People just use machine learning and gradient descent type algorithms. We can do it dynamically using the equations. Super cool. Other issues is what happens if we have moving observations, put buoys in the ocean. We can't always just stick a nice little grid in the ocean and hope we get observations everywhere. That's kind of annoying. Similarly, at depth too, if we're in the ocean, I worked a little bit in the ocean software, we often have more More abundant two-dimensional surface data than we have 3D data. So, for the primitive equations, it can actually be shown that for a certain degree, if you just have enough surface data, you can get the convergence for the whole system, which is very cool. There's also a bunch of other stuff in here, and I'm going to talk a bit about a non-linear data simulation algorithm, which is more mathematical as well. So, I'm going to focus on these two things, but first, I'm going to talk about parameter recovery. So, we're going to go back to Lorentz equations. Back to Lorentz equations, walk it all the way back. So here's my standard Lorentz model, x, y, z dot. Now I'm going to assume that I have some sort of guess at the correct parameters, rho, sigma, and beta. I should say sigma, rho, beta for each one. And I would like, in this case, I'm an ODE LAN, so there's no interpolation in space, so I'm just going to have to observe the data everywhere. I can turn it on and off. So since I have three systems, I have three. Three systems, three equations here. I can observe data here, or I can observe data here, or I can observe data here. So I can switch mu on and off. If I have mu on all the time for all the way of the equations, that's kind of dumb. But if I have it for one or the other, it's actually quite useful. And not dumb. You can't just reconstruct the solutions if you just have x data or just y data or just. So the idea is that, okay, I want to see if I can come up. I want to see if I can come up with an algorithm that allows me to adaptively recover the sigma parameter. I can do the real parameter and beta parameter as well, but sigma is, I don't know, they're all the same pretty much, but we're just going to pick it for this here. So I'm going to let u be the difference of my x's, v be the difference of my y's, and later on w be the difference of my z's. And I'm going to let delta sigma be the false sigma minus the true sigma. So then if I write down So then if I write down the difference of the equations x and x tilde dot, I get the u dot equation looks like this. So I want to do, and I said similarly here because I originally had this for Nafi-Silkes before, but there's a more direct math in what I'd already written up. So I'm going to multiply by u like a standard L2 energy estimate. So I have time derivative here, and then I have all these terms, and I'm going to rearrange them in a cute way. The time derivative of the energy squared. The energy squared, the energy in the component, and then a square term in v error, so v minus u times u. And then I have a linear term u, and then a linear term u weighted by a very, very large mu. So, if I do a haphazard magnitude analysis, I can say that this term is small. I'm going to tell you that this actually decays and goes flat. I don't want to explain that at the moment, but I will explain that in a minute. But if we neglect these two terms, But if we neglect these two terms, we can come up with an adaptive algorithm just using algebra. Kind of cool. The question is: does it work? Right? So we can work with recovery algorithms for each system. For the X system, if we observe on the X system, we can recover sigma. If we observe on the Y system, we can recover rho. If we observe on the Z system, we can recover beta. So this is a very disgusting thing that says, if I pick mu big enough, That says if I pick mu big enough and my division by the y minus x is not 0, then I have algebraic ammonotonic convergence actually of sigma tilde to sigma adaptively, which is really cool. So here's the idea of the proof. We have the U system, UVW system. This is how it's written out, kind of gross. You can do about two pages of energy estimates to get that this K here, which is the total energy. Which is the total energy has exponential decay according to mu, and mu here is the maximum of all these guys, plus this c term over mu1 times the delta sigma squared. So basically you have error controlled by your error in your parameter. But not only that, Young's inequality gives you this 1 over mu weighting, and that's critical. And 1 over mu weighting allows you to get the convergence because we also do the energy estimates for the u-dot system. So then when I write out the u dot, So then, when I write out the u-dot system with my incorrect sigma at time n, or at iteration n, not time n, I have sigma n minus sigma is equal to, I rearrange the other side. And now I want to substitute, I know what sigma n plus 1 should be because I've written an algorithm for it. What is this going to look like? Okay, and now can I bound this? Because I know these are bounded by exponential decay plus 1 over mu delta sigma, I can control all. I can control all of this by 1 over μ. And since 1 over μ is large, it takes care of all of the large bounds. And that allows me to get sigma n plus 1 minus sigma is less than or equal to epsilon prime times sigma n minus sigma, where epsilon prime is controlled by that large. So we chose it so that this epsilon prime is less than 1, so that we have the exponential decay. Or sorry, the algebraic decay and monotonic decay, which is really cool. Which is really cool. We had to go back to this because it was more intuitive to go back to Lorenz than do it for Nafi-Stokes. We originally did it for Navier-Stokes with computational background and back up the evidence for that. And eventually we used the ideas in the proof for Lorentz for each of the system, for each of the sigma rho beta, and used it to prove viscosity recovery in Navier-Stokes. You can come up with a very similar algebraic algorithm for the Navier-Stokes viscosity recovery. Algorithm for the navigator so it's viscosity recovery as well. So, this is improvement by Martinez in 2022. An alternative parameter recovery algorithm for spurious terms, possibly with non-linear dependence on the parameters, was also inspired by this, and it was work done by Pachev, Whitehead, and BitQuery 2022. This analytic proof, I believe, is almost done, if not already, or just about to open the archive. And then this inspired Farhat Laris, Martinas, and Whitehead to do a recovery of low-mode forcing. Of low-mode forcing. You can ask a CL more about that at a later date. But the idea is that we can do this for a whole bunch of things and we can do it analytically. We can recover terms that don't exist analytically. We can recover a little more forcing analytically. That's really cool. So that's one perspective of where we can come from here. I want to talk about mine. You got plenty of time? Okay, cool. You got funny. Okay, cool. Very good. So, this is interesting because then we can do things that people are often doing with machine learning or augmenting data simulation systems. We can do it analytically and we can do it really fast too. In idealized settings, of course, but it's the first reverse proof that I'm aware of for any sort of parameteric upgrade. If anybody knows of a different proof, I would really love to know. Or different perspectives and things where it's actually proven, I'd really like to know. To know. So, with that perspective, I'm actually going to shift gears a little bit towards something a bit more mathy. So, in terms of like the real world, if I'm going to be observing data and my data is corrupted, I kind of want to tune mu to be optimal. So, this is what common filtering 3d bar does. It does it in terms of the covariance matrices in the system, but with a bunch of other assumptions, right? So, for us map, people were like, well, how fast. For us, map people were like, Well, how fast can we push it? Why not? And we're not investigating this. So, the idea of Larius and Payne in 2017 was to change this mu to become adaptive, not in space, but in time. So, the question is here, okay, instead of having linear feedback control, which will give me exponential decay, can I get decay that's faster? So, I kind of want to motivate this by briefly writing it down. So, if I have So if I have u sub t equals f of u, v sub t equals f of u minus u i, and I'm actually going to just do, instead of this, I'm going to take ih to be the identity, and I'm going to ignore these two terms when I subtract. So I'm going to do something really, really basic. If I can control F and if IH is the identity. Okay? So something really dumb. But if I want to make mu a function of t, well then I'm going to put this on the other side and I'm going to have v dt of e 0 t u of s d s w t is a product. t is approximately 0, right? And so when I take the integral, I'll get w of t is approximately e to the minus 0 to t mu of s ds w of 0. So if I take time large and this is bounded, if this is bounded, I can kind of bound above below or above, if it's bounded in some ball. This rate is basically Some ball, this rate is basically still exponential decay. It's some constant times t, however, you're averaging that out. So, what I really need is I really need, as time goes large and as v minus u get closer to each other, I need mu to blow up. So in order to make mu blow up, I instead weight the ih of u by ih of u L2 norm to the minus gamma power, where gamma is between 0 and 1, right? So it's like a 1 over x. That's the idea. That's the idea. So, I want this to blow up so I can actually get stronger control on the decay. Okay, so this is the idea here. And then this term, it really doesn't matter whether or not it's there, but it's just the linear term to enforce exponential convergence when we're above one. Because this term hurts us when we're above one. Cool. Okay. So the idea. The idea here is: okay, very cool. We want to prove, well, posiness. That's the first thing we want to do. I said we need to know that the solution to the V system exists before we can do anything. And I don't think I said which system I'm working in. 2D incompressible Navier Stokes, Taurus, everything's beautiful, so super nice. I want to prove opposedness of the full nonlinear system with this nonlinear term. But the challenge is that the energy estimates are disgusting because your powers don't match. Because your powers don't match. You have estimates that look like y dot less than or equal to y plus y 1 minus gamma, which is a Bernoulli-type equation. So your energy estimates don't want to close, and solutions to Bernoulli equations are not obviously unique. I'll explain that a little bit later. So the solution for existence is to do some fixed point methods, and a partial solution for uniqueness is monotone operator theory, which I won't get into that one too much. It's actually like a four-line curveboard. So the idea here. So the idea here is we're going to use Shatter's fixed point theorem. So we're going to take a, we want to find a closed bounded convex set B, where F is a compact operator mapped in B, so that F is a fixed point. So we're going to consider this system here. So u tilde plus the bilinear term. So we projected everything using the Larry Helmholtz projection. And I'm going to have G of V here. So G of V in this setting is In this setting, is I want to find a fixed point of this guy. So instead of making it v, I'm going to make it u tilde. And then this guy is going to hang out over here. There? Because I still want to see data from this system. And I would like this V to match this U. Because this is my forcing. And I'll actually pull the forcing out of here, something like this F plus F. So I have all the forcing in the G function. The G function. Okay? Okay. So that's the idea, and then I'm going to give it some initial condition. So I'm going to take it in the classical, the solution. I know if g of v is in the appropriate space, since I'm picking v in l2h1, and I'm using h1 here because that's more meanable to everybody, but you know what I mean? It should be infinite, c infinity functions, mean free, periodic, all this. Functions, mean free, periodic, all this good stuff. But this is for notational purposes. So if I take a solution to this guy, because I know it exists by standards, not be Stokes theory, I'm going to take it to the strong solution to the system, and I'm going to take my set X to be L2H1, and I'm going to use standard energy estimates. They go all the way through to show that F is continuous and it's compact. It's annoying. You're just doing Navier-Stokes estimates over and over. It's not too bad. But the question is: okay. It's not too bad. But the question is: okay, how do I find this V set to actually do the proper fixed point theory? So the idea is, I want to, I'm going to base it around the initial condition. So I would like my R to have the same decay, same boundary here. So I still want to do all my energy estimates, so I need bounds in the proper space. So I'm going to take this ball to be all V in L2H1 such that it's integral bounded in this way. So for Integral bounded in this final point. So for sufficiently small time, I can prove that I stay in the ball. Here I have my standard energy estimates. If I do my nonlinear AOT term estimate, I basically just take the inner product and then brute force for Schwartz. That's it. That's where these 1 minus gamma terms come from. And I do the same for the linear AOT term as well. So when I do that, I can factor out this T1 star. I get a whole bunch of ugly stuff. I get a whole bunch of ugly stuff, but the nice thing about my T1 star, the way I chose it, it's less than one. So I can control, and by the way, I chose every capital R as well. All of this can be absorbed and bounded above by R, thanks to the smallness of T1 star. So we know there's a fixed point in a small time interval. And the idea is now, proof by induction, create a new Rn plus 1, initialize with the data from the system. With the data from the system in 0 to T1 over 2. So we chose it to be over 2, and then you just iterate over the interval. And then you get existence of the whole system, solution, whole system. That's kind of fun. So from here, you would like to do standard methods to prove uniqueness, right? When you're doing obvious does uniqueness, you just subtract the two systems and, hey, exponential growth, but we have the initial. Exponential growth, but we have the initial condition to zero, right? That doesn't happen here because we have this y to the one minus gamma term. And so you're like, well, maybe I could still have some control on this. Not really. So if you look at this system right here, you can actually write down and show that the zero solution is a solution to this guy, but so is this guy. Which is really annoying. So to kind of get your way around this, you actually harness the fact that solutions to Navi's jokes are unique. Solutions to Navius dokes are unique. You make an assumption on the interpolant so that you can basically get rid of that term, which is kind of cool. The assumptions are rather strong. Basically, we have to work with either volume averages or low Fourier load projection. So, if I consider, I'm going to make this assumption here that I have this positivity condition and I have this condition here. So, this one right here in particular is for. So this one right here in particular is Fourier protection. Oh, and this one also works for, yeah, this one also works for volume. If I take the difference of the two systems, this is your standard difference, so W is V minus U, and then I take the inner product of W, I have my usual estimates, my BWW, WW estimate. You just do standard to infinity 2, sorry, 44, and then my Sky up. Down this guy. Down this guy as well, but now because I made this assumption, I can replace the ihw with a w here. And then I have the nonlinear term, and then I have this add and subtract check that comes from the original linear analysis. So when I do this, I have my w to the 2 minus gamma term plus w to the minus gamma times the term I can control. I break up the blue term as I usually would for Navierate-Stokes, and then this term right here I can bound by bound. Here, I can bound by bounds on W minus I to W, i.e., how close is W to its intervalent? And that is controllable by our assumptions, which I kind of swept under the rug, but that has to do with the new age interplay. So it can be the tail modes can be absorbed by the viscosity. That's where the dissipation comes in. That's where it has to absorb our high modes. So with that, this term can be absorbed by the viscosity. This term, not quite, because we have. term, not quite because we have a 2 minus gamma. So on the left hand side you'll get a function that's x squared minus x to the 2 minus gamma and that guy looks like this. It would be nice if he was positive but he's not. He's bounded below by minus He's bounded below by minus epsilon. So we can't get rid of him altogether, but we can bound him and we can make epsilon really small by how we choose our coefficients. So we do this, and when we do this, that gives us an epsilon bound the others on this side. So we'll have a minus epsilon over here. But then over here, this non-linear term actually helps us because this will combine this squared with this 2 minus gamma because we're assuming. This gamma, because we're assuming u behaves nicely with large, well, it scales like large time bounds on our observational system. We can explicitly write this statement right here. So we have the time derivative is bounded above by, so x dot, plus equal to x dot minus x dot to the 1 minus gamma over 2 plus a little bit of, plus an epsilon. So that's annoying. It doesn't really tell us the rate. It doesn't really tell us a rate. It will tell us that we can get finite time convergence up to epsilon, but technically we can get this regardless because epsilon is greater than zero, right? If I have exponential decay, I will always hit anything not zero. Anything above zero, I will hit it in finite time. I can always find a time that does that. So that's kind of annoying. And what we wanted was to actually get better decay rates. So how can this actually tell us anything about the decay rate? Turns out there's a very cute inequality. Inequality that allows you to say for y between 0 and 1, because that's where this term is kicking on, I can say 1 minus y to the minus gamma is bounded above by the logarithm of y to the gamma. So indeed, my Bernoulli system actually has super exponential decay, exactly double exponential decay up to epsilon, which is super neat. So we proved this for L2 convergence and H1 convergence. And H1 convergence. In the first case, we don't have to have astronomical conditions. We can do Fourier truncation and piecewise constant interpolation. This should say volume average unwise piecewise constant. And the second one only is Fourier truncation. So my question was for a long time, like, why can't we send epsilon to zero? I should have known better. Because we have backward uniqueness. If we had u and v matching up in finite time, the feedback control term would be zero. We'd have two Navier-Shows equations, but the same. We'd have two Navier Stokes equations with the same initial condition, and we're kind of screwed. And so you can actually see that here in the computations, which is extra cool. So for IHFW above 1, we have the exponential decay coming from the beta term, the beta linear term, which I excluded from the convergence analysis for simplification. And then within this region, this is a log linear block. We have the L T norm of the string function. So scale it up because we have point. Because we have one query, right? We have double exponential decay here, and then it goes back to exponential decay, which is really cool. How much time do I have now? 10 minutes. Okay, with question items. Okay, good. Okay. So there's also a heuristic reasoning for why this is backward uniqueness is like the kind of underpinning, but you can actually go into the equations themselves and just do it with Fourier analysis. So if I consider a generic distributive system, any kind, you can actually see. Any kind. You can actually see this directly. So I have w sub t minus mu both w. I'm going to take this f tilde of v minus f tilde of u minus my non-linear term minus my linear feedback control term. So they're both here. So if I take my formal inner product, I'm going to have my time evolution, my good term for my dissipation, the rest of the forcing, whatever that looks like, it's nice, it's controlled by all this stuff. And then I do my usual add and subtract. And then I do my usual add and subtract of the and w and minus w plus w to get these terms. So I have plus minus the tail terms for each one. Okay? So now I want to compare these two and compare these two. So when I do that, I can move the good terms over to the left-hand side. So I'll have beta w L T squared over here, because QMW plus QMW plus W. And same for the And same for the nonlinear term as well. Both of these are good, so I don't need to worry about them. This one is okay as well. This one is bad. And so we can see this by expanding the term here in the Fourier expressions, right? So if I expand this in Fourier space, I have a k squared here with w, and then I'll have these are upper level terms in the, so I'll have the k equals n plus 1 to infinity. k equals n plus 1 to infinity. So I'll have my weighting term as mu lower terms to the minus plus beta from the linear term minus mu over 2k squared. The k squared can control the beta. If w is going to 0, k squared is linearly increasing in k. It cannot control this ever. So no matter what decipitive system you're looking at, you're actually showing that you can never get double exponential decay or decay in finite time. The k or the k in finite time to zero of the data simulation system with a nonlinear term to the original system in finite time. It's not possible. This was all done using equality, so this is even sharp. Right. So, like I said, it's an unsurprising result due to the backward uniqueness of solutions to the Navier-Stokes equations. The properties of the equations are basically fundamentally influencing the effectiveness of data simulation, with this finite dimensionality for determining modes of nodes being the most crucial. Modes and nodes being the most crucial. So, the question is: here: how can we identify specific useful properties of different systems to make our algorithms as effective as possible? This includes CommonFilter and 3D bar because they're all underlying this kind of, they all have this feedback control term underlying their actual structure, which is really cool. And what's also really cool, and something I've been really excited to see happening, and something I want to continue to work in, is the data simulation scheme has actually now been used to Has actually now been used to develop a regularity criterion for Navier-Stokes, 3D Navier-Stokes. So you know how most criterion are written in terms of like, oh, if we bound this norm, the full norm, then the solution exists, right? And is unique in all that stuff. We have strong solutions and everybody's happy. Father Christian and Biswas in 2022 showed this for the low modes. If you have normal control on the low modes only, then you will get Then you will get an existence of strong solutions. So, yeah. So, for further investigations, the question is: okay, how robust is this algorithm to combinations of errors? The 150 papers that have been out are usually looking at errors in one direction. So, now we need to figure out how to combine them and see how that affects the convergence of the algorithm. And we should understand how this is affected by the choice of equations as well. So, we're actually working on that. We're actually working on that in our research group and in the community at large. We have a research group that meets every Monday this semester. We're actually going to make it official. We've got a website and everything. And we've punched out a lot of papers from that. It's really, really fun. So there's other questions about maybe hybrid algorithms to leverage the benefits. I don't know if a hybrid algorithm will be a good idea, but it's something to consider. People come up with a lot of hybrid algorithms, and none of them ever work stupendously. Stupendously in a general form. So, of course, what are some issues more theoretical researchers need to be taking into consideration from the practical side and vice versa? Because we work in the continuous data simulation land. We can work on 2D and obvious Stokes in the periodic box all day long and be very, very happy. At least I can, anyways. But on the practical side, that's not useful. So one of the reasons I'm the school postdoc is hopefully to have that, continue having that crosstalk with actual applied people as well. Actual applied people as well. And so, another thing I would like to understand is: like I said earlier, particle filter is more rigorous, it's strong at its root than common filter and 40 bar. Not something I understand, something I would like to understand, similarly in the machine learning perspective. So, I would like to thank everybody who has supported me over the years. And yeah, that's what I have now. And hopefully, early enough for everybody to go eat dinner and sleep tonight or enjoy the outside. Or enjoy the hat right now. So you're having maintenance issues because you use shawler to use the fixed point. Well, what happens if you try to use stronger fixed points here, like Pana or something like that? But you are detailed, so you need that. As well as the existence. Oh, um Good question. So, the uniqueness was done separately from the Shadow Fix point, as you mentioned. I have not tried looking at Brouwer. I did Schaefer originally, actually, and then Andres came in on this later, and he's like, let's do Shatter. It'll be shorter. And it was a little bit shorter. But we didn't look into Brower. I do agree with you that we should have unique piss for. It's a little bit stronger, but you get the evening for free. That would be nice because the existence theorem here doesn't make a lot of assumptions on the interpolant operator. In fact, it's the most general out of all of the options here. You can still work with all the same interpolant operators that you do in the linear case. But in the monotone convergence, you'll be able to make a lot of assumptions, and I think it's spurious I do. So you might I should look at that, that would be very interesting. So perhaps one work because of that. Oh, Rowan? Okay, maybe. I don't know. It's been a long time since I've looked at those. I have a small question. Um, so are you looking into sampling randomly? So your interpolation and uh could be actually in homogeneous? Especially in emoji with what you guys sample randomly. I don't think anybody has done random sampling yet. I think that the best, the closest to that that people have done is moving observations and a moving subdomain. So I think you may have seen that work already. So that's by Adam and Mike Jolly, too. They've both done those kind of things. I think that's all that's been done for now. That's all that's been done for now. I've been working in another area for a couple of years, so it is connected, but I'm more interested in switching to I'm interested in looking at distribution.