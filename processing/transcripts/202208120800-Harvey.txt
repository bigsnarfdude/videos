See? Yes, I'm not. Okay. Okay, so thank you, everyone, and welcome to the last day of the workshop. And so it is a big pleasure to have John Harvey here, who's going to speak about circle actions and positively curved Alexander spaces. Thank you, John, very much. Okay, thank you very much for inviting me. It's sad to be so far away from you, but I'm glad you're all together there. Yeah, so I think it's exciting to have a meeting of this nature. So what I wanted to do was review some results of mine. Some of them are very recent, but some of them I'm also going to cast back a bit further into the past because I want to highlight. Want to highlight sometimes how proofs work or how things work in Alexandrov geometry compared to Romanian geometry, and maybe go into a bit more detail than I normally would, giving it to a more general audience. Not a horrifying amount of detail, but hopefully enough detail to advertise why it is that I like working with isometries of Alexandro spaces and where I see the benefit. Every result that I'm going to present to you is work that I. Present to you is work that I've been doing with Catherine Searle over the last many years. And it's possible, I suppose, I know Catherine spoke to you earlier, so she may already have introduced some of this stuff, but probably not in so much detail. So I want to start off. Everything already here is in positive curvature. So let's begin with this theorem due to Weinstein and Singh, which is about isometries in positive curvature. Isometries in positive curvature. So there's a version for even dimensions and a version for odd dimensions, but let's just look at even dimensions. The theorem says that if you have an isometry, say F, and it goes from an even-dimensional manifold to itself, then if it preserves the orientation, it has to fix a point. So the way this works. So, the way this works, the proof more or less, is you find some point P so that when you move P to F of P, this displacement is minimum. And then you look at the geodesic joining the two points and the space. And the space, the spaces that are normal to that geodesic at the two points. And then there are two ways to map the one normal space to the other. One way is to map by parallel transport, like this, and then the other way is simply to push forward along the isometry. So So this vector could get mapped to some other vector here using the push forward or the differential. I suppose it would be a more conventional notation. And if you look at what happens when you do parallel transport, so your parallel transport from one normal space to the other, and then you could come back along the differential, that's an orthogonal self-map of this odd-dimensional. Of this odd-dimensional space, and it has to have a fixed point. And then you use Singh's theorem to say: if we look at that fixed point, if we were to push the geodesic in the direction of that fixed vector, that would result in new points, Q and F of Q, which are actually closer together than P and F of P. So this is all quite classical. And very Riemannian. You can then move from that to look at what happens with circle actions. So the result of Berger, the most general way to put it, is that if you have a compact even-dimensional manifold and you've got a killing field, then the killing field has to vanish somewhere. Say you've got this killing field. Doing whatever it does. Well, if you just follow the killing field for a very small amount of time, that's going to give you an isometry. And that isometry will be orientation-preserving, provided you've got an orientable manifold. So, all you have to do for that is lift to the double cover. So, if we look at the double cover, look at the killing field there, and just Look at the killing field there and just travel along it a small distance, we're going to get some isometry. Right, so at this point, P has to get moved to F of P, Q gets moved to F of Q, and so on. So from the killing field, you make an isometry. The isometry must have a fixed point. Therefore, at some point, the killing field must have vanished. Now, Now, a particular example of that, I'm not very interested in killing fields generally in infinitesimal isometries, but a particular example would be a circle action, because of course a circle action is going to generate a killing field. So what we have from this is that anytime you have a circle action on a compact, even dimensional manifold and you have positive curvature, that circle action has to fix a Circle action has to fix a point, and that's sort of the jumping off point for a lot of classification results where we study group actions on manifolds, is we want to understand the structure of the fixed points because the fixed point set is always a bit smaller, inherits some properties from the larger space, and you can start to think about inductive methods. So I showed So I showed you sort of this picture. This is the proof for Finstein's theorem. Said you normally start off, you say you've got your points P and F of P, you join them with some geodesic, you look at the normal spaces, and you end up getting some map that goes from the normal space of P to itself. Now, when I was first presented with this, I'm pretty sure. Presented with this, I'm pretty sure it was presented simply as an algebraic fact. We've got an orthogonal matrix that acts on an odd-dimensional vector space. And you can look at the spectrum and see that there has to be at least one eigenvector with eigenvalue one. So there has to be at least one vector v, which is mapped to itself by t. So to remember what that is, we're saying, you know, if I parallel transported v. parallel transported v along to f of p I'd see that actually I ended up with df of v so that's the proof that I first saw and I think it's kind of the standard proof but when you go to work in alexandroph geometry you don't get a normal vector space you should have a space normal to the geodesic but generally that's just some kind of cow Just some kind of count. So rather than having a structure that looks like this, maybe you've got your point P here, you've got your point F of P. They're joined by a geodesic. More generally, you'll have a normal cone. And the base of that cone is not necessarily even a sphere. So this cone isn't even going to be homeomorphic to a vector space. It might be a cone. To a vector space, it might be a cone in a projective space or a cone on any positively curved thing. So, how are you going to deal with the problem in that case when you don't have the tools of algebra? The key fact for me is that if I look at that picture, I'm going to have to draw the picture again now, in SP, the cone is just one dimensional. Is just one dimension lower. It's an odd-dimensional space, just like the vector space was odd-dimensional in the Riemannian case. And then what about this base object here? We might call it the normal sphere at P, even though it's not a sphere, as I said. It's going to be odd-dimensional as well. If we have a 2n-dimensional space here, then the normal sphere has to be. Then the normal sphere has to be 2n minus 2 dimensional. And it's positively curved. So now you have the possibility of making an inductive argument. You can say, I've got this map from the normal sphere at P going over to the normal sphere at F of P. So as long as parallel transport is defined, I can Transport is defined, I can still take points here, parallel transport them over to points here, or rather directions here, and then pull them back again by the isometry. So now I have a self-map from the normal sphere at P to itself. This map is an isometry, it preserves orientation, and it's It preserves orientation and it's on a positively curved space. So now I simply use an inductive argument to say, therefore, this map fixes a point. And I like this much better because this is completely self-contained. You don't have to appeal outwards to geometry. You're saying, I want to prove a theorem about isometries of positively curved spaces in even dimension, and I do it by inductively finding a smaller positively curved space of even dimension with an isometry. Curved space of even dimension with an isometry on it. So, this is a much more self-contained, to my mind, much more appealing proof. And of course, this proof works perfectly well in the Romanian setting, just as it does in the Alexandrov setting. That's not to say this proof is easy. An enormous amount of work goes into constructing parallel transport and showing that you actually can do parallel transport from one normal cone to the other. From one normal code to the other, and that's thanks to Anton Petrunin who constructed that. But once you've got that construction, the argument is really easy. There's very little to it once you've got past that really ugly part. And I think a lot of Alexandruff geometry, and I don't know so much about the synthetic Ricci curvature band situation, but I hope it's similar. Certainly in Alexandruff geometry, you find yourself having to do sometimes very ugly foundational work with a lot of gritty detail. Of gritty detail, it's very granular. Once you've created the tools, then the tools are there and they work just as nicely as they would do in Romanian geometry, and to my mind, sometimes even more nicely, because it's set up to appeal to more geometric arguments. Let's generalize this statement now about circle actions. Any torus action on a compact, even-dimensional manifold with positive sectional curvature will have a fixed point. Will have a fixed point. So, any Tk, a torus acting on M2N, an even-dimensional manifold. So, why is that? Well, if you look at your torus, and here's the identity, say, you could go off at an irrational slope to find yourself a copy of the real line acting as a subgroup inside the torus. And if it's an irrational slope, then that real line will be dense inside the torus. So you've got this dense one-dimensional subgroup, and it will generate its own killing field. And now we use Berger's result to say, well, if there's a killing field, the killing field has to vanish. Where it vanishes, that point is fixed by the torus. And it generalizes also into the odd-dimensional situation. So, if you've got an odd-dimensional manifold, what does bubble of torus action do in positive curvature? Well, it won't necessarily fix a point. It's possible that it will produce a circle orbit. But the key point is there's always going to be a small orbit. Now, I want to give you again a proof of this statement because this is again another example where I'll Because this is again another example where I think using Alexandrov geometry proofs is so much nicer than using a Ramonian geometry proof. Let's look at this statement in Ramonian geometry, that a torus action on a compact odd-dimensional manifold of positive sectional curvature has either a fixed point or a circle orbit. Here's the simplest proof I know for this fact. We can assume that the torus is at least rank two. Rank two. If the torus is just a circle, then of course it's going to have a circle orbit. Now, this torus is not going to be able to act freely. There's an inductive argument for this, which is the second bullet point here. If the torus acts freely, then any circle subgroup also acts freely. So take a circle subgroup, it acts freely, quotient out by that. By that. So the manifold quotiented out by the circle is going to give us a new manifold. It is again a smooth manifold because the circle is free. It's positively curved because O'Neill's theorems tell us that curvature can only increase. And it's got an action of whatever is left over in the torus. We said the torus at rank at least two. Set the torus at rank at least two, so there's still some torus action left over on this even-dimensional manifold. That's got to fix a point. So if that fixes a point, well, then it wouldn't have been a free action because upstairs you've got something with isotropy of rank K minus one. Of rank k minus 1. All right, so we've proved that it doesn't act freely. That means there are some isotropy groups. So let's take a look at all the isotropy groups and find ourselves the maximal isotropy group. It's got a fixed point set, and that fixed point set is going to be totally geodesic. So you've got a totally geodesic sub-manifold. It is again. Manifold, it is again positively curved. So inside the 2n minus one dimensional manifold is some positively curved fixed point set, and it's going to have a free torus action on it. Why is that torus action free? It's because we looked at the maximal isotropy group. So if there were still any If there were still any if there were still any isotropy for the leftover torus action on the fixed point set, well, that would generate a bigger isotropy group. So we've got this leftover torus action on this smaller manifold. That torus action must have a rank less than or equal to one because by induction, we know that we can't have We can't have torus actions on odd-dimensional manifolds if they're rank two or higher. So that means the maximal isotropy has co-rank at most. In other words, there has to be a circle orbit. So what's happening here? You do two different inductive steps. There's one inductive argument to prove the torus doesn't act freely, and then there's a second inductive argument to prove that there has to be a circle orbit. Now, in Alexandruff geometry, you would use just You would use just one inductive argument. You can take any circle subgroup you like, assuming that it's not trivial. Now that circle acts on the odd-dimensional manifold, giving us some even-dimensional orbit space. Now, the even-dimensional orbit space is now not a Riemannian manifold, it's just A Riemannian manifold, it's just an Alexandrov space. But that doesn't matter because we're working in Alexandrov geometry and we've already proved Berger's lemma in the Alexandrov situation. So we're saying we've now got a torus action on the even-dimensional orbit space. That's got to fix a point, which you lift up to a circle orbit. So, you know, it's not like this is a vastly quicker proof, but it's far, I mean, conceptually speaking. For, I mean, conceptually speaking, I find it a lot simpler. I simply say I've got the odd-dimensional manifold, mod out a circle to get an even-dimensional space, and then apply the even-dimensional argument to that. It's a bit less fussy. So these are these two very classical circle statements in Riemannian geometry. A circle action on an even-dimensional manifold in positive curvature must fix a point, and on an odd-dimensional manifold. Must fix a point, and on an odd-dimensional manifold, it has to have a circle orbit. And we've shown that these are both true in Alexandrif geometry. And the proofs that we use for Alexandrif geometry, of course, work perfectly well for Romanian geometry as well, but they're not the proofs that necessarily jump to mind in Romanian geometry. They are the ones that come to mind first in Alexandrov geometry, and I find them more appealing, more geometric, and sometimes simpler. And sometimes simpler, as in this case, because you've got the flexibility of not having to worry about whether actions are free or not. If you're working in Alexandrus geometry, these actions with isotropy are absolutely fine. Okay, what can we do with this? Well, you can use it to bound the rank of a torus. Now, I'm sure you've already heard about this earlier in the week, but just to go over it very quickly, then, if you've got a torus, say of rank K. It's acting on a manifold, either even or odd, then we can ban the rank of the torus. We can say k must be less than or equal to n, where the dimension of the manifold is 2n or 2n minus 1. So is a sort of skeleton argument of how it works. What we showed is when a torus acts, there's got to be a small orbit. There's always either a fixed point or a circle orbit. So I'm just going to call those small orbits. To call those small orbits. Now you can therefore take a look. A small orbit is the same as saying there's a large isotropy group. So we've got another large torus, and it's going to act on the normal sphere. And the normal sphere is also positively curved. So from having a torus acting on our space, we go down to having another torus, which is a large torus, acting. A large torus acting on another space, which is also quite large. So the ranks and the dimensions are going down together, and that allows you to build an inductive argument. I'm not going to lay out the details because you can easily find them, but just to give the general idea. So let me look now at some newer work. Something that Catherine and I did recently is we took this result on positively curved four manifolds, which is due to Schang and Four manifolds, which is due to Shang and Kleiner, and we worked on extending it to Alexandrov spaces. So, if you're not familiar with this result, Shang and Kleiner showed that if you have a compact, positively curved, simply connected four-manifold, and it's got an isometric circle action, then it has to be homeomorphic to the four-sphere or to complex projective space. How does it work? What you do is you look at the orbit space and you look at the geometry. Look at the orbit space, and you look at the geometry there. The orbit space is an Alexandrov space. And if we look at the spaces of directions at fixed points, if P and X4 is fixed, then that means the isotropy action there is a circle acting on the full three-sphere. So this brings us down to some two-dimensional space, and that's going to be the space of directions in the orbit space. Directions in the orbit space. And these spaces are always small, in the particular sense that you can never have a triangle of perimeter more than pi. They can either be Cp1, or else it can be an orbifold which has diameter pi over 2. These are the two possibilities. And if you look at both of these possibilities, you see that you can never have a very big triangle in either of these. Angle in either of these. Then you can use this result to argue that there can only be three fixed points. Because if there were four fixed points, you can look at the 12 angles that are generated. So for example, here are three angles sitting at this fixed point here. Now, by the characterization of smallness, that's essentially. That's essentially saying that these three angles must add up to less than pi. Sorry, yeah, to less than or equal to pi. So doing that across all four points, we see that the sum of all the angles must be less than or equal to 4π. But on the other hand, you could consider it by triangle instead of by point. Of by point, and say what do the sum of all the angles look like if we do it looking at it triangle by triangle? Well, in positive curvature, the sum of angles in any triangle must be at least pi. So we get the sum of the angles, all 12 angles, is greater than 4 pi. That creates the contradiction. So there are only three fixed points. Now, if a circle acts and fixes a certain number of points, that will let you know the Euler. That will let you know the Euler characteristic. And Schlang and Kleiner proceeded by saying we've got a classification where if we know what the Euler characteristic is, we know what the manifold has to be. So let's move on then. How does it work up to diffeomorphism, which is a bit trickier? What Grove and Searle showed is that if you fix a large enough fixed point set, right, so S1 acts on the four-dimensional space, goes down to a three-dimensional manifold. Manifold. If that's got some fixed point set, it ends up looking like a cone. So above the fixed point set, you have the base of one disk bundle. And above the sort of vertex of the cone, you maybe have an orbit here, and you've got another disk bundle around that orbit. Disk bundle around that orbit. And you glue the two disk bundles together. And that allows you to describe much more precisely the structure of the manifold. They weren't able to address the situation where the fixed points are only isolated. And much later, Grove and Vilking did that. They understood what goes on with isolated fixed points. Essentially, when you've got, maybe these are the fixed points in the orbit space. In the orbit space, they're going to be joined by exceptional isotropy, which I'll denote by E. So what you get is a sort of a graph. You've got vertices, which are the fixed points, and you've got edges, which correspond to finite isotropy. So what they did was they understood what this graph looks like. You're able to see that it kind of degree at most two. Some very clever arguments allowed. Some very clever arguments allowed them to show that when you have a cycle in the graph, it's got to contain all the points, and that it's not possible for there to be any knotting going on. The cycle in the graph has to just be a simple curve. And by using that, then they were again able to argue, you know, more precisely what the structure was, and again able to show that there's still a disk bundle decomposition. So, in the most complicated situation, So, in the most complicated situation where you have three fixed points all joined by three structures of finite isotropy, what you can do is you can break the orbit space into two neighborhoods, a neighborhood of a single point and a neighborhood of the complementary edge. And you can show that both of those neighborhoods are disc bundles. And then you glue them together. And it's the lack of any knotting. And it's the lack of any knotting that allows you to glue them together in this simple, smooth way. Okay, so what we wanted to do was figure out how to generalize this towards, say, Romanian orbifolds or to Alexandrov spaces. So here's a theorem for you that we've proved. If you have a compact, positively curved, simply connected four-dimensional orbifold, and a nice And an isometric circle action, then the underlying space is either a four-sphere or a weighted complex projective space, and it's got a linear circle action. So first of all, just to be clear, what is a weighted complex projective space? You all know that the complex projective space in four dimensions is the five-sphere mod out of free circle action. Action. A weighted complex projective space has three weights, which we usually denote A, B, and C. And what's going on here is that it's just a circle that doesn't act freely. It's fixed point free, and it's got finite isotropy of order A, order B, and order C at different places on the phi-sphere. So it creates this orbifold with three singularities. So hopefully that makes So, hopefully, that makes clear what the theorem means. And now, also, comparing the theorem to our stated goal, hopefully, you see that we've only wanted to prove something general that would cover orbifolds or Alexandro spaces. And what we actually proved only covers orbifolds. So there's been a failure here to get all the way to Alexandro spaces. So the way to start, try to get a little bit more. The way to start trying to prove something like this is to say, well, what could go wrong? What could the problem be that's caused by me not starting with a Romanian manifold, but rather starting by something else? Let me go back to the proof and see where I need the assumption that I'm using a Riemannian manifold. We don't need a Riemannian manifold to know that there are three points with these small spaces of direction. That little picture of the tetrahedron can be drawn just as easily. Tetrahedron can be drawn just as easily in an Alexandrov space as anywhere else. So you've still got that crucial band, but there are a lot of things you don't have that you really need. First of all, we were only interested in the small spaces of directions because we said we knew the spaces of directions of fixed point sets would be small in this sense of having no triangles with perimeter more than pi. So, in general, is that So, in general, is that still going to be true? Even if it is true, well, how did Grove and Wilking rule out knots? What they did was they used this double-branched cover construction, just where you can take the knot out of the three-sphere. That always gives you something with fundamental groups. You can take a double cover and then you can glue the knot back in. And it was important for them that when they did that double. Them that when they did that double-branched cover, that didn't make the space of directions too big, and they were still able to use, therefore, the band of three. So, will that still work for me? And finally, when Grove and Wilking were doing this, a fixed point set always only had two branches going off it with finite isotropy. That's because if a circle acts on a three-sphere, there can only be two different sets of finite isotopes. Only be two different sets of finite isotropy. But in general, when a circle acts on a three-dimensional positively curved space, there can be three components of finite isotropy. That's what happens if you look at circles acting on dihedral manifolds, tetrahedral manifolds, so on. So it gets a little more complicated. So what we decided to do was make some assumptions. The assumptions are exactly the same as the things that would go wrong. Same as the things that would go wrong. We're going to assume that when the action happens, that at fixed points, the space of directions is always small. We're going to assume that when you take branched covers, you retain the property of smallness. And we're going to make a third assumption, which relates to what happens when there are three finite isotropy directions. We're going to assume that that space of directions is always really small, that it always has diameter less than or equal to pi of. Diameter less than or equal to pi over 4. And I'll explain why that's a useful number later. So if you make all those assumptions, then everything's going to work. So why do we make those assumptions apart from the fact that they work? Well, first of all, because they're definitely true in the case of Riemannian orbifolds. The thing with a Riemannian orbifold is that it's really rigid. So the R. Rigid. So the arguments that you use when you study Riemannian manifolds, you know, they're basically the same. When I say a small, the space of directions has to be small, it's because I can enumerate all the possible spaces of directions and make an argument for every one about why it is small. And I can do this just as easily if instead of a Riemannian manifold, I have a Riemannian orbifold, because it's very rigid. But I cannot do this for general Alexandra. Not do this for general Alexandrov spaces because for general Alexandrov spaces at a fixed point I'm going to end up with the circle which is the isotropy group acting on some totally generic three-dimensional space of positive curvature. I know nothing about it other than that it's positively curved. So how am I going to argue? Am I going to argue for any of these elements? So, really, some kind of equivariant comparison result is still needed. So, if you're looking to go away from this week asking yourself, what's something I can do about isometries with this particular kind of metric space, with Alexandro spaces? I would say the thing you could come away with is that we should have some kinds of equivariant comparison. Equivariant comparison. We've got all these comparison statements about triangles, about distance maps, about convexities. Can anyone do any of that in the equivariant setting? If you can, I think that would be really useful. So certainly, Catherine and I would conjecture that it's all true. Sorry, can I ask a question, John? Yeah, yes, please. So in this General Alexandra case, the This branched cover argument, you don't really know what you get. Do you? Can you say? Oh, the problem is even earlier than with the branched cover situation. The problem is, let's go back here. The problem just starts with the first statement here. If a circle acts on a three-dimensional You, if a circle acts on a three-dimensional space, do you get a bound on the three-extent of the quotient space? Um, Catherine and I have worked very hard on it. We've talked not to you, but to several other people who also, you know, thought, well, this is clearly obvious, as did we, but, you know, after significant effort, didn't really make any progress on it. So I think the question is. Okay, if you. So I think the question is okay. If you assume this, let's say, yeah, I understand that. Can you then say something about the branch cover? I'm not sure if it's no, I don't think so. Because this is, again, as you say, this is not rigid. It don't really exactly. So that, yeah. Okay. Thank you. So the thing you could, yeah, I. Could yeah, I would say that in making this conjecture, I would, you know, put different levels of confidence for sure on each bullet point. This, I would say, I have high confidence in, and this may be more like medium. And the third point might be somewhere in between the two. But I'd be very happy just to get started really on the. Just to get started, really, on the first one and to see some progress there. So, let me tell you, I suppose, what I do know, because I think that might be interesting. Suppose you start off with this three-dimensional space being a smooth sphere. Then you can find the shortest orbit on the sphere. And let's mark out that as being the point P in the orbit space. So maybe here's the orbit corresponding to P, here's P itself. Sigma is up there, and sigma mod out the circle is down here. Now, you can use Jacobi field comparisons. If you look at a normal field to this geodetic, you can use these Jacobi field comparisons that are basically like the Roche comparisons to. Comparisons to control what the volume of the tube, right? Let's select, we can make this into a solid torus and we can understand its volume. We can also understand the area of the boundary of the torus. So therefore, downstairs, when we start looking at distance circles around P, we can understand what those circles look like. And they are indeed shorter than they would be if you were in constant curvature for. Be if you were in constant curvature four. So that's all very good. And you can even say a little more. Suppose we're at the point P here, and we look at the tangent space, and then we want to map that on to this sigma 3 mod T1 using the exponential map. Well, if you just look at the segment domain inside the tangent space, so in other words, looking at all the length minimizing geodesics here and then pulling them back into the tangent space, that gives me the segment domain. If I look at that exponential map, this Rauch comparison analysis allows me to say. Allows me to say that you do get a one Lipschitz map. Suppose that I change the metric on this tangent space and give this a curvature four metric, then this map is one Lipschitz. But that's not really good enough because say I take this direction here and this direction here. Here, I don't want to bound how far apart they are over in the orbit space in terms of a curve like this. I want to bound how far apart they are in terms of a direct curve, which goes outside the segment domain. And we can't do that because the methods we have are just local. So, the cut locus starts to cause problems as you get further away from P. As you get further away from P, and the whole thing only works if you're based at P, and this is kind of as far as we've been able to get. So let me move on anyway and just use the next few minutes to wrap up how it is you can prove it if you do have all these assumptions. So if you have a simply connected four-manifold, that implies that you have to have a simply connected orbit. That you have to have a simply connected orbit space. So there's two possibilities. The orbit space could be a three-sphere or a three-disk. The three-disk case is actually quite easy. So we'll just look at the three-sphere for the moment. There's a lot of different bits and pieces you need to figure out by chasing back to the original literature. The first thing is to see that there can't be a loop of finite isotropy just dangling in your orbit space without any connection to it. Orbit space without any connection to a fixed point set. So if you're in the three-dimensional orbit space and you see a loop of exceptional isotropy, it's always going to have to have a fixed point on it somewhere. And that turns out to be for homological reasons. If you study this structure and you lift it up to the lift it up to the um to the to the main to the full space then you end up without a proper fundamental class entomology that's how montgomery and young showed this back in 1960 so there can't be any floating loops for purely topological reasons now there also has to be one fixed point that's for geometric reasons that will that's what we spent the first half of this talk talking about where a circle action on an even dimensional space is going to have to An even-dimensional space is going to have to have a fixed point. So, why does there have to be a second fixed point? It's because if you had one fixed point, it would get very lonely, it would be a very sad situation. That fixed point all by itself in X3 bar, say here, look at a little neighborhood of that, and then look at the complement. The complement is a three-disc, and there's Free disk, and there's no fixed points going on there. So that means upstairs, it's going to look like S1 cross D3 in X4. All right, that's there in X4. So that would imply that the space of directions at the fixed point would have to be S1 cross S2. And that can't be positively curved. And then And then there can't be a fourth fixed point either for the standard reasons that Shang and Kleiner used. So we've only got two or three fixed points. So using this terminology of a graph, you've got two or three vertices. The graph can have degree three, because when you act on a spherical free space, you could have three components of finite isotropy. But we're not going to refer to it as being. But we're not going to refer to it as being a graph anymore. What it could be is a multigraph. A multigraph is one where for a pair of vertices, it's possible to have more than one edge. So for example, in this case, these two vertices could be joined by two different edges. So that's the three-sphere situation. Let me go back to the three-disc situation, which I told you was so. Three disk situation, which I told you was simpler, it comes back to the fact that you've got the fixed point set with two dimensions. So this disk bundle argument pretty much works again. You've got a circle, which is at maximal distance from the fixed point set, and that creates this cone structure in the orbit space. Then it's very important that you take this isotropy action at that orbit and that you. Action at that orbit, and that you understand that the isotropy action describes what's going on locally. So then you've got these two cone bundles, or well, really, you just need one cone bundle. You've got a cone bundle on this orbit, and you glue on the fixed point set, and you get the same picture. And that gives you various spaces of the type that we'd already talked about. Suspensions of lens spaces. Lens spaces, finite quotients of weighted complex projective spaces. So essentially, they're all coming out of the four sphere or coming out of a weighted complex projective space. This thing about the cone bundle is really important. So I said you've got to have a two-dimensional fixed point set, and then you've got a point P, and it creates a kind of a cone structure. And then upstairs, And then upstairs, maybe you've got the corresponding orbit, and you understand what the circle is doing on the normal space. So extending the action on the normal bundle, right, this bundle of normal spaces, showing that that's actually the same as the action on the tubular neighborhood is an important step here. Is an important step here. So essentially, that's a slice theorem. So if you want to understand isometries and metric measure spaces, you need these kinds of slice theorems. I'm not aware of one apart from in the Alexandrov geometry setting, which we can see that if you have the action on the normal bundle given by the isotropic group. Normal bundle given by the isotropy group, it's the same as the action on the tubular neighborhood. And that allows you to use inductive arguments about the space of direction and actually apply those inductive arguments to the total space itself. If you can't do that, then there's no point in having the inductive argument. So what goes on then if you've got fixed points? So in the case where you have three fixed points, you end up actually with something really similar to... End up actually with something really similar to what Groven were looking at. I'm not going to go through it in much detail. You have these three fixed points, which are here. You've got finite isotropy joining them. So what you can do is say that the space decomposes into four parts. There's this solid torus around the finite isotropy, and you break that up into three chunks around the fixed points. And then you've also got a couple. And then you've also got a complement which is free. So Fentuschel laid the groundwork here by with his really great work on manifolds, where you use ciphered invariants. So we reworked that to make it apply in greater generality. So you end up being able to get weighted complex projective spaces out of this situation where you have three fixed points. Now, what about where you have two fixed points? We use these kinds of branched covering arguments to see that there are two basic shapes. There is the case where all the edges join one point to the other point. So there aren't any little loops. And then there's the case where there are little loops. So you can have one fixed point which has a loop based at it. And then maybe there is another bit of finite isotropy joining it back to the second fixed point. The second fixed point. So these are the two situations that you can get in a Riemannian orbifold. Where there are no loops, essentially, you cut the space in two right down the middle, and you can show that it's a suspension. And then you appeal to lower dimensional cases to see what it has to be. So you end up here always with quotients of the force here. What are the key things you need to look at? What are the key things you need to look after? I won't go through it because I know I'm a little over time. The key thing you have to look after is always knots. So the assumptions ensure that you don't have any knots. And with three edges, you also ensure that the entire thing is not knotted because you have that pi over four diameter band. That's what allows you to. That's what allows you to create a sort of a gradient vector field that goes all the way from left to right. And what if there are loops? Let me move on to that case. In the case where there are loops, this is really weird, but they do arise. We're able to construct one explicitly. The loop always turns out to have a Z2 isotropy. And what's happening is you've got some space that had three fixed points and you've got Had three fixed points, and you've got an involution on it. Here's the picture. Here's down here a three-fixed point space. So it's a weighted complex projective space, and the weights are 2k, 1, and 1. So you end up with three fixed points and ZK isotropy. So order K isotropy here, order K isotropy here. This is the kind of thing that can never happen in a Riemannian manifold. You can't have the same order on two different... Can't have the same order on two different branches. And the idea is you identify these two edges using an involution. The involution also happens to fix some other structure. So that fixed structure turns out to create this loop setting here. So the summary would be if you're looking at Riemannian orbital. If you're looking at Riemannian orbifulls, they always come out of a circle acting on a four-sphere or else a circle acting on weighted complex projective space. Or if you prefer, you could say that's a two-taurus acting on the five-sphere. So all the four-dimensional orbifles are really coming from four spheres and five spheres when they've got circle actions. And to prove this for general Alexandra spaces, you're going to have to prove some kind of equivariant comparison result. And as I was saying with Vitali, some parts of it seem kind of intuitively like they must be true, but other parts actually maybe, especially these branched covering aspects, it's not so clear what the basis for believing them really would be. This work has taken a long time, lots of different bits and pieces to it. So thanks to all the different agencies who have funded us during that time. And that's it for me. Thank you very much. For me, thank you very much. Thank you, John, for this wonderful talk. Are there any questions within the audience? Yes. Hi, John. Diego here. One simple question. So if I remember correctly, at least for part of the work of Grove and Wilking, was that the circle actions could be extended to torus actions? To Taurus actions, right? Do you think some possible is in this setting, at least for the weighted complex planes? For the weighted complex projective spaces, that sounds like it should be possible. For where you have two fixed points, it's certainly not always going to be possible because it is a suspension structure. Suspension structure, so the torus has to fix the two poles of the suspension, so that means you end up with a torus action on sort of the three-dimensional cross-section. So unless that's a lens space, you're not going to, it won't admit a torus action. But yes, I do think, in fact, yes, I mean, quite obviously, actually, you will get a torus action on the complex projective spaces, a topological action, because you. Topological action because you start out with a three-taurus action on the five-sphere, you mod out a circle, you're going to be left with a two-torus action on your weighted space. But that only came into their argument when they were analyzing the non-negatively curved situation, which we haven't actually looked at yet. Sorry, John, but I think suspension of a lens space does have a T2 action, right? Like lens space has got some. Yeah, sorry, that is what I said. Yeah, it's just the other cases that wouldn't have a T2 action. If it were, say, the Ponkaret homology sphere. Ah, right, that one doesn't, yes. But that, yeah, so it comes down to whether your three space admits a Taurus action or not, and some do, some don't. Okay, thanks. Thank you. Any more questions? Yes, I have one again. So, to the first bullet point about small spaces of directions, so exactly what is the conjecture about that part that if you have a circle orbit? Yes. Let me get myself a blank pen. Let me get myself a blank page. Yeah, if you have a circle acting on three-dimensional space curvature greater than or equal to one, then what we want to have is that the three extent of the quotient must be less than or equal to pi. Pi right, so for example, you know, if it was CP1, which conjecturally is sort of the biggest it could be, a sphere of radius one half, okay, then you can go have triangles that look like disks, and that entire circumference there gives you pi. Um, so in some way, that should be the biggest thing you have, right? Way that should be the biggest thing you have, right? Because you've got the biggest possible three-space to start with, is the three-sphere, and you've got the most extreme circle action you can have as well. Oh, okay. All the orbits are the same size. Yeah, that sounds reasonable. That's okay. So that's also the only case where we made any sort of headway is we said, okay, well, if you have an action on a three-sphere. Yes. Yes, well, but you have that structured by the sense this sounds like a reasonable conjecture to me, yes. Yeah, yeah, the other stuff, I kind of have no idea, but um, but this seems reasonable, but um yeah, we've been at a we've been stuck on that for many, many years. Thank you for the great talk. Thank you. Thank you. It's good to see you. Any more questions for John? I do have a very naive question. So does it help at all to look at the classification of circle actions on three spaces? Like, could you go like a case by case and look at all possibilities, or is this like hopeless? It's, I mean, the data. Uh, I mean, that's kind of where we started: is let's just look at free circle actions on three spheres. Yeah, and it's really about the kind of squishiness of the situation, right? You add that little bit of geometric flexibility. Topologically, everything is still totally rigid. You've got this clear list, you know exactly what's going on. But geometrically, the little lumps and bumps that you can have in Alexandrov geometry just deprive you. Just deprive you of that key tool, which I guess really is knowing that the two-dimensional space at the bottom is going to be a surface of revolution. Once it's clearly this, you know, they're ovaloids of revolution, I think it was a technical term. And you can look at those and you can see, well, this is the geometry of them, but So, you've always got that kind of extra symmetry, which you don't have generally, right? If you've got the circle acting on the round free sphere, it's sitting inside a torus. So, there's another circle acting on what's left over that gives you a bit more structure to start figuring out what's happening. Yeah. Like, for example, it seems that some examples could be very rigid, like suspension of RP2, since you know. Of RP2, since you know you're positively curved, does this uh um that's interesting. Um, we no, I don't think um that's not something I've looked at actually, um, but yeah, it does seem likely that having the suspensions because it gives you these two um distinguished points. To distinguished points. Yep. That is the kind of extrastructure that might be nice. Yeah. I see. I see. But suspensions of RP2 wouldn't come up in our case because we're looking at orientable spaces. So we're always looking at 3DFL. And none of them have that. I see. Okay. Okay. Thank you. Thank you. Okay. So if there are no more. If there are no more questions, then let's thank John again. Thanks very much. Kia Rigoni from Unidacité Tien, and she's going to speak on the convergence of metric measure spaces satisfying CD condition for negative values of the dimensional parameter. Thank you very much. So, first of all, I would like to thank the organizers for the opportunity to present this result here. Present this result here. So, in this talk, we are going to introduce the class of metric measure spaces, which in which we can introduce the curvature dimension condition for negative values of the dimensional parameter. And in particular, we are going to see the stability of this notion under a suitable convergence notion of topology. So, this is a joint work with Mattia Mania Bosco and Gerardo Souza. So, let's start. Soda. So let's start with our motivation. So, why it's important, it's meaningful to introduce this notion of a negative dimension. And the reason goes back to the case of weighted Riemannian manifolds. So, we take a Riemannian manifold in which the reference measure is given in terms of the volume measure associated with the Riemannian metric. But we have also a weight which is formulated in terms of Which is formulated in terms of this function ψ, which is a C2 function. We know that in this setting, also the Ricci curvature tensor is going to be modified. So we end up with a weighted Ricci curvature tensor, which takes the form that involves the part of the Ricci curvature tensor of the unweighted Riemannian manifold. Then we have this term which involves the Hessian of our function psi. Function psi and the last term in which we have the gradient of psi and at the denominator we have also the possibility to introduce a parameter capital L. In the standard theory, this capital N is taken to be greater or equal than the topological dimension of the manifold. And in particular, the case of the equality is obtained just in the case in which our Just in the case in which our weight is nothing but a constant, so we know that already this term is equal to zero. So let's say that typically the case considered like most of the time is the one in which capital N is greater than the topological dimension of the manifold. What the reason why it's important, it's meaningful to consider also the case in which n is negative goes back to our Goes back to a result proved by Hot and Takatsu in 2013, in which they proved that it's meaningful to study the geometry of the space to consider this relative entropy, which depends on our parameter M. And the fact that this M relative entropy is K-convex in the Vasse tense space is related to the fact that the N-weighted Ricci curvature tensor is. Rich equal to tensor is greater or equal than zero. And this capital N depends on the parameter M that we chose in the study of the entropy. In particular, M can be any real number different from one, and when M is greater than one, this capital N is less than zero. So here it's how this negative dimension appears. So in the study of the N In the study of the n-weighted rich curvature tensor. Sorry, can I ask a question? Of course. What is X sub M of psi? This is exactly, it's so let's say that in all this theory of the study of the relative the M relative entropy, also the reference measure that is considered in the entropy is not the one of the weighted Riemannian manifold, but we have to consider another. But we have to consider another weighted measure. And this weighted measure is given in terms of this M exponential, which is a little bit technical, but again, it's like the standard exponential, but also the parameter M is playing a role. Let's see. So it's just like a way to define this new function, which is an exponential which depends. An exponential which depends also on n. Is it can you write the definition or is it too too technical? It's a little bit technical, yeah. So it's uh it's a little bit involving, it's just like it's uh let's say it's a yeah, it's not also so necessary from my point of view, it's not so meaningful in the understanding of the theory. It's just the fact that they study, they managed to prove some geometric property of the manifold, studying the vast. The manifold studying the vast distance space and using this relative entropy, which has also this parameter n, and in for which it's meaningful to consider this entropy with respect to the reference measure, which is again given in terms of this M exponential. So, yeah, it's uh okay, fine. So, um in so So, using this bound on the n-ricci covert tensor, we can prove that already in the Euclidean setting we can find some nice example and also very, let's say, simple example of C D spaces for negative dimension, which are, for example, already the Euclidean space endowed with the Euclidean distance, and for which we consider this family of probability measures, which are called heavily tailed measures. Which are called heavily tailed measures, which were already introduced by Borel in the 70s and then studied by Bob Kov in 2007. And yeah, so this family of measures depends on a parameter alpha, and when which is positive and in a very high individual, we obtain spaces which are C D 0 minus alpha. This C n alpha is just a renormalization. Is just a renormalization parameter in such a way that this family of measures is actually a family of probability measures. So, this example was generalized by Milman in 2016-17 in the case of the sphere, the n-dimensional sphere, equipped with the heating distribution, which is a probability measure whose density is proportional to this function. And Milman proved that. And Milman proved that this family of measures on the sphere are such that the resulting manifold is a C D, something which is positive minus alpha space. So again, we have something which has a negative dimension. And again, all this definition relies on the fact that the n-weighted richie curvature tensor is bounded from below by a constant k. And indeed, this is just to recall that in the literary. To recall that in the literature before these results that we obtained with Mattia and Gerardo, there were already some results in the case of weighted Riemannian manifolds, and they were obtained by Nilman, Kolesnikov, and Hot and Takazo, indeed. While for the case of metric measure spaces, the only paper was the one of Hotta that now we are going to see a little bit more in detail, in which he's introducing a lot of the definitions. A lot of the definitions that we are going to use. So let's see what it means for a metric measure space to satisfy this C D condition for negative values of the dimensional parameter. So our starting point is the definition of C D spaces from the Lagrangian point of view. So using the theory of optimal transport. So we take a complete and separable metric. Take a complete and separable metric space and we endow it with our adon measure, and we take a parameter n which is greater or equal than one. So, this is just to recall how we define these C D spaces in the standard theory. We define a real value functional, which is called the Reni entropy, which takes value, which takes values from the set of probability measures with finite second moment, and it's such that if the probability of measuring the measurement And it's such that if the probability measure is absolutely continuous with respect to the reference measure and it has a density, the entropy is defined like minus the integral of this density to the power n minus one n over n and integrated with respect to the reference measure. If the measure is not absolutely continuous, we define the functional to be plus infinity. An important point is that the An important point is that the metric space has to be complete and separable because we want also the vastest space to be complete and separable. So, this is an hypothesis that we are always using. So, what Sturm did in 2006 is to introduce the class of CDKN spaces via the study of this entropy. And so, we say that a metric measure space satisfies the CDKN condition if for any Condition: If for any pair of probability measures, so in P2, there exists an optimal plan between them and a vast geodesic, such that the entropy functional evaluated along the geodesic is bounded from above by this integral in which we have these distortion coefficients that depends on k and n. And in particular, And in particular, when k is equal to zero, this distortion coefficient is equal to one minus t, this is equal to t, and what we obtain is exactly the convexity of the standard definition of convexity for the entropy. So the same approach is used to define the CDKN spaces when n is negative. Again, we define a suitable Renier entropy functional, which has again a real And which has again a real value functional, taking so as having as an argument measure simp 2. And it has exactly the same form, except from the fact that here we drop the minus sign. The reason being that when n is negative, this functional is already convex. And since we want the entropy to be the integral of a convex functional, here there is no need of the minus anymore. And what Hota proved. And what Hota introduced in 2015 is the definition of CDKN spaces, which is exactly as the one introduced by Schum. So for any couple of probability measures, we can find the optimal coupling and the geodesic in the Varsistan space such that this inequality holds true. And again, here the geosciential coefficients are exactly the same as the case of n greater than n. Of n greater than zero. And so here we have just remembered that the behavior that we had in the case of the CDKN spaces with n positive and k positive, now we have it when k is negative because the signs are going to be inverted. So, as a first list of properties, so now we have, at least in the case of weighted of the weighted Riemannian manifolds. The weighted Riemannian manifolds, we have two different notions, so or better. We have the notion of the C D condition introduced in terms of optimal transport, and we have also the study, so the more classical study using the n weighted Richie curvature tensor. And what is known in the literature when n is greater or equal than the topological dimension is the fact that these two approaches are actually equivalent. Are actually equivalent. So the fact that the space satisfies the CDKN condition and the fact that the n-rich curvature tensor is bounded from below by a constant k. Hota, in his paper from 2015, proved that also when n is less than zero, the two approaches are equivalent for weighted Riemannian manifolds. And so this is already an important point that the actually the two theories coincide. Two theories coincide. Another observation always due to OCA is the fact that this class of CDKN spaces with the n which is negative includes all the standard CDKN spaces for n positive and also the class of CDK infinity spaces. So, in a certain sense, we are enlarging our theory. So, another important result that Houghton introduced. That Houghton introduced is a definition or the result is the notion of Kn convexity for a function defined on a metric space. So we say that a real-valued function defined on a metric space is a Kn convex if for any couple of points which are in the domain of the function, and we have to assume also that the distance of the points is bounded from Is bounded from above by this parameter by this constant when k is negative. This always due to the behavior of the coefficient, the distortion coefficients. So we say that this function is Kn convex if there exists a geodesic gamma such that the function fn evaluated on the intermediate points of this geodesic is bounded from above. Is bounded from above by this expression where again we have these distortion coefficients, and this fn is the exponential of minus f over n. So with this definition at disposal, what Horta proved is the fact that if we have a weighted Riemannian manifold which satisfies the C D, let's call K two and two condition. K2 and two condition where N2 is greater or equal than the topological dimension of the manifold. Then and we have also a capital Psi, which is a C2 function, which is K1 and one convex. Then, if we consider a double, so weighted another weight on the measure, which is given in terms of this capital psi, then the resulting weighted manifold is. A weighted manifold is a C D K1 plus K2 N1 plus N2 space. And this N1, we chose it in such a way that N1 plus N2 is still less than zero. So what we have is exactly that once we have a weighted Riemannian manifold satisfying the CD condition and we weight it again with a C2 function, which satisfy another K1 plus and one And one condition of convexity, the resulting weighted manifold is a C D something which is negative, so in the parameter of the dimensional space. This is very important because using this result on weighted manifolds, what we did together with Matti and Gerardo is to produce some new class of examples. And already in the case, in the one And already in the case, in the one-dimensional case, we can find some nice examples, some let's say, some particular examples. So we take a parameter capital N, which is less than minus one, and so we consider the real line equipped with the Euclidean distance and the Lebesgue measure. So what we proved is that the R in so this space, which is again the real line. Which is again the real line, the Euclidean distance, and this weight on the Lebesgue measure, the weight is formulated in terms of this function. This is a C D K n plus one space. So n plus one is going to be always negative. And so here we have something which has a positive curvature. And so this function, this weight, is the hyperbolic cosine to the power n. To the power n. So, this is a nice example, but it's not, let's say, so interesting. But another interesting example, still when k is greater than zero, is the fact that the half-line is equipped always with the Euclidean distance, and this weight on the back measure is again a CD space. And this weight is the hyperbolic sign to the power n with the negative. To the power n with n negative. In particular, this function is exploding close by zero. But since we said that we want a metric space which is complete and separable, because for the study of the optimal transport, we want also the vastest time space to be complete and separable. We have to include zero in our space. And so this is even more clear in the case in which we are treating RCD. case in which we are treating a C D zero n plus one space because again we have the half line and as a weight we have the the function x to the power n. Since n is strictly less than minus one and we are in dimension one this function is never integrable around zero so it means that every ball center in zero is such that the measure of the ball is equal to plus infinity measure of the ball is equal to plus infinity. So already we it's clear that our setting cannot be cannot be the one of just the setting of radon measures. And this is also clear another similar behavior. We have it when k is less than zero, because we have that the compact interval, which is given by minus pi over two and pi over two, so let's suppose that k is equal to n and the And the weight is given by the cosine to the power n with n is negative. So this function is exploding close by these two points, minus pi over 2, pi over 2. And so in particular, the measure of this compact interval is equal to plus infinity. And again, we have that around these points, every ball centering these two points is equal to the hasma mass, which is equal to plus infinity. Is equal to plus infinity. So these are the first set of examples that we found. And as we were saying, what we did is to introduce a larger class of measures. So we take again the matrix space to be complete and separable, and we say that a sigma finite measure is quasiradon if there exists a set that the singular set with the noted. The singular set we denote it by Sm, which is closed, it has measure equal to zero and it has an empty interior, but is such that for any point in this SM, if we take a neighborhood of this point X, then the measure of the neighborhood is always equal to plus infinity, which is the thing that we were saying before about the balls centered in zero or minus. In zero or minus pi over two pi over two. But we have still a nice property on the measure, which is the fact that if we restricted it to the complement of the set of these nasty points in SM, then which is an open set, then the restricted measure is actually a Radon measure. So from now on, our setting is the one of metric measure spaces where the measure M is actually. Spaces where the measure M is actually quasi-Radon. In the following, we are going to consider pointed metric measure spaces, so in which the point P is in the support of the measure. And another terminology that we are going to use is the one of MathBBX, which are the equivalence class of pointed metric measure spaces, in which we also select class. We also select a closed set with empty interior, and the measure of this closed set is equal to zero. So, as you can expect, this set C in general will be taken to be the set of the set SM, so the singular set for the measure. But some of the definition we are going to introduce it when this C is more general. So, let's keep it like this for now. So, going back to our set of examples, the first one in which we had the real line with this very nice weighted measure in which this function is never exploding. So, this function V times the Lebesgue measure is actually a Radon measure. And so, the set of singular points is equal to the empty set. So, our class, the class of Radon measure is actually contained in our class of Contained in our class of quasi-radon measures, and the radon measures are the one for which the singular set is equal to the empty set. As for the second and third example, Sm is exactly equal to the point zero. And as for the last example, the set of this singular set is equal to minus the two boundary points. Two boundary points, so minus pi over two and pi over two. So at the beginning, actually, we were expecting that this kind of behavior on the measure was appearing just on the boundary of the boundary points of our manifold, let's say, because the way that we built these examples is just taking a manifold and then weighted it with a function that it happens to explode close to the boundary points. To the boundary points, and so we were hoping that this kind of nasty behavior of the measure was just something which was confined in the boundary points of the manifold. But we discovered that this was not the case, because if we take the second and the third example, which were so they are defined on the half-line, and we reflect the behavior for positive values of x to negative value to the negative values of x, what we obtain. Of x, what we obtain is the space which is the wall real line. And the functions are the these weighted functions are such that they are still the same, so they are exploding in zero. And the point zero can be obviously a middle point of geodesics in our space. Moreover, we can produce a space with as many as this nesting. As many as these nasty points as we want, just taking the compact interval, translating it, and gluing together J copies of this space, and this is still a CDK negative n space. And so, in particular, all these intermediate all all these points in which we are gluing to copies are actually inter can be intermedient points of geodesics in the space. Of geodesics in the space. So I don't know if there is some questions. Can I ask you a question just because I'm not understanding a small thing? So the it's not going to infinity, right? So about exin zero is zero, right? Sorry, I lost the first graph. The weight is vanishing. Is vanishing in zero, right? But we have here, so it's vanishing in zero, but we have this thing, the negative value. So my say, n, yeah, n is negative. Right, right, right, right, right, right. Which is very important because this is the reason that we have these weights which are when without the end, they are all nice because they are vanishing in zebo. All nice because they are vanishing in zero, but since we have the negative n, everything I get to get them accustomed to the negative n. Thank you. So, what we wanted to, the result that we were expecting or we were hoping for was the stability of this condition. And so, we assume that our sequence of metric measure space satisfied the CDKN condition for negative n. Condition for negative n, and that this sequence is converging to a limit structure. This is in our suitable topology with respect to a suitable distance. And we would like to say that also the structure which is at the limit is still a CDKN space. But as you can expect, already the first major difficulty is to understand. Major difficulty is to understand in which sense these metric measure spaces, in which the measure is so nasty that is exploding in some points, how we can define a suitable notion of distance between these structures. And the second difficulty in the proof of this result is given by the fact that the proof when for the condition C D for positive The condition C D for positive n relies on the fact that the Renee entropy is lower semi-continuous on the vastest time space, so on P2. But in this situation, the only thing that we can prove is that a weakly lower semi-continuity in the set of measures in P2, which are not charging mass on the set of our nesty points, so on our singular set. So let's start with the first problem. So, the one of defining the distance between these structures. In any case, if there are questions, just interrupt me because now we go in a bit on technical things. So it's not okay. So let's go on. So we fix a cutoff function, a lip shift function. function which is defined so for positive on zero plus infinity and takes value in zero one and is such that the this function is equal to one in the interval zero one and is equal to zero outside when x is greater or equal than two so using this cutoff function we we define the function fk which is such that the the when the That when the measure is radon, so when the set of points, of singular points, is equal to the empty set, then this function is equal to zero outside a ball around the point P. So we are in a setting of pointed metric measure spaces. So we have this point P and we have the ball which has a radius 2 to the power k plus 1. This function is a One, this function is equal to zero outside this big hole. While when the measure is a quasi-radon, so the set of singular points is non-empty, we have again this term which ensures that the function is zero outside the big ball. But we have also this term in which is saying that our function is equal to zero on a small neighborhood of Sm. Of Sm and this small neighborhood has the size of 2 to the power minus k plus 1. So we take this, we use this function fk to define our kth cut of the measure, this measure mk, which is nothing but our reference measure m multiplied by the function fk. So now we obtain a metric measure space which is given a pointed. Measure space, which is given, a pointed metric measure space, which is given by exactly the same space as before, but the measure now that we are going to consider is the measure MK. An important point to notice is that we are not cutting the space, but we are just cutting somehow the measure in such a way that we are excluding the set of nasty points and we are localizing our measure on the big poles. On the big walls. So now we want also some other regularity in order to make sense a bit of this set of nesting measures. We require a bit of regularity on them. And so in particular, we assume that the measure of the world space with respect to this Mk of the world space is always finite for any. Always finite for any k, which so it's saying us that the measure is always finite on big balls. And plus, another thing is the existence of this regularity parameter, which is given by this k bar. And it's such that for any k which is greater or equal than this bar k, it holds that the measure of the space is also. Of the space is also greater than zero. So, this means that we are not, when we exclude the neighborhood around the set of singular points, we are not throwing away too much of the mass. So there is always a little bit of mass which is conserved. Moreover, we define the set of a K regular point, so the K regular set, which is, as we expect, is given by the big ball minus. Given by the big ball minus the neighborhood of these points. And the important point is that when we restrict our reference measure to this k regular set, we find a finite measure, and the support of this mk is exactly given by this k regular set. So, with this notion at this position, we can now proceed in the finding. Proceed in defining the distance between these metric measure spaces. An important point is that the ideas to introduce this distance really rely on the paper of Gilly, Mondini and Sabare, in which they prove the stability of the R C D K infinity condition. But in their situation, the measure is radon. So in our situation, we have to deal also on the set of in which the On the set in which the measure is exploding. When our quasi-radon measure is actually radon, our construction is going back to is actually equivalent, is exactly the same as their construction. So first of all, we fix a cost function, which is a continuous function, which is non-constant and is concave, and it's such that this zero is zero. And when the parameter is going to plastic. When the parameter is going to plus infinity, the cost function is going to be finite. An example is the hyperbolic tangent, or we cut the distance with the one. And these are two examples of these cost functions. Then we can define the intrinsic Antorovich-Rubis time distance between two probability measures defined on a complete and separable metric. Defined on a complete and separable metric space. And here we set it to be: so we take the integral of the cost function on evaluated on the distance of points, and we integrated it with respect to an admissible coupling between m and n. And then we take the infimum among all these admissible couplings. What we gain in considering this cost function is the fact that here we don't have to consider That here we don't have to consider the measure the set of probability measures with finite second moment, but we can consider any couple of probability measures. Now, using this WC, we can introduce the distance between two metric measure spaces with finite mass. So now M1 of X1 is finite and M2 of X2 is finite. So we define, and moreover, as we said. Define and moreover, as we said before, we have these two sets C1 and C2, which are closed sets with empty integer and measure equal to zero. How we define this distance is taking the, so we take this term which measures how far are the two measures from being like, let's say, a probability measure. So you have this the logarithm of this. The logarithm of this fraction. And then we have a second term, which is an ininfimon over all the isometric embeddings of our two metric spaces into a complete and separable metric space XD. And what we do is to see the distance of the images of our two reference points. Then we see the Hausdorff distance. Then we see the Hausdorff distance of the images of the two closed sets, C one and C two. And last term is the WC, distance of the push forwards of the two renormalized measures M1 and M2. And this gives us a distance between two metric measure spaces with finite mass. Very well. Now we use this. Now we use this distance as we can expect when the metric measure spaces are defined with our cut on the measure. And so we say that a couple of metric measure spaces, so we define the intrinsic altars-Ruby stand-lasting distance, just taking this sum over all the, so this. the so this uh the sum the sum is taken um for k which is greater or equal than k bar which is the common regularity parameter we said that the regularity parameter before was the one ensuring us that even if we take away a bit of of the so the neighborhood along around the set Sn, we have still mass on the space. Since here we have just two spaces, we have a common regularity parameter. We have a common regularity parameter, which is just the maximum between the two regularity parameters for the measures. And we can define the distance between the two metric measure spaces using this mass, in which we have this term, which is rely on the fact that here we have the measures which are finite on our, the measure on Mk are finite. So this distance allows us to talk about. This distance allows us to talk also about convergence. And so we say that a sequence of metric measure space is a IKRW converging to a metric measure space. So if there is a common regularity parameter, now we have a sequence, so we have to require the existence of this parameter. And the limit of the distances between xn and x infinity is going to zero when n is going to be. Is going to zero when n is going to infinity. Very well, so now this is the intrinsic distance, and we see as the first properties that the fact that this convert, this distance is going to zero is equivalent to the fact that also the distance of the spaces with finite mass is going to zero. And here, the cut of the measure was taken. Measure was taken for any k which is greater or equal than the regularity parameter associated to the convergence sequence. Moreover, the fact that this distance is going to zero is equivalent to the existence of this effective realization for the convergence, meaning that there exists a complete and separable metric space and a sequence of. And a sequence of isometric embeddings from Xn to the common metric space, for which we have that this, so the one that was defining the distance, is going to zero. And here, all the distance are taken with respect to the distance in the metric space in which we are embedding everything. This is very important, this second characteristic. Important is a second characterization because it allows us to talk about also extrinsic convergence. And we say that a sequence of pointed metric measure spaces converts extrinsically to a metric measure space if there exists a common regularity parameter and there exists a complete and separable metric space and a sequence of isometric embeddings for which this quantity is going to zero and now we notice. Is going to zero, and now we notice that here the term involving the Hausdorver distance of the so the singular, the embedding of the singular sets has actually disappeared. So we have just the term measuring the distance of the two measures from being a probability measure. This is the distance of the embedded points in the sequence of spaces. Of spaces, and this is the WC distance of the push forward of the measures. So, paying the price of having from the beginning an effective realization for the convergence, we can get rid of the fact that we have to consider the distance on the household distance on the closed sets. The reason why we were interested also in this kind of Also, in this kind of convergence, was due to the fact that we were hoping to find also a way to approximate our half-line, which was given by zero included plus infinity with, for example, let's think about our measure, which is x to the power n. We would like to approximate this example by a sequence of spaces which are 1 over n plus infinity, so we are cutting the. Plus infinity, so we are cutting our half line close by to zero. But what happens that in cutting our space, we are also cutting the set of points in which the measure is actually exploding. So along the sequence, we would have actually a sequence of C D spaces for which the measure is radon. And what we obtain at the limit is a measure which is quasi-radon. But in this, for example, this particular This particular example is covered by this extrinsic convergence because we know that everything can be embedded again in the half-line, and there is no more need to talk about the house of distance between these singular sets. So, with these notions, this definition at our dispose, we have also to introduce another definition, which is the one of the approximation. Which is the one of the approximate CD condition, which is so we say that a metric measure space satisfy the approximate curvature dimension condition if the C D condition holds when we require that the two measures mu0 and mu1 are such that their support is actually contained in the regularity in the KF regularity set. This is in this This is important because, as you can expect, we need some approximation in order to get our result. And another important observation is the fact that our kth regularity set, so Rk, in general is not geodesically convex. So it can happen that actually we start with two measures, mu0 and mu1, which are the support is contained in RK, but the and we But the, and we take the W2 geodesic, we evaluate, we see that the measure, we see the measure of mu t, and what we have is that the support of mu t is not contained entirely on a RK, but it has a bit of mass which is going outside. This is important because again we introduced this definition of This definition of omega uniformly convexity, and so we say that a metric measure space is omega uniformly convex if there exists a function omega which has the following properties. So once we take two probability measures, measures with finite second moment and the entropy, which is bounded from above by a constant m. And they are such that so that And they are such that so that our these two probability measures have the support which is included in the cave regularity set. Then we have that the middle point mu t is such that it gives as the mass of mu t of the H, so another parameter regularity set is bounded from below by From below by the one minus some constant. What does this mean? So, this constant is exactly the one, this function omega gives exactly a bound on how much of mass we can lose outside Rh. And the important point is that, as you can expect from this thing, when Rk When Rk is actually geodetically convex, the function omega kkm is equal to zero because being geodetically convex, nothing is going outside. Instead, if the support of muti is a subset of the complementary of RH, this omega is exactly equal to one. Is exactly equal to one. So again, is exactly how much of the mass we are losing. And we would like to have it a control which is uniform. That's why we need this definition. This second property is very natural once we set this thing that this omega k H M gives us a way to measure the mass which is going outside the H cut, because when H is going to Because when h is going to go to plus infinity, this regularity set Rh are going to invade our space, and since the support of multi is contained in the space, this function is going to zero. So this is important because, as we said, what we now have stability, we would like to have a uniform control along the sequence of this quantity. So we take a sequence of We take a sequence of metric measure spaces which is converting in IKRW distance to a metric measure space. And we assume that in each step, so the metric measure space is a CDKN space with n which is negative. We assume that there exists an omega for which each metric measure space along the sequence, so each Space along the sequence. So at each step n, this is a omega uniformly convex set, space. And plus, we need some bound on the diameter of the metric space once the curvature is less than zero. And this is again just a matter of the distortion coefficients that they are going to explore. So, what we have, if we have these conditions which are satisfying, is that Conditions which are satisfying is the fact that at the limit we have a CDKN space. Moreover, this is also true if we have a sequence of spaces which is extrinsically converging to a metric measure space and these three conditions are satisfied, then what we have at the limit again is a CDKN space. So this is the result. I would like just to see some show To see some, show you a bit of the ideas of how we can prove it. So, first of all, just a matter of terminology, we want to prove that Sn, the entropy is less or equal than this integral that we call it T of Kn. And so, we have the important point is that here we have the pi, the optimal coupling between the two measures. Between the two measures, and here we have the reference measure. So, this is the thing that are actually entering into this function. So, we want to prove that for any couple of probability measures with finite second moment in X infinity, there exists a vassel standardizing and an optimal plan for which the curvature dimension is satisfied. And in order to do it, we will use. To do it, we will use two kinds of approximations. We call the horizontal approximation, the one which is done at the level of the single space, so xn x infinity. These are horizontal approximations, while we call vertical approximations the one that are so are are approximating our finite measures in terms of the single spaces xn. Spaces Xn. So, how we argued was like, first of all, assuming that the support of the two measures, mu0 and mu1, were actually included in the case regular set of x infinity. And then what we do is to consider this map P and K, which is an optimal coupling between the K measure. measure the k-cut of the measure in m infinity and the k-cut of the measure at the level of xn. So we take this map, which is the optimal coupling between these two probability measures, and making use of it we can project the measures, the measure mu0 and mu1, which are in p2 of the limit space, to the single layers of Single layers of so Xn and we find so this approximating sequence made of this mu n i and this is our vertical approximation. Then what we do is we know that actually at in each single X X n in each single metric measure space in the sequence of X N, Dn, Mn, we have that the C D condition holds. And so what we And so, what we can find is a pair of W2 geodesics in each single space and the optimal couplings for which the CD condition is actually satisfied. Passing to the limit in the vertical limit, so this vertical limit we refer to this from xn to x infinity. To x infinity, then we can find that there exists a limit multi pi that so far we cannot say that is a the right couple satisfying the CD condition. But once we prove the lower semi-continuity of the entropy functional and the upper semi-continuity of the functional T along so the sequence of xn, then we can conclude. We can conclude that actually the approximate C D inequality holds for the limit space X infinity. Approximate because we have said that the support of the two measures is contained in the K-the regularity set of the space X infinity. So far we have obtained this partial, so far, just partial result. What we want to do is to extend. we want to do is to extend also the case in which the measures mu0 and mu1 are actually in a p2 of the of x infinity and in order to do it so now we we we apply an horizontal approximation so we start with these two measures and using this horizontal approximation we can find a suitable sequence of measures which are converging w2 converging to Converging, W2 converging to mu0 and mu1 respectively, and they are such that at each single step K, the support of the measure is contained in the KF regularity set. Then, again, the approximate CD condition ensures the existence of the geodesic in P2 between the two measures and the optimal coupling such that the CD condition is such. The C D condition is satisfied. And again, the lower semi-continuity of the entropy and the upper semi-continuity of the functional T allows us to conclude that the C D condition holds also for this metric measure space at the limit. And this is what I wanted to tell you, and I thank you for your attention. Thanks for Thanks for the nice talk. Are there any questions? Okay. Can I ask a question? So are there any for this distance that you define under the your assumptions on C D K M with negative K. With negative K. Will you have any sort of pre-campaign statements or maybe under some extra assumptions like away from the singular set, do you have any kind of local doubling on these regular parts? This is a very good question because we are, yeah. So, the pre-compactness in general is something that we cannot expect. Yes, because like we do. Yes, because we cannot expect that the set of all the closed subsets is a singular set is a yes, I can that is pretty clear, right? But I'm not sure if you can do something to yeah, this is a yeah, it's very natural and very nice question. Also, this thing of the doubling condition, because it would be nice to have some doubling, like at least in some region of the space. At least in some region of the space. Right, right. But it's yeah, it's not so trivial because the C D condition is actually going in the wrong direction. Yes. So you will have some bound from below on the growth of the balls instead of above. And so this is something that is not clear. So it's nice, but it's we don't know so far. Okay. Can I ask a question also? Of course. I mean, just a booster. So, right, because so this CDKN with negative n includes also CDK infinity. And CDK infinity, I think we don't expect it to be locally doubling. No. Right, so maybe this is probably. Oh, or it includes CDK infinity somehow. I see. Yeah. Right. So I think this is kind of an abstraction. At least, like, let's say, in a say, okay, in some models or some with some additional assumptions, yeah, and some additional assumptions somewhere away from the singular set. I don't know. Yeah, it's impossible some natural conditions because this is yeah, yeah, yeah, yeah. Right, well, one is to you, you could, yeah, one minute. I don't know, like at least like say okay in the grid. Say okay in the class of CDKN spaces with negative n, if you have locally doubling, then you have to be automatically a CDKN space with n finite and positive would be, however, a good result. Sure, sure, sure, yeah, yeah, yeah. Yeah, and then kind of on the same steroid question, what kind of say geometric inequalities or geometric say estimates properties can we expect on CDK? Can we expect on CDK and spaces with n negative? So you mentioned some lower bound of volume of bolts. So of which kind? So it's kind of a reverse bishop gromo? I don't know. What kind of... Yeah, so like it's a bound of, let's say, the ball. So in, let's say, you have two balls and you can estimate the volume in the small ball with respect to the volume in the ball. With respect to the volume in the big ball. It's something in a quantified sense. Okay, so with okay, with estimates. I see. Then there are some, yeah, like Ota introduced some Talagrand inequality or so we have some inequality on the entropy and this kind of inequalities, but for many of them, it's not also clear if you how we. Which kind of conditions you have to put on the explosion of the measure, let's say. I see. Already, like we have these models, but it's let's say already it's not so easy to formalize how fast is the measure exploding because if you want to be just in the setting of a metric measure space, it's not clear to give a formulation of these things. Yeah. Right. But say these, I say, say, is it the CDKN coin? This, I think, say, is it the CDKN condition giving some bound on how fast the weight can explode? Because you are getting some inequality. No, is it going in the wrong direction? Okay. It's going the wrong direction. I see. So I can read. Okay, just I see. I see. Yeah, because exactly you can estimate the volume of the big wall with the one of the small walls. Right, right, right, right, right, right, right, right. Yeah. And plus, like, this volume has to be what. This volume has to be when you don't intersect the singular set, otherwise, everything is pass infinity. Okay, right. And can you define the Chigger energy on this kind of spaces? We are working on it with Mattia, Verencio de Los Cabo, and Kuhai Sutuki. Okay, because then the natural question would be: is there an Eulerian formulation using the Chigara energy and etc.? And this is what you're trying. Yeah, the standard. What we are trying, yeah. The standard theory is uh seems to be a little bit like uh uh far, in a sense, we are very far in the second long-term project. Yeah, indeed. So, let's see what that the formulation seems to be quite natural, then the equivalence with the Lagrangian approach is not so straightforward, especially because you need like some stochastically completeness, like in the paper in the work of Ambrose Gili Savare. Work of Ambrose Gili Savare is formulated in terms of the growth of walls, and in our situation, we don't have it. Okay, yeah, thank you. Very nice talk and problem. Yeah, I have a very basic question. So, the examples you presented at the beginning with the lines and concentrated measure, can you say something in those? Like, can you construct examples? Like, can you construct examples where somehow the measures are getting nicer in the limits? Or it's something that you would in general expect because somehow you're cutting off where the measure is blowing up, right? So these examples. Yeah. So you mean that so something that along the sequence is a quasi-laden measure. Is a quasi-radon measure, but at the end you have something which is Radon, you mean? Yes, something like that. This is something that we could not expect. Let's say that when things are going to be like they are going to not improve, but making worse, it can be, not like the fact that you are regularizing along the sequence. We don't expect it to be true. Especially because, let's say, when the intrinsic convergence. Intrinsic convergence, you have always this term which involves the fact that you have the distance, the outsource distance of the singular set with the one out the limit. So it's not so plausible that at the limit you have something which has a singular set which is empty, while along the sequence you had something which was quasiladon. Yeah, I see. Thanks. Thanks. Are there any more questions? Maybe one. Sorry, this is just curiosity. So, you mentioned some examples entering into this class. So, what and say this example, where do they come from? The CDKN condition for N positive N is kind of some geometric, say, usually this weight comes from collapsing, and they have some geometric motivation and say. Geometric motivation and say these weights that show up in negative n, they show up for improbability. So, what is the so? This is just like the construction based on the result of auta, which is the one that I was mentioning, the one of Kn convex functions. So, we know that the logarithm of this function is a Kn convex function. You can prove it by hand with. By hand with n which is a negative. Okay, but say that one by Bobkov, Milman, etc. They so basically so was basically solve an differential inequality and produce a weight or this kind of weight were kind of natural from other fields and probability or other motivations? Yeah, exactly. These are already like something which is uh which was already clear. Let's say they are models. Let's say there are models, so these ones, they are this class of measures, and you can prove that actually there are C D 0 minus alpha spaces. But these are examples in which the status measures are probability measures. And yeah, and these are for sure interesting, but it's something which is a more level standard. And as you said, it's a customer. Model standard, and as you said, it's a classical in the theory. Yeah, right. But say these ones were so they constructed these examples or they were kind of so my question is say is basically so what what is the the real motivation for this theory of uh of negative n is it geometric is it analytic it is uh it can compility so yeah it's kind of okay so the the the thing is uh The thing goes back to this paper by Hota and Takatsu. Yes. So the reason why they started studying this Milma pao. So these papers come from after this paper by Hot and Takatsu, in which this M-relative entropy is studied. And this is so it has an approach which is based on actually the porous medium equation and all these. Equation and all these fast diffusion equations. So let's say that these are, if I'm not wrong, when m is greater than one, it's the fast diffusion equation of all the tasks for sure a base on the PDE approach. And here, the fact that this relative entropy is a k-convex in the vast distance space was studied by Hot and Dakatu, and it has also this geometric application in the theory of. In the theory of rich equivalent tensors. Okay, thank you. Yeah. Maybe I can ask one question. Yes, so is there any example of space that would satisfy this for all negative n, which is not c d k infinite. Already our examples are not C D K infinity spaces. Our class of examples are C D K infinity C D K so for example this space the half line is a C D zero minus something space but is not a But it's not a C D K infinity space, C D V O infinity space. Right, but this, I mean, so when you fix N, this satisfies it only for some N, not for L, not for any, right? I mean, the space you mean for any negative N? No. Yep. This, no, I am not aware of it. Okay. Second question. Also, because actually there is like the monotonicity goes in the wrong direction, in the other direction, let's say. So you know that when let's say when you have positive n, a C D K n space is also C D K infinity space. And what Hota suggests is that plus infinity is equivalent to minus infinity, meaning that the entropy when you let N go into minus infinity. Going to minus infinity in our Reni entropy, you obtain the integral of rho log rho. So now, when something is a C D k minus infinity is a C D K minus N, so n negative. So it's going from minus infinity up. Let's see. I don't know. More questions to enrich the discussion? If not, we thank Chiara again for the talk and for the discussion. It's my great pleasure to introduce Chin Don from MIT, who is going to talk about the regularity of Lagrangian flows on RCDKN spaces. Flows on RCDKN spaces and applications. Please go ahead. Thanks. So it's a great pleasure to be here. Thanks to everyone for coming to check this out. And thanks to the organizers for inviting me. So I'm going to talk about the regularity of agronomic flows and also some applications of it. So this actually came out of working on the whole responsibility of Continuity of tangent problems. The methods used, at least in the general case, is an extension of the methods used in that paper. I will say the result is somewhat technical and the proof is sort of long and kind of annoying in some senses. But I think there is some ideas in there that's kind of cute. And I hope you'll find that interesting. It's very non-smooth in flavor. And also, of course, I think once you get away with it. I think once you get away with it, doing once you're done, all the technical details, and you really do get something about the flow of vector fields, which is sort of ubiquitous harmonic geometry. All right, so it would be good to have. All right, so let me. Sorry, maybe just me, but your mic your sound seems to be kind of cutting in and out. I don't know if you can. Okay, let me uh Can you just use it? Is this better? Yes. Okay, great. Thank you. So, all right, so let's start. So, let's talk first about the regularity of the bond and flows. Sorry, let's talk first quickly. Sorry, let's talk first quickly about what a regular quantum flow is. Okay, so the setup we have XDM, which is RCD space, okay, and then we have a vector field, which is L2. Okay, so that basically that means just if you look at the norm of the vector field, it's in L2. And so we say that a map from time zero to t across x into x is a regular Lagrangian flow of this vector field. Of this vector field. If the following three conditions hold, well, first, at time zero, it just takes x to x. So, you know, at time, if you think about this map as an x, a map from x to x, at time zero, it's identity. The second condition is a bit longer. It says if you have a Lipschitz function g, and then for almost every x inside of the space x, the map t to g composed with the flow map. T to G composed with the flow map is absolutely continuous. And in fact, you can differentiate it, and it comes out to be this way. So, what this basically means is: so, first of all, this condition kind of forces for almost every x for this to be a continuous curve, okay, like depending on t. So if you start an x, it's continuous. And then the fact that this derivative is what it is is basically just saying that it's pointing at the right direction. So, at any given time t, it's pointing in the. It's pointing in the direction of the vector field at that point. So, and of course, since we're working in RCD space, everything's measured almost everywhere, and this is sort of defined by duality, okay, which is fine for us. Okay, and then the third condition is that there exist an L so that if you push forward, sorry, there should be a bracket here. If you push forward the measure under the flow map, so if you sort of The flow map. So if you sort of fix a t, then it's really a map from x to x. If you push forward the measure, then it's bounded by lm for every time. Okay, um, so I point out sort of this has a lot to do with the divergence of the vector field, okay, because the divergence of the vector field controls how the volume behaves as you move along the vector field. And also, this has a lot to do with uniqueness. Okay, so if you think about a situation where the vector field is, let's say, Is let's say, uh, let's say you're just on r and then the vector field is something like root of x. Okay, then if you look at sort of flows, you know, in theory, you can stay at zero for a very long time before you move on, okay? But then the only type of flow where you have this kind of condition is exactly when you sort of move on from zero right away, okay? So, so this sort of this condition sort of makes sure you have some sort of uniqueness, right? So, um Sort of uniqueness, right? So it's a result of Ambrogio and Trevissan that in RCD spaces in particular, although it was a bit more general than this, that if you have a vector field which is in this, this just means it has an L2 hash, L2 covariant derivative with bounded divergence, then it emits a unique regular Lagrangian flow. Okay, so these are the objects of interest. We're going to sort of study the regularity properties of this, in particular, how distance changes as you move along. Distance changes as you move along these flows. Okay, so the first thing I want to do, okay, so is to sort of mention the main result. Okay, so I put theorems in quotation marks because it's actually upcoming work. Okay, so I haven't written everything out fully yet, but so in quotations. So suppose we have a B vector field, which is in H12. Again, that means it has O2 covariant derivative. To covariant derivative, and it's supported in some large ball. And then, suppose you also know that the norm of the vector field and the divergence of the vector field are L infinity. Okay, now if you consider the flow map, the associated regular Lagrangian flow, the claim is that give me any epsilon. Okay, I can find a large set S inside of this ball, okay, and some constants. Okay, and some constants such that, so first of all, the set is large in the sense that if you take it away from the ball radius r, it's less than that epsilon. Okay, so I can find a large set. And so that if you pick any x and y in the set, in this set, and you pick sort of two times, then the change in distance along the flow from time t1. Along the flow from time T1 to T2 between X and Y is bounded like so. Okay, so this is the holder bound depending on time. So I'll say quickly that this C0 here and this omega zero, which is sort of just how much time you can look at, depends on the L2 norm of the covariant derivative, the L infinity norm of B and its divergence, the structural constants K and N, and this epsilon right here. And this epsilon right here. Okay, but the important thing to note is that it does not depend on the original, it does not depend on sort of the distance between x and y here. And so in particular, you can compare sort of two points that are for a long time, right? Like these things can be very close compared to the time in which you're flowing them by. Okay, and so that's very important. Any questions about this? Result. Okay, so I'm really saying for a large amount of time, the distance changes in a whole trip continuous manner. Sorry, for a large amount of space. Okay, so then let me first of all describe what goes on in the smooth setting. And while I'm talking about this, I urge you to sort of pay attention to which part of this will generalize to the RCD setting and what ingredients we're missing. And what ingredients were missing. Okay, so and I should actually also mention before that that this result is in the full generality for RCT spaces, but in the non-collapse case, a version of this was proved in my paper with Elia Brew and Daniel Asimola. So I'll talk a little bit about this later as well. Okay, so let's go to the smooth setting. So in the smooth setting, we're looking at a compact harmonic manifold. I just say compact. Manifold. I just, it I just say compact here just to get rid of the ball radius r, like we a big, big R, like I'm let's just pretend the diameter is finite. And suppose we have a smooth vector field and let F be the associated flow. So we want to control, we have two points X and Y, okay, inside of the manifold. And for simplicity, let's assume there's a unique geodesic unit speed, let's call it sigma, between X and Y. So sigma zero is X and Sigma D is Y. is x and sigma d is y. Okay, so we want to control the distance between x and y as you flow by ft. Okay, and so here I'm just writing out two formulas. First of all, if you differentiate the distance at time zero between the two flows, then this is the first variation formula. Okay, it basically says that, okay, maybe let me just quickly draw this. If you have x and Quickly draw this. If you have x and y here, and this is your sigma, then and you're sort of interest, and you're flowing around here and here. So these are your directions b then the first derivative in distance as you flow along can be computed sort of using the inner product here minus the inner product here. Okay, that's all. So this is first variations. So, this is first variations. And then there's a second variations formula, which lets you sort of interpolate sort of what this difference is. So we're interested in this difference because it tells us the derivative. And that basically comes down to the covariant derivative of B. It says if you can calculate this difference by integrating along this curve, the covariant derivative of B applied to the tangent vectors of the geodesic. To the tangent vectors of the geodesic along with geodesic. Okay, so first variation formula and second variation formula, that's all. Okay, and let me just quickly point out that the second variation formula is sort of equivalent to the following thing, right? If you have if you have your vector field is the gradient of some function, then if you have this formula, which we do in the Riemannian case, it says if you differentiate, take two derivatives. you differentiate you take two derivatives f composed with the geodesic then it's a Hessian of F sigma prime sigma prime so if you integrate this once ds this side just becomes the difference of first derivatives which is exactly this diff this difference right here right and then this side if you integrate it is exactly like this right because a Hessian of f is the same thing as a covariant derivative of the gradient of b right so so as long as you have something like this then you can you have the secondary Something like this, then you can you have the second variation formula. Okay, and the reason why I'm pointing at this out is because later on we'll see that sort of this is what you have in the RCD setting, and so you can expect this type of formula as well. So this is how you would control the distance along the flow. Now, notice if you have an L infinity bound on the gradient on the covariant derivative of B, then you actually have pointwise control on this derivative, okay? Because you can just estimate this. Because you can just estimate this and therefore estimate this. So the question is: okay, well, what if you don't have L infinity bound? Now, of course, since we're in a compact manifold, you do, but let's pretend we don't have a quantitative L infinity bound, right? Let's pretend we only have a quantitative L2 bound on the covariant derivative. How do we handle something like this? Okay, so for this, you wouldn't be able to control things pointwise, right? Because it's an integral estimate now you have on the covariant derivative. On the covariant derivative. So, what you would try to control instead is the integral distance along the flow. Okay, so in other words, you would try to control, let's say, if you have two sets AB inside of the ball, you would try to control the integral of the distance between pairs of points in AB as you move along the flow, between every pair, right? So let AB be in the ball and let sigma xy be a unit speed geodesic so that at time zero. Be geodesic so that at time zero it's x and time dxy it's y. Okay, then first of all, we can just integrate the formula we had before where x and y can vary across a cross b. So x is anything in a, y is anything in b. Then you get this formula right here. This is just integrating what we had before on a times b. Okay, now these things are unit speed. So the geodesics are unit speed. So this is just As extra unit speed, so this is just norm one, both of these. So you can use Cauchy Schwartz to just get rid of them, right? So this you can estimate this like this, right? And then finally, this is a term that comes up in the segment inequality, okay, which is right here. Okay, so if you have a function g, which is an L1 lock, and you're trying to integrate G along geodesics between every pair of points in A across B, then there's a bound like this. A bound like this, okay. So, this is from Cheeker Kolding, and so here this quantity is just this nambla b is the same thing as your g basically. Okay, so you can estimate this side using the segmented quantity like so. Now, everything here has a measure attached to it because you know, what's the size of A cross B? So, really, you want to control the average of this, right? So, if I now add an average, then this. Then this kind of spits out an MA times MB here. So let's move it to the other side. Okay. All right. And now let's also take an average of this. So that means we multiply by measure of B2R. Okay, so this quantity is the same thing as 1 over MB plus 1 over MA. Okay, and you have the measure of ball radius 2r here. So for this to be an effective bound, So, for this to be an effective bound on the average distance derivative, then you really need to have it so that this measure isn't too big compared to the measure of A and the measure of B. Okay, so in other words, you can only expect to have control on the average distance if A and B are large in size compared to the ball itself. Okay, if they're small, then you lose control. If they're small, then you lose control, right? And so that's important to keep in mind. And that's what you expect, right? Because otherwise, you would be able to compare points. And then, as I said before, you shouldn't expect to be able to do that because you don't have L-infinite control on the covariant derivative. Okay. Now, notice if you're trying to, so this controls the first derivative. Now, if you're actually trying to go from some time t0 to t1, you would integrate this. Okay, so a, so what I'm saying is if you have a What I'm saying is, if you have a bound on the covariant derivative of B integrated on some time interval, then you have a bound on the change in distance on some time interval as well. Okay. Any questions so far? Okay, good. Okay, so this is a general strategy of sort of what you can do in the smooth setting. And notice basically so far, Notice basically, so far, everything I've introduced does carry over to the RCZ setting. There is something to be said for the second variation formula, which I already kind of alluded to. So now let's go a little bit further and see if we can get the theorem that I claimed at the beginning, right? So suppose you have a vector field where the covariant derivative in L2 is bounded, and again, the L infinity norm of B and divergence of B is bounded. Norm of B and divergence of B is bounded. And if you have F, the associated flow. Okay, so first of all, let me introduce a useful transformation. So suppose you have a function g on the manifold, then you can take the maximal function up to the radius rho of g, and that produces another function on the manifold. Okay, and the definition of this is that it's just a soup of the average of g on the ball radius r of x. Okay, so x is the input, right? So you look at all the balls. Input, right? So you look at all the balls of radius R around whatever the input is. You look at the average of G, and you take the soup where the radius goes up to rho. Okay, so in particular, R could be zero. And so this is bounded below by G, okay, just to point out. Okay, so a fact about this is that if this is standard maximal inequality, is that if you have a function g which is in L alpha, then its maximal function. Then its maximal function will also be in L alpha, and you have quantitative estimates on the L alpha norm of the maximal function in relation to the L original normal alpha norm of G. And this has to do with basically doubling, okay, which we know R C D spaces have. Okay, so now for each x inside of inside of the space, I'm going to define a function capital G of X like so. Okay, so let me just maybe quickly Um, let me just maybe quickly draw what this is, right? So you have x, okay, and then you have this thing which is its flow flow line, right? Ftx. And so basically what we do is at each point of the flow line, we look at sort of the covariant derivative, right? And we also on the ball radius r, okay, where r. Ball radius r, okay, where r goes up to 10. And then we sort of look at the supremum of the averages. Okay, so I'm basically looking for the biggest average at each point, and then I'm integrating from zero to t. Okay, so in particular, if you just pick any tube of radius less than r, less than 10, rather. Okay, so if you pick any. Less than 10, rather. Okay, so if you pick any tube of radius less than 10, so what I mean by this is if you just look at each point and then you pick you fix an r across all the points and you look at the ball of radius r, then and then you look at sort of the covariant derivative, then it's going to be bounded by this, essentially. Okay. All right. So notice that g is in L1. Okay. And the reason why g is in L1 is because the maximal function. In L1 is because the maximal function is in L2, right? Here there is a transformation, but we know ft is a bounded compression, so even if after you do a change of variables, it's still in L2. Okay, so then you square it, it's in L1, you integrate it across time, right? So it's still L1 on spatially. So G is an L1, and you can bound its L1 norm, okay? And it's entirely bounded on sort of the constants H and D, which bound the divergence. Constants H and D, which bound the divergence in the covariant derivative, and also on the structural constants and time itself, total time. Okay, so in particular, if you apply Chebyshev inequality here for any epsilon, you can find large enough C1 so that the volume of the things with the points which have G, this G bigger than C1, is bounded by epsilon. So what I mean to say here is there is a large set where G is less. This is the same thing as saying there's a large set where G is less than or equal to C1. All right, so let's gather. So let me make a claim here. So the claim is for any X where this is less than this quantity we just defined as less than or equal to C1, then at least half of the ball radius R around F T naught of X will stay close to F. f t0 of x will stay close to f t of x in a holder continuous holder manner under the flow. Okay, so the thing I want you to note here is that if g of x is less than or equal to c1, that means I can apply Cauchy Schwartz here to say that on a time interval t0 to t1, the maximal up to radius 10 of nabla b is bounded like this. Okay, so this is just Okay, so this is just applying Cauchy Schwartz to the time interval. Basically, you multiply this by a characteristic of t0 to t1, right? And then apply Cauchy-Schwartz on the functions in terms of time. Okay, so why is this true? Okay, so it gets a little bit messy here, so let me maybe quickly just describe the heuristics. So again, we have this flow line. Have this flow line starting from X. Okay. And then we have sort of FT0X and FT1X. Okay. So the first thing to know is that sort of we have a bound like this, right? And so in particular, because it's the maximal function, you can think about the radius zero. Okay, so really then you have a zero okay so really then you have an estimate on the curve itself right it says the integral from t0 to t1 of the covariant derivative the norm of the covariant derivative is bounded in this manner now note notice that the covariant derivative is basically the Lie derivative with respect to the vector field of the metric okay which controls sort of the so and this quantity controls the the size The size of the differential of the flow as you move along, right? So, being able to control this quantity along this curve means you get to control sort of the norm of the differential. And so, in particular, it says infinitesimally the differential sort of you can control its size and it's going to be a holder. And so, then by smoothness, you have that it's true for a That it's true for a small ball as well. So, for a small ball, a lot of this ball will stay sort of holder close depending on time, right? And then sort of, and then the next argument, basically, you kind of bootstrap your way upwards, right? So if you already know that there's a small ball which stays very close, then you can look at a slightly bigger ball, let's say radius 10r. So if this is r, we can look at the radius 10r. We can look at the radius 10r. Okay, we know a lot of this ball stays close, and so and also the ball radius r does have significant size in the ball radius 10r. That's just from Bishop Kromov. And so in particular, if you recall what I said earlier about trying to control the total integral distance, it is totally valid to use this as one of your sets, right? Like we're trying to. As one of your sets, right? Like we're trying to, I was talking about controlling the interval distance between two subsets A and B earlier. And as long as A and B had significant size compared to the larger ball, then you could control the integral distance. And so in particular, since this has large enough size compared to 10R, it's totally valid to use this as one of the subsets. And then the other subset we're going to use is maybe, let's say, the ball radius 2R. Okay, which again also. Okay, which again also has large size compared to the larger red ball. Okay, so now both of the so based on what I said before, you know, you're moving along a vector field X where you have control on this quantity, right? And this quantity sort of lets you control the integral change in distance between two large subsets within this ball, okay? Okay, and so in particular, if the green one you all know is already staying close to the curve, then this slightly larger ball radius 2r will mostly stay close to the curve as well. Okay, so this is what's giving you control here. Any questions with this? So, um So, this all works basically in the smooth case, and then you get this what I just claimed here. Okay. And then to finally conclude that the change in distance is holder, basically what you could say is, okay, well, let's say you have two X's, you have an X and a Y, where both of them have this estimate right here. Okay, we know like a large set of, a really large set of points inside of my space have this estimate. So let's Estimate. So let's pick any X and Y so that they have this estimate right here. So I know that a ball of some relatively large size compared to the distance between X and Y is staying close to Y under the flow. And the ball here is also staying close to Y under the flow. Okay, so now if you kind of look at If we look at, let's say, now a really large ball around the flow line of X right here, these two things, by the way they're chosen, I said, okay, well, let's just pick a radius which is relatively large compared to the distance between X and Y. These two balls will still have significant size compared to this big ball here. And so then you can use the control you have on the covariant derivative in this large tube. The covariant derivative in this large tube to sort of control the integral change in distance between these two smaller balls as they go along the flow. So then you know, sort of the distance between these two things don't change too much in integral sense. But then since they're both staying close to these curves themselves, that means the curves themselves also cannot change in distance too much. Okay, so again, we're first of all controlling, we're saying, okay, these two things are close to the curve, these two things are staying. The curve, these two things are staying close to each other, and therefore the curves are staying close to each other, at least in a holder-continuous manner. Okay, so this is what lets you prove sort of if you have two points inside with this type of estimate, then their flow lines also have to stay close in a holder-continuous manner, depending on time. Okay, so this outlines the argument that you would make in the The argument that you would make in the smooth setting. Notice again that everything I used is more or less available in the RCD setting. And then again, I'll talk about the second variation formula in the next page. Except for this start, except for the fact that sort of you have this estimate right here. So this is not available in the RCD setting. In particular, you don't get to start with some sort of infinitesimal estimate. Along the flow line itself. Okay, so this is the main issue we'll have to deal with. All right. So now let me quickly mention. So as I said, one of the key ingredients to all of this argument was a second variation formula and also the first variation formula. So in the RCD setting, the first variation formula is basically for free. The reason why is because if you have a flow of some vector field B, then Some vector field B, then the flow cross the flow is going to be a flow of the vector field B direct direct sum vector field B on the um on the space cross itself. And then D is a Lipschitz function. Okay, so then this just comes from the definition of a regular Lagrangian flow on x cross x. Okay, so the first variation formula, you can just get it easily. The second variation formula follows from a result. Folllows from a result of Jigli-Tamanini, which gives the following second-order differentiation formula along a Worscherstein geodesic. It says if you integrate F along a Worscherstein geodesic and you take its second derivative, it's what you expect it to be. Okay, so notice I wrote down a pointwise version of this in the Smoose case, and this is just an integral version of that, right? And here, phi is a potential. And here, phi is a potential corresponding to the Worscherstein geodesic. And so it's, it wouldn't, so as I mentioned, sort of this gives you the second order interpolation formula as well in the smooth setting, which lets you interpolate between these two quantities, right? And then that's in the same way, once you have this in the RCD setting, you can, after doing a little bit of work, also get the second order interpolation formula in the RCD setting. Order interpolation formula in RCD setting. Okay, but this was this is sort of the key step. Um, all right, so we have both of these, and therefore, you can assume what I said earlier about actually using the covariant derivative to control interval distance is completely valid. Okay, so the only thing we're really missing is these infinitesimal estimates. Um, all right, so let's let me quickly now talk about the non-collapse case. So, actually, the cool thing about the non-collapse case is that the Is that the same idea actually essentially works to get holder regularity from infinitesimal estimates as in this case? Okay, so and the other thing to note is that you actually do have infinitesimal estimates. So in other words, you can control, you can understand how the flow changes distance infinitesimally along most curves. Okay. So the reason why you have this is because, and this is coming And this is coming out of work that sort of was pioneered by Elia and Daniela for RCD spaces. So the key idea is to just use the Greens function instead of to analyze everything using the Greens function. Okay, so just as a reminder, the Green function, the Lambda Green function is defined as the following. So here, this is the heat kernel. Okay, so the Lambda Green function between X and Y is just the integral from e to the lambda t of the heat kernel between x and y integrated from 0 to. Between x and y integrated from zero to infinity. So this could be a priori infinite, but we have Gaussian estimates on the heat flow, depending on the distance. And so in particular, if you just pick lambda large enough, I think it's like c times some constant times k, then this will be a finite thing. Okay. And so I'm not going to say too much about how to handle these objects. I will say sort of three. These objects. I will say sort of three things about them philosophically. Okay. So the first thing is that if you look at the Lambda Green's function between two flow lines, this is much easier to estimate than the distance between the two flow lines itself. Okay, so that's the first thing to note. And the second thing to note is that in the non-collapse case, G lambda is really controlled on both sides by the distance to the negative n minus 2. So it's kind of equivalent to the distance in some sense. And then the last thing, which was really leveraged in the paper between myself and Ilya and Daniela, is sort of the idea that if you go to the infinitesimal, in other words, if you let y go to x, then g lambda and d are basically exactly the same. It limits to something. The same. It limits to something like this. Notice that these are just constants, right? n minus 2n and omega n. And then theta x is the density of the measure at the point x. And so in the non-collapse setting, this is really nice because it's just constant almost everywhere. Okay, so there's not much to deal with here. Okay, so basically, the key idea, building on sort of what Ilya and Daniela did, is sort of Is sort of uh okay. Well, let's analyze the Green's function, we can control it, and then infinitesimally actually gives us complete information on the distance function. Okay, so controlling the Green's function infinitesimally gives us complete control infinitesimally on the distance function. Okay, and so now we have complete infinitesimal control on the distance function, and then as I mentioned, you can sort of bootstrap your way upwards again, okay? So, this is really nice. Um, I will say one comment is that the infinitesimal. One comment is that the infinitesimal control one gets from this method is quite strong, it's actually optimal, it's uh it's basically a linear in time, okay, which is stronger than what sort of the holder continuity is able to get you. Okay, so this is what you do in the non-collapse case. Um, so how about the collapse case? Well, so the collapse case, this no longer works because you no longer have these nice things for the Green's function. And even Greens function. And even if you did, notice that this density isn't as nice anymore, right? It's not constant almost ever. It can change. So, even if you're able to control the Greens function, that doesn't necessarily give you control on the distance function unless you knew how this theta x was changing, which you don't. And so, in the collapse case, you don't get these infinitesimal estimates, and I don't actually know how you would do it. So, instead, we would just try to get the older estimates right away without actually dealing with. Away okay, without actually dealing with the infinitesimal part, okay. So, um, so let's talk about the general non-smooth case. So, recall that for each x inside of the space itself, we defined something like this. And this was basically an estimate. You can think of it as sort of an estimate of the norm of nabla b or the covariant derivative of b along tubes of this nature, where this is this. Of this nature, where this is this is f tx. Okay, so if you have if you if you bound this, then you bound the size of the covariant derivative along this tube for all tubes up to, let's say, radius 10. So as I mentioned before, this thing was naturally in L1 for each as a function of x. And we can, for each epsilon, We can, for each epsilon, find a C1 so that the size of the X's with G greater than C1 is less than epsilon. In other words, there's lots of almost a lot of your space has G less than or equal to C1. Okay, so we're going to call these points C1 nice points. Okay, so C1 nice points are the ones where if you look at the covariant derivative along these tubes up to a radius of Along these tubes up to a radius of 10, you have estimates. You can bound the covariant derivative squared averaged along this by C1. That's all I'm saying, right? So these are, so there's, so in other words, we have a lot of C1 nice points. Okay, so now we consider any X, which is a density point in the set of C1 nice points. So C1 nice points take up almost all of your space or almost all of your really large ball. Almost over your really large ball. And then you look at its density points. Again, that's almost everything as well, right? And so consider any x, which is the density points of the C1 nice points, and any radius so that if you look at the C1 nice points in the ball radius r and you compare it to the size of ball radius r itself, it's greater or equal to a half. Okay, so since you're a density point, this is going to happen starting from some radius depending on x. And starting from some radius and Starting from some radius, and for things which are smaller, this is going to hold. Okay, so we fix an x which is density point, and then we fix a radius where this is happening. Okay, um, so oh, right. So, let me let me now argue sort of what you should expect for these density points, okay? Um, and so this really comes back to something that I did also for the That I did also for the holder-continuated tension cones. Okay, so let's say we have this ball radius. So let's say we have x right here. Okay, and let's just do everything at time zero. Let's forget about the intermediate time. So we start at time zero and we go up to a certain amount of time, right? So this is we start at x, okay, and we look at a ball radius r. So this is this is r. And then we know that at least half of this ball consists of these c1. Least half of this ball consists of these C1 nice points. Okay, so there's a large portion of this ball that are C1 nice. And so in the sense that, and again, this means that if you picked a C1 nice point and looked at the tube around the C1 nice point instead, you also have reasonable Hessian estimates, so covariant derivative estimates, right? So now here's what you do. So we fix an R. So maybe we can bolt this fixed an R. Okay, and we now have these C1 nice points. Okay, so now let's look at also the ball radius, let's say 10R. So this is ball radius 10r. And then we have this curve right here, right? So this is F Tx. Okay, so as I mentioned, since we don't have sort of an initial infinitesimal estimate to bootstrap on, in theory, this could just sort of start leaving right away, right? So what I'm saying is that sort of this ball right here, in theory, it could just mostly do something like this. Okay, because we have nothing to hold it to this line right here. Here right before, if you had a smaller ball which was close to this line, then you can hold this larger ball to the if you had a small smaller ball that's close to this line, you can hold a slightly larger ball close to this line as well. Okay, but we don't have that in this case, so it could just do something like this. But even though when it's doing something like this, it still takes some amount of time to leave this large, large tube, right? So the minimum amount of time it takes is exactly dependent on the radius and Dependent on the radius and the L infinity norm of the vector field, right? So this would, so a minimum to leave this tube, the amount of time it would take. So let's say you're leaving, at this point, something has left the tube. The minimum amount of time it would take is something like, let's say, 9R divided by the L infinity norm of the vector field. Okay, so this is. So, this isn't nice because it depends on the radius. Okay, and so, in particular, if you just took this, then you can only get estimates between two points for a time, which depends on the radius. So, in other words, you can't compare them to far away, which is something that we like to do. So, the key observation here is: okay, well, in this short amount of time, you're still staying within this tube. Okay, so in Tube. Okay, so in particular, like everything in this ball is staying within this large red tube under the flow. And also, if you look at sort of the following two sets, so let's say A is your C1 nice points in the ball radius BR, and then B is just the ball radius R. Okay, if you look at these two sets right here. You look at these two sets right here, both of them for this amount of time is staying within the large red tube, and also they have significant size compared to the tube itself, okay, because again, Bishop Gromov. So in particular, you can actually sort of use the estimates I mentioned earlier, and these two things are both subject to this really nice covariant derivative estimate of the large red tube. Okay, so the conclusion is. Red tube. Okay, so the conclusion is most of A and most of B stay close to each other under flow up to time nine R B O infinity. Okay, so at least Okay, so at least till this short amount of time, you know, some things can drift apart, but mostly you're subject to the really nice covariant derivative, so you still have all the reasonable estimates. Okay, but at this point, you could have drifted very far away from this curve. Okay, like everything staying mostly close together, but from one curve, it could be far apart, right? So then the key observation is sort of we just, we just, we just change the anchor, right? Change the anchor, right? So instead of looking at the blue line, we now take one of these nice points, look at the associated flow line to it instead. Okay, so because this is a nice point, it has the same covariant derivative estimates around a tube around this as the original red tube. Okay, so now if so, what I'm saying is if you take a red tube. Take a red tube around this ball, and then you sort of move it along here, you have nice estimates as well. Okay, so in this way, you sort of switch your anchor and then you say, okay, well, you make the same argument again, right? So up from time zero to time nine R divided by this, everything is staying close. Most of the things is staying now close to this green line, okay? After which it could again drift apart, but then it still takes a certain amount of time to do so, and then all that time it's being subjected. And then all that time it's being subjected to the really nice covariant derivative estimates that you have associated to this green line. And so you can go further and further and further. Okay. And so that's the key idea. And so in particular, what you end up with is the following. So let me maybe write this quickly. The thing you get to conclude is there is some y in the ball radius r. In the ball radius r, which is nice. So maybe let me just write it this way, which is nice, which is C1 nice. So that most of the ball radius R around X stays close to Y in a holder-continuous manner. In a holder-continuous manner or holder matter for an amount of time independent of radius. Okay, so that's the conclusion of the argument that I mentioned earlier. Okay, so now what you do is you actually get to repick your original trajectory. Repick your original trajectory. So, so what I mean is, okay, so you had ftx, okay, and at every single scale r you found another curve, which is called fty, where in fact, it is what most of this ball is sticking close to. Okay, so most of this ball is sort of sticking close to this curve instead of maybe possibly this one. Now, it could. This one. Now, it could be that it's also staying as close to this curve, but we don't know that. All we know is that most of this ball is staying close to this new curve instead. Okay, and so you can do this at every single radius. So if you use a smaller radius, again, you can find a nice point so that the small ball is staying close to it. So in this way, you get a sequence of flow lines. And then you can take a limit of that. And then you end up with maybe a limiting curve. You end up with maybe a limiting curve. Let's say right here. Okay, and my claim is that sort of this is sort of a canonical choice for what the flow line with respect to X should be. Okay, so I mean, regular Lagrangian flow is defined measure theoretically. So you can always alter it up to a set of measure zero and it doesn't change anything. But it's kind of cute in the sense that for certain points, in particular, For certain points, in particular density points, to these C1 nice points, there is a canonical choice of what the flow line should be, right? The reason why the black line should be preferred over the blue line is because the black line has this really nice holder property in the sense that if you start with a ball around the black line under the flow, almost everything will stay close to the black line as well, right? Whereas the blue line doesn't have this property. Okay, so in this way, there's a canonical choice of Canonical choice of what the flow lines should be to your regular Lagrangian flow, okay, which again I think is kind of cute, right? And so now it takes some argument to say that, okay, well, this line actually, if you replaced, if you took sort of all your C1 nice density points and then you replaced them with this replacement, that it's still a regular Lagrangian flow and therefore agrees with the original almost everywhere. Agrees with the original almost everywhere. And this comes from the fact that just you can just check the definition. So I'm not going to do that, but it's basically these curves differentiate ellipsis functions sufficiently close to the original. And so you can, in the limit, it'll actually be the same. So it ends up being fine. Okay. Any questions here? Okay, good. So let me now talk about something else. Sorry, I have a question. Do you know if this avoids the singular set? If your flow lines are avoiding the singular set at all, sorry, does what avoid the singular? Does the this canonical flow line f t of x uh does it uh Um I think in the middle of the Almost everywhere it does, I think. That's all you can say. Because I think along the lines of proving this, you actually get volume density control. And then, so if you and in some in some sense, you get you get the same type of thing that you would like the same thing as the holder continuity of tension cones, essentially, along almost every single flow line. And so in that sense, So, in that sense, then if you put in a measure theoretical argument to say, okay, well, almost all of these lines have dense regular points, then you can conclude that, in fact, you have regular points along all these flow lines. I think that would work. I actually haven't thought about this, but I would expect anything that worked for the holder continuity detention cones would carry over here. It's not squeezing too much. Okay, great. Thanks. Yeah. Pardon? But yes, it's just not squeezing the meshes too much or to. Squeezing the measures too much or lowering the dimensions too much. It's controlled like that. Thanks. Right. Okay. So just to conclude, basically now we've established that sort of there's a canonical choice almost everywhere. And for everything in the canonical choice, you have these nice holder properties, which is nice. Okay, so let's talk about some applications of this. And I guess I'll have to breathe over. This and I guess I'll have to breathe over things quickly. So, so no applications of this type of idea is holder continuity tangent cones, which is basically if you have, let me just, so if you have an R C D space, and for simplicity, we just put the curvature bound to be negative n minus one, and then you have PQ in the space itself with distance, again, for simplicity equals to one. You can take a geodesic and then you cut off. And then you cut off sort of the delta ends. Okay, and then the claim is that if you take a ball radius r here and the ball radius r here that are sufficiently small that are sufficiently small. Right, where R0 is sort of depending on and delta, then the change in pointed Gomau-Hausdorff distance is holder-dependent in the time distance here. Okay, so I'll mention quickly why this is actually sort of a very specific case of what we just talked about, okay? And then just another application that's an extension of the holder-continuity contention cones is the fact that. Continuity contention cones is the fact that RCD space is non-branching. So, in other words, if you start with two geodesics which agree for some amount of time, then they'll sort of agree for the same amount of time still. Okay, so the idea of the proof behind the holder continuity tangent cones is as follows. Okay, so you're trying to construct a approximation from this ball to this ball, right? And what you do is you just, for any point here, Is you just for any point here, you connect it to P like this, and then you hope it lands in this ball, okay? And it turns out for most of it, it does. Some of it actually leaves, okay, which is fine, but most of it will stay in here, but we have to show this, right? So this map where you move this point here by the distance t1 minus t0, I'm just going to call it the gradient flow of negative dp. Of negative dp, okay, because you're you're this this is sort of a flow line of negative dp. There's a choice involved sometimes because geodesics might not be unique, okay, but uh you just pick one and then you move it here, okay? So measure measure theoretically. This is well defined, right? So you take this map right here, and that's what most of the most of this approximation is going to be. Okay, so now let me convince you that almost everything stays in here. So, first of all, Everything stays in here. So, first of all, the distance function isn't smooth enough. Okay, so in particular, you can't apply the second variation formula to the distance function in the RCD setting. And so, what I said before for regular Lagrangian flows of vector fields with L2 covariant derivatives doesn't apply here. Okay. But the key observation, this was made by Kolding neighbor, was that instead of looking at the distance function, you can look at the heat flow approximation of the distance function. And if you're trying to sort of construct And if you're trying to sort of construct an approximation of radius r, then the thing you look at is the heat flow approximation up to time r squared. Okay, so to get into how this works, let me just introduce a quick terminology. So an r geodesic from p to q is a curve sigma from p to q, so that the length of the curve is almost the length of the geodesic, the length of the distance between p and q. So it's like one plus r squared times. It's like one plus r squared times the distance between p and q. Now, if you assume the distance between p and q is just one, which we did at the very beginning, just for simplicity, it's just one plus r squared. And so what's true by integral abrasion grommau inequality, and you can find this in Mondino neighbor, for example, is that there are lots of points x around a ball radius r in gamma t zero, so that the curve px xq is an r geodesic. Q is an R geodesic. Okay, so if you look at a ball radius R here, that's well within the delta. So you again drop this delta n points and look at a point here. Lots of these curves will be in our geodesic. Okay, so this is not. When I say lots, I just mean like there's a quantitative lower bound on the measure of the amount of these points compared to the measure of the ball, right? Of the ball, right? Um, okay, so lots of these are our geodesics, and what is known, and so these are these points, I should say, are also called points of R squared access. That's another language for this. So what's known about R geodesics is that if you take an R geodesic and if you look at, again, this tube, you look at the Hessian of HR squared on the ball radius 10r along the geodesic itself. Are along the geodesic itself. So these tubes, again, they're bounded nicely. Okay, in the same way that it was bounded before when I was talking about the regular Lagrangian flows. Okay, and then the other key thing to note is that the gradient of distance function and the gradient of the heat flow approximation of the distance function are kind of close as well. Okay, and so what these two things combined lets you do is it actually lets you control the flow, the distance between the flow in some. The distance between the flow in some integral sense as well. Okay. So now, instead of these C1 nice functions, what you replace them with are just these functions of low access because you notice that they have the same features in the sense that they have good Hessian bounds along these tubes or good covariant derivatives bounds along those tubes. So you can make the same argument essentially, replacing the C1 nice functions with the With the fun points of R-squared axis. And then everything basically goes through. And that's how you control the distance along this flow. And it's going to be the same thing. It's going to be holder continuous in matter. Okay. So as I said, arguing as before, you can conclude. So this is why sort of what I so the what I just said for the regular Lagondron flow is just a slightly more general case of the argument here, but in fact. General case of the argument here, but in fact, the essence to sort of overcoming the lack of smooth structure is the same. Okay, it's arguing by sort of moving these anchors around and being flexible with how you choose your tubes. Okay, so and then I don't think I'd have time for this. So this also lets you prove non-branching. Okay, but I don't think I have a minute left, so I'll leave it there. Some other applications. Some other applications that I want to point out that was used in the smooth and the Rigi limit case for these for the flows of L2 vector fields. There's two that comes to mind, but I'm sure there are more. One is the generalized Margulis Lemma by Kapovich and Wilkins. It says if you have a compact manifold with reg bounded below by negative n minus one and diameter bounded above, then if you look at the fundamental group of m. Group of M, it contains a new potent subgroup of index less than or equal to Cn, and then the newpotent basis of length less than or equal to N. So this is something I'm actively working on right now with Dimitri Navarro. So I'm not going to claim it for RCD spaces because we haven't really resolved everything yet. But so what I'll say is sort of this is true for the proof of this heavily involves being able to understand the holder continuity of flows of Flows of vector fields where you have control on the L2 norm of the covariant derivative. Okay, so there's hopes that if you can do this in the RCD setting, you can just carry this over. Of course, here, you would have to replace this with the revised fundamental group. And then another thing which is a result of Kapovich and Li, and on Li is the sort of the metric measure holder continuity tangent cones. It says if you have a Reachy limit space. Have a Rigi limit space, and the tangent cones are holder-continuous in the interior of a geodesic with respect to the storm distance. Okay, and the and it's basically the same estimate I did before for pointed Gomev-Hausdorff, right? And it's and the argument here also heavily involves being able to estimate the hotocontinuity or regular flows of sobola vector fields. Okay, so I think this is a good place to stop. Thank you very much. Are there any questions, comments? Again, thanks a lot for this beautiful talk. Just a question. How we should interpret this last slide? So are both kind of a work in progress or is one of the two say the major To say the measure, say, I know that you're working with Dimitri on the first one, but say on the second one, is it done or is it also something you are thinking of? Second one, I'm very confident about. Okay. Because it's sort of, I think, just with what the result I presented in today's talk and sort of what I understood from Vitali talking to him, it just carries, the argument just carries over directly to the Just carries over directly to the RCD setting. The first one, there's some nuances to the, I mean, it's a really long paper. So, I mean, already already understanding the paper is non-trivial work. Yeah, and say, and right, can you maybe in the questions, can you briefly sketch the idea of the of the Of the non-branching. So, how does the non-branching follow from the estimates? Yeah, sure. So, okay. Yeah, so I would have talked about this if I had more time. So, I guess thanks for the opportunity to actually present this. So, basically, if you, I'll say something is a good geodesic, delta good geodesic, if you look at its delta interior and it has this nice holder. Interior and it has this nice holder property, right? So, like, you don't claim control on the delta on this part and this part, but at least inside of this interior, we have, so this is good holder control. Let's say, whatever that means, right? And then I say a geodesic is good if for any delta, it's delta good. Okay, so in the sense that if you if you kind of cut sense that if you if you kind of cut off any delta piece then inside of this you have you have good holder control on small balls as you as you flow along the negative grab dp um so what i what what was basically just shown is that if you start with a geodesic uh you can sort of and you pick a delta here you can sort of construct a delta good geodesic so this is from p to q you can construct a delta good You can construct a delta-good geodesic always. Okay, that's basically what the argument ends up leading to. So then, sort of, this will have really nice property inside of this interior. And so now, if you do this for every delta, you can come to a limit geodesic, possibly not the original one. Okay, and this will be just good. Okay, so we'll keep this. So you take a limited. We'll keep this. So, you take a limited delta goes to zero of these delta good geodesics constructor, you get a good geodesic. Okay, so let me just say if you have two good geodesics, then non-branching can't occur. Okay, so if they're both good, okay, and it's because if it did occur, then you can pick a small, if you can pick two small balls, which are small compared to the amount of branching that has happened. Happened. And then basically the argument, basically, what you would understand is that sort of these two small balls, first of all, has to still stay close to the, most of it stays close to the geodesics, okay, because that's what it means to be good. And the other thing is that while you're pruning everything, you actually show the volume changes in a holder-continuous manner as well. So, in fact, the volume of this ball compared to this ball shouldn't change too much. So, now you're flowing two separate balls. So now you're flowing two separate balls of really large size into this big ball, and the volumes don't change much. So that's impossible. You can't fit it in there, right? So if you have too good geodesic, then this just can't happen. So now let's, we don't know a priori, all geodesics are good, right? So let's assume we start with just two geodesics, which has branching. So what you could do is you could construct Could construct in the manner I described here a good geodesic between this point and this point. Okay, so this is good. Okay, so you just kind of forget about the rest first and just focus on this part and then construct a geodesic, good geodesic from here. Okay, now notice that this curve right here is also a geodesic, right? Like where you just Geodesic, right? Like where you just put these two things together. And so, in particular, you could carry out this construction again, right? So, in other words, I carry out this delta good construction on this geodesic right here. So it'll maybe do something like this. But the key thing to note here is that this is delta good, which means. That this is delta good, which means the red line is delta good, which means it has good behavior inside of this interval. And then this black line is just good everywhere. Okay, and that's actually enough for you to argue in the same way that I did here that this can't be branching. Okay, so in fact, this delta good line can't actually branch off here. It needs to continue with the black line up till this point. Okay, so this picture is actually impossible. And what you actually end up needing And what you actually end up needing to have is when you do this construction, is something like this. Okay, so this will be the new delta-good line constructed from sort of this geodesic right here. Now, you can do this for every delta, and so, and then take a limit, and then you ultimately produce a good, good line, maybe a good geodesic, maybe this one. It doesn't look like a geodesic, but share with me. And then you do the same thing with the other, same construction with this other curve as well. Construction with this other curve as well. So then you construct also a completely good geodesic like this. Okay, so now notice that these two lines are now both good. Okay, and then by again, this argument, there couldn't have been any branching. So this picture is impossible. All right. Thank you. Are there further questions? Are there further questions? If not, let's thank Chen again.