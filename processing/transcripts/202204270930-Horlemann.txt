Thank you for your introduction, and thanks for the invitation to speak. And well, originally the invitation to join, but unfortunately, that didn't work. But well, next time. Next time we'll all be there. Yeah, so exactly. I was asked or, well, also said I'd be happy to give an overview talk. And of course, then, I mean, once you start preparing the talk. I mean, once you start preparing the talk, you kind of notice that it's really difficult to decide on what you're going to include and what not. So I'm really trying to tell you a little bit about the different things you can do in code-based cryptography or people have done. But I'm not going to talk about any specific recent results. I'm not going to, yeah, not going to talk about my results either in particular. Because exactly, I think that was not the idea. Because exactly, I think that was not the idea of the talk. So, Philippe and Tanya are going to talk later today about more specific things and more recent developments in the area. So, I hope that they will kind of match or kind of extend the things that I'm going to talk about. And then, of course, the second difficulty is, well, it's a very mixed audience, or actually even a kind of unknown audience. And I figured, since this is a workshop in mainly coding theory, I'm really going to start very easy. I'm really going to start very easy with the whole post-quantum crypto setup and then well, talk about the different things in code-based crypto. So, that was my first disclaimer. My second disclaimer, as you see on the bottom of this page, is that I also didn't include any references because it just wouldn't have been too many, or I would have probably insulted someone by not including one, but including the other. So, there are no references in this presentation. However, Presentation. However, Violeta, Nicholas, and Joachim, Viga Gasna Rosenthal, wrote a very nice survey on code-based crypto, which is already on archive. So please have a look. Basically, everything I'm going to talk about, almost everything is included in there, plus many extras. So if you're interested in the references for something specific, just either ask me, of course, or have a look at that survey paper there. That's really nice. So for now, So, for now, so as I said, I'm going to really start very easy, slowly for those who are not very familiar with crypto in general or post-quantum crypto in particular. I'm going to give you a little introduction to the whole area. Then I'm going to talk about public key crypto systems, everything now in code base, of course, and then some attacks, general ideas of attacks that you have to consider for these types of crypto systems, and afterwards, a And afterwards, a slight excursion, it's really very brief to digital signatures. Well, and then have a summary conclusion part at the very end. All right, so this is my general communication setup. As you always see in crypto, Alice wants to communicate to Bob, so she wants to send a message to Bob. She does so via an insecure channel, meaning that some eavedroppers. Meaning that some eavedropper, Eve, or attacker, or whatever you want to think of, has access to this insecure channel over here. But of course, Alice and Bob still want to communicate in some sense secure way. All right. And when we talk about public key crypto systems, the setup is as follows. So still, Alice wants to send a message to Bob. What Bob does preliminary to that is he creates a, well, A key setup. So he creates two keys, a public and a private key. They belong together, okay? They have to be generated together. He publishes that public key and he keeps that private key secret. Then Alice can use this public key to encrypt the message she wants to send. She now sends this encrypted message, so the ciphertext over the insecure channel to Bob. And Bob then uses his private key to decrypt the message. So here you see the To decrypt the message. So here you see the asymmetry, where this is also called asymmetric cryptography. There is a public and a private key that are not the same. And the standard idea that you see or the standard picture that is connected to that is that of a padlock. So basically, you can think of this public key as a padlock that's somewhere out there in the open for anyone to grab. Okay, so it's an open padlock that Bob put out there and only Bob has the key to. Out there, and only Bob has the key to open it. Anyone can grab that key, put the message in a box, lock the box or chest with that padlock, send it via the insecure channel. Okay, Eve can get hold of the box, but she cannot open it because she doesn't have a key to that padlock. However, Bob has the key, so he can open it and get the message. So that's the general idea of a public key crypto system and kind of. And kind of in the same flavor, and just really inverted in the order of how you use the keys is a digital signature setup. So if Alice still wants to send her message to Bob, but now she wants to sign it, okay, to convince Bob that she's really the one sending the message, let it be a contract or whatever type of information that's where it's kind of important to know that the actual send. The actual sender is who she claims to be. So she wants to sign the message, and how does she do that? So now she creates a public and a private key. So this is independent of the whole public key setup. If you want to do both, Bob has to create his setup for the public key crypto system and Alice has to do her setup for the digital signature. So that is just independent of each other. So for the digital signature, Alice creates now a public and a private key, and then she uses the private key now to sign. And then she uses the private key now to sign the message. And then Bob uses the public key to verify the message. Okay, so it's really the same idea, just that now, I mean, the private part is the signing process. Obviously, that should not be the publicly available part. Otherwise, everybody could forge Alice's signature. So that goes first now. So this private key part goes first now. And then, well, anyone should be able to verify that this is really Alice's signature. So this is done with a public key. And here's this really mathematically beautiful example of how this can be done in practice. That's the RSA system. So what do we do here? We choose two large prime numbers, P and Q. Those are basically the private key. You compute the product of those two, call it N. Pick any number that's relatively prime to P minus one times Q minus one. And then you compute the inverse of that E. the inverse of that e modulo that p minus one q minus one call it d and hen then the private key is that number d and the public keys or key is the numbers n and e right and then encryption is very easy if your message is represented as some integer number modulo n you take this message m raise it to the power e that was part of the public key modulo n as the other part of the public key this can all Public key. This can all efficiently be done. That's your safer text C. Alice sends that to Bob and he decrypts. He now has this private key D. So he raises C to the power D, and then D and E cancel each other out in the exponent because it's modulo, the Euler phi function of n. And hence you get the message. Bob gets the message this way. So what's the actual point here from a security point of view? Actual point here from a security point of view, Eve now sees C and she knows N and E. However, to be able to efficiently compute this ETH root to get M back, she would need to know what the Euler-Phi function of n is, and for that, she would need to know what P and Q are. Otherwise, there's no efficient way for her to compute that ETH root if she doesn't know what the inverse of that. If she doesn't know what the inverse of that E is in modulo Euler Phi of n. And hence the actual security is now really based on well factoring n. Okay, so finding P and Q from the known from the known N. However, so for my code-based setup later on, I like the formulation better to say, okay, she needs to find a way to efficiently compute the ETH root, okay, because then that will then correspond to she, well, she needs. To she well, she needs to find a way, or any attacker needs to find a way to efficiently decode in some given code. So, so this is what we say here. However, in this case, efficiently computing the ETH root can be done if she knows the factors of n. And hence, well, this is the way to attack and break the RSA system. All right, so this is the public key version of RSA. There's also a signature version, and of course, Also, a signature version, and of course, it looks very similar. It's again just inverting when to use the private key and when to use the public key, order-wise. So, the setup is exactly the same. The private key is the same. The public key is the same. Now, what you do is you're signing your message by M to the D instead of M to the E. Okay, so M to the private key. You're sending the message together with the signature. You're sending M and S to Bob. Bob, well, takes this pair, computes S to the E, public. S to the E is publicly available as to the E mod N, and then checks if that is actually equal to the message that was the other part of what Alice sent to Bob. All right, so same thing, same security basis. So Eve can forge the signature or copy paste it to another message or change the message if she knows the factors of N again. All right, so. All right, so we're basically very happy with RSA. It's beautiful. We kind of have an idea of how secure it is, what we, you know, how we need to choose the parameters, how large they should be, for which type of security level. However, there's this one big problem that is Shor's algorithm. So, Shor came up with this algorithm already quite a while ago, solving the integer factorization problem, and actually then in Problem and actually, then in an adaptation, also the discrete logarithm problem in polynomial time on a quantum computer. Okay, so even in times where nobody really thought of actually building quantum computers, the theory was already there, what we could do with quantum computers that we cannot do on a circuit-based computer. So, yeah, this algorithm has been around and it's known that it breaks any type of Any type of crypto system that is based on the integer factorization problem or the discrete logarithm problem. So, because of this algorithm, once we have proper quantum computers, and now proper is really in quotes here, so whatever that means, I mean, it means really that it can factor the numbers that we're using in the currently implemented crypto systems in some reasonable amount of time. Okay, so we're certainly not there yet. Okay, so we're certainly not there yet, and experts have very differing, varying opinions on when that will be the case. But more or less, almost everybody agrees on that it will be the case at some point. So when that point comes, when people have proper quantum computers, they can use Schor's algorithm to break all these public key crypto systems or digital signatures based. Systems or digital signatures based on integer factorization or a discrete logarithm problem. So, what does that mean? That means we need new mathematical problems for asymmetric crypto systems. And this is exactly the area of post-quantum cryptography. Some people are always a bit upset about that post there, but because the term quantum cryptography is already used for a different field, well, we are the post-quantum cryptographers. Post-quantum cryptographers working on these problems. And I mean, also that, as I said, Schwarz algorithm has been around for a while. So people have already worked on it, even though those quantum computers weren't around yet. But there are a bunch of other ideas that you can use and base your asymmetric crypto systems on. So there's the synergy decoding problem that is at the heart of code-based crypto. So that's what we'll talk about today. Then there's also solving systems of multivariate equations. There's the short Multivariate equations, there's the shortest vector problem in lattices, there is finding isogenies of elliptic curves, inverting hash functions, and so on. So, there's a bunch of other mathematical problems that people have used more or less successfully, depending on the area, to set up other public key crypto systems. So, and as I said, for us, we'll talk about code-based crypto today. This is based on the syndrome decoding problem. And what most people are excited about when talking about post-quantum crypto at the moment is this big NIST post-quantum cryptography standardization project. So NIST is the National Institute of Standards and Technology in the US. And well, they are, or have been, or have decided that they are in charge of international standardization for, I mean, many things in the past, but now for. In the past, but now for well, post-quantum crypto for asymmetric crypto systems that are secure, also when quantum computers will be capable of breaking integer factorization and discrete logarithm problem. All right. And well, that project has been around since more or less 2017. So the first call was, I think, December 2016 or end of December 2016. 2016 and then officially opened in 2017. So it's been around for five years now. And well, it was planned and still officially is planned that the first standards will be out this year in 2022 and then a second round in two years in 2024. So this is more or less the schedule of this standardization project. Standardization project. And since 2020, we have, well, we're at the end of the third round. So we have these third round finalists and eight alternate candidates. So the finalists are the ones that look really good to them. Okay. So that were really, well, that the committee liked very much. And then the alternate ones are where they also said, well, they look very promising. However, we're not really sure. Probably there will be a fourth row. Really sure. Probably there will be a fourth round to evaluate them and so on. Out of these, so there's seven finalists and eight alternate candidates. Although I have to say, out of these seven finalists, as far as I know, one has completely been broken. That's why it's down in parentheses, that one green one down there. But I'm not entirely up to date with that one. So that's the rainbow signature. So we might be down to six only, actually. Down to six only, actually. All right, and then more or less three each. So, finalists and alternates are digital signatures, and the others are public key encryption schemes. And as you see in this table here, we have the most are lettuce-based, and then the second most are code-based. Well, actually, there's no code-based signature, but three encryption schemes, and then a multivariate signature to a hash-based signature, and then one isogeny-based encryption scheme. One isogeny-based inversion scheme. And well, we'll see. It would be nice to have a variety of different technologies for these standards available in the end. Well, yeah. I think I don't want to shout out my opinion about that because it's really just a feeling. So let's see what happens and let's wait for the standards. Wait for the standards until they come out. So let's have a look at this syndrome decoding problem that we base everything on now. So, what is it actually? So, it's really simply just this linear algebra equation. So, we have a syndrome s vector, which is equal to some error vector times a parity check matrix. That's the syndrome equation. And we want to say that given s and h, we want to find. That given S and H, we want to find E of some bounded weight. Okay, so that's the coding part that this E should have a prescribed up to either prescribed or upper bounded weight. And then this weight in general can be any coding weight. Okay, so classically it's always the Heming weight, but it has been generalized and well studied already in the ramp weight. The Lie weight is slowly coming up as well, the sum rank weight also. As well, the sum ring weight also. So, there would, I mean, you have a bunch of options there. Theoretically, it can be any coding weight that you like. And what do we know theoretically about this problem? So one of the cool things is that we know that the syndrome decoding problem is known to be NP-complete for, well, now I call it any coordinate-wise additive weight, where the zero vector is the only vector that has weight zero. only vector that has weight zero. Okay, so this coordinate wise additive weight is really what the Hamming and the Lie weight are. That you go coordinate wise, you take the weight of these coordinates, add up all those weights, and that's the weight of the vector. It's not the same for the rank weight, for example. So in the rank weight, we do not know deterministically if it's NP complete. However, we do have a probabilistic reduction from the class of NP hard problems. So we're kind of certain that it's also very hard. Kind of certain that it's also very hard. However, it's not as properly proven as for these coordinate-wise additive weights that we have here. All right, so that is very nice because, I mean, from a security point of view, you want something very hard, okay? You want something that is really hard for the attacker. If you have something NP-hard or NP-complete, that is, of course, pretty fantastic. That's really what we would like to have. And this is not. have and this is not the case for example for the classical for the classical problems that we um based our crypto system on so this is you know from from that point of view it's already very promising to look at to look at this problem and many of the other problems like lattice based and so on also have this np completeness so it's not that codebase is the only one that will do that for us but it's a very nice feature of the syndrome decoding problem now however what you always need for these asymmetries however what you always need for these asymmetric crypto systems is you want it hard for the attacker to be hard for the attacker but then you want it to be easy for for bob to decrypt right so the point is or the other point is of course we have a bunch of codes that we know how to decode very efficiently so that is the hope right if we want to set up something where we can use all this knowledge from coding theory um to make it easy for bob to decipher in the end to decrypt and on the other hand for the outside Hand, for the outsider not having the private key, it should look like this very generic syndrome decoding problem. Generic means H should be random or random looking. Then we know that it's basically infeasible as soon as the parameters are large enough to solve that for E or for any attacker. So that's a little bit the story of the syndrome decoding problem. So yeah, this is now how we set up code-based crypto systems in a very, very general idea. In a very, very general idea. So, the public key should be the parity check matrix or generator matrix or whatever representation of some random linear code. And for many systems, this will mean random looking. Of course, they're not random because then they have to be related to the private key in some sense. But that's the idea. It should be to the outsider, it should be a random linear code and a syndrome. All right, because then for any attacker, just seeing that information, we have this NP-hard problem. We have this NPR problem of the syndrome, general syndrome decoding problem. And the private key should then be an efficient way of finding the solution to that syndrome decoding problem. So an efficient decoder mostly. So usually you want to find a low weight error vector or the corresponding message or the code word to this syndrome equation. So in the end, that's kind of equivalent. If you know the message, then you know the code word. Know the message, then you know the code word if the code is known. So it depends on how you set up the system, what formulation you will actually have. But that's again the general idea. Publicly known, a random linear code in a syndrome. Private, you should find an efficient way to solve or decode in that random looking linear code. So usually it then comes from some other code that is actually not random, but actually very structured. And again, you. And again, you're allowed to use various coding weights, whichever is your favorite. And of course, I mean, then they have very different behaviors, they lead to very different parameters, and so on. So it's still to be determined what is the best weight from a security and efficiency point of view. All right, so that was my very easy introduction. Very easy introduction. Now, let's get to the actual public key crypto systems. What do they look like? So, the first one, and that's the one you will probably always hear about, is the McAliese crypto system from 1978. So, again, in computer science terms or information theory terms, really old. And it goes as follows. So, you take a generator matrix, call it G private of a GOPA code with a known error correction capability T. Known error correction capability T. You take some invertible matrix S and a permutation matrix P. Then, out of this private generator matrix, you create the public generator matrix by applying S on the left and P on the right. And well, you publish that, this public generator matrix, and also the error correction capability T. And now, everyone who wants to send a message takes their message vector. Message vector and encrypts this as an erroneous code word by, well, making it a code word. So applying, multiplying it with the public generator matrix and adding a random error vector of Hemingweight at most T, so that T was the error correction capability of the code. All right, so everybody can do that. This generator matrix is public somewhere. Take your message, multiply it, take some random E. Take some random E that fulfills that it's decodable. And well, that's your ciphertext. You send that ciphertext. And well, what does Bob do? Bob wants to decrypt. So he knows S and P. That's now the important part. Okay, he knows S and P. So he applies inverse of P to this ciphertext. That will actually make him end up in that GOPA code that he has an efficient decoding algorithm for. So he can decode. For so he can decode in that code, and then, well, at the very end, you simply have to apply the inverse of S of S as well, because that was just scrambling the rows of the generator matrix around. And you get M. All right, so, I mean, very simple. He knows the Gopper code. Bart knows the Gopper code. He has a good decoding algorithm for that. So he just takes that ciphertext and with this inverse of P brings it back into the actual code, into the private code. The private code there, he decodes. Well, that's this extra extra operation over here to get the original message back. And Eve, well, Eve, I mean, sees this ciphertext and hat. However, she doesn't know what the actual code is, the actual copper code is. She only sees this public generator matrix, and that looks like a random code. She does not have any idea about what this private code is, so she also doesn't have an efficient decoding algorithm. Hence, she is left with this NP-complete problem of. Left with this NP-complete problem of generic syndrome decoding. And that's infeasible for her to do. So, really, again, very pretty, I would say, especially if you're coding theorists, super easy, very easy to understand what's happening here. Also, of course, why it works as long as you're here, as your E is in the unique decoding radius, this is what we have to assume. Why does that work? Because P is a permutation matrix, it's an isometry. So, if P An isometry. So if p minus one is applied on e, it has the same weight, hence you can still decode this thing after applying p minus one in the code. Good. And then of course you can generalize that into, yeah, what degrees of freedom do you have more or less? Okay, what can you change and still have the same idea in this crypto system framework? Okay, so call this the general. Work okay, so call this the general Mecha Leese framework. Namely, well, of course, it doesn't have to be the Hemingway, it can be any other way, okay? So, it can be Heming, rank, lease, some rank, homogeneous, again, whatever you like. And then it doesn't have to be this P and S matrices. It can be some masking or disguising function. Just some way to hide this private code in a public code somehow. Okay. And in the class. And in the classical McLease system, this is an isometry that makes your life easy, but it also leads to a bunch of attacks. So you can even relax that condition. It doesn't have to be an isometry. It can also be something close to an isometry. We call that a near isometry. As long as you have an idea by how much any vector's weight can change by applying this function phi, then you still know, okay, how to choose your. Okay, how to choose your random error that you're adding in the encryption such that you will still be in the unique decoding radius? That's basically the idea here. So, the general framework then is, okay, we have some private code for which we know an efficient decoding algorithm and its error correction capability. We want to disguise it with this phi function, whatever that is. Okay, that's I mean, that's one of the key problems of creating good crypto systems. But the well. But the well, phi of the private generator matrix is then what we publish, so that's the public generator matrix, and then we publish the error correction capability basically of this public code, which we know if we have an idea of how close to an isometry this phi function is. Well, encryption is then still the same as before and decryption also. I mean, here I just made my life very easy. Whatever this phi is, it can be like one step before decoding. It can be like one step before decoding, one after, like in the classical setup, it can also be all before, all after, whatever. But you simply have to somehow bring back the ciphertext into the code, into the private code that you can decode there. Well, and then bring everything back just in the right order that you get the actual message at the end. So that's my generalized McAllis framework. And of course, as I say, you have a lot of degrees of freedom. You can try out a bunch of things, and people have. Have and many things have not worked, and very few things have worked and are still secure. But there are still lots of things out there that you can try. Now, the other system that you probably hear the second most about is called the Nida Data Crypto System that was a few years later, 1986. It's basically the dual version in the sense of that we're now using the parity check matrix. We're now using the parity check matrix instead of generator matrices. And we're not hiding or we're not encrypting the message as a code word or an erroneous code word, but actually as a syndrome via the parity chain matrix. So let's have a look what it really looks like. So we have a parody chain matrix that we keep private, this guy here. Again, classically GOPA code, but let it be any other code if you want to change that. The same invertible. The same invertible S and permutation matrix P as in the McAlee system. We do the same, okay? We do S times H private times P. That is what we're going to publish. That's our public parity check matrix and the error correction capability. T is also made public. So now here's this one little tiny, which I find ugly thing. So you have to take your message and you first have to encode that as some weight t vector in F2 to the n. Okay, so you have. In F2 to the n. Okay, so you have to encode it as a decodable error vector for the code that we have. And then you encrypt it as the syndrome, meaning you take that M, multiply it with the parity check matrix, the public one, and that's your ciphertext. All right, you send that to Bob. Bob again knows this decoding algorithm of the private code, so he multiplies by s to the minus one, which brings him. S to the minus one, which brings him back to the actual Gopper code. He can decode in there. Well, in the end, he has to apply the permutation matrix to get the original message out of that. And of course, you can generalize that again, just in the same way as the McAllis system. You can use any type of weight, doesn't have to be the Heming weight, you can use near isometries or other isometries as disguising functions. And then you simply have to. And then you simply have to adjust that this might not be t anymore, but something a little bit less than t, depending on what your phi does. And the rest really stays the same. So that's the general needlewriter framework. And of course, it doesn't have to be a Gappa code. It can be any type of code where you have an efficient decoding algorithm. All right, so one other system I want to show you that has a very different flavor. Show you that has a very different flavor. Actually, it rather has the flavor of what you do in many lattice-based crypto systems. Is what one of the crypto systems that Aleknovich suggested. And I show you only the first one. He suggested several versions. I only show you the first one because that's the simplest and kind of shows you a little bit maybe why I say this is rather or well the flavor of learning. Or, well, the flavor of learning with errors and not like the others, like the other code-based crypto systems. So, again, your private key is a random, well, a generator matrix of a code, but now it's a random generator matrix. So, actually, that's already very different from before. You do not need an efficient decoding algorithm for this system. Okay. And you take a random error vector of weight t, where t has to be determined depending on. Has to be determined depending on the probability that you want successful decoding in the end. Then you publish a parity check matrix for this code here. So that is the code generated by this private generator matrix and that E together. Okay, so you publish a parity check matrix of this code. And now you encode only one message bit per round. So you have to run the system several rounds. I've run the system several rounds if you actually want to get more than just one bit information across. So, per round, you just encode one message bit as follows. So, if your message bit is zero, then you simply choose a random vector from F2 to the n. If your message bit is one, then you create C as follows. So, you take a random A, create the syndrome with this public generator parity check matrix, and add this. And add this random E of weight E. If you want, you could also call this a generator matrix of the dual code, then this would be an erroneous code word of the dual code. Okay. And basically then, I mean, the question is, how well can you decide that whatever is the ciphertext is an erroneous code word from this given code or just a random code word? So that's kind of the similar setup to the AWE formulation. So, the encryption in this case is: well, E was part of the private key, so you're taking the inner product with C, whatever that was here. And well, you get everything is binary, you either get a zero or one. And by high probability, and again, my highest in quotes. If you really want to go through the parameters, it takes a bit more effort, so I don't have time for that today. But let's just say more or less by high probability. Today, but let's just say more or less by high probability, this is exactly the right one. So, I mean, if it was a random vector, it's going to give us zero. If it was an erroneous code word from that dual code, it's going to give us one. So, that is one other version of a based crypto system that you can set up. And then, the last one I want to introduce today is HQC. HQC, and I specifically want to introduce that because that's one of the three NIST systems that are still left in the competition. So yeah, HQC Hemming quasi-sidily crypto system from 2018. You can formulate it in different ways. I didn't want to go into other notations and polynomial rings and so on. So I'm trying to stay with just vectors and matrix. Trying to stay with just vectors and matrices for that, we need this funny multiplication definition over here. Okay, so if I say x circ y means, okay, we have our x vector and we then multiply it with this rotation matrix, it's also been called from y. So I just have, I'm in y in the upper row and then any type of shift by one, okay, of that first row all the way down. Of that first row all the way down. So that is this operation up here. So now the private key is two random vectors x and y from fq to the n of Haming weight w. And the public key is a generator matrix of an efficiently decodable code. So there are many options and what to choose here. Okay, and well, I'm already jumping ahead, but one of the cool things is you don't really have to worry about too much structure in this. Structure in this setting, in this type of crypto system, because it's public anyway. Okay, so this now, before the efficient decoder was kind of part of the private key, in this case, it's actually publicly known. So that's again very different from the Michelisa-Niedereta type of system. And then, so that's part of the public key, and the other part is you choose some random age, and then you do this syndrome over here. It doesn't look like a syndrome. Over here, it doesn't look like a syndrome if you're not familiar with this formulation, but it really is. It's basically xy concatenated as one long vector times a parity check matrix that is made up of the identity matrix as the first block and then the rotation matrix corresponding to this H as the second block. Okay, so we have two codes going on here. One is this. Codes going on here. One is this G corresponding to G, which is efficiently decodable. And the other one basically is this identity and H part over here, which we do not have an efficient decoder for, but it doesn't matter. We don't need it in this case. And then we encode a message. So we again have a normal message over here as follows. Namely, we, well, we once compute this thingy here, and then we compute this thingy here. So here you see we're actually. This thingy here. So, here you see we're actually encoding the message in this officially decodable code. And then we're adding a bunch of stuff, okay, on both sides. And we're adding it exactly in such a way that Bob can do this operation in the end, namely take this second part minus this first part times y and decode this thingy then in the publicly known code. And again, by high probability, here. And again, by high probability, he will then receive M. Okay, so these last two actually only work by high probability. So they have a decoding failure rate, whereas the Akales and the Nierita crypto system are deterministic. So if everything is set up correctly, then you will also for sure decrypt to the right message. And in this case, you have some slight failure rate of the decryption, but it's small enough that we accept that. All right, so some final remarks for this part. Mekalis and Nida Reiter are really equivalent from a security point of view. That's why very often you'll only hear people talk about one or the other. And it's a little bit a matter of taste what you like better. Most people, I feel, like Mechales better just from explaining things and understanding what the code does and what's happening. However, on the other side, Nida Redder is often more efficient in implementation. More efficient in implementations. So very often you actually theoretically study Make-Alise and then implement it with Needer Ruther. Alegnovich, or in a more general setting, you can say learning parity with noise, kind of analogously to learning with errors in the Lattice case, is mostly thought to be not practical. However, some people say there are promising variants. You know, if you generalize here, they're Generalize here, there, do something here or there. So, I don't want to say it's, you know, it's dead. I never want to say that. So, you know, have a look if you're interested in what it does and decide for yourself. But for the NIST proposals, so the three remaining code-based crypto systems that we have is really classic Megalese in a Nida Rita framework. Funny, yeah. So that's the finalist that they said, yes, we definitely want to go with. Said yes, we definitely want to go with that. Then HQC and BICE are the two alternate candidates. HQC, I showed you on the slide before. BICE is another one that is a Nila-Rata framework with double circulant MDPC matrices. MDPC is medium density parity check matrices. It's again in the Hemming matrix. And well, security is based on finding an MDPC matrix that allows for efficient decoding. So a specific Efficient decoding. So, a specific type of generator matrix for the code. So, the code itself is known again. So, the security does not rely on that, but the security relies on finding that exact generator matrix that will give you an efficient decoding algorithm. So, that's kind of interesting, an interesting twist there as well. Okay, last one: the parameters. People are usually interested in that. So, here are the So here are the sum suggested parameter sets for those three NIST public key systems. There are always three security levels that the NIST suggested that you need to achieve. So 128 bits, 192, and 256 bits. And well, I mean, as you can see, these are the parameters. In general, code-based crypto systems have the problem that the public key is always very large. And as you can see, the classic mechanism. And as you can see, the classic McElies by far has the largest public keys compared to these other guys over here. However, on the other hand, the ciphertext is really small for classic McElies. That is nice. And the other advantage that we also have is that encryption and decryption speed is also pretty fast. So that's nice. Yeah, but overall, you can see that HQC and BIC have much smaller public key sets, and it is more or less the main. The main goal we're trying to achieve is to find alternatives to the classic Michelese one that have smaller public key size, but are just as secure, of course. And just to compare, here down here, I have the RSA public key size approximately. Okay, so this is 400 bytes as compared to here, 261,000 bytes. That's a big difference, of course. These already, these two guys come much closer. Come much closer. Okay, cool. Of course, there have been, as I said, many variants of Mechalese and Nita Reiter people have used to try all kinds of codes, read Solomon, read Muller, algebraic geometry, LDPC, convolutional codes. They've used other metrics, particularly the rank metric. Philip will talk about that. In there, they've used Gabrieline codes instead of Reed-Solomon codes and the Hemming metric, or low-rank parity check codes instead of LDP. rank parity check codes instead of LDPC codes. They've tried using other disguising functions like knee isometries instead of isometries. However, unfortunately, many of these suggested systems have been broken by recovering the secret from the public code. All right, and that brings me to the next section, namely attacks. So what do you have to be careful with when designing or what do you have to consider good parameters when designing? Good parameters when designing such a group to system. So, first thing that you have to think of is generic decoders. So, what can Eve do? What can an attacker do? Well, of course, she sees the ciphertext. Let's just think of Michelis, the ciphertext, which is an erroneous code word in some random-looking code. She knows the code, that public generator matrix. Could she simply decode in there? I mean, that is the first thing, of course, she could try. And then the question is: okay, if that code doesn't have to be. And then the question is: okay, if that code doesn't have any structure, what can we do? Like, is there anything smarter than plainly brute forcing? Answer is yes, there is something smarter. And this is the general field of generic decoders. So an attacker can always try to decode the cipher in the public random code. And the best known generic decoder determines the security level more or less. And these generic decoders in the Hemming or Lee metric are, well, have first, like the first family of decoders have been called information. Family of decoders have been called information set decoders. That probably rings a bell to many of you. And then they have been more or less relaxed to birthday decoders. In the rank metric, there are again several names for the same thing. So there are rank support decoders that are kind of, it's a little bit the analog of what these information set decoders do. And in more general, people have also worked on the min-rank problem, which is slightly different, yet, if you have. Different, yet if you have a solution for the min-rank problem, then you can also use that to solve the ranked syndrome decoding problem. So you can also use these various types of algorithms for the min-rank problem to decode in the ranked metric, if you like. So I'm not going to go into more detail because anyway, I don't have the time for that, but just to have told you what's out there. More interesting are the distinguisher attacks. Okay, so if the system has a secret code, If the system has a secret code, as we saw, not all of them do have a secret code, but if it has one, then of course Eve could try to reconstruct the secret code from the public code and with that find an efficient decoding algorithm and also break the systems. And these attacks are usually based on a distinguisher. Distinguisher is just the behavior such that the structured secret code has a different behavior from that of a random code. Okay, and the most And the most known one, or at least in the Heming metric, is the square code distinguisher for Reed-Solomon codes. And related, then you can also extend that to other evaluation codes. It goes as follows. So if you define the square, this is the star product square, which is just the coordinate-wise multiplication of all the elements in your code. And then you generate the linear span out of all these elements. out of all these elements. So you get another linear code. And the cool thing is that if you take a Reed-Saldoman code, D is a Reed-Saloman code, then you get that the dimension of this square is 2k minus 1, if k is the original dimension. And on the other side, a random code will not have that. It will actually have a much, much larger dimension, namely k plus 1 over 2. So more or less k square, which is of course very different from 2k. Which is, of course, very different from 2k. And then, well, I mean, usually those distinguishers are still kind of like, well, not easy to find, but easy to understand, or sometimes easier to find. Then the next question is, how do you actually apply those on an attack? So here is an example of a square code attack. So if you have a Mechali scheme where the generator, the public generator matrix is constructed by inserting random columns into the private generator matrix. Private generator matrix and the permutation matrix does something. Okay, that's not too important. I mean, it's there, it's good, but for this attack, it's not too important. And this private generator matrix is a generator of a Reed-Solomon code. Okay, so we're inserting columns into this Reed-Solomon generator matrix. Then the attack goes as follows: So delete the ith column of this public generator matrix and compute now the square code of this punctured code. Punctured code. If the dimension decreases compared to the square of the original public generator matrix, then this column was one of the randomly inserted ones. If it doesn't decrease, if it stays the same, then it was one of the good columns. And you do that step by step, and you get rid of all the randomly inserted columns until you finally get the actual private generator matrix times p. Okay, so a permutation of the one, but then of course. One, but then of course, you can already decode in there. Yeah, okay. Well, you can get rid of the other problem. That's uh, that's uh, yeah, that is not the big issue here if you're talking about Reed-Solomon codes. All right, so this is an idea how you use this distinguisher in an actual code, in an actual crypto system. So, it really depends on what this disguising function is. Okay, in this case, it was well, S and P. Case it was well, S and P, just as before, but also this inserting of extra columns. So, depending on what this disguising function does, an attack based on a distinguisher can look quite different as well. No, okay, so the Frobenius distinguisher is the analog for Gabi-Dullin codes. Okay, the Gabi-Dullin codes are the analog of Ritz-Saloman codes, and the Frobenius distinguisher goes as. The Frobenius distinguisher goes as follows. So we define this g to the q for matrix to be just the coordinate-wise, qth power of everything, and c to the q is simply the code generated by some generator matrix to the q. And then we have that a Gabetelin code, so this is now d is a Gabitolin code, fulfills that the dimension of D intersected with its Frobenius, so the Frobenius applied to itself, is K minus 1. Is k minus one. And by high probability, if you do the same for a random code down here of the same dimension, you actually get, oh, sorry, zero, not 2k. You can formulate it the same way by saying the space spanned by the two, then you would get 2k down here, but you would get a different thing up here. So sorry, this should be zero down here. But anyway, it's very different. And you can launch the following attack. Can launch the following attack. So, if you have a Mecca Lee scheme in the rank metric now, we're using the rank metric, where the public generator matrix is constructed again by inserting random columns into the private generator matrix times permutation. And the private one is a Gabby-Duling code. What do you do in the attack? So, you construct a generator matrix, which I call g-extended, by applying this Frobenius U times. Okay, and well. And well, taking the span of all of those codes. And the non-zero columns of the dual code of this extended code that comes from this extended generator matrix form now the dual of a k plus view dimensional super Gabby Dolin code. So this code includes the original Gabby Dolin code. And by that, you can find the evaluation components of the super Gabby Dolin code and they define the And they define the actual private code, so the secret Gabrieline code that you started with. And hence, you have found the secret code in this case as well. All right. And the last note on attacks. So these were really more or less the big families of theoretical attacks. However, in practice, attacks on the implementation are even more important or just as. Are even more important, or just as important, of course. But in the NIST competition at the moment, these are one of the main problems that people have to tackle right now. So these are attacks on the physical structure of a crypto system, in which you gain information about the key or the message from reaction times or power consumption or things like that in the decryption process. So you're actually measuring something on the device that does the computation of all your encryption and decryption. And while these attacks And well, these attacks can be combined with other attacks, for example, with generic decoders, and they can help each other and improve each other's performance too. So these are attacks anyway that also need to be understood, of course, and need to be taken into account in that standardization process. Good. All right. And now I'm more or less out of time, but I want to give you this little insight, if I may, into the signatures. So, if you want to set up a signature with the same idea as the Mechaliso NidaWriter system, here's one version of how you can do so. So you fix a hash function, your private key is a parity check matrix, again, of a Gappa code, or you can try other codes, but mostly you run into problems. You again have your invertible S and your permutation matrix P. You create a public parity check matrix. Public parity check matrix out of the private one, publish that together with the error correction capability. So still the same as in the public key setup. Now you take a message and you have to now, and this is kind of the tricky part, which is like not great, let's say. So you have to randomly find now some other vector such that this thing here becomes decodable, let's say. So we want to randomly find this. We want to randomly find this m perp such that if you take all of this together, you hash that, well, and that s minus one again doesn't matter that much, you can decode in that in that code that you have, okay, in that code given by h, so that you find an e that fulfills this equation. Once you found that, your signature is then this m prime that you're adding, okay, and this e times p, which is. times p which is your permutation of your error vector all right so that's your signature you send that together with the message what can you do in the verification process well you check that well whether the weight of e times p is really t or less than or equal to t because then naturally also e has a weight less or equal to t. And you check, well, you recompute that E times P times H pub is really that hash that you computed in the signature process. In the signature process. All right, so that is, I think, a really nice idea of doing so. But of course, this finding, this extra little thingy that you add to the message that makes the whole thing decodable makes it somewhat inefficient and more or less problematic from a practical point of view. Okay, so that is this general setup. The original Niterite signature scheme used high-rate GOPA codes and was broken in 2013. Then there was rank sign in 2017, another needer write-type signature using the rank metric that was also broken. And then there were also some more. Okay, there were four or five others. And as far as I know, they've all been broken. That's why I haven't included them step by step. But again, they are out there in the literature. If you're interested, I'm happy to give you reference. Happy to give you a reference to that. And then the last thing that you can do is signatures based on zero-knowledge identification schemes via the Fiat-Shamir transform. Fiat-Nashamir transform is a very general thing that works for any zero-knowledge identification scheme, but doesn't have to be code-based. And just for completeness, let me show you one of the code-based zero-knowledge identification schemes out there due to. Due to time restraints, I'm not going to go through that step by step. But the idea is, again, here that you. So, the cool thing here from a setup point of view is that, again, you don't need a decoder. You don't need to keep your code secret because you can choose your, well, you start with a solution to the syndrome decoding problem. Okay, you basically choose an E, you compute the syndrome, you publish the syndrome and the party check matrix, and your E is the sequence. Matrix and your E is the secret that you simply keep. And then there is some back and forth communication between the prover and the verifier, which would be Alice signing and Bob verifying the signature, by which you can then have some probability of how likely it is that somebody actually forges this signature. And then you have to run it a bunch of times, this protocol to get to a security level that you would actually like to have, more or less. Okay. So the important thing, maybe, here is. So, the important thing maybe here is for a security of 128 bits, the public key is about 832 bits in this one, and the signature size is 51,000 kilobytes. So the point is, and that's kind of the general thing with these types of signatures, the public key is not the problem in this case anymore. The signature size becomes huge, and that is already automatically due to having to repeat these protocols really like thousands of times. And that will always make the signature. That will always make the signature more or less too large for almost any application, even if you're improving like in here a little bit. But it's still nice that they're out there because at least they're secure. They haven't been broken yet. All right. And this brings me to my summary. So, code-based crypto is one of the most studied and promising research directions in post-quantum crypto. So, very high interest in particular. So, very high interest in particular because quantum computers are being built and are being improved in their capacity of what they can do every year in quite some exponential speed, actually. So, in particular, many variants of this Mechaliso or Nida Reiter public key crypto system have been studied, and three out of those are NIST final lists or alternate candidates. So, that's nice. Overall, the advantage of Coast-based crypto is fast encryption decryption. Cross-based crypto is fast encryption, decryption speeds, and disadvantage is the large public keys. If you're thinking of Mechales near Writer type of systems, so one of the big questions is how much structure in the code that we use in such a system is good. Okay, so because we want structure to be efficient, but we don't want to have too much because then you can break it, you can attack it. So that's classical trade-off of security and p-size here. And that is really the ongoing thing that people work on. People work on digital signatures in the McAlise or NidaWriter style face the big challenge of making the message decodable, finding this extra little thing that you have to add such that it is decodable and then you can actually sign. So that's impractical there. And the other type digital signatures based on these zero-knowledge identification schemes promise good security because they're not dependent on the secrecy of the code anymore. However, they will always be large. Always be large, okay. So, depending on your application, maybe you don't care, but for signatures, I think that's that's that's really quite a drastic problem. So, it would be nice to find other digital signature schemes that are kind of Mecca Lee style, but maybe slightly different, that do not have this problem with making the message decodable in this sense. So, with that, I hope I gave you a good overview, and I thank you for your attention. And I'm open for questions or comments. Open for questions and comments. Thank you, Analena. You're perfectly on time. So we have time for questions, either from the audience or from Zoom. The Felicia invented the 10 seconds rule, apparently, so I have the 10 seconds rule. See, we get it. Okay, maybe I can start because I have just a clarification on your very last slide, Analena, on the zero-knowledge signature. It's not 51,000 kilobytes, right? It's 51. Oh, that's good. Yeah, I was just verifying. Yeah, it's still very large. It's still large. Yeah. It's still large, yeah. Yeah, but um, it's 50,000 bytes. Sorry, yeah, yeah, yeah. If it was 51,000 kilobytes, then there would be absolutely no. Yeah. More questions from the audience? We can move the questions maybe into the gap. The questions maybe into the Gather Town space if someone wants to join there, if Anolena can join there. My sons will enter the space at some point, but amazing that we like it so we can speak about skiing. Great. It was a great introductory talk. So thank you, Annalena. Let's thank Analena again, please. Thank you, guys.