But the math department is here. I remember visiting this booth in your mouth. Okay, so he's talking today about EDP convergence for brain systems, non-equilibrium, steady states. Mosburg. Thank you very much for the introduction, and also thank you very much to the organizers for inviting me to these really interesting. To this really interesting and workshop with a variety of topics. And of course, I want to highlight the picture. I hope this is the view we will have tomorrow evening from the gardens from Carmen de la Victoria. So at least yesterday it looked like this. But there might be rain like on Sunday. So today I want to combine two topics. One is grading systems. One is grading systems, which was not yet highlighted, but there will be more talks coming. And non-equilibrium steady states. This will be at least mentioned in one talk on Thursday by Josephine Baker. And so this is a topic which is typically not connected to gradient systems. But I want to show that this is connected if you do multi-scale theory. Multi-scale theory. So, first of all, I want to introduce my notation and my much wider view to gradient systems because I'm coming from continuum mechanics. And for me, gradient systems started with Moreau when he did plasticity theory in the 60s. And so I'm coming really from mechanics. Khan-Hilliard theory is a gradient Penrose V. Is Penrose 5 and so it's not related to Wasserstein, even so the applications will be related here. So, of course, we all know what is a gradient flow equation. So, you have a state Q, this evolves, and the gradient is calculated by the derivative of a functional and a geometry operator, which I call Onsager operator, because in mechanics you should. In mechanics, you should give a physics name. You have symplectic operators or Poisson operators. And so this is the equation. More often, it is written as a force balance. You have the potential restoring force, and you have the viscous force. And this G then is the Riemannian operator which gives the viscous force. Because many of the people here know this first law. Know this first law as Darcy law, but it is the gradient node of the enter is a length of abression. Is it the same already? Darcy's law could be one of the cases, but I will come to that. Darcy's law is only the kinetic relation. It's not. So if you put here the chemical potential, then it's Fick's law or Darcy's law, Brinkman law, whatever. So we will come to that. So for me, the gradient system is. For me, the gradient system is the triple state-space functional and the geometry operator. And the idea in these multi-scale problems is if you have an epsilon problem to find the effective energy. That's if you do multi-scale modeling. And as mentioned, the main point is we have a kinetic relation and we We want to find the effective kinetic relation and the effective energy. The kinetic relation is simply the relation between the driving force and the rate or the flux, whatever it's called. And this often is a linear relation. However, in many mechanical problems, you will have nonlinear relations. And it turns out that even in chemistry, you should expect nonlinear relations. Expect non-linear relations here. So the main point in my theory is that I will work not with the kinetic relation, but with the so-called dissipation potential. The dissipation potential for a linear relation is just the associated quadratic form with a factor one-half. And if you take the derivative with respect to q-dot, you get the linear relation. To q dot, you get the linear relation. That's classical theory, quadratic forms and symmetric linear operators are in one-to-one correspondence. And of course, you have two versions. You have the quadratic relation, the quadratic form related to G and you have the quadratic relation to K. G and K are, by this equation, simply the inverse of each other. And how, in general, these operators might be degenerate, and that is the good thing: if you do dissipation potentials, you can deal with degenerate cases, you can deal with unbounded operators, because quadratic forms can be transformed into each other by Legendre Evangel transform. And you don't need to have nice smooth operators. So now we come to a more general situation. A more general situation that we want to forget about the quadratic structure. So now our R is only a dissipation potential if it has three properties. It's non-negative, it is civil, and it's convex and lower semi-continuous. That's the natural setting, generalizing the quadratic operators. You can still do a Legion de Transform. Still do a Legendre transform, always only on the second argument. The first one is the state dependence, the second one is the rate dependence. If you do a Legendre transform, you get again a dissipation potential, but which is called the dual dissipation potential. So from this property, you get this property with a star, and from this property, you get this property with a star. So this is a trivial relation, and convexity is preserved. Convexity is preserved. So now the derivative or sub-differential inclusion, if you would write an inclusion here, should be an inclusion. I have changed this for a physics talk and I forgot to change it back. Sorry. So you have this equivalence that psi is in the sub-differential of R at V, if and only if V is in the sub-differential of R star at V. Of star at xi. So that's now a non-linear kinetic relation. And you can write the so-called gradient flow equation now either as a rate equation, but now you do not have an Onsager operator here, but you have a sub-differential here. So this is a non-linear combination. Or you can write down the force balance, which gives you the viscous force. Gives you the viscous force plus the distorting force together should add up to zero. Of course, there should be differential inclusions here in the general case, like when Giselle Stock. So now I want to point, of course, that we now have a family of gradient systems and we want to. Of gradient systems, and we want to discuss the question: how do we pass to the limit epsilon going to zero? So, what typically is done, you take your gradient system, you write down the PDE, you solve the PDE, then you throw your machinery and you pass to the limit by extracting suitable a priori estimates, and then you prove that there is a. Prove that there is a equation, a limiting equation. That's the typical PDE approach. And the main point is here, you simultaneously have to pass to the limit here and here by suitable apology estimates. But that's somehow strange because on this way, often you forget about the gradient structure. The first one who really pushed this was the work by Sandier and Sarafati in 2004, where they ideally said, Yeah, but of course, this should be a gradient system, at least in some cases, or in which cases. So the question now is, if we have such a situation, what should we do? Well, we should go back and look what did we learn for static gamma convergence. Why are we looking Why are we looking at gradient systems? We are looking at gradient systems because gradient systems have a variational structure. So we should remember what we learned for variational theory. If you think about gamma convergence, you have a functional E epsilon, you look at the minimizers, you may add a loading, and you have the minimizers. And of course, you can get up the Joge estimate, you find a weak limit. weak limit you can look at the order language equation and you get an they solve the order language equation but that's not gamma convergence gamma convergence is you go down here and you prove that going down here is consistent with going down here so the idea of gamma convergence is completely different you work on the functional and then you say if i extract the right limit on the functional Extract the right limit on the functional, then I have a commuting diagram. Commuting diagram means going this way is the same as going this way. And that's what we want for gradient systems. We want to have a commuting diagram for gradient systems. We want to go down here and show that we get the right equation. That's not the typical approach. So even San Diego is a fan. So, even Sandy is a fatty, you can interpret like this. They say, okay, you do something here and then you go backwards. But that's very dangerous. That's very dangerous. Why? Because the gradient structure is not uniquely defined by the equation. One equation can have many gradient structures. The gradient structure contains additional thermodynamic Contains additional thermodynamic information. So look at this equation. If I write it like this, you may call it not like this, but you may call it diffusion equation. If I use a theta, then most people would call it heat equation. If I use it like this, then some people may call it phase field equation. How do they differ? If you solve them mathematically, they do not differ. Them mathematically, they do not differ. But if you think about the physical background, you write down a different gradient structure. In this case, we learn from Otto, Felix Otto's work, that the right gradient structure is to use the Boltzmann entropy and what some people call the Wasserstein gradient structure. I call it the Otto gradient structure because there was not Because there was no tangent space ever to write a gradient in Masterstein's work, I checked it. But that's not important here. The main importance here is that this gradient structure should never be connected to the word heat equation. Because no physi every physicist would laugh at you if you would call this entropy for the heat equation. Be for the heat equation. Because in the heat equation, the functional has to be monotone in the temperature, the derivative has to be positive because it's a specific heat. But the derivative of the log u log u function is non-change sign. It cannot be the type form. So the heat equation has a different maybe logarithm for gas dynamics. It could be square root. Gas dynamics, it could be square root of theta if you think about solids. And then, if you want to write down a gradient structure, you have an Onsager operator which has a different power here. That's necessary. So the heat equation has a completely different gradient structure than the auto gradient structure for diffusion. And it's clear that diffusion is physically a completely different process than. Different process than heat. Heat transport means you do like this, but diffusion means you do it like this. That's completely different. The Markov process you would write down is a different one. So if you write down a microscopic model, here one particle is moving around, here particles are kicking the neighbor. And phase field equation, but sorry. But sorry, I made a late. So here you have an L2 gradient structure with a directly integral. Sorry, I made a mistake in latex B1. Anyway, so one equation can have several gradient structures. And my warning is if you have a multi-scale problem and you pass to the limit, choosing a different gradient structure to your equation may give a different To your equation, may give a different effective equation. So, the diagram is the following: we have this equation, we agree on this equation. Giuseppe chose one gradient structure, I choose another one. He's doing some limit, which I will call EDP convergence. It's a rigorous mathematical theory. He extracts a limit, he gets an equation. I go home, do my Switch on the EDP machinery, I get a limit and I get an equation. And we realize the two equations are not the same. This can happen, and the simplest example is here. Very simple equation. Every one of you can write down the equation, solution. It's the first two weeks of any linear PDE course. It's a linear hyperbolic equation with wave speed zero, you wouldn't do this. Wave speed zero, you wouldn't do this for the tactical reasons, but it's included in every course. So you have a simple ODE or PDE. Think about a Petri dish or think about some enzymes in the salami or think about grass growing between the cobblestones. The equation we know explicitly. Know explicitly. So, you want to find the effective growth or death rate in such a system. So, does it work? The answer was given by Lichter Tara in 1990. Homogenization of hyperbolic equations does not work is his result. My result is not the same. Not the same. This result is true. Everything is nice. I say if you choose the right gradient structure, there is an EDP limit. I didn't tell you what is an EDP limit. That's very good, because now I can make a multiple choice test with you. You have 25 minutes, then I will collect the results. I say there are EDP limits. There are EDP limits to this equation. I didn't give you the gradient structure. And at least two of the following four results are correct. So either the minimum of this V, the harmonic mean, the arithmetic mean, or the maximum. I ordered it by size. And we know that harmonic and arithmetic mean quite often appear. Maybe other values can. Maybe other values can appear. I don't say these are all the results which are possible, but some of them are possible. I just want to say that choosing the gradient structure beforehand and doing a rigorous thing may make a difference. And of course, we all know if you take gas dynamics, you can get the heat equation out of it, but you can also get the wave equation out of it. Wave equation out of it if you do the right setup at the beginning. That's why experimental physicists take a long time. If they want to measure the Higgs boson, they have to do something else than if they want to measure something else. And that's exactly well-prepared initial conditions and things like that. Anyway, so we have to do some serious mathematics and we have to remember that the gradient structure encodes additional features like biological. Like biological features, if you think about these experiments up there. Anyway, so what is EDP convergence for gradient systems? What is EDP convergence? Well, I have already explained that we have fental equivalence for the kinetic relation. But there's a third equivalent statement, namely that the sum of r plus r star at v. R star at V and psi star equals the duality product. That's equivalent with standard convexity theory. So the difference is these are in the Hilbert space or the Banner space, this is in the dual Banard space, but this is an optimality condition on the real numbers. If you plug in here Q dot and fox I minus And for ψ minus the storing force, then you get this simple term. And this, by the chain rule, is the derivative of the energy. And that gives you, if you integrate by time, what we call the energy dissipation principle. This I learned from Giuseppe and Ricardo Rossi when she did her PhD in 2003. In 2003, IF4, and we worked quite a lot on that and applied this because of my background in mechanical applications, viscoelasticity and other things. So the energy dissipation principle says instead of solving a PDE, you can solve an optimality condition, which is a scalar equation. So the old energy, the initial energy, The initial energy equals the final energy plus the dissipated energy if you write the dissipated energy in this special R plus R star structure. And that's the basis, of course, of a lot of theory in the, let's say, in the green book on metric gradient flows, but of course, it generalizes to the stack up with R and R star. So now, this is the basis of defining EDP convergence. EDP convergence is now a convergence which you define on gradient systems. You have a family of gradient systems. You say it EDP convergence if you have two conditions, the energy classically gamma converges and the dissipation written in this form. In this form, it's not the dissipation used by physicists. It's the dissipation functional written in R plus R star form, which is exactly given by this form. This gamma converges as functional on the space of trajectories. So you go to space-time curves, not only to space functionals like for the energy. So that's the idea, and the main point is that, of course, the result should again have exactly this form. Only then we call it EDP convergence. We do not ask that the R epsilon converges to R effective. That's, in fact, in many applications, not to be expected. We will see this. You will see this. I also want to mention that this is a non-linear combination here. And this is a crucial essential point. So you do something non-linear here. That's, of course, exactly the Santi-Safati approach. And so the main point here, but here it's written more clearly that this is a non-linear combination. Of course, the solutions of the gradient flow equation. The solutions of the gradient flow equation are not needed. It's exactly like for gamma convergence. If you prove that a functional gamma converges to something in the sense of the Georgi, you never talk about minimizers. You talk about Liminch sequence and recovery sequence. And here it's the same. The solutions are not needed at all. However, you can prove that if you have solutions here, that they converge to solutions. That they converge to solutions there. This is a consequence of the definition if you have well-prepared initial conditions. The classical things here I don't want to mention, there's not enough time. That's the definition. We will come to applications, but now I have to make a step away. I have to talk about non-equilibrium steady states. Why are non-equilibrium steady states related, or what are they? In fact, so because gradient systems are related to equilibrium theory, and equilibria are more or less critical points of the energy. In physics, you say an equilibrium has no fluxes, there's no dissipation. In gradients, In gradient systems, all the equilibria, all the steady states are equilibria, not non-equilibrium steady states. Non-equilibrium steady states arise if you have open systems. But my gradient system is closed. However, there might be metastable states which are gradients behaving like being in an open system. Being in an open system, so and this happens in systems where you have a multi-scale slow-fast structure, for instance. And so, inside of the gradient system, you have non-equilibrium structures, so to speak. So, this is my notation as before. And now, what we do is we introduce a so-called port, which means from the outside, you artificially drive the system. Drive the system by fixing some value of some variable and you or you inject fluxes. And if you introduce this on the gradient system, then you should also, this will be a Lagrange multiplier and you have a side condition which you force like a Diracle boundary condition. Diricle boundary condition, we will see is one of the classical situations. So we fix the eta and we allow a Lagrange multiplier f to compensate for this fixing. But we stay in the gradient system structure. So now a non-equilibrium steady state will be a solution. If you put a zero here, you solve this equation with this side condition eta and you allow. And you allow for the flux. And you say this is a non-equilibrium steady state if this f is non-zero here. So you have non-trivial fluxes. And you can easily check by this definition that eta times f has a sign because in this gradient structure you can relate it from this equation to r plus r star and then you have a sign. Explain again why we call it port function because there is now this famous port Hamiltonian theory and control theory. Port just means you connect to the outside. The island is isolated, but if you have a port, you can bring in goods and you have to pay for it. This is a Lagrange multiplier if you transport in something. So that's just to have an abstract. Let's look at the simplest one-dimensional. Let's look at the simplest one-dimensional example. You have a functional, you have now, this is the one-dimensional diffusion equation or multi-dimensional one. And what you do is you prescribe Diracly boundary conditions. This means you have to allow fluxes on the boundary, which allow this steady state to be. This steady state to be. So if you look at a Dirichlet problem, this is a non-equilibrium steady state. The functional, in my case, is the simplest one is u squared. The dissipation potential is the dissipation potential having the gradient, like in Otto theory. And you easily see that the dissipation you have by fixing the boundary is proportional to the difference of these two. Proportional to the difference of these two levels, and you get something non-negative. I just want to not go into detail, I just want to mention this work by Bodino, Leibovitz, Muhad and Vilani from 2014. They look at a diffusion equation with stylically boundary conditions and they have this nice sentence: the steady state u infinity is not explicit and depends. Not explicit and depends on the boundary condition in a non-local manner. This is a manifestation of the open nature of the system. So they write this a special paper on the Dirichly boundary data because it is a non-equilibrium steady state and all the classical theory does not apply. You have to redevelop Loch-Sovo-Lev inequalities and energy dissipation inequalities and so on. And there's also a famous Frigoshin theorem, which is the principle of minimal dissipation. So, and his statement is that if the dissipation is quadratic, then it is minimal in the non-equilibrium steady state under the given constraint. So, there is a long history, and there are many papers which try to characterize non-equilibrium steady state. Non-equilibrium steady states using dissipation, but it's wrong in general. And it's wrong in general. You can easily see. I do not have much time. So maybe we first go to this case. Yeah, let's first do this and then I will go back. If you take the classical linear diffusion equation with dyrich boundary conditions, you take Otto's trading structure with the Boltzmann entropy. Actually, the Boltzmann entropy. This is the auto-dissipation function, dual dissipation. You all know these formulas. So, what is the dissipation? The dissipation is the Fischer information. If you minimize the Fischer information with even Dirichlet data, you can do that. That's a nice functionality, it's elliptic, you get something, but you will not. You get something, but you will not get the linear solution of the linear equation, the steady state here. Because the square root is a non-linear thing, you will get something non-linear. In the linear ODE case, you will get a linear function for the square root. That's not the correct solution. However, there is a subtle point formulation. There is a subtle point formulation which we found by working on EDP convergence, which is the following. You take, you construct the so-called B function, which is R star at u and psi minus r star at u and minus b e. So this is a function now on the cotangent bundle. u is in this pilot. U is in this Hilbert space, let's say, and ψ is in the dual space. This function is obviously convex in ψ because R stars have dissipation potentials. And in many cases, like for Fischer information and in the upper case, it is concave in U. So, this is a typical functional where you can define so-called saddle points. And there is now this. And there is now the theorem that, under some technical assumptions, the non-equilibrium steady states can be characterized in a unique way by looking at this V function, minimizing with respect to psi, and maximizing with respect to U. So the non-equilibrium steady state is a zero point. And you can check it here. And you can check it here on this example. If you write down the b function, it looks like this. You minimize with respect to xi and you maximize with respect to u. And of course, you have to prescribe the correct boundary condition for xi, which are the chemical potential. And you can write down the Ode-Lagrange equations and you can. And you can check if you insert the solution of the linear problem that this is zero, then everything cancels. This term cancels if you plug in xi equals log u, then these two terms cancel, and the remaining equation is divergence of a grad u equals zero. So this is behind of the theory, and this. Of the theory, and this allows us to do EDP convergence for gradient flows which have a slow, fast structure. Slow-fast structure means you decompose your state into two variables. One behaves fast and the other one usual time. It looks very particular, so we assume that Q can be little. Q can be written, or little U can be written as capital U and W. W is fast, capital U is slow, the energy decomposes in a specific way, and also the dissipation potential depends on epsilon in a specific way. It looks very specific, but it turns out it's a very natural assumption for many transport diffusion problems. So now, if you insert this, you see. If you insert this, you see you get an equation where on the right-hand side there is no epsilon anymore, but there's an epsilon in front of double. That's exactly what we expect in slow-fast systems. On one variable, we have a relaxation time, which is epsilon, and the other one has relaxation time one. So what we expect is that the W relaxes very fast into something, but this something will not be in equilibrium. Something will not be in equilibrium because it is kept by capital U, it is kept in a non-equilibrium steady state. So if you drop this term here, here you can see that the equation you have up here has a u dot still here, but this u dot you can interpret as a flux, and this is exactly the situation of a non-equilibrium steady state. Of a non-equilibrium steady state. It's not important. You don't need to understand this, but there is now a theorem that if you have for this R star, if you write down the corresponding B function and you take the min-max, or we always find sub-inf. The order doesn't matter at the end because of the conditions. The end because of the conditions, it's the same. If you minimize the fast variables and maximize correspondingly, then you get a function which only depends on the slow variables. And the theorem is the following. Under this assumption, which I have given, you work on superg on the fast, right? It says super on the x-path, inf on the x-star part. Is on the X star part. Should only work on the fast. This works on the fast one only. So it's a fast state here, W. And mu is the dual variable, the chemical potential associated, which is here in the variable. The slow variables are fixed. So if we have such a situation and we know that this V. And we know that this VE function is a nice function, it's lower semi-continuous, and it has the important property that we have a zero here, which is more or less equivalent to the existence of non-equilibrium steady states. Then we have EDP convergence to a slow system where the slow dissipation potential is exactly obtained. Potential is exactly obtained by this min-max formulation. There, you have to re-normalize it. I just want to give you a short idea why this proof is so natural and simple. The idea is simple. The techniques to do everything is not so simple, but it goes back to some work with Matthias Lirau, Marc Pretty, and Michel Renger. So, the main point, of course, is to gamma converge. to be gamma convergence of d epsilon here we have an r plus r star structure which seems to be not related to the b function which is r star minus r star however what you can do is you can replace r star by a lower bound by legendre transform so you can replace this by This by a duality product minus R star because this is in most applications R star is given explicitly and R is not given explicitly like in Otto theory R star is this nice elliptic operator but this is the inverse of the elliptic operator which is more imposed somehow. So now you just have done Legend of Now, you just have done the gendre under the integral. That's a triple operation. You introduce a test function ψ epsilon μ. You insert this here as well. The epsilon cancels because this r epsilon is given exactly by this 1 over epsilon. This epsilon again cancels here. So on this right-hand side now, you have two R star terms. No epsilon. No epsilon showing up, so this is exactly the B function with a minus in front of it. This B function you can always estimate from above by taking the supremo with respect to W from X fast. Estimate from above is good because you have a minus in front, so it keeps a lower bound. Now for Now, for fixed test functions, nice and smooth, you can pass to the limit if you have u epsilon and w epsilon. Here now, of course, you have a sequence. You have to prove a limit-inf estimate along sequences. But still, this can be done. Here, you see that this term disappears because along the sequence, this is at least somehow bounded in some space. Least somehow bounded in some space, and this is nicely smooth. So this disappears, the w, then mu. And here you have this functional, because of lower semi-continuity, you can pass to the limit here. And now you see that there is no nothing collected to this little μ here because this W dot has disappeared because of the epsilon. Disappeared because of the epsilon. So, what you can do is you can optimize the lower bound by making this as big as possible, but there's a minus, so you can take the infimum over all mu and you get exactly B red. So that's a very simple program. To do it on an explicit example, it needs, of course, a lot of work. And that's why I have not written down the technical assumption. Technical assumptions. Of course, then you do another Legendre transform to go from here back to the original form. Okay, let's look at one example. The German is getting up. So let's show at least in one example that this is reasonable. It's a very simple thing. You look at a one-dimensional diffusion equation. However, you assume that the diffusion constant diffusion constant is small of order epsilon in a small interval around the origin. This is like having a cell membrane and the particle diffusing nicely on the left and on the right, but then there is this membrane and the particles get slower. However, the membrane is exactly of the right size, otherwise we would all die. So the membrane has some permeability. So this Ability. So this means the width is epsilon and the parameter is epsilon as well. Otherwise, you will not have any communication. So you take the Boltzmann entropy, you take the Otto gradient structure in this form, and the epsilon is in here. So the epsilon is only here in the diffusion constant. But what you can do is you can rescale. What you can do is you can rescale the equation. I have not done it. If you blow up the interval and you rescale it, then you have exactly a slow-fast system. What happens in the membrane is fast and what happens outside is slow. What you get is the following effective dissipation potential. You have the autostructure on the left, you have the autostructure on the right, and on the membrane you get something strange. You get something strange, something new, completely unrelated to what you know. So this is the cell calculation that you have to do. Then there is a new term. I will show you where this new term comes from. This new term, this C star, will be a cost function. So it's exponential and what you wanted to find. What you wanted to find. This comes out of the theory. I didn't want to find it, I had to accept what comes out. It's the right object. It's the right object. This calculation is the cell calculation that is lattice case. Exactly. And this approach with R, star, and R is necessary for defining this world. I show it here. If you want to calculate P R. You want to calculate the red. So now the port is the following: you have your small membrane interval, you blow it up, and the port is speaking to the left or to the right side. So you take the density on the left side, the density on the right side. You have the chemical potential on the left side and on the right side. What you have to do is you have to minimize the autostructure here for the mu car. For the mu, and you have the Fissure information inside of the membrane. This is now the functional which you have to min-max. You have to find the subtle point. You can do it explicitly. It took us in 2017, it took us five pages to do the calculation. In the paper, it's two pages. If you are not interested in the solution, now I have a half a page proof that this. Half a page proof that this formula comes out. So I still have not written down what the C star. This is somehow missing. I just want to write it here. C star of psi equals 4 cos. So that's the formula. Formula. So this comes out here, and you have a square root here. You have the harmonic mean of the densities left and right. And this is the well, the Dirichlet integral, so to speak, Dirichlet form for the discrete system. So the main message I want to make here is that our theorem says you can do EDP conversions on this model. You start with Model, you start with quadratic dissipation potentials, they are quadratic in side, but the result you get is non-quadratic in psi. So this is not classical functional analysis. You start with linear operators, you do something, you get a linear operator. In gamma convergence, if you start with quadratic functionals, the gamma limit must be quadratic. This is not the case here. This is not the case here, so I thank you for your attention. And maybe someone wants to turn in the results from the one we just need. You mentioned that two different So you mentioned that uh two different gradient structures can converge, I mean converge to two different gradient systems in the leaf. Is there also are there also cases where basically like you converge to the same gradient system? You choose two different creating structures and then you converge to the same grading system? I don't think you this is the right question to answer, ask. So my point is not My point is not the I want to make the following point. It's a different question whether you ask about effective equation or effective gradient structure. So you start with an equation for this equation has two gradient structures. You may converge to the same effective equation with the same gradient structure. But you cannot have two different equations with the same gradient structure because one gradient structure Structure because one gradient structure generates exactly one equation. A gradient structure from a gradient structure, there is a unique way to the equation. You just write down the functional and its gradient, let's say. So your question is, you could have the same equation with two gradient structures. That's not, of course, it happens, but that's not. Yes. Yes, yes, radic and the coach. Yes. Then could it happen that you converge to the same effective equation? Yes. Of course, if you do the same result as I showed with the membrane, you can use the quadratic gradient structure. So the linear Hilbert space gradient structure. You converge, you get the same. You converge, you get the same effective equation. The effective equation is a linear equation. I think it's nice to be the only one. And there is a... This linear equation has thousands of gradient structures. The question is not, you see, if you have a given equation, well, if you have a Poverse medium equation, there are infinitely many, uncountably many different gradient structures. And it's not the right equation from the equation to go to the gradient structure. That's not the right question. So now let me ask you the last question. In this example with the hole and the membrane in the epsilon, the result of finding the new term was known by Professor Tata? No, no, it's not the No, no, it's not related to Tracas example. No, no. The linear equation, the effective equation is the linear transmission problem. This is known probably since 100 years. That's not a question. That's not my question. The linear, you can pass to the limit on the linear equation and you get the transmission equation with the transmission coefficient B. That's classical theory. Everyone can. That's classical theory. Everyone can do this. This is two hours in your PDE multi-scale course. Just some a priori. But it does not give you the information that the right gradient structure for jump processes is not a quadratic one. And here it comes out automatically, even though you start from quadratic, you end up with exponential and exponential. End up with exponential and exponential gradient structures. Well, no, let's say, exponential kinetic relations are more than 100 years old. But they were forgotten in many textbooks because famous Gros de Mazur, many of you have probably looked into that book. I hate it for that reason. It's a big book, claims to do everything, and they do not contain non-linear kinetic relations. Okay, so thank you very much. Okay, so thank you very much. So you know that we need a care pass. Why do we tell what to say?