Okay, cool. Thanks for everyone for coming so early in the morning. Excited to present this paper. So I'm going to talk about our paper on the effect of privacy regulation on the data industry, evidence from GDPR. This is joint work with Yang Ku Chen and Tumi Solz, and we're all economists. And I want to start by talking about this tension at the heart of data privacy regulations. Tension at the heart of data privacy regulation. So, we've been talking in the past few days about how firms are increasingly making use of consumer data, whether it's for product experimentation, you know, using this consumer data to deploy technologies such as recommender systems, target advertising. And we've talked a lot about this notion the past few days and different methods for doing this. In this paper, we're going to look at another dimension of this, which is that this data is user generated and consumers increasingly want control over the data that firms collect about them. Control over the data that firms collect about them. So, this has been amplified in recent years by a number of high-profile data breaches, sort of inability to really understand what kind of data gets collected by consumers, and a bunch of secondary markets where data is sort of resold and combined in different ways. And so there's sort of this tension at the heart of data privacy regulation, which is trying to balance maintaining good data for firms to be able to allow them to make revenues, but also giving consumers control over the data that gets collected about them. So, what we do in this paper. So, what we do in this paper is we're going to study a particular landmark privacy regulation known as the General Data Protection Regulation, which became active in 2018 in the European Union. And it had a number of stipulations. It was one of the widest privacy regulations in recent history and had a number of different dimensions targeting firms' data collection and retention, as well as giving consumers the ability to sort of opt out of data collection. Of data collection. And so, what we wanted to understand in this paper is: how does a privacy regulation like GDPR affect the ability for firms to collect data and then utilize this for predicting consumer behavior and targeting advertising? So, there's two sub-questions there. The first is, do consumers actually respond to the ability to deny data collection from GDPR? So, there's a sort of famous result in the economics of privacy literature known as the privacy paradox, where people's sort of stated preferences. Sort of stated preferences for privacy are that they clamor for, you know, they really care about privacy, but in sort of revealed actions, there's very little evidence that they actually care about privacy. And so you might not expect that people actually respond to the ability to control that. The second part of the paper is going to ask, you know, how does the change in data affect firms' ability to sort of predict consumer behavior and generate advertising revenue? And there's not just the, there's more nuance here than just. There's more nuance here than just the data size gets reduced as a result of GDPR because the data that firms collect about consumers is sort of tracking them over time. And we'll talk about how different privacy controls of consumers sort of interact with the data that get generated in the data generating process that's observed by firms. And so to do this, we're going to study this empirically and we're going to use data that we get from a third-party intermediary in the online travel industry. So this firm sort of spans most of the online This firm sort of spans most of the online travel industry. They'll remain anonymous. They like, if you go to any of the major travel websites and sort of search for flights or hotels, they're usually in the background. And what they do is they collect data on consumer search histories and purchase histories. And they use this to try to predict purchase behavior and then use this prediction to sort of target advertising. And so we're going to study the impact that GDPR has on this firm. On this firm. Okay, are there any questions at this point about the paper or any questions about GDPR? All right, keep going. So to briefly talk about some related literature that I think is interesting, there's a literature in quantitative marketing and economics looking at privacy regulation. There's some papers looking at earlier regulations, a number of concurrent papers looking at GDPR as well. I think more interesting for this audience. I think more interesting for this audience is that there's a burgeoning literature in economics that sort of looks at the externalities associated with people's privacy decisions. So, you know, the main idea in this literature is really, if you think about when I share my information, this doesn't just give information to a firm about me, but also other consumers. And this impacts their ability to predict their behavior and how much they're willing to pay and so on and so forth for it. And so we're going to sort of identify a similar informational externality. Similar informational externality here. Okay, so before I get into the data, I want to step back for a second and really think about how does the data that firms observe get generated and how do different privacy regimes sort of impact this and how does that impact how we think about predicting consumer behavior. So the basic, at least in 2018, the main way that firms would track consumers online was by having cookies on their browsers, right? So a user would show up to a website. So, a user would show up to a website. There'd be a small file that's stored in the browser that sort of gives the consumer an identifier. And we view this as a panel identifier, right? So, you sort of have a consumer showing up across time, and this cookie is allowing the firm to sort of track this panel across time. And there's broadly two types of cookies. There's first-party cookies, which are sort of essential cookies. So like when you log into a website, allowing that firm, that website to maintain state across time is sort of an essential service. Is sort of an essential service and is not directly targeted, for instance, by GDPR. The second is third-party cookies, which are sort of those that are used by the intermediary we partner with and are directly targeted by GDPR, which allow a firm to sort of a third-party firm to sort of track what people are doing on different websites. And so, this is the types of cookies that GDPR enabled consumers to potentially opt out of. Okay. And how does privacy behavior before GDPR? Privacy behavior before GDPR impact the ability of a firm to collect this data. So, we talked about this a little bit in there was a talk a couple days ago discussing some of the pitfalls of sort of online experimentation is precisely that you don't necessarily have sort of consistent user identifiers over time. And this can come from a number of different ways. So people can delete their cookies. They can go in private browsing mode. In our setting, they can sort of turn on ad blockers, which is going to lead to continual regeneration of the cookie. Continued regeneration of the cookie. What you can think this really does is suppose there's some guy that's coming along that's doing a bunch of actions, making a bunch of travel searches. At some point in time, he deletes his cookie and now he shows up in the firm as sort of a second different identifier. So you sort of, it's the same guy, but the firm sort of sees them as two separate people. Okay. And the way we think about these existing privacy tools is really serving as some form of obfuscation where consumer's data is ending up in the firm's data. Consumer's data is ending up in the firm's database, but it's going to have a different identifier. Now, what changes when we move from this sort of pre-GDPR regime to GDPR, at least in our setting, is that when the consumer opts out, technically what ends up happening is that the firm is no longer allowed in any dimension to sort of collect this consumer data, even with an obfuscated identifier. And so, what happens with our intermediary is that when people opt out of data collection, they no longer see anything that sort of occurs. They no longer see anything that's sort of occurring on the website. And this substitution leads to a sort of different data generating process. And there's a, you know, I think it's best illustrated by this figure to really understand what's going on. Okay, so this is a super stylized example of consumers over time. And so there's three regimes. The first one I want you to focus on is the full visibility regime. Okay, so in this world, there's only four people. They can either show up in period one, two, or both. Either show up in period one, two, or both, and then either period, they can either purchase or not. Okay. And so, as you can see here, you know, if the firm could observe the ground truth, they would see that there's four people here. They each have distinct consumer histories, right? So here, this guy shows up in period one, purchases, doesn't show up in period two. Here, this guy only shows up in period two, but doesn't purchase, so on and so forth. Okay, now as an illustrative example, let's just suppose that only one of these guys is really privacy content. That only one of these guys is really privacy conscious. And so they're the only ones that sort of take any steps to sort of change their identifier for the firm. So after period one, consumer four now, let's say, deletes his cookies. Now he shows up to the firm as two guys. He shows up as four and five. And what happens now? So beyond the obvious fact that the firm now thinks it sees five people, you sort of see that the search histories of five and two are now pulled together, and four and one are now. And four and one are now pulled together, right? So, if the firm is relying exclusively on these search histories to predict behavior, you're now going to have different predictions potentially for consumer one, precisely because consumer four is sort of masquerading as consumer one. Whereas what happens in the GDPR world is now this guy just gets removed from the data completely. So the firm has less users, but you're sort of not having this pooling behavior. And so I want you. And so, I want you to keep this sort of example in mind when we're going to walk through some of the results later because we're going to sort of provide evidence that this is what we think is going on in terms of what happens after GDPR and how it impacts the ability of this firm to predict. Are there any questions about cookies or this stylized notion before I move on? Approximately, what fraction of people get deleted. People get deleted? So, here in this stylized example, there's one. We'll look at the data. We'll let it have a very concrete way of looking at this to some degree in the empirical results. Okay, gotcha. But this is sort of a, you know, I guess econ style stylized example trying to figure out, you know, what are the sort of possible mechanisms going on here. Okay, let me move on. So the So now let's turn to the data. The empirical strategy here of sort of identifying the effects of GDPR is pretty straightforward. So we're going to use a standard difference in differences design where the treatment group here is going to be the set of European Union, major European Union countries, the UK, France, Germany, Italy, Spain. The control set of countries is going to be countries that aren't directly impacted by GDPR, but which potentially have similar sort of travel and seasonal patterns. Similar sort of travel and seasonal patterns as these major European countries. And we're going to look at a tight window around GDPR, partially due to data limitations in terms of what we could get from the intermediary. And so there's also an additional benefit to this, which is that because we're in the travel space, we're really focusing on time periods when we think the travel trends are pretty similar. We're going to aggregate the sort of baseline data to an operating system, browser, website, country, and product level, and we're going to estimate your sort of standard. And we're going to estimate your sort of standard to a fixed effect difference in difference in specifications, as well as having some sort of a time-varying treatment. Okay? So what's the first thing we want to look at? The first question is, you know, did people actually use this opt-out feature from GDPR? And how can we get at this empirically without directly observing from the firm, you know, requests for opting out? And so at any given time, the number of observed users on the web on a website. Users on the web on a website J is going to be given by the number of true users of cookies or whatever minus the number of people that opted out. Okay, and so what we're going to have is that for the control group after GDPR, this is going to be zero, but for the treatment group, we're going to have that this is going to be weakly bigger than zero. And so we're going to suppose that there's parallel trends in the number of true users, and I'll show you evidence for this in the next couple slides, then any reduction in sort of Then, any reduction in sort of observed users or data that observed data that we see is going to give us some measure of what fraction of people opted out. Now, we can't technically say, you know, X percentage of people sort of opt out because of this sort of the fact that this identifier can potentially change over time, but we can answer the question of, you know, what fraction of the sort of data that a firm observes gets reduced after GDPR. Okay. And, you know, we find And we find a pretty stark effect where this is the aggregated to the weekly level. GDPR is enacted at the beginning of week 22. And we have a relatively flat pre-trend. We normalized to zero two weeks before because there's a couple of firms that we know sort of implemented a couple days before the deadline. And then after GDPR, you see this big drop that's sort of pretty persistent, which corresponds to roughly 12.5% reduction in the overall. Percent reduction in the overall data that the firm observes. So, this means that consumers are making use of this. You can ask some robustness questions, such as what if you use the different specification besides the ID. So we have robustness checks looking at synthetic control, which is a statistical seeks technique similar to difference in differences, where the control group is sort of synthetically generated to match the pre-period of the treatment group. We're going to find similar. Treatment group, we're going to find similar results. We specifically, you know, picked these sets of control countries because we thought they had very similar travel patterns. But if you weren't convinced by this, we additionally can control for these different travel patterns by using proxies for this from Google Trends and how often people search travel queries on Google. Control for this and you're going to find the same result. And so what have we established so far? So in terms of, you know, how does it, do people use this? Yes. It do people use this? Yes, it does reduce the amount of data that the firm sees by roughly 12.5%. Okay, now, what do we turn to? I think it's a little bit more interesting. Now we ask, you know, how does the composition of consumers change afterwards and what drives that? And so the measure that we use here is we basically look at the lifetime of a cookie. And so we base every week, we take the set of cookies that we observe, and then we ask what fraction of these guys still remain one week later. Still remain one week later, two weeks later, three weeks later, four weeks later. We put this through the same difference in differences specification. And for all of these, you find roughly the same thing, which is that, again, you sort of observe a stark increase at the onset of GAPR. And, you know, in terms of effect sizes, we're just looking at the persistence measure here. And it's roughly a 10% increase in this persistent that's robust across all these different K. And so when we And so, when we found this result, we were fascinated by it and wanted to understand what's going on here. And so, we have two possible explanations for this. So, the first is if you go back to that really simple illustrative example that I talked about before, you could have this sort of effect where, you know, if these, there's a lot of guys that are generating really short history so that their lifetime seems really short because they're opting out, because they're using ad blockers or deleting cookies. Blockers or deleting cookies, you might get that this increase in lifetime is just because these guys are the guys that are using GDPR, opt-out, and are getting removed from the data. The second is sort of a more classic effect of, you know, it just could be some selection where, you know, if I'm a big user of the website, maybe I'm more likely to consent to use this website. Okay. And so, how are we going to decompose these to really understand sort of how is the data that the firm gets getting changed? And we have two. And we have two, and I'll talk in detail about one in the next couple of slides, but we're going to exploit a particular kind of obfuscator here. So, our data provider told us that people that use, for instance, ad blockers when interacting with this firm, what will end up happening is that these guys will always just generate search issues of length one because basically what the ad blocker does is it targets the cookie that gets set by the firm and just always regenerates it every time that they do anything. And so, we're going to borrow. And so, we're going to borrow from sort of the zero inflation Poisson models to sort of argue that there is some evidence of these sort of single searcher inflation that gets changed after GDPR. So I'll talk about that on the next couple of slides. In the paper, we have additional evidence looking at heterogeneous treatment effects. But before I jump into this single searcher and inflation test, does anyone have any questions about anything we've done so far? Anything we've done so far? Okay. Cool. So what we do is, you know, we dig into the data of a few websites that we know sort of implemented GDPR properly and that we have sort of observed this reduction in number of users. And so the first thing we did was let's plot the change in probability maths, right? So we basically look at the, you can sort of view the data. The you can sort of view the data that this firm observes as basically generating some sort of count data, right? Where, you know, how many people show up one time, two times, three times, four times, whatever. And so we look at this distribution before GDPR, and then we look at it afterwards. And this is just differencing the mass at each count value, right? And so what we find is that, you know, there's this very stark drop in these guys that specifically have a single search. And for the rest of the number of searches, And for the rest of the number of searches, you see sort of a relatively weak increase, right? And so we wanted to understand this better. And so the main explanation we had for this was really that there's some inflation coming from these single searchers, which are these obfuscators that are showing up in the data as guys that only show up with one search. And so to test this a little bit more formally, you can, we basically, again, borrow from these standard. Again, borrow from these standard zero inflation Poisson models where the idea is really simple. There's two types of consumers: there's people that obfuscate, and then there's non-obfuscators that just have natural search distributions. So as a bit of notation, we denote by pi the probability that some guy that shows up to the website is an obfuscator. And these obfuscators, again, are always going to generate search histories of length one. So the resulting distribution that you're going to have on Distribution that you're going to have on counts is the probability that you see a guy with one search is going to be given by this pi, which is the probability that you're an obfuscator, plus one minus pi, so the probability you're not an obfuscator, times q, which is the distribution, the natural count distribution and the probability mass that people show up once. And then the probability that you see some guy K times is the probability that they're not an obfuscator times again, the natural. times again the natural count distribution here and the main idea of these of these poisson uh these zero inflation boisson models is that you're going to have you know that that the a standard poisson model won't be able to account for this because you sort of have this inflation of of single searchers and so we do a few things the first is we use the standard you know long test to sort of uh find that you know the single searcher model explains the data much better even once you do sort of a ic and bic corrections and we And we test two particular null hypotheses with this model. The first is that these estimated pi hats are, you know, the null is that they're equal to zero, right? So that there's basically no sort of inflation in the pre-period. And we're able to, you know, very convincingly reject this null hypothesis. So that in the pre-period, we're able to say that there are, you know, there is significant evidence that there is inflation in the data. The second thing is we want to make the claim that this. We want to make the claim that this fraction of people reduced afterwards, right? And so, this would be consistent with these obfuscator guys now moving to the you know using GDPR and no longer showing up in the data of the firm. And again, we're able to reject this and you find a reduction in the pie hats. And so, we do the standard, you know, we parametrized this Q as Poisson and negative binomial, and we basically find similar results. Similar results. And so we use this as evidence that what's possibly going on is really this privacy mean substitution hypothesis. So that illustrated figure before about how people will be using these sort of different privacy tools is going to lead to different data generation does seem to be what's going on. Okay. Now, a natural question after that is then we're going to look at how this affects the ability of the firm to really solve its classification problem. To really solve its classification problem. So, the classification problem here is a very standard binary classification problem, where in every given search, the firm is going to observe all the past history of the consumer and has to make a classification of is this guy a purchaser or is it, are they not a purchaser? And so the way that this firm does it, and so instead of, you know, so we're going to just evaluate the performance of this firm on answering this question, I think there is a interesting, you know, there's an interesting. Know there's an interesting thing which I think our paper sort of suggests, which is really thinking about how to best account for this sort of privacy selection in designing statistical methods to sort of predict behavior. But here we're just going to be looking at how this firm handles its prediction problem. And so we observe two things from the firm. We observe the output of its probabilistic classifier and the ground truth labels. So we observe the search and purchase history so we can actually construct what the ground truth is here. What the ground truth is here. And so, what we're going to do is we're going to evaluate the change in prediction error according to the standard error under the curve metric for these classification problems. And we have some discussion in the paper, which I won't talk about here about different prediction measures. But basically, this is the one that's used by the firm. And so we also use it here. And one of the very nice things is that we can actually use the same empirical strategy as we did before to look at this. We did before to look at this precisely because, you know, in this setting, so this firm operates on a bunch of different websites, but at least at the time when GDPR occurred, you know, there was a big issue where it's like firm two never wanted its data to be used to help firm one's prediction. So the only way that they trained their models was on the data for each of the individual websites. So the data only changes for the model gets trained on, only for the treatment group and not for the control. For the treatment group and not for the control group, here. And so, what we can do is we can use the same empirical strategy to try to understand how it impacted prediction error. And what we find is somewhat surprisingly that we end up being able to, we can reject the null that predictability is actually unchanged in the short run. So we document that the classifier does do some adjustment, but if anything, the AUC actually seems to get. Anything the AUC actually seems to get better, which we were very puzzled by originally. And yeah, the main mechanism we sort of think is potentially going on is sort of from the illustrative example before. And because of the sort of thing that we documented before, which is that, you know, this increase in sort of the average lifetime, so having longer consumer histories on average, sort of increases predictability. And the loss in data size decreases predictability. And data size decreases predictability. But we do also do like a sort of back-of-the-envelope calculation in the paper where we sort of take the causal estimates on this increase of trackability and loss and data size and just look cross-sectionally pre-GDPR, sort of how did these things impact AUC and so on. And find that you actually would think that this increase in trackability, given the magnitude that we were able to cause the identify, actually wins out relative to this loss in data science. To this loss in data size. So, what you have going on here is that this privacy regulation actually leads to a reduction in data size, but there is some nice selection that actually makes it easier for the firm to predict consumer behavior. Are there any questions so far before I move to the thing? Yeah. Yes. For ad blockers, the person has a tracking history of always that is always of length one. Issue of always that is always of length one. But I can imagine that there are other people who periodically delete cookies. And so their connecting length might be three or four, then they delete, and then they have another three or four, and then they delete. Is that going to be an issue for your analysis? So it shouldn't. So, I mean, if anything, this just means that we're potentially sort of underestimating some of these measures. I mean, so there was a challenge there, right? So basically, like a lawyer after at the end of the day is we don't, we don't end up doing a quantification of saying, oh, X percent of people are sort of. Of saying, oh, X percent of people are sort of using this thing, right? We really wanted to have some clean waves of just sort of understanding what is actually going on. And so we exploited this fact that we know that these single searchers guys will have a very distinct mark on the data, and we can understand, you know, how they will change pre and post to understand if this is the mechanism athletic. Now, I think the thing that you point out is very interesting as a, you know, again, the sort of thing I alluded to, which is thinking about, you know, actually predicting in this space and deploying statistical tools, you know, how do you. And deploying statistical tools, you know, how do you best take into account the sort of endogenous nature of the data from people's privacy decisions? So, again, that's not something we directly get at. I know a couple of papers, recent papers that are more in quantitative marketing that somewhat get at this issue, but I think it's sort of a fascinating problem that we don't directly interface with in the paper. So. Thank you. Are there any additional questions? This talk was intended. This talk was intended to be like 20 to 25 minutes, so feel free to chime in at any point. Okay, so the last thing we do in the paper is we look at how this changed advertising revenues in this setting, right? So I told you that the intermediary does prediction of consumer behavior and uses this to advertise to consumers a little bit. And the context here, though, is a bit different than some of the other. Is a bit different than some of the other settings where you know, really predicting individual behavior is super important. And the context is basically: you know, when you go on like a travel engine and you look up a particular flight, so here advertisers are bidding on consumers that own particular segments. So it's not that they see particular consumer histories and they're bidding for those, but they're bidding for the set of consumers that are sort of searching for a flight from New York City to LA. City to LA. And so this will sort of change how we think of the interpretation of some of the results. And one important detail to note here is that, you know, partially due to the, because of GDPR, like once these guys opt out, the intermediary is not allowed to show advertisements to them. So there is somewhat of a mechanical effect here where the fact that we're seeing this reduction in data is going to lead to a reduction in advertisements. So we find, you know, some So we find, you know, some there's a the firm uses the prediction to sort of slightly change how it places the different advertisements. And so we don't see the same sort of mechanical reduction in advertisements, but there is going to be partially this effect going on. And then the second is that, you know, payment here again is per click it and not per impression. And so we'll look at that's it, that's important to for some of the results. Okay, so what happens? So the first thing, so there's sort of three blocks. So the first thing we want to look Three blocks. So the first thing we want to look at is: you know, does it change? Does the number of total advertisers that actually get clicked sort of change? And the answer, again, sort of going with the thing we had before is, again, you're going to get a roughly similar effect size of nearly 13% in terms of a reduction in the number of advertisements that get clicked. Okay. The somewhat more surprising thing was we found pretty sizable point estimates for the reduction in. You know, the reduction in revenue, but for some reason there was some imprecision. So we're not able to statistically say that the revenue actually reduced GDPR after GDPR. And we partially attribute this to this finding that we found, which was that if you looked at the average bid, this actually increased. And so I'll show you the time series, like the treatment effects over time for this one. But we find that advertisers are paying more, are willing to pay more. Are paying more, are willing to pay more for advertising after GDPR. And again, it's important to think about to interpret this relative to this sort of keyword search advertising. So here it's not saying that the set of consumer histories afterwards are more valuable than the ones before. What it's saying is that like the average guy after GDPR is more valuable than the guy before, because here they're sort of bidding on what they think the average value of a consumer is because they're not targeting individual history. Consumer is because they're not targeting individual histories, they're sort of bidding on the average value of a guy from New York City to LA. And contrary to some of the other stuff that we find, you don't actually see that there is an immediate impact after GDPR, right? So we see, again, you see a relatively flat pre-trend. And then in the post-period, you sort of see a very gradual increase of this bid. And we were pretty puzzled. So was the intermediary belt. Puzzled, so was the intermediary about what actually could be driving this. And one explanation, so we don't claim in the paper to really have sort of nailed what's going on here, you could still see some similar selection effect, but we have one explanation, which we discuss a lot with the intermediary, which is that the sort of privacy mean substitution hypothesis here might also be playing a role in sort of how people are measuring, for instance, conversion. So if it is the case, So, if it is the case that these sort of obfuscators are more likely to opt out, what you could have happening is that the observed conversion rate for a lot of the firms sort of is mechanically lower because they're unable to sufficiently track these guys across time. So it could be that somebody sort of clicks on the ad and then, like, eventually at some point, you know, buys the thing, but in the middle, sort of their identifier gets lost. And so the firm would log this as, you know, oh, this guy didn't end up. Log this as you know, oh, this guy didn't end up converting, but in reality, they did. So, if it is the case that you're having a lot of substitution between these, and the guys that are showing up afterwards are more trackable, you could have some mechanical effect where the value of consumers is staying the same before and after, but now you're sort of seeing gradually higher conversion rates in terms of your observed data, particularly because these sort of guys are getting are dropping from the data and they would always generate sort of you know no conversions. So, your conversion rate. No conversions. So your conversion rate mechanically increases. But we don't claim to have sort of pinned this down. We have a number of possible explanations in the paper. Okay, so that's all that we do in the paper. So just to summarize, so I think that the third-party data access, we find a bunch of nuance, but at the end of the day, it is negatively affected. We do find this sort of surprising offset in revenue loss through higher prices, and a lot of our results sort of go back. Prices and a lot of our results sort of go back to this notion of externalities, where you know, the fact that my privacy behaviors could impact how much firms are willing to pay about other consumers and predict them. I think the most interesting thing for this audience is really, you know, I do think that this paper does provide some empirical evidence that, you know, the ability to sort of predict behavior here, you know, if you don't take into account the sort of endogenous privacy aspects, you know, it points to the fact that this has been. It points to the fact that this is potentially important in thinking about designing statistical tools for predicting behavior here and targeting advertising. Taking into account sort of the endogenous nature of this data seems to me like a very fruitful direction for future work. So that's all I have. I'm obviously happy to chat about this aspect of it or any aspect of the paper if anyone's interested. Actually, thank you, Guy. I have a couple. Um, I have a couple of questions, and maybe other people will too. Um, were you able to do a goodness of fit test on the zero-inflated Poisson or zero-inflated negative binomial? Yeah, so we have that, we have that in the paper. Um, it fits the data pretty pretty well, actually. Um, I don't remember all the all the specific details, but I do recall that. So, I mean, the first step, right, is to compare those between sort of the standard Poisson regression and negative binomial regression. We find that we're able to overwhelm. We find that we're able to overwhelmingly sort of reject that the standard Poisson and negative binomial regressions explain the data substantially better, even when you do the sort of standard adjustments. But yeah, we found that it's a really important thing. And even the intermediary was like these single searcher guys are always a problem for us in predicting. So like when you look, when you like plot prediction error, you see like weirdness on that single searcher guy because it's really tough for them to predict what's really going on there because they're all pulled together. What's really going on there because they're all pulled together. So, thank you. A second question: your data set comes from the travel industry, and I could imagine that people might not feel as privacy conscious regarding purchasing airplane tickets as they would be about other things. So, do you have any evidence that maybe how the GDPR affects industries by sectors? Industries by sectors. Yeah, so obviously, we're not able to talk about that in this paper because we're obviously constrained to one sector. I mean, there is evidence, you know, and again, it sort of depends on how you think of people's privacy preferences. So there's a recent paper that I think has a really compelling sort of argument for how people think about privacy. And so there's sort of an instrumental and a non-instrumental part, right? Where basically there's some intrinsic, you know, like I just care about my privacy. It doesn't sort of matter what the context is. And then the second. Sort of matter what the context is. And then the second is, you know, what's the instrumental value in terms of protecting my behavior? And so I think that, you know, part of the reason why we see slightly, you know, I thought these estimates were pretty big and I thought I was pretty surprised by some of the results is because people are very privacy conscious in these in these markets because they think that, you know, oh, what if the airlines are using this data to like price discriminate against me and they really have big privacy concerns about their data being used against them in potentially negative ways? Used against them in potentially negative ways. And so I would imagine that if you looked at another industry where the instrumental value of privacy is much lower, you wouldn't see a lot of the results that we think about here. But I think there's an important point there, right? Which is like, when you're thinking about the impact of how this privacy behavior sort of impacts your ability to predict, you do have to be thinking about what's the choice process of consumers in terms of actually protecting their privacy. Beyond the sort of mechanical, you know, like things that we're talking about. You know, like things that we're talking about here, which is these are different means of doing it, you know, the people have different motives to do it. And, you know, if you're in an industry where you don't think this is a problem, then it would be surprising to have to worry about it. But in travel, it is a big deal. So do you know if any sociologists have been doing surveys of people in Europe to see if they've exercised GDPR and why? So I don't, so let me. Don't so let me think. So, so what are the other evidence we have? So, there's a quantitative marketing paper that does a lot of similar stuff that we do that looks at Adobe data. And they roughly find like strikingly, like very similar results to what we do. And so they sort of span a bunch of a number of different industries. I haven't seen, so there's some people in CS that I know have done a few sort of micro studies looking at specific websites and having some surveys. And having some surveys. But I haven't seen a good, qualitative study of interviewing people, asking them why they opted out, if they use it, if they're aware of it. I've seen some of these studies for general privacy behaviors about, you know, do you delete your cookies? Do you use ad blockers and stuff like that? But at least I'm not aware of specific ones relating to GDPR. If anybody knows, I obviously be happy to take the reference and take a look at it. I think it'd be interesting. And take a look at it. I think it would be interesting. Thank you so much. Anyone else have comments or questions? I have a quick question, actually. Yes. Can I jump in? Okay. Hi. And thank you for your presentation. It was very interesting. I'm just curious about the parallel trend assumption. Trend assumption. So, if you guys have, I don't know, tested for it or not? Yeah, so I mean, obviously, parallel trends is pretty hard to formally test. I mean, the best you can really do is, you know, we have time-varying treatment effects, and you basically find zeros for most of our outcome variables in the pre-period. We also are robust to a lot of, we use synthetic control precisely because of this, so sort of has a have a robust robust. This sort of has a have a robustness because they're sort of pre-trends are mechanically supposed to be met, and we find roughly the same results. Um, so yeah, I mean, the one, and the one, the one thing that you might be worried about as well, right, is that, oh, like it could be because of travel that, you know, maybe we looked at, you know, it just happens to be that like before May 25th, like the travel pre-trends are really close, but then afterwards, once it's somewhere, there's some idiosyncrasies across countries delayed to different travel trends. Countries relate to different travel trends, but you know, once we, you know, the specifications that we use, sort of including Google trends to control for this, sort of have the same results. So, yeah. Okay. That's that's that's clear. Thank you. Are you able to look at data from the previous year to see if there are different trends in travel choices between the control and treatment countries? And treatment countries. So, this is actually a somewhat funny point. So, that was the first thing we wanted to do, but then it turned out-I mean, we started doing this in, I think it was 2019. We started looking at this data. There is a stipulation as a part of the firm side of GDPR where it's like the firm specifically wanted to delete data that was longer than two years in the past, and or I think it was like a year. Anyway, the point was that the firm had deleted that data because of GDPR, so we actually couldn't use. GDPR. So we actually couldn't use that data, which would have been a very nice, you know, additional robustness check of like, oh, you know, potentially using 2019 data as a possible control. One of the papers that I mentioned that uses Adobe data does take that route. And they find, again, sort of, they find that similar, similar results. So I didn't quite understand that. Why were they deleting? I did not think that GDPR were. I did not think that GDPR required you to delete old data that nobody was challenging. So, according to them, there, I mean, we, you know, I don't claim to understand all the different nuances on the firm side that like this would move them between different classes in terms of like the stipulation. Like, there's a bunch of different firm side regulations. And by having, by only retaining data up to a certain period, they claim that they didn't have to comply to like a more stringent part of the regulation. And so that's why they did it. They why they did it. But again, sort of there's a number of sort of firm-side things going on here. We really just focus on this consumer aspect, but there's like a lot of nuances to how firms have to change their data retention and collection policies. Thank you. There are some interesting statistical questions. If a man in France wakes up one morning and decides that he doesn't want his demographic That he doesn't want his demographic information to be included as part of the census, then he can opt out. And in principle, France's Census Bureau has to recalculate their tables. I'm sure that's not how it is done in practice. Do you know what is done in this specific context? So, there's two ways you can do it. So, there's different, so I didn't go into a lot of the nuances of GDPR. So, there's a few different Nuances of GDPR. So there's a few different aspects, right? So the one that we focus on is like you can actively consent to, you know, having the firm collect your data going forward. You can specifically request for them to delete all traces of anything linked to you going back to the past. At least according to this firm, not many people were actually using that. But my, you know, you would, they would have to retrain their models and stuff like that, right? And here it's less of an issue because these guys. Less of an issue because these guys are, you know, again, because of you know the industry, they're always retraining their model, so it's not like they have some sort of stale model that's sort of using a bunch of data. So if some guy would have a deletion request, they would delete the entry from the model or from the data, and then by the next day, his data wouldn't be showing up in the model, basically. But it is interesting. I actually don't know what institutions that like the census that sort of have a lot bigger sort of stale statistics and then somebody asks them to delete their. Asks them to delete their data. And then, you know, I would imagine that the census does not actively recompute all the tables and redistribute them every time someone does that. So I'm not actually sure what the practice is there. But for here, it's not as big of an issue. So I understand. Thank you.