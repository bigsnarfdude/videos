But yeah, so today in the first half of the talk, I would like to tell you about actually just probably the main idea and the main step in the proof of in the recent proof of the kind Kali conjecture. And then we'll see how to use these ideas in other settings, including sunflowers in the system without the VC dimension. Okay, so let me first start with the setup. So for our setup, we have any finite set X and a collection H of subsets of X. And we'll assume that this all of the sets. And we'll assume that this all of the sets in this collection have size at most some parameter L. And so we'll call this property that the family H is L bounded. And we'll also denote by XQ a Q random subset of X. And usually this can be sort of in either way. So it's a random subset where each element is sampled with probability Q independently. Or you can think of it as a uniformly random subset of density exactly Q. I think in fact for this talk, the second notion. In fact, for this talk, the second notion is actually slightly more convenient to keep in mind. Okay, so this theorem is the formulation of the Kan-Kalai conjecture that was recently obtained in joint work with Jinyong Park. And so let me parse this statement for you. So we have any collection of set H inside a subset of X that is L-bounded. And we assume this nice combinatorial property. A nice combinatorial property star. So, this property says that no matter how you choose a collection H prime, a subset of X with the following property that any subset H in our original collection must contain some H prime as a subset. Then such a family H prime needs to have a large cost. And the cost here is just the sum of P to the size of the set as the sets range. The set as the sets range over the collection H prime, and for a slash just means at least one half. Okay, so we call this property that H is being not P small. And this is a, so being not P small is a nice combinatorial property. We'll see a little bit more later why that is the case. But whenever this assumption on the family H is satisfied, then we can conclude that if we sample a random subset of X of density C times P times log L. C times P times log L. So C is some absolute constant that doesn't depend on any other parameter in this theorem. So such a random set must contain at least some set H in the collection curly H with high probability. Okay, so this is the statement of the essentially equivalent to the Kank-Kalai conjecture. Okay, so just for convenience later in the next slide, I will call out. next slide i will i will call out names for some of the quantities or definite properties that already appear in this theorem statement so first i will say that a collection of sets h prime covers h or forms a cover for h if any set in h contains some h prime in h prime as a subset okay so this is the picture uh of what a cover should look like so this smaller set smaller purple set form a cover for the bigger blue sets bigger blue sets then i will say that h is p small if there exists a cover for h h prime that have a small cost and again the cost is just the sum of p to the size of the set and we say that it's small if it's less than one half so the nice property that we assume in a theorem is the complement of this property so we assume that h is not p small and then we have some nice conclusion so it turns out that um if we relax the notion of a cover in the net definition of Of a cover in the next definition of peace more to a certain fractional relaxation, I won't say it precisely now, then you can have a fractional relaxation of peace more. We call it fractionally piecemo. And being not fractionally peacemall, which is strictly more restrictive than being not peacemall, is actually equivalent to a property that we will see later of being peacefret. So all of the results that I will say today will have a corresponding fractional version where you A fractional version where you make the stronger assumption that the family H is not fractionally piecemo. And but in fact, for most of the thing that we show today, we can just afford to work directly with the integral version. That is a more general result. Okay, so I won't say a lot more about the interesting background behind the cancer conjecture, but let me just mention why it is useful. So if we find the largest parameter P for which the cell system H is P small. Which the set system H is P small, then such a P is called the expectation threshold. And you can check that this theorem over here is equivalent to just saying that the true threshold for containing some set in H is at most like some logarithmic factor larger than the expectation threshold. And it turns out that it's useful in many applications because it's often very easy to estimate or determine the order of the expectation threshold. But I won't say more about that. Later, we'll just go into More about that later, we'll just go into the proof and see the main idea there. Okay, so before it's a question, okay. So before we go into the proof, let me just mention in the passing that about the same time that we put up a work on the Kankalai conjecture, with Jinyang, we also put up another work on telecrans conjecture. In fact, it can be in some sense thought of, but not strictly speaking, a much more general version of the kind. A much more general version of the Kang Kalai conjecture in a general weighted setup. So, in fact, the proof of Tala Kang conjecture is involved a lot more interesting idea and it's much more challenging, but somehow it went a lot more unnoticed. So, in fact, even just working with the fractional version of Talagrand's conjecture, that is, if we work with the stronger assumption that the family is not fractionally p-small, that is the place that I was able to find a key idea that I'll introduce to you shortly of the minimum fragment, which eventually is the key. Which eventually is the key component in the proof of the Kainkali conjecture. But let me just very quickly mention what this conjecture is about. So it's under exactly the same setup, we assume this nice combinatorial property on the set system H. Then no matter how you choose general weights, no matter how you choose a weight to assign weights on the set H, so no matter what function WH you have, so that it's supported on H and it takes non-negative value. And if you assume that the total weight of each set H in the family is Of each set H in the family is at least one, then a random set X P is always able to capture at least an absolute constant fraction of the weight from some set H in H. So let's know that it's somewhat surprising because the expectation of each of those weights is about order P, which can be very small. But if you do this optimization over all of the sets in the family H, and if you only assume that H has this nice combinatorial property, it is sufficient to get. It is sufficient to get to show that a random set of density p is actually able to capture at least a constant fraction of the weight from some set. Okay, so we won't see this again, so I won't tell on this a lot more. Let me now tell you about the proof of the first theorem, the Kankalai conjecture. And in particular, I will highlight the following main lemma. This is a key step in the proof. So, what does this lemma say? It says that if we have any test system H, that is. Testive sum H that is tell about it. And if we have any, and if we're given any subset W of X, so think about W as the random set of density roughly some constant times P, then there is a way to assign to each set H in our original collection a subset H prime with the following properties. So first, H prime is a subset of H. Second, H prime has the following nice properties. is has the following nice property whenever you look at h prime together with w so if you look at the union they must together contain some set h prime prime from our original collection h so this is the picture that you have in mind so h prime is a fragment and i call this property being a fragment so h prime here is a fragment because if we look at h prime and w together then it contains this set h prime prime from the original collection h and the And the third key property is that if we look at the cost, so just the sum of p to the size of the set, but we look at the cost of the collection of fragments h prime for which the size of h prime is too large. And here, too large just means exceeds 0.9 times l, and l is the original bound on the size of the set in h. Then this cost is very small on average, and the average here is taking. And the average here is taken over W sample according to a random set with density C times P. Okay, so let's note that this mapping of H to a fragment H prime implicitly depends on this choice W. Okay, but I will sometimes suppress this notation just to make it cleaner. Any question about the statement of this lemma? Okay, so if not, then, okay, I'll just very quickly mention. I'll just very quickly mention, but not go through this in any detail, that if you can obtain the first theorem by just iterating this lemma. So just think about a random set of density c times P times log L as roughly a union of log L samples of a random set of density C times P, and then apply the lemma with each of these log L random sets. And in every time that you apply the lemma, you can replace each set with a much smaller fragment. It's not always the case. There will always be some bad sets with very large fragments, but then Set with very large fragments, but then the main lemma guarantees that they can be covered with the cover having a very small cast. So you just ignore them in this step after this step, and then iterate with the smaller fragments as the sets in the next iteration. Okay, so I won't say a lot more about this. Let me tell you how you can prove the main lemma. And the key idea here will be what we take further later on. Okay, so the proof of the lemma, It the proof of the lemma, I will first tell you the key definition. It is proof that's of the minimum fragment. In fact, in fact, it's a very simple definition. So, roughly, given any set W and any set H from the collection H, the minimum fragment T between H and W is just the smallest subset of H, for which you can add that subset to W and guarantee that the union of W and T contains some set, some other set H prime prime from the original collection H. prime from the original collection H. Okay, so in other words, we just given W and H, let's look at the union of H and W. And in this union, let's make a choice of a set H hat so that H hat is from our collection H, H hat is contained in this union, and finally, this left over of H hat minus W has minimum size. Okay, so in that case, we'll let T be exactly this left over H hat minus W, call it the minimum fraction. H hat minus W, call it the minimum fragment. And another set that will play a key role in the argument is the set V, that is the union of W and T. Okay, so I just made a definition why this is useful. It turns out that the key property that we will use about this minimum fragment T is the following. It says that if we forget, so let's note that in this definition here, in order to define T, I go through both W and H, and from that I recover H. And from that, I recover H hat. So all of this information depends on both the sets W and H. But the point is that even if I erase W and H from this picture and leave only the set V, in some sense, I can still recover the set T with a small cost. Okay, so the idea is that if we look at only at Z, no matter how we choose a set H prime prime from the collection H such that it's a subset of Z, there may be many choices for H prime prime. many choices for H prime prime, but for all of these choices, T is always guaranteed to be a subset of that set H prime prime. Okay, so from this picture, we know that T is always a subset of H hat, but somehow, when we make the definition this way, we can actually guarantee a lot more. We can guarantee that no matter what other set from the collection H that's containing V, that also must contain T. So we will see in a bit why this is useful. But let me just. why this is useful. But let me just give you a very quick proof of this key property. Well, if there is some set H prime prime inside Z that doesn't contain entirely T, then you can actually just check that that H prime prime minus W will be something that gives you a strictly smaller fragment than what H hat gives. And that's a contradiction to the minimality that we made in the definition of T. Okay, so now So now let's go back to the main lemma. We have to make a choice of a fragment for each that H in our collection. And the choice of the fragment is exactly just this minimum fragment T. Okay, so the mapping psi will assign to H the fragment T that arises from H and W. So you can check trivially that all of the properties of the fragment are satisfied. So the only thing that we need to prove now is to upper bound this cost of This cost of the cover of the fragments that have a large size. And I won't, let's not, I won't say this. Okay, so this is actually just equivalent to showing the following bound. So you want to give an upper bound to a weighted sum with some of a large t, so t at least 0.9 times L, the weight is p to the t. And then what we want to upper bound is the number of pairs w and t for which w has density c times p. W has density C times P, T has size exactly T, and T arises as a minimum fragment of H and W for some choice of H in our original collection H. Okay, so this is what we want to upper bound. Okay, so let's see how we can upper bound the number of choices for this pair. Turns out that the key property will be useful here. The idea is that the first trivial way that we can give a upper bound here is just to give a bound on W. is just to give a bound on w and on t separately that's the trivial bound and you can roughly check that what we want to do is to meet this trivial bound so the key property tell us that actually we don't need to know exactly both w and t in order to recover t if we just specify the union z this takes less information in some sense t can be very efficiently specified inside the set z just make an arbitrary choice of a set h2 arbitrary choice of a set H tilde of Z that comes from the collection H and that is a subset of Z. Okay, so this choice only needs to depend on Z. It doesn't depend on W, H, or any other thing. But the key property tell us that this T is always a subset of H tilde of Z. So we can specify T as a subset of this purple guy. And let's note that this is a lot more efficient than specifying T as a subset of V of 5 little T because Of size little t, because the size of z is typically much larger than the size of h2 dot c. Okay, so let's see what this gives. So they recall that our goal is to bound the number of pairs, w and t. And now instead, we will go through z and t. And let's know that we can recover w just by taking z minus t. But now we also, the only property that we will require is that, well, we know that the size of z is exactly cpx plus t, and we want. Cpx plus T, and we want to require that T is a subset of H tilde Z. Because it turns out that now you can bound these two, about the number of these pairs trivially. So this is the number of choices for Z. And given Z, we also fix H tilde of V. So the number of choices for T is at most 2 to the size of H tilde, which is at most 2 to the L. Okay, so from here, everything is just some numerical calculation, and you can check that they fit in together to prove that the desired Together to prove that the desire value you want to show is very small. Okay, so is there any question about the proof of this lemma? I think the key thing to take away from here just essentially these pictures. Okay, so if not, I will progress to talk about sunflowers. So before I talk about sunflower, let me mention this property of being peace red. So this is equivalent. Being peacefully, so this is equivalent to the stronger property of being not fractionally peaceful. Um, and uh, and somehow this one just comes up more naturally when we are discussing sunflowers or we're working in the setup of sunflower. So let me mention this property. So we say that a family H is p-spread if there exists some probability measure lambda supported on H with the following property that for any subset S of X, the probability measure lambda. The probability measure lambda of all of the sets H that contains F have to be at most roughly P to the size of S. Okay, so you can verify that if you take the fractional relaxation of the notion of being P small, then being not fractionally P small by duality is actually equivalent to being P spread. And so this is a stronger assumption. This implies the property of being not P small. Okay. Okay, and just a convenient remark. So, well, we don't always have to work with a general probability measure lambda here. So, if I'm allowed to consider H as a multi-hypergraph, so if each fact can be repeated multiple times, then I can just assume that this Lambda is just the uniform measure over the family H, over this multi-family A. And yes, I remarked, so P spread, even though it's a stronger assumption, it naturally appears from It naturally appears, for example, in the setting of sunflowers. So, this is just to introduce this to the sunflower, just a family of sets for which the pairwise intersection is equal to the common intersection. And why P-spread naturally arises in this setting is because, well, if a family H is not P-spread, that is exactly the same as saying that there is some dense spot, so some choice of S, for which there are many sets of H that contains S. And in that case, just move S into the core of the sunflower, and then induct or recurs. Flower and then induct or recurs on the sets in the family that contains S. Okay, so we'll see this a little bit more precisely later. So, right, so about the same time that we worked on the Kankali or Talakran's conjecture, I also realized that the minimum fragment is not only useful for working in the integral setup. So, in fact, you can use this minimum fragment to offer new insights, even in settings where you can naturally afford to work with the more restrictive fractional setting. Restrictive fractional setting. Okay, so in particular, we can work, we can give much simplified proof. And we'll see in the next two lines, we can give self-contained proof of sunflower very quickly. And also, we can give a new result about sunflower incest system. So yes, I'll say later I can also obtain a result on sunflower incessant system with about it VC dimension. But in fact, another good example here is that of the fractional version of telecom conjecture that I don't know how to obtain without using a minimum fragment. Okay, so let's just. Okay, so let's just perhaps briefly see what happens in the case of sunflower. So both of the corollaries on this slide, the first one is a corollary of the main lemma, and this corollary is a corollary of the first theorem or the Kan-Kali conjecture. But when you can naturally afford to work with this stronger assumption of being p-thread, well, you can actually, you don't have to go through the main lemma or the conjecture. You can write direct proof. It actually becomes a little bit easier and more intuitive. becomes a little bit easier and more intuitive. So that's essentially the goal of these arguments here. But I won't go through it in detail. But roughly speaking, if you have the additional assumption of being P spread, then in the main lemma, you can afford a somewhat cleaner conclusion that almost all the sets in H produce a fragment of a small size. So before in the main lemma, the main conclusion is that, well, all of the sets with a large fragment can be covered by something with a Fragments can be covered by something with a small cost that is a little bit clumsy. When you assume an HTTP spread, you can just say that almost all of the sets produce a very small fragment. So the fragment decrease by some multiplicative factor. In fact, like if you have this, then the iteration becomes much more easy. And so you can go directly from here in a much more intuitive way to the conclusion that if H is P spread, then a random set with density C times P times log L will contain H with high probability. Contain H with high probability. Okay, so let's note that this is the corollary of the Kankalai conjecture because while being P spread implies that H is being not P small. Okay, so I won't, but okay, because of time, I won't tell you how to do this, but roughly you do the same thing as you did before, but just that it become a little bit simpler. Okay, so let me say how to go from there to the following bound on set systems lacking sunflower. So this is, I think, so the current current. is uh i think still the current the current best asymptotic bound that's known that's obtained in this paper by bao chulucha and wonky but uh the original prexiver was by uh slovet wu and zhang and and then there's some uh improvement in the middle by by as well so we'll just induct on the uniformity of the set system so if the set system is not spread then as i said before you can identify some dense spot s for which there are many sets in h that contain the set s Manifest in H that contain the set S. In that case, just move F to the core and then work with the sets in H that contains S and then apply the inductive hypothesis to that set system. So we can then assume that the family we work with is P spread, well, P is the choice of the parameter. The colory will imply that a random set with this density will contain something from the family with at least reasonable with probability at least one half. One half. So, what we do now is we take a random partition of the universe of all of the elements in the set system and take a random partition into some number of parts. So, in this case, each of the parts will have the same distribution as the random set, density c times b times log L. So, you can show that in expected value, at least with positive probability, you can find our different parts that each contain some set from the family H. family H. But this is a partition, so of course all of these R sets have to be this joint and this is exactly the R petals that you want to find for your sunflower. Okay so I guess I'm a little bit short on time so let me proceed to tell you about this new result on sunflower in census sums of boundary VC dimension. Okay so it's exactly the same setting as before but if we have the additional assumption on the VC dimension then we can show this much better bound. So we can show Show this much better bound. So we can show that the size of the family is at most some constant exponential, but only depends on V, the VC dimension, times R times log star of L instead of log L, and then to the power L. Okay, so this is a small improvement over a previous result of Fox Park and Soup, where they showed about this form. But this proof is also very nice, but it is completely different. And perhaps the point here is that perhaps this new proof may offer some. Perhaps this new proof may offer some other insight. So as before, to prove this theorem, we proceed first through this proposition. So in this case, we have a family H that is L bounded, bounded with C dimension, and we assume that it is not P small. In fact, in order to prove this theorem, you can afford to assume here that it is not fractionally peacemall or P spread. But well, the proof that I will show you will also work for this under this more general setup of being not P small. Okay, then we want to say that. Okay, then we want to say that a random set now with density P times log star L rough B will contain some set H from the family H. And this is essentially the playing the role of the Kankalai conjecture. And then to prove this proposition, as before, we have this lemma, playing the role of the main lemma. Now it is a tiny bit more complicated. So let me parse it for you. So we have the same assumption if the bow is L-bounded, VC dimension F D, and it is not P small. Is not t small. Then we want to show that for each set H, we can actually make a choice of two smaller subsets. So, first, we can make a choice of a smaller subset H bar that is made through this mapping C. And furthermore, inside H bar, we can choose a set H prime that is the mapping sign, and H prime will play the role of the fragment. Okay, so what we want is that, no, if we take H prime union with W, then it has to contain some set H prime prime from the original collection. prime prime from the original collection h and the final property is that if we look at the collection of all of the h for which it produces a fragment h prime that has size too large and now too large is just merely log l then if we sum the total cost of the h bar corresponding to those bad h then this cost will be small on average over w where we sample Average over W, where we sample W according to a random set of density C tilde times P. Okay, so it's roughly the same picture as before, but now we have this slightly more annoying intermediate set that we will keep track of. So we will use H bar inside the cover, but we'll use H prime as the fragment. That's the small difference here. Okay, so the proof is not very different from before. We'll use the same key property. key property so let's recall this picture this this picture is what uh that that is what like we want to remember from here so we have wh from there we define a minimum fragment t z is the union of w and the minimum fragment so as before the fragment h prime is or the mapping sign is actually just exactly this minimum fragment t but uh h bar uh so from given z we make a choice h tilde of z exactly as before and now the mapping phi will Now, the mapping phi will be defined as the intersection of H tilde of Z and H. So that's this red set here. So from the key property, you can easily verify that H is a superset of H bar, it's a superset of H prime, and furthermore, H prime is a fragment. Okay, so that's just follows from definition. So now the only thing, the only non-trivial step is to build the cost of the collection of cover that we have and That we have, and it now becomes a little bit more complicated. So, perhaps I don't have time to go over the algebra, but roughly the idea is just well, valuing the cost of this cover is just the same as before, as before, valuing some weighted sum of the number of pairs W and H bar, for which H bar arises as an image of the mapping phi over the set H, for which the minimum fragment psi have size too large, have size at least log L. size too large, a size at least log L. And then you can dominate this count by going through again Z, T, and H bar. So we always go through Z, that's the main idea here. But once we put it in this setup of counting Z, T, and H bar, then things become simple as before. So we just count these three guys separately. So this is the number of choices for Z. Once we are given Z, well, in fact, we will then count the in fact we will we will then count the number of choices for h bar and the key property that we use now is the property of we having bounded vc dimension so because we have bounded vc dimension the number of different intersection patterns of some set in h on this fixed set h tilde of z is at most polynomial so at most l to the d and from there we can specify uh this uh this fragment t inside it and we can just combine all of these bounds and go through some algebra and show that this expected cost is very small This expected cost is very small. Okay, so me not turn on the calculation. What we should remember is just this picture, and then we can essentially just work out the rest. Okay, but once you have this lemma, as before, like just iterated this lemma, we can apply, we can obtain this proposition where this random set of density p times log star contains entirely some set in h. And then from the proposition, exactly the same induction as in the case of sunflower will allow us to prove our original theorem, the result that we want. The result that we want on sunflowers in the system of a bit with the dimension. Okay, so I think that's all. Thank you. Now then, let's thank Huiga again. Thank you. And we'll have a five-minute break for the last taxpayer. Some of the texture is very interesting. 