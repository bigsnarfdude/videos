Yeah, so I will probably start this second part by ending the first part of this Dubai for this manifold. So we will give the next definition about the intersection form, because also there are also people asked about this Gauss-Manning connection. So maybe it's better to mention. So, the intersection form usually denoted by the blank bracket of a Fermi's manifold of the Dubai Frobins manifold for Bines manifold is a bilinear form. Defined on the cotangent space. So on p star m defined by so omega one, omega two equals the contraction with the Euler vector field omega one. So omega 1 times omega 2. So at each point P. So here, in the definition of this manifold, we have multiplication on the tangent spaces. But because we have the invariant flat metric, we can use this metric to give a canonical. This metric to give a canonical identification between the tangent space and the cotangent space. So then we can also define multiplication between differential forms. And we consider this omega 1 multiplication with omega 2 and contract with the Euler vector field, we get a bilinear form. And this bilinear form is called the intersection form of the Bromino-Ninis manifold. Of the Broadmin for this manifold. So by if we consider the local coordinates, so it's just dv alpha, dv beta, it'll be c alpha beta gamma dv gamma. So here v1, 2, vn are still the flat coordinates. And we always use our invariant flat metric to Flat metric to lower or raise the indices. So C upper alpha beta gamma will be eta alpha rho C rho gamma beta because we already defined one up and two downs and here we have two ups and one down. So so this gives locally the multiplication between differential forms and it denotes G alpha beta. it denotes G alpha beta will be D V alpha D V beta. So it's actually the so-called contravari given by this intersection form. And so we can do the computation if we use definition. This is just E gamma E D V gamma. And here we put the multiplication between the two. So C alpha between the two so c alpha c gamma alpha beta dv gamma and now we do the contraction it's very simple it just gives us e gamma c gamma alpha beta so this gives a contravariant metric on the Forebrines manifold and we have the definition it says the locus Sigma in M defined by where this G upper alpha data that degenerate will be called the discriminant locus. So define sigma equals point T where determinant beta equals Equals zero. So this locus is called the discriminant locus of n. So we can define g lower alpha beta would be the g the inverse. Of this GR beta on M, get rid of this discrete locus. So, and we know that on M, take off sigma, this G alpha beta is a metric. And the next lemma says this metric is also flat. So I will not give the details of this proof. So the proof is in this case, you can, the easiest ways you can do just directly by computing the curvature tensor. Curvature tensor. So proof is by computing the curvature tensor, which is identically zero, but sorry, I will omit the details. So the Levitivita connection associated to this G alpha beta, or you can also consider, so this is a covariant metric. You can also consider the concept. Covariant metric. You can also consider the original countervariant metric in upper alpha beta. In any case, the flat coordinates associated to this intersection form is called the period of the flat coordinates, we call the period of the Fermi's manifold. And the connection given by this metric, G alpha beta, will be called. G alpha beta will be called a Gauss-Manny connection. Okay, so yeah, but the more details, if we have time, we will explain later more details about Gauss-Manny connection, but at least I will write the theories. So flat coordinates. Oh, the intersection form denoted by usually by P1. By usually by P1 to Pn are called periods or period functions of the province manifold. Let's look at some examples. So, the first example when f equals over 6, we bound to power 3. And in this case, the period function will be p equals. will be p equals square root of v1. And the next example in the case of quantum coherence of P1, I mean GW invariance of P1. In this case, there will be two periods and P1 equals V2 in this case and P2 equals V2 minus 2 log. 2 log V1 plus V1 square minus 4 V2. Yeah, indeed, the questions about the globalness of the Fervis manifold raised by Sasha is very important when we consider period functions. So, okay, now let's go to the next. Now, let's go to the next part. So, now we will go to Samatonian PDEs of hydrodynamic type and their perturbations. Yeah. Yes, it's nice to make the number match, but I can also, yes, I can also give the example two. So the example two is indeed nice. The answer turns out to be simple. So if you consider equals e to peak plus v1, if you consider the roots of this equals Of this equation, it has three roots, but they satisfy the by the data theorem satisfies some the sum of them equals zero. So essentially two solutions, the two solutions are precisely the periods of this second example. Okay, so so I actually, yeah. Yeah. What integral? Period integrals. Yeah, yes, yes. It is essentially also, it can be realized by period integral. The period integral, yes. So one way is that, so roughly speaking, so So, roughly speaking, so you can realize this period by doing a Laplace transform of the Duborbin flash section of Duborin connection. So, from that, in that formula, from the Laplace transform, you already get an integral. So, in general, of course, I mean, so I mean, this is in general, but I mean, this is in general, but in concrete examples, in concrete examples, it's really can be realized as some differential form integrated on some cycles. Either the cycle is a family or the differential form has some family. So in concrete example, but in general, I mean, you can use Laplace transform. So, right, so now let's move to Right, so now let's move to another. Yeah. Yes, you mean the computation. So it actually corresponds to the same as the locus in singularity theory. Yes. Yes, so it's uh um yeah, because in this study of singularities, there's the discriminant there, there's also the Maxwell stratum. So, yeah, I think it's when it has the roots has the coincidence. Exactly, please. Yes, yes, yes, yes. It is based I think. Yes. Uh, so CD So, whenever the manifold is semi-simple or not semi-simple, you can always define this discriminant locus. Yes, yes. There is also this common location. Yes, yes, yes. But when it's semi-simple, there is another stratum called. simple there is another stratum called maximum stratum is when they there's also equal uh values for the critical values that is when it's it is semi-simple it's called the um semi-simple coalescence points so there are several interesting locuses in in this in different province manifold okay yeah sorry so so if if yeah maybe we or if more questions Or, if more questions, or we can, yeah, let's move to the next topic. So, of course, it will look like the two topics look slightly different, but actually, it's precisely the same topic. So, we will consider PDEs of hydrodynamic type. Also called PDEs of the Broadway time. So these are, in some sense, at least it looks like very simple partial differential equations, but of course, it's also very difficult. So, we will consider again n-dimensional complex manifold, and u1 to un are coordinates on this manifold, and we consider PDEs of this form. So, here a alpha beta, they are given functions, given smooth functions. Given smooth functions on M. Yeah, and we still use the Einstein summation convention for repeated grid indices with one up and one down. So here is the auto summation. And so these are equations. This type of partial differential equations will be called PDEs of hydrodynamic type. So there's also a more general form of the equation. I sometimes use u alpha sub p as the partial derivatives. So the generalization of this equation will allow more derivatives with respect to x. So usually we call x space and we call t time. So we can also allow We can also allow more derivatives in x. So then the kind of general form of this equation will become u beta x plus epsilon a1 beta gamma alpha u u beta x u gamma x all possible derivatives. But we can organize in the way that we use epsilon to track. We use epsilon to track the number of derivatives. For example, here in epsilon one, you have two derivatives, one x, one x, and here two derivatives. Yeah, xx. And then plus more terms. So this type of more general equations is called the Bohrman junk number four. Junk normal form of PDEs. So we can write it here. So this type of equations are called Boaring John normal form. Of EDEs. So these are generalized, these are perturbations of the EDEs of hydrodynamic pipe. Let's see some examples. Epsilon is a form of a variable. It's a parameter, formal parameter. Yeah. Yeah. Okay, so let's see example one A is U T equals U X plus U X X X. So this equation is the famous Potivish-Devray equation. Discovered by Frederick de Vries in 1895. So now usually for short called KDV equation. And it actually independent more or less at the same time as slightly before by Businisk. So, they discovered this equation in the study of water waves. So, shallow water waves, and can be obtained from the Euler equation by looking at the waves, the free boundary problem. And so, from PDV equation, it is an equation of the Barbing Chung's normal form. And yeah. And yeah, from this type of equation, you can always take epsilon goes to zero, and you get the PDs of the Brogno-Wickoff type. So in this literature, because it's about waves, this limit will be called dispersionist limit, but depending on literature, I mean the different occasions, it can also be named other limit. So another example. So, another example, this equation is about shallow water waves. Another important equation in the Bowman-John's normal form is this one. So, I use the sub-index 2G plus one. index 2g plus 1 to represent the 2g plus 1 derivative with respect to x. So uk will be the x to the power k of u. And here b b g b k are Bernoulli numbers. So b k is the kth bernoulli number. Yeah, so here we only use the even lines between only use the even lines B2G and this equation is called the intermittent long wave equation so so intermittent long wave yeah it also discovered in the study of water waves and the second example The second example is Bousinetski equation, the precise Bousinesk equation. I mean, Bousinik also discovered this equation and also this equation, another equation. So the coefficient, for example, this minus two-thirds, and so they are not very important coefficients if it's just very few. If there are a lot, this will be very important. So more or less it's quite rigid. It's quite rigid. But here, because most of these equations can be changed to arbitrary number by these feelings. Okay, so this is the Business equation. Okay, and the third example, yeah, because I indeed I want to make a match with all these things, and UT equals. and u t equals one over epsilon vx minus v x minus epsilon and v t equals one over epsilon exponential u x plus epsilon u of x so this two component equation is called the total lattice infinite total lattice Yeah, so it's equivalent to an infinite chain of springs, and the force is not given by Hooke's law, but the force is proportional to the exponential of this delta x. So it's the exponential nonlinear springs. Nonlinear springs, and this will be the total lattice equation. And if you do a Taylor expansion in epsilon, you will find that this equation is also has this Gubroman-Johnson normal form. So here, we can allow infinite many terms in PDE. Usually it's not allowed, but because we have this epsilon parameter, it is, yeah. It, yeah, so we can allow it to many terms. There is a control by this epsilon powers of epsilon. So, here you see the dispersionist limit of this example is also the same as this. So, the dispersionist limit of this example is just this part, and the dispersionist limit of this example will be this will. This will be ut equals vx and vt equals exponential ux or maybe there's a factor too. But anyway, so yeah. So here, you mean the dimension. Yeah, the dimension of the manifold now becomes the number of variables. Of variables, yes. So, so in this example, it's n equals one, in this example, n equals one, but in this example, it's already two components. You have n equals two, and in this example, also you have n equals two. Yeah. So, right, so now the this actually is correspondence, but uh so the fourth example. The fourth example about the GOE. So the equation will be infinite long, but I have not written it. But I only write the dispersion limit part. So more or less speaking, so this is also an equals tool. So, this is also n equals 2. More than speaking, all these n equals 2 examples already appeared in the dispersion limit. After you take epsilon equals zero, so you, in this case, you get this. So, all these equations in these examples in n equals two, when you take the dispersion limit, they already appear in the study of Riemann. About the gas. And actually, the main several main things I want to explain is all relates to Riemann's work. So, yeah, so now let's start from the simplest situation when epsilon equals zero. So, we just looked at. So we just look at this equation. So let's start with this equation. I call it star. And so the main assumption, I will write, maybe I write here. So the main assumption. The main assumption is that this given function A alpha beta, right? This given function. Right, this given function A alpha beta has distinct eigenvalues on some open set on some open set U of the manifold M. So, this is the main assumption. So, this is the main assumption of the study. And of course, you can see that it's a little exercise I will not do, but so when you do arbitrary change of variables from u1 to u1 to other, and other variables, you will, because you have this equation, you can describe this dynamical system in terms of the coordinate u, u1 to u1. You can also describe it in terms of other. To describe it in terms of other variables. If you describe it using other dependent variables, then this equation has a change, right? It's a change, the coefficient will change. So I write one upper index alpha, one lower index beta. So when you do a coordinate change, you'll find that this A alpha beta is nothing but a one-one tensor. Nothing but a one-one tensor. So it's really, we need to write one up and one down. So it's a one-one tensor. Yeah, so it's a little remark. Okay, so now let's look at some definitions. So how do we approach or what are interesting about this equation star? So the first is when we have a smooth function m and we will use And we will use f bar to denote the integral of f dx. So it's called the local functional. So here, of course, maybe I also, so here our g, the time will be considered in r and space will consider in s1 for simplicity. Okay, so yeah, so definition F bar is called a conserved quantity or a conservation law if df dt equals zero. Equals zero. Yeah. Okay, this is about conserved quantities. And second definition: so a PDE of the same type. M alpha beta u u beta x. A P D of the same type, this Bormino-Wykov type, is called an infinite testimony. Infinite decimal symmetry of star. Of star if they commute So now we will introduce the notion of integral system. So this equation star is called integrable If it has infinitely many infinitesimal symmetries. So, and usually we also required to be maximal rank in the sense that these even many symmetries should be parametrized, parametrized by n arbitrary functions of one variable. So, it's this kind of notion also comes from the very early works of Tabu and Gadan. S is a new time variable. A star is this system. Yeah. So, before we continue, we know that usually we want infinite hex image. Infinite symmetries and conserved quantity, we want they are corresponding to each other. For this, we will introduce the so-called Hamiltonian system. So I will denote by AU. So, I will denote by AU the ring of differential polynomials of U differential polynomial of U. And we will consider the space of local functionals f is f bar u. This is can be considered as AU quotient by the image of dx. And then we consider an operator P alpha beta equals G alpha beta EX plus gamma alpha beta gamma u. beta gamma u gamma x uh we consider an operator this operator is given by some functions so g alpha beta are given functions and the gamma alpha beta gamma are also given functions an operator of this form is called a Hamiltonian operator or say Person operator As some operator if the bracket defined by so f bar g bar goes to one bar x. X T alpha beta G if the bracket defined by using this P is a presumed bracket so and this. And this so person bracket means this bracket is a bilinear, anti-symmetric, and satisfy Jacobi identity. Okay, so yeah, and here we have a variational derivative and just recall the definition. So, f bar, g bar are local functionals. So is Soundity. So here, u alpha k is by definition dx to the power k u alpha. So and an important And an important theorem given by Dvoim Novikov in 1983 is the following. So P alpha beta is Hamiltonian operator is presumed if and only if the The following three conditions hold. So the first one is G. R for beta is symmetric and behaves like a contravariant tensor, two tensor and And this gamma alpha beta gamma behaves like the Christopher symbol, contravariant Christopher symbol. Contravariant Christopher symbol of some metric. Of some metric. And the second, some contravariant metric. The second is exactly this gamma alpha beta gamma is the crystal contravariant crystal symbol of the contravariant metric G alpha beta. And the third is Curvature tensor vanish. So it's a flat contravariant metric. So these are, so I also use upper because it's more suitable for the contravariant metric. So it's equivalent to what we usually It is equivalent, but here, because the point is that our given function is g upper alpha beta. So if you take the inverse, you need to take off the discriminant. But this curvature tensor is defined smoothly, has a smooth dependence. It's algebraic dependence in G alpha beta, G upper alpha beta and its derivative. Alpha beta and it's derivative, so it's more suitable to use in this setup. So it's the theorem of Dubroman normally prov. So, but we are not going to prove this theorem. So, it's to use this definition, one can give the proof. So, once we have the presumed structure for the For the local functionals that we are considering, we can define what is a Hamiltonian system. So this equation, star, is called Hamiltonian or a Hamiltonian system. Is or a Hamiltonian system? A Hamiltonian system. If there exists a Poisson operator, there exists P alpha beta, which is Poisson, and a function H Such that a star can be written as so because this h is just now a function, so it does not have So it does not have explicit dependence in the higher derivatives. So this is just a partial derivative. Yeah. So, and a natural theorem, and it's the same proof by Neutral tells us that if you have a Hamiltonian system, Have a Hamiltonian system, then our definition about infinitesimal symmetry and conserved quantity, they are the same. So it corresponds to each other. So the definition of interoperability is also equivalent to existence of infinite many conservation laws or infinite many conserved quantities. So yeah, now we will work on the Hamiltonian system. So in working on this So, in working on this Hamiltonian system, because of Uborninovikov's theorem, this G-alpha beta behaves like a contravariant two-tensor. So, now it's a metric, a contravariant metric, and it's flat. So, we can take the flat coordinates of G alpha beta. Right, and the second condition says this gamma alpha beta gamma is the crucible symbol of G alpha beta. But since G alpha beta is flat and V are flat coordinates, so in this flat coordinate system, gamma alpha beta gamma simply vanish. So if we take V1 to Vn as our dependent. Vn as our dependent variable. So we consider a change of a variable from u to v, then our equation becomes relatively simpler. So in this case, p alpha beta becomes just the eta are some constants dx. So eta alpha beta are constants. And the equation star now can be equivalently written as because it is simply a coordinate change or change of the dependent variables. So now equation star becomes partial V alpha, partial T equals eta alpha beta. eta alpha beta e x h e so h is a function so it's uh it's simply h so under the change of variable still h so but of course there is change of independent uh change of uh variables for h so but then so this will become eta r for beta where d v beta d v gamma So, which means, roughly speaking, in the Hamiltonian case, our A, so if we consider A in the coordinate of V, so this A, but in coordinate of V, it is a Hessian. So, it's more like, I mean, roughly speaking, it's a Hessian, but there is also a constant. Yeah, so this is the harmonious system that we want to look at. Okay. Ah, okay. U and V is a change of coordinates, so U1, Un goes to V1, VN. Since the metric GRP is flat, so we can get a system of flat coordinates, which means that. Flat coordinates, which means that the copy between these two is non-degenerate. So it's not zero. Okay, so yeah, it is the original equation. Now we assume it has, yeah, yeah, sorry, it's better written if. If star has a Hamiltonian structure, so is Hamiltonian is a Hamiltonian system. Then we can use new coordinates in V to simplify this because previously we don't have any information about. Previously, we don't have any information about this given function A. Now it's a second derivative. Yeah. Sorry, say again. Persum so here is about the PDEs. So So you're right, but it's infinite pursuit manifold. Infinite dimensional pursuit manifold. Yes, yes. So because I didn't explain that, you can construct a so-called loop space. Yeah. Sato grass money, because here in the case of KDV, I don't know if it has a relation with Sato Grassmanni. Subtle grass money. Yeah. Okay, so let's see. So now let's study this. So actually I will now introduce a definition, but that definition actually does not require it is Hamiltonian. But let's see. So definition, but I will still use the Barnum V already, even if the definition Even if the definition didn't require it is Hamptonian, I use V. So a function, a function R. A function R is called a Riemann invariant. The evolution of R is diagonal. So there exists some function S such that the DR dt simply equals S dr dx. So let's look at what does this mean. So this means if we consider If we consider the left-hand side equals dr, we use the chain rule, so it equals dr dv and dv dt, right? So it's the left-hand side. And now it equals dr dv alpha and the dv alpha dt is given by a alpha beta and the x. Yeah. So, and the right hand side equals this equals right hand side, which is S of V dr dx, which is dr dv again alpha a alpha theta so sorry it is just d V D the It is just V V d V alpha and B V alpha dx. So now the Riemann invariance says these two equal. So then we know that this gives us just the R d V alpha A alpha beta equals S times D R D V. So here's the Dumi indices. So for Dumi indices, we can So, for Dumi indices, we can change this alpha to beta and compare them. This is beta. So, this is precisely tells us that the gradient of R is the eigenvector of this matrix, A, right? And the eigenvalue is S. So, this gives rise to the following definition. So, a set of So a set of so a set of n Riemann invariants R1 for Rn is called complete if they form a coordinate. If they form a coordinate system, so if the Jacobian is not zero on the OpenSet U. Yeah, it's called the complete set of Riemann invariants. Invariants. And so, yeah, if we have a complete set, complete Riemann invariance, then of course our differential system star can be equivalently written as dr i dt equals lambda i. T equals lambda i d r i d x i from one to n so yeah this is another simple simplification for this star and there is a nice theorem a nice theorem proved by starlight Starlights by using the but we will not give the detail of this proof. Is that so yeah so so I just Yeah, so so so I just erase what I want to label. So so a Hamiltonian or let's just say a Hamiltonian a Hamiltonian PDE system of hydrodynamic type is integrable If and only if it has the corresponding A alpha beta V which is now roughly a fashion, so this has a complete set of, or as I say, it the system has a complete set Yeah, so this theorem by Tsaraf is proved by using some ancient work of Gadan and Ali Gadan and Dabu. So Dabu has four volumes of differential geometry, study curvilinear. Study curvilinear system or coordinate system. He used that result to prove this theorem. So, and then let's look at just a little bit what is the obstruction for this study. The abstraction is the following. So we have a matrix. The components are smooth functions. So this matrix value function A, we already assumed it has distinct eigenvalues in some open set. And here is the eigenvector. So the only things that we need the eigenvectors to be all have a All have a potential. So, all the eigenvectors of this matrix must have a potential. This is the requirement of this existence of complete set of Liam invariants. So, we need maximum, all the eigenvectors must have a potential. And this is actually another ancient question because Tsarav gave this criterion, and we also want a quantitative. A quantitative way to compute if a given system is integrable or not integrable. Yeah, we want some explicit computation of the abstraction tensor. If I had potential, it's a gradient of some function. So the eigenvectors, all eigenvectors must be a gradient of some function r. So it is a right. So, it is a right. So, yeah, it's a vector, but yeah, it also needs a potential. So, it's a very nice question. I gave you a matrix, right? It has n square components, and each component is a smooth function. And we know that we already assume that it has n eigen distinct eigenvalues. And we ask when all the eigenvectors all have potential. All have potential. All have potentials. So this is equivalent to complete existence of a complete set of Riemann invariants. So, and this question turns out to be studied by Shorten in some works, and then by Tonolo, and then by Nanibis. And finally, Santius gave a criterion. Finally, Hantius gave a criterion about this. He gave this complete answer for this abstraction for a given matrix value function when it has, when all the eigenvectors has potential. And then Duborin. So he has a, Hunt is has a has a hunt has a obstruction tensor so he says this existence of existence of a complete Riemann invariance is equivalent to vanishing of Hantius tensor and Duborvin transform because this is for general A and in SARF setup we need to be Hamptonian so Dubawin write down the Hunt's tensor explicitly when the input is a hex so Faction. So this can be written explicitly. Okay, so it's just some feeling about this interoperable. And of course, it also suggests that actually behind it, we already see there's one, one tensor A, there's also a function H, there are already some, and there's also. Already, some, and there's also this abstraction answer, H, Hunt's tensor. So we already see that actually behind all these stories, there is some manifold. So how it appear? So definition is the following. So two person operators of hydrodynamic type. Of hydrodynamic type, which means it's of the time g alpha beta dx plus gamma alpha beta gamma u gamma x of this form. I will just omit this form. So two Poisson operators form a Poisson pencil. Maybe this is P1, P2. They form a Persung pencil if P2 plus lambda P1 is Persung. So the notion of Persung Tanzo is actually discovered by Marguerite in 1970, early I think in 1970. I think in 19 around yeah, yeah, in 1970s. So then it's according to Margaret's idea, this definition now is quite natural. We want to consider a Poisson cancel. So for any lambda. Okay. And because this you see it's a person. You see, it's a presumed for any lambda it's presumed. So it's already suggests that P2, P1 must both be presumed. And we know that for each of them being presumed, there must be correspondence a metric, a flat metric. So this motivates the definition given by Dubawin that two contravariants. Two contravariant metrics one and two they form a flat pencil if number one so one so there are linear sum is a flat constant Sum is a flat contravariant flat contravariant metric for any lambda. And the second is the linear combination of the crystal symbol. If they crystal double a crystal symbol crystal symbol of the pencil and of course the the theorem by Dubravin By the Brawlin says T2, E1 form a Persum pencil if and only if the corresponding contravariometric form a flat pencil. Yeah. Right. So so ah, time is ah. Oh, so sorry. Sorry. So I will just end with the last remark is the following. So at the end of the forbidden manifold, we construct a second metric, G alpha beta, G alpha alpha beta. Matrix G alpha beta, G alpha alpha beta. So the result is G alpha beta in our Furbis manifold, this intersection form, and the invariant fragment metric, they form a flat pencil. And the structure of this flat pencil is almost equivalent to the fluvius manifold structure. For this manifold structure. This is what I just want to explain. Yeah, I stop here. Thank you.