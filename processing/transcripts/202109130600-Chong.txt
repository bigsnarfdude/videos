Well, good afternoon, at least here where I am. So, welcome to the second part of today's talks. And it's my pleasure to introduce Professor Shita Chong. So, he's a university professor and director of the Institute of Mathematical Sciences at the Of Mathematical Sciences at the National University in Singapore. And he's well known for his research in mathematical logic, especially computability theory. And he's going to talk about first order strengths of tree colorings today. Okay, Chita, please go ahead. Thank you. Thank you for the introduction. Thank you for giving me an opportunity to. Giving me an opportunity to give a talk here. So, I'm going to talk about the first order strength of tree coloring. So, let me begin by setting some notations. The talk will be primarily in the area of what we call reverse mathematics. So, we fixed a model that called A model called M that has two parts. Capital M is the universe, first order part of the structure. And capital S is the second order part of the structure. And capital S is a subset of the power set of M. So all structures will be of this type. All right. We say that M. We say that m is a model of I sigma n if it satisfies induction, the induction scheme for sigma n formulas. So we denote it as I sigma n. This is for n bigger than or equal to one. We say that m satisfies b sigma n, the sigma n bounding scheme, if the following is If the following is true, that every sigma n definable function maps a finite set, finite in the set of the model, m finite, otherwise we call it, maps an m finite set onto an m finite set. All right, so it was proved by Paris and Kirby a long time ago, 1978, that there is a certainly strictly strict hierarchy of inductive schema from I sigma n plus one strictly implies B sigma n plus one strictly implies I sigma n and strictly implies B sigma n and so on again for n bigger than equal to one I should also mention here that Sleiman has proved in 2004 In 2004, that B sigma n is equivalent over the B system R C0 is equivalent to induction scheme over delta n formulas. Well, these are formulas which are provable over R C naught to be equivalent to both sigma n formula and pi n formula. So, our interest in this talk is primarily on Primarily on models of RCA0 plus B sigma n, or also in some cases, sorry, B sigma 2 in particular, and the stronger part, I sigma 2. All right, so TT1. TT1 is a principle. TT1 is a principle that concerns final coloring of the full binary tree. So TT1 states the following. We color the full binary tree in finitely many colors. Then it has a homogeneous subtree that is isomorphic to the full binary tree. Homogeneous means that the Homogeneous means that the subtree has all the nodes on the tree have the same color. And that's what we call TT1. Now, TT1 has a simple, I mean sorry, yes, TT1 has a simple solution in models of RCA0 that also satisfy symmetry induction. This can be done in a Done in a straightforward manner by induction on the number of colors. And so, for example, if you color the tree, the notes on the tree in two colors, let's say blue and red, then let's say the notes with color red are not dense, then there is a point, there's a note above which no red color appears. Red color appears, then of course, then that subtree, but that the subtree above that note will be blue, and therefore we have a blue tree. On the other hand, if the notes with color red are dense, then recursively you can compute a subtree with notes all red. So that's simple under sigma 2 induction. And in particular, if m this is the first order. The first order part of the model is omega, then of course it is true. So we are interested in tree coloring for trees which are defined in a model that in which the sigma 2 induction fails. So the first thing to note, there are several facts. Note, there are several facts. The first fact to note is that TT1 implies V sigma 2. This was noted sometime agreed. So in the absence of B sigma 2, one can define a color over the model, over the full binary tree in the model without B sigma 2, in which there is no Which there is no solution. So that's the first point to note. And then in 2010, Cordian, Grossek, and Melati, they actually produced a coloring in a model of B sigma 2 or in any model of B sigma 2 in which there is no recursive solution, meaning that any homogeneous subtree that's isomorphic to the full binary tree. Isomorphic to the full binary tree cannot be recursive under the coloring. Well, subsequently, with several authors, Wei Wang and Yu Yang, we proved, it was published last year, that in fact more than that, that is a recursive coloring in which if you have a model of basic material. If you have a model of B sigma 2 only, then there's no zero jump, zero prime recursive solution. So that means that any sub-tree isomorphic to the full binary tree that's homogeneous for that coloring cannot be obtained from Zhouji. As a matter of fact, we even show that there is one can That there is one can define, produce a model of P sigma 2 in which there's not even that, not only that, there's no zero jump solution, there is no zero double jump solution. So that means that in the absence of sigma three induction, you can define a recursive coloring of a full binary tree with a solution that is very complicated. All right now to say a bit more about this, let me introduce, digress, I guess, introduce a principle that's called bounded monitor enumeration principle. This principle was introduced in the paper of Tess Lehman, Yu Young, and myself that That concern the stable problem on stable Ramsey theorem for press. And the principle says the following that for any monotone, sorry, for any sigma one definable monotone enumeration of finite of a finite sequence of A finite sequence of finite trees, there is a uniform bound. To make this notion precise, it will be a bit complicated, but it turns out by a result of Preutzer and Yokoyama, proved in 2017 that this principle, BME1, Principle, BME1, turns out to be equivalent to two other principles that are already known previously. One is the principle called P sigma one that again has to do with monotone enumeration, but not over trees. Instead, it's over a finite collection generated by a finite collection of sets. And in a certain manner, again, there is a uniform. In a certain manner, again, there is a uniform bound, or perhaps something more familiar is the principle that asserts the totality of the Ackermann function. So these three notions turn out to be equivalent. And so in the following, we will use the symbol P sigma one to denote any of these principles. Right. Okay. Okay, coming back to TT1, we are now interested in the inductive strength of TT1 and also problems concerning conservation of this principle. So, first of all, again, it was in the result that was published last year, we show that there is a We show that there is a model of RCA0 plus TT1 plus the failure of sigma 2 induction. That's our main interest here. So this is a model of TT1 plus B sigma 2. Of course, I mean, yes, TT1 implies B sigma 2, but in which sigma 2 induction fails. And therefore, of course, it follows immediately that Tt1 does not imply sigma 2 induction. imply sigma 2 induction. So what this means is that while under sigma 2 induction, TT1 has a simple solution without sigma 2 induction. TT1 is still true, but for some models, TT1 is still true, but the solution is not straightforward. Furthermore, if we take the base system RCA We take the base system RCA0, then over the base system RCA0, TT1 is pi11 conservative over P sigma 1 plus P sigma 2. What this means is that any Pi11 sentence that one can prove under RCA0 plus TT1 is already provable under RCA0 plus P sigma 1. P sigma 1 plus B sigma 2. Well, B sigma 2 has to be there again because T D 1 implies B sigma 2. Right, so we are, well, almost like one step away from showing that TT1 is Py11 conservative over RC0 plus BC Mark II. But but um in a recent work um the manuscript is already almost ready in the recent work with um wei wang and yueyang we show that um tt1 is uh plus rt22 rt22 is the ramsey's theorem for pairs plus wkl0 that's weak connects lemma That's a weak connect lemma is in fact pi zero three conservative over R C A zero. So that means that any again, any pi 11, sorry, pi 03 sentence that's provable under the system, which is a pretty big system now, TT1 plus Ramesis. Plus Ramsey's student for pair stud plus weak connects lemma. Any pi 03 sentence that's provable in this system is already provable in RCA0. Now, Pate and Yokoyama showed in 2018 that the RT22 plus WKL0 is Pi03 conservative over RC0. Conservative over our CSU. So, our result extends their result to include this principle on finite coloring of trees. So, a corollary of this is Corollary of this is that R C0 plus WK0 plus RT22 plus TT1 does not prove the monotone enumeration principle P sigma 1. The reason is because P sigma 1 or BME1 or totality of Eckermans function is expressible as a pi 03 sentence. So if RCA0 plus plus WKAS is 0.0 Plus WKL0 plus RT2 plus TD1 proves PC11, then it would already be provable in RCA0. But we know that this is not true because PC1 is false in the system RCA0 alone. So this brings up a question relating Ramsey. Ramsey's theorem for pairs with TT1. It's not, well, I guess it's pretty easy to, well, yeah, pretty easy to show that TT1 does not imply RT2. The reason is because in the presence of sigma 2 induction, TT1, as I said earlier, has a simple solution. It always has a recursive solution. Whereas an old result of Jockus shows Result of Jockus show that there is a recursive coloring, two coloring of pairs of numbers with no sigma two definable solution. And therefore, Td1 does not prove Ramsey's term for pairs. The converse, however, is not known. So is it true that over RC0, RT22 implies TT1? So this question is unknown. Surprisingly, Surprisingly, turns out to be quite challenging. I want to move on to talk about generalizations of TT1. So the first that comes up is what we call sequentially dense. Dense row vectors over a row vector nil. So let me define this notion. So this slide will be full of definitions, but please bear with me because we will need these notions in subsequent slides. So fix a number D bigger than equal to one. New, we call it a d row vector if the following. It is a d row vector if the following holds. So, first of all, we have d many trees: T1, T2, T3, T4, all the way to Td, finitely many trees, each of which is isomorphic to the full binary tree. So T1 cross T2 and so on cross Td. And new is a, we write new arrow. We write new arrow vector new right as a new one, new two, and so on all the way to new D. So that new one belongs to T1, new two belongs to T2, and so on. New D belongs to TD. That's the first condition. So the second condition is that they have the same length. So pictorially, they belong to the same role. So they are all line up very nicely. Or line up very nicely. So, and it's a D might, you can call it a D-dimensional vector. Okay, nu i belongs to Ti. So, this is what you call a D row vector. Secondly, if you take a subset of tau vector, vector tau, tau vector which is contained in this product, t1 times t2 times. times T2 times Td and so on and so forth. We call it a row vector if every member if all the members of vector tau of tau vector have the same length. So again, they lie together same row. But the difference between this and D row vector is that maybe in T1, for example, In T1, for example, there's more than one element that comes from tau vector. Maybe there are two members that belong to T1, but they all belong to tau vector. So tau vector is not necessarily a d-dimensional one, but all the members lie on the same row. So it's something more general than a d-row vector. Secondly, we say that tau is over, well, a tau vector. Well, a tau vector is over a new vector. Um, if well, every member of nu is extended by a member of tau. So, in terms of picture, you can think of tau as lying over. Nu is below and tau is above. So, so uh, geometrically, this is what we mean when we say that tau is uh over nu. Thirdly, Thirdly, if tau is over nu, then we say that it is S dense. S is a number. We say that if it is an S dense, if every node that extends new i, new i is the i component of the vector new. Every node that extends new i is extended by a man. Is extended by a member of tau. So you think of the picture for this is that we have tau vector that lies over new vector, but it lies in a certain manner, meaning that it's pretty high. Every node that has length s is below something in tau vector. This is what we call a tau vector that is extends over. That is S tense over nu. Okay. So just to fix a notation, if we have a row vector tau, since all the members have the same length, so we just write the absolute value of tau vector to represent the length or the height of tau vector. This is just for convenience. Right, now comes the key definition. Definition. If we are given trees T1 times T2 and all the way until Td, each of which is isomorphic to the full binary tree. And if we have a subset S of T1 cross T2 cross all the way to Td, we say that it is sequentially dense. This subset is sequentially dense if two conditions are met. First of all, the members of S are all row vectors. Right, so they are nicely lined up: first row, second row, third row, fourth row, and so on, so forth. And secondly, the S plus first row of this sequence is, well, okay, tau arrow S plus one is absolute value tau S dense over new. So we have a new vector. We have a new vector down at the bottom, which you can think of as base or something. It's a d row vector. So new vector is a d-dimensional row vector, right? Now we have S, which is a collection of row vectors, and all the members in S lie above this base nil vector. That's the first condition. The second condition is that The S plus first row of capital S is dense over the S row of the collection capital S. And dense in the sense that every member of tau vector S plus one lies above the corresponding. The corresponding members in tau S. Here's a picture. Okay, so here we have T1 to the left and dot dot dot all the way until TD. That's the last three, the one on the right hand side. All right. Now we have a collection called sequentially dense collection of row vectors. So all the members of S, capital S, are Capital S row vectors. So they're all nicely lined up. So tau zero, you see on the picture there is the first row of capital S. So it's nicely now, one straight line, sort of. And then the circles there are the nodes that belong to S. And then you go all the way to the S row, tau vector S. So again, it's nicely lined up. And every note. Every note in tau zero, tau vector zero lies below something in tau s tau vector s. And every note in the in this row, tau s, tau vector s lies below something in tau vector s plus one. Right. And Right, and we are interested in coloring of d-dimensional vectors and looking for homogeneous solutions. So that is the problem. So now, if d is equal to one, we are then looking only at one tree. And in that case, that one tree, if we do colorings of the full binary tree in any way that we Binary tree in any way that we do, we want, right? Just one tree. And then we ask whether there's a sequentially dense collection of nodes in this T1, one tree, that is homogeneous. That's the situation for one tree. And in general, we have D many trees and we ask analogous questions. Analogous questions. Okay, SHL, the strong Halpen-Lochli theorem. Small S there stands for strong. Okay, so let's introduce the notation. SHLD bracket K. This is a principle that says that every K coloring of D row vectors. Uh, row vectors in t1 times td. So we have d many trees all isomorphic to two to the to the full binary tree, right? T1 cross t2 cross td and so on and so forth. You take up all the d row vectors in this product and color them in any of k colors, right? Any such coloring, here's the claim, has a homogeneous sequentially dense. Dense solution over some nil. And what does that mean? That means that if you do a coloring like that, then you can find a d-dimensional row vector. Call it new vector or new arrow. Then over this new vector, you can find a sequentially dense Dense collection which is homogeneous for the colouring. So the strong-Halpen Lossley theorem states precisely that, that Z2 is the full second-order arithmetic, the system. Okay. Says that for D, sorry, for K bigger than D greater than equal to one. Greater than equal to one. SHLDK has a solution. Well, why do we want to consider K bigger than one? Well, of course, I mean, if K has is equal to one, then only one color, then there's nothing to do. So, of course, we are only interested in K bigger than D, D bigger than equal to one. For all such pairs, K and D. If you color the D-dimensional product of the full binary tree, the D-row vectors, that is, in K by K colors. In k by k colors, then there is always a homogeneous sequentially dense solution over some new vector. That's the Halpen-Loshley theorem. Okay. In what follows, I will report on joint work with my colleagues Wei Li and Yuyang. Right. Right. So the first results I want to mention is that if you restrict D and K to standard numbers, to the standard natural numbers, then the strong Haben-Loshli theorem. Lauschley theorem for D and K is equivalent to B sigma 2. So it looks like a fairly weak statement. Now, let me just give you some flavor of how a proof like this would go. Let me just look at one direction to show that. To show that if we just color one tree in two colors, right, the Halben-Loshley theorem, HL12, strong, sorry, strong HL12, must imply B sigma 2. So this is an example which is not exactly the It's not exactly, the proof is not exactly correct, but it gives you an idea of how one would actually proceed. So suppose M is a model of L C A Z in which B sigma 2 fails. All right. So what this means then is that we are going to do this thing that we are going to color the food. And we are going to color the full binary tree with two colors in such a way that it has no red sequentially dense solution over the root of the full universe, the root of the, sorry, of the binary tree. I call it empty set, that's the root, and no red solution over any. So how do we go about doing that? How do we go about doing that? Okay, now B sigma 2, the failure of B sigma 2 guarantees that we can, that there is a recursive function g, which partitions the universe into, there's a, also there's a, there's a constant, I guess, there's a number S0. So there's a recursive function g that partitions the universe m. partitions the universe M into two to the S0 many parts in such a way that for each i, small i less than two to the s zero, the set denoted that the set of y so that g of y is equal to i is finite. So the failure of B sigma 2 guarantees that. So what we will do is to exploit this failure to define a two coloring. To define a two-coloring that has no sequentially dense solution over the empty set, nor over any for red, and no blue sequentially dense solution over any new. All right, okay, so the first thing to do is that we line up the all the The nodes and the tree of height S0, we call them sigma 1, sigma 2, all the way until sigma to the 2 to the power s0 minus 1. So we have a finite tree whose root is the empty set and the height is s0. It has two to the s0 many nodes. And the way we do the coloring is this, that for any That for any tau, if the length of tau is less than or equal to s0, we color it red. If the length of tau is bigger than s0, then we do two things. One is that if tau extends sigma i and g of the length of tau is equal to i, then we color tau as blue color. Otherwise, we color it red. Let me show a picture here. Here's a picture on the left. So we have a the full binary tree is on the left with the coloring that's shown. So what we do then is that the red triangle tree down below is a finite tree with a root that's empty set and height is equal to S zero. height is good s0 so it is two to the it has two to the s0 many leaves yeah now so uh by definition all the notes that has height less than or equal to s zero has color red so that's why you see the red triangle there now um if g of y uh sorry G of y, sorry, now you take a note, tau, and then look at the absolute value of tau and compute g of tau. g of tau will send it to either sigma 1 or sigma 2 or all the way to sigma 2 to s 0 minus 1. Depending on where it lies, and if tau happens to extend sigma i, then tau will have color blue, otherwise you will have color red. Blue, otherwise, you have color red. So, what you see then on the picture on the left-hand side is that either the entire row in a particular cone is colored red, or the entire row in a particular cone at any one time is colored blue. And at any one time, only one cone cone is sigma cone with base sigma zero. sigma cone with base sigma zero sigma one sigma two and so on so forth at any one time only one row will be colored blue and everyone else will be colored red so so this is the coloring that we're gonna uh we define um for this uh full binary tree so now because um Right. So now we know the following. Coming back here. Because the colouring is done in such this manner, as shown in the picture. We see that you, after you go above the level S0, you cannot find a red color road. Color rows anymore. Well, in small triangles, you can still find color, red rows, but across from all the way from left to the right, there's always something in blue and something in red. So there's no more extension of the row vectors in a level S0 where everything is colored red. So that's one thing to note. So that means that this Means that this construction kills a red sequentially dense solution over the empty set. And simultaneously, because of the failure of P sigma 2, and because of the way we define our coloring, it means that on every cone from sigma 1 to sigma sigma 1 to sigma to the s 0 minus 1. There are only infinitely many blue ropes. It cannot be infinite because of the failure of p sigma 2. So the two statements here are just in written form what I said here that there is no blue solution over any Any new, and there's no red solution over the empty set, which is the root of the full binary tree. Well, this is an example of how we kill a particular instance of sequentially dense collection to be homogeneous. But in general, if we want to kill all red solutions, Red solutions, then we need a finite injury priority argument to define the coloring C, which I won't touch here. So that's the last statement. Now, a more general statement of this is the following, called S H L K. HLK, which is a statement that for any D bigger than or equal to one, SHL D K holds. So that means that for any number of trees, T1 all the way until TD, if you color the D dimensional vectors in K colors, then there is a sequentially dense solution for this coloring. This coloring. So, this is the strong Harpen Loshley theorem. Right. Well, it turns out, as we discover, that this statement, the strong Harbin-Losley theorem, even for two coloring, but for two coloring, but for any number of trees, is equivalent. Is equivalent to a sigma two induction. So the point is if we have a one thing to know is that if we have a sequentially dense collection of row vectors, then it actually includes within it Includes within it what we call a strong tree. And let me define what we mean by a strong tree. A strong tree, of course, is a tree, but has two properties. The first is that if pow is a note in the tree, then Um every sorry every if sigma is a is sorry if sigma is a note in the tree then every immediate the immediate extensions of sigma in in the tree T have the same length so that means that it's different from a normal usual arbitrary tree where the extensions immediate extension of of any node may be different you know if you look at a sub-tree of a given tree it could sub-tree of a given tree it could be happen like that but we are interested in strong trees so that every note for every note the immediate successors have the strong have the same length that's uh one point and the second point is that if sigma and tau are two nodes in this tree t and have the same length then their immediate extensions also have the same length so that's the picture you see on the left very nicely aligned so So starting from the base, that's of course the root of this subtree T. And then its immediate extensions lie in the same row. And then these two immediate extensions also have their immediate extensions. They also lie in the same row and so on and so forth. So they are very nicely extended. Extended. And of course, the immediate extensions, where do they intersect? They intersect at the point where they started. So if you have sigma and then, which is a node, then the two immediate extensions must split immediately in the full binary tree before they can go to their respective locations. So, this is what we mean by a strong tree. Strong tree. Right. Okay. So now we are looking at D many trees now, T1 all the way until Tdi. So given Ti, which is equal to the full binary tree, we say that we have a product. Subtree, a product subtree capital S of T1 times T2 organ to Td. We call it a strong product sub-tree if over new, right? If, first of all, each one, each component, S1, S2, S3, and so on and so forth, is a strong sub-tree of the full binary. Sub-tree of the full binary tree over new sub i. That's the first point. And the second point is that all the vectors in this product are lined up in one line. So that means that you have S, which is a subset of the product of T1 times T2 times all the way to Td in such. Td in such a way that separately each component of S, right, projection down to the Ti, the I component coordinate, is a strong tree. But on top of that, when they put them together, when we put them together, they all lie very nicely. One row, second row, third row, and so on and so forth. Okay, so the Harper-Loshley theorem says the following: HL, right? For any D bigger than or equal to one, any finite coloring of the finitely many trees T1 times T2 all the way through Td has a homogeneous Product strong subtree. So, this is a notion that is weaker than what we call a sequentially dense collection introduced earlier. That one gives rise to what's called a strong Harper-Nossley theorem, whereas this one is a weaker version. Version and therefore implied by the strong version. And we are interested again in the first order strength of the Haben-Losh Lee theorem as compared to the strong Haben-Losh-Li theorem. So to be more specific, you fix D and K. So HLDK says that every K coloring Every k-coloring of d-dimensional row vectors of t1 to td has a homogeneous strong product sub-tree over some new vector. So if you take the d-dimensional product of the full binary tree, right, and the color all the d-dimensional vectors in Dimensional vectors in any of k colors, k is fixed, then there exists a solution, a sub-tree, a product sub-tree, which is strong and in such a way that it is homogeneous, one color. Okay. HLD, let's k go to infinity. So every finite coloring of the D-dimensional product tree, T1 to TD, has a T D has a homogeneous subtree that solution that is strong for this coloring. So here's what we have. RCA0 plus HL1, only one tree, but strong trees now, implies B Sigma 2. Well, this is not surprising because HL1 implies TT1. And since TT1 implies B sigma 1, that's B sigma 2, then of course Hl1 implies B sigma 2. Secondly, for every model of LCA0 plus B sigma 2, I should say in which Sigma 2 induction fails, there is a recursive coloring of the There is a recursive coloring of the full binary tree so that again, just like the one for TT1, it has no Zhuojiang recursive solution. Again, this is implied by the result TT1 because HL1 implies TT1. So this is not surprising. But the third one is Is something different because again, under the basis system RCA0, HL1 is also pi 11 conservative over P sigma one plus B sigma two. And therefore, RCA0 plus HL one does not imply I sigma two. not imply I sigma 2. Well, this result may look similar to the result that we have on TT1, but the proof is, I would say, quite different because of the stronger requirement that any solution has to produce a strong tree that is homogeneous for the calorie. Yeah. So, so. So, so the clarity that one can derive from here is that HL1 does not imply a strong HL1. So, sequentially dense collection is always stronger than the HL1. And you can also see it in the following manner. If you have a coloring and then you have a sequential. And then you have a sequentially dense solution, homogeneous solution for that coloring. That solution necessarily has to be a recursive solution because of the sequential density. It's not difficult to see that. On the other hand, with HL1, where you only require solutions of homogeneous solutions with strong trees, it's no longer true because as True because, as noted in the theorem above, that you can have recursive covering with no zero jump recursive or computable solution. So, HL1 is vastly different from strong HL1. And yeah, so here's a summary, and that's the last slide that I have to give. That I have to give us a sense of where we are. You look at the center, the spine of this diagram, starting with SHL, the strong Harbin-Loch Lee theorem on top, which states that any finite number of trees, T1 to Td, any finite coloring of D-dimensional row vectors that is a sequentially dense. Dense homogeneous solution over some new vector. So that's a statement. SHL is stronger than HL. HL has to something similar, but instead of asking for a sequentially strong solution, it asks for a strong tree solution. Right. And HL is, of course, stronger than HL1 because HL1, you only look at one tree. Look at one, three. Now, HL1 is stronger than TT1, right? Trivially. And TT1 is strictly stronger than B sigma 2. Double arrow means strict implication. On the other hand, if you go to the top row again and moving to the left, you see that strong HL is actually equivalent to strong HL. Equivalent to strong HL with only two colors, which in turn is equivalent to sigma 2 induction. Now, coming back from I sigma to sigma 2 induction, it strictly implies HL1 and the converse is false. Now, if you go to the top row and now moving to the right. To the right, you see that for K and D standard, strong H L is actually equivalent to B sigma 2. So we have a rather interesting situation here where for finite natural numbers, the strength, the first order strength of this principle is Principle is weaker than the general statement of HR. But when it comes to strong trees, you get quite a similar, sorry, a different scenario because then HL1, for example, even HL1 is not able, it's not able to show a symmetry induction. 3 induction. Well, it is implied by Sigma 3 induction. I should also add that under Sigma 3 induction, HL1 will always have a trivial solution, namely a recursive solution. But without Sigma 2 induction, as we noted earlier, you can have a recursive coloring without zero jump solution. And in fact, there is a model of B sigma 2 without Sigma. A model of BCMA2 without CMA2 induction, in which not even a zero-double jump recursive solution is available. So that's my talk. Thank you.