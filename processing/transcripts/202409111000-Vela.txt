This is the story that I want to tell you today very quickly. It's related to DFT. Somehow, as we will see, it's somehow related also to orbital 3D FT. And the reason I want, we started this project, the This project, I want to tell you in the abstract, I said that it was going to cover three stories: conformational ordering, supramolecular assembly, and conceptual DFT. But for the sake of time, I will not cover the last part. I will show you all the highlights of the first two parts. The problem of conformational ordering is actually a problem. It's actually a problem of amino acids in gas phase. It's a problem that we have been analyzing and studying for many, many years. In fact, I started this project in Montreal many years ago when I was working with Dennis Salau in UDM, in the Université Montreal. And the project was very simple. The project was to, I have been developing exchange and correlation. Developing exchange and correlation functionals in the traditional and canonical way, let's say, for many, many years. And I was working with Emir Proinova and with Denis Alau, trying to produce new functionals that will improve the predictions of many properties, of many molecular properties, and of course, also in atoms and in solids. But in particular, And in solids. But in particular, we were interested in the conformational ordering of glycine. The pointer, what do I call the pointer here? Well, okay, forget it. Forget it, forget it. I will use the other point. Okay. So So, the problem of conformational ordering in amino acids is interesting in gas phase for two reasons. One is that there are very good experimental results with high quality spectroscopy, which have been known for several, actually, decades. And they have predicted the structure and the ordering, the difference in energy between different conformations. And these are some of the references that you can see, at least for glycine and alanine. And the quarries known for these three amino acids, these three amino acids are. These three amino acids are the most simple amino acids that you can find in nature. And as you can see, it is interesting that even for such a small system, you have a very rich conformational structure. And therefore, the aim actually of what we wanted to do is to see if DFT was capable of reproducing the structure. Reproducing the structure and also the energetic ordering of these conformers. If you talk about this project with someone coming from biophysics or from biochemistry, they will tell you, well, but are you interested in that? I mean, the amino acids in the cell, they are first in a liquid, are in a liquid. Are in liquids, the amino acids, they are not in the molecular form. They are a sweeter ion, sweeter ion. They adopt the sweeter ion structure. That means that one of these hydrogens moves away to this oxygen. And actually, that movement is crucial because that reduces dramatically the landscape or the possibilities of structures that you can have. Structures that you can have in liquid state for the amino acid. So, yes, that's correct. But in any case, I mean, from the point of view of DFT, since we have, since these are small systems, and you have good experimental data, and you can do very good calculations as a reference to compare. A reference to compare with DFT, that was one of our motivations. That's why we decided to do it with DFT. So, in that sense, we have developed several functionals together with some tricky, as Sam mentioned in his lecture on Monday. We have been working with Sam and with Josel Luis Grasquez for several years now. For several years now. And we have followed this philosophy in building several functionals. And the point that I want to stress is that basically what the most important aspects in the functional development that we have followed is that we want mathematically simple functionals and we want non-empirical functions. I mean, we don't want to fix parameters by fitting or anything like that. By fitting or anything like that, we use constraint. Actually, we typically use constraint satisfaction, as it is written here, to build and to fix the parameters that appear in the functional. Some of the functionals that we have produced are these ones. I just want to show you to be a little bit familiar with the names. As a matter of fact, coming to the point that these functionals, we have concentrated also in something. Also, in something. We have concentrated in producing GGAs with the idea. I mean, there are some papers where Jean-Perviu and his collaborators have said that the GGA rung is closed. I mean, that there is nothing else to be done besides the PBE made simple, right? Besides the GGA made simple. Well, we don't share that view. Well, we don't share that view, as you will see in the next slide. Actually, there is a lot of room to be improved, even at the GGA level. And also, because for one reason, if you, something that was the motivation in some of the developments or in continuing this effort was to try to find GGAs which provided better gradients, particularly not only for geometry optimizations. For geometry optimizations, but mainly for molecular dynamics. That was one of the motivations that we had. And well, just to see you that we are doing not that bad. Actually, this plot is not updated. We have a couple of new functions since 2020. And as you can see, well, we have not done bad. I mean, this is the mean average deviation in the heats of. In the heats of formation of the G3 set, which is 2000-something molecules. And as you can see, well, this is PBE, as you can see here. And the mean absolute deviation of Pb is huge. I mean, it's 20 kilocalories per mole. It's huge. And you can see, well, this is what we are very happy and satisfied that we are achieving our goal. That we are achieving our goal, that in fact, we can have produced new functionals at GGA level. I mean, all these results are GGA functionals. We can go, I mean, we are not below the five kilocalorie per mole threshold, but it's not bad. Unfortunately, I cannot tell you that we can extrapolate this, right? But it's not doing. It's not doing bad. And also, it seems, I mean, if you look at other properties, for instance, the frequencies, it's not bad what we are, that means that the Hessian and the gradients, the first derivatives and the second derivatives of the energy are well represented by the functionals that we are producing. But so that was the story. You said, okay, so we have good functionals. How about applying them to the amino acids? Well, Amino acids. Well, this is just to show you that for these amino acids, for glycine, alpha-alanine, and beta-alanine, there are very good ab initial calculations, even with the CBS extrapolation, with the basis set extrapolation. And so we have very good data to compare with. And if you do the comparison, let me show you. Do the comparison. Let me show you. This is the comparison that we did. These are the correlation functionals that we consider. We haven't changed much or worked much in the correlation part of the GGA. We have concentrated mainly on the exchange. We tune the correlation as it is done in PVE. The PVE correlation is tuned to the exchange correlation to satisfy the response of the. The response of the electron gas. And with this, we tried with all these correlations, and these are the exchange functionals. The functionals that you see in blue are functionals, but as you can see, we tried empirical functionals like the Minnesota functionals. We tried non-empirical functionals, global hybrids, meta-GGAs, here's a scan. Here's a scan. And also, I want to call your attention to this fact. We tried, we wanted to see when we were working with this, Kieran Burke, together with Sim, they presented this work, this very nice work about determining the energy, the errors in a functional. I mean, that there are two kinds of errors in a functional, that you have the functional error and the density. Have the functional error and the density-driven errors. And to determine if this problem is density-driven, one way to do it is to do a calculation, what they call the hard-tree-focused DFT, which means that you do not use the self-consistent density of the corresponding functional. You do, well, they say you use a better density, and here a better density is hard to evolve. Why? Why? Because you have the correct asymptotic behavior. I mean, it's, and also the behavior near the nucleus is better. And well, that's the procedure and the protocol that Kiron and Sim have proposed. We implemented that with the functionals, and these are the results that we obtained. These are all the combinations that we tried for glycine, and as you can see in the And as you can see in the scale, well, the first point that I want you to take a look is the magnitude of the scale. We are looking and we are after small energy differences. I mean, we're not after, I mean, when you see the differences, I mean, with all due respect, the differences that you show in the kinetic energy, I mean, those are really huge, right? I mean, for us, that's, well, I'm out of the ballpark, right? There's nothing else I can do. There's nothing else I can do. Notice we are between 0.5 and well, it's a two kilocalorie bar. So the energy differences that we are considering are really small. If we are in the right, if we are correct, then that means these are the conformers. And the heat map tells you if you are light, that means that you have the correct or all That you have the correct or almost correct energy difference. And if you have, with a given methodology, you have all for all the conformers, the same a light color. That means that you are describing correctly the conformational ordering. What is the message? Well, as you can see, there are, this is the See, there are, oh, this is not working. As you can see, there are many blues and there are many reds. That's bad. That's bad news. And so bad that, in fact, 11 functionals of the combinations that we made predict higher stability of conformer two, which is the conformer that you see here, here on the top. Sorry, this. Can you, how do I? How do I turn on the laser? It's not working, the laser. Well, anyway, then a very similar situation is we have with the other amino acids. For alpha-alanine, 25 functionals do not reproduce the correct ordering. And with beta-alanine, the scenario is even worse. Use even worst 32 functionals are not predicting the correct order. Those are bad news for DFT, right? I mean, uh, and well, actually, this is my first take-home message for you. If you are working in DFT with a problem where energy differences are in this range, you are in trouble. DFT will give you a problem, right? I mean, again, you can say, well, but who cares in the real biology? Who cares in the real biological systems? The systems are not like this. Well, but this is nature. I mean, this, this is, you have these problems. So, uh, what we did, well, this is the summary of the DFT approach. And actually, the reason we can give an explanation. And the explanation is that all the functionals that we tried have these interactions that are depicted here using the no-code. Here, using the non-covalent interaction approach, and as you can see, we found that this interaction is present in all the conformers that are predicted as the stabler conformers in this very small amino acid. This interaction is overestimated in the forechart. I mean, how can we correct that? Well, we haven't figured out how to do it. But then, in the meantime, we said, well, let's. Time we said, Well, let's start with machine learning. The reason is that we were working with something, something is missing here. Sorry, something is wrong in the slides. But we decided we engage in a project in Mexico to use not to generate artificial intelligent tools, but to use, actually, I want to underline and to stress. Underline and to stress the fact that Michele mentioned on Monday that I absolutely agree with him. That, I mean, it's important to produce new tools, new neural nets, new basis sets, new data sets, and to design new tools. That's fine, perfect. But it is very important to test them and to make them public to see if you can find. To see if you can find beta testers, I would like to. I call myself actually as a beta tester of whatever, if we find something, if we see published, if something is published, or we learn, oh, look, I heard about this neural net for this, does that, we download it. Now we have all the technology in my group. We download and we try it immediately and we try to see how it works. And I agree absolutely that it's very important for all. Very important for all those of you who are developing many artificial intelligence tools. It's very, very important to make it available and to help the beta testers to apply it to see how it works. I agree absolutely with that. I think that's exactly what we did with Annie. We downloaded Ani. Well, on the other hand, I have the fortune of being a very good friend of Adrian Reujberg. Friend of Adrian Reutberg. I mean, he's Argentinian, so we are always fighting about soccer. Unfortunately, he's always right that we will defeat you and say, This time we are going to win you. There is no way. So we always joke about that. And well, they published Annie. This is the story of Annie. And well, unfortunately, you don't see what is here. But Annie, the point that I want to stress is that Annie is a very Is that ANI is a very well-trained neural net? It has two features which are crucial, and you people know this very well. It has a very big data set and the quality of the data. That's the other point. The point that I want to mention is that it is not only a fact of having a lot of data, you need data of very good quality. The quality The quality, the data set that they use for ANI1 CCX, which is the neural net in the bottom, is CBS coupled cluster calculations, CCSET, with complete with CBS extrapolation. So the data is very, very good. It is trained with With stable molecules, with the stable molecular structures only containing carbon, hydrogen, oxygen, and nitrogen. Okay? That's all they have. So you can only do very basic organic chemistry, but that's what we have in our amino acids. So we decided to apply it and to make this. And we were working on that when. Working on that when, uh, again, here this slide is just to show you that, in fact, we are hackers. I mean, we are just beta testers. We were working on the project, and then it appears this neural net by Google, by DeepMind, which were very good colleagues participated. Colleagues participated, Paula Mori Sanchez and Aaron Cohen. And we decided to try it. I mean, we decided, well, it was available. We downloaded, we installed it and said, well, let us compare it. And we did the comparison. Let me go directly to the final comparison. This is the slide that compares almost everything. How am I doing time? How much time am I? 10 minutes? Perfect. Okay. 10 minutes? Perfect. Okay. So then, this graph summarizes our results regarding the application of machine learning to this problem of conformational ordering of small amino acids. As you can see, here we have four bars, the R2 scan, I mean the best functional produced by John Perdue and company, Ani in yellow, and In yellow, and DiM21, the neural net from Google Mind, in green, and the reference, which in some cases is Copper Cluster, and in other cases is QCI. And well, let us start looking at lysing. Well, the size of the bar, again, I want to stress the scale. Notice again, the scale, the scale, the energy scale. Scale, the energy scale in all cases. Well, here is in the case of glycine all the way to eight, but it is between three kilocalories per mole and eight kilocalories per mole. It's more. However, even with Ani, it's really, really good. I mean, if you see, if you compare the gray line with the yellow line, well, in general, the result is. In general, the result is quite good. DiM21 is not bad, but notice that DiEM21, for instance, is missing. There is a green bar missing in Alany. The green line is not there because it didn't converge. So we had problems actually. DN20, I like DN21 very, this is something that now we want to try to do. We want now to. To do, we want now to make neural nets. If someone is interested in joining us in that effort, uh, uh, uh, well, probably Paul will help us with that also. Uh, we want to build a neural net where I'm absolutely convinced that the functional, well, we were discussing, maybe it was too much biongi yesterday, but uh, but we were discussing about the seeing the exact functional. I'm convinced, I think not. Convince, I think not everybody agrees with me. That's normal, I mean, but sometimes not even I agree with myself. But anyway, I'm convinced that the functional is not a formula. I think it's an algorithm. And unfortunately, that's not my original idea. That was first mentioned to my knowledge by Kieran Burke. And I think he's probably correct that the exact functional is not a formula. Is not a formula, it's an algorithm, and which is the best way to exploit or to find that algorithm machine learning. Right, I think that's that's what my common, but as you can see, there is the comparison is very good. And here comes this, I mean, when I saw this, all these structures are 26 structures. As you can see, the machine learning is good and fast to obtain the 26. The 26 conformers with Annie, it took us one minute in one iMac. That's great. I mean, with that, you can explore, you can really explore chemical space, right? And you know this very well. But I just want to stress that even for these kind of problems where the energy differences are very small, you really are in business with some well-trained. Some well-trained machine learned or neural nets, current neural nets, are very good tools to explore reliably, at least to give you a very good idea, for instance, in this case, about the landscape of the potential energy surface of a, let me call it, complicated system. So, to finish my talk, let me go to the second problem. And the second problem is a little bit more challenging. More challenging is again chemistry. What we want to do is we want to explain this process. This process is called molecular ensembly. It's to try to understand actually our goal is to try to reproduce this curve that you can see here that corresponds to the ensembly of a molecular motor. This motor is, oops, is a rotor. Is a Rotaxan, which are all these motors are motivated by how nature works. You all don't know that very well. And actually, what we want to do is to try to find a protocol, a theoretical protocol, to explain, I mean, the way experimentalists explain how these ensemblies work and how the process takes place. Takes place, they usually, I mean, we're talking in good journals like this one, Cuchisa, Jax, they make these graphs, but these graphs are qualitative. I mean, these graphs are energy as a function of a collective variable, I mean, that represents the process of assembly. And our goal was: can we Was can we establish or determine or find a protocol that can help us to unravel this? Well, that was the PhD project of one of my students. It has been tried before with two approaches. One is with molecular mechanics. The problem is the quality of the results. I mean, you don't obtain very good energies. Your energy differences are not that good. Differences are not that good. So, I mean, you cannot really trust what the force field, the classical force field is reproducing. And the other approach is the fully quantum mechanical approach. And there's the problem that you can see in the case of the quantum mechanical approach, you don't plot the curve because it's impossible. I mean, it's very difficult. If you want to describe or if you want to calculate the intrinsic reaction. You want to calculate the intrinsic reaction coordinate for these kinds of problems, believe me, you're in trouble. My student was working with that project when the pandemic started, and he was frustrated. Well, first, because he was locked down. We were all frustrated because of that. But the second was that nothing was working. I mean, we were approaching that with normal DFT, good functional good basis sets, good grids, et cetera. With grids, et cetera, but it was not working. So we decided to, well, these are the systems that we have been studying in collaboration with an experimentalist in Simbesta. This is the machinery that we are using. What we want to do is we want to produce this energy. Let me call it energy path. But also, we want to analyze why the energy path, which kind of the energy power which kind of interactions are taking place or playing the role inside inside inside the inside the in the process of the of the actually they call it threading the the incoming and dethreading when the when the the the dono the torus is going outside of the axis this is all the machinery that we are using again we are using any but the point here what is the the the the part the important part is that The important part is that the non-judge elastic band, it's a very, I mean, traditionally, we don't use it when we are searching for transition states in molecules because it's very expensive. I mean, if you ask someone who has really an expert looking for transition state, I mean, studying a reaction mechanism, they will tell you, yeah, it's a good approach, but it's very expensive. And they are correct. If you do that with DFT, you are, you are really, it's very, very. You are really, it's very, very expensive. But if you, and this is something that we did, we ensemble the nodiet elastic band that is available in the atomic simulation environment in ASC with ANI, and we use this environment to obtain the energy as a function of this collective variable. And also, for all the points that you will see, we did single-point calculations with. Single point calculations with a PBE, PB0, and that basis set to analyze using Schubin's energy decomposition analysis. That was very nice discussed yesterday in one of the talks. And also with the non-covalent interaction analysis, all that was done in multi-double multi WFL. Multi-WFA. Which are the results very quickly? And this is the, I mean, when I saw the result, I said, wow, we're in business. One important point about this is experimentally, they can calculate the Gibbs free energy difference of all these processes. And again, look, these are not small. These are kilojoules per mole, but they are not that small, but. But they are not that big, also, right? So these are the experimental results for the assembly of the Rotaxan that you are looking at in the picture. This is what we obtained with Ani, with all this ensemble. Well, when I showed this to my colleague, you said, you are joking. I said, well, probably I was. But no, I'm not joking. This is exactly what we obtained. And well, the result is not that bad. Is not that bad. And well, then we decided to go: well, can we analyze the path? And that's the result. Well, what I want, the message that I want to give to you is, and this is my second message, is together combining this climbing image Nodget Elastic Band together with a good machine learned. A machine-learned potential, which in this case is Ani, you are able to obtain what we believe is a very good representation of how the energy changes in this very subtle, very delicate processes of molecular ensemble. One point, none of these systems, I mean, this is when we started this, I said, well, let's do it. This, I said, well, let's do it and let's see if it works. None of the systems that we are considering were considered as part of the training set in Annie. That's one point. And the other point is Ani is trained basically to describe minima, not to describe maxima, and we are obtaining transition states. How can we explain that? The reason is. Is, and that's the analysis. I don't have time to go into the details, but the reason is that what is producing the interactions that are responsible for the creation of the maxima in all these threading and dethreading processes are only no covalent interactions. And you can see here, all these surfaces are telling you that they are indeed no covalent interactions. Are indeed no covalent interactions taking place in the assembly. And well, it's difficult to see here, but actually, no covalent, the analysis also tells you that there are some hydrogen bonding points which are crucial in this process. But Ani, since you are not breaking chemical bonds, if you break bonds with Annie, you are out of business. But if you are breaking You are breaking and creating weak chemical bonds, let me call it non-convalent interaction bonds, and it works. And that goes are good news because then you can do a lot of analysis with this for systems larger. We have applied for more systems than this. And finally, to tell you is that we have doing Schubin's analysis, energy decomposition analysis, it's perfectly. It's perfectly online. I mean, remember the composition that was presented yesterday. The energy has all these components: the steric, the electrostatic, the quantum, and you can plot it as a function of the molecular path. Notice that, for instance, the steric, which is the green line, notice that in point 220, which is the point, the minima, the minima. The minimum point at the right. Notice that it's telling you that that's a point where the electrostatic, the steric energy is more, it's stabilizing the system. It makes a lot of sense. It makes a lot of sense. So we believe that this explanation is in the right direction. Well, we have also done the detrading. I'm going to finish with this, trying to analyze the static effects. As you can see, Effects. As you can see, it also works. Let me see if it moves. Yeah, it moves. Pay attention to the first number on each block, the EP out. That number, if you compare it, if you associate it with the size of the phenyl ring, notice that it has a lot of chemical sense because the number with the largest value corresponds to the fen. Corresponds to the fennel ring with more steric hindrance, with more, more, more, that is larger, bigger, let me say. And that makes that the barrier is higher and therefore it's more complicated to take away the torture. Okay, with this is basically finished. These are my messages. I think, well, I was not convinced about. I was not convinced about with machine learning, I was not convinced. I mean, as you can see, my history is analytics and mathematics and non-empirical. I said, no, no, if it is not like that, then it's not physics. But then we started this project. Then the virus appeared. So the virus was. appeared so the virus was in some sense good i mean it it it it obliged us obliged us to to to explore new new avenues and well we discovered what is written in this slide and we are very excited i think it is giving i mean unfortunately we don't have in mexico the the computer facilities that you have in china or in japan or in the states Or in the States. So we have, but we still love and we want to do good science. I think there are some good scientists in Mexico. And this gives us the opportunity to explore systems, which are complex systems, but reliably. I mean, I don't want to do an STO, a minimal basis calculation at hatrify level, which is meaningless, right? I want to try to present to the community. To the community, something that makes sense. And with that, I'm finished. This is the people who have been involved in the development. I want to stress the permanent encouragement of Sam and Jose Luis Gázquez. The work that has been presented here is mainly the work of the people in yellow, which are two postdocs and my PhD students. And of course, I want to thank the funding. The funding, the almost non-existing funding agencies in Mexico nowadays, but anyway, and you for your attention.