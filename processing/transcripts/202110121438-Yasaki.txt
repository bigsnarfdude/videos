Okay, starting good. Yeah, so what I'd like to talk about today is joint work with Governor Ash. I always love it when he contacts me to work on a project because I know it's going to be a lot of fun. So the basic idea here is given a real quadratic field, we're going to identify a stable subspace in the cohomology of SL3, or in the cohomology of a Of SL3, or in the cohomology of a congruent subgroup of SL3Z. And the basic question was just: what is that subspace? And how does that change as we vary the real quadratic field? And so what I'd like to do today is just be very, very concrete. And Andy presented a lot of these things, but I'm going to present them again. So, first, the players in the story here is the first one is the Tietz building. So, I'm going to fix the field K, and I'm going to look at flags of subspaces. And the vertices are going to span a simplex when they can be arranged in this way. And the Tietz building is homotopy equivalent to a wedge of n minus two spheres. Of n minus 2 spheres. And so, concretely, for n equals 3, if I pick three linearly independent vectors in k3, this is what the picture is going to look like. And so I have the one-dimensional subspace, subspaces spanned by V1, 1 by V2, 1 by V3. And they're contained in this subspace generated by V1 and V2, and also the two-dimensional space V2 and V3. V2 and V3, and the two-dimensional space V1, V3. And they're arranged in this way. And you can notice this. So this is n is 3, and 3 minus 2 is 1, and this is a 1 sphere. The Steinberg module is the reduced homology, so it's the only interesting homology that's going on in this situation. GLNK is going to act on subspaces, and so it's going to act on these simplices, and so it's going to act on the Tietz-building. Is going to act on the Tietz building, and so it's going to act on the homology. And you can extend this definition by replacing Q by any ring R, but we don't need to worry about that. So the next ingredient here is modular symbols. And so this is due to a theorem of Ash and Rudolph in the late 70s. The Steinberg module, you can think of it as generated by n to the n. It is generated by n tuples of vectors, vectors in kn, subject to relations. And so if the vectors don't generate kn, then the symbol is zero. It behaves well with respect to scaling. By permuting the vectors, you pick up a sign. And then this last one, this item four, for any non-zero vector x, you can sort of introduce it in various slots. In various slots. And we'll call this fourth relation passing through x. And so this is going to show up again later in the talk. So the symbol v1 up to vn is equal to the sum of the symbols where you just insert this x in every slot and add it up. And the Steinberg homology for gamma, so gamma is going to be our congruence group, is just the homology of gamma with coefficients in the Steinberg. Steiberg. This is stable under head operators, so these are the double coset operators that Adner mentioned in his first talk, or in his talk on the first day. And for people more, I guess, in my realm, this is interesting, for example, when R is C, because it's computing weight to modular forms. And more generally, in other cases, we'll have relationships. We'll have relationships to number theory, to arithmetic things. And I'll mention some examples at the end. So this has also been mentioned several times in the conference so far. I'm going to mention it in the context that I need it for the talk today. So this is the theorem due to Burrell and Sayre that the homology, the Steinberg homology, is going to give us the group cohomology. Is going to give us the group cohomology in a shifted degree. So nu here is the cohomological dimension, and the homology in degree i is going to give you the cohomology in degree nu minus i. And so here nu is n times n plus 1 over 2 minus 1 minus n minus 1. And I've written it out this way, just so that I remember how it goes. For me, all of these computational All of these computational techniques come from viewing the symmetric space as living in some cone of positive definite symmetric matrices, and so that's the n times n plus 1 over 2. I'm going to mod that out by homothety by scaling, and so that's the minus 1, and then I've got to take off the q rank, and so that's the n minus 1. The zeroth-Steinberg homology, and that's what we're going to be focusing on in the talk today, you can identify with a co-invariance. Coinvariance. And so, in work in 2018, Abner showed that there's a filtration of the Steinberg for Kn that's stable under the action of GLNQ. And so how does this filtration work? You take the span, the Q-span of the symbols, A1 up to some A sub n minus M, and then B1 up to BM, where the AIs. Where the AIs live in Q to the N, and then the BJs live in K to the N. What is capital K big N? K. Well, so at the beginning, K is just some number field. Eventually, we're going to specialize to K, and I'll change the name to E to remind myself it's a real quadratic field. Oh, so I'm comparing like Steinberg of some other number ring to a Steinberger Q. So we'll hear it. Yeah. And this is showing a predictor that these are not irreducible. Like if you restrict it to SLA. Irreducible, like if you restrict it to SLNQ. Yeah, right, yeah, yeah. SLNQ. Yeah, and so we have this filtration. And something he shows in the filtration is, well, these modular symbols, you can always arrange that. The representatives have this form where the B's are pure. So pure in the sense that if I take the span B1 up to Bm, B1 of the Bm, call that subspace W, then W intersect QN is just the element 0. Can you go back to the previous slides? I can remember what the context is. Yeah, okay. So the A's are in Qn and the B's are in Kn. But in terms of the filtration, you can always arrange that the B's are pure. Nice. And so then it's just a very concrete, simple. So I'm going to, Andy did some linear algebra. Andy did some linear algebra. I'm going to also do some linear algebra. Mine is going to be 2x2 matrices and 3x3 matrices, but here it's a little bit more general. But if your number field is degree D, and then you just think about vector spaces over Q, then the space W, which is dimension N, or the space over Q, that dimension plus N has to be less than or equal to D to the N. than or equal to d to the n. And so the k dimension of w is bounded by dn minus n over d. Right. And so for us, what we're going to do is we're going to set n equals 3. We're going to be looking at congruent subgroups of that cell 3. Here I'm changing notation to remind myself here I'm specializing to a real quadratic P. Peter has a question. He says, is that span over Is that span over Q? And possibly its previous slide. Yeah. So, stay sat again. So, W is the K-span of these vectors. So, it's a subspace of K to the N. And then I'm going to intersect that with Q to the N and just get the zero vector. But then here, in order to get the bound, I'm doing everything as vector spaces over Q. Does that answer your question? I can hear you, no one else can hear you. Or no one else in person. I guess Pierce is confused how a k vector. Or if you type it in chat, I can read it verbatim if you want. Verbatim, if you want. It's too hard to pop up chat on that computer, though. Maybe just carry on. Okay, yeah. We can talk about it after. Right. And so if you fix n to be 3 and look at k being a real quadratic field, so I'm going to change the notation to e. And so I'm going to change the notation to E to remind myself it's a real quadratic field. Then the degree of the field is 2, and this D times n minus n over D is 3 halves. But it's supposed to be an integer. And so what that's telling you is in this filtration, F1 is F2 is F3. And so the filtration really is just Steinberg of Q is F0. And then you have the F1, which is Steinberg of E cubed. So I guess that should be a Q cubed here. Here. And so we have this inclusion of Steinberg of Q cubed going into Steinberg of E cubed. And this gives rise to a short exact sequence. And so then we get a long exact sequence in homology. And so we're going to let H gamma E, so it depends on this fixed real quadratic field E, be the image in H. In H0 of gamma with coefficients in the Steinberg of this connecting homomorphism. And the goal when Abner approached me with this was just, what is that image? Is it always zero? Is it surjective? Does it depend on E? How? And so we just want to investigate this object. So the computational tasks, right? So the computational tasks are first we just need to describe C sub E in just explicitly. What is C sub E? Can we go back to the. Yeah, so it's coming from this short exact sequence. So we need to describe everything explicitly enough because this is going to be a very concrete talk. Yeah, this is going to be a very concrete talk. Uh everything's going to be concrete and explicit. We had to tell a computer what to do. And so task one was to describe the C sub E as a direct sum of induced modules, but then we needed to use that to describe the homology in order to describe the map psi explicitly. We're going to use one and two to describe what the vectors are in this image. And then we're going to compute and see what we get. And I'm going to focus on 3 and 4 today, because 3 and 4 are the sort of gory, explicit things, but elementary. We need some more ingredients here. Here's some of my linear algebra. So a 2 by 2 matrix H in G L 2Z is called unital. If H acting on the 0, If H acting on the line beta 1, on the projected point beta 1, is beta 1 for some beta that's purely in E and not in Q. And then for this unital 2 by 2 matrix H, we're going to introduce this 3 by 3 matrix in SL3C. By putting the unital matrix in one corner, epsilon is going to be chosen so that the matrix has determinant 1. Determinant 1. And then u is any vector in z squared. So I've colored that in red because this is one of the ingredients that's going to go into explicitly computing. It's easy to check that this 3 by 3 matrix has eigenvectors beta, 1, 0, the Galois conjugate, and then this third vector you can normalize to be A1, A2. You can normalize to be a1, a2, 1. So this third vector a, I'm also coloring it in red because this is going to show up in the computation. And then if p3 is a stabilizer of the plane that looks like this, L is just an explicit finite list of representatives of this double coset space. And so these are the ingredients that go into the computation. Go into the computation. And so the theorem is that h gamma of E is the Q span of the symbols that have the form F, gamma F, and D times A, where I've colored again in red the things that showed up from the previous. Right. So F here. So, F here is the first column of D. D was one of those explicit representatives of the double coset. Gamma is the smallest power of the conjugate of that M matrix that lies in the congruence group gamma that we're looking at. And then this A is that vector, not the beta 1, 0, and not its conjugate. And so this is a very explicit description that's coming. Very explicit description that's coming that's describing the image that we need to see. Sorry, I got this lost attention. Can we say again what H gamma E was? H gamma E is the image in H0 that's coming from this connecting homomorphism. From the long X X. From the long X X X, exactly, yeah. And so it's this image sitting in the And so it's this image sitting in the homology for a congruent subgroup of SL3 that's sort of tied to this real quadratic field E. And the goal was just, you know, what is it? Okay, so this is a theorem that, yeah, so now that the game becomes compute a bunch of those vectors, see what they are, see what they generate. And so the computational task. And so the computational tasks here are we need to find those unital H's, those 2 by 2 matrices that sort of stabilize lines beta 1, where beta is purely in the quadratic field. Then we're going to compute these symbols, f, gamma, f, and d times a. We want to understand the image as a Hecca module, and so we're going to understand the HECA operators on them. And the HEC operators on them. We need to represent the homology in a computer. And so this is the way I do this is through Voronoi. And so I'm not going to talk too much about Voronoi today. But there is a way to put this computation on a computer in terms of configurations of minimal vectors of quadratic forms. Right. Um right. And so then we just compute what that image is using these these modular symbols. And so first, here's my linear algebra with 2x2 matrices. How do you generate a bunch of unital H's? So a 2x2 matrix H is going to be unital if, when it's acting on an actual vector beta 1, it's going to be a unit in E times. In E times the vector beta 1. And so this turns out to be what you want to do is find a bunch of 2 by T matrix in gamma that have the property that the minimal vector is the same as the minimal vector of that unit. And so we're in a real quadratic field, and so you have this fundamental unit, and you start looking at plus minus powers of it, you get these minimal polynomials. And so if I look at the unit, Polynomials. And so if I let f of x be the minimal polynomial here, what do I need to do? Well, I just find a root of f mod n, so call that d, and then I can arrange this 2 by 2 matrix. And so computationally, the idea here is we're going to fix, we're going to try to push the computation as far as we can go with various values of n. With various values of n. And so we're just finding roots of the minimal polynomial mod n, lifting that to a specific integer d, and then constructing this 2 by 2 matrix. Yeah. Why does the expression at the bottom for h not depend on beta? Right. So the I guess the idea here is If I construct a matrix H like this, this H is really tied to eta, and there exists a beta that is in the real quadratic field such that this is true. And so it turned out this was an easier way to generate the unital matrices than sort of varying beta and trying to find a unit. Right. And so if you look at Right. And so if you look at this 2x2 matrix and you're thinking about, oh, I have to generate lots of them. Well, it's not that bad to find roots of f mod N. So those are integers D. You lift those up to actual integers D. But then you have this F of D that still needs to be divisible by some integer C. And so F of D might be a huge integer, and then it turns into a factorization problem. And so the actual implementation of this, this part of it, Of this, this part of it, there were some things where if the f of d was too big and factoring was too hard, then do trial division up to some point and then give up. So there's, yeah, lots of silly tricks, but you can generate lots of unital H's. Now I want to say a little bit about the HEC operators. And so these are Hec operators for congruent subgroups of SL3Z. Of SL3Z. And so now, if you're used to seeing HEC operators like TP, now there's sort of two flavors. There's a, or T L. There's going to be a T L1 and a T L2. They're coming from the double coset for the matrix 11L or the matrix 1L. You can decompose the double coset explicitly and get a list of these matrices. And then the way These matrices. And then the way that these H's act, so these H's are not those unital H's, these are just representatives for the double coset. The way the H's act on the symbol is just it acts on each of the vectors. And then I've got to understand that image in the homology. And so the problem that we get, so let me go back a little bit. So the problem that we get, right? The problem that we get is in the computer we have the homology described in terms of unimodular symbols. And so these are going to be triples of vectors with determinant plus minus 1. And these double coset representatives, these h's, have determinant either l or l squared, right? So definitely not 1. And so it's going to take this triple, this unimodular symbol that we know and understand, to something that And understand to something that is not unimodular anymore. And we still want to understand its image in the homology, which we have represented in the computer in terms of unimodular symbols. Right. And so we need a way of expressing non-unimodular symbols in terms of unimodular symbols. And we also need, I mean, this is also going to solve our problem of expressing. Of expressing the f gamma f dA from the theorem in terms of the basis that we have in the computer. And the solution is this passing through x. So the idea is if I have a triple w1, w2, w3, that's not unimodular, then its determinant has some size. Maybe I can cleverly choose x, pass it through, and get a sum of three things. And get a sum of three things of smaller size. This is how Ashruno does it, right? Yes, yes. So that's this. Well, so what we're actually going to do, or what I actually did, so this is Vengean, Van der Kohlen talk and Berkmos generalizing, or using some ideas of Ash-Rudolph, but choosing that special vector x in a different way. Right, yeah. So here's the idea. Here's the idea. Here's my linear algebra with 3x3 matrices. If I have a 3x3 matrix, so the w1, w2, w3, these are integer vectors, and its determinant is positive. So what is that going to mean? Well, that means that the determinant mod m is 0. So I can find some vectors in, or some scalars a1, a2, a3 in z mod m. In Z mod M, so that it's in the null space of that matrix mod M for some integer M. And so that's a, if I denote reduction mod M with a bar, right, then I'm saying that I can solve this explicitly. But then what I'm going to do is lift those a1, a2, a3 bars to actual integers, a1, a2, a3. It's supposed to be 0 mod m. So that means a1, w1 plus a2, w2 plus a3. Plus a2w2 plus a3w3 is actually divisible by m. And so I'm going to divide that vector by m and get an integer vector x. And this is the x that I'm going to pass through. But there was this lifting that happened, right? So lifting from z mod mz to z. And in order to make sure that the determinants shrink, I'm going to lift it to a's that are between minus m over 2 and m over 2. I'm going to lift them to small representatives. I'm going to lift them to small representatives. But then, I mean, determinant is linear if you freeze all the rows but one. And so the determinant of x, w1, w2, or x, w2, w3 in absolute values, you just pull out this a1 over m. And because of how you chose the representative, that's bounded by a half times determinant a. And so all the determinants. And so all the determinants, once you pass through x, are smaller by at least a factor of 2. In practice, it's a lot better, but at least a factor of 2. And then you just repeat. You get this sum of symbols. If anyone's, whether determinant is plus or minus 1, it's good, we like it. The determinant's bigger than that, then we just pass through a better x. Seems like this gives you a really nice bound for how, like, if you have a Bound for how, like, if you have a non-unimodular symbol for the number of unimodular symbols you need to have, and it's like some logarithmic bound, just each time you cut it in half, you double the number of symbols or triple number of symbols, or whatever. Right, yeah, yeah. Okay, so now I want to change gears a little bit. So, this is and talk about the boundary and interior cohomology. So, this is work of Lee and Schwermer. So this is work of Lee and Schwermer in the 80s, in the early 80s. And so the symmetric space for SL3, this is a five-dimensional symmetric space. And I'm going to take X to be the Borel-Sair vortification, the compactification. And T is going to be the T-building. The interior cohomology is the kernel of the restriction. Is the kernel of the restriction map going from x to the homology of x, the cohomology of x to the cohomology of the boundary? And what they say is you can describe it as an A plus a B. The B is coming from the homology, it's coming from the homology of the Tietz-building mod gamma. And the A is sort of, it's coming from maximal pair of. Coming from maximal parabolic subgroups. And so, what we get in the end is this Hecke equivariant decomposition. So, the Hecke operators that we talked about are going to stabilize these spaces into sort of this interior stuff, this A stuff, and this B stuff. I guess R doesn't need to be surjective, so when you remove the primes, that's just the image of this. Just the image of this. Say it again? So I guess R is not surjective, and then so the bottom line you have A and B without the prime. So I guess is that the image of R or something like that? So the bottom line is A and B, not A prime and B prime. So is that supposed to be just the image of this map R into A prime plus B prime? So yeah, the A and the B are the things in H3 that Three that the things, the pre-image of the A and the B in the under the automatic. Okay. Yeah. The pre-image. Okay. Peter asks if it's surjective when N is three. If it's surjective when N is three. I don't know. I don't know this part so well. And maybe if Avner's in the audience, he can answer. Or Schwarmer. Anyway, so here's the conjecture on that image, on that H gamma E. And so this is a conjecture based purely on what we saw, purely on computations. On computations. One is that the image is this interior cohomology plus the A part. And two is just a statement about the dimension as the difference in the dimension of H3 minus H upper 3 minus the dimension of the torus mod gamma. And so a few comments. One implies two. 1 implies 2. 2 came first. So we just computed the image and found lots of numbers. And Aubner said, hey, can you check this? But then once we had these images, we actually tried to start computing HEC operators on the images and saw how it was decomposing in terms of the A and the B. So this was formulated. So, this was formulated based on just numerical experiments. We did gamma0 n for n up to 50. So, we can certainly push n much, much larger. That's not such an issue. So, we did n up to 50 and then the prime n's up to 100. And then just to see a few more, we did the prime squares, 11 squared and 13 squared. For the real quadratic fields, we did just a selection of real quadratic fields. But I guess one of the important things that we're going to do is that we're But I guess one of the important things to notice here in the conjecture is the right-hand side, there's no dependence on E. Good. Okay. So what did the Hecca analysis look like? So Abner touched on this on the first day. So we're going to be finding these. So we're going to be finding these, we're going to be computing these Hecke operators on the cohomology of gamma. And then for each eigen class, we can think about constructing this Hecke polynomial. And maybe the reason for looking at these Hecke polynomials is to try to attach them to, attach each Hecke eigensy to a Galois representation. And the way we say that That the eigenclass is attached is if the polynomials match. So, this Hecapolynomial that we construct, if that's equal to this determinant of 1 minus for Benius. And this is how we're gonna sort of identify pieces coming from B and pieces coming from A. Coming from A. So this is work of Ashe and Stevens in the mid-80s. If I'm looking at the B component tensored over Q with C, then the Galois representations that these are attached to are coming from sums of characters, of levels dividing N. And the A part is attached to a direct sum of a Diersley character conductor again dividing N. Conductor again dividing n, and some odd two-dimensional representation coming from GL2. And so we can compute very far the holomorphic modular forms of weight 2. And so this gives us a way of if I have an eigen class and I can compute Hecke operators, then I construct these Hecke polynomials and then I try to identify the Galois representations it's maybe attached to, and then I just see. Attached to, and then I just see, well, is it an A type or a B type? And so here is an explicit example. Here's our explicit example. So gamma we're taking to be 11 squared. If you go and you compute the cohomology in that case, you get this 29. In that case, you get this 29-dimensional thing. Abner mentioned, you know, computing heck operators is a nice check on computations. And this is a prime example of such a phenomenon. If I just throw things on a computer and compute this 29-dimensional vector space, I don't know if it's right. But then if I can go and compute, I don't know, 100 hec operators, these are going to be 100 29 by 29 matrices. Matrices, and if I can simultaneously diagonalize them and look at the simultaneous eigenvalues and they match up to Galois representations, then I'm pretty sure that the space I computed actually was correct. And so this is the sort of check that we can do. When you compute, it's not always correct the first time. Signs are often tricky to get right. So we have this 29-dimensional space. 29-dimensional space. In this case, after the HECA analysis, we conclude that the B part is 13-dimensional, the A part is 14-dimensional, the interior is two-dimensional, and the image is 16-dimensional. And so what I want to do is just show you what that looks like in these pieces. Can I ask a question? Is it typical that the B part or the A part are so much bigger than the interior part? Yeah, I mean, I think the interior part is sort of related to cuspital stuff, and it's more rare. Cuspidal stuff, and it's more rare. Yeah. Is that the thing that's always zero starting at n equals four in top degree? Yeah, so at least the cuspital range is supposed to be sort of centered at middle and has some width, right? And for SL3, that cuspital range, the top part of it, intersects. The top part of it intersects the V C D. And so that's why we can use modular symbols and compute things sort of in that have this interior stuff. So Ash, McConnell, and Gunnels, they have a series of papers where they're doing computations for SL4. And in there, the top of the cuspidal range is one below the cohomological dimension. And so they're looking one below. Right, and so here's the B gamma part. And again, we just computed Hecca operators simultaneously diagonalized and then sort of tried to identify things. So we have corresponding to the trivial representation, in which case the Hecca polynomial would just factor as 1 minus x, 1 minus Lx, and 1 minus L squared x for the T L's. There was a 12-dimensional space. There was a 12-dimensional space coming from Dirchley characters, and they came sort of in this way. If you look at the Dirchley characters of modulus 11, there's a subgroup, a cyclical order 5 subgroup. And so there's four elements of order 5. Each of those four characters gives rise to a three-dimensional space with hecapolynomials sort of showing up like this. Showing up like this. And so if the character is chi, then you get these three heccapolynomials. And so then the 12 plus 1 gives us that the b gamma is 13 dimensional. And I guess I should mention that I'm lying just a little bit when I say that the eigensystems that we computed are sort of attached to these Galois representations. We can only compute out so far, right? And so we definitely can't compute. Right, and so we definitely can't come to you far enough to verify, but for 50 eigenvalues, if it matches, then I feel okay. Right, and so here's what the A gamma part looks like for this case. So I'm looking at G L2 new forms. So the GL2 level is one. Level is 121. Each of those is going to contribute a two-dimensional space. And so in what way is it going to contribute a two-dimensional space? Well, I'm going to have the eigenvalues AL1 and AL2, and eigenvalues BL1 and BL2. And they were related in this way: that AL1 was BL2, and it was just. L2, and it was just the AL plus L squared, where AL is the Fourier coefficient or the Hecke eigenvalue for the GL2 form. And then on the other side, it was AL2 was BL1, and that was just L times AL plus 1. And so what that tells you is that the Hecke polynomials are going to factor in this way. You get two of them, one for the A and one for the B. A and one for the B, and you see it popping out as a characterplus two-dimensional. And so each of the four new forms at GL2 level 121 contribute this two-dimensional space, and so we have this eight-dimensional contribution. And then we can look at GL2 old forms. So there's like the GL2 form at level of The GL2 form at level 11, the new form at level 11, and it's going to contribute to the SL3 at level 11 with multiplicity 2 in this way. And so then it's, as a GL3 old form, it's going to contribute that with multiplicity 3. And so this matches with This matches with computations of reader in his old forms on GL3, or on GLN. So we have the old forms contributing dimension 6 and the new forms contributing 8. And so the A gamma was 14 dimensional. And then the interior stuff, what was it on the interior? So at At level at GL2 level 121. So there were four new forms, A, B, C, and D. A and C are quadratic twists of each other. B ends up not contributing here because it has CM and so it's not going to be this interior stuff. But then these are going to contribute sort of as these symmetric squares. So the AL1 is going to equal the AL2, and that'll be the eigenvalue for the GL2 form squared minus L. And as I said, the GL2, like the A and the C, they're quadratic twists of each other, and so when you do the symmetric square construction, they both contribute the same thing. Contribute the same thing. And so this contribution of three symmetric squares only contributes two-dimensional to the cohomology. And so the interior is two-dimensional. And so this was sort of a separate computation, just a Hecca analysis on the cohomology. But then you also do the construct the image explicitly using the theorem of the F, the gamma F and the The gamma F and the D thing. And you see what subspace of the cohomology did it generate. And it actually did generate the interior plus the A. And so the 29 minus 13 is 16, which is 14 plus 2. And so I think I'll stop there. Thanks. Are there any questions? How surprised were you that it doesn't depend on E? Well, so this is the second part of a bigger project that Adner and I are working on. And the first part was we were looking at the n equals 2 case with a real quadratic field. And there, we were able to prove that. The dependence on E was was integrally not rationally, and so not super surprised, I think. And so do you think it's going to be the case also here? Here, we didn't try the integral calculation because echo, yeah, sorry. Yeah, I think there is probably subtle dependency. I think there is probably subtle dependence on the quadratic field, but you're not going to see it at the level of once you invert enough things, I think. But like I said, this was the conjecture, as far as I understand, and Abner can correct me if I'm wrong, the conjecture is, I have no idea why it's true. We computed a bunch of things, and this is what we saw. I would be very happy to see some more argument about why we could have predicted that ahead of time. Could have predicted that ahead of time. Peter's asking if we could see the definition of A and B again. They may have enabled people on Zoom to talk. I don't.