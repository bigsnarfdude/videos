I would like to thank you all for the work in the toroidal algebra field. So we will see, I mean, this conference, you will see how much different directions it takes to study quantum toroidal algebras. And so let me just tell you that trying to prepare for this talk, so I went this morning to the computer and I searched. I just put there the word quantum toroidal algebra, like this. Algebra like this, quantum toroidal algebra. And you can do it using, I guess, this Wi-Fi. And the answer was, I got 104,000 hits. Thank you for thanks to you all. And then I decided to compare. And so, what do you think I did? Next, I did. Next idea thermal last theorem well actually the number is wrong. Should we get the correct numbers 109 and here it was 142,000 all right, so we are slightly behind. Hopefully after this conference we will jump over but I mean to be fair this one is well, I mean this comes from Fermat Well, I mean this comes from Fermar in what 1650s So around 400 years of I mean a lot of time and this one okay comes okay the very first one was this famous paper by Ginsburg Campranov and Vicero and it was what 1995 less than 30 years Eric less than 30 years ago so I mean So, I mean, we are doing quite well, and hopefully, yes, we will take over, and quantum theoretical algebra will be more important than thermala's theorem. So, also, I would like to say that now, since so much work has been done, there are excellent surveys. And so, I would recommend to you this survey, which is also done with the help of our participants. And so, this is just Matsur, Navata, Nashita, and Ju. Noshita and Zhu. So, this is about 200 pages survey on the quantum of fine algebras. So, we have it, so probably distribute. And so, you can learn a lot of things about this quantum toroidal algebras. And again, I mean, this is kind of surprising how many things really come here. The starting point was geometry, okay, some Heck operators on some bundles, on some algebraic surfaces. Surfaces. So, but then it became, I mean, this was geometric intuition, geometric motivation. Then algebra kicked off. I mean, connection to the Magdon polynomials, duality to the double-affined Heke algebras, representation theory, beautiful, leads to some combinatorics. And then all these integrable systems come around: string theory, gauge theories, topological quantum field theories. Series, this topological vertex. I mean, everything comes together in toroidal algebras, and so I'm sure you'll hear a lot of talks about all this business. And for me, okay, my last surprise about toroidal algebras is how analytic it becomes. I mean, okay, I have algebraic background, and so normally I try to do things algebraically if I can. And of course, toroidal means, okay, you have to do something more than just algebra, you have to do some analysis. This is this is a This is this is okay, this is fine. But it turns out that it becomes too analytical for at least for me to digest, and that's what I'm going to try to report to you today. So, some analytic developments in this area. Okay, so let me start my talk now. And so, for me, again, this is such a great audience. I'm very much enjoying it because, okay, I just can say EN for me, this is just an algebra. For me, this is just an algebra, quantum toroidal algebra of type GLN. And maybe I don't have to give relations in this audience or generators, so I don't have to write all these things. So this is just quantum toroidal algebra of type GLN. So, okay, if you can put it like this, and it depends on three parameters or two parameters. Okay, we always have q1, q2, q3 equals to 1. So, as always, like this, and maybe the only thing. Like this. And maybe the only thing I should mention about this algebra is that the relations are written in terms of these exchange functions. So there are these functions g, z, and w, which governs the exchange among generators. Okay, for example, for n equal to 1, this is a very famous cubic function. So this is like this. This is z minus qi w. I goes from 1 to 3. So it's a cubic polynomial. And if you do like quadratic relations for each generator, so F generator. For E generators, or F generators, or FK generators. So, this is the main ingredient in there. So, this is just the algebra itself. And now, what is my interest to this? My interest to this is a system of what is called XXZ type. And these systems are very standard for the algebras, which are quasi-triangular Hop algebras. So, this is an example of such an algebra. In particular, it has this armatics. So, you can write it as a d infinite. So, you can write it as a DINFIRI double. And so, it has an R matrix. Well, this is an element in some completion of EN and EN. And so, the existence of this, okay, maybe I should say, yes, actually, none of my collaborators came, unfortunately, so I have to say some names. But anyway, this is not my collaborator, unfortunately. So, Andrei Negut, I mean, his work, I mean, he showed that this is a rinfill double, and so there's an R matrix. So, okay. Matrix. So, okay, there are many technical details which I'm going to skip throughout the talk. I mean, you all have computers in front, you can get the correct formulas and correct statements maybe from your computers. And of course, this aromatics depends on what kind of multiplication you choose and other things. But nevertheless, this aromatics is nice Young-Baxter equation. And so, therefore, what I can do is I can form what is called transfer matrices. So, transfer matrices, so transfer matrices is just So transfer matrices is just traces of R. So you just take transfer matrix. And this transfer matrix depends on two things. It depends on V, and so V is EN module. And it has to be some good module, otherwise the transformatics will diverge. And then it depends on some parameters P. So these are boundary parameters. And so the formula is just like this. You take trace with respect to the first component. With respect to the first component. So you take like this. So it means, so let me write it down and I'll say probably you all know this. So product, so PI, maybe minus lambda i here, and then you have R matrix one, two. So you have an R matrix, R matrix is an intenser product of two copies of EN, you act by the of E n, you act by the first, yeah, I have to write down here first. So you act by the first component of our matrix on the representation V and multiplied by some diagonal operator in this thing, which measures just the degree in this representation. And then you take trace with respect to V and you get some series which belongs to some completion of EN. And so this is called transformatics of GLN. Of GLN with respect to representation V and boundary conditions P. So there are N, well, this is just a vector here, there are n parameters here, and so the main property is, the main property, and this is a very standard thing, very easy thing, comes from Young-Baxter equation, is that this algebra, if I put them all together, and so And so they all commute. So I will call it bet algebra, depending on P and this is inside of EN, is a commutative algebra algebra. And so this is a very standard thing in these X-type models. So we have such bad algebra, it's a commutative one, and so what we want is we want One and so, what we want is we want to act in some representation and we want to understand the spectrum of this algebra. We want to diagonalize it simultaneously and describe eigenvectors and eigenvalues of this algebra. So, this is kind of this is the question which you want to study. All right. So, if I want to study this thing, so there are several very standard things and non-standard things known about these things. And so, let me write it down. So, some known things. known things so the first thing is that well uh so first thing is that we actually can compute this explicitly so first thing is that we have explicit formulas for some transfer matrices or for Hamiltonians I will call them Hamiltonians so what are the formulas so what you do is you write So, what you do is you write this, okay, so first of all, it depends on the representation, and so what I'm going to do is I'm going to take a representation, which is a very famous representation. This is called Fokk representation. Okay, it depends on color, so mu is in zero up to n minus one. So, it also depends on some evaluation parameter, and so this is a Fokk module. And so if I take this transfer matrix corresponding to this Fokk module and so P so then it becomes a series in U inverse and so I can write it down as a series from M equals to 0 to infinity and then capital M here u to the power minus M and then I have here G mu mu m of p so these are integrals of motions which I'm saying they have a formula so the formula I'm skipping some details here but this is a big integral so it's it's many integrals so the number of integrals is m times n so this is the number of integrations and so it looks like this you have here a product of say f1 first F1 first x1a then I have so a goes from 1 to m then I have product of F2 X2A A goes from 1 to N and then so on you have F n X N A product A goes from 1 to N and then you have some kernel kappa it depends on so Uh it depends on, so there are different, it depends on this mu. Uh it depends on all these parameters xi a. And then you have to integrate with respect to all these parameters. And the integral is like this. So if you have q1 and q3 are small, then integration contour is xia r on the unit circle. And so, okay, this is a big. And so, okay, this is a big formula, and I didn't tell you the kernel. The kernel is given by a suitable product of theta functions. It can be written explicitly, and in fact, this kernel is a pretty remarkable function by itself, which deserves maybe a separate talk. But, okay, I'm not going to write down here. The fact is that we can write out these integrals explicitly. Well, if you call it explicit formula, I mean, if some integration here, but still. So, vis-à-vis a. So we say visa visa Hamiltonians written explicitly. The next fact is that we actually can describe the spectrum of these Hamiltonians, and it's called Beta Anzatz. So the Beta and Zatz the Beta Anzatz says this. So now I take these Hamiltonians and now I act them in some other representation. them in some other representation of toroidal algebra. Well, other means I take again a Fokk module, but now I take a different Fokk module. So I will take rotated Fokk modules by 90 degrees. So by Mickey automorphisms. Okay, I really have to mention Mickey here somewhere. So there's a Mickey automorphism which changes generators to the perpendicular ones. And so, okay, I can take this and act there in a tensor product of Fog spaces. Tensor product of Fog spaces. And so then the answer is: I mean, how to describe the spectrum? And so the spectrum is described by Bettanzatz, namely, you do this. So if V is highest weight module with respect to opposite generators, maybe tensor product of Fox spaces, and if psi, well, psi 0, psi n minus 1, so this is the highest weight. Weight of his module of V. Then you can write down these standard equations. So you take TJI. So these are auxiliary variables, rapidity, so beta variables if you wish. And I is the color from 0 to n minus 1, and J, depending on how deep you have to go to the modules. And then you have this. Modules, and then you have this system of equations, which again, roughly speaking, looks like this. You have this PI. Well, this is almost the same PI as there. There is a small correction by some power of Q, which I'm again not going to write down explicitly. And then there is this psi i of t j i. So this is the highest weight. And after that, you just do this product J Tji Tj prime i prime divided by Ij ji tj prime i prime tji equals to minus one. So again, so there are some details, but but anyways, this is just some product, and so this is the system of semi-algebraic equations for the variables tji. The variables tji, and the standard Bethanza says that if you solve this equation, then solutions of these equations parametrize eigenvectors of the Hamiltonians. And you can actually write down the eigenvalue of those Hamiltonians. If you use Q character of this representation, you have to substitute their values of TJI in an appropriate way. So you can also do that. So this is the statement of the beta. So this is the statement of the beta answers and it says that for generic for generic P it should work. Well, at least physicists believe in that. And so, okay, I should here make some disclaimer. Okay, so with my collaborators, and so Boris Fagin and Michio Jimbo and myself and Mio Myself and Niva son. So we did, we proved it for n equals one, and actually there are two papers. One is using shuffle realization, another is using something else called Baxter equation and so on. So we proved that this works for n equal one. And I should say that general n is not written. However, the statement is rather standard. The approach is unknown. Ah, yes. Yes, I should probably also mention Malika could. Malik, uh, Malik Kunkov and Kunkov Aganadich papers who did it for the affine Jankin case n equal one. Anyway, so we have to you have to do this for other ends and okay. Blame on us, we didn't finish it. So, no, it's some technical work, you have to do it. We didn't do it yet. But there is no doubt that it can be done, it should be done, not easy, but will be done. So, this is, I think, it's a fact, more or less, established. It's a fact more or less established, which we have here. Okay, so this is another thing. And the third fact which I would like to mention today is called duality. So what I can do is I can start with bosonic formulas. So what I do is I take m times n. do is I take M times N, so this will be E M E N duality. So I have M times N three bosons. Okay, I also take lattice of the size Mn so this is the lattice of the size Mn. And then if I have these three bosons, I can write down this big, big F, which is the Fox space for all these three of these boson algebra. So this is the Fokk. Algebra. So, this is the Fokk module. And then the statement is this. So, what I can do is I can take this F and define action here of algebra EM with parameters Q1, Q2, Q3 and EN with some other parameters. Okay, Q2 is the same, but Q1 is slightly different. Well, it's different. Slightly different. Well, it's different. So I can define this an action in the following manner. So, first of all, the action to define here, I want it in such a way that this becomes a tensor product of Fox spaces. And how to define, how to make a Fox space explicitly from the algebra EM is a well-known fact. Okay, so this is another participant which maybe didn't come here, yes, but this goes back to Seiter. Yoshihi. Yoshihita cite. And maybe also I should mention a cited Kimuro glove paper, so which was kind of the well, it was the start of this, and inside all the formulas I written. And so you know how to write it down. And so I can write these formulas. They are given by some vertex operators. And so after this, the statement is this. So my F will become. Yes, yes, yes, in a second. In a second. I will say it in a second. At the moment, no relations. So F is, so what? So first of all, F will be, so it will be some direct sum, and so over Zn, latest. And here it will be tensor product. So it will be something like this. It will be F and M, so it means Folk space over E M and there are some mu here. There are some mu here, and so and this mu depends on s. And then there is some evolution parameter here depending on s. Okay, there is some more details. This is just the shift of the degree and action of one extra central element. So this is not very important, but anyway, just you just do it like this, and you'll get so the point is that it becomes so if I So, if I'm doing it over SLM, EM, I'll get tensor product of N Fox spaces. So, this is direct sum of products of N Fox spaces. And similarly, if I decompose it with respect to the other direction, it becomes same thing. It becomes now fork space. Becomes now Fox space N. Here I have some, again, some new color, color depending on this S. So there are some explicit formulas. And now let me call this check. So different parameters, check of S, S, and the tensor product of M now. So UM check of S S. So you have these two actions and You have these two actions, and with respect to this, this is tensor product of n folk spaces, okay, sum of such things, and for this, this is tensor product of m folk spaces. So, okay, these sections do not commute at the moment, just nothing, just like this. But now, the statement is the following. So, suppose my parameters are related as follows. So, first of all, I take parameters. So, what are my parameters? So, I have q1, q2, and then Q2. And then I have these parameters P. So the P, remember, is coming from my transfer matrix. So I have P, P1, Pn minus 1. So these are my parameters, well, slightly changed by some powers of Q. And so these are parameters for M, for EM. So there are M of them. And then there are also U1. So in fact, only ray. U1. So, in fact, only ratios matter. So, I have these parameters: Um, UN over UN minus 1. So, these are my parameters which I have in the play. So, now what I'm going to do is I'm going to choose Q1, QCHEC, and so on in the following way. So, Q2 will be the same. It's always the same. And now, P check, so this is P for E M. This is P for E M, E N, so will be related to Q1 to the power M here, like this. So this will be equal. This will be equal. So here it will be Q1 to the power N. And these guys will be U1 check over U2 check, check, and UM check over UM minus 1. Check. And these guys will be P1 check, P2 check. P1 check, P2 check, PN check, N minus one check. So if I choose my parameters, left and right, related like that, then the statement is, so I have this now two red algebras acting, and the statement is that they commute. So I have B of P, so this is coming from EM, and I have B check of P. Have B check of P check coming from EN and the statement is that these guys commute as an operator in this big F space. So this is the duality kind of thing. So the algebras itself do not commute. Well, in fact, the affine part does commute, but the algebras itself do not. But our systems actually commute here. And so, this is again our work. Maybe I should write down, since my collaborators are not here. So, this is again the same, well, different paper, but the same Fiegen, Jimba, myself, and Niva. So, we have such a result. So, here I just should say that good or bad, I mean, this result, yes, yes, before I go any further, I should say that, yes, this result. I go in field. I should say that yes, this result is written like that in that paper, but certainly the starting point and many formulas from that paper appeared, at least in the case when n equal 1, appeared previously in this paper by Fagin, Kajima, Shiraishi-san, and Watanabe. So this is actually the paper where first formulas were written, and the proof of Formulas were written, and the proof of that is very analytic. You just have two C sets of integrals, you want to commute them, you have to move contrasts of integration somehow, you have to use properties of this Kappa function, and somehow you can prove it. And so, the bad part is, or some kind of we would like to, a wish which never came true is so since they are commuting, it means Since they are commuting, it means, in fact, as an algebras, they are more or less the same. It's an infinite-dimensional space, but we always restrict to finite-dimensional spaces. And so, what we want is we want express with G mu m and g check mu n through each other. So you have two sets of integrals, one acting on the left, one acting on the right, and uh And since they commute, I mean, every two diagonal operators can be expressed through each other if they have a simple spectrum. So we would like to express it, but we don't know how to do it at all. Unlike the affine situation. If I do such a duality in a fine situation, okay, in a fine situation, an analog of this is known for Garden models, for example, and this is my paper with Varchenko and Tarasov. So we know really how. So, we know really how to express one set of integrals through the others. Here, no such information, and we have absolutely no clue how to attack it because the proof was analytic and not algebraic like in this paper. Okay, so now what? So now what we want to do is we want to take the conformal limit of this. And so, the next thing is, so this is the known facts, and now let me try to use it for something else. And so, what I'm Else. And so, what I'm going to do is, I'm going to take the conformal limit of all these constructions. So, what is known is this. So, if I have this duality on the level of quantum fine algebras, for example, and if I take the limit, appropriate limit, then what I can do is this. So, I have this algebra, say uq G hat. G hat and then if I do the limit, so I can get Janian of G hat, of G and on the other side I can get what is called trigonometric Gaden and so under such duality so you have two models which are both x type, but when you do the limit, one of them produces But when you do the limit, one of them produces the Youngian model, which is called XXX, not very politically correct, but XXX model, and the other one produces the geometric Garden model, and what you obtain, you obtain duality between those two. And so what I would like to do is I would like to do the same here for this system. Okay, so now. And so, and if you do it. And if you do it, things become interesting. So, first of all, this limit corresponds to the following things. So, Qi goes to one. So, all Qi go to one, but you keep the relation Q2 equals Q3 to the power minus R, I think. Yes, and because of that, yes, and also UI goes to 1. And so, because of that correspondence right there, what we know is that p check should go to one. And well, in fact, I'm doing the opposite way. Yes, yeah. Sorry, no, also p goes to one. This is one more, and p i are fixed. So, this is the limit, this is called the Jungian limit. Limit and so you can just do this. And so, according to this identification, the opposite limit is what? So, the opposite limit, QI check go to 1 and PI check go to 1, and P goes to 1, but UI check affixed. So, these are the two limits. So, this is for EM limit, and this is for EN limit. And this is for EN limit. So I'm doing it at the same time, and the question is, what do I get? And so, what I get is very interesting. Well, first of all, it's very difficult to do it because these integrals, which is which I am saying, which I am writing here, if I try to do this limit, these integrals have contours which are pinched. Because there are many residues, and when you try to do this limit, q goes to one. So there is a lot of pinching, and it's very. So there is a lot of pinching, and it's very difficult to see what happens to those integrals. However, at least in this limit, well, and so yeah, maybe let me just now concentrate to the case which I like very much. So this is the case m equal 1 and 10 equal 2. So this is the case for my applications, which is most important. And so what I want to say is that at least in this limit, I can take the first. I can take the first one here. So this is, well, one and one. Well, actually, one and even, yes, one and one. So if I take this one, so this is the first integral, I can compute the limit of that. And the result is some very nice expression, which is called intermediate long. Which is called intermediate long wave Hamiltonian first, and this is a paper by Litvinov and also with Mariko Kunkov. They have this Hamiltonian there. So anyway, this is some limit. And this is the limit when P is not one yet. So I have this P has to go to one. And if you go any further, P goes to one. P goes to one, then from that you get what is called one q k d v Hamiltonian. And so this is what I want to explain now. So the limit of the system produces a new system which is called quantum KDV. And quantum Kdv Hamiltonians, these are Hamiltonians given by integrals of local currents in Verasora module. Currents in Virasoro module, in Virasora theory. So if I have Virasora module, Virasoro algebra, so inside of that, there is a beta algebra for Virasora. And the first is L0, just the zero mode of Virasora current. And the second one is just the integral of L squared of Z. So this is the second current, and then there are more. So there's an So there's an infinite family of integrals of motions, but they are written explicitly. Well, we don't have explicit expressions, only for the first few. But anyways, this is the system which we would like to study, and we want to study this system acting on Virasora-Verma modules. So, such a system of such integrals, a commutative integrals, again, acting in Virasora-Verma module is called quantum KDV, and it became very, very And it became very, very famous and very interesting. And there's a lot of things happening in this thing after a series of papers by Bajranov, Lokyanov, and Zemolochikov. The first paper appeared around the same time as quantum toroidal algebras. And there's a series of those papers. So there are many, many, many results. And the results are physical. So I think many proofs are missing in this business. And one of the things which I'm discussing right now is. Things which I'm discussing right now is how to obtain some of the proofs in this story. So, anyways, one more time. So, I have E1, and from E1, I get quantum KDV. I cannot do it for all integrals of motion, but at least for the first integral of motion, I can do it. Okay, now what happens for the dual part? Well, for the dual part, I cannot do it on a single integral. The my limit is so difficult. The molymit is so difficult, then I don't know how to do this analysis. So we don't really know what it is. However, what I can do is I can follow my beta ansatz. And so I can see what happens to my beta ansatz in this limit for both cases. And so what I can do is I can do a limit of beta and zats equations. Equations. Hamiltonians itself is too difficult. No good, no way. I don't know how. Maybe you help me. But at least Bertanzat's equations, I can. And so then, well, in E1, these are famous Litrinov equations for the long way. And so let me just write it out. So this is, the equations look like Jungian equations. Yes. So like this. And then you have a product of. And then you have product of Ti minus Tj plus R Ti minus Tj minus R Ti plus T minus T J T J minus R plus one T i minus T j plus R minus plus R minus one and and then T i minus T j minus one T i minus T J minus 1, Ti minus Tj plus 1 equals 0. So J is not equal to I. And J equals here 1 and 2. So this is two Fox pieces. So this is the highest weight. So this is this piece here. So this is the highest weight. And there are three of them because, okay, erase, because of this g function has three components for n equal 1. It's a cubic polynomial. So you get something like this. So you see, this is again Bethanza's equation. So you see, this is again Bethanza's equations of the type xxx, if you wish. It's a Jungian type equation. And so this Jungian type of equation should describe the spectrum of this quantum KDV system. But what about E2? So E2 produces what is called a fine GL2 or SL2 SL2 betanzats, and it looks like this. That's and it looks like this. So, in this case, I have Ti's, and now I have Ti's of two colors, so I will call them Si, and Ti of color one, I will call just Ti. So, this is my yes. And so I have like this, I have one over Si minus one here, and then plus two M. So I'm going to write it, and then I will explain again what I mean by all this. And then I have Si minus Sj equals zero. And I have two L Ti Ti minus Sj minus plus sum to Ti minus Sj equals zero. So this is the system of equations. So I have variables Ti and Si, and there are equations like this. So if you have ever did better. So, if you have ever did better answers, this is very, very, very kind of familiar thing. So, we have Cartan matrix like this, because this is SL2 hat, Cartan matrix, 2 minus 2, 2 minus 2. These are my weights. And so, this is what we get. And in fact, yes, this is one Dermot module and one module of level one. And so, you can try to study. And so, again, the expectation is that they also describe. Is that they also describe the spectrum of quantum KTV? Yes. So now so now what to do with these equations? Well, I mean, this is GL1 affine, and so this is difficult for us. So, this is difficult for us. We don't know really what to do with this set of equations, except that you try to solve it and try, I mean, very difficult. But for this one, there is a big theory how to deal with Gaden-Betazat's equations of a fine type. And so, if I write one second, so if I put here y0 is product of x minus si, so this is a polynomial with roots si and y1 of x equals product of x minus. Of x minus ti, so this is y1. So this is again some polynomial which has roots si and ti. Then this system of equations, in fact, can be rewritten like this. So these equations, okay, this goes really a long time back, my paper with Varchenka 2002 or something, I don't know, so long time ago. So you have this very good. Good system. So you have y1, y1, tilde is equals to t1, y0 squared. And I didn't write to who is t0 and t1. So t0 is x to the power 2l t1. And t0 is x to the power 2m x minus 1. So this kind of encodes the weights of the system, this encodes the better roots, and then The better roots. And then this Betanzatz equation is equivalent to such an equation which says that there exists a pre-normal y tilde, so that Wronskin of is two is this and Wronskin of this two is this. And so this is how you kind of rewrite it. And okay, and then it becomes, so okay, maybe I should not write too many formulas, but it becomes a differential operator of order two. So, okay, I'll write it. So this is why. So this is y1 prime over y1 and then I have g minus t1 prime over t1 plus y1 prime over y1 and also minus 2y0 prime over y0. Ah, comes like this. So anyways, this is a second-order differential equation which has roots, which has solutions y1 and y and y tilde. Y1 and y and y tilde. So, and anyways, if you just conjugate it, conjugate it a little bit, the result will be the following operator. So, let me write it down here: l god n is like this. This is dx squared. So I have dx and dx. These are differential operators. And then you have this. You have l plus 1 over x squared. And then you have here summation 2x minus x. x minus s i squared and we have plus summation k plus s i x minus s i over x x minus si thing and k is 2m plus 2l so and so this is the kind of the open schedule operator so it has second derivative here and then it has potential And then it has potential. So the potential has this term, LLO over 1 plus x squared, and then there are kind of singularities SI. So you have residues here, C here, but okay, the known fact about this, this is really the manifestation of these Betta Ansatts equations, is that these singularities as SI are apparent. So it means that for you So it means that if I go around Si, there is no monondromy for this equation. So x equals 0 is one thing, but Si are all apparent singularities. And so therefore what we expect is that such opers, so if I write, see there is no T here, T disappeared, only Si is here. And so we expect that such opers without any singularities here, apparent singularities, should describe the spectrum Should describe the spectrum of the same QKDV. Well, anyways, this was just an order, but okay, there is an extra piece of information here which comes from, well, initially, Fagin and Frank in something like 2009, maybe. And then there is more. So there are papers by say Katausov Lukyanov. There is a paper by Gaiot Gaiuta Gaiota, V, Vaita, and Wu. So, what they say is that I have to take it, and somehow it makes sense to add here a term. And this term is this, x to the power k times x minus 1. And then you have here lambda. Okay, I'll put lambda squared, and I also minus. So you have to add to this for whatever reason, okay, and For whatever reason, okay, and I will say what one of the reasons is. So you can add such a term here, which depending on the additional lambda. So this lambda being a loop kind of parameter, because this is an affine or so you have to have lambda somewhere, so this is like that. And then the statement is that if you add this term, the statement about apparent singularities, which I said, which was true for lambda equals zero, remains for all lambdas. For all lambdas. So apparent, and now they are apparent for all lambda. So this term does not spoil this property of being apparent singularities. And this really has to do with this expression here, because this expression is more or less Lagarini derivative of this extra term you have here. Now, what I'm going to, and where am I heading? Well, Where am I heading? Well, so the thing is that in these BLC papers, it was written. Well, I don't want to say conjectured because physics papers just write it, and so I'm not sure, but it was conjectured or written that the spectrum of QKDV flows can be described by operators of the following part: BLZ, BLZ operators, let me call it. So it still has GRP. Call it. So it still has dx squared, I mean, the same term, then have L times L plus 1 over, okay. Now let me use a different variable. So I'll call because it's BLZ operas, so I will put different variable, z squared. Then there is this plan one over z term. Then there is this summation to z minus zi squared terms. And then there is this extra k thing. Think z z minus z i term here. And then there is this term minus lambda z to the power k. So that was written in these BLZ papers back maybe 20 years ago. And so we don't know why this describes the spectrum, but computer checks say it and they wrote it, so it's correct and so on. But anyways, look at this. Correct and so on, but, anyways, look at these two. They're very, very similar. However, not quite, because you have here an extra term here. And then this and this are different because you have here z to the power key, but here x to the power key, and then you have x minus one here, extra x minus one here. So they are very similar, but not quite the same. And this one comes from the standard theory, which we know Bethanzal's pteroidal algebras and everything. Theroidal algebras and everything, and this comes from physics brains. I don't know where they get it from. And so the question is: how to compare? I mean, why this? This question was around for a long time. There's no proof. There's no way. I mean, we see the similarities, but okay, what? And so now I'm going to report to you kind of the main result which I wanted to tell you about. So the question is: how are these two operas related? And this part is my work, my work with other collaborators. So this is David Mazzoeira, me and Raimonda. Andrea Raimonda, two Italian mathematicians. Okay, David is in Portugal, so I'm not sure he's Italian, but anyways. So the thing. So the thing is the following. So these two operators are parators. And now you have an extra lambda. It turns out that for such operators, you can define what is called spectral determinant. And that's where analysis comes. So the spectral determinant. Okay, the spectral determinant is the following thing. So I'm going to just talk about this and BLZ is done similarly. So Gaden models. So what you do. Models. So, what you do is this. So, first of all, you write down solutions which are called Frebinius solutions. So, when I say solutions, it means Lg times psi equals zero. So, this is my, I'm trying to find kernel of this operator. And so, Frabino's solutions, you can do it expanding around zero and doing some power series expansions. And so, these are like this. There is X plus. These are like this. There is x plus solution, which starts with x to the power l plus one. And then after that, it is a series. So I have i and j starting from 0 to infinity. And the appropriate variables is this. So AIG are complex numbers. And so this is a series. It starts from this, and then it's a series. It starts from this and then it's a series in variables of two kinds, x and not lambda, but such a combination. And so such a solution exists and is unique around, and this is the solution around x equals zero, but actually it is an entire function. It extends to all variables, to all parameters. And then x minus is the same thing, but now it starts from minus L. I mean, these are two indices for this equation. Indices for this equation, that's the starting point, but the rest is the same. And so you have lambda squared x to the power k plus 2 to the power i x to the power j d i j. So these two solutions are called Frabenius solutions. It's an operator of second order, so they form a basis of solutions. So this is just an answer around x equals zero. So this is x at x equals zero. So this is expansion. Okay, so this is expansion. Solution. And this solution is at infinity. So at x equals infinity. And that characterizes by the fact that it goes to 0. So this is xibouye. So I'll write x0, plus, minus, and 0. So this one goes to 0 as x goes to so X goes to so uh yes in in a sector this is like this so there is a sector and so you have two parameters lambda and text and if you go to infinity within that sector then there is a unique solution which goes to zero up to a constant and so okay we can fix constant I mean there is a way to fix constant and this I mean, there is a way to fix constant, and this is called the Simouth solution. And then the spectral determinant is something which connects these three solutions. So this is a solution at infinity, but okay, I can write it as a linear combination of these solutions. And so I do it. And the answer is this. So I have Q. Well, okay, let me put here. So this Q depends only on Lambda. It's a function of Lambda. Chi plus. chi plus plus q minus q minus of lambda and these two guys are called q functions or spectral determinants so this determines for me these two functions okay so take solutions at infinity which vanishes in this sector and write it in terms of solutions at at zero which are Frabenius solutions coefficients are called uh Q functions. Are called Q functions. Yes. And so these Q functions actually are very famous things now because of what is called ADE IM correspondence. So this is called OGE IM correspondence. OGIM correspondence. Okay, there are many papers again, so this is. Again, so this is Mazeira Raimonde and Andrea Valerie papers, there is Dario Tater papers, there is DLZ. I mean, there is plenty of stuff known about this, and in particular, this Q plus and Q minus, they satisfy what is called, okay, people call it now QQ relation. Well, it's not the same as QQ character, which will be later. It's just capital QQ relation. And I don't like this term because, okay, back in 2000, these were changing. Back in 2000 with Varchenko we called it reproduction equation, but 15 years later people discovered and rediscovered and called QQ relation. But nevertheless the relation is, so this is like this. You have gamma Q of Q lambda plus Q Q inverse lambda minus minus gamma inverse Q plus Q inverse lambda Q minus of Q lambda. Of q lambda equals one. So this is kind of discrete Fronskian with gamma, and so it equals to one. And so the big difference from this q relation to what we did with Varchenko back 20 years ago, these are now analytic functions. So Q of lambda is the entire function. Not a polynomial, as in our algebraic business, but this is really analysis. Really, analysis now, so it's an entire function. And so, okay, this is it. And so, now the theorem, okay, theorem is a strong word, so I'll write conjecture. Okay, I want to write theorem, so I will write C theorem, but okay, not Ethereum. So, this is this is this thing is this. So, if I take Q functions from a den model, plus or minus, well, minus, in well. Well, minus, in fact, yes, or plus, minus. So they are the same as functions in BLZ model. Well, when I say the same, there is some explicit shift of lambda, but not very big thing. I mean, you can write down explicitly. And the statement is this. Take an occur like this, then there is an occur like that, such that the aspect of determinants are just the same. So this is a statement. This is a statement, and this is a kind of to me, this is a very, very important statement. Why? Because another paper of BLZ says that such spectral determinants actually encode the eigenvalues of the Hamiltonians. So this is BLZ, also says that if I take Q of lambda, and so I can expand it at lambda equals zero or at lambda equals infinity, and then what you And then what you get is at lambda equals zero and infinity, you'll get eigenvalues. I mean, coefficients will be related to eigenvalues of non-local integrals of motions. And this is eigenvalues of local integrals of motions. And so this is an important object in the theory, and it turns out that this. Theory and it turns out that these two, despite these similarities, I mean, they look very similar, but analysis analytically is very, very different because the MDCOL zero limit is very, very different here. But nevertheless, they seem to share with this spectral determinants here. And so, this is way above my kind of pay grade in analysis, because if I want to prove such a statement, and I, you kind of more or less And I you kind of more or less proved it in some cases, uh but not in general. Uh so you have to study uh entire functions. These are both entire functions which satisfy the same equation. And then you need to know something about zeros of these entire functions, asymptotics of the zeros as zeros goes to infinity, and from that somehow you have to conclude that they are equal. And uh this is just a theory of entire functions, which is really I haven't learned completely yet. I haven't learned completely yet. I'm trying. And there are some other difficulties here, for example, to show that this function, one of the functions, is very difficult to show that it is analytic at lambda equals zero. So you have to do a lot of estimates to show this. And well, so initially when I thought about this, I thought that these two operas should be related by some algebraic change. So there should be some algebraic change. Change. So there should be some algebraic proof, not this crazy complex analytic stuff. But we know that such a map, so I can have algebraic proof. Yes, algebraic proof, I can do it only in one case. So if degree of this polynomial y0 is r squared, and degree of polynomial of y1 is r squared plus minus r. So there is a R. So there is a, I mean, I have these polynomials here, and so how deep I should go. And so in this case, in fact, the weight space is one-dimensional. And so both can be computed explicitly. I mean, and you can make a map. But in all other cases, it seems to be not. And the reason for this is what? So these ZIs also should be related to this non-linear. Also, should be related to this non-lo-local improve motions. So, this should be also related to Zi's. But Si's should be related to the opposite. So, Zi's should be related to the local integrals of motions, and Si's should be related to the non-local integrals of motions. And those local and non-local integrals of motions well, as I said, we have this duality B and B. Duality, B and B, but we don't know how to express one through the other. So we have B and B check, how to express, we don't know. And so therefore, somehow the correspondence between this and this should be difficult. At least expectation is it is difficult. And we couldn't find it. So we just resorted to these analytical arguments, which are very, very difficult. But at least this is the first time I can see how this one rigorously mathematically appears from something. Appears from something, in this case, from the duality n equals 1, n equals 2 duality of quantum toroidal algebras. I have to stop.