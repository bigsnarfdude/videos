Fluids are hydrodynamic approximation. So, as such, they have an inherent source of noise that is noise due to molecular fluctuations. So, we either have to take that into account or argue for why it's irrelevant. And as I would like to show in my talk, is that it's very much not irrelevant. One of the pioneers on the subject of the interaction of turbulent flows with the Driply flows with thermal noise is David Rurrell. In the paper that you see at the bottom, he estimated how noise impacts the predictability in terminal flows under the assumption of exponential growth of disturbances that is characteristic of chaotic systems. The game analysis is based on the mesh of grounds and estimated Levinov exponent to be dependent on the scale L as a power law and the time that it takes. Power law and the time that it takes to influence the flow at a scale L to be inverse proportional to the exponent of the algorithm fraction. So then he substituted parameters for air and concluded, here I'll just quote Raoul himself, that the time it takes for thermal fluctuations to affect the microscopic motion is of the order of the characteristic time associated with the smallest eddies, meaning Komogoro scale, multiplied by 10. Then, for large, he also specified that for larger eddies, the result would not be very different. And even though our conclusions can be quite similar, there's one crucial difference, and that is exponential growth is really only representative of the initial growth of randomness in multi-scale turbulent systems, and then eventually is overtaken by the self-similar growth in the inertial range. And one of the first prominent works in that direction is due to Edward Lorenz. Is due to Edward Lorenz, which is here that side at the bottom in 1969, where one of the questions that he asked is: how does the energy norm of disturbance at some small scale grow over change over time? And what he showed using a closure model of turbulent omnibus equations is that they propagate, perhaps not that surprisingly, from small scales to large scales. From small scales to large scales, with the envelope given by the energy of turbulent fluctuations themselves. And he estimated that it takes about five days for the disturbance to propagate to the scale of about 10,000 kilometers. So, even though he used the closure model of Nero's source equations, which is after considering ad hoc, he was able to. Or ad hoc, he was able to reach a very important conclusion. And here I'll again quote Lorenz himself: that certain formally deterministic fluid systems which possess many scales of motion are observationally indistinguishable from indeterministic systems. And then he clarifies that the two states of the system different initially by a small observational error, so he's not talking about thermal noise, observational error, will evolve in two states different. Will evolve in two states different as greatly as randomly chosen states of the system within a finite time interval. So here the finite time is going to be crucial, which, and this finite time cannot be lengthened by reducing the amplitude of the initial error. And he called that effect a butterfly effect, as was pointed out by Palmer, even though we now know it's typically associated now with regular chaotic systems rather than multi-scale turbulence. Turbulence. Okay, so now we know this phenomenon under the name of Eulerian spontaneous acousticity, under the name of an analogy to Lagrangian spontaneous acousticity that was first described on the Kraken model by Bernard Gowatsky and Kopjanin in a now famous paper that I studied. Okay, so now that I've described our professors, I'll state the goals of our work, and that is to study how molecular fluctuations To study how molecular fluctuations impact multi-scale turbulent flows, and in some sense, unite the ideas of Lorentz and Royal to illustrate complete randomization of the flow due to thermal noise alone in one large aviation. Because for such a study, we needed to work with a multi-scale turbulent system, which is not really feasible computationally for Nairo-Stokes, we used the sub-Rochal model. And then finally, we illustrate the self-similar. We illustrate the self-similar nature of the inverse error cascade due to thermal noise and how it fits under the umbrella of the phenomenon elsewhere to illustrate this. Most of what I'm going to be talking about today will be in the deeper. Just as a reminder, the Sapper model is a Schill model caricature of energy escape, the one usually sees in the Stokes equations with exponentially spaced velocity. Velocity and truncated assembly number. In the form that you see here, it is a caricature of fluctuating Nungi-Stokes equations. So we edit Y noise with the pre-factor such that without forcing the model satisfies the fluctuation dissipation relations and the space distribution. Of this distribution. Because we introduced white noise, there is a second non-dimensional parameter aside from the usual Reynolds number that we call theta k, expression for which is came here. And one way of thinking about it is that it's a non-dimensionalized temperature of a system. Okay, in our study, we use the parameters of the atmospheric boundary layer. Very boundary layer that we took from the book by Garrett, which produced the Komobar scale of about one millimeter and the theta k of 10 minus the. The smallness of theta k is really due to smallness of Boltzmann constant. So how do we characterize what are the ways in which thermal noise manifests in multi-scale turbinal flows? One of the first most intuitive things to look at. First, most intuitive things to look at is energy spectrum. And I'm not going to talk about this too much because Greg talked about it earlier today. I'll just reiterate the main conclusion that there is because the equilibrium scale is just one order, one decade below the Komogura scale, while the hydrodynamic approximation is valid for. Valley for up to a scale of about 100 nanometers. There's really three decades of scales with applicable hydrodynamic description where thermal noise dominates the which was anticipated by Batchman. You can also look at other structure functions aside from energy. From energy, and as you can see here, for so here on this plot, you see the structure functions for steady-state Sabra model with P that ranges from 6 to minus 0.9. And the more negative P is, the higher the scale at which thermal noise starts to dominate. So that actually provides us some insight into how we can. Insight into how we can potentially observe it experimentally. So, even though there is profound consequences on the steady-state distribution in the dissipation range, there is actually quite little effect of thermal noise on the steady-state statistics in the inertial range. And because we want to focus on that, we move on to the next point of predictive study that there's several. So of course there are several strategies, one of which is to look at a bowl of initial states and look at how it evolves over time. That is the strategy that was chosen by Alexei and the collaborators in the paper here, where they looked at the ensemble of slightly perturbed singular shear layer that develops Kelvin-Helmo's stability. But another strategy is to start from a unique initial state by introducing a waste into the narrows, which is, of course. Which is, of course, much more natural choice for studying the role of choice that we face is the particular initial state because the predictability horizon can depend and does depend quite strongly on the nature of the initial state. For the sake of that study, which is two different states, and one is the supposedly clean case, the homoborizationally self-silvery state given here. Silver state given here, and the second one is a randomly sampled from a steady state. The on the plot, the blue one being the issue self-similar state, and the orange one the wild state sample from the same state. Okay, one of the simplest measures of the exchange of predictability that we can look at is the total variance. On this plot, you see the The on the spot you see the dependence of total variance as a function of time, and you see, even for total variance, you already see all the regimes of how the predictability changes. And that is, we start from the linear growth that is primarily due to thermal noise, until the non-linearity starts to dominate and we transition into the exponential growth, a characteristic of chaotic systems. Of chaotic systems, which is what Royal described in his work, and which eventually transitions into power lock growth. This nice self-similar power lock growth, I have to mention, is only characteristic of the Komogorov initial state and not so much of the model state. So, you can try to deduce the power law of this similar growth with the Similar growth with using dimensional analysis under the assumption of complete self-similarity. Here, the only parameters, dimensionful parameters that variance can depend on is time itself, but also the dimensionful parameter in the initial state. So, under the assumption of complete self-similarity, we arrived at this formula, and because we start with the initial state, Start with the initial state with holder exponent h equal to one-third, we have to conclude that variance should grow linearly, which is exactly what we observe, which by the way implies that curiously there is no breaking of complete cell cellularity and no anomalous dimensions from time. And there is so far, we don't know of any other system that would that would break a reason. The wood breaks some similarity. So, now because we're studying inertial range effect, it makes sense to go into inertial units. Because in the self-similar state, there is no natural outer scale. We have to introduce it artificially, which can be done through introducing an observation time, which is really just the time that we look at on these. Through T sub naught, we can introduce undimensional. Sub naught, we can introduce non-dimensional groups such as Reynolds number, but we keep the theta k, the non-dimensional temperature, defined the same way because it just on because that one is physically motivated, since we want to look at the system at constant temperature. Using t7aut, we can non-dimensionalize the rest of the parameters of the system. Of the system and arrive at the non-dimensional Suprema model. I would like to note that both viscosity and noise term are inversely proportional to a positive R of Reynolds number, hence they vanish as Reynolds number grows to infinity. The importance of which will become shorter. Now, if you look at the variance in the inertial units as a function of time, Gibbons as a function of time at some fixed theta k but decreasing Reynolds number, we observe that after some non-universal initial transient, all of the curves collapse into one unifying parallel growth, which is exactly what we see for all the known spontaneously stochastic systems, such as so-called Saber model, mixing layer, toy model, of Lagrange spontaneous stochasticity, as well as Stochasticity, as well as others, such as Krigman model. So, this provides us with this picture that occurs again and again provides a nice interpretation for the definition of butterfly effect that Edward Lorenz came. So here the non-universal transient corresponds to taking a different initial separation, which eventually One unified curve. So there is a forgetting of the initial separation in the power lock regime. A more refined look at the inverse error cascade is given through the variance as a function of wave number for different times. Here you can trace the origin of each of the regimes of growth of variance, the initial linear due to white noise here, the tail. White noise here, the tail before the stochastic front, but then the ones the then the region of the cascade that the non-linearity dominates creates the exponential regime, which once it saturates by the energy of turbulent fluctuations and enters the self-similar growth of variance. With the stochastic front propagating towards larger and larger. Front propagating towards larger and larger scales, and the shells at high width numbers growing more connected. Here it's nice to compare how close this picture to the original plot of Lorenz obtained in 1969 using a closure model of turbulence, which indicates robustness of the right one of the One of the key takeaways of this study is: I define the randomization time, T sub R, as the time that it takes for the variance at each shell to reach the value equal to half the energy of the initial state at the shell. So now on this plot, you see the T sub r as a function of wave number in the units of the corresponding characteristic times. And clearly, as you go, as we go. Clearly, as we go towards larger larger scales, the T sub bar saturates at the value of approximately 1.5 any turnover time. So using, so our suburb model estimate is that scales of about a meter and above behave spontaneously stochastically. And which also implies that in one large eddy turnover time, the whole flow is randomized by thermal noise alone. Along. And now I'd like to move to the last part of the talk, and that is spontaneously stochastic limit. The essence of spontaneous stochasticity is in loss of uniqueness in the near-singular initial value problem as the regularization is taken to zero. Now, if we introduce noise, it could be initial data or in dynamics, and we take it to zero as the regularization is also taken to zero, if the double limit. Taken to zero, if the double limit leads to a non-trivial distribution over trajectories, the limit is spontaneously stochastic. I'd like to illustrate what I mean here on the perhaps simplest spontaneously stochastic system here, Lagrangian spontaneously stochastic system, that we analyzed using RG approach in the paper here side at the bottom. So we're looking at the Brownian particle with a near-singular drift that starts at the origin. Drift that starts at the origin, the drift is characterized by Holder exponent and regularized in the bowl around the origin of size L. Now if we take the limit of diffusivity goes to zero, we arrive at the deterministic limit where the only trajectory that becomes relevant is its particle states at the origin. So only one trajectory, and you know with certainty what happens. But if you take criticalization and diffusivity to zero simultaneously, dynamics couldn't require. Simultaneously, dynamics could remain stochastic. And what I mean by could is explained on this space diagram. So here we look at variance of a particle that at some observation time t0 when it started at the origin, the vertical and horizontal axes are correspondingly Reynolds and Paclein numbers that for the sake of this talk can be thought of as just characterizing regularization and noise. Virginization and noise, the size of them. Now, if we take the limit such that Reynolds number grows too slowly, then we arrive at the deterministic phase wherein the particle doesn't leave the origin and the only trajectory is, and there's only one trajectory. If we take the clay number to infinity too slow, then we arrive at the noise-driven phase where there is an infinite amount of trajectories that are noise-driven. That are noise driven. However, there is a big chunk of the phase diagram for the double when we arrive into a spontaneously stochastic phase where only exactly two trajectories are important, which are solutions of the singular problem. And each is realized with probability one-half. Okay, so now that I've characterized the spontaneous stochastic limit and the tween model, Spontaneous stochastic limit in the twin model, what is the natural choice in the sober model with thermal noise? And so we argue that what is natural here is to keep fixed theta sub k, which corresponds to constant temperature, while we take Reynolds number to infinity, which could be done through taking observation time, observing the system at longer and longer time scales, or taking viscosity to zero. Viscosity to zero. And as I've pointed out before, both viscosity, which really regularizes our problem, and noise both go to zero. Okay, so how do we answer the question whether spontaneously stochastic, whether this limit is spontaneously stochastic? We'll look at the PDFs of, for instance, energy per shell and ask the question: do they collapse on delta distributions or focus on just one? That are focused on just one value. And the answer is that they don't. They, for here, you see probability density functions for different shells for some similar initial state and wild initial state. And in each case, as Reynolds number increases, the PDFs converge to the distribution that's non-singular, not focused, and not concentrated on one class. So, as we take the limit of Reynolds number goes to infinity, the dynamics stays random, and the limit is spontaneously stochastic. Another useful point of view of the inverse Erica sc is in terms of multiplier variables, which were introduced by Komogoro in 1962. Here you see the PDFs as a function of time for both angular and multiplied variables as well as. Angular multiplier variables as well as magnitude multiplier variables are essentially the same. We start from a very singular PDF that once the stochastic front reaches it starts to diffuse and converge to a constant distribution at large time. If we change If we change n to, if we increase or decrease n, the picture doesn't change with the only difference that stochastic, difference that stochastic front moves towards smaller time or larger time, which indicates scale invariance in multiply variables of the stochastic wave, which was of course the whole reason, the scale invariance, the whole reason for Kumo-Horrick to introduce the multiply variables. Variables. Curiously, besides that, the distribution towards which it converges is indistinguishable from stationally developed turbulent statistics, which is what we call super-universality to contrast it with the usual universality that indicates the invariance of spontaneously stochastic distributions with respect to noise that Triggers said. To conclude, we showed that thermal effects are sufficient to randomize the whole flow at all scales in time of one large eddy turnover time. The thermal noise is irremovable. Hence, we really should describe physical turbulent flows as inherently stochastic. And mathematical foundations of Eulerian spontaneous stochasticity are only now coming to light with much recent progress on convex integration. Recent progress on convex integration and non-uniqueness in the Cauchy initial value problems, both for Euler and Navy-Stokes equations. And maybe a little more close to me as a physicist, there's progress being done from the perspective of non-unique ground states in the path integral representation of dynamics, which could be spontaneously stochastic. And of course, as Alexey just talked, showed there are no So there are no exactly solvable models that display. So hopefully there's a gap between phenomenology and sense of mathematical. Fantastic. Thank you, Deetra. Thank you. That was very interesting. So seeing as how this is the end of the session, any hope. End of the session, and the only thing keeping us from chatting and discussing math is dinner. Unless everyone's appetites are too ravenous, maybe we could take like 20 minutes or something and have a kind of a discussion about the three talks that we saw today. I would love to do that. I'm not particularly happy, but other people may but I mean, people can you guys feel free to Feel free to go to have your dinner anytime you want, but if you want to discuss, we're happy to discuss these three talks. We need to ask questions to Pero because I'm going to start to ask any question you can. So I remember that. But you start with Nita because she was just. She's a Tibetan. You're right. Okay. I have a question about your kind of story one. About your kind of toy model with stochastic differential equation. So, question following: if you consider it not as just one stochastic equation, but what is called stochastic flow. So, you kind of start from all initial data, but using the same white noise. And then you see, and then you get a map from position in time zero to position in time t. And then take the limiting procedure you have here. But you have something interesting, like an object which is quite popular, which is called stochastic flow. It's usually difficult, but in your case, it probably will not be really useful. Just random map from initial conditions to say what you see at time one. Well, of course, we don't have to introduce noise here in the dynamics, right? We can also introduce into initial data. I just want to keep it the same way with the video of the face menace as a whole. Yeah, okay. Then it's some interesting logic moment. I don't know in your limit of L D going to zero, but that should be the right limit. So what will happen? Not on the level of individual process, but at the level of the whole Greg, did you hear? No, not well. No? It was a little dim, sorry. No, I was saying that maybe it's interesting to consider stochastic flow, just running all initial data with the same noise, with the same white noise, and then seeing what are the map transformations. Oh, yes, I see, yes, of course. This is very interesting. I just want to say, you know, to some extent I come from kind of an alternative community, a smooth dynamics community, and there I often fight with people about the physicality of high entropy noise. And it's just very And it's just very refreshing to be in a room full of people who see things my way. I do. And obviously, we should all talk more. I was very interested by this person. Can I ask a question, if I can? Yes, John. So I'm not sure if I completely understood everything. I mean, I'm kind of harkening back, right? I mean, I'm remembering back to stuff like the stuff that Eric and Waynon did and the stuff that Jean and Raymond did. And at the same time, the simple example you did with the Same time, the simple example you did with the singular drift right around the origin, you know, looks like the kind of thing in Vensel-Freidlin theory you get when you average down and just get the limiting randomness at a point. I guess I was trying to figure out in the Saber, in the model you did, in the Saber model, was it more where there's a non-uniqueness in all the trajectories coming out of every point? And so every step forward is kind of a randomized choice of a deterministic characteristic. Deterministic characteristic, you know, which I guess would be more like the Jean-Raymond or the, you know, the burgers, the burgulance picture, right? With rough, with rough vector, with rough fields? Or, or is it more somehow like the illustrative example you had where you had the kind of regularized singularity at zero, I guess, right? That causes some if I understood that. I mean, that went by fast. So I may have gotten it wrong, either of you, whoever, whoever wants to answer that. Whoever wants to answer that, I know there are two co-authors on the phones. I'd say it's more like the Lejeune Ramon case. Okay. As far as we can determine, right? So we don't have any theorems, but. Right. So you don't really have a pathwise perspective on it in that case. Yeah, it's constantly branching. It is constantly branching. Okay. Yeah. I mean, we can take, for example, you know, different initial conditions, and we did that, you know, the Comogen. Did that, you know, the Kolmogorov scale invariant one or the wild solution, which is sampled from the steady state. And no matter what we take, it always randomizes. So you expect randomization constantly. Okay. So just constant, just picking random characteristics coming out of a point. By the way, I wanted to make a quick comment about Kost's question, which is that even for the Kreichnan model, in the rough case that was considered by Lajean and Ramon, Considered by Lajean and Ramon, we still don't know much about flow maps there. So I conjecture, I conjectured many years ago that in fact you have Holder continuous homeomorphisms, but they're random. But this is a completely open issue whether you have any kind of flow map at all in the Kreitnin model. So that's a really interesting, open problem there, not settled by. Problem there, not settled by that, you know, the existing work. I guess that's what Kost is getting at. Absolutely, absolutely. Um, to start with easier model, you maybe can answer uh are there questions to tell? Are there questions to Theo? Because Theo was deprived of questions. I guess my question to Theo was: how important was it that you had the freedom of L infinity perturbations over something else? In that last result? Yeah, I mean both at the level of like what you prove, can prove or what you morally think is true, where I probably care more about the second question than the first question. First question. So, okay, so in the last result, the perturbations themselves were smooth, but the closeness was in L1 of vorticity. I see. That was actually crucial for that. I mean, that result relied on being essentially far, if you even far for kinetic energy. So far. If I move to L2, it would be problematic. Yeah, it would be problematic. So, of course, I think the. Of course, I think as a general feeling, it should be that most initial conditions do not damp to shear. That seems to be more special than the rule. Of course, the only result about it goes the other direction, but it's in very restricted settings. So that being said, the theorem I presented was only, I mean, it's definitely a cheap argument. It's definitely a cheap argument relative to what you would need to establish that most don't go to shear. Thanks, Dia. Yeah. So I have another question. So you said that Judovich conjecture is still open, right? Yeah. And is it possible to, does it make sense to discuss Judovich conjecture for, say, case of finite number of vertices? And then it's a finite number of vertices, and then that's what does it mean in the conjecture in this case? Oh, so you mean for the point-vortex system? So it's a little difficult to say because you've taken all the spatial dependence out of the vortex, but you could ask questions. I mean, you could ask a question about the vortex wave system, where you take the point vortices and you add Vortices, and you add just like a bounded or smooth perturbation to them, and you let it all mix up. And that, you know, that's a well-defined system. And you could ask of that system, do the solutions generally develop singularities in the smooth part? And so that's a perhaps you could answer that question better because the vortices themselves mainly see themselves up to some lower. themselves up to some lower order perturbation so could be does that make sense or actually yeah there's let me the slides i didn't get to there were some really nice uh conjectures by other people about the structure of the whole limit set you know of like the whole ball in l infinity what does the limit set look like and there were some conjectures one by character and one by schnierlman By Schwarak and one by Schnierlman about its composition. And I just want to mention them. So, Schwarak conjectured that typical points, generic points in an L infinity ball of vorticity, have the property that Euler, if you start from them, will mix at infinite time. So enstrophe will go down at infinite time. And Schneerlman conjectured that the weak limits, the things you actually see at infinite time, At infinite time, correspond to points in the ball without that property, namely points that if you start from them, you don't mix at infinite time. And so an example of that would be steady states or time periodic orbits, quasi-periodic orbits, so on. And this is, of course, generally totally open, but there are three points about it. The first is that there's a simple proof also by Schwarak that says. Proof also by Schwarak that says if you look at the omega limit set of any initial condition, then it contains at least one compact orbit. So the Schnierlman thing, at least each omega limit set has one such. You don't know what it is. It could be steady state, it could be the other things. You don't know. The other point is that in the neighborhood of the monotone shears, we know from these inviscid damping results that effectively those conjectures are true because Conjectures are true because you converge back to equilibrium in that case. The issue there is just that that's a very, very small area in the L-infinity ball because there's small perturbations in the Givret topology. So really, really close. And the final thing is that there's some numerics done recently by Class Moden and collaborators, where they propose an even more remarkable conjecture about the Conjecture about the structure of the limit set. Before I say what it is, let me just say that if you put those two previous conjectures together, then it's some precise way to say there's a decrease of entropy on the whole for Euler, because you have a big set. The generic points don't satisfy this property, but the limit points do. So you have some contraction there. And Moden went on to conjecture what those limits look like. And it turns out that. Like, and it turns out that, well, his conjecture is that it's related to the largest number of vortices which are generally integrable for the point vortex system. And so he studied this on the sphere, and that number is apparently three, at least if you don't have zero total angular momentum. And so you run long time Euler and you see three vortices emerging pretty much every time. It should be, again, a generic statement. Should be again a generic statement, and then he tested it by saying if you take zero angular momentum, you have an additional conserved quantity for point vortices, and now the smallest number is four. I mean, the largest number is four. And again, if you take Euler with total angular momentum zero on the sphere, he sees generically four vortices. So it seems like there's some connection between the long-time behavior of the point-vortex system and 2D Euler, which I think is remarkable. 2D Euler, which I think is remarkable, at least from the simulation. It's very recent, it's within the last half a year. Alex, we'll see next five seconds. All right. Seconds. All right. No, I'm sorry. I actually, I also have a question, but this is maybe like a silly question. I don't know if this is too... Anyway, so I'll give it a shot. So you think of the vortex, the vorticity is being affected by itself somehow, and you see this degeneration into smaller and smaller scales as time passes and passes. Time passes and passes. And this seems an awful lot like the bachelor mechanism. And so it seems to me as though you should be able to characterize the generic power spectral law of this packet of L2 mass flying off to the deepest small scales. I wonder, A, does this even make sense? It's a kind of transient bachelor's scale, I guess I'm asking for, because Scale, I guess I'm asking for because you're not injecting anything, right? So it can't build up into a nice steady state. But I'm wondering if you can characterize this kind of packet of energy that's passing off down to zero, if it's like, it's probably not turbulent. I don't expect it to be, but I do expect it to be bachelor. Do you have any prediction? Is this a meaningful question? I mean, I think it's a meaningful question. I think a lot of people have thought about that. A lot of people have thought about that. Embarrassed to say, I mean, I certainly a lot of work on decaying turbulence. And there's, I guess, Bachelor, Saff and lots of people had predictions based on the structure of the turbulent, based on the structure of essentially the Euler solution. I don't think it's unreasonable. I just don't know exactly what you can say about it. Maybe someone else does. Maybe, Greg, you have, you know. You have, uh, yeah, I don't. Well, of course, I mean, that problem was studied in the passive scalar model itself. I mean, Kreichnan looked at this transient regime, and indeed, you do see a transient regime of batchler one over k, where it going off to high wave number and simultaneously the range is growing. But I don't know of anybody that was able to study that for the