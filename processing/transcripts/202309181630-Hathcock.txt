Yeah, so I'm going to be talking about this recent paper. The title is the same as the talk title, One Tree to Roll the Model, Polylogarithmic Universal Symmetry. And before I get into it, first I want to acknowledge my amazing co-authors, Costas Hatachi, Arnold Pellis, and Roger Mahan. So, yeah, let's start. So, yeah, let's start. So, I'm sure everyone here is familiar, but I just want to briefly discuss normal standard trees before I describe the setting of universal standard trees. So, what is a standard tree? You have a graph and vertices. The edges may or may not be weighted. And we have a root vertex, R, and a subset of the vertices are designated as terminals. Right? And, okay. When I gave Okay. When I gave an hour-long version of this talk last week, I had a whole story about Lord of the Ring. I'll spare you guys because this is only 30 minutes. So the IRSROM is our root, and we have these terminals. And a standard tree, you're looking for a sub-network which connects the root to all of your terminals. And specifically, we want one of minimum cost, right? And so here's an example. Right, and so here's an example of a standard tree for this set of terminals, which costs seven, but of course, uh, we can do a little better and uh use only six like this. In this example, all my examples are going to be unweighted, but you could imagine there are edge ones. Okay, and of course, Synergy captures some very natural, nice problems that we're all familiar with. If your set of terminals is all of the vertices, you're just looking for a minimum spanning term. You're just looking for a minimum spanning tree. And if your set of terminals is just the root and one other terminal, you get the problem of finding the shortest path. So, what's the setting of universal standard tree? Well, perhaps you want to connect your route to your set of terminals, but you want to do it repeatedly over time. And your terminals are moving around. Maybe you sometimes want to connect to fewer of them or more of them. And so universal standards. Universal standard tree is the problem of finding a spanning tree of your network such that for any subset of the vertices, if you think of those vertices as terminals, then the cost of the induced subtree on that subset of vertices, on those terminals, is at most a row factor more than the cost of the optimal standard tree on those terminals. The optimal standard tonphist terminus. Okay, so let's look at an example. So here's an example set of terminals. It's our same example as before. And in this case, the orange subtree is the induced subtree. If T, the blue tree is our candidate universal signatory, the orange is our induced subtree on those terminals. And in this case, when we compare it to the optimal signature on those terminals, it's actually the same thing, because this is the same. As terminals, it's actually the same thing because this is the same example we were looking at before. So this is great, right? You know, for this set of terminals, maybe we might think that this tree has a nice row factor of one or something, right? But let's look at a different set of terminals. The universal signer tree has to work for all subsets of vertices simultaneously. So here's a set of terminals. You have your root and one other terminal. And in this case, And in this case, the induced subtree that connects the root to this terminal has cost 6, whereas the optimal standard tree had cost 1. So this is not very good. This tells us that the row factor, sometimes called the stretch factor for universal standard trees, for this specific blue standard tree is at least a 6, which is probably not very good. You can certainly do better than honest with. Okay, does this make sense? And of course, the objective is to find. And of course, the objective is to find for any graph a universal standard tree with a low stretch factor. So, just some brief intuition about this type of object. It's a fairly strong object. And I want to go back to the special examples of standard trip that I mentioned. If you think about, since it has to work for all subsets, all possible subsets of vertices as terminals, if you think about the terminals being the entire vertex set, then the Then the universal Steiner tree condition tells us that this is an approximate minimum spanning tree, right? On the other hand, if you think about the terminal sets of just the root and one other terminal, like we have pictured here, it tells us that your universal standard tree has to approximate the shortest distance from the root to any other. So it's kind of like an approximate shortest path tree from the root. And we know there are simple examples, like on the wheel graph, where these two. Like on the wheel graph, where these two things, you can't have a tree which is both a minimum spanning tree and a minimum shortest path tree, and moreover, the best minimum spin or the minimum spanning tree is a terrible shortest path tree, and the shortest path tree is a terrible minimum spanning tree. So it's important that the root is fixed. That's a good point. Yeah, good observation. It is important that the root is fixed. Because if we didn't have a fixed root, then this would capture low-stretched trees, and you can't have a deterministic single tree that has low. Single tree that has a lot of stretch for every pair of chunks. Good observation. So, right, this is one tree to rule them all, right? We want a single deterministic tree that captures both of these, you know, minimum spanning tree, shortest path tree, and everything in between for all subsets of terminals. Okay, so what can we do? Well, in our paper, we found In our paper, we found, we gave an algorithm which, for any graph, again, the edges can have weights, gives a polylogarithmic universal standard tree. So a universal standard tree with stretch factor log to the seventh. And just to compare this to previous work, the best previous known general universal standardry result is from this 2012 paper, and they had a 2 to the root log. And they had a two to the root log stretch factor. So, you know, sub-polynomial, but super highly logarithmic. And in terms of how well you can hope to do, from 2005, there are examples, non-algorithmic, just information theoretic lower bounds that say, even for very special cases of this problem where the graph is a complete graph induced by a Euclidean metric. Induced by a Euclidean metric, whether like the edge weights are induced by a Euclidean metric, then you can't find a universal signatory with stretch factor better than a biolog. Yep. So it reminds me of various literature that I probably should remember. I mean, I kind of remember a whole thrust of sort of lightweight spanner kinds of results, which are exactly just about your two special cases of by criteria kinds of Of simultaneously approximable. So, I mean, I understand it's just the two extreme cases, but I'm just curious just to sort of frame what you're doing here relative to that. So, I guess in terms of the results on general graphs, the I don't think there has been much for universal sanitary. There has been much for universal center tree, you know, aside from this 2012, like two-to-the-root login result. There have been a lot of other works that address special cases where if your edge weights aren't, if you have a complete graph with edge weights in the past. I'm asking a different question. I'm just saying, suppose your problem is only to achieve a simultaneously good Shogus path tree and Shogunus out there. I just vaguely remember that there are good results. Remember that there are good results out there because I should remember better than I do. I guess I don't know. It's a constant. Yeah, it's a constant point. Yeah. Like the brothers controls by its last. Sure, sure, sure. Okay. So I'm just gonna do give a kind of broad overview of the machinery. Of broad overview of the machinery we used to prove this result. For the remainder of the talk, I'll only be focusing on kind of one piece of it, but I just want to have kind of a roadmap. So to get this universal Sinertree result, we go through a series of reductions. And first, we consider these two objects, these dangling nets. It's a term that is new on our paper, but it's kind of implied by some previous work. Previous work, and this cluster aggregation problem, which I'll be explaining in detail later. And if you can get solutions to these two problems with certain parameters, it gives you this hierarchy of partitions of your graph, which we call strong, sparse, partition hierarchies. And sort of the important difference here from previous hierarchies of partitions of the graph, of graphs, is the fact that the diameter conditions are strong diameter. Diameter conditions are strong diameter conditions. And if you can get such hierarchies, then it was shown that you can get universal standard trees, again, with certain parameters. And so this reduction from USTs to the hierarchies was from that same 2012 paper I mentioned previously. The reduction from these two subproblems to the Subproblems to the partition hierarchies. It was one of the two contributions of our paper. And then filling in these parameters, our co-author Arnold Filtzer showed that these dangling nets exist for log parameters. Getting a cluster aggregation solution with log parameters was the second kind of main contribution of our paper. And from there, everything is a log, and universal signer treaty you get with polylog stretch. Guide with polylog structure. So, for this talk, I'm just going to focus on the cluster aggregation problem because it's a nice self-contained problem that I can explain the algorithm for in detail. So, let's look at this cluster aggregation setting. You have a graph. A graph. Now you're given as part of the input partition of the vertices into clusters. These are always going to be shown in blue. And there's this delta parameter, which you can think of as the maximum strong diameter of a cluster, or a bound on the strong diameter. Remember, the strong diameter of a cluster is the max distance between two nodes on the induced subgraph of the vertices of that cluster. So you're not allowed to travel outside of the cluster. And then the final piece of the input are these special vertices called portals, and they're going to be kind of the centers of our new clustering. So the cluster aggregation problem is about taking an old clustering and coarsening it to a new cluster. So the objective is to assign the clusters to portals to minimize this additive. Kind of an additive version of stretch, what we call detour. So the assignment I'll always show with red-shaded regions. These three clusters are assigned to the portal and that red-shaded region. Every cluster has to get assigned, and you can't split up clusters. That's why it's called cluster aggregation. The entirety of any one cluster has to be assigned to a quote. And the details And the detour, we're trying to minimize the detour among the max detour among all the vertices. So, what is the detour? If you look at any vertex d, the detour has these two terms. One is the distance to its nearest portal. This is like its preferred portal. How far does it have to travel to get to any portal? And the graph, the original graph with no clustering. The other term is the distance. The other term is the distance that it has to travel to its assigned portal. How much more does it have to pay to get to its assigned portal? And importantly, this orange distance is within the graph induced on the assigned clusters. So the distance is in the induced graph of like a red shaded region. Okay, so notice in this example, v has a path of length 2 to its assigned portal, but we don't count that. We need a strong diameter type. Count that, we need like a strong diameter type kind of shunk. So its distance to its assigned portal will be three milliseconds. Anything inside the red region, or do you have to sort of force it to start the picture? Like, so the pink things are clusters, and the blue things within them are more. Yeah, so the blue clusters are part of the input. This is a clustering. This is a clustering given to you out front on the graph. The pink things are the output of the algorithm, your assignment of clusters to portals, or you can think of it as a coarsening of the blue clustering. But unfortunately, the coarsening has to respect the portals. So every red-shaded region has to have one portal in it. But answer your question. What's the green distance? Yeah, that's just the distance in the graph from V to is near. From V to its nearest portal. Yeah, just ignoring all clustering. That's just like how far it wants to travel to a portal. Makes sense. But here, so if the delta is zero, it's a singleton, so then everyone just moves to their own so if delta is zero so not every blue cluster has a portal. Every blue cluster has a portal. Is that shortest? If delta is zero, then yeah, yeah, yeah, yeah, yeah. Yes, you're trying to assign everyone to this question. This makes sense. Um yeah, and so for example, vertex V, the detour is two. For example, vertex v, the detour is two, because it has to travel two extra distance to get to its assigned portal versus what I have to travel to its nearest portal. And importantly, the detour is like an additive. But there's some condition you should cluster. I mean, you can just return the original blue things. No, so not every portal. Oh, sorry. Not every blue cluster. Not every blue cluster has a portal. Every blue cluster has to be assigned to some portal. So portals are given to you, as well. Yeah, the portals are part of the endpoint. Yeah, yeah, yeah. You're going to get it. Perfect. That's my next thing. So, what's the best we can hope for? Right, here's a very simple example. We can't have edgeways, and so here's. We can't have edgeways, and so here's the central cluster that has diameter delta, and you have to assign it to one of the two portals. This is the instance that's given to you. This is the entire input, right? But the problem is to assign, right? So we could either assign the central cluster to the right portal, in which case the left white vertex has to pay a detour of delta. It wants to travel distance one to its nearest portal, but its assigned portal is delta plus one away. And of course, And of course, otherwise, if we want to assign it to the right portal, we have to assign it to the left, symmetric, the right, white vertex has to pay at least delta. And so, as you mentioned, the best we can hope for is something in terms of delta. You have to pay at least delta. So, this is a very simple lower bound on what we can hope for, but we can also use this because our scale is now. We can also use this because our scale is now in terms of delta, right? We don't care if we pay an extra delta here or there. And so let's simplify the problem a little bit. And for each of our input blue clusters, we can just choose a single arbitrary representative vertex for that cluster, which will be these orange vertices. And we can just minimize the detour for the representatives. Because any vertex v, not a representative, it's in a blue cluster. And so... And so the difference between its detour and its representatives detour is at most 2 delta. Why? Because let's remember what detour is, right? We have to look at the distance to its nearest portal. So the distance to its assigned portal, right? For the representative versus the vertex V, they're almost delta different. And likewise, since they're both within. Likewise, since they're both within this cluster of diameter delta, the distance to their nearest portal, wherever that might be, is at most delta different, right? So triangle inequality really is at most two deltas. So we're just going to care about the detour of representative purposes. Okay, so yeah. Sorry, why can't they represent it over the nearest detail? That's a good question. So it's because of this strong diameter condition. So, yeah. So, yeah, basically, if you choose representatives poorly, you can cut yourself off, right? If you have your representative here wants to go to this portal, but maybe you have some cluster here and the representative here wants to go to this portal. Cut yourself off, and so this could give you like an infinite detour in the sense that maybe this cluster can't even reach this portal anymore. Because the distance to the assigned portal has to be within. To the assigned portal has to be within the set of clusters assigned to that portal. So it's the strong diameter type of issue. If you only cared about the kind of weak diameter version of the problem, what you said is optimal. You can get a constant times delta d12. Okay, so we show that with this problem for any instance, you can get at most a log delta dtor. To detour. And I'm going to quickly go over the algorithm. So here's an instance. This is the given instance, simplified, not showing any edges. And we'll just initialize things by first, you have to do this. For any portal, look at the blue cluster containing it and assign that cluster to the portal. Now we're gonna again just look at Now we're going to again just look at focus on the representatives for each of the remaining clusters. And the algorithm will is sort of like one of these ball growing type algorithms. We'll go in and round, look at each portal one at a time, and the portal will try to expand its neighborhood of assigned clusters, its red-shaded region. And the way we do this expansion is along these special paths. It's a little messy, but we call them mid-paths. We call them mid-paths. They're really just shortest paths. They're the shortest paths to the portal. So for each representative, we look at the added shortest path to a portal. This is like the green term from detour. What path does it want to take to a portal to? It's a neurist portal. And we're going to cut off the path. We're going to look at a prefix of it, which we call the mid-path, which just stops when it enters a register. Path, which just stops when it enters a red-shaded region. And then from there, the algorithm is simple. These mid-paths just dictate how a portal will expand its neighborhood. So a portal just looks at the mid-paths entering its red-shaded region. So, for example, let's look at its first portal. It'll look at there's just one mid-path entering its red-shaded region. It looks at all. It looks at all the clusters along those mid paths, and it scoops them up into its neighbor. Then it'll flip a coin. Oh, sorry. We also update the mid-paths to maintain this property that they're disjoint from the red-shaded regions. We cut them off, make shorter prefixes, so that they mean they stay disjoint from the red-shaded regions. That's what's shown here. We flip a coin for the We flip a coin for this portal. If it's heads, it'll repeat this step. If it's tails, we move on to the next portal. So we get heads here. Look at the midpaths entering your redshaded region. Look at the clusters along those midpaths. And expand your midpoint. Update the midpaths, maintain that they're disjoint from the redshaded regions, and continue. So I'll just show how the algorithm will proceed. And in the end, we get this clustering, this coarsening of our blue clustering. And this is the output of the algorithm. So you pick the first portal and you added a bunch of stuff, and then you went to the second one, and then you might come back to the first portal. Exactly. So if you go through all the portals in this way, that's one round of the algorithm. And you just repeat until everything is assigned. Assignment. So, why does this give you log decor? So, basically, there's two pieces to it. One is that with very high probability, every cluster is going to be assigned within 10 login, constant log rounds. And this is, I'm not showing the details, but this is. I'm not showing the details, but this is basically because in a single round, if we go through all the portals, that's one round. In a single round, every cluster is going to have a half probability of being a sign. Because basically, if its mid-path ever gets cut off or shortened, then the next coin flip determines either if it's heads, then this portal gets assigned, or if it's tails, it may not. But we always have at least a half probability. And this gives us this log n number of runs. Log out number of rings. The second lemma says that if you don't do too many of these expansions, then you don't pay too much detail. You pay, you know, if you do at most log n expansions, you pay log n delta d ch. And lemma one implies that you don't do too many expansions, okay? Or coin flips, right? The number of coin flips is the number of expansions that you do, and so in total. Is the number of expansions that you do. And so in total, every representative gets log n d tor, log n times delta d tor, and then every vertex gets both log n times delta d tor. So this is just a table from our paper showing that in addition to this general universal standard tree for general graphs, we looked at other special cases. We looked at other special cases of graphs with bounded doubling dimension or bounded path width. And you can get nicer, fewer logs there, basically. And so just some future directions that may be interesting. With the cluster aggregation problem, that's sort of the bottleneck right now in this technique. In most other places, it seems to be fairly tight, and so there. To be fairly tight, and so there is a log log n times delta lower bound. So we're not sure what the right answer is there, but if you could give an algorithm that does log log n, you could shave almost a log factor off of the universal symmetry result. And then kind of much more broadly, does this cluster aggregation problem or this new type of hierarchy of graph partitions have any uses in other network design problems? In other network design problems beyond universal sign. Oh, I have the thanks. Yeah, what? Yeah, so it's really just the key thing is that we're using these mid-paths, these shortest paths. Basically, when you Basically, when you expand a neighborhood along one of these mid-paths, because it's a shortest path, the detour is preserved. So for every vertex along the shortest path, you don't accumulate any detour. So it's like this inductive argument, right? If you look at the expansions one by one, when you expand along one of these shortest paths, for a vertex on the shortest path, you accumulate no detour. And for vertices in the clusters along these shortest paths, you might accumulate like two delta extra detour. Two delta x for detail. I'm just looking at that same example. So if you're if you're cut off, which you can be handy on yeah, so so when you're cut off, but let's say we have this representative whose mid path wants to go here, and we have some other portal whose expanded cluster just cut this off. Just cut this off, right? We update the minpath to be a prefix of it that now ends here. And now, if this cluster gets ahead on its next coin flip, it will actually eat up this cluster too. So this cluster won't necessarily be assigned here, and the cutting off isn't anything. So maybe I'm missing being assigned to that cluster is a bad thing, right? Because it just has to move all the way up there. Not really. Not really, so like the detour. So for this vertex to be assigned to this cluster, it means that it was in some cluster whose representative wanted to go somewhere potentially to this portal over here or potentially somewhere else. But in particular, when this cluster was absorbed by this portal, inductively the detour of this cluster. Inductively, the detour of this cluster isn't too much worse. And now, if this cluster gets absorbed, inductively, the detour of this cluster isn't too much worse. You accumulate just two diameters in each absorption step. Oh, yeah. So, am I right in understanding that every time these midpaths are getting updated, I lose another delta, and there's only log many times this midpath will get updated? Um I wouldn't exactly say the delta loss is from updating the midpath. The delta loss is really from just the fact that you have vertices that are being assigned to clusters that aren't the representative. They have to travel delta to their representative and it's a two delta because you have nearest path, like nearest portal versus assigned portal. So that, yeah. Like the because the mid-paths are all are always Because the mid-paths are all are always prefixes of shortest paths, they always kind of behave nicely in terms of detail. So do you believe there's a log asset? There's a log out there? What's the language? Yeah, that's a good question. Um for a while we believed that log was correct and we were trying to improve the lower bound, but for a while we were unsuccessful. For a while we were unsuccessful, and now we think log log might be right, but we're not really sure. But the whole problem? No, no. For the cluster aggregation. Oh, you mean for UST? What's the correct answer? Oh, that's part of it. I mean, honestly, I have no idea. Between log and some smaller polylog than ours, I don't know. All right, thank you, Dr.