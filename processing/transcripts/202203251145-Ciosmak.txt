to attend in in person. So um let me first start with uh some motivation and and some background on localization. So I'll start with old work of Payne and Weinberger from 1960s who applied basically Bohr's coulomb theorem to obtain this localization and what they had in mind They had in mind as an aim for developing this localization method was Poincaré inequality. So suppose that we have a convex body in Rn and a C1 function on that set which integrates to zero against some log concave measure. So log concave measure has density such that the negative disregard of the density is For guide of the Lens CD complex. And then in that setting, the Poincaré inequality tells us that if we integrate f squared with respect to mu, then we can bound it by the integral of the norm of the derivative with some constant then that can be bounded by the diameter of k only. And how can we obtain such an equality? Well, so if we'll apply Dorsou-Poulin' theorem, which tells that if you have a function defined on a sphere, then there exists, continuous function, then there exists two points on which the function has the opposite values. So our function will take a vector on a sphere, which is equivalent to taking a hyper Equivalent to taking a hyper space and we'll look at the sorry question what the uh what measure will I mean presumably some measure attains the lambda k equal to this bound, right? Yes. Or so what measures is obtained? So what measures is it taking for that? Well, so it's enough to consider one-dimensional measures and I'm sure that these measures are known. But they don't depend on the convex set K. Yeah, well, only the terms of diameter. Okay, so every convex set K there will be some measure that detains for which lambda K is equal to the bound or only surface convex sets K. I'm not sure immediately, so if you can postpone discussion later then I'll be great. Yeah, so the uh going back to the uh Board of Kuman theorem, we look at this function. We look at this function, which is defined on the sphere and takes vector to the sphere to a hyperplane. And then, since the sum of these two, so this is a hyper half space that is defined by the hyperplane H plus, and we have the other half space. So, they have negative, the opposite values, and they sum up to zero, so they have to be equal both to zero. Um so if we have these conditions, then we see clearly that if you have these inequalities both for k intersected with h plus and k intersecting with h minus, then we can recover the original inequality. Therefore, it suffices only to prove this inequality for these two subsets. And this Bolshevik current theorem will work as long as the sphere is one-dimensional which Which accounts to assuming that dimension of k is at least 2. And using this procedure, we can produce a measurable partition of our convex space. And then the conditional measures of μ with respect to this partition will be log-concave. And therefore, it will suffice to prove the inequality in the one-dimensional case. So let me not. Case. So let me not focus on the details. This is just a motivating example. And the question that I would rather like to concentrate on pertains to application of optimal transport to this kind of localization technique. So as I have explained, Weinberger were working in convex geometry and applying the localization technique in the context of convex geometry. Context of convex geometry, where they wanted to reduce certain a priori high-dimensional problem to a collection of one-dimensional problems. And applications include Poincaré inequality and various other functional geometric inequalities. But that method, as we have seen, only could be used in Euclidean spaces because of the Bose-Cohen theorem. The question And the question was: how can we possibly generalize this to various other spaces, for example to Riemannian manifolds? And in 2014, Claritak came up with an idea how to generalize this to Riemannian manifolds. And that idea involved optimal transport with respect to the metric cost function and further generalizations. And further generalizations were conjectured by Claude in that paper, where he presented this idea. And this thought I will be concentrating on this generalization of localization to multiple constraints. Let me just mention that beyond the setting of Riemannian geometry, this localization using optimal transport has been also generalized to Been also generalized to pin-square manifold by OTA and then by Cavalier in non-dino-to-metric measure spaces. So, let me briefly speak about the optimal transport and how we will apply it to one-dimensional localization. So, we suppose that we have n-dimensional weighted Riemannian manifolds, so this is just a Riemannian manifold. Sorry, this is Sorry. This is just a Riemannian manifold with a metric tensor and measure which is absolutely continuous with respect to the Lebesgue measure on that manifold. And we will assume that we have a function which has no integral and such that the first moment exists. And we will consider the optimal transport problem of between two measures, f plus dμ and f minus d mu. And well, we need to. And we need to properly normalize these two measures to be in the exact set of optimal transport. And what will actually be more important to us is the Cantor of Schlubminstein formulation of the problem and more importantly the dual formulation. So the Cantor of the Schrödinger duality tells us that instead of looking at transport of At transport of which minimizes the average distance transported, we can look at the maximum of integrals of the difference of our two measures integrated against one Lipschitz functions. And the controversial duality tells us that these two values coincide. So clearly by Arta scored there is a maximizer of that problem, and we will say that T is a transport way whenever T is a transport ray whenever it's a maximal set, such that if we restrict our maximizer to T, then we will get an isometry. So we see clearly that T has to be a geodesic on our manifold, and the transport set will be a Borel union of some transport race. Then the mass balance condition, which was proven perhaps by Evans and Evans and Galileo tells us that integration if you integrate F on any transport set, then we'll get zero. So as I have already said, these transport rates are geodesics, and what is moreover true is that they will partition our Riemannian manifold up to Lebesgue measure zero. And therefore, we get this partition. Partitioning, we can. Partitioning, we can disintegrate our measure, and the fact that this mass balance condition holds true will tell us that for any conditional measure, integral against f will be zero. So, this recovers partially the Fine-Weinberger approach that I told you at the beginning, but at that setting we also could say. Setting, we also could say the conditional measures will be log-concave. So, let us see what happens in this setting. So, log concavity makes sense on Rn. So, if you suppose that our measure is defined on Rn and it's log concave, then the fact is that the conditional measures are again log concave and they will be concentrated on the relative material of the. Concentrated on the relative material of the geodesics. But since we are in the setting of Fiemannian manifolds, there is a more complicated notion of a curvature-dimension condition, CD kappa n, which is satisfied by this weighted Riemannian manifold, provided this inequality holds true. And here, rho is the negative regarding the density of. Negative regarding the density of mu. So let us see what happens if our measure is flat so that the rich curvature is equal to zero and let's say kappa is equal to zero and capital N is equal to infinity, then we see clearly that the only assumption that we have is that the Hessian is non-negative, which is precisely to say that a measure is not concave. So this is, I just wanted to convince you that this is a far-reaching generalization of the log concavity. And in the setting of Bitina spaces, perhaps a better name for this is the Bakry-M-Merry condition. And if you have not encountered CD condition before, then that's an intuitive way of understanding this, is that the Ricci curvature is bounded from The Rigi curvature is bounded from below, and the dimension is bounded from above. So, what Clartak has proven is that if initial measures satisfy C D kappa n, then almost every conditional measure will also satisfy the same C D kappa n with the same parameters. So, this was that part of the talk on the background, and let me say And let me say now how we would like to generalize this to multiple constraints. So previously we had one linear constraint, which was just that the function was integrating to zero against mu. And now we suppose you have some finite number of functions, each of which integrates to zero against mu and we would like to know whether there exists To know whether there exists a partitioning of our Riemannian manifold into k-dimensional pieces for which the associated conditional measures will have also zero integrals against all of these functions f1 up to fk. And we will also like the pieces to retain the curvature dimension properties of the initial manifold. So, there would be plenty of applications of this if such things was true. So, I will just briefly say what the applications would be. So, we could obtain some bounds for high-order eigenvalues of Aplacian. We could also apply it to multi-bubble conjectures, which are generalizations. So, multi-bubble problem is a generalization of isoparametric problem, which Parametric problem, which already was mentioned by Yair in the Tuesday talk. Also, Gromov's waste inequality was also mentioned by Yair in the talk. And there are also related conjectures of Kanelovash and Simonovic and Bergen hyperbling conjecture. And the conjecture of Kanan Lovash and Simonovic was also discussed by Yair and Dan, so I'll not concentrate. Done, so I'll not concentrate on this now. So, such generalization was conjectured by Clartak to hold true in Euclidean spaces, and this is what the rest of the talk will be devoted to. So, if we have a probability measure and some k functions that integrate to zero against that measure, To zero against that measure, we can think instead of a vector-valued function that has total mass zero. So, in the previous setting, that would be just the probability function with vector-valued density f1 after f k. Yeah, m is scaling, that's something. Sorry for the but but that's good notation. Um and previously what was the most important for us was the Important for us was the optimization of Lipschitz functions. So here we also consider this optimization problem, but now in place of one dimension of real-valued Lipschitz functions, we consider vector-valued Lipschitz functions. And we consider these integrals. So clearly, this optimization problem admits a maximizer if If measure mu has finite first moments, and we will say that a subset S in Rn is a leaf whenever it is a maximal set such that if we restrict the maximizer to that set, then it will be an isometry. So, this clearly is a direct generalization of what was happening in the one-dimensional case. And A, I'll call it that it's a transfer. And A, I'll call that it's a transport set whenever it's a bored union of some distortion. So suppose that our measure μ is absolutely continuous with respect to the Lebesgue measure, so then in the one-dimensional case, the mass-balance condition holds true, so that the total mass of any transport set is equal to zero. So so n is always less than n, is that right? Um well, mm Well, yeah, this is the main focus. In terms of applications, considering m greater than m doesn't really make sense. At least maybe there are some applications, but it's not immediate for me. So, yeah, we can think that m is less than n. So, this was conjectured by Clartac that the measure of any transport set will be again zero, so that we can Do the same thing as we did in the one-dimensional case, and that the conditional measure would be also integrating to zero. However, this is false in general if we take m strictly larger than one. So, if you know that this is false in general, then you may think that maybe this is true if you replace the set of all one Lipschitz maps. Of all one Lipschitz maps with some strictly smaller subset of that map. But then it turns out that this is still false, so there is no such set for which this will work. However, this is not the end of the story. There are some ideas how to use this machinery to actually obtain this mass balance condition. I will speak about this later. So we considered here this dual problem, and there exists also a primal formulation of optimal transport of vector measures. So we assume that we have our n-valued measure on our n with total non-zero and with finite first moments. And we consider the optimization problem of minimizing. Of minimizing the average transported distance where we integrate against the total variation of pi, where pi belongs to the set gamma of mu. And gamma of mu is the set of all vector measures on the product for which mu is equal to the difference of the marginals of pi. So here we recognize that it's very similar to the standard formulation of To the standard formulation of L1 optimal transport for scalar measures. However, we don't have two marginals, we have just one measure with total mass zero, so we don't assume that the marginals are fixed of pi, but rather that the difference of these marginals is fixed. And if you look at this for m equal to 1, then by counter-boarding duality, you can clearly see that actually this gives the same value as. As the version with the fixed margins. Great. Now there's some version of this, sort of the high here. Sorry. Sorry. So there is a theorem that actually these two these two optimization problems give the same value. So that this infumo. So that uh this infumum is equal to the supremum also in the vector variant set. Uh and let me first speak about one condition under which the mass balance condition holds true. So suppose that our measure mu is absolutely continuous, has finite first moment and the total mass is zero and let v be an optimal potential and we suppose also that there exists an optimal potential pi which has absolute Which has absolutely continuous marginals of its total variation. And this condition is, if mu is absolutely continuous, then this condition is clearly satisfied in the one-dimensional case. And it cannot be true in the higher-dimensional case because here I can prove that if this condition is satisfied, then for any transport set, the mass balance condition holds true. True. So, this was a part of the talk that was concerned with the mass balance condition in the vector variable case. And now, let me look what happens with the curvature dimension properties in this vector-variable setting. So, the first fact that is true is that if you have only one lichens map, then the leaves of that map So essentially what you're saying is that things are well behaved in the sense that there's no deg degeneracy and things don't degenerate on on lower dimensional uh space. And they behave as expected. So is that the right interpretation that this lack of mass balance is for dimension offsets? Well, yes and no. Yes in the sense that yes sense that if we are concentrated on only on the on the set of highest dimension then mass balance condition holds true indeed but there are also cases in which the transport can be concentrated on lower dimensional spaces yet the mass balance condition still holds true and I will explain it at the very end of the talk so coming back to this partitioning it holds true It holds true also in the vector value setting that the leaves of M1 inches map form a partitioning of the space. So and this also holds up to the backnounce. And in the one-dimensional setting we've seen that the transport ways were geodesics and here they are closed and convex sets. And the dimension of these sets is at most heavy. And we may again disintegrate measure mu with respect to this partitioning. And if we assume that measure mu satisfies C D kappa n condition, then what I can prove is that for almost every leaf of dimension n, which is the maximum dimension, a conditional measure will also satisfy curvature dimension condition with the same parameters. And it will be also concentrated on the relative interior of the leaf. So, this partially resolves another conjecture of CLARTAC in the affirmative, so the conjecture basically says that this should hold true for leaf of any dimension. So, let me say what is the idea behind the proof of that fact. Of that fact. So basically, the idea is to perform a change of variables and then work with this change of variables and differentiate it and apply some estimates to recover the inequalities which need to be verified for the curvature dimension condition to hold true. And the idea builds upon the work of Robert, Caffoy, and Feldman. And basically, And basically, the formula for this change of variables is quite simple. If we take V to be the maximizer of the dual problem and we will look at the fibers of V and R will be a local parametrization of a fiber, then we just need to take a point in a fiber. In a fiber and apply to some vector B the adjoint of the derivative of B. And this formula actually provides a local diffheromorphism if we are working on the set of highest dimension, of the list of highest dimensions. So, what is more, what also plays a role in this proof is the Are the tangent spaces to the leaves? So, leaves are closed and convex sets of fixed dimensions. So, we can look at the tangent space to these leaves. They have well-defined projection, orthogonal projection on these leaves, which I will denote by P of X. And if we apply area formula and then a Fibonacoran, then we will see that the density on the leaves needs to be. The density on the leaves needs to be multiplied by this factor. And actually, the only thing that we need to care about is the factor that will multiply the density because we only are interested in the logarithms of the density. So here we see the second fundamental form of a fiber, which is, I think, it's quite interesting. And also Quite interesting. And also, another thing that is important is that if we are looking at the relative interior of the leaves of n dimension, then the derivative of V is itself Lipschitz, and we have this strengthening of one Lipschitz condition, which is controlled by the sigma, where sigma is the distance of Distance of points to the relative boundaries of the leaves. So now let me say a few words how the situation differs. How does the situation differ for leaves of lower dimension than M so if you look at the derivative of the maximizer on the tangent space, then it is a fine Space, then it is a fine, then the maximizing tangents on the leaf is a fine map because it's an isometry. And then the derivative indirection of the tangent space is constant and this isometry independent of the choice of x in the relative integral. But what can happen is that there might be directions on the leaf orthogonal to the leaf. Orthogonal to the leaf on which the derivative will be still isometric. And actually, what happens is that whenever at a point x and some direction derivative is isometric, then for any other point in the relative material of the leaf, derivative will be also, well, it will exist, will also be. Well, it will exist, will also be isometric, and will be equal to the derivative at the other point in that direction. And well, actually, we can consider this all the subspace of points on which derivative is isometric, and this will be independent of the choice of x on that leaf. And I will call these subspaces ghost subspaces. Ghost subspaces because they play an important role in analysis of the partitioning, yet they are not visible on the level of partitioning. So I will say that a gross subspace is trivial whenever there are no directions on which derivative is isometric, which are perpendicular to the tangent space to the leaf. So equivalently when Equivalently, when the Gauss subspace is equal to the tangent space to the leaf. So, as a first step for establishing curvature dimension condition in the setting of lower-dimensional leaves, I can prove that if Gauss subspace for S is trivial, then the conditional measure is absolutely continuous with respect to the Hausdor dimension of the correct dimension. So, this is a first step, of course, in establishing the curvature-dimensional condition, because that requires the density to exist. What is moreover true is that if you have an optimal potential for a vector measure for which all the Gauss subspaces are trivial, then also the mass balance condition holds true. Holds true. So it seems that the Gauss subspaces are very worth to look at objects because if they are trivial, it seems then both the C D condition would be true and as I can already prove that the mass balance condition holds true. Sorry, what does it mean? It means that there are no directions in each direction. Directions in each derivative is orthogonal, which the directions are required to be perpendicular to the time to space of a leaf. So, if a leaf is like that, there are no directions in which. So, it might seem simpler, well, because the main gain, if we assume that the Gauss subspaces are trivial, is that we can show that the tangent spaces to the leaves behind To the leaves behave in a Lipschitz way. So you might think that if derivative is an isometry, then it might be even easier to prove that this will be behaving in a Lipschitz way. But let me just convince you that it's not that obvious because if the repertof is an isometry, then we have no control on the behavior of this Gauss-subspaces. So we can have, let's say, two little We can have, let's say, two leaves like that, and in the target space, they will also look similarly. Whereas, if we have three AGO subspaces, then we'll have some contraction here in the target space, and it will allow us to infer some estimates. So, it's not the case that isometric the the larger the gold subspaces, the easier it is. So, this is all that I wanted to So this is all that I wanted to uh say here. So let me thank you very much for your attention. And perhaps before the question, let me take this opportunity to thank very much the organizers for organizing this workshop. I believe that it was as beneficial for all of us as it was for me. Thank you, Kristov. Yes. Now, do we have any questions for Krishna? Here or online? If you're online, just unmute yourself and ask what you see. I had a very difficult question. I think it's just probably more. I think it's just probably my black hole. Any day, when you wrote your function F there, is it obvious that you can take those parametrizations R in a sort of nicely dependent way on the fibers? Well, so R parametrizes a fiber. But now you want to have fibers. Yes, so it's clear that I can take them in such a way that they behave in a Lipschitz way. And you mentioned there are ten. And you mentioned there are counter examples where the transport sets don't have balance masks. Where do you decide the counter examples? Uh where? Yeah. Uh you can find this counter example here in the second flavor here. Yes. I mean, I don't know if there's can you say in one minute what the idea of the counterexample is or not? Yeah, it's not that difficult, so um I think I I can do this. Uh basically the idea is to um is to consider three points x1 x2 x3 and since we assume that our measure is absolutely continuous then we take some balls around these balls and our vector and we take some three vectors v one v two and v three such a way that the vectors sum up to zero Vector sum up to zero. And then if you assume that the mass balance condition holds true, then any point belongs to some leaf. Then if we take a point in that ball, then it belongs to some leaf. And because the mass balance condition holds true, then this leaf has to touch these two bolts. Is two bolts. So the sniff has to look like that. And this shows us that if we take optimal potential for this problem, then for the problem with here with some epsilon here, the radius of this ball, then it will be close to being an isometry. is an isometric. Uh but then what we do we uh we show that uh if I take epsilon to zero uh then uh the optimal potential has to converge to optimal potential for the measure supported on the three points. Uh yet the quality and because the optimal potential with epsilon here, non-zero, is close to being alize. Is close to being isometry, then we see that the optimal potential in the limited case will be an isometry. And therefore, it would mean that any optimal potential for any discrete measure supported on these three points with V1, V2, and V3 are finally independent, would have to be an isometry. And it is quite easy using duality to construct such vectors and points for which this doesn't hold. And points for which this doesn't hold true. So, in this example, both m and n are equal to 2, is that right? Yes, but actually, in any dimension, it's enough to take two points. Because this is enough to in a way to make this optimal potential. Just let me say that it's enough to consider. Just let me say that it's enough to consider two points in any any dimension greater than two points. It'll be a pleasure to host everybody, mostly online, but also in person here. Uh that's it from us in verse. That's it from us in verse. You can't see me, but I'm waving hands. Thank you so much, everybody, and enjoy your week. Thank you, Samari.