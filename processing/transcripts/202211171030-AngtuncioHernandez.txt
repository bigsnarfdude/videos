Quick, almost over. And thank you, Richie, and Nicolas, and Mark, and Cecil, if you are seeing this. Yes, another Mexican, Osvaldo, and I am working with Anita Winter in Essen and Gabrielle. It's in the University of Liverpool. We are working in this new topic for us about, so in some roughly simple, silly words. Silly words. This talk is about we are going to plant a seed and then put water, let it grow, and wait a long time to see grow a tree, a beautiful tree, a real tree which is the continuous random tree. I'm going to be very, very roughly speaking all the time, so every sentence is going to be before that. Roughly speaking, this, but it will be compensated with a lot of intuition. I hope you can. A lot of intuition. I hope you get the idea because I'm going to put some gibs to see the model. And basically, it's going to be how we did a construction of these trees. Okay, we'll start with the continuum random tree. What is the continuum random tree? You have heard about it. Here we showed some pictures, but let me give you this construction. This was by Adams. This construction. This was by Aldus, and it says that first we start with a graph and then with a spanning tree there, meaning that you have all of the vertices. It's a graph which has all of the vertices, no looks, and maybe a different set of edges. The uniform sparring tree is of course choose one uniformly at random. Let Km be the complete graph. So every So, every you have n vertices, every possible edges between every possible pair. And consider the uniform spanning tree on the complete graph. It has been proved that after this rescaling, the uniform spanning tree converges weakly to the CRT. So, if you do not know what is the CRT and I give you this convergence, this definition, it does not give you any intuition, geometrical intuition. Intuition, geometrical intuition of this object, the limiting object. So let's go to another construction. This is the root growth with regrafting construction. It has been done by Panita, Evans, and Pittman. And so let's start with an P, an homogeneous Poisson process with some arrival rate. So just think about the real positive line and put some points there. There. Okay. Then those points call them the cut times. They are going to be the successive arrival times of your Poisson process. So we are going to grow a tree. At time t, we are going to have a tree of length t. And so we start at time zero with just a point and then continue the And then continue the continue growing your point or let the time grow at unit speed. And then you are going to just wait until the first put time. Your put time, let's say it was at time tau 1. Then you wait until tai 1 and your root will always be in the very last time that you add your points. This is not going to be the root. And this is going to be at time tau 1. At time tau 1, what we are going to do is sample uniformly from this tree a point. Let's say this guy. And then we are going to cut this path and paste it here. But like this. And then between time tau 1 and time tau2, we are going to also grow. And we do the same at time tau2. Choose uniformly one point here. It can be here or here. It can be here or here, and then cut and paste it down in the ball and then grow again. Is it clear? You say uniformly chosen from essentially concatenating all the edges. Yes, you can say I can concatenate all the edges, or you can say, because this guy comes from a say at time t, it comes from an interval of leg t. So you just choose a uniform point at time t and good and pa t. IT and good impact. So if you cut at the mission point, you treat it well. Yes, exactly. I am going to mention that in one second. Yes, yes? The tree is rooted, right? Yes, the tree is rooted, and the root is the last point that you are adding. The root is moving, let's say. So every time the root is here. So that is why the root is growing, because whenever you are deterministic. You are deterministically growing the root between the squid planks, the root is way below. And that is also, I like really to do the root always below because the trees grow, the real trees grow like this, not like this. To the loud, yeah, yeah, to the top. Okay. And then it turns out that, so we call the UN. So, we call the UNs the cut points. So, whenever you choose uniformly, you choose the QUIT point. And after rescaling, it turns out that this tree converges also to the CRT. But this gives you more intuition of what is the CRT because, as she was asking, what happens in the limit? Will you have only two vertices which has two children? Why? Because it is with probability zero, you are going to have a good time here. You are going to have a good time here and put this guy and paste it here having three children. That is not going to happen, right? Because they are uniforms. So at the very end, you are going to have something which has only two children. And also, you are not going to have an edge which is positive because the infinitely many uniforms are going to cut every segment into small pieces. So the leaves are going to be dense. You are going to have dense leaves, all of the Thence leaves all of the between all of your chips. So this gives you a more intuition what is a limiting object. We have seen some simulations. Okay, so now the question. Is it possible to define a discrete root road we regrafting in, for example, the complete graph? In a sense that what what Adus proved, that is that the uniform spanning tree pre-scale converges to the CRT node. To the CRT, no? And this is kind of, let's say, static in a sense that you have your tree and then you start to converge to this guy. And in this case, we call it dynamics on the tree because you are going to have a process which every time it's evaluated or tree evaluated process and starts to grow also to the CRT. Can we do this construction? The root world will graph them in the discrete. And of course, the answer. And of course, the answer is yes. And the answer is given by the Aldos Brother Markov chain. So, what is this guy? So, I'm going to put a GIF. We are going to have nine vertices. So, we put a random walk here. The point is here. Then it moves to the right, then it moves. To the right, then it moves up, and whenever you move to a new vertex, you add this edge. You move to the right, you move down, and at this point, it will move to a visited vertex. So, what are we going to do? We force this edge by erasing the other edge whilst creating a cycle. And then I stop the GIF here, but at this point, it can move to whenever it decides. If you visit a new edge, if you visit a new vertex, you put this edge. You put this edge. If you visit a previously visited vertex, then you force this edge. Can you see why this guy is similar to this guy? That is the question. So, and this guy, this Aldus brother Markov chain is going to be a Markov chain, take values in space of rooted spanning. In the space of rooted spanning trees of the sub-trees of the graph. And it turns out that this guy has an invariant distribution which is the uniform spanning tree. So whenever you, now you visited all of your vertices in your graph, then it's a connected graph, finite graph. Then you are going to have this stationary distribution or you are going. So, you are going to obtain in the limit, so whenever you let run your algorithm in your graph, you are going to have the uniform spanning tree. And you mentioned it looked like you always have some topology or some neighborhoods, you know, you go to neighboring points. Is that true? So the result is for general finite um connected graphs. In the give I only put the nine times nine. I only put the nine times nine and during this talk we are going to discuss the the torus which is kind of the graph that I put. But so yes you you have your your graph and your random walk is moving there in the edges of the graph. Okay, so this is a lot but I am going to tell it in words. Why this guy, this Aldus brother Markov chain, Aldus brother Markov chain converges to the root growth with regression. Like in the first time you see it, it's like they are really different. But then we can have a picture of that. Let me put first the so this is again the same picture. Now we have a root there and we are going to construct a tree there. Whenever we are visiting new edges, the root is growing. But when we visit But when we visit a previously visited edge, what we are going to do is cut that and paste it here. So now this is the root, this is also the root, and I put in green toss that leaf. So you can see that at the very end, you are going to obtain the same. The address brother markup chain will give you a tree which you are also root growing and regrafting. Is it clear? So whenever you force this edge, erase this edge and force this edge, Erased such and forth the search. It is the same as cutting this part and pasted it in the roots. Okay, and what is the result that Anita gave? It says that you give me your Aldus Brother Markov chain in the complete graph. The complete graph is the most beautiful of this graph because it is really easy to go from one vertex to another just by one edge. And then do not And then do not start with. In this figure that I showed you, we started with a point. So we have a point and started a random object. But you can also start from a sub-tree. Give me an initial sub-tree, y and zero, and let's say that the total length of your initial sub-tree, it will go to infinity. If you rescale everything and you let grow your Address brother Markov chain there, you are going to obtain in the least. Going to obtain in the limit, their root growth viral grafting process. So I hope that it is clear that the root growth virgrafting is the limit of the others product because they are almost the same dynamics. Okay, and the nice thing is that if you wait long enough, then the stationary distribution of your chain will be the CRT. So it's a markup chain that takes values. Chain that takes values on trees, and at the very least, you are going to have the CRT as the stationary distribution. Okay, can this be extended to other graphs? The answer is yes. And it has been done by Percy and Rebell, Jason Schwansford, E and Asap Nagnias et al. What they do is to send it to this high-dimensional graph. For us, D is at least five. For us, D is at least 5. This works very well. And it says that you can do it for the discrete torus, the hypercube, the transitive expander graph, the complete graph. And for us, the torus will be, the discrete torus will be, let's say we have this lattice in set D and we have edges between adjacent points. And the extra condition is that these. The extra condition is that these guys in the very boundary will join the guys in the other boundary, you know, like this. And also this guy joins like this and so on. This is going to be the graph that we are going to work on today, the discrete torus of size n. And it turns out that so they proved that they proved it only this thing. That you give me your uniform spanning tree. You give me your uniform spanning tree on these graphs, and it will also converge to the CRT. The most resemble thing that shows something about the convergence to the root growth regrafting is just taking consideration of one point. Give me your root. Fix one point here and start your root growth with your graph. And start your root growth with your grafting. So just consider the root growing, then pasting, and everything. And look at the distance between this red point and the root. So if you plot that thing, it will start to grow linearly. And then whenever you choose the code point below this line, then you are going to paste it. And the distance is going to fall. And then row is going to fall. That is the most thing that has been done for these guys. For these guys. So, our construction says that we can recover not only the distance between the root and one point, we can recover the whole structure of the tree and to prove that this converges to the root world we're grafting, but also in this torus. What is the difficulty of the torus is that, of course, So, whenever you are telling me I want to converge to the CRT, then in the complete graph, of course, you can hit everything with the same probability, then you are going to kind of move a random walk, like a brown motion in the complete graph. But in this case, it will be more difficult because, for example, if you have, let's say, a sub-tree like this inside here, and let's say you have And let's say your root is here. So it is more difficult to hit this part inside because you can only hit the boundary of this guy. So it will be not that uniform. You cannot see like a random walk convergent to the CRT here. No, to the random walk moving like a burning motion in the toes. Okay, so I will go fast in this slide. Go fast in these slides because it is just we discretize the space and prove that we can the root quote we were asking, we can discretize it and the discrete guy converges. So just consider this triangle in R2 plus and consider these small squares of size Cn that goes to zero and That goes to zero, and we want also the good times and the good points, both disputes. So, in this case, your Poisson process now in this small triangle has a point here, and then you say, like, the first put time is six, and it was at height 3. Okay? And with all these guys, this is the important part: that you record what is. That you record what is the height whenever you have a point of your Poisson process in this discretized version. And then, so the discretized version is just as simple as my thing. You also have this discretization of R2, and whenever you are now going step by step, root growing. But at this point, at time six, then you are going to cut. Then you are going to cut at high tree and paste down and do also the same deregrafting. And then from time 7 and 8, you are good growing, and at time 9, you are going to also regraft. So you can believe me really easily that these dots are for the crosses? So the crosses are the points. So the crosses are the points of your Poisson process. Ah, okay, so yeah. The location is not that important. The fact is that there were two in each of them. Yes, and also if there are several, you choose the minimum one. And you only have to consider the time and the height whenever you see a point. Whenever you do not see a point, then you route growth. When you see a point, you will regard it. The height tells you how to break. Sorry, sorry? The height tells you how to break the chip? Yes, the height tells you. Yes, the high tells you that you have to it says like you choose the third vertex from the root and you could there you could there and paste it in the root. In this case you could at time 3, at height 3 or distance 3 from the root and paste it in the root again. And in the next example, at time 9, you could and you paste and where you could at time. Where you could at height for and you paste in the roots. Which branch? Which branch? It is the distance between the root and the. So every one of those guys has a label. Let's say the one, two, three, you are putting a label in each vertex. And then you look for the root, which has as distance four, I suppose. Maybe I put it wrong. Let's say. But each of the little edges has the arrival time when it grew. Is that? It is just a one. It is just a one when they arrive at it, they have the label, they label whenever you put them. And then you pick the fourth one. Suppose that is the fourth one. One, two, three, four. Maybe that was wrong. Okay. But the thing is that look at the guy which is at distance four from the root in the second cut. Okay. And then you believe that this guy that the S this X' that I it was in the GIF converges to the root growth quadratic. Because it was just a disquietization of this root growth quadratic. Now the thing is to construct an XN which will be very similar in some sense, a Roma Hauser sense. I'm not going to discuss a lot about it. But these three This tree, we want it to be very, very similar to the discrete root growth we're grafting. And of course, because the root growth we're grafting converges, then we are going to have convergence of our construction. But this guy will be in the torus. These guys are in a space, like we have the triangle and we constructed a tree. But this guy will be in the torus. Then let's construct kind of a similar guy. Kind of a similar guy as the Aldus brother Markov chain. Had written this, think about this other convergence. The Aldus brother Markov chain converges to the root growth we were graphing. No, this is the result of a miter, and we want this spot in the toes. Okay, what is saying there? Okay, what it's saying there Now we have a random walk W in the torus in that guy with d at least 5 The size that we are going to let run our random walk will be n to the d half is the square root of the volume the number of points in your torus as n to the d and let it grow to square root given a path lambda Lambda, we will let loop eraser of lambda will be erasing the loops how they are arriving in chronological order. So we have our random walk moving like this. And then we are going to erase loops as they were created. We erase this loop. We erase this loop. And then this guy. What we are going to have is just a path. What we are going to have is just a path, look less, of course. And so there is this simulation. Between, so we start a random walk there, and then we move in the torus. Why do you see that that point is moving from those spaces? Because the torus, whenever you are here, then you move to the other side and so on. And it starts to move. Whenever it touches itself, it erases that. It erases that look and then keeps moving. So there is another simulation with more vertices, I suppose 80, and then it also starts to move. And at some point you will see a really big graph. And the thing is that when you have your big D, this will converge to the CRT, which is well, but that's it, the three-dimensional. Yeah, yeah, of course. In this case, you could not. Yeah, yeah, with D3, with D equals 3, Sarah has worked with this. And she said, of course, you are not going to see the CRT there because that is impossible. I have proved it. Okay, but if you didn't prove it, then you will see maybe there is the CRT there. And then And then, an important point. So, we want the distance between. So, give me your uniform spanning tree in your graph. And give me two points, x and y. The distance there is on a unique path between them because you have a uniform spanning tree, a tree. That has the same distribution, but this has been proven by Robin. That distance is the same as you give me two points, start a random walk here. Start a random walk here and let it move until the first time it hits this guy and erase the loops. And that is way more simple because, of course, construct the whole uniform spine tree is more difficult than just a random walk between two points and the residues. And that is one of the nice things that we have. And the main idea to do this construction is as follows. Consider that you have your random walk. That you have your random walk with size, or you let your random walk run until time n to the d half times d, the square root of the content. What we are going to do is cut it into small pieces. The pieces are going to be of size roughly r. The r is going to go to three. How many pieces are we going to have? How many pieces are we going to have there, of course? And to the d half already. And think about those segments as guys WAI, where AI is roughly the first R points, then the next R points, and so on. And let's consider these guys. So it's telling you that one segment, one of your segments in your random walk, hits a previously constructed loop arrayed random walk. Peraised random walk. If that happens, you consider this indicator 1 and the s is the same as before, but for segments. And the main idea is that the main idea is this. First, you choose your first segment of your random walk, then loop race, then your second one, and then loop race, and so on. At some point, you are going to hit a previously contrasted Are you going to hit a previously constructed segment, and what you are going to do and then what you are going to do whenever one segment hits a previously constructed segment, you just erase a little bit of this, because that was the Alders Prodell algorithm. You force this edge, and then you erase the edge that makes a cycle. This guy, well, we should. This guy, what we proved is that this guy converges to the root growth with production. Okay, I'm going to skip this, but they are very similar. Your segments in your torus, this is the nice part of the take-home idea, is that your segment in your torus can be roughly seen as your points of your Poisson process. And the points of the Poisson process, you have everything ID and really nice, then you can couple them to show. Then you can couple them to show that you have convergence to the root of the grafting with the process that is there. And I think that's it. I have a question as well, though. Here you were very casual in erasing that edge, but in the first gift that you show us, you erase kind of the first edge. You erase kind of the first edge, like once you close a loop, you you erase the f the the edge next loop. Does it matter? It does not matter. So at the very end, you can erase, you erase it, the guy which is in the intersection between the segments. But you can also erase that. Because that will give you like an extra branch, but then in the limit, it doesn't matter. Exactly. That's what I want to say. You can also erase this. What I'm like, you can also erase this guy. You can also erase the half segment at the right. And the thing is that this guy is of lower order than your scaling, that n to the d half. So at the very end, you will have just a branch point with two guys. Because this small segment, we will interpret. But, so Gabriel says that it is very difficult to define the distance in the so this as a graph, the distance between these points. The distance between these points, and just if we erase this guy, it's easier than erasing this whole guy or the next guy. Because you have to do a lot of distance between these guys. Okay. The size of your segments, it would be a microscopic and the scaling limit. The size of your segments becomes microscopic and the scaling limit. So that's why these are points, so it doesn't matter where you're based. So what is the order of the these guys are of the order roughly? These guys are of the order roughly, let's say, n to the two point something. It's it's like a 188 or something like that. Two point almost the only thing that you need is that to be bigger than the mixing time. The mixing time is whenever you go to the station. So it's bigger than two and smaller than think about 2.1. Don't bug buttons. Okay, I think we have to thank the father again and set the next one to be a waiting time.