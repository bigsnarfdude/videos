And be there in person, but I'll give him my talk here. It's about understanding our loop formation with three polynomials of RNA secondary structures. All right, so this will be, this talk is about nucleic axis structures. And so a DNA structure is a double helix made of two anti-parallel strands held together by hydrogen bounding. And a single-stranded RA. And a single-stranded RNA could also photo onto it itself, forming a secondary structure like this. So, this is like a single-stranded RNA signal structures. And if we have like base pairs like C and G and A and U, and then they pair with forming this hydrogen bound, and it can form these RNA secondary structures. And it's made of like. Made of like stems of base pairs and these loops of unpaired nucleotide, like this, and they have different names, like the ones at the end are hairpin loops. And then if it branches with more branches, it's multi-loop, and it has a bulge and interior loop like this. To study RNA segment structures, a useful way is to use graphs, especially. Use graphs, especially trees. And RNA signature structures can be represented by trees. For example, like we have a straightforward representation where we put a node in a tree at each loop and then connect two nodes with an edge if they're connected by the stems of base pairs. And there are multiple ways to represent these RNA-signator structures with. These RNA signature structure with trees. Depending on what kind of information that we want to record in the trees. And to study these tree structures, actually any structures like not structures or length structures, the three-dimensional curves. If we have invariance, have invariants, then be a great thing. And we can represent these structures with invariance. And same here for trees. So why do we need, so we can represent these trees with polynomials. So why do we need these polynomials? Because we want to actually want to know whether if two trees are isomorphic or not. And if they're not isomorphic, how similar they are. They are. And invariance is a really great tool for that. So, for example, here we have like three rooted trees, and actually, the first two are isomorphic, and the third one is not isomorphic to the first two. And then we want to know how like how different they are. And if we have two RNA-second structures, we want to know how different they are. And we want to have a measure to compare them. A measure to compare them. And a tree polynomial, an invariant, is a really useful tool. And now I'm going to define this tree polynomial. And I'm going to say that it's one of my research showing that this polynomial is an invariant for rooted trees. So with this polynomial, we actually define it recursively. Polynomial, we actually define it recursively from the root, from the leaves to the root of the tree by multiplying and n plus y, simple recursive formula. And we'll see how to compute the polynomial for a tree in this example. So if we have only a single vertex, if the tree is only a single vertex, tree has is only a single vertex then it's just an x and if uh it is rooted at um if it is a rooted path like this then we just multiply whatever is down down here is just x multiplied by one and then plus y and if we have a rooted path like that we just multiply another y and then whenever we go up one level we just plus another y and if we have a cherry like this it's a rooted tree rooted at here and if we uh then Here and if we uh then what we do is we put x at each of its lifts and then we multiply what's down here and then plus y and so the polynomial at the root will be the polynomial that represents this the tree. And similar here, if we have like three leaf vertices, we just multiply these three nodes and then plus y. And if we have a tree that's constructed by joining these two subtrees, Joining these two subtrees. And what we do is we multiply the polynomials for these two trees, x plus 2y and x row plus y, and then we plus another y at the end. And we can FOIL that, have that. And so same here. This is the only subtree of this root. So what we do is just we plus another y. And if the tree is constructed by joining these two. Is constructed by joining these two subtrees. So you probably know what we should do. We multiply this polynomial and this polynomial that represents this trees down here, and then we plus y. So, and if we FOIL that, this polynomial actually represents this whole tree. And this polynomial is kind of interpretable. We can interpret the information about the tree from this polynomial. The information about the tree from this polynomial. For example, the leading term, the degree of the polynomial, it tells us how many leaf vertices in this tree. Like here, we have like six leaf vertices, and each of the term can actually be interpreted in a way so that we know that the structure of the tree. But we're not going to detail about that. So the important, like the Like the important interpretability is one of the important features of the tree representation. And another thing important is that this tree polynomial is actually a complete invariant for two rooted trees. And we can also generalize for two unrooted trees. So that means if two rooted trees or unrooted trees are isomorphic. On rooted trees are isomorphic if and only if they have the same polynomial. Right, so that's a good thing because now we can write trees as polynomials, and there is a one-to-one correspondence between these trees and the class of bivariate polynomials. And the polynomials can be written as vectors or matrices like this. Like, like this. And these are like coefficient matrix, like x squared plus y. We do have like, we put like one here and one here. That's the coefficient of the two terms that we have here. And so now we can basically represent trees structures with vectors or matrices, which are compatible with modern data analytic tools like Analytic tools like machine learning tools or distance-based tools. There are like a vast lot of tools to choose from. And now we have a tree polynomial representation for RNA secondary structures. So basically, we can represent these RNA secondary structures with trees. And for each type of tree, we can compute its. For each type of tree, we can compute its tree polynomial. And since there's a one-to-one correspondence between the class of polynomial and the rooted trees, and the rooted trees represent the RNA second structure, we can actually represent these RNA-second structures with vectors or matrices, as we just introduced. And with this, we can do a lot of things. We can like compare non-coding RNA secondary structures, and we can like infer from like the structures of non-coding RNAs. But here in this talk, I'll be focusing on R loops. And R loops are a class of abounded and functionally important. Class of abounding and functionally important and non-canonical nucleic access structures. So that consists of an RNA DNA duplex and a single-stranded DNA. So it usually happens during transcription when the newly synthesized, newly transcript RNA is paired with one of the DNA strands. And so here it's like an illustration of an R loop. loop and um so um uh so my hypothesis or our hypothesis is that um whether if the RNA so one once um trans transcribed or synthesized after from this polymerasis this RNA would form into would fold on onto a cell forming a co-transcriptional RNA segment structure so I hypothesize that these RNA second structure That these RNA-second structures may be related to the formation of R loops. So we studied this correlation between the co-transcription RNA signal structure and the R loop formation with an in-silical experiment. And I'm going to show how this experiment is designed. Okay, so from the experimental list, we get the sequence of a plasmid. Sequence of plasmid that are known to form R loops. So this is the sequence. And we also get, we're using a smurf sequencing and like bisulfide treatment, we can actually get the probability of our loop formation from experiments. And so we actually get the data from experimentalists. The data from experimentalists in what I mean, one data is the sequence, another data is the probability of R loop formation that tells us the probability of R loop formation at each site in at each nucleotide of the sequence. Right, so these two are actually the data that we get from the exterminalist. So, what we do is that we have a sliding window on this on this sequence of the DNA plasmid. Of the DNA plasmids. And here the sliding window has lens 50. And in the actual experiment, the sliding window has a 200 nucleotide long. And we get this sequence in the sliding window, and we convert this sequence to its corresponding RNA sequence. And then we predict the RNA signature structure using a co-transcript. Using a co-transcriptional RNA folding model called Dr. Transformer. And we're going to have a, so there's a typo here. It's not a, it's a co-transcriptional RNA folding model. And we get an RNA segment structure like this. And once we have this RNA segment structure, we can represent it by a tree, and then we compute its triple anomaly representation. So here we basically So here we're basically just going to compute one simple one simple like a quantity from this tree polynomial representation. We compute its coefficient sum. We basically add up all its all its coefficients. So in this case, we have a polynomial x plus 7y, and its coefficient sum is 8. So this is the in silico experiment where we get where we have a Where we have a DNA sequence and we acquire a coefficient sum for each sequence in that sliding window. So here is a toy example that we have. So suppose that this short sequence is the DNA sequence of the plasmid, and the sliding window has length five. And we're basically sliding this window along this. Along this DNA sequence. And for each shorter sequence in the sliding window, then we predict its RNA signal structure. And then we compute the coefficient sum of the tree polynomial representation. And let's just assume a few numbers. Like, so the coefficient sum is three for the first one, six for the second one, and seven for the third one. And so what we do. For the third one. And so, what we do is that we put three for each nucleotide in the first sliding window. And then we put the coefficient sum at the nucleotide in each sliding window like this. And what we do is that we sum this thing up so that we have like a function. And so we have like a function of coefficient sums, and we call it overlapping sum. And it gives us a number for each nucleotide in a sequence. And we're actually comparing this curve constructed from coefficient sum to the probability of R loop formation that we have from experiments. All right, so I'm gonna show some results. I'm going to show some results that we have. So, here we have a plasmid. It's called PFC8. And the blue curve here is the probability of R loop formation constructed from acquired from experiments. And the black curve is a scaled overlapping sum. So we have an overlapping sum, and we basically scale it. Sum and we basically scale it down. And then we compute the Pearson correlation coefficients. The Pearson correlation coefficient stay the same if we do scaling to the curves. So if we do the scaling, it doesn't change the Pearson correlation coefficient. So they're like really correlated. So we found that the probability of R loop formation is actually correlated, strongly correlated with coefficient sums of triple. Coefficient sums of three polynomial representations of the DNA plasmid that we just constructed. And this is for one plasmid, and this is another plasmid that we have. It's another plasmid called PFC53. And here we also see like a strong correlation between the two. So this is saying, this is showing that we can use this computational. Can use this computational pipeline to predict where the R loop is going to form in the genome or in a plasmid. Another thing, as I mentioned earlier, the polynomial is interpretable. And so not only that, we can use this computational pipeline involving the trip polynomial representation to predict where the R loop is going to form, we actually the R loop is going to form we actually we can actually see uh we can also see like uh what are the RNA secondary structures what what do the RNA secondary structure look like at the R loop hotspot right so what we found is that so if we take the sliding window around the like the R loop hotspot like in like like here and we found that And we found that these RNA-second structures usually have a lot of loops, interior loops or belges, which is showing here with red nucleotides here. That is the on-paranucleotides that form loops. So it is represented by a lot of loops separated by short, short. Separated by short stems, and it has multiple of these and multiple branches of that. So it makes us think that these kinds of RNA secondary structures, they can be like easily break. The hydrogen bounds in this RNA secondary structures can be easily broken. Broken in the process of transcription. And then that increases the probability for the RNA sequence structure, for the RNA strand to pair, for the newly transcribed RNA to pair with one of the DNA strand. If the RNA signature structure does not have many bubbles, and the stems and the base pairs are like really long in the RNA-second structure. Long in the RNA-second structure, then it will require higher energy to break it apart and less likely. And then in that case, the RNA signature structure is less likely to pair with the DNA strands because the nucleotides are paired with the other nucleotides in the RNA. So that's what we found using this. We found using this computational pipeline, and what we hypothesized what's happening during the transcription and during our loop formation. We still need experiments to validate this hypothesis. So, what we can do, so what we're doing actually collaborating with the experimentalists is that we have a Is that we have a sequence that can be inserted into a DNA plasmid? And the previous results show that the number of G and Cs, the GC content in this sequence, and the GC skew, the ratio between G and C is actually correlated with R loop formation. And what we can do here is that we What we can do here is that we use one sequence and we shuffle this, we shuffle this nucleotides so that we have the same GC countant and a GC skew. And then we can see whether that would affect the probability of R loop formation. So this is the original sequence that we have. And it has, and then we can shuffle it to something like this. And in this case, we have more or many bubbles or loops in this RNA signature structure as it is illustrated in this tree representation. So the path has many nodes. nodes, each path. So there are few paths with many nodes in the paths. And for the original one, there is only one branch like this and the path is not as long and these paths are not as long as these ones. So we can actually shuffle this RNA sick this RNA sequence so that This RNA sequence so that we have the high number of, well, the high coefficient sum, which means there are high number of loops in this RNA-signed structures or medium. So in this case, there are not many long paths in this RNA-signed structure. So there are fewer loops in this RNA-signed structures. And for this one, this is the one with the low coefficient, lowest coefficient. With the low coefficient, lowest coefficient sum, and it has loops, but it does not have, does not have like as many loops as the previous ones, and in the in the tree representations as like that. So we are we're sending these sequences. I mean, we're in collaborating with the experimental Ethan and Professor Chedin's lab, we're actually ordering DNA sequences that contain this. DNA sequences that contain these sequences. And we hope that the experiments can shed light on whether if this is going to have, we're going to see different level of R loops in this three different level of number of loops in this RNA signature structure. Number of loops in this RNA signature structures. So that would validate that the R loop formation is indeed related to the cotranscriptional RNA signature structures. All right, so that'd be all of my talk. Thank you. Any questions?