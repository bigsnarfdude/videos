Can you see? We can see. Yeah, you're getting to the first slide. Is that right? I'm sorry, yes. Up, it was from a previous talk. So, to use this in my starting slide. Okay, great. Okay, so I'll give you a notification of 20 minutes. So, Marios Christadulu is going to talk about quantum superpositions of graphs. So, take it away. Thank you very much, Christopher. Thank you very much. First of all, thank you for the invitation for organizing this great workshop. So I will be talking about a simple idea that came out of thinking together two not necessarily seemingly related topics, which is quantum cellular automata and quantum gravity. It's a collaboration with Pablo Ricci and Amelia Durbeck. There is a first draft on the archive. On the archive, and the talk is partly based on a second version that is soon to appear. So, let me give you some motivation from general relativity first. A main idea underpinning our modern classical theory for our established classical theory for general relativity is something called background independence. Background independence is sort of a metaphysical philosophical stance, if you want. Stance, if you want, that translates mathematically to the diffeomorphism variance or independence, their changes of coordinates, which we also know as general covariance. These are all names that more or less say the same thing. What's the idea there? In order to do physics, you need to use mathematics, and for that, even if you want. For that, even if you want to completely do away with a dependence on anything that is fiduci, you still will need to have some sort of amorphous blob below everything on which you define things. And that's what we call the manifold. It's a set that has certain nice continuity properties, so it is smooth, induces differentiability, and so on. So Einstein was grappling with this. So, Einstein was grappling with this a lot, and in his words, this was his main somehow Eureka moment when he realized that the points of the manifold are not to be identified with physical events. They correspond to exactly nothing. So the story goes that you have this set, this manifold, and now except from postulating it as a priori as existing in practice, you cannot describe it unless you put some additional structure on it. Put some additional structure on it. One typical choice is to lay coordinates. And once you lay coordinates, you can change coordinates. The idea is that under these changes of coordinates, your physics should not change. Anything real shouldn't depend on what coordinates you have laid down. A change of coordinates is changes of coordinates are in one-to-one correspondence with. One correspondence with diffeomorphisms, and thus you demand diffeomorphism variants. All right. So the premise of this talk is to try and see the same story, but in the discrete, in the sense that my canvas is not the manifold. I'm not in the continuous at all. It's a graph. A word of caution. I am not saying I. I am not saying I will take this graph and embed it in a manifold to make sense of it. So I'm not taking a graph, embedding it in an ambient manifold in the continuous, in particular, embedding the links between the nodes and interpreting them as curves. It's just a graph. And I want to use this as my ambient topological space. Now, Now, how do you describe a graph? It's slightly more evident here with graphs that names that we give to, let's say, points are really the canvas. But the first question is: okay, now we have the canvas, which is the graph. Shouldn't we again demand the invariance and their coordinates? And what are Variance under coordinates, and what are coordinates for a graph? Well, they are the names you give to the nodes. Let me make a couple of points here. First of all, about the links, as I said, they're not thought of as embedding them again. I've completely forgot about the continuous. So they're fully described by the names. If I call two nodes A and B, then the link that connects them, if it exists, is the link AB. Second, if you think for a moment for the generic case, If you think for a moment, for the generic case, for a generic graph, you cannot actually even define it if you don't use names. You could, for some cases, if there is, you could say, for instance, the maximally connected graph with five nodes and get a K5. But for the generic case, you cannot. You cannot just draw it on the paper, right? That is not the definition of a graph. You need to give name. Definition of a graph. You need to give names, put some adjacency matrix and put the names in rows and columns and say, I'm going to put a one if they're connected and so on. Okay, so now we have names. These are really like the points, like the coordinates in the manifold, where you can think of laying coordinates as giving a name to a point on a manifold. If it's a four-dimensional one, you will have some quadruple like x, y, z, w. Like X, Y, Z, W, and so on. And thus, changes of coordinates on the graph are going to be renamings, also known as graph isomorphisms. This R that I have here is a renaming and explaining the role of a diffeomorphism. Okay, one more word of caution because this is often a point of confusion. A point of confusion. Names are the canvas. I'm not talking about coloring. And the confusion that I had coming from Lupin Gravity was separating these two because typically we have graphs, we color them with some fields that are for spin networks, they are spins that label the representations of SU2 and so on. You put some numbers that have some meaning. So coloring should be thought of as fields that should. Sort of as fields that you add on top that potentially have a physical content. Again, making the analogy from the continuous, we have a manifold that is just some among ocean globulay coordinates. You haven't done anything more than that yet. You can then add fields, for instance, the metric and so on. But names are simply the coordinates. All right. All right. Now comes a postulate, which is we want to understand how you define a Hilbert space that allows you to superpose graphs. Whenever I say graphs, I mean named graphs, which is the same thing as we have just as I just commented. So what we do is we postulate that That we want to study theories for which we take different graphs to form a countable basis of the Hilbert space. And by studying the properties of this basis, then you can deduce the structure of the Hilbert space. Of course, once you postulated the basis, you still need to understand what is your inner product to have a Hilbert space. And a question. And a question immediately arises from this simple consideration, which is: what do we do with two graphs that are related by rename? Do we take them to be the same graph? Because there's just a name that is different. So what could be different between two, imagine two graphs that just have one node that's called A and the other graphs name B. Or should we take them to be orthogonal? So there. So the first feeling, at least that I got, is that we should take them to be the same graphs. This would imply essentially that the pre-color hilt space that I'm talking about here would be defined at the level of equivalence classes of graphs and the renamings. So the kets would represent isomorphic. Isomorphic graphs. However, what I will argue is that, in fact, it would be much better if we do not do that. We take two graphs that are just different by names, potentially only one name, to be orthogonal, and then find a way to remove names afterwards. Afterwards means after you do the dynamics, after you. That you when you think about how to define your observables. Okay, the way we do this is by studying one specific example where we see what is the trouble that may come up. So the Hilbert space is now, once you have a Hilbert space for the pre-color graph, for just graphs that have names, you can then extend it, obviously. You can then extend it obviously with any internal states that you want. And this is the H that I have here, where at every node you have a two by two matrix of complex numbers. And we are going to define this very simple quantum wall that has been starting also in other contexts, where the step is given by a unitary given by two operations h and t. I'm giving you the graphical definition of these operations. So, our state space now in this Toid model is that on each node, you may have one of four possible states. Internal states, there is either nothing, no particle, there is perhaps a B moving particle, perhaps an A moving particle, and perhaps both an A and B moving particle. There is no collisions. Comment briefly on this A and B is these A and B that I have here. I hope you can see. Have here, I hope you can see them. Are ports. They serve to keep track of the fact there are two possible directions in which two possible species of particles. They are not taken to be as names, and you could have put them in any way you want. Well, A and B doesn't have to be left and right. It will become clear in the next slide, I think, what the role is, but don't. Slide, I think what the role is, but don't confuse them with names. Names are this U, V, and W that you see over here. So, H, what it does is it has a mod operation on each node, depending on the species of the particle. And what T does is somehow shift the particle along its port. If the ports are aligned in this way, there is an A particle here, it would go. It would go towards the A port, it would go to the next node. So from V, it would go to U, and the B moving will go from V to W. So that's the toy theory we will look at. All right. Are you there or am I talking to the void? We're all here. We're here. We're here. Good. So, I need to go a bit faster, maybe. All right, so now let's see what happens if we apply this unitary twice on a given initial state. The initial state we take is the one over here. It's a circle with four nodes, and there is a name moving particle. So, applying H, what it does is create a superposition of a name moving and a B moving. Of a nay moving and a B moving at the same node W. Then applying T, which is U shifts the particle. If it's A moving, it goes this way. If it's B moving, it goes this way. Now, doing it twice, applying UI again, it's easy to see from these equations that you end up with this final state. State, which is a superposition of four branches. The main thing to note is that there is two, there are two branches that have an A-moving particle, this one here and this one over here. They come with a plus, the same sign. And there are two branches which have a B-moving particle, come with the opposite sign. Okay, let's try again, but now we're Now we're acting on a state space that where we have anonymized graphs. So now we're using as a basis these equivalence classes under renaming. Pictorially, what this means is that before we were taking these two graphs to be different, just because the name of this node was different. Here is V and here is W, while now we take them to be S equivalent, so they're the same thing. It's easy to see what happens is that, as we saw, the Haddam Art is not more. So, the Hadamard is not moving the particle from the node, it's creating a superposition on the same node. So, the only thing that is changing the name of where the particle is is T, but T is doing nothing now. So, you just get when you do U squared, you just get Hadamark twice, you get the identity. So, now this is our final state. This is the same as our initial state. Nothing happened after two steps of the dynamics. Steps of the dynamics. Right, so now we're left with two very different situations in our simple example. The physics are different. In particular, we have, in one case, when you used names, we have both B-moving and A-moving particles, while in the second case, when we got rid of names, we are left only with the A-moving particle. And this is a Getankin experiment that tells you. An experiment that tells you that these two dynamics are different physically. Local measurements can distinguish them because you can simply see whether you're detecting two kinds of particles or one. All right. And now this, I think this question was just asked on the chat for the previous talk. Obviously, somebody can say, okay, but wait a minute, are you showing now that we need names in order to have Need names in order to have these dynamics because this quantum work has also been applied. It has been applied, has been simulated in the lab with beam splitters and photons. And we would even fail to describe that situation if we try to use anonymized graphs. But obviously, you can fix it without using names by using some sort of external reference, some landmark, the lab walls or the fixed stars. Starts. Okay, so let's see how that works. It's easier to see with doing things on the line than a circle that I had before, but you can think of this as being a big circle, and we're looking at a piece of it that looks like a line. The reason we do this mental acrobatics is that if we actually think of it as an infinite chain, it would still work. The model is saying that it would. Would still work. The model is the same, but it would take us outside the framework of the mathematics we use because what we use is valid for finite graphs. That means the number of nodes has to be finite. But feel free to think of it as anything. Chain is the more or less the same. Where you see that instead of using a name, I have put an additional color, this green color, to align the graphs. And that is essentially what names are for when. For in when you think about superpositions of graphs. Instead of having the same name here, u or whatever, we add to our physics some additional to our model, some additional physics, which is this green color that is observable and it helps us align the graph. And you see that what is happening is as before. As before, that you do you once it would take bring a particle here and there, then you do it again. It's going to be one coming there from this one, one coming there, another one going two steps and two steps. And this is the four branches that we have. There is the A moving particle here and here, here are B moving with different signs. And if we had removed, if we didn't have the green color, then we would have gotten. Have gotten back the initial state. Would that work? Yeah, sure, it works. You don't need names, you can put these colors there. However, look what is the issue now. This landmark can be arbitrarily far away. And I put the far away because I haven't told you that the links mean distance or whatever. But if, for instance, you're describing the implementation in the lab with beam splitters, then it would be the distance. And now you're And now you're in a situation where your local measurements, imagine an observer at the node measuring whether he sees an A or B particle, imagine having agents in all the nodes identical with an apparatus that can detect A and B particles. If an agent sees both A and B, then he knows that if an agent sees a B particle, then he knows that in fact there was a landmark. And in fact, there was a landmark. And this landmark can be as far away as we want, which gives you some sort of instantaneous signaling. And you definitely don't want to have your theory behaving in strange ways like that. Now, let me do the result for Kate. Is this all too simple an example to matter? Well, I think it's the opposite. The fact that this is sort of the simplest panel. This is sort of the simplest part of the world there. The fact that you get this problem already there is telling you that you won't have to worry about this. Imagine that you have, you try to put down some theory with quantum cellular automata that you want to claim can describe a wide range of physics, including quantum gravity. What are we going to do? Are we going to take for any possible dynamics for any positional state and for an arbitrary number of steps? Check all the number of steps. Number of steps, check all the number of steps, check every time that this doesn't happen. How would you do that? Um, or are we going to put landmarks everywhere, which would totally take care of the situation? But it's the same in the end as putting names. So let's think of this of how it is in GR. In general relativity, it's the same. If you want to have a physical meaning of points all over the place, what you could imagine is that you have some sort of family of test particles going one way. Family of test particles going one way and the other. They're all distinguishable, and wherever they cross, that's an event and so on. And that's how you interpret the theory, which is totally fine. But in practice... Marios, this is the 20-minute notification. Okay, that's I just have one more slide. I went too fast, I guess. Thank you. So, all right, so this is perfectly fine. Right, so this is perfectly fine as an interpretation, but in practice we use coordinates. And now somebody might say, Okay, but wait a minute, why put these fitucial things? Aren't we just putting ourselves trouble? Well, no, because that's exactly how you see at the mathematical level that you have a symmetry, which is a mathematical concept in your theory. And this turns out to be a hugely useful conceptual. Useful conceptual and very powerful tool. So, what I'm suggesting is that similarly, instead of doing this landmarking, which can be done on a case-by-case basis, depending on the application, why not postulate renaming invariance as a symmetry principle? And in particular, as you have noticed, I've been talking about the superpositions of graphs, so this carries easily to the quantum real. Real, which can also be done. The continuous solution, in particular, has thought about these quantum manifolds and so on. But it's much more manageable, let's say, to think about genetics because we're in the discry. And this is my last slide, so I just leave you with our. You with our definition of renaming invariance, which is that observables O are defined to be those that satisfy this relation here. Because it's a basis, we only need to do it. We only need to define this on the basis of graphs, and then it would induce the same properties to an arbitrary state. To an arbitrary state. You see that this is really just saying that there is an if and only if, which you can see it here by inspection, that what this essentially requires is that this is equal to R. And then they can be pretty much really extended to unitaries because this is our basis on which we are defining the renaming zone. And I leave you with a question. Post this renaming invariant. Barrier teaches us there are the chance living on superpositions of space-times, which was a motivation from the beginning to think about these things because many, many people are thinking about superpositional space-times in various contexts, quantum reference frames, as we have just seen in the previous talk, and so on. Thank you very much. I'm happy to answer questions. Thank you very much. So we have time for questions. Please, I will. Okay. So Faye, Faye again. Thank you, Marius, for the talk. I just want to check in the example that you gave Is it right that you're in that example? There isn't any, there's just one fixed graph. There's just a circle. I mean, and the graph, the graph is space. And the dynamics is defined on essentially that graph translated forwards in discrete steps. So it looks very much. So it looks very much like this, a model that appears in many different guises all over the place. It looks in the form I know it best, it's the model on a diamond lattice. So people like David Meyer have worked on it. And so in your language, it's a cellulore, a quantum cellular automaton, but it's That it's um it's on a fixed it's on a fixed space and the space is just a circle. Is that a circle of discrete sites? Am I right in that? Yes. Pablo would be more suitable to answer this question since it's his background. So yeah, it's not graph changing, these dynamics. It wouldn't change the graph. It doesn't have to be this one, the only graph. Yes, David Mayer has looked into this model. So the point here would be that you already run into this issue before you start even thinking about graph changing dynamics. Okay, yeah, thanks for clarifying me. And Alex, you have a question? Yes, it's more of a comment. Have you encountered this work on nominal logic and nominal algebras? I think the first people were Andy Pitts and Jamie Gabai. Most certainly not. Most certainly not. Most certainly not. So there's been a lot of work in dealing with, effectively, in dealing with renaming in a fairly uniform manner. And in particular, notions of what it means to be infinite and finite, modulo renaming, and what happens when certain names are hidden, and what it means to be equivariant with respect to renaming. Be equivariant with respect to renaming. So you'll find a whole lot of papers kind of from I think the 90s and early 2000s working through a lot of this stuff, which that might be useful for thinking about these renaming invariant systems. Alex, can you tell us the name of that field again? Sorry? It goes under the name nominal techniques or nominal algebra. Algebra. And the names there are Pitts, P-I-T-T-S, and Gabai, G-A-B-B-A-Y, were the early ones. But then there's been a lot of kind of follow-on work about that, studying different kinds of nominal structures like finite state machines, modular renaming, and this sort of stuff. Sorry, Marius, I interrupted. No worries. Yeah, Alex, I will send you an email to get. Alex, I will send you an email to get the references. I don't think we're discovering anything. I mean, there must be a huge literature about, because graph isomorphisms, right? It must have been studied mathematically. The question is, somehow, how do we import this and see if we can use it to interpret physics? That's, I think it would be very interesting to follow up in this way. Yeah, so maybe an interesting thing is equivariance really plays a central role. Really plays a central role there. So, maybe this is connected to some physical notion of equivariance as well. So I'm not sure. It's because the word is the same is the only reason I'm speaking. Right, I don't know what it exactly means at variance in that case, but I'm happy to discuss about this. Okay. Okay, and we have the last question from Sumati. The last question from Sumati, please go ahead. Yeah, so yeah, thanks for the talk. It was very interesting. And this idea of, if I'm not mistaken, this idea of looking for these states which are label invariant. I mean, this is how we would talk about it in causal set theory, is label invariance. And you're thinking how to construct states which are somehow which are label invariants. Which are labels invariant in a consistent way. Am I right in asking, in interpreting it that way? That basically you're looking for things that are this discrete diffeomorphism invariant state. And since your states are the graphs and you're constructing a Hilbert space from the set of graphs via presumably some kind of GNS construction, you're looking for. You're looking for graphs that are equivalent, and therefore the state is, you know, that the state is identified in some way. Is that right? That's one question, but the second thing that I wanted to ask is that, are you only, I mean, I'm curious about the countability of these graphs and you're looking at these finite graphs. Does your analysis also extend to countable graphs? Extend to countable graphs or even, you know, I don't know, uncountable graphs, because you can, you know, you haven't said anything about those two cases. I was just curious about that. Thank you. Thank you. Okay, so for the first question, the question is not about finding the good states, it's more whether we should be working at the level of the gauge variant. Level of the gauge variant kinematic space, or whether we should be defining the theory at the level of the gauge invariant. So let me answer any steps. First of all, what you have seen is what we have. This is one paper that is sort of out there alone. It's not the usual things I talk about. It is, for me, it is inspired. For me, it is inspired from having a loop connogravity, where actually what is done is that you first would do their namings, and then I realized that I actually didn't know how we do superpositions with different graphs because we don't really deal with that. Now, when I so the main thing here is how do we have some sort of principle that's clear mathematically without invoking other things. Other things like fixed stars. That is just a simple formula, what I showed in the end, that would help us unambiguously identify observables in any given situation that you would then study. For instance, in GR, different variance is very simple to say what it is. And then, given a certain, whatever it is you're looking at, you can use that to see whether you could observe, which may turn out. Whether you could observe, which may turn out to be very difficult, but still, you don't have any update on what is your principle. I try to make things as simple as possible because I think it could be applicable to various things, including causal sets. That's why there is no specific details about what exactly are your dynamics of the model. We didn't do the infinite graphs case, you would have to involve. infinite graphs case, you would have to involve C star algebras and the rest. Yeah, I don't know if there is any subtlety there that would be that would break anything I said. I think it would just get more complicated. And I have forgotten about your second question. Can you remind me, please? I think you did. You just talked about the finiteness of the graph. That was the question. So I think you just did. Okay. Thank you. Thank you. Okay. Thank you. Thank you. Thank you. Okay, great. Thank you. Let's thank Marios again. Thank you.