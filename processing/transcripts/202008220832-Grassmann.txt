And here you see again the title, and my name, as you see, is Winfred Rasmal. And I'll talk about why Monte Carlo simulation is done so frequently. Monte Carlo simulation is really one of the most successful applications of applications research. Of operation three search and even beyond. However, the bulk of Veuring theory uses deterministic methods, that is, methods not suggesting to randomness with random variables. And outside Curing theory, many curing models are solved by Monte Carlo simulation, and the results of Turing theory are often ignored. And how can we make change? How can we change that? How can we make classical Turing theory more successful? Now, the first question is, why is simulation so successful? And I see three reasons for it. You see maybe others or more. One, for large problems, Monte Carlo simulation needs far less computer time. Two, simulation is mathematically easy. Simulation is mathematically easier. Most people have no difficulty doing simulation. And three, simulation is much more flexible. Now how can Turing theory compete? Let us look at the different issues. The first issue is the execution times. In Monte Carlo simulation, execution times start at a high level, but they increase length. but they increase linearly with model complexity as measured say by the number of variables you use. In deterministic methods execution time start at a low level but they increase exponentially with model complexity. So skewing theory is an advantage for small models but not for large models. Now to show you this I have here this graph. The red line The red line is deterministic methods. They start at the low level and go up very steeply, and very soon they take more computer time than simulation, the blue line. Now, simulation needs a lot of computer time initially, and in fact, before the advent of computer, simulation was not a practical method. However, the computer time increases. computer time increases very slowly with the number of values. Now the next thing is mathematics. How can we simplify mathematics? I think we should stress numerical methods. And maybe that's a little bit against the stream to say that people want results rather than formulas. Now if you use numerical methods you have a choice. numerical methods you have a choice. You can use the standard methods or you can use methods tailored to deal with probabilities. Now for standard methods you have lots of software available including software included in symbol manipulation languages. However in some cases it is advantageous to exploit the special probabilities special properties special properties of probabilities, namely that probabilities are also always greater than or equal to zero. And this enables us to avoid subtraction and thus reduce rounding errors. Now I should be clear here, subtractions do not cause rounding errors, but they increase rounding errors committed. rounding errors committed at earlier stages quite rapidly, often by orders of magnitude. Now if you use special algorithm to deal with probabilities, they often have a probabilistic interpretation and that provides additional insights. Now the third thing is can we increase the flexibility? One of the most used simulation paradigms used simulation paradigm is discrete event simulation. Can we copy this paradigm? Now we can use discrete event systems as they were described by Cassandra and LaForte in 2008 in a book. And what are discrete event systems? Well the discrete event systems have two main components, the state and events. And events. Now the state is a set of drivers, for instance Q length, and all changes occur in discrete steps, hence discrete event simulation. Now every change is called by an event, because an event can even be defined as something that changes the state. Now Qs are clearly discrete event systems. Why not? event systems, why not use this paradigm in queuing theory. Now first let us look at the state. Because the state consists of physical state variables, vibrant that you are interested in. It could be Q's. We assume that the state variables x are x1, x2, up to xd. And we also assume that the xi are between 0 and ni. 0 and ni. In addition to this, we need supplementary state drivers. If you have a schedule of future events, you need to keep track of this schedule and for this you use a supplementary state rather. Or you may record when past events have happened. Again, that would be supplementary variables. What you need is enough supplementary variables Supplementary variables such that the distribution of the future state variables can be calculated. And you do that, then the system becomes a Markov chain consisting of physical and supplementary state values. Next, we come to the events. Events come in different types, such as arrivals, departures, switches of freighting lines, and so on. Of our freaking lines and so forth. And each event is characterized by three things: an event function, an event condition, and a process that generates the events. The first event function, we call it fkx. And if the state before event k is x, the state after the event k is f. k is f k x. For instance, if your state is x1 x2 and you have an event function fkx1 x2 which increases x1 by 1, leaving x2 unchanged, then this would be the event function of something like an arrival to line 1. Next we have an event condition and events are prevented from occurring if the condition is not met. And then we have an event process that could be a BOSO process, renewal process, a phase star process and what have you. Now here we have an example of a discrete event system. A discrete event systems. They are two bins, bin 1 and bin 2. They have finite size, bin 1 the size n1, bin 2 the size n2. And arrivals to bin 1 are lambda 1, arrivals to bin 2 are lambda 2. The bins are used to do repairs, and each repair always needs one unit from bin 1 and 2 units from bin 2. The repairs occur at a late mu. Repairs occur at a late mu, and all these events are Poisson. Now, this system has two state variables, x1, the number in bin1, and x2, the number in bin2. And what are the events? Well, we have three events, replenish one, replenish two, and repair. And each event has an event function, an event condition and a rate. condition and the rate. So skip minus 1, well what happens? You increase x1 by 1, leaving x2 unchanged. And this has the event condition x1 is less than n1 because if the thing is full you don't accept derivals anymore and the rate is number 1. Similarly you have event number 2. It's similar, it has a gate of lambda. has a rate of lambda 2 and repair has the event function x1 minus 1, x2 minus 2. And this event can only happen if you have enough in the bins. That is, x1 must be greater 0 and x2 must be great at 1. And if that is true, then the event happens at an 8. Because now you have formulated this event and now you need a transition matrix because the whole thing is a Markov matrix. because the whole thing is a Markov thing. Because we create a transition matrix Q for, and I do it here for any Poisson events, because we have to find Qij, the rates of going from state i to state j, except for the diagonal, which you all know must be determined such that sum across the row must be zero. is you take a state out of the state space and you apply all events. And for event k you do the following. If the event condition holds, if c k holds, then you have a new state after the event, we call it x new, which is xk of the present state and the transition gate is x. Gate is xÎ½, which is set to the rate of event k, and this you do for all events and for each state. Now, this is not really a transition matrix, because the x are vectors rather than numbers, because we have to associate our vectors with numbers. Because we have to find for each state a number, and this number is And this number is used to find both the row and the column of the state. And this number must be in a one-to-one relation with the state. Now, if the state space is as simple as this, which is true for many events, including the for many discrete event systems, including the event systems I talked about, then you can use the alphanumerical order. order. That is, the event number is the rank in the alphabetic order the state has and this event number can be found by the following formula. You take the sum of ui xi where the ui are the products and j plus 1 or j equals i plus 1 to d. Or cables. Now we have the events, event number, and in some cases you can just enumerate the event numbers and you get the matrix gathered quickly. Now things are more complicated. If events are generated by renewal process, then we must add supplementary variables such as the time since the previous event of the same type or the time to the next event. All the time to the next event if the event is scheduled. Now, the times between events are often continuous random variables, and in this case, we need to discretize, unless we use phase-type variables. Now, discretization has a disadvantage. It forces us to deal with multiple events that occur simultaneously. that occur simultaneously and that increases the number of entries in the transition matrix quite considerably. Now if you look at equilibrium solutions, we can save computer time by embedding the system at the points where the events do occur. Now once you have generated your transition matrix, you want to find We want to find the transient equilibrium probabilities. That is, we want to find the pi j t, the probabilities to be in state j at chi t. And you probably all know how this is done. We have a recursive formula here that pi j t is pi j t plus 1 is a function of pi i t p. of pi i t p i j. Now, as you all know, if t is large enough, then the pi j t correspond to an equilibrium probability pi j and in order to find the equilibrium probability we have this system of equations which is obtained from this system by just dropping the argument t. Now for continuous time mark of chains we have a Instead, Markov chains we have a similar relationship. We have the rate matrix or the incremental generator Q. Now instead of a recurrence relation, we have a differential equation, because pi j prime t is the derivative of pi j with respect to t and here you have the formula for pi j prime t. for pi j prime t. Again, if t is large enough, that converges to an equilibrium probability, which is written down here. And now the next step is to solve these equations, both the transient equations and the equilibrium equations numerically. So this is what I propose. And let us do that. Let us do that. Now, first, however, let us look at the properties of the transition mechanism. The matrices are huge but sparse. If all events are Poisson processes, the matrix size is given by the ranges of the different state variables, the product of the ranges of the different state values. Now, the density Now the density however is low because the entries per row in the transition matrix is equal to the number of events and let the number of events be E. Consequently the density is E divided by N. Now if the events are renewal processes you also have to add the products of the ranges of your supplementary vibrations which are Your supplementary variables, which I call yi, and then you get the matrix size of this huge product. Now, in each row, we actually have two to the e events. It's two to the e because we have to look at all combinations of events at cantagina at canti. That's this is an approximation, but it's good for m i naught two. But it's good for mi, not too small, because we have huge matrices. The matrices are also banded. In fact, if x1 changes at most by 1, the state number, and that represents the band bit, changes by u1, which is a product of the ranges of the different state dividers, except state variables except for x1. It is n1 plus 1. Now here I have an example. I have four state variables and the ranges of the state variables are from 0 to 9 and if we have all in its Poisson that gives 10 to the fourth of 10,000 states. However the transition matrix has 10,000 to the square entries which is 100. Entries, which is 100 million. And if you assume five events, as it's true for the tandem queue, you have only five times ten thousand, that is fifteen thousand non-zero entries. Now the same is true for to a lesser extent also for men's generated also forms generated by renewal process. This suggests that we explore only the non-zero entries of the transition matrix. And I apply this idea now in order to find transient solutions of the discrete time mark of pair. Plus we use three arrays, one for the vote, one for the column and one for the probabilities. Thus we want to apply now this method to calculate pjt plus 1 according to this formula here, which is the formula for transient probabilities in discrete time markov chain. We assume that the total number of non-zero entries, we call it here n dot, which in some n dot, which in some cases in most cases is n times the number of events. Because this is the number of non-zero entries and we want to do the calculation for t going from 1 to t tot. And here you have the program to do that. We go from t from 1 to t tot, for n from 1 to m tot. We go through all the non-zero events. And this form And this formula really represents this formula here. That Pi nuj is ijt plus 1. The Pi Ti is Ii T, and this is the probability Pij. Now I is, of course. I is of course what you find in row I, tray what you find in row n, tray what you find in column N and the probability is given x. So we do that for all n. And the remaining statements should be clear, because I don't want to go into it. But the important thing is really that the complexity is Complexity is proportional to n. This is the important thing. Now we can look at Lance evolution in continuous time. Although in this case we could solve the differential equations, but we suggest another method called randomization or uniformization, which is pretty standard now. In this method, Now, in this method, you create a matrix P which is Q divided by F plus the identity matrix, where F is chosen such that P is a stochastic matrix. And thus we can look at the Markov chain described by P and after n plus 1 steps to the problem. steps to the probability to be in state play. It's this formula here, but there is now a difference. The steps are not steps of one, they are steps of exponential random variables with rate of f and consequently the ijt, the probability to be the continuous Markov frame in state j. Markov n in state j at type t is given by this formula, because you have the pi j superscript n and multiplied by the Poisson distribution. And as I said, this is the randomization or uniformization. This method can also be derived by a small modification of the Taylor series and here we have an object. And there we have an objection from mathematics. Now Taylor expansions of matrix exponentials tend to be numerically unstable. And it was argued, and I know that first hand, that this method is potentially unstable. But this is not true, and the reason is that we have no support. The reason is that we have no subtractions. And if there is no subtractions, rounding errors increase very slowly. Because randomization or uniformization, as this method is called, works for millions of states and it works for very high t without problems. And what is even better, it performs better than standard algorithm for than solving for solving different. So far, transient solutions, and now we come to steady state solutions. We discuss only discrete time Markov chains. First we have here the formula for the steady state of a discrete time Markov chain. This is a system of equations and we can use Gaussian elimination. Now the mathematicians say Gaussian elimination Say Gaussian elimination is unstable if you have something like 10,000 or 100,000 states. But this is not necessarily true because we can reformulate the system such that subductions are avoided. And what is more, when we do that, then the resulting algorithm has a probabilistic interpretation. Now if you look at linear algebra box, then if you solve linear equations and linear equations, then you start with the first equation and solve this first equation for x1. We don't do this. We start with the last equation and solve it for pi n. Well, why do we do that? Well, mathematicians. That? Well, mathematicians assure us that grounding errors are minimized if you start with the smallest entity first. Using this mathematical recipe, we eliminate pi n first and then you get the following result. Here you have Gaussian elimination. Here you have the system of linear equations. We set the chain. set j equal to n, so the set becomes pi n and then we solve for pi n. That's the solution of the last equation for pi n. Then we do the substitutions. That is we first split the sum into the sum from pi equals 1 to n minus 1. And then we have here the last term which only includes pi n. which only includes pi n. We plug in this value here and we simplify and what you have is a new system of equations which has n minus one linear equations other than n and the coefficients are now given by pij plus p i n p n j divided by 1 minus p n n. Now you can continue, because we can call these new coefficients pijn minus 1, which is pij plus pi n p n j divided by 1 minus p n n. This gives us a system of equations which we could solve for pi n minus 1. Then we get a new system of equations we solve it for pi n minus 2 and so forth and so forth. two and so forth and so forth and the coefficients after we have solved after we have solved all the pi's from n up to capital n, from small n up to capital N, are given by the following formula here. So psi ij superscript n minus 1 j superscript n minus 1 is pi i j n plus pi i n superscript n pi n j superscript n divided by 1 minus pi i n n superscript n. In order to obtain this formula, we also need pi n, which is this equation. It expresses pi n in terms of the pi i, where the i is less than n. Because this can be used in the back substitution phase. substitution phase for calculating the pipe. Now I told you there is a probabilistic interpretation of the whole thing and to discuss it we first need to use embedding. Now what is embedding? Suppose you have a sequence x1, x2, x3 and so forth which would be a Markov chain and in addition we have a set C. Set C. And now we create a sub-sequence of this sequence here. And elements XT of the original sequence are included in the sub-sequence only if they are elements of C. Because if the set C is 1, 2 and 3 and if X T is 1, 3, 5, 2, 4, 2, then what happens? Then what happens? Well, one is in C, does we keep it? Three is in C, does we keep it? Five is not in C, does we omit it? Two is in C, we keep it. Four is not in C, we omit it. And two is in C. Now we can actually embed into embedded Markov chains. Thus we can use can use this new sequence, we call it x superscript ct and we can embed it into the set D, where D is say 1 or 2 and what do you get? 1, 2, 2. Now, if you look at this, you will see that instead of embedding E into this sequence, into the sequence X supersonic. into the sequence X superscript. C, we could have embedded B also in the original sequence and we would have the same result. Because what happens is if you have repeated embedding then you could as well do embedding in one step or vice versa in order to do embedding in for a Embedding in for many, many different states, you can break it down into one step embedding sets. Thus, embedding can be done either in several small steps or equivalently in one large step. Thus, we can reduce the state space by one state at a time and until only one state is left. Only one state is left. And this I call state reduction. Now, if you have a Markov chain, and if you do embedding by set C, then the corresponding embedded chain is also a Markov chain. The problem is now to find the transition probabilities Pij superscript C. And what is And what is the solution? The solution is to add all the probabilities of all the paths that start in I, end in J, and avoid any state C in between. Now, what happens is that elimination, Gaussian elimination, is really invalid. Because we start with the original sequence, states 1. Sequence, states 1, 2, 3. He embedded into a set C, which goes from 1, 2, up to n minus 1. And in order to find C, we add the probabilities of all the possible sequences to go from I to J, avoiding any state less than n. We can go from I to J either directly. either directly, that's pij. We can go from i to n and from n to j. That's p i n, p n j. We can go from i to n, you can stay in n, go to j and the probability of this path is p i n, p n n, p n j and so you go on. Because for this sequence here you find the probability p i n p n n square p n j. P n n square p n j. Now we have to add all these probabilities together and we get the probabilities for the embedding set 1 to n minus 1 which is equal to p i j p i n p n n to the k you stay k times in state n p m j 8N, PMJ. And as you see, this is a geometric series, and the sum of the geometric series of these terms is 1 minus P n and N. Because what you get is Pij plus P i n, P n j divided by 1 minus P n. And this is nothing else but P i j. but but pij superscript n minus 1 and the rest follows the same holds now for all pij superscript n because you do state reduction you reduce the state space by one in each step and for the general for the general term you get pi term term you get P i j n minus 1 is P i j n, P i n n P n j n 1 minus P n and that is this is the transition matrix for the Markov chain embedded in the sets from 1 to n minus 1. Now here there's a subtraction and I said we should avoid subtractions and this can be done because all the P and because all the P and J's here are transition probabilities of Markov chains, that is, their sum across the j is equal to 1. Or alternatively, if you look at state n, 1 minus p n n superscript n is the sum j equals 1 to n minus 1 p n j n, such that the sum here is what if you move that over. move that over. And it follows that this formula can be written without using subtractions and you get the Gth method, the method of tax plus 1 taxahan. Now this method though has a problem. It is impossible to exploit sparsity. Well it is possible but it's very difficult. very difficult. Now if the matrix is dense, the number of floating point operations goes up with the third power of n. Because in the example I presented before we had n ten to the fourth states, that is 10,000. This means according to the formula here that we get two-thirds ten we get two-thirds ten to the twelfth flops. And if you do that, or if you do these many flops on a laptop, as I have here, as you have, then that needs around 100,000 seconds computer time, that's one day on the laptop. So this is not a good thing, really. Now you may say, well, we can exploit bandedness. Well, what do you get? what do you get? You can divide by the bandwidth, which is denominator here, but still you get an n to the third in the numerator. Because the algorithm are always n to the third. Because in the example you would reduce time from one day to one hundredth of a day, which is still you don't like to wait too long. You don't like to wait too long until you get results. What is even worse is if you look at transient solutions, they increase with n rather than with n to the third. Those transient solutions, in a way, are easier to obtain than steady-state solutions. Now, this is kind of strange, but for large dense matrices, this is easy. In fact, in order to find equilibrium solutions, you can just iterate the transient solutions until you have reached the equilibrium. Now you can increase convergence a little bit by different tricks, such as using the jump matrix and so forth. You can also go back to classical methods such as Gauss Eidel. I use that extensively and it That extensively, and it worked quite well. Now, in Gausseidel, the order of the states is important. And as has been shown by Mitra and Tsukas, if you order the states such that the events downstream, changing state varieties downstream, are done first, then the convergence is fast. The convergence is fastest. Thus, you look at the flow, thus, again, you have to look at the meaning of the model and by exploiting the properties of the model you can improve your methods. Now, state reduction is still great for some theoretical results. And I have here two. I have here two theoretical results and mention a third one. First, it allows you to deal with infinite state spaces. Secondly, it allows you to deal with matrices that have a repeated structure. And third, they can allow you to do good embedding techniques, which I don't have the time to discuss here. Now first, infinite statements. Infinite state spaces. Here there is the following result. If j is recurrent, then the state space can be cut in such a way that the pij superscript n, the only thing that we need to calculate the pi n, does not change by more than epsilon as long as xt plus 1 minus xt, the upturn. Minus xt, the up jumps are bounded. And here is the proof. If j is the current, most paths from i to j, ending as soon as j is each, have a finite length. Because we now only look at most paths and most paths, we can say these are the paths less than mu. And if you look only at those paths, And if you look only at those paths less than mu, then the number of states reachable between two visits of j is finite. And the states that cannot be reached on such a path can be ignored, and we can cut them without changing p ij superscript n by more than epsilon. Because in other words, you can always cut the state space to a finite size if the Markov chain is recurrent and if the up chumps are bound. Now the next thing is let's look at transition matrices with repeating columns. Now here I have a very simple proof, but you find more complex proofs in the literature. proofs in the literature. If pij is equal to pi plus kj plus k for almost all ij, which is true for all non-methods, then we have pijn equals pi plus k j plus k n plus k. And the proof is simple. If you have any path from i to j, superscript n, superscript. N. You can match that with a path from i plus k, j plus k, n plus k by just shifting the path upwards by k units. And when doing this, you have, you meet the same transition probabilities. Consequently, this result stands. Now this essentially finishes Now this essentially finishes my talk and here I have some conclusions. To go back to the beginning so to say, you may agree with these conclusions, you may disagree, but I think these things should be discussed. To increase flexibility, I propose discrete event approaches. To reduce computer time, you can try to reduce the number of You can try to reduce the number of statewiders and to make mathematics easier, use your innovative methods or simply modified to deal with probabilities. Okay, that is the, oh, here we have a number of references which I found useful. And of course my own papers are always useful, at least for me. At least for okay. Any questions? Winfrey, it's very nice, very interesting talk. So when we do numerical and also the Markov mental, what's your comments on a statistical approach in the future for queuing models? Well, you see, I mean, now the question is: what is my suggestion for the future of queuing theory? Is that the question? Yeah, because nowadays say the advances of this telecommunications, smartphones and and all these real li uh real time uh apps and a lot of times uh we do not have really have uh models and we have input we have something and then we have output but in order to in order to uh do the analysis or to design the system in the optimum way of course some Of course, sometimes based on the knowledge or other same information, we may assume here is a model, but even in that case, very often a lot of information are still incomplete. For example, parameters could be missing. And for example, if you want to say join the Join shorts remaining, but you do not really have that information upon arrival. Maybe information is delayed or information is missing. So therefore, we need to deal with that one. Oh, I see. Yes, okay, that is yesterday. I think you are alluding to. By which you are alluding to. Yes, that is something that has to be done in general. You see, in order to make the things applicable, QNCU, we should also look at real problems as actual problems. This is not something I did. Well, I did it in the past and there is also there used to be quite long for a long time a method Kazman Usch, which was a practical problem in airline maintenance. Problem in airline maintenance. But I haven't looked at this at this moment. But yes, this is very important that you look at the statistical methods, that you do that type of thing, that you look at actual curing problems and so forth. What I look at is easy methods that once you have formulated such a system, how can you solve it without going in? Without going in a lot of mathematics. So, this would be the second part kind of a problem. The first part, which you alluded to, the statistics and so forth, that would be the first part. Yes. Thank you, Winfried. Oh, by the way, I have a few words, but not related to Winfried today's talk. Today's talk. And most of you know, Winfrieda, actually, when I was doing my PhD, Winfried was my PhD supervisor. And actually, my career greatly impacted by the supervision of Winfried. And also, the directions I have been doing also greatly. Greatly influenced, impacted by Winfrey's work. For example, the state reduction method, the GTH method, randomizations, and factorizations or other things. So I really appreciate it. I'd like to use this opportunity to thank Winfried once again. Thank you, Winfried. Thank you. Thank you, Winfrey. Thank you for these nice comments. Hello? Hi. Yes. Hi, Winfrey. Very nice insightful talk. Thank you very much. My question is about the accuracy of simulation method. A related issue is: is it possible to use like, or when you use simulation, how do you simulation how do you identify system singularity and can you have do you have comments on those things yeah okay yes well okay um well first of all simulation since the error increases with the square root of the number experiments simulation in order to be very accurate needs quite a lot of A lot of runs. But this is with the computer speeds that you have now, this is no great problem. However, there are cases where simulation is doing poorly, and that is exactly if you have rare events. Or I I don't remember what you m you mentioned. simulation in the event is poor because the error is kind of well it's an absolute error and if you estimate small probabilities you really need very very many experiments. Yes, this is a problem, it's a major problem and It's a major problem, and there is a group to address exactly this point. Okay, thank you. Hello, Myron Huenke here. You were talking about these huge state spaces. Sometimes I have an issue that I don't even know how to order the states. Order the states. Is that an issue that you come up with? That is an issue, yes. And if you have ideas how to do that, I would like to hear about it. You see, I mean, there's two orders that I tried. And one order is the alphanumerical order, which I presented. And the alternative is to order as you create the states. The states. You start the state one and see which events bring you to the different states. You use these new states again to find further states and so forth. I initially thought that this is a poor method because it takes long to generate all states, but this is not true. You can find the states in linear time. Thank you. Thank you.