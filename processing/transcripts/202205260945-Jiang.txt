Thanks for the invitation and introduction. So, I'm going to talk about the experimental evaluation of algorithm assisted humidity decision making. And this is the joint work with Karskan Suan from Harvard Government Department and Jim Maran from Harvard Law School. So the use of statistical machine learning and artificial intelligence is pervasive in our daily lives. And there are many examples, including the facts or assembling lines. The factory assembly lines, autonomous cars, and drones, and computer games. And researchers have found some evidence that the decision-making based on algorithms outperforms human decision-making. For example, the alpha goal. But we humans still make many consequential decisions. This is true even when human decisions can be sub-optimal. And there are many issues in using AI for making. In using AI for making important decisions. For example, an AI doctor may make mistakes. It's unclear who will be responsible for these mistakes because the details of why a mistake happens matter. And the mistake may come from any point in the process from design to data and delivery. So even though we know that the algorithm-based decision-making may be more accurate than human decision-making, when we still want to. Human decision making, we may still want to hold someone rather than something accountable for the important decisions. So the desire for a human decision maker and the precision of algorithm-based decision-making has that hybrid system, the algorithm-assisted human decision-making. And in this system, humans make decisions with the aid of machine recommendations. And this has also been applied to And this has also been applied to many aspects of our daily lives, including medicine, investment decisions, and hiring. But so far, most of the literature focused on the algorithms themselves in this hybrid system. So they study the accuracy or the fairness of the algorithmic recommendations. But in this hybrid system, humans are the final decision makers. So we need to take So, we need to take into account the humans in the study. But so far, little is known about how algorithms interact with humans in making decisions in these systems. The goal of our work is to study how algorithmic recommendations influence human decisions. And we have three questions in particular. Do they help prevent negative consequences? Do they help humans make better decisions? And do they help humans improve the fairness of their decisions? Improve the fairness of their decisions. And to answer these three questions, we propose a statistical framework for experimentally evaluating the causal impacts of the algorithmic recommendations on the human decisions. And we also propose the fairness concept, principle fairness based on causality. And these two methods are applied to an important field experiment we're involved in. And this is the first. We're involved in, and this is the first ever field experiment for evaluating the pretrial public safety assessment in the criminal justice system. So, let me start with our application. So, this is in the criminal justice system. We consider the first appearance hearings. And in the United States, when a person is arrested, they need to attend the first appearance hearings, usually within 24 to 36 hours of arrest. To 36 hours of arrest. And at the first appearance hearings, the judges need to make decisions on the release conditions. So, under what conditions these arrestees can leave and wait for some time to attend the trial court. And the release conditions usually include the bail amounts and monetary conditions. And the judges need to make these decisions very quickly. These decisions very quickly. So, usually 30 or 40 cases per day. And the goal of the judges' decisions at the first appearance hearings is to avoid predispositional incarceration while preserving public safety. So, the meaning is that they need to make the decision under the presumption of innocence because the first appearance hearings hold before the trial court. So, at the time of this first appearance hearing, the arrestees haven't been decided guilty. Haven't been decided guilty. So, the judges shouldn't make a very harsh decision to incarcerate these arrestees unless they think that these arrestees are very risky. They need to balance between the cost of the pretrial detention and the risk of the arrestees. And the risk is determined by three negative outcomes. The arrestee may fail to appear in the trial court, may engage in new May engage in new criminal activity and it may engage in new violent criminal activity. And these three negative outcomes are considered in the pre-trial period. So this is the time between the first appearance hearing and the trial court. And the judges need to make the release condition, the decision on the release conditions based on the risk of these three outcomes in this pre-trial period. So, there is a lot of information available to the judges for there to make the decisions, and making these decisions not an easy task. So, the pre-trial public safety assessment PSA is an algorithmic recommendation used to help the judges to make decisions at the first appearance hearings. And PSA is a report containing the PSA scores calculated based on nine factors, including the democratic. Factors, including the demographic variables and the criminal histories of the arrestees. And there are two six-point scores for FTA and NCA, and one binary score for MVCA. So this figure shows how the FTA score is calculated. The first column is the factors used for calculating the FTA score. And for different responses to these factors, we assign different points. We assign different points. We assign different points, and then we add up these points together and threshold it into a six-point score. And the other two scores are calculated similarly. And these scores are restricted to be integers to ensure the transparency and the interpretability of the scores because the judges will see these scores and the weights are learned based on past data. So these are the three PSA scores, and in addition to PS scores and in addition to these scores, we also have a bail recommendation in the report. This bail recommendation can be either cash bail and or signature bound. And the cash bill requires the arrestee to pay a certain amount of money to leave. And the signature bound only requires the arrestee to sign a promise to attend the trial court. And this bail recommendation is summarized from the three PSA scores based on. PSA scores based on a decision-making framework. So, we will call this DMF recommendation. And this is a sample report of PSA. And you can see the information of the RST here, the MVCA binary score, the NCA and the FTA scores. And in addition to the three scores, we have the detailed charges of the RST and also the nine factors used for calculating the three scores. And in the bottom, we see. Scores and in the bottom, we see the bail recommendation. Here, the bail recommendation is a signature bound. And actually, in addition to the bail recommendation, we also have a recommendation for the monetary conditions. But in this study, we focus only on the bail amounts. So this is the PSA report. And given this PSA report, our question is how the provision of PSA affects the judge's decision at the first appearance here. Decision at the first appearance hearings. So we run a field experiment in Dan County, Wisconsin, and the experiment is still ongoing. So we're expecting more data in the future. And the PSA in this experiment is generated for each case using a computer system. We randomly make the PSA reports available to the judges. So for half of the cases in the treatment group, the PSA reports are given to the judges. And for the other half in the control group, The other half in the control group, the PSA reports are generated but not provided to the judges. And we have two-year follow-up after the randomization between 2019 and 2017 and 2019. So this is the experiment. And for the decision, for the judges' decision, we focus only on the bail amounts and discretize the bail amounts into three categories based on experts' knowledge. The three categories are signature-bound, smaller than, or are signature bound smaller than or equal to 1000 cash uh 1000 cash bound and larger than 1000 uh cash bound and you can treat these three categories as a no bail small bail and the large bail here is some summary statistics of our data so about eight percent of the cases are non-white females 13 are white females and non-white males and white males are about 40 percent of of the cases each and there is a little variation in the decisions for non-white females The decisions for non-white females, the judges impose a signature-bound decision for almost all the non-white females. So it's hard to conduct a subgroup analysis for the non-white females. And in our subgroup analysis, we combine the non-white females with the white females. And in the whole sample, the judges made a signature bound decision for about three-quarters of the cases. And for the other cases, the judges made a cash bail decision. And for the outcome, And for the outcome, about 30% of the restees commit FTA or NCA, and about 6% of the restees commit MVCA. These two figures show the distributions of the judges' decisions given each of the PAC scores and the DMF recommendation. And the width of these bars corresponds to the proportions of the cases. And the three colors represent the three decision categories of the judges. Categories of the judges. And we can look at the figures for FTA and NCA and see that the most likely scores are in the median range between 2 and 4. And for MVCA, most of the cases were classified as score 0, which means no elevated risk for MVCA. And the difference in the treatment and the control groups is not large. In both groups, we see a positive relationship between the PSS horse and the judges. Between the PAC scores and the judges' decisions. So, a larger PAC score is associated with a harsher decision of the judges. As we can see, as the score increases, we have a larger proportion of the cash bill decision by the judges. But for FGA and NCA, when the scores are in the lower range between one and three, the judges' decision distribution doesn't change too much. Doesn't change too much. And for MVCA, the judges were more likely to impose a cash bail decision for the cases that were classified as score one. But this difference between score one and score zero is larger in the treatment group than that in the control group. And for the DMF recognition, the judges impose it's more likely, are more likely to impose a signature bound for the cases that were actually recommended signature bound. So this is the So, this is the exploratory data analysis, and then we can move on to the evaluation of our PSA provision. And the first question we're interested in is whether PSA provision helps to prevent the three negative outcomes. And because in our experiment, the PSA is randomly provided, we can conduct intention to treat analysis. So, ITT analysis, just using the ITT analysis just using the difference in means estimators. For example, if we care about the effect of PAC prevention on the judges' probability of imposing a signature bound, we can just calculate the probabilities in the treatment and control groups and then take the difference. And this figure shows the result of the effect on the judge's decision probabilities. And the three shapes represent the three decision categories. For example, this line here with the circle. For example, this line here with the circle means that providing the PSA makes the judges more likely to impose a signature bound for the female arrestees. But all the intervals in this figure cover zero, so we don't have significant results. And this is the effect on the judges' decision probabilities. And similarly, we can use the ITT analysis to calculate the effect of PSA provision on the arrestee's behavior. On the arrested behavior characterized by the three negative outcomes. And this figure shows the result. And again, most of the estimates are not significant. But here we have this line here, means that providing the PSA makes the female arrestees more likely to commit a new violent criminal activity. And this is not a very good news. So, because the PA separation is randomized, we can just use a very simple Just use a very simple ITT analysis to answer our second question. And the result here is not very good. But to evaluate the PA supervision, we also need to look at the effect on the judges' decisions in addition to the three negative outcomes. Because if we focus only on preventing the negative outcomes, we can just assign the highest scores to every case in our experiment. And providing this kind. And providing this kind of PSA reports to the judges will make the judges to think all the arrestees are very risky and they will detain more arrestees and therefore prevented more crimes. But this kind of PS reports and the judges' decisions are definitely not good. So in addition to the first question, we also need to look at the second question about whether this PA parision helps the judges to make better decisions. And we might wonder. Decisions and we might wonder whether we can use the ITT effect in the first figure on the judge's decision probabilities to answer the second question. And to figure out this, we need to think about what does it mean by a good decision. So here is a toy example with three arrestees and two judges. And in this example, the judges can either make a detention or release a decision. Release decision. And suppose we're omnipotent, so we know that the behavior of the arrestees under both scenarios if released and if detained. So arrestee A will commit a crime if released and will not if detained. And arrestee B will never commit a crime regardless of the judges' decisions. And arrestee C will always commit a crime. And for the two judges, if the PSA is not provided, Not provided, both of them will release all the RSTs. And if the PSA is provided, judge one will detain ANC and judge two will detain BNC. And in this example, the ITT effects of the PSA provision on the judges' decisions are the same for the two judges because it makes the two judges to detain two of the three arrestees. But this doesn't mean that the two judges made equally good decisions. Pretty good decisions. And actually, the three arrestees have different risk levels. For arrestee A, detention can prevent a crime that would have happened if the arrestee is released. And for arrest B, detention is unnecessary. And for arrestee C, detention doesn't help to prevent a crime. So from this perspective, arrest C is more risky than A and A is more risky than B. And therefore, judge one made a better decision than judge two. Made a better decision than judge two because judge one detained arrest A and therefore prevented a crime, and judge two detained arrestee B who is a safe person who shouldn't be detained. So this example shows that the IETT analysis cannot distinguish between a good decision and a bad decision. It only tells us whether providing the PSA makes the judges' decision harsher or more lenient in general. And by intuition, a good decision should A good decision should detain the arrestees who should be detained and release the arrests who should be released. So, the meaning of a good decision varies with the risk levels of the arrestees. And the risk levels depend on the outcomes under both scenarios, if released and if detained. But in practice, we don't know these two outcomes simultaneously, and we call these potential outcomes in causal inference. comes in causal inference. And for the released arrestee, we don't know what they would do if detained. And for the detained arrestees, we don't know their behavior if released. So the fundamental problem of causal inference is that only one potential outcome is observed. But as this example shows, to answer the second question, we need to separately consider the RSTs with different risk levels defined by the joint potential outcomes. The joint potential outcomes. And let's formalize this idea. So I will first talk about the framework for binary decision, and then I will generalize the framework for discrete decisions. Here is the notation. So ZI is the PSA permission indicator for case I. DI is the decision, 1 for detention, and 0 for release. And Y is the binary outcome representing one of the three negative outcomes. And I will use the new crimes as the example in this. times as the example in this talk. And Xi and UI are the observed and unobserved covariates. We also need to define the potential values. So d of z is the potential value of the decision when the PSA provision is a small z. So d of one is the potential decision when the PSA is provided, and d of 0 is the potential decision when the PSA is not provided. And similarly, we need to define the potential value of the outcome of the arrestee's behavior. And this potential outcome depends on both. And this potential outcome depends on both the PA s iteration and the judge's decision. And I will make assumption to simplify this notation. And this definition of potential outcomes implicitly use the no interference assumption. So we assume there is no interference across cases, which means that the PA separation and the judges' decision of one case do not affect the outcome of another case. Affect the outcome of another case. And this is a little bit tricky in our application because in our application, one arrestee may have multiple cases. So the RST may come back many times. And in this case, the interference may exist between the cases of one arrestee. So to make sure there is no interference, we focus only on the first arrest of each arrestee. So our conclusion will be for the first arrests only. The first arrests only. And we make some assumptions based on our experiment. The first assumption is the randomization of TSA provision. ZI is independent of the potential values and the covariates, and this holds by our design. The second assumption is the exclusion restriction. So we assume the PA separation cannot affect the outcome directly. So the potential outcome is a function of the decision only. And this is plus. Decision only. And this is plausible in our application because the restees didn't know whether the PSA is provided to the judges or not. So it's unlikely that the PSA provision can affect the judges' behavior directly. It can only affect arrestee's behavior. So it can only affect the arrestee's behavior through the judges' decisions. And the third assumption is the monotonicity. And we assume y0 no less than y1. 0, no less than y1. Here, 0 and 1 are the values of the judges' decisions because we have exclusion restriction. And this assumption means that each arrestee is no less likely to commit a crime if released. And it's possible in our application because keeping the arrestees in custody will make them very difficult to engage in the new criminal activity. But we didn't fix y1 to be 0 in this assumption because we found. This assumption because we found in our data that the detained arrestees can still commit a crime or fail to appear in the trial court. So under the three assumptions, we can use the principle stratification framework to characterize the risk of the RSTs. So using this idea, the principal strata are defined in terms of the joint potential outcomes Y1 and Y0. The joint potential outcomes y1 and y0. And because y is binary, we have four principal strata. And the last one is eliminated by the monotonicity. And in the first principal strata, y1 equals zero, y0 equals one. So these arrestees will commit a crime only if released. And we call these preventable cases. And in the second stratum, we have the risky cases who will always commit a crime. And the third stratum contains the safe cases who will never commit a crime. So we can see the principle stratification. See the principal stratification classifies the arrestees into three categories, and then we can define the principal causal effects as the average causal effect of PSA provision on the judges' decisions in these three principal strata. And these principal causal effects are the keys to answer the second question. If the PSA is helpful, it should make the judges to detain more people in the preventable strata because. In the preventable strata, because detention in this strata can prevent crimes. And it should also make the judges to release more people in the safe strata. This means that if PSA is helpful, we should see APCEP to be positive and APCS to be negative. So we can look at the signs of these principal causal effects to answer the second question. But for the risky stratum, because the detention cannot prevent crime, Cannot prevent crime, the desirable sign of APCR depends on other factors such as the cost of incarcerating one person or fairness concerns. So one thing to note here is that the principal causal effects defined here are different from those in the literature. In the literature, the principal strata are defined in terms of an intermediate variable, and the effect is on the outcome, as in Alexandra's talk. In Alexandra's talk, the principal strata are defined as using the switching outcome, a switching variable. And the switching variable is an intermediate variable between the treatment and the survival outcome. But here you can see the principles are defined in terms of the outcome and the effect is unintermediate variable. So we can see the definition is a little bit different from those in the literature. A little bit different from those in the literature. And because y1 and y0 are not simultaneously observed, we need to formally study the identification of these principal causal effects. Under the three assumptions, we have these expressions for the principal causal effects. And we can see the numerators can be identified from the observed data. But the denominators depend on the distribution of the potential outcomes. Of the potential outcomes, and this is not identifiable without additional assumptions. But we know the denominators are all positive, so although we cannot get the point estimators for the principal causal effects, we can get the signs of them from the signs of the numerators. This means that under the three assumptions, we can get the signs of the principal causal effects, and therefore we can draw qualitative conclusions about the second question. Conclusions about the second question. But if we want quantitative conclusions, then we need to get the point estimator of the denominator. And this requires additional assumption. And this commonly used assumption is the unconfoundedness assumption. And this assumes a way the latent confounders between the decision and the Founders between the decision and the potential value of the REST dis behavior. So, given the observed covariance X and the PA separation, the decision is independent of the potential outcome. And this assumption is possible if we observe all the information used by the judges for their decisions. And if we don't have some of the information, the assumption might be violated. And in our application, the judges did have some information that's not available to us. The judges know whether. Thus, the judges know whether the arrestee has a job in the jurisdiction or the length of the time the arrestee has lived in the jurisdiction. So, in our paper, we develop a sensitivity analysis for this, for the potential violation of this assumption. But with unconfoundedness assumption, we can use the principal score to identify the principal causal effects. The principal scores are defined as the proportions of principal strata given the covariates, and we have to. Given the covariates, and we have three principal scores. I only show one here. And under the unconfident assumption, we can identify these principal scores and express the principal causal effects as the mean difference in the decision in the treatment and the control groups in the weighted population. And the weights depend on the principal scores. So to estimate this in practice, we can first estimate the principal scores and then plug in the estimated principal scores in this. Principal scores in this weighting formula. And we can also obtain more efficient estimators by deriving the efficient inference functions. And I will not talk about the details here. So this is the framework for binary decisions. And in our application, the decision has three categories. So we need to generalize the framework for discrete decisions. And in this case, the decision di becomes a k plus one level discrete variable. Plus one level discrete variable indicating different levels of the bail amounts, and a larger value of d means a higher bail amount. And then the monotonicity becomes that the potential outcome under a lower bail amount will be no less than the potential outcome under a higher bail amount. And this is plausible because imposing a higher bail amount will make the arrestee more likely to be incarcerated and therefore less likely to commit a new crime. Commit a new crime. And then we need to generalize the principal strata to characterize the risk levels of the arrests. And we define an ordinal measure of risk, which is the least amount of fail that keeps an arrestee from committing a new crime. This is the definition of this measure, and I will use an example to illustrate this measure. So consider an example with a three-valued decision as in our application, zero for no bail, one for small bail, and a two for large. One for small bail, and two for large bail. And under monotonicity, the principal strata can take four different values. And in the first stratum, all the potential outcomes equal one. And by definition, r equals three. These are the risky cases who will always commit a crime. And in the second stratum, y2 equals zero. And by definition, r equals two because r equals two is the least amount of bail that keeps this. Bail that keeps these arrestees from committing a new crime. And we call these preventable cases because we can prevent the crimes by imposing a large bill for this group of units. And the third stratum, we have Y1, Y2, both equals zero, and by definition, R equals one. And we call this easily preventable cases because we can impose a small bail to prevent the crime. And the last threatened. And the last thread contains the safe cases who will never commit a crime. And from this example, we can see a larger value of R means a higher risk of the arrestees. And by definition, for people with a risk level equal to small r, if the judges make decisions larger than or equal to small r, they will not commit a crime. And if the judges make decisions smaller than r, they will commit a crime. They will commit a crime. And because small r is the least amount of bail that prevents the crime for this group of units. And this fact motivates the definition of our causal quantities. We define the principal causal effects as the difference between these two probabilities. The first probability characterizes the proportion of crimes prevented with PSA in principle straton small r, because in this straton, if the decision is no less If the decision is no less than small r, the crime is prevented. And the second probability characterizes the proportion of crimes prevented without the PSA. So the difference between these two is the reduction in the proportion of NCA attributable to the PSA provision. And these principal causal effects can help us to answer the second question in the discrete decision case. If the PSA is helpful, we should have these principal causal effects to be positive. Causal effects to be positive. And under the four assumptions, including the unconfoundedness assumption, we can lamparometrically identify these principal causal effects. And I will skip the details here. So we apply this method to our real data. We first calculate the proportions of the four principal strata, and the four colors represent the four principal strata in these figures. We can see the safe cases have a very high proportion, about seven. Very high proportion, about 70% for FTA and NCA, and 90% for MVCA. And the easily preventable and preventable cases have a very low proportion. The risky cases have a slightly higher proportion. And this pattern is consistent across the three outcomes and different racial and gender groups. We then calculate the average principal causal effects. And unlike the quantities defined before, here we calculate a more refined quantity. More refined quantity, and this is the difference in the decision probabilities in the treatment and control groups for each principal stratum and each decision category. And from this more refined quantity, we can easily calculate the one defined here. And these three figures shows the results. And the four colors represent the four principal strata. And the three shapes represent the three decision categories. And we can look at the first column. And we can look at the first column. This is the result in the overall population. From the figures for FTA and NCA, we see that providing the PSA has very little overall impact on the judges' decisions. And for MVCA, we see providing the PSA makes the decision harsher for the easily preventable, preventable, and risky cases, because the lines with a square represent the probabilities of imposing a large cash bail. Cash bail. And the second column contains the result for the female arrestees. And we see providing the PSA makes the judges' decision more lenient for the females. And this is consistent across the three outcomes and four principal strata. And this may suggest that providing the PSA doesn't help the judges to distinguish between different risk levels of the female arrestees. And this is not good because for risky female arrestees, Because for risky female arrestees, imposing a signature bound is not a good decision. And then the last three columns are for the male arrestees. And from the figure for MVCA, we see that providing the PSA makes the judges' decision harsher for the easily preventable, preventable, and risky male arrestees. But these effects are not that significant for FTA and NCA. And this results suggest that providing the PSA. Suggests that providing the PSA helps the judges to distinguish between the different risk levels of the male arrests, but this holds only for the MBC outcome, not for the FTA and the NCA outcome. Now, one thing to note here is that most of the intervals here cover zero, and because we only have one-third of the final data, and we believe as more data coming in the future, we may have more clear pattern of this result. More clear pattern of these results. And these are the two questions. And we can see for evaluating the PA separation, we need to also think about the effect on the judges' decisions. And we cannot just focus on the ITT effect. We need to explore the causal heterogeneity across different groups of units with different risk levels. And the third question we are interested in here is whether PA. In here is whether PA separation helps the judges to improve the fairness of their decisions. And there is a fast-growing literature on algorithmic fairness, but most of the literature focused on the fairness of the algorithmic recommendations. And in our study, as we can see, we have humans in the loop. So we want to study the fairness of the human decisions. And we want to take into account the causal impact of the judges' decision on the rest is... Judges' decision on the rest is behavior. So, given the framework, we propose a new fairness concept called principle fairness. And the idea of this concept is that people with similar risk levels should be treated similarly. So the judges' decisions shouldn't depend on the protected attributes such as race or gender once the risk is known. And in our framework, principal stratum fully characterizes the risk level of the REST, so we require Of the REST T. So we require the decision to be independent of the protected attribute A given the principal stratum. And compared to existing statistical fairness definitions, our principal fairness takes into account the causal impacts of the decision on the outcome through the inclusion of the principal stratum. And here are some statistical fairness definitions, and they require some statistical independence between. Requires some statistical independence between the decision, the outcome, and the protected attribute. For example, the overall parity criterion requires that the judges detain the same proportions of arrestees across different racial or gender groups. And the issue here is that these definitions do not take into account the causal impact of the decision on the outcome because statistical independence is undirectional, but causal impact is directional. Directional, but causal impact is directional. Oh, Joshua, you have three minutes. Okay. Okay, just a few left. So, under, so we also connect our principle fairness with the statistical fairness definitions. Under this independence, we show that principle fairness implies all statistical fairness criteria. And this independence means that the risk level of one RST is not associated with. RST is not associated with the race or the gender of that RST. But this might be violated in practice. So, in another paper, we established more general connections between principal fairness and other definitions. Back to the application, we want to know how fair the judges' decisions are. So we define a measure of principal fairness, and the measure is the maximum difference in the judges' distribution function across different protected. function across different protected groups in different in each principal strata. And this characterizes the deviation from the independence required by principal fairness. And then we can take the difference between the deltas in the treatment and the control groups to answer the third question. If this difference is negative, then we see the PSA provision improves the fairness of the judges' decisions. And we apply this measure to the data, and we first consider the gender fairness. We first considered the gender fairness. We found that providing the PSA has a negative impact on the gender fairness of the judges' decisions. As we can see, when the PSA is provided, the delta is larger than that when the PSA is not provided. And from the analysis of our second question, we can get some of the reasons. Because when the PSA is provided, the judges' decisions are more lenient for all the female arrestees, but harsher for the risky males. And this difference for And this difference for males and females widens the gender gap in the judges' decisions. And then we consider the racial fairness. Unlike the gender fairness, we found that providing the PSA has no impact on the racial fairness of the judges' decisions. And some concluding remarks, we have a set of statistical methods for evaluating the causal impacts of the algorithmic recognition. The algorithmic recognitions on human decisions. And we have some findings in our application. And although I talk about the framework in our criminal justice system application, the framework can also be applied to other algorithm-assisted human decision-making systems, as long as there is algorithmic recommendation, there is a human decision-maker, and some outcomes of interest. And this is all of my talk. And thank you.