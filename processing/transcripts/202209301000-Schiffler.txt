When did we meet the first time? And I'm not sure when it was, but maybe in Bielefeld in 2006 or at this conference on cluster-tilted algebra. I'm not sure. We have met many times at conferences. I particularly can mention that I always enjoy your lecture series. For example, the one at the Hausdorff Institute in Bonn. That was very exciting when this one. Was very exciting when this monoidal categorification was very fresh. It was very nice. Yeah, so I'm talking about the connection between knot theory and cluster algebras. This is joint work with Veronique Basier-Matt at University Laval. So our aim is to study Study a relation between knots and cluster altras in a very systematic way. So there are many relations that appear somehow naturally between cluster altras and not theory. We have seen several examples at this conference. But most of the time, it is you do something with a cluster algebra, and then there happens to be a knot that appears. Then there happens to be a knot that appears. Our approach is quite different. We want to start from a knot and construct a cluster algebra for every knot and every link and then see what does the cluster algebra know about the knots. And yeah, so let me start here with an overview. So here's a knot. This is called the figure eight knot. And so, actually, this is the diagram of the knot, so it's a projection of the knot into the plane. And you see there are strands which go over other strands. And I want to ignore this for the moment. I want to consider this really as a graph where the crossing points are, so the not diagram I denote by k, and I consider it as a graph. So it has vertices and edges, so the crossing points. Crossing points will be the vertices. There are four in this example. And then the edges are the segments. And to really make clear what I mean by this, let me number them: one, two, three, four, five, six, seven, and eight. And well, then you can also Also, think of regions which I then denote by K2. And well, it's easy to see that K1, there's twice as many segments as there are our vertices. And then since everything here lives on the sphere, you have this last identity that there's two more regions than vertices. Regions, then vertices. Okay, we want to associate a cluster algebra. So we want to associate a quiver. And the data for the quiver is written here on the right. The vertices of the quiver is exactly the same set as the set of segments in the knot. So let me copy this here over just as they appear on the left. Here on the left. Okay, I have my vertex set. And the next thing I need is arrows. So I just say the arrows go clockwise around crossing points. So what do I mean? Here's a crossing point. The arrows go clockwise around it. The arrows go clockwise around it, so I will go from one to six to two to seven back to one. We get an arrow one to six, six, two, two, seven, and seven one. And then the second crossing point here gives six three five two. Um, okay, and so on. There's four, seven, five, eight, and the last one is one four eight three. And there you go, you have a quiver. This quiver has some automatic properties. Every vertex has three arrows attached to it. There is clockwise cycles and counterclockwise cycles. The clockwise cycles all have length four because these are the cycles that come from the crossing points. And the counterclockwise cycles come from the regions, for example, this cycle here, counter. Regions, for example, this cycle here counterclockwise has lengths three, comes from this region here, which has three sides. So you can define a potential naturally here by taking the clockwise cycles minus the counterclockwise cycles, or the vertex cycles minus the region cycles. And from this construction, And from this construction, you immediately get a cluster algebra. Yes, so you get a cluster algebra when you remove the two cycles. I prefer to keep them to have this the idea that we have this four-valency and to see where the naught comes from. But so if you on the level of the Jacobian algebra, yeah. Yeah, so if you have equivalent potential, you can find an algebra which is called the Jacobian algebra, which is a quotient of the path algebra by an ideal. And yeah, so then we don't like two cycles, but so you can modify the potential such that you can remove the two cycles from the quiver and to get the same algebra. The quiver and to get the same algebra. And so when I say the cluster algebra of Q, I really should remove the two cycles, but it doesn't change the algebra B. And so, yeah, well, we're done, right? We started from a nut, we have a cluster algebra. So the idea is: well, is this meaningful in any way? So these. In any way. So, these, as you probably know, these two things they talk to each other by categorification or decategorification, depending which way you want to go. And oh yeah, so first I want to remark the quiver yes. The quiver, yeah, the way I constructed it, it does not see the difference between an overcrossing and an undercrossing. So I did not take into account at all if this. Yeah, I just considered this as a point. I didn't look at this local situation, whether you go over the strand or go under the strand at all. So the quiver is not an invariant of the notch. Yeah, not at all. The cluster algebra is not an invariant of the knot, the Jacobian algebra either. If you modify your knot by some Reidemister move, you will get a different quiver, different cluster algebra. Not even the rank of the cluster algebra will be the same. The number of vertices will change. So it seems at first sight might seem this is completely senseless to do this, but still we can do something. Still, we can do something. So, our goal is to construct cluster variables that carry some information about the not. And there are two possible approaches for that. So, number one is to construct B modules and then use the categorification. And when I say construct B modules, we And when I say construct B modules, we will construct representations of the quiver explicitly, also by specifying the vector spaces at each vertex and the linear maps between the vector spaces. And the second possibility is to construct a mutation sequence directly in the cluster algebra, which produces then cluster variables which carry information about the knot. And when I say carry information about the knot, I And when I say carry information about the knot, I want to realize not invariance. So, in this case, the Alexander polynomial of the knot. Yeah, so that's the overview. Any questions so far? Yeah. Is there anything that is preserved at the algebra level by radimeister three moves? Master three moves the ones that do not increase the number of purchases Well, yes, you can you can realize Deidemeister 3 moves to as a sequence of mutations, so you would stay in the same cluster algebra I'm a little hesitant. I'm a little hesitant to say this, but I think that's correct. I mean, everything is defined in terms of the NOT diagram. So the question whether you move before or behind or in between the strands actually does not matter. So it's even stronger. So yes, you will stay in the same cluster algebra, but you have a different initial seed. Okay, thanks. Okay, so then let me talk about this part one: the construction of a representation of Q. And yeah, so remember this K1 is the set of segments of the knot, or the same as the set of vertices of the quiver. So I say here for every such segment, or for every vertex of the quiver, we will define a representation of the quiver. Of the quiver, which I denote here by T1, Ti. And yeah, so it has vector spaces, Ti sub X, and linear maps V alpha. And we do this as follows. So first I'll construct the vector spaces. And for that, I will construct a part. And for that, I will construct a partition of the set of all vertices or a set of all segments of the knot. And this partition has this parameter D. And it depends on the segment that you have chosen on this I. And how do we do this? The zero step is you take the segment I itself. The segment I itself. And then what I say afterwards is the boundary of K minus the segment I. What I mean is the segment I is contained in two regions. So you remove I and you remove every segment in these two regions that are connected to I. So if you think of the knot living on the sphere, you remove the segment I, there's suddenly a hole, and then you can think of the two regions that are around it as the boundary of what is left. And so you remove those. And so you remove those. Well, this this is the the k the k one zero part of the knot and so the k one one part you you take your your knot and you remove whatever was in k one zero and again you you have removed more from this knot and then you have a new boundary and so you that's that will be part of k one one. That will be part of K11, KI1. And then, yes, so intuitively, that's all you want to do, but sometimes there's more than that. I should probably do this thing here. So sometimes there's more that you have to do. And this is a little bit technical, so I don't want to go into the details here. But that's the idea is. That's the idea: is remove, always take the boundary of the next layer. So it's like peeling an onion. You start at your segment I, remove the boundaries of the regions adjacent to I, and then you remove the next boundary, and you remove the next boundary, and so on. And yeah, this is a recursive first construction. And then you define your vector spaces. Your vector spaces like this. So the dimension of the vector space at vertex x is d if x lies in the dth component of this partition. Okay, so let's look at this in the example. So I'm doing i equal one. So the first condition says we remove We remove the segment i, and then there's the boundary what's left. So that's here four and seven, and also six and three. So this is the ki zero. And then you remove that part and consider the boundary of what is left. Consider the boundary of what is left. And this example is everything that's left, is this next boundary 852. So the K1 in this situation has just these three elements, and then we can look back into our quiver. Yeah, so everything the support of the module is only on these vertices is only on the vertices that I have just mentioned. It's only on the vertices that I've just mentioned: 2, 5, and 8. And so I can remove all the others. So this is the support of T1 and that. And at each vertex, the representation is one-dimensional. And so I still have to define linear maps. In this example, they will actually be identity. So the T1 in this in the standard notation will be this representation 52a. Okay, what are the maps in general? Right, we want to define linear maps phi alpha for every error alpha. Alpha goes from x to y. The map goes from the vector space at x to the vector space at y. And to define it, I need first to prove a fact that the difference of the dimensions. Of the dimensions at x and at y is at most one, so it's one or zero. But if there's an error from x to y, so you have to show this first. But once you know that, then the linear maps are as follows. So if the difference is one, then you have a matrix with a block which is the identity and a row of zeros below, or a row of a column of zeros to the left. Column of zeros to the left. And if the dimension at both ends is equal, then there are two possibilities. Either you have the identity matrix, or you have this matrix here, which has an identity block and then a column of zeros and a row of zeros. So, in other words, this is a Jordan block with eigenvalue zero. And you note you see if you have this matrix J is the composition of these two matrices, the product of these two. And so the definition is such that if you go around a cycle of length four, a cycle which is given by a crossing point, and you compose the four matrices that you And you compose the four matrices that you see along that cycle, it will always be this Jordan block. Yeah, when do you did you do this, and when do you do this? Well, this depends on the part that I have skipped. This some more. So, in certain situations, when you have these extra things, then you use this Jordan block. So, I will just tell you what happens in an example here. So here I take now here the second segment, this one. Let me make this a little bigger. So if you take i equal 2 and you remove everything that's around it, then what is left is just 1, 4, 3, and 8. And in the quiver, 1, 4, 3, and 8 form a cycle. And And yeah, so the definition of T2 is then such that on this cycle, you have, first of all, we have one-dimensional vector spaces at every point, and then we have three identity maps and one zero map. So how do you see this zero map? So maybe I can yeah, this is the Yeah, this is the part where it's not supported. And then, how do you see the zero map? Well, we're looking at i equals two, so we start walking on this segment two, and then we enter the region that corresponds to the non-zero components of the knot. And then here we turn. So we walk along the boundary, you see, of what we have left. And here is a point. Here's a point where you come to twice. You reach this point. You reach this point twice, or in other words, all four segments at this point are contained in the same KID. And then there's a direction here. You reach it from here or from here, depends on which way you start. But it's this side of this point which is special. And so this map from 4 to 8 is the that is zero. This is the one which has the Jordan block. It's the sum of all the clockwise cycles minus the counterclockwise cycles. So with this four cycles be just in so I thought if you have a potential then like the Than like this before than anything like that, or you still have to do it. So that part of it should be equal. Because the flavor is like bigger. Yeah, so this is a little funny here because it's directly happening in the two cycle. Oh, so yeah. Yeah. Good. Yeah, very good. Yeah, good yeah, very good point. Yes, that's right. So the thing I want to point out here, this T2 that we have just looked at, is, and if you compare with the T1, these are very different modules. Well, first of all, you see the dimension of them is. First of all, you see the dimension of them is different. This one has dimension four, this one has dimension three. They are structurally different. This one is a uniserial module. This one is not, has two simple submodules. And this is something that happens in general. So for every segment, we construct a module and they are very different. And I really want to underline this word very. I mean, here, this is a very small example. If you take a big example. This is a very small example. If you take a big example and you look at the modules, there you at first sight you cannot see anything, any similarity between them. Here, if you have played with these things long enough, then you realize, well, this one has five submodules, and this one also has five sub modules. And that's really the crucial thing for us. Okay, so yeah, so this is uh Yeah, so this is how we construct the representations. I want to move on then to not invariance. I told you in the beginning that we want to recover some information about the knot from our cluster variables. And what people like in NOT theory is to look at knot invariance. So these are, for example, polynomials that you associate to your NOT, which can be constructed. To your nut, which can be constructed sometimes by recursive combinatorial method or by geometric or algebraic definition. And one of the oldest and most studied, not invariant is the Alexander polynomial, which Alexander introduced in 1923. It's actually a Laurent polynomial. It is defined up to a power of t and up to Of t and up to up to sine. So, for example, in the figure eight naught, in our running example, we have the Alexander polynomial is this, which is equal to this one. Yeah, so this kind of equality is denoted by an equal sign with a little dot on it, which means exactly this. You can multiply by a power of. By a power of t and with a sign. So it's basically you can multiply by a unit in this ring. Yeah, it's a very nice not invariant. It has interesting properties. It's palindromic, which you can express by this identity. Or you can think of it as if you read the coefficients from left to right or from right to left, you get the same. To right, or from right to left, you get the same sequence. If you evaluate the Alexander polynomial at one, you get plus or minus one if you are looking at a knot. You get zero if you're looking at a link which has at least two components. Or maybe I should have said this earlier. A knot is an embedding of the circle in free space. And if you have more than one circle, it you knot together, then it's called a link. Then it's called a link because the number of circles is the number of components. And there are several definitions or interpretations of this Alexander polynomial. You can define it in an algebraic way as a generator of some ideal. You can define it geometrically using the Zeifert surface or combinatorially by skein relations. By skein relations. And the approach I want to use here was introduced by Kaufman in 1983 via Kaufman states. And so what Kaufman did is he was able to express the Alexander polynomial as a sum of weighted states. And so I will explain next what. So, I will explain next what is a state. A state is constructed in two steps. So, the first step is to choose two adjacent regions in the NOT diagram. I call them R1 and R2. Yeah, so here's an example. There's two adjacent regions. If you have two adjacent regions, that means that they share a segment. So, it is the same as choosing a segment. So it is the same as choosing a segment. Yeah, I formulate it in these terms because that's usually how people do it, but it is really the same as choosing a segment, which is what we did for defining our modules. Okay, so you have your pair of regions. There are these two regions which are kind of special. And then step two is you choose adjacent pairs. You choose adjacent pairs, and these pairs consist of a point and a region. Here's an example: there's a crossing point P and a region, and adjacent means that the region sees the point. And so this pair P comma R, you can You can express it by putting a marker next to the point inside the region R. This is this red point in this picture. Okay, so this point region corresponds to little markers in your knot diagram. And so the condition here is that you want every crossing point and every region, well, except the two that you marked in the beginning. two that you that you marked in the beginning that you rem that you chose in the beginning to appear exactly once in the set of markers right in the beginning i told you there's two more regions than crossing points so you if you remove two then there's exactly the same number of both so at every crossing point you will have a little red dot which sits in one of the regions and such that you you never label the same region twice Region twice, and so this collection of these red dots is called a Kaufman state. And maybe before going on here, I give you an example. Yeah, so this is a Kaufman state of the figure eight-naught, where it shows the two regions which are at segment one. Well, one of them should be R2, I guess. So, equivalently, you can just choose the segment one, and then you put a red dot at every crossing point. Okay, so then there are, well, I could talk about this theorem first, maybe. So, Kaufman's theorem says that there's a weight function which associates to each state a monomial in our A monomial in our ring and such that the Alexander polynomial is the sum of all these monomials over all states. There's a sign also involved. So you would like to collect all states and then you just take the sum over all states. And there's a convenient way to do so because this is written here. Here, these states form actually a postset. And the postset, how is it defined? Well, the covering relation is given by these transpositions along segments. So you have a segment J, which I have drawn here in this picture. And see on the left-hand side, the segment J has two markers. And whenever you have this situation. Markers, and whenever you have this situation, then you can flip them, you can move them across the segment. So I can think of it as moving these markers counterclockwise to go from the left to the right. And then that's a covering relation in the poster. So either you think of that as this as moving the markers counterclockwise around the crossing points, or Around the crossing points, or you can think of that as moving the markers clockwise around the regions. Whatever you prefer. Okay, so this gives a postet. The postet in our example is here. Maybe we start at the top. If you look here, there's exactly one segment which contains two marks. Contains two markers. This is the segment number five. And I go one step down by moving these two markers. And I label this move by five because it's the transposition at segment five. And then at the new level, I have two segments on which I can operate. There's the segment two and the segment eight. So I have two operations going down. Two operations going down, and then, well, if you chose to do one, then afterwards you can still do eight, and if you chose to do eight, you can still do two. So there's two more ways to go down. And then you see here, there's nothing else you can do. And in this bottom most picture, the only segments that have two markers are the segments two and eight. And if you would do the operation there, well, you would go up, you would not go down. So this is all you can do. So, this is all you can do. Yeah, which is the segment that you have marked? This the segment i is the one that I chose, the i equal one. So, this was our module corresponding here, this t1 was this 5A2. So, I could also look at sub modules of 5A2. Of course, the module itself is a submodule. The module itself is a submodule, and then the direct sum of eight and two is a submodule. And I could label this by five because that's the difference between the two. And then from here, you can go down two steps. So I guess this should be eight and this should be two. And then you have the zero module. And these are all the sub modules of our module. So you see there's. So, you see, there seems to be an isomorphism between these two possets. And yeah, that's exactly what is happening in general. Yeah, I wrote the F polynomial here because it will be important later. So if you have this post-set of submodules, then you can write the F polynomial just by, yeah, the 5 to 8 will correspond to Y2, Y5, Y8, 8. To y2, y5, y8, 8 and 2 will correspond to y2, y8, and so on. It's just the dimension of the submodule. Yeah, so maybe let me skip this for, or maybe just to give you an idea. If you look at the segment two, then the POSET has a quite different structure. It looks like this. This is what I mentioned earlier. The module is uniserial. Mentioned earlier, the module is uniserial. But it happens on both sides. In the Kaufman states, you also get the same exact structure. And let me state the results. Yeah, so for every segment, we have our representation Ti. And the first statement is that the state poset, which also depends on the segment i that you choose, is isomorphic to the poset of submodules, as we have seen in the previous picture in examples. And then the main result, I guess, is that the F polynomial of our module specializes to the Alexander polynomial. Remember, the f polynomial has many variables. For every vertex, you get a y variable. The Alexander polynomial is a polynomial in one variable. And so the specialization is given here. So yj, though j is a vertex in the criver, it's a segment in the knot, is specialized to negative t. If the segment j goes from an undercrossing to an overcrossing. Goes from an undercrossing to an overcrossing. So the segment, you have an oriented strands here, so you need an orientation on the segment J to say what it does. If it goes the other way from an overcrossing to an undercrossing, you have a negative one as a power. And if it does neither, if it just stays above or below, then you specialize to negative one. To negative one. So the F polynomial specializes to the Alexander polynomial in this very particular way. So this specialization does not depend on the segment I. You construct a bunch of representations and they all specialize to the Alexander polynomial under the same specialization. It does for a link, but not for a NOT. So, if you have several components, it does depend how you choose the orientations on each component. The Alexander polynomial will change, but this is recovered here too. And I wrote here, just as a reminder, if you forgot what the F polynomial is, or if you would like an easy formula for If you would like an easy formula for the F polynomial, so is quite easy for these modules because they have this remarkable property that every submodule is uniquely determined by its dimension vector. So that's another thing you have to show, which is quite strong. It means that in the F polynomial, every term has coefficient one. Or if you think of it as Newton polytopes, this would mean that every vertex. That every lattice point in the Newton polytope is a vertex of the polytope. There's no multiplicities. And so, therefore, this is just the sum over all submodules here, and then it's really just the y to the dimension of the submodule. Okay, so in our example, we have seen the T1 was this: the F poly. T1 was this, the F polynomial is this. And in this special case, for this knot, since it's an alternating knot and I labeled the segments by following this trend, the specialization is simply T if this should be a J here, if J is even and T inverse if J is odd. So you're specializing one to one, Y8 to T, Y2 to T. This is a Y2 to t. This is a t square, and here there's one odd variable, so it's a t, and you get the Alexander polynomial that we had in the beginning. Okay, so this is the content of our first paper. Any questions so far? Yes? Can you say that regular specialization is not invariant without seeing that the equals dialects and replica normal? Wow, that's a very good question. No, I have not I have not thought about it. Yes, yeah, I don't know. Yes, one would have to translate the proof for the Alexander polynomial back to clusters, but I have not tried to. So I said in the beginning, the cluster algebra will heavily depend on the cluster algebra will heavily depend on the chose on the choice of the not diagram so it is not a not invariant at all and it it only becomes you only get this invariance under this under the specialization at the end so here somehow surprisingly this the specialization recovers all the information about the node the same for the phone that the same dependent on the phone That's correct, yes. When you use a weight function, that's right, yes. Exactly. Yes, the weight function depends on the over and under questions. Okay, so this was the progress on part one of the project. Part two, I said, was to find an explicit mutation sequence. So, what we have done so far, we have. So, what we have done so far, we have considered elements in the module category. And if you use the cluster character, you would get cluster variables. Well, elements of the cluster algebra, and then you can take their F polynomials. It's not clear that these are cluster variables. We have one for every vertex of the quiver, so we can specialize, we can use the cluster character on the on this on the. cluster character on the on this on this direct sum and we will get a set and so we want to show that that each of these x t i is a cluster variable but what we actually want to show is is stronger we want to show that this x sub t the collection of all the ti's is actually a cluster um which is i i find quite surprising that you have um you have a well okay you have some some variables in Well, okay, you have some variables inside your cluster algebra which specialize to this not invariant, but all these variables are compatible. They all sit in one common cluster. And so the strategy is to find a mutation sequence, which starts at the initial cluster and gets you to another cluster which contains all our variables and then with a quiver qt. With a quiver Qt, the mutation of Q. And so we use what we call the bygone reduction algorithm. So in your NOT diagram, you might have a bygone like this, and you can the algorithm is replace it by just removing the bygone and keeping everything else in place. So I'm doing this here in an example. I'm doing this here in an example. Here's a slightly bigger nut. Here's a bygone 6 and 12. I reduce it by replacing it simply by crossing and keeping everything else. There's here 1, 1, 11, 7, and 5. They are still exactly at the same spot. I just, I literally used the iPad and erased and replaced it by a crossing. And I, yeah, I really, there's no over-undercrossing here, it's just on the level of diagrams again. And then I can reduce next this 3.8. I get this picture. And then you see there's this 111, 4, and 9. So you create new bygons. This 111 here in the beginning was not a bygone. This was a region with three sides. But when you do these reductions, When you do these reductions, then you create new bygones. They were not bygones in the beginning. And well, if you continue eventually, if you're lucky enough, you get to a hopflink. So a hopflink is exactly this picture here where you have two circles which intersect each other like this. And yeah, this is kind of the heart of the knot. I like to call it the heart of the knot. And here you. And here you I still want to write here two pairs, and actually, these are exactly the ones which are not in a bygone. So I take two and five, and seven and ten together. And yes, so this little algorithm gives us two things. Yes, because that's the thing that works. You will see on the next slide what really happenings. So, first of all, this gives a permutation as a product of transpositions. And so, these first here are these bygons that I have reduced, and the last two are the ones from the last step. And it gives you a mutation sequence where the first part, speaker, the first part. The first part is the sequence of the bygone reduction. And for each bygone, it doesn't matter if you take six first or 12 first, it's the same. And then there's the middle sequence here, which is the Hopf sequence, if you want. And then we continue, we do not stop there. So we undo the bygone mutation sequence. So that's exactly the reverse sequence of the first one. The first one, so it's like. So, to answer your question, the first sequence here gets you from your original node to this hopflink. And then this part kind of turns the hopflink into its opposite. I think of it like that, like with you, you flip it over, you take the opposite orientation, and then you mutate back to. And then you mutate back to your, you build the knot back up in this in this reverse sequence. And theorem too, I put it in quotes because, well, it's not written yet. So assume you have such a bygone reduction, then if you apply it to your initial seed, you do get what you want. You do get this cluster of Xt. So it proves. Of Xt. So it proves that all our variables that we have constructed are actually cluster variables and they all live in the same cluster. And moreover, the quiver is quite particular. This permutation sigma we have also obtained from the sequence is actually inducing an isomorphism between the original quiver that we have constructed directly from the knot and this quiver, the ops. And this this quiver, the opposite of the quiver from the seed where that contains our variables. It's non-trivial. You have to send the vertex i in the original quiver to the vertex sigma i in the new quiver. So if you have this theorem, then it immediately gives you a corollary that the sigma actually induces a cluster. That the sigma actually induces a cluster automorphism of order two. And this is not a quasi-cluster automorphism, it's a cluster automorphism. Okay, so my time is up. This is really a very easy proof. It follows directly from previous work with Asim and Shramshenko. That the fact that it's an automorphism and this order too follows. Automorphism and disorder too follows from the fact that if you do the mutation sequence twice, you get the identity. So maybe a last remark is that not every knot has this bygone reduction. Not every knot diagram has this bygone reduction. So for example, here this is a Boromian rings. It's a link which has three circles. Which has three circles which overlap in a certain way, and you see there's no bygone in this diagram, and so you have to create first a bygone, which is coming back to Alfredo's question in the beginning. So, here's something like the Reidemeister III move. Well, usually for Reidemeister III moves, you have over and under crossings, which I completely ignore here. It just looks like a Reidemeister III move, where you move this segment here across the crossing. Across the crossing to get it below, and there's a mutation sequence which does this for the quiver. And you would move this segment here below the crossing. And then suddenly you have a lot of bygones and you can do the bygone reduction. Yeah, so we're working on this. We haven't completed this by. Complete this by. So, whenever you do these reductions, you have to show that on the quivals exactly and on your representations and on your F polynomial, it does exactly what you want it to do. Okay, so that's all. Thank you very much. Thank you very much, Frank, for this very nice talk. Are there any questions from the virtual participants? From the virtual participants. If there are questions, please feel free to unmute yourself and just post the question. Well, it seems that for the moment there are no questions from the virtual participants. Are there questions from the potential for participants? Do you know what you get if you take the quantum analogs of the X T I's? Analogues of the X T I's no yes I have not looked at it at all. Yes, uh-huh. Yes. There's something for the future, I guess. Are there known interesting refinements of the Alexander polynomial that you could shoot for? Yeah, there's this work by Osfad and Sabu. Yeah, so there's a second grading on NOTS. I forgot the name. So there's the Alexander grading, and there's a second grading, and you have to get a two-variable polynomial, which can be interpreted as the As the Euler characteristic of some homology theory, similar to the I better not continue talking now because I will get all the terms wrong. Yeah, so there's important generalizations of this Alexander polynomial, and I have looked at that a little bit, but I so far have not seen how if that is something we can do. Yes, it's something we want to look at, definitely. Yes, so the F polynomial is not a NOT invariant, and you have the specialization which is with one variable. And are there some kind of partial specialization which would be a not invariant with more information than the Alexander Polynesian? Could you? Could you again? I don't know. Yes, I don't know. It might be not. I'm not sure. So, a natural candidate one would like to have is the Homphy polynomial, which specializes to the Alexander polynomial. And we have tried to get that one, but we were not able to. Get that one, but we were not able to. And then the Homphley Pt polynomial is the most general polynomial which satisfies scan relations. So at least it seems like if there is a specialization, it will be not uniform, like this one, where it doesn't depend on the chosen segment I. Yeah, so for the Jones polynomial, Yeah, so for the Jones polynomial, we can do this for certain knots, but only where we choose a particular segment. We can do the same game, we can specialize, but it only works for two bridge knots, the Jones putting up a categorification of the Can you cook up a categorification of the Alexander polynomial using the additive categorification of cluster algebras, or you would need your cluster algebra to have a monoidal categorification to cook up the categorification of Alexander? I don't know. Yeah, sorry. Yes, I have not thought about it. You see, we are still in the beginning of you ask all. Still in the beginning, you ask all these difficult questions. We're still trying to fix the really foundations here, but we haven't gone that far yet. Well, you are only using very few representations of your quiver algebra in the beginning, so do you think that that other representation would be also meaningful? So, in the examples I showed you, this might be very misleading in general. So, here's a slightly bigger nut, not that much, really. And the quiver looks like this. And this mutation sequence is very particular. particular it's if you if you just do arbitrary mutations it it explodes immediately right so um and so even for for this so the one of the representations then looks like this and you you get already very big f polynomials um but um yeah so i i don't know so of course you you you you mutate you get to a You mutate, you get to a cluster, you find something nice, and you want to do the same mutation sequence again. But, well, unfortunately, or fortunately, I don't know, it's of order two, you come back. So, there was at some point that we had the hope that if you iterate this automorphism, you get something interesting, but it is not clear. Um so these representations is another way of asking these representations are distinguished uh for physiological, in some sense, they are Well, it comes in later. Yeah, I mean, if they form a cluster, then it would be some kind of cluster-tilting object. It's not so easy there to do much because the algebra in general are infinite dimensional. So a lot of the theory does not apply. For example, tau-tilting theory you cannot use. Yes. So, if I understood correctly, when you have this algorithm to find this mutation sequence, you have some initial choice of bygone, right? We are going to erase it. So you could produce different mutation sequences. Do those each produce distinct cluster isomorphisms? No, it's all the same. Okay. Well, I think it's well, yeah, you get exactly. I think it's well, yeah, you get exactly the same class. Sorry. Well, you get the same cluster. So I think what can happen is that the variables have different labels, right? So Ti becomes a Tj, and you have the fifth one in your sequence corresponds now to. Your sequence corresponds now to a different segment you started with. Maybe. I think it would be the same up to some relabeling. And then at the level of these algebra, they depend on the choice of not diagram. And so if you apply this Heidemeister move, so you get the different algebra. So how do you connect this? How do you connect this at the level of the algebra? Also, very good question. Yes, so you, and again, the answer is I don't know. You see, take headphones for your phone, right? It's a little string and usually it's an unknot and put them in your pocket and take them out after a day or two. Out after a day or two, it's a big mess. It is still the unknot, but it has maybe 100 crossings. And so you get a quiver which has 200 vertices, but it should be the trivial quiver. So somehow these algebras don't seem related at all. And it only comes out when you do the specialization of the F polynomial, which is huge, but then everything collapses. Yes, because each algebra corresponds to many nodes. Corresponds to many nodes depending on the choice of up and down. That's right, yeah, infinitely many. Oh, that's also true. That's right. Yes, the same algebra, if you just move a strand one over the other, then it corresponds to different knots. That's correct. Yes. They are not really associated to knots, but to these diagrams. To the diagrams, exactly. Yeah, so possibly you can guess the question I will ask you. So, in my talk, I drew some particular braid diagrams, which weren't quite the diagram for the knot I was interested in. But you could kind of get there by appending. Okay, so in my talk, there was the word beta, then you also have the word u. So you need to take a negative braid lift of u, stick it on the end, and then close everything. Do you know if you take some braid diagram like that, do you recover? That? Do you recover like kind of these other relationships between nodes and cluster algebras? Like, can you get playback graph quivers or something? Anything like that? Yeah, I talked about this a little bit with Jose. And so he said you cannot construct every nautilus where you need a positive grade, or so there are some conditions. And yeah, we have looked at. Yeah, we have looked at this a little bit, and I don't see how to go from one to the other. It might be that it just so happens that there's not plus the algebra and there's more than one connection, but I'm not sure. Just so far, I don't see any relation. I might have also a question. I might have also a question. I know people consider also quantum not invariance. Do you expect to get also quantum not invariance by passing to quantum cluster algebra? Yeah, so this is probably related to Ben's question. And the answer is still the same. We don't know yet. Yeah, so sorry. Are there any other questions? Are there any other questions? It doesn't seem to be the case, so let's thank the speaker again.