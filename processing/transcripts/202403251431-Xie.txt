One is mobile and the other one is generative model and the last one I'm going to add black is a DRO. So three concepts. So we'll see how different things, different themes play a role in solving these problems. And why do I need these things here? Okay, so this is a joint work with my student, Tisha student Jin Shuya at Georgia Tech, Jing Yao Li at Georgia Tech, and also my collaborator, Shimin Shionak. And so I'll start with And so I'll start with some background and then talk about this method, which is a flow PRO, and then talk about some experiments to show how this works and the theory behind it. And so you may wonder why do we need this? And so I think I probably don't need this slide here. This is very general audience, but everybody knows what the DRO is. Basically, we want to make the handle uncertainty introduced in particular by data. And distribution of uncertainty means that. And distribution uncertainty means that we don't want to have the parametric form of the distribution, but to consider arbitrary, general distribution around the observations. And so I guess this slide is also very basic. So how to represent distributions? And so classical statistics is parametric modeling. So there's a primary consideration distributions that are in the family of participant function four. And then you try to ask people problems that are. You know, here, oh, problem set up. We consider, you know, suppose there's some reference measure, reference distribution, and then we say that let's consider perturbations of this reference measure with certain metric, with certain radius. So that's which I'm going to consider. And so in particular, I'm going to consider various NDRO, which is a popular topic. And I guess I don't have to introduce too much. In particular, the authors are sitting in the audience and many people work on this topic. So And many people work on this topic. So it's basically a mini-max problem, like the talk has been mentioned this morning. So the basic version is to say: suppose we have some rates, right? And this risk depend on x. And so this is the data that we, some data or we have some observation belts. But we want to consider minimizing this exactly risk with respect to some distribution q that is not the observer distribution, but it To the observable distribution, but it is within a ball centered at this reference measure P, with certain radius itself. And so, mass system DRO in particular consider the measure of the distance between the distribution I want to consider, which I call the worst case distribution, and my reference measure using the mass system metric. And in this talk, I make it simpler and just consider the Rusty State 2. There are different kinds of Russian problems. Rasis State 2 is probably the most easy one to consider. The most easy one to consider, so let's consider that. And so, what else is, I think, a lot of times people consider what is this P? This P is a reference vector, and this is where our observation or data facts into this problem. And so, for example, you collect 100 samples, and essentially that combined information, and then if you just consider this breakthrough measure as the empirical distribution of the observations, this P is going to be great. Is going to be great. And that is an important structure exploited in solving this problem. And so today's talk actually: the focus is: suppose I want to solve the problem, where this P may not be discrete, but it is some unknown distribution that can be continuous, but I observe this P through data, right? This statistical point of view, and saying there's an underlying distribution, I don't know, but I have observation. So this P may not be strict. So the scheme may not be strict. This actually poses the difficult mathematical problem, how to solve it. And so like I said, I'm going to introduce some terms. The key will solve this problem. I call this key spherical distribution. And so many good results in the past have shown that in many cases, under some regularity condition, actually, for example, complexity, complex regarding this loss. Regarding this loss, you can actually exchange the knee and max. But I think the talk this morning by Jose actually provided a good motivation. You don't have to consider exchanging max. The problem considered here is just this. And in particular, I'm going to focus on the problems, like I said, P may not be a discrete distribution, but it can be a continuous distribution observed on theta. And then I'm going to focus on solving the problem of the inner maximization. Of the inner maximization. And so the inner maximization means I want to find a worst-case distribution I call the Q-star. And so this probably has been considered in the past, and I was like, yeah, and why do I need to introduce this method to find this Q-star? And so, again, like I said, I probably don't have to cover too much about more vision for processing. For example, I can also consider EPL as also a popular measure to. Is also a popular measure to introduce the stats, I certainly said, but Marshall's thing since you can move things around, right? So you can actually measure the divergence or distance between two distributions with different support. So that's why I consider processing as certainty sets. Okay, so some revisit of what has been done in this problem. And so like I said, let's consider this inner maximization problem. I want to find this Q that maximizes these kind of ways. That maximizes the waste. Centered around some ball, this center P is widget. And so I can write the due of this problem using Lagrangian. And then we can actually show with maybe two or three lines, it's not very difficult, that my due problem is going to be in this particular form. And so when I do this, I didn't make an assumption about what this p is to be. But you can see this is my view problem. This lambda is. This is my view problem. This lambda is my function multiplier. So look back here. This basically says that I need to solve this problem where I need to evaluate this blue term. And then where this x is following some p. This p, remember, is the center of the ball, which is my roughly smaller. And then inside here, this blue term is a point-wise maximization of the risk or loss. Okay, so I didn't play with the lead. So I didn't play with the theta, I just is for a particular theta, so you can think about the theta represents a particular algorithm. And then this basically says that if I can solve a point-wise maximum of my loss function with this particular regularizer, in fact you probably recognize that this already, this is so-called the Merolo Shina regularization, or it's also known as Mero envelope. And so why this is z minus x squared is because when I, as we said, Square is because for my superside construction, I use sparse system 2. So you can, you know, yeah, simply show whose term shows that corresponding partial system 2. And so, okay, it's a regularizer because you basically say that let's find the point-wise, you know, z that makes my race to be large, as large as possible. And this z is the perturbation from my data, right? If x is particular, if you take a particular x, and then this z will be close to. Z will be close to the X with this amount of penalty, and then make it worse. So you can solve this, and the rest of the problem is great. Because then you can say, okay, now instead of solving the primal, I can solve the deal. Solve the Dewe problem means I just need to solve this blender, which is just a scalar. And then the problem is solved. So, like I said, there's many nice results by Kuhn and Jose and Cal. And that was in the audience. I think many people have contributed saying in many cases to be shown there is a strong duality, solving this problem is the same as solving that problem. Okay. Okay, so like I said, I think as far as I know, a lot of the DRO problem solution is based on saying, let's look at a dual formulation, and if I can evaluate this metrical envelope for some risk, and then if I can, you know. And then if I can, you know, in order to solve this, I need to develop this expectation. And in some cases, you know, in a in a very particular choice of the P, when it is great, and then this expectation is just a sum, right? It's just a simple average. And the rest of it is just like, let's do winning this set. So you solve this scalar lambda, and sometimes you give the white search. It's a very simple problem. Okay, so what about the other p that is not impure distribution? That is not an empirical distribution of data. If this p, for example, is Gaussian, and it is also maybe not very difficult. So if your R is simple, and if you can solve the supremum point-wise, and then if this P is Gaussian, you can probably also derive something relatively simple, and you can also solve this problem. And so, in particular, I think there is a paper by John, like 2020, and then in particular, consider this for basically worst-case robustness. Basically, worst-case robust learning problem, we can solve this and the two-dimensional set. And so, basically, I also talked to my colleague Alexander Shapiro in the department, and he basically said, okay, the arrow problem, as long as you can sample from the scheme, the problem you can also, in most cases, you can solve. So, I think the complexity coming from solving the regional envelope, and then you try to evaluate this expectation. And if you can cycle from it, then you can. Expectation. And if you can cycle from it, then you're good. Okay, but the problem is, if I take a step back and try to answer my earlier question, I said, I want to find the worst case distribution Q. And so you can see by this Q formulation, somehow, the Q disappeared in the problem. Which is a nice structure because if you want to solve the problems to define the worst case Q, the Q is an arbitrary distribution centered around the reference member P, and it is an infinite-dimensional optimization problem. Dimensional optimization problem. So, how to solve that computationally is believed to be hard. So, although I can solve this DRO problem by using the dual formulation, as long as I can sample from P, but I still don't know how to get this Q star in many cases. Okay, so and then, okay, this is, I've seen some Q star formulation. So, what has been done is, for example, if the P is P hat, which is the empirical distribution from theta, Which is the empirical distribution from data. And so, this is one example where I have solved this DRO problem for robust classification. And then the blue and the red are the data points from the first and second class, or the hypothesis 0, hypothesis 1. And then I basically can solve this Q star, and then you can write as a byproduct that you can actually latest do. And then you can show that your Q star is also a discrete. Is also a discrete distribution. And then basically the problem became saying that if this is my reference measure, I just move the point mass around in the worst case fashion, and then change the base on them. And then you can actually find the Q star. And this basically reduces the problem to solving a linear programming, and then with n square variables. Okay, but you see, wait, what is n? n is a sample size, okay? Is a sample size. So in this problem, I have five samples for each class, and then n is 10, which is not too bad. n squared is 100. I have 100 metaboles. However, if you think about it, most of the classification problems, the n can be very large. So n can be thousands, can be tens of thousands, can be millions. And then, you know, this kind of thing quickly becomes not very easy to solve. And so another problem is this, you know. Another problem with this, I think, solution is if I solve it, if I consider my reference matter to be discrete, and then my Q star look like this. This is actually solved for this particular problem. And you can see they're basically discrete, and then move the passes around. Okay? But then you can think about if I want to build a classifier using this as my new perturbed Q star, and then it is quick, then that means my classifier. You know, that means my classifier is built for these data points. If now I give you a new sample, and this new sample is not supported on any of these places, it is a completely new sample that I haven't observed before, right? And then I cannot easily extend my classifier, robust classifier build out this Q star. Unless I do some interpolation, I can combine with the Gaussian kernel or something, but that's like an ad hoc approach. Okay, so my question is. Okay, so my question is: I want to be able to, hopefully, if this is my empirical distribution, I want to be able to solve my Q star being a continuous distribution. And then I want to add this constraint into my optimization problem. I want my Q star to be continuous, such that it can be generalized to data points I've hadn't seen before. So this is hopefully the motivation for why we want to consider this problem. Why do you want to consider this problem is suppose I want to find the worst-case distribution cost q star in my DRL to be continuous. And then, how do we probably solve it? And like I said, this is infinite dimension problem. And so these are two related problems. And like I said, I don't have to talk too much about this, but basically, why do you want to start is although you can solve a DRO problem, for example, using the primal dual approach, but Primal dual approach, but sometimes you still need the Q star because I want to sample a worst case distribution sample out of it. This is the worst case sample, this is an IP0 sample, and so I can actually use it to test my algorithm, test my system. Okay, so the idea actually comes from, you know, this, the motivation comes from the generative model. This is one of the color terms in my title. And so, I And so I would say generative model, this is one of the buzzwords nowadays, machine learning, and basically saying that I want to be able to build a generator, and the generator is basically sampler, and such that it's represented typically by a neural network, and then you can input a noise sample into this neural network. And this neural network has been trained, has been tilted, such that the output of this neural network will give me a sample that follows the same distribution as my data. Distribution as my data. So I can turn a noise sample into a picture of a cat. It's actually a picture of my cat. Okay, so for example, these are examples of the samples generated for the heterogeneous digits, with the CIFAR images and so on. And none of these images actually exist in the training sample. These are all generated synthetic images, but you can see they're pretty realistic. So it's a sampler and hopefully it's also valid. And help us also evaluate the likelihood. This is very different from the traditional representing the distribution because it's implicit, right? So you don't write what the distribution looks like, but you can draw a sample out of it to represent your distribution. Okay, so on the high level, basically, generative models are in the form of saying, I want to be defined a transform f, and this f will transform a z into my x. So some of you may be familiar with calculus, so this is a little bit. Copular, so this is a little bit like a generalized idea of that. So you sample from a Z, which is multivariate Gaussian, and you find some mass F, and this F will convert your multivariate Gaussian into the distribution. Yeah, so this idea has been basically used in many places, more or less in this form, generative model out of the zero networks, again, autoencoders, normalizing flow, and score-based diffusion models. And in particular, I'm going to. Models, and in particular, I'm going to consider the normalizing full network in this physical approach. And I'm going to talk about what this is. Okay, so what is the connection of this with optimal transport? It's a workshop of optimal transport. And so let's think about, you know, I don't have, again, I think everybody's familiar in this workshop. Basically, like, you can think about, right, if I have two distributions, T and Q, and the most consistent. And the most considered probably formulation is this Pentarowitz formulation, and you say about to define a couple of such as marginal, this carpony is PI and Q as specified, but it has the joint distribution that will minimize my algorithm transport cost. And in fact, it is also related to the Munch problem. And the Manch problem comes from a different context, but people can actually show, like Bernier's theorem showing that these two formulations. Shown that these two formulations are the same. And there are some general, there are general regularity conditions, and in particular, if your P and Q are both are continuous, has density. This is the important property going to be used here. If your P and Q are both continuous and have density, and they have boundaries, second-order moments, and then finding the functions that you can tarnish is the same as finding an optimal transport map. And so I have a very simple representation of that. I want to find the T. T is a R D to R D map. T is a R V to R V map theme. And if you think about this, what does this mean? This T tells me I have one data point, now where should I move it? So that's it. This is my transport map. And then I want to find this transform map such that I can move a distribution from P to Q, so this pushboard operator, and at the same time to minimize this expected cost, which should be expectation, at its own P. And so we're going to use this Munch formulation and CASA problem. And has a problem of finding my PO as finding this T basic T. And that's the main idea in this problem. Okay, so let's look at this follow-up DRO problem again. So like the problem problem is to say I will solve, okay, now I changed my notation a little bit. And so my V is the minus of my additional loss R. I want to find the risk case distribution to minimize this. Minimize this. And then I write this into the Lagrangian form. But here you can see I still keep this. This notation means my Q is continuous with bounded second half moments. And so by considering this set of the possible risk case distribution, we'll allow me to use the Bernier theorem and cast the problem as finding the T, the push-forward mapping or the transport map. Okay, so there is, I think, not very difficult to prove theorem, is we can show that this problem is the same as solving this problem. So the C is Rd to Rd mapping. And so you can see this term is nothing but saying that, okay, my X is following my Q. Q is, remember, the worst case distribution. And so how do I get this Q? It's just starting from your reference measure P. Starting from your reference measure P. And you find this mapping P, which is Rd to Rd mapping. And to the same map, given any data point, how I move this data point to the destination. So basically, this is V evaluated at, I should say this is a loose notation, basically means that this expected value of V, and then when the V is all, it's pushed forward. But this is V is convex. V? Okay, so. So, B, okay, so you have to show something. But this result actually, we don't need V to be convex. This is a general result. The goodness of this two. But if you want to show any convergence of the algorithm later, we need some convexity. And the convexity is not generic complexity because we're talking about the distribution space. So we need the convexity along geodesic. Continuity of Continuity of V. We need a continuity of V. Yeah, so V is basically the loss function. So if you think about the classification problem, this V is my classification cost. Or if I want to solve the generative model problem, this V is basically the KL divergence of my distribution from a Gaussian, which is also geogasmic complex. Thanks, Casadziki. For the push forward to be an actual transport map rather than a yeah, yeah, yeah, yeah, yeah, yeah, absolutely. This P is a density. This P is a density. So, okay, so this, remember I said this P is, in my much construction, that's the reference measure. So, this P is my reference measure. I don't know, but I can observe from sample. So basically, when I actually solve this problem, I'm going to replace this again by sample average. By sample average. But the difference is, you know, if I do it this way, my Q, I don't have to assume my Q to be this great because Q is the push-forward operator. Another slide for this. And so my Q should be the push-forward operator of the T, which is the population density I don't know, but I can observe data. So I think this slide probably summarizes the main idea how I'm going to try to do this. How I'm going to try to do this is, okay, so we don't know the P, but we observe with samples. And so, what I'm trying to do is, okay, I want to be able to say, I give you a loss, and I can allow you to push your data to make your loss as large as possible. And so, you want to find some Q, which is a risk-case distribution, to make your loss large. But how do I represent my Q? I'm going to use this Bernier's theorem, like push-forward, I'll find theoretical. I push forward, I'll find the representation. And finding a T, I call T. The worst name back to push my data distribution to some domain Q. And so, but since I don't know what the P is, I need to be able to learn it from data as well. Okay, so how do I do that? Is I'm trying to find another map, which I have Tg, that will map the Gaussian, multi-bear Gaussian, into this P. So currently, we're testing this as a two-step, but you can imagine that you can just do it like once, because essentially it's from here from this multivariate Gaussian to the Q, can I directly map it there? But currently it is basically, if I find the TG, this TG will map the Gaussian into my data distribution. So I don't know what this T is, but I have samples to help me calibrate. You say, I have the Gaussian, I find this TG push forward. I find this Tg push forward, and then I can match the distribution of the data, and then I further push it with my Tw, and that will maximize my loss, can make it worse. And why do I want to do this? It's because if I do it this way, now I have basically a generative model of my worst-case distribution. And so, since this domain is Gaussian, multi-general Gaussian, that means I can very easily sample from it. It's high-dimensional, right? High-dimensional Gaussian-like samples. Dimensional, right? High-dimensional Gaussian sample. And so I can take one sample, a fresh sample from multimedia Gaussian, and then push it through the Tg coupled with Tw. I will end up having a worst-case distribution sample here to maximize my disc. Okay, question here? So it's a, okay, so but how do I do this? Okay, so the general idea is basically finding these two T's, okay, and these two T's. Two T's, okay. And these two T's are R D to R mapping. And then I want to be able to represent this, again, using this idea of dynamic view of the density evolution, and then try to represent this T as a continuous way of transforming the particles. So because there's a one-time correspondence, the displacement T, suppose if I describe how my data is being moved by some so-called My data is being moved by something so-called velocity field, and then this is instantaneous over time. So it's basically OTE, or depending on how weave it, and then you can also use PDE. And then you can actually integrate this over a certain period of time that you need the corresponding T. But this is a continuous way of mapping. If I map my data this way, I can also correspondingly change my distribution, and the distribution needs to satisfy the sustainability equation, and then because the distribution needs to normalize to. Because the distribution needs to normalize to one, so actually, you know, this movement is along a curve. And this curve is the geodesic curve. And so, when I talk about if they find a way to push my data and find the corresponding t, we can also study how the underlying distribution is changing over this whole time. And then talking about convergence. I think I don't have too much time, so I'm just gonna try to highlight a few results here. So, taking this viewpoint, like I said, Taking this viewpoint, like I said, it's basically a geometric way of finding how to push distributions. And so I think this is one way of looking at the Y sustain two. It's basically the Y sustain two have this dynamic formulation. And then essentially, the Y sustain two corresponds to the minimum effort of moving the distribution function to Q and then by finding some velocity Q. So this effort is measured by the expected distribution. Measured by the expected square integrated over the time horizon of my velocity field, and at the same time, I need to satisfy this constraint, which comes from the cognitive equation. All right, so this gave us this idea of saying that, okay, so I now have a continuous way of seeing how I push my data, and now we'll change the underlying distribution. And I want to be able to use this to match distributions, right? So on one side is Gaussian, in the middle is data, and then the next stage is to And then the next stage is to make it further worse. And so, if you integrate that over time, you have the corresponding t. And I can discretize this continuous time process, and then that is the overall t. And why do I want to discretize this? Because if I discretize them into small intervals, I should have some good approximation of my continuous dynamic. And each discretization will be represented with implementation as a block of real batteries. Okay, and so it's also invertible. And so, most of the time, the neural network is not invertible, but this one you can invert it easily because you just integrate, you know, propagate this process forward in time and backward in time, and then you can perform the inversion. And so, the rest of it, I'm explaining how do I do this, the data generation part, and then how do I do the worst case part. And so, the data generation part is solved using a proximal. Using a proximal approach, and so this is motivated by something called the JKO scheme in actually in a paper, in classical paper in PDE, 1998. And so, essentially, what it's doing is saying that here, the loss function is the KL divergence of my next step towards the TL, which is the Gaussian. And then you're doing this in a small step and saying each time you just push your distribution a little bit, getting close to the Gaussian. Distribution a little bit, getting close to the Daussum, and don't get too far away from it. And by our current formulation, I said our solar function is t. And these t are basically represented by the integral of the underlying continuous problem. And so, you know, everything can be computed in sample version. And so actually, the KL can be valued in the curve form. So I'm just giving some details. Okay, so you can gradually push the particles in each stage. This is separate optimization. Stage, we solve a separate optimization process, and it will converge to the if you have large enough mu, as long as you have large enough iteration, it doesn't converge to the males. And so we can also quantify what this n needs to be, how many iteration needs to be, and I think that's going to be some interesting results. I'll stop there. This is one example, showing what actually happens. You can turn a rows into a Gaussian and come back. So that's the data, and that's the Gaussian. And I wanted this to be word. And I wanted this to be wordable because this gives us numerical stability, and then we can have a geometry model. So, this is pretty good, passed by experiments. And then, once you have this, I can go from the rows to the noise and back. So, the next stage is I can push it further worse. And this is my worst-case distribution problem. Like before, you just solve this, and then it's very simple. You just basically push forward one more step. You just basically push forward one more step by solving this problem, and this V is going to be your original loss function, right? I know what you're trying to solve. Is it a classification? Is it some other things you're trying to solve? Okay, and so here's my example. What does this process look like? And so if my data is a dog, and then this worst-case generator, using the neural natural implementation, you can see interestingly pushing the picture pixels a little bit, and actually looks like a crop. And it was classified as a crop. Frog and it was classified as a frog. Running out of time. But so, yeah, these are some examples. We use it five-zero learning, actually compared risks. What if you don't have neural networks or differential privacy? And maybe one minute, just one slide, we can do some, we can actually show the convergence of this by making a connection of this scheme with proximal integrations in the proximal. In the probability space. And so this part basically can draw an analogy between what happens in the vector space when you prove the proximal scheme convergent vector space. But here we're doing this in the probability space. And so we need the loss function to be so-called along generalized convexity. For example, KL satisfy that. And then the rest of it is basically we need to generalize everything from vector version. Everything from the back conversion to the you know this pumping space equip with various thing too and then you can have the desired decrement and shows that this actually converges fairly fast, which is pretty good. And then it's also, you know, you can show the generative guarantee means that I can learn a distribution close to my desired distribution using the bidirectional data processing quality, and then that's the whole proof. And then that's the whole proof. Okay, so that's, you know, the worst case part, this is the generative part, right? The worst case part, I need to be the solvent for the general V, which is not a KF, which is why D progress. That's it. That's not a good question. Thank you very much. Are there any questions from the audience? I'll stop the recording.