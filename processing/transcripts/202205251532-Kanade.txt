So I'm going to maybe try and be quite keep things simple. So I'm going to try and present one very simple result, which is which somehow has some nice consequences. And I'm going to use what Thomas already talked about. So just recall the offset condition that Thomas mentioned in the last talk. And what I'm going to show is how, if you run mirror descent on just On just the empirical risk, then you get, and if you do RD stopping, then you get this offset condition for free. Well, as long as you're looking at essentially linear models, linear or linear-like models, so you can have kernels and so on, but anything that can look like linear functions. So I've written some setup here, but hopefully that's pretty much the same as what Thomas was using in the nuts talk, so it's familiar. And what I'm going to assume that all functions And we'd assume that all functions can be characterized by some alpha, and they're essentially just linear functions. So that's the setup. And let me write the main results. I want to first say that we're going to look at mirror descent on unconstrained empirical risk of expansions. This is some good look at I'll present the continuous time results and one can do everything in discrete time. If you pay what you need to, but it would be just simpler. So let's say size your mirror map until the update So the update given is your and I will switch between g sub alpha and alpha. So when I write Rn of alpha, this is just Rn of G sub. Okay, so that's so that's the update of mirror descent and the thing that we care about is the pregnant divergence that's generated by this, which points us to And what we care about, so what, okay, so has everyone seen a proof of grid descent? Yes, I take it. Okay, so this is then familiar. So what we care about is how does this fragment divergence change of time? And this, if you just differentiate this, basically you get that this is just going to give you that. So it turns out that the time derivative of the break-mean divergence is just that. And I'm going to And I'm going to look at this term a bit more closely and write down what this. If you look at the case, Post two and I have to do a calculation in real time. So if I look at this quantity. Right, so this is something new right as well. And now if I plug in this, so this is just my Rn of alpha prime. This thing I will write as F alpha minus prime is R n of Rn of alpha. And this quantity here is just rewrite it slightly a bit. And this is just the gradient of the empirical risk. Assuming I've done all the calculations correctly, and what you get is that minus the gradient of this alpha times alpha times prime is equal to Rn of it. I've got prime oopsie. Okay, and so so this is actually an equality and one direction wrong. I think you're correct. The main point is, okay, so this is an equality. And if you look in for optimization, what you would do is you would just usually drop this last term and say that this is non-negative. But it's important for me to keep this term. And I don't remember why. I don't remember why, so Mattus told me several times where this. We had the first sound, but I've forgotten. So, can you remind me now? Perceptron. Perceptron, okay. So, this in the Nobicosme first? Yeah, right. Okay, so that's hopefully not the right algorithm in your deceptive group, but I mean if you just label the terms by the terms in your intercept group. I will look that up, and now we'll be on the record. This was the first time this. This was the first time this, as far as I can tell, was peer. So you can write this, and to simplify assertion, I'm just going to give these some names. So this I'll call Rt, so this is just the difference between the risk of your predictor at time t, excess risk with respect to some reference alpha prime, and this I will call f alpha t, which is this difference between that on the sample between f alpha t and f alpha prime. And so this F alpha prime. And so this is just r t plus delta t. Okay, so now there is probably a one half somewhere. Okay, now we can just do what we would always do and integrate this. In write the fragment diversions alpha prime alpha zero is sometime t is the Time t, and if we average these out, so this is integral from 0 to t based on the t, 0 is like a 2 the t 0. Okay, and so now the question is: what time do we want to look at? So, I want to make sure that this becomes sufficiently small. So, this is already non-negative, so I can drop this. So, I want to pick. So I can drop this. So I want to pick t to be larger than let's see. 0. So I've got a 2 here over epsilon. Okay. So I pick t to be large enough. So this quantity is going to be smaller than epsilon over 2. And maybe I want to fool that because of that extra 2. And so what I get is that using this inf Using this, inf of this quantity is less than or equal to epsilon of t. So I'm integrating this out from 0 to t, and this is the integer is less than this, so there must be some, the smallest thing, it must be less than or equal to that. And this allows us to define a stopping time, formally which I will define to start as the first time First time such that this quantity Rt plus delta T equals epsilon. So that's going to be the stopping line. And there's two things that I want to say about this. Want to say about this and what happens at stopping time. So, the first thing is what happens to the predictor itself, and what can we say about in what space these alpha t's actually lie. And so, the results is that the first is to hold t up to the stopping time. It holds that. And this second is it out to the socking point itself. Yep, so that we alpha t instead of alpha prime or maybe it is alpha prime. Alpha T sorry. Yeah, alpha prime. And we oh, that I said alpha prime is alpha t. Uh no, so that's just alpha prime alpha t. Sorry. Okay. But that's just it's because of this essentially that you're only integrating non-negative terms. So your frequency diversions is going to be decreasing. Alpha primers then? Alpha primes then? Okay, so I haven't said what alpha primes. So alpha prime is any fixed reference point. So the quantum phrase is for all alpha prime this holds? This holds for all alpha prime. It depends on alpha prime. D star depends on alpha prime, but this holds for all alpha prime. Ah, okay. It doesn't matter what reference point you pick, this is always. Don't have definitions. Delta T and R T. Oh, I sorry. So R t is Rn of alpha T minus Rn of alpha prime, and delta T is f of alpha T minus F of alpha prime in this square set. So, why is RT positive? It may not be always positive. But then, why did you say is integrated to the star? So, I'm picking T star to be the first time when this becomes less than or at initiation. But earlier you said that you're integrating only positive quantities. Up to T star. So, stopping before this quantity can become an eventually the Reign divergence will impact increase. So eventually the Reign divergence will in fact increase, but there will be a point onto which it will always decrease, and I'm making sure that I'm indefinitely. And the second thing really follows directly just from this conditional stopping time that this is less than or equal to epsilon, that this is less than or equal to epsilon. And so what you get basically for free is that at the stopping time, this predictor satisfies this offset condition. Satisfies this offset condition. And so everything that Thomas did in the previous talk can now directly be applied to this predictor that you get from early stopping. So this is a very nice and short proof that this works. And okay, so this is it only works for linear models. Okay, so you can handle kernels and that's perfectly fine. And that's perfectly fine. But the fact that the proof is so short is, I think, is something that I really like. Okay, so maybe there's a few things I want to so I already said that this always pulls and maybe one thing that And maybe one thing that is slightly funky here is what it tells you is that all of your predictors alpha t, yes, as long as t is in this range in 0 to t star, what you have is the g alpha t's lie in this. So what's actually strange, and I haven't been able to make any use of it, is that this is actually a non-convex ball around alpha prime. And so what it's saying is that we don't actually know what alpha prime is, alpha prime any reference point, so we would pick it to be the minimizer of the population risk usually for the results that we want. But this is somehow in some because Somehow, in some, because the fragment divergence need not be convex in its second argument, it's this is defining some convex ball. And what you're saying is that this is saying is that all of these iterates belong to this funky ball. I was hoping it would have some use where it could actually be useful, but so far we haven't found any. Okay, so are there any questions? So I want to maybe then spend the rest of the time I have on a slightly different problem, but again looking at mirror descent for it. And I think for me at least there are lots of open questions there and I'm hoping that those of you who understand mirror descent better than I do will actually be able to help with that. So this is basically in some of the new prediction under L1 constraints. But I'm really interested. But I'm really interested in sparse predictions. And this really comes from, okay, so this has been mentioned several times in this week, but I'll quickly repeat. So the starting point for looking at a lot of these things was these updates that were basically looking at alphas on the dental formula squared. Looking at alphas on the normal form u squared minus phi square and looking at how this kind of thing can be used for sparse predictions. So if you just agree in descend upgrades on this instead of this primary parameterization, then you can get sparse predictions. And this is morally, or really not even just morally, equivalent to looking at objects that look like alpha t plus one is alpha t. alpha t, so I can write this as alpha t plus, alpha t minus, and x minus m beta times the gradient of this alpha T so this is just the exponential. So this is just the exponential gradient algorithm of even four minutes. And there's a paper not very old, I think, by Elad is definitely one of your singer and some of that stuff. I mean, we basically showed that these updates are equivalent to using the file. are equivalent to using the following mirror map. Characterized by this, which is just hyper any degree. Inverse hyperbolic sign. So that's what they showed that these updates are equivalent to this. So this is really just So this is really just doing a mirror descent. And so what we can try and see is what does one get when one applies this to this problem. So the first thing I will state without proving is that so this always lies in this range. One. I'm assuming, so you need some conditions in gamma, so gamma needs to be something. I'm sorry. Some government's positive, some positive numbers. I mean, you just don't want gamma to be zero because this is why it would require some positive gamma. But if you want an inking valence between the exponentiality, the grain descent and the real descent, you should give you specific gamma. You want to let gamma go to zero. Gamma is related to initialization. Yeah, so gamma is related to initialization. So we want gamma to be small, and that will be good, but of course that's going to come at some cost. Okay, so if I apply what we get from the previous result that I mentioned, so if you look at what happened at stopping time, so we know that this quantity And this is really just our quantity that we care about. But in fact, this also comes out of this. I'm doing the same thing again. Okay, so the six sign here is. So the psi here is just x alpha prime minus y. So all of this requires a realizability assumption that I'm going to take here. So what we want is that psi i are i i d zero mean and subcussion And so this thing again is just Rn of Rt star. This thing is the same thing as that. And this is Rn. And so this difference is again just that. And so what I That. And so, what I will get out of that is the first thing that I'm going to do is to make a new one. I move some things around here and there, but basically this is what you get as this S and you'll notice that because of this calculation I did here, in fact you don't even need this offset that came out from where I just said you would have got it directly for this fixed design setting through this anyway. Anyway, and then we can bound these things with Holders inequality essentially. So this is L odd norm of this times L infinity norm of this and okay, so this I want I won't do the calculation, but this is basically going to behave like some sigma square root log d over n. And this we're going to show is basically at most ten times the L1 norm of this. I'll bump it separately. Okay, but this is making some mistakes, isn't it? But minus two where? Yeah. Do you realize the terms you need to get minus two by? But probably in some sense I don't care because I'm going to apply this inequality here anyway. But you're probably right, but in some sense. Because all I'm doing is looking at Rn of alpha t star minus Rn of alpha prime, and I'm just going to say that that's equal to this plus that, and just put that in there. So okay, so this so this is so basically one minus two is equal to this plus this and put that in there. Yeah, and and and then I'm gonna operate on this inner product anyway. So this in fact that doesn't really okay so so that's so this can be just so okay, so then you need to have an assumption on the columns of Some assumption on the columns of x, so you need that the columns of x are not too large, so you need that x over square root n has all columns that have norm at most kappa, and then we get our kappa factor here. And this basically follows from the fact that I said that this alpha t star is going to have the alpha prime alpha t star. It's going to be at most. It's going to be at most this. And so you can show that, in fact, alpha prime is also going to be in some slightly larger L1 ball. And so altogether, this basically ends up being some constant times alpha 1 prime alpha sigma squared log d over n times this in 9. times this enlight one over gamma factor and this log one over gamma comes from basically this so what I know is that this quantity is bounded for at the stopping time quantity is bounded for at the stopping time the Bregman diversions alpha t star with respect to alpha prime by that but I want an L1 bound on that essentially and and you lose this you get this unfortunate log mono gamma factor right and so this is almost the right rate we should get slow rate except for Except for this low model gamma factor, that seems to be spurious, which you shouldn't really get from. If you did something like Lasso, you would get basically this without that. You would get, which would be the min-max optimum rate of the problem. Okay, so what I want to maybe spend the last few minutes on is asking a few open questions. Well, first, okay, can one get rid of this one? Okay, can one get rid of this one over gamma? I don't know how to do that, but that's maybe not the most interesting one. But what's more interesting is can one exploit structure on the covariance matrix in this analysis of mirror descent? So we can, so what we're really saying right now is we look at these mirror descent paths and we can we're using this tool to find where the iterates can Where the iterates can be. But for instance, if we wanted, so we know that in general, if we're interested in sparse recovery, so we know that the ground truth is actually sparse, not just that its L1 norm is bounded, that we should get better rates than this, as long as the cooperative matrix satisfies some conditions. If you have restricted isometry or restricted eigenvalue condition on X, then we should get both predictions. We should get both prediction error and even estimation error that are basically like one over n for this problem. And the question there is, so we know from somewhat long and tedious analysis looking at these directly in under restricted isometry condition, for instance, that what happens is these updates stay sparse. So if you start, if you initialize close to zero, Close to zero, and you run gradient descent on u and v rather than alpha directly, we know that these updates basically be space bars. In fact, they fit, seem to fit coordinate at the time, where you just see the largest coordinate of the time you vector being fit, and then at some point the second largest, and so on. This is exactly how common that they stay sparse up to this topic? This is up to the topic time, yes, sorry. So, so everything here relies heavily on early stopping, right? So, at convert. Relies heavily on early stopping. So at conversions, all of these things will overfit. So we're not in any regime where you want to train for conversions and still hope to get good models. You have to rely on stopping time. And as long as you stop before the stopping time, you get only sparse vectors. If we reach a slightly painful 10, 15 pain, hours is the shortest that I've seen for something like this. And that seems unsatisfactory. So everything else is really nice. Really nice, and what would be nice is somehow if you could, if one could also argue that when the matrix X has these nice properties, somehow these alpha primes, the alpha p path that you get also stays by this parse if you have restricted isometry or stays within this cone if you have a restricted eigenvalue property or something. So, is there any reason why these trajectories would move out of these? Why these trajectories would move out of these things, assuming your design metric actually satisfies these conditions. And so it seems, at least based on these simulations, that they should stay in space. And then one should be able to get passed rates directly for this analysis, but I don't actually have any way of doing that. Okay. Yeah, maybe one more comment. So even i if you look to this diagonal neural network and even if you have restricted isometry, as far as I know there are no correct bounds. So this is even in the RIP setting, all the people ask for RIP constant to be bounded by 100 square root of sparsity, but it should be just But it should be just a constant. So, this is something I was going to mention here. So, this means that you get your results, the results only work when n is at least k squared and the same other things that you get, but it should work with k, not k squared. And again, I think based on simulations, it seems that k is the correct answer. You shouldn't require n to be k squared. What n to be k square log d or is it? And if there is with early stopping with early stopping, everything is without early stopping you would just recover the L1 recovery results. But then you can't implement the del Garza, but L1 is bad, I think this L1 is bad. You have smallest L1 bar, but this corn is large. Oh, this is not sparse setting, this is not just RA vehicle, it's the noise. There is no noise. I mean, do you know that it's bad or do you just? I know, so I did this simulation. So after the stopping time, we will fit all the other partners. We will output something that is quite bad. So it's bad in the generalization sense or bad in the recovery sense? Both. So it's estimation error. So estimation error increases and prediction error also increases after you because there is the other thing also that I wanted to mention which has been somewhat bothering me is that a lot of these bounds seem to depend on the L1 norm of the target vector alpha prime. And in some sense, if you're at least in the sparse setting, If you're at least in the sparse setting, the problem should be easier once you have a larger L1 norm. So somehow your sample complexity should be smaller if you have, because the signal-to-noise ratio increases. So if you have the same sigma, if you increase the size of the vector, your problem should become easier. But somehow this bout suggests that you need some something that increases with the size of the problem of this. Now if if you're over if you have an arbitrary target vector and an L one bowl, then maybe that's inevitable. But if you're just looking for a sparse vector, just looking for a sparse factor can one actually put something that's not dependent on and I guess the last problem which is okay so if you if you only care about prediction error rather than estimation error and you know that the target vector is pass do you need Do you need any conditions on the covariance matrix at all? So, so for estimation, you need these conditions because otherwise you can't recover the target vector. But if you just care about prediction and you want your error to be like 1 over n, then do you require any conditions on x at all? So I think Martin Rainwright has. I think Sir Martin Rainwright has a paper that shows under some class of algorithms that minimize some penalized loss functions, you cannot do it. But in general, it's not clear that this is one should actually require one of the get at least one of the square root n-like grades. Insisting your tractability. And then of course you can get it. You just do it. Be very desirable, right? That any tractable algorithm, that no tractable algorithm obtains, then you'd have to, I mean, in particular, what notion of tractability efficient algorithm. So if you don't care about computational eff efficiency, then you can do it. Uh but if you care about a computational efficient algorithm, about a computational efficient algorithm, then it's not clear why one whether one should really require any conditions on X. You only care about prediction. You seem to suggest that you're... Do you think that you can? Because I mean the main, to me the main issue, because as you said, I mean there are negative results for L1 normalization and we know that there exists interaction. And we know that there exists interactable outputs. So now to define the problem you have to like have some notion of tractability so that you know to be able to well if you think you can do it then that's actually tractability. So I guess Thomas and I slightly differ Thomas is more optimistic that it can be done. I'm slightly more pessimistic but the problem is that if for you I mean Thomas doesn't have a problem but for you I mean what's the notion of trajectability you're going to use because it seems have almost It seems have almost zero techniques to have inject, you know, uh sort of uh okay so the first thing I will try in fact is some kind of an SQ lower balance. Okay, right, so that's the difference in stuff. That seems also something really cool. But I mean I wouldn't be surprised if Fiton can push it beyond just you know having these kind of what you get directly from RIP or restricted eigenvalue data. RIP or restricted eigenvalue, there might be more conditions and kind of think. Meaning, so Sir Thomas had some simulations that suggested that one can actually get slightly better rates, which I intended to try and look up in my email, but because I moved to stop by one day, I didn't quite have time to look them up. If I find them, I will. But it does seem that there are some regimes where one can do slightly better than one over square root n, at least, even if not go all the way up to one over n by using mirror descent. Uh by using mirror descent basically. Mirror descent? I mean so do you if you're using mirror descent type of analysis do you also compute the time steps and do a discrete analysis? Yeah, yeah, I mean okay yeah. Yeah, so so I don't think discretization really is an issue in this particular setting. Yeah but if you if you take small enough subsize then you also want to do the time scaling right like because you have to discretize you can't have exponential size Don't have exponential status. Yeah, no, no, but I don't think one needs it. So I think you need some relatively mild assumptions to get the discrete version of all of these. But even in this sense, I didn't have a sense of what does the T star continuous time looks like. You mentioned like a condition, stopping condition, but like how does it scale it? So T stop was basically this is Basically, so it's the Bregman divergence between a starting point and target alpha point divided by X1. That's what you define T star as a condition under which it becomes. Yeah, yeah, but it's always less than or equal to this. It's some number less than or equal to this. I think just to crack it, when you say that the discretization is easy, you mean that you can do discernment polytime, and you can probably, I mean that data you can buy, right? If you manage to improve this continuous time, then you can get a tractive algorithm, a polytime algorithm. But getting actually care about like linear times, because the polytime or something like that. So again, I don't remember off the top of my do you remember what the results are. So in the paper for this kind of results, early stopping, so we have a discrete time results under for smooth bosses and strongly convex mirror maps. So under standard conditions from optimization side. Because we are just adapting the standard optimization approach and basically just keeping this offset term. That has to be basically at most still the same as in this case if you have this extra smoothness kind of thing. The stopping time is the same, but the stopping time So the stopping time is the same, but the step size has to be bounded by this. So then you use it. Anyway, that's okay. So thank you very much.