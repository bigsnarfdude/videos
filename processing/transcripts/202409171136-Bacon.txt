So I'm going to hopefully keep you still entertained and awake, at least through that period. Unlike my colleagues, I'm actually at Concordia University, so a little bit further down the road. And I'm going to talk about really some theory perspectives. There's not going to be any real direct modeling and more of a call for For some potential collaboration as I go through this, I do want to just start by acknowledging that I'm at Concorda University and the Cios Nordil de Morrill, which is located on unceded indigenous lands. The Kanyakahagi Nation is the custodian of those lands. But more importantly, I think a lot of those policies and issues. And issues of confederation are still being felt today. And part of our work that we do, and the work that my colleagues is really trying to amplify the voices of the Indigenous communities as this is still, the harms of certain policies of colonialism, white supremacy are still having significant impacts. Okay, I guess I'm a little bit. I'm a, I guess I'm a little bit unique in terms of I actually define myself as a behavioral scientist, and quite often when I say that to most people, they're like, well, what is behavioral science? So I'm going to come with my definition, and this is a definition that myself and my colleagues tend to use. So behavioral science is an insectoral approach to understand and study normal human behavior and decision making. And I think those things are really important to highlight. So the normal aspect of human behavior, the things we do on an everyday basis, and also this aspect of decision making making making making making making And also, this aspect of decision making, which often gets left off the table a bit. But also, it's not just about sort of understanding those things, but also working out how do we positively promote, how do we promote positive adaptive behaviours? And more specifically, I work in the area of behavioural medicine, which is the application of this to health. This is a shameless plug, just in terms of the centre I work at. Of the centre I work at, but just to give you some context. So I'm based at the Montreal Behavioural Medicine Centre. This is a collaboration between UCAM Concordia and the CS Nord de la Montreal. Really, we're a methodologies group, so we're interested in integrating behavioural science methods and tools into a variety of health contexts. And our ultimate goal is to develop and test interventions, behaviour change-based interventions. And that can happen at multiple levels. This is the model that we leverage. Model that we leverage, and I'm going to sort of show you where all this fits in in the context of today. So, you know, before we even, so we always start with, you know, a significant clinical question, what's the problem and how might this be implemented at the core of this? And then the first thing, obviously, is to go off and understand the issue. So, this basic behavioral science piece is really the bit that overlaps here. And this is where we use epidemiological systematic reviews and lab-based studies. That feeds into the pipeline of then really. That feeds into the pipeline of then really defining what intervention components we need to be thinking about for building an intervention. We then go through a whole development process. Once we've gone through that development process, we then actually do trials to undertake this. So that pipeline is really important. And I think, and the reason why I'm flagging it is because every time we ask these questions about just understanding, it should always be in the context of how we're actually going to apply this. Going to apply this within the MBMC. So, I'm going to talk about COVID just to keep the theme going with everyone else, but we all have a bunch of other data as well. And I've just briefly highlighted we do work in digital health, in metabolic bariatric surgery, health care professional training, and we have a whole arm on evidence synthesis. We also have a significant amount of epidemiological data. So, if anyone's interested in where to collaborate and want some big data sets, we have some. Most of our data is Most of our data is clinical-based data, and it ties a significant amount of clinical information with health usage information, a whole bunch of self-report data, and there's a spectrum of things that we capture with that self-report. We've got a very large ongoing metabolic barrier extreme surgery cohort. We did a phase one that's got just over 600 patients for five years' worth of data. We've got a phase two that's running at the moment and growing. At the moment and growing, and then the smaller scale one. And we have a significant number of cardiovascular respiratory data sets. So, some of them as small as 200 because 3,000 participants and data capture between three and 10 years. So, just to give you an idea for any particular individual, I think the average number of bits of information that we have is somewhere in the region of 10,000 to 15,000 bits of information from an individual in most of those studies. Most of those studies. It's my shameless plug for collaboration. So back to theory. So what drives everything that we do is the COMB model. The COMB model is this here. So capability, motivation, opportunity. And it's these three factors that actually drive behavior. And if you look at most of the 87. 87, I think it is, behavior change and behavioural theories and models that Susan Mickey identified. All of them have elements of this, either some or all of them. But what are these things? So capabilities, this is our psychological or physical ability to enact a behavior, motivation, reflective and automatic mechanisms that activate or inhibit a behavior, and opportunity is the physical and social environment that enables the behavior. Environment that enables the behavior. And we know that from an intervention perspective, there is a heavy, heavy emphasis on this aspect here of capability, because most interventions in the healthcare world are education. So knowledge-based. Knowledge is just a sub-component of psychological capabilities. There's clearly a whole series of elements here that are also important to behavior as well. And the thing that is often forgotten about is this opportunity part. And I think. This opportunity part, and I think we heard some really nice talks earlier today about how opportunity and context becomes really, really important in being able to sort of look through the lens of what's going on here. What's nice about the COMB is it's connected to a whole series of other models that lead to intervention. So on the left, you have the COMB. The COMB leads to this thing, which is called the behavior change wheel, that starts to sort of identify what we would intervene upon and how we might. What we would intervene upon and how we might intervene upon it. And this is just a study that's sort of taken that to a practical basis. And what you can see is that you can actually build out, once you understand elements for the behavior from the perspective of the COMB, you can start building intervention levels around the patient, the provider, and the system. So you can really start to spin this out. So that's the background. That's the lens. So that's the background. That's the lens with which we look at virtually everything in our lab, in our research group. I don't need to belabor the point that the behavioral preventative measures were important in COVID, and this is old, old data, but it's been replicated many, many times. We were very fortunate. I co-lead the MBMC with Kim Lavois, who's a clinical psychologist at UK. Psychologist at UCAM. And Kim, at the very beginning of the pandemic, was like, hey, we should do something. We know about behavior. This is a behavioral issue. So we started this thing called the eye care study, where we've really sort of been interested in sort of the driver as to why people do the things and don't do the things related to the pandemic. When we set this up, we started with just sort of this global convenience sample, and I'll show you some of the numbers and how. Sample, and I'll show you some of the numbers and how that looks later on. We then built on representative sampling and Canadian longitudinal study component to it as well. It started in March 2020. We're up to about 170,000 responses across all data waves still going. And also to say as well, this is connected to, you know, we capture Google mobility data and the Oxford index, et cetera. So there's some nice ways of connecting all of that. Nice ways of connecting all of that. This is sort of everything that it looks like. We're up to, we've launched survey 26. So we've done 26 rounds of this up to this point in time. And this is sort of a breakdown in the Canadian longitudinal sample. There's about 900 people or so with at least three measures. And the And the convenience sample comes from about there's data in there from about 150 countries, I think. We've got some data. Obviously, some have very small amounts and some have very large amounts. But that was very much at the early phases of the, up to 2022. And this is sort of what it looks like. And they're the countries that are participating in the repeated representative sampling data. Sampling data. Okay, what was important is when we built ICARE, we actually mapped it to the COMB. So a lot of the measures actually were there because we knew that they would be important in defining whether people undertook behaviors or not. And so this is a mixed mash of things that are in there, but there's lots of data in there. And of course, trying to analyze. Course, trying to analyze this gets very challenging. So, our approach has generally been to break this up a little bit and try and understand it from a macro perspective, taking micro data, which is not optimal, but that's what we've done. And what I'm going to show you is just a few examples of how we've taken the data in eye care, pushed it through the lens of the COMB to really try and understand what should we be doing differently. And one of our favorite. And one of our favorite ones is vaccine hesitancy, because vaccines are so critical to all of this. And there is a distinction that we draw between vaccine resistance and vaccine hesitancy, which I can get into a little bit later, but effectively, resistant people are just never in a million years going to get the vaccine. And that accounts for 5% to 10% of the population. So it's very consistent with the data around most behaviors. Most behaviors. So, I'm going to build this piece by piece and then sort of pull it all together into the COMB. And so, this is just data looking. This is Canadian data from the representative sample, various different at certain time points. This was, I forget which time point, it's terrible, but really just asking the question around sort of concerns and importance. And if you were, there's just an odds ratio of whether you were hesitant or not. Or not. And generally, people that were hesitant perceived, this is not surprising, they had a low perception of importance, they had low health concerns, and they had high financial concerns. We asked questions around why get vaccinated. So just interestingly compare and contrast those that did and those that didn't, or those that are hesitant. This is consistent with most of the data we've seen subsequently: those that got vaccinated, you're doing it for Those that got vaccinated, you're doing it for very, very altruistic reasons. I protect others, doing my part. In contrast, for the hesitant people, why would you, what would convince you to get vaccinated? This is really about them. This is about side effects. This is about effectiveness and being more confident that there are no problems and that this is actually going to work. And then finally, stitching in a little bit of the And then finally, stitching in a little bit of the issues around trust, asking people, and what's nice here is you've got all full spectrum: those that got vaccinated, those that hesitant, those resistant, who should deliver. Sorry, who do you trust around issues of vaccination? And this is just representing those that identify to a great extent or somewhat trusting people. A few things I'll pull out very briefly. Number one, national and regional leaders were not the people to be the spokesperson. People to be the spokesperson, people around vaccination. And if you look at those resistant people, this is almost sort of a toxic thing for them. But what we do see is their personal doctor. There's a little bit more hope there, but actually really interesting around friends and family. So that social norm element, but also people that are very, very close to them. So let's, if we take all of those pieces of information and map that onto the Pieces of information and map that onto the COMB, what does that kind of tell us? So, what do we know about capability? We need to provide accessible information on side effects of vaccines, consideration around childcare for vaccination. So that was something that came up that I didn't really emphasize. Motivation, identifying non-health reasons for why getting vaccinated is important. Health was not clearly a huge drive. Clearly, a huge driver. Use positive friends and family social norms and then opportunities, ensuring that getting vaccinated doesn't impact income. Targeting information and delivery through local clinics had to be a very local solution. So now with that kind of information, you could start thinking about, well, how do we shift our interventional perspectives if you were to get more people up taking, get great uptaking vaccines and start building out the intervention. And start building out the intervention components that are testable. So I'm just presenting a very, very simple, straightforward, take small bits of information, measure, do some relatively straightforward analyses and package it all together to try and understand a particular behavior. What we then started to think about is, well, we've got this very nice big data set, lots of complexity to it. What if we could start mapping this out? And so I'm posing a problem here, and I don't have an answer. Posing a problem here, and I don't have an answer. So, one of our doctoral students is very interested in the idea of looking at the relationship between trust and behaviors and how that might be mediated or moderated by individuals' acceptability of policies, but also the perceived importance of measures. And how does that change over time? Because we know that these things are pretty labile and have moved through the pandemic, and so we so. And so we, so she mapped out this sort of theoretical, almost like a DAG kind of scenario, thinking about what this might look like. And then we sat there, we sort of went, well, how the hell do we analyze that? We have no idea. And the reason is, is that this raises a series of challenges. So if I just think of this particular data, this is all Canadian data we're interested in. We picked three time points that really reflected the beginning of the pandemic. Time points that really reflected the beginning of the pandemic, the mid-peak of the pandemic, and then when all the measures were removed, that's of all of those data sets, which tried to pick some extremes, right? And so those timings create proxies of the pandemic, both in terms of measures that were in place and the amount of infections and so on. However, it's Canadian data, and one of the things about Canada is policies weren't consistent. Is policies weren't consistent. Different provinces had different policies, different provinces had different infection rates, and so on. So, then, how do you work that into this kind of model given we're trying to get this sort of higher level perspective, but those things are important covariates. The other thing, this is a representative sampling. So, just to say, we used Leger, and this is not repeated measures, this is just repeat representative sampling. Representative sampling. So it's not the same people that necessarily answer this. It's a fully anonymized survey process that we have, with the exception of the longitudinal study. And so this is not a repeated measure. So this then creates a whole series of issues, right? So you're getting these snapshot representative samples, but you can't connect individuals across them. The other thing is we. The other thing is, we have multiple prevention measures. You know, I think there's five or six that we've actually measured, but you know, mass square and physical distances, self-isolation are three of the bigger ones. And then how do you account for the overlapping kind of covariance that you start to see across those? And then something that's really sent us for a loop is our measure of acceptability. Effectively, when we asked people about how they felt the government measured, They felt governments, the government measures were. Were they too lenient about right or too strict? You see that there's a pretty reasonable spread across this. Most people are saying about right. But these are not, they are distinctly different from each other. So now not only, so we don't have continuous, it's not a continuous measure, there's sort of multiple levels within that particular mediator or moderator, depending. And then our measure of adherence. And then our measure of adherence to the measures is also on a four-point scale. So that's, you know, not always that straightforward. We could think of it as continuous, more being better than less, but these aren't equidistant necessarily. So in summary, this was a bit of a whirlwind. ICARE, we have a large volume of data covering a wide range of constructs. Range of constructs. We have challenges outside of the longitudinal cohort study, which are a little bit easier to conceptualize. The rest of the data, which is the largest part of the data, we really have these issues about it not being connected. And so if we want to model change over time, that becomes a little bit more tricky. We have a whole bunch of other data sets. So if mostly disease-based. If mostly disease-based, but they are all longitudinal data sets. So they're a little bit more interesting potentially to do some more complex modeling things with. And then my final point is really making sure that if we do this work, that we really think about using good behavioral science frameworks and theories, because that actually can provide some structure and meaning to the data. And I'm all for. And I'm all for a lot of the unstructured data analysis components. I think we have a lot to learn in terms of how things stick together. But we can then try and translate that back to the things that we do understand about theory and start putting it through that lens. And the reason why this becomes important is because you can move from data to then actionable areas that can then lead to the potential to develop. You know, the potential to develop interventions that actually will probably target specific, hopefully, if they're tailored, target specific populations and sub-populations and actually be able to have impact. But of course, the other thing is that this is a huge amount of complexity. So sometimes bearing it down to trying to keep relatively simple models is good, but then layers within that are going to be important. To be important for some of the subtle elements. So, thinking about that entire continuum. And with that, I just want to thank all the people that have worked on this particular study, the eye care investigators, all the universities involved, the staff. And then if you want more information, the website's wwicarestudy.com and that's the contact for the study. Thank you. Thank you, Pony Scrifton. Any questions?