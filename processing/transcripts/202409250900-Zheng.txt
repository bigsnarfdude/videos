Might be with a regular irregular tree and then it branches regularly. And then you can consider automorphisms of the signatures tree preserving the root. And then you have this risk recursion that describes what what a tree automorphism does when they go down the tree. When you go down the tree, the canonical object. So you have the symmetric group on the Z vertices of the first level, and then of course with fortune on the sub-trees high first level. So here you have example versus this in the first level. So I'm going to call this the So I'm going to call this the level 1 and the level 2 and so on, so just the level single 2. So you can write this as a permutation risk product if you want. That identifier ones where you have your first level and computation after that. You can certainly iterate this, and then you would. And then you would get a nice morphism between rooted three automorphisms having the very end. And then you will product with this automorphism of the top of the tree. The notes are with the end here, just to say you top the tree. You chop the tree, you start at the level n, so it's five at tree. So, this is what we call canonical risk recursion. It just describes you how a tree automatism works. And then, with this, you can set up some notations. So, for any element here, under this recursion, you can read off what it does on this substance. These subjects, you need to write them as these are called sections. And then you also have a finite computation, which at the top and then the treat, the suggested valuation, it's just good to identify them. Okay, so now if you have, say, some abstract mode for gamma. Say that gamma of sound similar action group gamma is just a homomorphism. So you send gamma to this written tree altomorphism. Tree isomorphism. And then you want the sections to live in the image as well. So let's call this homomorphism alpha. And then you want all these sections. So you read all the section and you want it to be the image of your first level. To level as hot. As basically says us of ready across the finished entrances for U, G and A of the X. So it just says that you do you you look at this homomorphism, you see an image acting on this diluted tree, and then you do the recursion, and then in the sections you do what this In the sections, you do not see new elements. They all live in the original image. So I identified TX with the T0 because they are all regular T0. I'm just going to move down. That's okay? Finding notation. Okay, so and then if the kernel is trivial, then we say this is a case for some similar action. So maybe it's anyway, sorry. So, this might sound a bit strange, but here maybe it's a good mention from the results of Nisha and Polish. It talks about analysis, what the kind of similar action analysis can do. For example, functional knowledge. So he considered a gamma lattice, irreducible lattice in key sets here, so this is all out of very good groups. The following argument, the first step that's our Kamba makes a faithful self-selement on a regular motility tree. You can also insist that which is the transitive on the first level, it's too much to ask it to be transitive on every level. We say the first level, and the second, it's equivalent to being arithmetic. So the proof of the theorem uses McCulli's arithmeticity theorem and we use commuter ratios to do this. So it somehow shows you that this type of action we are not too exotic, that arithmetic lattices you can find are principal of self-similar action spots. Actions about. But I want to focus on the amenable side. So we don't want to consider this type of self-similar action. So we're going to impose some conditions so that the action is not too complicated and then we can see in some good situations that the acting group is amendable. So that's where we're going. We're going to consider a low-complexity situation. So the condition we're going to impose is called contracting. We're going to use bisections. Yeah, it's a it's a fit into this level. So how is it algas it? So how is it audience that on the tree in that way? I mean obviously that's it. Yeah you use the you take some virtual endomorphism, you build a tree actually. It's not a very difficult but you can commercial tree. So whenever you have commercial endomorphism. Yeah, something like that. So it's not a very complicated thing. So so we're going to consider our contracting actions. So Actions. So let's say gamma we are already inside the tree of physics. And then we say it's a similar so it's like a self-contraction that is already uh embedded in the rooted tree. We say that uh gamma is contracting. Is contracting if there will exist a finite set, sometimes called the loopless, inside the group, such that for any group element if you go deep enough, Finite such that your section, the section in this sense, is in n for all x with level deeper than this. This is what's called contracting. It basically says that given any group elements, if you go down the tree far enough, then they Tree fi enough, and then they simplify, the sections simplify to some given finite action. It's not very obvious how you use this definition, but we'll see that it allows you to consider a lot of metric aspects. So that will explain a bit more later. So maybe give some examples. Can you hear already saved the main problem? Been around for a long time. So I contracted this on the door. We have the three alternative reasons that satisfy this kind of finance condition and can you decide whether such a rigid gamma is amendable or not. It turns out to be quite difficult, but it's good to say here that it's known. So the free group are two generators to modernize. Generators do not embed two such groups. So they at least do not contain three groups and two generators. And so we're going to consider situations where somehow your limit set or some structure allows you to understand gamma is not too complicated and from there we can deduce these examples are available. But in general, Are amenable, but in general, it's open just with this assumption. Can you tell whether they are amenable or not? Okay, so some examples. The easiest example is the biking program. And then there is a nice self-similar action binary tree. It is the retail binary tree. So you take the binary tree. Then you let A act by commuting the two subtrees commutation. And then B acts by, so on the two branches on the left branch you do A, so you commute the subtree hanging by this process. And then you continue this B on the right branch. B on the right branch. So, this is like a recursive definition, and then you keep on branching this and define what A does. So, and this is contracting because you can do a small exercise, say ABAB, and then you do the recursion once. You will see it becomes an AB. And then basically, you reduce the length 4 to length 2 intersections. So, from this, you can immediately see a section with. And so the main source of contracting self-stimular groups come from iterated monodromy groups. Any questions about the definitions?  So we stay state in a classical setting. So let's take some rational function. And think of it as the map around the rigid sphere to the south. So this is kind of homo dynamics. And then there you can talk about the critical points of this map. There are the places where your derivative vanishes. And then the forward image of the critical point. Forward image of the critical points are called post-critical points. So let's assume the instrument PF. I'm not going to say much, go into details about these dimensions, but just to illustrate how we construct these boots. So these are the first critical weights for an image of critical points. Then to get a contracting example, we assume this set is finite. This set is finite. Otherwise, you won't get a finite case. And then you can remove this set from, so let's write N. You take the Riemann sphere and then you remove the critical heat. So you think of F as a mapping from N to F. It's just a coordinating balance. And then you can take a point from this space and then look at this tree of pre-images. It's a point. So these are the two pre-images. Degree D, you will see D pre-images. Those here I pretend it's degree two. These are the pre-images. So you keep some, uh you keep some So you keep on pulling back to get this tree. It's going to be our root entity. The root is the reference points that you will start with. And then you can consider the fundamental group of N acting on this tree by depth transformations or the Jomi action. So this fundamental group acts on this tree. On the stream by hydrony or diet transformation. You take a little loop around, starting from T, you take a loop based at T, a loop around a post-critical point, and then you open the loop, you can trace it with the pre-images. That's the standard deck transformation the fundamental loop does. And then you mold out. You go down to the kernel of this action, you get to the iterating to monitor. So that's the action. So it will be the model that defines as this fundamental model, and then we mode out a kernel of this. Of this monopoly action. This is the main source of contracting self-similar groups. You can see it's self-similar because you're kind of iterating the same map. So what you do, retrieve. And um yeah, and it's a contracting because we assume that this PF is finite, so then we have a finite. Finite, so that we have no finite. So, associated with this, there is an important object associated with anything called the matrix set. This is the closure of uh Is the closure of repelling points of this map? So that's where the dynamic is expanding. So one of the pictures that you see, like a gasket, like a self-similar frackle or a carpet, they can be produced essentially a set of some measurement function. So these are nice frackle pictures you see. The alternatives are such. The alternate associated section should be assessed. And then, so we can. So, one thing we want to understand is how to relate the dynamics of perception with the subsimilar group. So, you know, imagine that your Julia set looks not so complicated. Can you deduce from the geometry or some other information of it something to say about that's the flavor of the thing? That's the flavor of the things we want to. So maybe, yeah, so next to explain what we consider here. So the vague point, or consider this very vague idea, is that when the underlying dynamic is not too complicated. So we want to consider situations that are easy. Then the associated group should be not so complicated, but you want to measure it in some ways. For instance, uh have have uh say sub is natural say sub is natural lingos actually quite a stretch to go but uh or trivial person and so on so this is the direction we want to go like to show that things are not so complicated that it makes any sense but i'll illustrate this uh But I'll illustrate this with more precise statements. So here we can observe the underlying dynamics from the Schwarz graphs of your action. So by Schwar graphs, I mean, for instance, in this tree action, you can take a point here and then this enter the rule, and it's going to move on this level. So you can draw the corresponding Shua graph. If I want. Fine light. Here it's convenient to go to the boundary. Let's say that your gamma is finitely generated. So this is finitely generated set. And then with And then let's say that it acts somewhere. So you can take, then you can draw the share graph on the right. So what you do is that you take the vertex set to be just the orbit and then the edges are. The edges are, so I'm writing things on the left, so X with some generator, and I insist that these are involved. So section A Hole is oriented. These are like oriented labeled graphs, not just geometric graphs. So I want to consult, you can make this slightly more precise. So saying that the underlying dynamic is more complicated, you can impose some conditions on complexity of these share graphs. So we need to assume something very strong, but it's uh true for many examples that uh people have studied. That people have studied the state slightly more presently, so here we have this finitely generated group. And for convenience, I'm going to assume S actually consists my generators are actually ordered two elements. I don't see why, but it's actually not such a good problem. Maybe I shouldn't assume it now. So let's say that we act on x points. Think of the tree boundary, and you act by homophysis. And then let's assume two things. Assume two things. No action. So first I pick some good point X. And then I just assume that the slow graph has the polymer clause to contact X nodes and polynomial clothes. For instance, like the Migotsu groups, the share graphs are just lines, so they have linear growth. This is quite typical. And then I also assume that as labeled graphs, they're linearly repetitive. So this graph is also linearly repetitive. It means that if It means that if I give you some neighborhood, let's say that you have some point Y in your immature graph and you can look at the ball of Rhyme's R around it. Again, you can find it being repeated in adding. In R distance. So anything you can find in linear distance, you can find I would like to copy within a distance to see up of any other text or a reference text. This is a symbolic dynamics with Asymbolic dynamics, this is like the strongest complexity. Now, with this, so why do we consider this? The point is that if you, so suppose say I want to consider volume growth or mock entropy on the group, with this type of assumption you can effectively reduce the consideration to triagraphs. And triographs are something that you can draw and understand but Draw and the sense, but the group itself is quite complicated. So, here we say, So this allows you to reduce problems to post your content, please give me the second. So, it's for any R, for any R, if I look at the ball, for any wine for any R, there'll be something. For any R. There'll be some constant CR. C in some fixed constants. But it depends on R. No, it doesn't depend on R. But why do I subscribe R? It's a linear. C times R also. So within linear distance, you can always find the occurrence again. And C does not depend on Y, right? So the quantifiers there is not just the same. Such that for any and any amount and then so for this all you can find. Okay. So the point of this is that it reduces counting the counting the from the global cabin to at least in the upper bounded direction to uh to kind of some what we call a poor trade counting on a shwer glass so if i portrait so in the context of tree automorphisms Tree out of physics. An example of what people usually mean by a portrait of a tree out of physics is like if you say take some element in gamma that already sitting behind the tree. And then you want to find this sub-tree. So you do the, let's assume it's a retracting, so when you go down the tree, you will see eventually the sections will be in the necklace. The sections will be in the necklace, and then I stop drawing when you see the section already. So you will find this sub-tree like maybe it looks like this. And then there is a sub-tree when you decorate this with the finite representations. And then draw some sections along the leaves. Say here in the A or B or whatever. So this kind of a picture are called portrait or portrait. Are called portrait of tree optimism. But if you think about it, what it tells you, if you want to describe those on the canter set, that sub-tree basically gives you a partition of the tree boundary, and then the cylinder corresponding to this vertex to have a cylinder center here. And all of any end here will see the Any end here will see the same permutation like you just go to see the A and so. So it effectively gives you a partition of the counter set such that inside each cylinder you see the same moves. So you can generalize this to a slightly more general situation where you don't have a tree, but you have a nice action on the cantoset. So a portrait you can define. So a portrait you can define in a photo manner. So let's say that you have a word in the jockeyers. And then you can give me any point in X. So I can first see how far this word gives. I wrote things on the left like this. Things on the left and writing this way. So you first test this word on this vertex, and you first want to see how far it can go, so it's right the radius to be the furthest you go. It's this uh I think here we can go down. And then here you go down, okay? So this is the neighborhood you need to see how this uh word moves the element. And then uh you can just uh draw this uh take this neighborhood this is in the Schreier graph and then you mark it with the beginning and the end So this tells me what neighborhood this world sees around this vertex, how far I am to go to determine where it ends up with, and then the point itself at its image. So this you think of it as like a labeled graph marked with the two points. And then you collect all these pictures. Collect all these pictures up to rap and morphism of a biomedical plan. Hope it's a finite thing, and um so this we call the portrait of Daniel. So it actually does the same thing as the sub-tree picture we have drawn, just in a different way of saying things. So this tells you, this effectively tells you if you give me this word, I would know how it acts on the set X just by comparing local neighborhoods. If I have a point, say another point in X, then I look at the local neighborhood in the triagraph. In the triograph, I will see some pictures. I look at the portraits, there will be one picture that's isomorphic to my own neighborhood, and then I would know exactly where to find my image. So, this describes the action in some slightly strange way. But the point is that if you know, and there is a low complexity assumption, if you count how many portraits, so like the size of this set for a word, say A word say up to a certain length, then you can bound volume growth and bound more control here if you want. So let's write it down. So I'm going to keep this assumption. So I'm going to erase this. After this I'll state two situations where you can actually make use of this. So it's a fairly simple-minded counting. So they are here and should say, given a group element, so let's write, divide the size of portrait to be, say, the smallest portrait you can find. So size. So size, by size, I mean how many pictures you have here up to the size of a physical. And then where this is a word represents defined as the size of the portrait. And then you can just by simple magnetic counting, you can see the numbers. So this is the size of the ball of the portrait. This is the size of the wall of the office and in the group. This can be bounded from above by some, so I assumed the graphs are polynomial growth, so this is the distribution of polynomial growth in the assumption, also assumed to be nearly repetitive. And then here you can put in the worst case is it the worst business? World business of the listening is also complete. Here, the implies that the degree of the growth doesn't depend on the vertex, that's something like that. Yes, but yeah, you can base, that's right. So, if you assume a polynomial growth, you pick some base points and then look at the neighborhood, like the radius n ball around it, you assume it's n. You assume it's N2 with the N and it's a really repetitive everything is within somehow. So the thing here is that the point of this growth estimate is that if you can show that this maximal size of portraits that you see up to this n, say is n to some power alpha less than one, then you get some exponential growth. And that's actually a mechanism for most examples we know. For most examples we know, for sub-exponential intermediate growth groups, actually your core trade doesn't grow too fast in the reason why you have small growth. And similarly, if you have say random walk entropy, the same mu is a random walk measure on step distribution on the map such that let's assume it's Such that let's assume it's let's say it's just finitely supported to avoid problems. Then you can consider the Schennel entropy of its convolution powers, which is the Schennel entropy. Then by the same company, you can see that it's bounded from above by Bounded from above by log n. And then you consider average. So here you consider the worst case possible. And then for random work entropy, you consider the average growth along the random walk. So here I just give some name. If Wn is the random walk, it has distribution, this convolution power. So if you can see that this poultry growth, like along the random walk, the typical growth is stabilized, maybe slower than any of the log n, then you get that person boundary. So these are like crude ways to bound the complexity by looking at how complicated your element gets. And then the worst case possible will be if you see this. If you if you see this a very strong contraction, then you have some exponential growth. Often it's difficult to understand, but along the random walks you can use some basic estimates to fast and so on. So yeah, so these are some basic estimates for this. I'll maybe be in the remaining ten minutes. In the remaining 10 minutes, I'll show you some examples where some classes where these considerations can be implemented. Let's say the reference. So, if you care if you consider this expected complexity growth. So, here the key thing is that you The key thing is that you want to have your shore graph has a special structure, and then the size of the portrait can be bounded by the number of traverses that you make between different regions. And then there you can use some walk estimates to bound the number of traverses that the walk can make. And often these come in the form of effective resistance. So if you know in your So, if you know in your graphs, so with the example is not here. That's just the last segment. And imagine that you have to traverse between the two endpoints to pick up the complicated sections. Then you see a significant slowdown effect because it takes you just a square amount of time to travel between distance n. So, this is uh something that you can uh capture using. That you can capture using effective resistance. And for iterated mono-drumming groups, we have this nice way to state. It's a state statement with the zero. It's a joint work with more multiple form. So selected G and the And we are standing similar to what you do finitely generated. Then if you have associated with G, there is the limit set. In the case of iterated model drawing coming from some F, it's the Shi Liniset of this map. And it also comes with this. It also comes with some visual distance. So in front of the set. Not going to define it, but you can imagine it with some rat hole like three. And the come with it is also a distance that it comes with the contraction. It's basic a constraint. Basically you realize that as some boundary or some Boundary of some hyperbolic graph, so it comes with a visual metric. So this comes with a construction. And then the assumption is that suppose we need this model dimension of this third is strictly less than two and And simple random mode mg as the trivial customer G. Or equivalently, this grand work entropy grows sublimate. And as a consequence, it follows P is unfortunate in this case. In this case. So, here this conformal dimension, it is the infimo of stove dimension of all metrics that are quasi-symmetric to European metric. With the boundary of the hypergraph, the visual metrics come as a quasi-symmetric family, with more like a unique choice. So you consider all the all metrics that are quasi-symmetric to the one type 2 of 10. To the one that you obtain from the construction, I take the integrable of the dimension. Usually it's not a tenth, but a certain thing. And so this dimension strictly less than two assumption gives you effective resistance estimates and allows you to run this type of argument, which you want to say that the walk angle corresponding share graphs do not move too fast and you'll be able to uh have some complexity estimates. Have some complexity estimates. And a nice corollary of this. So this formulation is nice because there are a large supply of examples with a formal dimension strictly as an 2. So if f is a rational function, say TCF was critically finite. Post-critically finite. So this post-critical point, use the P for most portraits. It's finite. So post-critical point is finite. And the Julia set is not the cold sphere. So in this case, classical conformal dynamics tells you that the conformal dimension of the The conformal dimension of the ADSET is strictly non-stand two. Again, it's uh ING use available, it actually revealed. So previously known examples, there are quite a lot of them. They all have uh dimension one. So when this uh series about it, we can uh go from dimension one up to two, but the critical case where dimension is exactly two is Where they mentioned this exactly to exactly where the method breaks down. This is too crude to treat. So this is one class of examples where this method is useful and it's hard to show among the it's not known how to see these groups are among the broad with other methods. Somehow this will provoke complexity completely. And uh so it's finished with uh a volume counting uh statement. It takes a bit of more to explain. So you introduce these portraits in this manner to illustrate that you don't have to have a tree to do this counting. And you can uh have more general form of self-similarity. If you give up on the tree, If you give up on the tree, you can see some similarity in the recursive construction of your trail graphs. So, if there is some kind of a symbolic substitution system that allows you to build your trail graphs by geometric pieces, then you can consider that as the kind of self-similarity building. And this is true for this class of simple groups that Michael Schembridge constructed that have intermediate. Uh, intermediate volume growth. So this is the state of the zero. And if you want to know more details, you can ask me the direct. So there was a breakthrough of changes a few years ago. There are stick-for growth of intermediate growth. Then with this portrait counting we can give some bound on the volume growth but we do not know sharp estimate. So it's a bit uh complicated to say, but let me Complicated to say, but let me I'm not saying it in correct form, but roughly sense the following. So you have some suppose you have some group gamma generated by evolutions, and I have been involutions. So for some reason in these intermediate gross groups, often your groups are generated by evolutions. So they act on some kind of set X. So, and then the key assumption here is that you have some point where, so you consider the stabilizer of this point, and then you mod out the open stabilizer. So, this means the group element that is fixed point-wise on a small neighborhood of the point. So, these are sometimes called the So these are sometimes called the isotropic group of germs. So this is the finite trivial. These germs are very important. So we assume that this is the first function. And then you also assume that for an element in here, the fixed points We accumulate this first assumption. And then the second assumption is that so the share graphs are line segments. So either the like z or like like Z or like halfway and linear negative. So actually a Rigochu Ku group will fit into this data. And then under these assumptions you can effectively control the portrait. is that there is constant alpha strictly less than one such that the worst case sorry finish the sentence so the size of the portrait grows less than this alpha and the volume grows And the volume looks like a fountain device. So with this information, we can use some methods to count the rate of portraits and obtain our own estimates. So here is the rather than the colour. Assumptions they apply to all these groups, all the examples