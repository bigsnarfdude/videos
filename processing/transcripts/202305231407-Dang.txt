Defined inductively. So let me not be precise on on on on on what is inductively but the examples we have to keep in mind is the ones that come from for example iterated monotromic groups. So basically you can deduce gamma n plus 1 from gamma n Gamma n plus one from gamma n using some by breaking your graphs and replacing, adding some subgraphs into some relay. Well, just there is a recursive formula from gamma n plus 1 to gamma n. Okay? Assume you have this with a group G acting on it on each gamma. On each gamma, on each gamma. Okay? And S is a subset of generating generators, is A1, A1 minus 1, AK, AK minus 1 inside the group gene, the generating set. Okay, so regular, let's say it's regular of degree of degree D irregular. It's going to be 2k regular 2k regular 2k regular graphs. So for example, the one that oh maybe I'm wrong. Let let let me not try to draw the the graph. The graph. Okay. And so we have these graphs, and let's say let me denote by, so R Dn, the vector space spanned by the canonical basis with canonical basis. E V, where V inside E M. Okay? And we will denote by AIM the matrices. So let me write them endomorphism of R V M where we decrete that A I N of AI N of E V is E A I applied to V. So what is this? So for each vertex V in V N, we have an action on the vertex and we map it accordingly to A i maps a vertex to another vertex W and you map the canonical basis like this. And the joint spectrum we are interested in. The joint spectrum we are interested in, as Grigor Schuf mentioned, so let me write Mn of mu lambda is sum of mu i A i plus A i inverse, so there is an N from I equals From I equal 1 to K minus lambda identity. I'm sorry, can you read it again? It's difficult to read. So it's mu i and then A i n okay this is index, I don't know. Yeah, so i yes, let me rewrite very big. Some new i A i N. n plus so ai inverse is one of the generators and I put parenthesis n because it's the action on the on the nth level of our entries okay minus lambda identity okay so what is this Mn is just a Vn times Vn A Vn times Vn matrix. Okay? And the joint spectrum is. So this is roughly, the mu i's are weights, and this is roughly, and this is roughly on the Markov matrix with weights. Yes, yes, yes. Okay, you give the word weights. If you say weights, you think of weights as real numbers because we are jumping with some probability. In my game. Well, I'm an algebra, so for me, they're just algebraically independent elements. Weights are going to be complex numbers. So let us be a little bit crazy. I mean, patients, we have their algebraic independence parameter space. Exactly. So the determinant, so we all learn, the determinant of nn of mu lambda is a polynomial in Polynomial in let's say C crochet mu one mu k and then lambda. Okay? And it's of degree it's of degree what? Of degree of degree the size of V n in lambda right so that is a point. So that is a polynomial, and what we are interested in is the joint spectrum. So I'm sorry for changing the notation in between the talks. Mn is the set of points mu and lambda, mu lambda in C k plus one such that Uh such that uh Mn of mu lambda is not invertible. Okay? And uh we have to mode out by d star so this is just the determinant of polynomial exactly and uh so it's an algebraic it's uh the zero locus of an algebraic because uh of an algebraic Because of an algebraic variety, because it's defined by a polynomial equation. Okay? Cool. So what is the general problem? In my talk, okay, we have this sequence of graphs that gets more and more complicated. and more complicated describe the asymptotic describe the asymptotic behavior of this sequence of subset of Mn as n tends to infinity. Accumulation points in house perfect sense? Yeah. Good question. I need to give meaning to this. What is this? In fact, we will see that this is, in certain cases, this is an increasing sequence of subsets. But maybe it increases. It always has a limit because projective space is compact and how star topology is compact. Yeah, but I want also more geometry. It's how some geometry is hidden inside it. So I will add, yeah, but I will that's the purpose of this mini course is give what does it mean to have a sequence of to say what is the asymptotic behavior of such sequences. Is there an inclusion map from the beforehand to the people end? Yes, yes. That's what I said that in certain cases I don't know in In certain cases, I don't know in every cases, but in certain cases where we have examples, it's increasing. Thank you. Right now, the graph is not related to the group. So when you say like uh your edges are the right graph edges or the callbacks on it and I mean And I mean in my cases there are going to be shire graphs, but I wanted to not define find uh shire graphs and just go there. They're like the matrix the matrix does not see the edges as well. The matrix. The matrices that you construct and the ratio that you're looking at, they do not see the edges as well. Yes, they do. So I am missing the connection between the m ends and the ends, or the gamma ends. I don't understand the connection. understand the connection. Okay, if gamma n is Kele graph and the Kele graph are labeled just the connection, the abstract connection. So this MN is some operator acting on L2 of the vertices of our graph. And so we have a And so we have, and we are interested in some kind of, and we have an operator that acts on L2 of Vm, if you want. And we are asking what is the spectrum of those operators, where those operators are. Is the map supported V and nowhere else? Yes. And then the extension would be the RAS. In the case where I have, let's say, the graph of example, if gamma n, if gamma n is a Kele graph, Kele graph of a certain group with some generator S and And then what you are doing is, let's say, let me draw a random graph like this. Okay, and then let's say, okay, let's say this is A and this is A inverse. A inverse. Okay, let's say this is your group, this is your Kele graph, and then what we are doing is like we are calculating here the adjustment. Here, the adjacency matrix of our graph. Okay? So with weights, with weights. Yeah. Last question. So when you say g acts on each gamma n, does that mean that the elements produce actual graph automorphisms? Or so that's where the edges come in. Yeah, I think the K is the same as the K the 2K recognition. Yes, it's the same as that number or generator. Somehow it's a homogeneous problem. Okay, so and of course this is like like in like in Roland's talk, he was taking some diamond lattices, okay, and then looking at some specific polynomials of those diamond lattices. Lattices. And here the spirit is the same, except that we are not looking at some partition function, but at some Markov operators. But the characteristic polynomial stays polynomial. Now, in certain situations, you're very fortunate. And how fortunate is this? Is that sometimes, so when gamma n When gamma n is the Schreyer graph of so Krigorchu group of Lamblin Hanoi and basilica and rabbit. And rabbit. Well, if you don't know those groups, there is some groups where there is a, you have a recursion formula for those characteristic polynomials. So let us call this chi n chi n you have a recursion formula that is of the form chi n plus one of mu lambda. one of mu lambda equals some polynomial p0 of mu lambda at some power d to the power l times chi m of f of mu lambda. So in those one, two, three, four, five, five cases, you have an inductive relation between the characteristic polynomial of the next level graph with respect to the characteristic polynomial of the previous level. Yes, that is d. At D, some number, so two. Some number, so two, three. It's going to be the growth of the size of the vertices. So Vn usually grows like d to the power of n, and that's the d. Okay? It's the degree of the graph that I have. Sorry? It's the degree of the graph that I have. Yes. And what is F? And F is what you call the renormalization. So someone asks what is R, what is R. Someone asks what is R, what is R. So this F is R. So F is going to be, and this is where rational maps come to play. It's a map from CK plus 1 to CK plus 1 defined by, well, mu lambda gives P1 over Q P one over Q1 of new lambda PK plus one over QK plus one over new lambda where pk, qk are polynomials. So that is the factor front, this essentially clears the denominator. factor in front of this this essentially clears the denominators so you get a polynomial sorry so so this factor of p naught or rho naught v lamb to the d to some power that that that takes care of the denominators you're going to be yeah exactly so just yeah very uh so you anticipate the host yeah yeah yeah so you get that that's the crazy part is you have a polynomial on this side and so here when you when you when you look at this formula you create denominator This formula, you create denominators. But so this formula tells you: no, no, there should not be any poles in this. The poles are all, actually in CK plus 1, the poles are all at infinity. So all the denominators that come from here, they have to be killed by this factor. Okay? Okay, so where? So where? I continue here. Where PI? Pi, Qi are polynomials numbers in mu i lambda, mu1, mu k, and lambda. Okay? And this is called a map like this. It's called the rational map because it's some bunch of rational functions that you have put in a mu and long. Put in mu and lambda. And so if you look at, if you believe in this, then you see that the joint spectrum can be described geometrically as what? So now the joint spectrum of Ln is, well, is the zero locus of this polynomial, okay? But so it's chi n equals zero. zero of m n plus one is chi n plus one square zero and and and but if I want to see this goal here describe the isymptotic behavior of the joint spectrum this formula star tells me that I only need star implies that I need to understand I need to understand to study the pre-images of what? Of p0 equals zero and and and chi zero equals zero uh by f By F. By F. So is the recursion somewhere that's the original recursion? Yes, it is one of the graphs. Yes, yes, yes. Somehow, I mean, it's kind of a miracle, but if so, in those examples, people have worked out that there is the recursion on those graphs. Recursion on those graphs induces a recursion on the characteristic polynomial. And so for this, it's Bartol D and Grigor Chuk, Gricorchuk and Zuk, Gricor Chuk and Sunik, and Gricor Chuk and Zuk. And I don't know about this one. I forgot. At the first step you only see p0 equals zero and then the pre-image of chi n equals zero by f. But at the next at the next iteration, you're going to have to plug in f inside p zero. So F inside P0. So, really, you need to study those privileges. But if you find this and then you compile into the formula, you can understand the asymptotic behavior of this. And so, my mini course is split into two now. So, first, we have to understand how bad this subset gets. Of course, they are going to get bigger and bigger. Of course, they are going to get bigger and bigger and which sense? So we are going to control the volume of this subset. There is a self-similarity playing underlying it, right? Yes. But still we need to understand the limiting. So what I want. So What I want. So our goal now is a study f minus n of k0 equals 0 and f minus n of p0 equals 0. That's our good. Then plug everything inside the formula and see what happens. So step one. So step one step one to do this is the algebraic nature is a is algebraic is how big big is f minus n of say p zero equals zero okay and if we are lucky if we are And if we are lucky, if we are lucky, with a little bit of luck here, so if we are fortunate, it's going to grow like n at the power p times some delta at the power n. Okay? What do you mean by pay? I mean, it's a hypersurface, it has a degree. I mean, it's a hypersurface, it has a degree, and that essentially tells you its volume is a complex variety in terms of the n minus one dimensional. Exactly. Okay, so now I define volume. That's the value. But that's its volume as a hypersurface. Yes. Its measure is still zero. Yes, yes. Yes, yes. And the way, but we need it to, it's the same as when you have probability measures. If you have some, sorry, some measures whose mass tend to infinity. Whose mass tends to infinity, you have to renormalize the mass to get the mass one, to get a sequence of probability measures, and to hope to have some limits. And here it's not probability measures because it's some curves. So the actual formalism is current. So this would give me a sequence of currents whose volume is like infinite. We're going to divide by the good factor. And if we're lucky, the good factor is n at the power of p t. Good factor is n at the power of p times delta to the power n, and then have a limit, and then this limit is going to be the asymptotic behavior of our John spectrum. Okay? So you... Okay. So that's exactly. So how big is going to be volume and step two? Step two, but I will define everything. I will define everything. But volume is going to be something of, and this is going to be the analysis step. It's going to be that we take f minus n of p zero equals zero, divide that by this factor, so n to the power p delta n, is going to converge and Converges in an appropriate sense sense to a limiting object object that I call T and this limiting object is actually a count, okay? Actually, account. Okay? So the keyword is this. And step three, I mean that's the usual. So that's what dynamics is about, basically. And step three is now forgetting about dynamics and is re-inject into formula star. Re-inject. Re-inject into formula star to relate T to the joint spectrum as n tends to infinity. Okay? And okay, so the main dynamic The main dynamical tasks are done in step one and step two. And so today I focus on this part, and tomorrow we say we look at the other part. So any questions? Is it related to the green function or green function? Yes, yes. So the the limiting object usually Limiting object, usually we want it to be associated to f. And that one should be the grain function. We don't know, actually, it doesn't work in, we don't have a general statement. Sometimes we are able to do that. So that's why I that's the green current. And yeah. And then, yes, of course, and the support of this green current has to be related to the joint spectrum. Has to be related to the joint spectrum. Okay? So, okay, so now to do this, so I'm going to define big in terms of what is the volume of an algebraic sub-variety. But before that, we have to start to say what is a rational map, why it is more difficult to work with rational maps than holomorphic maps. Signals. So let me start with some things about passional maps. Okay, so let's so Ashen remarks. Ashena maps are difficult because they are of the following form. So you have a map from P to Pk, PK plus 1 to PK plus 1. And I put some ROs because a rational map is not a map. Okay? So we say it's a world map, but it's not a map. So is rational. Is rational. If and only if there exist u and v, some Zariski open set, such that we have an actual F restricted to U from U to V is actually, this one is a holomorphic, means a realm, this one. A real map, this one, holomorphic and given given by quotients of rational functions, by quotients of rational functions. You can wrote the quotient because you're strictly don't say okay, okay, okay. I wanted to relate to the formula that I wrote just before so that people uh remember that there. Is that people uh remember that there are those denominators that that yes okay? So basically uh um you you just forget about the denominators where everything becomes funny and look at where everything is well defined and those are the U and its image is V. So um well V contains the image of some set will be constructible. So example. So an example. Well, so if you have a F given by the following, x0 xk gives p 0 x 0 x k in homogeneous comma p k of x 0 Of x0, xk where p i, p 0, t k are homogeneous polynomials of the same degree. I'm sorry to be uh so so slow uh with no common factors. With no common factors with no common factors and of course because I want to define the degree of my math, so my polynomials have the same degree, but if I had a factor, then the degree would not be defined because I can multiply by x at the power of a million. Million, and so you have to remove all the common factors, and then you have the minimal degree, and that's the one that I talk about. So, it's going to play a very important role, even though it looks like a definition type problem. Okay, and why is this definition so troublesome? Because there are problems. Because there are problematic points. So you people alluded to this. And so let us start to see what are those problematic points. So say you have A0AK. If A0AK is in CK plus 1 and And turns out I'm very unlucky. P0, PK, P0 of A0, AK equals PK of A0AK equals 0. Then at this point, I cannot look at this map because when I plug in A0AK, I get 0, 0, 0, 0. It's not in the domain of definition. In the domain of definition, it's not in CK plus 1 star. So we have a problem here. So this point A0AK is called an indeterminate concept. This A0AK is an indeterminate term. And I denote by I of F, I have a divided by 0 By I of F, the setup of indeterminates. Okay. Ah, and uh how long do I have you have until three o'clock. Ah, okay. So so uh So, this subset of indeterminates, it's a fact that it is of codimension two. So, how does one see that it is codimension two? So, assume there's a codimension one component inside I of F. So, fact is that I of f has codimension two. Or more. Yeah, yeah, yeah, yeah. Codimension Codimension bigger thank you. Yeah, of course. If you had a, let's say we had a co-dimension one. So if I of f contains, let's say, q equals zero, where q is some polynomials. Then what does it mean? Then this means that q divides e. Then this means that Q divides each of those components. But then, if it divides each of those components, then it's a common factor. So, then you should not have written it like this. So, you could have killed it. So, that is the Q divides each Pi for I from 0 to K, and that does not happen. So, Q equals 1. So, that's the proof. Okay? Then Q divides di. So it's a simple thing, but for all i. But we, and then contradiction. Okay? And this is one problematic set of points, and another problematic set of points is the collapsing locus. So in general, F has a collapsing locus. So there are some V. So C of F is what is this? Well, collapsing is something that when you apply F decreases in dimension. So it's an algebraic sub-variety, sub-varieties, such that F of V, the dimension of F of V. The dimension of F of V is strictly smaller than the dimension of V. Okay? And both sets are problematic. The set where I of F is indeterminate is problematic. And in dynamics, this thing is going to be problematic. So this is where I define it. So some examples. Is it clear that the collection sets all the components have the same dimension? No. No, no, no. The collapsing set is you can it's contained in the locus where the Jacobian vanishes. So you take the Jacobian of those P0PK and it gives you some equations. And sometimes, oh yeah, the intersection of some collapse. Of some collapse, of some device else. Okay, sorry, I need to think. It can have different dimensions. And it can also meet me, but it can meet in a complicated way. But they typically meet in an indeterminacy locus. Can I make a small suggestion? You might want to remove the indeterminacy locus and take F of V. Ah, yes, yes, yes. F of V minus the indeterminacy locus, of course. Thank you. Thank you. Thank you, thank you. Okay, so let's let's let's have some examples okay and yeah, it would would be nice if those f were holomorphic and not have not be rational, but so far we didn't have all the examples here are rational maps. So we need that's kind of interesting because I mean you you can have a Because I mean, you can have a degree D map from projective space to projective space, which is never regular. But that you always have one which is not regular is kind of interesting. But it would help our life. You have to live in the world you live in. Yeah, well, that's why I'm in this project. It's also, I have one point. It's interesting that the maps you have are not regular maps because it's special. Because it's special for a map of a fixed degree to be not regular. I mean, usually in dynamics, it's easier to construct a rational map than a regular map. I understand, but that you find a rational map naturally is interesting. Yes. Okay, let me give you some examples and you're going to see. Like, all the natural ones that come up, they are going to become rational and not. And not like the one where I think the first, the first example that I think I just take some polynomials that should be regular, right? So you take a polynomial from CK to CK, then you try to compactify it to PK, then it becomes rational. So that's why it's kind of real. But so examples. So if you take f on x0. You take f on x0, xk. So that's the nice guy. So x0 square, xk square. You really need to force it to have something regular. Then this guy has a zero in the terminus set, empty in the terminus set, and no contracting locus either. So it's like it's like tough. So it's like it's like perfect. Okay? Little bit more complicated. So famous guy, Cremona. So you take x, y in C2 and you map it to 1 over x, 1 over y in C2. Okay? And this is a, you see that if you iterate this twice, then If you iterate this twice, then c square equals identity. Okay? But so let us write this formula in homogeneous coordinates. So it's xyz gives zy, zx, xy. Okay? And in this coordinate, you see that there is, so, oh, this is called the. So, oh, this is called the Cremona involution. So, this indeterminacy locus I of C, let me do a drawing now. So, this is the point zero. This is the point 0, 0, 1. This is the on the set y equals 0, 1, 0, 0. And this is in the x equals 0, 0, 1, 0. So this is x equals 0, y equals 0, and z equals 0. Okay? Let's call this guy T1, this one. This one is P2, this one is P3. So the opposite point, this is L1, this is L2, L3, and this is L2. Okay, so the indeterminate C set is P1, P2, P3. And here, it's a little exercise that the collapsing set. Is that the collapsing set is L1, L2, L3? Okay? And basically, interesting, what happens is like L3 is mapped by C. So C maps L3 to P3 and it maps L2 to P2 and so on. And L1 to P1. And so we expect, so I told you this is an evolution, so we expect the inverse to map P3 to L3. But turns out that this is not defined. We have to do something else to be able to recover that if I have P3, then its pre-image was L3. Okay? Another example. Example. So, this is where comes my comment. So, simplest, simplest guide to polynomial in two variables, but y plus p of x, x. So, this is from c2 to c2. You see two. Then this is also an automorphism. H is an automorphism. You see, it's polynomial in C2, so everything's perfect. But when you write it now in homogeneous coordinates, so h xyz, it's given by okay, yz at the power of d minus 1 plus z. D minus 1 plus Z D P of X over Z X Z D minus 1 and Z at the power of D. And here the indeterminacy set is going to be here. So this point is indeterminate. Okay? And the line at infinity here The line at infinity is going to map to the opposite point. But maybe did I do something wrong? Yes. I think it's backwards, but okay, thank you. So this one is indeterminate and the line at infinity maps to the opposite point. Yes. Sorry, P is arbitrary here. Sorry? P is any polynomial. P is any polynomial of degree bigger than 2. Okay, I don't want. Okay, if P is degree 1, then you get an element of PGL2, so then it becomes holomorphic. But if degree of P in X, so P is in C X with degree of P bigger or equal to 2, then you automatically get something rational. Okay? All right. All right, so I wanted to say something about resolving indeterminacies, but I think I have seven minutes to tell you what happens to step one. So I spent some time defining rational maps, but what we want to do now. Marks, but what we want to do now is taking an equation, p0 equals zero, and taking its pre-match. So it's pullback. And so so we have f from pk plus one to pk plus one. To pk plus one rational given by x0 xk to p0 pk okay and we fix a Keller form so take omega the Fubinish 2D form. Form. So it's locally sum over dzi dxi which dxi bar over 1 plus sum of xi square as a square. So that's omega. So it's a one-one form, explicit, and it calculates the spherical metric on a pk plus 1. pk plus one. And now we take the hyperplane. H is sum of a i x i equals zero. And now we put it back. So f star of h is what? It's what? It's given by the equation sum of ai pi equals zero. Okay, so you have, you just plug in f in the You just plug in F in the formula, so you get this. Okay? So what is the volume? The volume of F star H? Then, on one hand, it's an analytic formula. So it's the integral on F star H of omega at the power of D minus K minus one K plus one to k. Thank you. So this is the. But this is the a actually your projective K space and this is the K minus one. Ah ah thank you. Thank you. But that but it doesn't really matter. But that that's thank you. Well the problem is we have one more index and dimension here. Yes. Okay. So this is the analytic formula. So basically it calculates the if you are in dimension two the area of this curve. Of this curve. And that there is an algebraic way. This is also equal to f star of h view as a hypersurface times itself at the power d minus 1. So what I mean here is that this is a class in H11 of in H D D of P at the P H K P. P H K K of P at the power k. Okay? So this is a very formal way to see this, but more concretely, this can be calculated using Bezou. So Bezou theorem says the following. So f star of h is an equation of a polynomial and Of a polynomial. And coupling with h at the power d minus 1 means that you take some representative of some hyperplanes, some generic hyperplanes. And Bezoud says that if you have a generic hyperplane, the good amount, sorry, k, k minus 1, intersected with this is the product of the degree. So it's exactly the degree of the p i. And I told you those degrees. And I told you those degrees of the Pi's are the same. So this volume here is going to be the degree of the Pi's. So now we iterate. So now F N is going to be is going to be x zero x k is p zero n p k n so the volume of f n star of h is the degree of those polynomial p0 n, p i n. Okay? And And turns out that you can see that this degree is sub-multiplicative. So the lemma. So this was due to Khrusakovsky-Schiffman, who observed that and Schiffman. I think it's in the 90s, if I'm not mistaken. So it's that the volume of The volume of fn plus m star of h is smaller than the volume of f n star of h times the volume of f n star of h. Okay, using this observation that it's the degree. So why is there an equal inequality more than an equality? More than an equality. Because in one variable, when you iterate a polynomial, it's multiplicative. And here comes from the fact that you write fn plus m. You're writing in the naive way. You plug in P0n of Pi of M. But who told you that there are no common factors? So you have to kill the common factors, and this gives you the component of Fn plus M. Component of Fn plus M. Killing the common factors kills some degree, so it drops a little bit. So in these compositions, you actually do find common factors in these compositions? Yes, you do find common factors. For the Cremona angular, C squared equals identity. So you have to find that the degree of the identity is one, otherwise uh there is a problem. But when you but the degree of the cremona evolution is two. The cremona involution is 2. And if you multiply 2 times 2, then you get 4. So there is a drop. Okay? Okay, so using this beautiful thing, then you can define the asymptotic growth of the volume. That's what we want. So lambda 1, lambda of f is the limit as n tends to plus infinity of the volume. Of the volume of fn star of h at the power one over h, and this is finite. Okay? And this is called the third, the dynamical degree of f. But do we want this? Do we want this or do we want this? We want the growth of the volume, not just the rate. Not just the rate. So we need to get more lucky and to be able to estimate the growth. And if we are very fortunate, it's exactly lambda 1 to the power n. And yeah. So I think I need to finish here. Thank you very much. And we have time for a couple of short questions. Otherwise, there is the gossip break and you can expand your questions. Yes, please. So I have first a couple of remarks with respect to the beginning, to the first part of your talk. So you mentioned five examples. I think that one of the examples is not really known. Session analysis has not been made. This is this red. Analysis has not been made. This is this rabbit group. For this, I don't think that we know this rational map or anything. And on the other hand, there are many more examples for which we do know. So even in the original table of Vatorze and Rigorchev, there was not only Grigorchev group, but two other groups, the Omer group that Slava defined, and also another famous example which is grouped the Sidki group. But then there is more recent work by Slava, myself, and Aitor Perez, where we cover actually an accountable family. Where we cover actually an uncountable family of groups, which is called the family of spinal groups, and for which this analysis has been made, and the recursive formula are given, and the spectrum of three is computed. So the set of examples, I mean, maybe there was some except. Then the second remark is regarding your second point, which is about the limit. So there is a natural procedure, especially to associate. Procedure is actually to associate a limit to a family of finite graphs, which is called the distributional limit of an eminent Schram limit. And it suits perfectly this setup of Schargs of self-similar groups. And once you have a limit for the graphs, then naturally it comes also with a limit for the spectral distributions. So actually, there is a spectral distribution of this limit, distributional limit, which is a natural candidate for being the limit of your spectral. Candidate for being the limit of your spectral distributions on finite levels. So maybe you get a new way to look at it, but definitely it has to be compared with this spectral measure on the limiting object. Okay, we can. And yeah, I'm finishing the remarks. I also have a question. So you first you you finished your first part, right? Uh could you tell us briefly what it tells you about the spectrum? So, the spectrum, so in two cases, we know what is going on. So, I mean, there's some type of disjunction in nature. So, in the trigger shoot case, for example, so there is this annoying factor that actually does not appear in the it simply cancels completely, this P zero at certain power. So, basically, what will happen is that this joint spectra are going to converge to the green current. Are going to converge to the green current, to the limiting object of F. And so this is when you have perfect cancellation in that situation. Then there's the other situation like Hanoi Basilica and Hanoi Basilica, I think, where you have, it's going to be discrete. It's going to be like it's going to be a countable sum of Countable sum of sub-varieties that are going to accumulate on the drip current. So, something like the analog of what happens in sense of measures, if you look at measures, where you do something like this, sum of AK dirac at PK, where sum of AK is summable. So you're going to have these types of limiting. Of course, here it's not going to be directed. Here it's not going to be direct at PK, but it's going to be some currents of integration along some sub-varieties, some of AKVK, but that's the scaling. So you get a bunch of curves that accumulate towards the green current. And the story is that if you remove the first term of the series and look at the rest, then the rest is going to be the green going to converge to the green garrot. Can't converse to the graveyard. So those are, but it's only on specific examples. We know this. Any other questions? Not we thank the for the continuation of this talk objective. For now we have a coffee break until it's seven. I mean, it's a very simple existence.  I think this is worked out. I think you just do it more. I think the show is fine. Okay, so we need to have more than a point. So instead of having one percent, what you have is just a set of allowed functions. So it's based on according to the. And it expands chosen because then you will generate doing your skill to go on the same colour. And if you do that, if you do that, then you actually end up with a nice, consistent composition of all very nice, but nicely don't do that weird edge at that point. You can actually do this sort of odd. You can actually do this sort of odd thing kind of thing where you start off devices or anything else. 