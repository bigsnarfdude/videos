All right. I would like to talk about computational advertising, and I'm not very expert in this area, but it seems to touch on many different things that we should be caring about. It's a new emerging field. Aspects of it touch on almost every kind of statistics that we do. We do. In 2019, the online advertising market was valued at $309 billion and it's projected to be valued at $982 billion by 2025. It's the dominant revenue stream for a whole lot of information technology companies, and it's certainly something to which we should pay attention. There are many aspects of computational advertising, but one is online ad clicks. When you type pizza into a browser, a virtual auction. A virtual auction that lasts a few milliseconds and the dynamics of that are astonishing. Domino's and Papa John's and Pizza Hut all try to bid to show their ads in the most prominent places. The process is complicated because bidders have to be qualified. And so, if you are trying to bid on the keyword pizza, well, Word pizza. Well, Domino's and Papa John's and Pizza are all going to be well-qualified bidders, so they'll get an advantage. But other people will get handicapped. If you are, oh, I don't know, Peter's pornographic pizza, then you are going to be penalized by Google. You can still get your ad displayed, but you have to pay a lot more than Domino's does to grab that ad space. And the The properties, the qualification algorithm, the qualification calculation is held secret because Google does not want people to game the system. Yahoo doesn't want people to game the system. And so there's a lot that's happening there that we really don't know about. Nonetheless, David, can I chip in real quick? Please, yes, Tim. A lot of the bidding on Google is Bidding on Google is the bid times the probability that someone will click on your ad. So the more qualified bidders with a higher probability of clicking have a higher chance. And then beyond that, it's a second price auction. So the price that you pay is based on the second place bid, what you would have had to bid in order to just meet that. Yes, exactly. It's a vicary auction, and I'm actually going to say. Um, and I'm actually going to say a little bit more about that later on. But you're right, there is a statistical issue involved in estimating the probability that somebody is going to click on that ad. And it gets complicated because the revenue that Google receives, it may be that Google gets paid simply for showing the ad. It may be that Google gets paid when you click on an ad, or it may be that Google gets paid when you download a coupon and actually present it at a brick and mortar store. Actually, present it at a brick and mortar store. There are lots of different revenue generation mechanisms out there that are possible. And so it's complicated. Here is a schematic that shows how the bidding process works. And in this schematic, it's hard to see. I'm going to walk us through it in a minute, but it does indicate how real-time bidding works. And you'll see this. Works and you'll see this non-real-time bidding over here, as well as this sequence of operations, these handshakes or exchanges that occur as the process proceeds. So the way it works would be a person's browser contacts a publisher's website, and that publisher could be cnn.com or the New York Times or Fox News or really pretty much anything, a blog post. A blog post, a blog site. And the publisher's website sends back contact, including placements that will need to be filled through an ad server. And then the browser will contact the publisher's ad server, and it will get the ads that do not go up for an auction. So it may be that CNN.com wants to include an advertisement for CNN, or it may be that they have a special deal with some other group that ensures that CNN. Group that ensures that CNN is going to post their ads or their impression without going through an auction. And if you are using an ad blocker, then this interchange isn't going to happen at all, but most people don't. And so step four is to have the publisher send back the predefined ad content that's already been agreed on by the publisher. On by the publisher. But there's still opportunities to place additional ads. So a placement is some region of the screen where an ad may occur, and some of them are already preset, but now there are other placements. And for those unused positions, the browser will contact an exchange with placement information and it will indicate whether or not a placement should. It'll indicate whether or not a placement should go out for a bid, or if there's some other private deal that's been set up for that placement. So, if you have real estate on your screen that is available for real-time bidding, then an auction is set up on the exchange. And once the auction is initiated, the demand side platforms are simultaneously contacted to participate in the auction. To participate in the auction, and all of this is going to run in parallel. But examples of demand-side platforms would be things like Velassis and Veritech and some of the other groups that are going to be participating in our conference. So basically what they do is they deal with Procter Gamble, they deal with Walmart, they deal with lots of stores who might want to advertise on the website. On the website. They'll deal with Domino's, Papa John's, Pizza Hut, all of those groups. So the demand side platform may or may not decide to bid on the placement. So if you've typed in pizza and the demand side platform believes that it's around dinner time in wherever you are and you have a history of buying pizzas in the past. You have a history of buying pizzas in the past online, then they may bid a large amount to show you an ad for pizza. If, however, it's, well, I don't know, eight o'clock in the morning and you've never bought a pizza before, then maybe the DSP is not going to bid very much to try and show you an ad for Domino's Pizza. The winning bid from the auction and information on the bidder, the DSP, is sent to the exchange. Sent to the exchange. The exchange returns the DSP-wrapped ad tag that contains everything needed to track the bid, the impression, and something called a director log join. And that's basically a link to the director so that they can obtain user information and pass back the actual creative ad tag. So that's sort of where the auction ends. And as Tim was saying, for Google. As Tim was saying, for Google, it's a second price auction, but for many places now, it's become a first-price auction. When all this stuff got started, it was largely a second-price auction field. So you would, the winner would be the person who bid the most, but they would only pay as much as the second highest bidder bid. And Ben Vickery got a Nobel Prize for basically proving that that encourages people to be honest in their People to be honest in their valuation of the market or the bid that they would do. They should bid their true value for the item on offer in a second price auction. But now the world is moving away from that. The browser is going to contact the DSP's director to attain the ad server tag. The browser receives the ad server tag. The browser browser The browser uses the ad server tag to contact the advertisers requesting the impression. So now we're getting to the point where you actually begin to see the ad. The advertisers ad server, so this would be Domino's or Pizza Hut or whoever, will return the impression, the logo for Pizza Hut, and whatever additional banners or links might be needed there. And it returns. Needed there, and it returns that to the browser. And that's the point at which you actually see the ad come up on your screen. And if the campaign or line item is using a third party for tracking, it is contacted with the impression and user information. And that's basically to sort of keep everybody honest. We don't want Google to say that it showed an ad to Jason when, in fact, it didn't. So very often there's It didn't. So very often there's third-party verification that, in fact, the thing has occurred. Nancy, yes, please. David, could you go back to point 10? Yes, of course. There's a lot of information here. I don't understand any of those words, really. Ah, yes. If you're going to cover it later, that's fine. I don't want to slow you down, but. No, Nancy, I am delighted that you asked. I think this is the right way to do it. I hope this. I think this is the right way to do it. I hope this will be a heavily interactive conversation. And I also have to say that much of this is stuff that I am not completely solid on either. This is the information that I got from Velassis, which brought out Max Point Interactive, which is a computational, well, it's a demand-side platform. And the demand-side platform are the ones that bundle all of the people who might want to advertise. All of the people who might want to advertise on Google. So they will reach out to Papa John's, they'll reach out to Domino's Pizza, they'll reach out to Pizza Hut, they'll also reach out to automobile dealerships and grocery stores and restaurants and anything. And if and they will set up the software that allows Papa John's to easily advertise. And so Papa Johnson's. And so Papa John's will make a contract with the demand side platform that says we would like to show our ad to 100,000 people in Southern California. And so we will pay you, you will then pay Google, and then that's how the ads get picked. And the demand side platform is going to see that. Platform is going to see that Patrick has just typed in the word pizza into his browser. And then the demand side platform is going to decide: do we want to bid for Jason's eyeballs or not? And the decision about whether to bid for his eyeballs depends on a whole lot of factors, including everything that it can guess about Jason. And both the demand-side platforms and Google have a lot of information. Have a lot of information probabilistically about Jason. They can guess his age, his gender, his location, his income bracket, things like that. So the exchange runs the auction. If, say, Velasis won the bid, then the exchange is going to return the The DSP's ad tag that contains everything that is needed to obtain the ad from, say, Pizza Hut, place the impression and the correct real estate on the website on your browser. And then there's this director log joins, and that is a way of tracking. A way of tracking what is going on to verify that you actually have received the visual that represents the Pizza Hut logo. Thank you. Of course. And I hope we're going to hear more about this as we move forward, but that's sort of the high-end view of all this. The browser then contacts the demand-side platform's director, which then leads them to the Director, which then leads them to the ad server tag. The browser goes to the ad server tag. This is where they actually contact Pizza Hut, and Pizza Hut then supplies the material for the impression. The impression is what they call the displayed ad. The advertiser, Pizza Huts, returns all the impression assets and the creative contact back to the browser. So the demand-side platform is. The demand side platform is the middleman, the exchange is this virtual auction, and Pizza Hut supplies whatever its people decided is an attractive ad for this week. And that gets all delivered here at this point. And then I was indicating you can have a third party to keep everybody honest in this because pizza. Because Pizza Hut is paying money to show an ad, they want to make sure that that ad actually does get shown to Jason. So that's the way it works. The third-party tracker sends back a one-by-one pixel as a verification or a handshake token. And I'm not quite sure where that one by one pixel comes from. I assume it is part of the impression that is shown to the viewer, but I'm not quite. The viewer, but I'm not quite sure how all that works. The add tag contains the JavaScript that the browser app needs, which will load when the impression becomes visible. And the signals are passed back only after the creative content is loaded. And so this occurs very late in the process. You're trying to front load all the stuff that needs to be done fast and then actually. And then actually sending the content comes late in the process after everybody has signed off on who is showing what to whom when. The demand side platform returns a one by one pixel to verify that the deal was done. And if the DSPs are tracking pixel fires, this information is going to be sent back from the browser. And let me pause and ask. And let me pause and ask Tim if you would like to provide any clarifications or comments. No, I'm not involved. I don't know a lot of these details either. I've got okay. The takeaway message is that it's really a very complicated process with lots of stuff going on. And it takes place, I think I was told, in seven milliseconds. It's some incredibly streamlined process here. So a lot of So, a lot of information is getting traded back and forth. And one of the key things is to try and figure out how much to bid for a particular person's eyeballs at that time in that place. And they can't be doing very much real statistics and trying to make that decision because seven milliseconds doesn't give them a whole lot of time to process whatever they believe about the person's age. About the person's age, gender, location, previous buying history, all of that stuff. So the DSPs want to pre-process as much of that as they possibly can in order to be able to have the highest yield rate on their advertisements, the highest click-through rates or the highest, yeah, the highest success with their advertisements. Now, this sketch is surely out of date because I got this back in 2018 and this world moves really quickly and things evolve very rapidly. It used to be that nearly all auctions were second price, but now many have gone to first price auctions. I'm told that the reason for that is a first price. Is a first price auction is less economically efficient than a second price auction. And so the demand side platforms think they can make a little bit more money by exploiting the gullibility of or the inefficiencies of people's algorithms in a first price auction. So that is their hope. And I guess they're probably right because they all see. I guess they're probably right because they all seem to be moving in that direction. There are lots of other things that are going on under the hood, but the main message is that this part of the process is really complicated. Computational advertising is going to touch on many different aspects of physics. During this workshop, we're going to hear a lot about design of experiments, causal inference, recommender systems, predictive inference. Recommender systems, predictive inference, and time series modeling. And those are all clearly related to computational advertising. For example, with Google, it is possible now to have complex, multi-armed, adaptive bandits that can perform millions of experiments, collect millions of data points on complex experiments over the course of a few minutes. And that's totally different from the. Totally different from the roots of design of experiments that started at the Roth Hempstead Research Station with Fisher doing agricultural experiments. And agricultural experiments, it takes, you know, six to nine months to obtain your observations. You're dealing with very small numbers. If a cow wanders into the wrong field and starts eating, then you've lost that observation. The modern world of The modern world of computational advertising is a very different scenario for experimental design. And I think it's going to breathe important new life into what was formerly a sort of stodgy field of statistics. Causal inference is another area where computational advertising is clearly relevant. There's an old saw that an executive said that half of my advertising budget is wasted, but I don't know what half. But I don't know what half. In that spirit with causal inference, you would like to be able to try and estimate what is the lift in your sales that is due from an advertising campaign. And people who do causal inference have lots of ideas about how to measure that. And we're going to hear from Mamadou and other people over the course of this workshop. Patrick LeBlanc and the Gorshi Sen are gonna be talking about recommender systems. To be talking about recommender systems, I'm going to be talking a little bit about them too, but recommender systems drive almost everything. A recommender system is essentially the technique that decides what ad to show to you and what ads not to show to you. The recommender system in a souped-up fashion is going to decide how much to bid to show that ad. But also, recommender systems are used to determine what books Amazon is going to recommend for you, what compatibility level Netflix thinks a particular type of. Level Netflix thinks a particular television show has with your interests. And in OKCupid, a recommender system is used to suggest people that you ought to go on a date with. So the recommender systems are a real engine of computational advertising that arise in multiple types of applications. And not very much has been done from a statistical standpoint with this. Computer scientists have jumped in on this. And so you do have collaborative filtering and content-based. Collaborative filtering and content-based filtering, and all sorts of things like that. But statistical theory is still unclear. Time series modeling, that's going to be important for a whole lot of reasons. In particular, for example, you'd like to track the success of an advertising campaign over time. And so at a certain point, an ad becomes stale, people stop clicking on it, it's time to refresh your creative content. Your creative content and time series is rolling for deciding that. But I will add that computational advertising also engages with many other aspects of statistics. Text analysis and sentiment analysis are both areas where computational advertising can be very useful. I'll be talking about dynamic network issues later on in this overview. Overview. I'm looking forward to the possibility of probabilistic ad contracting, which I'll build out in a minute. I'm also going to point out that spatiotemporal processes, sensor data, and other things all arise in the computational advertising domain. So I see this as a great area for academic research for a couple of reasons. One is that, well, I have former students and postdocs who are now working at. And postdocs who are now working at places like Google and eBay and Amazon and so forth. And they tell me that they really don't do theory, they don't find the best solution for a problem. They are fighting fires. And so they some problem, they rush in, they try and put a band-aid on it, and then they move on to the next fire. And academics have the opportunity to proceed with a slower but more principled solution. Solution. Additionally, when one of these companies does do deep research and tries to solve a problem in a smart way, often they choose not to publish it because it's a competitive advantage if they know how to do this and their competitors don't. So, again, that means that there's a lot of opportunity for academics to be involved. And that's really the reason why we're trying to have this. Reason why we're trying to have this workshop today. I'd like to try and explore what academics can contribute to the computational advertising field. So one thing that I think is an interesting aspect of recommender systems that is not going to be discussed by other people here at this workshop are active recommender systems. And an active recommender system mimics what a human being does. If somebody comes to me and says, David, I'm looking for a book to. Says, David, I'm looking for a book to read. Can you make a recommendation? Uh, I immediately ask them questions: What sorts of books have you liked in the past? Do you like murder mysteries? Do you like science fiction? Who are your favorite authors? And that is a system in which I am actively learning about the tastes of the person to whom I'm going to make the recommendation. When I log on to Amazon, it's going to recommend books. It's going to recommend books to me because that's what it does, but it doesn't use an active system. And I can imagine that someday I will log on to Amazon and they say, David, no matter what, we're going to make recommendations for you. And we're going to make those recommendations based on your previous purchase history. But if you allow us to ask you five questions, we'll do a much better job at recommending books that you really want. And some people see that as an intrusion on privacy, and I understand that. Privacy, and I understand that. On the other hand, if they can actually recommend books that I really want to read, that's a net benefit for me. It reduces the amount of spam that goes on. It saves me time. So I think an active recommender system is something that we ought to be exploring. And it's rather like playing 20 questions, but there are special features. I will talk about personalized priors, complexity constraints. Personalized priors, complexity constraints, and non-standard feature selection. And in principle, one could build a proximity matrix for books or movies or music that says how close two books are to each other, how close two movies are to each other. Oh, Pirates of the Caribbean 1 is probably pretty close in movie space to Pirates of the Caribbean 2 and pretty far away from the best years of our lives. Years of our lives are something that's you know also very distant in principle. Amazon can calculate a probability distribution for the chance that I will buy any book that they have on offer. And this would be based upon previous purchase I have made and some model for nearness or proximity in book space. Collaborative filtering and content-based filtering are the default methods, but those have been built. Default methods, but those have been built out in interestingly complex ways. And we're going to hear more about that from other speakers. This is, of course, not what Amazon does. In principle, they probably could do this, but it's a waste of their computational energy because they know that I have never bought a book about fishing. I never will buy a book about fishing. There's no point in them spending time and effort to calculate a probability that I'm going to buy a book about fishing. They're only interested in trying to estimate probability. Only interested in trying to estimate probabilities for books that I have, say, an 80% chance of buying or better. There, that's where they need to be accurate. At the other end of the scale, they don't need to be very accurate at all. So why spend energy on that? A friend of mine is an airline pilot, and he tells me that the accuracy of their fuel gauge is terrible when they're all filled up. When they're all filled up, but it becomes super accurate as the amount of fuel you carry goes to zero, because it only matters when you're very close to running out of fuel. That's when you need to be accurate. The rest of the time, it doesn't matter so much. So the same thing is going on here with Amazon. The model for near disk should be complicated and personally tailored. Tailored. There are some readers who follow authors, there are others who follow genres, there are others who follow the recommendations of the New York Times book review section. And so, in principle, Amazon could learn that, ah, David reads anything that's on the top 10 of the New York Times book review section. That's his approach. But his wife reads anything by Colson Whitehead. So we would have different recommenders tailored to what's known about the purchasing habits of the individuals. Habits of the individuals. And the model for proximity or nearness in book space is probably not something that you can embed in Euclidean space. And so that means you're going to need to use some other tool. ISO map or paramap are techniques that are out there. Patrick and I have been looking at this type of problem, and it appears that nobody in the recommender system world has yet learned about. World has yet learned about isomap or paramap, which are tools that are used in the multi-dimensional scaling world, non-metric scaling world, by statisticians. So here's a tool that we know about that most of the computational advertising world does not seem to know about, but the potential from trying to apply it seems large. So the next thing Amazon needs to do is to learn what questions it will ask. Do is to learn what questions it will ask me in order to learn the most about the books that it should recommend. And unfortunately, the best questions it would ask are things like, on the whole, do you like these 100 books more than you like this other list of 150 books? And there is no way that I can cognitively process that question. Amazon wants to ask questions that have a 50-50 chance of me saying yes or no based on their prior beliefs about me purchasing any given item. Purchasing any given item. So they're going to learn at the fastest rate if they can ask me 50-50 questions. But the optimal 50-50 questions may be too hard for me to think about. And so there's going to have to be a complexity penalty on the questions that it asks. And to find that penalty is going to be an area for future research, but it's clearly a special kind of regularization. And statisticians know a lot about how to use regularization. How to use regularization to improve our work. So, Amazon is looking for questions that have 50-50 chances of me answering yes. But there's a hidden optimization problem here. If Amazon is greedy, the first question it asks might have a 50-50 split on me saying yes or no. But underneath that split, it may be that subsequent splits in this question tree are going to have 90-10. Question tree are going to have 90-10 splits. And so Amazon is going to learn slowly further down in the tree after it asks me the first question, which is a really good 50-50 question. And if that's the case, then Amazon might want to think about choosing a question tree such that many of the branches in that tree have nice 60-40 splits as opposed to 90-10 splits. And that ensures that not And that ensures that non-greedily, Amazon will learn as rapidly as possible about my book preferences. This, I think, is a novel class of problems, and it applies to lots and lots of situations. I've pointed out that recommender systems are used for music, for books, for picking which ads to show you, and for picking people that you should go out on a date with. And extending this. Extending this methodology to active recommender systems strikes me as a very interesting thing to do from a statistical standpoint. Let me pause for a minute and ask if anybody has any questions about what I have talked about so far. I do encourage us to be very interactive throughout this week. Let me talk about another type of optimization problems that arises in the context of computational advertising. One financial model is that a company contracts to show a client's ads to say 100,000 women between the ages of 24 and 40 who live in California, and these impressions must be made between January 1st, 2022 and June the 1st, 2022. Then that company, Then that company, that DSP, writes a second contract to show a different set of ads to 200,000 people between the ages of 20 and 50 in Northern California between February the 1st of 2022 and September the 1st, 2022. And clearly, these two contracts have overlap. The same person could be used to fulfill contract one or could be used to fulfill contract two in many cases. Too, in many cases. Not everybody, but often. And so then the question is: how does the company decide when somebody logs in and it's a woman age 30 in Northern California in March, whether it shows the ad for the first contract or the second contract? Currently, my understanding is that most companies choose a person. Choose a person at random and either randomly assign them to contract one or randomly assign them to contract two if they fulfill both contracts. And that's smart. The concern, of course, is that they may not be able to satisfy the contract as efficiently, but they do it for a good reason. You could imagine a situation in which Imagine a situation in which Domino's Pizza has made such a contract, and it turns out that Google can fulfill that contract, or the DSP can fulfill that contract by showing the Domino Peaches ads exclusively to men who are 80 years old and older. And although technically that fulfills the contract, that's not what Domino's wants. They want to be able to reach the lucrative market that you. Want to be able to reach the lucrative market that includes young people and a diverse geography. So by randomly assigning people to fulfill contracts, that eliminates the possibility that you're going to wind up basically bilking the pizza company by only showing its ads to people who have low market value. Have low market value. So there's a statistical question about how we can ensure that people are sort of honestly assigned to fulfill contracts and match the expectations of the companies at the time that those contracts are written, but also ensure that the company does not pay a penalty for not having enough displays shown. Typically, the way Displays shown. Typically, the way a contract is written is: you're going to show, you promise to show the ad to 100,000 women between the ages of 20 and 40 in Northern California, in California. But if you're a little bit short, if you only display it to 99,000 such people, then the company will return a little bit of the money it received to the pizza company for the advertisement. And the company and the And the DSP or Google wants to return as little money as possible. And so they will change the probabilities as the time proceeds. So for example, the first contract has to be fulfilled by June the 1st. The second contract has to be fulfilled by September the 1st. So if you're coming up on June the 1 and you haven't fulfilled all of the first contract, then the randomization is going to upweight the assignment of people to the first contract. Of the assignment of people to the first contract and downweight the assignment of people to the second contract. But exactly how to do this in the optimal way is not at all clear. Additionally, some of the characteristics, such as age and gender, need to be inferred, and the contract must specify how that will be done. I look forward to the day when there are going to be contracts that are probabilistically written. You can imagine an agreement that says this ad is going to be shown to 100. This ad is going to be shown to 100,000 people who have probably 0.9 or better of being women between the ages of 20 and 40 who live in California. And that would be a very novel kind of legal agreement, but it's certainly conceptually possible. And it would open up the advertising space enormously. Because right now, very often you can only claim credit for an ad if you have a registered user whose gender, age, and location are known. Age and location are known. And most people are not registered users, but nonetheless, there's a lot of information that we have probabilistically about these people. We would need to have some third-party verifier to say that, yes, indeed, this belief that this person has probably 0.95 of being a woman in the right age range in the right location, that's a correct. That's a correct estimate of the probability. We're not goosing the numbers to help our advertisers. And it's known that Google has generally pretty good guesses about a user's age, gender, marital status, income bracket, and personal interests. And so all of that stuff could be fed forward into the creation of these probabilistic contracts. A different aspect. A different aspect of computational advertising that I think has promise is dynamic network flow monitoring. People log into the internet and they traverse websites. And if you have ever noticed, when you go to a checkout line at a grocery, that checkout line has stupid magazines and candy bars right there. And that's because grocery store owners realize that people are more likely to make an impulse buy as they are leaving the grocery store. As they are leaving the grocery store, they'll see the candy bar, they'll buy it. They don't have that type of impulse behavior when they're examining the vegetables, picking the fruit, looking at the cheeses. So as part of previous work with a computational advertising company, I and others analyzed flow within the Fox News website. And Fox News is amusing. We tried to go to the New York Times website. We tried to go to the New York Times website, but they manage their own advertising, so that's not visible. Other people have privacy concerns. Fox News apparently doesn't. So we were able to track people moving through the Fox News website very easily. And basically, we fit a dynamic gravity model with a technique that we call decoupling recoupling. And we're able to track flows through this Fox News website. So here is the landing page. So, here is the landing page for the Fox News website. That's the homepage. And from that, you can go to this page, which is US News. You can go to 22, which is others. You can go to 4, which is opinion. And so you can navigate within the Fox News website to various things that are of interest to you. So it could be politics, entertainment, technology, whatever. And the decoupling recoupling tool allows you to do process monitoring and change point detection. So, here we're looking at the estimated transition probabilities from the Fox News homepage to their entertainment page on six different days. And what you see is that there are clearly day-to-day differences in these transition probabilities. And we've got 95% credible bounds on each of these. Each of these flows. So, what we're able to do is to monitor how people are flowing from one portion of the website to another portion of the website. And the important thing about that is this can be used to determine when an ad should be displayed. People will typically have customary habits. They will log into the Fox News homepage, they will go to news. They will go to news, then they will go to the weather forecast, and then they'll go to entertainment. And now it's time to get back to work. And so, the time to show them an ad is just as they're about to leave the entertainment webpage. That's the presumably an optimal time to show ads to most people. Of course, other people may be very different, but we can begin to understand when to place an ad. This type of process monitoring is also going to be Type of process monitoring is also going to be important in tracking an ad campaign. So if Domino's Pizza has a catchy new slogan and music and video, you'd like to track whether it's doing well and driving business to Domino's Pizzas or whether it's becoming stale and old and should be retired. And this is going to be a tricky statistic. And this is going to be a tricky statistical modeling problem because it's not dominoes existing by itself in a desert. Instead, it's competing all the time with fresh ad content from Papa John's and Pizza Hut. And so the success or lack of success of Domino's ad is part of a game theoretic or adversarial risk analysis situation in which there are other agents that are also acting. Acting as part of the ecosystem of advertisements. Nonetheless, we have ideas about how one might try and model this tricky process. You have time-varying cost-proportional hazards models, which would be one way into trying to measure this. We could look at some of Mark Plickman's models for competitive sports. Mark has done lots of models for basketball teams, football teams. For basketball teams, football teams, all sorts of games, and we can regard this ad display competition as a game. Finally, deep neural networks and especially the generative adversarial networks are a potential tool for creating new content. Style transfer and other techniques are sort of sexy. Here is a style transfer example from which you have Picasso, Van Gogh, and Georges Seurat as the sort of three. As the sort of three different representations. Each of these is visually arresting, and it would be nice to try and use AI techniques to suggest add content that could then be chosen or not by a human being. So we get away from the madmen era where it's one person coming up with an idea and pitching it. And instead, we have smart AI pitching lots of ideas and human choice. Ideas and human choice are picking among them. I'm going to bring this in for a landing now. How am I doing on time? Okay. I think computational advertising touches on almost every aspect of modern applied statistics. You're going to use cluster analysis and multi-dimensional scaling to drive market segmentation and collaborative filtering. So those are tools that we know about. Market segmentation has been around for a long time, but I don't believe it's been properly applied in the e-commerce world yet. Latent Dirichlet allocation, sentiment analysis, word to vec, and natural language processing are all going to be helpful to computational advertising in many ways. If somebody's on a website that mentions hamburger, well, maybe you should show them an ad for McDonald's. An ad for McDonald's. But if it turns out that it's a PETA website, well, sentiment analysis would probably tell you that that's not a great idea. So those are tools that can help inform a DSP about whether or not it should bid for that person's eyeballs or not. Anomaly detection is something that statisticians have been studying for a long time and change points, and we have to have good cybersecurity. To have good cybersecurity if people if companies want people to click on their ads if it turns out that uh somebody hacks uh google or a dsp or dominoes such that clicking on a domino's pizza ad leads to a ransomware situation well that would be really really bad and so uh statistical tools for cybersecurity i think are going to be an important component of uh computational advertising Of computational advertising. Spatio-temporal models. I know that there are advertising companies that follow your cell phone around as you walk through a grocery store. And if you're standing in front of the serial display, it can send you a virtual coupon for Trix or Captain Crunch. And they send it to you because they know where you are and what you're looking at. In what you're looking at. So that leads to one kind of spatiotemporal modeling. A different kind of spatio-temporal modeling has to do with what region of the world are you in? What is your current time? And is this a time when you're likely to be thinking about ordering a pizza or not? So that also leads to spatio-temporal modeling. It gets tricky because people get on airplanes and their laptop flies to China and suddenly Flies to China and suddenly they're in a non-standard time zone. And maybe the system should be smart enough to notice that. So that is my talk. And I've left us about eight minutes for conversation before Tim does his pitch. So, does anybody have any comments? Fan, I see that you're online. How are you? Thank you. Great. Thanks, Sam. Yeah, I just wonderful talk. I just, I don't know much about this field. I just show up to, I just try to see what I can learn. None of us know very much about this field, which is why I think it is really important for us to jump in on it. We can define what the field is going to be as we move forward. As we move forward. And I see Nancy has her hand up. Would you like to go first, Nancy? Okay, sure. You made the point that there's a lot of opportunity for academics to be involved in the research, which is great, but if the data is proprietary, how can we ensure that the research is appropriate or realistic or not just confined to the ivory tower? It just confined to the ivory tower? There are various ways of doing that. For several years now, I have been working with a computational advertising company in the Triangle, Research Triangle Park, and we've signed non-disclosure agreements and we've had access to their data. There are other ways it can be done. For example, they can provide a mock version of the problem and we And we can work on trying to solve this toy problem that they have. Many of the things I talked about require conceptual breakthroughs first. So trying to think about how you would write a probabilistic legal contract to display ads is a question that can be done fairly abstractly without data. Trying to optimize ad display. We know if we have a We know if we have a contract required that's going to end on June the 1st and you have to have 100,000 people shown the ad, well, we can think about how to sort of optimally reweight the probabilities of assigning people to contract one versus contract two without actually having to work with data. So I think there's traction. Also, I will note that there are a lot of companies out there that want answers to these problems, and I think would be very happy to work with statisticians. Be very happy to work with statisticians. They just need to protect their own interests in doing so. Jiua. Hi, it's very interesting, eye-opening. Apparently, I don't have any idea of what is happening here until this moment. And I'm particularly interested you are talking about design of experiment as I'm teaching a course on design of experiment. We are talking about the agriculture experiment by fisher and by taco. By fishing and by Takuchi for industry and so on, so forth. I'm just think, you know, when I teach those, I don't have any experience on those. And I think probably in the future, what you are doing here will find its way into textbooks. So I'm just wondering whether you have a plan of that. Otherwise, it will be slow for the new generations getting into it. At least they have to find. At least they have to find these things in the company rather than in the textbooks or anything like that. You're quite right. The world of experimental design is changing rapidly under our feet. There are books about aspects of computational advertising. There's a 2018 book on recommender systems, which I think is quite nice. But this field moves so quickly that even a 2018 book. That even a 2018 book is going to be out of date very rapidly. So I agree a book would be nice. I think that's a little ambitious for right now. Today, I just sort of want to see if we can get more statisticians intellectually engaged with some aspect of computational advertising. And there are many different aspects that are available. It's a target-rich environment. It's a target-rich environment.