But uh, Pete is with us now. Um, let's switch those, great. Okay, so I'd like to present Janit Singer, who's going to talk about non-Euclidean metrics for cryo VM analysis. Okay. Hi, everyone. Sorry for the confusion with the time zones. I hope I didn't cause for too much uh disruption. Can you see my uh slides? Yes. Similar slides, yes, right. Okay, excellent. Thank you. So, yeah, I'll be talking to Babe about non-equivident metrics for cryogen analysis. I'm not sure if you already heard about cryogen in the workshop, so a very, very brief introduction. What is single-particle cryo-EM? So, this is a technology for determining the three-dimensional structures of biological macro molecules that. Macro molecules that nowadays at very high resolution, atomic or near atomic resolution. And the way it works is that you simply freeze the molecules that you want to determine in structure in a very similar ice. So the icer is so thin that you would have at most one molecule when you look at it at the vertical direction. And at the moment of freezing, every molecule just peaks. Freezing, every molecule just picks a random position and random orientation within the ice layer. And then you bombard a specimen with an electron beam. The electrons would go through the molecule, through the ice, and you record the projection images on the detector. So, what you obtain are two first approximation automographic projection images. That is, every pixel corresponds to Every pixel corresponds to the integral of the electrostatic potential created by the molecule in the direction of the Billion electrons. What you see in this picture is just an artist concept. It's not a real micrograph, just so you understand the polymer. So the main polymer is the standard chromium-cross-set polymer in which you want to determine the 3D structure of the molecule from such 2D noisy. Such to the noisy tomographic projection images. So, the main two challenges are that we don't know the pose parameters, the viewing directions, unlike say in medical imaging where the pose is known because the patient is being instructed not to move during the imaging process. And the other child meets a very high level of noise due to radiation damage, and this puts limitations on the maximum dose. Put limitations on the maximum dose that the practitioner can use. A few years ago, the Nobel Prize in Chemistry was awarded to three of the pioneers of Craw-IM. And this Nobel Prize came about five years after what is called the Resolution Revolution, in which CrawleyM really made a huge leap in its ability to determine structure the two. Its ability to determine structures at too high resolution. So, in the old days, Crowium got the nickname of blobology because it was able to find structures only at very low resolution, but with the new detectors nowadays, people don't get to very high resolution. And this was very quickly recognized with this Nobel Prize. And as you can see, Cry M is becoming more and more popular in structural biology. And so, the slide here is just showing you statistics of the number of Statistics of the number of structures that are deposited to the porting data bank to the PDB per year. So in red, you see the more classical approach of X-ray crystallography. And as you can see, it is more or less saturated at around 10,000 structures per year. NMR spectroscopy is even on the decline. Decline. And you can see in yellow the exponential growth of Crow EM. So the y-axis series in logarithmic scale. The little decline in this series just because the year still did not end. Okay, we have a few more months to go. So it is predicted that in about a year or so, we're going to achieve parity between X-ray and Cro if those trends continue. Continue. And you can see that this rise appears more or less around the resolution resolution in 2012-2013. Okay, so what is the basic of Cro-IM from a mathematical standpoint? So CroyM, the single-particle reconstruction form is an inverse problem in which you want to determine this 3D structure from noisy projection images. So we model the 3D structure just as a function of three variables of X, Y, and Z. Of three variables of x, y, and z, this is the ultra static potential of the molecule phi that is unknown. We're given the noisy projection images, the i i's, so we have n such images, and every pixel in the image, the x, y pixel of image i, is simply the integral of phi after being arbitrarily rotated. And here I assume that the images are perfectly centered, and also that we know exactly. And also, that we know exactly the CTFs associated with the images. So, just ignore them for the talk today, these are not really important. So, the basic rhythm reconstruction problem is to determine phi from the noisy projection images. The heterogeneity problem is even a more complicated challenging problem where you want to estimate not just a single 3D structure, but many proteins. But many proteins and other molecules of interest are flexible and they can have different conformations, different shapes. And so the molecules in the sample can have different shapes and you want to determine the distribution of those three-dimensional shapes from the noisy 2D images. So just to get you an idea of how images look like and the level of noise that we have to deal with in Crawer EM, so I show you just two images. I show you just two images out of much larger sample of experimental data set, one containing about 70,000 images, another containing about 100,000 images. And you can hardly see the molecule in there, okay, due to the very high level of noise, but remarkably they were able to get this restructure, okay, and publishing in a very high-profile venue. So, just to give you an idea. So, this is just to give you an idea. And the reason why it is possible is because, okay, we can average out the noise by basically obtaining very large data sets. I'm not going to tell you how the reconstruction process works today. I want to focus on what kind of metrics we can use in this process. So, typically Typically, people would use Euclidean distances in Croyan analysis. And there is a very simple reason for that, and that the noise in the images is modeled as additive Gaussian noise. Not certainly white Gaussian noise, but Gaussian noise. And then, if you're using any kind of maximum likelihood or likelihood methods, it naturally relates to. It naturally leads to Euclidean distances or weighted Euclidean distances in computational tasks such as 2D classification, if you try to classify images to certain view directions, or if you try to do 3D reconstruction, say in the model refinement, where you try to match projection images, experimental noisy projection images with templates of your current model. So also at the end, once you get the 3D map, the noise or the arrow in that final map tube then is also assumed to be Gaussian. And then when people try to determine the resolution of the maps, they compare different maps obtained from different reconstructions using only a subset of images. Using only a subset of images and assuming that the noise is Gaussian, again it leads to the Euclidean distances as a way to align those maps and do other type of analysis. So naturally we can ask ourselves, does it make sense even to use non-Euclidean metrics for prime analysis? And I'll try to convince you today that the answer is yes, otherwise I will just end my talk now. Okay, so I'll give you three. Okay, so I'll give you three motivating examples. Actually, other things that I will not discuss today that are still working for us. So the three examples are 3D heterogeneity analysis, 2D classification, and the alignment of 3D maps. So let's start with heterogeneity analysis. So this is joint work with Joe Kilil. I believe he also gave or will give a talk at the workshop. We'll give a talk at the workshop amit Moscovich and Nathan Zelvesko. So, our goal here is to learn the manifold of molecular conformations, okay, where each conformation is represented as a 3D density map. The Euclidean distances between conformations are sensitive to deformations or movements, either rigid or non-rigid. So, you can envision that some part of the molecule is moving while the other is fixed. Is moving while the other is fixed or rotating or doing even some other non-linear deformation, non-rigid deformation. And Euclidean distances are actually quite sensitive to it. And to understand why this is the case, just like you can see in this figure, just a very cool illustration of this phenomena. So if we look at the distances between A, so this is just one-dimensional figure. So this is just one-dimensional signal that looks like half-disk. So if you look at the distance between, say, A and C, and the distance between B and C, then those two distances are exactly the same in terms of Euclidean distance. But if you consider other distances, such as the Earth mover distance, well, it actually represents exactly the size of the movement, of the translation that you can. Of the movement of the translation that occur. So, Euclidean distance in that case would only be meaningful for very small shifts or translations, whereas other distances like the earth mover will capture much better the actual deformation that is happening here. So, EMD, there's more redistin changes more gradually and is more menu. Disney changes more gradually and is more meaningful to large deformation movements. So, if we're trying to do manifold learning and learn the manifold of conformations, then the motivation here is that with the Earth mover distance, we can hope for that fewer samples, fewer 3D density maps would be required to actually learn that manifold compared to, say, Euclidean distances. The problem that we're The problem that we're facing is that the computation of EMD between all pairs of 3D maps is very costly. So, the remedy here is to replace the costly computation of EMD with some other metric, okay, that we called weightlets EMD, WEMD. And you can see the formula of that distance here. It's simply a weighted L1 distance between the well-being coefficients. Coefficients, and I'm not going to why we want to use that, you can just view it for now as just as another metric, okay? But in some sense, it should behave as an approximation of the Earth's mover distance. So, here S is the scale of the Worldwide coefficients, and lambda is just the way to index all the Worldwide coefficients. So, both the scale and the translation. The reason why to use the Weber transform is because we can compute those distances basically in linear time. We can both compute the Weber transform of all the 3D maps in linear time and also those distances in linear time compared to Earth's mover distances. So, here is an example where, just in simulation, where we take a molecule and rotate, let's say, this blue part. Let's say this blue part, the dark blue part of the molecule. And you can see a comparison of EMD or WMD in orange compared to Euclidean distances in blue. And so you can see that Euclidean distances are very sensitive to the rotation. They capture the rotation only to very small angles, relatively small angles, where the W changes much more great. ED changes much more gradually. And even when with noisy samples, okay, it's still robust enough to show the same phenomena. So now we apply a dimensionality reduction method like diffusion maps, but we compare what happens when you use Euclidean distances with WMD. And you can see the embeddings that we get with Euclidean distances and WMD. as a function of the number of samples that we use. So diffusion maps with Euclidean distances required like at least 400 samples to get you a nice looking embedding. With noisy samples, you even need like 800 samples. Whereas with WMD, both with noiseless and noisy samples, remarkably, we just need like a few as 25 samples. Just need like a few as 25 samples to recover the down the line geometry of the data, the intrinsic geometry. So, let me switch now to the second example. We're going to use optimal transportation distances for 2D cluster imaging. So, here the goal is to somehow classify the large data sets of the 100,000 images into and so to group the images based on the viewing direction that are. Based on the viewing direction that are still unknown at that stage, just based on similarity between the images. So, here again, it's just simulative data where you can see that the top two images are just rotated versions of one another by 90 degrees. If you can somehow recognize that in a very large data set of, say, 100,000 images, align those images and average them, you'll get a much better quality image that looks. Quality image that looks resemble much more than the unlikely image that I showed you here. There are several reasons why one would want to do 2D class averaging. I won't go into the details here due to lack of time, but the main reason I think is that it allows you to get a 3D arbitrary model and to get you a quick assessment of the quality of the data sets that have been collected. So, the principle, as I said, is to find images that are believed to have similar gene directions and perform in-pane rotation and transitional alignment of neighboring images and then average those neighboring images to suppress the noise while maintaining the signal. And the main challenge is how to find images with similar viewing directions. And so, there are three main challenges. One is that we have to deal with very low SNR. So, it's difficult. So, it's difficult to detect images with signal view indirections because the signal is buried in the noise. The second challenge is how to compare images, that is, which metric to use-Euclidean or not-Euclidean metric, and then the complication and time. Okay, we want to avoid comparing all pairs of images because we also need to deal with the in-plane alignment, and together this is a very costly computation. So, we want something that will scale us linearly with an hour. Something that will scale us linearly with the number of images. So, here I'm going to describe joint work with Amit Moscovich and Ron Rau, who basically did for his senior thesis at Princeton at the time. He was an undergraduate. And we came up with a very simple procedure that is basically k-means algorithm that I assume you're all familiar with, but where we just replace the Euclidean distance in the k-means algorithm with vast. means algorithm with with vases time distances so uh so this will start with the input of n images you initialize k center c12 c k for example by just randomly choosing k of the input images and then in every iteration you assign to every image every one of the n images its closest center one of the c one of the c's one of the centers after Centers after implane rotation, but now you do it in terms of the weblet EMP. That, as I showed you, can be computed relatively fast. And so, the computation that you need to do here is for all pairs, but now it's n times k and not n squared because you only compare images with centers. And then once you assign new centers, you simply align and average those neighboring images. Those neighboring images. And you repeat this until you convert it basically until the loss functions stop decreasing. So here are some results. Okay, so here is simulation results with 10,000 tomographic projection images, no shifts, no CTS. We chose K to be 150 clusters. On top you see fast averages using Euclidean. Averages using Euclidean distances. At the bottom, you see cluster averages using the decay-mean Wasserstein distances. You can see more features in the one at the bottom. You can still say, oh, are they real or artifacts? So let me convince you that they're actually real. So because it's a simulation, we know exactly the viewing directions. Okay, so here I plot for you for every image and it's the neighbors. The neighbors, how they are basically the distribution or the histogram of the angle between the center image and its neighbors. Okay, and as you can see, the ones obtained with the W and D, the within cluster angular differences, they are much more narrow and clustered towards zero, okay, which is what zero angle, which is what we want. What we want, and there is a good reason why WMD works better, okay? So one can show, okay, that if you're working with Wasterstein p-distances between projection images, okay, so let's say I1 and I2 are 2D projection, tomographic projection images of 3D density map, then the vastly turned. Then the vast and p distance between them raised to the power of p will be bounded by just the angle between the view direction raised to the power of p. Okay, so we have this type of robustness. Whereas if you if you switch to Euclidean distances, okay, you can very easily come up with examples where no such bound can exist. Can exist for four Euclidean distance. And the reason is very simple. You can just take, say, a 3D shape with just, say, a point mass that is off-center. And once you rotate it, okay, and take projections from a slightly different wind direction, you have a very large L2 distance between them, no matter how small the angular difference is. So if you want to get a bound for the L2 distance, so you need to assume some smoothness of the underlying 3D. Smoothness of the underlying 3D map. And then you can bound the distances between the projection images in terms of the supreme of the gradient of that 3D shape. So L2 distance would work reasonably well for very smooth signals, but for molecules with some very non-smooth features, that it will not be a good distance to work with. Distance to work with. And this explains why 2D classification with Visosine distance may outperform Euclidean distance, as we've seen in the previous example. So let me conclude with just very quickly a third example, okay, of alignment of 3D shapes. So here the goal is to take two given volumes, say phi1, phi2, say represented 3D density maps, and to find the optimal rotation between them. Rotation between them. I know that some of you in the audience have looked at this problem before and even come up with algorithms that are based on optical transportation. So definitely this work is influenced by those earlier works, but here we do something a little bit different. So we try to find the optimal alignment. And first of all, one reason to use here Earth's movement distance compared to Euclidean. Distance compared to Euclidean is that you see that the landscape of the function that we try to optimize here is much nicer. Okay, so the basin of attraction for the Euclidean distance is very narrow. Here to visualize, I just show you the landscape as a function of two of the Euler angles, not the third one, because it's easier to make plots in 2D rather than 3D. And you can see that the Earth's mover distance is a much bigger. Bigger baseline of attraction. So, if you're using going to use an algorithm optimization method like gradient descent, EMD or even its approximation that we use of the wavelet's EMD would perform much better. So this motivates us to use the WMD and the optimization form that we chose to use is Bayesian optimization, which is a global optimization method. method. And so compared to gradient descent method, gradient base method, it is less prone to get stuck at local optima. And therefore, we should do very improved accuracy. And also Bayesian optimization explores the regions of high probability and therefore it would require fewer evaluations of the function compared to just exhaustive search and therefore improving the efficiency. So here is the comparison. So, here is the comparison using four different volumes, and we compare the three algorithms. So, in the box plot that you see here on the left is our method, in the middle is a relatively recent method called EMAlign by Arpad Shepolnitsky, and on the right, a method called AlignOT by Riai and collaborator. And collaborator that are in the audience, I believe. And the y-axis shows the recovery error, and the x-axis ticks indicate the running time. Okay, so you can see that patient optimization makes sense in terms of having a relatively short running time, but also finding you the right 3D rotation with a small error. With a small error. Okay, so before summarizing, let me just mention that the tools I presented today, many of them are already in SPIRE or to be included in InSpire. This is a software package for algorithm for single-particle reconstruction that my group has been developing. It's now available as an open source Python code. So you're all encouraged to try and give it a chance. It's really meant for. It's really meant for people like you, for method developers rather than prior and practitioners. So, people really want to come up with algorithms and develop new methods and give them a try. So, to summarize, I showed three examples, two genetic analysis to the classifications with the alignment from prior analysis, with non-Euclidean metrics, like Wasserschine distance and related distances, aquifer from Euclidean distances. While no statistics suggest optimality of Euclid, Statistics suggest optimality of Euclidean distances. The underlying signals in CrowEM, meaning the projection images or the 3D density maps, are better compared using non-Euclidean distances. And that's why we see those methods to outperform Euclidean distances. And there are more applications and other metrics that I did not discuss today. This was still work in progress and also I did not have time to discuss today. So thank you very much and apologies. So thank you very much and apologies again for being late. Hi, Amit. So yeah, thanks for the talk. Do you have any insights on how the EMD stuff that you have compared with the W2 matter time distance? So, yeah, so the issue is that with W2, it is very costly to compute, especially if you want to compare many pairs or even deal with the volume. So that's why we are not even using W1, we're using an approximation of the W2, of W1. And with what we've seen when you run like the when you have the time to spend on actually computing the W2, W1, they perform very similarly to each other and to the approximation. So we didn't see like a huge benefit of doing the very exhaustive computation. I was just wondering because you showed this nice picture. Because you showed this nice picture of the comparison between the linear and the earth movable distance, showing that the landscape was different. So, I was just wondering if you would get something that could be wider or not with the W2. So, like I mentioned in the result, both W1 and W2, and more generally, W and WP. Module in W and WP, they all have the same robustness to the rotation angle or the angle between the viewing directions. So you expect it to perform relatively similarly. And there could be other metrics that will have the same property. So it's nice for us to think about Vasset Shantism because they have all these nice properties. Them because they have all these nice properties and really the nice mathematics around them. But there could be other metrics that have the same nice properties and maybe they can be computed even faster. You described a nice k-means algorithm. I was wondering how do you pick the initial C for k-means algorithm? Yeah, so so one stupid way to do it would just to pick K images randomly.