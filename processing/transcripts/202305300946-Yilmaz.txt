Siblings is a sibling of Red Hoon and myself. He will talk about stochastic homogenization. No comics viscous viscous Hanantonia Kobe equations in one dimension, which we talked about in this sit. Right now we are coming to viscous. Right now we are coming to business. Thank you. It's great to be here on this beautiful location, the special occasion of Timo's 60-something birthday, but the number doesn't matter because Timo doesn't really age like the rest of humanity. Forever 60. So, yeah, I also. So, yeah, I also thank the organizers for putting my talk right after Freylun's because it's going to be a nice continuity. So, this is the main result is joint work with Elena and Andrea Davini from Rome. But before I get to that, I'd like to just try to orient you in higher dimensions. So, this is like a general kind of Amazon-Jacobi equation that I'm going to be interested in. Right now, we're in any dimension, but we're going to go with dimension one. Any dimension, but we're going to go to dimension one in the second half of the talk. So, this here is a second order, as you see. I have some second-order term here. This is trace, and this is the gradient of U, the enter is after the signature of Hamilton-Jacobi equation. And so, this A right now is a non-negative symmetric matrix. And this H, for now, just assume that it just grows sublinearly. That it just grows sublinearly in P, that's the kind of condition you need so that you can talk about, you know, solutions, well poseness, and such. You need a little bit more, but I'm not going to get into it. And so, yeah, the so-called Hamilton-Jacobi equations, because the first instance of such equations appear in the work of Hamilton and Jacobi in the 19th century. And you can have like a constant here, or instead of a time derivative, you can have zero constant, so that's what we call a static version of the equation. We call a static version of the equation. And more generally, these kinds of equations appear in optimal control. So if you're taking soup over some pats, so there's an action. So just like in Fredo's talk, we saw some formulas like that soup over something with the Lagrangian. Now, but if you just do optimal control, you get actually this A would be just zero. So it would be what we call an inviscid equation, first order equation. Call an inviscid equation, first-order equation. So now, and in those cases, that you remember from Finnish talk, H is convex. Now, if you want more general H, which I do, if you want non-convex, then you have to have an inf soup over some paths. So you have a two-person differential game. So, and in fact, for any H you give me, I can write a differential game that for which. That for which the so that this is the Bellman equation, optimal control, and this is the Isaacs equation in differential games, gives you any Hamilton Jacob equation of this form. Now, if you want A to be the matrix to be not zero, so second order equation we call a viscous Hamilton Jacob equation, then you have to go to stochastic optimal control or stochastic soup expectation of something or influence. Expectation of something or in sup expectation. And expectation is like over some diffusion process, etc. And what we will do, we will stochastic homogenization, which means that just like Ray Dun did, we will put ourselves in this random setting where the Hamiltonian and the diffusivity, they're both stationary robotic stochastic processes. Okay, so there is some underlying randomness, that rule omega. Okay, that functional rule omega. So, going to homogenization, so we'll zoom out, which means we'll scale things by some epsilon. So, wherever you see explicitly x, remember this diffusivity and the Hamiltonian. So, I'm going to put x over epsilon wherever I see x. And I want to also point out that this is the equation that we're going to study. I also put epsilon here, okay? And note that the Hamiltonian depends on the gradient, right? It depends on the space, it's random. It depends on space, it's random, but it doesn't depend on T in my talk. Okay, so it's going to be different from, for example, Yuri Bachin's talk or different from KBZ. So this is like there's no explicit T dependence. And so as epsilon goes to zero, does this Hamilton-Jacobi equation effectively become a simpler Hamilton-Jacobi equation? That's the question of homogenization. Now, why do we expect this? Because epsilon goes to zero. Epsilon goes to zero, you hope that this just goes away. And then, and then, you know, I have stationary ergodic condition, and so is x over epsilon, so it's going to be some kind of averaging, you hope, right, that's going to kick in. And then, so at the end, you want this to be replaced by some kind of average quantity, some effective quantity that no longer has any spatial dependence and is also not random because regular disity has to hold. And if so, what And if so, what is this h-bar, which we call the effective Hamiltonian? Okay? So the question is: can you give me a formula for it? Can you tell me properties of it? Well, that's the main question we have. Now, what does it mean for this equation to be effectively to become that equation? So, precisely, I don't want to get into details, but you take any initial condition that is uniformly continuous and that. Uniformly continuous, and then due to some of the assumptions we make, the equation that we have with the epsilon and the effective equation that can with it, they both have unique discourses solutions with that initial condition. And you want, okay, so the same initial condition, and you want to show that, yes, for any initial condition you take as uniformly continuous, you have this convergence locally uniformly for P almost every omega. Okay, so this is one formulation, I say probably the most standard at this point. Probably the most standard at this point. You could also ask me convergence in other ways, you know, L2 or whatnot. Also, I want to emphasize that I'm not going to be asking how fast this convergence is happening. That would be a question of quantitative homogenization. So Jessica's talk will be on quantitative homogenization, but here it's all qualitative. Okay, so here's a strategy, the classical strategy to prove homogenization. prove homogenization. What you do is remember here I had a u sub t. I replaced it by a constant lambda. And then instead of u I'm now calling the solution caps left. So caps left, I want this to be a solution of this static Hamilton Jacobian. I also squeeze the P here and I need an assumption. So suppose that for any P that I squeeze here, there's a lambda and there's a capital F that solves this static Hamilton Jordan equation. Static Hamilton J-Coul equation and the capital left happens to be sublinear in x as x goes to infinity. We call this hublinear corrector. So in this case, what happens is if you make this assumption, then you actually can write down a u superscript epsilon like that, okay? That solves that. Solves that, the original Hamilton Decode equation. You can just basically see this because you see, remember in the original equation, I had the time derivative here. Well, the time derivative is exactly that lambda. And then, you know, when you take the gradient, you get p plus the gradient of f. Well, that's right here. And then, you know, in the second derivative, this doesn't matter. So it just checks like that. It's just a simple observation. Once I make this correction. Now, so it's called the corrective because this is kind of the naive thing, and this is correcting that. So, what about when t is equal to zero? Oh, the initial condition is like p dot x plus that corrector, but with epsilon is small, the corrector is like a small thing, causes some linearity. And as epsilon goes to zero, that thing drops, right? So you actually get this. So you actually get this linear in T linear in X function. So we have this locally uniform convergence. And then you say, oh, this U bar, I call this U bar. A U bar actually solves this Hamilton Jacobian because you look, the left hand side is just lambda of P and the right hand side is lambda of P. So it looks good. So it looks good, except that the initial condition of this guy is just p.x. This was not quite p.x, there was a slight discrepancy. But using some comparison argument, you can fix that. And then you conclude that, oh, we have homogenization. And in fact, this lambda, right, this lambda that you have in the assumption gives you the effective Hamiltonian. And then after that, you can generalize this uniformly continuous initial data. Continuous initial data. Now, so this strategy works when the diffusivity and the Hamiltonian are periodic in X. So then you're in a torus, torus is compact, and you can prove that the strategy works, the assumption is satisfied, and you can move forward. This was done by Leon Scroponika Varadan in the periodic study, okay, when A was zero, so in first order, and it was generalized by Craig. And it was generalized by Craig Evans to do a viscous setting. Now, but what if it's not periodic? So then this doesn't quite work directly like this. This classical strategy doesn't quite work. So, but good news is, okay, there's another line of work that's very important. That is when h is convex in this gradient variable, okay, in the velocity variable. Okay, and the velocity variable that Raden called. So, in this case, you have these papers in which homogenization was established, first in the inviscid case and then in the viscous case. So, what happens is, what's the advantage when it's called remember? I can have an optimal control or stochastic optimal control representation. All these papers actually use such representations and then they analyze these representations, these formula, using either subtitle-recollic theorem or Lie Geriation techniques. or large variation techniques and then we get a radiational formula for the effective Hamiltonian. As I said these approaches bypass this they don't show that for every p there is a sublinear corrector and then lambda. In fact there isn't. Okay, so there are p's for which there isn't. This isn't the case. So this the classical strategy cannot go through as it is. Okay? And now as Okay, and now a special case of the, of course, the convex Hamiltonian would be just take quadratic, you can take a linear like that too. This is the kind of original Hamiltonian that you would encounter if you study quantized deviations of diffusions in random environments or quasi-free energy of diffusions in random potential and in that context the sublinear correctives correspond to Bozzmann functions. Correspond to Boostman functions, which have already been mentioned several times in this workshop. Now, if the effective original Hamiltonian is not convex, then things are much more difficult. We don't have a control representation. We'll have a game representation, but that's difficult to work with. Difficult to work with. But nevertheless, there are general results in dimension one, and the rest of the talk will be devoted to those results. Now, there are some positive results in higher dimensions. So, for example, if H is not convex, but if its sublevel sets are convex, so I I call this quasi-convex. There are several camps in the world of math, what they mean by quasi-convex. So here I mean the sublevel sets are convex. The sub-level sets are convex. In that case, in this inviscid setting, there is a result. There are some special classes of rotational invariant Hamiltonians. I'm not writing all the conditions, for which homogenization has been obtained, has been established. And also, if H is linear on every ray, you know, some condition like that, then there is another work when this is actually in the. Work when this is actually in the iibiscous setting. So, apart from these special classes of non-convex Hamiltonians, you actually don't have a general result. And for a very good reason, because actually there are counterexamples to homogenization in higher dimension. Yes. Maybe I missed, but what does convex mean? What variables do you look at? In P. In P. Or just P. Yeah, just P. And in X, it's like a And in X, it's like a stochastic process that is, you know, just like, yeah. So, counterexample originally due to Ziliotto in the university setting, where he constructed, gave a two-person differential game in a slowly mixing environment, and H was actually a settle point, and that's kind of where the interplay happens. And you, you know, is able to show that there's no organization. And then, this further was. And this further was elaborated on and developed in various other papers, but that's the essential idea of the same. So that means we cannot have a general result, homogenization result for non-convex. Now, so from now on, the second half of the talk, I will take d equals 1. I will not make any periodicity assumption. Why? Because we already have homogenization in that case due to Neosponikovara. Due to the also Ponyhole-Varzan and due to Evans, right? Not going to make any convexity assumption because we already have the results. So I'm just going to do something different, right? And I take t equals 1 because I can hope to get a general result in that case. So what I will do is, so I've just wrote the equation back here again. Okay, now we're in dimension one, so there is no need for a trace or something. No need for a trace or something in one dimension. Okay, this is just a good old derivative now. And I'm going to also assume that H is separated like this. Remember in Freightlin's talk 2, we had Hamiltonians like this. This is like already super rich class of Hamiltonians to work with. If you understand this, you're essentially done. I would say. I guess a subjective statement. So this G is another. Is now a superlinear function that is, you know, imagine like this. So I can always make it zero at zero by just some simple transformations. Okay, so this is g of p. So it's really not convex. Okay? It can have as many bonds as you want. It's quite general like that. Oh, superlinear so that you have some well-poseness of the so you can have there's a unique resource solution, there's a comparison principle, like kind of stuff. Comparison principle like kind of stuff. So, you know, some assumptions like the local ellipsoids, but really, just keep this picture in mind. And the potential, the potential is a stochastic process that is supported between 0 and 1 because I'm going to put a beta here, so I'm going to tune that. So just keep it between 0. And it has full support. And it has full support between 0 and 1. Okay? So full support. The Ethereum is 0, so between 1, like that. Any separated thing, you can actually write it like this with some simple transformation. So there is no loss of generality. Okay. Some continuity assumptions and then beta is just the tune, the amplitude. The boundedness of V is no? So I I we need the we need V to be bounded, yeah. We need V to be bounded, yeah. So, um, you know, it would be different qualitatively. I'm not saying it would be, you know, probably you could still prove stuff, I don't know, I haven't thought about it, but the qualitatively the answer would be different. Yeah. Would be like maybe degenerate kind of result, maybe. Maybe it wouldn't be too interesting. I mean, under the assumptions I'm going to make. Yeah, we'll see. It doesn't depend on T. Yes, again, again, just, yeah. So that's very different from KPZ. So that's very different from KPZ in that result. Okay, so here's a general result by Armstrong, Tran, and Yu. In the first order, in the inviscid case, in this generality, there is homogenization. And the effective Hamiltonian, okay, remember this the original Hamiltonian is this plus that. The effective Hamiltonian has some flat pieces, even though this doesn't. Okay? And so you get a picture. And, so you get a picture like this, okay? And wherever the effective Hamiltonian, the graph, is not flat, so there are some flat pieces. Outside of those flat pieces, for every P, there is a sublinear corrective. So remember the original scenario, the ideal scenario, for every P, there is a sublinear corrector. Now, for every P outside the flat pieces, there is a sublinear corrector. So that's kind of a compromise like that. Okay. And then once they And then once they proved it, Gao, who was a student of you, generalized it to non-separated Hamiltonians like that. Okay, so here's the main result of the talk. As I said, it's joint work with Andia Davini from Rome, Elena. It's just on the archive a couple of months ago. So if this time taking A to B positive, okay, so less than one, but that's not, you know, so that's bounded like that. Bounded like that. And I have an extra condition here: if the pair AV, which is diffusivity and the potential, satisfy the scaled Illinois condition, so stay tuned for that, then we have homogenization. Of course, I'm going to tell you what this condition is. Okay? After that, qualitatively, the conclusion is the same, that the effective Hamiltonian is constant on some intervals, and outside of those intervals, you have some linear coefficients for every t. Corrector for every p. So the same qualitative picture. So now, what is this Hill and Valley condition? Historically, we first have the regular good old Hill and Valley condition, and then there was generalized. Okay, so first, what is the regular Hill and Valley condition? So in the potential, so it's the regular Healer-Mallet condition just constant. So it's the regular Hill and Valley condition just concerns the potential, doesn't concern the diffusivity. So you basically set any height you want, any height h, and any length y, and you want the probability that the potential stays above this height. So it has a hill, L has a long hill. So you want this to have positive probability. For any height and any y you give me, Height and any y you give me, for each has to be positive. I don't need a lower bound, like a, it can be as small as you want, as long as it's positive. Okay, there's nothing quantitative about it. Okay. You have some translation invariant. So it's stationary ergodic. Yeah, translation invariant. So this property, I'm going to talk about this implications, but first of all, this property holds for anything that you can construct with some kind of That you can construct with some kind of, you know, imagine some kind of diffusion or something, just like as an decimal generator. Imagine you construct anything, as long as it's nimble, right? As long as it can kind of go through tubes. I don't care how small the probabilities, right? So, you know, so I'm not particular on that. But for example, take double-lick effect Laram-Brownian motion and modify it so that it's like Lipschitz or something, and it will stay inside this tube, right? Now, of course, if you take a rigid example, like a periodic potential. Like a periodic potential, it's not going to work, right? But in the periodic case, we already have homogenization. So we're trying to do something complementary to that. Okay? So by iodicity, like as just stationary in a translation range, if you have this, that means whatever heightened thing you give me, then that means somewhere, right, I can find this variable visit. Okay? Very good list. Okay? And similarly for valley, any bar you set a certain length, I can find a valley. This is happening, like that. Okay, now, what is the scale-deal and value condition? It says any height, for example, Let's Aqua Hill, any height you give me, any height you give me, I can find a I can find a hill like that, and the length of the hill, you know, for any length you want, I can find a hill of that length or larger, but now length of the hill is measured like this with this scale. Why? Because it appears in the equation. And remember, A is between 0 and 1, so that means even if something is short in the Euclidean sense, it In the Euclidean sense, it can be long in this sense. Okay? Like, like that. So, this is like a weaker condition. It's easier to be satisfied, right? You know? And they're not equivalent because A can be getting arbitrarily small. So I can really have something tiny Euclidean-wise, but it can be long in this scale. But of course, if A is bound away from zero, then they are equivalent. Okay, uh so and there's one thing else I want to point out is you know if A is zero then this is infinity, but this is trivially satisfied. I mean there's a better way to write this but okay so it's easier. So basically this condition that we have vanishes was trivially satisfied in the invisited case. So I want to go back to our condition. So you remember if you take the statement of our theorem okay and if you Okay, and if you just in the statement take a to be zero, even though it's not covered by the theorem, this disappears, and you get you recover actually the statement of the inlicit result by Armstrong, China, and Yu. So in that sense, our theorem is a viscous analog of Armstrong tan and U. We have this condition which vanishes in the inviscid case. Which vanishes in the invisible case. But of course, ideally, we would like to remove that condition altogether, and that's exactly what we've been working on. You know, we're working on currently. But really, without rebounding the condition, like having this condition, still have fairly general results, because as I say, it's a very natural condition from the perspective of stochastic processes, and also it's a very natural condition to mention here. It's weaker than the previous. Yes, yes, it's weak. This is Rundle, I think, called Mount Rundle. Okay, so I want to briefly mention some previous results that we have obtained with special choices for G. For example, if G is like this, so this was the first example, it's a two-parallel. The first example, so two parabolas like that, then actually there is a stochastic optimal control problem we can write that corresponds to this, but it's a risk-sensitive stochastic optimal control, which means that is an expectation of exponential of something, and then you take a log. So it's not a linear thing. So there's that non-linearity, large deviation kicks in, so you have like a kind of a Riodon's lemma, like you know, so it's like a it's almost like a game. So, it's almost like a game. And in this case, you can actually solve this control problem. So, we have done this with Offer in the context of control random walks, and then with Elena and Offer in the continuum setting. And then this is where the regular Hill and Valley condition was introduced. And I want to say that the sublinear correctors, remember, so the So, the picture, so outside of the flat pieces of the effective Hamiltonian, right, there is a salt linear corrector. So, in this case, you know, typically you obtain the effective Hamiltonian has a graph like this. Depends on the beta or something, but imagine like in some regime, like, you know, so either it looks like that or it looks like this. This is what the effective Hamiltonian looks like. This is at height. Looks like. This is at height beta. Depends on what beta is out compared to the C that I have here. You have these two pictures where they take this Hamiltonian. And so in these non-flat pieces, for every P, in these non-flat pieces, there is a sublinear corrector. And so we have a really good understanding of this effective Hamiltonians. But these sublinear correctors, wherever they exist, they have explicit representations with control expressions. Control expressions. Okay, so I want to emphasize that because so I can easily show that there is no sublinear corrector that would have stationary gradient or stationary increments. Now, if you relax that, I can probably cook up something that will fit the definition. So, yeah. So, yeah, thanks. That's a bit more rigorous to say, but yeah. So now, so this result was generalized by Andrea and Elena to this kind of original G, where it's piecewise convex, but there is no symmetry, but they have a condition that all the minima have to be the same. So why something like this? Okay, so why piecewise convex, all the minima the same? Because then they could use a result, a general result about the existence of subliminal. Result about the existence of sublinear correctors that is due to Cardi against is actually in any dimension, and this uses this piecewise complexity. And this result is actually an adaptation of the proof of data sub-Bushman functions in FPP by Dammer and Hampson. This is a result that I think many of you have heard. So it's really once you have this piece-wise convexity, you know, you can just kind of use this off the shelf, so to speak, but you still have to work with it, of course. And then to get the flat pieces, Get the flat pieces, they had to make this assumption. Okay, so then I was wondering: like, okay, can we do anything with something that's not piecewise convex? You know, so that was the first example that comes to mind, something that is decreasing and then increasing, but not convex. So, I call this quasi-convex. Okay, so the sublevel sets are integrals. So, now in this case, the question is: okay, This case, the question is: okay, how do you get the existence of sublinear collectors wherever they should exist? So, in the next couple of minutes, I'm going to show you general outlines, like our strategy where it works for when G is like that, and also when G is like this. Okay, so the same strategy, but of course, the implementation is different. So, look at the static Hamilton-Jacobi equation. Remember, I fixed a lambda here. Jacobi equation. Remember, I fixed a lambda here. Now we're in 1D, so it's F double prime. P is was squeezed in here, right? This is the equation. Now, recall the classical strategy due to Leon Spapo Nicole Avarda, right? So suppose that for every P there is a lambda and a sublinear F that solves this. But as we said, this is not valid, right? So, you know, okay, with that kind of fine print, okay, at least. Now, but I can just call this little F. I can just call this little f and then this becomes f prime. Okay? Then becomes like first order OD. We are in 1D, so we want to take advantage of that. I'm going to tell you something, very 1D. So now let's just restate this assumption here. So suppose that for every P there is a lambda and a little F that satisfies ODE and integral of little left. integral of little left grows like linear like p. Why? Because remember, this was sublinear, so the integral of this will be growing like p. Okay, so I just translated that condition. And as I said, this is not satisfied. So here is the relaxed version. Okay, so this is the relaxed version that for every p, suppose that for every p, there is a lambda and stationary. And stationary ergodic, F underline, F overline, not necessarily distinct, they can be the same, in which case you're back here, or they can be different. They solve both ODE, they both solve the ODE. They get arbitrarily close to each other, and instead of, and this will be the expectation, right, because of regulatory stationarity, instead of having exactly equal P, now we have two of them, they straddle P. Okay? So that's the relaxed strategy. Strategy and this weaker assumption. Okay, two things to be done. You have to first prove that this weaker assumption still implies homogenization, right? And two, you have to show that this weaker assumption is actually satisfied. So this weaker assumption, how does it still imply homogenization? You see, remember, when we just had one F, you integrated that and you obtained this. And you obtain this, and then you add it to that, and you got a solution for the Hamilton-Jacobi equation. Now, because these two guys get arbitrarily close to each other, I can jump from one to the other whenever they get close to each other. I can integrate that, and this way actually I get approximate viscosity sub-solutions and super solutions, the way it depends on how I jump, which direction I jump. Then use the comparison principle that it goes through. So you get homogenization. True. So you get homogenization with this effect on Hamiltonian. And you also get a nice bonus feature, which is that if these things are distinct, then the expectations are distinct. And actually, you show that you see that effective Hamiltonian is exactly flat on those parts. So this is the characterization of the flat pieces of the effective Hamiltonian. So, of course, then the question is: okay, is this weaker assumption valid? Right? So, what do you need to show? So, what do you need to show? You need to show that for every p, there is a lambda, stationary ergodic f underline, f overline, not necessarily distinct, just recapping. That solves this ODE. Now I moved around the ODE, so it looks more familiar like that. And they get arbitrarily close to each other, and the expectations are straddling are straddling P. Right? So why is this true? Why is this true? So, what needs to be done, and this is the technical part of the works, is that you're going to have to study global solutions of this ODE while you're looking at various choices for lambda. Locally, this uniqueness is no problem, right? But is there a blow-up? So you need to find the range of lambdas for which there is no blow-up. You have global solutions. Like from minus infinity to plus infinity. You need all the way. And then. And then, also, okay, then okay, I have global solutions. Then, what are those F's? What are the expectations of those F's? So, what you're doing is you're really building the effective Hamiltonian level set by level set. So, imagine this. Remember this case, for example. I'm going to just illustrate in this quasi-commiss case. So, you're really building this level by Really building this level by step level set. So, this picture you get, which I'm going to draw, is relatively simple when G is quasi-convex, but it's more complicated when G is like this. But nevertheless, it goes through and we are able to completely construct the effect of Hamiltonian. And I want to say that the flat piece, so this is like, for example, in this case, For example, in this case, you get an effective Hamiltonian like this. Okay, this is not quasi-convex. You get a flat piece. What happens is like, this is at height beta. For any lambda you pick above, you have an F that works like a charm, has expectation P, or you have another F with this expectation. But when you're down to this height beta, you actually have these two things that get arbitrarily close to each other. To each other, and the weaker assumption is satisfied, and you get this flat piece. And this thing is exactly where the scale-Hill and Valley condition is used because it basically, so the Hill, for example, means that lambda is beta, V is like 1, so this is all like 0. This is all gone, okay? The whole thing is gone. So you really end up in that hill, you end up like F prime equals scaling, negative G. Negative g. And because of the sine of g, you're able to see that you have these two solutions that are both like kind of in the middle of a long hill, they get arbitrarily close to each other. That's how this condition, the scale hill and valley condition comes in handy. Now, of course, in a half an hour talk, I can't really get into more details. In particular, I can't really explain to you the picture we get in this more complicated setting. So I'll just stop here. Thank you for your attention. Thank you for your attention. And cheers to you. Any questions? So the effective Hamiltonian is what would be the dual of the shape function, right? Analogy would play. Last class, I'm sure. So the effective Hamiltonian, so for example, large deviations, right? So it's like the The quite free energy. Yeah. I'm just thinking that these flat spots should correspond to corners in the Legendre transform. Yeah, the Legendre transform. And then that's where you get the left and right, like which ones there. Yeah, the discrepancies. These are the two. Yes, yes, these are the two. Yes, these are the two corners. Yes, these are the two corners. You mentioned that you need some sort of time evolution, CKBZ. But I mean, if you looked at a two-dimensional problem, one year the two space dimensions would be so from a probabilistic, so you need to have some kind of directed, because from a probabilistic perspective, what I told you about. From a probabilistic perspective, what I told you about the scale-development value condition, I told you how it comes in handy when you look at it from the ODE perspective. But from a probabilistic model, if you have a particle, like a control problem, if you have some area where you have a hill, if the particle can kind of go there and hang out there, and there is no mechanism that pushes it out, like some directiveness, then you're gonna get a very different answer qualitatively. So you can have a 2D thing, but as long as something is pushing it. Something is pushing it. It doesn't have to be perfectly directed, but some kind of drift, some kind of like, otherwise it's going to just stick around in that kind of hill. So you can prove that in the flat spot, other than these two, there isn't any vector that corresponds to the Can we prove something like that, like a couple of years ago, remember, in 1D with like uh in the In the yeah, for our yeah, for the you know one beat RWA kind of you know I can find the pardon notes in Dropbox Yeah, so yeah, there's no stationary in general yeah with the with the extra assumption that with the you know that is station but you if you want something with stationary increments, yes, I'm pretty yeah, I'm pretty sure that yeah, the answer is no. Sure, that the answer is no. Yeah, yeah, yeah. In the periodic case, yeah. For periodic case, you have for every, but in this, under this condition, yeah. The periodic case for every p, right? That's the classical thing. Yeah. Stationary rather than ergonomic as well? For the non-existence? You don't have to. For non-existence, if you just stay stationary, yeah, I'm not, I don't wanna say something firm, but I, yeah, probably, yeah. But I yeah, probably yeah, it's looking enough, I'm assuming for sure I mean yeah, I could probably just since we have this relaxed strategy, I didn't bother, you know, like because we don't need you know these things in the in the middle. Yeah, but don't you uh use the one on what you construct and build things in or not or not? So I think so yeah but but you see but you see they don't actually touch so you have to do a jump so you get you can get approximate but and it's also you get inequality so you get actually subsolutions you get approximate subsolution approximate supersolution but that's enough to pass through so that's why we don't have to be too particular about you know what's exactly happening we bypass all that Let's let's thank the speaker again. And we'll resume our class. Oh, 10:45. Okay. What at 211? Extra randomness on the state and now I choose random. 