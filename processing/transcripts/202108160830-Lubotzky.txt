If the distance between the commutator of A and B to the identity is less than delta, then there exists A prime and B prime in the symmetric group such that the distance between A prime to A and the distance between B prime to B is less than epsilon and A prime. And A prime and B prime, the commutator of A prime and B prime is trivial, namely they are truly commute. I mean, I'll define the metric in a second, but I want to stress that you can really make this definition with respect to various different metrics. But it basically says the following: if you have two permutations which nearly commute, which almost commute, With almost commute, the commutator of them is not maybe exactly the identity, but it's very close to the identity. Then, how do you get such permutation? Of course, one way is to take two permutations with truly commute and just, you know, deform them a little bit, then they will almost commute. This is the converse. This said that if you have two permutations which nearly commute, then they are not. Commute, then they are near commuting permutations. The metric, kind of the natural metric to use here, but you maybe can suggest your own, is that the distance between two permutations is the normal nice Aming metric, which means one over n, the number of i in the set one up to n, such that sigma of i is different than Is different than tau of I. This is the normalized matrix. And as I said, the theorem said that if two permutations nearly commute, then they are near permutation that truly commute. This is a non-trivial theorem. I mean, in fact, the original proof is using some model theory, etc. But let me not go into that. I will I will say a little bit more later on, but let me. What should I do? Oh, okay. Why they got to be interested. They have a very interesting introduction to that paper, and they said that they were really inspired by a long tradition in mathematical physics. In mathematical physics, it has been studied. It has been studied for many years the following problem. Assume you have two n by n complex matrices, matrices over the complex number. Usually you ask, sometimes you say any complex matrices, sometimes you say that they satisfy some property, namely you take a self-adjoint matrices, you know, physicists may. Know physicists maybe want that, or unitary matrices which almost commute. Okay, what does it mean? Almost commute. Almost commute depends on the type of norm you take on the complex matrices. Now, there are many different norms you can take. The Hilbert Schmidt norm, it should be written Hilbert Schmidt, the Hilbert Schmidt norm, operator norm. There is P-sharp. Norm, there is P-schachter norm. There are various operators, a norm which people in function analysis are interested. And the physicists and some mathematicians were inspired by that, were interested in the following problem. Assume that they are nearly commuting with respect to this norm. Are they near? Are they near with respect to the same norm matrices which truly commute? And there are many papers on that. And the answer, by the way, depends on the norm and on the product. Sometimes you can say, if you have two self-adjoint operators which really commute, maybe I can correct them to commuting, but not necessarily self-adjoint. There are some results which say that with respect to operator norm, you can. With respect to operator norm, you cannot do it. With respect to Hilbert Schmidt norm, you can do it. I won't go to that because otherwise I will not have time for our group theoretical that. Now, as a group theorist, it's clear to us that when we see such a question, that we can generalize it and we can ask such a question, not just with respect to one equation of the commutator, but with a system of. The commutator, but with a system of equation, namely, let x be the set of variables, say x1 up to xd, let R be the set of relation, like if you want, think of it as equations, which are r i of x are elements of the free group on the formal generators x1 up to xd. And then you want to ask: assume you have. To ask, assume you have again, assume you have permutation which are almost solution for this system of equation, are there nearby true solution? So let's say that this system of equation is stable if, again, just the same thing, if for every epsilon there exists delta such that if I have a d Such that if I have a detuple of permutation in the symmetric group on n, and again, in deep, everything should be independent of n, such that the distance, the normalized Arming distance between R i of A and the identity is less than delta, namely these D tuple of permutations are almost a solution, then there exists Then there exists A1 prime up to AD prime in the symmetric group whose distance that the Aj prime is very is epsilon close to Aj. And these are true solutions. The Ri of A prime are really is really equal to the identity, not just almost equal. Now, the crucial observation which The crucial observation, which I think makes it at least interesting for me and hopefully for you, because this conference is really dealing a lot with actions on permutation, finite and infinite, but also connection with infinite group, is the following easy observation, but this observation is crucial, which appears already in 209 in a paper of Glebsky and Riviera in a journal, which I have to admit that I never heard about. I have to admit that I never heard about it before. It's called the Taiwanese Journal, it came up from Taiwan, and it called the Taiwanese Journal of Mathematics. And then they made the following and also they made it more or less. And then in the paper which of Golmara and Liviu, they kind of make it in a very formal and clear way. The stability of this. Of this set of relations depends only on the group gamma and not on the relation, namely. Let gamma be the abstract group, the finitely presented group presented by the generators X and the relations R. Then, and assume gamma as another presentation with another set of generators Y and relations S. Y and relations S, even not of the same size. Then the system R of equation is stable if and only E, if S is stable. Once you make this observation is not difficult to prove. It's the kind of observation that we know that the growth of a finitely generated group depends, does not really depend on the generators, etc. It's slightly more, but it's a half a page proof. And then you say that R is stable if and only if it's stable, which means that the stability is a property of the group gamma. So this is a group theoretical property of gamma, whether gamma is stable or not. So gamma is stable. We'll take it as a definition, if you want, that gamma is stable if and only if the relation. If and only if the relation presenting it forms a stable system of equations. And the observation said that this is indeed a well-defined definition. Let me say just very quickly that now I define for you the notion of stability for a finitely presented group, but you can generalize it to any finitely. Can generalize it to any finitely generated group, and if you really want to any group, but let's we will talk today only on finitely generated group. And the following will be the definition, which for it's a little exercise to see that for finitely presented group, it is equivalent to the definition I gave before. So the definition will be gamma is. Definition will be: gamma is stable if we ever, whenever we have a sequence of maps from gamma to the symmetric group N. Now, when I say maps here, I don't mean homomorphism. These are just functions. I have a sequence of functions from gamma to the symmetric group Sn satisfying that for every gh in gamma, the limit of the distance, distance is the The distance, distance is the normalized I'm in distance, the distance between phi and gh and phi and g composition with phi and h, the distance between these two elements goes to zero when n goes to infinity. So these are kind of an asymptotic homomorphisms. Every map by itself is not homomorphism, but if you look at them locally for every g and h, then it behaves. Then it behaves like eventually it's converging to be a homomorphism. If you have this property, then there exist homomorphisms, there exist true homomorphisms, psi n from gamma to sim n, which are nearby the starting homomorphism, the starting maps, namely for every. Namely, for every g in gamma, the limit when n goes to infinity of the distance between psi n of g and phi n of g, the distance between them go to zero. So again, if you have almost homomorphisms, they are nearby true homomorphisms. And so this will be the definition of stability. So now we can ask as a group. Is a group theoretical problem about groups, finite or infinite groups, when any group gamma is stable? Can we classify which group are stable? When the paper of Golnara and Liviu came up, there were only basically only three known results at the time that three groups are stable, which is are stable which is trivial right if you take the empty empty relations then then almost almost homomorphism of the three groups are nearby homomorphism finite group are stable this was proved by glebski and riviera and that's not difficult and as i mentioned uh the results for for commutator in fact they prove little uh it's essentially by the the same that every ability The same that every abelian group is stable. That's all what was known. At the time, it was not even known if you take an abelian group cross a finite group, whether the product is stable. And if you think about it, it's not so easy, because if you take a product of two groups, that each one of them is stable, then each one of them you can correct to be. Correct to be to homomorphism, but can you do it simultaneously in a way that they will continue to commute? I should mention that free product of stable group is always stable. That's easy. So from this, you can get more groups. But basically, these were the only cases for which it was known. But those two papers were very influential, at least on me, but I think on a few others, because Few others because especially the AP they presented many open problems, which most of them by now we can answer. But Glebsky and Riviera made the following observation, which was also gave, I think, a lot of interest to this subject. And this is the following observation. Assume Assume that gamma is a Sophic group. If you don't know what is Sophic, I will define it in a second, which is also stable, then gamma must be residually finite. So let's first recall the definition. I guess we all know what is residually finite. Let me repeat it in order to compare it with the notion of so. Order to compare it with the notion of SOFIC. Gamma is called residually finite. Usually we say if you can separate the points by homomorphisms to finite groups. But now I want to define it slightly differently, though clearly equivalent. Every finite group is a subgroup of the symmetric group. So I would say that the group is residually finite if there exists a sequence of homomorphisms. Sequence of homomorphisms psi n from gamma to the symmetric book such that for every g different than one, the distance between phi n of g and identity is equal to one for n sufficiently large. If you think about it, this is just the usual definition of Res-Dolly finite. Of Resdali finite. You know, you say you have an homomorphism to a finite group G, so that the image of little G is non-trivial. You let G acts on itself by, say, from the left. Then this little G has no fixed point because when little G acts on G by multiplication from the left, there is no. By multiplication from the left, there is no fixed point, which means that the distance between phi n of g and the identity is really equal to one, and this is, and you can arrange it to happen whenever n is sufficiently large. That's easy to see that this is equivalent to the definition of resolute find that we all know. What is SOFIC? Sophic was defined to start with, is a notion which was defined for the first time basically by Gronov, but Benji. Basically, by Gromov, but Benji Weiss responsible for the name and for developing the theory. And a group gamma is so thick, you can really reformulate the original definition in the notions of almost homomorphism that I defined in the previous slide, namely, if there exists MEPs, phi N, not Fien are MEPs, not homomorphisms. Not homomorphisms from gamma to the symmetric group such that for every gh in gamma the limit is the should be phi n of g h not y g h and phi n of g phi n of h is zero namely they are almost homomorphism but we also want that these maps now i have another requirement that these maps separate the point of the boo by this we Group by this we mean that for every g in gamma, the limit of dn, if g is non-trivial, then the limit of dn of phi n of g and identity is equal to is equal to one. Oops sorry, I didn't mean that. Now I am getting red from this now. Um oops. Do you see the proof here? Because uh uh on my on my screen there is something which cover it. I don't know. Yes, yes, we can see it. You can see the full the two lines of the proof. Okay, good. Okay, so I hope I know it by art. Oh, you can see it. Okay, I cannot see. I can see the first line, but not the second. So let me prove why if gamma is a SOPI group which is stable, then Group which is stable, then gamma is regularly finite. This is Glebsky and Riviera, and basically it's an observation. Okay, you have to write the full proof. It will take seven lines, but it's really clear. If gamma is a Sophie, what does it mean? It means that there exists a family of almost homomorphism, as in this definition, right? Almost homomorphism. Definition, right? Almost homomorphisms from gamma to the symmetric group. So they are not necessarily homomorphism, which separate the points of the group gamma. But if gamma is also stable, then you can approximate these maps Vn by homomorphism Cm. And you can see that if you approximate them, they're almost the same, then now you have homomorphism which separates. Now you have homomorphism which separates the points of the group gamma, and therefore the group gamma must be resonally finite. So that's very simple. If the group is tropic and stable, then it's resonally finite. Okay, so this is just a little innocent observation, but it's very inspiring. Why? Let's just read it in the opposite direction. Now, if gamma is stable and not Stable and not res dual finite, then it is not Sophie. Now, let me remind you the problem which is one of the most outstanding problems of nowadays. I don't know how to call it, maybe geometric group theory or a dynamic group theory or whatever. Anyway, it's one of the most famous problems in the theory of infinite, say, finitely general. Of infinite, say, finitely generate or not finitely generated groups is the following long-standing problem of Kromov and Weiss. Are all groups Sophic? Now, this always been an important problem, but it became much more important in the last decade because when it was defined, it was a question. Over the years, it turns out that there are many kinds of Long standing open problems in group theory and operate related to operator algebra related to some other subject like Kaplansky conjecture, etc., etc., which people prove, we don't know if they hold for all groups, but they all, the answer is positive for Sophic groups. So now it's really extremely important to know whether all groups are Sophie. But frankly, But frankly, because so many applications, we have so many applications that if Sophic is true, and so many other things, if a group is Sophic, I think that most experts now believe that not every group is Sophic, but we don't know, even for the Egman group, for example. Anyway, I will not talk. I will not talk now about, but there is a different subject which went parallel in the last five years or so. As I mentioned before at the very beginning, you can ask this type of questions, not just for permutation, but also for matrices, almost homogeneous unitary. Also, it leads to other open problems like Leads to other open problems like every whether every group is eperlinear, whether every group is MF, various open problems for values approximated, etc. Some of the problems have been solved in the last few years using this philosophy, but not the most important ones, like Sophic and Hyperlinear. Anyway, I will tell, so the rest of my time. Oh, I see that the time oh i see that the the the uh um i uh i have to rush uh i want to give you a very quick review of the of a number of results which were proved in the last couple of years but before that i want to mention very very quickly i i plan to do it quickly now i see that i must do it very quickly some connection with pop with the computer sign and property testing in fact i i got attracted to the paper of uh of uh The paper of Valva and Ponesco, because I noticed the connection to property testing computer science that I was interested at the time for completely different reasons relating to error correcting code, et cetera, which I will not talk today. One of the deepest subjects in theoretical computer science, which has also a lot of practical applications, is the so-called property testing. Okay, I will go very quickly on. Okay, I will go very quickly on the formal definition of what is Q epsilon destability. If you have A is a finite set, and you look at A to the N, just the Cartesian product of A with itself n time, and you have to think of A is fixed, like A is the finite field of order P or of order 2, and N goes to infinity, and P n is a subset of A to the n. subset of A to the n the membership of alpha in P to the n is testable or sometimes you specify parameter q epsilon testable if there exists an epsilon and in R and Q in N and a random algorithm which is called tester which requires only Q independent of n coordinates of alpha you are allowed to read you are allowed Read you are allowed to read only a bounded number of coordinates from the vector alpha, and you need you want to decide whether alpha is inside, whether alpha has the good property, whether it is inside PN or not. Of course, you never can do it by reading only a bounded number of coordinates. A bounded number of coordinates if you want to get an 100% answer, which is always correct. But you want that the answer will be always yes, if alpha is indeed in Pn. But the answer will be no with probability proportional to the distance from Pn. Namely, you take the Aming distance, the normalized Aming distance from alpha to Pn, and you want to say that. And you want to say that if it's if it's, I may make a mistake and I may claim that it's inside if it's very nearby, but if it's far away, then with high probability, I want to detect it. Anyway, this is, I don't have time to elaborate this. Some of you maybe heard about what's called the PCP theorem, which is one of the deepest, if not the deepest. One of the deepest, if not the deepest theorem in current theoretical computer science. And it's all related to that. Anyway, let me make the following easy observation. Again, you have to think about it for a second, but I want to run. If there is a stability problem, you see, we will look, okay, it will be in a slightly different variation. We look at the symmetric group to end to the The symmetric group to n to the d we look at p to the n to be the set of true solution to the system of equations. And I want to decide whether my I want to decide whether the suggestion, somebody give me a vector of permutation, alpha one of alpha d. I want to decide if it is in a solution, but by reading only bounded number. Only bounded number of values of these permutations and still to give answer which will be with high probability correct. Then here is the algorithm. Choose the random i in n and don't check if they satisfy the relation. Only check if applying the relation to alpha one up to alpha. The relation to alpha one up to alpha d on i give you back i, right? If it's identity, it must give you i. So, if there are true solutions, it always will be S. The point is that if you will choose Q to be, if the group is, if you think about it, you see that if the system is stable, is equivalent to say that this algorithm with high probability will work. Will won't. And for example, the meaning of the theorem about commutation is that you want to check if two permutations A and B are nearby commuting matrices, then you just have to check if ABI is equal to B I to few randomly chosen I's between one between one to M. Okay, I Okay, I must continue, so I will not elaborate. I just make the observation, which is very similar to the observation of Glebski and Riviera, that the test stability of the relations depend again only on the group gamma and not on the relations. So we have now a mission, you know, we have a goal, and you kind of decide for groups whether they are state. Groups whether they are stable or whether they are testable. Let me, I will elaborate in a second. Stability implies testability, but for a while it was not clear if it's the equivalent, but it's not. If you want to read more on the computer science side, I will not really talk about it anymore. We recently put an update version to the Oren Becker and Jonathan Mosaev. Oren Becker and Jonathan Mosaev and I on the archive, you can see more on that direction. Anyway, from now on, in the last 15 minutes I have, I just will glance over a number of results. I prepared a little proof for one thing, but I don't know if I have time for that. Let me mention results. So, and what is interesting and nice that basically we are talking about a very simple We are talking about a very simple question. You know, you can explain it, the type of questions to every undergraduate student to know the definition of a group. But it took us to a journey to a various deep and interesting mathematics. So let me describe some of it. So let gamma be assume, say the first chapter now will be about stability and test stability. And testability of an amenable group. Let me recall: what is an amenable group? The group gamma generated by a finite set S is called amenable if for every epsilon there exists a finite subset of gamma which is almost invariant under S, namely the disjoint, how you call it, disjoint. How do you call it? Distant union SF minus F, union F minus S F is less than epsilon F. So like almost all the elements are, if you multiply them by S, are still in S, are still in F. You think about Z square, which generates epsilon E1 and E2. If you take a big If you take a big square around the zero, then it is almost invariant under F. So this is kind of the opposite than expanded. So in that paper, for example, we proved that every amenable group is testable. The proof is non-trivial. Other part is not difficult, but we use very deep results. We use the theory, the old theory. Theory at the old theory of Orange Ten and Weiss who study the action of amenable groups and they prove that it's kind of a dynamic ergodic theory type of results. And also they show that they define a kind of an hyperlinear, what's called a hyperfinite relations. And Eumann and Solder studied the testability of The testability of IPR finites for finite set. Anyway, we have to use fairly deep results in order to prove this result. But even maybe more interesting, to show you that there is some material, that there is not automatically everything is work, is the following results, which is a joint work with Oren Becker and Andrea Stone. This paper already appeared. His paper already appeared in Duke, like maybe two years ago, that a finitely generated aminable group is stable if and only if the finite index IRSs invariant random subgroups. I will explain in a minute what are these. The finite index IRSs of gamma are dense in the space of the gamma gamma gamma In the space of all IRS's of gamma. Now, this is an interesting story by itself because, in the last couple of years, there is a lot of study of this invariant random subgroup. So, what is an invariant random subgroup? An invariant random subgroup of a group gamma, gamma should be now a countable group, say. For us, it's always finitely generated. This is a problem. This is a probability measure on the compact space of subgroups of gamma. You see, you think of the subsets of gamma, the space of subsets of gamma can be thought of 0, 1, Cartesian product of 0, 1 to the gamma. You can easily see that in the standard topology, the space of subs, of subgroups, subgroups now, subgroups. Subgroups now. Subgroups of gamma is a closed subset of a compact space, so this is a compact space. Now you can define many measures of even probability measure on that space, but IRSs, invariant random subgroups, it is called for short, are those probability measures which are invariant under conjugation. The simplest example is if you have a normal sub. is if you have a normal subgroup of gamma, every normal subgroup of gamma define you a probability measure, take a measure which gives one on this normal subgroup and zero anywhere else. So this is invariant under conjugation. So this normal subgroups, if I knew a measure, of course, this is a very degenerate example of invariant random subgroup, but the invariant random subgroups. But the invent random subboosts were invented in order to generalize the notion of normal subboots. A famous theorem, which is a modern version to a theorem of Margulis. You know, Margulis proved that for higher rank lattices, every normal subgroup is a finite index. So it follows from results of Zimmer and Stark in the language of the modern language of these people who are studying this. Studying this that every IRS of these lattices is a finite index. What does it mean? A finite index IRS? A finite index IRS is a probability measure on the space of subgroups whose support is entirely on, well, at least measure one of it is on the finite index subgroups. And now another example of Now, another example of the basic paper which really invented all these subjects of IRSs, which gave the definition, some people, it became very popular subject. Some people say that it became popular because of the good choice of name, IRS, which America knows very clearly the meaning of it in the United States. Anyway, Abert and Yair Glasner and And Yair Glasner and Virak, who invented this or defined this notion, they proved that if gamma acts probability measure preserving on a probability space, then the stabilizer of a, you take a probability space with a probability measure tau, then the stabilizer of a random point is an IRS. And in fact, they prove that every IRS is like that. Okay, I don't have time to talk about that. Okay, I don't have time to talk about that, but I want to go back to the theorem. The theorem now tells you that a finitely generated amenable group is stable if and only if the finite index IRSs of gamma form a dense subset in the space of all IRSs. So suddenly, the algebraic question of stability. Of stability is becoming a problem in dynamic, or if you want, ergodic theory of that on a study in this space. And in the last couple of years, there have been a number of papers on that, and some of them can be useful for this problem. Anyway, even without this paper, from the results that we prove, the following follows very quickly, which Very quickly, which answers many of the questions which were asked by Gulnara and Liviu in that paper: that, for example, nilpotent groups are stable, polycyclic groups are stable. And I want to tell you, before that paper, it was not even known if an abelian group across a finite group is stable. And now we know that every polycyclic group is stable. The Baumschlux solitar group. A the boundslack solita group B1N is also stable. But a warning: if you want to go to jump out from polycyclic group to any solvable group, then that's not true. Not all solvable groups are stable. For example, in that paper, we show that the group which was Paper, we show that the group which was invented or presented, I don't know what one should say when somebody presents an interesting group, Abels, Herbert Abels, long ago, I remember it for my students' day, presented this group. I think he was interested to show an example of a finitely presented, a solvable group. Its center is not finitely generated. Anyway, this group is a solvable group, is the smallest group that we know. Group that we know, it's a derived length 3, which is not stable. The reason is that the center of it is not finitely, it has a finitely generated normal subgroup, which is not closed in the pro-finite topology. I don't have time to explain all this, but I just want to say that not all solvable are stable. And in fact, it's a major problem that we don't know to answer. Know to answer it is to characterize solvable stable groups and Dan Siegel. Uh, are you? Yeah, you still with us? Then this is a problem for you of the world expert on this type. Even to classify among the minimax solvable groups, which one is stable and which one is not. I don't know. I have a suggestion, but we can talk about it privately. Anyway, Anyway, there is something that I'm willing to. I don't know how to even suggest a general conjecture, but I'm willing to suggest a spatial conjecture that metabelian groups are always stable. Now, I want to mention the following remark, which I find very amusing and attractive, because if this is true, then this will be a significant straightening of the class. Straightening of the classical results of Philippe Paul asserting that every metabelian group is resolved final. Because you remember, these groups are amenable. I forgot to say every amenable group is Sophie. So if it's Sophie and stable, it is residually finite. So this will be a very strong form of resonaniteness. Those who remember the proof of Philip Paul, the wonderful proof we use algebraic geometry or more. Algebraic geometry, or more precisely, commutative algebra method. Now, for proving this, we probably need some dynamic ergodic theory to prove this straightening of the. So it will be interesting if this type of methods will come to the game here. Now, at least I failed to prove that every method. I failed to prove that every metabilian group is stable. I managed with RAV to prove that the lamp lighter groups, as well as many other metabilian groups, but not all, even I don't know whether the free metabilian groups are stable, but the lamp lighter groups is stable. But it uses delicate results from dynamics. It uses some work of Elon Lindenstrauss already from his thesis. Already from his thesis about dynamics. So somehow it took this type of question took us quite far. Oh my God, I have only two minutes, so I must rush. Yeah, so let me say quickly that the lamp lighter group gave the first non-finitely presented stable group, but parallel to it, Cheng also proved that the Gregorian Also, prove that the Gregorian group are stable. So, other groups, and short, and basically again, parallelly, I, Elevit, and I proved that there are uncountably many stable groups. All of them are amenable. All the groups we present are amenable. And other groups are going back to the old examples of Peter Neumann, Peter Neumann, and not Peter, Bernard Neumann, sorry, Bernard Neumann at the time. Sorry, Bernard Neumann at the time in the 30s shows that there are uncountably many two-generated groups. And in the 90s, Benji Weiss and I proved that they are all amenable. And now we apply the criterion. It still needs a work to show that they are stable. And Shen proved that uncountably many branch groups are stable. Okay, let me go. Me go one minute. Uh, I probably won't manage to do it in one minute, but uh, Alex, why don't why don't you, Alex, why don't you give yourself five more minutes? Thank you, thank you. Five will be enough. Thank you, thank you very much, and I really appreciate okay. So, now let's go, you know, in infinite group theory, a minimal group is kind of one side, the opposite side is the groups with Kajdam property T. Kajdam property T got a lot of publicity. Got a lot of publicity also because of application to expanders, etc. It basically says that every non-trivial, irreducible representation of gamma is bounded away from the trivial representations. And there is a nice colliery of that, which is easy to prove that any two finite-dimensional irreducible representations are bounded away from each other. Away from each other. And we, so, for example, example of group with property t are gamma, SL and Z. SL and Z, if N is at least three, has Kashdan property T. But SL2Z, which is a virtually free group, does not have property T. And the famous theorem of Kashdan is that all lattices and simple Lie groups of Iran have Kashdan property T, and with Oren Becker, we And with Oren Becker, we proved that if gamma is Sophic, now, for example, most groups that you meet in the street are Sophic, like every Hasdale finite group, every linear group is Sophic. So in particular, all these SL and Z are Sophic. If a group is Sophic N has cashdown property T, then it is not stable. Okay, unfortunately, it's the opposite. It's the opposite. And in that work with the computer science flavor, oops, what did I do? What did I do? Yeah. With Becker and Musaev recently, we show that it's also not testable. Testable is weaker than stable, but it's also not. If you know what is property tau, the same results all for property tau. Okay, I have a sketch of proof to show you that it's trivial. To show you that it's trivial. Let me finish, and then if I'll have a X, if I will manage to put it, then I will come back and show. No, no, I must show you that. Otherwise, the definition at the next slides will not make sense. So I will do it very quickly. Let me show you a proof for SL3Z based on an idea that we learned from Java. The group SL3Z, I want to show that it's not stable. Why it's not stable? Stable. Why it's not stable? It acts via its homomorphism to SL3P. It acts too transitively on the set X, where X is the pairs of one-dimensional subspaces of the three-dimensional vector space FP to the three. Now it's easy to see that you can always find a matrix or linear operator which takes any two. Which takes any pair like that to any other pair. And now it's known that if a group is acting on a set simply transitive, sorry, double transitive, then the induced representations on the zero sum, oh, here it should be sum, not epsilon. On the zero sum vectors, the vector we sum up to zero is an ill. The vector with sum up to zero is an irreducible representation. So, why is this relevant? Let n be the size of this set, and then let's do the following cheating. You'll see that this proof is a cheating proof. You take the set n, drop a point, drop a point, and now look at the same action of SL3FP on X minus a point. Of course, it's not an action anymore, but it's clearly an almost action. But it's clearly an almost action. Now, if the group is stable, then you correct it to a nearby truly action. But if you write down the meaning of that, it means that you will find a true action, a true representation in a smaller dimension, which are nearby this irreducible representation. Representation. But if we have property T, I told you that finite dimensional representations must be separated from each other. So this is basically the proof. But you see, okay, you have to do something. But you see that the proof is based on cheating. You say you have something which is really nearby an action. You destroy it by eliminating one point. And then you say, haha, this is not anymore stable because if I could correct it, I had to correct it with the I had to correct it with the n minus one points, and I cannot do it. I can correct it only by adding back that point. Anyway, this led us to the following definition, and I really wanted to bring it because maybe this definition might be more important than stable. We define in that paper that gamma is flexible stable if for every almost action on the symmetric group, like for almost homomorphic. Group, like for almost homomorphism, you can call, you can, it's nearby true action, it's nearby homomorphism, maybe not with the same n, but slightly larger n. Capital N is n times one plus little o of one. And while we know to prove that SLNZ is not stable, we don't know to prove that it's not flexible stable. Not flexible stable. In fact, I'll show you in a minute. We hope very much that it is flexible stable for a good reason. Anyway, the observation that Sophic plus flexible stable implies residually finite is the same as before. Frankly, up to now, we don't know any example of a group which is flexible, stable, and not stable. And I want to end up with the last slides with two with the following. With two with the following results. The first is the results by Nir Lazarovich, Arya Levit, and Yeir Minsky, who proved that surface groups, the fundamental group of Riemann surfaces, are flexible, stable. So that's a beautiful result with a beautiful proof. They brought in a covering theory from, you know, standard covering theory, but in a very clever way, related in a novel way to all this stability equation and managed to prove flexible stability. Flexible stability, we don't know if the surface group are stable. But even more interesting is the following very new results of Peter Bowen and Bowen and Burton. They prove that if they prove it for some reason, technical reason, if for some one n greater or equal than five, SLNZ is flexible, stable, you remember we proved that it's not stable. That it's not stable, but our proof does not eliminate the possibility that it is flexible, stable. If this group is flexible, stable, then there exists an unsoft group. This will lead to this most outstanding open problem that there exists an unsoft group. It won't be that group. This group is randomly finite. It's certainly solving. So that's kind of a very attractive direction and motivation to study this notion of flexible. To study this notion of flexible stable. Finally, I will mention a very last result from the last few weeks of Arya Levitt and Nila Zarov, which proved that virtually free group are stable. Why I mention it? I mentioned it in order to show you that you said, oh, come on, this must be trivial, because free group are stable in a trivial way. And we would expect that if delta is a finite index in gamma, then gamma is stable. If delta is stable, we don't know. If delta is stable, we don't know the answer to that in no direction. So you can see that there are many, many open problems still in this area. And I will finish here, and I really apologize that I went over my time. It's okay. Thank you, Alex. Thank you very much. Thank you.