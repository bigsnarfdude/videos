wonderful um uh workshop. Now my work is very very very very much related to this workshop because for a while now we've been very much interested in primarily flow networks, primarily in biology but not only. So I've also worked with on river related things with John but in general John. But in general, what we like thinking about is principles of topology in mostly living flow networks and how it correlates with function, how it correlates with adaptation, what type of developmental rules will allow you to make all of this crazy diversity of networks. Diversity of network patterns you see. Now, today I was planning to talk to you about a different kind of network, though, and I decided to change my talk because it turns out this might have much less connection to what you're doing, but I'm still gonna talk about it. But I first wanted to motivate it a little bit what this is about. So, this is a different kind of network. This is random walk, this is basically a This is a random walk. This is basically a random walk on a graph, and it's still a transport problem. So, let's do the following scenario, right? So, let's say this is the band generalized campus. You are here on the lounge, you had many beers, and you want to go back to your hotel, right? And you start taking the little paths and the little alleys here on this campus at random, and you start walking at random. And the question is, how fast will you reach your hotel room? You would say, Well, I wish that. You would say, Well, I wish that there was a direct link between the lounge and my hotel room because if I happened to take that at random, I would immediately be at my hotel room. Fine, let's build that link, right? But what about you had too much to drink at the restaurant at Lance and then you wanted to go to the lectures? The same argument, you did a link like that. So you continue. A link like that. So you continue this argument, and you'd think that if you are searching for something at random in a graph like this, you need to have as many connections as possible, right, to most efficiently reach your destination if you want to be democratic, let's say, if you want to average between all possible pairs of homes and targets, you can think of. So, this type of transport problem and this type of optimization. And this type of optimization, minimizing search time, will be the second part of the talk. But before that, I added a kind of big introduction about design and optimization of transport networks. So we've been talking a lot about flow networks. And even the ones of you that never cared to work about flow networks at all in your life, you probably realized by now in this conference that if you want to minimize this pay. If you want to minimize dissipation, let's say all of these links are your possible options, this is your source, this is your sink, the best way to do it is with a direct path. Now, if you have one source and many sinks, a direct path will be well, many direct paths, source to this thing, source to this thing, source to this thing, and so on and so forth. Now, this is not something we see in nature very well as an optimal pattern. We see this a lot. lot where in this case it this there is what we call economy of scale it pays to bundle it pays here to make a big link up to a particular distance and then use smaller links to send the load from here to here to this. Now this is something that has been studied a lot but again But again, this principle of economy of scale and branching is something we saw a lot in this conference. The reality, of course, is very different. We typically have a lot of loops, which is also in the name of this conference. So let me discuss a little bit about those loops. This is an old paper now by Bono and Manasco, and they discuss that if you have a cost to build the network, and if you have some And if you have some thing you want to optimize, like the dissipation, which is here, or equivalently for this type of system, this would be the average voltage drop, or if you're a plant, the average pressure drop, which is what plants care about. And if you consider, this little parameter gamma, which shows up in the cost, is how the conductance of each vessel scales with essentially the radius of the vessel. Of the vessel. I'm sorry, the cost, I should say, how the cost of the vessel, each individual vessel, scales with the diameter of the vessel. Then, depending on what a parameter is, for physiological gammas, which are for this type of parameterization smaller than one, you always get a tree. So, if you have a source here in every node of this network, Of this network is a sink. For large gammas, you get something like this, and for small gammas, you always get a tree. The trees are very, very efficient. An economy of scale basically means that as you go from smaller to bigger, if in this particular case you pay by how much wool you're putting in, here to increase your diet. Your diameter, you need to put more wall here to increase your diameter. You put more wall, but not much more wall, right? This gamma is smaller. You have more economy of scale, so you're more prone to make trees. However, trees are problematic. Now, I'm showing you movies that I made when I was a postdoc, which is so old, these movies are so old, I should be showing you to them in Sepia, right? From ancient times. But the kind of cool, and as I was discussing with Kevin, you need to show movies in the beginning so that people don't fall asleep, and this is the sole purpose. This is a ginkgo leaf. You punch the hole. There is dye, and you see here you don't have looks in this three network, these dies. This is the problem here. Again, I'm not telling you things you don't know. Here, this is a rose leaf. Rose leaf or a lemon leaf, I don't remember anymore. You do the same, you punch a hole, and you see how beautifully the loops do their job. And this is the one that I like the best because this is a monocode and in the beginning you don't see the loops, but if you repeat the same experiment, you see how it fills in because monocodes know that loops are useful for this purpose. So, again, in ancient times, we did this optimization. Times we did this optimization principle. You keep the cost constant for physiological gammas, what let's say the plants care about, and you minimize pressure drop, which is what plants care about, and you get things that look very much like dicot leaves, like modern leaves, zoomed out and also when you zoom in. Now, this whole thing was to connect cost functions, to connect optimization. Functions to connect optimization with form. And you can do the same for fluctuations. When there are fluctuations in the load, and we heard a lot about fluctuations, you get loops. But of course, things don't magically appear and they're optimal. They develop, they change all the time. And I love this movie, and you already seen it once. And I always saw this movie because I love this movie. And it turns out a lot of the next. Out a lot of the network and rivers as well development and evolution can be described by an equation like this, which tells you the rate of increase of conductivity of essentially width of the channel is a positive function of the flow. And this is a stabilization term that says if you don't use it, you're going to lose it. And it turns out this equation is the Faisarum equation that we heard of. Equation that we heard of before in this workshop, and you could use it. This is the sear stress equation that we already saw in disguise. But if you add this little term here, it becomes the oxygen canalization equation that we, well, again, in disguise, that we heard also in this workshop. It's a really, really nice. It's a really, really nice equation. So, that is a spontaneous production term that basically says that if you have no flow and no nothing, you don't have any conductance yet, you're going to start building vessels out of nothing. So, if you were a growing system, you can consider this. I should have put it like Loreline, really small, but I scanned them all to look the same. But I scale them all to look the same. And you develop it with that equation, and there is more and more blood coming in because it grows. You end up building a network here that looks really, really cute. And in fact, depending on how fast you grow and how important is that spontaneous production term, you can get stuff that in this phase plot of dissipation, essentially the columns dissipation, you can get stuff that are down here. Get stuff that are down here, which means they're less efficient, or up here, which means more efficient. So, this is a local adaptation rule that leads to a global optimum. I'll show you right now that this is likely the global optimum up here because it's deterministic. It doesn't matter what noise I put in, the system always finds this solution. So, local adaptation leads to a global optimum when growth is present. So, growth is great. Now, I lie a little bit. Is great now. I lie a little bit here, and I somebody asked, unfortunately, I think it was John who asked this question about symmetry. So we put in here in the network itself, we put something with disorder so that it looks more like nature because nature is disordered. But if we did a lattice, a square lattice would get risk, huge lattice effects because this is the global optimum, or probably the global optimum, or this extremely highly symmetric. So it wants to. Symmetric. So it wants to find the most symmetric solution, but it can't hear. Anyway, so I could add fluctuations here as well. Fluctuation means in this network, maybe the in is here. First few seconds, you know, the out is here, maybe the things now moved here, maybe here, maybe here, and so on and so forth. And I can play that game and I can change my three parameters now, three dimensionless parameters, one of which is the fluctuations. Of which is the fluctuations. And I can start plotting things in the space of objective functions. Because I prefer. Sorry? How do you define the fluctuations? Yes. So I hear that this is a very good question. I quantify them by basically saying there is a bump here, like a Gaussian bump, with a second width. If that width is really large, If that width is really large, that means that covers, you know, there are no fluctuations basically because everything goes up at the same time. And then I have an ensemble of both parallel universes where that central node with the Gaussian is here, here, here, here, here, here, here. So I consider an ensemble, and that ensemble of running conditions is my fluctuations. It's not this fluctuation. These fluctuations we were seeing when Urba was showing when you have these target pulse in a way. These are just uncorrelated, they are just things that move. So it's just they are different configurations. It's a statistical. Different things, yes. Okay. The things move. Okay. Anyway, so I can look at the space of objective functions, what the network is good at, and then I can take the Pareto front because here. I can take the Pareto front because here, if I am here is a network that happens to be both fragile and costly, this is a stupid way to build it. So, evolution, we allege we take it to somewhere where it is the optimal compromise between fragile and cost. This is the front here of that. And I only keep those networks, and it turns out they're in a line here. They are in a line here. And there are archetypes, the three archetype, which is cheap, but not robust, and also hierarchical. And this is more expensive, but robust. And with the same equation, you can get things qualitatively agreeing with what we see in our own body. Now, this is very old work. So, and I wanted to very briefly tell you something which is also old work. Briefly, tell you something which is also old work but we never published, and also Carl, I think, who's right there, he has something on this. And now I'm adding, I've been talking about minimizing dissipation, which is this term with different notation, and a cost, but now I'm adding a term which is equipped for fusion. So there is a solute in this network, right? This could be nutrients, something, and it literally outside. So the input of the network here will have more of. Here will have more of that than the output. And I'm telling the network, make a local rule from this equation that would make you also echo perfuse. And I'm a little bit late on what I was planning, but the bottom line is, and now we're about to submit this, because it's very, very different than what's on the archive here. We managed to match very well with minimum fitting parameters some. Some networks that were published by Timothy a few years back from the mesentery, where this it shows here that networks also care about perfusion. So here I've been collecting things that networks care about and I've been telling you how loops are affected. Here I didn't tell you that much, but you see if you have no perfusion, it's very, very loopy, whereas if you want also uniform perfusion, If you want also uniform perfusion, it's a combination of hierarchical which you can't see and looping. So, here I've been telling you about dissipation, building cost, fluctuations, robustness, diffusion uniformly and other stuff. And now I'm going to go back to our drunken walk here, which I promised. And now it's search time. So imagine you're here. You're here, but you can only move at random. And you want to make a network which will minimize how fast you arrive with your targets. Anyway, so the question is, this drunk person who lost the keys is thinking, hmm, which city is better to lose my keys in? This city or this city? And if you read the abstract, you will know the answer. So, which do you think is best? The right one. The right one. Okay. It depends, is the answer. So, here we have two definitions. I'm going to be showing you a little bit of math. And the math here gives one definition, which is the mean first passage time. And basically, it's the average time for a diffusing particle to hit a Diffusing particle to hit a target for the first time. And here we're going to be defining the target average global mean first passage time, which is a mouthful. So this is this, but average over all pairs, because we're democratic, we don't want preferential nodes. Like the hotel, there is no preferential node here. Okay, so this is again a little bit math heavy, but it's actually very simple. My edges are weighted. It could be how big and It could be how big and fancy the street is. So you might think maybe I'm drunk, but maybe I should follow the big street rather than the small path. And here, if you are at a node, you will at random pick one of the channels, but with a probability that is proportional to the weight. And then there is another catch, and that catch is that once you commit to that channel, the timing. The time it will take you to cross that channel, because you are on foot, scales as the length of that channel to a power to beta. If this beta is one, that is diffusion. If it is beta larger than one, and I will be repeating this at every slide because it's confusing and convention, it is sub-diffusion, which means slower than diffusion. So the longer you journey, no, no, no, no, we get tired and we walk even slowly. We get tired and we walk even slower. And beta smaller than one is super diffusion. But there is no memory of where you came from. No, this is completely Macobian. One and a half minutes. Okay, good. It's okay. Anyway, so this, it turns out we got inspired from the endoplasmic reticulum and it turns out it connects to the cosmological multiverse. So we did this and it's kind of, it's almost comical that we got funding for that. Okay, so it's actually simple. Imagine having you lost your keys here, and the question is: do shortcuts improve the search or diffusion? This is time, this is graph type. No. In this particular case, you add the shortcut, your search time will decrease. Now, it turns out there is a beautiful analytical way to write this, and this means. Write this and this mean time, the search time, is a product of a TG, the total transit time, which increases monotonically if you add links. And something which is related to the Graph Laplacian eigenvalues, it basically measures the numbers of parallel paths, which can go down if you add paths, depending on where you put it. So it's this product that tells you when you win and when you lose. win and when you lose and it turns out that there is a paradox which is called price paradox which means this is the nature of this paradox mathematically is very very different than ours but qualitatively is the same. Network extensions or reinforcements may deteriorate the system's functionality in traffic networks. So you add an extra parallel path and it might make traffic worse. Kind of similar Works, kind of similar to what we do. And this is something people have seen it in street networks, this is the New York Times, power distribution networks. And another interesting thing is that people traditionally have thought small world networks was optimal for information propagation, but in our case it is not. Now, the interesting thing is that I'm like maybe 30 seconds. So this is interesting. So, this is increasing D, which is slower diffusive propagation. So, here it is diffusion. The optimal is a ring. And if you go faster than diffusion, if you run faster and faster as the link becomes long, it pays to have shortcuts. And it's the same. I mean, we can quantify that, but the details don't matter. It looks like a phase transition, but I can promise there is the threshold is. Threshold is actually dimensionality dependent. So, this is essentially how looking the network is, qualitatively on this axis, not exactly. And this is beta. And the threshold beta changes with whether you are one, two, or three dimensions. And we can actually predict it. Now, I wanna finish quickly. This is has been recently accepted at the RL. Has been recently accepted at TRL, and we are interested in understanding where this idea of optimal search fits in the world. And actually, again, advertising for jobs. I'm half-time at the Flatiron Institute. And I mean, this is from last year, but the application season will open there. So, if you have any postdocs interested in computational biology, they should look it up. And again, I'd like to thank my group there. I'd like to thank my group. The last work was done by this guy here. His name is Jorgos Uneris. And this is Burba, who also talked here. And this is me. This is a very old picture. And this is the same pants. I realize pants. Thank you for your attention. So you will have two minutes for questions. I think you are younger than people. I think you are younger than me, but my evaluation was married. So exploration data sets on book, it would also be a nice example of what you actually work. And then the question is: in your random work, do you have a Do you have a probability that is dependent on the degree at each node? And second, how does it relate to the Laboration? Or does the Laboration that you're using has equal to widths? The answer is, if I remember correctly, yes to all. So the degree of the node is depends, of course, because if I have ten links of the same weight joining to the same point, Weight joining to the same point. Of course, the probability that I will go to one of them is 110. So you're spot on. And also the Laplacian comes up with the weight in, exactly as you said. But I think you know too much about this and we need to talk. Also tell me about the link stuff. Sorry that we are over time. So one last question and then for the general discussion we can. So you said adding shortcuts can increase the search time but I guess it can also decrease it. But I guess it could also decrease it. So I'm I was wondering if there's a way if given a network there was some algorithm that it would add shortcuts such as to minimize the search time. Is is that possible? It's possible, yes. It depends on exactly what you wanted to do. So again, we should discuss later. In general, on average, no, but locally, like what John was showing, we have a condition, let's say. We have a condition, let's say, for one link. But we can talk. I don't know if I'm clear.