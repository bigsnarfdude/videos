So I'll talk about how this large consortia came about. I don't need to make a case for why large numbers of diverse individuals is an important thing. And you just can't get it if you don't go about organize a large consortium. So the first one, larger scale, that I have put together at some people college, the University of California. California, and that was from clinical data warehouses. Each institution had its own clinical data warehouse, but they never share data across the system, even though it's one legal entity, one university. Each campus is very independent, and we are say we, and it takes a few years to but each. But each hospital is relatively small. They all together is a large entity and very diverse. So that made all the sense to aggregate, to use aggregate data, individual level data, to be exchanged, but as an initial phase, not sharing the actual data, just sharing access to data and studies, which later, once trust was built, Once trust was built, the centralized data warehouse existed because the data were already harmonized, they could be brought together in one physical space. But I can tell you, it's used for operations, but research still requires campus-specific authorizations to be done. So the organizational structure, in a way, persists. And how does that work? First, you need to have First, you need to have a joint governance model. It can be one institution trying to coordinate the others. As was always the case at the University of California, one of the two larger medical schools were trying to just put everyone under their coordination. That didn't work. You also have to have enough on budget. A lot of mistrust is based on not understanding who gets the bulk of the funds of a particular project. The funds of a particular project and so on. Once you put the open budget, people try to understand better. Common data model terminologies that's given, decentralized analysis again to build up that trust, and the ability to opt out of research studies and build trust. I mean, in this consortium, the way you build this spot, it happens that some site didn't spend their money, they returned. didn't spend their money, they returned it. That happened voluntarily without us asking, right? So that we could put more in another site that was struggling a little bit more. So that's an important aspect of it. Another consortium that we built upon this one is called the Patient Center Scalable National Network for Effectiveness Research. This was funded by CORE. Kaiser was another consortium in there. In this one, we got the One we got the University of California system. Also, a colleague of mine, Danielle Meeker, led a consortium in LA that had USC and LA Department of Public Health and a few other affiliates. We also included Cedar Sinai Medical Center, which is a very prominent medical center in the region. In the Bay Area, we included a federally qualified healthcare center. This is a community-based institution. Institution, Semitary or Medical Center. In addition to that, not contributing data, but contributing technologies and other University of California, University of Colorado, Rutgers, and Rexes. So this ran as a consortium for the Pepperi Cornet for quite some time, and it was larger in the scale. Now, you remember a 20. Now, you remember in 2016, New England Journal publishes this very controversial editorial on data parasites or research parasites. To this audience, I don't even need to comment on it. But one thing that I felt it kind of challenged me in a way is that when you're a data producer, you don't understand the data much better. Data much better. And this is something that came about, and we were no longer at the core net, and we wanted to keep the consortia together and say, why not we apply to be a recruitment site for the All of Us program? It's the OLMOB as well. We have the infrastructure, we can do this. We just need to add this recruitment parts that we, as informatics people, were not so familiar with, but then we got colleagues to help out so we could understand. So, we could understand and control how data are collected. This is very important. We added biospecimen and physical exam measurements to EHR data that gets shared, and we created a large cohort of consented input. Our organization consortium is 10% of the recruited people so far, so about 60,000 came from this consortium, whereas the whole This consortium, whereas the whole all of us program currently is around 600,000. So we did that because our clinics, again, not being large by themselves, the aggregate of them could create a lot of recruitment. We did try to include other states, but the program insisted it'd be California only, so we stayed within that area. Very early in the program. Very early in the program, this is a slide from NIAH. As you can see, they didn't have graphics before at the time. Right, it was very handy by somebody. And this was the initial consortium. So we were at California Precision Medicine Consortium in red with the regional medical centers. And they had national partners, they had FQHCs, the community-based. Based in community-based careers. So, in the beginning, this is also a slide from them. There was just 17,000 patients around 2018, and it has grown considerably since that point. Wipe is based in Mayo Clinic, it's actually large as well. In San Diego, we started our collaborations. I would recommend going. Go in a little bit out of your comfort zone and learn a new thing because it was very exciting to partner with this organ. Blood Bank, they called it the Blood Mobile particular site. And then we had also at UCSD, we transformed a a little house that was there into a recruitment site right right inside of Mexico Schools. Right the southern medical schools. Pharmacy. We also did in-hospitals, also inpatient recruitment, particularly oncology wards and a few others. And then COVID came, right? And then we were all online. Recruitment stopped and we were like, and if you remember in the beginning of the pandemic, there were a lot of questions, you know, oh, is this better than I want to comment on? I want to comment on fluoropoin either, but there were other things that were uncertain whether they were positive or negative in the treatment or prevention of COVID infection. So in the early pandemic, 2020, we assembled that particular network and added sites that were interested. And this was in a very low-budget kind of Very low-budget kind of emergency situation. We did exactly the same thing. It's like this is the money. We divide by 10 institutions. We didn't pay the international institutions because it wasn't allowed. In Germany, they still wanted to participate. Then we said, well, we will answer questions that the EHR can answer in early COVID. One of them was this one. If you remember, ACE inhibitors were, it wasn't. It was not clear. Many people thought they were actually harmful because of the way the COVID receptors or receptors to COVID worked and so on. We were able to show with 10,000 adult patients who were hospitalized with COVID, that the mortality did not seem to be higher, in fact it seemed to be lower. And in fact, stopping medications is the worst thing. This is the worst thing. So, this was empirical. After that, there were trials or more comprehensive studies that showed the same thing, that AIDS inhibitors actually were effective and should be. We also studied mortality related to racial and ethnic minorities. And for the patients who were hospitalized, we could not show. We could not show those disparities that were very much commented at the time. So you can see here the Hispanic or Latin patients actually had lower mortality than others. And female had lower mortality. Age was a main factor. And then a ratio, again, we could not show disparity. Not show disparity there. And why was that? Well, we knew it, right? You were just for age when it happens. So we did a multivariate analysis federated, so no one exchanged actual data, which is distributed algorithm. And it's not a meta-analysis that needs to be clear, too. It's an iterative algorithm memorizing that. Then we had, as you can see here, GLOR is the distributed algorithm. Is the distributed algorithm? The dark blue is if you had done the analysis on one side only, and the white blue is the other side. So you see confidence intervals will become smaller, but all of them point to the same thing, that age was the factor that was driving mortality. And once that is adjusted for, the others fall into a non-significant range. Significant range except the unknown race in this case. But also explain by being the patients who are more in more severe situation and are not as contained before our self-reported race. So, this was again something we did because of the pandemic needed some answers in New York. Right. So what happened is after the pandemic, I moved to Yale and we changed the name of the consortium. So now that's our consortium and rest assured, I know Puerto Rico is not in the middle of the Ocean. We are just able to display who we have. So we have six California partners as well, Yale BB, trade. being the trade and lead institution, and then we have Puerto Rico which was the previous part of AO. So this is for large scale consortia but you don't need to operate in large scale consortium because many times you're operating in smaller centers but that they also require the same type of collaborations. So this is the Center for Mexico Technology funded by NHGRI called Centers of Access. HGRI called Centers of Excellence of Science. And what we want to do here is, again, just as Neil was presented before, study a trait as a function of genetic determinants as well, as social determinants and exposures, right? And we want to do that in distributed environments because we happen to have data that cannot move from one environment to the other and so on. So we want to. So, what do risk scores? Can we improve on the methods? Can the scores be continuously evaluated? What about biases? Can we measure them? Can we protect privacy? Especially what to do with individuals who are mixed ancestries, because the types of mixture are different. And one global ancestry score doesn't really do justice for this racist score. So, we have college at UCSD. At UCSD, Melissa Gimrick and Tiffany Utel working on ancestry variablogenics course. Melissa also does structural variance, it's her expertise, and Ellie Fraser does HLA analysis. And then on the informatics side, we have the distributed analysis, working with colleagues from the group and veteran administration. We have Dr. Xu here leading the NLP and social determinants of health with a colleague, and also genome privacy, how we mix and introduce privacy enhanced technologies when we're doing centralized or distributed analysis. And this is with the University of Indiana and Ali and Guillaume. So, this is what we're doing right now: connecting all of us data with. Connecting all of us data with Millie Veteran program's data. The numbers here are a little bit outdated because there are 600K participants in all of us now, and the Millie Veteran Program surpassed a million veterans at this point. But it's very interesting because they're both in ENCODE, and as you know, the UP Biobank will be in the same model very, very soon. So that's a way to do federated analysis without. Analysis without violating essentially their principle that the data state with them. And also, the distributed analysis is not just a simple federated learning, it's that plus the privacy enhancing technology. So I I talked about consortia enabling science and precision health, and I talked about this horizontal we partition data. All the institutions have the same kind of data. Institutions have the same kind of data, it's different patients. But on the right-hand side, on B, you have also a consortia where each institution has different portions of the data from the same individual. That's called vertically partitioned data. The algorithms are much harder to do, and many are approximations to the exact same analysis, but it's done as well. So we have to endure that with a vertical partition. Do with that vertical partition data. There's the issue of interoperability with harmonization of data and technical harmonization as well. Because when you do the federated analysis, you need to coordinate that everyone is with the same output. I also worked a lot on consent and data use agreements because without that, you cannot use this consortium. It's simply. I did experiment with patient preferences and endoping for patient preferences. We are also working on blockchain ledgers and contracts. And this is with six institutions. We have also coordination of the Bridged Way Consortium, in which there are four major data generating projects involved. So a lot of work going on in this area. This area of activity, I will just draw attention to the Berkeley partition data sets, and that's with the Strong Heart American Indian Corporation. And in this regular R1, we have four institutions participating, in which there are this vertical partitioning of data. The Access Biomedical Institute has the genomes, and the University of Oklahoma has electronic health records and Electronic health records and all the questionnaire data and measurements from the strong heart study, which is the largest one on America in the United States. But that is in the order of few thousands and not large-scale. But again, very important cardiovascular risk type study. So lastly, I was going to say, our vision is no one needs to be left out. No one needs to be left out. The more inclusive, the better, both in terms of the patients and in terms of institutions. Large consortia are necessary to increase representation. They are not exhaustive, because if you look at our consortia, even though we had community-based clinics, there is a lot to be said about those who don't even get proper care in an institution or whose care is so. Or whose care is so fragmented that you can't trace back homeless population and a lot of doctors. Our biomedical informatics and data science community does develop new methods and tools that allow research findings to be applicable. So it's not just the data being collected in having done that participation, but we also have to develop tools that ensure that the analysis are done in the proper way. done in the proper manner. So large consortia help everyone have equal opportunity. That's important. We can link across disciplines that deliver back in the practical settings. That's called the learning healthcare system. I'll talk about that part today. And we can promote excellence in transdisciplinary training as we do all of that. So we had students who were more in the ethics portions, students who were in the very technical portions. Technical portions in, well, so we partner with a whole lot of people, researchers, clinicians, health services, public health administrators, all to make a decision. Lastly, I would just like to acknowledge the sources of funding and the team members at various institutions. First, where I have the privilege. The privilege of being junior faculty, and the other two where I had the privilege of building this basic conference. I mean, fun even so. So, thank you. I just wanted to clarify one point which we can touch on for the better of the learning. The federated learning probability and straight button, but federated mill says everybody basically has to have the same data in the same format. I think it's just, of course, it's all been collected protected data. There is that step of first, get your data to look like this as best you can. In the whole quality control around it, and we saw that in the COVID. We saw that in the COVID example, that one of the institutions that happens to be ranked first or second every year in the ranking of best hospitals in the country appeared to have a higher mortality rate. The note that that was going to be something clear. So by doing those quality controls, which is simple statistics, we could tell, oh, it's the way they're coding hospitalization as opposed to other. So the whole Other. So, the whole definition of hospitalization took weeks to develop, way more than everything else. So, by having consortia, you also can correct your own data because you can check how the peers are. And people in their specialties know, they know that San Francisco does not have way higher number of cases of ongoing infection than Infection than sing people or others. So various cases of incorrect coding of work or just for that example, how many institutions were participating? That COVID example that you gave, how many? I believe it was around 12, but one of them was the Veterans Administration, then creates hospitals all across the U.S. and territories in builds the systems. In both the systems were very large, too. So, when I mentioned, for example, San Diego, there were also the affiliated institutions sometimes. So, 10 major hubs and the institutions that they helped organize. So, it's a you know, it's a tree structure that they themselves are a consortia and it goes on. Within the branches, you can share data, but you have to do the federated analysis of course. Within a particular hub, typically the hub would centralize for those institutions. Yeah, we're not there yet to do several levels. I'm wondering when you find out when data harmonization isn't possible, right? Because you said the data producers, they already know their data, they know it's interesting. They really know their data, they know its intricacies. I mean, there must be some points where you can come up with plans and say, well, actually, there's just different data generation processes going on here. It's not appropriate to try and harmonise this data. And I'm wondering how you navigate that, like thinking, yes, we can smoosh this all together, versus, no, actually, it's not appropriate for us to even try and smoosh this data. Yeah, if you have like 10 institutions and one of them cannot get their pack together. Act together for this particular study, they don't. Right, but I mean, even just aside from not getting that act together, just like, no, the processes that they are using just make it, are so different from the processes that this other team are using. Like, for example, there's many ways in which you wouldn't try and squish UK and US to be together, right? Because they're fundamentally different health systems. And just managing how they manage the CCP differently. And then lastly, To think differently. And there must be some things like that, even within the US, right? Where it's like, it's just not appropriate for us to try and say that. And how do you work out when it is versus isn't appropriate? I think that's on the part of the investigators who are asking to do that research and not us, because they too know better than we on the data side whether that question is even reasonable to ask or worthwhile the effort to other people. Yeah, I've been thinking of seeing these comments, and I guess I have a lot of questions about comments. So, in a lot of analyses we do, we put recruitment side or whatever the participant side is a covariate, and inevitably they always come out significantly. The remote question is, does it undermine the overall conclusion? I mean, you can do a bi-vet-analysis, or you can just put it as a whole variable, right? I can tell you the genomic studies were involved in which the sequencing studies were diagnosis. Which is sequencing studies for diagnosis, all the sites are supposedly using the same ACMG criteria, and we all have very different diagnostic fields, especially for the USs. And those were dramatic, you know, highly significant differences. We didn't get into, to respond to what you were saying, we didn't really get into how they're annotating the variants and why they're annotating them differently or how they're annotating them. We were interested in is ancestry playing a role in diagnostic yield? And it turned out on each site it wasn't. Okay, so we did a meta analysis. So we did a meta analysis, and that was robust. So I think that conclusion was robust to the overall differences that existed that we did not identify or understand. So I think, you know, to respond to what you said also, I think that's right. I think that every setting is unique, every setting is different, every question is different, and you have to decide: is your conclusion undermined by the heterogeneity that exists, which you may not be able to display? I must say a lot of What if the people don't pay enough attention to the phenotype? That's where it can be more ascertained in some centers than others. And one example we have is Kawasaki disease, which doesn't have a marker. So it's a pure clinical diagnosis. Some people were more allergent to the science than others. But you do have a case where San Diego has a Kawasaki disease center, and there are many, many more. Center, and there are many, many more diagnosis there than in LA, for example. You know, there shouldn't be. So, the phenotype is so true important in all of these studies. I think it, you know, it saddens me when I see, you know, a whole lot of things that were not considered. Sounds good, natural way to see the next session, people talk about funeral types, right? People to talk about phenotypes, right? They can do phenotype harmonization. So language model has other things. I think Neonia's first presentation. Thank you. I love how three of them may be in 15 minutes. And also for the three speakers, I can't go because we're going to go. Yeah, just like