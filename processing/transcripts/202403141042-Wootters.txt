Computations on top of error correction. And like Dave alluded to, this talk is maybe not quite in scope for this conference, but Yuri said it was okay, so I guess it's okay. Yeah, so there will be some uncoordinated communications, but not much else. Hopefully you'll get something out of it anyway. Okay, so what is this talk actually about? Oh, sorry, I should first say that this is based on several joint works with Ingrid Fossley, Victor Kolobog, Yivali Shai, Tyler Blackwell, and Noah Sha. Okay, so what is the talk about? So the title of the talk. What is the talk about? So, the title of the talk is Low Bandwidth Computation on Top of Error Correction. So, let's break that down. So, first, error correction. So, in this talk by error correction, I just mean good old Reed-Solomon codes are our favorite. And I'm assuming that probably everyone here is familiar with Reed-Solomon codes, but if not, I'll define them in just a moment, just to set up notation. Okay, so that's what I mean by error correction. In order to introduce the second part of the title, let me say a little bit about the model. So, for this talk, I'm going to be imagining that we have. For this talk, I'm going to be imagining that we have some data that is stored in a distributed setting, protected with error correction, in this case with Reed-Solomon codes. Okay, and given that we have that data and it is stored in this distributed way, maybe we want to compute something on it. And that leads us to the next part of the talk, low-bandwidth computation. So by this, I mean, how can we compute functions of our data that is stored in a distributed fashion protected with read-semblan code in a communication-efficient way? And the punchline of the talk, I'll give it away now, is that we Way now is that we can leverage error correction to help us do this computation. So, in a little bit more detail about the punchline, is the following. So, one way of looking at error correction, which I think is the way that I typically looked at error correction, is kind of like a suit of armor. It protects our data, but it's a little bit clunky, it introduces some overhead, and if we want to work with the data, then we often have to do it in spite of the error correction. It's like in spite of the error correction, in spite of the overhead that that error correction has introduced. But what I want to talk about today is another way of looking at error correction, which, instead of being like this clunky suit of armor, is like this much more awesome suit of armor, the Iron Man suit, that both protects our data and also has a bunch of other cool features like lasers and stuff. So not actually lasers, but the basic idea here is that in doing this error correction and computing, for example, our parity blocks or something like that, we've done some useful pre-computation. We've done some useful pre-computation that we can then leverage later to do things completely unrelated to error approach. So that's going to be sort of the main theme for the talk. Yeah, so in a little more detail, here's the outline, and I've got till 11.10, something like that, is that like, okay. Yeah, so first I'll just give a quick overview of Reed-Solomon code so we all have the same notation in mind. And then the bulk of the talk will be about low-bandwidth computation of linear functions on Reed-Solomon encoded data. This is based on joint work. Encoded data, and this is based on joint work with Noah Shatti. And then, depending on how much time, I'll talk about some applications in homomorphic secret sharing. And if I get there, it'll be based on joint works with these codes. Okay, yeah, so let's get started with Reed-Sullivan codes. So I just want to set up some notation. I assume most people here are familiar with this, but just quick notation for error correcting codes as I'll use them in this talk. We're going to pick some parameters k and n. k is our message length, n is our block length, and we're going to have some data x in f to the k. Some data x in f to the k, where here f for the whole talk is going to be a finite field. And for this talk, I'm going to think about it as being a field with characteristic 2, so it has size 2 of a t. Everything I'm saying works if the characteristic is not 2, but in general, it does need to be an extension field. Okay, great. And then, so we have our data, and what we're going to do to it is add some parity checks. So we'll add n minus k parity checks to get a code word of slightly longer length. And the point of doing this is to Length. And the point of doing this is to protect the data. So if something bad happens, we should be able to recover our original data x. And for this talk, what something bad means is going to be erasures. So that is, some of the symbols are just going to disappear, but I know where those erasures have occurred, and I want to correct them. Okay, so that's the goal of error correcting codes, at least for erasures. And read-Solomon codes are one very classical way to do this. Here's how they work. In addition to our parameters k and n, we're also going to pick a bunch of evaluation points. To pick a bunch of evaluation points, alpha 1 through alpha n, in my field F. And then I'm going to treat my data as a polynomial and evaluate that polynomial on these points. So in more detail, here's the systematic way to do it, is to encode the data, we are going to remember the very useful fact that there is a unique polynomial of degree at most k minus 1 that passes through any k points. And we are going to interpolate this polynomial to go through these k points in particular with the evaluation points. K points in particular with the evaluation points alpha 1 through alpha k. So we're going to find some polynomial f of degree at most k minus 1 so that f of alpha i is equal to xi for all i fill in to k. And then we're going to write our data instead of x1 through xk as f of alpha 1 through f of alpha k. It's the same thing. And then to get our parity blocks, we'll just take this load-degree polynomial f and evaluate it on the remaining evaluation points. So we get our parity concepts. So the picture looks like this. Our data is sort of encoded in these points. We interpolate a polynomial through it. Interpolate a polynomial through it and then evaluate it at the other points to get more barbaric ones. Right, and then we'll forget the underlying polynomial and just store that. Cool. Okay, so why is this useful? Again, I'm assuming most of you have seen this, so let's go real quick. How do we do error correction with Reed-Solomon codes? So suppose we have some data, or actually, yeah, sorry, erasure correction with Reed-Solomon codes. Say we have some data and something goes wrong. So let's say that up to n minus k. Say that up to n minus k symbols are erased like that. What can we do? Well, hooray for low-degree polynomials. There are still at least k symbols left. So we can find the unique polynomial that agrees with those and recover our data. So the picture looks like this. We've got our symbols that we're storing. Some of them go away, but we still have enough points left to interpolate the polynomial and recover the missing data. Fantastic. Okay, so Reed-Solomon codes can correct up to n minus k erasures, and it turns out this is the best possible. K erasers, and it turns out this is the best possible due to the signals of that per A problem solved. And because of this optimality, as well as some nice algorithms that you can do with Reed-Solomon codes, they are basically everywhere. I mean, there are places there are not, but they are many places, including these. Great. Okay, any questions about read-solvent codes or the basic notation before I get into the awesome. Okay, so this has all been. So, this has all been like Reed-Solomon codes were proposed in the 60s. What's left here to talk about them? And so, what I want to talk about today is Reed-Solomon codes in a distributed setting. So, for low-bandwidth computation, this is where the new stuff is. So, first, let me set up sort of a very stylized model for this. So, suppose I want to do distributed storage with read-solver codes. So, say I have n storage nodes, and I have a data vector of length k over my finite field, which I've sort of internalized. Finite field, which I've sort of interpolated my polynomial through. And I want to store my data on my end storage nodes, but I'm worried about node failure like that. And so what do I do? Well, use a Read-Solomon code. I'm going to compute my parity blocks and put a different symbol on each of the different servers. So then if a couple of them disappear, it's no problem. As long as fewer than or at most n minus k nodes become unavailable, we don't lose any data. Great. We don't lose any data. Great. So, and in practice, Reed-Solman codes are used in distributed storage systems like this. Just for the rest of the talk, I'm not going to draw the yellow boxes because that's just too much PowerPoint. So, let's make those go away. So, instead, I'm just going to draw these symbols disappearing, but keep that in mind as saying, oh, the server that that symbol was on went down. Cool. Okay, so and also interrupt me at any time if there are any questions. Me at any time if there are any questions. Okay, great. So, what this talk is about is computing on top of Reed-Solomon error, Reed-Solomon coding in a distributed setting. So, I'm going to talk about two examples. The first one, which I'll just go over real quick, is kind of an older example, which is the example for generating codes. And the idea here is that we want to compute information about just a single failed node. So, I'll sort of introduce this and talk about it just real quick to kind of motivate. Quick to kind of motivate the next example, which I'll spend more time on, which is computing linear functions. And it kind of just kind of generalizes the regenerating codes setting. I should note that this is not the only work on computing on top of Reid-Solomon codes. I'd be remiss if I didn't mention the large body of work on coded computing, in particular polynomial codes and Lagrange coded computing, which also use Reid-Solomon codes to help with computation. But the model is slightly different. They don't care as much about bandwidth. Different, they don't care as much about bandwidth. So, I am not talking about coded computing in this talk, I'm talking about something else. So, let me tell you what I'm talking about. Yeah, so let's get started with this warm-up of computing information about a single failed node. So, let's say I want to compute information about a single node. So, what's the setup here? Say I have my data stored in a distributed way with my Reed-Solomon code, like we just talked about. And now one of the nodes fails, like that. And I want to repair the system, right? This is the whole Want to repair the system. This is the whole point we use read solving codes: that we haven't lost data. So I want to repair the system, so I want to set up a new node, new replacement node, f of alpha1. Okay, so let's see who's been paying attention and or who already knows what to do here. What's the naive algorithm? Shruck all the data, kind of below the point. Exactly, yeah. So the naive algorithm here is: well, I just told you how to, or you already knew how. Well, I just told you how to, or you already knew how to erase your correct Lee Sullivan codes. So, what do we do? We contact any other K nodes, we download all the information from each of them, we fully recover the polynomial f, and we compute f of alpha 1. Great. So, this is very straightforward, but it does feel a little bit wasteful, right? We downloaded, we only wanted the one symbol, but we ended up downloading k of them. So that's like kx overhead in the communication. The natural question is, can we do better? Okay, can we contact fewer than k nodes? Can we contact fewer than K nodes? What do you think? Anybody? It depends. It depends. It depends on how close, like what kind of code you have and how close you are to the frontier and how much extra hundreds of things. So I have rethelled and cuts. So I've just fixed, just rethel and cuts. Can I contact who? Yeah, exactly. Yeah, so I might say, oh, could I contact, let's say, K here was three. Could I get away with two nodes? Could I get away with two nodes? And the answer is no. And given any other k minus one evaluations, f of alpha one could be anything. That's like the whole magic of read-solving codes. And this is basically saying, give me two points and tell me that, I promise you there's a parabola that goes through them. Tell me the value on a third point. It could be anything. There's a parabola that goes through any three points. Great. So I learned absolutely nothing about f of alpha one. So that's a bummer. Okay, but we might want to know, can we do better? And as many of you Can we do better? And as many of you probably already know, the answer is yes. And the solution is to contact more nodes but to download less information from each one. So instead of just contacting two nodes, let's say maybe I can contact all of the surviving nodes, but instead of downloading this whole big old field symbol, just download a single bit or something like that. And it turns out, hooker, there we go. That this way you could dradically reduce bandwidth, and these go by the name of regenerating codes. These were introduced by Democrats et al. in 2020. By Democratus et al. in 2010, and over the past decade, decade and a half, there's been a lot of work on these and a lot of cool constructions, many of which are not Reed-Solomon codes, but it turns out that actually Reed-Solomon codes are optimal for this problem as well. So you can do this in such a way that you can reduce bandwidth. So this is not the point of the talk, so I don't want to dwell on this. But I just wanted to introduce this as sort of a first example of error correction helping with computation. Helping with computation. We had some data that was stored with the Reed-Soloman code, something bad happens to it, we've lost a symbol, and we want to compute f of alpha one with good bandwidth. And the idea here is that we sort of leverage the structure of the Reed-Soloman code to do so very efficiently. If we didn't have as many parity checks, we couldn't have gotten as low bandwidth. So somehow, having pre-computed those parity checks helped us compute this thing that we wanted to compute. So that's the perspective I want to take on regenerating codes here. And now I want to generalize. Codes here, and now I want to generalize that in a new direction. And what I'll talk about next is a generalization of this based on work with my former student, Noah Shatty, who's now at Google. And yeah, basically, we were like, what other functions can we do this for other than the give me just the one symbol function? And of course, the next natural thing to think about is linear functions, so that's what we looked at. So let me tell you what we've got here. Okay, so the problem setup is the following. So I have my So, I have my data x. It's stored with the Reed-Solomon code like this. And as before, it's possible that something goes wrong. Let's say up to n minus k times 1 minus epsilon nodes are unavailable. And so we saw that n minus k is the maximum number of nodes that could be unavailable. So I'm just backing off from that maximum by just a smidge. So we've got some explosions happening there. Great. And now a querier comes along who wants to compute some linear. Along who wants to compute some linear function of our original data x. So here's my querier, and she's got some vector v, and she wants to compute the inner product of v with x, the dot product of v with x. So she wants this dot product. And now the rules are each surviving node is allowed to send the query error a message, which can depend on the node. So the message that each node sends can depend on its contents, it can depend on this vector v, and it can also depend on the identity of the failed nodes. Depend on the identity of the failed nodes. This is exactly the same models in regenerating terms. So they all send her a message, and from this, the querier is supposed to be able to compute this linear function that you want them to compute. Okay, so this is sort of the problem setup. Is this clear? Yeah. So you said that those servers will send an information that depends on what, like one V and F. Yeah, so what can these messages depend on? They can depend on the content. Messages depend on, they can depend on the contents of the node. So, like the message that this node sends, it can depend on f at alpha1, it can depend on v, and it can depend on the identities of the failed nodes. Any more questions about the model? And actually, I want to point out that unlike regenerating codes, this question is actually interesting even if there are no failures. So, even if there are no node failures, it's still an interesting question. Like, I just want to complete this. Question, like, I just want to compute this linear function. Okay, so let's just focus on that setting where there are no the others. And let's sort of try to do our same exercise again of seeing what is the naive algorithm and can we do better. And to be a little more quantitative about it, let's say that there are t bits per symbol. So if I'm working over a field of size, yeah, so if I'm working over a finite field, let's say that field has size 2 to the t, so t bits per symbol. Great. Okay, so again, let's. Great. Okay, so again, let's see what we can do here. What's the straightforward algorithm? There are no failures. This is not a trick question. Download everything. Yeah, the data is sitting right here, right? We can just look at the data. So download the data and compute the function. Great. And it's worth noting that actually, if there were no parity blocks, we would have to look at all of the data to compute an arbitrary linear function. To compute an arbitrary linear function. Okay, and so what's the bandwidth of this scheme? By bandwidth, I just mean the number of bits downloaded. Well, it's k times t, because I contacted k nodes and I downloaded t bits for each node. Great. Okay, and of course, if there were failures, we could have done the same thing that we did in the regenerating code's case, just contact any k nodes. Great. Okay, yeah, so even with no failures, the naive algorithm downloads KT bits, and that's obviously necessary if there weren't any parity blocks. Necessary if there weren't any parity blocks. We need to look at all of our data to compute a dense linear function of it. Okay, but we still want to ask: can we do better? Can we somehow leverage this computation that we've already done to compute these parity checks in order to decrease the games? So once again, we can ask the same question. Can we contact fewer than K nodes? What do y'all think? Nod or a headshake. No, we can't contact fewer than K nodes. Can't contact two of the k nodes, not in general. It's the same reason as before. This is a strict generalization of the previous problem. The linear function, give me f of alpha1 is a linear function. So now I'm saying give me any linear function that could possibly include give me f of alpha 1, so I definitely can't hope to do this. Right. But in fact, we can do better in the same model that we had in regenerating codes, which is let us come. Codes, which is let us contact more than K nodes and download less information from each. So, as before, we're going to contact more than K nodes. In this case, because there are no failures, we could contact all of them, but we'll see what happens if there are failures in a moment. And the theorem is that, a very informal theorem, there is a way to do this that saves on bandwidth. So let me be a little more quantitative. So here's a slightly more quantitative version of this. And also with erasures. So our querier is going to broadcast an arbitrary vector. Is going to broadcast an arbitrary vector v. And now up to n minus k times 1 minus epsilon nodes might be unavailable. Remember, n minus k is the maximum we can handle, since it's backing off from that by epsilon. And now the result is that each surviving node can send some constant number of bits, which depends on epsilon in this unappealing and certainly not optimal way. Open question. What's the right answer there? And sends this many. Sends this many bits to the querier, who can then will be able to recover the linear function that they wanted to achieve. So I'm not going to state a more formal theorem than this, but hopefully the flavor of the theorem is clear. And the takeaway is that the total bandwidth here in epsilon is a constant is O of K. Instead of K times T, which is what we got for the naive version. So T here is the number, is like log. Here is the number is like log the field size because it's the number of bits in a field element. And so the field size is at least n, because it's a read-sell in the code. We need n distinct points in our field. So that means that kt is at least k log n. So this has saved a factor of log n and replaced it with some unspecified constant that depends on epsilon, which may or may not be a gain depending on what n is. But I will say that for the constants are actually not so bad. So for example, if the code is So for example, if the code is rate a fourth, then you can actually just download one bit from every surviving server if there are no failures. So that is savings even over like F256 or something. We also have a theorem that says bandwidth omega of k is necessary. So k is the right dependence. I do not think this dependence on epsilon is right. I would love it if someone wanted to look into that. Okay, so I have 10 minutes left. Yeah. Oh yeah, so you're asking how does this work? Yeah, so let me give just a flavor of the scheme and then maybe I'll address that in a second. And to answer your question, it has something to do with the fact that all of the nodes, the nodes have some linear relationship with each other, but it's not just that. It's not just that. So I'll talk about that more in a story. This one's one question. This surviving node sending one over lower one over epsilon over epsilon bits, shouldn't that also have a dependency on K and N? It does not. No. Yeah. In some sense, the amount of information a node contains depends on KIN, bits of information at a given node. Well, so the number of bits of information that a node contains, just like in terms of the space it takes up, is log of the field size. Right. And so, and the field size here is n? N, yeah, that's right, yes, I think that is n. So if n is very large, then the information at a given node is proportional to log n. Correct. And so it's not sending a fixed fraction of the information it contains, but just some fixed number of. But just some fixed number of bits. Exactly. Yeah. Yeah. That's exactly right. Yeah, and I think maybe that's one reason I found this so surprising: is that, yeah, it's just sending a constant number of bits if epsilon is constant. Or, yeah, like I said, if it has rate, if epsilon is one, so there's no unavailable nodes, and you can get away with just sending a single bit from a recent bi-man node, no matter what n is. Of course, you're contacting like n nodes in that case, so there is some dependence on n bandwidth, it shows up here, but not. But not in how much you're analyzing from each other. Any more questions? So, let me just say a bit about the proof, and maybe I'll answer his question while doing that. Yeah, so I'm not going to go into too much detail because I have five minutes. So we'll see what we can do. But the main idea at a super high level is the following. For all i from 1 to n, we're going to come up with a way of partitioning f, our final partition. Partitioning f, our finite field, into a bunch of parts. And this partition depends on the evaluation point. So I'm going to draw it like this. I have n evaluation points on my x-axis. My y-axis is the whole field F. And for each evaluation point, I'm going to partition up the field. So maybe for alpha 2, I'll partition it into these three parts, solid, stripey, and crosshatch. And I'll have different partitions for all the different points. So here I'm thinking of these solid things as all being part of the same partition. As all being part of the same partition, they're just not contiguous. And now I want to come up with these partitions so that they have the following property. And I'm basically just restating what I want, but this turns out to be a useful restatement. So what I want is that for any two polynomials, f and g of degree less than k, that go through all of the same parts, so say they look like this, so like f goes through the solid part of the purple partition and the stripy part of the blue partition and so on. Of the blue partition and so on, and so does G. So they're not the same polynomials, but they sort of agree on all these parts. So, for any pair of polynomials that have that property, I want it to be the case that their evaluation on the function that I'm interested in is the same. So, here x sub g is the data that would be encoded with the polynomial g. So, I want these linear functions to be the same. And the reason that I want this is because then my scheme will be the following: the node, so here's my scheme, assume I can get a Here's my scheme. Assume I can get these partitions. The scheme is the following. The node holding f of alpha i is just going to send the identity of the part that it lives in. So for example, alpha one node is going to say solid, and alpha two will say stripy, and so on. And so if there are w parts in each of these partitions, then each node is sending log of w bits. So in particular, if w is a constant, maybe depending on this epsilon, then each node is going to send some constant on, depending on epsilon number of bits. Depending on epsilon number of bits. And from this, we can figure out what this function is because even if I have, like, I don't, I'm not getting enough information to recover the polynomial, that's the whole point, but I know that any two polynomials that sort of have this same answer profile will have the same functional answer, and that's what I want. So the tricky part is, of course, coming up with these partitions. I'm not going to have time to do that in four minutes, but maybe just to answer your question and give a little bit of the flavor, the basic idea. Flavor. The basic idea is we kind of want to convert from, so let's say our field is FQ, where Q is 2 to the T. It's very easy to write down FQ linear relationships between all of these different symbols. Like, we know exactly what sorts of FQ linear relationships these symbols satisfy. Those are given by the parody techniques for the Reed-Solomon code, and everything's nice. What we want in order to do this is to come up with F2 linear relationships. And so the trick is kind of Kind of staring at things in the right way to turn the FQ linear relationships into F2 linear relationships and from that kind of identify these partitions. So that's super hand wave. Okay, so I know that this is super high level, but are there any questions? Yeah. Is it structural? You know what the partition is, or you know that there exists? It's constructive. Yeah, I can tell you completely explicitly what these partitions are. And actually, the algorithm. What these partitions are. And actually, the algorithm is like, can be implemented more efficiently than looking through and seeing, having a lookup table for the partitions. It's basically just, they're all F2 linear computations that the nodes are doing, basically descending F2 linear inner products. Yeah. Does this partition have anything to do with all of with all the cohesion? Right. That's a good question. That's a good question. I don't think so. Maybe the BCH subcode might be a special case for computing certain linear functions. Yeah, I'm not sure. I haven't thought about it. It's a good question. Do the partitions always exist? Or is there some restriction where they wouldn't be able to find one? So the main restriction here is that I need this to be an extension field. So I don't know how to do this over kind fields. I don't know how to do this over Klein scenes. Yeah, I think that's a big one. Speak it to linear functions that we might look at? Or can it be extended? Yeah, so for this, this is just for linear functions. It can be extended sort of in a black box way to simple polynomials. Basically, like if each node gets to do some local computation, then in particular, like they can square what they're holding and then they're holding f squared of something. You could do simple polynomials that way. These simple polynomials that way. But yeah, I think the next step would be to generalize it to bigger function classes. Yeah, more questions? Probably a lower bound on t, right? Depending on that t needs to be sufficiently large? Yes. Yeah, that's right. That's pretty needs to be sufficient large. I can pull up. There's I have a formal theorem statement in a hidden slide somewhere. Here's a simplified formal theorem statement. Oh, okay. I guess so you can get away with any t at least two, but it's going to But it's going to come out somewhere else if T is nothing else. Yeah, well, T needs to be growing with N because this is think of Q is going to with N, sorry. Maybe we can take this offline because it's a little technical here. Here's an even more formal theorem statement. I think, yeah, so I think that you get some statement for any t, but the statement is only good. Statement for any t, but the statement is only good when t is large. It's what I think is going to happen. But yeah, maybe we can take that offline because I'm already out of time. So let me, shoot, I wanted to talk about homework secret check, but I guess I'm not going to at all. So maybe I will just end by saying, okay, why is this useful? So one answer is, well, we often want to compute linear functions, and our data is already stored with our great Solomon code in a lot of settings. So let's just take advantage of that to minimize bandwidth. So let's just take advantage of that to minimize bandwidth when we compute our linear functions. So, those of you who are paying attention can tell that this is kind of BS. This is not a good answer. I don't actually know any sort of distributed storage settings where this makes sense. Typically, the data that is encoded with Reed-Solvent code, this is cold data. You don't often want to compute arbitrary linear functions of like, yeah, yeah, sider. I don't have a good answer here. I do have a good answer in cryptography. Do you have a good answer in cryptography? So, a more concrete application of this is homomorphic secret sharing, which I don't have time to talk about, but the basic idea is: if you're familiar with Shamir's secret sharing scheme, that's basically a Reed-Solomon code. Homomorphic secret sharing is a version of secret sharing where you want to do computation on top of the secret shares, and that maps basically into exactly this problem. You have to do computation on top of a read-solving code. And so, with these results, we immediately get some results from Get some results from homomorphic secret sharing with resolve accounts. I think I will skip all of that and end this here and just sort of conclude. I have one conclusion slide. Or is the chime? Yeah, so the talk was about low bandwidth computation on top of error correction. The basic punchline is we can leverage existing error correction that we might want to do anyway, either for correcting, either for Either for correcting, either for protecting our data or for a secret-sharing type of application to compute efficiently, and the view changes from clunky suit of armor to super awesome Iron Man suit with lasers. But the main question that I wanted to ask for y'all, and this is slightly related to the fact that I couldn't really come up with a distributed storage application of this, is what is this useful for? It feels like it should be useful for something. I can think of applications in crypto, but I can't think of a killer app in storage or distributed computation. So I'd love it if one of you. Computation. Oh, so I'd love it if one of you had a sense of suggestions. Okay, so that's all. Thanks so much.