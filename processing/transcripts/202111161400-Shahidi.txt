I'd like to thank the organizers for inviting me to speak in this important, interesting conference. It has been wonderful. And let me... I know Bill for many, many years. When I was Joe's student at Hopkins, I mean, he would get letters from Bill, he would get letters from Jake, and he would show them to me. And I remember, I mean, this issue of the Issue of the Casim Manshalaka formula was there. Joe, I think, as far as I know, he just figured it out for GLN himself. And I don't know even if he knew about Shintani or anything, but I mean, with Castelman, who was doing it in general, they kind of did it and they wrote this wonderful paper, which has been very influential in many parts of the subject, and of course, in my own work. And of course, in my own work, there was another work of Bill which was very influential in my work, and that was his canonical models for GK modules. And that was a, I mean, the paper, and there is a story about that. He, I had a paper on real books, which came out in Duke eventually in 1981, and he happened to be the referee. And I was the last part of the paper. I was trying to use his results, the economical vectors, and he, it wasn't ready yet. He it wasn't ready yet. I mean, there was all this discussion between him and Wolo, and it wasn't ready. He would send it back, hoping that maybe by the next time he would get it. Eventually, he forced me to use a definition and do it. But fortunately, soon after that, I mean, there were two proofs, one by him and one by Wallock, and it was great to have them. And Bill is a, I mean, he could be rough, but he's a he has a very nice heart. He's a I mean, I have been organizing within conferences and so on. Together with Jim and Bill, we did the Language Conference in Minneapolis in Minnesota, the Apple conference, and we did some other ones together. And it was a pleasure to work with Bill and Jim, of course, and with Bill himself in the other occasions. And Bill is also a good cook. When we were at the Institute together, he invited me. We were at the institute together, he invited me to his place and made some spaghetti for me. And if he invites you again, accept it. I mean, he knows how to do it. I love spaghetti, so that was one thing that he did. So happy birthday, Bill, at the moment. I'll have something at the end too for everybody, not just for Bill. So let me start with the mind putting yourself on video. I am. Am I not? Don't you see? Am I not? Now you see? No. There are two copies. Raydon is there. It's just a moment. I'll spotlight him. Here he is. Oh, good. Yeah, okay. Now we don't have anybody else, but that's fine. Maybe not. No, no, it sees me. No, it's all good. It's all good. Jim, you can switch between gallery and speaker view in the top right of your cor of your screen. Top right of your core of your screen. Oh, I see. Oh, okay. So I think the issue is that copy of Fray Dune is muted. If he unmutes that one and mutes the other one, that should bring him to front automatically. Okay. It doesn't matter. So you want me to mute myself on Zoom and on my iPad? And okay. No, no, keep as it was. It's fine. Touch a spotlight ideas. Everything is fine. Okay. Okay. I want to get rid of this unmute yourself. I don't know how. Let me get rid of this one because that covers. I don't see what I'm showing. Okay. Now I'm in normal setting. Okay. All right. My mandate was to give a semi-expository talk on problem and causal Engels program, and that's what I will be doing. And that's what I will be doing. Let me remind you: of course, everybody knows this: the work of Godemon and Joe K, when they wrote that important book, which was the beginning and of some of the good work on the L function, which was a generalization of Tate's idea. Let me just remind you: F is a p-adic field. I'm going to discuss it here. Of course, it's done also for Archimedean, but for the purposes of this issue and what I'm going to discuss later, let me assume. discuss later let me assume that f is a periodic field g is gln and mn is just n by n matrices and c c infinity of m n of f is just a locally constant functions of compact support and pi will be a an arbitrary red usable admissible representation of gl and f and f of x would be a matrix coefficient of pi and just simply pi of x v tilde v is in the space and v tilde is in the contribution And V tilde is in the contragran of the representation of the representation. Let me choose a function phi in CC infinity of m n of f, and let me take a non-trivial character of f. And then, of course, the Fourier transform is well known. It's just given by integration over m n of f of phi against psi of trace of xy, dy. And let me also define a Fourier transform for pi tilde, which is f of Which is f of f of f check of g is f of g inverse. And then, of course, the data function is just defined in this standard form: phi of x, f of x, determinant of x to the s dx. And then there is a rational function gamma of standard, gamma standard of phi of s, which is a rational function in q to the minus s, which allows this functional equation to work. So z of phi check. So Z of phi check, F check and 1 minus S plus N minus 1 over 2 is equal to the gamma standard times Z of phi F and S plus N minus 1 over 2. Now notice that there is a shift of N minus 1 over 2. And as you will see, I'll eventually put that inside pi when I do the more general case. This is completely equivalent to convolving the kernel of the Fourier transform, which is this, convolving this with F. So you take this kernel. So, you take this kernel convolved with f, of course, times the determinant, and that shift s plus n minus 1 over 2, that gives you the gamma here. And then, this is just a consequence of Schur's lemma and irreducibility of the representation. Now, Robert-Man-Causian is a vast generalization of this to arbitrary reductive group G and a finite dimensional representation rho of the L group of G. It has been refined by a goal and it's being pursued. Goal and it's being pursued by a number of mathematicians, among them Secular Rides, Gez. I mean, there are so many names I'm just going to put, and then Jiang and their collaborators. And let me also refer to Laurent Lafour's work, which is also related. And in a way, it aims to prove the functoriality using his approach. Now, let me discuss what the problems are and what are the replacements of these vis-à-vis what the Godemasha KD. The first thing is that we have. The first thing is that we have to replace this Mn, all the N by N matrices, and that's the theory of monoids. So, this theory of reluctant monoids was something which was done by Winberg and by Renner. There is also characteristic P with other people. Let's just assume K is algebraically closed. Let me take define a monoid is an affine algebraic variety with an associative multiplication and a one. And a one. We must have a one because I want to get units in. We also want m to be normal, just a standard normal notion for varieties. So, k of m, the polynomial ring is integrally closed, and this you can always do very easily by taking a normalization. And that makes work a lot easier when you do deal with in these monoids. Now, the group which comes out of this, the group which should be the units of this name. So, you have this monoid. So, you have this monoid, and you want to have a group. If you want to develop God-monjour k, you need a group to integrate over in the zeta function, and the group would be the units of this. I mean, sometimes you start with GL2, and you will see in the symmetric powers, the interior, the units inside M, the interior of M will be not GL2, but it will be SL2 cross GL1 in some instances. So, this would be the group that you will do the integration over to get. That you will do the integration over to get the zeta function. And now we want to extend. So, what is the next step? Is to have this G reductive and connected. Over K, we'll assume it's split. Go has done some work for the non-split cases. Let me assume I have a finite dimensional representation rho of G-check, which is Lg to GL of B rho. It is finite dimensional, and we want to attach to rho is a Attached to rho is the monoid M. We do this from ground up. We start with the maximal torus. We start with the maximal torus T and G. We fix that. Then we look at the dual torus. This is the T-check. This is the dual torus. And we restrict rho to it. And it will become a direct sum of the weights of rho. This is a representation of the L-group. So when you restrict it to the maximum torus of it, it will give you the weight. It will give you the set the weights of this representation. So, this would be our weights of this thing. And of course, the duality tells us that the character group of T check is the same as the co-character group of T. And let me call that lambda. This gives the rational structure that we need for the convex geometry that we will be working with. Now, w rho, which is the set of weight, will be a subset inside. is a subset inside x star of t or x star of t check whichever you like and then of course this has a i mean this is embedded in the euclidean space you just take lambda r to be lambda times lambda tensor r over z so this is this is the the euclidean space that we work with then you will take the cone generated by this weight just the natural weight that we define a cone this is a semi-group so the cone is defined This is a semiconductor. So the conus defined sum of all the linear. This guy did something crazy. All the linear. Let me fix this. This is a mess. This guy just switch off. Okay. So this is this. Okay. All right. So it's some of the C lambda lambda. Some of the C lambda, lambda, C lambdas are non-negative real numbers generated by the elements in this finite set W rho. So this is the cone and that is attached to the base generated by base and we denote it by C of rho. And of course we define the duals. We need the duality. I mean this is the theory of toric varieties. You take the characters of T, co-characters of T check, and you tend Of t check, and you cancel it over, of course, again over z by r, and you find this Euclidean space on the dual situation. Of course, lambda r and lambda r star are in duality. And this C of lambda, this thing, I mean, you take your cone, you have your cone here, and you have your cone here, and you dualize it. So this would be inside lambda star of R, and then you. The store of R, and then you intersect it with X star of T. So you get the rational structure, you get the rational dual cone sigma check. Now, this is very important. It's group algebra. Let me denote it by K of sigma check. This is group algebra of the semi-group. So maybe one should say group semi-algebra of, I mean, semi-group algebra of the semi-group sigma check. And sigma check is embedded inside K of Sigma check by attaching to an element there. Attaching to an element there is characteristic function. Now, it is very important to have a character. That's why this theory of, I mean, this reductive monoids, which are the monoids whose interior is a reductive group, do not really work for the semi-simple ones. I mean, you cannot find semi-simple groups as the interior of the monoid, the reductive monoid. And one important reason is that since your group is reductive, you can have a character. Can have a character, otherwise, you would have no character. There is a very nice character. This character new is basically obtained in a way that is dual. So, if I go, so this is G to G M, I dualize it. So, I'll go from C star to G check, and then I compose it with the representation rho. The result, I'll go from Z to G L of 0. I want this to go to Z times identity of rho. Now, then you will quickly see that the pairing between nu and omega is equal to one. Nu and omega is equal to one for all the weights omega in all the weights of rho. And this will tell you that this new, in fact, is in sigma check. Remember the definition of sigma check in here. So this will tell you that nu is in sigma check. And that will tell you that c of rho is strictly convex. Strictly convex basically means that it cannot have any full lines in it. You could have it, I mean, half lines, you could have, I mean, I mean, half nines, you could have, I mean, E1, E1, and E2 are the basis of R2. You could look at the cone generated by E1 and E2. That would be a strictly convex. But if you take cone minus E1 and E1, that is not strictly convex. The nice thing is that if you have a strictly convex cone, then you can produce a variety which is normal and it's unique in some sense. Now, this C of row uniquely determines a normal toric variety. A toric variety is just a normal. The toric variety is just a normal affine torus embedding. So dt goes to mt. It is densing here. This is really the closure of the whatever embedding you want to put it. And mt can easily be given by the spec of this k of sigma check. So you have this group algebra, k of sigma check. You take all these maximal ideals, I mean the standard things in algebraic geometry, and you end up with this variety mt. This is your toric variety. t this is your toric variety now the fact that you had the fact that the fact that you had a a strictly convex toric variety will assure that you will get a normal affine torus embedding so that this this mt is normal as a variety now and x of mt these are this is the mt is going to have the characters they are semi-group send they are character semi-group it will be a semi-group itself Semi-group, it will be a semi-group itself. And remember, sigma check is a cone, it's a semi-group. And the point is that these two are equal to each other. And this thing generates K of M. The polynomials on M are generated by this character semi-group, X of M T. And then I use a funny notion for push forward. And what that is, I mean, you have an embedding of T, you have this embedding of you have this embedding of T in M of T and that leads to a push forward. And that leads to a push forward from characters, the character semi-group of MT to the character group of T. And the image of this thing, and the image of this thing consists of dominant characters of T. And these are exactly those characters, those characters which extend to semi-group morphism from MT, from this toric variety into A1. Just here, I find one line. I find one line. Now, and in particular, nu is in this space, nu is in J star of X of M T. Now, the wall group, this structure is so that the wild group which acts on t and x of t also acts on mt and x of mt. So this is the characterization of this normal variety that we have. Now, if I take, if I Now if I take if I take a lambda dominant and of course it is integral a dominant weight then of course when the group is semi-simple there is a simple natural way of defining a finite dimension in a finite dimension meaning a rational representation a rational representation of G and then you naturally can extend it to the full group even though the group is no longer semi Even though the group is no longer semi-simple. And there are two constructions of the monoid. And let me define Renner's construction. That is the one that I will use. And it behaves reasonably well with what we want to do. I'm sorry, any questions so far? I don't want to be going very fast. That's the yes, wha what what's the difference in the two different constructions? In the two different constructions? Why do you need both? I don't need both. I don't need both. I said just there are two. I mean, you can, I mean, in Reynolds' book, he shows that they are equivalent in some sense, but I don't need both. I only need one of them. I only need, I'm going to use Reynolds construction because I'm going to use this. I'm going to do examples of this construction. And Reynolds is in some sense easier because I can do the full monoid and everything, at least to me. Done everything, at least to me. Okay, so let me choose now. This is how Reynold constructed the monomer. Let me choose a finite set of these, the finite set of these dominant characters, which are I show you integral. And in a way that if I look at the W translates of this lambda i's, their union generates this character. The character semi-I mean semi-group. And then for each of these, these are finite number. For each of these, as I said, I'm going to have a finite dimensional representation. So the space is going to be V of lambda i, and mu of lambda i is going to be the representation attached to lambda i. Now, of course, you set mu equal to the sum of these mu i's and v equal to some of these v lambda i's. I mean, it's a similar construction as in Winberg's. Is in Winberg's. I have studied that one too. But in this situation, I decided to do it this way. Now, we may take that mu1 to be that mu that we had, that character, which is very, very, very, very important to our setting. And then we can define this monoid M1. You take mu, you take mu and you eval mu of g. That would be, of course, inside the endomorphisms of V. This is V. And then you take its closure. And then you take its closure. You take its closure. That would be this monoid M1. Now, this monoid may not be normal. So you have to normalize it. And that's pretty easily done. I mean, the units don't change. I mean, the units of the two monoids don't change. But then you will be working with a normal object and life would be easier. Now, let me do an example of these things. So, what I'm going to do, I'm going to do the case of symmetric powers of. Of symmetric powers of GL2. So for GL2, the L group is GL2C, and the symmetric powers are just the standard n plus one dimensional representation of GL2C up to a twist by determinant. They are all unique. And the weights are just denoting by mu i. I will evaluate them. I mean, evaluate them. I mean, this, everybody knows what this is. I mean, this everybody knows what this is: mu i, a diagonal of x and y is x to the i, y to the n minus i. And then you can check that the cone generated by that, when you restrict it, when you take the rational parts of it and intersect it with x star of t, which is the same as the character group of t check, it's going to be pair. I mean, this is pretty easy from this thing. It's a pair of pair of integers m and l bigger than or equal to zero, which add up to m times z. add up to n times z. So they will be in this lattice n times z. And the dual cone will be, you can compute, the dual cone is going to be this. All the pairs A and B, A and B bigger than equal to zero. And then they are no longer in Z, but one over NZ times one over NZ. So they could be in this smaller, this bigger lattice one over NZ. A and B are again being equal to zero, and A minus B is in Z. And then C. Z and then sigma check is just going to be this. You can check that's going to be the span of these three vectors 1 0 0 1 and 1 over n 1 over n. Now, let me call these elements the images of these elements in the k of sigma check in this group algebra of the cone sigma check. Let me take this image of this, the x and y and z images of this thing. And then you can look at the polynomial ring of this thing. The polynomial ring of this thing is just going to be k of xyz divided by xy minus z. I mean, this is obvious from the relation between these. x times y is going to be, I mean, when you raise to the power m is going to be equal to, I mean, when you take this at root, it's going to be equal to z. Now, then the spec of this thing, spec of this thing is going to be empty and to see how empt looks like, this is going to be in this. Looks like this is going to be in this three-dimensional space. So you want to see the torus, how it looks in this space. You intersect it by k star of k star cube, and this will become the torus. The torus will look like this, t1, t2 to the n, t1 inverse, t2, and all the ti's are, of course, in k star, and i is equal to 1 and 2. Now, now this is the toric variety which is attached to this, which is that which is attached to this. Which is that which is attached to this representation rho, in fact, representation rho restricted to T, T check, in fact. So, this is the variety, this is the monoid attached to rho restricted to T check. Now, T is a T is a reductive group, so we can talk about these things. Now, let's find the one for GLN, GL2, I'm sorry. And this would be the monoid for SIM N. And let's do that. First of all, we can draw one of these with zero and one and one and zero W conjugate. I'm going to take one, zero. conjugate I'm going to take one zero and then what remains the two lambda i's I can choose them from this set one zero and one over n one over n and then these are both dominant weights the representation one is going to be one zero goes to standard representation and then one over m1 over n goes to nth I mean nth root of new I'll I'll show you how this will take how does this take place now when we have these two things Now, when we have these two things, so let me write that one directional space V sub ν. Now, of course, this will be V standard. So, the map will go from endomorphism of V standard direction V nu. And that is M2 times A1, two by two matrices. And G will go by the very definition, G will go to G and this character nu of G, which is the determinant to the power of one over N. And then, of course, I'll find this. And then, of course, I'll find this M1, which would be the closure of ν of G, and it's just going to look like this: it would be a spec of this thing. And let me make it, let me tell you what are the units. The units are basically a fiber product of GL2 with Gm. So you can see it is just pairs of G and A. So the determinant of G is A to D M. If you compute these things, you'll see that this. things you'll see that this n star the one the the g that you will have to work with is really either gl2 when n is odd or sl2 times g n gl1 when n is even and being this being a fiber product you have this diagram here you have gl2 cross gm projection one projection two takes you to gm projection one takes you to gl2 you take the determinants you go here so you really have this setting you have g and a going to Seven. You have G and A going to G, and you have A here going to the determinant of G, which should be equal to A to the N. So, as a result, knew really nothing about this projection too. So, it will give your itself to you. And to check that it is really the right one, just notice that Z under new check is going to go to diagonal. Z to the one over N, Z to the one over N. And the roots doesn't matter what kind of roots you choose because when you do sim N, it's just going to go. You do seam n, it's just going to go. I mean, when you take the algorithm and apply seam n to it, you're just going to get z times the n1 identity of n1 plus one dimensional space. So this is really, this is really your new, and you can, you can use this to define your monoid and everything. And this Reyner's construction behaves well with induction. If I have a parabolic subgroup P equal to Ln. Group P equal to Ln, then L is always uniquely chosen. We had a T, we started with the maximum torus, we will uniquely take it to be containing T. And of course, I have the representation rho of G check. And I look at rho L, just rho restricted to L check. And then, of course, with rho L, I can define by render, I can define a monoid M rho L. We also have L sitting inside G. And thus, if I take nu of L and take the closure of it. of L and take the closure of it, the point is that these two are equal. The one defined directly is the same as the one you get it as a being a subgroup, as a being a subgroup of G, closed subgroup of G. Now, so this is at least an introduction to construction of the monoids. Yesterday, Jillian, you talked about it, did a survey of the subject, and today Jace gave some more case. Some more cases and expositions. And tomorrow, I think Go is going to give us a talk, which I'm really looking forward to. And so they will somehow be related to these issues of Schwarz functions and Fourier transforms. So let me try to talk about them in general, in some sense, in generality. We need, if you want to extend the Gaudemanjo K to arbitrary group and arbitrary row, we need, of course, a short space. We need, of course, a Schwarz space which does that. So this is usually will be called a row Schwartz space. Rho is again the representation of the L group. And then this thing, the space of Schwartz functions of type rho should exist, which would generalize Gonemann-Jockeys and for which you can develop Gonemann Jockey. One expects that these things be contained in here. C. The Schwartz space should be inside, so it should be smooth and should contain. So it should be smooth and should contain the C C infinity of G. And of course, when I say G, I mean the rash k points of G. Now, similarly, you have the same thing for parabolic subgroups. If I have P equal to Ln, then with the usual assumptions that L contains T, we should have that C C infinity of L is contained in the short space of rho L and then in the C infinity of L. You can relate this rho of G to the rho of g to the functions on m not functions on m rho but again smooth functions who if you take the support if you take the support of this function it will be inside the intersection of a compact subset of m rho and g k so this is one this will be one way of defining these things and now to set up the to set up the zela functions which will do what which will generalize what golden mind you okay wanted and then and that Okay, one it and then, and that's, of course, the final plan so that we can really understand the properties of these L functions. And I mean, using converse theorems, you can prove cases of functoriality. To do all of that, you need to do some preparation. There is, if you remember, there was that n minus one over two in the case of GLN. We have to take account of that. So, let me put A d to be half the sum of the positive roots in a Borel subpoena, B containing. Borels output B containing T. Let me take lambda to be the lowest, the highest rate of rho, and let me just evaluate 2 eta g at lambda and then define this object. So this would be mu to the power 2 eta g times lambda. So this would be like that power determinant to the, I mean, n minus 1 over 2 that we have. Now we have the representation pi irreducible admissible representation of g of k. We will not want Of k, we will not want to have s, we don't want to carry s around, so we're going to twist, we're going to twist pi with the this absolute value of mu to the power s. So we replace pi with that. Of course, when we do the other side, we will have to replace with the we will have to replace with the inverse of the of this is these these machines. These machines are crazy. I mean, I teach online using this, and sometimes it just behaves really crazy. Okay, now f is again the matrix coefficient of pi, and again, we have f-check matrix coefficient of the control union of pi. And then we have a function phi in the Schwartz space. You can just set up the zeta function as before, an integral of phi of g, f of g, delta of charge. This remember, this is that. Of your this, but remember, this is that absolute value to the n minus one over two in the case of G Ln, and s is absorbed in here in pi and therefore in f. And to set up the other side, I mean the pair Gaudeman J, we have to use the Fourier transform. So this Fourier transform is supposed to go from S row to S row. And I mean, you know that if you have a function of compact support, I mean, it will, I mean, in the standard situation. I mean, in the standard situation, it could never go to a function of compact support under J rho. So you expect similar things to happen. Now, in the other side, I have to define, I have to also introduce a zeta function through which I can get the gamma. And again, this is how Gaudeman and Jacques did. You need the Fourier transform, you need the matrix coefficient of the contragradient. And we have, of course, absorbed in the F the effect of. The effect of minuses, the new to the power minus s, and so, and then we have this extra factor. That's why I call this z tilde. This extra factor is the effect of s going to one minus s in the functional equation. And then if you do that, then of course you have this z bar of z tilde of j rho of phi and f check is equal to gamma z of phi and f. Now this scale. Now, this scalar, of course, depends on S, but it really is a rational function. Let's call it a rational function. Jehidi, let me ask a question. Where's the additive character? It will come. Okay. The additive character, I mean, it will come. I mean, okay. Now, I should have put it in, but I didn't. It will come. It will come to roll in. All right. All right. Now, one of the important things that we have to deal with, which is the whole idea of what Gaudeman Joquet did, and the whole idea of all the people who work on L-function, is the unramified situation. If you have a, in the case of Gaudeman-Joquet, you take a characteristic function of Mn of O, it has to have the property, and then you plug it in together with the zonal matrix coefficient, it has to give you the L function. And so if function and so if i take f naught to be the normalized spherical uh co i mean the matrix coefficients of pi of g v and v tilde and then i'm assuming of course that this is equal to one and they are both invariant under the effect of k then this z must give you that and of course the right way of looking at it and the right way that now people look at these things that and this is the language function attached this is language and grammified function attached to L function attached to the representation pi naught. And one thing that people do is that they start with this thing. This is a function. You can define it as a function on t check, get w invariance of t check. And then you can, this is really on the heke, I mean it's in the hecke algebra of t, and then you can apply inverse subtlety transform on it. And that should give you that delta for that, that should give you that basic function. So that's the way. Should give you that basic function, so that's the way I think Castleman has some nice writing, which I will refer to it at the end. And it says that if you know, I mean, the Satake and Shimura tried to do what Godem and Jake did for Simplicik group, I mean, GSP4, and they had trouble. And it says that if they would have looked at it by looking at the inverse Satake transform, then they would not have as much trouble. Now, so it is clear that we need a short space, a strong. A Schwartz space, a strough G. We need a Fourier transform on it, JRO. And at the moment, the only cases that we really have everything about these things is, of course, Gaudeman-Joke and P.S. Ralis's doubling methods, which of course was completed by Lapid and Ralis. And this is the cases that within this new context has also been looked at by Wenwei Li and Jiang, Lu and Zhang. Lu and Zhang. And so I should mention these things. And there are some quadratic spaces due to cases. In these cases, we have these objects in the case of doubling, it's an intertwining operator, a degenerate intertwining operator. Now, to state some of the things that would help if we assume, is that let's assume that we know how the Fourier transform acts on the smooth functions of compact support. And we can define. Support and we can define a minimal provincial short space to be some of this thing and JRO acting on it. So, this would be a provincial space. It's usually, I mean, this is smaller than what Problem and Kajnon had in mind, but it would be very helpful to us in any computation we want to do. The first thing is that there is a uniform smoothness about these things. There is no uniform smoothness if a smooth function is not of compact support. Is not of compact support. I mean, it's not a priori true. If you have a function of compact support, it is uniformly smooth. The argument of the function won't play a role. So let me just state it in a natural way. Let me take K an open compact subgroup of G and let take phi to be a function in this space. Then if you look at the space span by the twist of phi, I mean both translations of phi in both sides by k1 and k2, both of them in k. And then of course the definition is here. When, of course, the definition is here. This space is finite-dimensional. So, it is it will tell you that although the Schwartz function is not con doesn't consist of functions of compact support, but still it is one dimensional. And in calculations that you do, this is very helpful. So, one thing that is there is that we have uniform smoothness, at least for the functions living in space. Another fact is that. Another fact is that one can use, I mean, one can prove just using Satake isomorphisms and JRO for tori that Goh has studied them. I'm sorry. And some GL1 calculations, you can show this is. You can show this is a proposition by myself and my student, William Sikorsky. The basic function phi naught belongs to this space. Excuse me. I've been talking too fast. Okay. Okay, before I show this proposition, okay, before I prove this proposition, let me introduce some other object. Okay, hot water out. So, let me define row high chandeli transport. Find the Roe-Harishandro transform. First of all, we have the Harishandro-Sitagi transform. It is the usual way. You take the constant term, you take the Fi P of L is delta P to the minus half of L times the constant term. Integral over N of K. Let me define an analog of this delta G rho. This would be delta L rho L. So this is on the levy and then let me also define delta L. also define delta L rho L to be nu L to the power and the eta L is just found by restriction. Now lambda i's are the highest rates of rho L, restriction of rho to L. And then let's put nu of G L, which of course depends on rho to be the ratio of these two things. And the rho Arishandro transform is this. You take the Sataki Arishandra and you multiply it by this extra factor. This appears in the work of Lafour for GL2. La4 for GL2. So it seems to naturally be of interest. And then what you really need to move on is that you need the commutativity of this diagram. We have J rho going from CC infinity to its image. You have also J rho L going from its C C infinity to its image. You have down here a rho arch chandra and down here another rho arch chandra. I'm assuming that this converges and then commutativity of this is very important. For example, Is very important. For example, it will prove for us the multiplicativity of these gamma factors. Multiplicativity is very important. And I mean, in any theory of L-functions, you need them, allows you to compute, allows you to prove a lot of results. And in my work with Kim in proving functoriality, this thing played a central role in our approach. My hope is that even, I mean, it is, I mean, if it is assumptions, you can prove it. These assumptions you can prove it, and I expect that in Kodeman Jok generalized by problem and causing that things is absolutely a very uniform proof for all the cases. And we can show that. We can show that. And so let me take sigma to be an advisable representation of L of K. Let me take pi to be induced representation from sigma. This may be reducible. And what you take just as And what you take just as any of its irreducible constituents, that's irreducible. You can define a gamma, gamma of pi naught, and rho. I'll call it gamma of pi and rho. The nice thing about gamma is that it is invariant on the constituents of the induced representation. That's not true of epsilon or L, but this is true. Gamma has this property. And multiplicativity basically says that if you have that diagram star, then these two gammas are equal. Then these two gammas are equal. Gamma of sigma rho L is the same as gamma of pi and rho, and gamma of pi and rho was the one attached to any constituent of pi, of the induced representation. Now, this is a consequence of that uniform smoothness. You need the uniform smoothness to prove this. Now, let me sketch for you how do we show that the basic function lives in this provincial space. It is a Provincial space. It is a simple proof. I mean, it just goes through if you do it step by step, the way that the theories developed through the Sataki transform for toroids. And of course, the proof. Now, first of all, let me assume that we are in the setting that G is equal to G L1, M is equal to 1. So the simplest cases, and J rho is the standard Fourier transform. Okay, I'm assuming size, I'm ramified, the Fourier transform. Ramify the Fourier transform is just defined like this, and then I'm going to normalize my measure to be equal to one on okay. And let phi naught be the basic function. So that is just characteristic function of okay. And let me look at the, you can do a simple calculation. If pk is the maximal ideal of ok, then phi naught is going to be one over q minus one, characteristic function of pk inverse minus o k. inverse minus okay plus q times over q minus one now notice that this is in the space of foul transform of a function of compact support this is a function of compact support and this itself is a function of compact support so the fine node on gl1 leaves inside cc infinity of functions of compact support plus the fourier transfer so in the case of gl1 this immediately is valid so you will see that phi naught is going to be That phi naught is going to be is going to be in the thiswara space for a standard of this guy is again in here. And now assume you go, now assume that you go to the torus Tm, GL1 to the power n, maximum torus of gln. Then of course you use this thing on every coordinate, so you easily have the same result that phi TN standard is F1 plus J standard of F2 for two functions. Plus J standard of F2 for two functions in C C infinity of T n of K. Then you can extend it to all of G L N. You use Saturday isomorphism. You have this spherical vector algebra here and the spherical Hector algebra, I mean invariance of this spherical hectares algebra on T n standard there. And again, the same story. I mean, we take phi standard GLN, that would be Satake inverse. I mean, you take the Satake inverse, you go from the T side. Inverse, you go from the t side to g side, so that would be Satakin inverse of F1 plus Sataki inverse of J standard of F2. Now, here you have to commute these two. That would mean you need star, but in this case, star was proved by Godeman and JK. You can twist them. So, Satochi universe of F1 plus J standard of Satochi universe of F2. So, you again see that the basic function for standard representation is inside. Standard representation is inside set out inverse of GLMK. Now you go to the general group, the general adoptive group. G, we have T maximal torus of it. We have raw representation of G check. We have the weights. We have restriction. And of course, dimension N, we write rho T as sum of the weights. And then we look at the dual situation. So we get this map rho t tilde from x1 all the way to this to this. So this is this is pretty standard dualizing. Are dualizing, and then you let u to be the kernel of rho t tilde. Remember, rho t tilde is given in here, stars on gmn, so it points its kernel. And you also define a character, h p psi, this is psi comes in, you have x1 all the way to xn going to the psi of x1, so the psi to the composed with trace, and then go defines the Fourier transform on the torus in this fashion. J rho t of the torus is integrated. J rho t of the torus is integration of this H over UK. And then you again have this commutative diagram here. This is very easy to prove using this definition. This is rho star. This is the push forward of O T tilde. I said I use a funny notation, but it is what it is. I have rho star going from a standard Tn to S O T of T and this is by definition image of rho star. This is how. Image of all star. This is how Go defines these things. We have J standard going from here down, and we have J rho T going from here, and this commutes. So again, the same story. You take rho star of phi Tm standard is going to be called to phi T rho, and then you apply, again, you do rho star of F1, rho star of J standard, F2. And this is rho star here. And then again, the diagram tells you that you can move it around. So you will see that the basic function on the toroi. That the basic function on the toroid of this reductive group belongs to the space of C C infinity functions on it, and it's Fourier transform. And then, of course, it's natural. You immediately know how to extend it to the group itself. And that is, you just put J naught to be restriction of J rho. We don't know what J rho is, but we know what it is on the spherical part because we have the Sataki isomorphism, and you have this general commutative diagram. Commutative diagram, and you start again. This is not a basic function on the full group G, that is Satoki inverse of the basic function on rho T. And then you apply again Satoki inverse to some of these two things. And again, you go through, I mean, these two commute with each other. And you're again going to have the Satalki, you're going to have this, I mean, the basic function belongs to some of these two things. So you will see that the basic function is in a stroke of G. Basic function is in a str of g. So the basic function belongs to this provincial space that we define. Now, I decided to put in some papers here at the end. This is supposed to be semi-expository. Of course, there is NGO's Goh's paper on Heichel Transform with the Japanese journal. There is their paper with Boutiye, Go and Saclaridis. This is an American journal, Igusa Memorial Volume. In this thing, they really get the basic function. They really get the basic function out of the geometry of monoid for function fields. Castleman has done a bunch of calculations for symmetric powers because, if you look at the, as you said, if you look at the, if you look at the way the L function leads to the basic function, you have to do it. You have to take an inverse for your transform. And then you will need to decompose. I mean, the symmetric. To decompose, I mean, the symmetric powers of representations, and he calculates the multiplicities of these things very clearly. And it's a lot of work. And that appeared in the bulletin of Iranian Math Society in 2017. Well, I think I'm done. I'm sorry I went over, but I started a little late. I hope you forgive me. Well, first of all, happy birthday, Bill. And secondly, look at this cartoon from Chalvin and Hobbes. I mean, just I'll leave it to you to read it. I'll leave it to you to read it. This is about having faith since we are this stuff that we do really need faith. Just read it through.