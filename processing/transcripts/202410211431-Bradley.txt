Starting to meet all of you, and I'm looking forward to a great week. So, this is a tutorial on diffusion, and this is based on a written tutorial that I worked on with Preetam, who is here, as well as our colleagues Hadi and Madhu. And basically, this is sort of intended as an introduction to diffusion for the mathematically in Khan, such as Rosalind. Mathematically in kind, such as results. But if you're already familiar with diffusion, I hope it can provide maybe some different ways of thinking about things. Okay, so just start off with a diffusion image. This was generated with SDXL, which is one of the most popular text-to-image diffusion models that many of you have probably played with. The prompt is photograph of a cat eating sushi with chopsticks, and out comes this quite detailed. This is quite detailed and impressive image. So, you know, diffusion models are really sort of exciting these days, and basically it's interesting to sort of understand how they work and what they're really doing. So, diffusion models are basically a class of generative models that have become very popular recently for text-to-image diffusion or text-to-image generation in particular, but they can be used also in other domains. Be used also in other domains, video, audio, even things like 3D modeling. And even also some discrete domains, although they haven't been quite as successful in those domains for reasons that we don't completely understand, although we speculate. So there are some interesting advantages that diffusions offer over alternative generative models like autoregressive models and GANs. So compared to GANs, they have better training stability and mode cover. Stability and mode coverage. So hands are sort of notoriously problematic in those areas, and diffusions do better. They offer non-autoregressive sampling, although it is still sequential in a different way. So auto-regressive sampling, some drawbacks are that basically it's linear, like the generation time is linear in the number of tokens you need to produce. And also you don't have sort of a global view of the thing that you're trying to produce. You only just sort of get to see what. To produce, you only just sort of get to see what you've done so far and click the next token. Although, autoregressive models obviously work very well in many domains and better than diffusions so far for a lot of things like text. So, diffusion models empirically are very well suited to image and other perceptual distributions and have done very well there. And then also they have very nice theory, which I hope I will convince you a little bit today. A little bit today. Okay, so the sort of super high-level view with diffusion is that the idea is: imagine that you take an image and you add a little bit of noise to it over time. And then you train a model that is able to just remove a little bit of noise at each time step. If you knew how to do that, you could start with pure noise and just remove a little bit of noise step by step until you had a clean image. Up until you had a clean image. Okay, so the first piece of that is what's called the forward process. And all you do is you take a clean image, like this dog, and at each time step, you add just a small amount of Gaussian noise. Until finally, you have removed so, or you've added so much noise that the clean image is gone, and all you see is just pure noise. And so, if you think about this in terms of distributions, basically, you can't see this closely, okay. You can't see this book. Okay, basically, you have this distribution over your target distribution, the thing that you want to generate from. And then at each step, you add a little bit of noise, which smooths it out a little bit. And finally, by the time you've added big T steps worth of noise, you've smoothed it all the way to just a gaussian. Or close enough. Okay, so if we take that image and sort of flip it on its side, we basically can think of these stochastic trajectories that are. Stochastic trajectories that are taking us from some point on the target image distribution onto the Scaussian distribution. Well, just a sample, basically. Every pixel is a Gaussian image is a Gaussian. I see what you mean. So, in practice, often you embed, you sort of use a latent space, but like you can think of it as just your X is the image. Just your X is the image. It's all the pixels of the image. And the Gaussian, the Gaussian is just in the same space, same pixel space. So if you have like an N by N image, you have an N by N Gaussian width, just IID, basically. Some colour which is the zero colour, or what's that? You you have so many coordinates, right, in this image. But space is a space of encoding colours as being numbers or well so I guess like you can you can sort of encode it however you want and then you just Because what what's a zero image? Around zero. What's the zero image? Well, it's average image. Like you embed the images in arbitrarily. And then now you just have a distribution of the images. Think about using like your favorite neural network, like Yeah. So it doesn't really look like a very interesting image. But yeah, a Gaussian image looks like this way. Okay, so basically we have these stochastic trajectories that are sort of These stochastic trajectories that are sort of mapping you from your target distribution to a Gaussian, and you can also think about that as a probability distribution for each time t that's sort of evolving from your target distribution into a Gaussian. Okay, so that was the forward process. So now let's talk about how you reverse this. So our role, of course, is to generate samples from the target distribution P0. And the key insight of diffusion is that many The key insight of diffusion is that maybe it will be easier to reverse these intermediate, small noising stacks than to sample directly from the target distribution. So like again, for example, basically the generator is trying to just go from pure noise and just generate, just go straight to the data distribution and generate something. But we're hoping that basically denoising a small amount of noise that's been added will actually be easier than making that full jump. Making that full jump. So, the sub-problem that we pose is: given a sample that's marginally distributed as Pt, we want to produce a sample that is marginally distributed as Pt minus 1. And if we can do that, then we can start with pure noise and then apply that denoiser. It's pure noise, nothing. So, information theoretically, it has no signaling. Like you you there exists some app for Magassia to within whatever this is a cat and not a building because you loved a very special no network that that like maps to cats and not buildings Okay, so one thing that you can think of is ignore the pure noise you can know what the mean of the data distribution is and in fact that's the first step that you take into That's the first step that you take in diffusion. So. Maybe it will become more clear as we go. Okay, so basically, let's suppose that we did know how to solve this sub-problem. Then we're going to apply that process iteratively, starting from pure noise, removing, applying this denoising step that maps us from Pt to PT minus 1, and finally we get a sample from P0. Okay. Okay, so the sort of the most obvious way to solve that sub-problem is: remember, we want to produce a sample marginally distributed as xt minus 1. So, let's say we have a sample z from Pt, and we want to produce a sample from the conditional distribution p of xt minus 1 given xt. And then, of course, it will have the correct marginal given that c is sampled from pt. So, that is one. From PT. So that is one thing that would work. It's kind of the most obvious thing. We call it DDPM because there are very popular samplers from these papers that are essentially that. And that's sort of the first kind of sampler that people really consider. And okay, so how are we going to produce this sample from the conditional? Well, we use this general fact that if you have a, if your probability of y given x is probability of y given x is a Gaussian with mean x and varying sigma squared, and sigma is small, then the probability of x given y, so flipped, is also Gaussian with the same variance and some unknown mean. And the mean is expectation of t minus 1 given x t, of course. So basically that, when we apply that to the diffusion situation, Diffusion situation, that means that in order to do this denoising step, actually all we have to do is learn the mean. It's much easier than learning sort of an arbitrary unknown distribution. So basically, yeah, in order to solve this reverse sample problem, all we have to do is learn the mean. Okay, how do we learn the mean? Well, basically, the conditional expectation, or sorry, the expectation of Xt minus 1 given Xt, we can get actually just by solving. We can get actually just by solving a regression problem. And we basically parametrize this with a neural network F T that depends on the denoising time T. And then we're going to solve this regression problem. So basically, the cool thing is that we can actually get the training data that feeds into this regression simply by sampling from our target distribution, so, for example, plain images, and then adding. Plain images, and then adding noise in the forward process to get our samples xt minus 1 and xt. And so that gives us, that's what we're taking the expectation over, we're able to generate that data efficiently. And then we basically want to train a neural network using this regression loss, and that gives us our required expectation. How do you put your neural network? How big it is, what the architecture is. How big it is, what the architecture is all. Oh, this is the heart. Okay. The biggest network you can possibly train given how many GPUs. We are in the Texas of Canada. Do you have to have like T different means, or is there some kind of like martingale thing going around with you? You need to learn. Basically, you condition your network on T and you think of this as sort of a separate model. And you think that this is sort of a separate problem for each technique. Like the network is allowed to share information. Like the network, if it's big enough, it could sort of split this into two completely separate problems, but it can also, if it wants to, share some information. But in general, you kind of think about these as being sort of separate problems, but you end up just doing one big network that's conditioned on top. But how does the, like, I don't know, like, I don't, I'm not being super familiar with any of that stuff, but like, how does the complexity or whatever? Stuff, but like, how does the complexity or whatever store? So, you can imagine different levels of how many times you want to have. Um, is it just like, yeah, like as you, if you want to make it very, very fine, is that gonna, how does that scale with your choice of T of I don't know if that's a real question. Yeah, okay, so one thing that's actually pretty important is that remember this point, this depends on. Point, this depends on sigma being small. So you need to have your delta t be sufficiently small so that this property actually holds, and that's really crucial. So having like sufficiently fine division of t's. In terms of the efficiency, I would think that, like, probably if you have really, really fine-grained tea, the network would be able to share more information. Would be able to share more information at sort of this, like, because you would think that probably the denoiser isn't super, super different when the time is really, really similar. So, there would be some amount of like sharing between the voids. Yes. So, this seems to suggest that sigma stays the same, the variance stays the same. Yes. How is that denoising? Variant stays the same. Okay, so basically, we are not actually trying to. This is for a single This is for a single syllabus. Basically, this is for like one of these. Let me see, maybe one of these steps. So basically, we're just saying going from here to here versus going from here to here. The forward and reverse process. But yeah, I kind of see your point. I see why that's confusing, let me think. I think you're we scale. I think you have weights so that we keep the variant constant. Shrink the previous image. Kind of like an Ernst Dein rhyme processing and that's kind of the So you you scale down your noise in your previous image so that you always have basically the same scale? You certainly can do that and that's actually very popular in practice. Like it's called the schedule that I'm presenting here is called the variance exploding and then but more commonly in practice people will scale the data and then also Data and then also scale the noise. But I think that really what's going on here is that this is in the limit as delta t becomes very small. So is that we want to instantiate this lemma for y equals xt. x y equals x t and x equals x t. So like you want to instantiate this for one step but you end up adding out a bunch of devices. That you end up adding out a bunch of ways. Yeah, but you keep the sigma the same throughout all the steps. That just means like each incremental step adds sigma. Yeah, basically, just to go from xt to xt plus 1, we're adding just a little bit. The sigma is the variance of the change and not the variance of the image? Yes. Yeah. It's basically like. It's basically like if you compare like this this one to this one that like the sigma is the variance of the noise that you've added just each variance of the noise which is on top of the yes yes but yeah I think that basically to understand this just think about the limit as as dt goes to zero and then you basically aren't changing the variance. Changing the variance. But you've got the right parameterization. Okay, where were we? Okay, so, right, so basically we are trying to train the neural network FT using this regression loss, and then talking a little bit about how these networks are usually parametrized. Well, first of all, they're conditioned T, you're asking. They're also usually conditioned on a text prompt or some other kind of conditioner that guides the diffusion, and a common architecture, to your point. Common architecture, to your point, is, well, at least for text-to-image, units are pretty common, although there are starting to be a lot of different architectures that people need to see. Yes? Can we just ask like a very high-level question? So imagine that we didn't have any computational constraints, memory constraints, we just could just be in a perfectly non-commercial setting. We could make any ideal function. We could solve this in transition problem itself. Yes. So I'm wondering, like, how do we get Like, how do we get new natural-looking images? So, let's say I have my training data, I push it through this diffusion process, I do, let's say that I can now do the reverse just perfectly. Like, I am not constrained by any architecture. Would I get back one of the images that I fed in as my training data? Like, how do I see something that I haven't put into? Oh, right. Okay, so, um So more specifically, I'm wondering if that comes from the fact that F is construed. I think it does. Well, at least it works. But there's another aspect, which is the sort of generative aspect of it. So basically, I think you're correct that basically if you had infinite fitting capacity, then you would be able to perfectly fit your data set. And then for every X max. Every X map that you saw in your training set, you would know this denoising function appropriately. But there's the generative element of this, which is that you then sample from the Gaussian distribution. And so actually, what we're going to see is that there's also a deterministic sampler that is able to deterministically connect a point in the target distribution to a point in the data distribution. And so, if you think of that in your setup where you have this perfect, like. Have this perfect, like you just memorize the training set. Then basically, you will be able, if you pick one of the points in the Gaussian that perfectly corresponded to one of your training set points, it will give you back exactly that training point set. However, you now are going to generate a new Gaussian random variable, and that might not be one of those ones that you sought during training. And it also is going to know. Also, is going to know how to follow this probability flow back to the data distribution, and it can give you something else. So, if I'm like, the way that I understand this is you're learning a mapping from your image distribution to a Gaussian distribution. Yes. And then you calculate the reverse mapping from some random Gaussian. That's exactly, yes. Yes. Yes. That's exactly right. That's exactly right. What's missing here is how does the text prompt factor in? Yes. Okay, so in practice, that's sort of, I won't go into full detail on that, but basically what people usually do is they use these unit architects, well, they use different architects, but one that they use is called a unit, and it has like CNNs that basically work on the image part. And then they have like a cross-attention block that takes the text prompt and like cross-attends that with the image. Cross-attends that with the image, the noise. At a high level, where does the prompt come into this procedure? Okay, so the prompt is basically an additional conditioner on F. So you basically say what is now the expectation of XT minus 1 given Xt and whatever conditioner. So you're adding an extra conditioner into this expectation. Okay, maybe let's talk actually about deterministic sampling because I feel like it may also clarify things. Okay, so basically the sampler, the stochastic sampler that I just introduced, is only one of one possible sampler that you could use. And there also, there are many. And there are also, there are many other samplers, but sort of the most basic version of a deterministic sampler. So, surprisingly enough, it is possible to use a deterministic sampler. And this is one example of that. Okay, so basically, the stochastic sampler samples from the probability of Xt minus 1 given Xt by first taking a step in this denoising direction, which is the expectation. Which is the expectation of xt minus 1 given xt, and then adding Gaussian noise. And it does so in order to basically try to start with a sample marginally distributed as P of XT and get a sample marginally distributed as P of XT minus 1. Okay, but it kind of makes you think if you had to add noise back, this is actually sort of to your question about why do these have the same variance. So basically, you're Have the same variance. So basically, you're computing this mean, and now you're adding back the same amount of variance. So that's like a little weird, right? Like if you had to add noise back, maybe we actually removed too much noise to begin with. So in this deterministic setting, our goal is to find a deterministic function so that the push forward of Pt by Ft is approximately equal to F. is approximately equal to f to pt minus one, which means so that's like a different way of basically now getting a sample that is marginally distributed as pt minus one giving is given a sample as pt, but it's not computing the conditional expectation, it's computing this deterministic map. So basically it turns out that you can do this, that the solution to this is actually to still move in this same denoise. To still move in this same denoising direction given by the expectation of t minus 1 given x t that we had from the stochastic sampler, but we just take a step that is the right, exactly the right size. Not too big. So the stochastic sampler took a step in this direction, and then it had to add Gaussian noise, which is moving in the forward process, to get back to the correct point. So in this case, we're going to still move in that direction, but we're just going to go exactly. But we're just going to go exactly the right distance. And that's sort of the basic intuition of the deterministic sampler. And I just want to quickly connect this to SDs and ODs because I think this actually may make some things more clear. I hope. Maybe less clear. We'll see. Okay. So, and in a way, SDEs and ODEs are sort of like kind of the easiest way to really understand. Way to really understand this whole setup, but we're getting there now. Okay, so basically, remember our forward process was that we were going to basically compute our xt plus 1 update by adding a small amount of Gaussian noise. And okay, so now let's imagine that we take smaller and smaller time steps and we add smaller and smaller amount of Gaussian noise. That is, it has basically the Gaussian noise has to scale with the size of. Noise has to scale with the size of dt. Okay, if you keep making tinier and tinier Gaussian noise, what do you get? Well, a Brownian motion. And so basically, if you take the limit as you're shrinking these time steps and shrinking the variance correspondingly, you end up with a zero drift SDE given by dx equals sigma max dw, where sigma max is the maximum amount of noise that you've added by the end of the process. The process. And so basically, this is telling you that your forward noising process is literally just given by this particular SDE. And now we can use some heavy machinery of SDEs in particular. And this is actually for a more general SDE that can have a drift and a more general diffusion term. Basically, we have a theorem due to Anderson that says that the time That says that the time reversal of this SDE is an STE with basically the same drift, or sorry, the same diffusion term. And the drift basically takes this original drift and then it subtracts a scaled version of this, which is called the score, the gradient of the log of pt of x. Of course, we do not. Of course, we do not know this, but it turns out that this is actually very closely related to that conditional expectation that we've been talking about this whole time. And so basically the idea is that you can learn this score. So this, you know, this time reversal is no good to you if you don't know the score, which you don't in general. But if you can learn the score, then basically you can discretize this SDE and be able to run your stochastic. Be able to run your stochastic process backwards. And it turns out that DDPM is actually just a discretization of this reverse SDE. And finally, the SDE has a deterministic equivalent. This is due to Song. It has a deterministic equivalent that's usually called the probability flow ODE, where basically now the drift term, okay, out pops the score again, which we don't. Pops the score again, which we don't know. No free lunch, we still have to learn the score. But basically, this gives us a deterministic way to reverse the forward process, and DDIN is actually just a discretization of that ODE. And I'm going to, well maybe I have two more minutes. There are some interesting relationships to long-term dynamics, but we will just skip through that. Actually, you know what? Maybe I'll end here because I feel Maybe I'll end here because I feel like there were still a lot of questions, possibly. Or if I don't get any questions, I'll just.