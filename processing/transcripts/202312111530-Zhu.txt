So, for this talk, I'm going to talk about change for the detection for tensors, particularly with heterogeneous sizes. This is a joint worker with my student, a former student and Jing Hui, who is at the Chinese University of Hong Kong before he was at the City University of Hong Kong. Um so for this one, as I mentioned, we talk about the tensors. So actually, so once we collected the data over time, and then we want to detect if there is some data structure change. So this is what we want to do. In this research, we focus on, as I mentioned, we focus on the offline tensor data. Okay. So, and So and here I would like to see two points for this problem. Many applications present a data structure. One, a structure model for tensor that may be categorical, and a corresponding slides may be presented ketogenetics genetic. So here I give an example. For this cheat example of three-wheat tensor, and we thought And we thought here we have three modes. The mode one is import, export, and net chip. This is a three-dimensional mode. And we also mode two, the goods and the service. And the mode three, we will call the structure mode. For countries, we have four countries. So why we say this is a structure, the structure mode, only because for a different country, we cannot expect the trade. Cannot expect the treatment and the variation should be the same. This is very hard to see. So therefore, here we call this one. Later on, we call this a structure mode. So, and the problem is if we want to detect the significant change during the time spending for this tensor, and if we want to define And if we want to define the distance between the tensors, you know, if we want to detect the change point, we must define some kind of distance to match the change. So if we put all elements together, probably the information probably will mix up. So therefore, we want to consider some other ways to deal with this problem. Okay. Yeah. Okay. So how do you Okay, so how to do it? Actually, here we also have some other examples in the literature. However, we haven't seen any method to deal with this kind of heterogeneous problem. So therefore, in this research, we are going to propose a model, we call it a mode-based C. mode-based signal screen screen for VS distance for the moving sum called moving sum of difference between two different tensors. Okay, yeah. So for this method, we are going to solve the following three problems. The first one, as we know, for every change, we can imagine, we can say the magnitude are the same or the unknown. Same are they are given, so this is hard to say. So, therefore, we wanted particularly actually, particularly in the heterogeneous case. So, how to approx appropriately determine this threshold is an issue. This is only because in the literature, there are several methods. There are several methods. They usually don't take this problem in account. They want to use a committee rate to determine. To use a commuter rate to determine the search code. But here, we want to use some other way to deal with. The first, second, probably for the tensors, probably the size of the center probably very large. So therefore, and we can see the tensor probably sparse. So therefore, how to estimate the sparse, we call it sparsely level to adapt to the both dense and sparse model structure. Sparse model structure. This is probably the interesting problem. Okay, yeah. The second. And the third one, as I mentioned, here, we just want to talk about heterogeneous slice. This is why we talk about mode-based, or we can simply speaking, we use slice-wise. We define the distance slice-wisely. Okay, yeah. Okay, so how to do it? Here, as Java said, we just Java set, we just take it relaxed. We just talk about the idea and the methodology. So, therefore, here I basically introduce the methodology. I don't give the too much mathematics development. Okay? Yeah. So, in order to introduce the problem, we firstly give some notion about the tensors. Okay, yeah. Here, we talk about here, xr. talk about here xi is a tensor okay here we consider xi is independent here independent over i uh the cover or the cover tensors and then the mean is here and then this is the arrow tensors okay so so what we want to talk about actually we what we want to detect is the change over the mean okay yeah uh so this uh this is uh this is a model and here This is a model, and here, kava, here, I just give some notation. The kaver is a number of dimensions, each dimension is called a mode. Um, and here, the element, here we use, you use x here with a subscript as an element, okay? And here, another thing is, suppose we suppose suppose we assume uh at the cabba's mode is a structured mode, so this means we want to. Structure mode. So, this means we want to fix the cover mode, and then we have several slices. And later on, we will define the distance for the all slices. Okay, yeah. Okay, so once the mode, this mode is fixed, any slice actually is all the Kappa minus one tensor. This is easy to understand. Okay, and here for the trend point. Here for the change point, what we want to talk about is here, suppose we have key change points. So, what does it mean in our structure? So, here we say we have K plus one segments. Okay, yeah. So, so for each, this means we have K chain chain point. So, this means K different mean tensors. And for each, in each set. in uh uh in each uh segment in each segment the the mean is the same okay yeah um and we also give the definition we also give the alpha n star as the smallest different smallest distance between any two change points okay yeah okay so what we want to do is to estimate the number the number of uh change points here k and the locations here this is what we want to do What we want to do, so um, how to do it here, as I mentioned, uh, we want we don't want to mix mix the mix the information from the all slices together. So, and then we want to separate, separate them. So, therefore, here later on, we just fix the L. So, this means for each slice and then slice, and then we want to define some distance. Here, it's very clear for the different slides. It's very clear for the different slices, different sizes, the number of change points should be properly different. Okay, yeah. So, and then here we defined the CL as a set of change points for each slice. Okay, yeah. So, but all together, put them together. This means this sum equals, sorry, this sum equals the whole set of the change points. Okay, yeah. Okay, yeah. And so, as I mentioned, we want to define the distance slice wisely. And how to do it? Here, we different very, somehow it's a very naive idea. So, we define the following, we call the mode-based signal screening additions. So, here, we here is element in this slice. In the slice, in the slides, all elements in the slice. And then we use a hard threshold to select the all values. We call the significant value here. So we have this sum. So this means if this value, the element is larger than some threshold. At the population level, this L N equals zero. But at the same level, we should choose the Level, we should choose a small value. Okay, yeah. So if zero, this means if this value is larger than zero, we use it. Otherwise, we root out them. Okay. And here, the normate is same. And it's very clear. Here, it just here is just the average for the significant elements. Okay. However, we have this small value. This only because if the all values This is only because if all values are very small, and then probably this is this is one by one, this is undefined, and then we just add some value so that this distance is well defined. Okay. Okay, so afterwards, and then we can we move to the contraption of our signal function. Okay, so we first use a MooseM we call. So we first use a moon sum, we call the moving sum. This is an existing method frequently used in the literature. And this means we have the we have this here the sum in the first segment and the minus the sum in the second segment and then move forward okay with the i and when we can have this sum minus the next negative sum so this is a we call it a moving sum and actually for this moving sum we have For this moving sum, we have the following formula. But this is mathematics. Here, I just give you a plot to show. So, actually, we can find for this moving sum, it has a very good shape. So, it will have a good curve pattern. So, actually, here, this peak is according to the change point. Actually, this means this maximizer is according to one change point, and then and so on. Point and then and so on. Okay, yeah. It seems we can simply use this one to construct the statistics so that we can detect change points. However, as I mentioned, this is a peak here, the height of peak is unknown. So therefore, it's very hard to see where is the threshold to determine this to find this maximizer. Okay, yeah. So as I mentioned, usually we use Mentioned usually we use a commuting rate of this moving sum. But we want to get a better solution. Okay, yeah. Okay, so this is just the moving sum pattern. This is good, but this is not good enough. And now we want to use the following. So you can find here, you can find. Here, you can find this curve is periodic. If there is no change point, because it must be zero, must be zero. And then we call this change point segment. I call this a change point segment. We see in this change point segment, and that is up and down, and here zero and up and down. Something like that. Okay? Yeah. On basal, sorry. Based on this periodic pattern, and then we defined another signal functions. Here, it's easy to either we use this ratio to define this to define the signal function. This means here we have this moving sum at i, and here it's at i. And here it's at i plus f n. This means we have a sheet to the left-hand side. Okay, yeah. So, and here, ci is just we call the ridge. So, this means this rich is just one, you just want to prevent the zero by zero value. Okay, yeah. So, um, and later on, we want to choose an adaptive to change reach. It can perform the Performance can be better, okay? Yeah. So, and then I also give you a plot to show. So, this means here, this numerate, this is a denominator. And for the numerator, as I mentioned, here we have a peak. Here, this is this peak, and this peak is according to the trend point. Okay, we have a big dispute, the zero, and then up to up to the highest. To up to a highest and then down to zero, and so on. Okay, and then we have a half n shift move to the left, and then this one here, this denominator, it is also zero and up to the peak and then down to zero and so on. So, and then and then you can find if we have this ratio, and then here, this is largest, and then this is smallest. Okay, so this means down to Okay, so this means down to zero. And here, this ratio is down to zero. And here is the largest, and then here is smallest, and then go to infinity. And if there is no two here, both are not in the change point segments. And then here zero is also zero. And the this means zero by zero. Okay, but here we use a ridge so that this ratio equals zero close to one. Okay, yeah. Close to one, okay. Yeah, um, and here, just plot here. This is the original, here's moving some something like it, and then this is the curve of this is a curve of the ratio. So, here, here it's just one and then down to zero and up to infinity and then down to one and so on. Okay, so therefore, so therefore, determining this threshold becomes much easier. This one because here between only because here between zero and one we choose a search code and then we can find we just we just need to find the minimizers okay according to the uh change points here and here and here and so on and it's very clear so once we have the threshold and then what we have to do is just to determine the intervals the intervals each containing one chain point that's very very easy to That's very easy to implement. Okay, yeah. This is what we want to do. So, and based on this curve, and then we can find, of course, there are some properties here. I just explain a little bit. So, for instance, if the spacing lens is larger than, here is larger than 3 alpha n, but sorry, the upper n should be selected by ourselves. This is a big problem later on. We will talk about that. Okay. Talk about that. Okay. And then we can have, if here, well, we can have this TN going down to zero and then up to infinity. Okay, yeah. If the spacing is between two upper end and three upper n, and then the curve is slightly different. So for instance, here, if here, in this case, if the spacing lens is smaller. That the spacing length is a smaller n3 alpha n, and then here it's down to zero and then jump suddenly jump to one and then here keep some distance and then suddenly down to zero and then up to infinity. Some the curve becomes more complicated, okay. Yeah, so but we have an algorithm to select the uh uh uh uh chain point, okay. Yeah, so here I just give you some idea. Um Some idea, and another thing is the range. We call it rich. This reach, of course, we can choose a constant rich. This is okay. However, here we use, we call the adapted to change rich function so that this rich function has the following property. If we really, here, I belongs to this, we call the change point segment. Change point segment, this value is sorry, it's outside this change point segment. This value is zero, and then this means this ridge becomes infinity, goes to infinity. Otherwise, this ridge goes to zero. Okay, yeah, so we just add this value so that this ridge can have this property. Okay, um, and eventually, now as we mentioned before, we actually we We actually, we construct moving some or construct the signal functions slice wisely. And then this means we have many signal functions. So therefore, we eventually we have this one, this is the minimum as the final signal functions. Okay, up to now, we always talk about something at the population level. And then what about the sample level? It's very easy. We simply use the empirical version to replace. We simply use MP version to replace it, okay? Yeah, okay, but uh, this one have two different patterns in the in the following two cases. The first one is if here, if all here, TL have the have the changes at the same locations, and then we can have this term, this pattern. So we here still, this means like the any uh any any uh uh any uh signal function for uh any signal engine for for uh for slides so so we have this one curve uh one down to is going to uh going going to zero down to zero and then up to uh infinity and so on so if we have something change so this means at least there are two uh tl having the change at a different location the curve becomes like that it's impossible impossible uh impossible to impossible impossible to get the infinity okay so this this is easy to understand so because we have a different change so uh and here so this means the infinity value just down is is is it's down it's going down to one okay so we have this pattern okay so and for the signal uh for the signal statistic and then we can we just simply use its impure version to replace it so but To replace it, so but this is for the sum, so therefore, here is a uh condition. I mean, at the population level, this is uh condition, uh, this is the expectation, but here we simply use uh single single uh uh observation to replace it. Okay, yeah, we can have this one and then we can use this one as a statistic, and then we can we can also use the imperg version. The empirical version to replace it to get the region function and so on. So eventually, we have this test statistic, single statistic. Okay, so and however, this statistic has some strange phenomena. This is only because, although this is simply an empirical version of the population signal function, but this one, But this one, there are some, we call the uncertain, uncertain set. There are in some uncertain set, this statistic doesn't consistent, doesn't convergent, okay, to its supervision level. So actually, where the consistency happens, so actually, it's in the on the boundary. Here, this is small set here, and here, small set, here, and here. Okay, this is only because. And here, okay. This is only because at probability level, the threshold is just zero. And at the summer level, we must use some AON, which is not zero, but going to zero. So therefore, we have this kind of inconsistency consistency, consistency. Unfortunately, the length or this small interval, the lengths are very short, which doesn't affect. So, which doesn't affect the consistent estimation consistency. Okay, yeah. So, eventually, here we give the orgasm to select the chain points. Firstly, we want to choose the disjointed interval. We each contain the true chain point. So, this means we need to choose the lower bound, the upper bound of this interval. Okay, left-hand end and the right-hand side end. end and the right hand say end and here so how to choose it we can use one for each uh a threshold poll and then we use this criteria to choose the right hand side to choose the the uh the upper bound okay and the lower bound we simply use upper bound minus this guy to get the lower bound so this one because we found you this is theoretical we basically This is theoretical, we basically theoretical development. We found here this one, it just includes one change point. Okay, yeah. So, and another thing is, as I mentioned, here, previously, probably if the spacing lens is smaller than 3 of n, and then probably we can have had a curve down to zero, suddenly up to one, and so on. Suddenly, up to one, and so on. So, this means probably in one interval, there are two minimizers. So, therefore, we need to rule out some superiors intervals. So, therefore, we use this criteria to rule out those intervals. So, eventually, we use the following to identify the location. Okay, yeah, so here we have a symptomic result. Here we have a symptomic result, and then here I just quickly give the idea. So if here, if the all elements, here, the number of all elements is smaller than or equal to n square, and then under only this condition. So we don't need to have the identically distributed property. We just independently, that's enough. Okay. And then we can, this is a And then we can, this is a weak condition. And if under strong condition, a stronger condition, including, for instance, some Gaussian, sorry, some Gaussian conditions. And then this some Gaussian condition means we standardized. Suppose we put all elements as a vector and then standardize it. Sorry, normalize it. Okay. So and then we can have this rate. So eventually we can have this rate. Have this this consistency and then this consistent consistency. That's it. Okay, yeah. So, um, and I want to give some numerical study for the numerical study. Um, here, uh, here I talk about, of course, in the paper, we have done a lot of simulations, but here I just use one set, a simulation set to give you. set to to to give you just give you some idea um and here this means we have a three three uh this is uh uh uh uh all three tensor okay yeah so by the tensor you can find the size is not very large um by the way here i don't i we we we don't use uh a low rank approximation for for the tensor only because for some reasons later on if you if you ask me that question i will i will i will answer your why here we don't use the why here we don't use the uh uh the low rank approximation okay here we the size are still small but for the our approx uh applications the size is really small okay um and then we in this one the sum of size is 200 and then uh and then we can have here we can have four uh chain points okay yeah um and the last here the mode three later on we will fix the mode three so this means mode three so this means for mode three we have this means we have how many slices yes we have four slices and then 20 slices and 40 slices okay so and then we construct the test uh control control signal statistic okay so um here we talk about various uh heterogeneous genealogy so we have five segments is very we have a four uh chain point we have five let me check out how many minutes so minutes three minutes okay so okay so here uh here i just uh i i will go go go go i will go through these uh these two slices very quickly um here five segments okay we have we have these five segments and then um for the elements within the old sizes of tensors arrow tensors here is from normal and then the m it just pia The M is just here. We have arrow tensor. We also have the mean. Okay. And for mean, we can have here is three in the two and four. And 2.08, we have the value. I mean, here is the first, third, and five, fifth segments. Okay. And then here, this is odd. And even for even slices, here from normal and here. Here's from normal, and here it's also here to take the value 0.2 and point 0.4. Okay, yeah. So, I just give you this one. Here, eventually we can find here, this is the mean. Means are slightly larger than four. And then here, you know, over 1,000 times. And here, the estimation, estimation consistently seems good. So you The consistency seems so good. So you can find here zero, and then here, this means this means here. Yeah, this means here we estimate this number is four, and then here is here is three, and then here is five. And then the percentages, the proportions, they're larger than enough. Okay, so okay, I squeeze. Okay, so okay. I squeeze. I don't give this part and go to the application directly. And for this, this application, as I mentioned, we have three dimensions, we have this is all the three tensors. Okay, yeah. And for this cheat data, and then eventually we have 176 data points. And we found the four chain points. change points here 19 1989 and then 1988 and 1998 and then 245 and then 212 okay yeah so uh the q1 means the first quarter okay so economic uh probably we this uh these four uh uh change points uh change points have kind of economic explanation okay um Nation. Okay. For instance, in this year, we found, okay, we found the worldwide supermarket crashed. And then this is in 1978, 87. And then this change point is very close to this one. And second one is 19, Pia, is 1998. Pia, everybody knows we have a crush, the financial crisis in the 1998, okay? In the 1998, okay, so and here is 2005. This Iraq war, probably it is also. I don't know, probably here. This is why I say much. I'm not working in the econometrics, eggnometrics. So, so probably this is the true. Okay, yeah. So, here is a Iraq word, and then here is a Libya word. And probably it's meaningful, I don't know. and probably it's meaningful i don't know probably i need to ask some some some some guide in the work in the economics okay yeah so i think i will finish here