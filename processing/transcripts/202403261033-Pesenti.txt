And so my name is Han and I'm from Light. I'm from the University of Calgary. So today I'm going to present one of my work, which is about astrology solution of a class of second-order HGV equations in the Watson-Science space. So my stuff is not that closely related to optimal transport or the distribution robustness, but as because I Robustness, but as because I'm doing something on the motor science base, so I think I can be vaguely regarded as doing some optimal transport. Yeah, so let's see what is it about. Okay, this is today's close. First of all, I'll go with the problem settings, and then I will talk about what's the field view of restrictive solution. And finally, I have little questions regarding the radium maps. I think we can just skip this slide. So it just introduced the Washington space, and I believe that you are more familiar than IG. Okay, so first of all, because I'm going to talk about some restorative solution stuff, and it is a PDE. So because it is a PDE, so we have to introduce some derivative notions on the Watson-Stein space. But as you know, then the Watson-Sein space is a metric space. Is a metric space, which is hard for us to define what derivatives are. And I know that there's an interesting notion of what's a sign gradient, but we have to have something of second order, so it is not applicable here. So we make use of the notion of L derivative, which is proposed by Pierre Remotes. So basically, it is saying that, well, for a function f, which is adding all Which is acting on the waste-time space, we can treat it as a function on the space of random variables. And once we treat it as on the space of random variables, then we can, because this space is a Huber space, so we can talk about the first shared derivatives on a Huber space, right? And we say that, oh, if it admits contains a first-rate derivative of this form, then we say it is like. Then we say it is like L-differentiable because the L here stands for Lyon's. And yeah, so if the lifting is, I mean, if the derivative, if the first derivative is differentiable for one more time, then we say that it's L-differentiable for a second time. So this is the main idea of the L-deal, which is not that fancy, but just the lifting of the Leaf thing of the Washington space to a space of random variables. So the X-JB equation that I consider today is coming from the following state dynamics. It is written as like Xs equals to plus C plus the, this is the drap plus the volatility part, and plus this red term. So for this, so here, the P W. The P W0 XT, it is denoted as the conditional distribution of Xt different W0. So here, actually, this dynamic, we can regard it as something like infinite dimensional stuff. What I mean by different dimensional is that you may consider this to be like there are n players. And each of them here, following the, you may replace this one by the amputal measures of all the players. And then Players and then this noise is acting on all the players, but this noise here is acting on the player alone. So this is the idiosyncratic noise and this is the common noise. So we consider this kind of stage and then as follows. And finally, we can define the value function to be like read t equals c equals to like here the alpha. It goes to like here, the alpha is in the control set. And then it could be shown that the VtC is actually depending on the law zone. So the V here can actually be regarded as a function on the Wolfsonstein space. And therefore, later we will show that this V will satisfy, we'll have the His Some standard assumption which says that I require those V to be. I require those B to be nucleus and bounded. Thank you. Yep. Why is it important to see this as a function on the Hassan space? Oh, yeah. Because it's hard for us to handle stuff on the space of random variables. Yeah, and this is actually a good question. But actually, we want to go back to the settings. Like, go back to the settings of Wolfenstein's place. Otherwise, because it seems like here, we can think of it as we lift the things up. Because originally, our input functions are some stuff from the Washington space. And then we lift the things up to the space of random variables. Of course, we have to leave things, we have to prove down strings, right? So that's why we have to like. That's why we have to like trace it back to the most nice box. So, if you are familiar with control theory, then this is quite a standard result which states the dynamic programming principle, which says that if you want to solve this problem, then you may first solve it from the terminal and then you just run time from T to this time. And for this moment, you may just simply ignore this supreme menu film mode. Ignore this suprema manufacturing, then there's a relation between the VtC and the Vs. And just for this moment, if you just naively put the Vs to your left-hand side, then you expect that this plane will lead you to some PD equations. So my work here is mainly about how to solve these PD equations in a restorative, I mean in a rich sense, which is in the sense of. sense which is in the sense of we saw these solutions. So here this left Polarian principle will lead me to this HPV equations which looks like this. And I have this like red term coming from the common noise. So if there's no common noise then yes done by someone before. So my work here is just to extend the stuff with common noise. Yep. So our role So, our goal here, as I mentioned, our goal is to show that the value function V is actually the unique distortive solution of the above HJP. So, because we talk about our distortive solution, so we have to choose what our test functions are. So, in this time, our set of test functions is all those lines from this function that satisfy this. I mean, they have some regularity, and then here, Here, it has a operation about this derivative. So, and here, so there's one point, like here, the bounds are about second moments. But compared to the usual set of test functions, I mean, in the usual temperature, they usually choose those with like the point-wise bar instead of the moment spawn. And because our equation here. And because our equation here is there are some integrals, so in some point you will you would expect that you have to use a dominated convergence theorem. If we have the light polymerized part, then it is much easier to deal with. But in this case, we only draw the movement part, so we have to use some more advanced techniques. And what do we draw? We're used solution is a continuous function such that, first of all, we repeat. First of all, we replace all the stuff of equalities to inequalities, and then we require that if this u minus phi where phi lies in the test function set and attains a maximum at some point, then we require the phi will hold the HTML equations at that point, but here we replace it to be an inequality. We replace it to be any inequalities at that point. So there is a problem that it will come later: is that we have to actually attain this maximum or minimum. And it is a problem in Washington space because the Watson-side space, I mean, the structure is not that nice. It is not locally compact. So we cannot guarantee that we can attain this point. Okay, so the existence theorem is easier. The existence theorem is easier. So we say that the theorem is that the value function v is a resulting solution of our HJP equations. So the schedule of proof is that we just simply examine this difference quotient and then we can make use of the dimension principle, a reloss, a relaxed detollema, and the regularity of the phi. Then we can get the show that the V is actually a restorative solution. So, the difficulty, as I mentioned before, like we have to make use of the dominant convergence theorem and we don't have the format span. So, the remedy is that we can make use of the second moment, which gives us the uniformity probability. I wonder where does the first we have to talk. We have to talk about the differentiations in this right. So the password mu is the Lyon stability. Yep. Okay, so actually we could choose another set of test functions which is easier for us to establish the existent theorem. But then it will pose a question on how to prove the uninitians because it is It is trying to ask for choose appropriate test functions because for the existent part, we have to show that those five in the test function, they are, it satisfies this property. So if they are less functions in the set of test functions, then it is easier to show the existence. But for uniqueness, we often use an contradiction argument. So if there are more functions in the test function, then If there are more functions in the test function, then we are easier to show the universe. So the reason that we are using this test function set instead of the more usual one is because we could not establish the uninitus in our case if we use the more usual set of test functions. So the theorem is that we can actually have the unimbus, and improving the unimbus. And in proving the uniqueness, what we often do is that we prove by contradictions. We assume that there exists some T0, mu0, such that this thing is greater than 0, and we require the U1 minus U2 to be achieved at some point, the maximum of U1 minus U2. Clarification, when you said you choose a different S functions, is it just a proof trick, or are you changing? Just a proof quick, or are you changing the nature of the results? I think it's just what Ristroli Solution does. We choose, so because usually we may not, I mean, the function itself may not have this kind of regularities. So instead of like we require the function to have this kind of regularity, we just uh just transfer the regularity um condition from the function itself to some test functions. The function itself to some test functions. So you're adding regularity constraints in order to get no. I mean, so the philosophy of restorative solution is that we may not have some classical solutions to these equations, but we have a solution in another sense, which is Which is written here. So we require that if this one, the u minus phi, attains a maximum at some point, then we require the phi would satisfy the HJB, but in an inequality sense. And this, I mean, this actually comes from some full dynamics. Should I continue? Yeah, okay. So because we require I mean and we require the maximum of U minus U1 minus U2 is to be achieved at some point. And as I've said before, the space of Osenstines is not that nice. So we do not have the local chunkers. So it may not be achieved. But the remedy here is that we adopt the same approach as this paper. like this paper, so which makes use of the variational principle. So it says that although your function, oh sorry, so it states that the variational principle says that although your function may not achieve the maximum point, but after a perturbation of the so-called gauge function, then we can actually achieve the maximum point or the minimum point. So you may wonder what is a gauge function? A gauge function is just something that looks like a maximum function. Just something that looks like a metric, but and it dominates the original metric, but without a triangle report. So we choose the gauge function to be, I mean, it's introduced in this paper to be like this one. So it's another kind of Lawrence-type distance. And the the philosophy here is that we are projecting our n-dimensional scale to one dimensional, and then we integrate along the whole ball. Along the whole ball, and this thing acts as an equivalent matching to the Watson-size space. And then we just like to make it more smoother, we trumble with normal distribution. And I know that I'm running out of time, so I'll be fast. So you may wonder why do I have to project into the one-dimensional? It's because in 1D, there's an explicit formula for the binary map. In this case, I can just simply In this case, I can just simply write my motor size distance as this form, where the t is the premium map here. And this helps to show the regularity of the metric which is needed. So here is just a statement of like, if I perturb my original function by the gauge function, then I can obtain the maximum or the mean. And here is the regularity of the metric. So finally, it goes back to the proof of uninhabitance. Goes back to the proof of units. So basically, I just will choose this one as my test functions. And then, because of my regularity, then I'm able to draw some contradictions because of the regularity proven. And I think this concludes my thoughts. Thank you. Unless there is a very pressing question, I think in the interest of time, probably about Interest of time, I'll move on to the second talk. And now, which I want to scale as much as possible. Second speaker is Ker Shan Chu, who is going to talk about quantifying distributional model courses. Okay. So uh I'm glad to give me give you the presentation here. This is a joint work with my advisor Yenti. Work with my advisor Yantin and another youth graduate. The name of this paper is Qualify Distributional Model Risk in Relaxed Marginal Problems with OT. So first let me give you a quick introduction of what is the distributional model risk. So in the paper written by Pranchel and Murphy, they define the Watson Stan distributional model risk. The worst understand distributional model risk as the worst associated with our loss function f as the worst case expectation of f where the distribution q is running over our Watson standball centered at the reference measure mu with radius delta. Here the Watson standball is defined by an OT distance. O T distance is the minimum transportation cost between two Between two probability measures, mu and gamma. Here, the cost function C satisfies our very weak conditions, only the positivities. And next, I'm going to introduce the WDRO. WDRO is defined based on the model. Model risk. So given a loss function at theta, theta is in a parameter space. And the WDRO is going to find the minimizer that the Watson stand model risk is minimized. So this is our minima experiments. So WDLO is a very powerful tool in many disciplines, including the machine learning. Disciplines, including the machine learning and finance, because it has a functionality of hedging against the misspecification of the model and also the distribution shift. The empirical access of WDLO is largely credited to the strong duality. So the primal problem is an infinite-dimensional problem. However, with strong dual However, with strong duality, this hard problem can be converted to univariacate reformulation optimizations. However, the dependency of the Watson sample on the reference measure mu limits the scope of application of WTRO, especially in the economic. Economic attribute econometrics applications, the reference measure is not point-identified. We only know a partial knowledge about the reference measure. Let me give you an example in causal inference to illustrate this point. So, first, let me introduce the standard framework of potential outcome. So, here we have a binary treatment status. So, when D equals to zero, this means the individual gets this treatment. So, when D equals to zero, the individual don't receive the treatment. And when the D equal to one, this means the individual receive the treatment. So, suppose we have a random sample, Y, X is the covariance, D is the treatment status. Is the treatment status because the y1 and y0 cannot be observed in four individuals, so we can only observe one outcome. Moreover, we also assume the standard selection are observables. So the first part of this assumption is conditional independency. This means given the covariate, whether this individual gets the treatment is independent of Treatment is independent of the potential outcomes. The second part of this assumption is the common support. This means the propensity score is greater than 0 and smaller than 1. So these two, with these two, with these two assumptions, we can identify the distribution of y0 and x and y Y what and X, mainly due to the conditional independence assumptions. So we can identify these two modulate distributions. However, the joint distribution of y1, y0, and x is not identified. So think about So, think about a scenario. We are interested in some causal parameters. ATE is an example. However, the difficulty is the treatment, the distributional treatment effect. Here the function is an indicative function. This is not additive separable. So without more information about the joint distribution y1, y0, and x, we can not point identify these parameters. Point identified these parameters. Under some weak conditions, some papers show the identified set of this parameter is a closed integral. So the upper bound and the lower bound is just an OT, is just a marginal progress. We were studied by Ruchendorf in 1991. And to be more specific, the upper bound is an integral where the measure, probability measure, is running over a Fauchier class. Fauchier class is the probability measure mu with overlapping marginals mu13 and mu23. Mu13 and mu23 means you can think about the example in the causal inference, the covariate parts have the same distribution. Have the same distribution. But yeah. However, we are interested in the case when there are some misspecification of the reference measure, or especially when there is a distribution shift, or the identification assumptions, especially the selection of the raw assumptions is invalid. So now we are ready to give you the framework of our methodology to get model risk against the reference measure misspecification and also the partial identification. Think about we have two data sets, S1 and S2. S1 is a product space of Y1 and the covariate. Y1 and the covariate X. S2 is another data set, and this is a product space of Y2 and the X. So for simplicity, we suppose they are both polished space. And we are given two reference measures. Maybe they are misspecified. And these two reference measures have the colour support on X, on X part. For notational simplicity, For notational simplicity, for any measure on space S, we let gamma L3 denote the projection of this measure gamma on the space YLN times X. So now we are ready to define what is WMDR in marginal properties. So this model risk is defined as the Is defined as the maximization of integral where the measure is running over a Watson state ambiguity. So this Watson state ambiguity is defined as the projection of this measure i centered at Watson Stan Ball s um uh centered at reference measure mu uh one three. measure mu13 and with radius delta 1. And another part of the projection also within the Wattson's temple, another Wolfenstein. So we don't impose the restrictions on the droid measure because we only have the knowledge on the marginal distributions. So the Wolfenstein distance is imposed on these two marginal distributions. But when the delta equals But when the delta equals to zero, our problems is reduced to the routing of 1991. So before giving you the most important result in our paper, the strong duality, let me give you some notation. So, first, define the space B as a product space, and a function sine B is defined. And a function psi v is defined for each lambda. Lambda is in R2. So this is the definition of psi lambda. And for each lambda in R2 plus, this means they are non-negative. We define lambda, f lambda v, f lambda v is a maximization, and we also define f lambda 1 and f lambda 2. So So the difference here is just the F minus lambda 1 C1 and F minus lambda 2 C2. So now we are ready to give you our results. So this re result is very general because the condi uh we only assume the the cost function is metrical. The cost function is measurable and satisfies the possibility conditions. Also, the loss function f is measurable and the expectation or the integral of f is bounded above from minus infinity for some measured in the Fauchy class. So for positive radius, our model. Our model risk can be reformulated to a bivariate optimization, where the production is consisting of the linear part. So this is the inner product of lambda and the radius. And another part is marginal properties. So f is defined in the previous slide. And the expectation is taken, is minimum is maximized. Is minima is maximized over a coupling set. So this is for the case when the radius are both positive. So another interesting case is one radius is zero and another one is positive. So this is due. So where the radius, where the radius So where the radius when the one radius is zero, it can be written as a univaricate formulation. And the inner part is still linear part and marginal problems. So because this is when the F lambda satisfies some weak conditions like semi-continuous. Semi-continuous. This part can be sought out by Cantor which dual things. So, some computational algorithm developed for OT can be applied to compute the model risk. This slide is discussing the example I reached in the previous slides. When the loss function is an indicative function where the y2 part is greater than y1, this is not additive separable. So when delta equal to, when the radius above zero, this recovers, this is reduced to famous Markov bound as the upper bound, and the boundaries can be written in this form. However, if we are interested in some model specification of the reference measure, and the distance is the transportation cost is written as a quadratic form, so the model risk can be reformulated in these two, this univaricate, not this bivaricate reformulation. So this strong duality for the positive radius implies this model risk is continuous in the radius. And when the radius is going to the zero, the optimal value can be convergence to as a marginal probability. So, I just want to stop you, and I'm welcome to comment and see if we can get a little bit of a distance. How do you try to implement this? Like you do some numerical calculations? And if yes, are there any like challenges that come out of it? In this paper, we don't have any numerical experiment because as I mentioned here, the numerical part should be implemented by the first part is the marginal problem, can be solved by the computer. Can be solved by the computation OT. And this should be solved point-wise for each lambda. And then again, we should solve out the alter maximization. From my perspective, it should be difficult, but maybe the next step of research. generalizes to more than two variables. It's a little bit more. I think it is implementable. This is a good question. Based on the Routine Doctor's paper, if the system, so in this paper we just studied the very simple system with one overlap, right? But if there exists more But if there exists more overlapping and more marginal problems, when delta equals zero, I mean, the problem is we are studied by Ruchinda 1991. For DRO case, I think the answer is yes, but we don't have the results yet. But maybe this is the first one. You expect something similar to this, very similar, almost like Yes. Yes. But the system should satisfy some conditions. Yes, because if the system is too complicated, there is no joint distribution exists. That's interesting. You actually could have joint distribution when the problem doesn't. Right? The only problem that we in the visible doesn't fit. But as you put the ball, it might allow for Yes, yes. Yes. Last one. Work. Okay. Third talk of the morning. Third talk of the morning by Wendao Xue and she'll be talking about correcting strategic misreporting behavior. So hi everybody, my name is Wundao Xue. I'm a PhD candidate at the University of Washington. I'm going to be a close dog at UTLC. I'm honored to be advised by Professor Black. And today I'm very excited to share my work correcting strategic misreporting behavior on outcome variables in estimating treatment effect. Treatment effect. So, this work does not aim to advance any OT or DRO theory, but however, it aims to use OT as an application to enhance cost of inference methodologies. So, suppose you are a researcher interested in how can I reduce crime and violence behavior in light area. So, and you are wondering, could the cognitive behavior therapy be an effective one? Therapy be an effective way? So, this is the exact research question that Blackman et al. We are interested in answering in their 2017 AER report. So, to do so, they hire 3,700 subjects and they randomize into treatment group and control group, where in the treatment group, they receive the eight-weeks cognitive behavior therapies together with a $200 cash transfer. However, to collect the outcome variable, they use a survey data and try to ask the question: how many times have you conducted criminal behavior or criminal-related behavior in the past few weeks? However, their research faced criticism from the audience saying that, okay, because they are criminal related activities, is your measure of your outcome variable reliable? Reliable. So, because those respondents, they always have the incentive to under-report their criminal activities, I think that's a valid concern. In fact, there's a famous Bouhart law saying that when a measure becomes our target, it ceases to be a good measure. So, to tackle this concern, Flatman also did a second paper, which is published in 2016 in the Journal of. 2016 in Journal of Development Econ, which they collected the validation data set in both the treatment group and control group to tackle this concern. So here's this result. So this is the result from the AER paper saying that the treatment significantly could reduce the criminal activities for those criminal related activities. In their 2016 JDE paper, JDE paper, they find that use the validation data set, you know, they're just using the reported outcome, it could underestimate the treatment effect. Seeing that here, using the reported outcome, it's minus 0.4, but however, using the validation data set, it increased to minus 0.5. Okay, so what does that mean? It means that the respondents, there is the, you know, the reporting behavior is not consistent in the treatment and in control. Consistent in the treatment and in the controls. If they are consistent, then you know when you do the treatment effect, you subtract from that, subtract the control from the treatment. So if it's consistent, then it does not matter. It will not bias the treatment effect. But however, we find that there are inconsistent misreporting behavior in treatment and in control. So our paper tried to propose a method to tackle this problem. And the scenario, here is our result. Here is our result, and we find that under this our proposed method, we could correct the bias. But it seems like it works magically. So what is the insight? We all know the famous no-free lunch theorem. Am I violating this no-free lunch theorem? So I know you have lots of questions, but maybe hold on, I will be to that point. Point. So there's one more interesting thing I want to mention. In our proposed method, we only use half of the validation data set in the data set. We only use half of the data set in the treatment group to correct that, to correct the inconsistent misreporting data. But I will get to that with our identification assumption. Okay, so some of you might also have a question saying that this is high-stake reported outcome. High-stake reported outcome. So maybe, you know, in terms of criminal-related activity, yes, there are inconsistent strategic misreporting behavior. But how about other outcomes? So here I'm saying that if your outcome, your reported outcome, can serve as an incentive to induce your strategic misreporting, then it will bias the strategic effect. So another example here is if a researcher is interested in Research is interested in, you know, what is the effect of adopt chat GPT in helping the employees' working performance. So, in this case, I summarize that their, you know, employees, they could, you know, over-report their working performance. I summarize here there are two kinds of incentives. One is the incentives related to the reported working performance, such as bonus. The second case is not the value of the reported outcome matters, but the The reported outcome matters, but the rank of the reported outcome, which serves as an incentive, so that like promotion decision is usually given to the top two employees with the highest working performance. So I will tackle the strategic and misreporting behavior for those two different kinds of incentives. So our research falls into the literature of the differential measurement error. So differential measurement error. So differential measurement error means that even conditional on the observable covariance, the measurement error is different in treatment and in control. So we find some empirical evidence of such differential measurement error exists. There are also some methodological paper tackle on this differential measurement error. So Venderland, their approach is they try to use sensitivity analysis, but however, they require the knowledge. Require the knowledge, the prior knowledge of the sensitivity time, which is the direction and the magnitude of the differential cycle. And Will Lee, and they use validation data sets to provide such information of the prior knowledge. And Huawei and Marker, they adopt partial identification to tackle this. So, our paper is different in the sense that first, we tackle all this strategic misreport. Tackle all the strategic misreporting behavior. So, which means I kind of, you know, narrow down the approach of the why there's a differential veteran car, because there are strategic misreporting. And the second thing is that we also use patient data set, but in the treatment. This work is also related to the application of optimal transpose theory in economics. And yeah, so due to time. So, due to time limit, I'm going to skip the second part of the literature. So, here I'm using a simple economic model to first to pin down the notation of the potential outcome framework, and second, try to illustrate that when there's incentives linked to the reported outcome, people could report differently in the treatment. So, in this case, I used a Y star, Y zero star. I use the y star, y0 star, and y1 star to denote the potential outcome of the potential true outcome. I use y0 and y1 to denote the potential reported outcome. And the difference between the true outcome and the reported outcome are the measurement error. So here I use W1 and W0 to denote that. So when a respondent deviates A respondent deviates from his or her true outcome, he could face some cost. So, some cost of misreporting. Here, this is denoted as the cost function C, which is a function of the how much he deviates from the true outcome and also his observable covariance. And he could also, by deviating from reporting his true outcome, he could receive some reward. So, here, because the So so here, because the reported outcome serve as an incentive, so the reward function is a function of the co observable covariant x and the reported outcome. So a rational respondent will maximize his utility here defined by the value difference between the value and the cost and choose an optimal amount of misreporting. So here we can see that because the value function at a The value function at a higher value of the reporting outcome, the slope is flatter. So, this causes the optimal amount of misreporting is going to be different in the treatment and in the control. So, to summarize, we doubt a potential outcome framework. And moreover, our data, we can observe the reported outcome, the covariance and the treatment assignment. And the treatment assignment, and also, I need to assume that we have a validation data set in the treatment group. So, we are interested in the average treatment effect on the untreated. For example, in the criminal-related activity case, we want to know what is the treatment effect if such therapy can be applied to a broader population. So, then that's the average treatment effect on the untreated. But, however, this framework. But however, this framework can be easily extended to other treatment effects such as ATE or ATT. Okay. So we assume the strong ignorability assumption of the true outcome, but however, we do not assume the strong ignorability assumption holds for the reported outcome. So if I denote the genome in genome And note the gena and gena prime as the misreporting behavior in the treatment and in control group, then we can write the average treatment effect on the untreated to be as the second equation. So this is to say if your mis, you know, the second part accounts for the misreporting behavior, you know, if the inconsistent misreporting behavior, and the first part accounts for, you know, but that could be directly. But that could be directly identified from your data set. So, this tells us if you do not have inconsistent misreporting behavior, if your misreporting behavior is consistent, then you can directly, then your parameter of interest is identified by your data. So in the baseline model, we are saying that if your reporting behavior is consistent, then your treatment effect can be written as this. Can be written as this. So, well, here the nuisance parameter mu naught is just a conditional expectation function. And estimation is very straightforward. You can replace the conditional expectation function using any non-parametric estimator or machine learning algorithm to estimate this conditional expectation function. Then you just simply use a plug-in estimate to get the treatment effect. Exactly. Okay? So then back to the first scenario when there's incentives linked to the level of the reported outcome, we assume this. So that is to say your strategic, your misreporting behavior, conditional on the covariance and also the reported outcome should be the same. So what does that mean? So back to our simple economic model. So this is essentially So this is essentially so people are making decisions by marginal benefit and marginal cost. If you have, you know, your company value function and x cost function, you can write the optimal amount of this reporting behavior as a function of the covariance x and the reported outcome. So this essentially is saying that your optimal reporting behavior was conditional on the reported outcome because it serves as incentive. The outcome because it serves as an incentive, then it should not be affected by the treatment effect. So, that is to say, in other words, this assumption says that, for example, in the employee case, you should compare the employees with who, you know, say, report eight hours a week for the working eight hours a day, for the working hours. You should compare that to the people who also report eight hours a day. So, because their incentives are. Because their incentives are some kind of similar, and their strategic misreporting behavior are comparable. So, this is essentially what this identification assumption is trying to say. So, under this identification assumption, we can write the treatment effect as the following equation, where again, there are two nuisances. There are two users parameter which denotes the conditional expectation. And to estimate them, you can simply use an empirical sample average of this, and also you can estimate those nuisance parameters with the parametric estimation. So then in a So then in the second scenario, we are trying to tackle their incentives not just related to the level of the reported outcome, but also to the rank of the reported outcome. So here, we try to, you know, so here we use the state-of-art definition of the optimal transport to define the multivariate rank, which plays an important role here. So, yeah, so here this transform map is defined as a push-forward map between the reported outcome in the treatment group and the reported outcome in the control group so that their rank are comparable. So, we order that the optimal transfer series, I will skip this. This means that under this identification assumption, our parameter of interest can be written. Of interest can be written as this. So again, so we need to estimate the conditional expectation function, but here we need to estimate one more thing, the optimal transport map. So we adopt the estimation strategy in Chen Ben Xie, which we did, you know, we try to estimate the optimal transport map in three cases. One is in the univariate. One is in the univariate case, and second is when the optimal transform map is in the having map, and third is we use a more general case. We use a spline estimator to estimate the potential function, and the optimal transform map is given by the derivative gradient of the estimator for the potential function. Okay? So here we give the empirical application, empirical result. Application empirical result using BLATM et al their data set and give the two scenarios estimator for these two scenarios. So we find that if we account for the strategic behavior due to incentives on the value of the reported outcome, you know, using the reported outcome could overestimate. But however, if you account for the strategic behavior, where the rank of the reported outcome serves as Of the reported outcome serve as an incentive, using the reported outcome could underestimate your treatment effect. One more thing here is you can find out that the standard error of our scenario two is much smaller than the standard error in their paper. Although, again, we only use half of the data set. This is because we make more assumption on the, you know, we make more assumptions on people's. We make more assumptions on people's strategic behavior, so we have more statistical power on that. Okay. So the takeaway is, so first of all, ignoring strategic misreporting behavior can introduce bias to your estimation for the treatment effect. And we study the identification under three cases, a baseline scenario when the reporting behavior remains. The reporting behavior remains consistent, and that strategic misreporting behavior due to incentives linked to the level of the reported outcome, and that's strategic misreporting behavior due to incentives linked to the rank of the reported outcome. We use a plug-in estimator, and we show that the estimator is consistent and asymptotic normal in our paper. And we also study the performance of the estimation to the estimator through simulation. To the estimator through simulation and empirical applications. That's pretty much for my presentation. Comments are welcome. Questions? So I was wondering if you use more data better? Use more data better, get better results? Yeah, definitely it's gonna be better. If we have more data sets in the treatment group, then it gives you more knowledge of this strategic behavior. And also, we make the link for the strategic behavior in the treatment group and in the control group using our identification assumptions. So, to answer this question, first, if you have more data. This question: First, if you have more data sets in the treatment group, that's going to be better because that's going to tell you more about the strategic behavior. If more, you have more data in the control group, that actually can tell you that if my identification holds or not, as you see, I have two identification assumptions. If you have validation data set, you can actually know that which scenario you are foreseen. So, that definitely could be better. Question about the main assumption. About the main assumption about the reporting error. So, can you go back to that? I'm not sure I understand the logic, so the mean of the W1 is equal to the mean of the W2. Yeah. So so you're saying that in your toy model, it's just like static optimization for the reporting error, that would be satisfied? Or the reporting error that would be satisfying this assumption. What do you mean exactly on the utility, cost, behavior? It seems like it's a little bit like what are you assuming that the link between the reported outcome and true outcome is the same in the two groups? That's not exactly what you are assuming, right? Because we want to differentiate measurement outside. I'm not quite sure why this would work. So, first of all for the utility, it serves as an i example. So, if, for example, here So if, for example, here you have a value function that is concave, you have a cost function that is complex, then you can write your strategic by maximizing utility. You can write your optimal amount of misreporting, which is not affected by the treatment assignment. So that is essentially what I'm saying. So, regardless, you are in a treatment group or you're in a control group, you are creating the same incentive. You're missed your. We are misreporting the EPF. What's the conditional or reporting or option? Yeah. Assumption to decide your reporting just like to decide the we can do change. Thank you for the money. And we can be in at one thirty.