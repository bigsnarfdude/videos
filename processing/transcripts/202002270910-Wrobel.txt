Hearing what you all have to say about the different wearable device and aspects of it. I'm going to talk about registration of 24-hour accelerometer profiles with an application in circadian rhythms. My name is Julia Robel. I'm an assistant professor in the Colorado School of Public Health in the Department of Biostatistics and Informatics. I started there about eight months ago after coming from Columbia doing my PhD there. So I'm going to be talking. So I'm going to be talking about activity count profiles from a functional data analysis perspective, kind of like Jeff mentioned on Monday. But what I have here are two subjects from the BLSA data and three days of activity count measurements for each of them, measured at the minute level. And in this functional data perspective, one of these 24-hour cycles is sort of your standard observation that you're trying to understand. To understand. And one of the couple, there's a couple things I want to point out here. One is something that we've touched on a couple times already: this wearable data has a diurnal periodicity where you're awakening or asleep. And that's something I'm going to talk about today. Another thing is the intensity count data can be quite spiky and hard to interpret. So I'm going to talk about it in a sedentary versus active framework by using a threshold to binarize this data. To binarize this data, but I'm still going to look at sort of binary counts over the course of 24 hours. And finally, I'm only going to focus on one day at a time for each subject here, though extending the methodology I talk about to multiple days is something that we are hoping to do soon. So what is an binary activity profile? I've shown you here one subject from BLSA. And what you have is each minute throughout the day. Throughout the day, a zero or a one, zero indicating sedentary behavior, and one indicating active behavior. It looks like the transferring files screwed up the equations a little bit, but I took most of the equations out of the presentation anyway, so we're just going to look at the pictures. But anyway, this is the activity profile over the course of 24 hours for one subject from the BLSA data. And we think about this data as having an underlying probability of being active over time, which you have to. Active over time, which you have to estimate from the binary data, and I've shown here. For this particular subject, they're not active while they're asleep, unsurprisingly, and then they tend to be most active like after 6 p.m. And so the main thing I want to get at is a misalignment that occurs in accelerometer data due to the fact that people wake up at different times, they go to bed at different times, and they have longer times that they're asleep or awake throughout the day. And I want to represent this here. And I want to represent this here with a binary, a plot of all the binary activity for all of the subjects in the data set. Jawei represented a plot like this earlier, but I'm going to just explain it again. It's called the lasagna plot. And what it is, is each row is one subject in the data. Each column is one minute in time throughout the day. Light blue indicates minutes of sedentary behavior, and dark blue indicates minutes of active behavior. And what you can kind of see is, of course, throughout the population. Plan to see is, of course, throughout the population. People tend to not be active from midnight to 6 a.m. because they're probably asleep. They're more active as they wake up throughout the day and less active in the evening as they're going to bed. But it's hard to pull out more patterns than that because of this sort of time misalignment. And just motivating that a little bit further by showing the probability of being active over time for all of those subjects, you can see two people highlighted. You can see two people highlighted in particular here, where both people have similar probabilities of activity in terms of their shape. Whenever they wake up, they tend to be more active when they first wake up, and there's sort of a dip in activity, and then they're a little bit more active in the evening. But they wake up at drastically different times. So those patterns are sort of masked in the data. How do you estimate a couple of questions? How do you estimate? I've used GAM here for just sort of. For just sort of a visual representation of the data, I just smoothed the binary. But in that methodology itself, we use ba binary functional principal components analysis, which I'll talk about a little bit, but not too much. And so what I want to get at here is a two-step registration algorithm that we developed to align these types of curves. Registration is a methodology from functional data analysis that is meant to align curves. Analysis that is meant to align curves that have similar patterns. And we had to do some work to make it computational efficient and handle binary and other types of data. And this is a schematic of how it works. You have two different subjects in here, one in light-gray and one in darker black, and that's their sort of binary data. In the first step, you estimate that template with that probability of being active over time, for us using functional principal components analysis. Components analysis. In the second step, you estimate what's called a warping function, and these warping functions stretch and compress time so that the main features of the data are aligned across the population. And you have a separate warping function for each subject. And then after using that new time that you get from that warping function estimation and using it on the original data, you have a data that's now aligned in time. And then a little couple of. And then a couple more words about that. It's actually an exponential family framework, so I'm using it for binary theta here, but it generalizes to other data types. So yeah, in the first step, you estimate that probability template using functional principal components analysis. And the second step, you estimate those warping functions, which map your observed or chronological time to a new registered time scale, giving you a new time scale t. And then you iterate between these steps. And then you iterate between these steps. So, first step, you estimate your template, which is conditional on your current estimate of time. Second step, you estimate a new time that's conditional on your current template. And I've highlighted here that you can get these parameters out of each of these different steps. You get parameters which are scores from the FPCA. And then you also get the slopes of the warping functions. And I'm going to talk about these in the context of circadian rhythms and how you can use them to analyze people's circadian behavior. People's circadian behavior. Can I ask a question? So, what does it mean alignment? How do you make that mathematical? What does alignment mean? Alignment? Yeah, so basically we minimize the distance between the binary data and then the calculated template using like a Bernoulli loss function. So, I'm going to talk about these working functions a little bit more and how you interpret them. So, they're just strictly monotonic functions. They have to be increasing and they can take a lot of different forms. But for a paper I'm currently working on, we're using a pretty simple, like piecewise linear form because we find it easier to interpret. And so, this is just one subject from that data set. This is their warping function. This is their chronological time scale, and this is their. Their chronological time scale, and this is their registered time scale. And for this particular subject, and have, so if you're unlocking the identity line, that just means that your chronological time and your warped time aren't the same. Basically, you have the average time characteristics of the population. For this particular subject, their first slope is quite steep, which means that they wake up early relative to the population. And then their last slope, their third slope, is also less steep, but a little bit steeper than the Steep, but a little bit steeper than the identity line, meaning that they're also going to bed later. So they just have a longer active day. So you can sort of get these pieces of interpretability from the working functions, from their slopes. And so now to the actual results for the VLSA data. I'm going to gloss over this a little bit because I want to talk about something else, but I'm happy to take questions on it. So on the left-hand side is that plot I originally showed you. Plot: I originally showed you where the row is the binary data for a particular subject, and each column is a minute in time. And you have light blue is inactive, dark blue is active. And after applying the method, you see that you have much better alignment of the subjects in time. And you can see sort of characteristics in the data like wake time and sleep time, as well as higher density of activity in the morning for a lot of subjects, and a midday dip for a lot of subjects. A mid-day dip for a lot of subjects as well. And just because I think it's sometimes easier to see those patterns on the probability scale, I've plotted that here as well along with the warping functions. And you see those patterns like feet, waking, sleep onset, and the mid-day dip. So this method is, and the software I published online, it was published in Biometrics last year, and we published a software which we call Red. Published a software which we call Register in the Journal of Open Source Software, and it's available on my GitHub page. So, what I want to talk to you about next is a paper that we're currently working on using this registration approach to understand human chronotypes. And human chronotypes are behavioral manifestations of circadian rhythms. Circadian rhythms are associated with a lot of different diseases, and it's been shown that certain chronotypes, like people who tend to go to bed later, Types like people who tend to go to bed later have a lot of more unhealthy outcomes. So it's important to study. And these time and activity variability, these separate sort of functions that we've been able to separate using the method, embed different behavioral patterns that we might be interested in. So the warping functions embed time components, so sort of diurnal prototypes. Are you a morning or an evening person? And the registered accelerometer profiles. registered accelerometer profiles tell you about different types of activity and how people sort of distribute their activity throughout the day. And some of these chronotypes are already available, exist in the literature. The morning lark and the night owl is a typical example. And so we've come up with a couple other different types of chronotypes named after birds that we're trying to get past the reviewers in this paper. So I would love feedback on that. And so the other bird chronotypes that we've come up with are penguins. That we've come up with are penguin and hummingbird, and then also roadrunner and rooster. And I'm going to describe what those things mean in just a second. So it's important to first talk about the functional principal components that come out of this alignment. I guess I only have a few minutes, but that's fine, I'm almost done. And so, what I've plagued here are the means of the population plus or minus the first principal component. Is the first principal component and then the second principal component from the aligned BLSA data. And these are actually typical. You see this in a lot of other accelerometer studies, similar PCs like NHANES, for example, I looked at. But so the first principal component can basically be interpreted as an overall up or down activity shift throughout the day. And so those are the penguins and the hummingbirds. So if you're somebody who has a high value for the score for the first principal. High value of a score for the first principal component, you're somebody who's probably going to be pretty active throughout the day. You're a hummingbird. If you have a low value, you're less active. We're calling you a penguin. So I'm a hummingbird. And also these aren't mutually exclusive. You can be a hummingbird and a morning lark, for example. So the second principal component is people who tend to be more active in the morning versus more active in the afternoon. And this one was hard to come up with birds. And this one was hard to come up with birds. The rooster is the more active in the morning. We had inverse roosters for a while as our type until we realized that roadrunners are the afternoon active people. And this is a pattern that you see that comes out in a lot of different types of accelerometer data. And then so the other chronotypes that we're interested in, the more traditional ones, the morning miss, eveningness, come out of these warping functions. And as I mentioned before, Mentioned before, the slopes of the working functions actually tell you about the morningness and eveningness. So I actually don't love this plot, and I'm going to remake it. But the morning larks, if you look at this first plot here, the morning larks are the people who have, are highlighted in red here. And they have those very steep first slopes. And then you also have the night owls who have the very steep third slopes, the people who go to bed late. Late. And so you can either be, and then they're sort of the opposite: the people who wake up early or the people who go to bed early. And so that's basically all I have to show you today. I had some actual pictures of kernel types in the data, but I took those out for time. And basically, what I'm going to get at, I think registration is a reasonable thing to do. It provides decent results and allows you to set. Provides decent results and allows you to separate this sort of diharron patterns from the activity itself. And they're still both important, but you can then separate them. You can analyze them jointly or independently. And one of the things that I think is really important to do and we're working on right now is to extend this to multiple days. Because you can imagine that maybe somebody wakes up every day at the same time and has exactly the same pattern of behavior. But we know that that's not actually true. Like people have different behaviors all the week. True. Like people have different behaviors on the weekends than they do on the weekdays if they work a nine to five. And so we want to be able to sort of come up with a way to quantify somebody's sort of average behavior and then the deviations from that on sort of a weekday or weekend basis. Another thing that I'd like to do is validate this on other wearable device data, because I think it would be fairly straightforward to extend it to other things that are sort of measuring twenty-four hour cycles of activity or anything else. Activity or anything else. And then another thing I've sort of talked about with people who are using accelerometer data for prediction algorithms or for clustering, I think it actually would be a really useful pre-processing step rather than just throwing all the raw data in there. So perfect timing. So I came from Columbia Biostatistics where I worked with Jeff. So this is a project with Jeff and Aaron McDonnell, who's a current student. And Erin McDonnell, who's a current student there. And I've also worked with Jennifer and Vidium on this project as well. So cool, thanks. Any questions for Julia as we are making a transition? So the next speaker, if you could. I'm just curious, because it seems like me that you use both FTCA on the line data and also the open function to define the prototype. The DDFI, the prototype, or IDA, right? Are you using both of them together? So, and how does the result compare, like, if you're using them separately? So, the FPCA is just on the actual activity part of it. And then, so we're analyzing sort of like you get an FPCA sort of for free out of the way that we do the methodology. Like, it's used to calculate the template. And those are the FPCAs that we're looking at. And we're kind of thinking about it as two separate pieces. And we're kind of thinking about it as two separate pieces of information where the activity is embedded in the FPCA part and then the working functions are sort of containing information on time variability. But we don't actually do FPCA on the working functions. So like we thought about a couple different ways to parameterize the working functions in such a way that we can get interpretable values out of them. And we we have found that just using simple linear working functions still gives you pretty good registering.