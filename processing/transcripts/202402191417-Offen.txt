And I would like to talk about how to learn Lagrangian dynamics using Gaussian processes with uncertainty quantification and using neural networks. Okay, so what is this learning problem about? So you observe some motions, so the task is to do system identification, so you are observing a dynamical system, so you might observe trajectories, you might observe status. Might observe space-time data, and you're trying to infer the dynamical system that generates these motions. For instance, to interpolate motions or to maybe look for symmetries afterwards or maybe to infer some structurally simple solutions. So, for instance, you might want to learn a dynamical system and then later on look for traveling waves. Okay, and you might get Okay, and you might get discrete data, or you might have continuous data, and you might have velocity information, or you might not have velocity information, and you are trying to learn the dynamic assisting. Okay, plus you want to use prior knowledge. In this case, the kind of prior knowledge that I'm looking at is that you know that it's coming from a variational principle. But there are many, many aspects of it, and it's There are many, many aspects on it, and it's an incredibly big research community that looks at all kinds of different systems. And we have already seen in this workshop people learning Hamiltonian systems. So I'm going to learn Lagrangian systems and show you how. Okay, so I've already said the kind of prior knowledge that I have about my system is that there is variation in structure. So I know I've So I know a priori that my motions are governed by a variational principle, so they will be extremizers of some action functional. So I don't know the action functional, but I assume that they are extremizing some first principle of physics, which is equivalent to saying that emotions are solved the oil at a launching page. And the idea that has been around, and for instance, Kramer and Fanny did this. Kramer at funny did this Lagrangian neural networks. They were saying, just okay, learn the Lagrangian L, if you know this. And there are many variations of this idea where people make an answer for L, splitting it into dynamical part, into kinetic part, into potential, or where they have a right-hand side as well, some forcing terms. So that is one of these ideas you can do the same. Do the same in principle, you can do the same for Ps as well. So, if you've got a more common, if you're observing space-time data, and then you assume, you know, that it's coming from a variational principle, so all this field theory stuff, right? And then you're trying, so this means that if your motions are stationary points of this action functional, it means that they are solving the Euler-Laurent equation, which in this case is a PDE. In this case, it's a PDE, and then you can try to learn the Langer density L. In general, it might not be the best idea to try to learn the continuous theory, because while learning the continuous theory, you would somehow need to check, think you model L is a neural network or something. Then the Euler-Laurent equation would be in the loss function. And you see that there are quite high derivatives coming up here in the Coming up here in the Euler-Laurent equation, and usually you don't observe them, but you only approximate them, and then you have biased error in your training data because you're approximating the derivatives. So, it can be a better, or it's a much better idea to learn the discrete dynamics directly. So, like the one that you want to use later on to compute motions. So, you'd rather take a discrete variation of principle. Variational principle like coming from discrete variation integrators by Mars and Best. So you rather make an answer for the discrete variation of principle and then you try to learn the discrete Lorentz n. So you will get discrete versions of your ordinary of your Euler-Laurent equation, the ordinary differential equation case or in the PDE case. One thing that is a little bit better. One thing that is a little bit better here about the ODE case when you're thinking about theory is that exact discrete Lagrangians exist in the ODE case, in the PDE case. Well, exact discrete Lagrangians do exist, but they are defined on the whole mesh, not just on finitely many data points in the mesh. So you will get a small quadrature error. That makes it a little more tricky in terms of theory, but in terms of practical machine. In terms of practical machine learning application, you don't really see that problem. But sometimes you need to think a little bit about which kind of Lagrangian you take here. Do you want to have a stencil based in just three points? Sometimes for stability reasons, you need four points. So there's a bit of thought that you need to put into this. But the biggest problem is learning a Lagrangian is not, it's a very highly ill development. Is a very highly ill-defined task because there are many, many Lagrangian that govern the same dynamical system, and you somehow need to tell your machine learning algorithm which Lagrangian you want to learn. Because if you let it run freely, then it might just learn a constant Lagrangian. For a constant Lagrangian, the Euler-Laurent equation or the discrete Euler-Laurent equation is just. Discrete Euler-Laurent equation is just constantly zero, so it's consistent with all data. So you certainly need to do something. But you don't want to do anything that prevents you from learning your system. So you need to really think hard about how do I regularize this. And this is what I want to show you today. Okay, so what is the problem? So the problem there are So the problem, there are two types of ambiguity when learning a Lagrangian. There are alternative Lagrangians and there is something called gauge freedom. So let's start with the first thing because we really need to understand the theory to develop the right recognizers. So there are alternative Lagens. So I explain this on a simple example, linear motions. Say you want to give Lagrangians that describe linear motions. Give Lagrangians that describe linear motions. You can take any real-valued function j, write down a discrete Lagrangian in this action here, which is the difference inside. Then the discrete Euler-Laurent equation will look like this. And solution to this discrete Euler-Laurent equations are given by linear motions. So for any G, this discrete Lawrence equations. This discrete Lagrangian is a valid description of your system. And if g has a non-vanishing Hassian, then locally, this solution is even locally unique. Okay, but so this illustrates that it's highly ill-defined, right? So it's an ill-defined inverse problems. The long are not uniquely determined by the motions. By the motions. And even depending on G, depending on which kind of G you learn, the discrete Euler-Laurent equation might be very easy to solve or very difficult. So you need to take care of this. Try to learn one which makes it easy to solve afterwards for numerical. By the way, as an aside, sometimes it can be diffi it can be interesting to learn a couple of different Laurentins. Different Lagrangians, right? So not just one, but two of them. If they are sufficiently different, you can derive a whole series of conserved quantities. And people in the 80s, so physicists, usually, I mean, they didn't care about machine learning or anything, right? They had the formulas, and they were looking for different Lagrangian descriptions to derive things like complete integrability and so on and so forth. So, this is interesting in its own right, but this is what we now ignore, at least for the machine learning part. So, we just want to learn one Lagrangian that works well when I apply numerical methods to predict motions. Okay, so this is one type of ambiguity, alternative Lagrangians. There's also another type of ambiguity that doesn't really affect the Pointer-Laurent equation, so there's something that I call which. That I call, well, which is called gauge freedom. So if I have a discrete Langen, I can add a total divergence, and I can also put a scalar multiple here, I can put a constant there. And the only thing that changes for my discrete Euler-Laurent equations is that it scales. So this is a freedom that you always have. The other freedom that I've just showed you about alternative Laurent. Showed you about alternative Law engines that is just depending on the dynamical system whether they exist or not. But this is a freedom that you always have, which makes your learning problem ill-defined. But here it doesn't really matter which one of those you learn for solving the discrete Euler-Launch equation later, as long as you make sure that it's non-degenerate. Okay, and there is also the Okay, and there is also the setup of points where the discrete Lagrangian is invariant. This is invariant under these equivalence transformations. So the same works on discrete Lagrangian, on continuous Lagrangians. Same thing also for PDEs, by the way. Okay, but let's look at this a little bit further. So you have this type of equivalence relations, so it doesn't do much to Doesn't make doesn't do much to the Euler-Laurent equation. You can derive quantities once you've learned the Lagrange and you can derive quantities like conjugate momenta, so they are not invariant under range transformations. Symplectic structure is invariant up to a scalar. Liou-Will volume form is also invariant up to s to the n times Liou-Will. S to the n times viewable volumes form. Hamiltonians are well defined up to a scalar multiple and a constant in this case, right? So we also, when we learn the Lagrangian and later on, derive these qualities just for system identification, we need to keep this apart. Now, are Lagrangians unique up to this gauge freedom? No, they are not. We've already seen a counterexample. We've already seen a counterexample linear motions. Actually, generically, this answer is affirmative. Under non-degeneracy conditions, there's up to gauge equivalent only one Lahore gentle, so no alternative Lagrangian exists. Okay, right, so with this in mind, how do we set up our How do we set up our learning problem? Let's start with Gaussian processes. So, first, we somehow need to make sure that we are not trying just to fit something so that the Euler-Laurent equation is fulfilled, but we also need to come up with good normalization here that are compatible with machine learning. Let's start with, well, what can we do? So, by the gauge freedom that you've seen here, Freedom that you've seen here, we can freely fix, we choose a base point, right? And we can freely fix a value of L at this base point. We are free to do this. We are also free to choose the value of the conjugate momentum at a base point. This is fine and perfectly covered by gauge freedom, but it doesn't really help with the non-degeneracy, right? Because look at this simple example. Right? Because look at this simple example. L of qq dot is q dot plus one. It fulfills these normalization conditions here with one and one, but it's still the nullar bonge and so very degenerate. But still, it is nice to fix these things, and this is what we will see later when we look at variances of derived Hamiltonians, derived Lagrangians. You could look at this plot here. At this plot here, where I'm plotting the variance of the learned Lagrangian, and then you see that it helps to pin down as much as possible because there you're driving down variance, and otherwise you have lots of variance just because it's ill-defined. Okay, so this is interesting, but we need to do something more to really make sure that what we learn is non-degenerate. And okay, so let's go to the symplectic fonts. Go to the symplectic form. So if I learn a Lagrangian, I can derive conjugate momenta. If I have conjugate momenta, I can write down the identified symplectic form. If I have an identified symplectic form, I can build the global volume form by just taking the nth exterior derivative. And I've done this for you. And what I get is: well, this is like the standard volume form, so g. Standard volume form, so dq1, fetch dq.1, plus fetch dq2, fetch dq.2, and so on and so forth. And the neobal volume form will differ by this form, by this factor. So this determinant of this part of the Hessian matrix of L, which by the way is the same one that determines whether the Lambrungian is degenerate. Lamong is degenerate or not. Okay, so you've seen that it was coupled by gauge freedom this constant, at least at one point, right? Because I can scale the volume form with s to the power of n. So I can add as a normalization that this determinant here should be some specific constant. Should be some specific constant. And if the number of Q components is even, then you can only these absolute values here. If it's odd, then you can leave them out. So this condition now will, if you have this condition, you can actually forget about the other ones. So if you have this condition and you know that the other And you know that the Euler-Launch equation is fulfilled. So imagine this condition is fulfilled and the Euler-Lawange equations be fulfilled everywhere. This guarantees that the sort Lawrence are non-degenerate. So assume that no alternative parliament exists, then if you impose these two conditions, then you know that solid paramount chains are non-degenerate. This is fully covered by gain. This is fully covered by gauge freedom, and you can also add, and it's compatible to add these two extra equations here for further regularization. Great! Okay, so now we know the machine learning task what we need to impose. Now, how do we do this in practice? So, how do I learn this system with Gaussian processes? This is what I tell you first, and then later with neural networks. Okay, well first, same stuff in the discrete setting, same, well, not the same in PE, but that's you want to see some pictures first, I think. Okay, so how do we learn this with Gaussian processes? Take a prior. Take a prior Gaussian process, right? Then you condition on your observation, so you've got a Your observations, so you've got a couple of observation points, and you condition on that the Euler-Laurent equation is fulfilled there. And you condition on these normalization conditions, okay? So if you only condition on linear, if you only have linear conditions, right, then your a posteriori process is again a GP. So now the big So now the big trick is: okay, so the Euler-Laurent operator is a linear operator in L. Our normalization things, the first two that I've showed you, they were just linear in L. And then there was the thing about the symplectic volume form that is nonlinear. I told you that is the most important one, and now I tell you, forget about it. We only take this. We only take the linear ones when we use Gaussian processes, and I'm going to justify this a couple of slides later. So the big trick is now to forget this last normalization condition and only take the very first normalization conditions because then it's easy, then you only have, then you are only conditioning on linear observations, and then your posterior process is again LGP. is again a GP. So if a GP, if it's a GP, then you know you only need to calculate the posterior mean and the posterior variance, and then you're good, right? And otherwise you need to look at otherwise it's more complicated to compute the posterior. Okay, so let's do this. Let's add a couple of details here. How do you actually compute the posterior? Compute the posterior. So I've told you you need to compute the new mean and you need to compute the variance. And we also want to do uncertainty quantification for all the derived quantities. So say I learn a Lagrangian and then later I derive a Hamiltonian, then I want to have uncertainty quantification about how certain I about my Hamiltonian. MI about my humble t. So, how do we do this? Well, we take some setup in a reproducing kernel Hilbert space. So, you choose a kernel and then you have observables. So, which observables do we have? So, on this slide, I just assume that I want to learn a continuous Lagrangian, and I observe that. And I observe that my Euler-Larrange equation is fulfilled at some points. So at these points, I observe position, velocity, and acceleration. So this works the same in the discrete setting, which might be more realistic, where you don't need to observe velocities and accelerations. Okay, so that's the setting, just to explain it. So now there are observables, the evaluation functional, the Functional, the functional that gives you conjugate momenta, and the Euler-Laurent equation at a certain point, at some certain data point, q, q dot, q dot dot, which are all linear observations. So then you put them all into a long vector, put your observations into a vector as well, okay? And now you need to compute the Compute the posterior, so you take a prior, so we just take the constant zero as a prior. And now you condition on this observation that pi of L, L is solved, is equal to y. So now you need to calculate the mean and covariance. So to calculate this, you first work out your covariance matrix. out your covariance matrix for your observations. So you need to, so how does this covariance matrix look like? Okay, so you have all these observations and you need to pair each of these things, Euler Laurent with Euler Laurent, P with EL, evaluation with Euler-Larange. And then in each of these components, it means that you are applying your Euler-Laurent equation to your current. Launch equation to your kernel. Your kernel has two inputs, x and y. So you apply one to y and the other one to x, and so on and so forth. So you make this big matrix, and then you can compute the conditional mean in this fashion. So here you've got your observation, and here you need to solve a linear system. Then you have your conditional mean, which you can then evaluate. So, ideally. So ideally you save you save some LU decomposition or I mean in theory it's even symmetric. It will never be symmetric from a numerical perspective. So you can take an LU decomposition or if you're lucky you can take Chelsea. But these are details. So in principle now you can evaluate your conditional mean. Evaluate your conditional mean and you can compute the conditional covariance operator. So the conditional covariance operator, into this operator, I can take any observable and it will tell me the variance. So you can compute the conditional covariance in this fashion. And I'll give you an example because the most interesting example is the Hamiltonian, I think. The energy. So the energy in this setting is a linear observable, linear in L. Because if I've got L, then I can compute the Hamiltonian at one point as the conjugate momentum minus the Long Gen. Okay, and if I want to compute that, the variance of this one here, right, so then I can compute these mixed applications of the inhomogeneous. Applications of the Hamiltonian operator to my kernel, and then this mixed application of phi, which is my Hamiltonian operator, to the observable variables, so to the Euler-Laurent Hamiltonian, Hamiltonian conjugate momenta, Hamiltonian evolution. So I get this factor, and then I can compute this conditional covariance, and this will give me. Covariance and this will give me the variance at one point. So this is very nice now. We can get, for any linear observable, we get uncertainty qualification. Okay, so let's do this in an example. So I take the coupled harmonic oscillator and here's some illustrations. So here is a projection of this four-dimensional Projection of this four-dimensional space to two-dimensional, where I tell you where I've put my data points. So at these points, I have observed my system and know the Euler-Laurent equations fulfilled that. So at those points, I know Q, Q dot, Q dot dot. In the middle there, this is the point where I normalize that the Lagrangian is... That the Lagrangian is one and the conjugate momentum is also one. This is required at this point. Okay, and then I can learn consistently. So I can afterwards check how certain I am at a specific point that my Euler-Laurent equation is fulfilled. So I can have a heat map here and you see. Each map here, and you see where there's large uncertainty. I can put more data points, I can put more samples, and I kind of see from this plot how certain I am about my Euler-Laurent equations at that specific point. And you see what happens if I use more data points here. If you look at the scales, so the uncertainty goes down. So, by the way, this is also, if you can size. This is also if you can sample from a data set, this can also inform you about where you should sample more and where you've already learned enough. Okay, let's use these Lagrangians to predict motions. So this one has not enough data points. 80 was not enough. So you see the motions that are predicted here are nice and smooth. They are quite wrong. And you can also see this because. And you can also see this because at each point here, you can check how certain you are to have learned the correct Euler-Laurent equation at this point. So you get a measure on the local error that you can expect there. And there's quite a lot of local errors. So you see kind of the range here. If I have more data points, I can also predict motions. And you see the range of uncertainty goes down. Goes down and it already looks so this is if this is like looking like a reference and nice thing now you can also as I explained to you the Hamiltonian in this setting is just a linear observable so you can plot the Hamiltonian function and you can plot the standard deviations so here you see So here you see even just with 20% standard deviations, the Hamiltonians can look quite different. While here with more data points, you see that it's much more certain about how the Hamiltonian looks like. And here, by the way, at the point at the origin, of course, there's no uncertainty because this was actually what we fixed with gauge freedom. If we didn't fix this with gauge freedom, If we didn't fix this with gauge freedom, of course, we get more uncertainty than we really, really need, right? Because then it's just not uncertain for physical reasons, but it's uncertain because we've never anywhere pinned down where the Hamiltonian is. Why is it that you did not need to use the Nicholas transformation in the H? Uh okay, s well, so this is here I um computed H in terms of Q and Q dot, not in terms of P. Not in terms of P. So it's if you're not really damaged on in a sense, yeah. Yeah, it's it's it's the energy, right? Yeah, but by the way, we can, I mean, you get uncertainty quantification for the piece as well, for the symptomatic structure. Yes, but I mean, it's a very good point. For all the linear ones, you get this so nicely. If you want to get the answering quantification for the acceleration or for the Hamiltonian vector field. The Hamiltonian vector field, for instance, right? Then this goes with the inverse of the syntactic structure. So you need the distribution of the inverse, which is not linear anymore. So there you need to sample to, oh well, in the most general setting, you need to sample to compute the variance there. And here you just get the variance with very simple formula. Yes, okay. Yes, okay. And here, well, a bit of theory here. So let's assume no alternative balancers. So then the condition that the Euler-Lalange equation is fulfilled everywhere determines the Hamiltonian up to rescaling in a constant. And this is why this works so well. So especially with we are determined with these two normalization conditions that we have added, they fix L, they fix H. They fix H. By the way, the upper termonic oscillator has alternative Laura Gens, but that's just as an aside. And now the question is, why didn't we have to impose that the learned La Rangen is non-degenerate? And there's some very nice thing. And there's some very nice thing. It very, very nicely, this type of working very, very nicely fits into a technique by Shen, Hosseini, Ohardi, and Skewer. By the way, OHADI has a couple of papers on this topic about learning solutions to PDEs with Gaussian processes, right? They looked at Processes, right? They looked at learning solutions for PDEs, for Gaussian processes. So you can interpret this as learning a solution to a PDE. Because, well, the Euler-Laurent equation is a PDE for L, and you're trying to solve this system for L. And these non-degeneracy conditions, they are like a very weird boundary condition. So you almost get everything. Almost get everything that they need for their theory except their uniqueness. So then you need to work a little bit. But you can reformulate this as a minimization problem. So by computing the posterior, what we're actually solving is the following minimization problem. So it's a minimization of the reproducing Colonel-Hilbert space norm of L, strand minimization and the constraint. Minimization and the constraint is that the Euler-Lawrence equations are fulfilled at the data points and that our normalization condition holds. Okay? And okay, so if the true Lagrange and if there is a true Lagrange, the work produced in kind of Hilbert space, and it's the unique global minimizer of this problem, where the Euler-Lagrange equation is fulfilled everywhere, and the conditions are fulfilled. And the conditions are fulfilled everywhere, then you even get convergence. So they have convergence proofs by putting in more and more data points. You can get convergence and you can harvest these results and transfer to this setting. And now look at this. Unless you are really, really unlucky, you can leave out this condition about this not. This non-linear condition about the non-degeneracy condition on the sympathetic because you will still compute the minimizer and you would be very, very unlucky if the minimizer was a degenerate bound. Especially if you put CB here equal to 1 and the reference PB equal to 1, then you will Be equal to one, then you will compute the minimizer. And it would be a coincidence if that was exactly a degenerate Langer. So that this condition here makes the difference between degeneracy and non-degeneracy condition is quite unlikely. Of course, if you were to put CB equal to zero and PB equal to zero, then it will find the prior. Find the prior, which is a degenerate low-large. But this gives a hint of why we were allowed to just delete this and stay in the linear setting and having everything work so nice. Okay, and you even get convergence through that theory, which I find is very satisfying. Same thing. Ah, one more thing that I want to mention here. That I want to mention here is the same thing works for discrete Lagrangians. This was just illustrating it here for continuous Lagrangian. So if you learn a discrete Lagrangian, you can compute the continuous Lagrangian. Because Matz Vamier in 2017 showed us how to do backward error analysis completely on the variational side. And then you can apply kind of an. Then you can apply kind of an inverse version of this backward error analysis to your learned discrete Lagrangian. And then you can identify the true Lagrangian, the continuous Lagrangian, and also the true Hamiltonian, and so on and so forth. So there's nothing that should keep you from learning discrete quantities. You can get the continuous quantities back in. And it actually works also in a machine learning setting. In a machine learning setting, so this is fine. But those are expansions, right? They are expansions, right? So you can get into any order, and they are expansions in H. It is not expected that they converge. It is expected, it's not proved. So convergence on the variational side is not proved. It works a little bit different. It works a little bit different to the Hamiltonian setting, but at least in terms of convergence and so on and so forth, it looks like it's exactly the same as in the Hamiltonian setting. So this means that first it converges, you get superconvergence, it converges exponentially fast. Well later if you take very, very, very many, very, very many of these charges. Very, very many of these terms here, it will eventually diverge. But this is just coming from the observations of just adding more terms, a posteriori cutting off later, and then seeing how well the energy is conserved when I compute the corresponding Hamiltonian to this. Okay, but if you check the first couple of terms, it works nicely. One thing that comes in if you take very high-order terms is that you also get very high derivatives, which can also be a problem numerically. But most of the time, second order already looks very, very nice. Okay. Um yeah, PDEs. Um I just want to show you a couple of examples here in the PE setting as well. Should be finishing fairly soon. Well, I should be finishing fairly soon. Okay, so I should speed up. Oh, so I'm actually slow. Okay, right. Okay, so the discrete order Long function here, based on a nine-point stencil, we do exactly the same stuff that I've explained to you, just for this discrete Lyman here. We normalize local conjugate momenta instead of momenta. You have You have these two training data examples, just two, which is this wave with a little bit of higher Fourier modes on top. And this already contains all the information about your system. You can use your Gaussian process and then predict these very nice smooth motions with this initial condition here. Looks exactly like the reference and And you can get uncertainty quantification and see where it's uncertain about its behavior. One thing that I always like also with neural networks is to put in the initial condition of traveling waves and you see it will find the traveling waves, though if you make it predicted for very long time steps, you will see it exploding here and you can also see it in the uncertainty quantification. Okay, let's see whether we can. Okay, let's see whether we can still cover a bit of neural networks. But actually, it's kind of the same ideas, right? I mean, same theory should apply. But the regularization works different. Because, I mean, for Gaussian process, I can nicely just condition on something saying it must be zero there, or it must be one there. This doesn't work for neural networks. This doesn't work for neural networks. So, for neural networks, now we don't really use these conditions. We use this condition with a symplectic structure instead. So not the first linear ones, but the non-linear one in this case. So you model your discrete Levant as a neural network. You have a data consistency trip that you can fit, and you need new racquizers. And the new racqualizers, they look like Recognizers, they look like this. Jumped over a slide here. So you look at, after learning, I need to solve my discrete Euler-Laurent equation for the next point of the stencil. So I look here, which kind of, if I apply a numerical, if I apply something like mutant iterations, how does my convergence How does my convergence theorem look like? I look like which constants do I have here, and what determines how big these constants are. And it is the smallest eigenvalue of this mixed derivative matrix of L. And then I just need to punish very small eigenvalues. So I put recognizing terms here. For instance, value that punishes small eigenvalues. Punishes small i values, or just one divided by the smallest i value, or some modification of this. And by the way, so if I if I use, if I were to use here, if this was an ODE example, if it was an ODE example instead of PDE, then this is the same term that you had in the symplectic structure or in the real world volume form. So there it all merges together. Together. Okay, the high eigenvalues are controlled simply because it will blow up this error term, so you get actually guarantees on numeric conditioning. It works for the wave equation. It works for traveling waves. You can even find the traveling waves to learn your condition and then look for traveling waves and then locate them there. It works for, let's see. For let's skip over this comparison here. It works for the Schr√∂dinger equation as well. It works for different stancils, so a very nice and fine thing. So thanks so far. Sorry to rush you, but we have time for about one question, I think. Tier. So for the GP Let's. How sensitive is it to the choice of prior? Okay, so how sensitive is it to the choice of prior? The convergence theorem is not sensitive. But in practice, I haven't tried enough to answer this question well enough, right? Yes. Question: If anyone's got one? Any question? Is there a reason to prefer the Lagrangian framework versus kind of? Prefer the Lagrangian framework versus the amount of work? No, but here it's interesting because you have to work out these normalization conditions. If you do the Hamiltonian framework, you usually assume that you know your symplectic structure in advance and then you don't know, then you don't need the regularization. But you will have exactly the same problem if you were to say we learned the symplectic structure at the same time as the Hamiltonian structure. Then you are exactly in an equivalent And then equivalent condition here, right? Okay, well, thanks very much. So, it's now coffee time. We have