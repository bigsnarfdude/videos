For the this conference, which is in a beautiful landscape, both the natural one and the mathematical one. Okay, so some of the talks, the title of the conference is random algebraic geometry, somewhere less random, somewhere less geometric. Mine is going to be less algebraic. Although it does connect to some of the talk we had and I would try to emphasize that. And I would try to emphasize that. So, the setting is the following: we have a smooth manifold. If you want to think algebraically, you replace manifold by violating of dimension m. And then I'm going to take on the manifold a random function with value in Lk, so I can think of it as a system of k functions, and I take them randomly. And I'm interested in the And I'm interested in the solutions of the space of the zero set of this function. And these are going to be my random sub-manifold. So I'm going to describe what kind of model I allow. It's going to be pretty general, but first I'm going to tell you what exactly I'm interested in. Okay, so I'm interested in studying this sub-manifold, but more specifically I'm interested in two types of question. The first one, The first one, I want to do the following thing. I want to take a differential form. So, this first question I'm going to call it the signed count. Just about an ID in mine. So, I want to take a differential form of the gig M minus K. So, if everything goes well, if my system is not degenerate, this Well, if my system is non-degenerate, this thing is going to be some manifold of codimension k. So, on sub-manifold of codimension k, I can integrate forms of degree m values k. So, I can do the integral over z of my differential form, and then I get a number. This number is random because my z is random, and I want to take its expectation. So, why do I call that the sign count? Because A sign count because if, for example, k is equal to m, then I expect a discrete set, maybe a finite number of points if I'm compact. And then this thing is going to be the expectation over the sum over f of p equals zero, of the point in my zero set of omega of p. That now omega is what? Is a zero dimension? A zero dimensional form, it's just a function, right? And then I get the sine of Vpf, which is just the orientation of maximum. So now if omega is just one for every bit, I get the sign number of the sign count of the number of points. So you can think of that as a signed volume, okay? Sign count of a volume of Of a volume, of course. Okay, so this is one thing I want to do. And the second thing I want to do is the norm sign count. So I want to count the volume of my sub-manifold. So for every open set in M, I want to answer to the following question. I want to take my open set and look at the volume of the appropriate dimension. Oh, yeah, maybe I should say. So this felt case, I need my n to be OE. I need my n to be orientable. And in this second case, I'm going to assume my n is Riemann. So I can talk about the problems. And yes, I want to look inside a window, U. I look at my Z inside that and I want to say do I have a lot? Do I want how much of my Z is inside this? Much of my Z is inside this. Okay, so I want to count the volume of Z in this window I choose. And again, I want to tell you about the average. So this is the type of question I'm interested in. Is it clear? Okay. So again, this in the case where k equals to m, this is just the expectation. The expectation of the number of, let's say, solution of my system in u. But this time without size, the number of points. Okay, this is the kind of thing I want to evaluate. And under a good assumption, the first result is that under a good hypothesis, so under On my random function f. Tuesday we have two different words for good, a Basque and another one, I don't remember that my word for good is going to be what? Dopro Dopro, but I don't remember for well from where it's Spanish Ukrainian. Yes. Okay. My word for good is Skok. It's my own language. It's actually mine and Vikene. Okay, so under this hypothesis that we'll tell you later, we have a good answer for one. So the theorem so I'm gonna put yes, this is a theorem we have for the reason we tell this economy. And we have this BKS economy. It may already have been known as a feature of the cat's high sport, you know? Okay, and what does it say? It says that to answer question one, I have to compute a differential form. So there exists a differential form, EZ, that is of degree k. And let me emphasize that this is not random. Let me emphasize that this is not random. This is like, okay, not random. This is like computing the expectation. Only I compute a differential form, a deterministic, and this differential form answers question one. So, such that for all differential form of omega, The expectation of the integral over Z of omega is equal to the integral over M of omega which ECA. So if you know like point of virtuality, it's something that looks like it, except like we have a randomness. Um okay. One thing I didn't say, and I should have said um is that we're interested in these two types of questions, but we intersect maybe a little bit more. Maybe a bit more. We want to know also in the case where Z is an intersection of two independent Z1 and Z2. Independent intersection. So if you remember, for example, in Lego's talk, I think, we had a system of equation of each line was independent of the other, and we will count the number of points of intersection. I want to be able to do that also. And the nice thing with this form is that I can do that. form is that I can do that. So if Z1 is F1 minus 1 of 0, Z2 is F2 minus 1 of 0, both are good score and independent, then the differential form corresponding to the intersection is equal to the wedge of the D F differential form. Wedge open DFM for the majority of the majority of the media. So you're looking at the rank homology, like different classes forms, I guess. So it's a little bit more than the Durand homology because I can integrate any form, not necessarily closed. What this object is, actually it's a current. Yeah, yeah, yeah, I was thinking. So yeah. But yeah, you're right. If you do that only for closed form, then you. That only for closed form, then you obtain like the Commonwealth class and exactly. So, what it says is that the current of integrating about the random current, if you take its average, it's represented by a differential form, exactly. And then I think it's like the intersection is given by the wedge product, and you have a bit more. You have, if you have a smooth map, it goes from n to n. To n and such that phi is almost surely transversal to C. Then I can also compute the form of the pullback of the C. So if my map intersects nice and easy, I can take the pay match, it's going to be also a submarine for random. I can take, look at its form, and it's the pullback. The pullback of the present function. So, this is nice, I like that, because why? Because Z is a complicated object, okay? What knowing D is knowing a probability distribution on the space of C1 functions with a complicated object. I don't want to remember all that. The moral of this story is that if I only want to do count things like that, I can throw away my z and remember just the differential form. I keep the differential form. I give the differential form, I throw away all the rest. And I know if tomorrow someone gives me an omega, I can integrate it. If someone gives me another Z2, I can still do the intersection, and I can still pull it back. So all the things I need to compute this kind of thing are contained in this differential form. And I can throw away the complicated thing that is a random function. I just remember one differential form, which is an easy object. Which is an easy object. Okay? Okay, so this is great. What about two then? So for question two, for two, there is something, there is something called the Katzhais formula that we already saw something. I don't know if it was mentioned explicitly, but it was in some of the talks. And what does it say? It says that. It says that there exists a function on my manifold, which is the cat's highest density. Again, this is not random, this is just a function, such that all open set the integral, so the answer to question two, the expectation of Expectation of the volume of z is equal to the integral over u of this function, delta t for the Riemann and whatever the notation, just the integral of this function on this open set. So you may say this is nice, a function is also a simple object comparable to another function. The problem with this is that you don't have property B and C. So And C. So the coupling delta Z one delta Z two is not it does not does not determine the cut size density of the intersection. So if you know does it determine the pullback So, if you threw away your Z and you only remember the density and someone gives you a Z2, those code, you cannot compute. Or someone wants you to pull it back, it's too late. You throw away your Z, you cannot answer anymore. So you have to remember all the D of the random function, and you don't like that. It's a lot of things to carry, and you would like an object that is like this differential form, in this sense. So the punchline is that. So the punchline is that let me work punchline say punchline okay so um the analog of E Z of the differential form E Z for question two is a zonoid It's a zonoid, so it's a convex body, and this zonoid, I'll call it zeta z of p, I have one for each point of my manifold, and he lives in the same space where my differential formula lives. So it's a zonoid in the lambda k of the t star p m. Okay? Okay? And now I can write the theorem. Yes, I can write it here. I have a theorem for question 2 that says, first, my zono, it answers to question 2. So for all open sets, the expectation of the volume of Z Of z inside u is equal to the integral over u of what? Of something I want to call the length of my isolated. And this length is something called, more commonly, the first intrinsic volume. It's a geometric quantity. Intrinsic. And then I can also do B and C, meaning that if I want to compute the zonoid of the intersection, C1 and C2 at a point P, I can do an operation on my zonoid to compute this one. And the operation is the wedge product of zonoid. Is the wedge product of zoning that I will explain to you later. And it's an analogous of the wedge product of differential form, but at the level of this convex matrix. And I can pull it back also. Theta phi minus 1 of z in a point q in m is some kind of pullback. The only thing that makes sense. The only thing that makes sense. Okay, so that's, and I even have more E, I have that this zonoid as every zonoid is centrally symmetric, and the center of delta z at the point P. At the point P is precisely my differential form EZ and I just have a one-half. Okay, so this is great. I can throw away my random function, just compute the zonoid, and then I will have the answer to all of these questions. I can just, it has enough information to compute this expectation of volume and all this. And all this intersection, pullback, and even the sign count is also contained here. Any question? Okay, great. Is it already in your thesis? That one? No. Yeah. It's in the thesis. Yes. So I should really read it. Everybody should read it. Okay. Um I will try not to erase that. That will be difficult, but we are going to be able to make a new one. Okay, so let me. Okay, so the plan is I'm gonna tell you a little bit what these zones are and what this wedge product of zonoids is and then I'm gonna tell you what the cog functions are and then hopefully I will be able to tell you some nice application that I have. Okay, so zone it's So, dunoids are convex bodies. So, convex bodies, you know already, they are convex, coarse, compact and non-empty. Very simple. They come uh with a distance called the host of distance that provides a topology that makes it a complete metric space, so we have It's a complete metric space, so we don't care. Okay, I'm going to tell you how to build a convex body in a particular way. The first step is you take a random vector, random stuff, and then you consider it not as a random vector, but as a random segment. This here is a random segment, this n point zero. Segment, design point zero, and my random vector. So I want to build something that would be like the average of this random segment. I want to build some kind of expectation of this random segment as a convex body. How do I do that? I do that because I'm able to do that thanks to a strong law of large number. There's something called the strong law of L. There is something called the strong law of large number. It's usually for numbers, as its name indicates, but there is a version for compact sets. And this is something by Ashtein and Italy, you don't know when. So, what does it say? He says if the expectation of the norm of x is finite, so usually the law of large numbers says if you have a random variable and it has a mean, then you can take several IID copies, sum them, divide by the number you have. We call that the empirical mean, for example, and you let n goes to infinity and then you converge to the mean. And then you converge to the mean, I'm not sure. This is a strong law of marginal. You should not say for compact, complex sets. No, it works for compact sets. It's more general. The limit thing is complex, but the compact set you need not. You need to understand what this condition is, but yeah. So what do you do? You take x1, xn, iid, x, x, x, IID copies of X. And then you build the sum. What is this sum? So this is the Minkowski sum. I'm going to tell you exactly what it is. By n. So this guy here is let me have to come here. What it's that, it's all the convex combination of x one, x ten, okay? Of x1, xn, okay? So x1 plus n, xn divided by n, and all the a i's are in 0, 1. So it's what's called the Minkowski sum. So I take this segment, and I make the Mikovsky sum, and we normalize, I get a random polytope, random zon top, and the zone glow of large numbers said that these components. Said that this converges almost surely as n goes to infinity to a fixed compact, convex set. So this is like convergence in host. So it's convergence in the host of distance almost surely. I mean like with probability one, I converge in the host of distance to this fixed thing. Okay? Okay, is it clear? Is it clear? So, um definition for me today: um the convex bodies that arise this way are called zones. And then translate. So usually you probably have seen them with another definition, but they are equivalent. So you can define them as a limit of sum of segments. So this is clearly a limit of sum of segments. You have to prove that you can realize all of them like that. And this was done by Vitali. You may have seen them as. You may have seen them as something with a measure on the sphere, and you can also take the measure of the sphere from the ball with the distribution of x. But today, this is my definition. I'm going to call the space of the noise Z of L. So I like this definition also why? Because it's a bridge between the probability and the convex geometry. And I have, for example, to illustrate that, I can tell you this. I can tell you this little fact that this expectation of the norm of x, so you may want to call that the first moment of the Ramon vector, this is the first intrinsic volume of this convex volume. So this is probability, this is convex geometry. You can switch from one to the other with this zones. Okay. Okay. Questions? So are there other ways to get this? Like, I mean, like, there's a support function, like the integral. Exactly where functions are the important case. The support function, so I call that expectation of the O X. This means that the support function of this guy is the expectation of the support function of this one. This was also written at at some point in the regular sort of novel. These are the same. Yeah. These are the same. Okay. Yeah. Um I just like this definition, this should be more geometric, but yeah. The support function is well what you work with. Okay, so now the zonoid, this multiplication of zones. So this is a joint work with Paul Biding that is here, and Peter Pengiser that is also here and Antonio Ledrario. And Antonio Ledrario, he's not here, but he's a little here sometimes. And myself. Which says what? He said that there is a billinear continuous relation. Unique that is I want to call the wedge product. That takes what? That takes a zonoid in Ln, another zonoid in Ln, and gives me a zonoid in this lambda 2 of L. Takes a wedge product. What does it do? And such that And such that, okay, so yeah, this operation I can define it on these guys, yeah. And what does it do if x and y are non-vector independent, then I can compute the expectation, the wedge product of these two zonoids And this is expectation of your x wedge of y. This can be, if you want a definition, you have to check that things are well defined, but they are. And this defines an operation on these zonoids, and you see that I can here change that to Lambda k here, lambda L here, and here I have lambda k plus l. This defines billinear operation that we can also call multiplication on the space of zone widths of the exterior algebra. This operation is billing, as I said, it's continuous and it's the only one that does that. So it's kind of a wedge product of forms. Of points, but for some compact sets. It's not as simple as just a point-wise definition. If you're trying to say, I take all the points here and all the points here, and I wedge them, you don't obtain a convex operation. The result is not going to be convex. So really, you have to restrict to the zonerist to have this structure that allows you to do that. This may be a little abstract. So maybe the most important example The most important example is the following. That if I take n zonoids in n, let me take a look more space. I don't want to cancel that. So if I w if I take a man. K1, Kn polynomies in N. And I look at their wedge product. So this guy is a zonoid that lives in the lambda n of Ln, that we can also call L. So it's a zonoid in L, really it's a segment, and its length And its length, so the length of this segment, is given by the mixed volume of this summary. So what I can think of is that this wet product is some intermediate term before computing a mixed volume. So it's like doing a mixed volume, but you live in some spots empty. What you have is a convex volume in this exterior algebra. Okay, and this is what the wedge. And this is what the uh the wedge called the hotzonoids means. Any questions? Comments? It's not. Yes. I call it Lisonid algebra. Good remark. It's not an algebra. I mean, Kotski Som does not add a members, as you may have noticed. So what you can do is artificially create an is artificially create an inverse and you we add a code rule construction. Algebraically it's very easy, you just have a minus and then there is a cancellation rule so nothing happens. But things happen topologically. So here you have the topology given by the host of distance. If you do the rotating reconstruction you have a vector space, but you also just have the topology on this cone and it does not determine the topology on the whole vector space. In fact you can Topology on the whole vector space. In fact, you can have two different topologies that do not agree. But really, zonoid, as I said before, there are measure on the screen, and the weak star topology does give the same topology, so you can take the weak star topology. There are also continuous functions, the other support function. You have the null topology, does also come uh give the host of topology, but it gives the different topology in the world case. I mean, yeah. So it's not an algebra. So it's not inevitable. And if you do that, if you do the algebra, then the continuity becomes non-trivial. Sometimes things are not continuous. Okay. Okay, now I want to tell you what is called field series. So, remember the setting that I just erased, I think. M is a smooth manifold of dimension M and F And f is a random C1 function. Its value is derived. So I'm going to state some conditions on this random function that I will go to talk. These conditions are not a condition on the function. They are a condition on the probability distribution of the random function. Okay? I don't yet. Yeah. Okay. So I've spoke. Spoke is. So I have three conditions. The first one is pretty reasonable. The second one is technical. Once I've written it, you can forget about it. And the third one is a bit technical, but has some meaning. I'm going to try to explain why. So the first one is zero is a regular value. Already one of the first things I said, um, almost surely. And almost surely. Value of f almost surely. So my system is not degenerate, almost surely. So my z that I'm studying is indeed a smooth sub-manifold of codimension k. Second one is that point in p in m, the value at a point p, which is a random function, a random variable in lk, this has a density. I want to call O f of pin, I want to be original, and this is continuous pin zero. I can forget about it, I just need this letter. But anyway, yeah, I don't want any too pathological behavior. For example, if this would be a delta in zero, I would have what is called a base point, like my front. What is called the base point, like my functional module is zero at this point, I don't want this kind of thing. Okay. And the last one is that there exists a condition random field. So I do want to be able to condition to the fact, so I want to call that condition random field. And so this is conditioning my function to the fact that P is a zero, or Z passes through P. In general, this is going to be an event of measure zero. You cannot condition by an event of measure zero. You need some more regularity on your probability distribution. This is what you require here. So you need to be able to say, okay, I would have only the random events, the random functions that are. Events, the random functions that are only the outcome that passes through P. And what we want more is that if I call F, so F is a value in Rk, so I have F1, FK, okay, and I want that under this conditioning, the Jac normal Jacobian is uh finite in expectation. expectation. So I write that f of p equals zero. So I want that the expectation of this guy, which is just a normal Jacobian of F, conditioned to the fact that f of p equals zero, is finite. Okay, so the only thing I need to, yeah, the thing you need to remember is that you need to be able to do this conditioning. For example, if your variables are Gaussian, or if you If your variables are Gaussian, or if you live in a Gaussian world, this is always possible because Gaussian are nice. You can slice a Gaussian and obtain a Gaussian and you can do this sort of thing. But yeah. Mainly it's like slicing in the space of parameter by the equation f of p plus 0. You see that as an equation for f. This gives you a subspace in your space of parameter, and you want to restrict to that subspace. So you want some regularity on your probability distribution. Regular distribution. Be able to do that in a continuous way. Yeah, you need some regularity. Okay. And this is the finish. And maybe, yes, maybe an example. Because this may be like a bit difficult to check. So the example is if most of the cases, I should have said that earlier. I should have said that earlier, but F is going to be something like that, where phi 1 phi D are fixed and A shift these parameters are random. Okay, so we saw about already a couple So we saw that already a couple of times, like phi1, phi d would be monomials or these cost land monomials, and then A1, AD would be normals, independent normal 01. Okay, this was in a couple of talks, and was always talk also that we have this sub-exponential, this kind of thing. And here, f is cog, well, rather, if so. If so, I'm going to say a sufficient condition to be sculpt, and if A admits density, the C0 density, to be standing in the space of parameter, which is here L D that decreases as as normal to the minus d at infinity and f is coc. So really those cover are the case of exponential distribution, it decreases fast enough at infinity, sub-exponential also, but many other. Just take the space of function, finite Space of function, finite dimension. So you need that to be non-degenerate in some way. But if they are, take any distribution that is polynomial enough at infinity. And then this is covered by the theory. And now with this score field, what you do, when you have a random vector such that the norm is finite, you can stick, we're going to take the son of it. So zeta, so again, f. So again, F and C1 and K. S cock. Then I take C to be the zero set as before, and I define my zone lead P to be the expectation of this segment. K condition to f of p and I want to remultiply by this guy here the density of f of p at zero. And this zonoid is the one that started. Okay. Questions? Yes. Yes, so this again is a little bit abstract, but thanks to. Oh, yeah, I shouldn't close it. So combining that, that, and that, we can find a more concrete example, which is a collary. Again, the OM stuff stick on you. In the case where we get independent hyper surfaces. So the third thing is just if I take F1, Fm, that's our this time these values L, they are all coke and independent. And now look at the eye, which is so Which is the solution of your set. Then, and now you take an open set M, then the expectation of the number of points of the intersection equal to this time it's the integer. This time it's the integral of m factorial. If I take that down, this is equal to the integral over u of m factorial times the mixed volume of this guy. Okay, so this is some generalization of what the goal is. Of what Ligorius was talking about. In this case, you have Gaussians, and the thing you obtain here are ellipsoids. Now, I'm telling you, if you take some other distribution, you can still write that down as a big volume. Only the thing you obtained are maybe more complicated and you have to compute them within this volume. Okay. But only knowing that it's a mixed volume, so if you want convex geometry from the analysis side, and you see a mixed volume. On the analysis side, and this is a next volume, and you have a lot of inequalities about Alexander Frenkelian inequality, Brunikovsky inequality, and they do translate as inequality of this categorized density of the interception. So this guy now is a density of the number of solutions in your okay. It's like how much how many solutions will I have near this point. Yes, can I ask a question? Just a quick illustration. I mean Just for illustration, I mean, this week we all prefer about sway results. So it just wouldn't be nice to say what this zono is in that case. I assume in each point there is some multiple unit ball, right? Yes, exactly. So this zonoids here, like if you have some invariance of your field, they are going to reflect on the invariance of the zonoid. And for example, in the example. And for example, in the example that Peter was citing, so the cosm polynomial are invariant by the orthogonal group. So you're going to be able to deduce that the orthogonal bowls really. And so you can compute their radius, some square root of D will appear, and then you will have just a mixed volume of bowls that will be normalized or something, and the square root of D will all appear. You can actually do the computation by hand, and it's just comes out. Just comes out. Of course, in that example, it's not very useful to have the meat volume, it's one of the boles. But yes, you can, you can, you do see it. Just like see that the zone is a square root of t times per bowl. And some other examples like things we are working, if you are in a homogeneous space, you have some action, and these guys are going to be also invariant by some group, and you can study the volume, and this is what. So, what we have in our unpublished work is a corollary of that, right? Yes, although what's interesting, especially with this in line, here it's more general, but also you can say less thing. Yeah, yeah, for sure. But already, for example, if you do Alexander Feinkel here, it's not directly in. Here, it's not directly an inequality on the number of points of intersection, but really an inequality on densities. You can only directly compute something. You have an homogeneous space and everything is invariant, you don't need to integrate over the microphone, you can do everything at the point, and this integral disappears. Okay. Other questions? I have I have two minutes on my hand or another. I have two minutes. Two minutes or more. How much time do I have left? Five minutes. Five minutes if you're too sorry. That's why. A little example. So the example I want to say is nice and that I was about to compute thanks to this. Thanks to this point of view of convex volumes and bits volume, the following. So I just have now my random function is of the following form. This is a fixed function phi, I CO maybe, plus tau time a random Gaussian function. So what are the tau tasks here? ECO is just small. Is just one of m fixed. Tau is a small parameter that I think is small, and I want to call something like the temperature. And G is a Gaussian random field. What do I mean? This means this. This means this has precise meaning, but let's say just for now that that value at each point is the standard Gaussian. So what do I have? I have like, and then, oh, okay, this is phi. F tau, and I look at z tau is the pay image is the pay image of f tau, z over f tau. So I have like this fixed thing. Uh this fixed thing is at zero, and I perturb it a little bit by some Gaussian. So maybe it does something like that. But it's gonna stay close if my toe is small. So the idea is to try to say when toe goes to zero, I expect this to concentrate around my z zero, and how fast does it concentrate? And can I say something qualitative about that? Qualitative part. So this may be already known, but the thing is like by studying the zonoid associated to the non-centered Gaussian, so I told you earlier, if I have a Gaussian I meant centered Gaussian, vector, then the zonoid associated is an ellipsoid. But if my Gaussian is not centered, it's not an ellipsoid anymore, something can form, the leap bit. Something performed a little bit. But I can still study it. I have a support function. I can do some asymptotic, compute their volume, it's something manageable. And I can deduce things in this random field theory. And I'm going to tell you exactly what can I deduce. I'm going to write UL, that is just window, the neighborhood here, 150 or smaller than L. Yeah, okay, so I have something like that. I want to look inside this window here, and the theorem is that when tau and l both go to zero, and I'm gonna put some notation. So this way is toe is way smaller than L. Tau is way smaller than L, which means that L over toe goes to infinity. Then I look at the expectation of the number of points of IID copies of this. Inside this window, you are that is also getting smaller. We're still going. Order with toe going to zero, and I'm looking at the limit as toe goes to zero, and L also goes to zero, and I'm able to say, so sorry, I didn't say that one that I told I copies up set toe. Set top and the limit is a constant that only depends on m times the volume m minus 1 of z. And this constant is explicit, and the very last thing I'm going to say is that if even in the critical dream where this goes to a constant, I can also compute what is lost here. I think it's done. I think it's that. And this is all possible. I mean, it may have been done before, it's not that hard, but this is quite easy to do by studying this sonoid. And this is like given by computing the volume of this guy, the asymptotic volume of this guy. And this is made possible in that case by this geometric picture of the zones. And that's all I have to say. Good questions