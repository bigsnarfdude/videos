So our last speaker of the day is Neil Waten from Durham and he's going to tell us about optimal scheduling months wage. Okay, take your way. Okay, yeah, thanks for having me. So this is with Sanadei Bambe and Thiru Vasantam, who are two colleagues of mine at Durham University as well. And it's funded by Informed AI, which is sort of the AI hubs in the UK. So I So, I'm not going to bamboozle you with quantum mechanics because I don't know enough. But this is really about sort of extracting the key elements of some quantum systems and then converting these into some matching problems, which you all kind of recognize. So, I'll probably try to spend a fair bit of time on motivation. And then I'll explain why things that we used to say in a classical internet route switch, the kind of Cisco style, probably wouldn't work. Probably wouldn't work in a quantum scenario, or at least in the same, at least the sorts of algorithms that we've used there in the past are not necessarily going to transfer over, and what sort of corrections we can make to make sure that they do work. So here's an outline of the talks. I'll talk about quantum networks in general. I'll talk about classical switches and can make a comparison with what might happen in a quantum switch. I'll talk about Max Weight algorithm, which is a kind of famous sort of matching algorithm for queuing systems. And I'll say I'll prove. And I'll say I'll prove to you why max weight isn't optible, isn't going to have the usual behaviours that it has for these systems, and then I'll give you an example of a system that is going to deal with those issues. Because it's an AI hubbock opt to include reinforcement learning, I'll mention things about this, so I'll do that very briefly and explain how kind of Markov decision processes are going to be useful for these kinds of systems. And then I'll kind of, depending on how tired everyone looks, I'll kind of skip through section five and go to six. So we'll see how we get on, okay? We'll see how we get on, okay? Right, so what's the quantum link? So basically, you take two photons and you can run them really close together, okay? And then what happens is the two photons get a bit confused about which one's which, okay? And then you send one and sort of trap it where you are, and you send the other one off on some fiber optic cable, okay, and the other person receives that, okay? And then you can take a measurement of the polarity of that both photo. Both photons, and they should essentially give you the same result on both sides. And there are ways of doing this so that it ensures essentially secure communication. So you can randomly decide which basis to measure this polarity on. And then this is the basis of most quantum cryptography algorithms. So basically, you just set you kind of get these two confused photons and they get sent to either side here. The issue is that. The issue is that you're sending an individual proton and you can't individual that far. So we're looking at distances of like 50 kilometers, maybe 100 kilometers. We also have the issue that so usually what you do in a classical communication is you'd kind of you'd you'd get the signal, you do a little bit of error correction and then you kind of just ramp up boost it and s keep it going, okay? It and keep it going. You can't do that in a quantum system. Essentially, there's a result called the no-cloning theorem. You can't clone or boost or repeat a state. All you can do is you can measure and introduce correlations within the system. So if we want to have a kind of long-range QKD communication where we're using qubits the whole way along the communication, so keeping it secure, then what you can use is a quantum repeater. So, how does that work? Same idea. So, how does that work? Same idea. We have our repeater in the middle. The repeater sends a photon to the person you want to talk to, and it keeps its photon tracked. You take a photon and you send it over to the repeater, and then the repeater's got two photons, one that it sent and one that it received. It takes a measurement operation, which essentially creates an entanglement between these two guys, and then by doing that, these guys are now. And then by doing that, these guys are now connected to both sides. Okay? All right, so there's no boosting, you just repeat the signal, and then you do this measurement operation in the middle. Okay? Right, so that's the repeater. So it's just simply the way to kind of repeat things through the system. But you can actually imagine, you know, we could link repeaters together and they're going to make nice lines for us that we could then send over a long distance. Okay, but you could imagine the situation where we now want to create networks as well. Okay, so if we're going to have networks, these Okay, so if we're going to have networks, these repeaters are actually going to be switches, where we're going to have to decide which entanglements we're going to use with which routes within the network we're trying to communicate across. So how would a quantum router look? Something like this. So we've got two people over here, and then the switch has maybe got three photons it's going to send out to this side of the network. So it sends out a photon, it's now got A photon, it's now got two entangled photons set up. It does the same here, it does the same here. Okay, and then what can happen is maybe this user wants to talk, share a qubit for entangled state with this part of the network. So same thing as before, it sends its photon over, we do the measurement, that creates entanglements between here and here, and thus we've got entanglements all the way across the chain, and so we've completed the communication, okay? So we've completed the three patient. Now, let's suppose this person wants to happen here. The problem that can happen is that once we've sort of stored the photons within our sort of quantum memories, is they can decohere. Okay, so what can happen is essentially they kind of, these two photons come together, they get confused about which one's which, but over time they kind of go back to being two independent photons who don't, you don't. So that could happen here. So this So, these two entanglements will essentially break down, decohere, and so when this person sends his photon over it, there's no one on this side to furnish these. Okay? All right. Is that fairly clear at this point? Okay. All right. And so, to explain what this might look like is in a network scenario like this, the users are sending their protons to switches, and then the switches are then. And then the switches are then creating entanglements with other quantum E parts of the system, such as, say, a quantum computer here. And so we have something where we can have a single link, or we can have longer links going over several of these entitlements. And so what I'm going to be interested in is sort of thinking about how one of these quantum switches works, or indeed, a bit like with the data center, we could think of the whole network as being just one giant switch as well. Well. Okay, so this is sort of the rough setup. And this is just me repeating what I said earlier: that we can't boost signals, we can't amplify them, we just have to essentially use swapping operations throughout the system because of the way the sort of quantum mechanics works. So we just have to kind of repeat things within the system. Now I'm going to kind of show why this corresponds to like a Why this corresponds to a matching problem. So I'm very grateful to Shrookamp for including exactly my model in his talk. So we have something like this. Think of these as the memories where we're storing those entanglements. We call them link-level entanglements within our system. So just think of this as the storage of entanglements. And all that's happening is that users are coming in and they're making requests for sets of entanglements. For sets of entanglements. So, really, this user is requesting one entanglement from here, maybe the one that the user actually created themselves, and they might require this entanglement from over here, which is the one that the router made for them. And then all they're going to do is they will then use those two entanglements, will get measured and put together, and then they'll go away. And that request will go away. Does that make sense? Go away. Does that make sense? And due to the physical constraints of the routers themselves, they don't really have a very big memory. So we're kind of bounded on this side in terms of what the memory is. We have a process by which we create entanglements. So it could be like a Binary process or something like this. We have a process by which requests are made by the Lambda Sega here. So it's very much like we could model the whole of that system really. Like we could model the whole of that system really to two-sided matching queue. Okay? All right. So, yeah, so one way of thinking about it is this is just one switch within this system. Just clarification on the previous slide. So if you can... So each request need not be associated with just two links. It can be associated with more than two links. Yeah, correct. So you're trying to entangle all three. Yes, that's right. That can happen. So when it's two, it's called a bare. So, when it's two, it's called a Bell state. When it's three, I forget what it's like, G W something. There's a name for it when you entangle three things, and you can do any number if you see it to me. And then there are things where you can do sets of individual pairs of entanglements as well. So, we'll leave it general in terms of the model as to how many uh links you're going to use, because not necessarily just too many yeah. I have another question. So, can you control the rate for generating the entanglements? For generating the entanglements? Maybe those lambdas are up to lambda L1 L. I'm assuming that they're fixed. It's a good question. It could be, yeah, I mean, I don't see why it couldn't be a control parameter of the system, but for now, let's assume that they're not, that they're just fixed. And the decision we have is like, which of these are we going to match, and then let's take them out of the system. Actually, in terms of the theory, the model that we use for this part of the system can actually be quite arbitrary. I've written it this way for concreteness. The concreteness, but you could assume there's any finite state Markov chain going on over here. And it's actually not really a Markov chain, it's a Markov decision processor. So really what's happening here is we've got a Markov chain, but then the decisions we make in terms of schedules changes the state of the system as well as the diagonals. Okay? Okay. Um so yeah, so it could be an individual part of switch within the system. Switch within the system, but we could also think of the whole system as just being one giant switch as well. The kind of algorithms I'm going to discuss are quite centralized, so you might not want to do that in a distributed system, but nonetheless, perhaps that way. So by analogy, we could think of it like this, that these parts of the system are just simply taxis and cars coming in, and the right-hand side of the system are people making requests, and then we're sort of more in the, I guess, a sort of environment. More than that, I guess, a sort of environment I'm a bit more familiar with. Okay, so please insert your favourite large tech company here as well. So, okay, so now sort of stepping back from that model, I want to explain. So, I've explained to you, hopefully, okay-ish, what a quantum switch looks like. I'm going to step back, I'm going to talk about what the kind of classical internet router looks like. So, this is called a cross-barred Q-switch. Called a crossbar Q-switch. The idea is that we have n inputs here and n outputs here. And then within each input, we have a special queue devoted to each output. And then within these systems, you can serve one thing per unit time from each input. And you can only have one thing going out per unit time from each output. And so essentially, the sets of allocations we can. So essentially the sets of allocations we can do are bipartite matchings between the inputs and the outputs. So if we take this example, there are two matchings we could do between 1 and n. We could do 1 to 1 and n to n, or we could do this 1 to n and then this n to 1. So which do you guys think would be better than Do you guys think would be better that the parallel choice that I mentioned there, one to one and n to n, or the one that goes across from n one to n and n to one? Can you take this on? Sorry? Across. Across why? They seem like longer lines. See the longer lines. Okay, yeah. It's a good answer, but it's not the right answer. I like the texture. Any other texts? So I guess parallel, maybe? I'm suggesting. So why might that be? I'm suggesting so, so why might that be better? I mean, there's longer-ish queues, yeah. Yeah, exactly. So, yeah, the intuition is that there's basically longer queues from here to here, longer queues from here to here, plus more of the demand is being expressed for going parallel compared to going across. So we might as well serve the web demand where it wants to go. Okay? Um so um yeah, so uh that's just explained the model, um explain the matchings that I mentioned. Explain the matchings that I mentioned. So, typically, yeah, the way that the scheduling works within these systems is that it consists of a matching phase. So, we do might do what Zeeve mentioned, and we go with the parallel route. And then there's a switching phase where you actually physically take the packets or the jobs out and then look at my data go into the outputs, okay? And the matching phase is deterministic, and the switching phase is non-probabilistic, okay? Typically, okay? The other thing that I should mention is that the decisions that I do now do not affect my future decisions. So if I decide to make one decision, I do one from here and one from here, the next round, well, it's still just a cross-par Q-switch again. The set of service availabilities remain identical to what we had in the previous round. Okay? Um so a bit of history. Um So a bit of history. So it was found in the sort of late 90s that the sort of Cisco internet routers were running at about 58% of true capacity. Then in 99, Nick McEwen, Jean-Walran, and Benton Antarau wrote a paper that proposed this algorithm called max weight. And this achieves the maximum available throughput of the system, so it gets the most amount of packets pumped through this system that you can possibly get. It's pumped through this system that you can possibly get. And I'll maybe discuss briefly what that means. And then McEwen developed this into a practical variant called iSlip, which was commercially deployed in Cisco routers. So let's just quickly compare this with the quantum switch. So basically, take-home message from this slide is this max weight algorithm here. That's sort of the benchmark of what consists of good in. Of what consists of good in terms of classical routers. Let's just make a few comparisons between this and the quantum switch. So the user requests come from different entangled states. That's not too much of a difference. One thing that happens is that these LLEs, these entangled states, will decohere. After some amount of time they leave. Think of that as abandonment or renegade servers or whatever you like. Whatever you like. Swapping operations will fail. In fact, most of the time in practical systems, these measurement and swapping operations fail all the time. So you're spending all this time sending these entangled states all the time in advance of a request coming. And then the request comes, and then you can match, if you like. The important thing here is that the matching, or the dynamics of this part of the system, are not deterministic. They're now Markov. Deterministic, the now Markovian, and then the swapping phase is probabilistic. That's less important, but the fact that this part of the system is now evolving in a Markovian way is important. So it's not like previously the architecture of the crossbar was fixed at each round. Now it's not. It's like you've got servers and are they there or not? You don't know. The other thing that's most important is the decisions that I make currently affect the way this part of the system is distributed and the things that happen. Distributed in the future. So if I'm always taking this LLE out or this one, then it's going to affect many of the queues within the system. So we might want to be careful about making sure this part of the system stays well stocked with entanglements. So research questions. We want to ask kind of what max weight type system achieve maximum capacity for these quantum switches. Maximum capacity means the maximum set of arrival rates that I can support within the system. That I can support within the system. And the answer is: like, max weight's not going to work. We can come up with a counter example that proves that max weight isn't going to work for these types of systems. Can we find, nonetheless, can we find a throughput or close to throughput optimal schemes for these quantum switches? And the answer is yes. The point is that you need to use some NVPs, say RL, because it's an AI, because the AI people, but just NVP algorithms for solving these systems. Okay. All right. So this is the model. I think I've explained the model enough from the picture. I won't bore you with notation, because it's too late in the day and I'm too jet lagged. Some related work. Theru has some past work on this where you don't have these fusive entanglements on the left-hand side. So you can just apply normal max weight out to that. And then Theru, who's in the room, sorry, Sieba's in the room. Thiru is in talent. Sievers in the room. There was Tau Sievers. I'm sorry, I'm Siebra and Martin Serlia and Prekit came up with this nice way. They were looking at essentially a model quite similar to this, one I proposed here, using max waves and could prove it works for certain topologies, essentially. That's not a paper I like very much. Okay, so anyway, so what is this max weight policy? Essentially, it's the policy that does what It's the policy that does what Zeeve said. You try to make the maximum weighted matching based on the queue sizes of the requests. So you basically look at the queue size requests and then you make the matching between the right-hand side and the left-hand side that matches mices, the sum of the queue lengths amongst available set of schedules that you can do. It's easy to implement, it does not require knowledge of the arrival rates of the system, so those are two advantages. In fact, the arrival process can be chosen up for self. Driver process can be chosen adversarially, in fact. But the problem is, as great as max weight is in the classical switches, it doesn't work in this setting. So I'll give you a quick counter example that can be generalized. Imagine that we have sort of request queues here, three of them, and this request queue requires one orange entanglement. This blue queue requires one blue entanglement. Requires one blue entanglement, and this third hue requires one of each colour. And let's suppose at time one, an orange entanglement arrives, and it lasts three time steps for here. We've got a blue entanglement here, last one time step, and here. And then this green one comes along, it's just there for that, the third time step, and that only that. Okay? So if we did max weight on this system, and let's suppose all have three jobs in their request fees. All have three jobs in their request fees. So if we did max weight in this system, what would happen? Oh, yes, it just explained that's how long they last. What max weight would do is it would say, well, there's no available servers here. These haven't arrived yet. There's one orange drop, so I'm just going to match it. Okay? And that gets used up. Then next round, it turns up, and there's no orange one, there's no green one, there's just this blue one, so we'll just match that. Okay, it's the only available scheduling decision. Scheduling decision. And then it gets to round three and it sees there's no green, there's no orange entanglement, there's no blue entanglement, there's only a green one, so this guy can't use the service. What's happening here is no matter what I do, so long as there's work in this queue or this queue, this person's never going to get served. I just kept repeating this cycle. Okay? And one of the referees, when we submitted his paper, complained that this was. Reason when you submitted his paper, complained that this was all for deterministic things, it doesn't work probabilistically. And then I rolled up my sleeves over Christmas and proved that it indeed for the stochastic system, you can prove it doesn't work. I won't bore you with the proof, but basically, yeah, max weight starts out the final Q. The key insight is this because max weight is a planet head. Okay? All right. Um that and and it this is an example of a counter example from an earlier paper in two thousand six by Bono from Suvio. In 2006, by one of them studio. Yeah, so this is me rolling up my sleeves and proving the result, but this is, if you don't like proofs, you just like simulations, this is skyrocketing opposite infinity. And this is our policy, gracefully doing the right thing. So I explained where that good policy came from, and I'll do that by explaining actually the logic behind this max and weighted matching, max weight algorithm. The idea is this. The idea is this to use a Lyapunov function argument. So, in this case, we're going to have a Lyapunov function which is going to correspond to the sum of the squares of the request queues. And then remember that really, imagine I could differentiate everything and it wasn't discrete time, the change in the cues would just be derived as minus the departures. I could then look at the derivative of this Labanov function. The derivative of this Lyapunov function, okay? And I would just apply a chain rule. I just get the derivatives of these times the derivatives of these. What that would give me is the sum of the Q's times arrival rates minus the sum of the Q's times the departure rates. And so max weight says, I want to get the drift down as much as possible. So we're moving this Lyapunov function towards zero where the system's empty and in a nice state. Okay? So then what we Okay, so then what we do is we maximize this term. And that gives you the max weight algorithm. The problem is with this system is because when we serve the jobs, the queues are not refreshing and they're moving around. We've actually got this kind of Markov process that's running in the background in terms of the service of the system. So those LLE queues on the left-hand side, they're kind of moving around according to a Markov process. And so if I was to write down the correct differential. And so, if we have to write down the correct differential equation for this system, there should actually be an expectation in here. We're actually like missing an expectation that takes the average of the evolution of the left-hand side system. Okay? So, if I had to write down the correct differential equation for this system, my policy that I implement for matchings induces a stationary distribution on this side of the system. And then I want to maximize the Q's times the departure rate. The Q's times the departure rates over the stationary distributions of the left-hand side. Okay? Does that make sense? So the scheduling decision now is really we're choosing the stationary distribution of this guy in order to get the drift going down as much as possible for the Apple function. Okay? Alright? And so whenever I say I'm going to try and maximize the stationary distribution of some reward function, really what we're having here is a Markov decision program. We're having here is a Markov decision process. So when you say the stationary distribution on the left-hand side, it changes because of arrivals to the rate. So it's ignoring that part. No, it's including the arrivals. Just imagine just according to some process, just ignore the cues here. According to some process, I just ask for matchings from this side. This is just going to evolve as a Markov process. And the rule, and the process that I decide to make these matches might depend on the state of the site. Maybe these matches might depend on the state of the side of the system. So just think of that as state. Actions are the matching decisions that we make. The only thing that's a bit weird about this MVP is each request queue is getting a reward process from this MVP over here. Okay? So it's like a MDP but with a vector reward. Okay? Yeah? Sir, is there a policy showing up in two places here? Showing up in two places here, like, because previously it was like in both the end superpi and the steady-state distribution, are policies affecting both of these things? Is that so? In principle, let's suppose these Q's are really big. Yeah. So, like, any decision that I make here doesn't make a big difference over here, but it does make a big difference to this side of the system. So, when I'm really writing down that differential equation, I'm taking this Boolean limit where I'm assuming the right-hand side of the system is big. Yeah? Okay? So, yeah, to get the best negative drift I can out of the system, I need to solve this maximization problem. So, and like I say, we're really solving Maximus Trikant's top again, a bit more seriously this time. Yeah, basically, this is actually the kind of average Reward-Markov decision process that Trikant was writing down earlier, and the Bellman equation for that, which Trikant wrote down earlier. The only difference was Trikant. The only difference was Trick Ad wasn't looking for temporal difference learning, so it didn't have this maximization. So, in principle, we can solve that. It's a well-known problem, so then, and that's essentially what a policy is. It just says, you know, solve the, look at the queue sizes, solve the MVP, implement that for a while. As long as your left-hand side process has enough time to mix, because markup changes are going to mix. As long as it has enough time to mix, then it will. Mix, then it will stabilize the system. And it does that in a way where you're only observing the right-hand side cues of the system. You don't need to know the arrival rates of the right-hand side of the system. So just like max weight, you could have adversarial injection of the requests as well if you wanted. Okay, another thing that's weird about this system, so like even this result is very difficult because when I say about Because, like, when I say about it maximizing throughput, it's not even actually very clear what that even means for this system. So, typically, for the previous example, for that input cube switch, it just corresponds to the set of bipartite matchings that you can support. So, just a convex combination of the sets of bipartite matchings. In this case, it's not clear, but now we've got this kind of MDP intuition, we can kind of work it out. But basically, it's like an MDP where the policy induces a Where the policy induces a reward sequence on all of the requests, and thus those are the sets of arrival rates on the request views that can be supported by this kind of vector NUP. So that's basically what this is saying, is saying that an arrival rate lambda belongs to the stability region of our system, is something that's in a capacity region, if we can come up with MPP that's bigger than it for all of the requests. Okay. Okay. Is that okay-ish? And that's a necessary and sufficient condition. So I was surprised we could even prove this to start with. So once we've got this, I was pretty happy. And then informally, can you find an MDP whose stationary vector rewards exceeds the arrival rate vector? Okay, and then we prove a theorem that says it's asymptotically optimal, that we can get as close as you like to the capacity region of that stability region. And I promise you I'd skip this part, so skip, skip, skip, skip. So, skip, skip, skip, skip, skip. Conclusions. So, yeah, so for this max weight scheme, we showed that there's a limitation of these quantum switches, that we propose an optimal scheduling scheme for them. I think this connection with MDPs is just of interest, well, not necessarily of interest, but I think it's interesting outside of quantum motivation. So, you could, we'll have a kind of problem session. We'll have a kind of problem session, so I'll discuss some potential extensions of this. So, like, we could think of the Q exercise one being a dual problem, and then the primal problem is where you try to maximize utilities. We can talk about that. And it also has some implications on the way that quantum switches might be designed, as in, like, if you can understand the LLE process by which the switch generates and creates an individual's LLEs, then it basically says that you need to solve a a reinforcement learning problem for that switch in order to get the the best throughput out of it. The best throughput out of it. So you can't rely on straight sort of matching, smart matching policies. That's pretty much the end of the talk. But I just want to say, although there's not that much quantum mechanics in the talk today, I do think there's a whole host of interesting problems that come up that are basically matching problems because there's entanglement sharing issues that come up in this space, not necessarily write-sharing, but online adverts and things like this. So it's quite fun space to think about. Okay, thanks. What makes the left-hand side more like a Markov decision process than in the classical case? Is it a bounded buffer size or? In the classical case, all the output ports are available from the input ports at every bound. So they just don't change, essentially, the architecture of the system. But it's more like Can you expand the number of queues and uh Cues and which arrivals which subset? I don't think so, because it really is genuinely the decision I make now. I mean, okay, you could say, like, I'll make the optimal decision over time horizon of t, and then consider that as a static problem and solve that, but then you'd just be solving the MDP over a final time horizon will be my answer to that uh that that that observation. So uh so so I I still think there's still some value in that kind of MDP implementation. Okay. This is the question about the skip slide. I saw something, something Foster Leopard. What fancy Foster Leopardum thing do you need? I think you could just use the standard kind of Foster Leopard. Oh, it's okay, exactly. There's nothing massively special about it. Getting the fluid limit is tougher because essentially you're proving a time-scale separation argument. So, at a technical level, if you kind of want to gape out on that, then it's sort of. out on that then then it's sort of you need to prove that the left hand side of the system is moving faster than the right hand side of the system and thus and you also need to take care of some of those dynamics there's technical trickery that's needed there that's that's fun uh but I don't think after you've done all that trickery it's standard rinse and repeat kind of diehara you know doing die scale food analysis and the time scale separation is why you end up with like both the sort of steady state distribution but then also something that depends Distribution, but then also something that depends on like this individual decision. Yeah, exactly, that's correct. And that's important because that decouples the left-hand side from the right-hand side. So I don't need to know things about the arrival rates on the right-hand side of the system. I just need to know about the dynamics of the left-hand side of the system. Just curious, I don't know hardly anything about quantum, but the left-hand side then, the assumption here is it's kind of an exogenous process that is creating new things, new resources. New resources. It's creating new. I mean, just think of it like ride share. Like, you've got cars that come in and then they go offline when they get served, and then maybe they come back later. You know, it's just a markoff process. Just a markup process where the decisions you make in terms of scheduling affect the future. Right. I guess my question is, is that reflect the physics of the system? So, is that actually how the process is it really like a kind of a memoryless thing where the revivals are like that? I think they have okay, so like. I think they okay, so like getting to the physics of it all, they basically have the photons get sent into a crystal and then the crystal goes into like an energy state where basically you know the electrons are on shells and they end up between two shells, so they store it that way and there's a physical number of these that they will store within the router within the repeater. But it's still kind of very emerging feel, so I don't think they're like designing and maybe. Designing and making quantum switches, yeah, repeaters and things like this. And the next obvious step is that when they're going to start to make networks of these things. At the moment, what happens is they have these trusted nodes, so they just basically say, we're going to do QKD, QKD here, and then we're going to have this node that we make highly secure as much as we possibly can, and then use that for doing all the switching stuff. But that's not as secure, obviously, as doing end-to-end entanglement through the whole system. So that's a little bit more of the answers around the kind of physics of it. The kind of physics of it, if you see what I mean. But in terms of the model, I mean, just think of it like a rideshare system, other cars come and go. I'm just trying to like talk to, so we talked to some companies, we talked to some businesses, we talked to some people that have a quantum network in Bristol University, and we're kind of chatting with them about how their system works. So they just kind of tell us stuff, and then I'm kind of like, let's try and make a model out of this thing, make it something that we can, or at least I can understand. We can, or at least I can understand. Yeah. Okay. Thank you for the speaker again.