Thank you. And I'm really sorry that it was impossible to be present in person during this week. I know we're a little bit all fed up with the Zoom talk. So I'll try to make it as light as I can. So I want to talk about some new ways to seeing the New ways to think the mean field limit. And mean field limit, so it means mini-particle multi-agent system. You guys are already very familiar with this. There's a huge list of things that these kind of models can be applied to. But where I specifically want to try to focus today is on neuroscience. Neuroscience, and in particular, on trying to understand the behavior of networks of biological neurons. And, you know, that's a little bit away from the classical physics problem. So that's sort of the other extremum in a sense, right? So, which is to say, well, let's look at plasma, right? So, and let's try to derive something like the plasma plasma. To derive something like the Lazarus Poisson-Pocker-Planck equations, which were the first mean field limit ever written. And I actually come back to that in the proof because there are ideas in the proof that also applies to breast money and they're a little bit easier to explain. And since, again, I want to keep the talk away from being too technical, already will be enough, as you will see. So I'll actually come back and focus on class. Actually, come back and focus on plasma toward the end. But that's right, more what I'm interested in during this talk. So this is a piece of the rat's brain. And what you see are the cytoskeleton of each neuron. And it's a relatively nice picture. So you see the center of each neuron, and then you see the axons and the dendrites that connect them. And the dendrites that connect them all together. And a very important recurring feature that will play a big role in the difficulty of the analysis for us here, right, is you see that there is a lot of connections per neuron, a lot of axons, a lot of dendrites, but obviously not every neuron is connected with every other. So you have a very complex. So, you have a very complex structure that exists in the brain that says this neuron is talking to that neuron and not to this other. And this is something that we'll put in the model. And again, that will be the source, a major source of difficulties. And just to give you a final idea in this very broad introduction as to where we are in terms of the numbers, right? Of the numbers, right? The numbers of agents, so the number of neurons. And human brain, you know, it's around 100 billion. 86 billion is supposed to be the more accurate number. So it's large without being outrageously large, right? We are not definitely not at the 10 to the 20, 10 to the 25 ions that you may find in a typical plant. That you may find in a typical plasma. But on the other hand, much, much higher on other multi-agent systems that you can find in economics, where the number of agencies is more in the thousands. So that's a little bit on the intermediary scale in terms of number. All right, and now let me jump right in and let me write the model that I'm going to be studying. The model that I'm going to be studying. And I should start by saying that there is actually a long history of trying to model the behavior of neurons, with the first attempt being at the beginning of the 20th century by Lepique. And there is now, as you can imagine, a huge literature. So I will only focus on one particular type of model, and I'll explain a little bit why this is considered. This is considered a reasonable model for the kind of large-scale behavior with a lot of neurons that I'm interested in. And this behavior is sometimes called a spike dynamics or an integrated fire type of dynamics. And it has a very simple logic, which is to say that most of the time we are going to track the potential of the membrane of the neuron. Of the membrane of the neuron. And I'm going to call that D. And most of the time, this will follow a very simple ODE or SD, so you can add a small running motion to it if you want. So the membrane potential will grow slowly, typically, with a little bit of noise if you add it. And then from time to time, the neuron will spike. Spike. And when the neuron spikes, then you reset the membrane potential to a certain rest potential. For simplicity here, I will just assume that it's zero. The actual, you know, if you measure it in the brain, it's not actually zero. It's a slightly negative number. We can just, again, add the same number to everyone so that we are zero. And then you're in stop again. Then you're installed again. So the last thing to determine in this very simplified model of just one neuron is how do you decide whether the neuron is going to spike at a certain time or not. And here I'm going to take a probabilistic model. So I'm just going to assume that a neuron has a certain probability of spiking at every time, right? And that probability. At every time, right? And that probability depends on its membrane potential. So you have a certain function of u is typically increasing. So the higher the membrane potential, the more likely the neuron is to spike. And this is it. And you have tons of variants around this model. The spike can actually be deterministic when you reach a certain potential, then you automatically spike. Then you automatically spike, for example. You can complicate a little bit v the ODE or SDE that is sold in between spikes. There are a lot of possibilities. And some of these variants, the same approach that I'm going to tell you here will work identically, and others would require a few extra steps. So this is something that I'm going to remain a little bit vague because I don't want to do a catalog here. Here. But of course, right, we do present some constraints on the analysis sometimes. Okay, so that's one neuron. And one neuron is not what we are interested in. It's very difficult, by the way, to actually model even the behavior of one neuron. But I want to put tons of them together. So the question now is: we are going to have a large number of neurons, and they are going to be somehow coupled. Coupled, and we want to understand how we can couple, you know, several of those dynamics. And in this model of integrated fire, there is a relatively simple thing, which is to say that the neurons are decoupled until one of them fires. So let's say that one neuron fire, and let's say that we call it neuron number I. Call it neuron number i. When neuron number i fires, then its membrane potential goes back to zero, but it is going to change the membrane potential of all neurons that it is connected with. So for all neurons J that are connected to I, the membrane potential VJ is going to change by a certain number. And that number is not identical and depends on the strength. Not identical and depends on the strength of the connection between neuron I and neuron J. So to keep again things as simple as we can at you know through this type of system I'm simply going to enter in the matrix all the strength of connection and I'm going to use them when calculating the jump that all the have and you know Have and you know in they are connected to fires. So we're going to call this matrix double. And to keep things consistent with the rest, that means that when neural I fires, then neural j that is connected to i has a jump that is proportional to w j i. And I'm going to call in general those w coefficients. W coefficients, the synaptic connections. And they are a little bit complicated because they are supposed to represent the super complex structure that we had seen from the original picture. So trying to say who's connected to whom. So just a few remarks, mostly to tell you what they don't do. So, first of all, there is no sign here because Because you can have positive or negative connection in the sense that two neurons can be one neuron can excite the other or it can inhibit the other. So the Wij could be positive or negative. There is no particular reason why there should be following any sort of rule. And I'll come back to that because that's very, very important. So, in that sense, the WIJ could be different. The WIJ could be different, completely different for every pair of neurons. And, you know, I'm not a neuroscientist, of course. To me, it makes sense that if you're going to build something as complicated as the brain and you wanted to solve very complex tasks, then you would try to have as complex an organization as you can have, because that's how you're going to make the most of each neuron. You're going to make the most of each neuron. So, in particular, something that I absolutely do not want to do during this talk is assume that, for example, the Wij are given by a certain random process, right? So I don't want to assume that W is a random matrix, for example. Someone will give me the W, and it's going to be whatever it is. And it's going to be whatever it is, and I want to make as little assumptions as I can, and in particular, I don't want to make any structural assumptions on what the W is going to be. And one last comment here, this is still a very simplified model because, in particular, the Wij are fixed in time, right? I'm not going to let them vary, which means that in that model, you are not learning anything. That model, you are not learning anything, right? You're set. The brain would react in the same way all the time. So, of course, you will need to have some learning to get to a more realistic type of model. But as you can see here, the combination of those two, right, puts you a very, very different case from the classical many particle system that you can get from physics. That you can get from physics. And it's much closer, in fact, to, I think there will be other talks around that, where you have a multi-agent system and they are not identical and they try to have different interactions depending on the agent. And this is a little bit bad in this more or less extreme situation, where again, I'm not going to. Where again, I'm not going to put any rule on the connections. So, this is a very, very quick summary of the modeling. So, this is sort of my disclaimer slide saying, you know, there's, of course, a lot more to it than what I described in 10 minutes, because each neuron is already an extremely complicated. An extremely complicated cell that has very complicated response. But interestingly, there's a point that I want to make here, which is sometimes apparently making a more complex model for each neuron does not lead to more accurate results when you're considering networks. So I'm sure you've heard of Ochkinoxley type of model. Heard of Ochkinaxlay type of models, right? Where you sort of have a set of ODEs on each neuron, which are supposed to model much more accurately the evolution of a membrane potential in terms of all the unit channels and all of this. And we can couple these systems, but they seem not to perform as well as taking a simple integrated fire, as I've just described, at the scale of a network of neurons. Network of neuron. And one neuroscientist says because spikes are not as well defined in that kind of model, and so the interaction between neurons is not as well captured. And a last point that I want to make here, and which is really fascinating if one hopes to go further. We have made so much progress in medical imaging that we now have enormous full picture of what this matrix WRJ looks like, at least where WRJ are different from zero on some simple animals. And so this is called the connector, right? And for example, just a year and a half ago, we had the connector. A half ago, we had the connector from a fruit fly, but the whole grain of the fruit fly was obtained exactly by medical imaging. So there is a point where you might think it's not so much science fiction to actually try to solve a model like that on some exact picture of the brain, at least again for very simple animals. Now, let's discuss a little bit more precisely the scaling in that business because I want to do method limits, so I want to look at large scale. So, I have to understand a little bit what are the large numbers, what are the smaller numbers, and distinguish them in all of this. So, as I said, the number of neurons is relatively large, 100 billion, again, around that for humans. Of course, you might not want to solve the whole grain, so you might have much smaller numbers, right? Fluff fly is several hundred thousand euros only. What's interesting, however, is to look at the average number of connections per neuron, right? So the average number of other neurons that a given neuron is connected to. And that's around 7,000. Which is both large and small, because if you're thinking, you know, that means that's a lot of dendrites, right? 7,000. On the other hand, you know, if you compare the two numbers here, 7,000 and 100 billion, right, there's a clear discrepancy between them. And so that means that when I'm looking at this matrix of connections, this Wij, it's something. This WIJ is something extremely sparse. So, where do we fit in the mean field limit here? Well, we find ourselves in a very interesting position, mathematically speaking. We do have a very large number of agents. So, it completely makes sense to try to look at macroscopic behavior. Each agent actually interacts with a fairly large, less large, but still fairly large number of other agents, right? So if I'm trying to say that the total sum of interaction has to be of other one, then I can expect that the maximum number of each of the volunteers is going to be small. So it wouldn't make sense that there are large numbers. That there are large numbers that stop coming into play at this scale. But we're also in an extreme situation where we are very, very far away from a plasma where each ion interacts with all the other ions, right? Because again, this is extremely sparse. All right. So the idea. So, the idea of deriving an inference limit in that context is actually also very old. And again, the point that you will not be able to follow each neuron individually when you want to have a microscopic behavior, you know, people have seen the usefulness of that long ago. But the derivation itself has basically failed to fit. As basically failed to fit with what I described of the model as it is, and in particular, with what I described of the scaling. So there is a very popular field which is called neural field models that started developing in the late 60s, early 70s, and that is trying to derive continuous limits for networks of neurons. And people still use them from time to time, so they remain popular. They still suffered from some big criticism at the same time. The main one being that to make this derivation, you basically have to assume that the WIJ, the synaptic connection, basically depends smoothly on the relative spatial location of the neurons in the Of the neurons in the brain. And that doesn't seem to be the case, right? So you can have two neurons that are very, very close and who have completely different set of connections. So in that sense, as of today, the question, even in the simplified model that I was just described, the question of whether you can find a continuum limit that Can find a continuum limit that will fit the scaling that we impose is absolutely unclear. All right. And now, before giving you a bit of the new ideas that we brought here to approach the problem, I just want to mention the connection with. To mention the connection with you know the classical mean field limit so that at least we can see the equations, right? So, this is a very simple basic multi-agent system where each agent is identical. I've also taken a much smoother dynamic, so K here is as smooth as you want it to be, right? And a little bit of noise and you see the very difference between the two, right? Between the two, right? Where here, each agent I, I'm summing over all the other j, and I'm averaging over all the other j, and this is it. And so again, it seems that this is a very different type of system. I will actually use this to give you a bit of an idea of what some of the proof looks like because it's a lot simpler, so I can show you. A lot simpler, so I can show you more precisely what the new techniques are doing. And again, in that case, the mutual scaling just means that I'm putting a one-over and in front of everything so that everyone is the same. And I'm going to put things on the taurus. But in that case, contrary to the neuron dynamics. That case, contrary to the neuron dynamics, right? If you want to use this for something like plasmas or something else, right, then k has to be singular. And that's a source of difficulty. I'm not going to say much more about that. That's really not the point. But of course, it's a very big question, which is to still do the mean field limit in that case, where one key is not Lipschitz, but is more singular. And again, everything on the torus. And in that framework, let me recall again briefly that the notion of new field limit now is relatively well understood. And what we are doing is we are replacing this discrete system by a partial differential equation on the one particle distribution, which I'm going to call f. So f of t and x is the probability of finding any particle at time t with constitution x. And so, in this system, I wrote before, we have a very simple equation, which is the following non-linear induction diffusion equation, where of course you keep the diffusion and you have the mean field interaction through the convolution between K and S in the second equation. And this is a system that can be derived. Be derived from again the discrete ODE by doing what is called a Muthiel approximation, which means that we are replacing this discrete sum in the ODE by its expectation. And once you've done that, once you've removed part of the noise, it's a conditional expectation because, of course, you see that xi figures in every term of the sum. So you don't want to take the expectation. Sum, so you don't want to take the expectation with respect to xi, you want to take the expectation with respect to all the others. Um, then we have the key. And this is true, of course, this looks like a low of large number, discrete sum replaced by its expectation. So you would expect it to be true if you have vanishing correlations between the particles. And this is what we call chaos, right? And the whole game in this. And the whole game in this standard classical model is to show propagation of tails. Now, I'm going to come back to my integrated fire system. And of course, let me stick 10 more seconds on that slide. The first issue is there is no clear notion of chaos, right? Because chaos means that particles are almost dielectric. This means that particles are almost IID. Well, maybe they are, maybe neurons are almost independent, but certainly they are not identical, right? Because each one is different. So what is the new idea what where do we go if we want to try to derive a mean field limit for the super complicated system? For the super complicated system with the WIG. And there are two big points here. The first one is a new definition of the right objects that we should be looking at. And that's what I'm going to describe here. And then the second point is a new approach, a new technical approach to propagate adequate quantity on a hierarchy. And that's going to be the next section. So, the first question, again, when I'm facing this system of integrated fire on neurons, is because they are all different, it's not even really clear what I should look at. So, I want to take a statistical point of view, right? Because that makes sense. We don't want to try to follow individual trajectories, we believe that. We know that every individual trajectory is going to be completely different, so not even clear if this would be doable. So, I want to be again in the statistical direction. Okay, statistics, the tool we have, right, is the joint law of everyone. Okay, so that's what gives you the whole statistics. So, I'm going to call that object Fn. Object Fn and Fl is going to be the probability density of everybody, right? Of V1, Vn, all the membrane potential. So that one contains all the statistical information on the system, right? Not all the information. This is important to notice because I'm moving correlation in time. I cannot reconstruct trajectories from Fn. I can only. From Fn. I can only reconstruct probability distributions. But right, that's a crazy object, as we all know. Even with 100 billion neurons, I don't want to try to study a function of 100 billion variables, right? That's basically a non-starter here. Okay, so then there are the marginals, right? And the marginal instead of And the marginal, instead of taking the joint load of everyone, I can pick up a subsystem and I can consider the marginal of that subsystem. Yeah, but they are not identical, right? So if you want to deal with marginals, you have to identify clearly each neuron that you're looking at. Right. So, in that case, if I'm looking at the marginal of small n neurons, I have to tell you, well, I'm looking at the marginal of neuron I1, I2, IN. And then that's the joint law of the subsystem. That's also something that I can obtain from the full joint law, of course, by integrating the extra variables. Obviously, this is a mess, right? Obviously, each one of those is a huge mess because, okay, so that means that if I'm looking at even one neuron, I have capital N different functions, right? If I'm looking at the two marginals, so marginals for two neurons, then I have n n minus one. And I have n minus 1 over 2 different functions, and so on, right? So this is not going anywhere at the level of the marginals either, obviously. There are too many, and we are potentially all different. So here is the big idea. We are not going to look at the marginals. Not going to look at the marginals, we're going to look at a linear combination of the marginals. Okay, so I'm going to choose a certain order, and then I'm going to take all the marginals at that order, and then I'm going to do a linear combination of them. Why not? Why not? And I'm going to call that an observable. Code add an observable. Okay? But here's the trick, right? If I just take any linear combination of the marginals, I won't get anything. This will work only if the object that I defined by this linear combination satisfies some sort of reasonable equation. So. So I'm averaging the marginals, okay? So which weights do I take to average them? Do I just average them all the same or do I try to distinguish saying, well, that marginal is actually a little bit more likely to show up than another? And that's the difficulty. And that's where this formula starts becoming absolutely critical. Critical and absolutely non-trivial. And you see that this product here, right, that's the weight. That's what tells me how much I'm going to take into account the corresponding marginals. And how am I building this? Well, now I'm not only going to consider the marginals in a certain order, but I'm going to consider That I'm going to consider a sub-tree of interactions. So, what does that mean, a sub-tree of interactions? I'm going to put at the root of the first neuron. So, neuron I1 is going to be at the root. And then I'm going to say that neuron I1 is influenced by the neurons that are at the next level. And then I'll do it on my bus. Okay? So that gives me a tree. So that gives me a tree. Which tree is the right one? None of them, right? I'll have to consider all possible trays in that business. There's no particular reason that one scheme of interaction will happen more often than another. But okay, so I will choose a tree that will give me a scheme of interaction and then Well, I have limits on that tree, right? Because between two neurons in the tree, well, now I know what they are, and they are supposed to be interacting with each other, so they are supposed to be interacting with the corresponding W ij. And now I'm just going to multiply all those weights together, and I'm going to average the result. And that gives me an object. And at this point, you know, the normal reaction is to think: okay, this is completely crazy. Completely fair enough, right? The whole point, right? The magic in this new idea is that those objects which are going to call are observables. This are going to satisfy a very natural set of equations. Now, before I'm showing you this equation, let me backtrack a little bit and let's go back to the identical agents, right? So, in the identical agents, everything is so much simpler because now I have only one marginal of the certain. Of the starting order K, right? And of course, you see here that if all the PIJ are equal and all equal to one over L, then here I have a very basic average of that is the same marginals. And so all my observables are actually equal to this, right? And these marginals are nested in a hierarchy in the sense that Hierarchy in the sense that I can get a marginal of lower order by integrating the marginal of one higher order. Just nice. And we have a famous PBGKY hierarchy that connects the dynamics of all these objects all together. So I can write down now, I went back to my tar model with my interactions for the kernel K. And then I have this BDGKY hierarchy, which tells me. The GKY hierarchy, which tells me that the time derivative of Fk is going to follow certain dynamics, but to know the dynamics that is being followed, I need to know Fk plus 1. I'm going to go back to this hierarchy because, of course, it's still a major pain in the neck to work with this hierarchy of equation because of that connection, right? Because of the fact that new equations. Because of the fact that no equation is actually closed, except the last one when k is equal to n. Because if you want to do anything with that, then you're stuck relatively fast. But that's for the next section. Until then, at least we have that, right? So again, in the identical case, I have the marginals, they make sense. It's the rule of the reduced system. And then they follow this sort of nice hierarchy. Let's go back to the non-identical case. So now I have defined my observable like that. And it also solves a sort of hierarchy. And that's how you know that I was not completely crazy and that I chose the right observables. Now it's sort of different, it's a little bit different. It's a sort of different, it's a little bit different again because we have integrated fire, so there are jumps, right? But you recognize some of the terms, right? You recognize the diffusion here as expected. This is the adduction coming from solving DODE, right? Neuron of V is the likelihood of jumping. So this tells you that one of the neurons is going to be jumping, right? Jumping, right? And this is a little bit of a more complicated term, but when you jump, your potential is reset at zero, and this is what this is doing. And then as before, those equations are not closed. They are here totally not closed, but the first point is, of course, you cannot solve an equation by knowing just a given observable. You need to A given observable, you need to know observables at the next order. In the identical case, right, you had this very nice nesting of the marginals with k leading to k plus 1. Here we had to use trees, and the nesting is a little bit more complicated. So, from a certain tree, capital T, now you go to a tree, capital T plus N. And that tree capital T plus N, you obtain it. This is just a notation, of course, you obtain it by taking the tree T and adding a leaf and the vertex number N of the original tree. So you add a new tree with one more leaf. And of course, you have a certain number of vertices. I'm denoting the absolute value of t is the total number. Absolute value of t is the total number of vertices in the tree. And we can add the leaf at every vertex, right? Including the root. So instead of having a nice linear nesting, right, now it bipurates. Which is also why you end up adding trees, because even if you start with a trigger tree with just one root, then with that With just one root, then with that argument, you built the whole lot of them. So you really cannot stay away from looking at all the possible trees here. There's another issue, which is this extract here and boost remainders. Again, we have a jump process here, and at the level of the jump process, At the level of the jump process, you cannot have an exact equation for that. So, you actually will have turns that are vanishing, that are vanishing in the total number of agents, but they are rare. And that's the second reason this is not a closed equation, because those terms actually do not depend only on the observables I've chosen, but depend on the whole set of marginals. So, when you are doing the actual analysis, which is what we've done, so when you're going to pass to the limit in an equation like this, you'll have to show that this is going to zero, that those are vanishing. And that's difficult. But so far, we found a new statistical object, right, which is this crazy family of observables indexed by trees. They have a crazy definition as well. Crazy definition as well. But when we put everything all together, it seems that we are finding an equivalent of a BBGKY hierarchy for this system. And what's the big point here? If you neglect those remainders, right, the synaptic weights never show up. The diffusion is there. The diffusion is there, sigma, right? The adaption, the POV is there. The probability of spiking is there, the function neural, right? Here, here, here, but that's it. You do not see a Wij at any point in this hierarchy. They are only hidden in the vanishing terms, but they don't show up here. So, what that means for the analysis is Analysis is: I don't need to know what the WIJ are to work on this system. I only need to know what my initial observables are. Because of course, WIG are there in the definition of the observables. That's the reason this is working. But I have a countable family of observables, so I can use it. So, I can use the diamond process. I can pass the limit into them, right? As n tends to infinity, no problem. And then they solve this nested system of equation. And there's no double UIJ. So at no point in this process will I have to actually take a limit on the double UIJ or assume anything against about them. Diurnal extraction is. Director extraction is going to take care of the whole thing, which is really miraculous if you think about it. Okay, so what do we need to do to get a proof out of this? We have to draw direct estimates on the observables, right? So I have to show that the vanishing terms are vanishing. I have to be able to pass to the limit in this system of equations. Pass to the limit in this system of equations. So I have to have a stability sort of uniqueness principle on this hierarchy. And of course, the boundaries, again, the equations aren't opposed. So I have to find a way to get uniqueness, to get stability, right, even more than uniqueness. So a uniqueness argument that will still perform under perturbation. Will still perform an DRP attribution for a connected IRP like that. And that's quite technical, unfortunately. And it requires the use of very precise weak norms and stuff like that, because whose remainders are only vanishing in appropriate weak norms. So this is very complicated, and I'm not going to talk about that. So for the next section, I'm instead going to go back to Plasmas, right? To Pasmas, right, or things like that. So, to completely exchangeable system with identical agents. And I'm going to tell you why there is a hope to actually get stability on this kind of hierarchy. So, I'm going to go back to my classical DVGKY and I'm going to show you some estimates on that DBGKY. Okay, so I just wrote it, and again, the issue is. Wrote it. And again, the issue is the equation on SK depends on SK plus 1. So let's say I want to propagate an LP bound, okay? So I want to say that if Sk was small, this is a linear system, right? So stability just means that you have to show if you're close to zero initially, you remain close to zero for all time. So, okay, I'm going to provide another PBA. And I'm going to propagate another P bar on Fk, right? And you see that this first advection term is probably going to be okay, at least if the divergence of K is fine. Diffusion, of course, is going to be all good. But then the adversance term, right? That is implying Fk plus one, and we are losing one derivative. So if I'm not really paying attention and I just want to propagate an L T bound on Fk, well, that requires. Well, that requires a sub of F bound on Fk plus 1, right? I need to control the L D bound of the gradient x of Fk plus 1. And then this propagates, right? So every time you're going to go to the next equation, you'll have to pay with an extra derivative. And you end up with some analytical space, something crazy. And that was the And that was the status of this, right? But then, what we realize is this is crazy. Because in that case, I have diffusion, right? Diffusion makes me gain one derivative if I'm propagating an L T bound. I can use diffusion to avoid losing the derivative here. So, this is extremely clumsy in a system where we have diffusion. System when I have diffusion. If I do a minimum amount of integration by parts, providing VRP bound on FK only requires VRP bound on Fk plus 1. I'm not losing any derivatives. And that's exactly what you can do. So in a case like that, let me call XK the LQ norm of FK, right? And let me assume that K is divergence. Assume that that case divergence-free for simplicity, then I actually have a system of OD that I can write like this on each L2 norm. So it's a hierarchy OD, and what's remarkable is this you can solve and this you solve and And this you saw, and if initially the ODE behaves, the initial conditions behave well, and functions of k variables. So what does that mean? Well, that means their norm has to be some constant to the power k, right? If you have that initially, you're going to propagate what you want through this hierarchy. Okay, so. Okay, so let me write down a theorem to fix things here. And this is simple enough. So I'm going to look at my multi-agent system. And the only thing I'm going to assume is that A is in some LT. I'm not going to assume the chips, I'm not going to assume there is a T string, nothing like that. Now I need a bit more than L1, okay? L1 will not work. Anything better than L1. Will not work. Anything better than L1 will work. And I need some assumption on the divergence of K, which can be relaxed, but let me not go there. And now I have a mean field limit. In that case, if the initial marginals converge weakly to a tensorized marginal for each fixed k. Marginal for each fix k and they have a right bound, so they are bounded like something to the power k. Then that means for a time of order one, I have an info limit. And this is a theorem that we can actually prove in a couple of pages using no more than integration by parts. So it's very, very new. And it's also completely new, which is very interesting that sometimes. Very interesting. That sometimes you miss the absolute obvious. Well, that's what's going on on the crazy hierarchy, right? So that's the kind of things that we're doing here. We're using the diffusion to compensate the derivative that is being lost here. And we get to a good system of. And we get to a good system of ODE, and we have stability, and we have uniqueness. The whole difficulty again is I've showed you the calculations in the LT norm, which is super obvious, and here we have to do it in an appropriate weak norm. So you have tons of commutator terms that becomes very painful. So I'm not going to try to write down a very precise. Try to write down a very precise CRM in integrate and fire because that would take me three slides with the exact technical assumptions, and I don't want to do that. But I want to show you the limit and the main assumptions. So, what do we assume on the weights? I have to replace the classical mean field scaling by something, and that something is I'm just assuming that, you know. Assuming that you know, um, if I'm summing, uh, so I'm taking a row and I'm summing the weights of a row, right? And that's sort of the total influence that a neuron number i feels from all the neurons in the system. And I'm assuming that this is a harder one. And for technical reason, I also have to assume the converse, so I also have to be able to sum up the columns. And I have no. And I have no idea if the second term here is really optimal or not. Okay. And the second point is: I have to make sure that I have a low-large number. So I have to make sure that the maximum influence is decreasing to zero as n tends to infinity. So that you don't have a total neurons that are mostly only connected to each other and only talk to each other without talking to the rest, for example. And then I have a mean field limit on a certain density. But there is a trace on this mean field limit of the synaptic weight. And this trace is represented by a certain kernel. And so to see that, I cannot just look at the one particle distribution, x is. The one particle distribution f of t and d, I have to add an extra variable that will sort of represent the diversity among neurons. So I'm globing a sort of artificially extended density, F T V and psi, let's call the extravariable xi, right? And then this solves an And then this solves an equation, and again, I'm not going to spend too much time. The equation here is pretty much what you would expect after the Newfield limit of a jump process. So, of course, you still see the diffusion, you see minus the probability of jumping, you see the advection by Vini, we see here the reset, right? So, you're putting back all the neurons with membrane potential zero, and then you have this jump term, which is Jump term, which is represented by this S, right? And that's what comes out of all the jumps. And this S involves this limiting synaptic kernel W. And to give you a little bit of the idea of how painful some of the proof can be, the synaptic kernel is in this weird space. In this weird space, so it's L infinity in one variable with value measure in another variable. That's a space that fits with this scaling, by the way. You can see that this is a sort of LNC in TL1 norm. But so in particular, it's not even clear that the last equation, the third equation here makes sense easily, because the extended density actually is not continuous. In ψ, it's at best. not continuous in ψ, it's at best L infinity. So I'm integrating an L infinity function against a measure. There are issues there. But again, I'm not going to explain how to resolve them. I'm just going to say we can resolve them. And so we can rigorously derive this equation. But I just don't want to put the names here and here without. The names here and here without having the necessary technical explanations. And this is a little bit what we have, but you know, so at the level of the observables, it's a little bit nicer to express. So I can build a limiting observable from this limiting f. This leading f, right? And then I can write a clear theorem here, which is to say that the observables for a fixed end converge to the limiting observables. And by the way, the observables contain the one-particle distribution, so you have angers this here and the convergence of the one-particle distribution. And this is it. And this is it. So I think it's a fascinating subject. It's obviously only the beginning. The combination of the new observables with the new technical approach on the hierarchy is really critical and I think super important. And actually, also one goes to the origin as a person software to using a variant of the same ID. So I think it's a very promising way of seeing things. But there are so many questions that remain open. And I'll just mention one, which is, again, I've assumed that the synaptic weights were frozen in time. And of course, they should evolve because neuron systems are built to learn. And it's absolutely not clear how you would incorporate that. How you would incorporate that in this kind of analysis. I'll stop here. Thank you very much. So I was wondering on what time scale does your propagation of chaos result hold? So for this view, I'm it's It's a mean time scale of order one. So it's not uniform in time, but you get a mean time scale. At this level, it's a time scale T star. T star is of order one, so it doesn't depend on n, but it does depend on the various norms of the interaction kernel. And we are pushing this, so this should be extended. But as such, when But as such, when you solve this hierarchy of equation, it does blow up in time of other one. And so, does this theory, as a side sort of effect of this result, do you actually have a lot of oppositeness of your infill model? No. Not here, which is interesting. interesting. Not only do we not have the repositeness, but this is typing which shows, you know, it shows what is going on in this non-identical case. We don't even know the uniqueness of the limit as I formulated it here. I can cook up examples where I have different S and different limiting kernel W that both represent the limit. And that's because I have limitedness on the limiting hierarchy of observables, right? But of course, there's a missing piece here, which is how do I connect this equation to the limiting hierarchy? And it's not a bijection. Each solution here will give you a solution to the hierarchy, but you could have two different solutions. But you could have two different solutions that give you the same solution to the hierarchy. So it's a weird repository, if you want, right? The only thing I can say is if you take two solutions to this system of equations and they are identical at time zero, then they give the same observables. But I cannot say that they remain identical. And some, you know, this classical loss of limits, right, you do get the end from initial condition by empirical approximation. But here it seems to be more likely. Yeah, yeah. So that's, of course, they are the same, right? If the particles are identical, then the hierarchy is the same as the. Same as the mean field limit. So right positions on the hierarchy will give you the right positions on the mean field limit. But here, because the system is not identical, you break that. Any other questions? Okay, so let's thank the speaker again. Thank you. Thank you very much. So I'm going to stop the recording. 