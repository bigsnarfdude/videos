So, yeah, first of all, thanks to the organizers. I'm very happy to be here, Oaxaca. It's very close to home. I don't have to take two more flights, but okay, that's life. So today I'm going to talk about work that I did in collaboration with Pierre Van Ho, who is also at PHD in Sacle. So, and the work is about how to And the work is about how to construct differential equations of the Picker-Fuchs type in general dimensions. And the idea was actually to extend the usual Griffiths D work approach for the case of twisted differential forms. So let me start by saying more or less what's going to talk about. So in the first part, I'm going to give a brief motivation and just And just introduce very briefly the usual Griffiths D work approach. In the second part, I'm going to show how to extend it to general dimensions. And then I'm going to show applications and finally conclude. So let's start. So, okay. Finite integrals, they are very nice, mathematical structures, but they are useful. So we need them in collider physics to calculate To calculate cross-sections, so which we can then compare against experiment. And recently, we have been using them also to, you know, also help people who observe gravitational waves and for theoretical predictions in that area as well. So, but how finite integrals appear into the story, right? So, they appear basically by this basic equation. By this basic equation, which tells us that an amplitude is a linear combination of something which is the Feynman integral, which is precisely here, which is called basis, and some coefficient that depends on kinematics and other ingredients that appear in our observability, right? So, and that is from rational terms. So, this basic. So this basic fact tells us that one of the things, so this thing is relatively easy to get, but this one is not easy. So we need to evaluate them, right? So for that, we need differential equations. So there are several types of differential equations we can set to these integrals. So the typical example is this one. So the differential equation in terms of the masters. So this vector here means masters. Right, so we can put them in the epsilon form, and then if we manage to do that, we are happy because then we can, you know, turn our machines and then just evaluate them. There are also picker foods types, which are relevant for the talks that we have seen today, and we will see as well. And there are also other more exotic type of differential equations that we can set. Okay. So, uh, but okay, for this uh workshop, we also have another motivation which is math, right? Another motivation which is math, right? So, so mathematically, final integrals are these polynomial functions. So, this implies many interesting things about them, like they can tell us that the number of matter intros are finite, among other things. And the algebraic geometry of them are just interesting on their own, right? So, mathematicians have worked on them. There are many that have contributed to the field. Have contributed to the field, and I put them here that someone only, okay, they just do their work, and then just we discover that, wow, this is just relevant for what we were just doing, right? So, for this workshop, then we are gonna talk about the speakerfoot separate, because they give us hints of what is the geometry of the finite integral, what's behind this. And here I'm putting algebraic. And here I'm putting algebraic geometry, right? So, examples in which these geometries that are beyond elliptics appear are these bananas and multi-scoop diagrams, which all of them are edible. And Sarah is going to tell us about other examples. Good. So, let us start by saying what are finite integrals. So, final integrals are projective integrals whose integrals whose integration region is this one, it's essentially the positive ortan. And there is a differential form associated to this integral, which is given by this form. Here u and f are the so-called semantic polynomials, which I will define in the next slide. And there is another differential that appears typically, which is this canonical differential space in projective space. In projective space. So, this differential form is defined in this cohomology, which was proposed by these authors and then by Brown, later by Brown. Very good. So, the Siemensi polynomial. So, the first one is a Siemensi polynomial which depends on spanning trees, which means that if I have a graph, I cut it a certain number of times. In this case, I cut it just. times in this case i cut it just the number of loop that of loops that the graph has and this is what defines the first semantic polynomial so the degree of this polynomial is the number of loops there's a second semantic polynomial which is defined by instead of cutting l times the the loop you could you could the maximum amount of times that you can have so that so that you generate separate trees right so this is what are called spanning Right, so this is what are called spanning two forests and from this some from the graphs you can you can just construct the the the differential form and the find an integer so this polynomial is also a homogeneous polynomial who has degree loops L plus one the number loops plus one very good so now we want to construct the differential equation for that integral so Integral. So, what do we do? So, the solution, if I want to construct the differential equation of the Picker-Fuchs type, was given by Griffiths and DeWork. And first, let us consider the happy case in which the integral is finite and the form is rational, which means that I'm going to take, I'm going to fix the dimension to a certain value, certain integer values. So, this is a rational. integer value, so this is a rational differential form. Okay. So in this case, now suppose that I'm interested then in acting on the differential equations with respect to a some parameter, which I'm going to choose to be t, which is some invariant that appears in my second Timancy polynomial. Okay. So, and I'm going to act on my differential form, actually not yet integral, in my differential form, I'm going to act A times. Going to act eight times. Okay. So I'm going to act eight times on my form, and what I'm going to get is some expression, some inhomogeneous term because I acted on this rational form. But what I'm interested in is operator in which the coefficients that are acting on my integral only depend on the physical information of the integral, which means that the masses, the kinematics, Which means that the masses, the kinematics, the kinematic factors, and so on. So, as I said, if the dimension is an integer, so we will have a rational differential form. Let me for the moment just focus on the case in which I take just one kinematic invariant. And if I act on my differential form here, what is going to happen is that when I take derivatives, the poll order. Take derivatives, the pole order of this polynomial is gonna go up. Okay, so I need, I don't need this, okay? I don't want this. So the solution to reduce the pole order that appears because I acted on my rational form was precisely given by Griffiths and DeWork. This is what is called the Griffiths-DeWork vault reduction. So, our remark is that you can also find this speaker for IBP. So, you just go to Operator from IBP. So you just go through all your IBP procedure machinery, your LIDRAD, your ERA, and so on. And you can also find this operator the same way, right? This is time consuming, especially if you have many master integrals. So, well, let's not do that. And for that, instead of explaining this general Greek work, let's focus on this example that we all love. So the fancy. That's it. Moreover, I'm going to focus on the case of the equal mass, right? So, in this case, the differential form is this one. So, because I set the dimension to equal to two, in this case, the polynomial, so the u polynomial here in kill the power is just zero. So, then the rational form only depends on f. Well, it depends on u implicitly. You implicitly in this expression for f. So now suppose that I act twice. So don't ask me why I'm acting twice at the moment. Okay. Let's say I act twice on the rational form. So what happens is then I increase the pole order here. And then, in fact, what I have done is just, well, I have some numerator and then I have this power two, which I need to be one. Okay, so what do I do? So, first, also another happy assumption. Suppose that this polynomial in the numerator is what is called in the Jacobian ideolog. What does it mean? It means that there is a way of expressing the polynomial in the numerator in this way. So, expressed in terms of some polynomials, certain degrees, and times the derivatives of this, of the Of this of the f polynomial with respect to each of the variables. So, this is a suppose that this can be done. Okay, so let's also count our degrees. So, in this case, so the degree of this polynomial is six. The degree of f is just the, so loops plus one. Sorry, yeah, loops plus one, so it's three. The degree of these things is just the degree of p minus the degree of f plus one, which is four. The degree of f plus one, which is four, right? So we're all happy here. So the idea of Griffiths is that I can reduce the pole order by adding form. And that the form is defined in general in this way. So I add this form to the region thing that I have. And when I do that, then by subtraction, what I get is precisely some term that depends on the. Depends on the pole, but just reduced by one. So that's the idea of Griffiths. So, in other words, what I can do then is just to, after I combine this term and this term, just express this derivative, second derivative of the form in this way, in terms of something that has the pole reduced, plus something else, right? Yep? So I know where the C's came from, where did the G's come from, G2s? G's come from? G2s? How do you know what those are? Well, this is, let's say, this is a definition at the moment. I defined the beta in this way. In terms of these polynomials. G is defined in terms of exactly in this case. Yeah, this is that I use to reduce my polynomial, right? Very good. So I do that, and then I have reduced the pole order by one, and then I. Pole order by one, and then I can iterate this procedure to then now in the case in which I act once, then I also reduce the pole and I get this operator which will depend only on the kinematic parameters. So that's the idea. And at each step, of course, I'm going to have this form, and I'm going to do exactly the same game, iterative. So that's the idea. And this is nice. This is the idea of briefs. This is nice, this idea of brief dwork. And so let's ask what can go wrong. So, what can go wrong is, of course, that the original algorithm assumes that the algebraic variety is smooth. And what I just told you, like that the polynomial lives in this Jacobian ideal, right? So, this is in general, it doesn't have to be, so it cannot live in the general Jacobian ideal. So, in that case, Deal. So, in that case, what I have to do is then express p in a normal form, which is called the normal form. I can use, for example, group rebases. And in this case, then I'm going to express this polynomial in this form, where R is some reminder. And then at each step in my reduction, what I can do is then recursively, for each of the derivatives, I can recursively apply the Griffith-Zigwork reduction, whole reduction, and then I'm going to have And then I'm going to have at the end an algorithm that gives me this deconstruction in general. So that's what you have to do in the case of when the algebraic variety is not smooth. Sorry, in the case of where the variety is smooth. But also it can happen that the variety is not smooth. So in this case, you have to do something else. And you have to also include some freedom given by these. Given by this CCGS. So, if you're not familiar with CCGs, CCGs tell you that if you have a set of polynomials, then I can find some polynomials which, when I multiply to them, then the result is zero. This is a CCG. Okay? So, in general, in fact, to do this decomposition, what I have to do is actually consider higher order CCGs, even higher order relations between my polynomials. Yes, yes, yeah. Other thing that can go wrong is that this form might have faults that are not present in the rational form. This also can happen. So, so far, we are going to consider cases in which this doesn't happen. So, let's see how it's So let's see how it's done in the general case. So in the general case, now I'm going to consider not the rational form. So my epsilon is now explicit. My finite integral is not zero, right? And I'm going to be, because I can, I can also consider analytic regularization, which means that I can also put the powers of my propagators to be shifted to the integers, right? So what happens if I do that? So if my propagators also are shifted. my propagators also are shifted what i have is that the uh that the that the form has two contributions one that is telling me that i'm doing dimensional regularization and the other that that my the powers of my propagators are also shifted a bit from integers right so the reasons why this can be interesting and this is interesting is because this type of integrals appear in context of correlators which i will not touch here today Here today, so we are going to focus on dimensional regularization, which means that these kappas are just zero, right? So, in that case, then I have this form, and notice its properties. So, there is the part, there is a part which is also rational form, and there is this part which is essentially the twist, the twists that were mentioned yesterday. And an important property of this. and an important property of this of this twist is that the um is that it is homogeneous of degree zero right so you can see that uh because the power of this so the the the degree of f is l plus one sorry while the degree of u is l so this thing is going to be homogeneous of degree zero right so very good Moreover, I'm going to consider now the general case in which I'm not acting on my form with a single parameter. So I'm going to act with all parameters, or in principle, all that can appear in the second semester polynomial. So this gives rise to some expression. So what we are seeking then is some form, right? Sorry, some operators that when they act on this form, then And this form, then they have they produce some henomogeneous term in general, right? And we want this to be independent of this of the variables. So they just most depend only on the kinematics and will depend now also on the regulator in general. So now, how do I get the differential equation for the finite integral? Well, I can just integrate because the domain of Because the domain of integration does not depend on the kinematical parameters, on the kinematic parameters, right? So, what I get then is that in general, so I'm going to have the same operator, the operator that I just constructed, acting on the integral and producing some homogeneous term, which you should integrate, right? So we should also integrate this to get this homogeneous term. So there is a case in which So there is a case in which you don't, the problem simplifies, and it is what you consider the maximum cut. In that case, we know what the cycle is. And in this case, this integration, essentially the right-hand side vanishes. Oops. So this right-hand side. So you get this point. And this is the differential equation for the maximum outcome. Very good. So then. Very good. So then let's see. How do we extend this reduction to the case in which you also have regulators explicitly? So what we would like is to preserve the main features of the Griffiths debork reduction. So now the derivative will also hit the twist, right? Producing some polynomial that depends also on the also on the will also depend generally on the on the regulator right but it's the same i'm going to act eight times so this a volt which i have some reason got lost well so the so a bolt here represents the sum of all a's that i am acting so i'm taking derivatives then So I'm taking derivatives then with each of the kinematic parameters A times, A1 times. This is the index of the number of times that I act with this respect to the kinematic invariant. So it will produce a homogeneous polynomial which has this degree, right, in X. And as always, so the pole order in the second semantic polynomial has increased by some number A, right? By some number a, right, which is what we want to reduce. And we are seeking the coefficient that depends on the kinematics, the C that is below or above. Good. So now we're also going to let us focus on the case in which the powers of my proparators are just one. So in this case, this new parameter is just n. This new parameter is just n. And I'm gonna define some quantities for later purposes. Very good, which are these lambdas, okay? Which depend on the regularity. Very good. So we are gonna do the same. So we are gonna try to reduce the polynomial in this Jacobian idea. However, in this case, because we have a regulator, we can't really apply. We can't really apply the same techniques that we applied for the Griffin's de work reduction. In this case, in this sense, we will abandon algebraic geometry and think of this problem just using linear algebra. Think about this reduction using linear algebra, right? So the motivation to do stuff is not just out of the hat, is that we can because this is something that you can also do in the rational non-smooth case when there is no twist. twist okay so in a sense this is a leap of faith that this uh this is this can be done okay very good um so now i'm gonna consider then this vector here c which is gonna be also a homogeneous polynomial so in fact this is gonna be a collection of homogeneous polynomials right because this is a that there are many polynomials in the Polynomials in the product above, right? And I'm gonna consider them. I'm gonna write them writing them in these terms, right? So for me, this is some polynomial which has n variables and which has this degree, right? So C is a collection of this polynomial. So, and C are the coefficients, the coefficients of this polynomial. So, here I'm using. The coefficients of this polynomial. So, here I'm using the multi-index notation. So, E here is a vector which tells me what are the powers of my variable. And I consider them as unknowns. Okay. So, what I'm saying here, this is the poor man's way of computing CCGs. So, here, of course, I'm considering also that there might be CCGs that I need in general. And in order to generalize the Griffiths-DeWork, then we set. The Griffiths de work, then we set the form to have the form below, right? In terms of these G new polynomials, which depend now on the form that is now twisted. So doing so, we can let's see what happens. So, first of all, like this differential form, well. Well it's in the bob. So this is the new expression for d vita. And now when I act on my rational and on my differential form, what happens now is that there are two things. So the first thing you will recognize because this is what happened precisely in the Griffiths deep work reduction. The second term highlighted in red now it's produced because of having Now it's produced because of have a twist. The derivative is also acting with twist. So now we actually need to do a second reduction, a second reduction with respect to the Jacobian ideal of f. So the first reduction, in a sense, was just to reduce the polynomial to this Jacobian ideal of f. But because of the twist, when I act with these operators, what is going to happen is that there's going to be a new term. Is that there's going to be a new term? So, what I do then to continue the poly reduction is just essentially do a second reduction with respect to this polynomial. So, again, I'm going to express also these, these are polynomials that I don't know, which are written in terms of some other polynomials. So, this, in fact, is a reduction which is equivalent to a CCG. Which is equivalent to a CCG, and this is precisely what you will find you will understand, you understand as a CCG precisely. Some polynomials which I multiply with these generators of the ideal, which gives me precisely zero, right? So the reduction will have now two contributions. One contribution due to the reduction of F. Reduction of F and the other due to reduction of U. So, this is the new thing that happens because of the twist. And you can continue the same procedure many times. So, the algorithm then proceeds as follows. In a single step of the reduction, what you need to compute is precisely this object M. To do that, you have two systems of equations. Two systems of equations. One which tells you how to reduce your polynomial p, and the other, the second one, that tells you how to reduce the expression, which is the term with the term highlighted in red. Okay? So these are the two reductions that you need. So this is the rank of the system. So in general, it's going to be big if you increase the number of variables. Big if you increase the number of variables. In fact, this is a dense system. And but fortunately, we can actually use, because this is linear algebra, we can use techniques of finite fields. In particular, we have used the common dense solve of finite flow to automate this computation of the equation. So using this technique, it's relatively fast. Okay, no, no, no, for any we've tried any number of legs. There is no there is no nothing that prevents you to go to many legs. Well, we have tested higher loops. I mean, for examples that are, let's say, easy, like the sunset. The sunset with equal masses, we have tested 20 loops. So it actually, it's fast. So are the coefficients you get in this procedure generally rational functions of the kinematics or can they be outspread? No, I rational. Rational. Yeah. Yeah, it can appear in the denominator as well. We will see actually what happens in that case. So, yeah. So let me just remark, well actually I have remarked twice, but let's remark it the third time that this way of solving the linear system implicitly includes this freedom of the CCGs that mentioned that you had in the rationale. You had in the rational. Very good. So, once you know how to do the reduction, you can just automate it and essentially do the iteratively this. So, at each step, you set some starting order of the differential equation. So, I'm going to say in a bit how you set this starting order, right? So, as you know, actually, what bounds is this starting order is the number of master integrals or the Euler characteristics. Of master integrals, or the Euler characteristic of the algebraic variety associated with the final integral. So, you set the starting order. This starting order in general depends on whether you are using which regularization you are using. So, this is the meaning of putting here explicitly the epsilon and kappa. And of course, depends on the graph, right? So, this is the first red. So this is this is the first reduction. So you iterate the reduction until you get oops good so then this is the this is the first term you continue this reduction a second time what you get is then this term which then you do to which you need to reduce a second time and so on. So this the And so on. So, the system of equations will then determine at the end of the algorithm the coefficients that appear in this function. And basically, one iterates the procedure until the polynomial has this power, right? In general, you will have to apply it many times. Apply it many times. So the last step in the reduction is just when this function is of degree zero. And in this case, you simply can read off the coefficients that appear in the reduction. And of course, there is an inhomogeneous term that depends on the things that you were solving. So it depends on the solutions of your equations. So this is something that appears in this site. So, and you also have this term, right? So at the end of the day, what you get for the differential equation is you get for the differential equation is just an expression in which you already fit you you already find all these coefficients and some inhomogeneous term right and as i said the upper bound it's just the number of master intervals you can actually start with that order right you can compute it in other way like as i said one good way is use the order characteristic you can also think about the Think about the rank of the GK state system and so on. So, there are other alternative ways of setting this starting order. Yes. If you start with that degree, which is very conservative, then the system is not going to close. So, the variables, you will. The variables, you will not be able to solve for all the coefficients. That's what is going to happen, right? So, it's not going to be closed, that sense, right? So, this is similar to an approach that was done by Müller-Stach, Vancouver, and Tayede. Also, increasing the order until the system has a solution, right? But more importantly, so you But more importantly, so you can actually determine also this order numerically because you can set your epsilon and all your parameters to some values and use finite flow or whatever you prefer and just precisely run your solution of the system and just set this order to that precisely. And then, if you are interested, you can actually compute the analytic values of the coefficients. This is one. This is one. This is what you can do. In general, as we know, so in this case, there's no exception, the Griffiths Dwork does not give any reducible operator, so it can be factorizable, and you can also use your tools of Maple to factorize the operator, right? Good. So let's see some applications. So, for example, for the equal mass answer. For example, for the equal mass answer that we just discussed before. Good. So in this case, we know that we set this number to be two in this case. So we act twice on the rational form. We obtain this numerator, as I said, now depends explicitly on epsilon. And there is this form which is twisted. And there is this form which is twisted. So we reduce now the polynomial in this way. So these lambdas are precisely the coefficients of my polynomials, which are unknowns. I reduce a second time with respect to the Jacobian of u, right? And I obtain my m, which is just the derivative of these coefficients and this c2, right? So c2 is still a non-homogeneous polynomial, degree three, right? Very good. So then I achieved the So then I achieved the reduction of the pole, right? Of the first reduction of the pole. Then I now I'm interested in the second. Since I started at order two, then I need to reduce the order one. And in this case, then I'm going to have another term, which is here. It's m1 because it's what I obtain when I act once to the derivative once of this form. So then this information. So then this, in fact, this M1 is what I obtained in the previous step plus the new polynomial that I get because I acted once. So you do the reduction a second time, the direction of this M1. Now, again, with respect to this Jacobian ideal, again, these C's are unknown. You can do the procedure, find the solutions, and then you have reduced the pole again, right? Again, right? Good. So the last step is just the constant term. In this case, in principle, you can also have to do, you should also have to do a reduction, but in this case, reduction is just trivial. It just has to be one over F in this case. So they're just proportional. The last reduction is trivial. And then you obtain the operator that acts on the intro with an explicit dependence on epsilon. Dependence on epsilon. Good. So now there is something else, right? So because we are interested in the full integral, there is also the henomogeneous term. So this term, its integration, might be complicated. So we are not saying that this is that there is still work to do, of course. You have to solve for the henomeneous term. And this might be complicated. Let me just mention that one trick to actually solve the integral that Actually, solve the integral that appears in the henomogeneous term is to actually keep the coefficients, the unknowns, unset until the very end. This is one trick that you can use to evaluate the integral. Because we have epsilon explicit, we can actually work, apply this approach for integrals where you don't have in principle a graphics d work approach because the integral is divergent. Is divergent, right? In this case, we have also applied this procedure explicitly for this non-planar double box, and we have found this operator, right? Explicitly dependent on epsilon. And of course, we have worked out the suns and integral at higher loops with especially with equal masses, but we have also considered the case. But we have also considered the case when the masses are not equal. So, in the case of the transit integral, we have this form, we have this form which has this twist, and these are the Siemensi polynomial. So, what our findings in this case, in this case, what we found is that for this integral, so the number of reducible Number of reducible master intervals is this one. So, this is the same order that we found. So, we started with this order and we found that the system closes. We've also computed the minimal differential operator for the all equal mass onset. So, what we found is in the generic mass configuration, we found that the operator is of order one at one loop, at two loops is order four, and at two loops has order 11. And that we look has order 11. Of course, when epsilon is zero, what can happen is that the order of the minimal differential operator can be less than the number of master integrals. This is something that also has been observed. And in fact, so there is this result that tells you what is the order of the curve-fuss operator for generic mass. Generic mass. Good. So let me also mention that what is interesting is that the part that does not depend on epsilon is the part that still factorizes. So this is what we have observed in the examples. So all the results you can find them and this GitHub page. GitHub page. Good. So let me just then conclude. So what we have done then is extend the Griffiths D work approach to derive the differential equation of the Picard-Fuchs type in general dimensions. This algorithm works well for the non-smooth case, which is the general case for finite integrals. Case for finite integrals. The algorithm is easy to implement, I mean, it's very easy to implement, and also handles divergent integrals, and it becomes a linear algebra problem, which is easier, of course. And for that, we have used the finite flow, but you can use your favorite tool to solve essentially a large system of equations. So, what we would like to do. What we would like to do now is that because we have an operator that depends explicitly on epsilon, so why don't we evaluate the integral directly now that we need actually something, some function from it? And so what we are thinking is precisely use Fravenius method for that purpose. And so this brings me to convolution. I think I finished early or no, but thanks. Before I open up for questions, I have to ask what the quote at the bottom means. It means many things is with the Batsikop Colabal. All right, any questions? Included the previous slide. Yep. Yeah, just the first line. The number of irreducible masses integrals, you mean for this graphics we work? Because no, no, no. I mean, this is the I'm just quoting what is the number of. So if I do two loop sunrise, so it's two to the power three, eight minus four to four. Yeah, yeah. But the mass continuous irreducible in this. By irreducible, I mean that, yeah, of course, the order of the degree. order of the the the degree the order of the differential equation is of course the um the the number that you're saying right but the griffin like the operator factorizes so what we call the irreducible is precisely the part that is non-factorizable that's the irreducible or maybe i don't understand what this means no the irreducible means the the as i said Reducible means the, as I said, the order of the operator, right, which gives you the number of master integrals, but you also have the part that is non-factorizable. As far as I remember, this is the number that is correct. Yeah. So this is what we are interested in. Of course, for us, is the interesting part. There was another question? Yes. Yes. Can you comment on the relation of your work to the one by Clemen collaborators? I think that the factorizing is the same picker books operator for nanos. Sure, but they used the fixed D. And for sure they didn't have the notion of the twisted differential form. I think they use epsilon equals zero. But maybe correct me. Maybe correct me if I'm wrong. The other question is: can you go to negative dimensions? To what? Negative dimensions. Negative dimensions. You mean, like, okay, let's see. Well, there's this version of Timrick called negative dimensional Timrek. So for us, the dimension is this number, this D here. So do you want delta to be negative or? Yeah, but this is an idea to go to negative dimensions where the integrals are very simple and then analytically continuing, which is typically. Yes. Yes, yeah, but I know that there is a push to the continuum. Yeah, I know that the negative dimensional approach, but uh, how is how is this related to that? Well, in your machinery in parameter space, you principle can take it to put a negative domain. I see. Uh, I don't know first, I don't know. I don't know. We can slide there. Other questions from the audience? I have one final question, which is, are you planning to apply this to then something like the double box? Or we applied it already to those boxes. Yeah, we applied it already. Okay, we applied to. I'm showing the non-planner because it's. Apply to know, I'm showing the non-planner because this is a bit harder than the gasless case. There's a madness case, so we are planning to apply. I mean, in principle, it's just that the well, we can do it. Let's relate it. You're not worried about the indifferent scale. No, because what we so what increases the difficulty of the problem is not the number of scales, but rather Not the number of scales, but rather the number of edges. Yeah, this is what the, because if you have more edges, then you exactly. Yeah, yeah. That's what is more concerning than scales. Yeah. Well, with that, let's thank Leonardo again.