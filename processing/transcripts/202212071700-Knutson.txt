And it's all pretty much as I wanted to pick it. All right, so we were closing last slide with some recipes that go between some G spaces, and I'll say what space means in various different categories of space. Space and G spaces. And where here T is a maximal or as G, these guys are taking out some complexity groups, so I have multiplices in G L and C. So a very basic one is what if I have some here at P lambda, then I want that under this correspondence to correspond to just the one-dimensional space. The one-dimensional space, which is the highest weight space. So this lambda here is a dominance weight. And here I just have a one-dimensional space on which T is acting with that weight. So what's good in our recipe for vector spaces in general? Well, I could say every vector space has a balance of feeds. So inside those vector spaces, pin balance the highest weights. Out to the highest weight spaces. I don't really want to take a vector space, decompose it into irreducibles, do this recipe, sum them back together, because that sounds like a major choice. And there isn't actually a choice. So a way to phrase this is you take your representation to the invariance. People kind of take that to the unitary group. So here n is something like this group inside geons. And there isn't quite a map the other direction, not as obviously. If I have a one-dimensional T representation, then it might not be the highest weight space of any representation at all, because it might not be a dominant weight. So the way I'm going to write down a map the other direction, and I wrote it down last time, so I'm just going to write it down again since the cat's out of the bag, is That's out of the back, is I will take vector space here. Probably no one's going to confuse this with while group. And I'm going to take this guy, I'm going to tensor it with the functions on g mod n. So I tensor those together. Now, what are these things so far? This is the t space. G mod n has a g action on the left, and it has a t action on the right, because T action on the right because this subgroup is normalized by T. So I've got G acting here, T acting there, and I've got T acting here. Take that thing and take the T invariance with respect to some diagonal embedding, maybe not quite the standard diagonal embedding, but I have to do a choice of YW dots into here. So to figure out why these would be in any sense These would be in any sense inverse operations. They're not quite, but to what extent are they inverse operations? Let's think about first what functions on G itself looks like. So G here is this complexly group, like G L and C. So when I'm talking about functions, I'm thinking about algebraic functions. And if I were thinking about like L2 functions on the compact group, L2 functions on the compact group, then I would get some Hilbert space direct sum. But since I'm talking about algebraic functions, I'm just going to get some algebraic direct sum. And this is an isomorphism as G cross G representations from GFRS reaction. What does a G cross G representation look like? What does an ear act look like? It's an ear out of this. And it's there an ear at the back. Of actual. And if every year up exactly once, tensor with its dual. So this is the algebraic version of your bottle. So that's functions on g itself. Now, a function on g mod n is the same as a fun. Well, if I take a function on g mod n and I pull it back to g, then it'll be a function on g that's invariant under the right action n. So functions on. So functions on g mod n, that's functions on g invariant under the right action of n. So that's going to be, in this direct sum, I'll have these, and each of those, I will pick out the n invariant vector. So this would sum over down against lambda. It's going to be lambda. Tensor C minus W naught lambda. lambda is the highest weight in the dual representation of lambda. So if you say looks one-dimensional, whatever, forget it, then you see you're getting every ERF exactly once. But I in fact want to think of this not just with the G action, but with the T action also. So this is as a G cross T space. Okay, so what's this recipe then going to do if I start going to do if I start with like C lambda. Or maybe a C mu is better. So I take C mu, I tensor this thing, I tensor this thing with C mu, and then I ask, so here I'm getting something one-dimensional, it's got weight c sub mu minus w0 lambda, and when I take the t invariance, I'm asking that mu minus w naught lambda should be equal to zero. Lambda shouldn't be equal to zero. If for the invariance at all. And if the view is, then I'll pop out this v lambda. So I want this w dot in there in order to get that to work out right. With that, a weight here will come here, it'll match up with one of these, maybe, and if it does match up with one of these, then we'll get the corresponding hereafter. At first, what could go wrong? At first, what could go wrong is you might start with a C mu on the side where mu isn't dominant. And then when you do this, you get zero. So that's the failure of this. Okay, so let me say if you compose this, then that's the identity on vector spaces. So if you start with our G representations, right? If I start with G. Our G representations. If I start with a G representation and I do this and then I do that, I'll get my G representation back. If I start with a G representation and I do that and I do that, then somehow I'm losing all the non-dominant traits. Okay, now comes the extra. Now comes the extra thing. So this is so far a story about vector spaces. So we're going to draw a line and say everything here is about vector spaces. But fun thing, if w is a ring, well, functions on g mod n is also a ring. It's a subring of functions on g. So then the tensor product is a ring. And the invariance in it is a ring. And so this recipe as written, well, both Be as written. And also, the n invariance in a ring is a ring. So I can think of this as going from G rings back and forth to T rings. And then this composite is not the identity on rings. It doesn't take a G ring back to the same G ring. It's going to take this ring to its degeneration that I talked about last time. So we have lost any of that. Basically the issue is that this direct sub over lambda is not a ring direct sub. It's only a vector space direct sub. And it's the same issue. You multiply things in v mu, by things in vu, then you'll end up in b mu plus nu possibly minus some of the positive roots, not just in mu plus nu. So this guy also has an interpretation, and it's called Symplectic Cutting. So even the algebraists call it symplectic cutting. Well, I guess there is this paper by Graham and Edit Dean where they give us another name. Does it call it algebraic cuts or something? But anyway, I mostly, it was thought of first in some plastic. It was thought of first in the synthetic world, and it was then really obvious as Geelins for the algebraic one and most cuts along the positive line chamber. So usually you simply like to cut along just one wall at a time and along a bunch of walls. I don't want to define this because other stuff I want to talk about, like the Lauvier, Roseberry, Kerschel, Pasquier, Parmeshoire. Plus Pierre Parbuchar generation. So, one more thing I want to say on the well, okay. So, yeah, so principal player in this story is this guy with functions on g mod n. And so we get this space called g mod.n, which is defined as spec of the functions. Of the functions on G mod n? And why do we need two different things? Well, g mod n is a nice, complex manifold. It's a homogeneous space. When you take the functions on it, and then you take the spec, there's no guarantee you get the same set. And in fact, you rarely do. So if G is a trivial group, you do. But if G is, for example, SL2C, you don't. So what this thing looks like, SL2C model. Like SL2C modulo 1 star 01, that's C2 minus the origin. SL2 acts on C2. It has a dense orbit. The stabilizer is a standard vector meeting this. So this is what that open orbit looks like. Take functions on here and say what's the spec of that. What is the functions on here? It's just polynomials and two variables. Any function on here uniquely extends over the origin. Over the origin. So gbod.n will actually put in more stuff. If you're used to doing GIT quotients and having to throw things away, that's because you're used to doing GIT quotients by reductive groups. And this guy had violates most of the things you read in books about GIT. In particular, it's not, you shouldn't in general expect dividing by n to get you something new here. So why is this? Why is this ring that I've written down right here? Why is this ring an Ethereum ring? And we have this picture of g mod mod m as a subscheme of a vector space and therefore the next Ethereum thing. So I'm going to get a hold of it by, I'll take the direct sum over the over omega, the fundamental weights. of the fundamental representations. Inside there, I'm going to have the highest weight vectors for each of those, and I'll take the direct sum of those. So I end up with one vector inside this big vector space. If you think about the stabilizer of one of those vectors, well, you should first think about the Well, you should first think about the projective stabilizer for some of those vectors. Think about the g orbit through the projective point that that vector is defining, and what you'll get will be a g mod p for some minimal p. Sorry, Alan. There's no rescaling of that. I haven't finished writing this thing down. I will say. I just didn't do so much without speaking. Ask me when I finish writing the line down. So if you consider the stabilizer of this as a vector, not just as a projective vector, it gives me one-dimension smaller. And so what you end up getting, so if I just intersected the stabilizers, let's think inside the GLN case, if I intersected those stabilizers, so what those stabilizers look like, projective stabilizers in the GLN case, the projective stabilizers. The productive stabilizers in the GLN case look like this. So that's the stable. So omega would be like omega k, which is the corresponding representation Alt K S E N or Wedge K S E N. That one-dimensional space is stabilized by this maximal parabolic. If you intersect all of these maximal parabolics, you'll just get the upper triangular matrices. But I want something that's. Matrices, but I want something that's one dimension smaller than each of those. And when I intersect those, I won't just get the upper triangular matrices, I'll get N. So I don't think I'm going to write that down separately. So what I'm going to do is I'm going to take this, take the G orbit through that, and that will get me a copy of G mod N. What I'm going to think about living inside this vector space and take the closure. Yeah, could you say again what to feel? Yeah, what could you say again what the fee only is? How will the fee omelette? No, no, no. It's the highway it's a choice. Doesn't matter which one of highway drivers. Oh, so it doesn't matter which one. It's not. Okay, that's what I was just saying. In fact, any two choices are going to be in this same g order. Any two choices of these will be related by unique element of T. Will be related by a unique element of t. So therefore, so I'm going to get exactly the same orbit inside that button. Anyway, now I've presented this thing to you as a subscription vector space, and as such, it's a So there's one more um space I want to point out here. Space: I want to point out here, which is so if I think about functions on G degenerating to G functions on G. Again, this is the degeneration from the last time. I'll be using the G cross G action to find that. Then when I take spec, I'll have. Then when I take spec, I'll have this guy G degenerating to this guy G0, the Vinberg semi-group. So I'm defining G0 as a spec of this invariant ring. So this guy, of course, has the G cross G action, this guy has a G cross G and a T action. But it's closely related to the space I already have. To the space I already had, this guy is g mon mod n cross n dum dum g. Okay? So this has a g and a t action. This has a t and a g action. I only want one t action, and so I'm going to take a quotient by t. I'm going to be a I'm sorry, what is the backwards die? The backwards, the DOM DOM, or is that what you call it? It's only to tell you which action I'm dividing by. It's the N on the left. I'm so sorry, I missed something. What role was G naught? G0 by definition was spec. Was spec functor. So G naught, by definition, is a spec of the degenerate version of the functions on G. And can you tell us how to think of it geometrically? So I'm better at thinking about this guy geometrically. So let me start there. Start there. So this guy obviously looks like he's closely related to G mod B. This is something where if you took different T quotients by it, you would get the G mod B with the different symplectic structures on that. So this is this one magic space that sort of has all the quadrant orbits in it exactly once, but if you want to get a hold of them, you have to do two functions. So how do you think of that? Instead of thinking of just flags, Of thinking of just flags, I want to think about volumetric flags. So, volumetric flags, which I'm now going to divide, which is that for every one of my quotient spaces in my flag, for the I plane on the I minus one plane, I want a notion what the volume is of that. And so, what can our frame ratio, for any high plane mod J plane, I want to know what that volume is. And what could happen. And what could happen is that one of these volumes could go to zero and some subspace could disappear entirely. From the I3 plane down to the one plane. So on the boundary of this, so G mod n itself is simply, G mod n is thought about as flags with a choice of non-zero volume for every one of those quotients. But it has its extra stuff around the boundary. It has this extra stuff around the boundary, like this guy has a zero boundary of that. And that boundary comes from as these volumes head towards zero, then your subspaces can start to disappear, and you'll start getting volumetric partial flags. And so you will see all of not just these things living over G mod V, but in the boundary of living over all the G mod P's as well. So that's my best picture of it. That's my best picture of the Gmon Moda. So there is this nice way to blow up GmodMod N to get a vector bundle with light variety. So did you like that? Maybe. So over G mod C spectrum. Over G mod B, take the direct. Over B G1 B, take the direct sum of the line bundles corresponding to minus the funnel volts. Yeah, so okay, so there's a vector bundle. If you consider the activization of this, that'll mean some. Got to be some, there's got to be some cluster algebra interpretation of why we're going to do this. Because if you think about the tangent space of the base point, then you see the negative roots. But let's see. Repeating roots. I think I'm trying to decide whether I want them positive or negative. But I think the tangent space here, the base point, you should see all the negative roots and just the second roots. So the almost negative roots restore alpha version. All those. What's a finalization? When you take a space, you consider the functions on it, and you take spec of that. So if you start with a projective space, then you think about the functions on it, they're constant, and you take spec of that, you get a point. So the autonization is the universal thing you have to factor through whenever you map to any of the applies. So you have a map between Do you have a math between G mod1 and G mod3? No, if I do a GIP quotient or a selected quotient of this guy on the right, then I will get G mod P. And not G mod P? Uh no. I mean, if I do a really singular version of it, yes. Probably should ask him later. You're taking an aphorization just of the thing upstairs, is that right? Of the total space of the vector bundle. Yes, okay. All right. I really want to get to the the other topic. So um so the other topic is actually going to have some not so much torque generation yet. Not so much Tori congeneration yet, but I want to start with a sort of local picture that's easier to think about, and we'll see a whole bunch of semi-toric generation. Sorry, I guess there's something that hasn't come up out loud yet, and everyone should say it. So let me, if I have g acting on X, and this And this X is a proj of some ring. Then we talked about generating the ring to disassociate the gradient, having to do the G action. And I'm going to call that thing Ger sub G S. Okay, so there's going to be a There's going to be a flat family like this. The total space of the flat family is given by the Reese algebra, the multi-reese algebra that I was second guessing myself about last time, but it does just work out. So there's flat family, which is the sum over lambda of Over lambda of these guys, R lambda. Remember, we had R was the direct sum of the biscuit components, and R lambda was the sum of I lambda minus sum of positive rates. So we want to take those filtered pieces and multiply them by this placeholder, e to the lambda, which we're the where's Which where the where c bracket leads t over lambdas is just this polynomial here. That's going to be our base. And this guy, that's this Ries algebra. And so Clando is the ring of the dominant weights as equal. All right, so the point, though, is that there's a map like this into this ring, because if I have a, oh sorry, where does this thing live? This is a subring of these placeholder variables, tensor, Variables tensor with R. So that's where these things live. R sub 0 contains 1 in it. And so when I have t to the lambda, I can take it to t to the lambda times 1. And I end up with a map of rings. And I get this map backwards spec of the Ries algebra. Spec of the Ries algebra to spec of this polynomial ring, which is isomorphic to the algebra of the torus. Why did t to the lambda times one actually lie in the something that there is a direct sum? No. Because the um uh um let me um let let me assume right sorry sorry uh let me assume for right now that uh G is adjoint. Um uh sorry about that so uh oh uh no that's not a problem that's not a problem because I only want Because they only want, so if lambda is in here, this lambda here is right. So lambda here lives in dominant weights that are equal to sums of positive roots. Of positive roots. That's the cone that I'm thinking about. So therefore, each of the R lambdas that I need to worry about contains R0. Because each of the R lambdas, by definition, contains I naught, and I naught is I naught is where the identity lives. So that's why one will be in the middle of the middle of the center. So that's that's the base of my generation spec of this thing and isomorphic to uh actually to for a torus. So the so inside here we have a general point or sorry inside here we have a general point and we have omicra and over the And over the fiber general point, we will get spec R. And over this, we will get specific. So there's handle generating project R and Project R or spec or whatever. Right, and so the main example is Is take G to be GLNC. And we think about, so it's acting on some guy X, which is produced of R, but I'm going to stop talking about R and just talk more geometrically as being X. And I think about generating X to GR GLN X and then to GR GLN minus 1. G L n minus 1 of Gerber G L N of X and I keep going down to Gerber G L 1 of Gerber G L 2 of X. So what are these things that I'm getting? This has a GLN action. This has a GLN cross TN action. This has the GLN, I forget the GLN. I forget the GLN action from here to here. I just say, throw it away, go TLN as well. I keep the TN that I have. So I've got a TN here. Just for an excuse to use the hyperbola chalk. So I pick up a TN action here. I pick up the TN minus one action there. And by the time I'm done, I have this action. So I've treated. So I've traded my non-abelian action and lots of smoothness for this massive torus action. And in the case where x was just a fine variety, then when I'm done, I will have a toric variety whose polytope will be the Fontana polytope. This is an algebraic way to get yourself to a toric variety using a bunch of steps that aren't actually toric generations. Well, can it happen after the first step of a generation if your g action becomes trivial? No, because the two rings are isomorphic as g vector spaces. So this uh So this enhancement of the symmetry is really a so this enhancement of the symmetry on the vector space level is really stupid. It says if you have a G representation, then you can break it into isotivic components. Now it's a G cross T representation. But dumb on the rep3 level, but it's more interesting on the reading level when we actually change the ring structure. For me to go off TVA. Sorry, one question. Does this depend on the embedding of GLK into GLK plus? Yeah, so okay, so but the construction works, you would just get a different part of the quality. So but I think the different ways you would stick them in there are transcripts to another to another, and as such you would get a nice and large effect. What we choose my general, so not just general meaning. Right, so the difference is, so what was good about this was that I had this massive chain of subconscious. I could use any chain of subprimes at all, and I would get something that's more toric than what I started with. The only thing that's special here is that you can start with a generalifying manifold here, GL mod B, and so that sounds big, and manage still to make it entirely torn. Florida. So you could imagine doing something with a G2 flag variety. And so you've got G2 and SL3 and GL2, or you've got this chain of subgroups. And it's very easy to calculate how much Taurus you'll have acting when you're done. Is it enough to completely integrate your system? I mean, it depends on whether this guy was small enough. So for a full G2 flag variety, I don't think so. For a G2 monitor rolling, they. For VT moderal. Alright. And now for something fairly different. So I want to give you a family. And this is not a family in the sense I defined so far, in the English sense. Uh family of uh semitauric generations. So the input is first going to be some group G. And you can take GLN if you want. This is again complex, connective, productive and just crush. Okay. And I want a pinning of it. So the G contains a borel, it contains a torus. We have the roots, we have the positive roots, we have the bile root. Whatever. So Delene explains to me what to derive from the French word for Where I think is what Ruby Key first started naming. Instead of writing out what all these things are, once you hear this word, you're supposed to know, we have, of course, B's for Borel, Ts for Forest. And that is, I said, so what's an empty moulage in French? And so it's like, English, I'd be a butterfly. And the pieces of, just a, you know, I hadn't thought of a leaf root as like a beautiful. A leaf root as like a beautiful butterfly before, but I've always had a sense. But now it's late. So that's an important part of studying observation. So that's not much of a start. Then we're going to have Q will be a word in the simple reflections or the words. Or the symbol roots, whatever, or the vertices of the data diagram, any way you want to index them in the bio group. And no reason for this to be reduced. Very often we'll see people make assumptions that some word is reduced and then write down a theorem that doesn't actually use those. So it's kind of a verbal tick. We'll speak for root here. For here, try to catch yourself doing it. So, Word, and I'm also going to have some guy little W in slide big W. Okay. So, to Q, we associate the bot Samuelson. I'll emphasize for people who are new to those, there is no letter U in here. We've been defined before, but I'm going to define it again, and I'm going to write it this way: so I'll have my first letter in Q and my second letter in Q up to, and is this good Beth? Yeah. Okay. Up to fine. First letter in Q, second letter in Q. Letter in Q up to my last letter in Q, last. And then I'm going to start dividing by B's. No, no, no. I want to put one more gratuitous B up front before I start dividing by B's. So I'm going to divide by B at the very end, but also by B's along the way. So what are these PQIs? They're things like upper triangulars, but uppercuts. Um, upper triangulars, but a little bit below the uh um the diagonal. So they are subgroups, they contain V, and they're one dimension larger. There's one of these for each position below the diagonal, which is to say for each negative simple root, or each positive simple root. So that's why I'm taking my Q, getting Very Volaty and mining by all this stuff. So the B belongs up here and not down. The B belongs up here and not down there because this is not a finer product. It's a quotient, not a subset of the ordinary product. One thing you can do with Bots Amelson is forget the last part of it and just remember what's up front. And I want to be able to do that all the way down to forgetting all the in getting down to be mod big. So that's why I stuck this curtailer to be upfront. So each time you do that forgetting, So each time you do that forgetting, you end up with this fiber bundle where your bot Samuelson Q goes down to Bot Samuelson without the last letter. And that always looks like one of these new parabolics, modular B, and that's always the projective one. So this guy is this iterated bundle of projective. Iterated bundle of projective levels. Perpendicular, it's smooth, projective, has a nice torus action, is isolated fixed points. I'll seem to do something about it. So I'll talk about the full bot sampleson more next time, but right now I want to focus attention inside the bot sample. Well, one more thing I want to say about it is there's this. wants to say about it is there's this map to G mod V. I'm going to call M for multiply. So an element in here is not a tuple of group elements because it's only that up to this equivalence relation that came from dividing by all these beads. As such, you have to check that it makes sense. Check that it makes sense to multiply all of these together. And it doesn't because of the V I divided by the end. So I still have to divide by that. And I get this V equivariant map from Ubaugh Samuelson to Jamaica. Okay, living inside here is the old Umbach Andelson. I mean, that looks like a jot stop Gmod. Um, yeah, but I like Gmod V more. No, no, they're BSQ. Well, anyway, sorry, sorry, just so BSOpenQ. I'm going to give you an isomorphism to this from just affine. From just affine space of this same dimension Q. So, what this map, what this isomorphism, so okay, I guess I need to define this guy first. What's the open one? So, but well, I'll just define it as the image of this map. So the map is going to come from to the cube, and this map is going to take a year. Just 100 meters open over here. It's going to take Z1 up to Z, so the size of Q2 is product of matrices like this. And so this is going to be the G is GLN example. And people who want to think about, the sort of people who care about generalizing beyond GLN will know how to. We'll know how to. So you can ask me if I'm wrong about that, but let's try it and just seeing GNLN's as a whole. So what we're going to do with the ZI, I'm going to look inside this parabolic. So remember the parabolic looked like this. It was just a little bit bigger in one place here than the Barrell. So I'm going to look at that same place at that 2x2. Now there's an SL2 living inside there, and I'm going to do the And I'm going to do the identity everywhere else. But in there, I'm going to put my ZI at a 1 and a negative 0. So these are real size. ZI, 1, negative 1, 0. And I've got the negative 1 there in order to make this guy be an SL2. So there's a paper by Lescoud, Leclerc, and T. Ball. Sorry. Yeah, I think that's Coo-Rogan. In which they don't put that minus one there, and boy, do they pay for it. And boy, did they pay for it. Anyway, so if you have other simple roots in other groups, they'll have SL2s. Those SL2s will have lifts of the while group to some degree like this, the S2 vial group in there, and the unipotent group. So that's the sort of thing that goes on in generalizing this. Generalizing this. I'm going to multiply those together. And no, no, I don't want to multiply those together. I want to take the tuple of those. And that, of course, is the module of this equivalence relation. So a given list of numbers, I take a very specific list of elements of here above. And then what I'm next going to do is compose all the way to here. All the way to here. So let me call that map q let me call that map m tornado. It depends on q, of course. But we'll write it out a little. So did M. So this is a map from affine space to flex. Okay, so Okay, so um here's the theorem. Uh excuse me. This is a while ago. Let's take n tilde inverse of x sub w. So x sub w, in my notation, is the b minus orbit through w, closure. So inside, so G log B had this B equivariant map, and it also has this B minus equivariant map. So, equivariant and B minus equivariant. And so that's enough to make those two sort of positions. Sort of in their position, transverse, such that this is a reasonable thing to look at. Okay, so this sentence, no verb. So, this is some, what do we have so far? We've got some sub-variety. This whole thing is some sub-variety of CQ. I'm going to take that guy and let init this sub-variety. So, what does that mean? This means. Um this means replace all generators in the ideal all elements. I don't know who's the generators, I'll just do it all elements by their let's leading terms. So ideal goes in, or sub-scheme of affine space goes in, hence polynomial ideal. Hence, polynomial ideal goes in and monomial ideal comes out. So this is reduced. So even polynomials, the ideal you get when you're done, the monomial ideal, is generated by square-free monomials. That's what this is saying. That's what theory. That's what theory. Well, there's more to say, but yeah, that's okay. The monomials generating this R squared. So of course we want to know more about which monomials generating this. But in general, so you could do this, this lex and if thing. Do this, this Lex and it thing, you can do this with any polynomial ideal at all. And you get this, you get this one of the standard ways to do a group of degeneration. Maybe not the most standard, which is called red flex, but a lot of them are. But what will happen 99% of the time is that you'll get monomials that aren't square-free. And so the limiting thing you get will be schemy. It won't be this. Schemy. It won't be this reduced view of boilerless spaces. So you should ask at this point, as I believe Lesio is hinting at, what is the actual limit? What union of coordinate spaces do you get? So it's equal to the union. So if I'm End. So, if I want to talk about a coordinate space, I will have some subset of the coordinates. And I'm going to describe the coordinate space that uses that subset like this. So this is my notation for the coordinate subspace of C to the Q that uses the coordinates R and doesn't use the other coordinates. What does that mean? It's things like. So what does that mean? It's things like 0, 0, star, star, 0. It uses the third and fourth coordinate, and they're free. There's not further equations other than some coordinates are 0. So I'm not going to get everything. As written, this would say, well, let's take R equal Q and we get the entire thing. So there's conditions on R. And the condition is that Q minus R is a reduced word. Is a reduced word for W. So those are the pieces. That co-dimension, like W. Right, let's check, let's do a dimension count. Before you do that, quickly, this equality seems like it's between an algebraic object and a geometric object. Maybe the equality moves. This is a geometric object. Yeah. Yeah, okay. As this seems. And this scheme is a scheme. This is resistance. Yeah, that equality. This is a geometric object. So too is that. Oh, yeah, but this first table is about less init of that value. So where are we? Spect of this. Speck of this. Okay, that's all I wanted. Is there a missing stack on the board? That's all I wanted. Yeah, there's a latest generation for that. Well, the question is: are you willing to take in it of a sub-scheme, or are you only willing to take in it of an ideal? Oh, probably just gonna kill it, sorry. It's important to get over, so you're all over. Oh, this W this W is the is the only this W is in two places. So there was a W on the board before, but it's. It was part of the inputs. But there were no conditions on that before. No, but Q was a condition. Q is a word for W. Q is not a word for W. Oh, you made that assumption. Q is just a word. It was not a reduced word. You emphasize it. Q is just a word. Q is just a word. And unrelated to W. Sorry, what is W? W is a. So the input began with. So the input again was a word and then called Q and Lit December a volume revolving delta. I mean volume gone. Correct. Yes. Both sides this could be on visit request. But they would not be at the same size. So in other words, this is your sub report. Yes. So what's so if you haven't thought a lot about the no So, if you haven't thought a lot about monomial ideals and unions of coordinates of bases, one thing to do with the union of coordinate spaces is to look at the real points of it and say, okay, I've got real coordinate spaces. That surely is the same amount of information. And then think about, well, what if I just thought about not r to the n or r to the cube? Not r to the cube, but r plus to the cube, or r to the r. Let's think about taking this guy, if I intersect it with a positive. With positive, with having non-negative real entries. And I'm going to intersect it also with vectors where the sum of the coordinates is 1. Now, if you did that with the entire C super q, then what you would get is the standard description of a simplice. What I'm getting instead is a bunch of sub-simplicities of that simplice. So, from this data, you can extract the simplicial complex by this recipe, and it's the same data. From the simplicial complex, you can describe this. So, one thing that's then fun to do is to look at these quotial complexes as ontological spaces, and that's what they so I want to do the dimension check, and then I want to do an example of this. So, the dimension check So the dimension check is that x sub w inside g mod b, its codimension is the length of w. So these, I claimed that these guys were transverse enough because this was a b invariant map, this was a b minus equivariant map, and that's enough. So that says that the codevention of this thing inside. C to the Q will again be the length of W. So that says that the sizes of these R's should be length of W less smaller than size of Q, and that fits with this complementation. So let me soup up this theorem. What if I had not just one? What if I had not just one xw, but I had a union over w inside some set? So I've got a bunch of them. Then that's going to commute here. I'm going to w in that set. So this is a surprise that this is not at all a trivial extra step from what I said before. So imagine you're thinking about like two skew lines in the plane. Few lines in the plane, kind of diagonal, and you imagine the limit where they're each falling down to be just a horizontal line. So that's a growth-group regeneration where I'm privileging y over x. And this guy falls down to be y equals zero, and so does that. If you take the union of them, then it'll fall down and become y squared equals zero. They'll fall on top of each other. So I'm saying in this degeneration, these guys don't fall on top of each other like that. How each other look like. Is that something you observe after you do check every one of them, or is it more complicated than that? Are you asking a historical question? Imagine about the proof. I will not use the proof. It's one proof. It's not a stepping stone to the whole thing. So, one of the things is telling you also is, so put another one. If you consider a subword of Q, then you can ask, from which W did it come? And I just told you it's not going to come from all the different W's. Now, not every subword is actually the complement of a reduced word. So, I could take a bigger union, you know. Take a bigger union in order to see every subword, a union of supposedly more things, such that when I finish taking the union, it's not any bigger. So the way I'm going to spell that out is this. I'm going to define a map from 2 to the Q, so just as subwords. And so let me emphasize that this is how many subwords I want. So it's not just abstract. Want. So it's not just abstractly does like one sit inside one, two, one. This is not what subword means for me. That's a subword. That's a subword. So I'm considering subwords, and I've got a map from there to there called the Demizer product. And the Demizer product of S is defined. Is defined as the unique maximum, so there's a fear of else going on here that I'm not getting to right now, of the unique maximum of products of R, where R is a sub root of S. So for example, if I have 1-1 inside 1, 2, 1, the product of 1-1, by which I mean, this is simple reflections in S3, the product of Uh, and that's three. The product of R1 and R1 would be the identity. But if you went down from there to just this, the product of R1 would be one, bigger than the identity. So that would be the denser product in this case. These three guys all have the same denser product. All right. So the theorem, and this is me with Fazor Miller, I think this is in 05, is two things. One is each Demiser inverse, well, so let me call this map Dems of Q. So for sub words Q. Each DemQ inverse of Is the faces of an open ball contained inside the simplex with vertices 2. So I'm going to think of these as a one-to-one correspondence with A one-to-one correspondence with faces of a simplex. So if you, like on the triangle, for example, how many faces are there? There's this one, that one, that one, this one, that one, that one, the whole thing, and the secret empty face. So depending on which verge these are in, you get a face. Two, it's closure. Closure is a closed ball, and that ball is what we call a subword complex. And third, the closure relation is given by through hour. Prove our work. So let's do an example, and for today, Q is 1, 2, 1. So because of the complementation, I don't actually want to label the vertices by By the letters of Q. I'd like to label them by the complement of letters of Q. So here I'm going to leave out the third letter, here I'm going to leave out the second letter, and here I'll leave out the first letter. And then, so I haven't gotten to the figure in yet, I thought I'd done it right. I'm just worrying about how to label the faces. So as I go to bigger faces, I will be intersecting the things you see here and getting smaller. Things you see here and getting smaller assemblies. So the intersection of those two is this, and those two is that, and those two is this. And then of everybody is that. So now, so what is this one two one? One, two, one, or R2R1 is a reduced word. For W0 and the classic. Is it impossible to reduce for QA to be used for it? I didn't write that it was not reduced. It also holds for reduced words. So, okay, so there's the simplex labeled by subwords. Now let's hit it with the theorem. So I want to compute the demos of. So, I want to compute the Denison product of things here. And I mostly get all different answers, except for these three guys who give me the same answer, R1. So, let's kind of have that one. So, there is an open one ball in this simple box. This guy down here is getting me a different open one ball. And then these guys are getting me some zero balls. Guys are getting me some zero balls. The guy in the middle is getting me an open two ball. And hiding on the empty face is the subword 121. It uses everything. And it's getting me an open negative one ball. That doesn't cast these things in conflicts. So what I want you to observe is like I have the open balls and like the closure of this blue guy. The closure of this blue guy is now from this vertex around here to there, so that's a closed one ball. And who's in the boundary of whom? So who's in the boundary of whom? We're seeing the R1, R2 contained in R1, R2, R2, R1 contained. R1 contained in W0, you're seeing the S3 free order. So this guy being a boundary of that thing is like this being above bat and Bruha order. So I like to call this thing the Bruha decomposition of the simplex into a so this is maybe a stupid section A stupid semi-tauric degeneration because these toric varieties here are so boring, it'll get more interesting. So it's still interesting to do that because you can then prove things like this. You can prove things like this guy is colon Macaulay, not only the ones who do these units. But any single one of these is Colin Macaulay is something you prove combinatorially by analyzing these, and it's closely related to these guys being. And it's closely related to these guys being false. And when you have a degeneration's colon collie, then the original scheme's colon collie. So it's a kind of bad fact about these parts of the relation correct. 