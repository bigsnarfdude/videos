Anyway, so this is joint work with Wesley Peggren and it's about spanners. So I probably have to define a spanner, right? Okay, so we're given a connected graph and the edges have length and we let dvw be the shortest distance between the vertex. Be the shortest distance between vertex V and vertex W. And so, you know, basically, you want to know what the distance is between vertices in the graph. It could be that the graph itself is very dense. And what you would like to do is keep a subgraph, a subset of the edges, such that if you compute distances with respect to the subgraph, then these shortest distances should. Then these shortest distances should be strongly related to the distance in the whole graph, gives you a good estimate. So, you know, you don't have to carry around the whole graph. So let's say a T spanner will be a subset E prime. So if you use D, so if you compute shortish distances in E prime, call it D prime V w, then D prime V W is at most T times D V W. So I'm So obviously T is obviously at least one here. And what you would like to do is have E prime as small as possible, given that you want to keep T small. And what else could I go to say? Well, there was something else. Oh, never mind. Okay, so see this conference about random stuff. See this conference about random stuff. Um, I'm going to talk about the problem where the length cells are random variable. All right. Oh, yeah, I want to say that T is one, if T is one, so that D V prime equals D W. So what you're saying is you're trying to find the smallest set of edges such that if you compute shortest distances using the subset, you get the right answer. Right answer. So that's, I think it's a sort, it's actually a sort of computer science question, it's been hammered away and there's books on it, but I don't not much stuff has been done on the random case. It's obviously, as usual, it's the worst case. Computer scientists focus on the worst case. Okay, so there's two, we're looking at two scenarios. Okay, the first. Okay, the first is the independent case. So first let's think, suppose we took the complete graph and we give every edge an independent, each edge has a length which is uniform 0, 1. The question is, and now we want a one spanner. So we just want to keep a set of edges which such that every that there's a That the shortest path within those edges is actually the shortest path. How many do we need? Well, it's an old result of Svante-Jansen that you the length of a longest, the maximum over the shortest distances is about three log n over n. Okay, so if I threw away all the edges that were of length longer than three. Of length longer than three login over n, what's left would actually be a one spanner. And how many edges are there of length? Three login over n or less. That's about three over two n log n. Okay, so obviously three is an extreme here, and a typical pair of vertices are about a half an log n, about about About log n over n a part. So you might expect then instead of being three over two n log n, you would get you only need a half n log n edges. And that's what we prove. And we can actually generalize it from the complete graph. It's not difficult. And first of all, you can either take a regular graph. Regular graph. I'm not sure why. I don't necessarily think, well, maybe regularity is important. But anyway, it's a regular graph with Dn regular, D some constant, and D is strictly bigger than a half. That works. Failing that, if it's a DN regular and D is, say, one over 10, then you have to insist on some connectivity. Okay, and so I'll give some idea of how. Some idea of how, so A, that would that said a one spanner needs roughly a half end login, upper and lower bounds of about a half end login. And then you might say, well, suppose I took, suppose I said, I want a, I'm not so desperate to have the exact shortest part. Suppose I'd be happy with 100, you know, shortest parts, they're all within a factor of 100. They're all within a factor 100. You know, can I sort of reduce the get rid of the login? Can I get a linear number? And unfortunately, you can't. So that's the lower bound. It says, you know, you need, you do need n log n if you want a lambda spanner. Of course, if you want a login spanner, then you only need a linear number. Okay, so that's one result. And then having finished that, That we thought, okay, let's try something else. So we looked at points in, say, the unit square. In fact, definitely in the unit square, right? So suppose curly x is x1, x2 up to xn are n randomly chosen points from the unit square. And so And so, and the edges, and the important problem here is that the edges, we only have edges between points independently with probability p. So let's call that xp, curly xp. So this was something that Wesley and I worked on a few years ago with respect to the traveling salesperson problem. So, what it is, we take GNP. GNP and we randomly embed it in the unit square. So that's our model. So I think this is perhaps the third paper that ever mentions this model, right? And so the point there is that every edge, so since it's Euclidean with probability of one, every edge is the shortest distance between it and its neighbors, right? So if you want a one spanner, you have to. want a one spanner you have to take all the uh you have to take every uh edge right so it's hopeless trying to well it's not interesting that's it right so what's more interesting is um you take a small epsilon and uh you want to get a one plus epsilon spanner right i'm not saying this is a sort of model that you use when you're doing google maps that's probably When you're doing Google Macs, that's probably a bit of a thread, right? Uh, but it's probably related somewhere. So, what we prove is that as if NP grows fast enough so that the edge so that you've got connectivity, then how many ages do you need? Then how many, so we can find an a one plus epsilon spanner and it needs the following number. It needs the following number of edges. It's sort of n, obviously. 1 over p. That's right. So n over p is the right number for the number of vertices and the probability. But we got the, we seem to have the seem to have the dependency on epsilon wrong. So we've got an upper bound of epsilon to the minus three log one over epsilon, which is obviously wrong. And And so that's just with expectation inside. If you want a bit of concentration, we actually, well, the way we proved it, maybe I would assume actually that it's concentrated, the expected value of the theme we can... The size of the theme we construct is probably concentrated around its mean, but we didn't manage to prove that. We had to sort of boost, we had to increase P. Sort of boost, we have to increase p to get that, and then it's concentrated around the mean, right? And when we say concentrated, we didn't actually, yes, we do prove concentration around the mean, um, but all we just say there's a you can add another order n, which is small compared to the n over p epsilon q. Then the question is, well, if you do want a one plus epsilon spanner, how much do you need? And the answer is you need n epsilon to minus one p plus. That's a lower band, and that's probably Lower bound, and that's probably right. I'm just guessing that that's probably right. Okay, so now I have to sort of justify these claims. Now, I'm going to avoid calculation, showing calculations, so that means that the talk will be very short. All right. Well, yeah, so here's something. Well yeah, so here's something alpha is something close to one. Just think of alpha as something close to one. And for a vertex v, delta v is the distance from v to its nearest neighbor. So I'm doing the lower bound now. I'm just going to prove the lower bound. Well, prove in quotes, the lower bound. So here's the picture. So xv is all those vertices, oh sorry, for a given vertex v. that for a given vertex v x v are the neighbors x which are close to v and the claim is that a one spanner must contain all the edges between v and x v okay for most v they're this is this we're doing a lower bound we don't have to prove this is true for all v we just have to prove this is true You just have to prove this is true for most V. And for most V, there's about login of the, yeah, there is about, well, there's about log n over n of these guys, right? Because you have to multiply by D. It gets rid of the D there. There's about log N of these guys for most of V. So that gives you N log N, but you have to divide by two, right? Because an edge has got two n. And so the question is, why is that? And so the question is, why is that the case? Why do you actually need most of XV? Well, there's the picture with XV. And if I deleted this red edge, then somehow I've got to get from here to here. Right. And you know, if I take another edge, that's no good. That's too long. So I have to get from here to here. And you can argue that with high. Here, and you can argue that with high probability, most of the time, these edges are all longer than alpha log n over dA. Most of the time. Not always, most of the time. And that shows you that the XV is the right concept and you need roughly half n log in it. Okay. Now, what about the upper bar? Well, I'm going to do the upper. Now, what about the upper bound? Well, I'm going to do the upper bound very carefully. So, the upper bound, you pick some guess as the short, what's the short edge. So, you take all the short edges, right? And short is some particular value. And then you take all these short edges, and the number of short edges is about half n log n. And then what you have to claim is that there are very few long edges that are in some shortest path. So the claim is that we take E1 to be the edges which are long and there's some shortest path that uses it. And then we prove that there's only little o n log n that does. And how do we do that? Well basically And how do we do that? Well, basically, we analyze. This is we sort of take a page out of Janssen's paper and we follow Dietrich's algorithm. And we ask ourselves, what are the chances that we're going to use this edge E, this long edge E? And it's very rare that we're going to use this edge E. Okay? The probability of using HE is little. The property usernich is little o1, okay? So that gives you sort of n log n. Lit log n over n. So you get little n log n of these guys. And so you can throw these in on top of it and you get the upper bound of about a half n log n. That's about all I have to tell you on this particular one, without going into sort of gory details. Details of using the first moment method and god knows what, right? Um, so uh, yeah, I didn't actually what did I say? Ah, did I say there were uniform zero one? No, I didn't mean to. Oh, yes, um, I did say uniform. I think I use uniform zero, one, but then we always, but then we overestimate it with E of one, but they're basically the same. Make it with E of one, but they're basically the same and use the same length, right? So, open questions are replace E of one, if I was using E of one, by E of one to the alpha. Now, this makes, so this, the problem with that is that Janssen's analysis goes out the window and so Janssen's analysis goes out the window and so does ours. Window, and so there's ours. And there's a paper by, I think it's Banidi and Hofstad, and who've analyzed E1 to the alpha, but look, they haven't really nailed it as tightly as Janssen did. And it's a much more complicated thing. So that's one thing one could do. Okay, so relax the constraints on the graph G. And what's the third one? I don't know why I put this one in. Edge disjoint path. This is a completely different setup. And I'm not even sure what the question is, but unless presumably you wanted to find any disjoint paths of a given length between specified pairs of vertices and how many do you need. You need. Anyway, and then presumably there are other related things with spanners. I know sparsifying graphs is a computer scientists are interested in sparsifying graphs. So you can sparsify them for other reasons. Okay, so that's the independent case. So now let's move on to the Euclidean case. So as I said before, probability one, one spanner who wants all the edges. And wants all the edges. So, what you want to do is a one plus epsilon span. Okay, so an important, how are we doing? We're doing good for time. So an important idea, an important idea is this idea of a cone. Suppose I want to go from capital A to capital B. What we do is that for every What we do is that for every point A, we imagine it's the center, it's the apex. Well, we have all these cones. So we have tau, which is two pi over epsilon, rays coming out of A, and each pair of adjacent rays is a cone and And suppose I'm going from A to B, and suppose that I can find Y, suppose that A is that Y is the closest one in the cone to A, and it comes before B, then it seems like a good idea to go to Y and then try and find the path from Y to B. And this is a sort of This is a sort of an algorithm that the worst-case people use, and if it works, you get a path of length, the actual Euclidean length of AB divided by cos epsilon minus sine epsilon. And cos epsilon is basically one if epsilon is small. And sine epsilon is basically epsilon. So this gives you a one plus epsilon spanner. So this is a sort of an idea. So this is a sort of an idea, a good idea, except the only problem is that since edges only exist with probability p, what are you going to do if that doesn't work? I mean, you could try the second closest, I suppose, or the third closest. And we never tried that, right? So what did we do? We say the following. Okay, so are we going to. So we're going to define some, all right, so P of AB will be the shortest path between A and B in the graph, chi P or X P, and let its distance be V of AB. So we have this out, okay. So first of all, we take all the short ones, so we have the short block here, and this is this. Rather strange constant. Okay. Oh, that there's an end missing there. Or is there not? No, there can't be an end missing there because otherwise we'd have... Yeah. So there's, so if you, if you, how big is this one? This is order n. Well, with the epsilon, right? This is of order n. Pi r squared times n, that's the number of, that's roughly the number of points that you get. Okay, so that's E1. Okay, so that's E1. And now here's the idea. Here's the algorithm for building the path. Okay, so what we're going to do is going to build a path which starts at A, that'll be Z naught, or Z naught, since we're in Canada, right? I go Z naught, Z1 up to ZK, which is B. And how does this go? So we suppose we suppose we're at Zj. we're at zj so if zj is uh if zjb is in e1 then we can use it right we've got the edge we might as well use it otherwise um we'd what we'd like is that zj minus yj is less than zj minus b but if it's further if so yj is the closest what is yj yj is the closest point in the cone In the cone, and when I say the cone, I mean the cone that contains A and B. The yj is the closest one in the cone. And if it's closer than B, then we'll, then, okay, if it's not closer, then we just have to take this shortest path. So assume it is the shortest path. But if the shortest path is very long, sorry, if the shortest distance from dyj to b is long. d y j to b is is long then that's no good could be that could be bad so then we take the shortest so we don't go to yj instead we go to z we go from zj to b and we take the shortest path okay and if we get through d2 and d3 then we move in the cone then we move in the cone all right so what we're trying to do is move in the cone to something that's close In the cone to something that's closer and for which the distance is the shortest path distance is good. And then we just argue that, so what we're doing, we're taking some lots of edges here and lots of edges here and we're taking cone edges and we've got to argue that when we add all this up, that we've only taken a linear number of edges. Okay, so first of all, there is some value of big capital R epsilon so that when you're far away, when you're far away, you can go into the, with high probability, you can move within the car. So things only get bad when you get close to your destination. All right. Okay, so if it, so certainly true, you can actually prove that construct doesn't doesn't make, always gives you, is an is a six eps, but is a six epsilon spanner. Obviously, you just readjust epsilon. So that's not the issue. There's no issue here. The issue is how many edges are we using for this? You know, because we're taking these shortest parts. Okay. So what are these? So these are, so B, B, curly B epsilon and curly C epsilon are basically a superset of edges that contains the paths that we'll use for a construct. So their distance is bigger than that, right? And they're Bigger than that, right? And they are that should be less than or equal to or never right. And in the span that we construct, we use these E1, union, E2, unit, E3, unit, E4, right? So this should be less than. And then we can prove, so this is trivial, this is just a Chernoff bound. This is trivial, this is just the number of cones. Just the number of cones is n over epsilon. And this is a lot of work. All right. And this is where we fall down in the sense that we don't get the right answer. And this only gives us an expectation. And And then it took us a bit, you know, this took, you know, the independent case only took about a week to do. So this took time to do. And then we had a bit of trouble with proving concentration. I mean, initially, we were using telegrams inequality, and then we just kept getting it wrong. And then we realised the right way to do it and to get telegrams inequality to work. To get Teregrant inequality to work. And then we realized actually if you've got the right way to do it, then the Azuma inequality works. And in particular, McDermott's version works. So, oh yeah, so I'm almost done. Thank goodness. So now what about the lower bound? So the lower band, I should have drawn a picture here, but I thought it's probably not necessary. So we say an edge is lonely, an edge will be... An edge is lonely, an edge will be lonely if you look at the ellipse with A and B as foci, that the A and B and distance are apart. You look at the ellipse with A and B foci, and the sum of the distances is one perception on R. If you look at that ellipse, okay, if there's nothing in the ellipse of any use to you, you that means you've got to take you have to take this edge that's a lonely edge you have to take if you want a one plus epsilon on span right because there's nothing else you can do and then uh a little bit of work uh we just use chevy check chevy check right to finish it up okay so what are the other Okay, so what are the opening questions here? The obvious other question for this one is close the gap between the upper and lower bound. And well, it was hard enough getting what we did, so we take that, we took what we've got. Well, what other things we do? All right, then. Okay, it's obvious replace the. Obvious replace the unit square by zero ones at unit hypha q, unit q. And that I should think is just completely trivial to do. I don't think there's any real problem with that. And but more of a problem would be other norms. So I think people do consider other norms. I don't think. I don't think I had any other questions. So thanks very much.