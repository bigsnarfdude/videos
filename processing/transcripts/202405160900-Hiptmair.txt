Okay. It's my pleasure to present the talk of Ralph Hippmeier. A conference on a trust method without Ralph Hippmeier will not be the same because it will not be a real conference. So we will speak about coupling finite elements and Tref's approximate. Elements and have approximation, and I think we will really enjoy it. So it's your time, Paul. So, thank you, Sebastian, for the introduction. And my apologies for having opted for the online way of delivering my talk. Well, I will try to do a job as good as possible to inspire you. In fact, this In fact, this presentation is connected to a project of about five years ago that I conducted with people from electrical engineering here at Etihazurich. Employed on that project was my then PhD student Daniele Casati, who did most of the computational work, and my colleague from electrical engineering involved in the project. Involved in the project is Jasmin Smajic. I would like to start with a historical note and also remind you of a large and important group of Trafts users and also developers of Trafts method that are not so well represented at this workshop. What I have in mind. What I have in mind is those many computational electrical engineers that have been using Dreft's methods for ages. And a prominent figure among them is my former Etiha colleague, Christian Hofner. He retired a couple of years ago, and throughout his career, And throughout his career, he has essentially built his entire research on the use of Thraft's method. He was a leader and a pioneer in this respect. And he's hardly known in the math community because, well, all his research was very much oriented towards concrete applications in electrical engineering. In electrical engineering, I should add that Christian was, in fact, a mathematician. He is a PhD student of Peter Henrizzi. And some of you may know Peter Henri as the author of those monumental volumes on applied in computational complex analysis. But Christian Hafner never bothered about mathematical analysis. About mathematical analysis of his methods. He was happy to apply them and, well, make other engineers and physicists happy with his simulations. So he has made major contributions to Draft's methods, among them these two books, where he elaborates the details of his Draft's approach to electromagnetic field computation. Electromagnetic field computation, and he has also developed a massive suite of codes, all using Treft's methods to approximate electromagnetic fields and acoustic fields for frequency-domain wave propagation mainly, and also electrostatics. And this is the And this is the background of the project. Jasmin Smaj, in a sense, is the successor of Christian Hofner here at Etiha. And he inherited all these codes. Some of his people still use them. And well, he asked me to get involved in upgrading the codes. Upgrading the codes in the direction of Upgrading the codes in the direction of making it possible to use also finite elements methods in combination with the drafts methods of the codes. So this is the background of my presentation and well the context of why I started looking at this coupling problem. I would like to point out that the last part of Peter's talk Peter's talk on Monday was also devoted to the issue of coupling drafts methods, in his case the ultra-weak variational formulation, and standard finite element methods. So I'm going to continue this topic here. But I would like to keep things simple. So I keep a focus on scale. Focus on scalar second-order elliptic diffusion problems posed on the entire space, so equipped with appropriate decay conditions to render the solution unique. The setting I have in mind is the following. We have a right-hand side source with a small support. Support and that source is also located within a zone of inhomogeneity where the diffusion coefficient may vary in space. Outside the diffusion coefficient is just one outside this bounded region of homogeneity. This is the simple setting. There's a slightly more complicated situation depicted here. Again, we have this zone of inhomogeneity with some complicated material and outside of it the space is not entirely homogeneous. Entirely homogeneous. It consists of several regions filled with homogeneous materials. Simplest case is illustrated here. You have another piece of material which is homogeneous, say this means constant coefficients. And then outside say empty space with coefficient one. With coefficient one. And then now, after this is a workshop about Draft's method, the kind of approach we would like to choose is fairly clear. In the homogeneous regions, we would like to opt for a Trefts approximation, whereas where there's a variable coefficient. As a variable coefficient, I would like to employ a finite element method. Apologies to Lise Marie, I'm not going for her quasi-trafts methods here. Well, I would like to use classical finite elements. And this of course raises the central issue of how to couple both types of methods. Both types of methods. Before I'm going to address this, let me first remark that, of course, the main focus of that project was on electromagnetics. I told you for the sake of simplicity, it's all scalar elliptic in this presentation, but everything has been done and extended to Maxwell's equations in the frequency domain as well. Well. And before I come to the coupling issues, I would like to elaborate some details of the draft spaces. And these are the draft spaces used by Christian Hoffner throughout his scientific career. You may remember the title of one of the books. In the title, there was Multipoles and it's Multipole Drafts. multipole drafts spaces that are used in Christian Hoffner's code, and that were the main tools for drafts approximation in that project. So, what is a multipole? Well, multipole is the counterpart for a harmonic polynomial on an underscore. On an unbounded domain. So, a harmonic function with a or a family of harmonic functions with a right decay properties and all of them have a singularity in an anchor point here. For this phi L, this would be a singularity in zero. Remember that we aim for drafts approximation also in this unbound. Also, in this unbounded exterior domain. There we need these multipoles. The 3D formula is this. It involves the spherical harmonics. Multipoles come as a family and they can be numbered and they have a characteristic order. Order a visualization just to give you an impression why they have been named multipole fields. Multipole fields are also known for the Helmholtz equation and of course they can also be found for Maxwell's equations. Equations structurally very similar to the multipole fields that we use for the Laplacian. In the case of Maxwell's equations, two families, radial and transversal. So these are the main building blocks for the draft spaces. And now there are two ways And now there are two ways to use multipoles to span draft spaces. The first approach is a slight extension of the method of fundamental solutions that we have already heard about in Pedro's presentation. When you want to approximate a harmonic function outside omega star, then Then you do this by a linear combination of multipoles placed at certain points inside omega star. I assume that these points are located on some curve. So this is the, I would say, the H version of the multiple drafts family. Family. Resolution can be increased by simply increasing the number of multipoles located on the curve. There's also a p-type family of multipole traffic spaces. Oh well, I should first, sorry, forgot this. How to choose that curve? In 2D. In 2D, using complex analysis, there are some very solid recipes. Look at that paper by Barnett and Petke. It's based on the Riemann mapping theorem. In 3D, not so clear. How did Christian Hoffner do it? Well, Well, his codes are sort of semi-automatic. He usually interfered manually and plays the multiples guided by his intuition. So, when I asked him whether this wasn't a bit too cumbersome occasionally, he told me. He told me, well, it would be much more cumbersome trying to develop an algorithm to do this automatically. In 3D, there is still no clear-cut recipe how to place these multipoles. The placement of multipoles is not such a big issue in the case of this p type family of multipole draft spaces that I've already mentioned. Spaces that I've already mentioned. Because for this family, you place all the multipoles in one point and you enhance resolution by increasing their order. So these are the options we have for multiple draft spaces. Now how do they perform in terms of approximation? Of approximation. Let's assume a nice setting that the function we want to approximate on omega naught is analytic and has an analytic extension beyond the boundary of omega naught. Domain of analyticity reaching inside omega star and then let's place some multipoles in the center. Poles in the center and see how well they approximate. There's no comprehensive theory, not really in 3D. But what you observe in this nice setting is exponential convergence in the number of multiples. There is, of course, some theoretical understanding. Some theoretical underpinning, which is fairly complete in 2D, and there are some results in 3D. The 2D results can be found in that paper with Andrea and Ilaria and Christoph Schwab. And they confirm exponential convergence. So we get very powerful exponential. Very powerful exponential convergence, provided that we have this analyticity beyond the boundary of the domain on which we want to approximate. And this is the necessity of this requirement is immediately clear when you do some computations. Let's look at some numerical results. Numerical results. This is the p-version multipole approximation of a function that possesses an analytic extension. And the H1 norm of the approximation error is nicely located on a line in a Lin log plot, exponential convergence. We see it here. We see it here. Now, let's place the function or let's choose a function that has a singularity right on the boundary of the domain on which we want to approximate. Here it was the unit square. So now the function we want to approximate cannot be extended analytically anymore. Extended analytically anymore. And immediately, convergence degrades. Instead of fast exponential convergence, we have to put up with merely algebraic convergence, which, moreover, is rather slow. So when the When the function that we want to approximate in the multiple Treft space has a singularity inside or on the boundary of the domain on which we want to approximate, then the powerful approximation properties of the Trafts functions cannot be used. They well, Trafts functions then do a rather poor job about approximation. Poor job about approximation. And this is now the main motivation for the coupling with finite elements. The electrical engineers, they frequently encountered situations where they had, say, three different materials coming together in a point or along an edge. And invariably, field singularities arise there. And they observe. And they observed that the multi-pole approximation codes, they did a very poor job in these situations. And so now the idea is, and this was also the main motivation for the last part of Peter's talk on Monday, that you resort to finite elements, maybe. Finite elements, maybe on suitably graded meshes, to resolve such singularities locally. And away from the singularities, then you can exploit the power of Traft's approximation. So now let's see the overall setting in which The overall setting in which this coupling should be done now, after we know about these approximation properties. So we know that Kraft's approximation should be done on subdomains on which the solution has an analytic extension. Let's look at the simple two-subdomain setting. If we chose, say, the boundary of this pole. Say the boundary of this polygon as the coupling boundary. Well, we would not be able to benefit from exponential convergence because we would certainly encounter bad singularities of the solution, say, at these corners. So, the idea must be to move the coupling boundary away from the single. Away from the singularities, so here away from this polygonal boundary of omega star. So we move the coupling boundary some distance into the region where we already have homogeneous material. Then call the outside domain omega naught. On that omega naught, we have a solution that possesses an analytic extension beyond. Analytic extension beyond the boundary of omega naught, and there Treft's approximation will be powerful, will converge exponentially. So it's an artificial boundary across which we eventually will do the coupling. So the drafts domain is outside the artificial boundary in this simple Artificial boundary in this simple situation and the finite element domain inside. What about the more complicated situation with the two homogeneous materials outside? Same idea. You should again move the coupling boundary away from possible singularities. So, again, move it into the regions of homogeneous material. In this situation, the final element domain, for instance, could be chosen like this. Then, at least on the drafts domain, so this pink one and of course the exterior domain, we would benefit from the existence of. From the existence of analytic extensions of the solution. Now, finally, to the core of the presentation. After the setting has been established, let's look at coupling strategies. We came up with several ideas how to do the coupling. And I'm going to present them all for the simple model problem. The simple model problem discussing advantages and drawbacks. First one is the DTN-based coupling. Simple idea, very natural for somebody who has ever looked at domain decomposition techniques. So we convert this PDE on the final element domain into weak form integration. Domain into weak form integration by parts. And this introduces a boundary term. Test space clearly H1 over the whole finite element subdomain. This is omega F. And now you see the Neumann trace of the finite element of the solution occurs in the boundary term. This is this gamma. We all know the transmission conditions for second-order scalar elliptic problems is the continuity of the solution and the continuity of the Neumann traces, the flux. And now let's use these transmission conditions. We use the agreement of Dirichlet data from both sides. Of Dirichlet data from both sides of the coupling boundary weakly and the agreement of the Neumann data strongly. That is, instead of the Neumann trace of the interior solution on the final element domain, we now plug in the Neumann trace from outside, from the Treft's domain. From outside, from the Treft's domain. This is what I would call strongly imposing because we really replace the functions. And the second equation now in this variational problem imposes the continuity of the Dirichlet traces weekly by testing. And what we end up with is a variational settlement. Up with is a variational settle point problem. What about its properties? At first glance, it doesn't look so nice, but now when you remember that for traffic functions you have this identity, it's clear that you can replace the the bottom right block with an equivalent volume integral here. Volume integral here. And now you see that you have a very nice blocks, Q-symmetric structure with positive definite diagonal blocks. And this immediately means that the ballinear form corresponding to this settle point problem is positive definite because of the block's geosymmetric structure. So very nice. And now when we do And now, when we do Georgian discretization, we immediately get quasi-optimality. Well, this was easy for the case of a single closed coupling boundary. The more complicated geometric situation raises difficult issues concerning the Concerning the weak coupling, what are the right function spaces? What are the right test spaces? I haven't got an answer yet. First open problem Well, I've already mentioned that Gajerkin discretization is more or less here straightforward. Let's look at this simple situation. Let's look at this simple situation where we have this elliptic bilinear form underlying the settle point problem. And so we can simply plug in conforming trial test spaces. So the traft space for the UT and the final element space for UF. So let's use some Lagrange final elements. Here, the Treft space. And then we have quasi-optic. We have, of course, the optimality of the Skyokine solutions in H1 norms. Very nice, very clean properties, but it's not clear how to extend this to more complicated geometric settings. Well, this is why we are not done yet. Maybe we need. Maybe we need another coupling approach that is more flexible. Let's look at this. This is a discovery from Pavia. Pavia also plays a big role in Treft's methods. So nowadays. A long time ago, Brezzi and Marini came up with a three-field domain decomposition approach, another coupling strategy. Another coupling strategy. What is it about? Neumann data are introduced as a new unknown. You're called lambda. The original Neumann transmission conditions are now both treated weakly by testing. And this results in the following saddle point variational problem. So the first So, the first is the big formulation of the P D on the final element domain. The second is the enforcement continuity of the Neumann traces in a weak sense. The second equation, because the first and the second. The first and the second combined mean that the Neumann traces all agree with lambda, and the third is then the weak way to enforce the continuity of U across the coupling boundary. So this again is a variational settle point problem, a bit more complicated than in the case of DTN coupling, but still amenable to a Still amenable to a full analysis, and this analysis shows that here the LVB conditions are satisfied on the continuous level to begin with. And then also on the discrete level after Georgian discretization, because we can also use the Trafts approach here for you to. Here. For UT, draft space. For UF, final element space. And now there's another issue how to discretize the Lagrange multiplier. What we did is we discretized it by the trace of the Lagrange in finite element space. And this results in a profably uniformly stable Garyokin discretization. Discretization because you have the discrete in subconditions also here. Sorry, now the more complicated situation with the say two trafts domains separated by an interface. There is a continuous three-field formulation. This is, in fact, the original domain decomposition approach by Prezzi and Marini. It involves another unknown, a function on the skeleton, that is the union of interfaces. This is here called T. And that function should be in the Dirichlet skeleton trace. Dirichles skeleton trace space, H1 half, so H1 half sigma, sigma stands for the skeleton, the union of all interfaces, is just the restriction of H1 functions on to that skeleton. So there's some built-in continuity here in this H1 half sigma space. And this gives us a lot of trouble. Because when you want to use draft spaces, Spaces outside the finite element domain, then it's not clear how to choose this H1 half sigma, how to approximate it. In particular, this is a challenge on the interface between the two traffic domains. I've thought about it, but I cannot offer you a solution here. It seems Solution here. It seems that also this coupling approach is not flexible enough to handle more general geometric situations because there's no clean or natural way to find the subspace of that H1 half sigma skeleton trace space. Well, so the search has to go. So, the search has to continue. And finally, we come to a coupling approach that has been used in computational engineering for a long time. Least squares coupling. In the very beginning, it was used for pure Trefts approximation. Say you have piecewise homogeneous. Say you have piecewise homogeneous materials and you want to employ Treft's approximation on all the subdomains. Then, well, a natural idea is to define the global solution as the local drafts approximation, minimizing the Dirichlet and Neumann chumps, or more precisely their skeletons. Or, more precisely, their skeleton L-tunome. And this is well established and well analyzed. Now, let's try a similar idea for the coupling of finite elements and thefts approximation. To begin with, let's look at the simple. Let's look at the simple situation. And here we can convert this least squares approach into a PD constraint minimization problem. So what we want to achieve is an agreement of the Dirichlet traces by forcing this L2 norm on the coupling boundary. Two norm on the coupling boundary, the two norm of the difference to zero to the minimum. What about the Neumann traces? Well, the Neumann traces we again take into account in this variational formulation. Note that here we have replaced the UF already with UT in the Neumann trace. And so we have a minimization problem with a variational, linear variational constraint. And there's a And there's a very powerful mathematical machinery to deal with such constraint minimization problem. So we can use this machinery and it's the say the theory of Lagrange multiplic multipliers and what it gives us is a var equivalent variational formulation. Equivalent variational formulation, optimality conditions in variational form. And this is the variational formulation that comes out of this PD constraints least squares approach. When you look at it more closely, it's nice. In subconditions are satisfied, and so we have existed. So we have existence, uniqueness, and stability of solutions, and also for the Lagrange multiplier. Well, I should have said this, because stability we don't have. Not in this formulation, because L2 is not the right framework. You may have suspected this because You may have suspected this because we take an L two norm of a Dirichlet trace and this is not the natural norm. The natural norm for a Dirichlet trace is the H1 half norm when the energy norm underlying your problem is H1. And so stability we can only get when we pursue this. Pursue this minimization approach, but now not in least squares sense, but by minimizing the H12 norm of the Dirichlet jump. And then you have the right functional setting to obtain stability. However, the A. The H12 norm is awkward, it's non-local. And so, for the implementation of this method, this is not an option. What Daniel implemented in the project was just the L2 norm, so the original least squares approach, with some age-dependent weighting, however. Remember, our motivation for looking at this coupling approach was the desire to deal with a more complicated geometric situation, the multi-domain draft approximation. Now, let's look at this. Here, the good news is that least squares coupling. That least squares coupling can be extended to this situation rather straightforwardly. So let's look at the detail. Now we have two Drefts domains, omega 1, omega 0, and both omega 1, omega 0 homogeneous materials, finite element domain. And we have the boundary of the final element domain called gamma. Called gamma and an interface between the two Treft's domains. And now the least squares coupling just augments the L2 norm of the jump across the boundary of the final element domain, the jump of the Dirich latrices, by By L2 norm of the jumps of the Neumann trace and the Dirichlet trace across this interface between the two traffic domains. And now this sum of norms is minimized, sent to zero, under the very same variational constraint that we have already seen, that ensures the continuity of the Neumann traces across gamma. Across gamma. And then you can crank the machine and it produces another variational settle point problem. Of course, affected by the same stability issues as before, because here we again use the L2 norm. The saddle point problem will again turn out to be much nicer in terms of mathematical analysis, in terms of stability. When you switch to the right trace space norms, h one half, h minus one half for the corresponding traces. Then everything is okay, but unfortunately this method is not suitable for implementation. So the least squares coupling approach in its L2 version. Version can deal with a more general situation, has some stability issues, but when you do some H-dependent weighting of the norms on the discrete spaces, there can be a sort of remedy. Now, finally, a coupling method that we have also seen in this workshop. I think this was the idea underlying the last part of Peter's talk. Coupling by DG. Let's start with the more complicated situation right away. Simple idea. Now the sub. Idea. Now the subdomains are Digi macro elements. The interfaces are this or this set of edges is just the skeleton. And then we can formulate a DG variational problem on this macro triangulation based on the usual DG. Based on the usual DG speak, say some ideas of jumps and averages. The various kinds of DG methods can be written down in this setting. I'm going to give you the simplest, the symmetric interior panel TG. And this is the corresponding variational formulation. And now it's already giving you this. I'm already giving you the discrete version. Inside omega F, we use as space the final element space, H1 conforming Lagrangian final elements. And in omega 1 and omega 0, we use dreft spaces. And we plug everything into the DG formulation. The dreft spaces make it possible to do another integration by parts and And remove the volume integral over the traffic domains. There, we only get boundary interface terms. And then we have the usual DG terms, ensuring consistency and symmetry, all on the skeleton, straightforward to implement, and of course, also the penalty term. And it turns And it turns out that the choice of the penalty parameter is not so critical. What we did is we chose it depending on when it was this penalty term was visiting the boundary of the final element domain. We linked alpha to the local mesh width on the interface between the traffs domain, we linked it to the multipole order used in the drafts domain. Drift domains. So straightforward, and this method can easily cope with complicated geometric arrangements. So you do DG on the macro triangulation and then some parts you plug in traffic spaces, in others standard finite element spaces. The DG numerical analysis just carries. The DG numerical analysis just carries over. I should add in the DG context, when we applied this to Maxwell's equations in frequency domain, then we used that Maxwell drafts DG formulation that Andrea, Ilaria, and myself had developed before. Works well. Works well, though I'm not going to give you any results about this. Now, finally, let's look at a few computations. One simple numerical test. So, H version of the multipole Treft approach, method of fundamental solutions, so the simplest, lowest order multipoles were used. Multipoles were used, lowest order final elements. And since we expect exponential convergence of the Trevis approximation, we link the number of multipoles to the logarithm of the number of degrees of freedom in the fine element space. And look at the L two error. And look at the L2 error and compare with a reference solution obtained by final element computations on a very very fine mesh. It was a 2D example. So set up the following. We have two materials, in fact two homogeneous materials in this case and And in the blue region, one material, and outside the blue region, another material. And then we employed that idea of moving the coupling boundary away from possible singularities. So the coupling boundary is the boundary of the green region. So it's moved into the exterior homogeneous region. So you see the final element mesh, and where you see the final element mesh, the finite element method was used to compute the approximation. Everywhere else, drafts. Drafts, lowest order method of fundamental solutions, and these small squares that you see here are Surrounding the blue region represent the locations of the multiple sources. So, this was this location was also chosen by hand here. Okay, this is the setup, and then We chose two different artificial boundaries. The first one was smooth, so rounded. The second one was just polygonal with corners, of course. Now let's see it. Let's look at the results. I'm only giving you the results for the DTN-based coupling. This is the simple situation, so all the coupling approaches. So, all the coupling approaches that I've outlined will work here, and all the coupling approaches perform in a very similar way. In one of the papers, you can find the results for the other coupling approaches. What we observe is convergence. So, multiples seem to converge exponentially with respect to their number because we Number because we linked their number to the logarithm of, say, the mesh width. Convergence is not really impressive, but this is due to, in my view, rather stupid choice of meshes. You see here you have this refined region, but they are not really graded meshes towards the corners as you should choose them. These meshes, as far as I remember, were These meshes, as far as I remember, were generated using some software package that was very rudimentary in its capabilities. So I should apologize actually for these meshes. They are not really good. And this is reflected by this not so overwhelming convergence rates. But we see some algebraic convergence and the methods work. The methods work. All right, and this has already brought me to the last slide, on which I would first like to refer you to the papers for more details, in particular details about application to Maxwell's equations. And then we also applied this. And then we also applied this to eddy current equations and put it in the framework of discrete exterior calculus. This is the most recent paper about Treft's co-chain calculus. Also the coupling of discrete exterior calculus with Traft's approximation. There you find details. A lot of aspects, in particular concerning numerical analysis, are still open. I've mentioned a few open problems. How to extend three-field and DTN coupling to the more general geometric situation in a way so that it can be implemented easily. And the analysis of the coupling approaches, even in the simple setting. Approaches, even in the simple setting for Maxwell and Helmholtz. I would also like to communicate my recommendation concerning the use of Traft's method. What I've learned in this project, what I've learned from the electrical engineer who have used Traft's method for many. Traft's method for many applications for a long time. Traft's method can really make a big difference if you apply them as spectral approximation, P-version. So this is one of the take-home messages that I got from this project and that I would like to communicate. Use, if possible, a piece. Possible a P-trefts approximation. Then you can benefit from fast exponential convergence if you have this existence of analytic extensions and then it really pays off. I've shown you several coupling approaches, but I don't want to compare them here. To compare them here for the simple setting, they all worked for more complicated settings. We had not managed to adapt some of them. Others work, do a good job also there. Not clear what is the best. I'm personally rather in favor of the DG coupling because it's very versatile, general. But But the engineers are more fond of the least square space coupling, I have to add. And then, of course, a persistent problem, placement of multipoles in 3D. So this is still open. Now, with Christian Hoffner retired, there are not so many people left who have this magic intuition to place the multi. To place the multipoles for a concrete application and then to obtain excellent simulation results. All right, that's all I've got to say here. This is the end of my presentation. Thanks for your attention, and I'm happy to answer your questions now. Thank you. Thank you, Ralph. Could you hear me with this microphone correctly? Ralph, you could hear me with this microphone? I cannot hear you very well. You should use the speaker's microphone. This is one. Okay, now it's now I can hear you well. Co could you hear me, Peter? Yes, now it's good. Okay. Uh this is why I was checking. Thank you a lot for this talk. Uh we'll Thank you a lot for this talk. We do take the question. Perhaps we start online. Igor? I will read it. Oh, yes. Thank you very much, Ralph. Since you mentioned Christian Hafner devoked some memories from the distant past, a colleague of mine from the old years, by name Mikolaj Gemeshi, I put the reference to that paper in. The reference to that paper in the chat. The title is Hybrid Finite Element Traft's Method for Open Boundary Problems, and it's 1996. And I should maybe mention also that, well, first of all, Nikolaj, unfortunately, is no longer with us. My name is in that paper, but that's an accident, so I contribute absolutely nothing to it. And the state of the art, of course, was very different in 1996 from what it is now, but I think in some sense this was kind of a little ahead. Since this was kind of a little ahead of its time. But well, the question that I have just to get myself oriented in the method that you presented or different coupling methods, are they, if the DG version of that, would that be different from what Peter presented on Monday? The DG version I presented was this simple symmetric interior penalty variety. What Peter presented is What Peter presented was the ultra-weak variation of formulation. Well, under certain assumptions, it can be recast as a DG method, but with a different so-called numerical flux. So the structure is the same, the kind of penalty term and the symmetrization and consistency terms are a bit different. So we use. So we use this kind of DG methods for the electromagnetic field computation in frequency domain. And then secondly, in Christian's method, apart from the placement of the multipoles, there is also the placement of the collocation points. And I think that was a weak part of it, Red, because that leads to instability and also there is this art of choosing the collocation points. So I wonder if there is. So I wonder if there is, as far as development of his codes, if that has been mitigated in some way. I have not addressed this kind of coupling method here, because what you are referring to is, in a sense, the least squares coupling, where these integrals over the skelet are discretized by numerical quadrature. Then you get a sort of Then you get a sort of pointwise coupling that can be also viewed as a collocation method. I think in Christian Hafner's code, he used a QR-based solver for the systems. Of course, also the multipole-based traps method, they struggle with the sometimes intrinsic instability of Instability of the basis. But this was not due to the choice of the collocation points, as far as I remember. So this falls into the class of the say least squares, couplings, plus quadrature. This is the collocation approach, but it's, I don't remember. Remember that it was affected by unusual instability. Whenever you use Treft's method, you have to take care that the choice of basis does not lead to very ill-conditioned linear systems. But the multipoles do a rather good job about this because they are related somehow. Because they are related somehow to generalized harmonic polynomials, and those are known to control ill conditioning rather well. Thank you, Ralph. Thank you for that. I can't hear the question. The question is coming in. You have to use the other mic. The speakers. To use the other mic, the speaker's mic. Only this one works. Can you hear me now? Yes, very well. Yes. Thanks for the great talk. For me, I wanted to ask, first, you have a sharp interface problem that is static. Either we relax the sharp interface maybe to not sharpen. Not sharp, to be more smooth. And then the interface is maybe moving. Can some of these approximations or techniques or couplings that you described be applied to such a scenario? Well, I should point out my interface was an artificial interface. Whenever there is some, say not a smeared interface. A smeared interface, so a coefficient varying continuously. Then you have to put all this into the fun element domain. Draft's domain cannot handle this. This is why it's important to use this artificial coupling boundary away from all these complicated physical interfaces. interfaces. So the interface is sharp, but the interface is artificial. Okay, so if this if this basically domain that the singularities happen happen to grow somehow, so your artificial domain needs to be expanded, move, then can this technical. The singularities are located at the corners here in this simple cartoon and And well, of course, I assume that the geometry is sort of fixed. So, anyway, the model problem is stationary here. And so, there's no movement, and the singularities are there, but they are fixed. And even in a frequency domain problem, the location of the singularity is already known a priori. So, the choice of this. So, the choice of this artificial coupling interface can also be done more or less a priori, and it will not change depending on the data. Does this answer your question or explain the idea concerning the artificial interface? So I have a just I missed at the end. You had two scenarios, one with a smooth interface and one with a square interface. Whi wi did was there any difference in performance? Difference in performance? Okay, so since the artificial interface is located in a region of analyticity, when you have a corner of the artificial interface, it does not trigger any singularity. And then when we look at the results, this was the smooth interface. This was the smooth interface, and this is the polygonal interface. There's no difference. Okay, thanks. That's what I thought, but I just wasn't quite sure. Thank you. And this is great. You can get away with choosing a simple polyhedral polygonal interface. Yeah. We have another question. Two or three. Hi, Ralph. It is Bruno at around the Ralph, it is Bruno speaking. Yeah, great to see you, even if it is quite far from okay. But okay, concerning your conclusion, suddenly it reminds me that I myself implemented a method of with multiple methods with fundamental solution in Maxwell in 3D some years ago, and the problem is. Ago, and the problem was exactly what you have mentioned. I mean, to know for a domain with corners, a scattering domain with corners, exactly to place the multiple functions or the fundamental solutions somewhere where I can get both accuracy, general accuracy, this you have commented, but also correct accuracy near the corners of the object. Of the object. And it was so difficult. So, after four months, I decided to stop the research and to send everything to the trash because it was extremely difficult. So, I didn't find any way to control anything. And also, of course, the numerical analysis of this traffic method. The numerical analysis of this trust method was not absolutely not at the level at which it is now. So essentially, there was no tools to try to... So it is a very difficult problem. My own experience, I confirm that. But my question is the following. So of course, in this electrical engineering you are working with, there are problems with the stability of the from time to time. Stability of the from time to time, of course, of these matrices that they have to invert because there are near spectral accuracy or whatever. So, what do they do in terms of controlling the stability? Do you have some information? Do they have a specific algorithm? Do they have specific procedures to practically control the stability of the numerical methods? Yes, I can tell you what. Yes, I can tell you what was in this project. What we used is a sort of direct solver for all degrees of freedom associated with the drafts domain. And this worked reasonably well. So the direct solvers could handle the ill conditioning. And of course, we tried to avoid choices of basis or orders of multiple. Of bases or orders of multipoles that could no longer be handled. This was also the recipe that Peter advocated in his presentation: don't overdo it with the resolution of your draft space because otherwise ill conditioning will hit you. So this was the first thing. Then what Christian Hoffner did is he used he did not use the least square. Use the least squares approach, leading to a symmetric matrix in the sense of normal equations. He used the collocation coupling conditions that were implemented in his code as just raw equations. Then he had many more equations than unknowns and then used a QR solver. Solver to compute the solution of this linear algebraic least squares problem. And you know, when you forego the normal equations for an algebraic least squares problem and go for QR, then ill conditioning is no longer such a big problem. Then you can get away with poorer choices of basis. Poorer choices of bases than in the normal equation approach. So, this was Christian's trick. He used then a dense linear algebra QR factorization to solve this collocation coupling equations. Th thank you, Ralph. It was very interesting. And uh the question enrich a lot uh the talk. So we will have a twenty minutes break. Will have a 20 minutes break to have a coffee and then no, I was thinking it was a no, it's Elaine's talk now. I have a I have a programme, but it is the old one. Now we'll go uh to Elaine. Okay, so now is the time for Elen. Which have 30 minutes also  I think not sure because my voice is the same. It's okay. Hola hola, hola, hola.  Let's try it in there now. I will if necessary, I will use use the data. Oh, no one's and the operator is here. Okay. Okay. Okay. Okay. Thank you very much. Okay, so I hope that you are ready for out-of-scope talk. Of scope talk, and there is a call because I will talk about HDG approximation, which is not a trust method.