Alex's talk this morning and Tamson's talk because I'm going to address some similar themes but in particular for Greenland this time. And so this is work that was done primarily by Andy Ashbonden as well as some other folks at UAF and some other places. I'm going to start with results first and so here's our And so here's our sort of best guess for how likely some given portion of Greenland is to be ice covered in 3000. So white in this case means that there's more than 84% probability that this region will be ice covered in 3000. Clear is less than 16% probability of ice coverage. And light blue-ish is like is like Is like 50-50. And of course, we might want to know how this changes depending on what people do in the next thousand years. So there's a different scenario here for RCPs, 2.6, 4.5, and 8.5. And underneath that, of course, is a velocity field. In particular, this is like maximum likelihood. Maximum likelihood velocity for different potential configurations of movement at the year 3000. And so we can see that under 2.6, there's a pretty reasonable probability of some marginal retreat here in the southwest and the north. Jakob Savan has sort of peeled back from the margin a bit. Maybe we're going to Maybe beyond 2100, you just kept forcing constant? Yeah, we did a bit of extrapolation. We linearly extrapolate until 2,500 and then it becomes constant thereafter. Yeah, for sure. And 2.5 is pretty mild in terms of retreat compared to 4.5, as you might expect, where there's pretty significant retreat with high probability. Significant retreat with high probability. You know, instead of having Jakobsavan Ispora, we have the Jakobsauvan coast now. And then same with northern Greenland. And then for RCP 8.5, the ice sheet isn't really recognizable in the year 1000 anymore. And in fact, there is no location outside of the high mountains like Gunbjöngel. Like Gunbjörngeld that has ice with probability greater than 50%. So there's not really much to say about the velocity field there because the most likely situation is ice-free in the year 3000 for ICP 8.5. So these are sort of the results of this talk. The rest of it is going to be about answering the questions, how did we get these pictures? How did we get these pictures? And how, in the future, can we reduce the remaining uncertainty that exists in making these sorts of predictions? And so here's a schematic process, which is essentially to do what everybody does with ensembles, which is to define some priors on unknown model inputs. Here we have them grouped into a couple categories. Sample a pretty big number of samples from those distributions of model inputs, run them through an IHG model, come up with a bunch of different potential realities, and then try and compute some statistics based on all those different ensemble members having been run through the ice sheet model. And so, first, let me tell you about the ice sheet model that we used. Tell you about the ice sheet model that we used. It's PISM. In particular, it's PISM forced with a Hearham simulation of regional climate. And of course, solves an approximation to thermomechanically coupled Stokes equation supplemented with some equations governing things like subshelf melting. We have a bomb-myces stress. We have a bomb-myces stress calving law in this particular simulation and a pseudoplastic sliding law, which you see here, which also depends on a non-conservative hydrologic model to sort of get some sense of a spatially varying effective pressure. It's a pretty simple model as far as hydrology goes. Hydrology goes, but sort of better than nothing, particularly given that we're going to be doing long simulations of this thing. And in this model, all our parameters are going to be global across Greenland. There's no sort of spatially varying basal traction or anything like that, because that's not necessarily defensible over long time scale sort of runs. Long time scale sort of runs. We'll run this thing at a 900-meter resolution everywhere. We've since updated that to 450, but for now we're doing 900 meters. And we are using as a basic topography model BET machine version 3. Okay, so now let's talk about the parameters and The parameters and forcings that we will use to inject uncertainty into this model. And like I said, they occupy roughly four groups corresponding to sort of climate uncertainties, uncertainties in parameters associated with surface processes, parameters associated with ice dynamics, and parameters associated with ice-ocean interactions. So we can go. Interactions. So we can go through each of these groups individually. So here's our climate group, and in particular, there are two parameters here. One, I use the term parameter roughly. The first parameter is a switch, which randomly switches between which global climate model we derive a temperature anomaly from. So there are four of them here: GISS, E2, H. SS, E2, H, and some other nice acronyms. But each one of these sort of global climate models yields a 300-year projection of temperature anomaly. And we switch between which one we use sort of randomly. Additionally, there's a random parameter that varies between 5 and 7% per Kelvin. And seven percent per Kelvin that tells us how much precipitation changes as a result of warming temperatures. Now we've also got a sort of surface processes group. This primarily corresponds to positive degree day factors and the fraction of surface melt that's available for recruiting. So these are all uncertainty. Uncertain, they've got their own sort of a priori defined probability density functions associated with. Probability density functions associated with them in this case. Truncate, we're modeling them as truncated normal distributions. But that's a choice, right? Like, you can choose whatever you want here. These ones seem to be reasonable. We're fairly careful to try and come up with sort of sensible distributions of a priori parameter values based on the literature. Sure. Our third group is sort of oceanic considerations. And so we've got a couple of sort of ensembles of parameters that are related to spatial and temporal heterogeneity and sub-shelf melting, minimal ice thicknesses for ice shelves such as they are in Greenland, and also the maximum stress. Maximum stress for our von Mysis catting criterion. And then finally, we've got a couple of uncertain parameters associated with ice dynamics, which I think maybe is, well, a sliding law exponent and an enhancement factor. So stuff related to how fast the ice moves. And let's see, once again. Let's see. Once again, we just draw from these prior distributions via some low discrepancy sequence type method. This says Latin hypercube that's outdated. We're actually using Sobol sequences now, and I'll tell you why in just a minute. This 500x is also outdated. We now have ensembles of 4,000 of these things, which doesn't appreciably change. Things which doesn't appreciably change the results compared to running 500 ensemble modes, interestingly enough. But in any case, we run a bunch of experiments based on random draws from, well, pseudo-random draws from these probability densities, and we get this nice map like I already showed you, which maybe is more interesting to look at in a sort of spatially integrated way. Integrated way. And so here is the C-level contribution. Let's see, these are 5%, 95% credibility interval envelopes here for the different RCP scenarios. And we see that what you would expect that for RCP. For RCP 2.6, we get 1 to 2 meters of sea level rise after 1,000 years. RCP 4.5 produces 2 to 4, and RCP 8.5 produces between around 5 to 7, but it has a somewhat different qualitative pattern in terms of when that sea level rise is produced. And because of the fact that around 2500, some of the simulations start melting the entire ice sheet. Start melting the entire ice sheet. Okay. So, of course, a natural question to ask is the attribution question, which is to say what drives the width of these posterior predictive distributions? And as it turns out for us, this is a tractable question. So, first, let's take a restriction. Let's take a restrictive view of what an IG model is, which is to say it's a simple function that takes some uncertain parameters and outputs a scalar value, like, for example, sea level rise contribution. Then if we decompose this function via non-sats into something that looks like this, if you do that and then make an assumption about the orthogonality of the individual terms. Orthogonality of the individual terms. Turns out that these individual terms have to look like this, which is to say some perturbation around a mean value of the predicted variable. It's called the syllable decomposition. For our purposes, we're going to eliminate higher-order terms in this decomposition and only look at sort of the only look at sort of the sum of the expected value of mean sea level rise and the individual function inputs, namely our insert parameters, their individual non-interactive contributions to that same value. And now if we assume that this function decomposition is square integrable, which it is. Square integrable, which is, if you square integrate it over the independent variable distributions, you end up with a sum that looks like this, which is to say that the variance in the model output, in our ensemble, is a sum over our various, well, terms associated with our various. Well, terms associated with our various input parameters. And what are these various input parameters? Well, each of these terms in the sum represents for a given parameter, how much would total variance in our prediction be reduced if that value were known exactly? Or alternatively, how much of this total variance is attributable to variance in the input parameter, which I which I posit is a useful thing to know because if we then normalize by this left-hand side, we get this thing called a first-order Sobel index, which tells us the fraction of the output variance that's explained by the prior variance in an unknown parameter, right? It tells us how much of Greenland sea level rise contribution is attributable to a lack of knowledge. To a lack of knowledge of the sliding law exponent, for example. And as you might imagine, computing these things analytically is intractable for models such as these, but for a judicious choice of parameters, samples, we can take sample statistics in order to come up with an approximation to these different variance terms. And what these give us. And what these give us is sort of a table that tells us what we need to do better to reduce uncertainty in predictions of things like sea level rise. And maybe the most important thing to come out of this plot is that surface uncertainty and surface processes, degree day factors, things like that, matter a lot in every simulation. Same with ice dynamics. Same with ice dynamics with a caveat. What you choose in terms of climate forcing matters in the middle, less than the other two. And how well you know these oceanic parameters and green land makes them matter very little in terms of predicting rise. And that's at all time scales. My quick question on this. Is it clear why its time variant depends on different scenarios? Is it clear why reduction of uncertainties depends on what the scenario and varies for different times? I mean, is it an obvious explanation? I would mainly thought that that would be a constant, or just it doesn't Be a constant, or just it doesn't wouldn't vary with time or something. I'm not sure I know. I'm not sure I know the answer to that question. Yeah. In your model domain, how well are out andacious you show? It's a 900-meter resolution model, so pretty well. Reasonably well. I mean, not up to 900 meters. And you would argue that the biggest insert. And you would argue that the biggest uncertainty is this as false. In this case, yeah. Yeah, for sure. Depend depending on the time at which you look. Here, let me actually look at this next slide, which is maybe easier to understand in terms of answering that question. This gives us the proportional influence of each of these sort of parameter groups about three parameters. Just wondering how important all the cases are. Yeah, sure. So what I'm getting from you is that you have it in your domain and you can find the certain must files because it wasn't important. In the long term. Don, can you go back one slide? Does this matter what ice dynamics parameters are? Well, these are Uh these are um what are Q and E? Q is the sliding law exponent and uh E is an enhancement factor. And why the sum is not ever always one of the sum of all these functions? Because there are interaction terms that we're ignoring. Yeah, so if you were able to in fact We were able to, in fact, keep higher-order sobal indices, which give you the sensitivity of some output to the combination of Q and E, and also the combination of Q and E and F sub I. You know, if you could actually take that infinite series, then it would sum to one. But since we're just using first order effects here, we lose that sum to unity. Doug, are the Doug, are the sofal indices normalized by the width of prior distributions on the parameters? Right, so for a lot of your parameters, distributions, you're picking a uniform distribution, right? Yeah, okay, so de facto, in order to sort of make this analysis work, you have to rescale all those distributions to the unit interval anyway. So, yeah, there's an Um so yeah, there's an a priori re rescaling that goes on here before computing the stuff. And is there a way to understand these numbers relative to the prior width on that unit interval? Right, so like let's say parameters, some parameters are more uncertain than other parameters. Okay. And is what we're seeing in these numbers reflective of that, or is it reflective of basically how? Of basically how. Oh, it's totally reflective of that. Okay, yeah, for sure. So, anyway that we can disentangle this? That's a good question, and I don't know the answer to that. Like, I think, correct me if I'm wrong, what you're sort of saying is that maybe you have a parameter that's really important, but we have, for whatever reason, given it a very narrow prior to begin with. When you look at sort of the effect of that or try and quantify the Trying to quantify the fraction of sea-level rise variance as a function of that, it's going to be really small no matter what, because you chose maybe some stupid prior distribution that's way too small. Yeah, that assumption, this whole analysis sort of hinges on the idea that the a priori specification of parameter uncertainty is the correct one. And I don't, in an obvious way, know how to. In an obvious way, know how to get around that problem. Sorry? Which one? This one? No, no, the one. This one? Okay. So the fact that, like in the last one, variance is not 100 means that E terms that are more important as you're interactive terms that are missing. Yeah, for sure. Missing. Yeah, for sure. But yeah, I don't know. This is kind of a nice plot to look at. It basically says the same thing as the table that I just had, but in a more intuitive way, which sort of indicates that to start off with, if you want to get an accurate estimate of sea level rise out of Greenland in 2100, the thing that you should be paying attention to. The thing that you should be paying attention to is improving parameterizations of sliding or reducing a priori variance and what you think sliding law parameters are, or enhancement factors. And it turns out to be sliding law parameters. But after that, it seems to be the case that, and maybe this isn't surprising, the ice sheet turns into a machine for moving mass from the surface. Moving mass from the surface to the ocean and how it does that starts to matter a lot less over the long term, right? And in that context, parameter uncertainties associated with climate and the surface mass balance that comes from that climate end up sort of governing the behavior of the model relative to ice dynamics. And interestingly enough, whether it's because of a misspelled Of a misspecification of uncertainty in oceanic parameters, or because there's just not that much of Greenland in contact with the ocean, these ice-ocean interaction parameters, uncertainty in those don't seem to have that much of an effect at any time on Greenland's contribution to sea level rise. All right, so that's all I've got to say about this. Got to say about this. So we ran this ensemble. The ensemble results suggest a higher Greenland ice sheet level sea level rise contribution, unsurprisingly, but uncertainty is relatively high still. Uncertainty in glacier change predictions this century is primarily due to uncertainty in ice dynamics, and beyond that, centennial scale, climate and surface melt rates seem to be the thing. Rates seem to be the thing that we should focus on if we want to bring the sort of spread in sea level rise prediction numbers down. Thanks. Questions? I have a political question. Yes. Which is, us ice sheet modeling people depend on the climate, the atmospheric climate community for providing stuff. Yes. And in this case, And in this case, I know what we've depended on is Regina's familiarity with degree day models, to choose which parameters to look at and even how to model the surface balance. My political question is, whose responsibility is that? Who matters what you think? I don't have a clinic. Whose responsibility is it to model what matters to the glacier, namely the surface mass balance, as opposed to the quantity that are currently coming out of ambassador model? Whose responsibility is it to model that? I think the people that are primarily accustomed to doing that and are good at it, perhaps with some feedback from us with respect to the sorts of things that we need to make our models better. I guess would you prefer to put all the uncertainty into the climate inputs, that is to say, instead of the climate? Climate inputs, that is to say, instead of having a choice of four, you're going to have a choice of many more because there would be choices on the climate model side of how these mass mass is computed, as well as changes in precipitation and temperature. I would prefer everything to be done as explicitly as possible by the climate modeling. uh climate modeling groups so that I can simply take the numbers that they give give me and and run analyses like that with them. I don't know if that's an answer to your question. I don't either. That's sort of the answer I've come up with too. I don't want it to be my responsibility is what I interpret that is. Yeah, I mean like it doesn't make sense for for me as like a person that I mean I didn't even look at That, I mean, I didn't even look at PISM source code, I just, you know, typed out some ensemble numbers and ran some models. It doesn't make sense for me to say, all right, based on these conclusions, I'm the person that needs to go and adjust the surface mass balance models. That wouldn't be a very sensible division of labor, maybe. So, I don't want to derail the discussion of questions, but this might be a good topic for later on, just like a more general discussion of who's responsible. Discussion of whose responsibility it is the ice sheet community or the ocean or the atmosphere to do these things. So maybe they're all time. This afternoon was timely. This afternoon. Really naive question. You obviously have the input from the climate community to do this for a thousand years. What about the last thousand years? Could you, I mean, it would be, it would just sort of be, well, from my standpoint, it would be interesting to see, could you do the same exercise going from what? Going from what sketchy information we have for 300,000 years ago to present day. Yeah, to do this same exercise in a hindcast sort of context and see if that, well, for one, if the resulting distributions are true. Yeah, I think that that would be a great idea. The the previous Rashford in the handwritten title. Is the first word in the title. Your simulation essentially went up to 3,000 years, right? Sorry? Your simulation is going up to 3,000 years. 1,000 years. I guess I'm a little bit surprised that is static adjustment isn't starting to play a role as you go out that far. Yeah, it probably is. I don't think that we are really looking at that effect very closely in this case. Very closely in this case. It shows up in this model, but we're not like there is no parameters to vary associated with it for us, although it certainly could be done in that way if we feel like that's an important sort of uncertainty source to consider. Presumably that would only reduce the influence of the ocean. Yeah. No, no, for sure. Right, yeah. Right, yeah, for sure in this contact with the ocean. But it could have a feedback with the mass battle. Yeah, yeah. Well, in a small way, presumably you can have erosion at the base, so that the base that you put in now is presumably not the base, you should be putting in at the bottom. That's another hard modeling problem. So, presumably, there's sort of two components to the uncertainty due to the choice of climate model, one being the The choice of climate model, one being the climate sensitivity of the climate model, which you, when you showed sort of the different climate models, obviously they have they all seem to have very different climate sensitivity, but also presumably due to the internal climate variability. Right, so do you have a sense for how you can think about pulling that out here, right? Right. Because those are two different those are two different sorts of things. Yeah. You can bias correct the climate sensitivity apart. Yeah, that feels dangerously close to me doing climate modeling. Right, like trying to. But could you use this ensemble to provide an answer to that question of how much of the difference between the ensemble numbers is coming from? Between the ensemble numbers is coming from the fact that the climate model inputs just have like a different mean temperature versus different very like the exact trajectory of climate that you're putting in is different. It's a good question. I don't know how you would necessarily do that given only one instance from each climate model.