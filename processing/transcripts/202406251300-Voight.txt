You know how to do it. Uh in here. There we go. Someone know how to turn off somehow like settings and captioning. Captioning. Oh, it's already worked. Yeah. Okay. Then I'm not doing anything. Okay. Then another related thing. So, are you people ready? Let me say they're ready. So please share. Go ahead. All right. Thanks, Alessio. You guys can still hear me? Yes. Okay. I'd say it's great to see everyone, but you're so small on my screen. I guess I will say it's good to see you in aggregate. And thanks for letting me. Thanks for letting me Zoom bomb your meeting here. I'm tuning in from Italy and am not able to attend most of the week because I was double booked at a workshop here, number theory and physics in Triesta. But still, but still, the organizers were so nice. They invited me to speak to you anyway. And so thanks for squeezing me in. I do hope I'll have something interesting to say to add to the workshop. Understand you guys are really interested. Are really interested in understanding computational geometry and pushing the boundaries and crossing the threshold and whatever else we want to say that's analogous. So I was inspired by that. I'm about to cross the threshold, the threshold being the equator, moving down to Australia. I don't officially start until August 1st. So this is like a practice. This is like a practice. Like, I'm not yet in charge of anything. Let's put it that way. So, I'm really, well, I hope to give you some sense of computational geometry in magma. That'll be the first part. And then in the theme of the workshop to say something about parallelism in magma, it's all of a demo sort. So, I really, even though it's hybrid and a little awkward, I hope you'll interrupt me if you have a question. I hope you'll interrupt me if you have a question. I think probably the best way is to just shout it out because I won't be able to see your hand or anything. And that's the goal, I guess, would be to invite discussion, help us understand what we're doing, and fuel the discussion session that Alessio will lead us in. And maybe I think I'm involved in that too, immediately afterwards, where we talk about HPC, which is related to parallelism, of course. Which is related to parallelism, of course, and maybe even the problem session. Okay, all right, so I looked at the participant list, and I think that many of you are in the magma fold, if that makes any sense. But still, I thought I would practice enunciating what magma is, should be, could be, just to see how it sounds out loud when I vocalize it. So see what you guys think. So in a nutshell, I think of magma as being a computer algebra system. Magmas being a computer algebra system whose primary focus is computations and algebra number theory. Algebra number theory. Okay, maybe I have to edit this. I can do that as I go. In fact, though, it has a lot of functionality and everything else that's connected to that. So that's combinatorics and group theory and on and on and on. One thing that I also want to take just a moment to say thanks to Niels Brown and Edgar Costa. I don't know where you are, if you're in the room or online, for making this Jupiter interface to the magma kernel. I've never given a talk like this, but I do hope that it works. So thanks, guys, for that. So a magma, the reason why it's called magma, I'm told, is because a magma in the sense of Bourbaki is a set with a binary operation, and that's what everything in mathematics. Binary operation, and that's what everything in mathematics is built on. So, that's so too should our computations be so framed. And the thing that Magma tries to do is to provide a mathematically rigorous environment with highly efficient algorithms and implementations. And those two things are often at odds. Maybe the most, the fastest algorithm that you can dream on about has not, there's nothing you can do. Has not, there's nothing you can do that is rigorous about it. And conversely, maybe the most rigorous algorithm that you could imagine is not gonna be efficient. So, the way that I have used magma is trying to, you know, given that those two variables are subject to a constraint, to try to push where it will be really useful. So, we want theorems very often that are computational in nature, but we can't wait because we're impatient. Okay. And the way that we do this is that the highly efficient algorithms. Highly efficient algorithms and implementations, the things that are called frequently at the low level in the C kernel. And then to provide advanced functionality, there's an ever-increasing package of library functions that is meant for higher level aspects. And there is a handbook that is supposed to provide not just adequate documentation, but inspiring examples and links to. Examples and links to the mathematical literature that really tries to see this type of thing as being well integrated into the life of a research mathematician. So one thing that I was taught when I was a postdoc at the magma group 19 years ago, this is the Kool-Aid that was poured down my throat. Is the mathematical model that underlies magma? And they really Magma. And they really did try, even at the very founding, to think in category theoretic terms. Every object belongs to a unique category. Sometimes those categories are extended in the sense that they have extra structure. And we even group together those categories into the next level up, which unfortunately is called a variety. I'm not sure that that's the right word to use in this audience. So I don't mean variety in the way that you're thinking. It's just. The way that you're thinking, it's just, you know, the thing that contains the categories. We need, okay, you could call it a two-category something, but it's really grouping those things together. And they're based on something useful, like they have the same representation in bits, or they have something that they can use in common. So each one of those objects has a unique parent structure that describes the mathematical context in which it's viewed. And the basic example is univariate and multivariate polynomial rings form the categories ring u. Form the categories RingUPAL and RingMPAL. I think these should be with little dashes next to them. Do you ever get annoyed when people fix their typos during the talk? I don't know. Is it better to leave the typos? Okay. And the RNG, the ring, is the variety that they live in because univariate and multivariate polynomials have certain features in common that can be used. And sometimes, for example, you might have a univariate polynomial ring over the Variant polynomial ring over the whose coefficients lie in the integers. And then you have this bracket ring int. And then a parent of a universe of a polynomial will be its polynomial ring. And that is almost type theory in the way that we understand it in a modern context. It's sort of a version of that that's trying to achieve some other effects. And they frame it in terms of sigma algebras. And isn't that great? That's the magma model. Okay, this is natural pause. Okay, this is natural pause just to see how the question and answers work. Do you guys have anything you're curious about? So far. Okay, good. I'm going to see if this link works. Does it, can you guys still see the screen? Yep, yes. Okay, so the page load. Yeah, great. Okay, so I guess we're not all algebraic geometers because we could understand geometry quite broadly, convex geometry, arithmetic geometry, and so on and so on. Arithmetic geometry, and so on, and so on. But this is an example of a page from the types of things that you might want to do. And so I'm going to demonstrate, I think, some of these that are my favorites. That doesn't, you know, I encourage you, if you've got your laptop open, to also go to the handbook and play around, or you could follow up with my example as you like. But like, I don't know, there's a lot of work that was put into. Of work that was put into algebraic curves and to schemes, and they don't always talk to one another. There's a lot of stuff on algebraic surfaces, but it kind of assumes that for the advanced functionality, that you're a hypersurface in P3 with not too bad singularities and on and on and on. So those are the types of things we could talk about if we want to. But let me just show you some of the things so we get a sense of it. Okay, so maybe in the beginning there are monomial schemes. I guess we all learn about those at some point. We all learn about those at some point. So let's see how you might do that in Magma. Apologize if you've seen this before, but hang in there. I'll show you some parallelism, and I hope you still enjoy seeing some examples. So we start by defining an affine space over the rationals. And so that's our A. Schemes are defined in a way that I hope is clear. Inside the affine space, you define a sequence of polynomials. Polynomials. And the most basic types of invariants. By the way, is the font size okay? Okay. So here are the basic types of things that you might ask about your scheme. What is its dimension? Is it reduced? And then what are the primary components? So the answer is: the dimension was two, it was cut up by two things. It is not reduced. And it's got It is not reduced, and it's got these primary components. There are three of them, one of them is X, and here you see one highly non-reduced scheme in the middle. So, those are the type of, and the rest of the things that you're kind of used to that can be computed with a Grobner basis calculation, which I'll have a bit more to say about, is available. So, let's play around, I guess, a bit with this sequence of primary components. As usual, As usual, you access things with index with brackets. Magma starts at one, and you can do things like: so you take the first one of these components, which is cut out by X. It has its prime components, the ones that it lists to. So this was like the underlying prime scheme, and then these are the other prime components. And the X reduced is this one here, the X Y X Z. The x, y, x, z, that's the underlying reduced prime components of x. And then you look at the reduced subscheme, and I guess you see how this x, y, x, z is really the intersection of x and y, z. All right. What else can we say here? It returns things like the inclusion map from this F that we computed gives the inclusion of the reduced subscheme into the subscheme. I, the sequence of polynomials that defines it, is described as follows. So it remembers all of this information. It caches it along the way, so it'll never have to compute. So in particular, it remembers things like the dimension and these other predicates that we checked on. One thing that I always struggle to remember the name for is how you recover. Remember the name for is how you recover the ambient ring that describes the ideal. And for some reason, that's called generic. Sorry about that. And you can also define the sub-scheme of projective space that you get from this homogeneous ideal rather than the affine space by defining proj R mod I. So that's sort of basic functionality for schemes. All right. Now, a lot of this infrastructure relies on Grosvenor Basie. Relies on Grosvenor bases. So let's play around a little bit with that. It'll also be some good setup for parallelization. So here is, well, what I was told is sort of a really important practice ideal for understanding how Grosvenor basis algorithms work. It's the cyclic six ideal with respect. It takes the lex order by default when it computes a Grosvenor basis. But anyway, so you take a polynomial and six variables and you write down these six symmetric functions together with this set. Together with this setting the product of them equal to one. You can think about this as defining like the coefficients of a polynomial with these as roots. I guess I felt bad already writing out polynomials like that. So I decided to show you a little bit about how you might try to, if you had to do this for a high, I have some function below that does it in general, but here's the type of That does it in general, but here's the type of thing that you could do to also recreate those functions by taking one of them and shifting it by the cyclic permutation that's evident. So you define this homomorphism from P to P, the polynomial ring, just by shifting the variables accordingly. And so sigma of x is y, and sigma y will be z, and so on. And then to make the generators for your ideal, you just take each one of these monomials, x, x, y, x, y, z, and so on. X, X, Y, X, Y, Z, and so on. And then you hit it with sigma to the I. So that's all the powers. And then this ampersand plus is adding them all together. And then you put those all together together with this final product. So that's a slightly more compact way of writing it. And I just checked that literally the set gens that I just created is the same as the generators of the ideal up above. Okay. And then although almost all of Although almost all of our lives is spent waiting for a Grobner basis calculation to finish, is that how you would describe your life? All right, at least for this one, I picked a nice small example where we didn't have to wait. It just has 17 elements in it. And once you have the Grobner basis, all the rest of these computations are pretty simple, like the dimension which is expected. And in particular, you can take the final element of this ideal, the 17th. Of this ideal, the 17th one. And because we used the monomial order being x, the only thing that will remain is whatever the last variable was. That gives you some degree 48 polynomial, which is, because this is a zero-dimensional scheme, is some map to that zero-dimensional scheme of which the fibers will also be finite. And so this basically describes the set of solutions, and then you can factor. And then you can factor this polynomial. By default, it does it over the field that you asked, that you're working in. In this case, I took the rational numbers. And there you go. Those are the irreducible factors. And then you can also ask for the roots over the complex numbers. So this is an example where I guess in a really good computer algebra package, you want at the same time to be doing commutative algebra, but you may also need, like, we could ask for the Also, need like we could ask for the Galois groups of these polynomials, or and you may want to do some numerical things with it. So that's part of the thing that makes has made magma useful for me is that I don't have to go somewhere else to do a computation and put it back. But whenever there is an extra feet, especially the first line of those computations, we should try to make it available whenever we can. I guess this is a time to apologize for the dollar sign.1, which is one of those plagues in magma. It refuses to name various. It refuses to name variables that you don't name because it doesn't want you to get confused. And so it just says, dollar sign is whatever the thing that this belongs to, the dot one is like the generator. So in this case, it's supposed to be a complex number. That's the dollar sign, and the dot one is the generator of the complex numbers, which is I. So to fix that, you have to take these roots, declare your complex field, and ask for them in that complex field. But I left the dollar sign dot one by way of explaining what the hell that's about. And I'm sorry. About, and uh, I'm sorry. So, John, before you asked for the complex roots, did you convert that into a univariate polynomial? Yeah, the univariate polynomial. Yes, which is a great question. Moving between various rings can be slightly headache, but if we asked for the roots of a multivariate polynomial, it would understandably. Multivariate polynomial, it would understandably complain, and that's the rigorous environment it's supposed to be providing, or whatever. What else? Okay, that's kind of basics then. You can also do an elimination ideal, which just asks for those polynomials that are supported in the variables, the last four variables, I guess. And all right, so that one went too quickly. So, here is a little function. So, here is a little function that I wrote that creates a cyclic n ideal. So, this is kind of what functions look like. You take n as your input, you make a polynomial ring and n variables over the rationals. Now, I'm going to take the ith generator together with one and permute them this way. I think that should be p.1, right? No, no, it's okay. It's okay, no, no, it's good. It's okay. You're adding it to the list of indices. Yeah, it's good. Okay, all right. Sorry, this is the problem with me having something late. So I appreciate the backup in the room there, you guys. All right, and then it shifts them, takes the products, and then builds the ideal that has the generator. So make that function. For some reason, I'm doubting it. So I want to, as soon as I move the zoom window out. Want to, as soon as I move the zoom window out of the way, I just want to see what this ideal looks like for cyclic and ideal seven. Okay, I guess I did this right. I'm a little surprised, but all right. I guess if we can't surprise ourselves, who can we surprise? All right, and then now I think we have to wait a little bit for a Grodner basis. So while we're waiting, I thought. So, while we're waiting, I thought I would show you the verbosity feature. So, you can increase this verbose flag up to three, I think. Various functions have verbose flags attached to them that it's supposed to provide you feedback on how the computation is going. This is especially important for me when I do Grogner basis calculations, because while you're waiting, you want to be entertained. And so, watching polynomials fly by the screen, I always find to be very pleasant. If it's telling you instructions about it, If it's telling you instructions about it, or you can also have a good sense that it's doomed. So, all of those are kind of helpful things. So, here's the type of it tells you a lot, and it also shows you how complicated the algorithms are for computing a Groebner basis. It starts with a search for homogeneous weights, then it computes some limits, tries to see if it's zero-dimensional. The main algorithm is called the Fougere F4 algorithm. It starts actually in It starts actually in graded lex. I have no idea what a use pairs delay means. But in any case, it's doing to make a really informed mechanism to compute all the S pairs as it goes along to minimize the stress in the linear algebra, to do it in some kind of structured, organized way using various heuristics to try to, it doesn't change the theoretical running time, but it has a significant impact in practice. So here you see some row sort time. So, here you see some row sort times and insertion times for monomials. And this is trying to describe to you one of these linear algebra steps. Okay, and this basis length and Q length and total monomials tells you about how hard it's working. So, step three, step four. Okay, now you guys get to enjoy the scrolling. How does it come across there on the screen? Satisfying? Pretty good. Go ahead. Okay. It goes on for a second. And it finally does succeed with a basis of length 209, 3299 S pairs computed, and then it makes the term order change using a Grobner fan technique. And here, so that means it went from graded lex, and by default it takes lex. I don't know, maybe if we didn't want it to do this step, you'd If we didn't want it to do this step, you just ask for any Grogner basis, you should ask for it to do it in graded lex. But all right, so then it does, and it finally succeeds. Okay, this one only took seven minutes to do the FGLM and a total time of seven seconds and a total time of nine seconds, which is much shorter than what it took me to blather on about. So, okay, I guess you ought to enjoy my commentary more than the wait. But this gives you another one of these polynomials. You see that it's a dollar sign dot. You see that it's a dollar sign.7 now for reasons that I explained. Okay, and maybe the last thing I'll say about Grogner bases is that, and polynomial rings, is that I seem to find myself very often needing kind of specific term orders. So here's one that creates a weighted order using these monomials. Like when I was Like when I was trying to give an initial ideal and kind of universal Grobner basis for a curve, a stacky curve in its canonical embedding, then you really have to be able to adjust the term order exactly right to get the simplest kind of equation. So that's another feature that is really helpful to have. Oftentimes you need graded polynomial rings so you can work in a weighted projector space. But anyway, this is the type of thing you can do. And then as you see, a plus b squared. And then, as you see, a plus b squared plus e cubed to the fourth, the leading term here is the b that it pulls it out. And even when it's producing it, it says that the leading, the initial term is b to the eighth. Okay, so maybe I will do one more of these examples and then pause. So another thing that I have really enjoyed, this is a short one, is to desingularize a curve. So here's a curve. So here's a curve with a singularity at the origin, and a function that resolves the singularity. Maybe I'll try to leave that on here, is just the resolution graph. And this one, the resolution graph describes the singularity by the components that you get in the blow-up and how they're glued together. And here, the singularity is described by six blow-ups from the six vertices, and they From the six vertices, and they describe the various components: the self-intersection, multiplicity, and the other details that you need to compute things like genera and other aspects of the curve. I guess I'll use this as an opportunity to say, gee, I wish it made a picture. Numbers in an array are not nearly as helpful as actually being able to visualize this. Maybe a thing that would be useful as long as we're, for those of us that try to or find occasion to use magma in this notebook-like way. Magma in this notebook-like way is to have more visual components like pictures of fundamental domains, graphs when they're available, that type of stuff. Okay, in particular, this allows you to compute the genus, which happens to be zero. And I think that concludes the first part of what I wanted to say. How am I doing in the room? Do you feel like those of you who haven't seen magma before got a good sense, and the rest of you still enjoyed? Do you got any questions? Yes. The only question. Yes, the only question. Just a non-serious question out of personal curiosity. You apologized that something was named dollar.one. What would you name it instead? Instead of magma? No, no, no, because dollar.one is generator. Oh. Because I mean, if you give it like a name, like X, then it might clash with something the user has specified. So as far as I see, dollar is fine, it's fine as anything else. Yeah, except where you get dollar and.1. Yeah, except where you get dollar.one times dollar.1 if you have a stack of extensions. Ah, okay. So it it could also remember the name of the ring that you're using. You say r equals monomal ring. It could have used r.1, which would have been slightly better. Better than low. But that was complex field, right? Or yeah, if you then, well, I think what Sage does is hold it I. So yeah, I'm telling your question. Answering your question, John. Okay, maybe continue. I have one question. If this resolution graph thing, how general do resolutions of Timuler is for Magma? And what is, I mean, do we only get the graph or do we get the scheme which realizes the resolution? Oh, that is a good question. That is a good question. Let's see. I disagree with the comments about.1. Maybe it's the least worse option, but still when I have students or when I show magma to somebody new and they're like, what the heck is dollar sign.1? I mean, it is expensive to use magma, but I don't think the dollar sign really conveys the right. Um all right. And um you increase the font size a bit on this. Yes, I should. Maybe more. Okay, I'm pretty sure that one can extract. I'm pretty sure that one can extract reading this description. I'm pretty sure one can extract more fully a description of the resolution of that singularity. It probably doesn't do that by default because it's faster to compute this resolution without necessarily keeping track of all the associated data. Like you work analytically rather than the blow-up. But I think that's as far as I can answer the question just now. But if you don't find what you need by computing it around, you know where to find me. There is like a normalization command that also very often works. If I'm being honest, the way that I can resolve these types of singularities is when it's genus zero, I find a parameterization. We could try to see if that works here. That's not really, is that what you're asking for? I mean, it's a different way of thinking about the blow-up rather than in each of the steps, what do you get? No, I guess what I'm asking for is more to which extent does your Schemes framework really realize the blower as schemes? Yeah, okay, so here's, I mean, it will even, here I made for you some kind of explicit parameterization. It doesn't look that complicated. It was just a monomial type thing for the singularity that was provided there. And then you get this x, y plus z. xy plus z squared. But the reason why I am semi-confident that the answer to your question is yes, is because we need often to know these stable models of curves when we want to compute conductors. And in that computation, it really does have to produce the scheme because we need to know like more description of the genus one components and that arise during a blow-up and things like that. And so that infrastructure must also, I think, have an answer to your question. Must also, I think, have an answer to your question. If that's just for curves, for other types of singularities, I'm not sure of the full extent of that infrastructure. I do have some experience working with surfaces, and sometimes it works, sometimes it really gets stuck, especially for singularities that are codimension one. Okay, great. Maybe then it's okay. I'll say a few words on parallelism, and I would like to leave some time for further questions. And I would like to leave some time for further questions, discussion, maybe also a little break. So, the other thing that was requested, Alessio, am I doing all right? Time to talk about parallelism? Don't worry about it. Just okay, great. We had a really fun little parallelism day in our Simons collaboration, and Abhinash Kulkarni taught me a lot about how parallelism in magma works. I think when I get In magma works. I think when I get there, too, I'll have a much better sense from Alan and Jeff and the other folks that are working on it. So maybe we should consider this still from the outsider's perspective, but I'll show you how I've gotten it to work and you can let me know what you think. Okay, so there is again a handbook page that describes the parallelization of key algorithms. So there are two ways in which you can ask magma to be parallel. The first one is The first one is, as I explained, there are algorithms in the kernel that are primarily written in C. And for those, very often there is a parallelized version, or for many of them, some of them, there is a parallelized version that can take advantage of many cores on your computer. So here's a list. I think this is the complete list once I scroll down of all of the options. So these are kind of the basic functionals that like multiplication. That like multiplication of matrices over a finite field of prime that fits into word size. And once you have multiplication of matrices, a lot of the other linear algebra functions over these finite fields, echelon form, inverse, canonical form, all such determinants, all that, is also then parallelized because they often use this multiplication algorithm as its primitive. Like we looked at for Gogner bases, I think I did all of those over Q that shows a little bit of my bias. Little bit of my bias, but if you do a Grosvenor basis over a finite field, then those are parallelized. So if you do have one over C, first defend it, descend it to Q in some way, then reduce it mod a prime, and you'll get a good sense, a random prime, and you'll get a good sense of what the answer is supposed to be by taking advantage of this Grogner basis. There's no coefficient explosion, which would be death, I think, for some of the parallel algorithms. And this is something that's just done automatic. And in particular, there's a Done automatic. And in particular, there's a really, really fast algorithm if you do things over F2, if you're ever so lucky. Other tasks like enumerating points on an affine variety over small finite fields, I call this brute force enumeration. It's a little bit more clever than just plugging in for all the variables and seeing it was equal to zero. It does some kind of partial filtration factorization with the pieces so that it tries to do that as quickly as possible. Multiplying polynomials, computing resultants, factorization. Computing resultants, factorizations of integers, LL reduction, short vectors and closed vectors can also be parallelized. Two for linear codes, and maybe one representation in the number field that it can compute the class group by computing relations and doing some of the linear algebra steps also in parallel. Okay, so in this first version of parallelization, this is you're we're just relying on magma to have someone done something very clever with parallel. This is to tell it that we have how. Just to tell it that we have how many cores available. So, first, I'll do a example of a matrix multiplication. So, I took random matrices over F2 of size 20,000 and computed x times x. I guess since we're in a new notebook, it takes a little bit of time for the kernel to load. This is supposed to take a little bit of time, so we have something to compare against. Okay, so I don't know how long you think that should have taken. That should have taken. A 20. I can't show you the 20,000 by 20,000 matrix. You wouldn't. I'm not sure. As much as I said, I love and enjoy seeing things scroll by the screen. I'm not sure that zeros and ones have the same feeling for me anyway. But okay, it took 15 seconds to square. I think that this is running on one of our servers and through a notebook. And I don't think we should be considering that to time things precisely in any sense. But I'm always impressed when computer algebra. I'm always impressed when computer algebra systems can do that. A 20,000 matrix is pretty large, just ask my linear algebra students. Okay, so now what we'll do is we'll set the number of threads to use to be four and hope that it's faster. I should have taken that swing of water after I hit return. All right, maybe I'll take another one. So the four that's produced here just confirms that's the output of getN threads. N threads that says that it really was using four threads, and the time that it took was four seconds, which is pretty close to 15, 16 divided by four. Okay, now this is a little cherry-picked. I'm not trying to make us look good. As you all know, sometimes it's slower to do parallelized algorithms. If I did 100 cores, I don't think we'd get a factor 100 speed up. Maybe we're going to talk about this type of thing in the HPC discussion, or we can discuss, you know, talk about it. Or we can discuss, you know, talk about it later. But let me, this is maybe you just want to always set n threads to be eight on your laptop whenever you're using Magma or on a server when you're using it, because it very often will just make things faster without you having to do anything for those underlying algorithms. So that's my speed for making computations go: I don't really have to know anything just to add this extra line. What is the R there? What is the R there? It's just to remind you that it was that it used multiple threads. I don't know what the word that they're abbreviating with R is. There must be a term that's used for the residual or something timing. Maybe it's only measuring some part of it rather than all of the time. Real time. Yeah. Real time. Okay. Thanks, Edgar. I also see. Okay, thanks, Edgar. I also see wall time. I thought it was wall time, and they should have used W, but R for real time. Okay, great. Okay, and then maybe we want a computer Grogner basis because I said that's what all of our lives are. Okay, so here is an example from the handbook. I couldn't do any better. There is a multivariable polynomial system over F2 that is used, that is broken by this implementation. This, you try to hide your secret in a point of something of degree 100. And for this, so it takes actually a little while to compute even the defining system of polynomial equations. I don't, that's like security through computational suffering, which is not a really good to uh don't be impressed by uh the fact that there are 80 variables. All right, this is what we're gonna see, okay. What we're gonna see. Okay. And so here I set the end threads back to one to give us a thing to compare it to. So here there's a couple of other, well, I'm going to kill a little bit of time while this is running. There's a couple of other features that I've also found it to be useful to take advantage of. One of them is that if you're, you can always compute a, if you can't compute a full Grodner basis, sometimes. Computer a full Groebner basis, sometimes, sometimes you can get information by computing a partial Groebner basis. And that's this second argument up to degree four. It looks at S pairs up to a given degree and in the ordering, and then it makes sure that it's computed all of those as necessary. And that's a useful thing. This HFE is a var arg parameter that's reminding it to use extra special features of how this multi-variety. Special features of how this multivariate polynomial system was, how what properties the ideal has. When I talked to Alan about this, he was really insistent that this is, especially this aspect of timing and getting things to run is more of an art than a science, in particular in the parallelization, but even in this version where it is not being parallelized. Features that you're a generic system that, if you just use a generic If you just use a generic algorithm for make bomb, whereas if you are able somehow to tell it about that extra feature and get that into the F4, then suddenly it will work. And Alan had another example just last week of something that came out of a Pan Lev√© 6 equation, something about the elliptic curve group law when you blow up nine points on the plane and you do some translation among the various components. And it just with a bit more information. With the bit more information that he was able to put into it, all of a sudden something that looked like it was never going to finish took just 10 minutes. So, I guess that's an invitation to send us your hard problems. If we don't see anything about them that we can take advantage of, then it'll be hard to make any, if it's a random system, random then system, we don't have anything to say. But sometimes these systems with extra structure, they really can do something with. And there's other heuristic parts of the algorithm that are. Something to behold. If you look at the handbook page that describes all of the features of the Grogner basis algorithms, it's actually a little bit overwhelming. It's nice that you don't have to know any of those just to get an output, but if you are so inclined to push the boundary, I think that's what we're supposed to do this week: is to really reimagine or identify the hard problems or see where domains are. Then this is a place where we could. This is a place where we could already imagine in adding more parameters if we need to. I'm also reminded of some work of Emre and Avi, and I forget the other collaborators, who used machine learning techniques to inform a Groebner basis calculation to do a Picard-Fuchs deformation to compute periods of a system. And that's another, it's pretty amazing that you can go from a solution here to a solution. A solution here to a solution here. And if you go through another vertex of a reduction graph, it's faster. And that's another example of there's really a lot of mushiness in the way that the Grogner basis is calculated. So that I think is an area, right, for other ideas, techniques, maybe AI automization. I don't know. I'm just speculating here. But okay, well, I managed to kill enough time. It took indeed three minutes. Three minutes. It prints out the elements of the Grogner basis, which were pretty simple in the end, and the variety that defines the ideal. In magma, that means the set of points over the ground field. And here you see the vector of length 80 of zeros and ones that describes the solution. So that breaks the crypto system. And then now we try to run it with eight threads instead, and we hope we don't. Instead, and we hope we don't wait three minutes for it. Here, sometimes it kind of memorizes the kernel-based computer or memorizes something, and then the second time you compute it, it's much faster. It's almost unfair now, is it? It's cheating. Well, if it's cheating, it's doing a good job of making us feel like it's computer. Making us feel like it's computing something along the way. Still doing something. I'm surprised this is not setting the threads to hear the cache of something. Yeah, I think that's what's happening. So since. Oh, that's just a list of. I would say it has. Yeah, it's the HFE system. So the second tax level. And the second taxonomy meeting is all good. Okay. There you go. 54 seconds. So we only got a factor, what, three or so, three and a half from eight course. That's, yeah, you're not going to get, it's not as embarrassingly. You got to pay a little bit of a toll. But okay, I guess I just wanted to show you that this was, you don't have to know anything. You just got to set end threads. Do you feel the power surging through? So just please use, use that aspect. Please use that aspect and let us know. Like, well, I'll have some concluding thoughts and questions about it. Wouldn't it be nice if all of the kernel algorithms were parallelized? Okay, well, we should focus on the ones that we use the most frequently. Absolutely. I mean, you're saying this is not possible, or there are technical obstructions if you have, well, you're working over Q so that this coefficient exposure cannot be done, or it's just hard to do. Alan tells me. Alan tells me that it is challenging. And the way around that is to compute mod P, the Grobner basis for lots of P, and to try to remember how that Grobner basis was computed so you don't go down dead ends with S pairs. So I think that's how I would. It's like, you know, you don't to compute a determinative integer matrix. You really, you know, work mod P and compute determinants and glue it back. All the best algorithms are of that sort, exactly to avoid the explosion of size. The explosion of psi. So I think that is a possible but not implemented situation. Okay, and then before I end, I want to show you user-controlled parallelization in a real life example. So this is where you have something that's parallelizable. It's not a magma internal that needs to be fast. So it's this framework for what we think of as manager-worker model. What we think of as manager-worker model. And you just need a problem which is embarrassingly parallelizable. So you have like, you want to do a thousand things, and you just need to run down the list and do task one, task two, task three, and they don't need to talk to one another. So in particular, the manager and workers are in separate processes. The source code should be in separate files. There's no shared memory. The workers run as a script. Workers run as a script, the worker has to quit afterwards, or no. So it's just spawning these processes, running code that you've fed to that process, and then you've got to make sure that it terminates. The host and port information need to match. I have some security questions about this. If you're running it on a shared machine, someone logs in with the same port and has access. Now they can run any magma code. And because that has access to the system, I'm not sure that that is a great idea. But I'm not in charge of security yet. I'm not in charge of security yet, so maybe they understand this better than I do. And there's also limitations. Only one argument can be passed, but you can pass a tuple. Okay, so let me show you how this worked in a real life example for me. I hope this can be included in geometry. So I am in the business of computing belly maps. These are three-point branch covers of P1. And how are they enumerated? They're enumerated by their monodromy. The monodromy is given by permuting the sheets of the By permuting the sheets of the branch cover of degree D, we represent that by three partitions. And more properly, those three partitions to actually be realized by monodromy need to come from the conjugacy class specified by those partitions. And then the monodromy is given by the permuting of the sheets. And because you're over P1 minus three points, whose fundamental group is the free group on two generators, or the one generated by three things, whose product is equal to one, then the set of Then the set of solutions to that equation up to simultaneous conjugation in ST represents basically all of the isomorphism classes over the complex numbers of Riemann surfaces that map to P1 with this monodrome of a given type. So maybe I'll show you a random example. We call this a passport when you list the data. So here's an example from the LM FDB of what this might look like. If I ask for this partition, Partition. So it's in degree 8, 5, 1, 4, 3, 1, 2, 2, 2, 2. Those are my three partitions. I can ask up to simultaneous conjugation. Can I find permutations in those conjugacies classes whose product is equal to 1? And the answer on this passport is that there's exactly one up to conjugacy. And here are representatives of the permutations. Okay, so this is the type of thing where you really want to loop over the partitions and do a calculation. The calculation is pretty involved in terms of permutations. Is pretty involved in terms of permutations. We do it with some double coset machinery in magma. So it's really a group theoretic computation, but still geometric, I hope, if you'll allow it. And I actually couldn't get this to work via the Jupiter notebook, but that's okay. I'm just going to launch a terminal. And then the way this works is I do magma. Oh, maybe I'll show you what the Do magma. Oh, maybe I'll show you what the code looks like. Is that going to show up? Okay, so here's what I've got some code that does some passport managers. So I've got some preliminary computations, which sets up the transitive groups and lists the possible permutations, possible labels. And then here's where the parallelization happens. You've got to describe your host, pick a port, I set the Port. I set the verbose flag so we can kind of watch what's going on. And then you launch the workers. This ampersand detaches them so it can run one right after the other. And then this distributed manager runs my passport program with respect to the socket and then does a little bit of printing afterwards. Okay, so that's like the manager who sets them things up, lists the tasks for all the workers, and then sends them, says, here's your workload for. says here's your your workload for the day and the um this is what the worker instruction looks like you have to match the host and the port again the preliminary thing and then this is the uh when it accepts a task it accepts this function passport info it takes this passport which is that set of partitions and does the calculations necessary to to compute something okay so now i should Thanks. Okay, so now I should just be able to do run this. Okay, very much in the theme of watching things scroll by. Hope you see that it is running through a whole long list. You're probably seeing these partitions fly by. Workers are getting assigned tasks. When they're done, some of them are shorter, some of them are longer. They come back and ask for another task. They come back and ask for another task. That's the way in which this parallelization can be really made a lot more useful because you don't, you know, sometimes it might take a couple of minutes, sometimes it's clearly empty and the workers are just always waiting. When they're done, the manager automatically says, okay, this is the next task that you need to do. John? Yeah. Is this parallelization new? Did it exist, let's say, a couple of years ago? I think it is. I think it is, it's after COVID, but not that much after COVID. So it was. Ellen told me that it was really nice to have a project like this to work on during COVID because it, you know, it helped fill the time. But it was under the hood being worked on for quite a long time. So this, it finally got a major push. I think 2022 was when the official announcement. 2022 was when the official announcement was. I'm not sure how well known it is. So that's part of the reason why I think it was a good idea to try to show you what it looks like. Maybe it's explained in the handbook. I had to do a little bit to get it to work. But anyway, okay. So it took a total of 49 seconds for each of these workers. So we really did get a savings of eight for each of the workers. And then it made these files for passports of size 10, and it creates all these 48 seconds. And it creates all these 48 seconds ago, according to the transitive group. It lists the associated permutation triples. So that is, so the thing that changed for me when I saw this parallelization was back when I was a kid, if you wanted to run thing on a lab, most of your time was going to be spent like making sure all, like trying to get the machines to work with one another. Are they done yet? Saving to a file. How do I get to them? Yet, saving to a file, how do I get to them? And this is almost now automatic, at least if you're running it all on one machine and can ask the local host there. So, you really, if you have 100 workers, you really can almost get a factor 100 speed up if it's of this embarrassingly parallelizable sort. And that just changed my framework. So, we went up to degree nine, I think, in the LMFDB. As you see, 10 now took less than a minute. So, we'll easily be able to put in passports up to degree 14 or something like that by really cranking it through. By really cranking it through. Okay, so I guess the question now is the future and yeah, question. Because what you're basically doing is you're creating a process that's just listening and accepting connections on a socket, right? Yeah. So did they put in any kind of authentication or security or are you just exposing that port to whoever has access to this? I think we're just exposing the port to the entire. We're just exposing the port to the entire world right now. No, no, no, no. You're having a little local call, so it's not that bad, but on a multi-user machine, this is already a problem. Yeah, so if someone's logged in, then they can access that portal. So it's safe on my personal laptop, but not safe on a server? On a shared user machine, I would be cautious. Yes. I'm not that. I'm not as sophisticated to understand what is the danger of opening my laptop to another source using my laptop. I'm the only one security. User ID protections. That's what you everybody. That barrier is broken protections. And I've had a comment in the chat. Everyone was saying about. The chat. Edgar was saying about orking. Yes, Edgar reminded me that there are, this was the two main ways I think that parallelization will be used. It's not the complete description of it. There is a way to use some shared memory if that's necessary. I think the future really does include things like making this easier to use and more available for the types of features that you really want to. Of features that you really want it to be worked with. So, I don't have any experience with the C4 call, but maybe Edkar could tell us more about it. Are you saying that there's a shared memory so that the worker could, well, throw away a lot of it, but declare kind of common variables that other workers can access? Yeah. Yes, that's what I'm saying. But it's tricky. So see the example and is there a four comment in this? It's not advertising. But it's not advertised that it exists as a very recent, especially for these American parallel things, that's a very efficient way of getting the data to the worker. You want to kill it afterwards, anyway. Thanks, Edgar. Is there anything else you guys wanted to discuss? It might be a good time for a break, or other things you wanted to ask me about? Yeah. Yeah, so maybe tomorrow morning we're going to have a talk where the abstract starts with due to the fact that we're basically don't really profit from parallelization. So it's the What do you say about it? Can you maybe elaborate a little about how things, how why it works? I can confirm that Alan is a genius and somehow like the tricks that he knows to really make it work. I agree with the abstract that it really is hard to do parallelized Grubner bases, but that doesn't. Parallelize Grobner bases, but that doesn't mean that it's impossible. So, I guess is what I try to show you. Why are we working on my for Jared? May I correct my own abstract? Yes, please. I mean, yes, of course, there are ways to do it in parallel, but they don't profit as much from it as other algorithms do, on one hand. And on the other hand, of course, there's always the P-modular approach that you can try. That you can try. So, yes, there are ways, but it's not as obvious as in other contexts. So, I should say they pose a serious problem to profit from parallelization. All my experience agrees with that. Yeah, it's not embarrassing, Lee parallel. It's really quite complicated because of the way that the up, especially in F4 and the way that the highly optimized. F4 and the way that the highly optimized techniques work and the search path that it uses, thinking about parallelizing out was a huge effort that Alan undertook. I have a parallel-related feature request, which is the ability to set timeouts. So there are cases where there are two algorithms in Magma, and on some inputs, one of them takes forever, and on other inputs, the other one takes forever. And it would be really nice to say, I would have tried this one for 10 seconds, and it then. Ride this one for 10 seconds, and if that doesn't work, I'll try the other 15 seconds. Or try them both. Yeah, try them both either way. But, like, I mean, even just to literally say, I want to stop a computation after a certain amount of time, the only reasonable way I know to do that is to start it in another thread or process and then killing kill, though. Yeah, yeah, yeah, but it's like a nice interface where I like I can say I you know, I think there is a way for the worker to. A way for the worker to okay, yeah. There is a magma command that will just terminate after a certain amount of time that's like in the magma engine. I don't know if it plays well with parallelization, but um, I have the same feeling sometimes. You just want to try, and if it doesn't succeed, okay, never mind. You know, yeah, so you have like a command that's like parallel wait all, and you wait until everything's finished, but that's a parallel wait first. First one's finished, but that's filled immediately. I mean, this is also what Granny basically is: that any human looking at the verbose version can sometimes tell that this is going to blow up, the coefficient explosion is coming. And then, I mean, it would be very nice if the computer could kind of detect, kill this process, try PR, they could be paid more P and then try Chinese remaining tricks instead. This is like a key with some kind of parameter. I never understood why this is called the various improvisation, but it's super useful. Well, it's embarrassingly easy. That's why they call this. Well, why do they call it Polonovas? It's a bad name, too. It's historical. You can't do anything about it. You can fight, I mean, you can try to get all the tie pack, but no, it says important. So somebody in the chat is saying that. Just to say that alarm and will turn in the next second. I think it killed the entire work. Yeah. So yeah, does it just kill the worker and then you have to spawn new workers or is that okay with the parallel? That's the only question. So it's it might just be alarm to make alarm 10 work within the parallelization. Thanks, Klaus. Yeah, my priority fork was that yeah. Yeah, my plan with fork was that yeah, you fork, you put alarm and you let it run and then if it succeeds it's right to the file, if not you don't get the file after ten seconds. Plus speaker says it will kill everything. It's a very aggressive function if that function doesn't. If you run a script, Python script, then you can do these ones. Yeah, like I said, it seems like it's possible to do. I said, it seems like it's possible to do. I sort of want to make the user interface more friendly. That would be ideal. Okay, thank you for that request. And it looks like we've got to start. What else? Ultimately, any asynchronous interruption of mana is basically potentially unsafe because the memory state is probably not completely guaranteed. Same in classically. If you like kill it at a random place, like it's the middle of writing a polynomial. I mean, it tries, and like sometimes it will keep working. Yeah, so maybe we need like an alarm and restart so the worker knows to just freeze whatever they're doing, throw it on the ground, and just like get back to work with whatever the next task is. So I think that's that should still be possible. Maybe even this non-aggressive alarm. So we also give the worker two seconds to please. We also give the worker two seconds to clean out itself and then just just fork just fork and hardkill if you don't want the result anymore. But you're saying the hard kill sometimes causes darkness problems. Not if the process doesn't do anything afterwards anymore. If you completely kill the process. Oh, you kill the process. All right, organizers. Should we take a 10-minute break and circle back for discussion? Sure. Yeah, let's do that. We'll be back in 10 minutes at 4 p.m. Okay, there are some interesting chat discussions. Now, unless you can inform us of who we are. Inform us of the later. We did discuss. Yeah, I tried. I was watching the chat and mostly fed back what was shared. So, how do we design a nice functions everything from the model is relatively slow? I think it's stable because there's got to be caching, whatever, because they just can sit on stack, but they're not in, but they're not you are stopped recording. If there's a piece, you're now recording the break, so maybe you follow it. Well, I mean that's circle.