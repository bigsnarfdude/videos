Sorry, I couldn't come. So, my talk is a little bit probably off the theme of the at least declared theme of the meeting, but it's certainly related to periods of automorphic functions. In that sense, it is a branching problem. Branching problem. So, in fact, what I'm going to tell is kind of a remark on the really great paper by Paul Nelson and Rick Shaivin Kates, which appeared in practice about six years ago. And I think its impacts on the starting to show. I'm going. To show, I'm going to discuss something which is related to the original paper by Paul Nelson and Akshay Ivan Katesh. Since then, Paul wrote more papers with absolutely fantastic results. But these papers are their global input, global input, these are papers about First, about atomorphic functions, atomorphic periods, their input is coming from different arguments, namely from relative trait formula and integral representation. So this is something else which is not present in the original paper. Okay, so the story revolves around. The story revolves around automorphic functions. And although they appeared prominently yesterday in Cova and today, I will stick to more classical language for the reason that the machinery so far was mostly applied and had impact on analytic questions related to the real presentation. Um, real representation of real groups. Um, although I would suspect and expect that then it will also play a role in Pyadic and this story one way or another is idyllic. Um, okay, so um, let me start with some generalities. So, uh, it is about automorphic It is about automorphic functions, representations. And also, I will not discuss it, but the main aim is to understand analytic properties of periods. So I would know real. Real reductive group. Well, drill and are or SLN are better. So it's unimodular and GAM and the quotient. And the quotient, the automorphic quotient, Gmax gamma. So I will assume with simplicity z x is compact, but it's really not needed. And there is a measure and we normalize measure, for example, by one. Okay, so what is automorphic? Okay, so what is automorphic representation? It's a tuple of representation, which is assumed to be unitary, the space of representation, Hilbert space, and a realization in the space of L2 on X with respect to Gatamaccontaine. And this is a discrete, but even better casped representation for the particular group and the lab. And so the important point that new is isometry. It means that the space came with a certain unitary law. Unitary norm. Okay, and then automorphic functions are just vectors. So a function in the corresponding representation is a result of sending vector to a function. V is a vector. And now it is much more convenient. It is much more convenient and nice to work with the functions which are not L2 but smooth. Let's not care what is L2 function. So it is known that if we consider the smooth smooth vectors, which I will denote by another letter. Then this embedding for the casped or representation sends smooth vectors into the smooth vectors in our representation, which are just smooth functions on x. Okay. And in particular for smooth vectors, there is There is a value at points. Okay, so this is a absolutely basic object which we studied for ages. Now, what Nelson and Akina is. And Akshay realized, or at least Claire indicated in a very profound way, that instead of functions, of functions, of automorphic functions, equally well, you can work with automorphic kernels. Automorphic kernels of operator. And this is the kind of on the surface very clear picture. So if you have a vector and out of it we consider a function, we can take a collection, but it's more convenient to talk about the sum, but not of vectors. Sum, but not of vectors, but of something in a tensor product, and then to it, just do the same. So we have x x prime, just pair of points. But now this is clearly an operator. Clearly, an operator. So it belongs to operators in my representation pi. It's more customer to take this in pi and this in pi bar and consider this kind of quantities. And now this turns out to be, at least from the point of view At least from the point of view which Nelson and Tadesh promoted, a much more manageable object. And we will see why. It's kind of a reflection of a general principle in quantum mechanics. And a lot of things, at least on the philosophical level, came from this orbit method, which reflects properties of quantum things. So instead of function, they Function, they work with apparatus. And then they demonstrate that many things you can do better with this object. Okay, so in particular, okay, this is a kind of an important point. An important point that you switch from just functions to a collection of functions. Okay, and this leads to the kind of do picture. Do not in the sense of do Langlands relative language to other sense, but do picture what is atomorphic representation, namely Prabenio's function. Namely, Robinius function. This is something which we worked for a long time. So the representation, atomorphic representation is essentially pi and mu, which is the sinusometry. So mu is an element. Nu is an element in the space I will mix pi and v pi. So maybe I should but this is easily seen as the same as a map from my previous lecture. So smooth vectors, and this altogether gives this very well known Frabenius reciprocity of Gelfand, Greif, Famin, Petevsky, Shapiro, and Nijmer. It's not clear to me what exactly a right name to attach, but it's a collection of information. But it's a collection of in different situations. And so here you have a functional, and this probinius functional, nothing else on a vector, it's something very simple. You just realize your function is a function on automorphic space, and then you evaluate it on the image of identity. Okay, and you can recover if you have a functional. If you have a functional, then you can recover realization of a vector at the point g, which is in g mod gamma, is just i applied to the shift. So this is the correspondence. The correspondence and all out of the isometry we obtain a functional well functional on infinite dimensional space and so uh it's a natural question to ask a what kind of a functional it is like it is Functional, it is like a distribution, not classical. So it took some time, people realize that there is even such a question, and there is a nice answer. So in the last century, we proved we determined the class of this function. In the class of remission formula, and I would like to state the theorem: so let n be in the remission form on smooth vectors. This means that there is some. That there is some irremission form, this is a norm coming from irremission form. Okay? And then which we require that it's continued with respect to the action sphere. Namely, that it has a it's not necessary invariant form, actually. The invariant form actually interesting cases when it's not invariant, otherwise there is no statement, but it has a distortion reflection with the continuous function. Okay, and then there exists a constant, it depends on the representation, on group gamma, on the norm, such that the norm of a functional A functional which I recall your soup of the value divided by the norm of the vectors is bounded by this constant times what is called relative trace of two forms. Where this p is Where P is a unitary invariant irremission force. Okay, and the trace I'm not going to define for you, the trace relative trace of these things, but in certain situations, it's easy to describe. It's just a trace of operators. Q is assumed to be non-negative. And then And then P, other way around from what you said, P is defined via self-adjoint, non-negative operator A. And then this relative trace of two forms is nothing else than the traitor. Nothing else than the trace of T. Of course, it could be infinite. But if it's an infinite, the theorem states that then the functional is not bounded in this norm. It's sharp statement. Actually, it's even more sharp that for X compact, we have a opposite in the colours. Uh in the core too. Okay, so uh this is the theorem and simultaneously with us Wilfred Schmidt and General Tal proved some other statement in this this kind of a statement determining. Of a statement determining the class of this probe function, but actually they determine folder class of this thing properly defined. But the results are for SL2, and it's not clear even how to state them in general. Our result is completely general, just in complete generality. But we are missing them. Okay. Great. So maybe. Okay, maybe example for SPL2, but this is a general machinery. And this general machinery is very well fitted for the variation on orbit method of Powell and Action. Okay, so probably many of you know many things about orbit methods, certainly much more than I do. But for a long time, the teacher that there should be an orbit method which allows you to do computation. Um, computation, uh, the representation of a group, not of an algorithm, but of a group, um, was somehow expected, but we were not able to do it and we had very long discussions with Akshay. Um, but at the end, um, Rigash performed this miracle and uh wrote it. Miracle and wrote a paper with a lot of details and with proofs and very clear statements, some of them which were not anticipated. And then gave a fantastic application of this machinery. So in a sense, some many things are exactly those which you would expect. But at the end, before you At the end, before you have this machinery settled, it's very difficult to work with it. As intuition, it works very well for all of us, but not as a machinery or a proof. But now it's just a machinery to use, which you can use in the proofs. And more, you can think in these terms. And this is something which is new, at least. New at least for me. So let me give you a very, very short review of the construction of statement, basic statement. So G, again, the same or in fact it's real Lie group. Again, you don't switch things. So G Lie algebra. Algebra. Again, the real space. Then the dual one, not the complication, the imaginary part, that's what, because it's the harmonic analysis, it's just from linear real forms into the range imaginary numbers. And that because it's connected to It's connected with the harmonic analysis. What is very convenient is the map into the circle. Okay, and the correspondent guide that goes to this function. Now we fix a ball in Lie algebra containing zero, just a fixed open small neighborhood. Everything happens in this neighborhood. Everything happens in this neighborhood. You have an exponent, exponential map to the group, and you relate measures, dg Jacobian dx on dx, this vector space, and measure. And now you choose or fix most. Most characteristic function a chi from ball to r. It's non-negative most one around open neighborhood of zero. Okay, and now we can see the Schwartz function on j hat. On the head, no do functions, which are called symbols. So, all this resembles, and it's really mimicked on the differential falcons in analysis, but in equivariant way. There is a There is a Fourier transform, as usual, which is goes in both directions. Okay? And I will denote a function from P body to this one and the in opposite direction is the In opposite direction, it denotes like that. Okay, and now the whole theory is asymptotic in Planck constant, which is of course not Planck, but not a constant, but it's a parameter. Okay, everything is going. Everything is going to be asymptotic, but asymptotic in an effective way. All bounds are really bounds and not some way asymptotic expansion and so on. All operators are bounded, reminder is bounded by the norm and so on. It's really important because at the end, you somehow want to get numbers. Okay, so for a symbol, which is again Which is again a Schwartz function, but even though it's think about smooth, compactly supported functions on the door defines, it defines an H dependent operator, which they denote op H A or it actually depends on. Depends on a lot of data, which is not equally important. And it's a parator in representation. So representation spine is assumed to be relevant to the orbit method. It doesn't cover all it doesn't cover all representations, but so it's really interesting. So it's unitary terms out of this template representation of G. And then it's just, well, just, I don't know, just this is an integral over G of Lie algebra. There is a cut off, which is scaled by H. By H, Fourier transform of the symbol, and the exponentiation of from Lie algebra again of scale thing. This is the formula. And this belongs to the operators in pi. Pi is here. So you have to, I'm not constructing. I'm not constructing a representation, it is given to me. Only then I can perform this thing. Now, it's not difficult to show that op obtained this way is a compact trace class operator. Again, in this for that scene. For that symbol, they actually extended to other symbols, including differential operators, and the curios formula, the most important artifact of orbit map takes the following form. Trace of this iterator. Of this iterator. There is some normalization because of the scaling h to the power minus d integral of a symbol with respect to the period against scaled order up to small order terms, which are effective. Again, I stress everything is effective. Express everything is effective. This is an orbit prescribed here orbit method. You now note that if representation is fixed, this is some fixed orbit. Fixed, this is some fixed orbit, then a scaled object goes approaches the cone. Okay, this will be important. Okay, now these are operators, and I told you one of the essences of the paper is to switch from function. To switch from functions to collection of functions, namely to the kernels of operators. These are operators. Okay? It's also convenient to consider a relative of this thing is a remission form. Apparatus and remission form are the same thing. So I just wrote quickly you apply this. You apply this operator to the vector, in pair of the vector with respect to the given form, and the association is very nice. Non-negative functions go asymptotically to non-negative apparatus. Real functions go to asymptotically self-adjoint appearance. And the most important property there are many important things, but one are Important things, but one which preserves the action. This is the equivariance, and this means that I have an operator and I can conjugate it by the action in my representation. The answer you expect to be a parator from a symbol which is shifted by Which is shifted by the same element. This is an action, there is an action, of course, adjoint action, and this is co-adjoint action and function so. And this is almost true. And here is a catch. These apparatus are very close, effectively close, but not for the whole group. There is a condition. The element of a group should not be only one. P1. Okay? Otherwise, this equivalent is destroyed. So you cannot act with the whole group, but still a large piece of your group is still acting and it is controllable action. Okay. And also we have operators in our In our representation, they are parameterized by H. Out of them, you obtain a kernel. There is a kernel. These are nice operators. Okay, and so for example, many things are preserved. Preserve. The trace of operator, of course, is just the integral of the value. But on the other hand, Kirio formula tells you what it is. It's integral, H minus G scales orbit. orbit symbol against the keral form okay so this allows you to control something in terms of symbols which is has nothing to do with the automorphic piece through the related to the automorphic picture okay and so it turns out that you want That you want to understand how this term becomes pointless. And it's not surprising if you're interested in periods. The periods are just integrals of the same thing along some cycle. If you know, if you can say something non-trivial point-like, you can say something non-trivial about period. And this is how in their paper they achieved this connection. Okay? This connection. Okay, so the object to consider is the following one. You have a symbol, you have this parameter h, and then it's convenient for me to write it in the following way. To Frabenius functional, I also can correspond to the remission form. Frabenius remission form, which is on a vector v, is just i v squared. V square. It's around one form, but of course, it's not coming from smooth vector. And then I have a remission form, which comes purely from representation theory. It has nothing to do with atomorphic picture. And I just pair these two forms and take just Keller product. After all, this is the vectors and pi tensor pi or pi tensor. Pi tensor pi or pi tensor pi bar and pi bar tensor pi pi. If this pairing exists, then it makes sense. Now it might be infinite. But in fact, the theorem which I quoted about the relative trace of the functional ensures that for smooth symbols this is the finite thing. Okay. So this in terms So, in terms of this quantity, you can express period values of automorphic functions, but again, not for one function, but for a collection. And there is an easy, so they exhibit examples how you can work instead of with the fixed atomorphic function, you can work with this thing. So, we usually do. So we usually do use this notion of test vectors. The test vector is something which on atomic on invariant functional produces some interesting number or some controllable number. So they showed how you can do the same exactness, but not with test vector, but with test operator. Okay. And then the question is. Okay. And then the question is how to deal with this quantity. So in fact, we proved more or less long ago before this paper, something which could be interpreted in the following way. So for a fixed symbol, Symbolic symbol we have the following bounds. This quantity, which is just evaluation of a coronavirus again, is bound by some constant, which is effective h to minus d. This is the normalization, actually, it's volume. Normalization, actually, it's a boolean normalization of the orbit. Oh, I forgot to say that d is the half of the dimension of the orbit, which is, of course, even because it is a practical. We just integral of what you expect to be in the trace. But again, this is of the size of the trait. Right, and this is a point where okay, so in fact, the proof is quite soft. So the main result of, I won't say it's the main result, but certainly that's the result which got them into introduction to state a fantastic theorem about everything. A fantastic theorem about the average value of L functions in gross parameters problem. They prove under the same condition, which is this one fixed, that this is asymptotic. If h goes to zero, is as if that explains. I think toxic to the pointwise, at every, in fact, if you prove it at the identity, you prove it everywhere. Okay, now their proof is much more unexpected. It's a Ratner theorem. And Ratner's theorem comes exactly because Exactly because of this remark which I told you that scaled where is it that the scaled orbit approaches the Nilcone. So they discovered hidden symmetry. Hidden symmetry, which absolutely wasn't on the surface. There is no unipotent symmetry nowhere in the picture. But they discovered a hidden symmetry, and this hidden symmetry allowed them to use to great effect Radner's theory. There is, of course, a certain complication. Radner's theory is not effective. At least it's not effective to London der Strauss and A London der Strauss and group or someone, or maybe somebody else, will not prove it effective in all situations. Maybe it happens soon, but this is a non-effective limit. It is a limit, but you cannot estimate when it happens. Maybe not happy. So, the result which I would like to report is kind of shrinking of this relationship. So, you can look at this statement in the following way. We have a Frabenios functional, and then it works like a distribution on symbols. On symbols. Symbols live on do of Lie algebra, but in practice, Kirillov's character formula tells you that in practice, it leaves on the orbit. Okay? And the question is how it is distributed there. So this statement, what we This statement, what we proved a long time ago, and exact, a much more exact statement of power and action, says that on the big balls, because the fixed symbol, it's like taking a big ball, fixed ball at near Nilkon. But what happens if you shrink? On the big ball, it is like a trade. It is like a trace. If you free it, you expect that it became less than a trace. And this is a statement. So for age-dependent symbols supported. On small H to the delta box near Nilcom. This is only there, it's important, otherwise you just miss your representation completely. What we have is the same quantity, which is again, it's a point-wise estimation of Estimation of closure is bounded by some constant. This is the rate which you get for free because you have it for big balls, certainly you have for small balls. It's all the claim that you get polynomially better bound. So there is this sigma greater than zero, depending only on the group, not even in the representation, that you group. Uh that you you go you get better. So this is the result. How much time I have at any? Actually the time is up because for our conference the lecture is for 40 minutes but you start a little bit later so I think it will be okay to have five or three or five minutes. Okay. Great. I don't need more. Okay. I don't need more. Okay. So here is a conjecture. And I will tell in the full one version of conjecture and another one I will tell in words. So assume pi is fixed and consider this age-dependent bobs, like in the theorem which I In the theorem, which I quoted, Paolin actually introduced a class of symbols which allow you to shrink your symbols exactly so that they look like characteristic functions of small box. Not too small, apparently. I will not give a definition, but this is something which I told you in the work. Told you in the work, in the work. So my conjecture is on clear conjecture, certainly not stated there, but implicitly, of course, it appears to me to be a trace. That the correct bound should be the trace bound. But it's not clear if it works for all both. So, a conjecture that there exists delta zero, which is less than equal to one half, this is actually the Planck regime. And then this holds for any delta for any delta less than delta zero. Great. This conjecture is. This conjecture implies many subconvergence, which is bounds. Okay, and the second conjecture and the second part of a conjecture are that if you change your representation. That if you change your representation. And then something similar could be stated, but it's much more tricky even to formulate what you should expect because of all kinds of counter examples which are known. There is a huge difference between these conjectures. Third conjecture would follow from Ratner, from effective Ratner. This with no connection that I know of. And so, the second conjecture I didn't formulated that they were formulated in my paper is. Um is a very intriguing one. Okay, thank you.