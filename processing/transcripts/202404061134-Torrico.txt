Thank you very much for the invitation, organizing this great event. Today I'm going to talk about a recent work that we just put on archive, joint work with Omar and Ulis, who was an intern with us last summer, now deciding what to do, PhD, where, I don't know, do we know? Maybe in a week we will. Okay, so the main motivation for this work is toy-based matching platforms. Matching platforms. Of course, you are familiar with many of them. They cover many aspects in life, like accommodation, dating, carpooling, outsourcing. Pop a ride, it's just blah blah car in Canada. So they have different characteristics, but they have common ones. They are generally two-sided and decentralized, like in the sense that the platform doesn't choose for the customer suppliers. One aspect is that users have preference over the other side. Over the other side. But also, they may differ on the form of interaction. One platform might be two-sided, or one-sided, one example, Serbian P is one-sided, or classic dated platforms have two-sided. Also, they may differ in terms of multiple selections or single-selection, Serbian Pizza single selection, dated platforms and multiple selections. But the key aspect is that both sides must agree to generate a match for a transaction. So at the end, the platform. Transaction. So at the end, the platform serves as a mediator to control what users, how users interact or what they see. Okay, so one of the challenges that this platform faces, one is efficiency, what they see, what actually the users see. So the platform wants to control supply and demand. Why? Because there are many popular options. You may imagine in Airbnb there is a very popular apartment. So if you don't control what the user sees, then most of the But the user sees that most of the requests were going to be concentrated in one option, and this supplier cannot handle many. So, preference might be correlated, which can lead to inefficiency. So, the challenge here is to show relevant options to the users, kind of like keep them engaged, but with the challenge of avoiding contention. So, the second challenge is design of how users interact. So, one question there is who or what? So one question there is who or which sites should initiate the matching process. So I mentioned that one platforms are one-sided, one specific exception here is one pole is a taken out but it's one-sided allow only women to start the interaction and two-sided platforms. So the challenge here is how we can compare, can we compare different forms of interaction and what is the benefit of one platform design over the other. So how users interact and what they see may lead to Interact or what they see may lead to better experience, efficiency, and higher revenue. Okay, so let's jump to the framework. So we have two sides, customers and supply, pipeline matching. Each user have preferences over the other side, which is going to be a discrete choice model. So for customer, we have Phi I you can choose your favorite random utility model using MySome MNL. And also the suppliers are going to have a choice model. Suppliers are going to have a choice model, 5J. So they're going to choose someone from the assortment or to leave the market. Not too much. In the same forecast. So we don't impose any constraints on the assortments, and the match is going to happen if both they mutually select each other. So both see everything. They may, I mean, you may show everything, but do you not have constraints on it? Also, first you pick. Yeah, you have to choose the circuit. Yeah. Maybe distracting question. We dislike why bomb bell is actually one side of it. Why bomb bell is actually one third of the movement? Yeah, so only women are allowed to interchange. I'm also about to say no. Sure. Sure, sure. But to start talking, as far as I know, to start talking, only women can. Okay, so the goal of the platform is to maximize. So, the goal of the platform is to maximize the total expected number of matches, but the question here is how the interaction happens. Just let me give you some informal description of that. So, the platform is going to have available policies, and the policy kind of determines the tasks that the users are going to be processed, which are going to denote this red square, and the options that are going to displace to those users that are being processed. Okay, so how we should process a user. should process the users. So should we start with all of them? Should we start with all of them at once and show assortments to everyone simultaneously? So you may imagine some platform at the beginning of the day selecting assortments, pre-compute assignments for everyone and doesn't change during the day. That's covering everyone at once. Or should we start with customers first and then go to suppliers? We show assignments to customers, observe their choices, then go to suppliers? Go to suppliers. Or if that's the case, should we start with suppliers from 10 customers? So finally, another option is to go one by one in each site. And once we are done with that site, we'll go to the next site. And there is no limit on the number of offers? There is a limit. So you can only process once. Once. Every user. I'm going to formalize it, then also have a policy and you can. So why you didn't click internet? Interleaved, like customer, and then oh, it could happen. That's also available for policy. We focus on our four specific classes, but yeah, those are also possible. So, all of these options are kind of like abstractions of different platform designs. So, let me give you an example just to motivate why one platform design is much better than the other one. So, let's consider this platform with two customers and one supplier. Okay, so the choices are the following. So the choices are the following. So for the customers, they're going to choose will probably be a half if they choose the only supplier. And for the supplier, depends on the size of the sales of the customers. It's going to be uniform. So let's see two different policies. So the first policy is going to process everyone at the same time. We're going to show actually everyone to everyone. So both I and I prime are going to see J, and J are going to see both I and I prime. So you can actually So, you can actually compute probabilities and see that the expected number of matches is going to be one-third because you have one C. So, the other option is to actually process I and I prime first, and we're going to show J. Then we'll set the choices, and we'll have two cases. One case is only I chose J. In that case, I'm going to show I back to J. Similarly, for I prime. And the other option is I. And the other option is that both of them chose j. And in that case, I'm going to show both of them. So you can compute this, and it's going to give 5 over 12, which is better than 1. Good motivation for the class. Good. Cool. Okay, so the question is: how much value is one type of policy over another class? And given a policy class, can we actually approximate the number of policies? So in this talk, I'm just going to give you the two-sided assortment optimization framework. We started a wide range of policy classes with a choice preference, like very general choice preferences. We're going to focus on four main policy classes that are kind of like static and adaptive, one-sided or two-sided. And we are going to study the idea gap between those classes. Kind of determining how users interact and how much benefit you get from one platform design over the other one. And we also, I'm going to show you some. And we also I'm going to show you some approximation guarantees if we have time for specific points in the market. Okay, so literature is very extensive. So market efficiency has been a study in the past, kind of like how to design the platform in terms of signaling and limited information. Also, some organizations you know has mainly focused on single customer and not preference on the other side. Again, the literature is super extensive, but if we go to the recently, But if we go to the recent literature on assortment planning for two-sided markets, they're kind of like the first work was by Thaya, Daniela, and others in 2020 that studied a specific version of the coding that I'm going to tell you today. I'm going to point out to that. And there are some recent work on dating apps and also the work by Ali and Manila on the online version of this problem and so on. But no work has focused on different policies in an adaptive On different policies in an adaptive framework. Okay, so let me describe now the policy classes. So, again, we have two sides, we have the choice models, no constraints on the assortment, and the goal of the platform is to design a policy to maximize expected amount of classes. So in each step, a policy is going to select a subset of the users. So each user can be processed once and offer an assignment to each of those users. And offer an assignment to each of those users. Then we observe the choices and continue with the remaining if there is any. That's the basic notion of a policy in our case. Just consider that we're processing users only once. So we have four main policy classes. The first one is fully static. Fully static is going to process all the users at the same time. I'm going to denote that as five effects. Then we have one side static. Then we have one site static, which is first represents all the users in one site first. For example, if customer starts and then suppliers respond. Or similarly, you can think of suppliers start and customers respond. That's also included in that type of policy. And this is going to be another files. Then we have one-sided adaptive policies that go one by one in the same side. So customer start, then we've got supplier respond, and similarly, Supply of response, and similarly, we supply correspond like customers. And finally, I'm going to tell that by OA. And finally, we have a full adaptive basis one by one by an alternate. It's the most powerful type of concept, right? So you can go one by one in the number. So I have all these policies. Of course, you can see this, that these policies are nested, right? Because you can simulate any policy here by a policy. Any policy here, by a policy here, right? And so on. Any questions on the policies? Clarification. When you respond, that means that you offer a servant. And then you select. So let's say on the customer side. So then you go and offer that customer to the supplier. Right. In our setting, it's optimal to show everyone that shows them. Any other questions? Okay, so the main problem here is that given a policy class pi, we define the octpi as the maximum number of expected number of matches for the policies in that class. So since the policies are nested, of course you can see that the optimal values are not ordered. So we define the activity gap as the worst case ratio between two policy classes. Between two policy classes. And an approximation of guarantee, as you may expect, is just design a policy in some class that gives you some factor math. So let me give you a brief idea of the results that we have in this work. So the first one is to compare these two, fully static and one-sided static. And after you think a little bit, you can see that the TT gap here is arbitrarily uncharged. You can imagine a platform you You can imagine a platform in which you have n customers and one supplier, and the customers are very big. So, you need to serve their choices first to have some match. Then we compare one-sided static with one-sided adaptive, and we show that the adaptive gap is exactly one minus one of them. Is this by any means related to the adaptive gap of some modular function? Or material defects? There is a lot of connection with some other organizations. So, the main idea to prove here is that the lower bound is a novel linear program relaxation plus a correlation that goes back to what you said, and the upper bound is some non-trivial distance that I did not have to correlate. Next, we compare one-side adaptive with fully adaptive, and we show that adaptivity gap is actually a half. It might be a little intuitive because you have more choices than two compartments side by side. Okay, so that's on that activity. So, yeah, so the lower bound here is by a couple of argument, the upper bound is two-digit joints. Some market actually is a copy of this one, but just swap. My damn the half. Okay, so this is the adaptivity side. If we go to the approximation algorithms, one of my previous work, we showed that in this specific case, this was decided by Slag and others, we showed a one-minus one-over variety approximation guarantee, which is. Minus one very approximation guarantee, which is tight. So you can imagine that already you can produce an algorithm for full adapting, right? You just use this one and then you use the authentic algorithm that gives you kind of like 20%. So actually we prove that. We specifically show that for one side adaptive, we obtain a half approximation parcel. And then you can, so this is a greedy type of algorithm, and we do a prime and do an analysis, you can recover a half. You can recover. So, just the last aspect that I simply asked: Is it kind of a polynomial time argument in the sense that I have seen this coupling argument for stochastic probing that, hey, I start from the adaptive optimal policy and then I'm going to come up with a non-adaptive policy that has half a conclusion. But then computing the adaptive optimal policy might be a computational power. So, your result is not constructive. You don't give us a non-adaptive policy. Non-adaptive, but it's just the adaptive. For this one, also, it's expected LP, so it's not balanced. In the last result, we have that this is a very cute problem, but very hard. We have for the multinomial logic, we have about 6% extension compared to fully adapted. This one? Yeah. No, this is the approximation factor for this positive. The approximation factor for this positive class? For the best in this case. So we do a bunch of realization plus a random argument, basically separate the instance in low and high weight, low and high value instance. Value meaning the multi-analytic. Also, when you say a half approximation factor, it's the best. But they don't construct it as simple. For the approximation factor, yes, but for the T graph is For the theta gap is productivity gap is theta. Improve upper and lower, both just okay. So we're going to have you tried comparing the ECC like the expected optimal offline? Like so you just look at all the utilities that are not zero and you find zero. No, no, no, but no, no, no, but comparing it to stronger opt-in utilities. Ah, yeah, that you cannot do anything with the gap. You mean like the municipality? You mean like the munition optimum? Yeah, you know all the scratch the optimal side. No, you do you can perform five so for one-sided adaptive the half-approximation couldn't it be derived with Ali and Daniela's thing? So of course they look at the online version, but you could say that the online 3D algorithm would be about half. Exactly. So until here, this is very related to online. This is very related to online submodular website, which is go back to Ali and Daniela's work and this one. So, this is actually a random order green. Which is like a random order version of algorithmic proposals. Yeah, that was non-adaptive green. So, I think this is adaptive green. Right. So, today I will try in ten minutes to go where I have. To go a bit, a little bit on this, we'll see the lower bounds on here, here, and ideas on. Okay, so the activity gaps, what is the value of obtaining more information on the same side? Between the one-sided static and one-side active? So you can imagine that the optimal value of the one-sided static is basically if you start from customer, what if you start with suppliers? And the same for And the same for one side that can decompose that optimum. So let's fix initiation inside only to customer. The argument applies when you do one for suppliers. So I'm going to show you a relaxation of that problem, a relaxation of one side advantage. So let's denote lambda J C as the probability that J sees assortment C, and tau IS, the probability that customer I sees assortment S. Of course, these are greater than zero. So every customer is chosen. So, every customer is chosen by some subset of suppliers. So, that means that the sum of the tau has to be one. Every supplier is chosen by some subset of customers. Remember that we are starting with customers. So by the end of the process, suppliers will see some subset. So, the sum of the lambdas has to be one. And finally, they have to connect these two probabilities, right? The probability that J is the supplier J is customer I equals the probability that J is in the assortment. Equals the probability that j is in the assortment of i and i chooses j. So we sum over all subsets that contain the customer I equals to the sum of all subsets on set J, the probability that we show that assortment times the probability that I choose J. So the dollar is your policy, right? That you will show everyone who chose J will. Right, exactly. So one argument there is that after you're done with Is that after you're done with showing assignment to the customers, then the best that you can do is to show everything that was chosen to each supplier. And it doesn't really matter how you process suppliers, either one by one or simultaneously because these are independent. Right, so the number of expected number of matches is, as you can see, is lambda times f and f is the demand of the supply chain. So it's the probability that I choose someone from C. Without loss, the suppliers you can show at the end, right? Like yeah. But without loss, the suppliers are choosing at the end. Without loss? So without suppliers, can you show the assortment of customers to suppliers during the process? No, so at the end, you finish with customers and then you go to suppliers. Okay, so this is an upper bound of one-sided adaptive. So the sketch proof is as follows. Sketch proof is follows. Consider an optimal solution of this problem. Okay, we don't need to compute it, just consider one. Then, with tau star, we can construct a feasible one-sided static policy. And actually, the objective value of this policy is very, it's kind of familiar, is related to this. It has a specific form of lambda, which is known as the independent distribution. And then we can use a correlation gap that kind of like study the relation between the independent distribution. The ratio between the independent distribution and the worst case distribution that is given by these lambda steps. So, in the case of models or some modular demands, then we can show the one minus one correlation. Any questions? Okay, so let me go now to the one-sided adaptive or fully adaptive. What is the value of collective information on both sides? So, then here the proof is as sketch proof is as follows. Sketchproof is as follows: Regressive to CL5 starts on optimal policy. Then you can imagine that if you go from top to bottom, like the policy just goes from top to bottom in terms of processing, then you are going to jump from one to side. You could just be jumping from one side to another side. At some point, it's going to be a match either to someone before or with someone after that you're processing later in time. So if you might like later in time as going down, then you could either match someone before. You could either match someone before or someone after, in that police. So let's denote YIA as the variable that indicates if the user A was matched to someone before in PyStar. Remember, in fully adaptive, you can move from one side to another side. So we can couple PyStar with two policies. These are two one-sided policies, adaptive policies. So the first one is that So, the first one is that we are going to follow PyStat for suppliers and we are going to skip customers. We are going to simulate the choice just to follow the decision tree, but we are going to wait until the end and show the same as PyStam. And we can define the same for PyC. Just follow customers and then skip suppliers. So, the key argument here is that the probability of matching A in Pi C, A is here supplier, is at least the expected value of this value. Why? This value. Why? Because the contribution here happens only with someone before, but here, since you have to finish all the customers, then this A could match someone before and after. So that's why it's not. Okay, so finally the argument is super simple. So the optimal one-sided adaptive is just decomposed like this. This is at least a half. These are two feasible policies. And then you bound this one with this one. Bound this one with this one, you get the half. Because this sum is actually the number of matching pipelines. Any questions? Okay, so that is for adaptivity gaps. Let me just go briefly on the approximation, a half approximation for one-sided adaptive. So, I'm going to show you a greedy algorithm for that. So, we use a random order greedy. So we use a random order greedy, and as I mentioned, we can focus on one side, right? Because we can decompose the optimal value as customers for suppliers. So let me just fix the case of customers. So random order grief goes as follows. We are just going to sample a random order over the customers. Let me do that. So we just get an order and go from top to bottom. And every time, okay, so now I'm going to hear the backlog of each of the customers. Sorry, the supplier. The customers, sorry, the supplier. So, these are going to be the set of customers that shows each of the suppliers. So, we go for the first customer and we're going to solve some single assortment optimization problem for that customer with some weights here. And these weights are going to decrease in time as you proceed in the policy. So, the customer chose someone and we collect that information there. And then we continue with the next one. Continue with the next one, solve the problem with the new weights. Choose someone, and we update the backlog. Then we continue with the next customer, update the backlog, etc. We obtain a bunch of backlogs. That's actually the marginal value of the demand. Okay, so once we're done with the customers, then you're going to show each of these subsets to these files. It doesn't really matter if. It doesn't really matter if you do one by one or all at the same time because they're independent choices. Okay, so formalized, we sample the random order. For each customer, we select a server with the largest weighted marginal contribution. And this is the point. So it's a marginal demand on the current backlog. This is similar to what Ali and Benera did in the paper, the difference that we are doing around the model of the current. Why did you random model? Yeah, why did you need random model? Yeah, yeah, take any order. Pretty marginal for one nice submarge order for maximum distribution. Okay, so once we're done with that, we serve the choices and we show the value of two suppliers. So the prime maturalysis, this was a technique, some techniques by the manure and others in 2013, different problem. So we had this formulation, okay? So we just compute the dual. So we just complete the dual, have this dual, and then the sketch proof is simply just we set the variables according to the greed instructions and the customer choices. Then you can simply show that the expected values are feasible in this dual and that the primal object is at least a half of the dual object. The key assumption here again is that the demands are monotonous. Here you're comparing against the MP not to get the difference together. Yeah. Yeah. So that's a key. That's a good point. Next. That's a key point because I mean you're comparing with the actually optimal DP as far as I remember. So it depends on the arrivals of the customer, but this is fixed for any remote. Okay, finally, the Qt problem. So for the fully static, yes, quick. So if there is an So, if there is a notion of picky and flexible customers, I mean, in some model, let's say ML, we can derive a notion of a picky customer and a scalar, which is picky or flexible and process in that order. Is there an order that you can? Yeah, I mean, the intuition says that you you definitely should start with the PTOC with a figure. Can something be shown there, or? Uh in general I don't know. Uh in general I don't know. For a specific cases you can for MNL, I mean if you study specific values, you can do some some examples in general here. In practice we can always see this. I mean I have another work on dating platforms and you observe that yeah you need to start with the picker side of the market. Okay so this is a big problem fully static. We give us 6% for the Static, we give us 6% for the case in which you have multinational projects. So let's assume that every user has some ML model. So the customer value over suppliers is VIJ, and the suppliers value over customers is Wij. So you can imagine that designing assortments is equivalent to selecting edges, right? Because if I sees J, J has to see I. Because they're looking at the same time, single times. It doesn't contribute. I mean, it doesn't. I mean, it doesn't, it doesn't, in the optimal solution, it's better to show positive sensitivity. So, the main problem here is that, okay, we have variables, binary variables, to select in the edge ij. And this is the probability that i selects j, and this is the probability that j selects i. So, actually, this problem is strongly in p-half. So, the main technique that we use is we partition the edges in different ways. In different ways. So we have a separate additive argument there, and we solve each of these cases. Actually, this is the more complicated case in which both of them are peaking. So this is a sketch proof. We get 1 over 27, which is 3%. You can tune this one to get 6%. Okay? So for the first one, we get a half approximation. You can show that. Approximation, you can show that you can get a concave relaxation flash, the randomized pipeline running, which is known in some other organization. For this one, it's equivalent. You just switch the roles of suppliers and customers. And for the last one, you can construct an NP relaxation plus an independent random, you get one amino. So at the end, you select the best of these options, best of these solutions, and you get one-third of the one over nine, which is maybe one over two. Questions is very fast discussion. If you have time, do you want to tell us about this contributor extension? So basically it relates to you can you can imagine that customers already chose. I don't know. We're gonna maybe speak uh about that. Uh okay, so just main takeaways. Okay, so just main takeaways. User preference and interaction determine what is the outcome of the platform. Fully static policies are not generally good in the worst case, but actually in practice they perform recent. One-side static policies are great, kind of like not that far from fully adaptive, 30%. And fully adaptive policies are the most powerful but may not fit every platform because applications. Each policy class presents their own unique. Each policy class presents their own unique challenge in terms of approximation. And actually, I didn't mention this, but for the independent demand model, you can show that the gap is one between fully static and fully adapted, so everything collapses. That's really absolute. So what's next? Well, there are a lot to improve. One thing is to maybe improve this one, because this relates to online some molar welfare. Or maybe just go directly to FA. I believe that maybe random or degree here could do something. really here to do something. And this problem, I mean, this seems like very static is this one by the die and the original. No, the die side. One side is this is one fourth is just the product of the two halves. Yeah, one fourth is just the product. Okay, thank you very much. So, one quick note. After lunch, we will be together.