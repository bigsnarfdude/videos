So welcome back everyone. Today is the second lecture and so we're going to continue on with the slide deck and if we have enough time I'll talk about a few other ideas. So just as a reminder, yesterday we kind of briefly talked about general ideas in UQ, some of the challenges that are present when you go to model. That are present when you go to model these systems, which are inherently high-dimensional, high-dimension of unstable directions, strongly nonlinear, stochasticity. And we talked about some of those issues in detail and how they kind of manifest themselves or how they manifest in this typical dynamical system, which is general, right? This is completely general. And so we looked at this model and how, you know, if you break it down into a system that is quadratic, how the quadratic terms are responsible for the transfers of energy between different scales in the flow. And so that's very critical. We looked at the computational challenges that arise because of this, that high dimensionality and that non-linearity. And that nonlinearity, and in particular, that wide range of scales in these systems. And then, importantly, we talked about the idea of, you know, whenever you're simulating a system, you're not quite simulating truth, right? There's always some kind of model error you impose, even if it's just a numerical method. And understanding that model error, I think, is one of the most important things when you go ahead and try to do anything. Try to do anything in science, right? So just so just be mindful of model error, I would say. And this is how that relates. You know, you have your imperfect model and there are errors here, right? Whether it's misspecified parameters, misspecified noise, maybe you do some order reduction. So M is not the same as N. And so it can arise from different. So it can arise from different contexts. You can also use model error to your advantage, say, in the context of data simulation. Sometimes it can help you. And again, the idea is we want to kind of overcome this curse of ensemble size or by trying to maybe reduce M and increase L, which are the number of ensembles in a Monte Carlo style simulation. Carlos Stas simulation, okay, if that's what you want to do. Okay, um, we also looked at this idea of projecting on modes and how that translates to, or how you can then see how the mean interacts with the fluctuations and the different scales of the fluctuations through this projection idea. So, this is, I think, very interesting. And then I think I mentioned that when you do this kind of breakdown, you get an equation. This kind of breakdown, you get an equation for the mean state and an equation for the covariance term. And if you drop this QF term, which is this third order term, which describes the exchanges of energy between these kind of triad interactions, that can cause a lot of issues. But again, this is typically done in practice, but what you would rather do is you replace QF with some additional noise. With some additional noise and damping. And the idea is there you would tune those so you can match the statistics of this reduced model with the covariance of the truth model. Okay. And one more thing I want to say about this is, so here I have a mean and a covariance. So the only distribution I can really fit to this, or the only distribution I would get if I did some sort of closure, is a Gaussian, right? So just keep that in mind. So just keep that in mind. So these are kind of some general ideas when it comes to these closure methods. We looked at data assimilation and this was the problem we tried to solve in the problem session. So I put the code up, the solution for the problem. So please take a look at that. And again, this. And again, this idea was: you have the truth, you have some model which might be imperfect in the homework. We used the same model for the truth as for the imperfect or the filter model, which is not necessarily true. If you continue and read that second chapter, you can see where they impose filter models that have model error due to numerical discretization. Model error due to numerical discretization. And some of those models are unstable. But with observations and tuning this noise term, you can actually have a filter that performs well, even though you're committing large model errors due to numerical discretization. Okay, so I would say that's pretty interesting, and I'd encourage you to read up on that. Kevin? And then we looked at some examples of extreme events after talking about general reduction methods. So we have the idea of non-Gaussian statistics. Okay, we talked about this a lot. I'm going to continue talking about it today. And we looked at how they might arise in physical systems. So we looked at some prototype examples where we have instabilities. Where we have instabilities that cause non-Gaussian statistics. And we mentioned that extreme events in these high-dimensional systems are really characterized by two attributes. One is the nonlinearity that couples different scales, and maybe uncertainty due to internal instabilities or stochastic excitation. And we saw that these systems typically have very large N. Systems typically have very large n millions small generally. So, direct computation through Monte Carlo is typically impossible. So, maybe if you're doing things from a purely data perspective, you have to go look at ideas like extreme value theory and so forth, or other approximations. Some of them we might talk about today. So we looked at linear systems where you have non-Gaussianity due to multiplicative noise. Okay. So this was the example. We looked also very quickly at a nonlinear system with both additive and multiplicative noise. So we'll probably revisit this later today in more detail. And we mentioned that this system has Has a bimodal style PDF with potential skewness depending on the model preference. Okay. And the last thing we talked about yesterday was this conceptual model for intermittently unstable systems where you had a correlated stochastic parametric excitation. And we saw that the switching of alpha between positive regimes and negative regimes causes large growth in the response of E. Large growth in the response of each. So, this is a simple thing, but again, I'm trying to actually, there's no closed form analytical formula for the distribution of U in equilibrium. So, my first paper was actually, I derived an approximate formula for the analytical formula for the distribution of u for the system. And so, the funny thing about So the funny thing about that is initially when my advisor told me about the problem, I thought it was already a solved problem. So I thought it was like a, he was just testing me. So I worked very hard because I didn't want to look, you know, I want to look like I wasn't too stupid. And then I derived like after many months, after many months of tweaking, an approximation for you. But the main idea there was just based on this picture, right? It looks like there's This picture, right? It looks like there's regimes where not much is going on. And then when this happens, there's a regime of the bursting behavior, right? And so that's what I leverage to help formulate that approximation. So very simple system, but very non-trivial. So another model where we see extreme events, but in this system, it's not due to instabilities. Not due to instabilities, is this passive tracer invection model where you have damping terms? Okay, so again, you have this nonlinear coupling term here. This is the distribution of the tracer and V is the velocity. So this T describes the concentration of a passive tracer. So passive tracer is a tracer without any mass. It's an idealization. In reality, tracers might have mass depending on what you're. Tracers might have mass depending on what you're looking at, but if they do have mass, this equation becomes non-local, it becomes a lot more challenging. And so one approximation is to assume the tracer is massless. Otherwise, it's a complete mess. And then so you have some additional damping terms as well, right? So this is your basic invection diffusion equation. Equation. So, one thing that has been done for this model over many years is consider different forms of the velocity field. So, here we have this velocity field with this specific structure, U for the horizontal velocity field and V for the vertical velocity field. And so, U is maybe modeling some sort of zonal flow, which only depends on time. Depends on time. And V is a shear, right? So V is the vertical velocity, only depends on the X director. So this is some sort of shear. And through this idea where we are imposing this structure, the velocity field, which is a simplification, right? Typically, this would be the solution of Navier-Stokes, but we're trying to make some simplifications here, which are still kind of characteristic of real life, but are not fully. Life, but are not fully truth. We oppose also the fact that the tracer probably has some sort of mean gradient as a result of the shear. And then if we substitute these two terms, we would have something like this. And then additionally, because we're working on a periodic domain, we can assume this V structure by projecting on Fourier modes. We could find out that. Um, we could find out the equation for how those Fourier coefficients evolve in time, and you'd get maybe something like this, right? So, you have again that imaginary term, which you can play around with to model different types of dispersive waves. And then we have this equation for the U variable, right? And this is the same equation that I showed a few slides ago, okay? So, this is kind of this double well distribution for the zonal flow. For the zonal flow. And what's interesting is you can carefully sit down and derive equations for the tracer statistics in this model. And you would see that the distribution of the tracer coefficients, like the Fourier coefficients, which was the Z's, if you will, in the few slides. You will, in the few slides ago, are non-Gaussian, right? So you have non-Gaussianity in each of the different coefficients of a tracer. And this is pretty interesting because it's actually, if you look at the resulting equations, you have this sort of maybe, I don't know if you'd want to call it resonance, but you don't have an instability. You don't have an instability that causes this. But because of But because of the interaction of this variable with the dispersive term, you have these regimes where you get non-Gaussian features. So just wanted to mention that as an interesting example. Okay. Another quick idea is this notion of conditionally Gaussian systems. And this is just a framework that can help you. Can help you more easily predict if your system has the structure non-Baussian statistics. So here I have U1 and U2. And this system is non-linear, but it has the special structure. It has a very special structure. And the way that we're thinking about U1 and U2 is that U1 represents maybe some observables. Maybe some observables in nature, maybe some slow process that we observe. And typically, the small scales are fast processes that we don't observe. And if I look at U1 and U2, if I assume U1 is fixed, if I assume U1 is fixed, right? If I assume U1 is fixed, I would see that this looks pretty straightforward, right? Pretty straightforward, right? If U1 is fixed, this is just like a normal SDE with linear parameters, right? U2 only enters this equation linearly. So this is useful because U2 becomes conditionally Gaussian given, say, a realization of the slow process, which means that the conditional distribution of U2 given U1 up to, say, time t. U1 up to say time t is Gaussian. And of course, the full statistics of U1 and U2 together can still be highly non-Gaussian, which would of course depend on U1. And so this is interesting because you can write down a closed form analytical expression for the mean state of U2 and the covariance of R2. And the covariance of R2, right? Given this fact. And this is exact, okay? Remember, U2 given U1 is Gaussian, so I only need the mean state of the covariance to characterize this. And here are the closed form formulas for that. So this is a type of filter, if you will, in the continuous time formulation. Okay, so maybe we'll talk about that a little bit more towards the end of the lecture. Towards the end of the lecture, if we have time. Okay, so this is nice because now I can observing, if our system has a structure, I can, you know, I have a realization of the truth, and then I can use that information to predict what the unobserved or fast processes are in the system. So, there's a good paper here on this idea, and they have many examples of systems that have this structure, which, of course, is. This structure, which of course is not true in general, but it helps to see examples of this because maybe you're looking at a specific system and perhaps you can make some simplifications or some reductions where you have the structure. And you can maybe use some of these ideas for UQ tasks. So one example of a conditionally Gaussian system is the Loran 63 model. Lauren 63 model. And this is a very old equation now. Just maybe a conceptual idea of atmospheric convection, but it's been used in many other domains now, from circuits to other areas of engineering as well, right? And this is your standard chaotic system with the butterfly tractor. So, I think in the original formulation, this was meant to model like a two-dimensional fluid flow that is being heated from below. And so there are like some parameters here that relate to the different constants in the original idea of this modeling convection, if you will. So if I look at this equation here, maybe you can tell me if I observe what. Here, maybe you can tell me if I observe what which variables should I observe to make the other variables linear, right? Um, where I have some non-linear terms here, x, y, x, z, and that's about it, right? X and Y changes to the next, sorry, yeah, yeah. It's just X. Yeah, exactly. Right. So if I fix X, right, this is linear, right? Z and Y are linear, and then this is now linear and linear, right? So if I observe X in the system, Y and Z become conditional like Gaussian, right? So this is a simple example of that, right? Of that idea where if X is your slow process or the observed state, I can exactly predict Y and Z. Now, here are some trajectories of that butterfly attractor. So, the idea would be that I only see X, right? And then I would get these two. They're mean states and the covariates. So it would be a probabilistic quantification of U2, right? So that's the idea there. There are other examples. There are other examples of this that are maybe a little more realistic. So, here's, I think this is like a theoretical framework to kind of understand large-scale atmospheric dynamics. So, maybe Richard and Adam know more about this. And so, these were derived from projections on bases functions, right? So, the idea of projection is still very useful, right? I think someone asked me, like, Very useful, right? I think someone asked me: Do people actually do this or use this in practice? Well, they do, and it helps them build conceptual models of what's happening in the atmosphere, such as switching events, right? And so this is one model for switching in the atmosphere. And once again, in this form, you don't have that conditionally Gaussian structure, but you can make some tweaks and show that there is some variables here that are. Some variables here that are conditionally Gaussian upon other variables. Okay. So that can be also obviously then leveraged for certain UQ tasks. And I think this helps to model like blocking events, right? Yeah. That was one of the main things here. And you can see in the phase space, you have kind of the switching between two eclipses. Switching between two equilibria in the cyclical. So you have transitions, which in this case are not that rare, but it's a useful conceptual model for understanding them. Okay. Okay. So now I would like to switch gears and talk about the basics of a very basic toolkit for. A very basic toolkit for UQ. So, I don't know how many folks here said they have seen SDEs in the past. I don't think maybe like three or four, right? By show of hands. Okay. So I'll try to go relatively quickly on this, but and you can maybe spend more time on this. I wanted to give just a quick highlight of SDEs in a very practical setting for UQ. Okay, because if you look at the literature, Okay, because if you look at the literature for SDEs, it can either be very mathematical, which is interesting, but maybe not, maybe you can't directly connect that with some of the applications. So since the topic is so broad, there's many books with many different flavors ranging from very theoretical to some more applied. The books on the very applied settings, I think, are less good than the pure math ones. There's not, I would say, The pure math ones, there's not, I would say, as many really good ones. But if you look at maybe some of the engineering books, where they use SDEs, they're quite good. So here are just some standard references. I think maybe I should have put another book from the engineering side that's also very good, which also talks about things like power spectra without going into too much of the math and being too detailed. Okay. So I think this one is pretty. Is pretty, um, a pretty good one from the physics perspective that I would recommend, and then I think this one's a little more theoretical. And this is numerical simulations book, which is kind of old at this point, but also good to kind of quickly scan through if you are. Okay. So let's quickly talk about some of the basics of probability. I think I'll only spend 30 minutes or 40 minutes on this. 40 minutes on this. So, um, remember, uh, concepts in probability, we have some sort of probability space, which is a three-tuple of a sample space, space of um, and events, and some sort of probability measure where we can assign real values to the events in the sample space, right? So, there is some structure I want to make sure that these events have. Um, so the jargon there is that it's just some sort of sigma algebra. Um, and And as I mentioned, this probability measure is a map from events from the sample space from 0 and 1, and it has to satisfy some of these two properties, right? The probability of null is 0, and the probability of the sample space is 1. And then we also have the fact that if A1, A2 are disjoint sets, then the probability of the union of those sets is the sum of the probability of those sets. Probability of those sets. And then, if these are maybe not necessarily disjoint, then the probability of the union of those sets is bounded by the sum of the probabilities of those sets, right? And that's hopefully easy to see from this, because if these are not necessarily disjoint, you lose some probability by the fact that they can overlap. So, the idea, yeah, these have to be, I think, closed under certain operations. And that's what a sigma algebra ensures. And there are some other kind of maybe details that are important that maybe I missed, but high level, these are the main axioms. Okay. A random variable. This is simply a mapping. It's simply a mapping of a sample space of Rn such that the inverse of this is an element of the sample space. So again, AR events on the sample space omega and script B is sigma algebra on Rn containing all of the subsets. Okay, so these are Theoretical details, which are important, but in practice, you don't usually think about these when you're doing manipulations, right? So there is a conventional notation for random variables, which the probability of a random variable should be written like this, but we typically do not have the probability of x in B versus this notation. Because this is telling me what's the Because this is telling me what's the probability of the events or the events at A, but we typically use this notation to denote that, right? So that's all I wanted to say about random variables. Do we have any questions? Okay. So distribution functions and density functions, we've looked at this in the figures, but here's In the figures, but here is the definition. Okay, so the cumulative distribution function is the probability that that random variable x is less than or equal to some real value r or see real value x, little x, which might live in our might be vector valued. And this is obviously understood component-wise. And then the density function, if it exists, is basically just Is basically just the derivative of this cumulative distribution function, right? So if x is a random variable, if there exists sort of this non-negative integrable function p such that this holds true, then p is called the density function for x. So we're doing things all in the continuous sense. We're not worried about degenerate distributions and all of that. Degenerate distributions and all of that, which typically might not arise in physical systems. So we're keeping things simple. So for the Gaussian distribution, we have random variable x, and we typically use this notation tilde to mean that random variable x is distributed like a normal with mean mu in covariance sigma. And then we have the value. The value for the density function here, where Î¼ is the mean of the random variable, and sigma x is the covariance matrix. And these mean values are computed by taking the following expectation with respect to the density as I've written down here. So we often use this kind of bracket notation to denote expectations. And similarly, the covariance would be defined by this. Would be defined by this, which again, to represent these integrals, we'll usually use this angle notation. So, this is all about probability. And then we are now looking at a stochastic process. So, a stochastic process written up there is a family of random variables. This is called the stochastic process with continuous. This is called the stochastic process with continuous time. So for each time t, x is a random variable, and t is continuous. And then one famous stochastic process is Brownian motion, and this has some special properties. So Brownian motion often denoted by W or maybe even V. This is a real value to Cassie. This is a real value to Castic Process such that we have several important properties. One is that it is continuous. The initial W at zero is equal to zero. And it has this important property, number three, which is the increments are independent and they have a normal distribution with variance t minus s. Okay, so this is heavily. Okay, so this is heavily used when you want to numerically solve SDEs, this fact, right? And the expectation of this Brownian motion is zero, and the expectation of the Browning motion squared is T. So the variance grows linearly with time. And so we have the property over here rewritten again for maybe small delta. For maybe small delta t, and we see the variance is delta t. So, eto SDEs, so we say a stochastic process satisfies the eto SDE if it has this kind of form, right? form right um so and then this is really a notation for this right um this is just notation for this and so you have an integral this is your standard integral um you know from normal capitalists maybe generalized a little bit to handle more exotic functions a and then you have this etho integral which is integrated with respect to brownian motion like that um so obviously um we know how to do these types of integrals We know how to do these types of integrals. We may not, we don't know how to do these types of integrals, so we have to kind of impose a definition on this. And the definition you impose on how to integrate that second integral gives you different types of calculus, right? So here in the Ito case, the way we integrate this is as follows. So we evaluate B at Tj minus one. Okay, so at the initial point. Okay, so at the initial point, and this gives us our standard veto calculus. Okay, and this is more useful for practical applications because we don't want to use the future value to evaluate this integral because in applications like finance and engineering, we want to use the current value to predict the future value of the system. But you can, there's different calculuses or different Different calculuses or different stochastic calculi where you use maybe the midpoint. There's even more exotic ones where this is evaluated at other points between Ti and between Tj minus I and Tj. But in applications, we typically stick to this. It's interesting that the limit becomes different depending on what you achieve. Yeah, that's the. Yeah, that's the that's that doesn't happen to me work with branchable functions yeah it's pretty interesting and and uh I didn't know but there I thought there was only like two options for this either the initial condition or the midpoint but I looked into it there are some people have invented different stochastic calculi where this is evaluated at other points in the domain like Evaluate at other points in the domain, like the endpoint, and they get there's books written on it because I had one student ask me that, and I looked into it. I was like, Oh, okay, I thought it was only on either Ito or the other when you do the midpoint, it's the stretch onovitch, right? So, um, and I don't remember what the name of the calculus is when you evaluate it at TJ, but but but you can look it up. But from a physical perspective, if you're taking sort of a white noise limit of a process that's actually correlated with time. Yeah. Correlated in time, then you do converge to a Skatonovich model. So often in the physical setting, it can be useful too. Yeah, okay. Yeah, yeah. So basic calculus, so properties that are heavily used if you actually want to manipulate SDEs are presented on this slide. Okay, so the expectation of this integral is zero. We also have the expectation of two integrals, two Ito integrals is this function here. So here, the time when you from t0 to t is the same in these two integrals. So it's the expectation of the functions integrated with time. And then we have this equation at the bottom here, which is pretty important, which tells you how to take the differential of a function of white noise. Of white noise. And this relates to the Ito formula. So because dw squared is dt, when you go into a Taylor expansion, you have to be careful. Unlike normal calculus, when you want to do a first-order Taylor expansion of a function like f of x here, maybe, or f of x here, rather, you would get. Here, rather, you would get only terms up to dt, and you'd neglect all the other terms. But because dw squared is proportional to dt, you have to carry that expansion up to second order. And if you do that, you would get the following ito formula. So that's something to keep in mind. I usually don't even use the Ito formula. Use the ITO formula. I just go by the fact that let's see where we are. Yeah, you have dx ADT plus B D W. So you just have to be careful that DX squared, when you carry this out, this is. This is V squared DT. The order is DT. So that's why when you look at plus a half here, that's why you get this term here. So that's the additional term here compared to normal Taylor expansion. So I usually just use this definition and just makes things easier instead of having to remember this all the time. Having to remember this all the time. And this is also important if you were trying to derive some of those equations earlier in the slide for the covariance terms, keep this in mind, right? Because you will miss a term if you don't use this. So for a scalar SDE, the ETO formula is used to derive how the density of the Density of the state evolves in time. So, this is very important. So, the Folker-Planck equation, this describes the evolution of a probability density function associated with a stochastic process. And this is straightforward to derive by looking at the time derivative of the mean of an arbitrary function f with respect to x, which is this scalar process here. And if you do integration by parts, you can easily show that. Easily show that the density P should evolve according to this P du. So, this is the famous Walker-Planck equation, and this is an invection diffusion equation. We have first derivatives, and then we have this diffusion term here, which you'll see has this B term, which is this last term. So, that's this diffusion term, and A is responsible for some. A is responsible for some advection of that density. Okay, so isn't this kind of the general case of Italy's formula? Is this a general case of Vitos formula? It's just that here we have a P term which is a function of one x and p is the density of x. P is the density of x. So the E2 formula, this is in the scalar. Ito formula, this is in the scalar case. So they're not the same. They're describing different ideas, right? This is the evolution of the density of X. Isn't this just a general case of Ito's equality? I don't think so. No, no. It's used here. You use Ito's formula, but it's not Ito's formula. We use Ito's formula to do this integral. To do this integral, right? Here's where it's used, right? I want to take the derivative of this. So I move the derivative inside this expectation, and then I get these two terms. How do I get these two terms? Well, I get them from this, right? Remember the expectation of the second term is zero. So that's where it arrives. So it's used, but it's not the same. All right. How do we use this? Well, when we're looking at systems, we often care about what's happening. We often care about what's happening in the equilibrium for looking at long-term forecasts. So, what we're really interested in are stationary solutions of the Fokker-Planck equation. So fixed points of the Fokker-Planck equation. The script L is kind of this operator here. And if I consider the linear SDE here, I can write down the Fokker-Plaf equation for this. And I want And I want dp/dt to be zero, which would imply that I want to solve this equation when it's equal to zero. And if I would solve this, which is pretty straightforward from normal manipulations, I would get a Gaussian density. There are some conditions you need to impose, such as the distribution goes to zero and x goes to infinity and same derivatives, but this is what you get. Chicken. Okay. So, this is how we use the Fokker plug for the Langevin equation, or sometimes called the Ornstein and Lubeck equation. Okay, so I've summarized some of the results for the Langevin equation in the unforced case on this slide, the pathwise solutions, the second order statistics. Okay, so it's a good exercise to see if you can derive these formulas for the variance and the expectation and the equilibrium statistics. And the equilibrium statistics. Okay, so remember, the equilibrium statistics, I'm looking at what happens when t0 goes to negative infinity, when I forget about all initial conditions. So this goes to zero, this goes to zero, and I'm only left with this, and this also goes to zero in the unforced case. If I had forcing, the forcing would impose some non-zero mean. Did you go very well? Yeah, could you go back one slide, please? So, the condition you mentioned, such that the density, I guess, should go to zero as x tends to be infinite. Can there be another case? Can the density may not go to zero as x tends to infinity? Physically, no. Physically, no, no. Because otherwise, the density would integrate to infinity, exactly. So, yeah, it has to integrate one, so it has to. One, so it has to fail. So, but like, I also wanted, like, is there a restriction like as t so density is a function of both x and t so the density may be limited by t at some point, like x may not tell to some points in some time, etc. But there's nothing like that, right? That seems x at sometimes. Times. No, I mean, you're looking at the stationary distribution, so DPTs. Yeah, well, yeah, exactly. Stationary, it should integrate to one. There might be some pathological cases, to be honest. I mean, in probability theory, there's a lot of, and probably Denise knows a lot more about that than I do, but there might be some pathological cases that I'm not aware of. But for practical purposes, I would say it's unusual. Probably not. I don't know exactly. Probably not. I don't know exactly. But also, physical systems, you know, you don't have things like unbounded energy, right? So density has to converge to zero at infinity. So you could change the topology of your domain, right? You could do it on a range by service. And then you'd have different boundary conditions. Okay. Good point. Yeah, exactly. So that's a good point. Yeah. So maybe I wasn't right there. So, maybe I wasn't right there when I said that. So, there's probably cases and different boundary conditions where that's not necessarily the case. Vector case, these are the corresponding formulas. Again, we have the pathwise solution, also exact mean and the covariance. Okay. Good exercises to double-check this. Okay. And these are again, this one is helpful when you're looking at. Is helpful when you're looking at the decomposition, the Galerican kind of style decomposition. So now I want to just quickly maybe look at a system. Maybe I'll just talk about this extremely quickly. And part of this is in the exercise where we have a two by two linear system, and we have this epsilon term that couples X with Y or vice versa. Okay, so So now this system is linear, but it has some interesting dynamics. Okay, so I've taken this model and I've written it as follows, where we have this operator L, which is given by the following plus some forcing turn. And so we want the system to have some sort of stable attractor. So we're imposing that the eigenvalues are negative. So a result of that is that the product of those two eigenvalues should be positive. And the sum of those two eigenvalues. Positive and the sum of those two ideas values should be less than zero. Okay, and given these two conditions, the system has a tractor infinite time. So this matrix L, you can compute the eigenvalues and you'd find that they would be given by the following. And yes. Can I ask for clarification? Are you using a tractor to mean that there is a stationary design? To mean that there is a stationary distribution here, you're not really formulating as a random dynamic. I'm talking for the deterministic. Yeah, forget about the noise. Yeah. Without noise. Oh. Yeah. Yeah. So often what we do is, and there's noise on the y variable, but we're thinking about analyzing the system, forgetting about the noise, seeing what the deterministic dynamics behave like. Okay. Behave like okay, yes, and then we have the noise, which again is some sort of forcing, you can think of it as some forcing in time, okay. Um, so um so you're looking at the system without noise as a homogeneous dynamical system, yeah, and you're using the term attractor in the yes, yeah, exactly, yeah. Um, otherwise, I think. Otherwise, I think it's quite challenging to intuitively understand the behavior of the system when we're trying to build some intuition about the system, right? So that's the idea. So we have any other questions? So pathwise solutions. Okay, this is linear. We saw the result here. So this is the formula. So, this is the formula for the pathwise solutions. Okay, they're in terms of this exponential of a matrix, which I can derive here exactly. And I can also derive the eigenvectors of this matrix, which are very important, okay? Because those define how the solutions behave in a pathwise sense. So we see that the eigenvectors depend on epsilon, okay, and epsilon. Okay, and epsilon, we're thinking of it as being some parameter. And the angle between these two eigenvectors is given by the following. So this is interesting because there are two limiting cases we're going to be looking at for this two by two system. One is when epsilon is small, and the other case is when epsilon goes to infinity. And in both of those two cases, these eigenvectors Vectors become parallel. They become parallel. So you can see that from this limit, right? Epsilon goes to zero, they're going to become parallel, and same with epsilon goes to two. What about the statistics of this two by two system? Okay, again, we can do this completely analytically, and we would have the following formula for the mean dynamics. And then we would have the following for the covariance. So these are not on the attractor yet, right? We have a T0 and we have some initial conditions. On the attractor, we're going to just take these equations and see what happens when t goes to minus infinity, when we've basically forgotten all those initial conditions, and we define that the mean state. And we define that the mean state is given by this. And you could integrate this exactly, and we'd find the following equations for the x and y state having the liquidity. And if there was no forcing, these would just collapse to zero. Same thing with the covariance, and this is interesting. So if we look at the covariance limit, and this is actually a pretty tedious algebra for the covariance, it's very tedious, but you can do it. It's very tedious, but you can do it. You would obtain the following, very simple-looking equation, but rather annoying to actually write down and get to here. So this is the covariance on the attractor. And then what we're going to look at are the eigenvectors of the covariance matrix. And remember, the covariance matrix, this is some Gaussian density, right? So what we're trying to find. Density, right? So, what we're trying to find, you know, if we have a density like this, the eigenvectors tell me, you know, the direction of the first one, maybe where most of the mass is concentrated, or and the second one, maybe where less mass is concentrated. But it just kind of gives me the two directions that characterize that covariance matrix. And so, again, you can derive the eigenvectors of the So, again, you can derive the eigenvectors of the covariance matrix, which you would define are given by the following, and you can verify that these are orthogonal. Okay, these are going to always be orthogonal. And also the eigenvalues. So the limit is called the covariance of sigma on a trial. The covariance of sigma on a tractor. Yeah, the long-term covariance, yeah. Sounds like an evasive terminal because now you're looking at a random attractor. Yeah, because this is based on the pathway solutions, right? We're looking at the like we're looking at the pathway solutions given by this. Yeah, and then we And then we're looking at the deterministic attractor. So I said deterministic here, right? Is that what I said? I think you're right. So those two are different things. So this analysis is based on ignoring noise. Yeah, so the issue is not. This one is not the same as the attractor that you're referring to there. I think it's a different concept of attraction. You're talking about a pullback attractor or something like that. Yeah, so that's how it's formulated, right? You're letting T0 go to minus infinity. So it's a pullback random attractor. Or are you just saying that this is the limiting distribution? For the covariance? Yeah, this is the limiting. Yeah, it's a Gaussian. This is the limiting, yeah. It's a it's a Gaussian at the end, right? It's a Gaussian at the end. This is the covariance of the Gaussian. Um, have you suppressed the forcing to do this calculation? Uh, no, forcing is not suppressed because the covariance doesn't depend on the forcing. Um, you subtract it away. Um, yeah, it's only in the mean, yeah. Yeah, that makes sense. So on this. On this, it may be an elementary question, but like t0 is going to minus infinity. But is t tending to infinity? But why does t vanish? I do not. Why does t vanish? Because the difference between them also tends to take the infinity. You can either think about this as t goes to minus infinity or t goes to infinity. Goes to minus infinity or t goes to infinity, you get the same results. Okay, um, either t zero goes to minus infinity or t goes to infinity. So, it's just a big difference between t0 and t that we're looking at. It's like your system has been running for a really, really long time. So, what time it is now is that building that yeah and Yeah, and again, you can, you know, you can look at, let's see, yeah, you know, there's different, you know, if t goes to minus infinity, and remember, L has negative eigenvalues, this drops. Or if you could think about t goes to infinity, same thing also drops. So different ways to think about it. Same results. And question on page 51. My question is that why do we care about the arguments between the ideas? We'll see the relevance of those in a moment. So very quickly, then so we have this system here, okay, and what you can derive is Derive is first, you can have the following solution of the y variable. So you can integrate the y variable directly and you would get the following solution. So this is integrating this. I first integrate this and I plug it back into X. So then the differential of X dot is given. The differential of x dot is given by the following, okay. So let me so again, so this is integrating this, okay? So you have epsilon x fy, epsilon x fy, and then by, but then because this is we're using an integrating factor, it shows up as the result is these kind of convolutions. And then once we have this, we're going to just. We have this, we're going to just see what happens when you plug it into x, okay. And the result is the following, okay. And this is x dot. What's interesting in this result here is we have one term at the end, which is epsilon sigma. Okay, so when epsilon multiplied by sigma goes to infinity, a lot of the variance is pumped in. Is pumped into the x variable. And remember, we're only injecting noise on y. So when epsilon sigma goes to infinity, we're injecting actually a lot of the noise into that x variable. And then in the limit where epsilon multiplied by sigma goes to zero, the dynamics become deterministic. Okay, because that last term stops. Last term pops out. And then so it's and that also makes sense if I just look at this equation here. Epsilon goes to zero, y does not impact x, so x basically becomes deterministic. Okay. So from the UQ perspective, this is significant, right? Because we're increasing the variance of x. Increasing the variance of x, right, in that configuration. Because one way of thinking about this two by two system is we have a resolved variable x and unresolved variable y. And so if we're in this configuration here, we're getting a lot of variants being pumped into the X variable. And so that can make things more challenging from the Make things more challenging from the UQ perspective. So, but before that, let's just look at some configurations of this two by two system. And maybe we'll kind of quickly go through this in the interest of time. So, in this configuration, when epsilon is very small, again, we have those eigenvectors of the dynamics itself being close to parallel. So, those are given by V1 and V2. And then W1, W2 are the eigenvectors of the covariance. And so we see in this state, as I mentioned previously, most of the energy is still contained, or most of the energy is contained in the unresolved variable, which is W2. W2. So that's this direction here. And the eigenvectors of the dynamics are roughly Are roughly parallel to W2 if you plot them. In the other configuration, when epsilon is large, the picture flips. So you see here now, the eigenvectors V1 and V2 are now parallel to W2. Okay. Whereas in here, sorry, I think I flipped. I think I flipped my description around. Yeah. W. Yeah, so this is, sorry, this is correct. Yeah. W2. What's important here is, yeah, so the eigenvectors are parallel, but the eigenvalue of w2 is tending to infinity. So all the uncertainty, the eigenvalue of w2 tells me how this. How this is stretched. Okay, and so you see now in this configuration, the dynamics are now parallel to that direction where most of the variance lives. Whereas in this other picture, the opposite happens. So this is the text. Is the x direction here, and this is the y variable. Whereas here, this is x and this is y. So there's more variance in that x variable. And then you have, you can also see what happens when epsilon is order one, and in which case here, nothing, I would say, terrible. I mean, this is an okay configuration, right? Configuration, right? Both of the two variables are, I would say, kind of order one in terms of their variances. So it's not a terribly interesting scenario because also you don't have transient growth because the eigenvectors of that L matrix are now orthogonal. So you don't have that transient growth due to kind of. That transient growth due to kind of non-normal dynamics because those two eigenvectors are close to each other in that in this regime where epsilon is greater than one. Okay, so sorry, this is the last letter. What's the green dot there? The green dot, I believe, is the fixed point, or I don't actually remember what the green dot is. What about like where you have those are the string functions? Those are the stream functions of the flow. The deterministic, yeah, the deterministic. Here's an important slide. So we have X and Y. We know this is a two by two system. Suppose we only observe X in nature. X okay, in nature. So the only thing I have access to is the mean of X and the covariance of X. Okay, so the only thing we have information or access to are marginals. And so what we're looking at is, okay, so we have an imperfect model which has the same structure as the original model, but with unknown parameters with the tilde here. Okay, so all the parameters here are unknown. Parameters here are unknown, but we only observe X. We only observe X. What are some of the interesting problems that can happen when you go ahead and use this to maybe determine what these parameters are? Okay, so we already computed the density, so we can find out what the value for the marginal mean is. We can find out what the exact formula for the marginal variance is. Marginal variances, and even the autocorrelation function, which I don't spend too much time on, but it's just maybe the variance in time of x or 1, 1. That's the first variable. Okay. So these are all constraints we can use to determine what these parameters are. Okay. So I have a constraint for the mean, I have a constraint for the variance, and I have a constraint for the autocore. Constraint for the autocorrelation function, which is really just two constraints on the two eigenvalues. So I have six unknowns and I have four equations. And this is telling me that my imperfect model with the tilde should have the same eigenvalues as the truth. And this quantity here, which is from this term, should equal the truth as well. Okay, my unknown parameters will equal the truth. The truth. And this equation comes from the covariance. So I have six unknowns, four constraints. That leaves me with two degrees of freedom in terms of how to parameterize that. So one way to parametrize that is given by the following. So suppose I decide to parametrize sigma and the forcing. And I go back. Okay, and I go back here and I, you know, use these equations to determine what all the other parameters are. I could do that. So, this is a two-parameter family of models that have the same marginal equilibrium statistics as the truth. That's by construction. And what do we see here with this epsilon tone? W1, w2 are three. So, what do we see here? See here. And this is an issue, right? So depending on what W1 is, the dynamics can range from epsilon being very small to very large in the imperfect model. So this is, you know, we can, you know, depending on any fixed epsilon in the true system, depending on what value of W1. Depending on what value of W1, we can choose. The imperfect model can display dynamics ranging from normal to very non-normal. So, this is kind of, I think, an important kind of test case or things to keep in mind when you're maybe looking at other systems. And it has important consequences, obviously, for UQ, right? Epsilon is an important parameter of the system. Is an important parameter in the system. And so this type of parameterization would lead to a failure. So these equations are all in front of the stationary distribution. Aren't there other things that you can use to estimate the parameters, like the dynamics, the derivatives, for example, dx terms? Oops. Well, we're trying to construct the system with correct equilibrium statistics. Well, in addition to those, you can also try to fit the dynamics. Through like maybe some sort of parameter estimation on a signal or on one state or one signal. Is that what you're thinking? Certainly. There's other ways to fit the parameters. Very true. There are other ways to fit the parameters. There are other ways to put the parameters. Like Ax plus B D T sigma, I can get my d axis and do a regression and try to get the a and b to and if you did that would you have the correct likelihood estimation type of thing you can certainly do other ideas i i'm not like if you start from a different perspective that might give you something but a mean That might give you something, but it may not maybe have the correct equilibrium statistics unless you maybe build it in. So, this is kind of, you know, people care about the equilibrium statistics. It's not the only way you can find model parameters, right? You can use, you know, you can construct the likelihood and sample from the likelihood to find what those parameters are. But matching equilibrium statistics is very easy to do if you have the truth. If you have the truth. And that's kind of what I mentioned earlier on when we had that QF term, where I said, okay, we know nature has some sort of equilibrium. So let's tune the covariance to have match statistics. But that's not the only way of doing it. It's possible, you know, because, I mean, as you say here, you can come up with a very different system if you just try to use a stationary, the equilibrium distribution. A stationary equilibrium distribution, you need to use additional information. And you know the dynamics, I mean, you know the basic structure of the dynamics. So you could, I mean, you need to have likelihood or some other estimation. And then in addition, you can incorporate these as constraints. Even if you do likelihood, you know, with epsilon being so sensitive, it may not. You know, sampling from that posterior may not, it may be challenging, right? Because it's so sensitive to epsilon. So, there, I think there are other methods, certainly. I haven't maybe tested seeing what happens when you do parameter estimated likelihood on this, but there is still the sensitivity epsilon, which I don't think maybe is completely avoided for other techniques, but that might supplement with more information, which could help constrain the system further. Constrain the system further. Yeah. But it seems to be that any other information would have to come from deviations from stationarity. Yeah, exactly. Or also the same information that you already have. Exactly. And I'm not sure in a real state, how you, in a real system, I know how far you are from it. Well, you're trying to look at short-term dynamics. But you're looking at maybe a single realization in that context, right? And that is prone to error, right? If you're just looking at a single realization. Looking at a single realization. You mean like a single trajectory? Yes. You're observing the same dynamics. You should be able to. I think it's a problem. I don't think it's. I think it depends, right? I think it depends. So So, okay. Maybe I will quickly just talk about these, but I won't go into detail. So, this system, you can derive, as I mentioned earlier, the equilibrium density, which we have written down here. There's another system here, which has both multiplicative and additive noise and forcing, and surprisingly. And surprisingly, you can actually drive the equilibrium statistics of this system. And you would find that the stationary solution is given by the following. It's pretty interesting that you can do that. And it's a little messy. When you go ahead and actually integrate this, you get arctags and so forth, but it's doable. And so you'd get Depending on the regimes, maybe Gaussian, maybe non-Gaussian. Depending on the forcing, you can introduce skewness. And again, these are all analytical results. So the black is analytical. The numerics are the right. So it agrees with the numerics. And this slide is showing that we, I think in this figure, we start off with some initial density, and it's showing you how that density evolves to the. How that density evolves to the equilibrium in time, right? So it initially starts off here and shrinks to the equilibrium overhand. Well, there's this approach to the equilibrium density. And this is the same thing, but for a different class of problems. This model here, and we looked at this previously, so we had this nonlinear This nonlinear potential here, and we have multiplicative and additive noise. Again, interestingly enough, you can derive an exact formula for the equilibrium density for the system, which looks as follows. So heavily non-Gaussian even has bimodal features depending on C and B and A, but this is the density for that. This is the density for that, which is pretty interesting. Okay. And obviously, when A and B is zero, we get the standard formula, which you can derive just very easily just based on the gradient of the potential. Okay. Okay. So maybe I'll also mention a few more points here about systems that are conditionally linear with regime switching. Regime switching. So at the top here, I have the standard Ornstein-Lullen-Bach-Mongevan equation, right? We have gamma, omega, and some forcing. And here, if gamma is some diffusion process, this is the formula for the statistics of U. And again, this is a non-Gaussian system, okay, non-Gaussian system. And I mentioned depending on gamma. And I mentioned depending on gamma, you can trigger instabilities in the system. So, one thing they've done here is looked at cases where gamma is a two-state jump process between negative and positive values. And in the negative regime, you have the following formula, right? So, this is the distribution, or this is the solution of you given gamma is positive, and this is maybe given gamma is negative, right? Negative, right? So, the switching behavior, similar to that other example that I provided, triggers these instabilities, right? So, we see gamma goes from regimes where it's slightly negative to regimes where it's positive, and then we have the solution in each one of those regimes, okay? Conditional solution. So, the point of this slide is we can use these types of ideas to build more complicated features. Complicated features in PDEs with like large-scale instabilities that are vected due to waves or dispersion, right? So this is one example of that. We have a PDE at the top here, okay, on a periodic domain. And so you could represent the solution of a PDE on a periodic domain through Fourier modes, which is what you do here. And And the result of this is that each coefficient, each Fourier coefficient, is described by this linear Langevin equation. So that's the result. And these are coefficients defined in the Fourier domain, which represent damping and wave-like features. So these are the terms that have the imaginary. That have the imaginary component here. And these are the damping parameters here. So you can have, you can construct different types of damping, such as linear damping, such as normal viscosity or engineering viscosity or hyper-viscosity by changing how what value of k here is. So K should be powers of two to have it damp. Powers of two to have damp the modes and script p and can gamma, those are functionals on the derivative operator. Yes, yeah, yeah, these are defined in the Fourier domain. Yeah, yeah, yeah. So odd powers give you wave-like dispersive features, even powers will give you damping, which would show up here, okay? So these are going to be IK to the power two, maybe four, and so forth, okay. So forth, okay. So, this is what you have. So, what you can do is: okay, so we've seen that depending on gamma, I can make the system stable, unstable. So, I can build this into this system here. And here's an example of that, where you have this case where it's stable, it switches to this unstable regime, and then you have this kind of wave propagating, this unstable wave. This unstable weight propagating in time. This is in that original PDP. So, this is pretty interesting, where you can kind of build simple models that are pretty representative of natural signals. So that, I guess, concludes this lecture. I will also post another slide deck later or after this talk, talking about some other ideas on. Talking about some other ideas on how you can compute non-Gaussian statistics through sampling ideas. And this is kind of based on leveraging methods in Gaussian process regression and how to do the sampling to define regions in space where extreme events are important. Um, extreme events are important, okay. So, I'm not going to have any time to talk about that. Um, so I'll just post this. And if you have questions or are interested in how this works, um, feel free to reach out. Okay, so I think that concludes today's lecture, so I'm happy to take any questions at this point. It's based on slide 39. Slide 39? Yes, that's the Sharm-Made Raw model. The parameters of the equation of the model based on a real-world scenario, real-world data. Sorry, can you quite hear that? I was just wondering if the parameters of the model, the equation. Parameters of the model, the equations of the model are based on like a real-world scenario. No, this is just a simulation of this directly. Okay. Numerically integrating this. Okay. There's more loss of it. Is there another question? No, sorry. Okay, if there are no more questions, I think we have a coffee break. Okay. And we have another exercise session later today. The exercise session, the problems that I posted are all, you know, verifying some of the facts in the slide deck just to make. Find some of the facts in the slide deck just to make sure you can do things. Different than yesterday. I did post the solutions for the filtering problem. So please double check. And I think that's it. Yep. Thank you. That's good then. I don't know. Yeah, maybe I should have approached that. Uh yeah, maybe I should have bridged that off and double-checked your slides. It's a lucky coincidence. Either finder well they're not so um so we can observe cross letters like Xtanel like the prime This is an option for the children. It was nice. You want additional meat, you want different parameters. There's a whole lot of statistics of things. Like the two clothes. The dynamics are very triangles. All you need to do is there's a triangle. It was like eagle, eagle, trip, then this appearance. And then this becomes a process. So there's the residence. You go this way. Yeah, so you go to residence. Yes, and then you keep it up and go into the language. Yeah, okay. Yeah, we could slice up. And then the likelihood is based on, I guess you can use multiple trajectories to do the likelihood or sample multiple trajectories. As long as it is long enough. Sure. Sure. Long enough. I mean, if you don't have a long enough trajectory. If you don't have long enough trajectories or if you don't have a long enough trajectory, then why would you think it was stationary? Yeah, you know, people typically have measurements of the degree of density. You know, we know the mean state of the climate, we know the rock variability of the climate. So then it's because we have observations. But then the question is: which signals should I use to match? I use to match X or let me think about. So, this is done per, I guess this can, you can do this for also not a scalar as well, right? For the vector case, you could do the likelihood, right? Yeah, I mean, this should work as long as your noise has independent influence, right? Then you can just take an interval. Can just take an interval, you're essentially dividing it into small intervals, and you have independent observations on those intervals. Um, I don't know. I mean, I can try it as an exercise to see if it gives you anything different. I don't think you really, do you think this is going to add more constraints or it's going to be better than just matching people? Identifies the parameters, like I mean, of um, six parameters. Symptotic consistency, it's it's known. Consistency. It's known. But then it's like, how long does this signal have to be, right? That's the question. How fast is that? Or how many trajectories do I have to do? And it's this is based on a single trajectory. So consistency would look at how the p-hats converge to true parameters as p goes to infinity. I think it shouldn't take too long. Think it doesn't shouldn't take too long if your noise is like something like brownie motion. Yeah, I think some of the challenges I've had with likelihood in the past is that, you know, if the model is like, sometimes it doesn't give you the actual truth. Like it's not like the truth is here, but the value is not where the truth is. Like I forgot the way to describe it. It's like the system is unidentifiable, so it doesn't actually give you. So, it doesn't actually give you like I've had problems with that where it's no matter what, you get a posterior from a likelihood, or you can sample the likelihood and find the posterior. And it's like the value is here where the truth is like here, right? It's like depending on the structure of the model, it's not in a way which are unidentifiable and like Uh, like, I don't think you can just do this and always get the correct answer. Yeah, you're right. Yeah, there are situations, and also, you know, matching the statistics, if you can do it, I mean, that's way easier. And I don't, I don't know if this gives you more, because here you're using a trajectory. And then that's like maybe a short ensemble. Maybe you don't have it for infinity, which you typically don't, right? You can only maybe simulate a short amount of time. Maybe simulate a short amount of time, or maybe you can simulate multiple ensembles from, so you can somehow adapt this to be that. Okay, so the thing is, as long as you have a lot of observations, it doesn't matter how long it is, right? So it depends on your time resolution. It could be a short interval, but you have high resolution, you have enough observations in that case. But if you have only four observations in a trajectory, yes, this wouldn't work. But if you have high. This wouldn't work. But if you have 100 observations, that should give you enough information. Because you create those independent intervals, and it's essentially like those are your independent observations. Yeah, parametrizations that are like essentially unidentified. That's what I know. Yeah, I know, but those, you know, that's like a separate type of problem. But I do think that problem has that characteristic. If you do do this, maybe I'll double, I'll try it, but I think it has that problem. I'll double check because it's like these slow fast systems, it's like it's like one of the main challenges. But I don't believe that just putting the stationary distribution, you can correctly identify the parameters. This is a, I mean. I mean, I don't think there is a theory that says that that's going to give you like consistency. But for this, there is a theory. I don't know. I don't, maybe, maybe. I think matching the statistics, I think, is a very good idea because at least, like, what if I do this and then I find the equilibrium statistics of this don't match my truth? Many different statistics. Match the truth. Many different systems with the same equilibrium distribution. Sure. Right? Yeah, sure. They can have different dynamics. Sure. Yeah, they know, of course. But the likelihood, the thing is, if the dynamics are different, your likelihood function, like the densities are going to be different. The parameters need to identify the likelihood, but they don't. I mean, yeah, I just, I don't know. I mean, Yeah, I just don't know. I mean, I've had problems with likelihood not giving me the correct parameter values in the. Well, it's because most of the time you can't really maximize them numerically. Well, if you do, if you just sample from the likelihood, like if you do MCMC, just sample it, I've still had issues where it doesn't match the truth. Well, the likelihood is that the thing is, this is not a convex function of p. So you can't find the optimal p. And that's the problem with maximum likelihood. You can't. You can't numerical methods want. So, maybe not. I'm not sampling from the likelihood to find the posterior, right? Not just maximizing the likelihood, like if you actually just find the posterior of those parameters, right? Like, so I've done that for certain problems. I'm not a posterior distribution. I'm talking about okay, this is the maximum likelihood, or or what if it's bimodal? You know, it's bimodal, and then your maximum. modal and then your your maximum likelihood tells you this okay um so i guess my point is that i i don't think it just works um your likelihood defines the p it doesn't really give you your um i mean are you saying the distribution of the p hat is no i'm saying this is my likelihood say uh the distribution of the the posterior likelihood The posterior likelihood just gives you like the max value here, right? Or if the likely, if the distribution of the posterior is like this, or the likelihood, right? I mean, just forget about the posterior, just say the likelihood. The distribution of the likelihood, it's a probability density, right? Well, the maximum likelihood is just finding that point P, right? And of course, it's not maybe one dimensional, it's maybe some high-dimensional destroyation with multiple parameters, but it just gives you that one value. Parameters, but it just gives you that one value, right? Um, and so I guess the problem is now in most of the time, your likelihood is not a convex function of p it's not, it's not like that. And most of the time, you don't know how it looks like. Yeah, that's why it's not a very practical method to use because you can't really maximize it. Really maximize it, you don't know how analytically it looks like, and you know that it's non-convex. So, there are lots of local optimas numerically, it's a pain to try to optimize, and it's super slow. So, those are the things that makes it not work. But in simple cases, you can write analytical formulas would work. Yeah, um, yeah, yeah, yeah, yeah, no, definitely. Yeah, yeah, yeah, yeah, yeah, definitely, definitely. Okay, so let's go get coffee. Yeah. Yeah, there's different approaches. I don't know. When I tried to do that was one thing I was doing, I was doing combined data simulation with parameter estimation. And then, yeah, you have a posterior for the parameters. Parameters. You can do MCMC, find the posterior distribution. And it doesn't really match what the actual values are because there's this kind of unidentifiability in the original system. So I guess my point is, I'm not convinced this is going to be better than just matching equilibrium statistics. It might be in the context. I don't know, to be honest. I don't know. I just feel like, you know. I just feel like, you know, matching. Symptotic consistency should imply that it will match. It will match. No matter what the system is and the parameters of the system. Well, if you have a theory that says that your estimator, maximum likelihood estimator, is asymptotically consistent, as T goes to infinity, those parameters will have to match the stationary. T infinity, that's the problem. Yeah, so maybe. Yeah, so maybe yeah, I mean, I guess for that system, you can probably play around with it and see what you get. So two by two, but you have this small epsilon. That's what worries me with the non-normal. I was pretty sure that it's actually not really hard for sound or something. I don't know if it's just sounding or is it talking? Oh, there we go. Hey, if you hadn't happened yesterday, and I was wondering, I don't often use my tablet at this.  Do you have weight access as good weight data when you talk about it? I don't. That's the common answer. I don't know if we weren't at the workshop last year, but you were. Here, but you were Mike, you know, he used to work at En-ROAL, yeah, closely with these folks. So, I mean, well, I've seen wake maybe one individual surviving with some, you know, but they did one experiment. I mean, because it takes a lot of measurements to characterize a wake and that makes it a really yeah. I mean, I think there's good, there's good. I'm going to show a picture of SAR data, right? But you can see the wakes from there. Yes. Yes. Can't even get it. I just realized what for Joshua. You do all this numerical approximation of weights, but you don't have a lot of data to compare. I guess. You know who does, sure. It's only farms. But even they probably have, you know, they would know the weight impacts on the power generation at the next turbine. But I'm guessing there are no measurements in between. Twin stuff or yeah, yeah, unless you're doing 100 minutes like the flyer thing gets pretty expensive, right? It's not like you would go out there and have like dozens of them in your lines or everything. And even would. And even then, you get maybe you get turbulence intensity, but that's not necessarily the best way to, yeah. But you have something. You have something. Yeah. Can you get higher order? I mean, with ATCP backups, you can get higher order turbines. You can give higher order turbulence measurements. I haven't looked at some of them IR. I don't know that people have done that. I mean, it's similar in nature. It's just, I guess, there might be some. I know with ADCP, there's a lot of it's difficult. So it's much easier to set up your ADCP with the beams or why the flow and things like that. And if you don't, it's all quite. I haven't read a book why it's challenging. I quickly. I'm quite sure that it doesn't. They don't need to do it when the beads aren't aligned, right? It's all calculated. They're just not exactly. They're getting full 3D curly boxes from the United States. Well, I don't think full 3D curly boxes. What kind of sample they take up? You can either like GAL or Hertz or something like that. So you're using a pretty high sample. That's your pretty high sales that you make. Well, that's one area that you can do with lighter than okay. That's that's the challenge. You think you know, they have these spots they do with different reasons. But I mean, maybe if you were just to do a fixed beam, that wouldn't be quite what you mean. Must be more difficult to just fix beams on the ABCP. So it's maybe that the behavior of the beams is more predictable. Beams. That's a more predictable water than the heat into air. Like this, a single beam strain value lighter labels must work recently. And this is where I kind of know. I've never really broken into that. It's not as fault. My initial instinct is it's not as easy to just partially because what's been driving. partially because what's been driving the innovation and the use is that ACs are the, or there's the industry out there that's driven by oceanographic research. LIDAR is driven by really being driven by industry more than the main ECPs that are sold. I see. You know, the amount of money is very expensive, right? And people are paying a lot of money into them. But they were not experimental apparels for explicit research and stuff like that. And the people using that fully are. People using that bully are the industry, right? So you're building an ADCP and you're, and most of your clients are oceanographic researchers. Well, that's what you have to deal with. They have to tell them how they work. You have to describe it. Most of your clients are industry and all they want is the result. Do it all on the machines. Don't tell me anything. Yeah, I know the ADCPs do that. Some of them come with all the software, does it all know social math researchers trying to rip it all apart? Researchers trying to rip it all apart. Yeah, we were data stuck. And we'd see weird things, and I'd be trying to figure out what was happening. And luckily, the reverse engineer was going on. At some time, there was a project manager who was working on coordinating this project who was in direct contact with Axis. And so they couldn't go and ask them these questions. And ask these questions, but yeah. That's what you need. That's difficult, right? Yeah. You don't need to process data. Are you doing it right? Do you want to discuss it? No. I still did that, but I.