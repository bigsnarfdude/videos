Thank you very much. Thank you very much for the opportunity to speak at this workshop and to tell you about some work, which is not exactly what you guys are looking at, but I'm hoping to present to you some other areas and problems where your tools and the dynamic algebraic combinatorics can be applied. Bray combinatorics can be applied. So let's start. Let me just select. Okay, so linear extensions. Of course, we know very well what this is. So we start with a positive. I put the smallest elements on top, and these arrows are indicating that B is bigger than C, for example, in this case. So this is the In this case, so this is the notation. And linear extensions, of course, are all possible ways of ordering these elements to a total order so that they respect the partial order. So we can view them as permutations of the elements or words or labelings of the elements of the post-it with numbers which respect the order, right? So here for this particular post-it, there are This particular posit, there are five linear extensions, and each linear extension is also a word of the element. So A is labeled one, so A comes in first place, C is labeled two, C comes in second place, and so on, right? So this is standard notions, okay? And so the So, the thing that we, as combinatorialists, care about is the number of linear extensions. And in general, this is a sharpie-hard problem as Peter Winkler's result from more than what 20 years ago. So, we cannot really hope for any kind of formula. We have, though, nice formulas in some cases, like in our favorite cases of standard young W. Standard Young Double. So, if we take our posit to be a Young diagram, like in this case, the partition 3-3, then the number of linear extensions here is just our favorite Catalan numbers, right? So, from then on, so looking at these general notions, there is one, so other than One, so other than the fact that there is no formula, but there are still properties of the number of linear extensions that are not understood or could be understood in some quantitative sense. And this one of them concerns the sorting probabilities of two elements in the posit. So, for the remainder of this talk, I would be fixing some particular elements. Particular elements, and I will be considering linear extensions with some properties with respect to these elements. So, for example, in this case, we care about linear extensions for which x appears before y, or the value of x is smaller than y. So, here let's take this. It's the simplest interesting posit that we can do is this. This union of two chain and a singleton. So then, if we look at the sorting probability of A less than C, we are just looking at what is the proportion of linear extensions for which A appears before C. And in this case, we have two out of the three, so the sorting probability is two-thirds. And these two-thirds. And this two-thirds, and for the other case, one-third is a magic number. So, just some background why people cared about this quantity has to do with sorting under partial information. So, our comparison-based algorithms have an upper bound in how fast they can work, and the optimal solution would be to always choose to arrange. To arrange pairs for which this sorting probability is close to one-half. Okay, so the magic numbers one-third and two-thirds are the basis of this one-third, two-thirds conjecture, which is so still open for so many years. And it says that for every posit, which is not a total order, there exists two elements for which the sorting probability. For which the sorting probability is between one-third and two-thirds, or if we want to do this in enumerative combinatoric style, we just want to say that there exist two numbers, two elements in the posit x and y, such that the linear extensions for which x is less than y are no more than twice the number of linear extensions for which y is less than x. For which y is less than x. And in their survey, Brightwell, Felsner, and Trotter in 1995 said that this problem remains one of the most intriguing problems in the combinatorial theory of posets and is still open now 25 years or 26 years later. And what are some results here? So this was a relatively quickly This was relatively quickly obtained. So these bounds are a little bit weaker than one-thirds and two-thirds. So here is another closer bound. But the other results concerned special types of posits, which I will show you in a moment, just to get some feeling how these things work. So post-its of WID2, so post-its of WIT2, just every anti-chain has or The every anti-chain has order most two and various other special cases. So notably, Bruce Sagan and Olson proved in 2018 that this calls for any skew-young diagram. So let's, by the way, please interrupt. By the way, please interrupt me if you have any questions, or so this is not maybe a very familiar topic. So, okay. So, actually, now I can see more of you. Okay, so um Let's do a warm-up. And so, this is going to be a simple proof, nothing new so far, but the reason I'm doing it is so that gets you a feeling what sort of quantities would be important in this business. So let's take our favorite young diagrams and let's say that we want to prove the one-third, two-thirds conjecture for them. Conjecture for them. So if you proceed like an enumerative combinatorialist, you would want to choose, you want to figure out which X and Y they're going to be. And that's actually the hard part because the whole thing is about existence and we can't really figure out which pairs are going to be the major players. But let's make an educated guess. So let's take X to be the X to be the second element on the first row, and we are going to choose Y from one of these guys. And how do we do this? So we consider restricted linear extensions. So, and this talk is about restricted linear extensions from now on. So, there is the first thing is how many linear extensions have y0 before x before y1 and And this means that, well, this is the smallest element gonna be one. X, so then where does 2 go? So 2 is either Y1 or X, so it's going to be X in this case. And then Y1, actually, no, we don't know what the value of Y1 is going to be, but it's going to be bigger than 2. So how many standard Young Tableau are there with these properties? These properties, well, it's exactly the number of standard seang tableau of this shape, skew shape, so which is this guy, right? Okay, so now let's go to the next probability. So x can be have a value between y1 and y2. So same business one, two. One, two, three, and that's it. And then now again, so what is our skew shape? It's lambda slash 2, 1. And so on. So we can figure out in terms of standard young tableau what these probabilities are for any of the situations where x is between two consecutive elements. And this Elements and this this exhausts all the possibilities. So we have that q1 plus and so on, all these probabilities sum up to one. And they are also decreasing because, well, you can see that we are counting the number of standard young tabloids, smaller and smaller shapes that are contained inside. So they are going to be less and less. So these numbers are decreasing. And now what we do? So if So if Q1 is less than or equal to one-half, and we can always assume then, because otherwise we will flip the positive, the diagram. Then if Q1 is also greater than or equal to one-third, then we are done. So basically, the elements that we are going to care about are going to be these two guys. And if Q1 is less. And if Q1 is less than one-third, then, well, we know that this guy is less than one-third. This Q2 is actually less than Q1 is also less than 1 third. And we are going to sum up consecutive numbers, which are all less than 1 third, until at some point our sum becomes bigger than 1/3. But because at every point, we were adding something smaller than 1/3, we know. Smaller than one-third, we know that when we add the next thing, it is going to be less than one-third plus one-third, and which is so we have the previous thing, then it's going to be less than or equal to two-thirds, and that's then we are done. So, this is an example of what kind of This is an example of what kind of reasoning people did here. And so, what's the important message is we want to figure out the number of linear extensions for which x has a certain value. So in this case, x is equal to k is when each one of these probabilities we care about here. And in the process of the partial results that people obtained for this, to prove this one-third, two-third conjecture, they considered such probabilities and developed positive inequalities of various natures. So the first such low-concave inequality was Stanley. Was Stanley in 81, so Richard Stanley. He was not actually trying to prove the one-third, two-third conjecture back then. It was actually he was applying Alexandru Fenchel inequalities in combinatorics to obtain log and cave sequences. And this was one of these beautiful applications. So n k is the number of linear extensions where L of X is. Extensions where L of X is equal to K. So X is a fixed posit. There's a fixed element in the poset. L of X equal to K is a restricted linear extension for which X has this particular value. And then this, the number of linear extensions with this property is actually a log concave sequence in K. And log concavity has been a hot topic. A hot topic recently. So, this inequality itself is not enough to get anything for one-thirds, two-thirds, because it's just about one element in the posit. So, what Khan and Sachs did is they found another inequality. So, this time we have two elements in the posit, x and y, fixed. We look at all linear extensions for which f of k F of k so for which the difference between the value at y and the value at x is k and then this number, so the number of such linear extensions is also log concentration. And the proofs of all these results were done using the mixed volumes in order polytope. So they considered order polytope. So, they considered order polytope and applied Alexander Fenschel inequality, which is highly intransparent, and we have no, it does not give you any combinatorial flavor of what's actually going on. And last, this is so this inequality is still a conjecture in for all cases. So, then it's called the cross-product inequality, and this is a more powerful inequality than. Is a more powerful inequality than the previous inequality, so we can prove the previous inequalities using it. So now we fix three elements in x, y, z in x, y, z in the poset, and we considered all linear extensions for which ly minus lx is equal to k, and lz minus ly is equal to l. And then we have this hyperbolic property of this function. Of this function. So if we increase both values by one, then this product is actually smaller than if we increase just one or the other. And so what we did in a series of papers was that we gave combinatorial injective proofs of all Of all these results, but for only for posits of width two. So anti-chains, each anti-chain has its most two elements. And the way we did this is using lattice path injections. So let's move on to some more to some combinatorics. Any questions so far? Everybody good? All right. Okay. So where is the more visual combinatory for where are these injections gonna come in? So now I'm going to restrict myself to with two pulsates, which means that we With two posets, which means that we have two chains and maybe some other relations between them. So, this is our poset P. And so these are, we're labeling the elements alpha and beta for the two chains. And now we look at the linear extensions. So, these are the values of the linear extensions. So, the horizontal steps are going to be labeled. Steps are going to be labeled by these elements alpha, and the vertical steps are going to be labeled by the elements beta. So beta 1 up to beta 7 in this case. And we take this linear extension and we look at it. So we read the values. So this is going to be beta 1 is the first thing. Is the first thing that shows up, then it's alpha one, then it's alpha two, then it's beta two, and so on. And now we form a lattice path reading this: so the betas become upsteps and the alphas become right steps in our path. So the first step is going up, then we have two right steps, then we go up again. Steps, then we go up again, and so on. Okay. And so we get from a lattice path from this linear extension. Then how do we make sure that this lattice path actually gives us a linear extension for this particular posit? And the thing is that. That the poset itself is encoded in the fact that these guys have to be inside a given region with a monotonous boundary. So there is some sense the minimal and maximal linear extension are defining the region in which our path is going to move. And for every posit, and we can also increase the width. And this is how we were studying sorting probabilities with the geometric. probabilities with a geometric argument you can with the size of the maximal anti-chain d we can embed the linear extensions in as a lot as lattice monotonous lattice paths in z d okay and of course our favorite example with the catalan posit so this is our young diagram so in this case for four this is a linear This is a linear extension, and of course, we know what the lattice path in this case is. And now I've actually rotated down. So, what the real lattice path is in this region after we rotate it back. So, this is just a more regular representation for the die pads, but it's the same thing. Same thing. Okay. So, if we want to prove some of these positive inequalities, we can actually prove things about lattice paths restricted to various regions. And here is a bijection, sorry, injection, which proves an inequality between pairs of lattice paths. So, let me, other than you reading the statement, let me just show. You're reading the statement. Let me just show you on a picture what this is about. So, suppose that we have four endpoints A, B, C, and D, and we are going to look at pairs of lattice paths from A to C and whatever B to D. That are all. So, remember that somewhere here we have a region that we are not allowed to leave. To leave. So, of course, otherwise, we know the formulas are just binomial coefficients. It's not interesting. Okay. So, these are pairs of lattice paths which are of this form. And let's say, let's take green. And pairs of lattice paths which start pass a little bit closer. So, this is going to be a print, this is going to be. So this is gonna be A prime, this is gonna be B prime, and they go to the same endpoints. So the number of green paths in this picture is bigger than the number of these red paths. And those paths can all cross, right? Oh, the pairs of paths can cross, yes. Yeah, so we have pairs of paths non-interacting. The only condition on these paths is that. The only condition on these paths is that they have to be inside the same region. And now, so how do we prove this inequality injectively? And I mean, this is my, I guess, my invitation to you, why these positive inequalities are not something you should try away from algebra and combinatorics. So here, So here, so we take this path from B to D and we translate. So let me just choose a different color. Let's see. So we translate it up to the point that it starts at this point. It starts at this point and goes up to this other point. So, this is also on the other picture here. And when we do this translation, so it's the topology of this picture is telling us that we necessarily will have an intersection point somewhere. And let's take the last intersection point. So, we have a direction here. And once we take this last intersection point, which is Last intersection point, which is in this picture, we can reassign the path. So, classical LGV Lindstr√∂m SOV and O type of argument from now on. And the reassignment of the paths is going to be so this is one path, and this is the other path. And now we take this path and we translate it. Take this path and we translate it back down here, and we get a pair of paths which start so this. So we translate this part back, sorry, the top part. So this goes down here, and we have a pair of paths. These red paths, this is our image. Image in after all. And so, what did we have to keep track of? Well, exactly that we are inside the region. And the fact that the region has monotonous boundaries is helping us here because we can make sure that when we do these translations, these are the outer, the inner paths are more likely, are more in the region than. Are more in the region than the outer parts, and everything works this way. And any questions so far? So, and then the same thing we can do if our endpoints are horizontal versus vertical. So, there is a reason we need this. And okay, so where do we use this for the post-its? For the postets. This is bear with me a moment. So, here is a general application that maybe Peter Winkler and Jim Propp would appreciate more is there is a probabilistic generalization and we can actually do random walks which intersect with the same type of argument. So, if we look at random walks which are inside Which are inside a similar region, although this time we only need the monotonous boundaries in one direction, and then we are going to look at the exit probability at a certain point. So this is k this is k, this is k plus one, and so on. So where does this exit? Turns out that the exit probabilities are low concave. Exactly with the same type of bijection, just time a little bit more involved. And again, because we have arbitrary regions, we don't have any exact formulas. So this is an application of this argument for lattice paths, but let's go back to the post-its. So where do we use this in the post-it is here. Is here. So let's take Stanley's inequality. And the first thing we can do is we can actually add parameter Q, which was not present in the original inequality. And so if we have a poster on two chains and maybe some other. Two chains and maybe some other conditions on that posit. So alpha one, alpha two, alpha three, whatever, there is some other some other elements here. So nq of k is going to be going is going over all linear extensions for which this special element, so x, this. X, the special element is alpha R is equal to K, and then we're going to go at Q to the values of the linear extension and on one of the chains. So this is, so it depends, of course, of how we break the positive into chains, but it's a natural statistic in that sense. Then it turns out that this polynomial now in Q. Now in q and n q k squared minus the minus n q k minus 1 and q plus 1, it's not just positive, it's a polynomial with non-negative coefficients in q. And how do we prove this? So we use this lattice path. So this is in this case for Is in this case for Stanley's in a quart. Alpha R is our special element X, and the fact that L of X is equal to K means that the horizontal step of the path right above X happens at the k step of the path. And because we have only two dimensions, we know exactly where the path is going to come. Exactly where the path is going to pass through. So it's going to pass through the points here: r minus one, k minus r plus one, and whatever other point, r minus. And the other point is going to be r okay, there are some typos here, but anyway, so so. So this it's at points r and r minus one and and then when l of x is equal to k plus one that means that the path is passing exactly one level above and lx equal to k minus one means that the path is passing one level below and by this lemma that we proved we know that the number the pairs of paths which go The pairs of paths which go from here to, well, in this case, it's going to be the same point from zero to these points are going to be more than the pairs of paths which go from here to here, for example. And likewise on the other side as well. And this is how the proof works. And the last the last And the last part of the proof is to observe that this statistic is exactly a shifted statistic from Q to the area under the path. And because we are doing this translation, vertical translations, we are recomposing the paths from the same pieces, then the total area is preserved under the pairs of paths, and we have this identity. We have this identity inequality. So one can generalize this further. So for each or a vertical step, we can have a different variable. And so we can have this type of statistic. So for each. For each i, we have some variable qi, and then we are looking at the difference of the value in the linear extension between alpha i and alpha i minus one. Now, this is a multivariate polynomial. And so, q now q is just this formal variables. Then, this is a polynomial with non-negative, the difference. With non-negative differences, the difference of these guys is a polynomial of non-negative coefficients in z. And if you want to see something familiar, then we can, of course, take the posit, which is just two chains without any actually this poses, and for apologies. So, without any. So, without any other restrictions, then this polynomial is just the homogeneous symmetric function of order i evaluated at the first batch of these variables, and then the other homogeneous symmetric function of order j. So, i and j are these guys over here, evaluated at the other batch of formal variables and then. Formal variables, and then the difference between this log concave difference is just when you do the expansion, actually, is just sure function times this homogeneous symmetric polynomial and another sure function times this homogeneous symmetric polynomial. So, we actually now see why it's positive, and we can see also what the difference between these two guys means and. And what we can do with this approach is we can also analyze exactly when equality occurs in these inequalities. And in general, equalities in Alexandru Fenschel inequalities were subject of recent studies of Schenfeld van Handel, and it's a very complicated situation. But when you have some combinatorics, it's easier to keep track. So equality. So, equality in Stanley occurs exactly when, if and only if it's for the Q in the Q case as well, and it's only if and only if all these numbers are actually equal. And this means, what does it mean for the posit? It means that our special element X satisfies this K pentagon property, which means this picture. Which means this picture over here. So there are, these are this x is our special element, k is already a fixed number. So the other elements should have these relations around it. We could also see this on the in terms of the lattice path. Okay. Any questions so far? Any questions so far? So when I was discussing the talk with the organizers, one of the organizers specifically requested that I address what the algebraic properties and operations have to do with this. And so here is So here is the setup, and I must say that this is all work in progress, which I was sort of trying to finish of past few days. So it's still a little bit rough and open-ended in some sense. But so here is, we are going closer to dynamics. And it all starts with this. And it all starts with these questions that we also prompted by the equality case. So the first thing we want to know is when is this number actually non-zero? I mean, this is somehow non-trivial already. If you have a general posit, is it possible that some element has value k? There is a linear extension with that element at a particular... That element at a particular position. And in general, so what we proved using this geometric and lattice path interpretation was that the difference between these two numbers is actually counting some types of pairs of lattice paths. So this is implicit in the proof using the injection. And if you want to formalize, so informally, this means is there a combinatorial interpretation? A combinatorial interpretation for this difference? So, does this mean anything? Formally, we like to phrase it in complexity terms. Is this in sharp P? Sharp P is the class of exponentially hard problems, but they can be enumerated with an exponential sum with things that are computed in polynomial times and they are positive. Times and they are positive. So is it a sum of possibly exponential sum of some positive easy to describe and compute objects? And so here is a criterion for when this guy is positive. So in order to characterize it, we need this interval counting. This interval counting function, so we have an element x and an element y, and we can always assume that x is smaller than y in here because we are only going to consider linear extensions for which y minus x is some certain positive number. And then we are looking at all these elements z, which are between x and y, or z that is. Z that is smaller than y or bigger than y. So this is our function h x y is counting the elements between x and y. And this funny notation, h less than x is just the elements which are smaller than x. And h x smaller is all these elements that are bigger than x. And this number is positive. Is positive if and only if the natural condition holds. So the elements that are smaller than x are less than k, and the elements that are bigger than x are bigger than n minus k, and that's it. So we can always put x somewhere in place. And the same thing calls for can sec. Codes for CANSACS, which now this analysis doesn't really work with. So equality in CANSACs is much harder to discuss, but at least we can figure out when is this positive. And this is for general posits. And it's something similar. So it's k has to be bigger than the number of elements that are between X and Y and should be. and should be smaller than n n minus h smaller than x and h bigger than y and y is this condition. This is so we have x, we have y here. So we have k element, we want to put k minus one elements between k and x, but there are going to be some number of elements that are smaller than x. That are smaller than x, and some number of elements that are bigger than y, always. And we want this these sets, of course, are going to be disjoint, so the total size should be smaller than n, and this is where this inequality comes from. So, the other one is kind of obvious. So, this is the elements that are between x and y. And in general, how do we generate? How do we generalize all this and how do we how do we prove this these types of results? We consider the generalized situation in which we have a certain number of elements u1 up to uk with values. With value, which are supposed to take values a1 up to a k. And we consider the set of restricted linear extensions for which this element has the particular value. And this would actually encode all the other cases that are already considered. And so what Stanley proved more in bigger generality is. And in bigger generality, is that these numbers are also low concave in each of these variables, and the other ones are fixed. But what we would consider is that whether when is this number positive? So, when is it possible to pick your favorite elements in the posit and assign them specific values? And this is exactly. And this is exactly when the intervals between any two pairs of elements are smaller than the difference of the values, and which is a natural condition, so definitely obvious in one direction, turns out in the opposite. And here, here you jump in here and say you have three minutes left. So you want to split that between wrapping up and asking questions. Can I finish in two? Finish in two minutes? Yeah, you can have two minutes to finish. Okay, so the way this works is how do we prove it in the other direction? And this is exactly where this promotion comes in play. So now I'm going to just do this on a quick example. So let's take So let's take our favorite posit again. We take start with some linear extension and we have a target. So these are our special elements u1 and u2 and we have a target a1 should be 3 and a2 should be 6. So this is the position for u1 or the value of u1 in this in this guy and a2. And what we And what we can do is we just start with a linear extension. So, for example, take one, two, three, four, five, six, five, six, seven, eight along rows. This is going to give us one linear extension. And these inequalities are telling us that there is an incomparable element somewhere on the other side that we can move ahead. So we do some kind of a local promotion operation. Promotion operation. So this guy moves over here and then we shift U1 to position three, which is okay, which is what we want. And now U2 should shift to position six from position seven. And what we would do is we will so D and U2 cannot be interchanged, of course, but C can actually move. But C can actually move, and we can insert C here again using a promotion operation. And all of this can be formalized in algebraic terms. And so this is what we've been doing recently is to define a more general group of actions on these restricted posits, which This restricted posets, which actually will describe how we transition between the various restricted linear extensions. And so these are the types of results. And if somebody is interested, I can talk about this in the break. And thank you very much for the attention. Well, let's thank Granna for a fascinating talk. Thank you very much. So, if people have other questions or any questions for Greta, as she says, they can go into her breakout room. Also, there's the slides, which are, I think, on the web through the conference website. And anything else I should mention before we go into the breakout rooms? Let me just apologize again for cutting you off, Greta, because it's a great talk and good results, and I'd love to know more. So, I may be looking for you in the breakout rooms. I'm sorry, I saw that I don't. I'm sorry, I thought that I had 45 minutes to talk. I didn't realize I should have. We should have made that clearer. Yeah. So, anyway, for those who aren't going to Greta's breakout room, the question is, did you like math as a child and do you like math now?