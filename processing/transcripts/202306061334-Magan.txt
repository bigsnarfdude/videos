Okay, thank you. I want to start by thanking the organizers for organizing this conference in this amazing place. It's my first time here. So today I'm going to talk about a series of works in collaboration with Villier Balaso-Raman, Pablo Caputa, and King Kegu, aka Hostin. They deal with new aspects of quantum state complexity, their relation to quantum chaos. Relation to quantum chaos and quantum black holes. And also we will see how they suggest a new approach to random matrix theory and quantum chaotic system. So the motivations are kind of straightforward. First, we want to find explicit relations between complexity and quantum chaos. Where here by quantum chaos we mean the old notion of quantum cha of quantum chaos, which uh is about the fine grain Which is about the fine-grain, the universal fine-grain structure of the spectrum of abiotic hamutoni. Related to this motivation, we also want to understand in detail the long-time behavior of complexity for chaotic systems and probably verify the conjecture that was done by Saskind some time ago. We are also interested in We are also interested in seeing whether all these endeavors help us understand what is, well, maybe I don't completely know here, but it's known as Mandacena's ADS-CFT version of the information paradox, which is basically the statement that in chaotic systems with finite entropy, thermal relaxation, like a thermal two-point function, cannot decay to zero, but has to saturate at some point above zero. At some point above zero and oscillate erratically there. And finally, we were interested also, of course, in the conjectural relation between complexity and the volume of the black hole interior, but I don't think I will have time to arrive there today. So let's get started. And to do so, we need a notion of complexity. This is kind of a wild zoo, but today we will choose a But uh today we will choose uh a notion of complexity that was inspired uh that is it that is inspired by that of uh of Kiro complexity that was introduced in this paper here in 2018 as a measure of operator complexity. But it turns out that it can be straightforwardly generalized to quantum states, so we are going to describe that now. The idea is very simple and starts basically uh in a situation in which what Basically, in a situation in which we have an initial state, typically we think about it as an initially simple state, and we evolve it with a unitary evolution. And in this situation, we can compute the action of arbitrary powers of the Hamiltonian in the initial state. And this arbitrary action of the Hamiltonian produces a set of vectors, this till the side, that are neither orthogonal nor normalized. But we can We can produce, let's say, a canonical orthonormal basis out of those just by applying the Grannes-Smith orthonormalization procedure to those vectors. Now, basically, we take these vectors and we apply the Grand-Smith procedure and generate a basis. This procedure is very well known in the literature. The solution is also very well known. It comes under the name of the Lancos algorithm. Lanso's algorithm, and the output of the Lancos algorithm is exactly this basis here that is sometimes known as the Kilo basis. The algorithm is defined, I don't have time to go through the details, but it's defined by two very simple equations that basically instruct us how to get the kilogram basis vector m plus one from the previous one. In a way, they also generate a set of coefficients, these a n's and b n's coefficients. A n's and b n's coefficients that are called the Langshaw's coefficients. Now, given these two equations, it is very simple to realize that if we write the Hamiltonian in the Kildo basis, just produce, this Hamiltonian becomes a tradiagonal matrix. And the tradiagonal, so all these are zeros, here and here are zeros, and the tradiagonal matrix elements are the Lancashire coefficients. Now this implies that the That the Schrodinger equation becomes just a one-dimensional hopping particle. And well, I don't know, maybe for you it's kind of not surprising, but it is kind of cute that every time-dependent problem can be framed, even in quantum theory, can be framed as a one-dimensional Hobby motion of this form. So, the first step in this game is to compute this version of the Hobby. In this game, is to compute this version of the Hamiltonian. You can think about it, you can compare it like with the diagonal version. So the diagonal version would be about finding the name values, the triagonal version goes about to find these coefficients. And for finite-dimensional matrices, like for example the ones that we are going to work in a moment, the ones that appear in chaotic systems such as SYK, this version of a matrix is typically Of a matrix is typically known as the Hesse-Ber form of the matrix. So, and there are numerically stable algorithms to compute such form, and we will use those. But there is a method I just want to mention. There is a more general method that is valid for continuous systems and infinite-dimensional systems that starts from what is known as the survival amplitude, which is just the amplitude for the state to remain unchanged through the pollution. Change through the pollution. And I'm not going to read this method here. I can explain it later. You can find it in the article. It's a little bit complicated, but it's straightforward. I just want to mention that it's important to keep in mind that everything that I'm going to say, for example, this version of the Hamiltonian or the complexity itself, at the end of the day, is always a functional of this survival analytic. This is going to be conceptually important. Well, in any case, choosing any of the available methods to try to analyze the matrix, once we have done so, we have found the Lancashire coefficients, we just expand the state-dependent vector, the state-dependent quantum state, we expand it in the Kilo basis, and we solve the Schrodinger equation then. Once we solve the Schrodinger equation and we have the amplitudes, we can compute this notion that is known as Kilov complexity. Known as kilo of complexity, that basically measures complexity as the average position in this one-dimensional change. So I start with the initial state, that is the first state in the kilo basis, and then the volution will basically complexify the state. And the way we keep track of that is just by the position of the state in that kilo basis. Yes? So are you assured that this Lanchov state does not terminate after finite time? Terminate after finite again? Well, that's a very important question. Let me come back to, yeah, that's not going to be key later. But so let me just say something now. So, of course, there is a question about when this iteration process terminates. And for sure, it should terminate at the end of the filter space, if the filter space is finite, but it could also terminate before. But well, let me just Actually, but well, let me just say that for a moment, but we are going to come back to that. For chaotic systems, we expect that it won't terminate until the end of the Hilbert space, but also it is very difficult to prove that it terminates. And that's going to be it. So, okay, so this complexity measures the position in this basis. But now you could ask why this basis? What is special about this kilo basis? And in our article, And in our article, we proceed differently. We basically define a notion of a spread of the wave function over any choice of basis. So you give me a basis, and I give you the spread of the wave function in that basis. And in the spirit of Polmogoro, we define complexity as a minimization of the spread of the wave functions over all choices of basis. So this we call spread complexity. Expressed complexity. In principle, these kind of minimizations sound very well, but they are very difficult to accomplish. But in this case, we were kind of surprised that this minimization, this functional minimization of a role choices of basis can be accomplished and that the solution is the kilo basis itself. So in this sense, well, we see this as a recontextualizing of kilogram complexity into a A more solid framework. So, well, this is the notion that we are going to use. Probably it is still, of course, arbitrary to some extent for you. Let me give you a reason why, a very concrete reason that is what really motivated me to push this forward. And it goes by considering the thermofield level state. So, the thermofield level state for the ones that they don't know what it is, so if I have a They don't know what it is. So, if I have a Hamiltonian and I have a Hilbert space, I can duplicate that Hilbert space by taking the tensor product with itself, and then I can take the energy eigenstates, this n here, and the energy eigenvalues, and construct this state in the duplicated heat stage. Basically, the main the main motive of constructing this state i i is that it purifies it is a canonical purification of the thermal density matrix of Of the thermal density matrix of one of the Hilbert spaces. In this context, for this state, we can consider a kind of insightful unitary evolution, which goes by evolving the thermofield level with the, say, the right Hamiltonian. So we evolve it now just with one Hamiltonian, say the right, and this is going to basically produce some phases here that I modify here by some analytical continuation of the temperature. Continuation of the temperature. Now, why is this important? This is important because in ADS CFT, the thermofield level is dual to the terminal black hole in a T-design space. And this evolution has been argued in several works, some famous works, that it might describe aspects of the black hole interior. And it is basically one of the main, let's say, processes in which one we want to understand the complexity of Moscow. Complexity evolution. Now, before going to the species results, let me remind now that everything that we would compute is a function of the survival amplitude. So what is the survival amplitude for this process? So we can just compute it, very simple computation, we get the analytically continued partition function. What this implies is that the survival probability, which would be the modulus of this complex number, is what is known This complex number is what is known as the spectral four factor of the theory. Now, for those that, so is this quite a key? This is called the spectral form factor. For those that are not familiar with this concept, let me say that this concept has played a key role in the context of quantum chaos. Of quantum chaos over the past 30 years and recently over the past 10 years in the context of quantum black holes. Basically, it is important because it codifies in a time-dependent way the spectrum of the theory and this quantity, as we are going to show in a moment, it shows all the universal properties of theotic systems that show up in the spectrum. Now, what is important here is that our notion of complexity is a functional of this. Complexity is a functional of this spectral four factor. So we get two outcomes, just two conceptual outcomes. The first is that we are going to get some relation between complexity and the universal properties of the spectrum, but we hope to get that. And the second one is that the non-saturation of this quantity, this quantity saturates at some point, as we are going to see, will be equivalent to the saturation of complexity. So the saturation of this quantity in this context is what is known as Manda's. Is what is known as Mandacena's version of the information paradox in this scenario, and here it is unified with saturation of complexity. Is there a question about this? Maybe I'm going a little bit fast. If not, let me just go to the explicit the results. So we can use this idea and apply it to quantum kinetic systems. To do so, To do so, one could take your favorite quantum theory system, but when we diagonalize the system, as we all know, in quantum mechanics, this has a lot of computational costs. So it is better to work with random matrix theory. Why we can do that? We are allowed to do that given what is known as the quantum chaos conjecture. This conjecture basically states that the fine-grained properties of the spectrum of the Hamiltonian that appear, for example, in this quantum. The Hamiltonian that appears, for example, in this quantity, they are well approximated by the universal properties of random matrix U. If we join that with the energy-time uncertainty relation, this tells us that if we want to understand aspects of the long-pipe dynamics of chaotic systems, this is going to be again well approximated by the long-pain dynamics of random matrix theme. So, we are going to start with that, we are going to study this notion of spectral. Going to study this notion of spread complexity for the thermofield level associated with the simplest random matrix theory, which is the Raussian unitary answer. And this is the result for different temperatures, different betas of the thermocytable. What is interesting here is that this Gaussian unitarian sample complexity displays four regimes. We have a linear ramp. Notice one thing here, I'm Notice one thing. Here, I'm writing the time and the complexity, both normalized by the dimension of the Hilbert space. So, all these numbers, all the times and the complexity are always of the size of the Hilbert space, as we expect, as it was the Saskine conjecture. We get four regimes. We get a linear growth for exponentially long time in the entropy until a peak and then which is exponentially large in the entropy as well. Is exponentially large in the entropy as well, we get a language slope and then a saturation. This, of course, reminds us, well, for the ones that are familiar with the spectrum four-factor, it reminds very much to the spectral four-factor. So this is the quantity that I was mentioning before that has been studied during the past 30 years in the context of quantum chaos. This is the typical The typical figure, I mean the universal properties of this quantity for Captain Systems, it shows also four regimes. It shows a downward slope, then it shows a dip, then a linear ramp and a plateau. In this case, what is important to realize is that this dip and this ramp are related to what is known in the random matrix theory as spectral regime, which are the As spectral acidities, which are the universal correlations of chaotic systems. Now, we would like to say that in the complexity story, this kind of slope? These are different beta. And here I just plot one beta. Are the different lines different realization? What? The different lines that clustered or different? Yeah, they are. Yeah, they are yeah, it's a yeah, it's uh so um yeah, this is computed by generating special instances of random Hamiltonians and doing all the process later. But each line is an average. Each line. No, no, each line is a is a particular Hamiltonian. And lower temperature is it down? Lower temperatures is down, yeah. So is it like the lower? Yeah, sorry. Sorry, I mean the the better the better then the behavior of the peak. Is the behaviour of the peak suppressed? Yeah, yeah, yeah. And so here is more difficult to argue that this is related to spectral rigidity because there are more things that enter into competition. But actually, it can be argued in three different ways. We argue in two different ways, and the group recently, the group of Johanna and Menger, argued in a third way. Another way that actually is the case. This complexity slope is originates in a spectral unity and it codifies the universal structure of random matrix theory. So this is really the, well, at least in this case, it's the complexity avatar of the universality of quantum geotic systems. Is there an analog of one-point functions here? Formally with the form factor, we subtract off like a non-universal piece of check? Yeah, well uh here yeah so so here basically the uh this part this part would be would be like like uh morally it's not exactly the same, but morally it would be like like the slope, which is related to the one-way function. And then the and then this part, which is the ones that you need to to input uh correlations, I mean uh uh this is this basically all this part. Is there some way to say how this initial function That that is that is yeah. Uh that is done by the group of uh recently by the group of Johanna. Yeah, this is one of the arguments that we give. So we exactly do that. I didn't put it here, but yeah, so very good question. So one, I mean, I didn't do it for the sake of time, uh, but let me just say it then. So what he's proposing, which is the right answer, is that to um Is that to one of the one of the ways to see that this is going to be originated in the spectral humidity? Is to now, instead of taking a random Hamiltonian taking from the Lausanne Unitary ensemble, I just produce Hamiltonian with the right semiconductor, the right density of states, but just produce, I mean, I just produce the spectrum itself and no universal correlation. And then the result it is just like this. It's the same, it's the same, but no peak and normal. It's the same, but no peak and no slope. And the symptomic value is the same? It's the same. The symptotic value we have computed analytically. It's going to repeat soon. And it doesn't depend. The asymptotic value, this value, it just depends on the density of the states. It doesn't depend on the one-point function. Which is true for the four-points. Which is true for the, yeah, which is true for the spectrophoto. Okay. So, well, these are like So well these are these are uh like very uh suggestive numerical results and we would like to get an analytical handle. It is a it is a well complicated problem but uh we made some progress. So basically let me remind what we have done. So in this Lancos story for time-dependent scenarios, what we do is we take an Islamic state, we take a unitary evolution driven by some Hamiltonian, and then we run the algorithm. Hamiltonian, and then we run the algorithm, the Lanzos algorithm, to produce a random Hamiltonian. I mean, to produce a tradiagonal Hamiltonian. Now, if we started from a random Hamiltonian, the tradiagonal version, this output is going to be a tradiagonal random Hamiltonian. So the Lancos coefficients are random variables. And the problem is then to find the statistics of these Lancashire coefficients, which basically more concretely is to find the joint probability distribution of those coefficients and the Of those coefficients and the generic correlation function. This process, for the ones that are familiar with random matrix theory, is completely analogous to the way we attack random matrix theory by matrix diagonalization and we derive the geometry distribution for the eigenvalues and we derive generic correlation functions for the densities of the states. So the geometry distribution for the lungs of the For the Lancash coefficients in random matrix theory turns out to be given by this function, where this trace is to be taken in the tradiagonal version of the matrix. We have three proofs of this joint probability distribution. For the sake of time, I haven't included them, but you will see that the numerics match perfectly. But once we have this, this joint priority distribution that plays exactly the same role as the fame. That plays exactly the same role as the famous gain probability distribution of the eigenvalues of the matrix theory, we can follow just the usual steps that a physicist would follow. So we take the locality of this gene probability distribution and we interpret that as an effective action for the Lancashire coefficients. Again, in these effective actions, you have to remember that this trace is to be taken in the diagonal form. Now, as with the eigenvalues, With the eigenvalues, taking the thermodynamic limit helps in getting an equation. So, if we take the thermodynamic limit, it's better to write things, to write the Lancashire coefficients as a function, instead of little n, as a function of little n divided by the dimension of the Hilbert space. This is x, and in the thermodynamic limit where this capital N goes to infinity, this goes from zero to one continuously. So, after certain calculations, uh one arrives at at a continuous uh sal uh a continuous action. Continuous action for the Lancashire coefficients in random energy state for a generic potential. Once we have this action, we can just derive the solid point equations in the usual way. This would derive the one-point functions of the Ramshaus coefficients. This would be the average values of the Ramshaus coefficient for generic potentials. And then we can expand this action, we can expand. Expand this action around the solutions of these saddle-point equations and find the two-point functions, the covariance. Now, this can be done basically in full detail. And here we verify the analytical results with numerical calculations. So, here we take three potentials now. So, we take the Gaussian one that we started with. This is a six-stick potential for the random method theory, and this is a quartic potential. Theory, and this is a quartic potential with a third-order term, so an odd term. There is a hard line in the middle of the noise here and here, and the hard line is the solution, the analytical solution to the saddle-point equations. Well, just to remark two things. First, the match is kind of impressive, and more importantly, related to the question that Question that was done at the beginning, we are able to prove something very non-trivial: that the Langshaw sp coefficients, in all cases, they decay to zero continuously exactly when we reach the dimension of the Hilbert space. It was a problem in the theory. And well, given this nice match, one could ask. This nice match, one could ask: well, what if I now take another Hamiltonian, not the one I started with, but another Hamiltonian, in which I just fix the one-point function and two-point functions of the Lancash coefficients to the solutions of these equations, and I take that as an approximation for my Catholic Hamiltonian. How would it be that approximation? And here we plot the SAC solution for the security amplitude and the SAC solution for the complexity of both Hamiltonians, the SAC one and the approximation. Hamiltonians, the second one and the approximation, and we see that the match is also very good even until very long times. Okay, with this, I finished. Let me just see if I have one minute. I have more? Well, five minutes including discussion. Okay, perfect. So let me just come back to the to the questions and this will uh that maybe they were not because of the sake of time I I didn't have enough time to like kind of contextualize them. Time to kind of contextualize them. But now let me at least contextualize them with the talk. So, first, in relation with the first question that was: can we find explicit relations between complexity and quantum chaos? In this sense, we have pointed out that there is a suitable notion of complexity called a spread complexity that, when we apply it to the thermofield level, to the pollution of the thermofield level, is a pure functional of the Of what is known as the spectral factor, and therefore, this is a very promising bridge to a very promising place to build a bridge between complexity, quantum chaos, and black holes. In relation to complexity and non-times, we saw that this notion displays four regimes, it satisfies the conjecture by seisting, but it refines it. Because we see that it doesn't just go to the saturation. It doesn't just go to the saturation smoothly, but there is a funny thing going on at exponential times. And actually, this funny thing codifies the spectral rigidity of the chaotic system and the universality class of the chaotic system. So, this is really the habitat of the chaotic behavior. In relation to Mantasena's ADS COT version of the information paradox, we have seen. We have seen, well, I didn't have time to explain very well, but for the ones that didn't see it immediately, so in this scenario, this paradox, or this version of the paradox, would instruct us that we should prove that the survival probability, in this case the spectrum for factor, should saturate and should not go to zero at long times. We have seen that this is completely equivalent to the saturation of spread complexity, so this in this scenario we unify we unify We unify two problems. But what is interesting is that these two problems are further equivalent to another problem, which is a unique abstract, which is the vanishing of the Lancash coefficients. So the Lancashire coefficients is, so I remember they were this piece here. As long as these V's are non-zero, the one-dimensional, these Vs are like the hopping parameters, the hopping amplitudes, so that The the hopping amplitudes so that the particle keeps moving moving to the right. So, in order for the particle to not move anymore, this disc have to vanish. And we were able to prove that this is the case. Sorry, we were able to prove that this is the case analytically in general and on Matrix theorem. So, in this sense, we proved this version of the paradox at this for Captain. For chemical systems with compact density of states. And well, I didn't have time to explain the connection between complexity and the volume of the platform interior. Let me just say that in these recent articles, one in collaboration with PJ, Albion, Martin here, and myself, and the group of Johanna, and also the group of Eliezer and Julian and Sergei Rabido. In different ways, we want In different ways we were able to find different ways we were able to find a specific relation between this complexity and the volume of the platform interior. In our case, they go through this notion of platform microstates that were found in this paper. And if you want, we can talk about that later. And with this, I finish. Sorry. Thank you. So is there a way to compare the spectral phone factor, the behavior of the spectral fun factor versus the complexity in terms of understanding colours? Can you compare? Are you getting similar? I mean they are different quantities, no? So the spectral extracting information, yeah, yeah, yeah. So this was part of the work, and so there are many ways to So, there are many ways to do so. And yeah. Let me just say for the moment that this quantity is the, so this quantity in this case is, from our perspective, is just the survival probability of the process, so it's let's say survival, the probability of a state in the first state, okay, as a function of time, and the complete. As a function of time, and the complexity, so this is P0, and this P0 is just one entry in a very large probability distribution, which is the probability distribution of the state in the enterprise. And this quantity is not any entry, it's just by definition this kind of thing. So they are different quantities. It's not that, but there is. It's not that, but there is a relation between them through the Langsha algorithms. Is it showing more powerful? Well, so do you think complexity is more powerful? It's equivalent. So at some moment you showed this other plot with non-Gaussian sectic and quadric scenario, right? So did you study how they change with the coupling or the interaction or the control parameter or of the control parameter or? Because you have you have you must have added the sectic or the quartic term, so inner potential. So yeah, but but but not not with small parameters. I mean they are they are fully non-perturbable. I mean yeah. No we didn't we didn't study we didn't study how it bar how it it depends on on the but let me say that basically everything depends on the on the density of states, many more things than one would expect. So I don't think the so hold on. So this plot is not going to change very much by changing the coupling because everything just depends on first that there is going to be a growth for those facts. This depends only on the density of states. And then this part, I don't know, maybe it gets a little bit unotiled. I'm more interested in, like, so for example, if I add a vortex potential, right? So then how does that change the slope? The initial, let's say, the early behavior. Let's say the early behavior with the parameter versus the change of the spectral form factor with the same sort of yeah, we haven't studied that in detail. I mean, you see here, let me just show here. Yeah, just here you see that these are the different potentials. It's a split complexity for the different potentials. It's very much the same. I mean, of course, there are going to be different, but yeah, sure. So maybe we should. Yeah, sure. So maybe we should continue on in the discussion since we can talk more about this. So let's go ahead and do that.