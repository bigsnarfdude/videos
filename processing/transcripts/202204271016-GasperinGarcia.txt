Yeah, yeah, yeah, yeah, of course. So let me share my screen. So, can you see my screen? Yes. Okay, cool. So, um Okay, cool. So, good morning. My name is Eder Gasperin, and I will talk about this work done in collaboration with Jose Luis Caramillo. This is about the role of the energy scalar product in the quasi-normal mode spectral instability problem. And maybe I'll repeat some things that we have heard in the previous session, but for completeness, let me just say them. Just say them. So, what are quasi-normal modes in a nutshell? So, they are the eigenmodes of non-shell-fad joint operators. And well, these appear in many different areas of physics, ranging from optics, seismology, and more relevant for us, in general relativity through linearized black hole perturbation theory. And one of the easiest ways to see what a quasi-normal mode is, is just to look at a wave equation with a potential. Equation with a potential. One way to solve this equation is to make a Fourier or Laplace transform of the field, and then you turn this PDE into an ODE, like the one here, which you can read as an eigenvalue problem. In the case of black holes, one has to put out going boundary conditions, which essentially means that the field goes like this at infinity. This at infinity, and this has deep consequences. For instance, that the eigenvalues now are complex. And if you just check what this implies at the end of the day is that the field is going to be, so you want this to decay in time, just like we have in bringing down, but you will see that the field diverges at spatial infinity. Infinity. So, this I mention this because this is like one problem, let's say, and this is one problem that sort of connects with other interesting problems in general relativity, such as the so-called problem at spatial infinity. And this so-called problem at spatial infinity was observed way back to the works of Penrose and then further developed by Frederick and Juan Valiente and others. Juan Valiente and others. So, since part of the purpose of this workshop is also to make connections between topics, I thought of mentioning this. So, one way to go around this problem, at least for quasi-normal modes, a sort of elegant way to solve this is sort of rock the problem under, like put the problem under the rock in an elegant way by simply not going to spatial infinity, but rather going to null infinity. Going to null infinity. So, as Rodrigo was explaining yesterday, so instead of considering these Cauchy slices which end up at spatial infinity, one considers these hyperbloidal slices that touch null infinity. And I'm mentioning this because I want to just pre-discuss the work of Jaramillo, Panos-Masedo, and Al-Sheikh, where they use these two ingredients: hyperboloidal slices and Ingredients, hyperboloidal slices, and pseudospectrum, in order to understand in a systematic way the quasi-normal mood instability in black holes that was observed way back to the work of Noller and Price, where they saw evidence of instability for the spectrum of the Schwarzschild black hole. And so, yes, I was saying, so there are these two ingredients: hyperalloid slices and pseudo-spectrum, and the focus of And the focus of this talk and the paper that this talk is based on focuses on the following observations. So, whenever we say that an operator is adjoint, we should say also what respect to what scalar product this operator is adjoint or it's not self-adjoint. So, we always have to specify this, otherwise, our statements could be lack of meaning if you don't specify the inner product. Also, in the same way, Also, in the same way that a joint is related to the scalar product, the pseudospectrum is a notion that is dependent on the norm. And as I will show you in a minute, I will show you the definition of pseudospectrum and relation with norm through what I consider a very illustrative example, which is the following. So consider a differential operator with constant coefficients. The constant coefficients defined on this finite interval from x0 to x1. So this operator q. So how do we define the adjoint? So the adjoint is defined in this way through an inner product. You just pass the q through the other side, let's say, and okay, that's the adjoint. And the formal adjoint, we say that q is formally sorry, normal whenever the commutation of q and q dagger is zero. Okay, so with this simple example, let's Example, let's compute the formula joint of this operator Q using this L2 inner product, so the standard one, and with Dirichlet boundary conditions. Just for simplicity, so if you do this calculation, you will see that Q dagger is given by almost the same Q, but with a minus sign on front of this big coefficient. So then you conclude that this Q is not. Conclude that this Q is not self-adjoint, but it's not self-adjoint with respect to this inner product. Now, there's two twists, two catches in this story. And the first one is that it's not self-adjoint, but this operator is actually formally normal. If you compute the commutator of Q and Q dagger, you will see that this vanish. But it is only formally normal. We cannot say that it's actually normal because to be actually normal. actually normal because to be actually normal you have to check that the domains of q q dagger and q dagger q they have to coincide and this is not the case for for this for this operator with this uh putting the richlette boundary conditions so okay so so far we have q is not self-adjoint but it's formally normal so the other twist in this story is that if you just try to solve this as an as an ode so you know that you can put an integrating factor and this An integrating factor, and this turns this q into the strong wheel form. So this just entails introducing some functions w, p, and q, which are defined here. And so this has an associated weighted inner product where you have this weight here, w, and this defines the strong lobial inner product. And it turns out that if you repeat this calculation, but now with this inner product, well, you will find. Inner product, well, you will find that Q is self-adjoint. So that is just to emphasize and to motivate the importance of the choice of this colour product. Okay, now let me introduce what the pseudo-spectrum is. So as Rodriguez was explaining yesterday, the pseudospectrum are those points in the complex plane that are realized as the eigenvalue of your operator plus a small perturbation. A small perturbation. And whenever we say a small perturbation, we say the norm of the perturbation is less than epsilon, but we have to specify which norm we are using. And I think this is also very well illustrated with this simple operator Q. So let's do the following. First, let's rescale our field in this way in such a way that if you require that the rescale field is bound. The rescale field is bounded at the boundaries, it's finite, then the other, the rescaled field, actually vanishes at the boundary. So, this is sort of some way of encoding the usually boundary conditions. And if you make this change of variables, then your operator now is an operator with coefficients that depend on the coordinate x, but nevertheless, essentially the same story goes through. Essentially, the same story goes through. If you compute numerically, say, the spectrum, so you'll find this, you'll find the eigenvalues, so they are real, nothing surprising. Now, if you compute the pseudo-spectrum for this operator numerically using the standard L2 inner product, then you will find this figure here on the top panel. And if I didn't tell you what this operator is, and I only give you this plot, Only give you this plot, you would naively think that this is the pseudospectrum of an unstable operator. And by unstable, we mean that if you make a small perturbation in the operator, you can have a potentially large change in the eigenvalues. So you can see here that around the eigenvalues, there are these here, very tiny circles that they are in. That they are increasing, they're bigger and bigger as you go to what in quasi-normal mode would be higher overtones. So, here I can values with larger, uh, yeah, larger absolute values, so they are real. So, um, so, and you can also see that these epsilon superspectral lines, they open up and you can reach a bigger area in the complex plane, right? So, that means that a small perturbation can lead to a big change in the eigenvalue. So, this is In the eigenvalue, so this is uh, you would interpret this as a spectral instability. Now, but this is because we are measuring things being large or small using the L2 norm. But if you now use the norm induced by the Stone-Robile inner product and you make this calculation again numerically, you will find this plot. And here you can see that around the eigenvalue. Around the eigenvalues, we have concentric circles, which mean that, so if you make a small change in the operator measure in the sunlobile form, you will see why you see this constant. These epsilon pseudo-spectral lines, they look flat. Edgar, we lost you for 30 seconds. You for 30 seconds. Can you come back? Yeah, yeah, yeah, sure. So, so, uh, so, what was the last thing I was saying, or right? You heard? We have already the circles. We have already the stable circles. Okay, yeah. So, so, yeah, what I was saying is that in the extromulobial case, so you see this pseudo-spectrum, right? So, for each eigenvalue, if you look at the pseudo-spectrum, The pseudo-spectrum, you will see these concentric circles, which is the area of the complex plane that you reach by making an epsilon change in the size of your perturbation. And this means that this operator looks spectrally stable from this plot because you see this sort of democratic behavior. So, for all of the eigenvalues, so you have these concentric circles and the epsilon pseudo-spectral lines, these ones. Spectral lines, these ones here, they look flat, right? So this sort of democratic behavior for these, for the eigenvalues, and this flat pseudo-spectrum is what you would interpret as saying, okay, if I see this plot, this is telling me that this operator is spectrally stable. So this shows the importance of whenever, if you are going to trust plots like numerics, one has to be very One has to be very precise in which norm one is using because one could be misguided by the figure. So, yeah, that's the importance of specifying the norm and the inner product. And from the point of view of mathematics, maybe one thing that is interesting is to see how can you change your inner product in order to have control of this. Of this problem, right? How can I control? How can I change my norm and my inner product so that I can, whenever I make an epsilon perturbation of my operator, I still get an epsilon change in the eigenvalue. But from the point of view of physics, our notion of what is big and what is small should be guided by physical intuition. And our physical intuition, in this case, is going to be guided by the energy. guided by by the energy so let me just uh recap um some of the like the main the main points of uh what rodrigo was discussing um yesterday so first how do you get to quasi-normal modes uh very quickly in this particular setup so you can look at solutions to the wave equation on a spherically symmetric background like this so you have this f and this the only uh non-trivial This is the only non-trivial metric function. So, how do you get to quasi-normal mode? So, the recipe is that you divide one over r times, you rescale your field in this way. You expand in spherical harmonics, so you have this reduced field, little v. And when you do this, your wave equation, four-dimensional wave equation, turns into a two-dimensional wave equation for your reduced field plus a potential. A potential. So we call this the reduced equation, and this is sort of the starting point in the analysis given in this paper. So how do you get the quasi-real mode? So first you start by introducing the time derivative of your field as a reduction variable psi, and then you make a Fourier transform or Laplace transform to get to an eigenvalue problem. Now you do An eigenvalue problem. Now you do this, but in this particular work, this is done not taking a time derivative respect to the time adapted to a Cauchy foliation, but rather an hyperboloidal time. And there's a sort of standard recipe to get to these hyperboloidal slices. So this procedure goes more or less as follows. First, one introduces the tortuous coordinate, R star. R star, then if you want to construct this hyperboloidal slice, then you consider this change of coordinates. So you change little t by tau, which is given by this expression. So this h function, h of x, is known as the height function, and this raises up your slice so that you can eventually get to know infinity. And then for the tortoise coordinate, you make a compactification. make a compactification so you introduce the g of x and the g of x is usually chosen such that you make a space compactification and here i should mention that this is just a compactification in space it's not a compactification in in full in space time including the time um so uh so that is to say you could also choose this g of x not to compactify your spatial coordinate but just to like squeeze or Like squeeze or expand your change it a little bit. Anyway, the point is that given this standard recipe for these hyperboloidella slices, you can compute these functions that appear here. They essentially just depend on this h of x and this g of x. And these functions w, gamma, and p, they will become important in a minute. So the thing is that when you So, the thing is that when you express this eigenvalue problem using these coordinates, so the operator looks like this. So, you have an operator L1 and L2. L1 and L2 have this form, which depend on these functions W, gamma, and P. And these have sort of the form of the L1 has a strum-lou form where you can see like the resemblance with the toy. Like the resemblance with the toy model that I showed before. And so, using this equation and this form for L1 and L2, you can just write what is the energy associated to this reduced field is given by this expression here. And you are compactifying your spatial coordinate from minus infinity to infinity in the tortoise coordinates to xA to xb in. To XA to XB in the on physical or the hypervolatile radius. So you have this expression for the energy, and in the work of these authors, they computed the pseudo-spectrum using this energy as a way to specify the inner product. And they computed the pseudo-spectrum for Schwarzschild. But if we are faithful to the notion that we are interested in the physical energy of the field, then Energy of the field, then something that we need to clarify, which is a straightforward calculation, but nevertheless needs to be clarified, is what is the relation between the inner product and hence the energy of the physical field and the reduced field. And well, this is a straightforward calculation. How do you do this? Well, you know that for the reduced field, there's a energy momentum tensor from which the energy follows, just contracting. The energy follows, just contracting with the time-like Killing vector. And then you can do the same for the physical field. And then at the end of the day, just compare the two expressions. So what you obtain is not very surprising, but it's significant. So that you have that the total energy is just the sums of the energy for each mode. And first of all, at the beginning, we thought because of this hyperboloidal poliation that there could be. Of this hyperboloidal fouliation, that there could be a modulating factor between the total energy and the sum of these partial energies. But no, actually at the end of the day, the total energy is just the sum of the energy of each mode plus a boundary term. And this boundary term is the one that actually makes a connection with the topic of today's session. And as I will try to convince you in a minute. convince you in a minute. So this boundary term contains f, so the norm of the time-like queuing vector divided by r, r is the coordinate that goes to infinity, times the modulus of the field, and this is evaluated at the boundaries. So if you are on a asymptotically flat space-time and you choose, yeah, and you choose as your boundaries the horizon and null infinity, well, this F goes like one close to f goes like one close to the conformal boundary close to null infinity so divided by r this will go to zero assuming that your field of course is bounded and on the horizon this f is going to vanish therefore this boundary term is not going to contribute so that is just to say that everything learned here using the effective energy is completely fine and it's okay and now that you have this expression well one thing that you can do Well, one thing that you can do is just compute what is the energy flux. And so, the time time hyperloidal time derivative of the energy is equal to this F evaluated at the boundaries. And this F is given by the following expression. So you have, again, a sum over all of the modes of the time derivative and spatial derivative of the reduced field times these functions gamma p. These functions gamma, p, and f that appear f is the only function in the metric, and gamma and p are functions that essentially depends on your hyperboloidal slices and in the way you choose h of x and g of x. So for the particular case of the work of Jamio Panos-Maseda and Auckshake, so things are chosen, you do this hyperbole slice, in such a way that this p In such a way that this p actually vanishes at the boundary. So this second term here is not going to appear. And again, if you assume that you are on an asymptotically flat, in the asymptotically flat case and your boundaries are the horizon and at infinity, null infinity, well, this other last term is also not going to contribute. But the term that you cannot get rid of is the first one, the one with the gamma. So, and that is going to be relevant. So, and that is going to be relevant for making the connection with, hopefully, with BMS charges and symmetries. Okay, so now that we have clarified what is the energy inner product, the physical one, and we are following this intuition, well, another parallel, another thing that you can get from this is: okay, so we can recast this eigenvalue problem. Value problem in a weak form. So the weak formulation of this eigenvalue problem is as follows. So you consider a test function, you multiply this by the left, you take the inner product respect to the energy, and then you can integrate by parts to reduce the number of derivatives appearing in this L, and you end up with this integral equality. And this is interesting on its own, but what we did here was. What we did here was to say, okay, now that we have this expression, we can actually take advantage of this in order to make a sanity check in the numerics. And that sanity check is to say, okay, so the phenomena that was observed in the work of Jameo Panoso Macedo using Chevyshev spectral methods uses this numerical method. So, what happens if we change the numerical method? Nothing should change. That is expectation, and one That is expectation, and one check that we did here, just a proof of concept, is using this radically different way of writing this eigenvalue problem and using finite elements methods to just make the comparison qualitatively in a toy model. The postulate toy model is the kind of benchmark for these quasi-normal modes, and we observe qualitatively the same the same behavior that was observed in the other paper. So, again, this is just a proof of concept, and it's just to Is just a proof of concept, and it's just to say this instability the numerical method is not to be blamed about this instability. Again, here this is not a proof, but we have numerical evidence that if you change the method, nothing will change. Okay. Another thing that you can do now that you have the energy inner product that you can trust. So one thing that one would like to do is to express the field in terms. Express the field in terms of these eigenfunctions, these quasi-normal modes. And as Rodrigo was explaining yesterday, so these don't form an orthonormal set. And so appearing it's not clear if you can express your field in terms of these functions. Nevertheless, there are different ways around it. Rodrigo, I think, has developed one way to do this. To do this. And in this paper, and also in another paper of Haramillo and Alt Shake, there's a way to do this in the case of this paper for applications in optics and for our case for the quasi-normal mode case for relativity. So, how do you do this? Well, you use the Keldysh expansion theorem. And this theorem tells you that if you are given an eigenvalue problem like this one, so you consider Like this one. So you consider the right and left eigenvectors. So the left eigenvectors are just the eigenvectors for the adjoint of the operator. And using the right and left eigenvectors, you can write the resolvent of the operator using these left and right eigenvectors that is shown here. Something important here is that this sum is given on a, so you fix a region on the complex plane, this region omega, and inside that region you are going to catch a certain number. And you are going to catch a certain number of eigenvalues, so you just take a sum of a finite number of those eigenvalues. And one particular appealing way to rewrite this Keldys expansion theorem is using something that also Rodrigo introduced yesterday, which is the conditioning number. So the conditioning number is given by this quotient, which is the product of the norms of the left and right vectors divided by the inner product between them. And whenever Them and whenever you consider a self-adjoint operator, well, this k is going to be one because the left and right eigenvectors are parallel. So you will get one here. But something that is not true for general non-normal operators is that this k doesn't need to be one. Nevertheless, one advantage that we have here in the hyperbole case is that we can In the hyperloidal case, is that we can normalize these left and right eigenvectors. Remember that we have the problem at spatial infinity, and these eigenfunctions are not normalizable. But now, with this hyperboloidal approach, you can normalize the right and left eigenvectors, which allows you to rewrite your Kelvis expansion theorem in this way. So, you have the product of the left and right eigenvectors written here in the brackets notation times the conditioning number. So, So, this already suggested that if you are going to make a quasi-normal mode expansion, you better take just a few of them because you don't have guarantee that this sum is going to converge. In the self-adjoint case, you have that guarantee, but in the non-self-adjoint case, you don't have that guarantee. So, having this, so you can just essentially rewrite this for the particular problem that we have. So, the quasi-normal mode. Quasino remote resonant expansion. So the original problem can be looked in this way. So you have some initial data on your hyperboloidal slice. And using just this formula, just on wrapping things up, you can find an expression for the field in terms of the following. Your right eigenvectors times a coefficient. And this coefficient depends on two things. The first thing is the projection of your Is the projection of your initial data against the left eigenvectors and taking this projection using the energy inner product times the conditioning number and of course times the exponential of omega tau your eigenvalues. And this sum is made over a finite region in the complex plane, this omega. So you catch a certain number of eigenvalues plus an error term. And one of the things containing the Keldys expansion theorem is an S. Kelvin's expansion theorem is an estimate for this error. And this estimate is as follows. So, this error in this energy norm is going to be less than a constant that depends on your domain in the complex plane, on this omega, times a decaying exponential on tau, your hydrological time, times the size of the initial data. So, this is telling you that if you give a certain number of eigenvalues, you take, I don't know, one quantity eigenvalues in your omega, and you wait. Your omega, and you wait long enough in hyperloadial time, this error is getting smaller and smaller over time. But this constant depends on this integration, this domain in the complex plane. So there's no guarantee that if you take a bigger omega, where you are catching more eigenvalues, that this constant is not going to change. This constant could increase if you take a bigger area. The only guarantee in this The only guarantee in this energy bound is that given a fixed number of eigenvalues, over time the error is going to be smaller and smaller. And again, you can unwrap definitions up to find an expression for the original field in terms of, again, projection with your initial data and this conditioning number. And again, this is telling you if you are making some approximation. Some approximating your field using these quasi-normal modes, we know that this k is not going to be one, this could be large. So we better take just a few of them because we don't know if this sum is converging or not. And this makes, I mean, kind of rounds up the importance of the energy inner product and the hyperoidal setup where we can normalize these eigenfunctions and then we. These eigenfunctions, and then we can actually make all of these, right? Now, the connection with today's topic on BMS, and this is actually heuristic and also a bit bold, but that's sort of part of the point of this workshop, to try to find inner connections with other topics. And is that if you look at expression for the flux, it only depends on the time derivative of the field times this function gamma, right? And this function gamma is something that has to do with. Gamma is something that has to do with how we chose the hyperboloid affiliation, right? So can be computed from the height function and the compression function. So it turns out that this gamma is not coincidental because if you compute what is the adjoint of your operator, you will see that the adjoint of L is given by L itself plus another operator, which only contains this L to delta, which is given by this expression. So in this expression, you find this function gamma again. This function gamma again. So, and this L2 is the one that is associated to having a non-self-adjoint problem. Therefore, I mean, if you put gamma equal to zero, you have a self-adjoint problem, and consistently here, the flux would be zero. So, this is sort of pointing out towards a possible connection between maybe VMS structures, because you can sort of write this L2, this. Write this L2, this operator, in terms of gamma times the product of K and L. K is the generator at null infinity and L A is an orthogonal null vector at null infinity. And so, of course, this is just minus one or minus two, depending on your convention. But by rewriting this expression in this way, you could interpret this vector here, gamma k, as As one of these super translations. So, this is sort of pointing out that maybe this could be used in order to find a notion of normal mode, right? What I'm saying is that the leakiness of the system is contained in this gamma. And if we incorporate these missing degrees of freedom, maybe one can really have a conservative system and maybe try to define a notion of normal. Try to define a notion of normal modes. Again, this is just heuristic, and this is plans for the future, and some general ideas coming from this observation with this gamma. Now, another thing that is important here is that we use this hyperboloidal prescription. However, we think that the most important thing here is this gamma given here at the boundaries. And we are Are trying to see if there's a way to geometrize this approach, namely, just forget about hyperboloidal coordinates. Say you are given that here at a cut of null infinity and at a cut of, say, of the horizon, and then you just put any other hyper surface connecting these two boundaries. And given the intrinsic and extrinsic geometry of these arbitrary. Of these arbitrary surface that connects these two boundaries, if one can somehow repeat the whole calculation. And we believe that one of the important boundary data is going to be this function gamma. And yeah, that's it. Thank you. Thank you for listening. Thank you very much for having me. So thank you very much for having kept in time. So now we have plenty of time, twenty minutes for discussion these about this talk, or you can also connect with the previous one. So the slide, is there any question for Eda? Yeah, I have a couple of questions. Can you open the slides again? Yes, yes. Okay. So my question is rather like So, my question is rather like one question, but it's multiple places, which is which is so you mentioned the domain of the operator is very important, right, at the beginning. Yeah. However, I might have missed it. Did you do okay, so if you go to the weak formulation, first of all, of the quasi-normal mold? I can you hear me? I think your voice is broke. Yeah, now I can hear you. Okay, okay, it's better now. So, my question is related. Now, so my question is related to the domains of the operator. You mentioned that it is very important at the beginning, right? Yeah, yeah, yeah, yeah, it is very important as shown in this. So here, we don't actually make a full analysis very carefully about the domains of the operator. But actually, maybe one starting point for this is the weak formulation. So, yeah, so that's my first question. That's my first question. It's related to the weak formation. So, do you have an idea? So, what do you do? Like, when the numerator take the numerics, you take the analytic view. For the numerics, I can tell you what we do. So, for the I suppose it's analytic view, right? So, for yeah, yeah, for the, for the, actually, and even for the test function, we assume that the test function vanishes at the boundary. So, we can get rid of this boundary term. So, by test function, you do not mean it's most compactly supported. Yeah, compactly supported, yeah. And smooth, yeah, yeah. smooth yeah yeah no no yeah yeah i think yeah we assume that it's smooth okay but for the operator itself it's just like yeah so for the memory we do that but actually so we didn't actually really further develop uh an analysis along along along these lines of determining very carefully what is the uh spaces uh but but yeah this would be the starting point and i think there are some works going in that direction Going in that direction, there are these Jevre classes. So, which point out that, like, I mean, this function should belong to one of these Jevre classes. So, maybe one could try to understand that in the hyperbloidal approach, starting from the weak formulation as written in here. But yeah, we didn't follow that direction nor analyze that very carefully. But don't you think this would have a big effect on the distribution? A big effect on the distribution of the or even including or removing some cosinomal modes and some important parts. So, I don't know if you will have a change in the spectrum, it's rather how do you define these. So, for instance, like was in all modes, in this case, like the spectrum is a point spectrum for this toy model. But for instance, for an Schwarzschild, you have the branch code, you have a continuous part of the spectrum. So, how you define this. So, how you define these was in oral modes, including or not the branch code or not. And I mean, and these and these subtleties have to do with the fact of where you define your eigenfunctions, right? Yeah, of course, yeah, of course. Yeah, exactly. If you can go one or two more slides, just like one last thing. Yeah, this energy, energy, the one before that. Uh, the one before that, the one for uh, this one, like say in the question about the expansion. Uh, so um, it's always still the same question, but but I assume, like, do you would you have an idea what would be the domain here and uh for L when you take the energy, the initial data to be in finite energy, the U0? No, here you just assume, you just assume that the here initial data, when you take the note, the When you take the size, the norm of this data in terms of the energy norm on your initial slice is finite. But I mean, we take this as an assumption, but we don't really analyze the details of in which function space this has to live in order to have this, right? So we take this as an assumption. Yeah, but it seems natural from this to take like finite energy spaces of the completion of some of some of the competitive support or something. Okay, but you haven't tried this. No, we haven't tried it. So, I mean, probably the try this so i mean probably this this can i lost you written you have to analyze this detail i didn't hear what you said sorry because because uh we lost you first yeah that like we didn't we didn't analyze with with with detail in which in which spaces really these the initial data has to live and this this might be this might actually also have a connection with the problem at spatial infinity because At spatial infinity, because so, as in the talk of Lars, he was saying that assumptions on spatial infinity can be, or the initial data, decay close to spatial infinity, they can be translated into certain properties at null infinity. So, here we're starting already at null infinity. So, probably this could require certain conditions on the initial data, how the initial data behaves. Data, how the initial data behaves close to the cut of non-infinity, but yeah, it would be interesting to look at these things. Okay, thank you very much, and thank you for the talk. Thank you. Other questions, comments? Yeah, I have a couple of questions. Can I just continue or is that okay? Go ahead, bye. Okay, okay. So, just looking at this slide itself, first of all. First of all, I mean, so what happens to the tail terms here? Because here you have got this expansion just using quasi-normal modes, as I understand it, but maybe I misunderstood something. And the small error here, right? That is, of course, here. So, but still, everything is within causinormal expansion, right? Cosinormal mode expansion. So, I mean, the integral part of the expansion, right? integral part of the expansion right you that you yeah actually that is here we actually code that part by by by by assumption so there is a a technical assumption here about we make about the operator l to get rid of that that term yeah it's not there yeah it's it's it's almost got by by by by hand by hand okay uh the second thing is that with your norm um so i didn't understand can you repeat i i have not understood Repeat, I have not understood neither the question nor the answer. Okay, my question. My question was whether, um, I mean, there is a formula on this slide with u of tau x equal to something. But that formula just used really only the causinormal Morse expansion. Even the error term has to do with causinormal Morse, as I understood it. Maybe that's what I'm not sure about. Not sure about. But on the other hand, we know from the talks we hear from Arik Takis yesterday that there are these tail terms, and those will not be expressible in terms of this causal normal modes. And as I understood, the answer was that, in fact, those told tale terms will cut my hand in definition of this operator L somehow. Yeah, Jose, so the assumption that we make about L of this Fredholm assumption about L. Home assumption about L. So, yeah, so I mean, this is an assumption that we put on L, of course. So, yeah, a refinement of this would be removing that. Yeah, that's fine. Actually, the goal of this slide was to recover Lax Phillips expansion. So the resonant expansion with Lax Phillips. This expression of the scattered field as a sum of the discrete Again Mario. Of the discrete eigenvalue modes, it is just a road term, it is just the expression you get in a scattering theory when you define resonances as the pulse of the metamorphic extension of the resonance. So, in that context, they don't care, they are not able neither to take care of the problem of. Happens in our problem of interest, which is black hole. And then the statement is that this was truncated. That's the answer. That's the answer I understood. Yeah, no, I understand. The tails overtake. Can you repeat? Sorry, we lost you for a second. So we would expect this expression to be valid before the tails. Valid before the phase overtake the exponential. Right, right, right, right, right, exactly. Um, the second thing was about the norm that we use and the significance of infinity. At one stage, you had a formula which said that that norm was equal to sum over all lms of E L M. Yeah, that formula. So that E0 L M is, I mean, that sum is what is the, I didn't understand the notation. Is that I didn't understand the notation basically. Oh, yeah, zero lm is the same as what uh is that the yeah is it related to the stretchery tensor norm or so so I mean this this this big sum is is just a is just a shorthand for the sum over from L equal to zero to infinity and n from minus L to yeah right but I understand but is is that the answer I would get for that initial? Is that the answer I would get for that initial data on the hyperboloid? If I just use the stationary tensor and I computed the norm with respect to the killing vector field, is that what? Yeah, yeah. I mean, this term comes from the, right? So you have the relation. So this is the physical energy, this one here, and this is the reduced, the reduced one, right? So the relation between little phi and capital V is that one is a harmonic decomposition of the other, right? One is of the other, right? So, this is where the L and M come from, right? All right. So, so then the term at infinity, which is the, which then you look at it in the scribe, and yeah, this are flux here that you look at, right? And then you emphasize that there is a gamma that still remains. That gamma had to do with the height function. But that gamma is it independent of the u-coordinate on scry, or is it independent of time, only depends on angles? Independent of time, only depends on angles. So, so yeah, so gamma, gamma is given by this is the quotient between h prime and g prime. So, here here we don't have any dependence on the coordinates. And that's my point of trying to geometriize this, right? So, here we are doing spherical symmetry. And so, yeah, there's really no dependence on the angles. And this is not a geometric thing, right? This gamma is just this quotient. is just the discourse between this gh prime and g and g prime, right? And this depends on this particular prescription of changing the coordinates. So what we mean by geometrizing this is to actually lift this restriction and say we just have a gamma given on the boundary, which is a function that can depend on the on the on the on the angles. And for instance, if it just contains the L C L L equals 0 L equals 1 harmony could be at the Call one harmonic could be a vector, would be a relevant vector via a translation, but it depends on all of the other harmonic would be a super translation, right? That's what we mean. So in this case, everything is quite rigid. But can I add something here? Something that I drive notice afterwards. Gamma is the shift in the triple formulation. So it can perhaps be tied to some geometrical thing. It to some geometric or thing at t plus one. So I also w is the lapse, uh, p is the metric at the surface, and then gamma is the shift. So it is so that it brings some sound. So what does the lapse? I we couldn't hear you. What does the lapse? Uh, W. W is a lapse. Where is that? I don't want to be so sure on this. I mean, gamma is a shift. I mean, gamma is a shift. Yeah, no, I don't want to make a full strong statement right now, but yeah, but they can be connected. I'll have to double-check. But it seems to me that consistency would require that the flux through Skry would just be the flux of energy. And so the flux defined by the killing vector here. You just have. Killing vector field. It just has been expressed in some unconventional way because you are using hyperboloid slicing, so you're going to clax and shift. The killing vector field is not normal to this particular slide, a particular slice. So it seemed to me that the answer you should get should just be the flux of energy. Otherwise, it doesn't seem consistent to me. Because the sum or ELM was just the flux of energy. What just the flux of energy as measured by the Killing vector field on the hyperboloid, and then you get, of course, a boundary term. And that boundary term should just be the flux of the same energy. I don't think there is any superspansillation involved at all. Okay, I see, I see. Well, that's the P, not the gamma. Not the gamma. Yeah, yeah, the P is zero at the boundary, but not gamma. PC or the Panderable Mock Tammer. Yeah, so I think that somehow, because of the way the slicing are used, what you mean by that the translation given by the keening vector field is a little bit mixed up. It is not, you know, the translation, yeah. And so therefore, otherwise it will not be consistent, you know, because supposing I don't know anything and I'm just trying to find out what is the energy lost between, say, two hyperboloid, two slices up here. Slices up here. So then I should just get my conservation of energy.