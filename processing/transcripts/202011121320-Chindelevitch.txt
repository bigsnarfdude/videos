Okay, thanks very much, Alex. And thank you to all the participants and all the speakers. It's been a fantastic workshop so far. And I'm really looking forward to the rest of today and tomorrow. So I'll be talking about some work that I did while I was still at Simon Fraser University. I'm now at Imperial College London. I'm now at Imperial College London. And it focuses on using interpretable machine learning to predict drug resistance. And I realized that I made the title fairly general, but the truth is that so far we've only tried it in mycobacterium tuberculosis. So that's the one that I'll be talking about. This is joint work with a number of people and primarily my PhD student, Human Zavetti. So what are some examples? What are some existing methods for predicting drug resistance? So, previously, people have primarily tried to look for individual variants such as SNPs that are able to predict drug resistance. And the problem with those is that, although it is a very interpretable kind of predictor, it is not often very accurate because bacteria can always develop new mechanisms for developing drug resistance and also. Developing drug resistance, and also we might not just understand enough about the mechanisms of new drugs, for instance, that appear, new antibiotics. On the other hand, there's a lot of work using more complex machine learning techniques, especially deep neural networks, such as the one that you see here. And the nice thing about those is that they tend to be very accurate, but it's very hard to understand what it is that's going on behind the scenes there. And our group. And our group has tried to develop some of these, and we have some success. There's a reference at the end of this talk that I'll point you to, but there's just not a very easy way to explain what it is that happens inside a neural network to somebody who's interested in understanding. And so, what we thought about trying is the idea of rules, if-then rules, and those are going to be. Rules, and those are going to have the advantage of both being interpretable as well as potentially having a reasonably good accuracy. What are if-then rules going to look like? Here's an example of one. And this is a way to predict who's going to voluntarily resign, let's say, within the next month or so, based on different characteristics such as job role, base salary, month since promotion, and how they're compensated. Okay, so this is a Okay, so this is a very easy to understand kind of criteria, and they give you a very natural interpretation of what it is that you're looking at in order to make your decision. So how do we then get such a rule-based classification method? Here we're using an approach that's a combination of group testing and Boolean compressed sensing. So I'll explain what those are in a minute. First, group testing. First, group testing is a technique where we test people in groups instead of individually. And this arose in the United States during the Second World War, when a large number of people had to be tested for syphilis, people who were being recruited into the military. And this process was fairly costly relative to the number of individuals that were actually infected. So testing everybody individually ended up Everybody individually ended up easily spending 100 tests to maybe detect one positive person. And so then this statistician named Dorfman suggested the idea of pooling blood samples into specific groups and testing those groups together. So how would this work? So we would basically decide, okay, the first group is going to be these three people, next group is going to be this one person, then we're going to have two people, then we're going to have those three people, and so on. Those three people, and so on. And we're basically just going to select for each group who are the people who are going to be part of it. And then we test the groups separately from one another, but all the samples from the individuals involved in a group go into one test tube, I guess. And if we get a negative result, then this actually means that none of the people involved are actually infected. If we get a positive result, then that means that one of them is. A positive result, then that means that one of them is infected. We don't necessarily know which one, and it could be more than one. Okay, so the thing that Dorfman was able to show is that this can substantially reduce the number of tests that are needed, as long as the prevalence is not too high, as long as the number of positive people is not too high relative to the total. And now we're going to use the same idea, but to build interpolation. To build interpretable predictors. Okay, so I'll show you how this works. But first, we need a couple of concepts here. One is the matrix A, which is the membership matrix, and it's basically going to record a one in a row if the corresponding person is part of that group. Okay, so basically, each row is a group, each column is a person, and we're going to put a presence absence with a zero or a one or two. With a zero or a one or a zero. And then the status vector y is going to be the result of those pools. Okay, so when we test people one, five, and six, we got a positive result. But when we test only person five, we got a negative result. Okay, in this case. And so what are we going to try to do? We're going to try to figure out who are the actual positive people in this situation. And how are we going to do this? Well, we're going to notice that. Well, we're going to notice that if we get the correct vector of statuses, w, and it's going to be a binary vector because everybody is either zero, meaning uninfected, or one, meaning infected. The way that we obtain the vector y, which is the vector of statuses, assuming everything happens perfectly with the tests, is by doing a Boolean product with V, with W. So, what is a Boolean product? A Boolean product is simply taking Is simply taking the row corresponding to A and taking the column corresponding to W and doing, instead of a matrix multiplication, doing a Boolean multiplication, which is to say that a 0 times 0 is 0, a 0 times 1 is 0, and 1 times 1 is 1, but the addition is such that anytime we have more than a single one, the result is only just a single one. So it's basically like all the ones collapse into a single one. ones collapse into a single one, whereas any number of zeros don't make any difference. Okay, and so by doing that, we got exactly what we want. And we can actually try to recover this vector w. For instance, in this case, what actually happened is that people number one and number seven were the ones that were positive. And that is what explained all these tests. So let's compare this with something that a lot of other people have talked about today, which is Today, which is often used in microbial GWAS and also other areas that are related, which is to say linear or logistic regression. So in linear or logistic regression, we're going to try to minimize something that we know is easy to minimize, which is the one norm or the two norm. And those are convex norms. And the regularization penalty is going to encourage the coefficients to be sparse, but it's not going to enforce. Sparse, but it's not going to enforce their sparsity. Okay, so typically what we're going to do is something like in the linear regression with regularization context is going to be something like finding the best vector w for this objective function, which is the difference between the predicted and the observed values in the two norm plus some coefficient times the one norm of the vector itself, and the one norm is what promotes the sparsity. One norm is what promotes the sparsity. However, what we're doing here in the group testing and Boolean compressed sensing approach is we're actually minimizing zero norms. And what's a zero norm? It's simply the number of positions that have a value different from zero. Okay, so it's the number of non-zero coefficients. And this is what the L1 norm tries to minimize, but doesn't always get there. Get there. Okay. And so then we can also allow misclassification penalties that differ between a false positive and a false negative. So depending on how much we want to predict a incorrect resistance status versus an incorrect sensitive status is going to be a possibility that we can include here. And notice that the only difference in, except for the norms, which are both zero norms here, is this Boolean product between Boolean product between A and W rather than the usual matrix vector product. And there's a lot of literature on this type of optimization. It's going to look surprisingly hard because of the zero norms, but it turns out that with modern techniques, it can be achieved fairly quickly. And in fact, none of our problems required more than an hour or two to be solved. So, what are we going to do in order to make this into a classifier? We're going to turn the predicted W, okay, which is the subject of our optimization problem here. We're going to turn that into a classifier as follows. Anytime we see a new vector x, which is to say a vector of zeros and ones, we're simply going to take the Boolean product of x. Boolean product of x with w, which is the w that we extracted from the solution. And in other words, what we're going to do is we're going to say that the predictor is going to be a one if at least one of the features selected by w is going to be present in x and zero otherwise. So, in a way, we are coming back to something very similar to the initial catalog-based prediction, but it's a slightly more general. But it's a slightly more general approach here, which we can also generalize further, and I'll show you exactly how. And this is because of the flexible nature of our objective function that we're working with here. So now, of course, we no longer have people, right? We're going to have features instead, and groups are going to be replaced by genomes or isolates. Whereas the labels, instead of being the Instead of being the result of a group test, they are now going to become the resistance status with one or a sensitive status for zero. Right, so now that we have this, we're basically going to be able to turn it into a rule of the form if then. And the rule in this case is simply: if feature one is true or feature seven is true, then predict that the label is true. Otherwise, false. So, this is a little bit about the way that we process the data. A little bit about the way that we process the data now, and then how do we actually evaluate it is going to be the subject of subsequent slides. So what we did is we took about 8,000 isolates taken from VSEC-TB and the Patrick database, which are two large databases for tuberculosis isolates with a lot of phenotype data on different drugs. We turned it into a feature matrix, and we also. And we also have label vectors for seven different drugs that we looked at. And then we are simply going to solve this problem, and that is going to give us a predictor. Then we did the standard machine learning things, so cross-validation and looking at the performance on the held out part of the data set. So how do we then formulate our problem? Formulate our problem in a practical context. Well, we're going to need to be able to turn this formulation into something that a solver, in particular, an integer linear programming solver, can deal with. Okay, so we're going to think of it as an integer linear program, and we're going to look at how to formulate this in a flexible and easily programmable way. So we're going to take our penalty. Take our penalty over here, which is the penalty on the weight. And remember that the weight is a 0, 1 weight. So whether we do a one norm or a 0 norm is actually not going to matter. And then we're going to have the psi i and psi k for the positive and the zero parts of our problem, which is to say the resistance and the sensitive isolates. And we're going to construct. Isolates, and we're going to constrain those in such a way that if the sample i is misclassified, then Ïˆ i is going to have to be 1. And if sample k is misclassified and it's a negative sample, which is to say a sensitive sample, it's going to have to be one as well. So this is the way in which we can account for the misclassification penalties, and these are exact misclassification penalties, which Exact misclassification penalties, which is to say we score one if the classification is wrong and zero if it's correct. And there are some constraints here which are not so important. But the nice thing here is that actually these sums over here are exactly the false positive and false negative totals that we make in our prediction. So we can actually play around with this and we can change the constraints around. For instance, if we care about a particular Care about a particular specificity being a threshold, then we can try to maximize the sensitivity at that specificity or vice versa. And we can also put the size of the rule as a constraint instead of a part of the objective function if we want to limit it to, say, rules of size at most 20, which is to say we're allowed to use at most 20 SNPs for the prediction. So at the end, we need to evaluate all of this, and there's this. All of this, and there's this framework for evaluating interpretable models, which looks at prediction accuracy, descriptive accuracy, and relevancy. And so, we're going to look at all these three criteria. So, in terms of the predictive accuracy, we're doing a little bit better than random forest models, which have been used in the past. We're doing a little bit worse than straightforward regularized logistic regression. Regularized logistic regression. However, we'll see later on that there might be some redeeming features for the way that we do things. In terms of our description ability, we get reasonably okay areas under the curve. And you'll notice here that the curves look really weird. They're not actually supposed to look like this. They're supposed to be monotonic. But the problem here is that we're not quite able to get them to be monotonic because of the Able to get them to be monotonic because of the idiosyncrasies of the solver and the process by which we solve things, which I'm not going to go into, but we got some approximation of the, I guess, true area under the curve. And then finally, in terms of the relevance, we can look at, okay, well, how many of the predictors that we picked out actually found or actually going to land in genes that are known to be associated with drug resistance to those drugs. And it turns out that we, in comparison to the That we, in comparison to the logistic regression, if we capital the same or roughly the same number of rules, a number of elements in the rule, which is to say 20, we're actually going to do a lot better. So far more of the red, which is to say SNPs that are found in known genes, are going to be present in our approach versus the logistic regression. And so a quick summary of all this. We can infer rules. We can infer rules through modern optimization, and I believe that it's a powerful method for predicting as well as gaining insight into drug resistance. So, we're currently planning to extend this to other bacteria that might be less colonial than TB. There's some indication that the relevant variants are being recovered. And of course, ultimately, we would need to do something like what Kevin showed in his talk, which is to confirm them experimentally in a lab. And they're also flexible enough to allow different kinds of labels. So, right now we're doing binary resistance-sensitive labels, but we could look at continuous MICs with the exact same framework. A large number of features can be accommodated. We might in the future look at presence, absence of k-mers, like Pierre's talk yesterday showed. We can also restrict the rule complexity and we can play with different types of rules. So, for instance, Play with different types of rules. So, for instance, we can look at conjunctive normal form rules, disjunctive normal form rules, or even linear combinations. And we can play with some trade-offs between the sensitivity and the specificity as well. So with that, I'd like to thank you all for your attention and acknowledge all my collaborators. And here's a list of references to this work and some other work from my group. Thank you very much. Thank you very much, Leonid. Oh, it just answered the question. But well, here's another one. Do you think the small performance gap between your method and logistic regression is due to solvent sub-optimality or model expressivity? Oh, that's a great question. I think this requires a little bit further investigation. So, one of the problems that you get sometimes is that the solution that you get That you get is one of many possible optimal solutions. So, how do you distinguish between several equally well-scoring solutions is not always clear. And so, that's something that we want to explore in more detail. I think the model expressivity does play a role as well in the sense that there probably are some interactions that might be. That might be interesting to look at, or perhaps there might be some weights that logistic regression is able to assign, which we don't. So we basically treat every feature as equal. But yes, it could be either, I guess. Could be a bit of both. So when you do the analysis, you're looking at one species only, right? At one species only, right? At the moment, yes. So, can you think of like combining different species and looking at genes instead of SNPs or something like that? Yes, absolutely. So, gene presence absent data would be another good thing to try with this technique. And in fact, we would probably want to look at multiple. So, for instance, we could put all the gram-negative bacteria together. Negative bacteria together do a large gene presence absence matrix, which, as I found out earlier this week from one of the speakers, is actually not so easy to do because the gene nomenclatures are not consistent between different bacteria. But never mind, assume we can overcome that. And so, yes, then you could basically ask yourself the question of: okay, so what are the genes in all these bacteria that lead to drug resistance? And in presence of things. And in presence of things like horizontal gene transfer, that would be a very sensible thing to do. So, how big can this matrix be to be the computer? That's a great question. So, we had 8,000 rows, and in this case, we had only about 70,000 columns. So, that doesn't sound huge, but there are previous examples where the same or a very similar type of framework, so integer linear programming, has been successful. Programming has been successfully applied to hundreds of thousands of rows and millions of columns. So it is still within the limit of feasibility. Of course, you have to be very patient because it might take a while, but they do converge even on such large problems. Interesting. Nice. Okay, thank you very much. Thanks a lot.