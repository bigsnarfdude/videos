Thank you. Yes. So, hi everyone. I will add my apologies to all the other remote speakers who have not been able to go. As I mentioned to Marco earlier, anyone who knows me knows that I've enjoyed previous visits to Mexico and I was really looking forward to this one, but alas, here I am. Alas, here I am. So I'll do my best and give hopefully what is an interesting talk about predominantly about combining gravitational wave observations with gamma-ray burst observations. And then towards the end, partially because I forgot I left it in the abstract, but okay, I will also show some work on kilonovae and also combining kilonovae and gravitational waves. Kilonovi and gravitational wave-related work. So, the Kilonova work is done by Lawrence Dratrier, one of our PhD students, and the majority in all the GRV work, which is the majority of this talk, is done by Fergus Hayes, who has been, which basically the material I'm going to talk about has been his PhD project. We also get some interesting input from a theoretical astrophysicist, Gavin Lamb. Astrophysicist is Gavin Lamb, who is at Leicester, and we have regular meetings with him. Oops. Okay. Right, so here's the overview of the talk. Just to sort of get everyone's mind into gear, I'm just going to give a very, very brief sort of intro about gravitational waves and short GRBs and GW170817 just to pose the issues that we need to deal with. And then I do. And then I talk about looking at the jet structure, so looking at the short gamma-ray burst jet structure. So everyone hopefully is aware that post-1708-17 and observing the gamma-ray burst GRB 1708-17A, the concept of gamma-ray bursts having a structure, basically having varying luminosities as a function of the angle that you look at it from, is Is now sort of the main approach, and we want to figure out what this jet structure is because it has implications for astrophysics but also for cosmology. And so I will discuss a few aspects of this. So the first aspect is a sort of predictive kind of study where we simulate a population of binary A population of binary neutron star observations and correspondingly some short gamma ray burst observations. And we combine them together to see how well we can infer the jet structure. It's just, for example, to predict how well we can distinguish one jet structure model from another in the near future. And then the second part is actually about taking data we already have. So inference on the short gamma ray burst rates on the binary neutral. Burst rates on the binary neutron star and neutron star black hole rates, combining them together, and then using that to infer a jet structure. And there will be a slight detour because doing this second part of the analysis requires, well, it's quite computationally heavy. And so luckily, one of our other PhD students at Glasgow, Michael Williams, came up with a nested sampling method with this machine learning. With this machine learning aspect built into it called normalizing flows, which really sped up sampling. And since we're also talking about machine learning at this meeting, I'll just spend a couple of slides to describe this approach. And then, as I mentioned before at the end, I will also talk about just some kilonova parameter estimation, especially this BNS merger time, from just looking at kilonova-like curves. Okay, so introduction, and it's actually a bit of history. You know, it's sort of a funny thing. Then postdoc Silong Fan, who was working at Glasgow, Chris Messinger and myself, we submitted a paper in early 2017, long before August, about how we could use gamma-ray burst observations and Observations and gravitational wave distance posteriors, and combine these two to get the luminosities. Because the observations from short gamma-ray bursts are just a flux. You don't know the distance. You would typically get the distance from identifying a host galaxy, say, or some other means, but anyway, typically identifying a host galaxy, and then measuring the redshift to that galaxy, and then getting from that getting the distance. Getting the distance. And so we proposed that actually, given that if you have a joint observation of a short GRB and a gravitational wave, then you could actually get the distance. And actually, we showed that we could get a distance with an uncertainty that is on par with the galaxy, the host galaxy identification approach. So the red line is basically the probability distribution on the luminar. probability distribution on the luminosity. So the true luminosity is the pink line and the black line, sorry, so the red line is that for gravitational waves and short gamma ray bursts and then the black line is for short gamma ray bursts and an identified host galaxy with a perfectly known redshift, i.e. no biased in the distance. And in this sort of toy bottle, we showed this idea that actually gravitational waves can fill in the blanks. Fill in the blanks. So the issue with short gamma-ray bursts is that you don't always identify a host galaxy, you don't always get a redshift. And so our statement was that basically with gravitational waves and what we were thinking about eventually Einstein telescope and so on and so forth, we could see all the BNSs, all the binary neutron stars, within the same volume as short gamma-ray bursts. And therefore, we can just combine all the short gamma-ray bursts with gravitational wave distance. By memory bursts with gravitational wave distances, and then fill in all the blanks missing with the astrophysics. And at the time, one of the blanks was fitting this thing called the luminosity function, which was basically the distribution of the luminosities of short gamma ray bursts. And we thought, okay, let's do this, because it's more or less a straightforward extension from doing this to doing this and trying to infer this function. Infer this function, this luminosity function, looking like this with a power law, a broken power law, with indices alpha and beta. And so we showed that, okay, after about 20 events, we actually get a pretty good error bar if your alpha is equal to one in this simulation. And we thought, hey, this is fun and this is good. But everything that we've done here assumes a top hat jet. And this is basically fine because this is what Was basically fine because this is what everybody was thinking about prior to 1708.17. And then, of course, 170817 occurred, and we saw it in the gamma-ray burst, X-rays, optical, radio, and all sorts of multiple bands. It was a wonderful event. But the thing is, it was also very low, relatively low luminosity, which meant that, well, and also the gravitational waves in Gravitational wave information pointed us to the fact that we were observing the event from an off-axis, a significant angle from the rotation axis. And so in this diagram taken from this paper, you would have the central engine of the gamma ray burst here. And I hope you can see the mouse still. So here, and typically the gamma ray burst in the traditional model would have a burst in this direction. Have a burst in this direction, okay, and similarly in the opposite direction. And it would have, in the top hat jet, that would have some uniform core corresponding to some opening angle. And so the emission within this dark region is uniform and it just goes out. So this is the top hat. And the idea was that for 17017, when we were looking at the off-axis, maybe we were looking at some emission from the beaming, the Doppler beaming, coming out of the Beaming coming out the side of the event of the core, and that's why we could see, and that's why it was dim. But then it was also put forward other models. So this is another model, which is where you have, again, the GRB emission in this direction. The core is no longer uniform, and this is what the shaded color tries to convey, that maybe it's stronger in the middle and it's weaker at the edges, and that's just what it intrinsically is, and we are just observing. Basically, it is, and we are just observing the weaker emissions coming off from the edges. And we actually have this structured jet instead of this sharp cutoff in this top jet structure. And then there's another proposal, which was that given that when you have two neutron stars coalescing and colliding and everything, it's a very violent process. A lot of material is thrown out everywhere. And this material, if it's not thrown out far enough, could Material, if it's not thrown up far enough, could form a cocoon. And this cocoon basically could also create some emission, gamma-ray emission, that is observable. And so you have, for example, a jet again, which may or may not be uniform. And then you have some sort of cocoon emission on the side. Okay, and we are observing actually the cocoon emission, not part of the central jet emission. So these were the sort of main scenarios that have been going around since 1708-17. And well, to some extent, this top hat model is maybe a bit less fashionable nowadays, and people are exploring more the structured jet models. And so when we were doing all this work, we think, ah, now we have to take into account structured jets. But we could do this. And we could do this, again, by combining binary neutron star observations with gamma-ray burst observations. With gamma-ray burst observations, or rather, actually just gamma-ray observations, or to put it another way, the observations from a gamma-ray observatory at the time. Why am I saying it like that? Well, it's because what I'm about to describe basically involves counting the number of neutron stars, spinal neutron star mergers observed, noting the inclination angle. Angle or the viewing angle, if you like, of that binary neutron star, of that population of detected binary neutron stars. And then for each binary neutron star observed, ask what the gamma-ray luminosity is at that particular observing angle. And as you can see, if we just take note of the inferred observing angles with the gamma-ray burst observations, then basically we are kind of like drawing out Like drawing out, you know, if the purple line was the real structure, then we're just measuring the brightnesses at different points. And it doesn't matter where, if we don't see anything, we can say that it's limited by noise, so we don't expect to see this very dim edge out here. We can code this into our analysis and basically ask: given the gamma-ray burst observations at very Ray burst observations at various inclination angles, which jet structure is more likely to describe the actual jet structure of a gamma ray burst? Okay, and here we have assumed, and many people say it's reasonable, we have assumed that there is a universal gamma-ray burst jet structure. So we asked the question whether all gamma-ray bursts have a jet structure that looks like this thing called Gaussian, which is the purple line, or a power law, which is Or a power law, which is this line here. And the power law consists of this sort of flat central core of uniform emission, and then a power law decay, and then some cutoff at some outer angle, which is why it looks the way it is. And so to demonstrate this, we simulate our analysis. We simulate the population of binary neutron stars. And then we also simulate... We also simulate for a given jet structure the corresponding GRD luminosity, and we add as part of the simulation the uncertainties associated with the measurements, for example for the Fermi GBM observations. So this work and all the details, we use this thing called hierarchical Bayesian analysis to combine the gamma-ray burst observations with the gravitational wave observations. Observations, and this is what Fergus has, and this is all described in this paper here. And the hierarchical Bayes approach basically gives us this thing called the base factor, or at least we make it give us the base factor. So here I need to explain what the base factor is. And so, very quickly, this top equation here is Bayes' theorem, for those unfamiliar with it. For those unfamiliar with it. And so on this side, you have the posterior, the posterior, which is what we are after, the thing we want to know about. The likelihood is what the data tells us. The prior is our assumptions about either the model or the parameters. And then the evidence ultimately is like a normalization factor. It's got uses, but let's not worry about that too much. So basically, it says that what we know now is proportional to what the data tells us multiplied by what we know. Tells us multiplied by what we thought was happening prior. In this formalism, I just written it in terms of the probability of the model or model A given the data given some additional information I. So what we want, this posterior, is the probability that model A is supported by the data. I mean, if we have two competing models, then we have model A here and we have model B here, looking at this. And we have model B here looking at this lower equation. So we can take the ratio of the posteriors, if you like, and if you take the ratio of the posteriors, you'll find that the evidence is common, so it cancels out. And you end up with two factors, one which is the ratio of the priors, and one which is this thing called the Bayes factor. Now, in this context, the ratio of the priors is basically your prior belief in one model over the other. One model over the other. And without any additional information, we typically have the prior odds to be equal to one, right? That both models are equally likely, okay, because we don't know one over the other. Now, on the other hand, if you're testing and you want to be sophisticated and maybe the evidence already is stronger for one model over the other, then you can declare this by having this prior odds to be not equal to one. But typically, we set this to be equal to one, and we look at To one, and we look at the base factor. And so, in this sort of form, in this writing of the base factor, we find that if base factor is greater than one, right, then model A is preferred because the likelihood of the data supporting model A is greater than that for model B. So, base factor is greater than one. And similarly, the base factor is less than one if model B is preferred. Okay, and if the base factor is approximately one, then well, we can't distinguish. One, then we can't distinguish between the two models. Just one final note about Bayesian inference is that here I've written this Bayes theorem in terms of model inference because I want to talk about model selection. But the same can be said, I mean, this is basically how we do our parameter estimation. Probability of a parameters or a set of parameters given the data if we assume a model already. Okay, so that's essentially the expression that we have. The expression that we have when we try and infer all the, for example, masses, inclinations, and distances of the binary neutron stars of the binary black holes, and so on and so forth. Okay, so we have the simple tool, and we just need to know whether the factor is bigger than one or smaller than one, depending on how we compare our models. Okay, so jumping quickly to the result, and there's a lot on this page, but let me just point out firstly this experiment. out firstly this expression at the bottom here. So this is what we have in the vertical axis is the log base factor which is the log of the power low model versus the Gaussian jet model. So if the power low model is preferred then the line should go up and if the Gaussian jet model is preferred then the line should go down. And what we've done here is And what we've done here is because this is just a simulation, so we've simulated two universes, if you like: a universe where the gamma-ray bursts are defined by the power law jet, which is the blue line, and another universe where the gamma-ray bursts are defined by the Gaussian jet, which is the purple line. And we see that our analysis works very well, that you can actually start to distinguish between one jet structure model. Jet structure model versus the other after about 25 or 50 events. Now, when I say events, I just want to be clear, right? The events here are just binary neutron star detections. We do not need these binary neutron star detections to be jointly observed with the gamma ray burst. So we don't need another GRB 170817A situation. All we need is that whenever we have a BNS of a merger, Of our merger, we look at the gamma-ray burst monitors and ask what is the luminosity that they record at the time. Because even if it's the background, that is still information that can go into this analysis. And so after about 25 or 50 of these BNSs, which is actually quite possible around A plus time, we can possibly distinguish between We can possibly distinguish between models already. But of course, there are many caveats here. This is a simulation toy model. We've assumed quite a few things, but it's an indication of what can be done. And I stress again, we don't need joint GW gamma-ray burst observations. We just need to have a GRB observation of that part of the sky to tell us what the corresponding estimated flux is. So we did this actually. So, we did this actually for the GECAM mission. So, the GECAM mission is a Chinese mission of where they have two all-sky monitors, one on each side of the Earth, so that they can monitor the whole sky. And so, with the GECAM, because you can monitor the whole sky, then we can easily convert events into years, assuming a BNS rate of this amount. Actually, that's just plugged out and approximate number. And so we can translate basically 25 events to four years, 50 events to about eight years, assuming you have all-sky coverage, of course. Also, we assume this 300 megaparsec horizon and 70% duty cycle. So we don't assume that the gravitational waves have 100% uptime. Okay, so this is kind of the fun things we can do. And if you have other missions you want to try, And if you have other missions you want to try, we can try, we can play with this kind of characterization as well. Oh, and if you're wondering, the other lines there are just sort of different instances of that same universe, if you like, because the way the line goes up and down is a function of which order of observations you have. If you're lucky and you observe a very close one very quickly, you get more information very quickly, and so this line will deviate. Very quickly, and so this line will deviate, will move faster, and so on and so forth. So, if you like, these other dotted lines are just uncertainties associated with different instances of the same experiment. So after doing that, we just decided, we just thought about, hey, that's what we could do in the future when we have many binary neutron star observations. In principle, In principle, we actually have information that we can use now. So, the information that we have now are the rates of the binary neutron stars and the neutron star black hole. And this, we kind of, well, as a gravitational wave person, we sort of have a pretty good handle on these rates because we know the selection effects. We calculate the selection effects based on these observations when we estimate. Observations when we estimate the rates. We can take this and we can actually combine this with the rate of short gamma ray bursts. Because there should be a relationship based on the jet structure, the short gamma ray burst jet structure, between the binary neutron star and the short gamma ray burst. Because we've already established from 1708 17 that binary neutron stars should always emit well. Should always emit, well, we assume it always emits gamma ray bursts. Okay, so if we make this, if there is this connection, the only thing that's unknown in between is the jet structure. The thing that's a bit tricky is that with the short gamma ray bursts, there are many selection effects that we are less familiar with. So we know the selection effects for binary neutron stars and black holes. It's selection effects for short gamma-ray bursts. Selection effects for short gamma-ray bursts is a function of jet structure, but also many other factors as well. So, we previously did this inversion, assuming top hat jets, which was published here. But then actually afterwards, there's a paper by Kentaro, Marco, and Carrel that actually sets out a very useful formulism for structured jets that we use in our analysis here. Okay, so I'm going to show you some. Okay, so I'm going to show you some equations in a moment, which is quite long, but they are basically based on this nice work that was done by Kentaro and Marco and Karen. Okay, the key here is that from this work, we are able to relate the number of observed short gamma ray bursts to the number of neutron stars, binary neutron stars, or the rate of binary neutron stars. Neutron stars or the rate of binary neutron stars. And from this formalism, we basically aim to again get a base factor and figure out which of these jet structures are more likely. But this time not with simulations, but this time with actually historical short gamma ray burst rate data and binary neutron star rates. So these are the rates of these things we already have. Have. So, this is the formulism that we are using, which is from Kentara's paper. And there's a lot of stuff here. I tried to squeeze everything onto this slide, and maybe it's a mistake. But let me just talk through this very, very slowly. So, this is the number of short gamma-ray burst observations given the parameters of your jet structure model, whichever one you want to believe. So, here you can insert different jet structures. Different jet structures. This is the observing time, this is the average antenna response, and this is the rate of short gamma ray bursts at zero redshift. This R0 basically is where the neutron star, the binary neutron star and the neutron star black hole red comes in. R0, because we can only observe to effectively zero redshift since we can't see very far. This value is basically where Is basically where our BNS rate and our NSBH rate is coming. And I'll talk about this equation in a moment. And then inside here is where the rate of GRBs is. We're trying to infer the number density of GRBs as a function of their luminosities, their redshifts, the viewing angle that we see them, and their intrinsic luminosities L. Okay, so the other bit that we need, which is from That we need, which is from we get from observations, and how it relates to our jet structures, is that this threshold is from the detectors, but this threshold value is what we observe, what we can observe based on the jet structure. So this threshold value is basically 4π the distance, given a rift shift, some k correction, the flux, and then this is the jet structure bit here. Okay, y is basically the jet structure structure structure structure. bit here. Y is basically the jet structure. So the value you see of the jet structure at some particular angle theta. So if you are looking down the barrel right on the axis of the short gamma ray burst, then this theta would be equal to zero, right? And this y of zero value would be basically equal to one. And if you're looking very, very far away, then this value Very far away, then this value will be very small. And then so this ratio will be very large, which means that the threshold, the value that you have to see, is much larger. Which means that the amount of flux you require from the luminosity you require for looking at an off-exit axis beam is much larger when you are looking at an angle that's much larger. That's kind of what this. That's much larger. That's kind of what this equation is trying to tell you. And then the last part is the rates, which is a combination of the BNS rate and the NSBH rate. And then there's these epsilon factors. And I've said that we've assumed that every BNS emits a GRB. And so that's equal to 1. And then the literature tells us that this fraction of NSBHs that give off gamma ray bursts is between zero point one and zero three. Is between 0.1 and 0.3. So we don't make this a fixed value. We also make this a free parameter. So we try and infer this parameter, actually the rates parameter. We just use the rates that we have as a prior. We try to infer the shape function. And then we put them all together. And then we try to get that to fit the number of observed GRBs that we have. That's kind of the longest, the quick way of saying what we're trying to do. The quick way of saying what we're trying to do. And all this actually has a lot of joint probabilities and likelihoods underneath. It's, well, it's frankly just a lot of equations which I don't really want to show. But that's basically what we are trying to do. Now, there are a few more things we have to think about before I show you any results. So, firstly, the short gamma ray bursts, because we are not looking at nearby gamma ray bursts, we're looking at historical short gamma-ray bursts. We're looking at historical short gamma-ray burst rates. They're all observed very far away, so we need to take into account cosmology and this k-correction, which I mentioned, which actually we do. We also need to take into account the response of the detector that observed these things, which is the Swift-BAT detector, which is what we also do. We take the rates from GWTC2 catalog paper and also the NSPH detection paper. And then we take all these numbers and we throw them in a pot, and we ask, what are the jet structures? And we ask what are the jet structure function parameters for assuming one of these four structure functions. So the top hat function, Gaussian, power law, and the double Gaussian. So the top hat is the old school, if you like, and the Gaussian and the power law are the new, more studied Gaussian and power law jet structures. The double Gaussian is meant to sort of model the cocoon structure. The second Gaussian is very broad. Gaussian is very broad and it basically models the cocoon structure with a central Gaussian beam in the middle. I'll show you these structures in a moment. We also need to put in the Lorentz factor. So we throw in the Lorentz factor. And then we also need to assume actually a distribution for the brightnesses of the GRDs. And this is the luminosity function, or rather, the intrinsic luminosity function. And we found actually our analysis is. And we found actually our analysis is sensitive to the intrinsic luminosity function. And so the results I show you here is for what we would like to consider an agnostic luminosity function, which is basically an inverse gamma function. And there's this L0 parameter which defines the mode, basically whether if L0 is large, then the luminosity distributed on a large value. Similarly, for small, it's on a small value, and so on and so forth. Small value, and so on, and so forth. And also, it also tells you about the variance, okay? It's proportional to the variance. If we put all these things together and we throw them in the pots, we get something that's like 10 parameters, possibly more, depending on the jet structure. And this can take a very, very long time. And luckily, and it was taking a long time, it was taking weeks for Fergus to run this. Luckily, so Michael Williams came up with NASI, which is based on this machine learning. Which is based on this machine learning approach called normalizing flows. I'll mention this very quickly in a moment. And this really sped things up. And so I'm going to show you a result for three situations. The first situation is where we do the inversion of the rates based on only the historical short gamma-ray burst rates plus the BNS and SBH rates. And then we add more information by throwing in the inference for GW17087. Inference for GW170817 plus the rates, right? And then we have rates plus 170817 plus the other newfound star, which is 190425. Okay, and we can see what, and we can talk about the fun things we see from that. Okay, so just so you know, have some visual idea of what we're looking at. So the top hat jet is basically a top hat, okay? But if you apply various Lorentz factors, then you find that you have emissions out at high. You have emissions out at high viewing angles. But these emissions, by the way, I just want you to see that this vertical scale is a log scale. Okay, so these things are about less than, it's 10 to the minus 4, 10 to the minus 6 kind of levels. But in principle, we should be able to see something here if it's bright enough, which is a possibility for 17.0817, right? Because it was so close. So the power law jet now looks like. So, the power law jet now looks like this. So, a power law jet, the red is the jet structure, okay? And it has this bit here, this flat central core I was mentioning, and then there's an outer cutoff, which is way out, which you can't see here. Now, the jet structure has an additional parameter because the Lorentz factor also follows a structure and it has its own power law index, which is A. But the thing that we care about if we But the thing that we care about if we're thinking about the intrinsic luminous jet structure is the power law index for the jet structure itself, which is S in this parameterization. And then we have the Gaussian jet, which is again like this. And similarly, if we have different Lorentz factors, you can see that there's more emissions out there. And finally, the double Gaussian jet, where you have this Gaussian here, okay? And then you have the cocoon, which is a much broader Gaussian. Cocoon, which is a much broader Gaussian going all the way out somewhere. And so the combined jet structure function is this black, is this sort of red dashed line here. And then if you have various Lorentz factors, then you have the various black lines that you see here. So it doesn't actually change that much. And you'll see this parameter, I'll remind you about it again later. C is basically the fraction of energy in the cocoon versus the energy at the central core. Core. So if we just calculate the base factors, I'm jumping straight to the results. So we put all this stuff into the machinery. We ask it, you know, which jet structure is more likely. And we calculate the base factor. Now, the base factor here I'm calculating is the base factor of the Gaussian jet model versus the top hat model, or the power law model versus the top hat model, or Versus the top hat model, or the double Gaussian model versus the top hat model. Okay, so in this graph, basically if it's less than zero, the top hat model is favored. And if it's above zero, then it's depending on the color of the line, the other model is favored. And it's quite interesting. So here we have just historical rates, no information about 1708, 17 or other new things. And here we see that, okay, previously everything seemed to point towards top hat being slightly faded. Okay, these values, by the way, are very small. So, I mean, we are talking about sort of hints, if that, here. And so, it's just fun to think that, you know, this is actually consistent with the popular sort of approach of having top hat jets prior to 17.17. Jets prior to 1708.17. And then once you add the information for 1708.17, then the top hat jet actually becomes much less favored. And so it becomes, all the other jet structure functions are slightly more favored now. And then the higher it goes, the most favored, in the way I've plotted this, the higher it goes, the more favored the jet structure. So the double Gaussian is actually the most favored for if you have history plus 1708 17. Plus 170817. And then, if you add the other BNS observation, which is 190425, this one was not observed with any notable gamma-ray observations, and no gamma-ray burst was observed. So it sort of muddies the waters a bit. And so it seems to point to these two being slightly preferred. And you'll see in a moment, actually, it's not obvious whether it's actually pointing to the Gaussian or the non-Gaussian. Point to the Gaussian or the double Gaussian. So looking at these values, we can look at the parameters we see. And the parameters we see, let's first look at the top hat because this is top hat is what people thought of prior to 170817. And so the top hat prior to 170817 should, according to our analysis, should have an opening angle of something like this, 16 degrees, which is consistent with the literature. Consistent with the literature at the time. It was like 10 degrees, maybe 5 degrees. Some people said maybe it's 30 degrees. So it's kind of consistent with this. And then we add 170817 and the other BNS. We end up with a smaller jet structure function. And this actually surprised myself and Fergus because 170817, in particular, you were observing it and an offer. In a particular, you were observing it in an off-axis, so you would expect this to actually have a much broader, you know, if anything, it should broaden, it should broaden the jet structure. The key here is to actually look at the, so this is from the posterior, and for those who are not familiar with looking at these plots, the contour plots are basically of probabilities. Okay, and so the pink contour plot gives the probability distribution for the luminosity. For the luminosity parameter and the opening angle, the top hat jet parameter. And the most probability is for high energies, high luminosities, and relatively low jet angles. And the green, and this is for 170817 only. The pink is for 1708.17 only. Green is for 190425 only. And for green, it can't say very much because it doesn't see. Can't say very much because it doesn't see a GRB, but it still sort of points to the fact that there's something at lower angles. And the black is basically the inference prior to that, which is very hard to see here. But the long of the short is that basically the product of the pink and the black gives you, starts to squeeze the probability to this region. And what's happening is that saying that if you believe that the top hat structure is still the right structure to explain your model, then Your model, then you are basically having very narrow five-degree top head jets, but extremely energetic intrinsically. And that's why you have this Lorentz factor tail-off, which is why you fit 170817. Remember, the top hat had this sort of curve because of the Lorentz of the Lorentz factor Doppler beaming. And so that's that's so that actually this narrowing is actually sensible. This narrowing is actually sensible and kind of made sense, which threw us off at the beginning. But so, if you want to see, this is the rest of the corner plot, there's not very much else to see. And in the interest of time, I think I won't say very much about it, except to say that actually it's consistent with previous observations, because the rates don't change very much after we add new information, nor all the other parameters. Sorry to interrupt, but you have about five minutes left. Okay, thank you. Thank you. Is it like five minutes to is it quarter to the hour or is it like 10 to the hour? Sorry. Yeah, it's about quarter to the hour right now. Okay, thanks. Yeah. Okay. So the double Gaussian, we see that the That the well, okay, they have the best support. And so these are the parameters associated with them. And at the moment, let's just say whatever. It looks like this is theta, which is the inner angle, the central jet, and then this is the size of the outer cocoon size. And then this is a ratio of the energy of the cocoon to the central energy. The thing to note here is this is about 10 to the minus 4 less than. This is about 10 to the minus 4 less energy in the cocoon than the central energy, which is actually not surprising. I think that's kind of what's expected. At least it's on par with what's expected, so okay. But the other thing to note is that if we look at the Gaussian, here are the posteriors, which is a mess, but I'm showing you just so that, just to say that we have them. But if we look at the Gaussian jet, we find that the Gaussian jet also gives you The Gaussian chat also gives you an opening angle, a single Gaussian gives you the same opening angle as the double Gaussian for the central core. So it seems to suggest that actually at the moment it can't tell whether there's a cocoon or not. But it seems to suggest that the Gaussian jet fits the data the best. And finally, there's a power law jet which is slightly less favored, but nonetheless, it gives you an angle that is consistent about five degrees. Five degrees. The thing to note for those who do maybe astrophysics is that many people assume PowerDOT indices of two, but our analysis seems to suggest Power indices of 3.5. I don't know what to make of it. If you can say something about that, that's great. Okay, nested sampling. So I said I will say something about Nested sampling, and so, or Nessie, rather. So, Nessie is this unknown creature in Loch Ness, which In Loch Ness, which may or may not be there. And this is basically how you pronounce this thing. It's called nested sampling with artificial intelligence. And it uses this normalizing flow approach. So normalizing flow basically takes a sample of points, and then you may or may not want to re-normalize it. But basically, it's a transformational approach where you can take these samples, you transform it, and then you map it into a latent space. Latent space. In this latent space, it should be Gaussian, typically a Gaussian. And so the thing about normalizing flows is you can go forwards and backwards with this transformation. And so the idea here is that we want to take a machine learning algorithm to speed up the sampling process for nested sampling, in particular the likelihood calculation part. And so we just asked the machine learning algorithm. Part. And so we just asked the machine learning algorithm, or rather, Michael did, to learn about what the likelihood contours is like. So you explore the contour space, the normalizing flow, maps it. And then every time you want new samples for your nested sampling, you just draw from this machine rather than trying to draw from the calculations, which is slower. And that's basically the principle for Nessie. And we see that actually, so Nessie actually. Actually, so Nessie actually interfaces with Bilby. I think you can actually choose it in Bilby, but I'm not sure if it's mainstream Bilby, but it exists. And if you compare it with Dynasty, which is the standard sampler that most people use, we find that firstly, we need fewer likelihood calculations for the analysis to converge, which means that, well, it should converge faster, and it does, because you see, here's the runtime for Here's the runtime for Nessie, which is about 10 hours in this case to 100 hours. Whereas with Dynasty, it is more than 20 hours or so, typically. So that's nice, and they have this nice paper about it. And we used it, and it actually turns runs that were two weeks down to about a few days, which is very helpful for us. Okay, I am going to finish with this Kilonova. I am going to finish with this Kilernova stuff. The Kilernova stuff I want to mention very quickly because it's something that's fun, and it also uses a bit of machine learning, uses Gaussian process regression. So if we have LSST and LSST, the large, or Vera-Rubin telescope, rather, and it's doing a survey of the sky, and it can observe serendipitously kilonovi. And these kilonovae, if we observe them and we can have multiple points, then we can use them to try and figure out what the merger time was for BNS. And you can say, well, we should be able to observe the BNS. We don't need the merger time information. Well, there could be situations where, for example, we are off-axis, or for example, which is what you would expect for observing a kilonova anyway, or if you have a sort of single-detector, far away observation kind of thing. Far away observation kind of thing. So it could be useful to know, to have somebody else tell us the merger time for these binary neutron stars. Okay, and that's the idea behind this. And just very quickly, because I don't have a lot of time, Lawrence did this. And we find that if you have a binary neutron star merge at 200 megaparsecs, and we observe this with Vera-Rubin telescope, and we actually observe it two days. And we actually observe it two days after the merger, okay? Because Vira Rivin doesn't look at the same sky, every at the same part of the sky every night, it comes back after a few days. And so in this case, it came back, it goes every four days. And so the first observation was two days after, it managed to recover the start time to within one and a half days. So it is possible to use the Kilonova curve observations to trigger gravitational wave searches because Gravitational wave searches because these kinds of time windows, even though it's days and not seconds, is on par with the supernova searches that we're currently doing. So it's something that's quite feasible. And then in the more optimistic case, here actually we observe it two days past, and now we have a much tighter, sorry, here we have an uncertainty that's of plus or minus a day or two, maybe. Here we have an uncertainty that's plus or minus half a day. Okay, and so this is kind of the nice things that we can do. So, this is kind of the nice things that we can do. All right, that's my summary. And basically, we can do, we've shown that with joint observations of GRBs and gravitational waves, we can probe the jet structure. And we may not need actually to detect the short gamma ray burst. We just need an observation. Okay, so it doesn't need to have a burst, we just need to know that something was looking at that part of the sky. And we want to extend our analysis. We want to extend our analysis to include x-rays because x-ray aftergo modeling with our collaborators, we have this paper here, can also help us, for example, narrow the inclination angle or even the jet structure for individual events. So instead of looking at populations, we could actually combine different bands, x-rays, maybe even optical, to see, to try and do a multi-band inference of a single event. Event. And then I just put this here because I wasn't sure how much time we have, and it turns out I don't have enough time. But we also tried this non-parametric Gaussian process jet structure. So instead of assuming some analytic function for your jet structure, we said, well, let the data tell us what the jet function is. It's not straightforward. If you want, you can ask me. I have a couple of slides about this. I think I'll stop there because the Kilonova stuff, I will say that it is interesting, and the Kilonovi. It is interesting, and the Kilonovi uncertainties can tell us something about the merger time and hopefully be useful for trigger searches in the future. Thank you. Cool. Thanks. Okay, so we have some time for questions. I see Michael has one in the chat. Michael, do you want to just turn your mic on and ask it? Sure. Sure. Hi, Xiong. Great luck. So I think I'd like to understand from your perspective how this sort of GW sub-threshold sub-threshold stuff would support actually identifying the kilonovae in the LERD stream, right? I mean, we've seen a number of talks and people have said over and over again, one of the main problems is not being able to fit kilonovae to models. That's fine, but the, you know, differentiating them from the Differentiating them from the various other things in the alert stream, especially you're talking at the sort of the edge of the localization volume, right? So, how do you envision this improving what is otherwise a very, very difficult problem? This is a good question, and actually, we haven't considered this. One would hope that we could potentially supply a sub-threshold trigger rate that is low enough. Rate that is low enough that it could help eliminate large portions of the sky or large portions of time. And maybe that can help reduce the false alarm rate. I'm just flapping here because I really haven't thought about this. But if we think, well, I mean, if we combine the observations from Veri-Rubin and let's say a rate of triggers from Say a rate of triggers from substratal triggers from the gravitational waves, we could give them a substructural rate that maybe helps them pinpoint to times that could help identify these things so that the act of sifting through the contaminants might be easier. Maybe that's just a thought. Yeah, I mean, I could, I think I understand the, I mean, the benefit of the I mean, the benefit of the gravitation, like the non-sub-threshold events, seems clear to me, right? Because the localization really does cut down the amount of sky you're looking at, right? However, for these sub-threshold events where the localizations will be very poor, of course, then you are just sort of talking about this T naughts. But due to Ruben's cadence, the T naughts will be very poorly constrained, right? And so it's kind of a it's a very, it seems like a very difficult problem, let's say. Yeah. Yeah, I don't. Yeah, no, you're right. This is a difficult problem. Maybe we should talk offline about this because it sounds quite interesting. Yeah. Okay. Do we have any questions here in the audience? There was one question from the pin now. Oh, okay. You can turn your microphone on and ask it. Hi, great talk. Again, I was wondering that. wondering that for the for the so I had two two questions firstly for the for the GRB case have you taken because you know you get this result where the opening angle is is is more than what traditionally had been reported I was wondering if the distance inclination degeneracy in the gravitational waves themselves you know gives a selection effect because you know in for gravitational waves For gravitational waves, it's a known result that we have a tendency to see inclinations which are around 30 degrees. And this is irrespective of the detector era or how many detectors are participating and such. So I was wondering if this has a selection effect and if you have undone that or maybe accounted for it in some other way. Yeah, that no, that's a good point. Yeah, no, that's a good point. The short answer is that I hope this was taken into account when we estimate the rates of the BNS. And I think it should be, right? Because we take into account the antenna patterns and we take into account all that kind of stuff in our simulations and so on. So I think that has been taken into account. However, we've not thought about this very much. The thing that seems to affect the opening angle result most actually is, well, from the 10%. Actually, is well from the test that we've seen is the assumptions about the luminosity distribution of the GRBs. And there are varying proposals in the literature that give quite different results for the opening angles, which is why we chose this agnostic approach. And we want to ask the authors of these other papers why did they do these other things. But I mean, different people have maybe slightly different motivations. But for the moment, we not. But for the moment, we have not actually thought about this degeneracy, and maybe we need to study this a bit more. It's worth testing for sure. Thank you. Yep. Yeah. The other question I had was, so regarding this Kiranova case, when you simulate these Kiranova light curves and assume a specific cadence, how do you do that? Do you do, so for example, the Kiranova, the So, for example, the Kiranova, the uncertainties in fluxes, do you take into account, say, the detection efficiencies of Rubin, or is it mostly some kind of... I was wondering about that. And let me just, you know, just, there was another follow-up. So the way you have proposed it, so this is like a blind search for Kilonove that, so are you pitching it as a search or as a parameter estimate? A parameter estimate because this seems like a parameter estimation to estimate the peak. And there are other peak fitting algorithms, like a Bayesian fit, which is generically used in this kind of photometric classification algorithms previously. So I'm wondering how this would compare, compared to something like that. Maybe it's more simpler. No, no, yes, I understand. So here, No, no, yes, I understand. So, here, yeah, well, so we chose Bayesian because that's what we know how to do, and so we went with it, and we just did it for parameter estimation. But the parameter that we wanted was the T0, so what we would call the coin as the merger time. To answer your first part of that question, there was uncertainty associated with it, and that is taken from the LSS. From the LSST webpage. They have that thing about the five-sigma detection threshold kind of thing. And that's worked into here. But whether this is, I guess, a bit like parameter estimation. To estimate T0, we also need to estimate all the other parameters associated with the model. And so we just show everything. But the predominant thing we show here, we want here actually. We want here actually is T0. But as Michael points out rightly, what we've done is we've already assumed that we know that we're looking at the kilonova curve, right? Whereas if we don't know which one is actually the kilonova, it's going to be very hard to determine which one it actually is. Right, exactly. So the search has to be done first, and only once you know that this is a kilonova, then this method is what you're proposing. Yeah. Okay. Thank you. Yeah. Thank you. Yeah. And Michael has a comment that we should use the math, and I think he's right. But from looking at the math, I forget what it's called now, what it stands for, but the math needs some sort of math engineer to run it. And we are not expert enough. So maybe we just need to talk to somebody like you. I mean, we're doing these Kilonova cadence optimizations using the math, right? So we have these suites of Kilonova models, and we're recovering for the various. Nova models, and we're recovering for the various Rubin cadences the appropriate, you know, the detection fractions, where detection is mostly defined as, you know, can we identify these objects as being fast-fading enough to be, you know, plausible kilonovi? I mean, you also have, you know, all the contaminants, but I think there's a lot of work going on to try to improve upon what's been done now. So I really think plugging into that work would be the way to make real progress here. Okay. Thanks. Okay. Thanks. Okay. So I think we should probably move on. So let's. Oh, yes. Go ahead. Just a quick question, Sean. This is very nice work. Have you thought, since you have all the base factor machinery, to test if there are two different populations of GRBs instead that. Instead, that just one overall profile. I know that it's adding one extra parameter at least, but would be yeah, I think we can do that. So, I mean, the way to do it is to... So firstly, let me just show you. This is the luminosity function that we use. And this is not to say that there are two different populations. This is the extrema of the priors, of the parameters that we've chosen. So it can vary from this dotted line. It can vary from this dotted line to this solid line here. So, this is kind of the space that we're covering: about 10 to the minus 49 ergs to about 10 to the 54 ergs each. We can choose not to do this, and we could choose, and actually, Fergus has done a profile that is more on this side, and another profile that's more on this side. What Fergus has not done, which is actually now that you mentioned it, an interesting suggestion, is to calculate the base factor of one versus the other. To calculate the base factor of one versus the other. So maybe that he can, he can suggest that to him. So that's a good suggestion. Thank you. Okay, so let's thank Siong again. 