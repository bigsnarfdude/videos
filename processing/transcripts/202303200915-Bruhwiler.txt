I would say that there is a lot of air quality work going on in NOAA, and we do collaborate with the air quality people in some of the other labs and try to cooperate on data simulation issues. I'm mainly going to be talking about the climate side of things today, which is my expertise and what we do in my lab. Okay. So here's what we're here to talk about today. This is a schematic for a Schematic for a data simulation flux inversion modeling system. I get to be the first person to show the cost function, which I'm very happy about. There it is, right up there at the top at the center. And the basic idea, as we're probably all aware, is we combine our best prior understanding of emissions of something, in this case CO2, along with the transport model. We make predictions, then we bring in the observations, we systematically compare, and we adjust. And we adjust whatever it is we're trying to estimate in order to obtain optimal agreement with the observations. What we get is either analyses or estimated fluxes. And you can do these in different orders. You can calculate the analyses first and then derive the emissions or do the emissions first and then reconstruct the atmospheric state. And we're going to hear about various approaches to that this week. And let me just say that I'm really looking forward to what I'm going to learn from you all this week. I've been looking forward to this work. All this week. I've been looking forward to this workshop for a long time. Anyways, back to this. You know, this is very similar to a weather prediction problem with one or a couple of major exceptions. One exception is that the weather people usually don't try to estimate the forcings, which are the fluxes in our case. We're trying to do that, and that creates complications. Secondly, as Richard mentioned, we're trying to do it with much fewer data, and that creates. And that creates challenges too. In fact, that's why we need to have priors because we right now don't have enough data. So I've been charged with kind of giving an overview and some rationale for why we're interested in this sort of problem, and I want to start with the Earth's energy budget. And what I'm showing you here on the left is radio deforesting, which is the anthropogenic contribution to the Earth's energy budget since pre-industrial times. And what becomes obvious here is that our big problem is CO2. That our big problem is CO2. It contributes most of the radiant to foresting. Its contribution is rapidly increasing over time. On the other hand, the green area, that's methane, which we know is a much more efficient greenhouse gas, but there's less of it in the atmosphere because the emissions are lower and it's destroyed with chemistry. Now, if we want to turn this sort of information into temperature changes since pre-industrial times, we need to use climate and chemistry models. Need to use climate and chemistry models. And this in itself is a rationale for what we're trying to do because if we can use the data to evaluate these climate chemistry models, then we can improve these models and make better projections of what's going to happen to the climate. So the recent IPCC report says that CO2 could have contributed about three-quarters of a degree to the temperature change we've seen so far, methane a half a degree, which seems very much out of proportion. Which seems very much out of proportion with the direct radio divorcing I'm showing you here on the figure. And the reason for that is that CH4, methane, is chemically active. It affects other radiative forcing agents such as ozone and middle atmospheric water vapor, and therefore it can have an outsized effect on temperature. And it is this chemical reactivity that also presents us with an opportunity if we could reduce methane emissions, then maybe we can get sort of an immediate climate pattern. Can get sort of an immediate climate payoff. But the takeaway here, though, is that we should not expect to solve the climate problem by just addressing methane emissions. And likely, there is a lot of attention on methane emissions. The numbers in the parentheses, by the way, are the ranges of the model, which gives you a window into how uncertain things are. The ranges are actually quite large. Now I want to move on to a policy consideration. This complicated diagram is from the GCOS planning document. From the GCOS planning document, and what it describes is the stock take process. Every five years, countries are supposed to assess progress towards their climate goals, and they're supposed to set even more ambitious climate goals for the next five years, and we're coming up on the first stock paint. Now, NOAA is an operational agency, and where do we picture calculations and modeling systems like the ones we're using fitting in? Perhaps in climate services, if we can operationally estimate. If we can operationally estimate the budgets of rated enforcers, maybe we could help inform the stock take. This is a challenging thing to try to do, and among the many complications, we also need to keep track of lateral fluxes, such as transport of carbon to the oceans or movement of agricultural products. So, this is a pretty challenging thing to try to do. Right now, the picture is that the stock tank will be done with inventories. Another policy thing, the global Another policy thing, the Global Methane Pledge, we're supposed to reduce anthropogenic emissions of methane globally, not by country, by 30% below 2020 levels by 2030. And the map here shows the signatories onto the methane pledge. And the thing you should notice is that some major oil and gas producing regions or methane producing high-methane emission regions have not signed the pledge. And so meeting this pledge places a burden on the people. Places of burden on the people that on the countries that have signed. This is a study by Acco et al., which looks at mitigation potential of methane. And the main takeaway from the slide is that most of the reductions have to come from oil and gas. This is what we know how to reduce. It could be economically advantageous and feasible to do it. In this figure, the light-shaded wedges are what is economically feasible, things we can do relatively cheaply and pay. Relatively cheaply and painlessly. Then the next category, the darker shading, is technically feasible. Things we could do, things that are going to cost money and maybe require sacrifices. And the bottom line here is that fossil fuel emissions are the best opportunity for reducing emissions in an economically feasible way. When we talk about microbial emissions, then it's much more difficult. And of course, these are things that we're doing to produce food or dispose of waste. To produce food or dispose of waste, much harder problem. So, what does this mean for those of us doing these kinds of calculations? Well, we cannot meet the methane pledge cuts with the current countries reducing emissions that have signed off to the pledge. We only can cut about half of the fossil fuel emissions, I estimate, with the pledge signatories. So, we will need to consider cutting microbial emissions, and we will need to know what microbial emissions are, and that's where these data centers. And that's where these data assimilation flux inversion modeling systems can be potentially helpful. But it's going to be a difficult problem. You can see in green here that there's a lot of processes humans are doing that contribute to methane emissions, but there's also natural microbial emissions. And it's going to be really hard to distinguish these from using top-down approaches. And then there's the thermogenic component as well, and orange and biomass burning, which is kind of a blend. And biomass burning, which is kind of a blend of stuff people are doing and natural wildfires. So, we can talk more about this methane budget in the future. This one happens to be determined to match the isotopic composition of methane in the atmosphere, so the fossil fuel emissions are a bit higher. But I want to turn to another reason why we do these calculations, and that's because we don't know how the natural carbon cycle is going to respond in the future to climate change. And so we need to be monitoring. And so we need to be monitoring. We need to keep looking at the carbon cycle in the atmosphere. We need to understand whether it's changing, perhaps, in response to either something people are doing or nature itself. Currently, the oceans and the land surface take up, and these are the two shaded regions that show you the uptake of carbon from oceans and land ecosystems. This is what accumulates in the atmosphere. Currently, oceans and land take up about half of what we emit. About half of what we emit. Here's what we emit up here above zero: land use change and emissions. Will this continue? We don't know. Climate models that have coupled carbon cycles are predicting what's going to happen out in the future, but how do we know how good these models are? Indeed, our data simulation modeling systems can help us with this. Then there's methane climate feedbacks, especially in the Arctic. We know that the Arctic partners. In the Arctic, we know that the Arctic permafrost has four times the amount of carbon we've already emitted. The Arctic permafrost is thawing, and some studies project that Arctic emissions could double over this century and then accelerate over the next century. So far, when we look at our observations, we don't see evidence of large changes. However, I'm starting to hear of papers that are in the works that may start to claim that we are seeing the first suggestions of increased methane emissions. Methane emissions. And then there's tropical wetlands. We don't really know much about tropical wetlands. We don't know where all of the methane regions are. We don't know how humans are changing these environments. We don't know if they're drying up or expanding or perhaps both. So these are big questions in terms of methane feedbacks. And now I want to turn our attention to the measurements we have available. This is what my lab does. We operate the NOAA air sample. NOAA air sampling network. The blue symbols are either continuous or air sampling measurements. The pictures here show you the various ways we have of collecting air samples. Most recently, we've started to fly samplers on balloons so we can get up into the stratosphere. And then there's other organizations, other countries, ECC, ECCC, for example, has a network, the Europeans have a network, Brazilians. So there are other networks. So, there are other networks. There's a problem because the data is not always shared in a timely fashion. And so, this affects our ability to reproduce other people's calculations. And that's an important scientific principle. Can we reproduce results? You cannot using these modeling systems with in-situ data only if you can't use all the data. So, data sharing is really important there. Here's what our measurements show. These are important measurements because a lot of what Important measurements because a lot of what we know about the atmospheric budgets of these radiated forcer has come from these measurements so far. Here's the iconic Mauna Loa time series. You can see the relentless rise in CO2 at Mauna Loa, which reflects the global background. You can see sometimes the growth slows down a little bit. This is probably related mostly to economic activity. The methane curve looks different. It's very interesting. And I like to point this out because you can see that it was rising for a long time. Was rising for a long time, it leveled off, and now, ever since about 2006, it's been climbing again. And this growth is accelerating, and we don't understand this completely. Now, the reason the methane curve can look like this is because of chemistry, and so we believe that this sort of plateau is, in fact, a time when sources and sinks came into some sort of temporary quasi-equilibrium. I started working on methane towards the end of this plateau, and I remember my colleagues were talking about how we don't need. My colleagues were talking about how we don't need to worry about methane anymore because it wasn't increasing. And surprise, surprise, now we really have a problem. But we can get insights into what drives changes in the methane growth rate if we sometimes look at other species. For example, the isotopic composition of methane in the atmosphere. When methane started to rise in the mid-2000s, the atmosphere started to get lighter. And in these crazy isotope units, Crazy isotope units, more negative is lighter. And the reason for this is: you know, probably microbial emissions are increasing, and microbes like to use the lighter carbon. All life likes to use light carbon. It likes to ignore the heavier carbon if it can. So, this is a big tip-off that microbial emissions are probably playing a major role in this increase. And indeed, when we use the isotopes in atmospheric The isotopes in atmospheric inversions, we find that about 80% of the growth is microbial. Another thing we have learned from using the isotopes is that fossil fuel emissions are likely higher than what the inventories say. But there are important uncertainties, and hopefully I won't run out of time so that I can get into this because I think it's pretty interesting. There's other species we can use as constraints. Ethane can teach us about boiling gas, radiocarbon can teach us about fossil fuels, and methyl chloroform is. Fuels and methyl chlorophore is a manufactured gas which has long been used to estimate the abundance of OH, which is the dominant zinc, but not that in the atmosphere. So, we also these days have satellite measurements, and I like this figure from Paul Palmer, and it shows you the relative density of observational information. So, here we have the network, and you can see it's very sparse. Some regions of the world are barely observed at all. And some of these samples, importantly, are weekly samples. Weekly samples. Some are continuous, like hourly or daily, but many of these are just weekly samples. Now, if you start considering the satellite data, and here we're showing GOSAT and Tropomia, you see you start filling in the information. GOSAT has some ocean blint observations that are included here. And if you look at monthly, you can see you really get a lot of information, especially for tropomy, which has high spatial resolution. So in situ measurements and satellite. In situ measurements and satellite measurements are complementary. Satellite retrievals give us high spatial temporal resolution, but lower precision, and there are possible biases that we need to understand. The in situ data has low spatial temporal resolution, but it's high precision. You get points in the Arctic, and there's high surface sensitivity, whereas for satellites, you're dealing with column averages, which reduces the information about stuff going on under the surface. We also have nowadays. We also have nowadays the source imagers, and this is the Canadian GHG set. It's a private venture, and here you see emissions from actually a facility. And if you know something about the meteorology, the structure of the atmosphere, the planetary boundary layer, how you go in and so forth, you can turn this into emissions. This is great for spotting leaks. It might be a way that we can really get a handle on oil and gas emissions. I really, at the current time, don't know how to make. Really, at the current time, we don't know how to make use of this in our inversion systems. Perhaps we could use it to improve priors, or perhaps we should revise a cost function to include that kind of data. I think that's a research question. So now I want to talk about one of the things I've been interested in recently, and that is uncertainty. Uncertainty is the other half of the answer, and yet many of us ignore it. We don't estimate the uncertainty as part of our data assimilation techniques because perhaps we're using a 40. Because perhaps we're using a 4D bar system, although Cousser√© has developed a way to actually estimate uncertainty. Or perhaps we say we don't believe that it reflects the real uncertainty. I like to think of uncertainty in two categories, and maybe some of you mathematicians have better jargon for this, but I think of internal uncertainty. That's what we estimate along with our mean values of our parameters. We get a posterior covariance matrix. This is what I think of as internal. This is what I think of as internal uncertainty. And then there's external uncertainty. And this is really interesting because these are things we don't know very well, like how good our transport model is or what the fractionation factor for the OH reaction should be. So we can either try to estimate these things, but of course we don't have that much data, so do we really want to, or we can use an ensemble approach or do model sensitivity experiments to get a handle on these types of uncertainties. These types of uncertainties. So, here's an example from my old carbon tracker release. We are updating these results through 2021. That should be ready by May in time for our annual meeting. But this is from my old carbon tracker results. And the red and the red shaded region is the prior and the prior uncertainty that I use, whereas the blue is the posterior mean, and the shading is the blue posterior one sigma uncertainty. And what do you see here? Okay, the posterior. And what do you see here? Okay, the posterior mean estimate is higher than the prior. The estimates are retrieving some inter-annual variation, which is really interesting. And the estimated posterior uncertainty is reduced compared to the prior. Should we interpret this as our true uncertainty on these parameters? Absolutely not. But it is important information because we are learning what the observations taught us. And I think too often this kind of thing is ignored. Especially if we're going to produce country emission doubles, we really need to give an idea of whether our results are different from the priors. And a lot of times I don't see this happening. But this is one case where it did happen. This is the OCO2 myth, and I'm showing you what I like very much, which is something that has been weighted by agreement with withheld data. At least that's what I understand. But Brad, maybe you can correct me on that. I'm not involved in the OCO two method, but I like very much what they're doing here. I like very much what they're doing here. They're showing you what the prior is, and since this is an ensemble of bubbles run by different people, there's a range of priors people are using. That's the black. It gives you an indication of how the priors differ. And then on the right here is an average result. I happen to pick one of them, which I've heard performs the best. And you can compare these two figures to see how the observations have informed and changed the prior. You can also see that different models. You know, different models, that this is the model range. It is not the internal uncertainty, but it's giving you a window into transport differences, differences arising from how uncertainties were defined going into the calculation, and also different choices of parameters. So now my phone has gone to sleep, so I have no idea. Okay, good. I'm good on time. Great. Okay, so I like this very much. There's a whole Very much. There's a whole lot of information in here. One could download this data and really do some analysis and learn some things. This is good. And I'm showing Canada because I like Canada and that's where we are too. But now I want to talk about, I want to get into some details about what I call external uncertainties associated with using isotopes in methane flux inversions. There's a lot of problems. First of all, we don't really know what the source signatures are. We don't really know what the source signatures of the emissions are. So, you know, what is the isotopic composition of what cows are birthing up, for example? That's what I mean by a source signature. And we don't know their spatial variability really well. But we think we have a way of getting around this particular problem because for oil and gas, we have a large database of source signatures. And we know that most of the oil and gas is emitted in a very narrow range in source signature space. And so we hope. Signature space. And so we hope we can narrow the source signature uncertainty for fossil fuels, and therefore we can use isotopes to separate the heavier thermogenic or fossil fuel emissions from the microbial emissions. And I'm happy to discuss this more because this is an aspect of using isotopes that has been often criticized. So I can discuss that more if people have questions. But there are other problems. First of all, we don't really have very good ideas of Don't really have very good ideas of where the wetlands are. We either have surface inundation from satellites, and that's not necessarily wetlands because if the water is deep, that methane doesn't make it to the atmosphere. What we really want to know is where are all the saturated soil environments and the shallow waters, and that's something that's more difficult to see from space. And overlying vegetation, that's another complication. So, wetlands are a significant problem for methane invergence. Another thing, the atmospheric counter. Another thing, the atmospheric chemistry fractionates. Just like life, OH and CL like to use the lighter isotope. That goes a little bit faster than the heavier isotope. And we also need to know the distributions of these things. Both of these things, OH and chlorine, they're really, you can't measure these and characterize their global distributions. We have to use models. Maybe we adjust the models by observations of something like methyl chlorophore. But it's very difficult to characterize. But it's very difficult to characterize these things and their spatial temporal distributions. And chlorine itself, it's a really small part of the methane destruction term, but it matters a lot for the isotopes because reaction with chlorine is heavily fractionated. And this is a big problem. Right now there's debate in the community over whether this is the tropospheric chlorine really is coming from sea salt or whether it's coming from pollution. It's coming from pollution and the precursors that people emit. So we don't even really know that much about chlorine. Next, we need to know the fractionation factors, which are, you know, how much faster is the 12C reaction compared to the 13C reaction. That's the fractionation factor. There are two measurements of this thing for OH, and they're very different numbers. Their uncertainties don't even overlap. How do we know which one is right? Do we know which one is right? So, what I would like to propose is that we come up, just like the OCO2 people use log likelihood approach using withheld observations, we can come up maybe with observational metrics that give us insight into whether we're making good choices for some of these parameters. Now, these spaghetti plots, I will walk you through them, but for the top two, I'm using Top to, I'm using the high-latitude annual cycle as an observational metric that I'm going to use a posteriori to assess whether some of the choices I've made in the inversion are actually more successful than others. So to summarize for you, the blue and the red lines are using an inundation-based wetland data set, and the pink and the blue are using Elaine Matthews' old. Using Elaine Matthews' old inventory of wetlands from the 1990s. We've been using this thing for years and years. And the question is: can we tell whether one of these wetland distribution approaches matches the data better than another one? And it's pretty clear to me that in terms of 13CH4, you match the seasonal cycle a little bit better if you use the old static wetland distribution than if you use the inundation. Than if you use the inundation-based product, but neither of them are entirely successful, and this is sort of a reflection of the problem we're faced with when it comes to wetland distributions, even in the northern hemisphere, which is fairly well observed. Now, what about the fractionation factor? I told you we have a problem with that, too, because there's two numbers. They differ quite a bit. Can we tell whether one number is likely to be more successful than another? And the black line, I think I forgot to mention, is the opposite. Black line, I think I forgot to mention, is the observations, and the colored lines are all different versions. And so, you know, in the deep southern hemisphere, you're pretty far away from any methane-significant global sources. What you're seeing is transport of northern hemisphere emissions to the southern hemisphere along with chemical reactions along the way. So, this seems like an ideal place to evaluate whether one fractionation factor maybe works better than another. Factor maybe works better than another one. And indeed, we find if we use the Cantrell OH fractionation factor, we get a better fit to the average seasonal cycle than if we use the newer Saurosic number. So, you know, I guess this is an example. There are other factors that maybe could change these results. But I think coming up with observational metrics in order to evaluate our posterior results might be one way. Results might be one way of handling external uncertainty. Here's another thing we can do: we can look at the north-south gradient of isotopic methane, and you know, you just cannot match this thing. It's really frustrating. The problem is a combination of wetlands and lack of knowledge about chemistry. But what you can do is run a bunch of sensitivity studies and see what gets you closer. It turns out that just like I was showing for the seasonal cycle, I was showing for the seasonal cycles. If you use the Cantrell fractionation factor and the static wetland distribution, you get closer, but it's still not very satisfying. Using isotopes is a very difficult problem. Among the many problems that I haven't mentioned is that it is also nonlinear. In order to reconstruct the posterior isotope abundance, you have to use your estimated methane state. Methane state. And so if there are errors in that, those propagate into the isotopes as well. It's a pretty challenging problem. But what we really want to know in the end from the isotopes is how are methane emissions divided into fossil and microbial components? So this is our base inversion, the one we will make a website out of pretty soon. And you can see that we get a partitioning that looks like this. By the way, these little notch lines are where I've tried to use the boost. Lines or where I've tried to use the Blusseraire approach to estimating the uncertainty, and since this is a TM, this is a 4D bar system. That means doing 100 inversions, constructing an ensemble, and then making your posterior covariance matrix. And I think that these uncertainties are suspiciously small. I'm worried that our ensemble does not actually represent the true variance that we have, and that's why I'm really looking forward to. Have, and that's why I'm really looking forward to Shay's talk later on. And so now back to the partitioning. You know, if you only use the methane observations and you do not use the isotopes, you get smaller fossil fuel emissions, larger microbial emissions. But then, if you apply, if you use the 13 CH4 measurements and the alternate OH fraction emissions, by which I mean the Cantrell number, you get something that once again looks like You get something that once again looks like you only use the methane alterations. The bottom line is that this partitioning is very sensitive to some of these external uncertainties, but yet this is something we really want to know. Also, there are some caveats. If tropospheric chlorine is different from what we've assumed in this calculation, then the fossil emissions will once again be higher and microbial emissions lower. That moves us towards this solution again. Towards this solution again. And also, the wetland prior can affect the partitioning, especially in this calculation where we've only used the in situ data, which is very sparse. And by the way, this is the one that I'm saying agrees best with the observational metrics. And this is the one we're currently, I said we're going to release this one, it's actually this one, and we're currently working on calculating the uncertainties for this. So my last topic is my pet product. My last topic is my pet project, which is to use the NOAA forecast model, the NOAA unified forecast system, driven with a reanalysis of this model to build a new data simulation system. And the reason why I want to do this is because I want to know whether, if we increase the spatial resolution and the temporal resolution of the model, can we get better simulations of the greenhouse gas observation? And furthermore, GAS observation. And furthermore, the GEFS reanalysis has an ensemble of 80 members. And I think we could use something like ranked histogram approaches to estimate the model data mismatch error. Also, I'd like to hook into the data simulation tools that come with the UFS to estimate the state of CO2 and methane and perhaps do the fluxes as a second step and maybe iterate. That's going to be computationally very expensive. I don't know if I'm going to. Computationally very expensive. I don't know if I'll be able to do that, but we'll see. And then another thing I'm interested in is what happens if we include a detailed land surface model that also treats carbon in one of these prediction models. Does that have an effect on our ability to predict seasonal forecasts? Unfortunately, this is another tough problem. The model does conserve total dry air mass. It was constructed to do that. I verified that. To do that, I verified that. However, the physics package that has been adopted for this model does not conserve mass. And here's an experiment I did where I had a constant CO2 field, and you can see that that constant CO2 field was not preserved. Instead, gradients developed. These gradients happen because physics doesn't conserve mass. Instead, zero concentrations of invective moisture variables are set to zero. That doesn't conserve mass. Total trace. Mass, total tracer tendencies and conductive schemes are not kept track of because the weather people are only interested in precip and so forth. So right now, me and some of my collaborators on the effort to try to use the UFS for air quality and greenhouse gas data simulation, we're working on trying to get people to fix these problems. And I don't know if that's going to happen during my career. So now, two more slides. I just want to Now, two more slides. I just want to make some editorial comments. You know, when you think about the weather data simulation system, we have so many ways to collect observations. We have so much data. We have many types of satellite data. We have aircraft, commercial aircraft. We have automatic weather stations, 10,000 of them, including in places where it would be very difficult to collect greenhouse gas measurements. Countries share their data because Share their data because it's everybody's benefit to collect this data and use it to make good weather forecasts. It's a life and property issue. To me, climate and greenhouse gases are also a life and property issue, but with a longer time scale. And we need to move towards an approach like we have for weather. And the WMO is starting to talk about this. There was a meeting recently about this. I was not at it, but Brad was, and I'm sure he could. Brad was, and I'm sure he could talk about that. And we need to share data, and we need to help developing nations set up monitoring stations so that we have data from those places too. The problem is that the measurements we make are labor-intensive and they're expensive compared to what we keep track of in the weather. And then my last slide is sort of an aspirational slide. You know, what if we actually included details? Actually, included detailed land surface models that include things like the carbon cycle into our prediction systems. Because the biosphere matters. Here's an example. This square indicates the Amazon basin. This is a really complicated figure. What you're seeing here is 850 hectopascal winds, relative humidity on the left column. On the right column, you're seeing deuterium isotopes of water, which tell you. Isotopes of water, which tells you something about whether the water in the region has come from the oceans or whether it's come from the biosphere and also the moisture flux convergence. So it's a pretty complicated figure. But the takeaway is that the rainy season actually starts earlier than you would think, just considering the movement of the ITCZ, two to three months earlier. Why does this happen? It happens because the biosphere exists. Biosphere exists. In the late dry season, trees are able to access water in the soils, pump that into the atmosphere, that initiates convection. And once that convection starts, then moisture transport from the oceans happens. And so, you know, the biosphere is really preconditioning the rainy season, making it come earlier. What if we were able to incorporate this kind of thing into our prediction models? We might be able to improve seasonal. Models, we might be able to improve seasonal predictions. And in my mind, the more detailed terrestrial models must also include a treatment of the carbon cycle because water and carbon fluxes are intrinsically linked. And that is my last slide. So that's it. So I understand that people also remotely can ask questions. Also, remotely can ask questions. We're supposed to hear them and they speak out. Is there any questions for now? Just a few. Yeah. Well, why do you consider seal to animation? Do you consider some loss in the production while in the air or everything is out to the surface? For the methane system, we have a parameterized loss. Parameterized loss. So we have a climatological seasonal cycle of OH chlorine, and we calculate the reaction rate as it changes with temperature and things like that. And so it's kind of semi-online. But we only have that repeating seasonal cycle of OH. And there's a lot of debate over what the hydroxyl radical is doing over time. If you use methyl chloroform, you get a lot of variability, and you get transformation. You get a lot of variability and you get trends. If you look at the troposphere of chemistry models, you get a slow but steady increase in OH over time. So that's a science issue. I'm really looking forward to the talks later on chemical data simulation because I think maybe we can get OH from that. That would be great. And now for CO2, that's all surface. We don't inject emissions at the current time. Like, so suppose you have. Time, like so. Suppose you have pyro convection, you know, you have a fire. Those emissions are still going in at the surface, but one of the things we can do with the UFS model is use the plume rise calculations, and some regional models have this as well. We should do that. We haven't done it yet. Does that answer your question? Yeah. Can I have a question? Of course. For the copy tracker, I could use an introduce model and use the observation. The model we're using right now is a chemical transport model called Tracer Model 5, which is a European product driven by ERA interim and now ERA 5. And at NOAA, we're supposed to use NOAA products, and that is another reason why I want to move to the UFS, actually. So, by static, operational means you have control over the whole chain of stuff, including the transport model, and you know. Including the transport model, and you know, we actually are dependent on our European colleagues to get the transport, so we have to change that. Hopefully, the scientific reasons overshadow that reason. You know, if the UFS isn't a good model, we certainly don't want to give up what we have now. So, yeah, I know, but we need to move on. And one more question, perhaps, a short one. Question: Perhaps a short one? Yes, go ahead. So, when you talk about uncertainty partition, do you mean the uncertainty apportionment? Like, you get a total uncertainty, but you are trying to figure out which one source comes with the most uncertainty? Well, you could get that information from the posterior covariance matrix. But what I was trying to talk about was the fact that, you know, we. The fact that we can get an estimate of the posterior covariance matrix, but there are things we don't estimate, which I refer to as external uncertainties. And we need to know how sensitive our results are to those things. And, you know, the ensemble approach is one way to do that. So maybe I used the wrong term. I'm not as much of a mathematician as probably some people in this room are. So maybe you can educate me on the topic. That's what we call a model error for your textbook, right? For example, right? Right, well, so model error, yes. Yes, and so something that you don't, the real model error, not the model error you believe. Yes, and so, you know, you'll remember early on when we were doing inversions, we referred to what we now call in my field the model data mismatch error. We used to call that the observation error, and that really wrangled the observation people. So, okay, there might be some terminology differences. Some terminology. Well, maybe that's the topic we should address and represent. Yeah. Oh, that's it. Okay. Okay.