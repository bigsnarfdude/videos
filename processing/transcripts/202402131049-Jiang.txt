Okay, so I'm going to talk about the online estimation of the Pung Tao and also the inference under the local differential privacy guarantee. So this is a framework with our graduate students and also a colleague who just left. So Hong Tu gave the presentation on Quantile regression and the motivated why we're studying quantiles of We're studying quantiles oftentimes instead of just the median or the center, because, for example, median, everybody agrees that median is a better or robust estimation of the center of the distribution because it's mainly due to its robustness. And then often, also oftentimes, we are interested in different parts of the distribution inside of the center. So, here we're studying the quantile using SGD and then the main motivation for The main motivation for looking at stochastic gradient design is because data oftentimes arrives sequentially, and then also oftentimes we don't have the storage space to store all the data. So, SDG is naturally because the way it estimates things, then it's a very natural approach. So, we just update the estimate whenever the data come. And then we also know there are recent data stats studying. There are recent papers that study the convergence properties of ICD and also the asymptotics, but we don't fully understand how we can repeat everything when we have the privacy concern. So in this particular paper, we're looking at local differential privacy. So probably I should wait until Dr. Shen give the tutorial on privacy to give the talk. Anyway, so we are looking at local differential privacy for those of Local different virtual privacy for those of you who have the background of different virtual privacy. So, the original different virtual privacy actually deal with this situation where all the users actually trust a curator. So, they upload the data to this curator, but then before we release any information based on the data to the public, there's a concern of privacy leak. So, for that reason, we virtual privacy come in the picture to protect the information. Protect the information of the users. But here we have a different scenario where there's no trustworthy curator, meaning that the users are not comfortable transmitting their data to the curator without any privacy protection. So we actually impose this. So we have to apply some kind of privacy of the individual level data before we can do any kind of statistics before releasing to the public. Listening to the public. So, for that reason, we are looking at this local differential privacy paradigm. And then we, as the title implies, that we're doing an online version of the online estimation of the quantiles and also statistical inference using SGD algorithm under the local differential privacy guarantee. So, we propose a consistent estimator and then we An estimator, and then we construct a confidence model for this consistent estimator. So that's what this is what our contributions in this talk. So this is just a quick refresh of the memory, what the quantiles are. So for example, if we are interested in the toss quantile, the interpretation is this quantile will split the density curve into two parts. And then in this part, the area under the curve is tall, and then on the other side. is tau and then on the other side is one minus tau. So this is what the interpretation of the tau's quantum. And then as Hong Hu mentioned that we can obtain the quantile by solving this minimization problem based on the check loss. And then once we have the data, then we just solve this imputable version of the same loss function. And then that's it. And then given the SGD, there's another version. So we just There's another version, so we just iteratively update the quantile estimates based on previous value and based on also the new data that comes in. So the DNA is just a step aside in this ICG algorithm. So as you can see, if we're using ICGD, it's very natural approach. It's very well suited for data.online data.com sequentially. So every time you have a new data point, we just update. Data point: We just update the estimate accordingly. So you can see the only information that are based on the data is actually this binary chart. So that means if we want to do everything under the differential privacy guarantee, we have to find a way to perturb this binary variable. And then the approach that we use is randomized, random response. Actually, this is a Response actually, this is a privacy protection technique proposed by a statistician back in 1970. But people realized actually random response is a way to actually make the data perturbed data differentially private. So I don't have time to dig into the detail, but this is a summary of our algorithm. So again. Yeah, so like I said, the only term this in this whole algorithm is this binary term that means the protection. So that means before actually transmitting the individual data point to our SGD algorithm, we have to protect this binary term. So the approach we use is randomized algorithm. So instead of releasing the true value, Releasing the true value, we are drawing a random sample. So basically, there's a certain probability that the user will give you the truth or the opposite. And then we choose, so this R basically determined what's the probability that the user will tell you the truth, the truth about whether his value is indeed greater than the current estimate of the quantum or not. And then we choose this particular. we choose this particular value R here based on the ISO the differential privacy criteria that you do choose. For example, if you want to repulse ISO BP, if some DP, then accordingly, we have to choose, we have to solve this equation and then obtain a value model. So there's a closed forming expression in here. And then once we take care of that step, then the whole SGD process can be run smoothly. Process can be run smoothly. But there's also one thing we need to be careful about. Even though everybody is saying that you add noise, that inflates the variation. But it turns out there's a bias involved as well. So we have to correct for that bias in order to obtain the consistent isometer. So this part of the algorithm is actually doing that kind of bias correction. So then we can obtain the consistent isometer. And then also during this whole particular And also during this whole procedure, we have to see some of the values for later because this is used in the construction of the confidence interval. So, like I mentioned, there are recent papers that study the asymptotics of estimator based on SGD. So, for example, if we are using that approach to estimate to construct a confidence interval, so this is the tau's quantile and this is true, then we actually know how to do that. So, this is not the unsolved. To do that, so this is not an unsolved problem. But the issue here is that if you look at this term, this is the so fx here is the density, is the Q density. So we have to estimate, worry about how to protect this term. So in the differential privacy paradigm, so everything, if you want to use any value that are derived from the user's data, you have to kind of perturb it so that this is diversional private. So this is something that. So, this is something that bothers us for a long time. So, for example, naively, you can find a way to isolate this term private. But it turns out this is an even more challenging task than isolating the quantile. Or in other words, if you know how to isolate this private, then why bother doing the quantile, the DP version of the quantile. So, this route doesn't work. And then we found out there's a way actually, so this is not future. So, this is not Jun Shao, but Xiao Feng Shao 2010 just a JRC paper that talks about how to do the construct the standard error for estimator using the self-normalization technique. So, for example, the most familiar T statistic is actually a self-normalization process. So, you have a normal in the numerator and then square root of chi-squared in the denominator. square root of chi-squared in the denominator so that this n the new instance parameter sigma is cancelled so a similar uh strategy that allows us actually to construct a confidence interval so um there's some technical but we can get rid of so the short answer is we can get rid of this term and due to the time constraint i'm not going to go through all the details but eventually we are able to actually signal Actually, simulate samples from this running motion and then numerically construct the confidence interval. So, the formula is given here. So, you can see this is why we actually save some of the values through this SGD process because we do use that. So, the constructing is also very straightforward. So, we just, so, this is the estimated value from the ISPD. Value from the ICPT algorithm, and then we just add some additional terms. So that becomes our lower bound, upper bound of the confidence interval, because this is still based on the wall type of confidence interval. Okay, so this is some new work results. Here we're showing the estimation of the median. So this is a Estimation of the median. So, this is the truth. So, the delta value is the truth. And then we have the predicted values. So, this is again the good curves are the differential parade median estimation using our algorithm. And then you can see there are two components intervals. So, the green one are the one using our approach. And then this if we then the red one is the The red one is the invisible one. That's actually the one that one can construct without worrying about privacy protection. So eventually, so when the sum of size is small, of course, naturally the red one, our green one is much wider because we have to take into account the uncertainty introduced due to the DP process. So it's wider, but eventually, once the sample size is Once the sample size is getting large and large, then the two will converge to each other. So basically, we will get the one, even though we take into account this DP process, but eventually they will converge to the one without DP protection. Yeah, that's all for my talk.