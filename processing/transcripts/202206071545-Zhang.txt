So thank you to the organizers for putting together this conference. It's a very exciting panel of talks and I've enjoyed all the talks so far. And I want to share with you the work, some recent work on manifold learning in single cell genomics. And this title is a little different from what is shown in the program. I will be talking about I will be talking about denoising, but mainly I want to talk about how we can use deep learning to separate out three sources of variation in single-cell transcriptomic data. They are extrinsic variation, intrinsic biological variation, and technical noise. And I will define those terms in a bit. So I don't think this audience needs an introduction. Audience needs an introduction to single-cell data, so I will jump right into the details. In single-cell RNA sequencing, we after the appropriate data pre-processing, we get a matrix where each row is a cell and each column is a gene. This is a very high-dimensional matrix. So, say, for example, we look at all the genes in the transcriptome. It's about 20,000, 30,000 columns. Columns and usually we have in experiments we do nowadays, we have thousands, even millions of cells. And usually we would want to visualize this data, cluster into cell types, find trajectories, as has been described in the many talks that preceded this one. And for example, here is one data set that we will look at in a bit. That we will look at in a bit is the aging mouse atlas. And these are cells that are in the bone marrow of the mouse, right? So these are immune cell types. And, you know, what I want to convince you is that this is all manifold learning because this high-dimensional single-cell transcriptomic data is living in a much lower-dimensional manifold. And when we are And when we are doing cell type identification or trajectory reconstruction, what we are learning is properties of this manifold. So here's an outline of what this talk is going to be about. First, I'll present a model. This model gives us a basic decomposition of single-cell RNA sequencing data into three sources of variation. Three sources of variation: extrinsic biological variation, intrinsic biological variation, and technical noise. And then I will show you two example applications of this model. The first is in a very practical technical task of denoising single-cell data. And this has already been published two years, three years ago. But this, I hope, set the stage for the next topic. For the next topic, which is very recent work, which is estimating the intrinsic biological noise and how that relates to cellular aging and cellular response to stress. Okay, so going right into the model, what you observe is on the right-hand side, this is the matrix Y that is cell by gene matrix. Very sparse, very noisy. We assume that. We assume that Y is a sampling of the true RNA population in the cell, which we don't observe, and that we call X. Now, the true transcriptomic variation, we assume to be comprised of shared variations across genes, meaning variations that are correlated across genes of certain pathways, as well as As well as idiosyncratic, unpredictable variations specific to each gene and each cell. Now, those is sometimes thought of as biological noise, and I put noise in quotes because I will show you that they are actually meaningful. So the lambda, which we call the shared variation, is usually what most single-cell analyses are about, right? Are about, right? It's trying to estimate the correlation across genes, correlation across cells, and the geometric structure of this underlying cell population. Okay, and you can imagine since this is a deep learning workshop, we're going to use a deep learning method to try to get at that manifold. Now, the technical noise is also pretty well studied. We're going to use a Poisson model. Going to use a Poisson model where we say that if we knew the x, then y given x is Poisson with a cell-specific size factor, LC, which we assume to have been either known or estimated. And there are methods for doing that. So actually, in the early days of single-cell sequencing, I just want to say that people didn't use Poisson models, they used zero-inflated noise models, but there has been. Noise models. But there has been a series of work starting from the work by Jing Shu in 2018, where we showed that if you have UMI single-cell RNA-seq data, I mean, basically data that is where it's molecular barcoded, then the data, the technical noise is not zero-inflated. That Poisson gives you a pretty good approximation of the true technical noise. Okay, so I talked about lambda. So, I talked about lambda, I talked about why. Now, this, what a lot of this talk is going to be about is the intrinsic biological variation, which means if you have, if you look at the manifold, let's say you know the manifold, where is x in comparison to the manifold? And we have no idea what this distribution is, so we're not going to make distributional assumptions. We're going to assume that x given lambda has mean lambda. Given lambda has mean lambda and a variance that scales with a gene-specific dispersion parameter theta g on lambda. So it's a very simple model. We say that the gene, the idiosyncratic noise is gene-specific with a specific mean variance relationship. Okay, so that's our model. This is a very simple model. It has three parts: lambda, x, and y. Lambda, X, and Y. And it's a hierarchical model, meaning that given X, we have a model for Y, and given Lambda, we have a model for X. Okay, so let's first take a look at how we use this model for transfer learning and denoising. Okay, what is denoising? Okay, this is a very simple concept. So, in single-cell RNA sequencing, we usually get between 1,000 and 8,000 UMIs per cell. UMI meaning molecule. Per cell, you and my meaning molecules, earning molecules, depending on how much you want to spend on the sequencing. And if you have a low coverage experiment, right, then you don't get as much signal in the data. You probably cannot even tease apart the major cell subpopulations. Whereas if you sequence at a high depth, then you can perhaps even look at the fine details of cell subpopulations, subtypes. Subpopulations, subtypes. And our goal in denoising is taking a low-coverage single-cell RNA sequencing data, or a data that, you know, say 5,000 UMI per cell, and then hopefully getting from that the signal that you would get if you were to get have, say, 8,000 UMI per cell. So basically, get from your data signals that you would, you know, you would have gotten with much higher sound. So, how do we do that? Well, this is going to run through the rest of the talk. So, this is a key concept. Remember that our model is hierarchical with the underlying manifold lambda giving rise to the true expression with gene-specific dispersion, and that true expression giving rise to the observed expression with cell-specific size factor. So, what we're going to do is we're going to use the YGC. GC and plug it in a deep learning model to get a lambda hat. Now, that is a prediction for X, but it may not be accurate for all genes. So, what we're going to do is we're going to form an estimate for X, which we call X hat, which is an intermediate value between your prediction, lambda hat, the deep learning-based prediction, and your observed YC. And you observed YCG divided by the cell-specific size factor. So, this is a weighted sum. And this is a typo. It's supposed to be LC, not SC. Okay, so it should be this thing. And then the weights are going to depend on your predictability of the gene, the coverage of the cell, and this gene's mean expression. Okay, so say, for example, in a situation where you have a In a situation where you have a highly predictable gene, so you really trust your lambda, and you have a low-efficiency experiment, meaning you have low coverage, then what you would want to do is to take your observed values and shrink them towards your prediction. You have heavy shrinkage. In the other extreme, is where you have an unpredictable gene and a high coverage experiment, then you're probably going to stay put where at your observed YGC and not. Your observed YGC and not shrink too much. But of course, in most experiments, you're going to be in between those two extremes. So we're going to have a dynamic way using Bayesian shrinkage to adjust to the best level of averaging. Okay, but the problem here is that lambda, right, is not, you know, all this is contingent on you getting a very good estimate of lambda, the manifold. But you might imagine that. But you might imagine that if you have, say, not enough cells, or maybe if you're looking at a rare cell population, where, you know, even though you sequence, say, millions of cells for the population you want, maybe, you know, the rare cell type, you don't have that many, then what are you going to do? Right. So you have a lot of options because now we have a lot of public data, right? There's human cell, there's cell atlases for every tissue of interest. Tissue of interest. For example, if you're looking at brain, right? There's already a million plus brain cells the last time we checked out there, right? Lots of groups have published cell data sets with many cells sequence for the brain, for blood as well, right? For kidney, right? For almost every tissue, right? You have an accumulation of public data. And also there's the mouse cell atlas, right, where there's, you know. Right, where there's the different mouse, these different disease models and treated with different drugs that you can harness, right? So the question then is, how are we going to harness all this data? Which was one of the original motivations that we went on to look at deep learning, because with a deep neural net, it is so easy to do transfer learning, right? So, okay, so I'm just going to show you the since this is for deep learning workshops, I need to have a Deep learning workshops. I need to have a neural net in here somewhere. So here is the neural net we used to estimate lambda. And then we played around with multi-species data as well. So we have mouse cells and human cells. And if you have human cells, then you use these input layers with the homologous genes and human-specific genes. And then if you have a mouse cell, then you will use the pink and blue layer, which is the Which is the mouse-specific genes. And then you will plug in this Y on this side, it will go through the neural net, and then you will get back the lambda hat. Okay, and then so you will train this using the gene level that the model that I described for you. Okay, and then you're going to use that lambda to form your X hat. Okay, so the way that we make use of public data is very simple. Is very simple. It's a very commonly used transfer learning paradigm, which is you use the large public data sets to pre-train your network to get a prior initialization of the weights. And then starting from that initialization, you're going to train more on your target data and then update your weights again so that you can get better fit to your target data. Okay, this is all pretty standard. There are a few key details in here that Few key details in here that made it work for us. First, we performed cross-validation, meaning that we don't assume every gene is well fit by auto-encoder. There are some genes that are just poorly fit, even compared to just using the mean of the gene. So then we will just replace the predictions by the target data mean. Okay, that's one thing. The other thing is that, you know, like I described to you, we use empirical-based shrinkage, meaning that we don't just directly use the last layer of the output. Use the last layer of the autoencoder, we used a weighted mean between that layer and the original input layer. And that tends to give us better predictions for the true gene expression. Okay, so you know, one question is how much can we learn from data generated from other sources, especially, you know, data from different species? So I'm just going to quickly go over some example studies. Here is one where we use public data of 900 blood cells. 900 blood cells. And then we see how training in the 500,000 immune cells in the human cell atlas can help us in denoising those 900 blood cells. Okay, so this is the original data. Okay, it is pretty noisy in the sense that you can tell apart the B cells, the monocytes, the NK cells, but all the T cells here are mixed together. So if you blow them up, you cannot see the structure between the T cell subpopulations as well. And here I show you the T cell. As well, and here I show you the T cell markers. You see that you don't really see the block structure that you would expect to see. Now, if you were to do the manifold fit and the denoising on this data itself without looking at public data, you get pretty far actually. You can actually start seeing the T cell subpopulations. Okay, and you can argue that this might look better than the one, the original. But the real improvement, really. Improvement really comes when you start pre-training on the 500,000 immune cells that you don't see, okay, that's in the public database. And then, if you do that, then the T cell types really separate. Okay, so it's oftentimes very hard to get an effector and a naive and a regulatory naive to separate. But then, if you were to use, make use of the ATLAS for pre-training, you can do that. Now, what if you have a novel cell type that is not in? A novel cell type that is not in the ATLAS. So we tried taking away the regulatory T cells, the regulatory T cells from ATLAS and say, okay, we pretend that we didn't see that ever before in other studies. And now let's pre-train on the ATLAS without the regulatory T cells and see whether that affects our denoising. And it really doesn't affect it too much, at least in this example. So it's pretty robust. Okay, here's another example of cross-species learning. Okay, so here in the Okay, so here in the target data, we have high coverage human cells from mid-brain during development. And we want to see how training on a parallel mouse data, mouse developmental data look like. Okay, so here is the human down sample UMI data. Okay, and then so we downsampled it so that we can use the original high coverage data as a gold standard reference. Here is the Reference. Here is what it looks like without the pre-training. Here is what it looks like with the pre-training with the mouse and the human. Okay, and remember the coloring is by the cell type and the cell types are from the original high quality data. So it's very good, trustworthy cell types. So you see that when you pre-train, even on the mouse, you do better than no pre-training, and only a slightly worse from pre-training on human. Pre-training of human. Okay, now people are worried about this because we wonder: does transfer learning from the mouse erase human-specific features, right? And for example, if you have a human-specific gene expression pattern, does pre-training on the mouse give you false mouse expression patterns that end up looking like the mouse, not the human in your human data? And that's not desirable, right? So we tested this. So the way we tested it is we So, the way we tested it is we started again with the high coverage human data, down sample to low coverage data. And then we have the mouse data, which we use to pre-train the autoencoder. And then we use that autoencoder on the low coverage data to get the denoised human data right here. And then what we do is we look at differentially expressed genes between the original high coverage human data. The original high-coverage human data, which the algorithm never saw, and the mouse data. And then we also looked at fold change between the mouse and the denoised human data. So we have two fold changes, and then we can plot them against each other. The original fold change, which we use as gold standard, and the denoised fold change using the mouse for denoising. And here is just an example with five different cell types. You see that we actually get pretty close to the identity line, meaning that we are doing pretty well. We are doing pretty well to recover the original differential expression value. And the reason we can do this is because we do the two-stage weight training, we do cross-validation, and we do the empirical-based weighting between the predictions and the raw counts. Just to show you, without the cross-validation and the empirical-based shrinkage step, we get a dampening of the signal to the x-axis, which means that human-specific signal is lost. Okay, so that's just quickly, you know, the Quickly, you know, the published work on transfer learning and denoising. Now, I want to focus on some recent work that we did with this manifold learning method on the estimation of the intrinsic cellular noise and cellular aging. Okay, so the way we do this is, well, remember that previously, all our sort of what we've been trying to do is to estimate the lambda. And that lambda is what plus. That lambda is what clustering and trajectory methods all start with, right? But the question is: does this manifold tell us everything we want to know? And the answer you might expect is no. Why? Let's look at an example. Here is the data that I showed you earlier from the aging mouse. Okay, and this is mouse bone marrow. And we're interested in the hematopoietic stem cells in the bone marrow because lots of human age. because lots of human aging related diseases have to do with um like for example clonal um uh clonal hematopo you know the the the um the accumulation of mutations within these uh hematopoietic stem cells that lead to say um leukemia when when we age okay so if we look at these cells we blow them up and put them on a umap and plot them against age we see that they're really We see that there really isn't much difference, right? I cannot see much difference between the cells, the different age groups, right? And that's kind of surprising because we know that the mutational burden increases with age. That's shown by many studies. And there are also studies that show that there's epigenetic drift that we basically are APAC, our chromatin. Know our chromatin state also sort of changes as we age. So, but then you don't really see much signal in the transcriptome. In fact, here is from this paper where they give you sort of, I think that the gene that had biggest change with aging is their best marker for aging, which is CDKINA2A, which the protein product is P16, a well-known marker of aging. And you see that it actually does not change. Not change that significantly with age, right? The p-value is significant, but you know, just looking at these plots, they're not very convincing. So, and I want to convince you later that the difference when cells age is in this beta G parameter, this gene-specific dispersion. Okay, and we are going to try to estimate this. And, you know, the precise estimation of this gene-specific dispersion is contingent on us having a good estimate of the manifold. us having a good estimate of the manifold and a good noise model without without either you won't be able to get at it okay um so the way we do it is that we estimate the manifold and then we use maximum likelihood to estimate data g okay so prior to this study um we searched the literature and these are the three papers that we could find that tries to get at this transcriptional noise and given that there were just so many studies so many methods papers in single cell uh Papers in single-cell RNA sequencing, we feel that you know there really is a lack of attention to this aspect of the data. So, for example, in this first paper, they first identify cell types and then measure distances to the mean of each cell type, and that they call transcriptional noise. And then in this other, this 2017 paper, they did similar things. They only focused on one cell type and then looked at increased invariance with age. And then finally, in the Age. And then finally, in the third paper, they measured a global coordination level of transcription across cells. This measure is just one single measure across cells across genes, and they cannot get a gene or cell-specific measure. Okay, so our idea was really simple. We already fit the manifold. Then we're just going to use the distance from the manifold to estimate this theta gene. Okay, so you could have cells that live on the manifold or cells that deviate away from. Or cells that deviate away from it. And, you know, low noise, high noise. Low noise, high noise. And remember, the trend, the technical noise, we assume is already removed. So what's remaining is biological intrinsic noise. Okay, so the first question we ask is, well, we are not the first to come into a room and talk about intrinsic noise. It has been studied for decades. Is this way of measuring intrinsic noise what people classically call intrinsic noise? So we go. Intrinsic noise. So we go back to the original experiment in 2002 when intrinsic noise was first defined. And what was that experiment? What they did was they took bacteria and then they put two of the same promoters in the bacteria, but harnessed to two different genes, one for the cyan fluorescent protein, one for the yellow fluorescent protein. So if you transcribe the CFP, it's going to look CFP is going to look green. If you transcribe the YFP, it's going to look red. But if you transcribe both, it's going to look yellow. And then they image the cells to see what color they get, right? So under this system. Probably about two to three minutes. Okay, yeah, I can do that. So under this system, if all the noise were extrinsic, then you will basically get all yellow. If you have both extrinsic and intrinsic, then you will have a variation in colors. Well, instead of Colors. Well, in single-cell data, we can't do this, but we look at a system where we have the F1 cross of mice and you have two different alleles at certain genes, and then we can look at allelic discordance. And through that measure of allelic discordance, we see that our measurement of dispersion by taking the distance from the manifold corresponds very well with allylic discordance, which gives us confidence that we're measuring intrinsic noise, which is what it was originally defined. What it was originally defined. And then this measure of intrinsic noise does correlate with cellular stress and damage. For example, here is an experiment where cells are radiated and with higher doses of irradiation, we find that we have higher dispersion. Now, going back to this original mouse aging study, we see that indeed, the dispersion increases with age. And that is something that we couldn't see before without this method. See before without this method. Okay, so this is in hematopoietic stem cells, so they increase with age, but it doesn't happen in all cell types. For example, granulocytes, the age signature is much weaker. And then for monocytes, you see that it doesn't actually increase age. So there's some kind of like a buffer in the system that, you know, these long-lived stem cells that accumulate noise, it doesn't propagate to the terminal phase. So that's what I talked about. I talked about. And then, in the continuing work, we're continuing to characterize the relationship between aging and stress on cellular noise at both the epigenetic DNA levels and seeing how they propagate to RNA. And then also, you know, underlying all this are methods, you know, we need to figure out how to adjust for bash effects in these experiments. And I didn't get to talk about that, but I think that's a very important application of deep. Important application of deep learning on single-cell RNA sequencing. Okay, so I want to thank everybody who contributed to this work: the students in my lab, especially Jane Shu, who headed Saver X, and Paul Hess, who led the work on the aging study, and the collaborators, Ardrin Rogers Lab, for doing validation experiments on the SABER and SABER X, Ming Yao Li, who is a longtime collaborator on all these projects. Collaborator on all these projects. And then Bradley Johnson, who is an aging expert whom.