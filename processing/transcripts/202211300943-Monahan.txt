It's going to be very different than everything else we've heard so far. There's going to be no dynamics in this talk. This is about nonlinear time series analysis. And it comes from, it's another step in sort of my career-long effort to try to understand the physical origin of non-Gaussianity in geophysical fields. So just here, kept going. Yeah, let's see if I advance with this. There we are. I would like to start by acknowledging that verse is on the traditional land. That verse is on the traditional lands of the Sony Dakota nations of the Wesley, Chenicki, and the Bearspa, the three nations of the Blackfoot Confederacy, the Pekani, the Kainai, and the Siksika, and the Sutina nations, shared with the MÃ©tis nation of Alberta, and that before the signing of Treaty 7, which governs these territories in terms of the relationship between these nations and the federal government, that this region was also used by the Tunaha and the Muscoches people in the broader area. In the broader area. Okay, so to get to the time series analysis, there are many quantities of geophysical interest that can be expressed as Gaussian processes, at least to a first approximation. So for example, if we're interested in the displacements of sea level through ocean waves, those are often reasonably well approximated as Gaussians. So if we are interested in the wave power density, that's the square. In the wave power density, that's the square of a Gaussian. If we're interested in wind speed, and I've spent a lot of my career interested in how wind speed works, the squared wind speed is the sum of the squares of the components, and under certain circumstances, the components themselves can be represented as claims of the process. Of course, trivially, when you square some time series, it results in frequency interactions from the original process. And the simplest example would be if we imagine we have here, right, a time series. A time series, x of t, that's just the sum of two sinusoids of frequency omega with coefficients that are just independent normals drawn from some distribution of mean zero. If I square this process, I end up with a process that has frequency contributions from the sum of different frequencies of zero of two omega. It's kind of a trivial statement, mathematically. Of course, the other thing that happens is if I square a Gaussian process, I end up with something. Square a Gaussian process, I end up with something that's skewed. So I end up with strong non-Gaussianity. And it turns out that this is not an accident. There's a fundamental connection between time-scale interactions in a time series, or frequency interactions in a time series, and non-Gaussianity. And this is very nicely brought out by the theory of polyspectra, so moving beyond thinking about spectral densities to other quantities which characterize the higher moments. Characterize the higher moments, and in particular, the bispectral density, which I'll be talking about today, decomposes the third statistical moment of the time series in a way analogous to the way in which the power spectrum decomposes the second-order moment. Now, what this allows us to do is it gives us some insight into the processes that are producing skewness in a time series. But also, interestingly, it allows us to systematically understand how our time series behave under filtering. Very often in a geophysical context, the data sets that were provided have been The data sets that were provided have been subject to some sort of temporal filtering. You might end up with hourly averaged or daily averaged quantities, and you want to understand how that has affected the statistical characteristics of the quantity that I'm trying to understand. So bispectra are a very nice way of probing the frequency content of the third-order moment of a time series. The problem is that their sampling characteristics are terrible. If you want to estimate these for a time series, they're extraordinarily They're extraordinarily very, very noisy. It's a very, very messy thing to do. You need very, very long realizations or many realizations to average out and get something which is robust statistically. And so what's quite nice is the fact that if your time series is Gaussian and you think about the square of a Gaussian and that's what you want to analyze, we actually have simple closed forms expressions for the bispectral density of that squared Gaussian process that we can then evaluate and we don't have to worry about all the complexity. And we don't have to worry about all the complexity of the sample. Okay, so just by way of review and essentially to establish notation, just to remind you that if I have a stationary Gaussian process x of t with some mean mu of x, it can be completely described in terms of its covariance. So this is just the mean of the product of the quantity at some time, and then at some later time, t minus the means. Of course, the stationarity implies that this depends only on the separation between these two. Depends only on the separation between these two times, not the absolute time. So this tells us everything about the time series statistically. And equivalently, I can just Fourier transform the spectral density and the covariance and I get the spectral density. Going to zero frequency, I can see that the variance can be simply decomposed as an integral across frequencies in the spectral density. And in some formal sense, we can think of the spectral density. We can think of the spectral density as being the average of the product of the Fourier transforms of the original process, different frequencies, with the constraint that the average of this product is zero unless the frequencies add to zero. So that's just standard spectral density. We go to the bispectra. The way we start is by generalizing the notion of a covariance to the bicovariance, where we take the where we take the process at three separate times, s, s plus t1, s plus t2, and take the average of the product of those three quantities with the means removed. That gives us a quantity that depends on two separate time lags. And then we Fourier transform that to two frequencies, and we get a two-frequency object, the bispectral density here. I'm assuming everything here has a density, so I'm including in that the possibility that there might be delta peaks in these quantities. Be delta peaks in these quantities. Now, what this allows us to do then is it allows us to write the third-order moment of our time series as an integral across this bispectral density across all frequencies. And again, in the same way that we can think of the spectral density as resulting or as corresponding to the interaction of two frequencies F1 and F2, we can think of the bispectral density. Bispectral density as corresponding to the average of the Fourier moments or the Fourier coefficients of the original time series at three different frequencies. Those frequencies have to add up to zero, and so we end up with this essentially interacting triad of frequencies characterizing the third-order moment of the time series. So this is where the multi-time scale process comes in in the context of this particular workshop. So again, thinking of a very simple case of a monochromatic wave. Case of a monochromatic wave. So if x of t is given by just again this pure sinusoid with some non-zero mean now, and I square it, I can write down the pyro spectral density in terms of delta masses at the zero frequencies, about the difference frequencies of the original one. I have the doubled frequency, as well as the original frequency, how the original omega comes into the power spectral density because of the presence of this non-zero mean. The presence of this non-zero mean. So we still have these three frequencies. I can represent this schematically in terms of these delta masses at the frequencies of minus 2 omega, minus omega, 0, omega, and 2 omega. So this is what things would look like from a power spectral perspective. For the black spectral density, things get a little bit messier. We have more terms, more interactions. We have a mass involving zero frequencies. We have a mass involving differences of two omega. 2 omega or 4 omega, and then we have a whole collection of terms that arise because of the non-zero mean of the process. It's probably easier to visualize this than try to interpret the actual mathematical expression. So if we look at this in terms of the distribution of these delta masses in the two-frequency plane, so each of these dots represents a different contribution to the bispectral density. The black dots are those that are there. Are those that are there even if the mean of the original process is zero and the circles all come in because of the non-zero mean of the original process? So you see that there's this interesting scatter of different frequency pair interactions that are producing the asymmetry of the distribution that results from the squaring this Gaussian process. Okay, but that's for a pure monochromatic wave. That's pretty simple. What about the general Gaussian process? What about the general Gaussian process? Well, there's a very nice result that goes all the way back to the classical paper of Rice in 1945 that says if you have a Gaussian process and you swear it, that the power spectral density of the product is essentially just the convolution of the power spectral density of the original unsquared process. Plus another term here that results again from the fact that we have a non-zero rate. So this is an old result. And so the novelty here is that you can actually. So, the novelty here is that you can actually generalize this. So, this is something I've done recently: generalize the result to the bispectral density. And it turns out that for the squared Gaussian process, you end up with this rather simple term involving now convolution-like integral involving the power spectral density of the original process x of t in this triple product involving these three frequencies here. And so, if you have the power spectral density of the original process, that's a relative. Spectral density of the original process, that's a relatively easy integral to evaluate. And then we get, again, this kind of term that flows along because we have a non-zero mean original process. So, what this means then is that if we have some Gaussian process with a non-zero mean and we square it, we can actually understand analytically up to this integral exactly how frequency interactions produce asymmetries in the probability distribution of that quantity. So, to start with, we can move from that monopoly. So, to start with, we can move from that monochromatic picture we just had to perhaps the simplest continuous generalization of a narrowband spectrum. So, if we assume that our Lag covariance function is given by this sinusoidal function with frequency omega and then some sort of decaying amplitude with inverse time scale mu. It's quite simple to show that the spectral density of our process x of t, and for the moment I'm just going to assume the mean is zero to avoid having too many turns floating around. Avoid having too many turns floating around. If we have the covariance, this is the bispectal, or this is the spectral density, quite a straightforward integral to evaluate. And then similarly, we can evaluate the integral for the bispectral density, and we end up with the situation where we have exponentials that are centered at a frequency of zero, and then frequencies that correspond to the doubling of the original frequency. Doubling of the original frequency. So we have again this manifestation of the sum of different frequencies going back, except now in this narrowband spectrum, not these point masses. And again, if we look at this visually rather than thinking just about the mathematical expressions, if this is the original power spectrum for our unsquared x of t, when we square that and get what I'm calling y, we get this distribution of power. The difference frequencies we get between these two pieces. These two peaks result in extraordinarily strong amounts of power at very low frequencies. So by squaring this narrow band process, you end up with these very low frequency oscillation results, not the DC result that you get for the point nodes. Bispectral density is a little bit more work, lots and lots of terms. But again, we can look at this visually. Again, in the plane of our two frequencies, F1 and F2, we end up with the And F2, we end up with these concentrations of mass that contribute to the third statistical moment of our distribution. And again, you see that they're arranged in this quite symmetric way around our plane. So it's an interesting aspect of bispectral densities. In the same way that for the power spectrum, we have completely redundant information between positive and negative frequencies, right? So you really only ever have. So, you really only ever have to represent the positive frequencies from the spectral density. There's very strong symmetries in the bispectral density. And in fact, you can reconstruct the entire bispectrum if you only consider this principal region here, this little wedge. So all of the information about the bispectrum is contained in this wedge. So from this point onwards, I'm only going to be showing information in that wedge so as to avoid giving too much redundant information. And so we can actually then. And so we can actually then zoom in to this wedge here. And also, because we're now only focusing on positive frequencies, we can rescale the frequencies logarithmically to really zoom in on what's happening at these low frequency scales. And we can see all of these cross-frequency interactions within the low frequencies and a concentration here as well at this doubled frequency 2 omega. Now, in these plots, and I'm going to show a number of these going forward, exactly the same information is shown. Exactly the same information is shown in the upper diagonal and the lower diagonal parts of the plot. All that differs is that here the contours are scaled logarithmically and shown in color, and the black and white contours are scaled linearly. So it's redundant information, but trying to bring out different aspects of the bispectral density. So we start now to be able to see exactly how these different frequency interactions combine to produce this asymmetry in the distribution in this. And the distribution in this squared narrow-down process. But we can move on and consider other sort of paradigmatic processes. Of course, the next natural one to consider would be the Arnstein-Whelenbeck process, again, for which the stationary spectral density is very well known. So if we have this quantity, then we can go in and consider the spectral density and the bispectral density of the squared process. Even though it's going to add some more terms, I'm going to allow the mean. Terms. I'm going to allow the mean of my x of t now to be non-zero, just so we can see how these things come in. So, again, we end up with a nice closed-form expression for the spectral density of the squared process, and a nice closed-form expression for the bispectral density of the squared process. Right? Lots of terms, lots of factors, not terribly easy to interpret just looking at this. Looking at the formulas, so let's look at some figures. In the top panel, In the top panel, I'm showing the spectral densities. In the middle panel, I'm showing bispectral densities. I should have noted before that when I've moved to scaling my frequencies logarithmically, I'm also multiplying the spectral densities and the bispectral densities by either one frequencies or a product of frequencies in order to preserve the integral. It's kind of a classic trick you play in working with power spectra. So, what we see here, and again, this is also an effort to try to prove to myself. And this is also an effort to try to prove to myself numerically that my integrals were evaluated correctly. So I have generated on Strangled Beck processes many tens of thousands of them so that I could compute their bispectra empirically and average over them to actually get reasonably robust statistical estimates. Similarly, with the power spectra, so in the upper panel, we have in blue the numerical estimates of the power spectra and in black the true estimates. The true estimates and they match quite nicely. And as well, just as kind of a bit of a game, I've also plotted the power spectrum, the empirical power spectrum, because of course I don't have a closed form expression for this, not for the square of the process of x plus mu x, but the absolute value. And based on some other work that I've done in the past, I had reason to believe that the power spectrum of the absolute value up to a scaling factor should look like that of the square. Of the square, and you see that approximation seems to work pretty well. Going down to the bispectral density, we now see these really characteristic structures of frequency interactions in the squared orange-diagnoy-Nullenbeck process, which are resulting in our non-Gaussianity in our squared process. And as I change the mean of my process, I can shift this quantity around laterally. So, what's also useful about having these analytic results is that it turns out that the spectral density and the bispectral density of the squared orange-de-Ulenbeck process have identical mathematical forms for the spectral density and the bispectral density of something that Jorn had mentioned yesterday, which are these so-called correlated additive and multiplicative noise models, which have been used for 20 years now, longer, as kind of paradigmatic. Longer, as kind of paradigmatic models of non-Gaussianity in atmospheric and oceanic flows. And so, in such a model, and this is now just the stochastic differential equation that characterizes such a process, we have two noise terms, one of which is multiplicative, the other which is additive. For such a model, you can also analytically compute the spectral and by spectral densities, and they take exactly identical mathematical forms to a squared Ornstein-Limbeck process. Steiner Limbeck process. And so, again, from the point of view of trying to think about from observations this problem of understanding what is physically producing our non-Gaussianity, this raises a bit of the question. Now, it's maybe not so surprising. We all, you know, it's probably not surprising to say just knowing the power spectral density, you can't determine physically what produced it. But this is a case where you have, you know, power spectral density and a bispectral density, and there's really no ability to distinguish between these two different classes of model with very different physical. Of model with very different physical origins of non-gasing energy. Okay, so the last example I'll talk about is essentially now moving between the narrowband spectrum we talked about before in the Einstein-Limbeck process, which is considering a damped harmonic oscillator. So if we have a two-dimensional stochastic differential equation that has a drift term that involves damping and oscillations, and it's just the diagonal diffusion term. Again, it's just a multi- It's just a multivariate orange-dynamic process for which the statistics are analytically tractable. We can write down the spectral density for the first component. So we can now take this and evaluate our integrals to get the spectral and bispectral densities for the squared quantities. These are not so tractable analytically anymore, so you end up having to resort to numerical integration, but in principle you can do that. And we get the following. So what's shown here now. So, what's shown here now is in the upper panel again are the spectral densities, and the lower panel are bispectal densities for three different values of the damping parameter. So, as A increases, you move away from a weakly damped oscillator to a much more strongly damped oscillator. In the weakly damped case, we have in the red curve here the power spectral density of the original process, and in black of the squared process. And again, we kind of see this splitting of power between the Between the original frequency and this low frequency and this high frequency. And if we look at the power spectral or the bispectral density, we see this quite interesting structure with all sorts of interactions with these very narrow bands that correspond to the essentially the doubled frequency of the oscillator. So this is at omega, this is omega, and this is F1 equals omega, this is F2 equals omega. F1 equals omega, this is F2 equals omega, and this curve here is F1 plus F2 equals omega. And then we get this sort of broadband background with which it's also interacting. So we have these low frequency interactions and then these low and high frequency interactions, which come together to produce the asymmetry in our time series. And then as we increase the damping, we essentially cause these narrow peaks to weaken relative to that sort of broad background, and then it Broad background, and then eventually just end up as something that looks more like the orchid-on-deck process that we had earlier on. And again, you can play the same game where we now allow the mean of the process X to be non-zero. We fix the damping and the frequency, and we increase the mean of the process. And we see again now this multi-frequency interaction where the presence of the non-zero mean results in. Non-zero mean results in still power at the original frequency omega, and then we have low frequency power and two omega, and then that is also reflected in this kind of complex way in the bispectral density with interactions among all of these different kinds, all of these different characteristic frequencies of the problem. Okay, so just to wrap up here, the bispectal density decomposes the third statistical moment into contributions from interacting sets of frequencies. Contributions from interacting sets of frequencies. So it could be a useful way of probing sort of the time scale contributions to some non-Gaussian process. And I haven't talked about this in detail, but you can systematically understand how the, say, low-pass filtering will affect the skewness of your distribution as it essentially cuts out parts of your plane and sets those to zero. And by looking at the remaining parts of the bi-spectral density, Looking at the remaining parts of the bispectral density, you can understand the behavior of these skewness under LaPass filtering. And what's really nice is that for these squared Gaussian processes, we have an analytic expression for this bi-spectral density up to an integral, which is not too hard to evaluate numerically. It gives some insight into the frequency content of skewness, but the example of the squared-orange-stein-Ulabeck process tells us that you can know what the bispectral density is, you can know what the spectral density is, and that actually tells you. Density is, and that actually tells you nothing necessarily about the physical origin of the non-Gaussianity, because you could have two very, very different underlying models that produce the same kind of structure. Now, in terms of future work, what I plan to do is to actually now take these ideas and think about to the extent that it's possible based on the fact that observational time series can be very noisy, or that bispectral estimates from observational time series can be very noisy. Bispectral estimates for observational tensors can be very noisy. Try to understand in observations and climate model simulations, how these results can help us understand some of the frequency content of the non-Gaussianity that we see in environmental time series, and then how the averaging that we do affects those. And also, an important question, of course, is that. Question, of course, is that you know, I've assumed in this whole calculation that my X of T process is Gaussian. Very few things in the real world are absolutely Gaussian. So, then from a practical perspective, the question is, how important are modest deviations from Gaussian be to this theory? Does it cause it all to fall apart, or do things stay relatively robust under these small changes away from strict Gaussian very little? So, thank you all very much. So, thank you very much for this interesting talk. Questions, comments? Yes. Question on the last part about the observations. I make a connection with Gubert's talk before. Do you think you can, like, I mean, you can identify triad interactions through that? So have you looked at any observations already and can you say, are there maybe some triad interactions of these scurry waves and things like this? And things like this. Is this something you think you can study? I mean, possibly. The problem is with finite record time series, I mean, spectral analysis is problematic enough with producing spurious peaks. Bispectral analysis is even worse. And so you need a very long time series, either observationally or from models to dampen the noise. So you can imagine taking a hundred-year, thousand-year simulation from. Year, thousand-year simulation from some Earth system model, and then you know, analyzing that one year at a time and then averaging those thousand years together to damp down the noise. That's something which I'm just starting to look at doing. So in principle, you should be able to identify these frequency interactions. But of course, it's also important to remember that these are frequency interactions that are relevant to the production of asymmetries in the distribution. They aren't necessarily, they aren't related to the power, they're not related to the variance. They're frequency interactions that are associated with a very specific aspect of the property distribution. Perfect. So, concerning actually this non-one-to-one relation between the source of the strong version energy and the spectroscopic density, to me a natural thought would be when we go one moment up, right? We have been to the third statistical moment. And it gets worse, right? I guess. I mean, there's other things you can do. And I cheat a little bit when I hit when I click. And I cheat a little bit when I talk about this because if you actually look at the marginal PDFs of those two, the square Gaussian process and the CAM process, they look very different. So there's distinguishability there. Yeah, so it's not that there's no distinguishability whatsoever. But I did find it quite striking that these two quite distinct aspects of characterizing the the temporal contributions to the statistical moments of a process should be absolutely identical for really quite different processes. For really quite different processes. On the same question, if I read the spec word, doesn't it mean that try to upgrade their models to a stochastic model and then they pick a stochastic process? They use it for anything but doing certain statistical estimates. They run the danger of doing violating the physics of the problem. So, noise isn't noise, right? G-physics actually does a reasonable job on representing the statistics that we come with. If you have the wrong underlying model and you use that as a parametrization, and this model interacts with the rest of the neutral statistic parts, you might be scrambling it all up without noticing. Yeah, noise is not noise, and that's why you need the physically predicated analyses in conjunction with the time series analysis of stochastic dynamics in order to come up with a few characterizations. So, I don't see any more questions. Thank you very much again. So, our next talk is a surprise talk.