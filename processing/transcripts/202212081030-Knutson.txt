Yes, here um so uh here's maybe some more detail about the one you um uh that I drew on as a triangle. So that was uh we had C3 that isomorphically to the open part of the ones we wanted box and listen and then we had boxamessen and that mapping to the five six three GF map. And I said that where a ABC where ABC goes is to the product of the three matrices and then get it in there. And so So I'm actually going to multiply out these matrices according to in front of the room. We know how to multiply zero three matrices. But the way I'm going to do it is I'm going to draw this with an A here and a linance there. And these are very sparse. So there's very few connections from these three to those three. And I'm tempted with how much we grew up. And then I'm going to have. Should move up. And then I'm going to have these community switches with the minus line here, there, and these people switch, minus line here, and C there. So if I want to compute this matrix, the entry here is going to be what I get all the ways to get from here to there. I could either come down through this minus sign, then I could come across this B and come up. So I get a negative B. I could go straight through this A and straight through that C. Straight through this A and straight through that C and right here with B C and that's it. There's the only two ways to go straight through one of the letters or follow the paths and from here to there. That's going to be one way. From here to there, I'm going to go through the A and the minus. And I think that's it. Because if I come, if I come down, then I'll. Down, then I write it blue here and from there, and here again. And from here to there, I simply go through this minus and then minus, and I go. Then from here up to there, I could go up and then go through the C. Or I could, well I have to go up and then I could come down to here, minus one, and close it. Yep, and from here I gotta go up. Yep. And from here, I've got to go. I've got to go. So inside here, remember I had these guys XOW, the E minus orbit closures. And what I want to look at right now is pulling back, not an arbitrary one of these, but specifically the divisors, the XMRL. The XMR alphas. And what happens when you take XMR alpha and you pull this up on this whole thing? And you fold it again. And you say, we're just going to go to, when we apply m total inverse. So this subset is what? And it goes, sir, let's say I. And it goes to the northwest I by I determinant. Determinant being zero. So in this case, I've got either negative B plus A C is zero, or I've just, and so that's this one by one determinant, or I've got this two by two determinants zero. And the okay, so those are the two devices. Okay, so those are the two divisors. They live inside the entire space. And I could think about making other varieties out of those using this intersect and decompose algorithm that starts with whatever set of varieties you want and constructs a whole stratification from that set. So if I intersect these. So if I intersect B, then I'm imposing that B is 0 and AC is 0. So that's reducible. It brings me into B is 0 and A is 0, or V is 0 and C is 0. And then, so I intersected first, and then I decomposed to get A is 0 or C is 0. Then I'm going to intersect these guys, and I don't have to decompose 'cause it's all going to be something. I'm finding um S3 root order in the sojourn. S3 root order in SOJ. So, what I was saying yesterday was you can take any one of these subschemes of your vector space here and let's emit them. So these are very simple because they're complete intersections. But there's only one of them, even in this tiny case, where something's going to happen when you let's emit, which is this one. That this polynomial will become an eight-linomial. A monomial and which monomial wins? Well, I look for the high power of A. And the highest power of B and the highest power of C. That's what the device means, and the highest power of A because we know it's A's together. But one of them doesn't break, and the other one does break, and that's what got us this versus that one triangle yesterday. So it was the one dash dash and the dash dash one, and they put them together on the one dash one. And we'll go on one dash one. And this has to do with where the positions were of the A and the C units. Okay, so I claim the theorem and frankly to hear something about the proof of it. So I want to give you a recipe that Recipe that I didn't finish this example. This was going to be the example of this word, which is an auto-reused word, and this element in S3. This is a case where there's nothing higher than W0 in S3, and so when I said that the closure relation The closure relation on the cells was given by Freehauer. Since there's nothing higher than this, this guy will have no boundary. It'll be a sphere. And if you compute, the dimension of the sphere will be the length of this minus the length of that minus one because we produce a bunch of topics. You get a, so I was on my way towards finishing up this triangle sphere. Alright, so I want to give you a recipe that cooks up these varieties inside here as a good thing to look at. So one thing that we know about them, of course, is that they're torus invariants. So I want to try and generalize that notion. So the how to pick out These guys inside our apple table. Let's see. So the first thing I might hope is that they are exactly the torus orbits. And if that's not true, this is three-dimensional example, and the Taurus is only two-dimensional. We're not going to get this open orbit that way. So I want to generalize. I want to generalize that somehow, the idea of being an orbit of a group. I want to generalize that to pick up more stratifications than orbit stratification. So in addition to the T action on CQ, there is An algebraic response structure on CQ. And I'm not going to completely write it down. I want to emphasize this is not, don't think O CQ is a Kayler manifold, therefore it has a real symplectic form, and therefore it's a plus. And therefore, it's a Poisson manifold. That's not the Poisson structure that I'm using. So that one doesn't respect the complex structure as trivially as I want. I want a Poisson bracket on functions that's complex bilinear. And so it's enough to say, you know, if you want to write down the Poisson structure on the function, Yeah, the Poisson structure on things, it's enough to say the bracket of xi with xj is equal to some polynomial, and you get this anti-symmetric nature. So of those polynomials, then they have to satisfy some condition that says structure can actually give you an algebra that satisfies the Jacqueline. So, but why do I think of these as so closely related ideas? So, what you can do. So, what you can do with the Poisson structure on here is think about the Poisson sensor, which is a section over CQ, whatever, of the wedge squared of the tangent level C2 CQ. So it's not a So it's not a vector field, it's a bivector field. And you can use it, so you can ask what are the sub-manifolds of our space that are Poisson and are maximal within a given dimension. So I don't want to say, well, the entire space is a plus sign or everything. Entire space is a Poisson, everything, and increase up to that. But I also don't want to be able to take a Poisson sub-manifold, take an open set in it, and say that's the thing I want. So let me back up to the Taurus action. So how do you define an orbit of a Taurus action? Well, you take a point and hit it with the torus. What if you only had the Lie algebra? The Lie algebra, you only had the vector fields coming from the torus action, you didn't have the entire finite non-infinitesimal group to be acting. Then you would say I'd like to look for sub-manifolds such that the vector fields are tangent to the sub-manifold and the sub-manifold is as large as possible with its dimension. I can't increase it without increasing the dimension. The dimension. So that's a kind of unpleasantly roundabout way of thinking about torus orbits, but it's one that only refers to vector fields instead of the group action. And so I need that idea in mind to think about what the corresponding thing is for y vector fields. So this was a wordy way of saying I want to think about t orbits, or maybe the algebra of t orbits. Orbits are analogous to symplectic leaves of our Poisson structure. So these are, so in both cases we have sub-manifolds such that the Bolton vector field Vector field is tangent to it plus some maximality condition. So there's another thing that's analogous here, which is that the vector fields from the torus action all commute. And there's an extension. And there's an extension of the Lie bracket of vector fields to multi-vector fields, like a Poisson tensor, called the Scouten bracket. And the condition for a two-tensor to be Poisson is the condition that pi commutes with itself, that the Poisson bracket of pi with pi is zero. Now, the Scouten bracket of pi with itself is zero. Now, the Scouten bracket is not anti-symmetric. What it is is super-symmetric. Symmetric. What it is, is supersymmetric. So when you bracket vector fields, you expect them to anti-commute with each other because they're degree one. This guy is degree two, so there's no particular reason it would anti-commute with itself. There's no particular reason it would bracket to zero with itself, and so it's an extra condition. Okay, so what if we have both Have both T and action and a Poisson tensor and this Poisson 2 tensor. And so now putting them together, of course, the thing you usually say is, let's have the Poisson tensor V T invariant. But really, I want to think of this again as just one more commuting step. Again, it's just one more commuting statement. The vector fields commute with each other, the Poisson tensor commutes with itself, the vector fields commute with the Poisson tensor under the Scout and bracket. So now I could ask for sub-manifolds that are such that these tangents, these vector fields are tangent to it, and the Poisson tensor is tangent to it. So if we ask, So if we ask for tangency of both, you get, so it's very easy to actually get a hold of one of these. You take a symplectic leaf and you hit it with the torus action. Okay, so that will be, that will be Poisson and Taurus invariance. Facade and torus invariance, and these will be the minimal things that are now generalizing the notion of being torus orbits versus being symbolic leaves. So in particular, if I make my torus action trivial, I get leaves. If I make my Poisson tensor zero, I get orbits. If I have both of them, I get these things. They are called television. This terminology is due to Ron Richel. Running my chill. And I think it's important that there's a C dot here, not a dash, because it's about taking a leaf and moving it around using your tools. So theorem and the It's a little hard to blame this on any person in particular, but I think I'm going to give it to Vilaine Yakimov et al. is there's a Poisson structure, again, algebraic Poisson structure. On this guy and the T option, of course, such that these guys next to a blue open are exact, so these things that you get are exactly the two. The two leaves. So it's kind of like the next step after being a toric variety. A toric variety, you have a torus action, and it gives you a decomposition to finitely many pieces. A symplectic manifold, you've got a Poisson tensor, and it gives you a decomposition into one piece. So here, I certainly don't have a big enough Poisson structure on here to break into finitely many symplectic leaves because frequently this guy. Symplectic leaves, because frequently this guy is odd-dimensional. But mixing the two together, doing the tea leaf thing, then you can get, you discover that this space is like a Tauric variety, it's got finitely many pieces, but you need to mix the two concepts to get a hold of that definition. Okay, so there's another any questions right now? Uh well any questions right now? Um it's not too hard. So it um uh so remember this guy lives inside here and the Poisson structure comes from there and this guy we got as the big product of B's, mod B's and the statement is And the statement is that the place the Poisson structure naturally lives is on G. So, for a simple Lie group, there's a unique such Poisson structure such that the map from G cross G to G is Poisson and unique up to conjugacy and scale. So, in that sense, I've told you what it is. I'm not very good at. I'm not very good at writing it down. But the unique opticogenese, there's going to be only one Varel, then will be a Poisson subgroup. And then that guy is the one you use. And then all the parabolics that contain it will also be Poisson subgroups. And that's what's going to make everything here Poisson. Yep, so is it a hotness equation? Hoitney subfusion? Is it what? Hoitney subfusion? No. I'm not understanding what you're saying. So Poitny? Who? Whitney structures. Is it a Whitney stratification? I mean, everything here is complex, algebraic. That's quite exactly. Once things are complex algebraic, then they're openly stratified. Yep. Given what you just said about where the cycle structure comes. Just said about where the sign construction comes from. Is there a reason that you've written this on does it extend to the elementary? So this statement wouldn't be true. So if you want to know what are the t leaves on here, then you get them. You say, well, let's first break this up into the subbot samples that way, and then break them up by taking these pre-images of these. Of these, and that's exactly the tea leaves on the entire closed wet sample. Okay, so I want to bring up some other structure that one gets from this story, from this enhancement of things, to know that we don't just have the Taurus action to think about, but also the sound structure. So, one way to say that there exists an open dense leaf is that we can take the Poisson tensor and wedge it with itself a bunch of times until it's just about to die. Until it's just about to die. Okay? So obviously, if you wedge it until it gets above the dimension of the manifold, then you get zero. But I'm going to take this the maximum number of times, and then I'm going to wedge with some vector fields. One, two, it doesn't matter which ones in fact. And these are from the action of the Lie algebra of Taurus. Of the Lie algebra torus. Okay, so one way to say that there's an open dense tea leaf is that we can get this to be a section of the top exterior power. So that I can wedge so many of these so that I eventually get something that's like a volume form, except inverted. So the volume form is a section of the top exterior power of the cotangent bundle. So let's take one over one of those. Not quite because this thing will have zeros and so it's not going to be one over a volume for me. But the main thing is that I want to. But the main thing is that I want this to not be zero. So you could imagine a dumb case. What if you have pi is zero, so it's not helping you make T leaves, all you have is T orbits. What if T isn't big enough dimensional? So you try to follow this. You say, what's wedge pi the maximum number of times? That would be none. And then I'll start putting in vectors. And then I'll start putting in vector fields. And even if I used all the vector fields I have available, I wouldn't make it all the way up to the top exterior power. So let me call this guy Sigma. It is this top exterior power of the kind of one of the thing initiatives. Sorry. Want to put the interest waste? Sorry. So, another way to say this is that the divisor or sigma equals zero is an anti-canonical divisor. Okay, so what here's a here's a fun thing you can do with an anti-canonical visor. If It's algebraic M, and soon M will be given by Samuelson. Let's just take the algebraic M. If some algebraic M has an anti-canonical section, so let's say some anti-canonical section. canonical section sigma and it is defined over z. So basically think that all the equations that come up in writing m down have integer coefficients. So that's not maybe the final way to think about defined over z means, but definitely where you should start. Where you should start. And so here I want both of them to define infracy. M and sigma should both be defined in Z. Then you get sigma P on N P, which will be M reduced mod P. So this is now a scheme. So, this is now a scheme over Fp instead of a scheme over Z. On MP, there exists this Cartier operator that goes from closed Durand forms to all Durand forms. All Durand forms and of a given degree. It's Cartier operator. And it has this fun property that if you give it some form, alpha, and some function up front that's been raised to the pth power. Then, when it comes out, then sorry, it'll come out. It's linear, this Cardi A operator, but it's linear with a P through involved. So, this is a thing that shows, this Cardi operator is a thing that shows up. I don't want to write down the formula for it. It is Googleable. But it's something you only get a hold of in characteristic P, and it has this P3 property. Property. What I'm going to do with it is mix it with the anti-canonical section that I have. So I'm going to define for f a function on m and you could worry about section of the structure sheet or whatever, but my m is going to be affine space in a moment anyway. For f a function on m. Um for f a function on n, I want to define phi of f will be I take f, I divide it by sigma. So this guy right now is a top form with poles, right? Because sigma was a top exterior power thing. Sigma lived in the dual bundle to that and here. And potentially had zeros. I take this volume form, and no, because it's a top form, it's closed. And I cardiate it. And so it'll still have poles, but those poles will be 1 over p as bad. And then I multiply by sigma again, and now it's a function. So sigma, if sigma had zeros in places, If sigma had zeros some places, then this will have poles, this will make the poles less bad, and these zeros will then fix those poles. I mean, obviously, this isn't going to work if sigma is zero everywhere. Are you assuming the vanishing locus of sigma is that not? I don't think I need that for this. There's another way to do the calculation where this thing comes in here and it gets something that isn't really. And you get something that isn't really C applied to F times sigma to the P minus first power. So there is another way to do this that makes it clear that I don't have to care about questions like that. But if it isn't true, then other bad things are going to happen soon that I'll mention. But so far I don't care about that. So this is now a So this is now a this is now some recipe that so from functions to functions with this p-through problem that this guy had, which can pull things out and take a p-through process. Okay, so what do you think? Okay, so what do you do with something like that? So, definition, they map phi from R to R. So, R is a ring containing FP. So, it's an algebra over Fp. Um is if we need a splitting if phi is additive that seems innocuous enough if so I want it to be a P3. So I want it to be a pth root. So what I want is the following equation: phi of a to the p is equal to a. And I'm going to make that a stricter condition and a weaker condition at the same time by putting a b here and saying it's not that you can take the p through to things, so you can pull p throughs out. And now, for behaviour splittings are easy to come by, right? Take phi equals zero all the time. So that's. So that's not what I'm going to want. So this is going to be the hard condition, is the length of the sign. So if you considered just these, those I'm going to call near splings. But if you have this extra thing, I'm going to call it a Hermenius. And the place I learned almost everything I know about Ferminia splittings is from this book that you can steal on the web. If you go to a certain website where there is a, let's see, Note Commons Exposé, and the very bottom it says Olto. And you click on Alto. And you click on Alt, and you find out that there's this book, The Benefit Splitting, in Representation Theory, and Geometry by Brian and Kumar. Send you some time. Is that the only way it fits us to go more by each time so? Places available by email and stuff here. I mean, it's on the web. Is it in the library too? Or the library? Yeah. So the program is a web. Yeah, if you want it all the paper, we'll do that too. Okay, so now we have this. We're going to get back to the semi-toric generation stuff and so on, but one of the main things that was Was that one of the main surprises in the degenerations that I was laying out with these LexiNit stuff was that after I degenerated my sub-schemes, they stayed reduced. And I want to say that this setup is just great for studying reduced things. So, Ethereum: if R has a Verminia splitting phi, then Then R is reduced. I don't think I even need to write down the proof of this, right? If you have somebody who's, if you have some nilpotent, then you raise it until it's just about to die, and then that guy, its pth power will be zero. Now you apply this thing to find out that that thing was already zero. Contradiction. So that's really easy. You could imagine making a category now of these. So, pairs: I've got a ring, I've got splitting, and I think about homomorphisms from one ring to another, such that I can feed before or fee after. And that leads you quickly to the definition of I inside R, an ideal, is compatibly split. And it's clear what the universal algebra condition should be about, right? V of i should be containing an i. Now, it turns out that this implies that phi of i is equal to i, because i contains its pth powers. So you apply phi to them and pth roots them, and you get everybody at i. But I mean, this is the thing you obviously need if you want, for example, phi to descend to R box. phi to descend to r mod i. And so what if phi descends to r mod i? Then r mod i is reduced, which is to say i was radical. So this implies that i is a radical ideological. All right. So theorem one, okay. Let ij inside R be compatibly split ideals and let J just be an ideal. Then one, I intersects J is compatible with Spain. I hope everybody will use that. I hope everybody believes that. i plus j is compatible. That actually uses an axiom, okay, and it's not a complete tautology like the previous one. But you should be really impressed by this, because what am I saying here? I'm starting with two radical ideals, so I'm starting with two sub-schemes, you know, like this one, that one, and then I'm adding the ideals, so I'm intersecting. Adding the ideal, so I'm intersecting this thing, that point in this case. And I'm saying, well, it's again split, therefore it's radical. You shouldn't be able to add two radical ideals and hope to get a radical ideal again. The notion of being radical ideals is this delicate one, easily broken. But the notion of being compatibly split is much more robust. And the proofs are, you know, they're half a line. So here's a more interesting one. I colon kit. I colon k is compatibly split. So, if you don't know this algebraic computer algebra thing, this is those guys R and R such that when you multiply the entire k by them, you end up inside I. And what you do with this sort of thing is, for example, let's take the ideal xy and colon out the ideal x. Colon out the ideal x. So I'm looking for those things that when I multiply them by x, have now become multiples of y. And the answer is xy. The answer is that they were multiples of y to begin with. So what you get to do with this is take some ideal that defines a union of a bunch of pieces, a bunch of components, and you get to throw away those components that are inside K. But you're just taking the colon and not the whole saturation. It's also. Yeah, but everything's so reduced. Yeah, so everything's so reduced that it doesn't matter. Yeah, that's that's all very nice. Yeah. So, in particular, what this is going to say is that intersect decompose algorithm I was running before, if I start with things that are compatibly split, and then I start intersecting them, that'll be compatibly split, and I start decomposing them, those will be compatibly split, and I'll just keep making things that are compatibly split. Compile display. So here's an example of this notion of compatibly split, or sorry, of splitting. Let's say R is just a polynomial array in n variables, and let's phi of, so if I want to tell you a phi, because phi is Is additive, and because I can pull out pth powers, and because the coefficients, Fp, all are their own Pth powers, it's enough for me to say what this does to a monomial. So what I'm going to do, I'm going to take that monomial and take its pthroot. Well, I'll do that if there exists a pthroot to that monomial. And zero, if there doesn't. And zero, if there doesn't exist, a P3 to that many mm. So there's a very brutal verbini of splitting called the standard splitting on affine space. So you can, it's kind of a fun exercise, what you know so far, to figure out that if an ideal is split with respect to this splitting, then it's a standard Reasoner ideal, and vice versa. So those are exactly the compatibly split ideals for. I can probably split ideals for this guy. In particular, there's finitely many of them. But that is actually one of the hard theorems in the subject: that there's always, if I have an Ethereum scheme R, and I've got Frobenius splitting on it, then there's finitely many compatibly split ideals. So that takes three pages, not a half of them. So there's this three-page paper by Kumar and Meita that proves that. And there's also a similar result by Similar result by Carl Shri around the same time. All right, so here's the theorem line. If f is a polynomial in n variables and And of degree n. So that might seem like a weird thing, but I really mean n twice, I do. For example, if f is a homogeneous polynomial, then you should think what it's defining something inside projective space, and it'll be defining an anti-canonical divisor on projective space. That's what you're doing. Quality of the ads that you can be there. Such that Such that oh shoot, I um I need one more definition before this. I uh I like talk. So that one more definition. Um so here's this uh near splitting tru. So tru of monomial is Is rather like this, but what it does, it takes your monomial. Thanks. It takes your monomial, it multiplies it by all the variables first. Okay? So now the monomial has all positive exponents. Then we try to take the pth root if we can. Now, Now the exponents have gone down by a factor of p, but they're still positive rational numbers, or hopefully integer numbers, because I'll do zero otherwise. So if they're positive and integer, they're at least one. So I can divide by the product of variables and give them a nominal. So that's a near splitting on AF. On affine space. And actually, the set of near splittings is naturally a module over the ring itself. In the case of affine space, that module is free of rank one, and you can use this as a jet here. So I don't need any of that. I just want to be able to write down a particular kind of splitting ring. So if f is a polynomial degree n, With a leading term, the product of variables. Then phi sub F, so this is going to be defined as we take this thing we're feeding into phi sub F, we multiply it by F to the P minus 1. To the p minus 1, and then we take the tra of that. Then this is a splitting. So not only does it satisfy the easy conditions, but it satisfies phi1 equals 1. And the ideal J by F data is compatible with split. So, this principal ideal. Now, that's really easy to see. So, this is also easy to see, but this is really easy to see. So, if I have somebody hit that ideal, then it's of the form f times something. So, then I take it, and I multiply it by this, and now it's got f to the b times something. So I can pull the f out, which is. Out, which is the statements that I stayed in that idea. So what order do you have to leave in term in? Doesn't matter. Any leaving terminal. Any order such that any binomial order. Yes. Okay. That that seems to be deep and signed. Right. So that's why it's a condition. Right? So that's why it's a condition. If you take the really obvious example of this, where f simply is a product of variables, then you run into the standard splitting of this end. Okay, so remember the example from before where I had negative E plus AC? Negative B plus AC and B. So the hypers, so I'm going to take F to be that product, and then the leading term will be the products of the variables. That was an example. And so in particular, in that case, the six things that we got, three factorial things that we built from that, were all compatibly split with respect to the splitting this guy defines. So here's now the sigmatoric degeneration part of things. If I is highly split, so I inside our polynomial ring is compatibly split. With respect to this splitting VF that we just find over here, then init I is compatibly split with respects to V of init F and therefore is Stanley reasonable. Is standard reason. So, it's a minimum value. Sorry. Square-free minimum value. So, what's happening? We're taking the F that's so what the F looks like is it's got this one so here. This one, or so here's the Newton polytope of F. It's got this one corner, it's the all-ones corner, and it's got a bunch of other stuff. And I'm going to degenerate f to just being this single term product of the variables. While I'm doing that, while I'm moving the f, I'll follow the i at the same time. And I have this closed condition that says that i is compatibly split with respect to f. I is compatibly split with respect to F. And so in this family, as the I is moving and the F is moving, it's staying compatibly split. And so then, because that's a closed condition when I'm done, I have this thing is compatibly split with respect to this limit guy here. But this limit guy here was chosen to be just getting the standard splitting. And the compatibly split things with respect to that are the monovial ideals, square-free monomial ideals. So one's used to things being becoming bad in taking these limits. And so you just have one thing to check doesn't become bad, which is that the F doesn't become bad. And then everybody who's rebuilt out of the F by taking these, by running that intersective compose algorithm, for example, all those things that you built, they also will not become bad because they're constrained by. Uh because they're constrained by splitting respects family ones. So the principal thing that's tricky in my paper is establishing this, is saying if you take the union of the divisors in G mod B, and you pull them back along M tilde, and you end up inside. Tilde, and you end up inside this affine space, you want to know that that union, the equation defining that reducible divisor, has this property. And so that's a certain SL2 calculation. And because it's just an SL2 calculation, it works for counts of groups. All the varieties I was talking about were finite-dimensional, but you But you can do it in a case when G mod B is infinite dimensional. Alright, so where does this fit in with the T Poisson story? So I got a hold of this F. Well, here I just said, if you have an F with this nice property, then that's good. But before I was getting a hold of these anti-canonical divisors, Canonical divisors on affine space from the t force on structure rather than from writing down a function, vanishing on them. And you can imagine as you're deject, instead of taking this term order, this cleverly chosen term order that's maximized at this point instead of at some other point, instead of using that so that waiting on your variables to degenerate f, use it to degenerate your original Poisson structure. Poisson structure. And then the statement to figure out is that the Poisson structure degenerates to a standard one, where the Poisson bracket of xi and xj is just a multiple of xi times xj, rather than somewhat complicated component of that. So if you get that, so those, there's this extremely infelicitous terminology. Poisson structures such that Poisson structures with the property of xi, xg. Structures with the property that xi xj is just some number times xi xj. These are called a log canonical. So the canonical is from this quantum mechanical terminology about canonical commutation relations. And that would be so that would be about like the bracket of x, i, and x, j, the, and. Like the bracket of xi and xj being a constant, right, like in the Eisenberg religion. But the log canonical is that log xi and log xj satisfy the canonical commutation relations. This has nothing to do with log canonical as used by the mineral model program people. Even though that concept ends up being tightly related to the Frobenius splitting. The Frobenius splitting, the pattern split, the sub-variety set. So be on the lookout for that. Let's see. Provisional this time. Oh yeah. So what you get for free in this story once you have this condition is all these things degenerating to standard user ideals. What you don't get for Ideals. What you don't get for free is knowing the generators of those ideals. So you'll know they'll be square-free, but what are they? One thing you do get, I said, so let's see. If I have two compatibly split ideals, then their intersection will be compatibly split. So I degenerate that, and that'll still be radical. So that was this thing I was saying before, that we won't have two of our compatibly split sub-varieties end up falling on top of each other. Falling on top of each other as we take these limits. So, given any coordinate subspace and the limit, you can ask which of the compatibly split sub-varieties did it come from. Actually, let me give you a hint about where you find compatibly split sub-varieties. So, of course, this was the intersect decompose algorithm. So, theorem, this is me with This is me with Thomas Lamb and David Speyer. If starting from this anti-canonical, starting from this f equals zero, if all the sub-varieties constructed Constructed by this intersect decompose algorithm if they're all normal. So I argued with this that when you intersect, that's that, when you decompose, that's that, that you'll keep meeting comatally split sub-varieties. Sub-varieties. And if these we need are all normal, then they are all the Adelaide sub-varieties. So it's a classic theorem now. I think of Roman Elfin from the 80s that tubert varieties are normal. Two is in fact. It two is, in fact, I think originally proven with through Benia splitting techniques. So that's enough to guarantee that in the bot sample example, the M tilde example I was seeing before, I was in fact meeting all of the compatibility spit sub varieties. Oh, for this? Yeah. Yeah, let's see. So we write it as a slightly different algorithm. We say consider pairs of a sub-variety and what will And what will be its boundary, which is the anti-canonical, split, anti-canonical divisor in that sub-variety. And the notion of being anti-canonical is, of course, easy to describe on somebody smooth, harder to describe on somebody normal, and much less pleasant to think about on somebody abnormal. So, what we say is: if you've got a, so if you have one of these things, and So if you have one of these things and you have this anti-canonical divisor in it, where this guy is irreducible and this is the rest of this anti-canonical divisor, then the next step you're going to work with is with this component and its intersection with the rest. And so using the normality and using the adjunction formula, we prove that this thing will be anti-canonical inside here and work our way down from there. And work our way down from there. And then you can say, you know, if I have a, if I have a mountains with sub-variety, then it'll be contained inside the smallest one of the things that I've met so far, and then figure out that you'll actually necessarily be it. That last bit is where you see it all over. Yeah. So, what's going on in this picture? If we think about the dumbest case of all this, which is a drawback variety, where the Variety, where the anti-canonical divisor is the boundary of the toric variety, is the complement of the open orbit. The way you should picture this is: I've got like a polyhedron, and on my polyhedron, I have one face and the rest of the faces. And I say, instead of thinking about this 3D guy and it's one face on it and the rest of the faces, I'll take that one face and intersect that one face with the rest of the faces, and I will get the boundary of that single face. And then we'll get the boundary of that single face. So that's a way of going from boundary here to boundary face by face, and then it keeps going down from there. All right, so the very last thing is... So what I was dealing with was I had this vector space and I did this lex init of the vector space and it stayed a vector space. I mean there wasn't a, this wasn't very interesting. This wasn't very interesting on the level of varieties, but it's interesting on the level of varieties with a Poisson structure, with a Frogenia splitting, with the stratification. So the ambient thing wasn't, nothing was happening there, but inside it, the sub-varieties are doing something interesting. Alright, so this lives inside the entire Botsamuson, and this degenerates to a toric variety. A toric variety, in fact, a smooth toric variety. So remember that this guy is defined as this parabolic, mod V, parabolic, mod V, P1, P2, whatever. So in this paper by Grossberg and Kershaw, They thanked Peter Matyar for clarifying the form of the degeneration of this to that. So, what Peter Matyar suggested was instead of a B action here and a B action here, instead of dividing by a diagonal B, let's take that diagonal. So the diagonal B is pairs BD. Great? Let's Let's take that and move it using a circle to B. Instead, the pairs B and B gets conjugated by row check of T of B. So row check is a matrix like T, T squared, T cubed or Or there's an analogous thing like this for other groups in geometric. So it says first conjugate by mat. That'll suppress what's happening in the upper triangle here. When you take the limit as t goes to zero, then instead of having a pair of upper triangular matrices that are equal, you'll have an upper triangular matrix and a diagonal matrix, and only the diagonals are equal. And as you do that, then what's nice is that that group is. nice is that that group is normal inside the B cross B and so when you take the quotient by that you get the Kivatorus action. So the problem is that we're taking invariance by a family of different groups and that's a family of subrings and that's not what we mean by an algebraic family, which should be a family of sub-schemes or a family of ideals, not subschemes. Or a family of ideals, not subreigns. So the first person who really writes down what this looks like as a family and describes the total space of this family as a scheme is Par Michoir. So, but definitely building on the inspiration first from Peter Matiard and And as made use of by Rosberg and Trashan. And Poskier gets close, he gets a hold of this thing as algebraic space, but not as a scheme. But if you want to see it as a scheme, we'll leave it. What's going on in this story? Analogous to the theorems I was telling you about degenerating into a subword complex. So this guy is degenerating into a very simple kind. Into a very simple kind of polytopia. It's practically a cube. It's got two to the cube, any fixed points. Combinatorially, it looks like a cube. If you follow one of the n tilde inverse of xw's, the analog in here, it's just n inverse of xw's, if you follow it under that, then it'll degenerate to a union of sub-cubes. So we'll have this cube. And here's this top point on the cube. And here's this top point on the cube. And we'll get a union of subcubes there. Maybe this one and that one. And all of those subcubes will touch the top point. And now people don't talk about... Sorry, what did it rates to those? So in here, I've got this m inverse of x double. Right, that m being my map to solve. So it degenerates to a union of cubes, and it's got to do that because it's going to be. This was a Grogner degeneration, had the full torus action. You can follow sub-values, and it'll end up being torus variable and begun. You can follow the hand canonical divisor, and it will generate to the boundary of this guy. So, all the families splitting technology will tell you things stay reduced. You follow a particular one of these, you'll get some bunch of sub-cubes. Turns out all those sub-cubes talk. Turns out all those subcubes touch the top point. If you just look at what's happening nearby that top point, like you snip it off, you'll see a simplex. And so that's where you see the simplicial complex, which is the subgroup complex that we're telling Let's come. All right. Thanks. Any questions?