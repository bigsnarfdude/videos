Professor Andrew Yori and she's going to be talking about zero density for the Riemann Zeta function. Hello everyone and thank you for organizing this event. I'm going to talk about the zero density for the Riemann Zeta function. My talk consists of introduction and motivation, history, and then at the end I'm going to tell you a bit about the stage of groups. Uh zeta function is a very important function in mathematics. Uh let s be a complex number with sigma its real number and t its imaginary parts. Then we define the zeta function as the below summation. We have zeta of s is equal to the summation of 1 over n to the s and from 1 to infinity for all sigma is greater than 1. And for the remainder of the complex And for the remainder of the complex play, it is defined as the analytic configuration of the above function. The study of the zeros of the zeta function plays an important role in number theory, analytical number theory. Riemann hypothesis is about the locations of the zeros of the zeta function, and according to this hypothesis, According to this hypothesis, as you can see in the picture, Zeta of S has trivial zeros at negative even integers, like minus 2, minus 4, and etc. and no other real zeros. And other non-real zeros, which we call non-trivial zeros, lie on the critical line. And still now it is an open problem. So, what is our motivation? The zeros of the zeta function are The zeros of the zeta function are intimately connected to the distribution of prime numbers. For example, an exclusive formula and a study of the zeros of the zeta function lead to this estimate here, where pi of x is the number of primes less than or equal to x, and log of x is the logarithmic integral function defined by the integral of 1 over log of t from 2 to x. And the shape and colour. The shape and constant here that we have in the error term are determined by what we can prove about the number and locations of the zeros. Zero density. We define n of sigma and t as the number of zeros, number of non-trivial zeros of zeta function, and with real parts greater than sigma and imaginary parts between zero and t. So that sigma is between half and half. Let sigma is between half and one, and t from zero to infinity. So we have n of sigma and t is equal to the number of a rho, which zeta of rho is equal to zero, and gamma is between zero and t and beta is between sigma and one. I want to find an explicit upper bound for n of sigma and t with this rectangle region. And this type of result is kind. And this type of result is commonly referred to as a zero density result. From paper that I read is about tediary lonely and ink, bounds on L of sigma and t often take the shape of this inequality. And my goal is to improve both bounds for C1 of sigma and also I want to change slightly the shape of the bound. The shape of the map. Now, I want to tell you a bit about the history for the zero density. There have been several authors who have worked on the zero density. The first one, in 1930, Boehr and London proved that n of sigma n t has this error term here, s t goes to infinity. And in 1937, England showed that n of sigma n t has this. N of sigma n t has this error term here by assuming that zeta half plus i t is equal to w of t to the c plus epsilon. Ramarin had proven an explicit version of England's bound. For example, if you put sigma is equal to 0.9 in England's bound, we have this inequality here. And everybody Habiba, Lisa, and Nathan have presented a result that provides a tighter bound for N of sigma T, and their result improves upon both Rameri and Ingham's estimates by following Ingom's argument by using a general based function. For example, if we put sigma is equal to 0.9 for their bound, we can see that this is their inequality. This is their inequality, and if you want to compare these two with each other, you can easily see that their bound improves the Ramari's and Ingong's bound. Now, I'm going to tell you about the idea of proof. I only present an outline of the proof which Happy Van Atin and Alisa use, and my approach will be to follow their proof but improve on it by using. On but improve on it by using new results established since our publication. The main idea for finding an upper bound for the N of C1T is multiplying Zeta of S into an entire function that we call it P of S, which is equal to 2 minus Zeta of S times M of S and M of S, where M of S is a moly formula. And let F of s is equal to Zeta of S times is equal to zeta of s times m of s minus 1 and we can write the f of s as a below Birchless series. So we have f of s is equal to the summation of lambda n over n to the s for n which are greater than 1. So we have the final function which is h of s and we can define h of s as these three equations. Equation and since any zeros of the zeta function is zeros of the new function h, so our goal becomes to find an upper bound for the new function h. And this means the key thing here is to replace the function ZHAPS with the new function h and count the zeros for this function. There exist many useful tools for counting as Tools for counting zeros for the holomorphic function in a rectangle region. And in my thesis, I use the classic idea of Bohr and Lambda, which is stated in Titmosch, and which uses the residue theorem. We can bound the number of zeros by those following integrals. So, for n of sigma t, we have this inequality here, which consists of four different integrals. And my goal becomes to find an upper bound for each integral. And as t grows larger, their main contribution arises from the first integral. And now I will give an idea of how to simulate each integral. What is h? H is a new function. Now a large h. Large h? Cat h. Oh, we wanna find the integral from h to t. H is something H is somehow three times ten to the power of H. Yeah, like that's the dynamic for the partial representation. It's a constant determined by it's in imaginary parts. If you have the real part and imaginary part, from zero to t, you want to find the count the zeros in this rectangle t from H to T. But the why gonna start at one. This is what I'm gonna the Renaissance hypothesis is not up to H. This is not up to H. Can we be computed very much? Up to H? Up to 3 times 10 to the power. Okay, and it gives a difference in the computation? It gives a difference on the explicit constant, is what you're saying? To put H in the alpha. So, about the first integral, the smoothing, unsmoothing method, and Smoothing or a smoothing method and convexity estimate is used for finding about for the first integral. For any f non-negative, and since we have h of s is less than or equal to 1 plus f squared, we have this inequality here. So if we want to find an upper bound for our first integral, we can find an upper bound for the inner integral here, which we have. One idea to find an upper bound for integral of find an upper bound for integral of f of sigma plus i t square from h to t is we can try a smoothing method, smoothing another smoothing method. By using a smoothing method, we introduce the general weight function g as a characteristic function and we can multiply to our to our function f which becomes more easy to analyze the integral of the smooth function rather than the original one. So by a smoothing method we have this inequality smoothing method we have this inequality here and omega 2 is a positive function that depends on the g and now the goal is become now the goal becomes to find an upper bound for the smooth function unsmoothing seems to involve reversing or inverting the process of smoothing, so by unsmoothing method we can obtain the bound for a smooth function. For a smooth function. And the thing here is: if you have a bound for f of sigma and t, we can find the bound for the smooth function. Since the error-time arrows here is this segment, omega 1 times this integral, so one way to make the estimate tighter, we can choose another general weight function. Nevertheless, this is an Nevertheless, it is an open problem to estimate what is the best function for this problem. Since the goal is to find an upper bound for the smooth function, one way to find an upper bound for this smooth function at sigma is we can use the convexity theorem. Because by using the unsmoothing method, we can find a good bound for a smooth function at sigma 1, which is half unsmooted. function at sigma 1 which is half and sigma 2 which is 1 plus epsilon. And based on the convexity estimate we can find the bound for a smooth function at sigma. Convexity estimate tells us this inequality. So by unsmoothing method we can find the bound for these two and based on the convexity we can find the whole bound for J of sigma. It means if we have something like this. This is our half line and this is our sigma. Half-line, and this is our sigma, and this is our one. If we want to find the bound for our function on sigma, first of all, we smooth the function at sigma, then we use the convexity to make it find the bound on half and one, and at the end we unsmooth the function to have the bound for a signal. So, for reusing the convexity, we need both bound and We need both bounds. First of all, we need estimates on the half-line, and the other one is estimates on the one possess epsilon. For the half-line, we need two key inputs. The first one is bounds for zeta function on the critical line. That's Habibal and Atten Analysis use the below bound here. They use this bound for Zeta of S on the half line. And to improve the final bound, we can substitute the. We can substitute the improved bound by Petel and Yank, if I pronounce the name correct. And they have this inequality. So if I substitute this bound instead of their bound, we can improve the final bound. And then the second key inputs here is bound for the modifier and the critical line, which we have this one here. And about the sigma 2. And about the sigma 2, based on the expansion that we have for f, we can write f of sigma 2 and t like this summation. So the idea for finding an upper bound for this one, for this integral, is using the mean-value theorem for Dirichlet polynomials. And also, we will use this idea to find an upper bound for the fourth integral 2. So, with combining the bounds that we obtained for J of sigma 1 and J of sigma 2 from unsmoothing method and applying the convexity estimate, we can find the bound for J of sigma. And then we substitute the bound for J of sigma in the smoothing method. And finally, based on the results and bounds that we obtain from these three methods, we can provide a bound for F of sigma and t, which we have this inequality. So F of sigma and t. So f of sigma and t is less than or equal to j of sigma over omega 2. And if we compute everything, we have this inequality for the first integral. Second and third integral. The second and third integral is about finding an upper bound for the difference between these two each other, which is less than or equal to this statement. So if we want to find an upper bound for the difference. An upper bound for the difference of these two integrals, we can find a bound for the summation of absolute value of these two with each other. The last integral, as I said, it's like somehow like the thing that we had in the first integral. So we want to find the upper bound for minus integral log of h of mu plus i t from h to t, or we can find the lower bound for the positive one. Lower bound for the positive one. So, this is very similar to bounding the f of sigma 2 and t. And the idea is somehow similar. So, the general idea for finding this bound is use the standard mean value for Bounce La polynomials. And therefore, we have the blue bound for the last integral here. And finally, after these steps, I'm able to compile all the bounds that I have and find. Bounds that I have and find the bounds for the n of sig1 and t and thank you all. 