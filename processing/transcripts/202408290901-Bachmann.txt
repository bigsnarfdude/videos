   All right, I apologize for the late start. We are very happy to have Tom Ackman tell us about duality and residual future sessions. Well, thank you. Thank you very much, I guess, for writing this paper with me. But also, I mean, for inviting me to what is certainly the most significant conference location I've ever been to. It's been fantastic so far. Okay, yes. Um okay, yes. So I wanted to say something which is possibly related to the theme of the conference. I thought that's that's often a good news. And so I want to promise that this will be, but maybe only towards the end. So yes, so I want to tell you some story about growth and deep duality. It's basically some algebraic geometry thing. So I guess it's a good direction of geometry. And basically I want to tell you how the growth indeed duality theory works versus Duality theory works for something called a residual influence. And well, I will admit that Groton Deek duality is not maybe my strongest subject. So to warm up, both me and maybe some of you, I want to explain the case of a regular immersion first. Okay, and so for this, I will start unsurprisingly with a regular version. And uh what this means, of course. And what this means, of course, is that X is a scheme. Maybe I'll assume it to be Gorenstein. And Z is a closed sub-scheme. And locally around Z, this guy is defined by a number of equations. And that number of equations is the same as the codimension. So it's defined by a regular sequence. That's why it's called a regular diversion. And I mean, maybe when I'm saying Gorenstein, I'm already saying it's locally no theory, so I'm not doing any basic non-etheri. Generalization is probably something that. Generalization is probably something that we said, but even for the most classical geometry, it's sort of innovative enough. And so then a bunch of things happen. So I will write I for, well, the ideal Xi of defining this Z. And I write C of Z over X. Okay, this is the co-normal sheaf. Okay, this is the conormal sheaf, and this is just I take my sheaf i, which is an x, and I pull it back to z. In other words, this is just i mod i squared, where you observe that this guy is a module over, of course, Ox mod I, which is also known as OZ. So that's how he lets this stuff. Okay, this is completely well-known stuff. And what it turns out is that this guy is local. And what it turns out is that this guy is locally framed. The locally frame of Z module. Okay? In fact, in fact, if I put myself into some local situation where z is cut out by sort of some number of equations, let's say a1 up to a c, which is exactly the. Which is exactly the codimension, then these A's, of course, they live in I, and there are classes in here, they will be a basis. All right, and so now actually I should come to the duality, right? And so my duality factor is going to be B and it's the function. And is the functor of sort of derived harms from whatever into OX. Okay, that seems like a pretty reasonable definition of taking the dual, right? And what's going to happen is that if I look at the dual of all z Okay, that's that's some sort of coherent sheet on X. I can do this R-hong thing, I get some kind of complex out of it. And what I will do is I will shift it up by the codimension. And what I really mean here, of course, is the rank of this dual thing, it will be an OZ module, so in particular supported on Z, right? And this And this conomal sheaf, right, is some locally free sheaf. And what this C here means is the locally constant integer, which is the rank of this sheaf. I mean, basically, I think you can always pretend this is just some constant. I will always pretend that. But for example, if you take the disjoint union of two regular immersions of different co-dimensions, it's still allowed. And then this thing. You mean I lower star would call that this. Yeah, that's the other thing, right? I mean, I could put this ILOR star here. Probably I should. But on the other hand, it seems also pretty fair to call this in the white spot. Seems also pretty fair to call this in a white model. But yes, yes, actually. And one can determine what this is, right? So it turns out to be you take the determinant of your co-normal function, you take the dual of that, and maybe now let me write this here. Okay, so the determinant as an OZ module, but of course, right? It's a finite locally free thing, so it just means some exterior power of this guy. So it will be some line by. Of this guy, so there will be some line band on Z, and you just push it forward, okay? And it turns out that these two things will be the same. And that's in some sense the Groten Deep duality statement in the situation. Let me write any questions so far? So the sigma C was just the shift normally would be okay. But for the algebraic geometry, this the topologist might do it. Oh, okay. Oh, okay. I try to. Okay, okay. So now let me explain one thing that is nice about this, right? What do you mean by this physical complete? This says that if you put I lower star cox, the right tangent of I lower star is I average. Yeah, that's what I'm going to get. I average is. I mean, I think this is some sort of duality theorem, and I'm going to explain now how maybe I can make it look more complicated, but I feel like this is sort of a primitive statement. So I'm going to recall that I have this functor i upper star, which I've already used, I guess, maybe, have you not? And it's right adjoint to this functor I lower star, which I've surely used. And this has another exceptional right adjoint, which is this I upper shooter. And in the case of a And in the case of a closed version, one knows exactly what this I-urshriek is. It's basically, one has I-apper shriek of something. It's always going to be, I do this R harm from my guy, I know from OZ, I know a star of OZ into my guy. And I view this as an OZ module via this. View this as an OZ module via this first variable, and in this way it defines the complex on Z. So that's what high upper stream is. And if I reread this thing here, then what I learn is that what I learn is that I have a shriek, half O X is determinant polynomial sheet z over x dualized. z over x dualized shifted by minus c. Okay, maybe that looks more palatably like we wanted the duality statement because it involves most exceptional functions. And then I can use this, for example, I can use this to push around symmetric bilinear forms. So for example, I can see I can start with this thing here. Okay, what is that supposed to mean? Basically, it's supposed to mean symmetric bilinear forms on Z, but they don't take values in OZ, they take values in this thing. Now, of course, this is a complex, it's not at all concentrated degree zero, so really. Not at all concentrated in PB0, so really you have to think of complexes with a symmetric bilinear form. And let's assume for safety that 2 is invertible in Z, so that we don't have to get into this whole mess. But yeah, one can make sense of this kind of thing, and then you sort of completed some commission k theory of growth. Alright, so in there, basically, you get something like class of some complex M, and this M has a map, M tensor M goes to this thing here. No. No. And this has to be symmetric, and the induced map from M into the harms into I upper street low x, this should be an equivalence. That's what the symmetric bilinear form is. And now I could apply my functor i lower star, okay? And I claim that I get another symmetric bilinear form, this time what x, but This time what x with coefficients table. Oh, x, oh yes. There's a minus 0. Yes. Right, I mean, it's just that you have this map m tensor m to i upper 3 o x. I upper 3 is right adjoint to i lower star. So you get, out of this here, you get a map i lower star m tensor well close to all x and then this i X and then this I lo I lost star is a lax symmetric minority that's being right adjoint to a symmetric minority function I upper star and so there's I lost draw m tens I lost draw m here and the composite looks like some sort of symmetric bilinear form on m. You still have to convince yourself that it will remain non-degenerate and symmetrical, but you can. This will all happen. And I mean you can play similar games if you have a smooth proper morphism, you can use grotto duality for these kinds of You include growth and digitality for these kinds of morphisms. You can push forward symmetric bilinear forms on the big variety to the small one. And here I do a similar thing. So a regular merge and I can push forward a symmetric bilinear form on the small one to the big one. Okay, I want to claim that's an interesting thing. Any questions so far? Great. It seems like you have not obtained a binary form. Obtain a bilinear form on sheaves on X. No, no, I'm not making a bilinear form on X. I'm saying if I have a bilinear form, I mean not on the category of sheaves, just examples of symmetric bilinear forms in these sheaves, the map of groups. Yeah. Take a bilinear form on Z and make a bilinear form on X. What does a bilinear form on X give you? It's a map of a complex, Hetzer complex form. That's sort of complex. One fixed column that. That's a but not a category, it's an object in oh, just like for vectors, basically say quite bigger vector. Yes, yeah, that's a quite large. Okay, and so basically, ah, right, there's one more thing which I wanted to say about this, which is how does this work? Okay, this is a reminder about how growth indeed duality works. One way of explaining this, probably not the best, but the one which I can sort of understand. So let's begin. Okay, right, so there are two things which are supposed to be isomorphic, and both of them are like cheap. And both of them are like sheaves of complexes, so making an isomorphism is maybe not super trivial. But let's begin locally, okay, and then try to work from there. Now, locally, this I thing is generated by my regular sequence. And now, strategically, what am I supposed to do? I'm supposed to compute some derived form from i lower star oz. form from I lower star OZ into OX. Now there are two things I can do. I can try to resolve this guy injectively or I can try to resolve this guy projectively. Now surely writing out an injective resolution I'm not going to manage, so I have to write out a projective resolution of this guy. And then I can, okay, right? So you know of course what to do, you take the cosuit complex. As a cosuit complex guy and this is some complex in the lowest term I get y. the lowest term I get Ox and then I get Ox to the C. And this map here I can tell you quickly, right, is just the corresponds to C elements in Ox and the elements are obviously the A's. And then there's the next term which is lambda squared of Ox to the C. So this is some other free module, okay, of some higher rank. And there's a map which you can put there, I don't care. I have to put the correct ones, of course. And it goes up to a lambda C of. Up to a lambda c of O x over C, which is just O X again, and then it stops. This guy has a map down to OZ, right? Just OX maps to OZ, and obviously the relations that you've enforced are precisely what you want to get. So in pi 0, obviously, this will be an ISO. And the whole point of the regular sequence in Cosu complex story is that this is a quasi-iso, or it's a resolution. This is a free resolution. Maybe this is a previous solution. And what this means is that I can compute this dual guy here. Well, it's going to be sigma c of the dual of the Pausi complex. All right, but I mean, that just means the dual of O is again O. So basically, you're just turning. Basically, you're just turning, replacing this term by this term, and this term by this term, and so on. But look, OX is also the same thing as sigma c of O x to the C, and so on. So there's some symmetry going on here. And some classical story that, in fact, this complex is isomorphic to its own via some symmetrical linear formality. So this is, in fact, just the Passover complex again, which is in fact just O Z. Z, which is what we were supposed to get, right? Okay, we're supposed to get some line bandwidth, but this line band is trivial because I've told you that these guys here make a basis for this. So this is no trivial. So I have the, it looks right, but I mean, it depends on my choices, apparently, and it's only a local statement, right? I'm supposed to make a global statement. For example, if I had written OZ here instead of OZ here instead of this determinant thing, then the same proof would work. But the global statement would be false. So you have to contend with that. And this is as follows. I can consider the following map. I lower star of this determinant guy. Still working locally. Now I trivialize this. Now I trivialize this, y up my A1 after AC. And this is just OZ. And this is, where am I going? Yes, so this is equivalent to the Kausul complex. And now the Causoul complex, it has a canonical map to sigma c of Ox, right? It's just projecting to this highest term. So there's a funny map here. Finn map here, I wanted to write this, right? So all x. Now this is already quite interesting, right, to have produced this kind of huge extension. But I mean, of course, two complex basically is an extension. And so I've made this map here, okay. And it depends, by construction, on the choice of these A C's Choice of this AC. But what you can check is that actually it does not. Okay? And moreover, what does this mean, right? Is this a map in some infinity or derived category? So if I take a different choice, what I'm saying is that these maps will become momentum. But more is true. You can look at the entire space of maps from this guy to this guy. But locally, I mean, we've worked here, right? So you already know what the dual is. And so what you can convince yourself of is that this space is actually discrete, which just maps from OZ to OZ. And what this tells you is that even though normally in an infinity category you have to be very careful with saying the two things are equal, here you don't. Are equal. Here you dot. The space in which we're working is discrete. And in particular, now let me work globally again, okay? So then I cannot do this, but I can still look at this space of maps. And I can view this as a sort of a sheaf of spaces on X. And this sheaf is discrete, right? Because locally I can always do this kind of thing. And so it's locally discrete, and so it's globally discrete. And so, in particular, if I want to exhibit a point of it, it will be enough to exhibit. It, it will be enough to exhibit points locally which, well, catch together at the intersections. There's no higher coherence problem. And because, well, this thing was read by independent choices, it tells me that these maps here, they glue together to a global map of the same signature. And this is called the trace map. Isn't it just a little easier? Because you're just saying that the change of coordinates in the scribe in the C-spirals in your decks is the same as the change of coordinates on rho C, the O and C. Right. That's exactly why it's independent of this choice. Now I want to glue them together. No, but you don't have to glue them together. But I mean, like, if X is big, then maybe such a regular sequence doesn't. Then maybe such a regular sequence doesn't exist. Yeah, but you can change the coordinates of the different frameworks. Voices that you reflect changes in coordinates of the signals. I think that's enough, that's what I'm saying. Okay. Well, that means that I make an open cover and everywhere I have a map. And if I go to the intersection, I have a homotopy between them. Presumably, maybe several of them. Yeah. Because you could have used different regular. Because you could have used different regular sequences on these things, right? Now, if this were arbitrary sheaves of complexes, then you would. This is not enough data to glue them together to get a map. I think it works. I think there's an elementary. I don't know. Probably you're right. I try to think about it like this, and then I feel safe knowing that there's a discrete space. Anyway, this map. And so I have this map, and this is an OZ module, and so you can add join basically over the module structure, and I'm space and time. So we get this thing. So maybe I'll just work here for a second. So the point is just I can add join over this sort of map over the tensor I know a star with determinant like this number I know a star here right sheet. And then there's another error star here, right? Oh, I see what I see. You get a global section in H0 of sheet X, but that's all there is in the souls. Okay, so I take this composite here, I just use the module structure. Composite here, right? Just use the module structure and then apply my trace map. And I can now adjoin this over to a map from I lower star determinant of the Ponon machine, dual to R on from this to this, which was the dual of Z shifted by C. Okay? C. Okay? And so this is now some map which locally induces these equivalences and it's completely well-defined. So it's a completely well-defined canonical equivalence. That's somehow the story. This is the story for the regular immersions. And I wanted to very quickly review and spend half my talk on it. Okay, so if there are no questions, I'm going to press on to go to page two of four. We started five minutes later. Yeah, but I still have to not talk so much nonsense. Right, so I want to now come to the actual point, because I assume most of you basically know this, and it's also in many books and so on. So I want to talk about these residual intersections and their duality to them. This is more complicated. Okay, so I just said I don't want to talk so much nonsense, but maybe I want to talk a little bit nonsense before I get into the nitty-gritty. So what's the residual intersection? And basically, what you do is suppose you have some enumerative geometry problem where you want to count some things. And you know there's only finitely many of these things, and you just want to know how many there are. Well, you need to describe this modulized space of the finitely many things, maybe in terms of equations or something like that. And that's hard. Like that. And that's hard, right? And so you do your best. And you do your best. You find some equations, and they seem to be pretty good at describing the modules space. And then you do the computation, or you look at some examples, and what you find is that you sort of get a picture like this. Well, this is going to be a parallel picture. Going to be something like this. So you get a bunch of points, and these are the things which are the ones which you actually want to count. And then maybe you get some claim or something. Like there's something which clearly shouldn't be there, it's just too big. Be there, it's just too big, but like the equations which you managed to write down maybe because they're sort of symmetric, unfortunately they also have this thing in it. And then you say to yourself, Well, I mean, come on, man, just remove this plane. I mean, how hard can it be? So you remove this plane somehow, and what you're left with is just these points. Okay, so that's the guy which you actually wanted to know something about, and that's the guy which you somehow can describe. And that this year, this is some algebraic way of. This here, this is some algebraic way of removing some component. It's usually implemented using an ideal quotient. And if you do this, then in some situations, what you're left with is called a residual intersection. Moving is more subtle. Yeah, the removing is very subtle. And in particular, this picture is misleading in very many ways. But this is how I imagine it should go. How I imagine it should go. For example, right, it is not at all obvious, right? I mean, this looks like just three points embedded into some plane. Obviously, that's a regular merge. But in general, it's not at all obvious that if you have a residual intersection, that the map to the ambient space is a regular merge. And in fact, it's false. But, and I guess the thing which got this whole thing sort of started at some point, well, I'm not saying it's quite started. Well, I'm not saying it's quite solid, but okay, there's an interesting theorem due to some guy called Fulrich. And what he proves is that this residual intersection under certain very strange hypotheses, I mean to me very strange hypothesis, but I'm just going to run with them. This residual intersection is called Macaulay. So it has a dualizing complex, which is concentrated in one degree. And in fact, he can give an expression for this dualizing complex in terms of the residual intersection. And that suggests that you should be able to do this kind of theory here, right? Able to do this kind of theory here, right? I mean, basically, he's done it. Except not quite, right? Because if you, if you, there's not really their dualizing complex or their dualizing sheet. It's only well-defined up to non-canonical isomorphism. And so you give some expression for this thing, but it's not canonical, and so you cannot view it together. And one of the things which Kirsten I have done is to make the expression that Bernd Ulrich comes up with, with the Eisenberg together, I guess, to make this expression more canonical, and then to Expression more canonical and then to globalize it. And this is what I want to explain. But, right, now I actually have to give you some definitions. But that's the goal. Okay, so I have. Okay, so I have R is some Korenstein ring and then I will have some idea I here and I have some idea J in here and this guy is of codimension maybe G. Maybe g and this guy here is generated by s elements where s is bigger than g, or equal to g. Okay, and then there will be k, which is the idea quotient. That you said what you right so. Oh yes, I'm sorry, S. Ready, equal to G. k is this ideal quotient now of course you all know what an ideal quotient is but let's just put it in there to remind me so this is the set of all elements r and r such that r times i is contained in j. Okay, so this comes up, for example, in primary decompositions and well it implements this sort of picture. Well, it implements this sort of picture. Okay, so you say I is codimension G in sub-scheme R, pure codimension G. Or codimension, each component has codimension. I think each component has codimension greater than or equal to T. For expecting point on this, you expect the co-dimension to be two, which You expect the co-dimension to be 2, but you have 3, but you have this plane. But J is the whole thing, right? And I is the plane. I is the whole thing. I is the whole plane. Right? So we have... But what is true is that Z of J is, as I said, the union of Z of K and Z of I. So in our picture, this is the plane with the points. This is hopefully just the points. Just the points, this is just the plane. Okay, but I mean, this is only true set theoretically, and I mean, also, right? You could in principle be bigger, but that's that's the hope that it follows. These could be embedded points, or you really get that point. Okay. And now I should tell you when it's the definition. Oh, this should have been, of course, local. I'm sorry. Okay, and then K is called an S-residual intersection. And K is called an S-residual intersection. If the codimension is at least S. Okay, so it's some guy generated by S element. So it's some guy generated by S element, so you might think the co-dimension should be S, but okay, unfortunately it's not. Then you remove something else, which is of smaller co-dimension, and then you get to the desired co-dimension. And that's when you call this k-thing, which is left over. This is then called a residual interstation. I'm not super sure, convinced that this terminology makes entire absolute sense to me, but that's how it's called. It's called. And there's one trivial example to keep in mind, which is where you take a regular immersion. So, like this. So, there's a trivial example, which is that J is in fact generated by a regular sequence. And then I can take I to be A, and then K is also J. And this satisfies the assumption of a residual intersection. So this is a proper generalization of the notion of a regular motion. Let's capital A. Just something. Oh, R. I'm sorry. Yes. Okay. And so the first thing which I want to do is I want to immediately globalize this notion. I'm going to give you some definition, but it's not at all obvious that this is well behaved, but I just claim that this will work. And so, okay, so let XP a Gaur instinct scheme which I think means is locally Noetherian and all the local rings are Borenstein rings. And then I have some ideal sheaves, j contain i contain x, phi contain j. 10 people X, 5 is for your idea of Sheaves. And I set K to be the ideal quotient. Okay? And this is called the residual, we call this a residual intersection. If for all points back of all x mod k maybe I call this back to dimension in x In x plus q is greater than or equal to the minimal number of generators of J localized at x. Um so there are a bunch of things to look at. So there are a bunch of things to say here. The first is that over here we have a notion of an s-residual intersection, and here I just call it a residual intersection. And the reason is that actually this number s is determined by the rest. Somehow it looks like you have a choice, but you don't. And I'm going to explain this in a little bit. And this is already baked into this definition here. The other thing is, it's not obvious that if you take this S-residual intersection, If you take this S-residual intersection here and some local Gorenstein ring, it will satisfy this. But it does. Again, yeah, so this is a correct definition, but it's not obvious that this is correct. Sorry. This idea J localize. I just look at the local situation, right, and I ask all of them to be residual intersections. And then this number of generators, of course, it changes depending on which point you look at. It changes depending on which point you look at. Yeah, but you want all of them to satisfy this each logo. Okay. Ah, okay. So now I just want to mention something which is called Mention something which is called the standard hypothesis. So these exist, but I'm not going to tell you what they are. So Eisenbach and Ulrich in their paper on residual intersections, in this sort of situation here, they define something called the weak hypothesis and the standard hypothesis and the strong hypothesis. Okay, and they basically mean nothing to me and I'm just going to push them forward, carry them around. I mean, these are some conditions, both on the number of generators of various of these ideas in certain loc localizations, and about the depth of certain powers of, I think, maybe J or maybe I, I don't know. Or maybe I, I don't know. So this is, I have no idea. Okay? So they're in particular, they imply that the thing is generically a complete intersection, but there's a finite number of partitions depending on the number of partitions depends on this value s. And I don't know how you've come up with them. I don't know why anyone, how you would ever check this. But they're two guys, which one is to three guys. Which one is to multiple? Okay. I think. I think. Yes. K should be local in the computer essentially. Yes. So, I mean, I can look them up for you. I can write it on. This doesn't mean anything to me. Maybe it means something. I will just run it up, okay? So sometimes I'm... Maybe you know some class of examples for which the hypotheses hold. No, that's like, yeah, so this is like my main problem with this. They prove this paper, and they prove the right paper, they prove some interesting results. But how do you ever find examples? I will, at the end, give you some examples. At the end, give you some example where I can actually explain what the condition is. But yeah, it's not clear to me why this is supposed to be a reason. But they are reasonable guys, so I thought we could probably. But how do you happen? Let's discuss the examples when you get there. Okay. Let's see if I get there. Yes. But now, okay, so now I can actually tell you some techniques. This was warm-up and definitions and stuff, but now let's get where it is. And the first theorem is as follows. I mean, all of this very strongly based on this work of Ulrich and on Eisenberg-Ulrich, so maybe I will just say this. Well, okay, it's alright. Maybe plus epsilon. Now that I'm thinking of it, maybe it's quite big epsilon, but I don't know. So basically, here's the Sinon, but I don't know. So basically, Kirsten, I observed something about their work, right? And what we observe is the following thing: that so if this in this above center here, if k satisfies the read hypothesis, oh, and again, you globalize these conditions by asking for them pointwise, just as before. And again, this will generalize the previous definition. Will generalize the previous definition. It's not immediately obvious, but anyway. Then the following thing will happen. I will write Q mainly for this. I did already write Q for this guy here, right? Or maybe shouldn't take Q. So then what I can do is I said W is this guy X mod J. And I can look at the co-normal. And I can look at the co-normal sheaf of W. Okay? Now, this guy is anything, is wild, because this W guy is wild, right? It's pretty bad. But what I will do is I will restrict it now to Q. Okay? So this is again, this is some explicit thing in terms of ideals. This is just I squared not. I squared not J times I no, I sorry. It's J times J. Okay? This is a module over, of course, OK, I mean OOQ. And the claim is this guy is locally free. Okay. In fact, if I take S generators, I mean if I take my S generators of J, then they will form the basis of this thing. So maybe locally free of lateness. Is that hypothesis is a codimility of K is? It's not S, it's bigger, it's less than S. Codiment of K is S, pretty much. It's S. This picture of K is the K has the expected potiment. That's the definition of a residual intersection. Oh, K is the expected. In like yeah, yeah, okay, I wasn't uh pictured, right? But notice, notice that this thing here is defined, I mean, without saying anything about s, right? So this number s is determined, and it's the rank of this sheet, which happens to be free. Okay, I don't have much to say about this theorem. Once you somehow come up with this idea, you look at the You look at their paper and you find, and copy some of the things which they do, and it works. I mean, some pure algebra, I don't know geometrically what any of this means, but you come. So, in your picture, what's this thing defined by the model? It's the whole thing. It's what? So, J is the whole thing. J is K is the only thing that's left. Yes. That's I. So you, I see. W is the co-normal to J. To J. W? Yes, W is the conormal thing. W is just that thing. This is W or the conormal UC C. That's a funny thing. When you restrict, I say when you restrict it to the Q. Yes, this is Q, the finite value plus that's the Q, when we restrict it to Q, then it's local with three. Great. Okay, so now I already well maybe I'll just leave this picture. It seems very good to keep it in mind. Okay, I mean now I guess it would be fine if the time is over because I think everyone can finish the talk now. Well, I mean you have a non-canonical expression in which Canonical expression which came up with this. But of course, you know what you have to do, you're going to twist the non-canonical expression by the determinant of this guy, and then you're going to get the canonical twelve. What else can you do? And well. Okay, so from now I'll have to assume that the strong hypothesis holds. And there's a number t which is defined to be the number s, which was the rank of this guy. Minus the minimum number of generators of J I, which was G, right? I think it should be this codimension of y. I don't think we want to say anything about the number of generators of I. This was this number that we call g for. That's a mobile thing. Right. Okay, so the t also is a mobile. The t is also a function. But let's pretend that it's a number. But you're right. And so now. And so now Olovich proves the following thing for us. He proves that maybe I'm in the local situation again, this Armad K guy is called Macaulay and I to the T plus 1 modulo J i to the t is a dualizing sheet. And now, with this out of the way, maybe I must take our main theorem for the purposes of this talk. So, in the above situation, so maybe point zero is we can make sense of this sheaf globally. Okay, so maybe I'm underlining this t here to say this is a function. It depends on what you do and where you are on x. For example, if you're outside of w, then this guy is just supposed to be zero. And if you're at sort of around some point where these numbers are fixed, Where these numbers are fixed, then it would be this, but somehow it varies in a it's not a totally free chip, right? But I mean, it varies in some unpredictable manner. Well, not that unpredictable, but some complicated manner. But the stocks, for example, it does this, yes. And then there's a canonical trace map. And what does it do? It goes from I know a star of sigma minus s i t plus 1 tensor with the determinant of this logi free sheet that we found. And match to all X. And if you add join over, you get an equivalence. Okay, so that's perfect. Just in my lines on the trees. Yeah, that's right, and on the S. What? Thank you. Thank you. And also it's the rank of a locally free sheet, so it's a locally constant function. T is also locally constant function. Right, two is the adjoint map. Which is what sigma to the S V over Q the map goes into the other direction. Yes. I lower star of this whole chip line here again. Well, no, without it. Okay, I'll just quantify this. Okay, this is an equivalence. Well, play the same game as with the regular version. So I use this. This is actually an OQ mode. So I use that this is actually an OQ module. And so I actually make the map OQ cancel this, goes to this, goes to here. And then I just move the OQ to the right side. Does that make sense? And then it turns here into R home OQ O X, which is this. And I've chosen Y. Move this sigma. I see. Ah, and also. Okay, so that's the claim, and now probably I've had 10 minutes. So, what am I going to say? Right. So, maybe I'm going to say something about well, I wanted to say something about the proof because I'm going to explain to you the proof of the proof of the broad leg duality thing. Of the broad lead duality theorem for regular emergence for a reason. And the reason is that we can essentially imitate the same argument. So again, I work locally, where I can assume that I is generated, J is generated by these S elements. Then I look at the Cosmo complex of this. And inside here, I define a modified version, which I define as the, or I call the modified first word syntax. Now, how is that going to work? Well, in degree i, let's say, this guy is lambda i all x to the s, right? x to the s, right? And here I'm just going to use a certain submodule of this guy. Namely, I'm going to multiply by the power of i. So this is going to be i, so just going to be t plus 1 minus i'm going to be able to do it. Right. And because I mean the structure maps are more or less multiplication by these A's, which lie in I, this is a well-defined component. And what one can prove, again, somewhat miraculously to me, is that this is a resolution of I. resolution of the resolution of oh i to the t plus one but j i to the t. Okay, so it's clear that it should be clear, that pi 0 is what it should be, right? So you just i to the t plus 1 modulo i to the t times this. Pi total t times these generators of j. So pi zero is correct, but it's not at all obvious why it should be executed, right? And again, I have zero intuition for why this is. We were dreaming of how the theory might go, and I was like, oh, it would be super good if this is the resolution, right? And everything would work out nicely. And I mean, we tried to prove it for a couple of days, if I remember correctly. And at some point, we were looking at this original paper of Kolwich, and he had some strange lemma which says that some sequences are exact, and the red is the ones which. Are exact, and what is the ones which you need it? I don't know. Okay, sorry. To me, this is a bag of mysteries, but it works, apparently. All right, and now basically, from that, you do what you did before. So, this allows you to write down a local trace map and do a local computation, and you can view them together. Oh, oh, yes, okay, and at some point, of course, you need to know that locally you have an isomorphism. But this is where we use this result of Ulrich, right? And he tells us that this is a dualizing shield. In fact, how does he prove that? In fact, how does he prove that? I mean, essentially, he gives an isomorphism between, right, you have to make some map from this to the dualizing object, and we need to argue that this is the one which also will wish rights down. But with the problem, is on the form I wish we could something. Right. Yes. But we can. Okay, and if you do these things, then just X in the right direction to the cheaper we have. The buttons are cheek that we have more. Yeah, I think that's what you're proofing. Right. We need to show that, I mean, this kind of map makes a map from here to the X thing, and we want that to be an isomorphism. Okay, and so now I'm out of time, but I've said something. So maybe let me say one thing about the applications, okay? And maybe I'm not going to write anything. But here's one thing which you can do, okay? I have to write something. Okay, well, I have the right something. So I have a scheme X, and over it, I have a vector bundle, and I have some section sigma. Now, vector bundles will have Euler classes, right, in various co-multi-theories, and maybe you're interested in what they are. Let me just write it in some sort of bit group associated with X. Maybe you want to know what this is. Now, what can you do? Well, there's this sort of Pronkari-Hof theorem. Ponkari-Hoff theorem, which says that if the vanishing locus of sigma has like dimension zero, okay, like say the dimension of v is the same as the dimension of x, then there is some formula for this Euler class, right? It says you look at the look and you learn the general section, it has finitely many zeros, at each zero there's some local index, you add all of them up, you get an answer, that's what Euler says, okay? All right, but what if it's not dimension zero? Okay, so maybe it's dimension one. So this is called the almost complete intersection, apparently. Um and in this case, um you can far yeah but so I'm out of time. So let me just say what what will what will happen here, right? This is some sort of curve. Let me assume that it is um generically reduced and then it has a Golden McCauley locus, which is basically the curve minus the embedded Minus the embedded points, something like that. Maybe also minus the isolated points. And what you will want to do is you want to remove this cold-make call emulocus, and you get a residual intersection. So you obtain the embedded and the isolated points of C as a residual intersection. It's basically the closure of the generic roles, essentially. Yes. Right. Something like this. And so what you can show is that this is one of these residual intersections. So you get your well-defined duality theory and you can take a form here and then push it forward to X. And what one finds is that the Euler class of V will be pushed forward form of some specific thing which you do on these embedded points. These embedded points. So there's like a generalized Point-Carrier-Hoff formula where if the dimension isn't zero but it's one, you have to not sum over the zeros because there's infinitely many. You sum over the embedded and isolated points of the zeros and add certain local terms and then you get the Euler, Euler Na, or Euler productions. And that's unfortunately where I run out of time, but that's what I wanted to say. So in this example you had a push forward with growing degrade groups, right? Does that generalize to this situation as well? What do you mean? So maybe I should say something which is there is a push forward on the number of growth and degroup groups for sure. And I wrote that this equality. Well, I didn't write anything, but I wrote it in the width group because the equality holds in the width group. It does not hold in the growth group. So there's. So there's yeah, they're just not the same, okay, right? It's like modular hyperbolic planes, they're the same, but the hyperbolic planes are literally different, in general. Yes, I mean, okay, so how does this proof work? Well, there is a paper of Duke van Strachen and his student warrant, and where they do something about almost complete intersections. And if you reinterpret what they do, And if you reinterpret what they're doing, it's basically they're looking at the Kausul complex of this catalysection and they are analyzing the class in the wid group. Now, what's the difference between the width group and the Groten-D-Wid group? Well, I mean, with like over a field, it's just the hyperbolic planes. But in the derived setting, what it means is that you're allowed to change it by algebraic surgery. So you can sort of get rid of Lagrangian somehow. Basically, get rid of an explicit Lagrangian and then turn it into. And then turn it into this point. So that's why, like this, literally, we use the defining relation of the bit group in order to get this quality. Otherwise, it's not. Actually, the original complex, which is complicated, really is the Euler class in the normal bit. Yes. It's just because so complex, there's always the Euler class, right? You get rid of. Yes, so after getting rid of some explicit Lagrangian, you get something which is supported on here. You get something which is supported on here, which you can then show us. Well, I haven't told you about this. It's explicit. Yeah, yeah, it's some explicit thing, which I haven't, as you said, I didn't have time, but some explicit form to relatable these i's and j's one comment which is that one of the nice things about eyes and but the morris's favorite thing a lot of examples are from the computer of algebra and sympathetic if you'll let me read some so the strong hypothesis which was read cells. So the strong hypothesis, which also satisfies the weak hypothesis, is only on I. That hypothesis is just on I. And if you are, if I is codimension 2 satisfying a condition called perfect, that works. If you take a surface into P4, you have to take generic 2 by n matrices. So, I mean, they, and their paper includes a whole bunch of examples. Maximal minors. A bunch of conditions on the maximal miners to make it. Well, I see it slightly. There are definitely determinantal ideals in there. Let's thank Tom again. Sorry, there was a poster that was. Sorry, there was a potion. There was a push-