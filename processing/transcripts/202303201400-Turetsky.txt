Okay, so welcome back. It's my pleasure to introduce Dan Turetsky from Victoria University of Wellington. He will be talking about randomness today. I'm sure. Interesting talk. Thank you. Thank you for the chance to speak here. Thank you to the organizers for organizing this conference. I'm really looking forward to it. My remit for this talk was to give an introduction to randomness for people in other areas to give a sense of, so they have the basic ideas and kind of have a sense of what would be good to know for possible collaborations. So, I'm going to be talking about a few things in that vein. And because of that, there are some things I won't be talking about. I won't be talking about some. So, one thing that's near and dear to my heart is K-triviality, and that will not be showing up at all because, as far as I can tell, that doesn't seem to lend itself well to crossovers with other areas. Having said that, someone will then prove me wrong, and I look forward to that. That will be great. But a couple people in this room will see their results in here. My apologies for not including. For not including credit on things. I just have theorem, theorem, theorem, without who did that. Great. So, we're gonna, we want to talk about a number being random, a real number being random. We don't want to talk about a random variable or a random process, a random generally generated, a randomly generated variable. Generated variable. We want to point to a particular real number and say that number is random. And a probability theorist would say that's impossible, but we're going to do it anyway. So I'll start with some motivation. This is not the only way you can motivate this subject, but one motivation is to say there are a bunch of these results that hold almost shortly. So if you've got a non-decreasing function, it's differentiable almost everywhere. Almost everywhere. If you have a measure-preserving transformation of a probability space and you have a measurable set E, then almost every element of E gets infinitely often returned to E. Poincare regards. Or Birkhoff's ergodic theorem. So now, if you're not familiar with Ergotic. So now, if you're not familiar with ergodic theory, don't worry about it, but this is a standard example of time equals space. Time frequency corresponds with size. So I've got an ergodic transformation that for almost every point, the frequency with which it returns to E is the measure of E. Or Lebesgue density theorem. I have measurable set E for Measurable set E for almost every element of E, if I zoom in on, so I make a small ball around the point Y, I measure how big is E in there proportional to the size of that ball. It goes to one. So we have all these results that hold almost surely, which means if we pick a point randomly, it should Randomly, it should satisfy the conclusion of the theoretical. So then the question we could ask is: how random does it need to be? And can we compare these conclusions? Can we say that even though they both hold almost surely, somehow the conclusion of this theorem is stricter than the conclusion of that theorem? So I'm skipping over a bunch of the history. Skipping over a bunch of the history, there were various attempts to define what randomness means. And until computability theory came along, people had a lot of trouble getting started because there's this idea that you can't impose more than countably many conditions on what a random sequence should be, or else suddenly you don't have any sequences that satisfy it. Well, Martin Loff, so then the idea came along: oh, well, here, we want a counter. Oh, well, here we want a countable set of conditions, the computable conditions, whatever, in some sense. And there were a few attempts, and Martin Love had this insight, which is what people are doing is they're defining statistical tests, and a statistical test is a measure zero set. So we're going to use computable functions to describe measure zero sets, and you're going to be random if you avoid all of those measure zero sets. There are only countably many computable functions, so there are countably many measure zero sets. Countly many measure zero sets, so almost every real is random. Yeah, so but now the question becomes, okay, how do I use a computable function to describe a measure zero session? So here's one more point. He said, first of all, a sigma zero one class, it's generated by a CE set of strings. By a CE set of strings or computable set of strings, it doesn't matter. So, measure theory tells us that every measure zero set is the intersection of sigma zero open sets whose measure goes to zero. So let's do that. A Martin Love test, it's a sequence of effectively open sets and uniformly effectively open, and their measures are going to zero. In fact, they're going to zero at a In fact, they're going to zero at a quick rate. Since the one's going to go to zero, let's just say the n1 has to have measure no more than two to the minus f. So then the measured zero set that's being described is the intersection. Sorry, can you say what you mean by a uniformly sigma zero one plus? Oh yeah, I should have mentioned, please interrupt with questions at any time. Yeah, so a uniform, so I mean that the sets A which generate the sigma zero one classes should be uniformly C. Uniformly sequel. So, therefore, or computable. There's a uniformly computable sequence of sets such that the nth one gives me vn. Is that good? Yeah, thanks. All right, so Martin Love, this is Martin Loff random. You're Martin Loff random if you avoid all of the measure zero sets that are described in this. Yeah. Okay, so just repeating the definition. A Martin-Love test, we've got this uniformly, effectively open classes. Their measures are bounded by 2 to the minus n. Well, how about instead of saying they're bounded by 2 to the minus n, we say they are 2 to the minus n? You might think, there's no real difference here. I just take my Martin Lovesite, and if its measure is too small, I add a little bit more. More. So, this gets us what we call a Schnorr test. And this is not the same. Turns out, so naively, since Schnorr tests are bigger, a Martin-Love test is doubted by 2 to the minus n, a Schnorr test is exactly 2 to the minus n. Since the Schnorr test is bigger, you'd expect a Schnorr test would capture more than a Martin-Love test. So fewer things would avoid the Schnorr test. Fewer things would be Schnorr random. It actually goes the other direction. Or random, it actually goes the other direction. It's actually being a Martin-Love test, since this is more permissive. It's easier for something to be a Martin-Love test, so more measure zero sets are described. So there are fewer values. Or a week two test. What if instead of saying, right, we still want the measures to go to zero, what if instead of saying they have to go to zero at a prescribed rate, what if we just say the measures? Rate. What if we just say the measures have to go to zero? So, in this way, we have different ways of taking computable sets or computable functions, however you want to think of it, and translating them into measure zero sets. The exact way we do this translation will get us different random dispositions. Why is it two values? Why is this called a week two test? Yes. Okay, so Martin-Love random is also called one random test. There's something called. There's something called week one randomness, which is a terrible notion because it's not really a randomness notion. Week two tests. Yeah, it does feel like it's more like a strength than you would mark up test, so it feels like it should be called strong one-randomness. I argued this. It used to be. Yes. I argued this in threshold, but they wouldn't change the name for anything. Yeah. Yeah. Not everyone agrees. Yeah. It's not widely considered a good name, but it's the name that sticks. Consider it a good name, but it's the name that sticks. So there is something called two random, which is just, if Martinloff is one random, do Martinloff relative to zero jump, and that's two random. This is a weakening of that. So hence the name. Other questions? So here are three ways we can turn computable functions or computable sets, whatever, into basically we can turn the notion of computability. Basically, we can turn the notion of computability into measure zero sets. And they give us three different randomness notions. So I'm going to go back to comparing Schnorr and Martin-Love. Again, this was the key distinction. A Schnorr test, the levels have exactly measured 2 to the minus n. A Martin-Love test, they have at most 2 to the minus n, but maybe less. And I claim this is about partial functions. So, there are CE sets which are not computable. There are partial computable functions which cannot be extended to a total computable one. I say it's the same phenomenon here. There are Martin Love tests that cannot be filled in to turn into Schnorr tests. This is a behavior you only see in computability theory, this concept of a partial computable function that can't be extended to a total computable function. There's no concept in set theory. There's no concept in set theory. Like, if you look at constructed functions, every partial constructible function can be extended to a total constructible function. Or complexity theory, every polynomial time partial function can be extended to a polynomial time total function. So this intrinsic partialness, so here it is, you don't know if something is going to happen or not. Here, the idea is I don't know if I'm going to fill up all the measure. If I'm going to fill up all the measure, so I've got some potential measure that I'm allowed to use. It's an open set, so I'm seeing neighborhoods fall into the open set. So my idea for how big, how much measure I've used is going up. I don't know if it will ever use it up. So for this reason, I feel like Martin Love random is something you can only see in computability theory, and I think it's It's very central to kind of what's going on in computability theory, this phenomenon. And Martin Loft random tends to be kind of the core randomness notion that most other randomness notions are compared to. I'm sorry, can you just clarify one thing going back to the original definition of going back a couple slides? Yeah, right there. Okay, so V is a collection of. V is a collection of reals. Yes. It's the body of some tree, right? Where the nodes are labeled by A. A is a well, okay, you can think of it. So it's an existential to get it. It's just if some initial segment of the real shows up in A, then we take the real. So A is a collection of finite binary strings. It's an element of 2. Binary strings. It's an element of 2 to the less than omega. Correct. It's some CE subset of 2 to the less than omega. You're fixing some effective bijection of that with omega. Yes. Okay. And then you're looking at all the reals, such as some initial segment lands in that set. And then for the uniform version, your A would really be, you have like a parameterized family of these things. And so the nth, the nth V. The nth V comes from the nth version of the A? Yes, exactly. Okay, cool. Thank you. I just wanted to clarify. Yep, absolutely. Other questions? Okay. Right. This is what I was saying. Modern left random, it has this intrinsic. It has this intrinsic partialness, and for this reason, it doesn't tend to be a good analog with other areas of logic. So, set theory has something they call random wheels. They do random real forcing. And that's often a good analog with Schnorr randomness. A lot of what happens with Martin, with set theory's randomness compares with what happens with Schnorr randomness. And this can be made effective by look missing an end here. I think I had a ligature that didn't type set correctly. I think that's what went on, what happened there. Q-Scholz, Shee-Hons diagram, which is about different cardinals in set theory. It has computability theory parallels, and it's Schnorr randomness that lines up with set theory. There's also, you can do randomness in complexity theory, and again, it's Schnorr randomness that works because. randomness because functional randomness doesn't have this partial partiality so this intrinsic partialness it lets us get a uniform listing of tests I can't list all total computable functions I can't list all computable sets I can list all partial computable functions I can list all partial computable functions. I can list all CE sets. And in the same way, I can list all the Martin-Love tests. By because I can list all the Sigma 01 classes because I'm just listing out different CE sets. I'm monitoring the measure. I never let the measure of a given one go above what it's supposed to. So if I have some CE set, I say, Some CE set, I say, okay, don't go. I'm listing a CE set, which was potentially VIN. That's not supposed to go above minus measure 2 to the minus n. I just say, don't let it. And maybe it's the empty set. Maybe it never enumerates any springs, but maybe it enumerates some. And I don't know if it will use up all its measure. This is why trying to list out Schnorr tests is no good, because I can't speed it up to make it list everything. Maybe it will just never use some of its measure. But I can list. Just never use some of its metrics, but I can list them all out and then. Sorry, can I ask about that? So, what you just described says that I know that the nth one is okay, that the measure is small enough, but don't they have to know that for each n? Right. So, what I'm going to do, I'm just going to enforce that. So, I'm going to lit um I've got a list of all um CE sets. So I'm going to take each CE set and chop it up into pieces. Is this visible? If you look at the one that needs to be to extract so if you look at the camera that has me, the window on Zoom that has me speaking, Speaking, you should be able to see, yes, that should be this camera. I do see it, but if you can try it with black. Let's try that. Yeah, that's much better. If I take a CD set A, I define AN to be so I use pairing. I have a CE set, I think of it as a set of pairs because I have pairing. Because I have a pairing. So I chopped my CE set A into the columns. So AN is all the pairs, all the K that get paired with N into A. What I want to do is define, I want to say, okay, here's the nth level of my Martin-Love test. But I want to make sure that this doesn't go above 2 to the minus n. So I'm just going to. Above 2 to the minus n. So I'm just going to look at all the so I'm thinking of k, now I'm thinking of these as strings. I look at all the sigmas that I'm seeing being enumerated. I'm counting out how much measure they've used. If it attempts to enumerate something that would take me above the 2 to the minus n threshold, I just say, no, that doesn't get enumerated. So I don't actually take a n. I take the shrunk version of a n. Actually, take AN. I take the shrunk version of AN that just forbids going above the measure boundary. So, in this way, I get a listing, like a list of all the CE sets. I take every CE set, I chop it up into pieces, and I take the pieces, and I make a Markov text. So, this way I get a listing of all the Marklov texts. Sorry to belabor the part. Sorry to belabor the point, but don't you, but you just said that for a given n, right? So, how do I know it passes? How do I know the measure is less than or equal to the minus n for all n? Oh, that was uniform. What I was just describing was uniform. It's a uniform process. I'm enforcing for every n that I'm just enforcing in the enumeration of a n that the measure isn't allowed to go above. I just block strings from going in if they would take the measure too big. Oh, okay. Oh, okay. Okay. Yeah, thank you. So I've got a listing of my Martin Lofset tests, and I'm going to list them as columns. But here's the first, here are the levels of the first test. Whenever I try to make a doubly indexed A doubly indexed array grid like this, I always screw up the index out. Now, since everything's uniform, I can make a new sigma zero one class by taking By taking a diagonal union. Take the union of this, with this, with this, with this. And then I do the same thing one step higher. One step higher. These diagonals go on to infinity. Okay. These are all sigma 01 classes because everything was effective. Sigma 01 classes are closed that are effective. Sigma 01 classes are closed that are effectively. The measure is well just a dyadic sum, so are bounded by a dyadic sum. So the measures are appropriate. So this, so call this one u0, call this one u1, u2. That's a Martin-Love test. And it's a universal Martin-Love test. Because if it suppose I have some real that's captured by this. Some real that's captured by this test. Then, since it's in the intersection of all of them, it's in this one, which puts it in there, and it's in here, which puts it in there, etc. So any real that's captured by any Martin Love test is captured by this Martin Love test. This gives us what we call a universal test. And I should mention, I should mention, Schnoor randomness does not have a universal test. So I claim that universal tests are an expression of this intrinsic partialness behavior. Why is that not working now? Okay. Okay, so there are other ways to use computable functions to describe measure zero sets besides the three I've listed: Schnorr random, Martin Love random, week two random. Martin Love random, week two random. You could use martingales, these are betting strategies. Depending on exactly what you do, how you do the translation of a computable function into a betting strategy, you might get Martin Love randomness again. You might get computable randomness. You might get some more esoteric ones. The idea is, if I have a betting strategy, a strategy that sees the sequence of bits in a reel, zero or one, the house always wins. The house always wins, or statistically, the house always wins. So the probability that my betting strategy wins big wins an infinite amount of money should be zero. So that's my measure of zero set, the ones on which the betting strategy wins an infinite amount of money. I'm not going to get too deep into that. Combo growth complexity from information theory. This can give you Martin Love randomness again, or it can give you some other ones depending on exactly how you do things. You can go back to the version that we were doing of Martin Luff randomness and make some other with Martin Luff tests and make some other changes. You can change the topology so that instead of them being intersections of open sets, they're intersections of some other level of complexity. So there are a lot of variations. Okay, and this gives you a zoom of different randomness notions. Different random distortions. You might not be able to see. There are little arrows which are implication. Generally, it goes down. So, this is the up here is one of the strongest random distortions. So, anything that has pi 11 random is Martin Loff random, is partial computable random, is what else do we have? Here's Schnorr random. Here's week two random. This is incomplete. This is incomplete. This is from 10 years ago, more than. So there are other random notions that have been explored since then. There's one that I'm particularly fond of that sits in here. So we get a whole zoo of different randomness notions depending on exactly how we define our measure zero set. Any questions so far? Okay, so I want to go back to those almost shortly theorems. Just because since I introduced them in the motivation, I should talk about what some of the answers are. Non-decreasing functions are almost everywhere differentiable. This turns out to be exactly what's called computable randomness, in the sense that if you have a computable non-decreasing function, then a computable random will be a point of differentiability. Random will be a point of differentiability. Conversely, if something's not computable random, there is a computable non-decreasing function that is not differentiable, that the function is not differentiable at that point. Poincaré recurrence theorem lines up with Martin Love randomness. Birkhoff's theorem lines up with Schnorr randomness. The Lebesgue density theorem, that's complicated. So the conclusion was the limit. The conclusion was the limit is one. Well, you could weaken that to say, well, just the limb suit is one. And then, well, Martin Love randomness suffices, but we don't know exactly what exactly it lines up with. Or you could say that the version of the theorem I stated, which is that the limit is one, Martin Love randomness is not enough. It's something stronger. I'm not going to say more about these, but I just wanted to get back to those questions, those examples. Okay. So I should really build you an example of a random. I've been talking about these things in the abstract. I've been saying, here's what a test is. These are almost everything is random. Let me build you an example. So again, we're going to use this. So, again, we're going to use this idea of listing things out. So, I want to talk about left CE beams. Real is left CE if there's an increasing computable sequence that converges to it from the left. Alternatively, the set of rationals which is to the left of the real is a CE set, left CE. So I've got a real alpha, there's an increasing increasing. An increasing sequence of computable increasing sequence Qn, where since it's increasing, the suit is the limit and it's FO. If I restrict my attention to the unit interval, I can get a computable listing of all, well, I can't get a computable listing of all the sequences, of all the total sequences. I can get a computable listing. I can get a computable listing of enough sequences that they represent every left CE real. And it's because I can just kill time. I look at a computable function. If I'm not sure whether it's going to converge, well, I just keep enumerating the last value. So I start by just enumerating zero in my sequence until I get a value from the function. And then I say, oh, okay, I'll enumerate that. And then I keep enumerating that until it gives me the next value, if it ever does. So because I have the free. So, because I have the freedom to kill time, I can turn all partial computable functions into increasing sequences. And again, I just don't let them go above one. If a sequence tries to go above one, I say, nope, you're not allowed to do that. I'll just keep doing the last thing I saw. If a sequence tries to be, fails to be increasing, I just say, nope, I'm not going to allow that. You just have to keep enumerating the last version, the last thing that I did allow you to enumerate. And you're not allowed to go smaller. Smaller. So I've got this computable listing. So I'm going to make a dyadic sum. I'm going to call this omega, capital omega. And I can get an increasing sequence for this dyadic sum. I just take my computable listing and I do the dyadic sum of computable listing. So I've got a left C equal omega. And of course, since my listing had all And of course, since my listing had all of them, omega itself shows up in the listing submarine. So you can do nice recursion theory games with recursion theorem games with that if you want. So speaking of the recursion theorem, suppose I'm building a left CE realm, meaning I'm building an increasing sequence of rational numbers inside the interval 0, 1. By the recursion theorem, I already know the index for what I'm building, which means by the recursion theorem, I know where the real that I'm building appeared in this previous list. So I know the coefficient that it contributed, that was used to put it into omega. That means when I increase my real, I know how much. Increase my real, I know how much omega will increase in response. I control that much of omega. This means that I can force omega to move out of the universal test. If I see the universal test currently capturing my current guest to omega, I say, okay, how much do I need to increase it by to get out of there? Increase it by that amount. I always run away from the test. I can just force omega to run away from the test whenever possible. Since that level of the test is open, if I constantly move it out, then by just topological considerations, omega, the limit, will not be the open set. And this is not usually the standard definition you'll see of omega. It is equivalent to the standard definition. The usual definition. Definition. The usual definition given is a kind of probability that you will generate a program that runs and halts if you flip a point. So, omega is random. And this works for any left CE or right CE, which is just left CE, but from the other side. That it has to, it permits some sort of coding. I have the ability kind of post hoc to contribute to omega a certain amount. To omega a certain amount. So any left CE real that has that property is going to be random. So if you're doing something and you think, oh, well, here's some measurement of my system and it naturally has approximations from below. Maybe it's a wrangle. There's a decent chance that it might be a Markov wrangle. Any questions? Any questions? Sorry, can you go through the argument again as to why omega is more like you know the index i of omega? Omega is alpha i is what you're saying. Well, no, so I'm building a left, I'm building some other left-see rhythm, an auxiliary left-see judgment. And by the recursion theorem, I know that it's alpha i. So I know what i is before I even start both of them. Okay, I'm sorry, I don't follow. So, you defined omega on the previous slide, right? Yes. It has the alpha i's as the binary coefficients. Right. Right. It has this dyanic sum of alpha i's. Yeah. Okay. But then now you say, okay, so, but omega is itself one of the alpha i's. That is the case. I'm not using that. That was that was. Case, I'm not using that. That was just a parenthetical comment. I'm not using anything. Then, what are you saying here when you're using the recursion theorem? So, I'm just going to sit down and build a left CU wheel, which means I'm just going to declare a sequence of rationals that are inside the unit interval that increasing. And because of the recursion theorem, I know that, so I know that's one of the alpha i's. And because of the recursion theorem, I know what the i is. Okay. Okay, which means I know how much. means I know how how much it contributed to omega in the definition of omega. Okay. Okay. So did it? There. So that means when I increase my real, I know that omega will increase by 2 to the minus i times i plus 1 times the increase. I increase my real, omega increases in response. When you say my real, you're talking about the real in the first paragraph of this slide. Yes. The first paragraph of this slide. Yes. I'm building a real beta. And every time I increase beta, omega increases in response to that. Okay, I follow now. I follow. So because of that, I can make omega increase when I want, as long as I don't ask for it to increase by too much. The total amount of increase I can do is 2 to the minus I plus 4. So the flexibility is when you're doing the enumeration of the alpha i's. Of the alpha i's is yeah, so this particular beta I'm building, I'm just going to say 0, 0, 0, 0, 0 until I realize that I need omega to go up. And then I say, okay, how much do I need omega to go up by? I'm going to increase my, I'm going to put some Q there that will cause omega to increase by however much I want omega to increase by. Okay, because this omega has to work for all the UIs. Omega has to work for all the UIs. Yes. So the omega has to avoid a single UI because it has to avoid being in the intersection. So I pick a single UI and say if I avoid this, then I've avoided the intersection. Right, okay, right, okay. Thank you. So yeah, so I pick the I that I get from the recursion theorem. Since the measure that I have to run away from is no more than the measure that I have, the amount of The measure that I have, the amount of increase I have to work with, I always have enough increase to move omega out of that set. Got it. Thank you. Okay. Same idea. I'm going to use, again, I use the recursion theorem. The recursion theorem tells me how much of omega I control. So this epsilon, this was 2 to the minus i plus 1 on the previous slide. On the previous slide. In general, the recursion theorem will say you control this much epsilon much of omega, and it will provide the epsilon. So I wait until n enters zero jump, and I increase epsilon by a dyadic multiple, or I increase omega by a dyadic multiple of epsilon. Because I don't want to use more than epsilon total. So this is how I ensure that I don't use more than epsilon total. So now that was my, so I run that, and now post hoc, suppose I had Oracle omega. Well, with Oracle omega, I can tell when the approximation to omega has gotten close to the true omega. And when it's gotten sufficiently close, then I know that if n hasn't entered zero jump by that stage, it never will enter zero jump. Because when n enters zero jump, I cause omega to make it increase. Cause omega to make it increase. And this proves that omega is equivalent to zero Turing equivalent. So, in fact, this holds more generally. Any left CE random, bar and love random, will be a Turing equivalent to zero generally. Right, so changing gears a bit. So, changing gears a bit. Suppose I have a measurable set, and suppose it's invariant under finite differences. So, if a real is in and I make a finite change to that real, then it's still in. Then we know that it's the only possible measures are zero or one. You can't have any intermediate there. So, any Turing so one way to get invariant under finite differences is to be Turing invariant. is to be Turing invariant. So any nice, so nice meaning measurable, Turing invariant property, it's either going to hold for almost every real or it's going to fail for almost every real. So that means if you take something sufficiently random, either they all have that property or they all don't have that property. The set of reals which computes zero chunk has measure zero. So this So, what this is saying is anything sufficiently random will not compute zero choice. Okay, so this can get us randomness as a source of weakness. So, you might think, oh, things that are random are hard to compute. They're very far from being computable. That must mean they're powerful. No. Basically, randoms are weak. So, I'm going to go back to what I was talking about, modifying the definition of marketing. Talking about modifying the definition of market loss. Instead of using sigma 01 classes, let's use a difference of sigma 01 classes. So a difference test, you've got two sequences of sigma 01 classes. And what you're really interested in is the difference of the two. And you take the intersection of that difference. So the difference randoms, it turns out, are precisely the Martin-Loff randoms which don't compute. Precisely the Markloff randoms which don't compute zero job. So here's the picture. I've got zero, I've got zero jump, I've got the cone above zero jump. There are randoms up there. Up there aren't enough randoms. And there are randoms that don't contextual jump. There are randoms down here, Martin Loff randoms. The difference randoms are this band right here. So you've got this measure, zero set of Martin Loff randoms, and most of the Martin Loff randoms right here. Just an example. This is an example of computable weakness as randomness enhancement. I said if you're Martin Love random and you're weak, in this case weak means doesn't compute zero jump, then you get this stronger notion, which is difference random. Or another example, here's my picture of the delta two sets. Here's my picture of the delta two sets, the things between zero, jump, and zero. Some of the randoms that are in here, they can compute a solution to Post's problem. They can compute an intermediate CE set. But randoms way far away, they can't compute an intermediate CE set. Those are the weak two randomness. This was a stronger version of randomness than Love Random. So, again, weakness. So again, weakness, not computing a solution to post-problem, is what it takes to enhance Martin Loft random to weaken to it. Questions? Yes? That's by Kuchera. There's a construction. So, yeah. But it's not just the delta twos. There are also random deltas, but it's delta 2s. Also, random dynamic still compute solutions post-problem. But yeah, in particular, all the delta two minutes compute solutions the post-problem. Other questions? In fact, they're not. I understand. Yes? Oh, excellent. Johanna and I showed that. Actually, it's on the logic block. We put it up there a few years ago. I guess no one reads the logic blog. Um what if I should do it? Okay, so yeah, Joe's point was that this picture might indicate the difference randoms are convex. It's not actually the case. There are turning degrees in here that don't contain randoms. Okay, so this there's a general scheme. The reals, so you take a randomized notion stronger than Martin, right? And Random and the reals which satisfy the randomness of that randomness notion they're precisely the Martin-Love randoms which are computationally weak in, well, in some way that depends on the randomness notion. So the difference randoms are precisely the Martin-Loft randoms which don't compute zero jump. The weak two randoms are precisely the Martin-Loff randoms which don't solve post-problem. There are a few other examples like this. There are a few other examples like this. So there's basically we got a schema of randomness of theorems. Okay, so that was randomness as weakness. Let me talk about randomness as strength. So I want to talk about the fire force construction. Do you decide you have to celebrate? You need to. You have to celebrate. You need to go buy a firework. And you want to set it off at home, and you know, part of your celebration. And you don't want it to be a dot. You want it to, at the appropriate time, you want to light your firework and you want it to go off and look nice. So you go to the fireworks cellar. But you're worried that they might have a dodge. They say, okay, you can test my fireworks however you like. Of course, fireworks are single-use. Once you test a firework, that's it. You can't then go take that one home. Fortunately, the Fortunately, the vendor is happy for you to test as many as you like before you go home. So before you buy one. So they say, I'll just put out a long line of my fireworks. You can just go down the line testing them at all. You'll see that they all work. And once enough of them have gone off successfully, you can buy one and go home with it. So that's what you want to do. You want to buy a good firework, or if you light one and it's a dud, well, then If you light one and it's a dud, well, then you get to rub the vendor's nose in it, and that's satisfaction. So that's another picture. So you want to do one of those two things. And the question is, how can you win? How can, well, this has to be a probabilistic thing. How can you guarantee that you have a very high probability of winning? So our strategy is pick a very big N and now uniformly at random pick a small Uniformly at random, pick a smaller K. You're going to go down the line and test K of the fireworks. If any of them are a dud, then you win. If they all go off successfully, you'll buy the next one. So there's only one situation. Suppose that there are duds. If there are no duds in the line at all, then great, you're guaranteed to buy a good one. If there are duds, well, if the dud is, look at the very first dud in the list. If it's one of the ones you tested, then you make. If it's one of the ones you tested, then you win. If you stop testing before the dud and then you buy one that isn't the dud, you win. The only problem is if you stop exactly before the dud and then buy the dud. So there's only one value of k that causes problems. So your chance of losing is 1 over n. So that's the fireworks. Well, that's the fireworks strategy. Well, that's the fireworks strategy. Let's turn that into a construction. Almost every real computes an escaping function. So this is a function which escapes every computable function. So did I miss the hypothesis there that there was only one dud? No one? But consider the earliest dud. Okay, okay. Right. If you go past the earliest dud, then you found a dud and you win. If you stop, Found a dot and you win. If you stop for the earliest dot, you do assume there's only one earliest dot. I'm assuming that it's a well-ordered sequence of fireworks that are being laid out. So it's okay. So, what was I escape? So, an escaping function. This is something that exceeds every total function. So, we're going to do the fireworks instruction. I'm going to pick an N and then n and then for phi e the partial computable function I'm going to choose a KE bounded by 2 to the e plus m. This 2 to the e plus n, that's my capital N from the previous slide. Testing the pattern work, well, I'm testing whether or not Phi E converges. So I ask Phi E, okay, I want to see you converge up on some initial segment. Up on some initial segment. And then once it does, I'll ask it, okay, I want to see you convert. Then that's the first firework going off successfully. Then I ask it to converge on some next initial segment. So if the current stage is S, at which it finishes converging on the first one, then my second test will be, okay, now converge up to S. And when I finally see that, I say, okay, now converge up to whatever the current stage is. So, I'm building a function. It has to be a total function. So, one thing I might do is I might pause the function and wait for phi e to converge. So, I've defined the function up to some point. I pause my function until phi e converges on that value. And now I can define my function, and I'll always define it to be bigger than anything I've seen. So, if I define in my function after phi e has converged, I will escape phi e. I will escape phi because I'll just make myself bigger than that. The problem is, of course, what if I define my function before phi e converges? Then I don't know what phi's value is, I can't escape it. So at some point I might say, okay, I'm going to go on pause and I'll wait for phi e to give me a value. Now the concern is that phi e might never give me a value and then I'm paused forever and I don't actually build a total function. So I'm doing the fireworks. I test phi E. I test phi e as being total a whole bunch of times, and then I pause the definition until phi e gives me a value, and then I say, okay, great, now I've handled phi e. What's the probability that I wait forever? Well, the probability that I wait forever with phi e is the probability that I've chosen the exact wrong KE. Because if there's, if I do end up waiting forever, if I had chosen a larger KE, then that I would have asked phi E to converge. I would have asked Phi E to converge one more time before I believed it. It wouldn't have converged, and I would have never waited for Phi E. If I chosen a smaller Ke, then Phi would have converged far enough, and I wouldn't have waited forever. So there's only one value of Ke that causes problems. So the probability that I get a problem because of phi E is 2 to the minus E plus N. So the probability that I wait forever because of any of the phi E's is at most the sum of those. Yeah. Sorry, I just missed for a second. Yeah, sorry, I just missed for a second there. Did you know why it's not a problem which is too large? Ah, because so I just erased it. I only have to worry about total computable functions. So if so, I put down here, I said, I'm going to wait for phi E to converge up to here. And if it never does, then I never do anything for phi E, and phi E is partial. Great. That's a victory against. Great. That's a victory against Phi E. I think that we know commercial, so you just don't care. Since I never see a conversion error, then I never do anything and I win. Right. So if I've chosen my phiE larger than exact than the problem value, then it just, then I never see it converge, I just stop worrying about it. It's equivalent to finding a done. If I choose a smaller one, well, then it has converged. Maybe it's not total, but at least it's converged as far as I'm waiting for. But at least it's converged as far as I'm waiting for, so I will see the value in L time and I'll give it that. Okay, so in total, depending on what n is, you get a very small probability that I go into trouble. So the probability that I, if I do this in parallel for every n, almost surely one of them will succeed. So if you're sufficiently random, one of these attempts will succeed and build an escape information. You can. This is from the perspective of: I have my wheel, here's what I do. If you want to try to figure out exactly how much randomness do you need, you want to figure out what does the null set look like, you need to take kind of a bigger view where you look at how is the computation playing out on all reels, what's the problem set of reals. Well, it depends on exactly how you use your oracle to choose the K, but. To choose the K, but you define a method. There's been some work on figuring out exactly what this takes. If you're familiar with one generics, this argument could have been used to build a one generic instead of an escaping function. So almost every random computes a one generic. Questions about this at all? Yeah. So while you're waiting for it to converge to eight times. Yeah. For it to converge to eight times, you might define your function much past that. So you're taking not necessarily the next value, but some much later. Yeah, so once it converges up to here, my next challenge is converting up to as far as I've defined. So it's not quite the same, like it's slightly different than the firework? Well, it's just a firework is an interval, and a dot is any being partial to any wrong interval. Whereas success is converging on the entire interval. But the next one might be like much later. One might be like much later, yes. So, yeah, the next one, I don't know what the where you're going to the vendor, it's like the very next one. Yeah, okay, okay. Yeah, I in instead of testing one at a time, you could think of it, yeah, you're going to the vendor, you say, okay, I'm going to test the first 12. That's my first test. And then by the time I've let them all off, I've decided, okay, the next test will be the next 55. Other questions? Okay, again, just because I want to talk about central notions. So, leaving behind the firebox perception, I want to talk about Von Lambogan's theorem. So, Von Lambogan's theorem says that suppose I have two wheels and I interstitch them. That will be Martin-Love-random if and only if the first one is Martin-Love-random and the second one is Martin-Loff random relative to X. And the proof is basically Kubeni's thing. So, this is saying: if I've generated a real by randomly flipping a point, the sequence of even positions shouldn't know anything about the sequence of odd positions. That's what this part is saying. And the sequence of even positions should itself be mentioned. Usually, this doesn't hold for other sorts of. This doesn't hold for other sorts of randomness notions. But it can be fixed often if you change what exactly relative to x means. You have to massage this notion slightly, and then it usually is fensible. This has analogs in set theory. So, in set theory, they force with random reals. So, you start with a countable transitive model of set theory, you add a random real. Set theory, you add a random reel, and then maybe you decide you'll add, you'll do that again. So you've expanded by adding a real, and then you add a real again. You could have gotten there in one step by adding a single random reel, which is the joint of the two redempts. Or conversely, if you add a single reel, well, if you take that reel apart, what you'll find is there was a smaller thing in between that you skipped right over that you could have gotten into. So, this is their iteration of forcing, but for real forcing, it's exactly on the model that's there. Okay, well, it turns out Bangladesh-Bogen's theorem shows up elsewhere. Here's the statement again. But it's true if you replace random with one generic. X join y is one generic if only. X join y is one generic if and only if x is one generic and y is one generic relative to x. Or low. x join y is low if and only if x is low and y is low relative to x. And as I mentioned, iterative forcing, the one generic corresponds in set theory to co-enforcing. And so it's iterative forcing of co-enreals. So, when you have potentially, if you have any sort of relativizable class, so Martin Loff random can be relativized, Martin Loff random relative to X, one generic can be relativized, potentially it will satisfy Barton-Bogos theory. I've got a little bit of time left. Okay, leaving behind randomness per se, but. Per se, but a topic that I feel that the interest in it has been motivated by randomness, at least, is lowness notions. So if I have a randomness notion, Martin Loft, Schnorr, whatever, I can say that an oracle is low for it if that randomness notion relative to A is the same as the randomness notion. So A is no good at derandomizing. Anything. Derandomize. Anything that I thought was random, A thinks is random. Or conversely, if A can derandomize something, then the empty set can derandomize that set. So I can just generalize this to any old task. I have some task. An Oracle's low for the task means it's no better at the task than the empty set was. So we've got low for randomness, but you can talk about low for one genericity. You can talk about low for isomorphism. You can talk about incomplexity. In complexity theory, they have low for speed. In learning theory, they have low for learning. There's this whole host of lowness notions. And low for randomness turned out to be incredibly rich. There's this huge amount of interesting structure going on there. And I think that motivated people to start looking at Lobus for other notions just because of how successful Lover on this notion has been. Loneliness notions. Right under this has been about lonely notions. Questions about anything? Okay, actually, no, I did want to say a little bit about just for an example of what can go on with load assumptions. Let's get to isomorphism. So, unpacking the definition. An oracle is low for isomorphism. You look at two computable structures. Two computable structures. If A can find an isomorphism, there was a computable isomorphism. Or you could talk about, I could modify this, I could look at pi 01 classes. I can say, if A can find an element of this pi 01 class, there was a computable element. So we're going to call that loaf of tads, except they're the same thing. It turns out. So you can get, it can be very interesting to look at and compare different low businesses. There's a question in chat. Is anyone monitoring? Or does it stay in the comments? Sasa said hello. Gotcha. Thank you. There it goes. Okay. I didn't prepare much on this because I didn't really expect to get there, and it looks like I'm pretty much out of time anyway. You can also apply randomness to geometric measure theory. Theory, or at least the ideas there. You can get effective characterizations of different fractal dimensions, Hausdorff dimension, packing dimension. This can be used to give new definitions of the classical version, and you can then get proofs of classical theorems using this. The expert in the room is Elvira. Okay, if you wanted to read more about this, there's an article in the BSL, Calibrating Randomness, which it's a few years old at this point. It talks about it talks about Martin Lof randomness and a few others. It talks about schnor randomness. It's a good thing to start with. Then there's a Then there's a text by Frank Lydon Horter, which says, Okay, you've learned the basics. What else can we do with this? So there's higher randomness, where you look at randomness relative to hyperarithmetic. Or there's random says, okay, what if we do randomness and computable measure theory? Or what if we change the measure so it's not Lebesgue measure? There are a bunch of different things that say, okay, we've done randomness, let's stretch it a little bit. We've done randomness. Let's stretch it a little bit. And then there is the book by Downey and Hirschfeld. This is not a good book to just sit down and read and learn, but it is a fantastic reference. If I think it is, if you figure out how the index works. I think the index works very well. You just have to. I think the index works very well. Not everyone agrees. You have to figure out how it's set up. And then you can find all sorts of stuff in it. It's very good at. In it, it's very good at tracing back the history of exactly who to credit. Thank you.