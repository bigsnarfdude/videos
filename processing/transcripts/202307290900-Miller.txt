That's okay. All right. Good morning, everybody. It's great to be here. So I just got a short talk on kind of a variation of a talk I gave at AGU last year with stuff that Don put together. But I've changed the title from what it was. From what it was in the original one, but it's kind of the same thing. So it's around kind of how I use a lot of open source tools, specifically the two main ones we're talking about this weekend, kind of in my day-to-day workflow from everything from collecting data through hopefully to a nice shiny publication at the end. So I guess why open source? To me, it really comes down to the first one. To me, it really comes down to the first one. There's a proverb in New Zealand that says, what's the most important thing in the world? And it's the people, the people, the people. And that really, I think, holds true for a lot of open source communities of users and developers. But there's also that ability to customize the code and tailor it for your specific application. We talked a little bit yesterday about starting from scratch every single time versus building on the works of. Time versus building on the works of others. And I like that you can kind of have a seamless workflow between multiple different packages that each do their niche thing, but it's all in the same, especially in pipeline, it's all in the same environment. You can kind of figure out what's going on under the hood and you can reproduce it, hopefully, further down the track if you need to. Or other people can take your experiment and reproduce it. And that's actually been demonstrated quite nicely. Demonstrated quite nicely just last week. There's a quite a big article out in Science that they predicted we can see this precursor to earthquakes. They had all their codes and scripts online available. People took the notebooks, did some extra analysis, and maybe disapproved their hypothesis within about three days of it being published. So I thought that's a really nice example of the power reproducible work. So this is kind of a bit So, this is kind of a bit of a workflow that I'll just kind of outline here through his myself. This is actually Elen collecting gravity data in Chile and then all the steps to go through some processing using some various Fatiando packages to get our data ready to look at it over into Simpeg, discrete. Over into Simpeg, Discretize. I talk a little about GeoApps, get our model, then making it look nice with PyVista and some more stuff. Of course, Playtech in the middle, and then our application at the end. So field data reduction, so I'm just going to be talking here about gravity. Typically, with gravity, depending on your instrument, you'll be writing numbers in a notebook or you'll get some text file that you'll have to work with. At GNS, we've got our own. At GNS, we've got our own processing package called GSolve. We're actually rewriting that at the moment, and we might be able to think about using some aspects of Bool for that. But that's basically going to spit out kind of a table of data like this with the relevant station values, values for each station that's become our raw data that we'll process up further. So, here we're going to take our raw file of numbers and we're going to convert it into something that looks like that map on the right. So, for doing that, we're typically doing a bunch of corrections for the reference ellipsoids, taking those away from our data. So Boole has got the packages for that. Then, maybe we'll do some other processing in Harmonica, maybe some upward or downward continuation, filtering, regional. Filtering, regional field removal, and so on. We can grid it up using Verde, and then we can also do things like polynomial surfaces using Verde as some kind of original approximation. Subtract one from the other, and we'll end up with our residual field here. So then we can plot it up using our favorite tools here. So this is all gridded with Verde, this is our wart virgin corrected data. Virginia connected data. This is some kind of regional approximation, and this is what you get if you take better worth of that. So now we've got our data in some kind of format that we can start to interpret. We've got some gravity highs around this main gravity low, but we really want to know: well, what's the physical property distribution that generates this anomaly here? This anomaly here. So, this is where we go into our version. First of all, we need to create a mesh. So, we'll use discretize here. I've been using Octree meshes a lot so we can kind of find the cells around the topography, stations of interest, course the cells away from where we don't need them, just to reduce the amount of computation that we need to do. So we can fiddle with this till we get a mesh that we like, and then we can run our gravity inversion. And then we can run our gravity inversion from Simpag simply using the potential fields gravity part here. The great thing with Simpag has got all the different physicses, magnetics, gravity, various EM flavors. We can run our inversion, probably need to run it several times before we get something we like, and then we're basically And then we've basically got our model now. So I've been working quite a lot recently through DOM with using this GeoApps application. And this is another great example, I think, of open source, the way that Simpeg has been licensed to be able to be reused and modified. So GeoApps, if you haven't seen it, it's a collection of Jupyter notebooks that basically provides a front end for screening. Provides a front end for streamlining inversions. So you don't need to write your own inversion script anymore. There's kind of a standard script where you can still tweak all the parameters that you need to tweak, but the actual script itself is taken care of. So you can kind of guarantee you probably you haven't spent a day or a week writing the script and debugging it. It's already there for you. You can kind of get on with the actual making the inversion run. And that's And that's the thing linked to the Geoscience Analyst, which is a free version, a free viewer, where you can visualize the results as well. So I've been using this quite a lot lately, just to save myself time for writing scripts, but for standard stuff. So then we've got our version, we're finally happy with it. And the great thing here is there's actually a method in discretize where we can write it. Method discretized where we can write it to VTK, and that's going to really then facilitate the next step of like making a pretty picture. So, here using PyVista to basically generate a picture that looks like that. There's a bit of detail via Inkscape, which is our kind of open source, like fiddling with the picture tool. I've forgotten the name of the other one because I don't use it. Of the other one, because I don't use it to make it look pretty. And then you end up with your kind of a final figure which you can use. And typically, I guess for a paper, you do this several times. You know, you maybe make several models, and then you've got to make different figures, slice it all up. Then you can write your document here using LaTeX, and then usually in the middle here, there's some decision to be made about paying some money. Paying some money or like some kind of a form of open access journal. There's a bunch of time that usually goes past, there's a bunch of back and forth, and eventually you'll end up with this, and then you can get your simply grad badge, hip some beers, and celebrate. So that's kind of just a very brief summary of a typical kind of workflow for me that I use quite regularly. It's entirely open source. Source from the data processing through the publication. The great thing about it is this interoperability between several different software packages here, so that I can essentially reproduce the whole paper just by running a series of scripts that enables reproducible science. And so, I guess, just a big thanks to the Fatiando and Symphetic team, the core developers, and all the contributors for allowing that to happen. Thank you. Thank you. Thank you, Great. Questions? Virtual participants can also ask questions. Go record it. So great. Thanks for free talk. I've seen this before, but it's still free. So it's like a hard part of open source is always maintenance. And also, a versus like. And also, like a version is rapidly changing here. And certain process depends upon the maturity of the source packages. So for instance, let's say you publish a 10 years ago. And then at that point, you have a specific version of codes. Now you're using tens from 10 packages. Now, can we still say, even two years later, is it still reproducible? Reproducible, like, I mean, if we manage all the parts, like the versions, and I'm just thinking about the core details, like, okay, if you manage all of the versions and the environment of the setup, then that's actually reproducible. Yeah. But, like, it's the time span of reproducibility is somewhat limited. Like, yeah. What's your, as a practitioner, what's your general kind of thoughts on that? I mean, I agree because there's. I mean, I agree because there's that work we did with the X and D's, which I guarantee I could not reproduce right now. But I think, you know, if you can create, it's more work, but if you can create like those environments with those fixed versions, if they're still, you know, if you're not digging yourself too much of a hole because they're not too old, that's one way of doing it. But I guess, you know, that is an issue to deal with. I don't know the right. Issue to deal with. I don't know the right answer for that, sure. And I guess that also comes with perhaps using code that's still in rapid development. If you're kind of at a leading edge of that, that's a risk that you take to like, well, I can get this result, but I know that the package I used maybe is going to actually be changing rapidly over the year. And so how much effort do I need to put in to maintain? Effort, do I need to put in to maintain what I did two years ago so that somebody can still reproduce it versus just fixing it back to the old version the whole time. I guess at some point you've got to decide do I need to spend the time to update it or not? But yeah, great point. Uh when you said it's reproducible, do you mean it's reproducible for you? Mean it's a closure for you or for like the community and where do you how do you share your code? I mean for everybody? Yeah, because your workflow is the paper. But it's in the paper when you share the stuff. Yeah, so I guess I'm mostly thinking of like say the models that go. Of, like, say, the models that go into the paper. So there'll be like the data, the raw data, and then various scripts that you could use to run the inversion on to get the model. Maybe it's not going to be the same. I mean, I wouldn't necessarily always publish the code for all the figures, but there's nothing stopping me doing that. So it just depends on what level of reproducibility you want to do it. You want to do it. But I guess my point is that all the tools are there to actually do that. So. But you don't actually share the result? No, you could do. Yep. Yep. I mean, you could put them on like Zenodo repos. In fact, a lot of journals these days are now requiring that. They won't publish your work without some kind of repository of the data and Data and code that you use to actually produce your results. And that goes back to that science paper I mentioned at the start. They published all their data, all their notebooks that they used to do their analysis. People were able to take that directly and then actually do some extra analysis in the middle of their notebook and kind of attempt to disprove what they had suggested as a hypothesis. So they were kind of building on, they were able to initially reproduce their results, which is good, and then are able to say, well, if we actually add a few more steps here and clean up some more noise here, your signal disappears. So actually, so two questions. One is how much of the workflow time creation is Time creation is spent on looking at the output formats of one open source program to the input formats of another. Like, for example, what comes out of, I don't know, better there, and then putting that into sync. How much of this is that? Not too much. So, I mean, I guess with the Verde things, the output of that is generally some kind of grid. So, it's more. Grid, so it's more of like a figure, whereas for an inversion, it's going to be some kind of text file of numbers and that. So, it's easy to format those into as an output as one line sort of thing, right? Yeah, yeah. But actually, the thing I would highlight is that when Bain Sullivan started Pythista, I happened to meet him just at the right time. I happened to meet him just at the right time, and so I was kind of talking to him quite a lot and said, Hey, could you, you know, I use the UBC format, could you write a little importer to handle that? And he's like, sure. And the next day he done it. And it was, you know, that, so kind of working with the communities and say, hey, I've got this need here. This is a pretty common format. Here's what it looks like. Are you able to something in your code to? Something in your code to output that. I think there has to be some communication going on in that sense. Yeah, definitely. If you're working towards putting good comment. Yeah. So I think it's worth people who are developing code thinking about am I inventing my own format just for the sake of my own format or is there something Of my own format, or is there something else that I could use that's already doing that job, which you know then makes it more accessible? Because if, say, it's a widely used format already, do I really need to invent yet another format for my data? And my last question was, like, if you already have a very nice and unique workflow that you spend a lot of time building it, are you planning on adding something new or implementing? Do you want to add another part to the workflow? Want to add another part to the workflow that you want to? I think it depends on the case-by-case basis. So this is a kind of a generic example for gravity work, but it's similar for magnetics. I guess it's really around not so much the specifics for each one, but more the philosophy behind it. So, you know, I'll take this general workflow, but I'll tweak it for every single generation. Tweak it for every single thing I do. But it's the same kind of general process throughout. And what I really like to be better at is I could have my own kind of workflow that was a bit more organized rather than kind of take this bit from that script that I used last time and put it over here again. I'm sure we've all done that, but it's kind of like the balance of the time getting organized versus that. Time getting organized versus that versus the actual just getting it done. So, yeah. So, we have a few questions from your two participants. Yeah, we can let them jump in. Leo's is quite timely with the discussion on reproducibility. Leo, do you want to unmute and jump in? I see Leo's still muted. Leo, I can read out your question, but if you do decide to unmute, just jump on and interrupt me. So, the question he's asking is: so he was asking if that was Saki's question with respect to reproducibility. And he said, on top of that, do you think there's a trade-off in terms? Talk of that, do you think there's a trade-off in terms of long-term personal reproducibility from using open source software over something like MATLAB or Montage, which won't change all that much? I guess my experience with MATLAB is that if you are trying to make it available and you use the MATLAB, I can't remember the thing, but there's the export and you know, with this huge amount of stuff, that's tied to Of stuff. That's tied to a specific version of MATLAB. So that doesn't really solve that problem. I mean, maybe MATLAB code doesn't change as much. I don't know. I don't use MATLAB. But yeah, I think it comes down to the stability of your packages. Like, some packages don't change that much. Whereas I guess the tools we've been using here, you know, they're relatively new, there's steep development curves, so you kind of expect they're going to change. Curve, so you kind of expect they're going to change. It's kind of like the trade-off for, like, I'm going to get some cool stuff, but maybe next year I'll have to rewrite my scripts because things will have moved on. But I would have got a lot of benefit, you know, in that time. And it's not going to be a wholesale start from scratch, rewrite. I might have spent like an afternoon or a day, you know, just putting copy, you know, find, replace the right, essentially. If it's that level. If it's that level, sometimes it's like, sometimes it's like, oh, it's a major restructure, I have to kind of add the whole thing. But for me, that's kind of like an acceptable trade-off because I've got some really good stuff out of it. And so a little bit extra down the track to like, oh, especially if people are interested to say, hey, we want to reproduce your work, but this is a really old version. Can you update it? Then it's like, well, sure, I'm now motivated to actually put that effort in because there's that interest there. Because there's that interest there, so on. So, just to Neo jumped in, he's got a vacuum cleaner back now. And he said to clarify, it doesn't necessarily mean other people writing the code, more yourself writing it a year again. So, perhaps kind of thinking about, I'll jump in and Leo, sorry if I'm butchering your question or taking it in a different direction. But perhaps you've got a workflow, as Andrea noticedly pointed out, that you kind of can adapt to other problems. To other problems, do you find that that's easy to continue adapting and working upon in the future? Yeah, I generally do. And I think it, you know, I think there's always the temptation to jump on like the newest version and that requires, oh, I've got to adapt this now, but I've kind of become more like, actually, I'll just stick with this version until there's incremental change that really requires me to use the next version. Because you can kind of, it's always like. Because you can kind of, it's always like, you know, updating is always kind of cool and fun because you're like, oh, I've got new stuff, but you've got to think, is it actually, do I really need it right now for what I'm doing? Yeah. I think Joy, you had a question. Yeah, so when we publish papers, right, there are some aspects of the data processing and some aspects of details. Aspects of details, we don't report, or we just briefly mention in the manuscript. So, typically, for researchers, especially for students, to reproduce everything, they need many more details than what's reported in the manuscript. So, do you think or do you think it's, do you actually do this? Do you think it's necessary to publish a separate documentation? I mean, separate from your main manuscript? Manuscript. Submary documentation, just detailing the step by step, step by step. I don't know if people do that, but to me, I think for students, that's probably more helpful than just reading papers with a whole bunch of codes. Yeah, yeah. Yeah, I agree. I think there's always a trade-off of the amount of time you have available to do the job. The job, and maybe in your situation where your students are wanting to reproduce that, it's more important. Whereas for me, it's kind of like, you know, it's been a long journey just to get to this point. And by the time I submit it, I'm kind of like, sure, I'm done. But I do see that it would be good if I had the motivation and the time, most of the time, to actually say, oh, if I spend another couple of days. Say, oh, if I spend another couple of days tidying this up, making it all good, and if my skills and some aspects were a little bit better to help manage that, then I could have a really nice quality resource there. That could be a tutorial or something. So I think it's kind of, it depends what your position is, or what you're where you're coming from in terms of the work. So I think at the bare minimum, you should be able to. Be able to, and I think journals are becoming more and more requiring this kind of stuff, so I think it's only going to increase. But you know, whether you need every single detail to be reproduced or not, I think so long as you can reproduce your model, but perhaps whether you need every single step from taking my scribbles in my notebook through to a final figure. Of figure. Some steps are kind of standard, I guess, so it depends on where you want to draw that line. Thank you, Chris. Thank you for all the questions. We have more questions online. So what I'm going to encourage you all is to post questions in the Slack channel. You can pick Craig and you can continue your conversation from there. Okay. So we'll move on to next speaker.