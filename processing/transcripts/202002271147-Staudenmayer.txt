So, we all want to be rock stars up here, you know? But probably this is where I want to be today. And there's nothing wrong with being down here either, because the average audience member is overrated. If you want to talk to a subset, that's fine also. But I'm going to try to be up here. And we haven't seen talks here, luckily. Okay. So I'd like to do three things. So I'd like to. So, I'd like to, we have a big data collection project called Mocha, and I want to describe this to people. And then, and so really what I'm doing is a lot of times statisticians, we get crappy data, and we develop new methods to try to address the crappy data. And I'm not doing that. What I'm trying to do is collect better data. And then, after I show you the Bunker Project, I want to convince you why we are undertaking this crazy endeavor. And then, And then I'll call it the bigger picture because, but really, then there are some things that I want to say, some comments that I want to make. I'm after that. Okay, so these are my collaborators, John Serard and Patty Friedson. John's a professor at UMS Amherst, and Patty Friedson is emeritus at UMS Amherst. We all look older because we've been through the MOCA project now, too. So, the goal of the MOCA project is to increase. So, the goal of the Mocha project is to increase the validity of accelerometer-based estimates of physical behavior. So, by physical behavior, I mean, say, sedentary time, or time in MVPA, or bouts, or the various stuff we've heard about over the past few days when people talk about accelerometers. And the project is focused on 18-month-old to 24-year-old people. That wasn't our plan, but that's what got funded. And then the way we're going to do this is we're The way we're going to do this is we're going to collect a lot of labeled free-living accelerometer data. And I'm not going to talk about the modeling part, but the next, once we have the data, then there's going to be modeling also. And these data are not going to be sufficient to address to answer our problem, but with other people's work, hopefully if we combine that, then it will address this goal. So, what is most So, what is Mocha? So, the proposal was to recruit 300 participants in those age ranges and spread across those age ranges in various categories. And then to recruit them to four one-hour sessions in different settings. So, we're not going to tell people what to do, but we're going to recruit them in a different setting so that we can get a diversity of it. Different settings so that we can get a diversity of activities in those settings. And the settings are home, school, community, and exercise. And they're going to wear an actograph on their wrist, an actograph on their hip, both at 80 hertz, the three axes. And they're also going to be video recorded during those sessions. And okay, so that's what the data are. And then the So then, an army of undergraduates supervised by graduate students will watch those videos and in a structured way annotate what is happening in those videos. And by annotate, so we're talking about the behavior, which involves posture, the activity, the energy expenditure, relative energy expenditure, which comes from the compendium. Which comes from the compendium of physical activities, and a tag for location, or for locomotion, and maybe some other tags, also. So the goal is once we have this stuff, then we can derive the measures of physical activity that we're interested, or the measures of physical activity and activity that we're interested in. Relative energy expenditure, sedentary time, walking time, out durations, etc., etc. Okay, so. Okay, so the this talk is not going to take 15 minutes either. I'm realizing now. So the type of data that we get at the end of that process is we have an accelerometer signal. So this is not a signal from this project, but this is a cartoon and stand-in for it. We have three axes at 80 hertz. At 80 hertz. And then at each time point, there, we also have an indication of what the person was doing from that activity, et cetera. These are the labels. And then we also have a label of relative energy expenditure, which then could be used to define, you know, you want to say MVPA or you want an older person's version of MVPA or whatever. But here are the labels that we're going to want to be able to predict, and here's the data. Here's the data that gets labeled. That gets labeled. Okay, so this is. So, why the heck are we doing this? You know, this seems like a, this seems, this is a lot of work, you know. Oh, and I should also say, we're manually annotating this stuff here. It would be awesome to have help from people that do, that process video signals to give some aid. Signals to give some aid to the manual coders. Maybe, or it would be awesome to have a magic wand and have a computer code this for us, but maybe we're not there yet. But anything that could help this annotation process would be great. We're collecting these data. There are other groups that are also collecting video, sort of video annotated data. And the videos are on hard drives, and this is a future R21 or a future R01 to develop. Or a future R01 to develop methods to help annotate visual data. Okay, and why is this important? Well, let me talk. So this is a grad student, Rob Marcotte. You probably haven't heard of him yet, but you will in the future. He has a bright future ahead of him. And he took the quasi-adult sample that we have, so the 18 to 24-year-olds, about 50 of them. So that's four hours each for 50 people. That's four hours each for 50 people in those four settings, more or less. And this is a very healthy group. So, this is a crappy sample, right? But it's what we have. And he's focusing just at looking at existing methods that we have to classify sedentary time. Let's look at how those existing methods do relative to Do relative to the ground truth of direct observation. So, the methods that we're using for the HIP, we're using some cut point methods. We're using some statistics, I'll call it statistical learning since I'm a statistician, but it's machine learning. Methods that were developed by Pate and some other people at UMass. And then another cut-point method developed by a group in Europe. So, cut-point methods just means that if the just means that if the measurement, if a measurement from the accelerometer is above a threshold or below a threshold, you call it sedentary. It's above a threshold, you call it, you know, it's the simplest thing you could imagine. And then for the rest, there are some cut point methods. There's a cool idea called sedentary sphere, which uses arm angle and activity. Other cut point methods. And two statistical learning methods. I won't tell you who developed these methods because they didn't do very well. Methods because they didn't do very well. But, and YarlSlaw's new method is not on here, so maybe it would do much better. But the thing that you should take away from this is these are relatively simple methods, okay? Or developed on not a large data set, or an appropriate data set for the problem of interest. So let's see how this stuff does. So let's see how this stuff does, how this stuff does. And I'm going to show both accuracy and a measure of precision. So good news for the HIP methods. So the 100 count cutoff is probably the most common one that's used, and it's relatively unbiased. So we're biased on the y-axis. This is out of an hour or two. So that helps you sort of gauge what 10 minutes means, a bias of 10 minutes. But it's relatively But it's relatively unbiased in a population. You know, there are some crafting methods, but the cut points you use, the work more the sojourn methods, those work pretty well. That's good news. And I think that this is, there have been other papers, so Sarah has some older papers, has some papers also that agree with this. So we're not the first ones to show that. The bad news is that. The bad news is that the HIIP method is not all that precise. So the mean absolute error is the measure of precision, or percent agreement over there on the right. Sensitivity and specificity were similar in this. But this is a hard sell because the precision is measured on second-by-second classification. So if you're wrong on a particular second relative to the video, then it's incorrect. That's it's incorrect. So, if you smooth that a little bit, this would be a little bit better. So, it's not a magic wand, but it isn't terrible. This is for the hip. For the wrist, you know, it's poor. So, this is, we're just trying to detect non-movement here. Well, we're trying to detect non-movement. We're trying to detect non-movement and sitting down. So, some of the problem is that the risk confuses sitting down from standing. You know, if you're standing still, you're not sedentary. But we didn't find any unbiased methods. So, again, maybe your Oslaw's method is unbiased. We can check that out. But we didn't find unbiased methods. And so there this is this is for walking or just standing? For walking or just standing? Oh, this is just sedentary. Okay, just sedentary. This is all about sedentary. The example I'm showing is all about just detecting: is someone sedentary or is someone not sedentary? Supposedly an easy problem. Right? Yeah, the cut point should work well. Well, the cut points work well for the hip if you only care about bias. If you care about some measure of precision, okay. Okay. We have to be a little bit more careful. But the fact that the adaptation was actually taken from the videos, and the students who were making this adaptation might have messed up especially. Yeah, no, I'm not talking about quality control, but there's a ton of quality control that goes on. And yes, no, this is a serious concern. Do I believe that there are some errors in the annotation? Probably. I think that there are fewer than. Probably. I think that there are fewer than there were yesterday, you know? But there's a lot of quality control, and I could talk about that, but it's I've got I have 15 minutes, okay? You know, but we do the sensible things where we, you know, so people have to pass tests on standard videos compared to an army of expert observers. We go back and we spot check, you know, things that look, we screen the data to see things that look weird, et cetera, et cetera. The data to see if things will look weird, et cetera, et cetera. I believe it. You can trust me or not trust me, but I believe it. So John, sedentary is defined in terms of macro expenditure. No, it's sedentary is determined in sedentary is energy expenditure and posture. So if you're sitting down lifting weights, you're not sedentary. If you're sitting down and moving not too vigorously, then you are sedentary. Or lying down. Than you are sedentary or lying down. But Chiprian, cut points should do well. Okay? Cut points don't do well, is what the data say here for the wrist. Yeah, but go ahead. You have 15 minutes. And the precision is even worse from the wrist. Okay, so now what do I want to say? So the sedentary time classification difficulties were just an example. Classification difficulties were just an example. There's another student who's not done with the paper yet looking at the validity problem for MVPA and for other measures of physical activity. And it doesn't get better when you try something harder than just estimating non-movement, believe it or not. In our example, hip worked better than wrist. I'm not sure that that's true in general. I think it might be that cut points would work better for the wrist, but I would, you know, pet the But I would bet the money in my pocket that statistical learning with enough data could do better from the wrist. So, more data, there's a need, I think, if we think this is an important problem, then larger and more diverse training, free-living training data sets are probably necessary to make transformative progress here. And I'm also making an assumption here. So, one of our rock stars So, one of our rock stars yesterday talked about that there's no magic bullet. It's not one measure that leads to health. It's a number of measures. And I think that the benefits of physical activity also probably accrue multivariately. So it's not just total activity. It's this vector of descriptions of activity. And those are behaviors. And I want to estimate behaviors. I don't want to just take the output from a signal and treat that. Take the output from a signal and treat that as a Y in stats. And I think that that's also important because behaviors enable public health interventions and messages. And there's an established EPI literature that talks about the relationship between behaviors and health. And in order to find out what is important and what is the minimum effective dose and stuff like that, we need to focus on behaviors, not just on whatever our device gives us. You know, whatever our device gives us. Oh, and if you like mountains and you like statistics and devices, et cetera, there's going to be a conference in Keystone, Colorado, which is a wonderful place to have conferences, in June 2021, ICAMPAM, which is the meeting for the International Society for the Measurement of Physical Behavior. And it's a fun conference. It's a conference like this that will have more people that are sort of public health type people, but it would be great to have more quantitative scientists. People, but it would be great to have more quantitative scientists there, also. Thank you. Jennifer. So your assumptions were based on the population that's 18 to 24 years old. But the coaster cut point is based on a sample with a mean age of 78 years old. So I'm not surprised that it's biased here. And so we've actually looked at that in several of our populations, not in Our populations, not in depth where we're actually observing what they're doing, but looking at points of overnight activity and trying to get this idea: are they moving yes from now? And we've had actually really good agreement with that 1853 number. Okay, this compared to what's the criterion measure? What do you mean? So you say you have good performance, so how do you know it's going to. No, it's not performance. I'm saying looking at the overnight hours, like between 11 p.m. and 6 a.m. where we know they're doing little to nothing, maybe even sleeping. We've had, we see that. We've had, we see that that 1853 number is pretty good across multiple studies of older adults. So I'm not surprised you don't see agreement with the younger people. But when you say pretty good, it's compared to direct observation in free-living people? No, we don't have direct observation. I've said that. This is overnight. This is, you know, we don't have it because it's thousands of people. So looking at the population level, I'm sure there's a lot of variability between people, but at the population level, I don't know. I'm just saying we've had good agreement with it, and I'm just curious, and part of the reason you're I'm just curious, and part of the reason you're seeing the bias is because you're looking at it in people who are 60 years younger than what that measure was created in. That's all. Sure. Yeah, no, that's a. Is that a question? I'm not sure. I don't know. I'm just curious if you've thought about that at all. I mean, if you looked at the age range of the cut points that were over here, there's no question that we need larger training data sets. We are close to that 1853 number. 1853 number in the overnight hours. So I'm just, I guess I'm just kind of defending that cut point a little bit. I think we need to look at it. Yeah, I'm pushing back a little bit, though, to say that I don't know that you have a good criterion measure for free-living people to say that that's a good measure. Why? If we know it's at night and we know in general they're not moving much. But that is until you during the day the sitting. I'm not looking at the day. I'm not looking at the day. Well, that's what the threshold's meant to do. Let's take this offline. I think that's the initial problem. I think I think. So I think the definition is a little bit different. So one thing is not moving. And actually I think that not moving in older and younger populations probably it's about the same thing. The things that are different are in the definition, in the posture. And I think that that may have something to do when you stand up that you may actually move a little bit more. I think it's a fantastic data set and a fantastic talk. Said and a fantastic talk. I wonder whether you would plan to go back to some of these results and see where they fail and why? Yes. I think that would be super exciting to see. Are they totally wrong or are they missing something because of that? No, so we have confusion. We have lists of when, you know, if there's a false positive, what's the actual activity? If there's a false negative, what's the actual activity? And we're certainly going back in to try to figure out what's. To figure out what's it's hard, right? But yeah, look at the data and say, why has this failed? Was it the two failure or was it because it could be that the axon matter was good? Well, your comment gets to it. I mean, you can be inactive standing or inactive sitting, and the criteria cares, cares, posture, and device doesn't. We see more problems with wrist data, though, with sitting and driving, and as we've talked about before, and sitting and typing. So, at work, the wrist is. Setting in typing, so at work the risk is worse if you're just using a threshold approach. So I think it goes both ways. So I was going to ask about the other piece of the criterion that you mentioned for seturing that you said it's posture plus energy expenditure. Like sitting would count, but sitting and lifting weights wouldn't count. And I wonder, is there a way from any of these devices that you can get at that piece of energy expenditure? So if you're sitting and you have enough movement in your And you have enough movement in your wrist, then, I mean, I don't know. This is a good question. I'm sure that there are some ways of sitting and expending energy expenditure that will not be picked up by a wrist. This is not going to be magic. But at that point in time, but does the surrounding accelerometer signal tell you something about that? Accelerometer signal tells you something about that. So, what you're doing before that time point, what you are doing after that time point, might inform whether you're sitting on a stationary bike or whatever. To Jeff's comment, even if you detect the motion, you can't tell if it's a pom-pom or 100-pound barcode. I guess like as much as anything I'm I I don't know, I don't know that, you know, activity counts as the way to get through energy expenditure in in uh that sort of yeah, low bearing environment. Yeah. Low bearing environment. Yeah, yeah, no. I mean, presumably it's not. And even a higher, even a signal beyond activity counts, you know, three axes of acceleration, maybe plus the gyroscope. Maybe that won't get it for you either. Mr. John. Thank you. We went to our last speaker, Loki.