Okay, so things are audible and visible. Okay, great. Let me know when I should go. Oops, did I lose audio? Or people can hear me, right? Yes. Right, yes, okay, and I'm good to go. Should I start? Yes, please, Maru. Okay, sounds great. So, I'll tell you about some recent work on streaming and some sketching works on constraint satisfaction problems. This is joint work with a whole collection of people. I'd like to give a shout out to Santoshni, who's also online somewhere. Santoshni, you can wave your virtual. Wave your virtual hand if you want. All right, so what's this talk going to be about? I'll tell you a little bit about what constraint satisfaction problems are. Just make sure we are all on the same page, our results and some proof ideas. So relatively straightforward. So just want to make sure that we are all on the same page. We will be talking about maximization of constraint satisfaction problems. What are these? Each problem in this class is specified. Class is specified by two integers and a finite family of functions. Q is the alphabet size, k is the arity. You can think of it as the maximum arity of a function. Every function looks at k variables, exactly k, just to keep it simple, and then either likes or dislikes certain assignments to those variables. You have an entire family of functions. An instance of this problem, so these three parameters specifically. These three parameters specify a problem, and there are infinitely many problems in this class. A particular problem in this class is then got many instances, and an instance is specified by n variables and m constraints. Each one of these constraints picks out k distinct variables from the set of n things, and in fact, in a particular order, and then requires that one of the functions from this class be satisfied. Be satisfied. Okay, so that's the basic object. And what we are interested in is maximizing the fraction of constraints. So I think today I'll be doing sorry. So fraction of constraints, which are satisfied by this the maximum overall assignments of the fraction of constraints that can be satisfied. That can be satisfied. Now, familiar problems like maximum cut, maximum directed cut in a directed graph, SAT, colorability, et cetera, et cetera. Many of them have constraint satisfaction problem formulations. And we are interested in trying to understand the approximability of all of these in the streaming setting. One quick note: Was there a question, by the way? No, and by the way, feel free to. And by the way, feel free to interrupt me. I can even see the chat screen, so I should be able to keep track of that. But if I don't pay attention to it, give me a shout out on the audio and then I'll try to answer that. And of course, people in the room should definitely speak up. And hopefully, we'll be able to hear you when you do that. All right. So a special case that I want to mention is just because some previous works talked about boolean. Talked about Boolean constraint satisfaction problems. And Boolean ones are different in the sense: not only is the domain size Boolean, so variables only take values 0 or 1, but also people tend to differ in the convention. And there they actually apply constraints to literals. So I might actually pick out x1, x2, complement, and x3, and so on, and say, well, some function of these things should be satisfied. This is a restriction in two ways, both. In two ways, both the literal part of it and the alphabet part of it are restrictions. When we talk about query things, it's not even clear what should a literal be, so we never will talk about literals. Here, functions just have to be applied directly to some sub-sequence of variables. Variables are always distinct. Okay. And the class of things that we are looking at is definitely richer because even though when I fix a family, Boolean Max CSP may not be the same as Max CSP. CSP may not be the same as Max CSP. I can actually express any fun constraints on literals by amplifying the set of functions that I have. And the first function, the family might apply to all variables unnegated, the second one to the first one negated, etc., etc. All right, so that's the set of problems we'll be looking at. Hopefully, this is familiar to you, but definitely do feel free to ask questions whenever something is unclear. Unclear. Now, streaming and sketching. Once again, streaming should be pretty familiar to you. Sketching may be not familiar to everyone. In streaming, we think of all these constraints as appearing one at a time. Say, know exactly how many variables there are going to be and exactly how many constraints there are going to be. Not knowing these is not going to make a big difference. So we'll stick to the simpler format. But the constraints appear one at a time and say this particular set sequence of Say this particular set sequence of variables, apply this function, this sequence of variables, apply this function, etc. etc. At the end, what we are interested in knowing is the maximum fraction of simultaneously satisfiable constraints. We are not interested in the satisfying assignment. Finding an assignment, in particular, representing an assignment in your head, may be just too expensive. That may be much over the space limit that our algorithm has. So, we are interested in algorithms which use very little space. Which use very little space. S of n is going to be the parameter, typically, kinds of things that we will think about space as polylogarithmic space or square root space or almost linear space. And try to determine the maximum fraction of simultaneously satisfiable things or approximate them. Now, a special subclass of streaming algorithms that we'll be considering is what's called sketching algorithms. So, this is perhaps something. Algorithms. So, this is perhaps something that not everybody might have seen before. So, let me briefly say what this is. Usually, in a streaming algorithm, you say, well, once I've seen the sort of the first half of the stream sigma, I should be able to present some sketch of or some compression of this thing. The state of the algorithm is some S of sigma. And given S of sigma and tau, I should be able to figure out what should be S of sigma and composed. S of sigma and composed with tau. But in streaming, in sketching algorithms, I expect a stronger composability. If I give you just the sketch of the first half and the sketch of the second half, I should be able to compose the two together and get the sketch of the combined thing. So this is not a feature every streaming algorithm has, but many familiar streaming algorithms do have this feature, especially those that tend to compress. Especially those that tend to compress by a linear, you know, multiplying the some the input represents some vector in some form, and you are storing some linear projection of that of the input at all times. Those tend to be sketching algorithms in this sense. And our algorithms, our results will often talk about the general case, but the ones that talk about all cases are the ones that talk about sketching algorithms. Are the ones that talk about sketching algorithms? All right. Now, solving CSPs exactly is always tends to be hard. It will also continue to be hard in the streaming setting. And in streaming setting, hardness results are typically unconditional. They just come out and say, okay, there's no, we don't have to assume NP is different from P, et cetera, just because these are much more restricted forms of algorithms. The usual notion of approximation is. Of approximation is, you know, an alpha approximation. Here you say that you would like to output a value which is upper bounded by the optimum, but also at least alpha times the optimum. So the larger the alpha, the better the approximation. Now, in complexity, we often talk about gap problems. And here I will talk about those quite often. The gamma-beta distinguishability. The gamma-beta distinguishability problem. Here, you will be promised that all instances will have optimum at least gamma or at most beta, and you have to distinguish between the two. And roughly, this gamma over beta is the approximation factor that you're able to receive. This is a more refined notion in the sense that when beta is very close to one, or rather, when gamma is very close to one, maybe beta can be pushed very close to one. If that's the case, we will understand. If that's the case, we will understand that. If that's not the case, we'll be able to prove that, etc. So, this is more expressive, but this is the version that somehow also fits our study well. Okay, any questions at this stage? All right. So, before going into the kinds of things that are possible, let me, sorry, that are non-trivial, let me talk about some trivial approximations. In general, if you're given, you know, you In general, if you're given, you know, for instance, max cut, you know, the input could be potentially on n vertices, the input can be of size n squared, but you never really need n squared space to solve any problem. The reason for that is you could just take a random sample of all the input instances, and this random sample of about linear size will roughly be able to give you a very good approximation to the optimum solution. So, in fact, if you're willing to spend So, in fact, if you're willing to spend exponential time computing the optimum max cut on a linear size graph, then you can actually get a one minus little of one approximation to the size of max cut with O tilde of n space. So this is a trivial space bound, and this is the maximum space bound we will ever talk about. On the other hand, if you are given constant space, you still have non-zero approximations. Non-zero approximations, which should be defined as being trivial. So, for instance, in MaxCut, an algorithm which always outputs half is always correct because every graph has a fractional solution, which cuts at least, has a solution which cuts at least half of the vertices, half of the edges. So, a half approximation is trivial. In the usual literature in optimization, if you've seen this, this is usually expressed as, oh, what can I Usually expressed as: oh, what can a random assignment do? Now that's the wrong formulation of this definition because for constraints which are always satisfied by, say, the all ones assignment, if you have a family of constraints that are always satisfied by the all ones assignment, a random assignment does not give you satisfy 100% of the solution of the constraints, but the assignment of all ones does satisfy 100% of the constraints. So here is a more trivial definition of Trivial definition of triviality. If there is no instance that has value less than some number, then that's our definition of trivial. Okay, so you can always output Roman and you're always correct because there is no instance which actually achieves value less than Roman. Okay, so this is going to be our notion of trivial. This actually is a specializes to the value of the random assignment for Boolean CSPs, but CSPs, but actually, we will, you know, it works very well in general, and it's trivial. So, these are two set trivial settings, maximum space, best approximation, minimum space, worst approximation. And now the question is, you know, when can you do better and how much better? And really, we want to get very, very refined pictures in the future. Okay. All right. So, a little bit of salesperson. All right, so a little bit of sales pitch. I don't want to spend too much of our time talking about this, but yes, CSPs are of natural interest because there are natural problems. And we all know from the study of CSPs in other contexts that they always allow the possibility of classification. And classification in general is nice for a couple of reasons. One is that these actually highlight very general phenomena. So they tell us what are the interesting algorithms out there, because I've completely classified. I've completely classified the optimization of an entire class of problems. Well, what were the algorithms that we used? Well, you have to, you know, if I write a finite sized paper, there has to be a finite number of algorithms out there. So, you know, there you are. So somehow it tells us about all the interesting algorithms that are there. It tells us about phenomena, like, you know, in all these explorations of streaming algorithms, we never found data to the square root of n. to the square root of n square root of log n space algorithm or all the approximate you know approximabilities of optimization problems we rarely ever find an optimization problem whose approximability looks like this why does this happen well constraint satisfaction problems uh tend to be uh you know occupy a majority of our interest and in these spaces these algorithms do not exist they simply you can either do better or you can not do anything at all okay Do anything at all, okay? Um, all right, so turning to CSPs. Well, yes, question: Was there a question there? No, okay. So in 2011, there was this famous workshop in Bertinoro where we basically said that. So we know nothing. It was sort of the first time we ever realized, oh, there should be some work on. There should be some work on CSPs. Actually, I asked Roby about this recently, and he said, Oh, actually, we only asked about max cut over there, but yeah, even for the max cut problem, which is sort of the most basic question, we actually didn't know anything about that, neither positive nor negative, nothing non-trivial, nothing trivial. Sorry, nothing, no non-trivial algorithms, no lower bounds. And then in the period from 2015 to 2015. The period from 2015 to 2019, Michael and others worked on this question. And we started getting some idea of the lower bounds. And eventually, what the final ultimate result, this is a beautiful result due to Michael and B3 Kachun, which says that basically any non-trivial approximation, half is a trivial approximation, any non-trivial approximation requires Requires the maximum amount of space that you can think of, more or less. So up to the tilde factors, this is linear space lower bound, this is a linear space lower bound, and up to tilde factors, this is optimal. So that I'll tell you a little bit briefly about this result, not the omega of n lower bound, but maybe the square root of n lower bound. But that was the state of affairs till even five years back. You know, five years back. And at this stage, if somebody had said, you know, okay, look, this is what we know. What do you suspect the picture of the world looks like? I would say basically every non-trivial approximation is hard. I mean, you have a vast constraint satisfaction problem, n variables, m constraints arriving, and then at the end you're asked some question. What could you actually really say? And my guess would have been nothing non-trivial. Okay, I can obviously always output Roman, and that's a constant factor of. Roman, and that's a constant factor approximation algorithm, but that's the best you can do for any problem. And this picture was changed by some works of Santoshni with Guruswami and Amaya Villinker, and also with Chauvo and Galevnev, where they started getting non-trivial algorithms. And this was a sort of an eye-opening moment for me, at least. A problem like maximum directed cut turns out to have a non-trivial algorithm. So that was very surprising. And in fact, Surprising. And in fact, by the time Chav Galavnev and Velashrami were done, they even started getting classifications. So, for instance, they could say for every Boolean max CSP with on two variables, where the constraints are on two variables, they could classify its approximability completely. And this approximability would be, you know, pinned down exactly up to a certain value of alpha. This problem is. Of alpha, this problem is approximable. Anything beyond that requires square root of n space. Okay, so it wasn't just that we were starting to get an idea, we were getting more or less the optimal idea over here. But unfortunately, this work only works for k equal to q equal to 2, at which stage you have a finite number of different problems to work with. It's only when you start looking at k and q going to infinity that you have infinitely many different constraint satisfaction problems to look at. So, what we were able to do is to get a dichotomy for sketching. So, this is joint work with Chao Golovnev and Velashami. We are able to get a dichotomy for sketching for every problem, for every gamma, every beta. Either you can solve this problem in polylogarithmic space, or it requires at least the square root of n space for a sketching algorithm. Okay, so this is the result that I will mostly focus on. Is the result that I will mostly focus on the rest of the talk. A few other, few interesting consequences. So it wasn't immediate from our paper, but this is true, that actually we give polylog space algorithms for infinitely many constraint satisfaction problems. So we classify everything, but actually our classification is kind of non-trivial in the sense you have to look at gamma, you have to look at beta, and you have to look at the family of constraints that are available to you, do some computation on it. It's not Do some computation on it. It's not that there is a closed form expression which explains what happens now. Do some computation on this description and then come out with an answer saying, Okay, which one of these two settings are you in? But it does turn out that there are many new algorithms in this thing and infinitely many ones. So this was proved in follow-up work, which I unfortunately don't have references for right now, but Ghoshni is one of the co-authors on all the results that I'm All the results that I'm thinking about. And finally, I mean, while we are ruling out sketching algorithms for every problem for a very, very broad, again, infinitely large class of problems, we actually rule out streaming algorithms generally and just say omega of n square root of space lower bonds do hold. The gap between sketching and streaming remains one of the big open questions in this area, and I'll try. And you know, I'll try to say a few words about it towards the end. All right, so this is as much most of this dichotomy is for square root of n space. When we go beyond, well, it's our knowledge is a little bit worse, but we are in a further follow-up work, and this time with one of these V's being Amaya Velinker added to the set of authors. We have linear space lower bounds. So this is. Linear space lower bounds. So, this is extending the Kaparolov-Kratchun result for a broad class of functions, but it is not a very cleanly defined class of functions. It's not something nice. It's just, okay, this is what we could work with. And what it does is either you can use it as saying, oh, gives tight an approximability for linear space algorithms for a broad class of functions, or Broad class of functions, or for every function that you want to consider, every family of functions, you get the, you nail down the approximability within a factor of q. So it's an approximation to the approximation factor. And it's a q factor approximation to those, the approximation factor for every problem. So this is the remaining amount of uncertainty for every problem. And there are some further results with Noah Singer, where we get results for what's called order. Results for what's called ordering CSPs, but I won't tell you about those today. So that's it. So that's the statement of results. Certainly happy to take any questions at any stage. Anyone? All right. So if not, we'll jump to some ideas. So are those results in the worst case or random order? Two things change if you. Okay, that's like a thing. That's why I don't. Fantastic. So, in fact, work that I'm not advertising today, but now I am, is some follow-up work with Santoshni, Noah Singer, and Raghuvansh, who's hopefully also somewhere around here, and where we do consider random ordering. Most of the all the results stated here are for worst case ordering. The first result for max cut actually held for random ordering also. But as far as I know, even the omega of n space. I know even the omega of n space lower bound for Max Cut has some worst case ordering to it. And certainly the future, but in what we are seeing in our new paper is while many of these results can be extended to random ordering, there exist problems, in particular the directed cut problem. The directed cut problem seems to be the highlight problem in this space. In this space, that's the, you know, it's really the problem that's most exciting to watch. And this problem actually has much better algorithm. Well, it's better, a better approximation factor provably under random ordering than it does under worst case ordering. So you for MaxCut, can you or you cannot run Romans-Williamson in this? No, you don't have time to run, you don't have space to run Gomans-Williamson. Romans-Williamson. So you cannot do anything. So, MaxCut, the belief is that under random ordering, you should not be able to do it. Even under random ordering, you should not be able to do anything. And what we've proved so far is that under worst case ordering, you cannot do anything. Okay, thanks. Any other questions? All right, so proof idea. So let me start with the game. Let me start with the game. Here's an example of MaxCut. And the claim is that actually this graph is either bipartite or it's completely random. And okay, and so I hope you're getting an idea. Okay, so that's what a streaming algorithm sees, right? So, you know, how many people would be surprised at this stage? People would be surprised at this stage to say, I can't tell whether it's a bipartite graph or a random graph. I mean, you know, you can't tell, and the streaming algorithm cannot tell. All it requires is a proof. Okay, so indeed, this is what turns out to be true. A nicer distribution, which is actually not invariant under random permutations, is the following. We take, so what's an input to So, what's an input to a MaxCut? It's a sequence of edges. We'll divide the sequence of edges into a constant number of chunks. Each one is almost linear size or epsilon times n size for some small epsilon that we pick. And we will then ask, okay, look, at this stage, I'll give you a matching. Okay. And well, it's a matching. So obviously it's bipartite. Okay. And Bipartite. Okay. And but there is a hidden bipartition which I might be using to seed all of these random things. Or it may be that I'm just giving you random matchings. And the fact turns out that these two are actually indistinguishable. And how is this, how do you prove this? It's not, turns out to be not so hard given very nice previous work. So in particular, Ronald and others have very nice. Have a very nice lower bound on what's called the Boolean hidden matching problem. And what they show is that when you actually see one of these substreams, even if Alice knew exactly what the hidden by partition was, and Bob, and so at this stage, maybe Alice knows exactly what the hidden bipartition is, sends a message to Bob who sees the remaining edges, and Bob has to determine: was this bipartition respected? And was this bipartition respected or was it just random? Turns out, this is impossible to tell if Alice's message to Bob is less than the square root of n bits long. Okay. And now, once you have this, basically you can do a hybrid argument, which sort of says, oh, after the first so much, the polynomial space, the square root of n-space algorithm, which can be simulated by Bob, didn't learn anything. Oh, another sequence, Bob still didn't learn. Another sequence, Bob still didn't learn anything. Another sequence, he still didn't learn anything, and now you're done, and you haven't learned anything. That's morally what happens in this proof. And, you know, one can work this out. And with, so armed with this tool, the hidden matching lower bound, this proof is really very, very straightforward. By now, you know, we sort of think of it as very easy. By the way, let me advertise Noah Singer's bash. Singer's bachelor's thesis has a nice summary of this proof written with random unions of matchings and so on. So it's a nice reading. Now, there is a much more, if you like complicated proofs, there's a much more complicated proof out there of a much more powerful result. I won't get to it today. This is the omega of n space lower bound due to Kaprillova and Krachun. That's, you know, you. Cratchoon, that's you know, you that really needs to do much more careful thinking, and this reduction to one-way communication doesn't really work there. All right, so that's all I want to say about that problem. And I have a slide on what the Boolean hidden matching is, but I won't dwell on it. I might come back to this kind of a problem later, but not really. So, now I want to turn to so where are the non-trivial algorithms? So, recall, we just saw this instance where This instance where the optimum value of max cut could have been 100%, every edge crosses the cut, or the graph that you're given is a completely random graph. And we said you can't tell the difference for max cut. Now, what's turning out with die cut is something very different is actually true. If I give you a graph which has, say, 100% of its edges going from left to right, and you don't know what's left and what's right, versus a graph which is a random graph. Versus a graph which is a random graph, you can tell the difference. In fact, this is much more qualitative. If I throw numbers, hopefully they're correct, but may not be tight. So either 99% of the edges are crossing the cut in the right direction, or at most 90% of the edges are crossing the cut in the right direction. These two can be distinguished. So this is pretty surprising. So die cut is not behaving the same way. So, die cut is not behaving the same way as maximum cut. And let me try to give you a little bit of an idea of how this is shown. So, this was shown by Guruswami Velinkar and Velaswamy, and then Chow Gulavnev and Velashami. What they do is define this very natural quantity associated with a graph, which is the bias of the graph. What's the bias of the graph? Well, we start by defining a bias of a vertex. A vertex has some edges coming in, some edges going out. You look at the Some edges going out, you look at the difference of these two numbers. That's the bias. And the bias of the graph is you sum up these numbers, the differences in absolute value, and you take half of it, half just to normalize it so that it's a number which is between zero and m, the number of edges. So if the bias is very large, it's sort of suggestive that every vertex has either got all the edges coming in or all the edges going out. Edges coming in, or all the edges going out. This suggests a natural partition, which will take all the vertices with edges all coming in and put them on one side of the cut, all the edges with vertices with edges mostly going out, put them on the other side. You should get a pretty large cut. And much of this turns out to be true. Once you have the bias of the graph, it's very easy to come up with a non-trivial approximation of the dichotte value in the graph. Uh, of the die-cut value in the graph, in fact, it gives you a two over five approximation. The trivial would have been one-fourth. If you take a random cut, you cut one-fourth of the edges. The most important observation here is that you can actually estimate the bias of a graph by standard L1 norm estimation algorithms. Because at the end, what are we looking at? You have a vector in n dimensions that you're trying to maintain called the bias vector. Vector, it has one coordinate for each vertex. This vector, as I've defined it here, it's a vector with positive and negative entries. But the bias is really the L1 norm of this vector because I want to sum up the absolute values of the entries at the end. Each edge that comes in updates this vector by saying, oh, add one to the in-degree of this vertex and add one to the out-degree of that vertex. So add one to the bias here and subtract one from the bias there. Bias here and subtract one from the bias there. These are linear updates. So you're trying to maintain the L1 norm of a vector with linear updates in the turnstile model. And this is pretty much the textbook problem in streaming algorithms. It can be done with a polylog space sketching algorithm. So because this can be done so effectively, you can compute the bias and then you're in business. You already get a two-fifth approximation and each one of these. Fifth approximation. And each one of these inequalities that I've written down here is a very good exercise in graph theory for beginners. Okay, so you don't really have to do much to prove any of these things. So you have a good approximation, non-trivial. Can you do better? And Chow Galavnim and Valasami actually answered that question. They said, well, you know, here is a different inequality about how large the die cut is as a function of the bias. It actually looks like m over 4 plus. Actually, it looks like m over 4 plus bias squared divided by 4m minus twice the bias. If you think that this is the right algorithm, I mean, if you started off thinking this is the right algorithm, I mean, kudos to you. I mean, I would never have thought this was the case. But then they prove that this is achieving a four-ninth approximation and nothing can do better. Okay, so somehow all this really strange-looking functions and rounding and so on are necessary and sufficient. Necessary and sufficient to get the optimal algorithm for maximum directed cut. So, this is roughly where we were. We've seen the lower bounds, max cut. We've seen the upper bounds, max directed cut. Now, we want to generalize it to all problems. Okay, so there's obviously challenges. So, if you have some constraint, constraints can look pretty weird and ugly. So, for instance, if I have a constraint which says x and y parity z. And y parity z. And I start seeing some constraints saying, oh, apply this to x, a1, a2, apply it to a1, x, and y, apply it to y, x, and a4. What's the bias of x at the end of all of this? I mean, how do you say, oh, this variable wants to be zero or wants to be one? And that's roughly what I think a bias has. But even some heuristic sense, I don't really know how to translate this to numbers. So it's dealing with general problems seems to be much more. Problem seems to be much more hard. And then there was this use of L1 estimation. So, here, why was L1 estimation turning out to be useful? It wasn't a priori clear, but then at least for this, we managed to find a good answer that convinced us, which was that, look, if I look at the L1 norm of some vector x, x whose coordinates are x1 to xn, what am I computing? I'm really computing the following, I'm solving this optimization problem. Okay, I mean, it's a complicated way of saying. I mean, it's a complicated way of saying the L1 norm is, you know, the sum of the absolute values of the Xi's. I optimize over Ai's in plus or minus one, the summation of Ai Xi. Okay, so this is definitely, you know, at least has some syntactic similarity to problems that we want to solve. It's maximum over A sitting in a Boolean domain of some linear function. Okay, we're not really solving a linear function, but maybe. Not really solving a linear function, but maybe that's where you know you approximate the problem that you want to solve is somehow being approximated by a linear function, and then you're able to maximize over this. And so if you want to go to other domains, there are many other norms that could probably be useful. And we found various norms that were actually useful for us. I won't talk about it much, but they do exist. So at least the L1 norm estimation, we could get a handle on it. You could go to other QRE problems. That you could go to other query problems and still manage to find other norms which could be useful. And there are lots of norms that can be computed in Perl log space. That's the good news. All right. So, but then this diecat analysis has all this graph theory in it. I mean, you know, it's a beginner in graph theory, but they still have to be, you know, do some graph theory. There's some, you know, this form that you have, you know, has some optimization going on. You have to optimize some weird. optimize some weird rational function over uh of degree three uh in a few variables how did it how did we get get to this and how did it turn out to be optimal all of this seemed a bit mysterious and one wouldn't one shouldn't think well there should be a you know classification looking coming up immediately but i have about 17 minutes and i do have to give a classification so let me tell you a little bit about how this happens so what we desire So, what we decided to do was we stepped back a bit and said, okay, look, there's a lot of optimization going on, but let's give this algorithm that we have even more information than it has, much more than it can store, and then ask what can it do. So what's the information we decided to give? We said, let's, you know, you have some constraint satisfaction problem. Let's pretend for, by the way, I should have said this earlier. Think of a single function only in your family. More functions will just confuse the. And more functions will just confuse the explanation without being helpful. So, single function, the family. So, but still, it has k positions in which a variable can appear, and each position has its own different role. So, let me give you what I will call the one-wise marginal of this instance, which is for each variable i, for each location in the constraint from one to k, so each location j. So each location j, I tell you what fraction of constraints actually use the i-th variable in the jth position. So this thing here is a big matrix as n columns and k rows, or maybe the other way around. Should have been the other way around, but anyway, this is what I call m i j. That's i, that's j. And it tells you, okay, what. And it tells you, okay, what fraction of these entries appear here? This seems to be a lot of information. And now we can ask the question: okay, suppose all this information is given to the algorithm, no charge for the space, do whatever processing you want, and that's it. No more information about the instance. Okay, the instance is thrown away at this stage. I give you MIJ and I say, okay, that's it. What can you do? So let me say something which is not rocket science. Me say something which is not rocket science at this stage. Oh, that's the problem with doing so. The picture vanished, but I hope it's not needed anymore. So here's a tautological statement. So if I can find two instances, Psi 1 and Psi 2, one of them has a very high value, one of them has a very low value, but they both have the same matrix. Then obviously this algorithm cannot solve the gamma beta approximation problem. Approximation problem. Okay, the goal is to distinguish gamma from beta, but the only information you have is no longer distinguishing. So, this is the tautology. I mean, okay, this is, I claimed one direction of it. If you have these things, then the algorithm cannot solve. But it's also trivial to say that if you never find two instances that look like this, then the algorithm can solve. It's not uniform and it's not clear how it's going to do it effectively, but at least the information is there. Sorry, Madu, a quick question. Quick question: when you algorithm gets this entire incidence matrix, then it doesn't do any streaming paths or anything. Nothing, yeah. This is not a streaming statement at all. Yeah, okay. Just some, you know, it's a trivial kind of a statement that we're making here. It's just you don't see the instance, you just saw the matrix, and you didn't get charged for using the matrix or doing any computation on the matrix. What can you do? It's an information theoretic statement. Cool. Thanks. Great. Great. So the key theorem is that this algorithm can actually be sketched in polylog space. Okay. And it uses some of these norm estimations and so on. So whatever this algorithm wants to do, the information that this algorithm wants to produce can actually be sketched in polylog space. It's not, should not be immediate at this stage. In fact, this relies on some things that come up later. But I won't tell you more about this algorithm, but just to say that. But just to say that actually it turns out this algorithm can be implemented in Polylog space. And in fact, I mean, for the first time, I think in the sketching literature, we are actually solving a whole collection of gap problems, gamma, beta, in order to be able to find the right approximation. It's not as if we directly go in there and say, oh, look, here is an instance. We'll just find the value of the optimum solution. We really sort of look at all possible, you know, build a net of all possible gammas and betas and say, can I distinguish? Betas and say, can I distinguish? And amongst those that I can distinguish, what's the best answer I'm getting? And furthermore, if this algorithm cannot solve, then there is no little of n space square root of n, little of square root of n space catching algorithm for this thing. So this is where, so somehow this very strange matrix captures everything we want to do. Okay. Now, this is still not. Now, this is still not great. In some senses, it's like saying I specify an algorithm and then I say it works if it works, right? Because we are saying if this condition holds, whoops, if this condition holds, then it's a nice algorithm. If not, it's not, and I don't know. So, at the moment, we haven't said the most interesting thing. The one more sentence that we need is actually this criterion is desirable in finite time. Time. So, and this should be interesting. We haven't specified how many variables this psi one and psi two can have, but of course, psi one and psi two should have the same number of variables, otherwise their matrices will not be the same. But there's infinitely many possible number of instances that we are enumerating over, but we can still find out which one of these two conditions hold. The reasoning for this, before I get into it, maybe more, is It maybe more is simple. Trying to say how does an algorithm perform on every instance may be a complicated statement. Trying to say what is the worst instance for this algorithm and what's the best instance for this algorithm is probably not as complicated, which is part of the reason why we are able to say, you know, decide this criterion. It's part of the reason it's not everything. But, you know, we are not asking how well will it do on each instance. We are just asking what's the Each instance, we're just asking what's the worst case instance of this algorithm, and maybe it's something that's easier to find out. So, once you have this theorem, this classification follows, and really this is the nature of our theorem. We have no idea what is the gamma and beta for which we are going to say yes, where we're going to say no. You would really have to analyze this criterion, which is complicated. And indeed, if you wanted to apply it to die-cut, you have to. If you wanted to apply it to die cut, you have to go through pretty much all the analysis from the previous paper by Golovnev, Chow Golovnev, and Velashami. And we decided to, there was a follow-up work by a bunch of students at Harvard, including Santoshini, which applied this to other problems. And for each one, you actually have to do a fair amount of analysis in order to figure out what's the approximation factor you can get. factor you can get all right so um now i'll try to wrap up by just saying a little bit about uh what the uh why the decidability turns out to be uh easy in fact what turns out to be the case is that in order to figure out what's the maximum gamma you can ever get and what's the minimum beta you can ever get in the set you really only need to look at instances on kq variables okay and the number k times Okay, and the number k times q is there for a very good reason. You really are going to think of a planted assignment in the good case, and this planted assignment will have k sets of variables, one for each location of the constraint. And these variables will be planted to have a given, you know, take on a given value. So if you give the variable in the ith row where i is an element from one to q, this variable we will This variable, we will always set it up so that the constraints are likely to be satisfied. Gamma fraction of the constraints will be satisfied if this variable takes on the value i. So it's all planted. And on this planted thing, we want to make sure that you satisfy at least gamma fraction. Then we say, well, okay, there is some distribution on, you know, Q to the K that is being implied by this instance that you found, this instance which satisfies at least. Found this instance which satisfies at least gamma fraction. So converting instances on KQ variables into a distribution took some little bit of manipulation, and that's how it's done. And if you can somehow create another distribution, so each constraint naturally looks like a distribution on, I know, every instance is a distribution on constraints. That's kind of natural for us to think of things that way. And when you start saying, oh, the ith variable is appearing in the kth constraint, et cetera, there's some marginal distribution that's produced. And it turns out that if you look at all the instances, they can be mapped somehow into somehow a distribution on Q to the K elements. All the distributions which have gamma fraction satisfied under the planted assignment forms some convex set in the space. Some convex set in the space. All the instances that form that satisfy at most beta under any symmetric assignment forms another convex set in the space. And the criterion for intersection for easiness is these two sets should be disjoint. If they're disjoint, then you can somehow separate the gamma fraction satisfiable instances and the beta fraction unsatisfiable ones. So going from here to the algorithm is not trivial. Going from here to the algorithm is not trivial, but we won't do it. The thing that I want to mention here briefly is the kind of communication problem that comes up when we want to show a lower bond. So in the lower bond, we have these two convex sets and they happen to overlap. Okay, and each one of these sets is, you know, is a family of distributions. Okay. So in particular, there's one distribution in common in the two cases, or which has this. Or, which has the same marginals in the two cases. And this is the distribution that we want to find. Sorry, these are the distributions that we want to use in order to separate, in order to show that the streaming problem is not solvable effectively. Okay, so modulo, you know, all the things that I didn't really Dilo, you know, all the things that I didn't really explain clearly. When the algorithm does not exist, we are able to find two distributions which are supported on Q to the K. So this is on satisfying assignments of one constraint for the space of assignments of a single constraint is the way to think of it. With the feature that both of these distributions have the same marginals. So for each letter of the each coordinate and each position, you have exactly the same distribution. You have exactly the same distribution, but the distributions are themselves not the same. And we now have to use, leverage these two distributions to show that the problems are hard to solve. So roughly what happens in our paper, and I'll try not to take too much time. I want to just say what happened, how does this look like in the case of Max Cut? In the case of Max Cut, somehow you have. Somehow you have either variables going from across the cut. So there's either the uniform distribution on dy would be the uniform distribution on this set and dn would be say the uniform distribution on even this would be work. Okay, so here 100% of the edges are crossing the cut. There in the planted cut, only 50, you know, none of the edges are crossing the cut, but in the Crossing the cut, but in the, even though we want to, you know, but no cut will satisfy more than half the vertice, half the constraints. And max cut basically says, okay, if I have these two underlying distributions, then there's some communication problem that arises. And that exactly turns out to be the Boolean hidden matching problem. And so the lower bound for Boolean hidden matching told us that this associated communication problem is. Associated communication problem is hard to solve. For other settings, there are other problems, and there are infinitely many problems: one for every pair dy and dn that have matching marginals. And we basically show that, look, if they have matching marginals, then they're hard to solve. If they have no matching margin, if the matching marginals do not match, then they're trivially easy to solve problems. So, how much time do I have? So, maybe I'll just tell you about this problem, and then that'll probably take me to the last slide, more or less. So, I'll just say what the problem is. So, this is a variation of the Boolean hidden matching problem. It's a one-way communication problem between two players. Alice gets some planted assignment, X, which is on N variables, and each variable in X takes the And each variable in x takes the values in one through q. And Bob gets a sequence of projections of x. Okay, so as in the max cut case, in the max cut case, Alice would have a random 0, 1 string corresponding to a cut, a planted cut. And Bob will be getting pairs of bits, one for each edge in a matching. Here we will pick similarly, you know, a hypermatching. You know, a hypermatching because there are maybe constraints are carry, and on each one of these things, I'll say, Okay, what's the value of this variable? What's the value of that variable? What's the value of this variable? So, in some senses, it's slightly different from Boolean hidden matching. Well, if I just gave you the values of the variables that would be giving the problem away, what I do after I pick the set of, you know, if I have these n variables, I decided to look at these three. And this one happens to have value one. This one happens to have value one, this is two, and this is three. What I'll do is pick a random string from the distribution, either dy or dm. And this will be, say, b1, b2, b3. And output, you know, this one 1, xor, b1, 2, xor, b2, and 3, xor, b3. And actually, xor is actually some modulo q in this case. Low q in this case. So, if you look at it in the case of max cut, this is virtually giving the same information because if you're coming from the yes distribution, then b1 and b2 will be always opposite in signs. So you're more or less getting to know whether this edge is crossing the cut or not. And that's all the information that you get from this problem. That you get from this problem. The way we've defined the problem here, you can set it up in the framework of any arbitrary pairs of distributions dy and dn. So you take a projection of the set of vertices x, and then you mask them on each edge to make sure that you're not revealing too much information about whether which one of the two distributions you're coming from. And then you ask Bob to say, can you tell whether you came from DY or? Say, can you tell whether you came from DY or from DN? And it turns out that this requires about square root of n space to solve. The solution, how we get proof that this was done is not immediate. It actually requires sort of two types of proofs. One where we try to extend the previous proof of Gavinsky et al. And another step where we say, okay, look, that works up to a large class of D. That works up to a large class of DYs and DNs, but then we have to go through the remaining things. And so there's sort of a more combinatorial argument to stretch this proof into apply to other places. All right, so let me stop after the slide. Just a couple of very brief open thoughts on the open questions. There are tons of these. In fact, Santoshini is a great person. I hope she'll show up at the open problem session and tell you a little bit about it. I don't know if Tell you a little bit about it. I don't know if I will be able to make it that late. Stretching, and one of the things is, so there was sort of up to a very large part of this paper, most of the thoughts were really about streaming algorithms. And where things broke down was really not in this proof, which works everywhere, which really aims to look at the streaming problem, but in this hybrid argument thing. This hybrid argument thing, which said, Oh, I take a stream, I divide it into many small pieces, and then I glue them together. In fact, an early version of our paper thought, you know, completely missed this issue. And then Gilath and Raghavanj and maybe Huacheng and others sort of wrote to us saying, oh, look, you have a bug in this paper. And sure enough, it was there. So that sort of scaled our results down to sketching, but it seems to be for an inherent reason. It's not that the proofs are what's That the proofs are what's wrong, it's maybe that the theorem is not true at this stage. We don't know. It could be that all the lower ones which we prove for sketching for little of square root of n-space algorithms actually extend to streaming. Maybe, but we don't know how to prove that at all. We are clueless. We don't even know maybe the right family of distributions. It certainly kills the distribution instances that we had. And there are like And there are like sort of concrete algorithms that are coming out of it, and these algorithms actually perform well in the random ordering setting. So, there's lots of issues that pop up here. There's also this thing. Initially, when we solve this problem, we said, okay, look, we managed to get square root of n space sketching after we fixed our error, lower bounds. But clearly, this should extend to omega of n space streaming lower bounds under the. Lower bounds under the random ordering, right? That's there should be nothing in between. And by now, we know lots of counterexamples to this extension. You know, it falls in multiple, it fails to hold in multiple ways. But there's still this question, okay, so what kinds of problems can actually be solved in a non-trivial way with sublinear time, with sublinear space? And are there any things? Things at the moment, I mean, we are very close to, I think, showing that die cut can be approximated with a little of an space, though we don't have a formal paper claiming that, but we get it in many special cases and many variants. All right, so I'll stop now. Thank you. Maybe I'll also have questions. It seems for many of your lower bounds, you reduce from the Boolean hidden matching problem. Do you think these problems are about as hard as the Boolean hidden matching problem? And the reason I ask this is because this, like, a famous example of problem versus the algorithm that's exponentially better, Facebook plays. Like, how do you spot what we're looking at? Yeah, okay. So it's not. Yeah, okay. So it's not clear to me how to reason about is the problem, is one communication problem as hard as another communication problem in this setting, especially when you know the truth is, you know, that both of them are hard or something like that. So what we have not been able to do is do a black box reduction from the communication problem that we want to solve to the Boolean hidden matching. And matching. And this would be very, I mean, in some senses, okay, it wouldn't be sufficient if we just reduced it a generic problem to Boolean hidden matching. But if we could do this reduction somehow more like our generic problem to max cut, then you could get, you could imagine getting all kinds of linear space lower bounds, which also we are not getting as easily. So we aren't getting those by reduction. So if that's Aren't getting those by reduction. So, if that's the drift of the question, then yeah, I mean, I don't know how to reduce these things. We do reduce problems one to the other, lots of these communication problems one to the other, but none of them actually goes down to one single problem. At least there's sort of infinitely many different underlying problems that we had to show were all hard. I do. Let me ask you a technical question also. So, these lower bonds that you are talking about, it seems that at the end, all of them reduce to some multi-party communication lower bound for a constant number of players. It depends on Q and K, but it's at the end of the day constant. Do you think that's like, is there some even intuitive reason to think you never need more than constant number of players? Number of players? No, in fact, that's a great question. So, at the end, for some reason, we are reducing it to a constant number of players, but I think that's really, I mean, you know, really the results should be stronger, but then quantification would be much harder. So, what's happening? We are saying, look, say, Max Cut, a sequence of edges is arriving. We batch them into groups of size a little low of n, let's say, for simplicity. And after each one of these batches, saying, oh, we didn't learn much. Oh, we didn't learn much that clearly implies that after each edge was presented, you didn't learn much. But how do you quantify that particular statement saying, After getting a single edge, you learned a little, but very, very, very little. And I think we don't know how to quantify that. And if we could, then we could do much better proofs. But then some of this might also be inherent. I don't know. I mean, you know, we know that there are problems like die cut and so on where random ordering is. Cut and so on, where random ordering is not going to be hard. So if you're only sort of looking at one edge at a time, you sort of don't really, I mean, I don't know that you could distinguish random ordering. The proof probably works for random ordering as well as it should for worst case ordering. And so something in the middle, like I don't know, a square root and edge at a time. Do you think that will give algorithms any power or I think? Any power or I think it will give. I mean, so the big challenge which with random order seems to be that you, you know, when you accumulate a large number of, you know, almost linear number of edges, you have lots of cycles in the in a graph, maybe. Cycles. No, I mean, you don't get cycles, sorry. You get a fair number of, you know. You get a fair number of connected components of constant size. And as you go towards square root of n, I don't know, I mean, a little bit below square root of n, you would have a matching. And then it would look like a random matching. And then, you know, you would just say, oh, look, if I could put square root of n of these matchings together, then I get the result also to apply for the random ordering case. So somehow there is definitely. So, somehow, there is definitely a difference between these two cases. We are using it, but I don't know that it's essential or necessary. Yeah. God, thanks. Okay, thanks. Maybe I can ask one. Do you think there will be a problem for which the tight approximation ratio, tight bound for non-trivial approximation is n-tego-three-quarters, for example? If right now it's For example, if right now it's square root n and n, we are definitely hoping that's the case. I mean, otherwise, you know, we'll have to close the book on all of these things. So we are hoping for, yeah, more algorithms and more things. I think they're there. We just need better analysis. Oh, so you do have a candidate, a candidate CSP, I guess. I'm almost sure the die cut will be, will have a different approximability behavior beyond square root of n space. Uh, behavior beyond square root of n space, and then the question is: okay, what will it be? Will there be multiple stages? And one could easily imagine that for a KRE constraint satisfaction problem, n to the one minus k to n is not distinguishable, but just a little bit more than n to the one minus one over k might be actually, you know, or tilde of that might actually contain the best algorithms. Thanks very much. Bye, folks. Okay, Rick, go ahead. Thank you. Okay, we're coming out of tender.  I was thinking about mapping up more time for the magic getting the cover of getting a little bit of more. Yeah, yeah, it's all right. You have a lot of  I mean the problem with the company doesn't mean that's a problem. But unlike you, you go to study multiple newsletters, and the bottom has to be the final age half of the books. It's a plan for most and then they just plan to spend the standard image from the what is your random stuff. So it's kind of a harder because it's a long situation. What he showed is that basically log in three cases. I mean, so far we can do three analyzes, but they say I mean construction it's I wouldn't put markets yeah I worked on itself if you don't have it's not like integrals then I can how my budget is VHR you can And now what happened on the last side, the other one and we can create 200,000 page. Do I have to sell login? I don't think we have any logic on the hard thing, it's just become you don't even have this. So, this is not part of the target easier way to convert everything on the line. Each protocol gets some kind of worst case. But I mean, you don't get this kind of Yeah, it's data. Yeah, it's not hard. We also have that. We also have that. Yeah, so what is next one? Oh, then the server and vectors. Just like well, And I have a lot of the largest dense is where you spread them. In fact, there is a cover. So it's basically a little as no matter what the next time. And starting observation in this paper is that at the same time, no matter what the users are dating,  And it's possible that you can strengthen this. You just have to expand the thing. And I wonder if this is average in the form because if you look at the sunish. 