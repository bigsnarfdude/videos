Professor of Medicine in the Chang Division of Network Medicine at Brigham and Women's Hospital at Harvard Medical School. He's also an inaugural faculty member at the Cold Spring Harbor, what is now the Statistical Methods and Functional Genomics course. And we were all planned to run that course right now in a week, but it's been unfortunately. It's been unfortunately put off this year, hopefully next year. He was the editor-in-chief of the R Journal. He's the scientific director of bioinformatics at NIAID Immune Tolerance Network and on the scientific advisory board for the Vaccine and Immunology Statistical Center for the Collaboration for AIDS Vaccine Discovery. He's also a co-founder of the Bioconductor Project, which we all The Bioconductor Project, which we all know and use and appreciate. And just checking out his webpage, I think seeing the packages that he currently develops helps to understand all the different areas that he contributes to. So he has numerous packages in cancer genomics, in scalable and cloud computing, in human genetics, ontology and text mining, machine learning. Mining, machine learning, and annotation, and curated data. So he's really had a huge impact, and we've all probably used packages that he's developed, and it's helped us accomplish our goals. So without further ado. Well, thank you, Michael. Audio is okay? Yep. All right. Well, I guess I will share my screen. And we'll just share it right there. Now, I had a plan, and I will jump over to the slides. I had a plan to start us off. How do I get the slides here? Is that it? Yeah, there we go. And Vince, let me ask you one question. If questions pop up in the chat, would you like me to voice them? Definitely. Okay. Okay. Very interruptible. Interruptible. I'm going to show it like this for now. I have a roadmap and let's see whether I know how to move this. So what I thought we would do is warm up with a game. And it involves the chat system and Zoom. And we'll start off with that. And then we'll look at a little schematic to try to get a handle on what's relevant to what I'm going to talk about. What I'm going to talk about, and then talk about scalability, the notion of proceeding by dividing and conquering our obstacles, and the software ecosystem notion. And then we'll look at the bioconductor ecosystem a little bit, and then talk about an interesting development that I think is related to this ecosystem problem, which arises from work that Sean Davis has done with. Work that Sean Davis has done with GitHub Actions to make workflows for workshops. So, yeah, it's going to be fun. Here's the idea of the race. Now, I don't know exactly how we're going to keep an eye on this. Let's see if I can just see the chat here. I haven't tried this before. But anyway, keep an eye on the chat. The idea is I'm going to give you a notorious phrase to which certain substitutions have been applied, and to win points, you have to be the first person to chat the name. You have to be the first person to chat the name of the author of the original phrase. And so, for an example, here's the notorious phrase: To consult the statistician after an experiment is finished is often merely to ask him to conduct a post-mortem examination. He can perhaps say what the experiment died of. Now, for the game, we would give you the phrase as follows. To consult computer scientists after a program has been coded is often merely to provoke them to propose that a different language be used. They can perhaps say why the original They can perhaps say why the original choice was a fatal one. So, for that substitution quote, the answer would be Ronald Fisher. Let's go to the game. Here is the first sub-quote. All programs are wrong. Some are more useful than others. So, to play the game, you would enter in the chat the person to whom the original remark on which this is based. Anyone chatting yet? I'm not good at seeing it. I'm not good at seeing it. Yep. George Box from Lauren is first. So I'll let you guys decide whether someone has won or not. Do we have an answer? Yes. The answer was box. The next one. Bioconductor is the most successful genomic analysis platform. Those who ignore it are condemned to reinvent it. I'll give you just a few seconds to come up with the answer there. Anything in the chat? I wish I could see the chat. No. I'll let you know if we have something. Nothing? No. Efron? Okay, sorry about that. Efron? The answer is Bradley Efron, who said statistics is the most successful information science. Those who ignored are condemned to reinvent it. So sorry about that one. That's a tough one. Now are we good to? That's a tough one. No, we got it. We got it. Someone got it. We did get it. Okay. Well, there we go. So, third race: it takes a blank to raise a blank. And in this case, we have a software ecosystem to raise a compelling analysis in multimodal single-cell genomics. Who popularized the proverb from which this is derived? Clinton. Very nice. That's from Susan, by the way. Just moderating. Yes, you know, it's not original with Hillary. Yes, you know, it's not original with Hillary Clinton, but and there's a big controversy over where it originates, but she certainly popularized it. All right, here's the one. I shall not today attempt to define compelling analysis in multimodal single-cell genomics, but I know it when I see it. What is the name of the Supreme Court justice who wrote the original quote? Anyone got it? Anyone got it? Nope. It's Potter Stewart. And finally, to create a Bioconductor package is to battle with trolls in the vaults of writing our extensions and the build system. To run BioC check over one's package is to sit in judgment over oneself. That is a pretty tough one, and that is, if we don't have it yet, it's Henrik Ibsen. It's Henrik Ibsen from Peer Gint. To live is to battle with trolls in the vaults of heart and brain. To write is to sit in judgment over oneself. All right. So this game was not simply frivolity. We know this phrase, I hope we know it, all models are wrong. Is that true? But its modification, all programs are wrong? Is that false? Should Bioconductor be reinvented? Should Bioconductor be reinvented? What is a software ecosystem? What makes a multimodal single-cell analysis compelling and reliable? Can we define it? And what about BioC check? Where does its criteria for warning or error come from? So this is a schema that I had hoped to use during the Cold Spring Harbor course that Mike Love mentioned. And the idea is that there are three big vertices. Big vertices that we have to work with. My own job is to try and deal with this idea of personalized genomic medicine. And some very big concepts are floating around there. What is homeostasis? What is a disease? And how do we get people from disease out of disease? Organism development and structure are relevant to both of those, and therapeutics are a big deal. So that's where I need to go. And I think a lot of us are shooting for Of us are shooting for contributions to this space. Now, what we were going to do was teach students whose main focus is basic genome biology. And the things that they use to do basic genome biology are typically sequencers, things going on with cell dissociation, genome editing, and so on. Biotechnology is the big thing that these guys are expert in, and we're trying to bring them over here to high-dimensional data science. So, the contents of the course will be, how do you work? The contents of the course will be how do you work with things that come out of here to do computations? How do you structure the data? What algorithms are good? How do you visualize? And then how do you learn? What kind of simulation is done? And how do you come up with false discovery rates? What is this idea of selective inference? These are the things we need to teach in order for this to be done and interpreted appropriately. So these two vertices are important. Vertices are important. We flow from here to here via biotech. And then, if we get the high-dimensional data science right, we can actually do inference on population genetics and genomics and come back to personalized genomic medicine. Likewise, people who are in basic genome biology need to really work on the mechanisms of what they see in order to get systematic and network-based explanations for what they're doing, what they're seeing, and that flows into personalized genomic medicine as well. Central to all of this, and the way. Central to all of this, the way we teach it, is Bioconductor, which always has had three main concerns: pre-processing, analysis, and annotation. They're handled separately, they interact with one another all the time, and keeping them separate and contributing to each one of them and doing them each efficiently is what we try to do, what we try to get people equipped to do. Back to the beginning. Sorry. So, I just want to connect those ideas to some ongoing discussion. So, for example, in the benchmarking section, there was this comment, should we leverage single-cell EQTL? Through G-Text, we have a large set of known tissue and cell-type-specific EQTLs to benchmark methods. We should expect to find relationships at single-cell level when we see them in bulk. And my question here, from the point of view of our software, is what's a Of our software is what's a good representation or good API for GTEx. Remember, you've got the whole human genome and you've got the whole human transcriptome on a bunch of tissues, on a bunch of people, and the representation of the inferences on gene regulation is still something which I don't think we have a very good solution for. So, thinking about this seems very germane to the team that we're assembling in this workshop. Shop. Then, on the spatial and SC proteomics end, we see that there's a lot of interest in reusing concepts and structures in atmospheric modeling and geography. And my question would be, how are we going to coordinate the efforts that are going on in all these different groups that we've assembled here to develop integrative data structure designs and analysis methods so that isn't every tub on their own bottom and we aren't sort of scrambling to put things together. Can we plan? To put things together, can we plan first and then act, or do we really need always to experiment first? So someone comes up with a package and a structure, and then another one does, and then we see, well, what's better about one and the other, and so on. The example here is the tree-summarized experiment, which I don't think I've seen any references to, and I think I forgot to put a link to it or to put a picture from it in here. But this idea that we can have, in conjunction with the summarized experiment and all its features and its samples, Experiment and all its features and its samples, hierarchical data structures that organize those features and samples, that has been solved. But it was solved by two groups independently, one in Mark Robinson's group by Fiona Huang, and another in Hector Carado-Barro's group, and it took some time to come to consensus on how to do that. I think we'd like to avoid those events where there's a lot of independent development, which sort of has to be broken down in order to get a consensus. In order to get a consensus, let's try to build consensus earlier than later. There was also a piece by Chris Kansarkan, I think it's the name, who brought in this observable HQ in order to look at a dynamic single-cell visualization. And this observable HQ is very interesting, developed in conjunction with D3. D3, and you know, purports to really be the best notebook system for doing data analysis, particularly focused on visualization, but many of other analytic components. So it was interesting to see that and to think about, you know, is there a fragmentation going on with respect to thinking about how do we convey material that's pretty well cooked at a high level to people we're trying to teach or interact with, collaborate with. Collaborate with. This is an interesting environment. What's good about it? What other environments do we have of the same nature? I'll talk about one towards the end of the talk. So, the basic facts as I see it for this problem are it takes an ecosystem to make an analysis. There's no way that anybody's going to work in this space and write from scratch, you know, top to bottom, ingest the data, get it into a reasonably interpretable form, and then actually do the interpretation visualization. Then actually do the interpretation visualization. We're all going to be pulling from different places different things that we think are useful. So it takes an ecosystem to make an analysis, and it takes an ecosystem to make an ecosystem. So you're going to be building your genomics software using system software, compilers, graphical systems, browsers, other languages, and so on. And so the question is: where do we begin to think about the ecosystem components for our problem, which is integrative Which is integrative multimodal single-cell genomics. Where do you begin? And so I'd claim that there are two elements that are absolutely fundamental. The first is the ecosystem builder, let's say. And in the case of Bioconductor, we have such a thing. We can look at it, we can think about it, we can think about how to improve it. We also have an evolutionary strategy, which I think some people view as an obstacle. It certainly adds cost the way we do it, but I think it is very interesting. But I think it is very interesting to be sure that you understand what the evolutionary strategy of Bioconductor has been for the past 20 years. It has some very specific components, very specific obligations, and I think by tackling them and paying a high price, we've stayed alive and we've made good contributions. But it has not been easy. So here's a fun fact. Software ecosystem health assessment is a real thing. A real thing. I learned about this when I went over to the Essential Open Source Software meeting in San Francisco in February, just before the pandemic. And there's publications, a number of them come out of the University of Copenhagen talking about this health of software ecosystems. And we'll put references to those in the paper as we write it. But another thing that I did meet in the Chan Zuckerberg meeting is this thing called chaos. The community health. The Community Health Analytics Open Source Software. It's a strange name. It's not community health in the sense of epidemiology, but it's really an assessment of the health of a community of individuals contributing to open source software. And the idea that we have common metrics to look at open source software as a basic framework for contributing new computational tools. Diversity, inclusion, evolution, risk, and value. Evolution, risk, and value. These are things that these sociologists who are interested in open source have developed in this framework. And here's an example: they keep an eye on Bioconductor. So iRanges is a package in Bioconductor. They look at all the Bioconductor packages and they assemble information. For example, what's the license coverage? In this case, they say this guy has 247 files, but only one of them is a declared license. So there's a bunch of files without licenses. Now, of course, I don't know. Now, of course, I don't know how we get the license to propagate to all the other files so that their metric would be right, but that seems like it would be worth doing. They also keep an eye on who's contributing and what's the pattern of contributions over time. So this is something we can do, but they are doing. And the idea is to come up with principles of open source community health that people can learn from and have better open source communities. Communities. I didn't know about that. This is their schema. This is just a little tiny slice of the schema. And notice that it has things like code of conduct file, security issue file, security audit. So if you can identify these things in your open source project, these get identified and they become properties that can be thought about in the context of all open source software development. So it seems to me to be a very interesting project, and we need to understand these concepts and make sure. These concepts and make sure that our community, both Bioconductor as a whole, and that sub-community that's devoted to single-cell genomics in a multimodal mode, also satisfy those good criteria. So the big question for us, I think, if we're interested in Bioconductor, and I am, what does Bioconductor need to be a superb platform for multimodal single-cell genomics? And I'm going to give three things. And I'm going to give three things. I'm sure we can add more. First, support the development of efficient data containers and data services. So this idea of a data service, I don't think, is much on our minds at this point. We still think about what's our object design, how do we get it on disk, or is it a database, or do we use HDF5, and so on. Eventually, the data are going to be too big for those things to be reasonable solutions. Be reasonable solutions. I'm talking about, you know, very large collections of single-cell genomics, let's say, on a population, in something like TopMed or whatnot. And it's just not going to make any sense. Of course, you can do data reduction to some facet, but there's going to be a point where you're not really going to want to have a unified archive on some server that you expect people to be able to deal with holistically. You're going to be thinking in terms of a service so that a query gets resolved. Service so that a query gets resolved and can be done efficiently. And I'll talk a little bit about an example there later on. So that's number one. Efficient data containers and data services. And I think we've put a fair amount of time thinking about that. You see multi-assay experiments, you see spatial experiment, and so on. We really want to coordinate on this and make sure that we're doing a good job. And as technology changes, HDF5 seemed good at one point. People are looking at tile DB now. You know, where is the You know, where is the cloud scalability of the data representation you're using is going to be a question for us, and we want to make sure we're on top of that. We don't want to be too much on the bleeding edge, but we want to make sure we're using well-established and functional solutions for this problem. Second thing, we want to support software developers in the achievement of scalability in their tools. So scaling up to TopMed is a great thing to be able to do. You can do it for many things. You can do it for many things. You also need to be able to scale down so that you can test what you're doing on your laptop. You can figure out whether things make sense. You can do sanity checks and so on. So this idea of scalability is not always just going big, but it's being able to do things at different scales. And we want to make sure that we're able to do that. Finally, I think it's pretty clear that we want to support end users in adoption of the tools and successful use of the tools. And that is And that is costly. That means you've taken some time off to teach a course. You're going to get the software in shape so that people with limited experience can go and use it. And if we can streamline these things, and that's what I'll be talking about towards the end, that also contributes to making a superb platform. So I'm going to give some definitions. A system is scalable if it's through... Is scalable if its throughput can be increased through cost-effective additions to its capacity. So we hardly ever think about the capacity of our software. We think more of the capacity of our hardware systems. And that's really, I think, what we're talking about in this space. We're saying, well, listen, I've got a piece of software and I can run it on my laptop. But if I run it on a cluster, am I able to take advantage of all the different cores, let's say, in any given time? Of all the different cores, let's say, in any given node, and all the different nodes on the cluster. Those are additions to capacity. And if I don't have to do anything to the code, then I would say the code is scalable because its throughput is increased by cost-effectively adding to the capacity of the system that's running it. So we'll say that adding cores or RAM is preferred to reformatting data, although that can be also important for scale. And all of that is preferred to refactoring, rewriting code. Rewriting code. But often we get into this bind when we didn't anticipate, oh, yeah, you know, you really want to parallelize something like this, but I wrote it in this sort of a single-stream model. We need to be thinking about this at the outset. So designing new methods for scalability is intrinsically hard, and it's an unstable information technology environment. Rapid changes in biotechnology make it harder. So it's a discipline to say, listen, I'm going to have to sit back and take some time and figure out how can I make it. And take some time and figure out how can I make this scalable. And I don't think there are good solutions, good frameworks for helping you to do that without actually paying some significant price in terms of design, testing, and debugging, debugging parallelized code, debugging as you go to bigger environments. I think a lot of people on this call know more about it than I do, and that's good so that we can write those things up when the paper comes out. Now, all the components of Now, all the components of a software ecosystem need to be jointly tested in realistic settings. That's a point that I think is a key theme, and it's costly. So to do the tests in realistic settings means there's real data there, and everything has to work together and be tested together. And what it turns out to be is that we're all engaged in this idea of continuous integration, testing that all our modules work together, but also continuous distribution, because anytime a user asks, Because anytime a user asks for the stuff, they get it. And if something has been updated, they're going to get, probably, depending on what installation system they're using, they're going to get that latest version. So we have to be dealing with continuous integration and continuous distribution, whether we like it or not. And every component and all the underlying platforms that we're working with can change at any time. We do not have the luxury of a walled garden in which we are sort of saying, okay, it's time now we're going to cut a new release. Cut a new release. Yeah, we do that in Bioconductor, but still there's CRAN packages that can be changing underneath the release, and that introduces a degree of maintenance cost that we deal with, but it's costly. Vince, if you want live comments or questions, so there was a question from Stephanie. How can we motivate developers to make their code have more capacity, be more scalable from the start, from the beginning? The beginning, or be willing to refactor their code? Yeah, I think that's a you know a very essential question, and I don't have a good answer. You know, motivating, I think the way I would tackle it is to say, here are some solutions to think about. Here's where it actually happened. And one of the places I go to first is Big LM. It's a CRAN package, and you know, it may not be the best way to do something like run. Something like run a generalized linear model on a data set that is bigger than you could ever fit in RAM. But getting a handle on how they did that and the ways in which you can solve problems like that, I think is worthwhile. Motivating people to do it is an interesting problem because usually you're trying, you're struggling to get a paper out and you need the code to run fast or that you will be scooped. And being in that situation is not a good one. Is not a good one. So I think, you know, it's sort of a continuous building of this consciousness and tool systems that help us to go there and having good examples. You know, if you look at HDF5 and delayed array, there's been a lot of discussion about how that gives us the capacity to work with huge data structures with very limited resources. But do we really tap into it to get high-throughput analyses that take advantage of all of those capabilities? I think there's a lot of. Of those capabilities, I think there's a lot of discussion about seeing that that happens, but it hasn't happened yet. And then, oh, sorry, go ahead. Go ahead, no, please. Then I'm going to go a little out of order, Emerit. So then Alana has a tag on question. If there are, are there or thoughts about having software developers who computational biologists could consult as part of Bioconductor. Part of Bioconductor in terms of developing better absolutely. I mean, we have, you know, the question is: can it be done in a timely fashion? And is it done in an equitable fashion? Because there's, you know, taking people to a skill set, it can be very time-consuming and challenging. I think we need to build teaching materials that can be referred to for that purpose. But the Bioconductor Developers Forum, which has a Slack channel and Bioconductor Community Slack channel, would be a place. Community Slack channel would be a place to be a member and start to get a dialogue going with people who are actively engaged in this on a regular basis. And then there was the other question was from Emrit, which is regarding biomedical data sharing, do you have thoughts about blockchain? No. But others do. And I welcome their comments. George Church had a paper on this recently. Paper on this recently that you know you could have a look at, but no, I don't do that, and that's not part of my job. All right. Well, keep those questions coming. Let me run through this slide, and then we can see if there are some more. So my personal thoughts are that divide and conquer is a reasonable strategy for achieving scalability. And I'll say what that means. So, divide and conquer means that the data can be deep. And conquer means that the data can be decomposed in arbitrary ways and then thrown at resources that can consume them and then put things back together when it's time. And so your programming for data access for these decomposable resources, you may have to deal with sparsity and you have to deal with fault tolerance because once you get into this space, something's going to ask for a piece of data and fail. And you don't want to just kill everything that's gone before. Kill everything that's gone beforehand. You have to be able to respond in a safe way. And we have mechanisms for doing that. You'd be surprised. There's something called in the BioC parallel package, there's BP redo. So when one of your tasks fails, you can tell it what to do, and it can try to recover. And having that in your programming toolkit is important, and I think we actually made it easier. Now, divide and conquer. Now, divide and conquer seems hard to implement in social coding and in the organic development of a software ecosystem. That is to say, if you just sort of let it go and everybody comes up with some tools and then maybe we have a conference, we talk about them, you'll find that this idea that you actually took an opponent and broke it up and beat it down. And I'm sorry to use such violent language, but I think that's the way it's one model for this. It doesn't actually happen. And there's lots of things that are being done. And there's lots of things that are being done piecemeal, and you have to sort of scramble. Another personal thought is this idea of mileage. So, you want to use high mileage tools, things that are being used all over the place, and so that when the bugs are there, they get exposed. And this idea of building mileage on our tools is important. So, you don't want to write a new tool if you can use something else that lots of people have used and have shown that it has fewer bugs than the new one that you're going to write. So, for very new byte. So, for very new biotechnologies with emphasis on speed of deployment, these principles can be very hard to adopt. And some things can help us: containerization and automated continuous integration and continuous delivery. These are helpful, but they have their own costs. You can get bit rot in some of these spaces, and it all has to be thought about very carefully. Any questions at that point? There was a question about There was a question about from Al, if there's some kind of code health or maintainability rating for developers to motivate them to refactor or keep their code up to date. I don't think so. Not that I know of. I don't think that's part of the chaos yet. But that's an interesting community and you can interact with those folks and see whether there has been some development in that area. Whether there has been some development in that area. I don't know of any. So, one of the things I heard in one of the brainstorming sessions is this idea that everybody thinks their own problem and method is unique, and so we get lots of tools, even though they implement very similar solutions. And, you know, I think there's some truth to that. And I'm not sure I know what the solution is other than getting together, talking, mapping out tasks, taking responsibility for pieces of it, and making sure that the whole thing. For pieces of it and making sure that the whole thing weaves together properly. And I don't know that we've really done that in any conscious way in Bioconductor. There's lots of redundancy in there, most likely. But I still put it as a central component of these three pieces of genome biology, high-dimensional data analysis, and personalized genomic medicine, because for 20 years it's been dealing with key problems that arise at genome scale analysis. Pre-processing, parsing the crazy formats that manufacturers come up with, deriving Factors come up with deriving quantifications, assessing bias, and then maybe doing something about it in a legitimate way. Single sample, multi-sample transformations for comparability, which is called normalization. And a lot of these are black boxes, which seem to have worked, and we've got them in there, and it seems to have added to genome biology. That's one thing we do. The other thing is object designs. Thing we do. The other thing is object designs. So, when you leave separately different tables, one of them is about the samples, one of them is about the features, one of them is the actual measurements, you have risks of mismatch, you have complications of joins and so on. And so this idea of binding the metadata to the assay data in a summarized experiment or some extension of that, where it's like a matrix, and the first index refers to features, and the second index refers to samples, and having an endomorphism so that when you do this, you get something that's the same class as X. This, you get something that's the same class as X. This has proven to be quite productive. And understanding this fully in all the domains that we work in, I think, is important. How it relates to the tidyverse is still an open question. There's a package called Fluent Genomics that looks at the ethnomorphic concept in the context of these pipelines, and I don't think we're exactly where we want to be in that space, but there is some progress. Annotation is another piece that platforms, in the case of microarray platforms, In the case of microarray platforms, let's say, or platforms for doing protocols on your single cells. These have to be annotated in a systematic way. Genomes have to be annotated, pathways, ontologies, and we need to easily join them into our workflows and our objects at any time. And so, flexible programming for annotation, binding to objects, dealing with pre-processing and downstream stuff, this is something we know how to do. Visualization and analysis. Visualization and analysis. Here, I think we didn't want to invent the wheel, reinvent the wheel that we don't have to. So we capitalize on R and CRAN and all the CRAN task views and so forth, and we extend the package and repository concepts that originated in CRAN 20 years ago. CRAN packages didn't have vignettes until Bioconductor came along. So there's a lot of vision there that has sort of percolated back into the general data analysis community. So, what is a package? It's a set of functions and documents that includes a collection of tests. The test should test function correctness and adequacy, and it should pass those tests. Then it's a package, in my view. And the test should exercise these functions in realistic ways. And one of the things it's kind of hard to do is to make random tests, but you really should. Random inputs, random requests. If you repeat the same test over and over again, you're not really learning much as time goes. You're not really learning much as time goes on, even though the underlying platform and all the other components may be changing over time. This is not easy, and I don't have good answers for it, but it's something to think about. Now, a package can have the capacity to be usable on different technological platforms, and when they do this, it's called a portable package. And we've insisted on portability for just about all Bioconductor packages. It's good for your package to be portable. When you find a bug on Windows, it's probably a bug that just didn't show up someplace else, so fix it. Cells, so fix it. And a package may require the existence of other packages. So the virtues and costs of software packages, modularity. It's one of the basic components of divide and conquer. There's protocols in the case of R for documentation and testing. And there's issue tracking when you use a repository. So that's good for your packages. You've systematized portability, maintenance, and management. There are costs, though. In management, there are costs though. So, one of the costs is: are you going to be dependent on other packages or are you going to be self-sufficient? If you're self-sufficient, you have more control. If you depend on other packages, you have less code to write. So, it's an important dilemma. There's another dilemma. Are you going to stay stable so that your users always get the same thing? Or are you going to introduce new features and improve things that may break older features? So, we try to control these, but they are dilemmas. You have to think about them. They are dilemmas. You have to think about them. So, management, maintenance, and portability become obligations that require effort from the developer in addition to their obligation to do research. And so, these costs are non-trivial. And, I mean, there's now, you know, nature papers about credit for code and so on. But still, the ability to recognize just how costly it is to make reliable software that works for people that you don't ever know, you didn't meet them, they don't. You didn't meet them, they don't file bug reports, and so on. It's very serious. So, an ecosystem is a collection of packages that includes a collection of package interoperability tests and passes the tests. And it can be deployed on one or more technological platforms, for example, an operating system or a cloud computing system or a clustering system. And it co-evolves with different platforms that are changing at different rates. I don't think there's much of a question of that, but Question of that, but it's complicated. So I looked at Giotto. This is the code by Rubin and GC, and has some wonderful examples, small, scalable examples. And I was interested to see that as you run it, it says, well, consider installing these optional packages. They aren't necessary, but maybe you'd like to. And then you might even need some Python to do something. And then it says, should I install a Miniconda Python environment for Jyotto? A Miniconda Python environment for Giotto. And I said yes, and then it went and did it. And it told me where it put it. So that's very nice. I consented to this, and it did it. But this Python may be in addition to and redundant with Python that I already have sitting on my system. We deal with that. Now, Aaron Lund has made a package that addresses this extremely systematically. It's called Basilisk, and it's in Bioconductor. And the idea is that a base conda environment will... The idea is that a base conda environment will be stored in a systematically defined user cache area, and it'll be keyed to the current Bioconductor Basilisk version. Okay? So when you change your version of R, you get a new conda system that's compatible with that. When you change your version of Bioconductor, again, this will be updated. The client packages. So this is a new concept. And you would say that Giotto is potentially a client of Basilisk if it went this way. Client of Basilisk, if it went this way. These client packages specify the exact name and version of the Python modules that they desire, which are acquired and cached as needed. So the idea is that when you work with these conda environments, you may get a situation where the binaries for different environments are somehow in conflict. And we want to avoid that by focusing the specific versions in specific environments and using only those environments where this versioning has been controlled. Provisioning has been controlled. And so there's an example. Yep. Two questions. So, one on the topic you just mentioned from Amrit was: Can't you just use a virtual environment? You know, I'm not a Python expert. I think virtualization has been done to the limit that it can be done, and it isn't enough. But there is a virtual environment concept in Basilisk, and I recommend that you take a look at it and see whether it answers your question in a satisfactory way. And the other was. Satisfactory way. And the other was: I held from Stephanie was on your previous slide: if you have a package for mostly for visualization or EDA, what type of tests do you think are good to incorporate? You know, again, I think there's an answer to that. There are test protocols for graphics, and I don't know them, but they exist. And I would agree with you that we I would agree with you that we should put some time into that. But I'm not sure the answers are great, but I think there are tools for it and we should be exploring them. Okay, so BioClearn is an example of a Basilisk client, and it exposes some of the things in SK Learn. And my recommendation is to be very precise about the versions of the Python software you're using, and don't go it alone. So here's what it looks like. If you bring in So here's what it looks like. If you bring in Basilisk and you list packages, these are the exact packages you're getting for all the Python dependencies that it considers sort of fundamental to work with Python in R. And then if I bring in BioC Sclern and do something with it, 11 more packages get introduced into the environment specific for Basilisk. Someone else may need a different version of H5Py, and they can have their environment use that version, and it would not cause any problems for Version and it would not cause any problems for me. Okay, so that's just a slice of the issue of ecosystem interdependence, Python and R. And I'm now going to talk about the build system for Bioconductor. If you've ever written a package or used a package, you may have come to the build sheets, which are easy to find on the Bioconductor site, and you can see already that there are Can see already that there are two versions being maintained simultaneously: 3.12, which is a develop branch, and 3.11, which is the release branch. You can only fix bugs in the release branch. You can't introduce any new features. In the develop branch, you can do things subject to certain constraints. You can introduce new features. You can take things out, but you have to deprecate for one release. So there are three platforms being addressed in each of these. Two streams, release Devel. We track ours versioning. So from October to March, we're doing Devel. So, from October to March, we're doing Devel branch, and we're using R patched from April to September. This is fast enough for the most part for biotechnology, and that we get a point release every six months. So everybody will be synchronized every six months to have all the same code, versions, and so forth. And we work from that. There's limited back compatibility, so there's a deprecation protocol, and the software, annotation, and experiment packages are all first-class citizens. Are all first-class citizens with respect to the build system? One of the downsides, I think, for people who want to use GitHub packages only that aren't in CRAN or Bioconductor is that we don't allow those dependencies. If you want to depend on a certain R package, it has to be in CRAN. At least. I'm not going to talk about ingestion and review for bioconductor packages. There's a big protocol for that. I think it works well. And that's something you can learn about on the slide. That's something you can learn about on the Slack channel if you like. Now, one of the peculiar things is that in order to support the 1844 software packages in Bioconductor, you need a total of 3,800 packages, which include the CRAN packages. So you can see these numbers here, and you can get the exact versions of all the packages that go into a certain build using the build system pages, which are all developed by Hervé Page, and it's an amazing and colorful review of all the resources. Review of all the resources that are there. Now, there are limitations to the build system. We see a lot of it because people can't reproduce the problems that they see on the build system on their own systems. And a big question for us, I guess, is whether containerization of the builder infrastructure is going to help with that, so that we can actually give people the real resources so that they can reproduce every event that they might see on the build system. When we get to containerization, the idea of creating binary package repositories so that you don't have to compile packages in your Linux container image, let's say, when you need a new package. This now becomes a reality, and we have solutions for this. One thing that is, you know, I'm really just getting involved with a little bit is this continuous integration and delivery via GitHub actions. And there are other systems that are like this, but And there are other systems that are like this, but I'll talk about a little bit of GitHub Actions in a moment. Data services are another issue in the ecosystem that I think we need to contemplate more. And then from the point of view of analysis services, the Global Alliance for Genomics and Health, GA4GH, has these protocols for registering tools so that people can reuse them. They get bound to containers so that you can really sort of spin them up and just. You can really sort of spin them up and just use them to do things like alignment and so forth. This is a really interesting set of standards when it comes about to understand. There's something called DocStore that implements this protocol, which isn't really fully fleshed out. Then the Workflow Execution Service is another set of standards in GA4GH. And for large genomic workflows, we certainly want to be able to use standards whenever they're relevant. I'm going to transition now. I'm going to transition now from these ideas to the final topic, which is this idea of a workshop component, which gets into the concept of the ecosystem needed to illustrate one particular activity. It might be single-cell genomics, it might be some subset of that. You want to teach people how to do it. You want to make sure that what you're using actually works when you show them this. So, containerization plays a role, CI/CD plays a role. Role, CI CD plays a role. And so I try to make one of these workshops in conjunction with this talk. And so it's at my GitHub called Int MMO, Integrative Multimodal Omics. And if you go to that repo and you go to the GH pages branch, you'll see that there's a ton of stuff there, including a.github workflows. And that holds a YAML file. And I really don't like this language, but there are lots of good. There are lots of good examples out there, so you can sort of take them and then just make the changes that you need. And I think a few people on this call have gotten involved with this because they're building workflow workshops for the Bioconductor Conference that's coming up. So, you know, let's take this for granted that you can do that. Then what you get once you commit to your repo, once I commit to this int MMO repo, GitHub Action starts doing its magic. And you'll also see this in conjunction. Its magic, and you'll also see this in conjunction with the menu bot. It does its thing, and what comes out is this new GitHub pages site, and there's an article in there which corresponds to one of the vignettes of the int MMOR package. And that vignette is about a cloud-resident data service called HDF Scalable Data Service. And so, when we look at the article, we see that it's markdown and it's a mixture of text and R code. R code, and we'll scroll down just a little bit further. And this is what I really wanted to talk about. This is a package called Human Transcriptome Compendium. It's been in Bioconductor for a while, and if you load it up with Summarized Experiment and run HTX load, you get a summarized experiment that has gene-level information on 181,000 RNA-seq studies. So, this is a snapshot of the sequence read archive that Sean Davis. Sequence read archive that Sean Davis made in a project called Big RNA about three years ago. And it's all uniformly processed by salmon. So what you get is a large chunk of 181,000 RNA-seq studies, and all their quantifications can be looked at as a delayed array. And that involves something called RHDF5 client. That's a package that negotiates between opera. Negotiates between operations that you perform on this summarized experiment, which is a small object sitting in RAM, and the large object that's sitting in the cloud that has all the quantifications. So, understanding this idea of a data service mediated through a nice summarized experiment extension is one of the things I think will be worthwhile for this group as the data that we need to work with gets larger and larger. But the efficient analysis of this that is able to do, let's say, chunk-wise X. That is able to do, let's say, chunk-wise extracts and do linear algebra on this in an efficient way, I think we still need to do some more work on this. We think that this is actually a viable system because it was paid for by NASA, and I think they were happy with it, but we don't know exactly how they're programming on it in order to get the things that they need. It'd be nice to know more about that and then adopt them into the genomics workspace. So, that's the end of the talk. So that's the end of the talk. My conclusions are: we have an unstable software development situation because everything's evolving so rapidly, both in terms of the biotechnology and the things we get to work with and have to work with in information technology. Coordinating our teams, I think, is crucial to avoid redundancies and to learn from one another and gain mileage on our components. And it's not easy. I mean, how often can we get together like this? Slack is helpful, GitHub is helpful, but Is helpful, but you probably need a bit more. Now, for developers, this idea that I can't even reproduce the errors that I see on the build system is a definite pain point, and how to ease that with things that are now available like GitHub actions and containers, I don't quite know. We have to think about that and get it right. Finally, I think these ideas of standards for things like tools and workflows should be revisited frequently and should be a part of our consciousness as we think about this problem of As we think about this problem of multimodal omics in single cells. So that's the end of my talk. Thank you very much. And any questions or comments, I'm happy to take. So there's some, yes, we've got, looks like nine more minutes before the break. So there was continuing discussion in the chat about, so let's see. So Alana pointed out that she says, I worry that restrictions may be imposed. Says, I worry that restrictions may be imposed by our prior expectations regarding unit testing for visualization. And then Stephanie followed up to say, I agree on not wanting to depend too heavily on prior expectations, but curious if there are a set of standards that developers of data visualization or EDA packages should be thinking about. Yeah, I think that needs to be discussed. I think the risks of prior expectations, I mean, that's Expectations. I mean, that's definitely baked into a lot of what we do, and trying to be conscious of that and avoiding it is very important. There's all kinds of concerns about accessibility and interpretability and so on. So I share those concerns. I don't have answers, but it probably would be profitable to put some time into it, but there are probably higher priority concerns as well. Let me see what else I may be missed. If somebody Missed. If somebody asked a question during the talk and I didn't address it or didn't bring it up, feel free to repost it. Oh, here's a question from Amrit. Instead of data in a package, what are your thoughts on fronting it with an API, which may be easier if the database grows, allowing it for targeted queries and preventing Queries and preventing bloat on personal machines. Oh, I'm totally, totally on board with that. So I think it's a somewhat new concept to have the data off the machine in a bioconductor package, let's say. I guess there are examples. I mean, I've tried to do it. I tried to show it here with this human transcriptome compendium. So I think there are precedents for that. I don't think we have a lot. I don't think we have a lot of experience with it, but I think certainly avoiding data bloat is a necessity in Bioconductor packages because you're only allowed to have a 5-megabyte package now, I think. I've grandfathered in some that are bigger, and I'm sorry for that because it's a nightmare to fix that. But yes, I think this idea of a data service and an API is going to be very fruitful. Let me see. There is some discussion on the chat about with respect to accessibility and visualization packages should use colorblind friendly color palettes. I believe that in the newest version of R, there's a palette called Okabe Ito, which is specifically designed for Design for being kind of maximally distinguishing colors for what it's worth. That's just in the 4.0. Yeah, you know, if you're getting federal funds, you have obligations for accessibility that, you know, there are services that will go over your site to tell you whether you've met the ADA requirements. And I think they're actually fairly usable. So those sorts of concerns are definitely valid and should. Valid and should be a part of our working principles. Any other questions for Vince? You can either post it in the chat or unmute. From Alexis, when you develop a new method, how do you choose between making your own little package so that people cite it in publications versus integrating your functions in another great package for more coherence? For more coherence, but then you don't get cited. Yeah, that's a very, you know, I wish people didn't have that dilemma, but clearly it exists. I think the modularity concept would push us in the direction of making a small package that really contributes in a seamless way with other tools. And then your attribution concern, I think, would be allayed. Concern, I think, would be allayed because it really would be an independent package. You'd get a DOI for it, you could write a paper about it. F-1000 Research, I think, you know, is an example of a publication system where we have been able to get packages that have fairly limited scope, get publications that are ultimately indexed in PubMed. So I think there are solutions to that. I think modularity suggests that you It suggests that you keep packages small and have them solve one problem well. So, this idea of a big package that solves lots of problems, I think we would tend to wonder whether that's the best way to solve a problem. It gives people coherence, right? If you look at something, think of one of these big packages like Seura, it solves a lot of problems. You only need to get that, but then all these dependencies are very serious. And the maintenance of this giant thing sort of falls. Giant thing sort of falls on the Syrah person rather than being distributed among members of a team. It can be done, but weighing costs and benefits is a business problem for us. I mean, just one small comment. One way I've done this with DESeeq2 is that if there's a new method, including something written by another group that I want to leverage, and it's very clearly not part of DESeek2, now we're running Matthew Stevens's ASHR. Matthew Stevens's Ash R package, I print out a note in the console that now you're using, this is leveraging someone else's method, and you should cite this paper if you use this in a publication. Keep the modularity, but also give credit. Yeah, that's a very nice feature. And I've seen that message, and I like it. There's a question, there's a conversation about is color Is colorblind palette friendliness part of Bioconductor peer review, and or should it be? I think so. I don't know that it is, but it should be. Yeah. Question from Adine. Can we maintain small packages but use the tidyverse idea such that they work better together, but one library loads them all? loads them all uh i would say that's a that's a user developer level decision i mean you can put a function in your package that does that um i don't know that um you know bioconductor per se would go in that direction you know it it if you think of cran task views there's a way of loading in all the packages or installing all the packages from a certain view and i think for the bioconductor task views we might have had that concept as well We might have had that concept as well. So I think, Edine, that there are solutions in that direction that we could explore and see whether they're very productive. So it's a fair point. I think I was making the point because sometimes I'm not up on the Slack or whatever, and I've missed a new package that came along that works really well with existing packages I use. And it would be a nice way. And it would be a nice way if it was just tagged in that I go library on this, and then my favorite packages plus these new packages, you know, actually were available to me. You know? Yeah, yeah, yeah. So, you know, there has been a tendency to have this function called available packages in certain contexts. And, you know, having something which periodically gives you a list of the things that are available in a certain domain, you know, it's a community. You know, it's a communication problem, it's an endorsement problem, and I think it's important for socializing the process. So, coming up with patterns there that actually work, I think would be valuable. And as packets, the more packages, it's a problem. I was just going to, so we're coming up on the hour, and I want to make sure everybody gets a break before we keep going. There's some a couple notes. So, So, Aideen, did you want to announce the SC proteomics announcement? Yeah, so there was a bit of discussion earlier in the proteomics group with about creating like a little Bioconductor package of the proteomics data set along with the code as little vignettes. And so, we any other products that we want out of the proteomics, and while we're actually physically. The proteomics, and while we're actually physically in the meeting, I wanted to have a quick chat with people. It's literally 10 minutes, it's in breakout session two, and it's posted in Slack. Okay, and then so we're gonna have a half-hour break at