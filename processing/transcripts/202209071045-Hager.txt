Yes, thank you. So I would like first to thank Arald and all the organizers for this nice invitation and regret that I cannot attend in person. It looks very beautiful area. So this is joint work is Alexandra Niam Tou. She's from the University of Constance. She's a professor. I'm a postdoc at Technische University. Uh technician University Berlin and it's uh going to be about quasi-linear Roth revolution equations. So as is a good custom is to start with motivations in a talk and this is a particular motivation that I had that I actually encountered during my thesis. During my thesis six years ago. And this is a particular model that is used in micromagnetics, and it's a very important equation in physics. So because many reasons, there's a lack of uniqueness of solutions without noise. With noise, nothing is really known about this, etc. So it's a very interesting model. Uh, it's a very interesting model, and um, noise here is represented in this uh in this violet term here as a Stratonovich product, and this cross is a vector product, three-dimensional vector product. So, you can put a Neumann or periodic boundary conditions as you like. So, and usually the open set O represents some ferromagnetic material, and the vector U is the magnetization. The magnetization. Well, the noise accounts for thermal fluctuation and has therefore a very important physical meaning. And during the last decade, it has been studied by Grazenk and Goldis, among others. And you have when the noise is specially constant, you can use those sus-manned transformation. More recent work that I did with Work that I did with Manuela Guzzetti from Guillefeld is that of pass-way solution using a rough path formalism and a priori estimates formalism. So it's an entirely different method that I'm going to present today based on my solution. But it's possible in dimension one at least, you're in a dimension one domain to use another solution theory. Theory. So I will be very quick on this one. This is another potential motivation that is also presented as an example in the paper. And the common point with these models is that you have an elliptic operator as the main part of your equation in red here, and it's not linear. Not linear. We know that for all u, it's an elliptic operator, but it's not linear. So, this is hydrolinear operator. And of course, here in this context, we want to put noise, which makes things more difficult. A partial reason for that is what I'm going to explain in the following slides. But let me first say that this can be all reformulated as an abstract Cauchy problem where I put this quasi-linear term. Put this quasi-linear term here in this calligraphic L, and N represents a non-linearity of lower order, and F is some product with some noise. So this is some non-linearity as well. Here, I think in the example of this model, you want to take quadratic type noise. Here it's linear in the you know. So there is a summing group approach. So, there is a summing group approach for this problem, and this is what we want to do here. Summing groups are easy, somehow easy to manipulate, and also give some kind of elegant way to solve the PDS. So we start from this answer now as an abstraction, and we want to introduce the exponential of this operator as a functional. Operator has a functional analytic meaning. And we want to formulate the equation under this form. And the possibility to solve such equation is to use a fixed point argument. But in the case of noise, in the case of DW being, let's say, Wiener process, you have Have issues of measurability because, here, as you can see here, the operator part in this Ito integral is now anticipative because there is some information here. So, the integral here does not respect the filtration. So, you have to make clear what does this term mean, right? Termin, right? And it's so here it's absolutely a possibility is to use a concept of password-might solution. This is what was done by Kuhn and M2 in a paper. Well, they use some kind of integration like part formula here and reformulate the problem. So this is a possible angle. This is a possible angle of attack, but of course, here I'm here to talk about the possibility to do this with RoughPass, which is different and also gives some interesting generalization. Other references are the singular case. So, what this is when the noise is rough with respect to the spatial variable, it's not. Respect to the spatial variable, it's not something that I do, but it's not something that we do actually. But yeah, so for the record, it has been done in the last five to six years by these authors, Baiol de Buchof Manova, Ferland Gubinelli, Otto and Weber, and also Mate and Martin Aira in the In the context of regularity structure. It should be possible in principle to do this by regularity structures, but it's kind of not what we want to do because we want to use functional analysis tools rather than green convolution with green functions. So the framework is a bit different. Also, we would like to allow for more general boundary conditions. Boundary conditions here, for instance, right? So, very quickly, let me go back on this problem and this abstraction. I have an abstract dana space, which is the space where my initial condition belongs. And I look at the problem of this form. And here now, the x is a rough path, integration with a rough path, and so one has to do. rough pass and so one has to do one has to give meaning to all this uh so there is a first component the second component i won't explain what is a rough map here i think you're pretty familiar uh most of you and um you can think of it as dimensional uh one dimensional because otherwise it requires some vector notation and for only notational reasons take d equals one. Take g equals one in what follows. So, the tools that we want to use to make sense of the equation, namely to make sense of the rough convolution, the tools we want to use is a parabolic space-time regularity. So, there is a regularity that you can guess for parabolic problems. There is some particular Problems, there is some particular failing. And these are modelized, these are incorporated somehow in the effect, in the functional analysis effect of the evolution operator as we remember this exponential. Now I said functional analysis, so I need to introduce some function. So I need to introduce some function space. But these are done in an abstract way. So I don't have to explain all the time that actually for the examples that I have in mind, it would be Sobolev space or a Bessel potential space or Besov space, for instance. So but the theory we built here is incorporating all these function space. These function space ones because these function space have nice interpolation properties. So, what we do is the following: we suppose that we have a constant domain for a fixed argument of the for a fixed argument of the Kaiser linear operator. And the domain is constant, and we call it B1, and it's continuously embedded in B0, which is a reference balance. Which is a reference banner space. Now we define intermediate spaces. So you have one and zero, and now we define the intermediate space, alpha between zero and one, and we define them by interpolation. So if you do not know anything about interpolation, it's really fine. And it's a complicated theory, but you have to just accept this as a black box. And And if you want to remember anything about interpolation, it is that it gives you this sort of inequalities. So whenever you have an element which is in both spaces, you have these interpolation inequalities. So you can bound the norm in an intermediate space beta by estimating between alpha and gamma. So that's Alpha and gamma. So that's this a bit the philosophy of interpolation. So the point is, if you think about this, the standard elliptic operators, like the Laplacian and many others that we are familiar with. Then these bases are well known and depending on which interpolation technique you use, you will end up with Sobolev spaces or besof. Spaces or Besov spaces. It's all these cases are included in the theory. So the Kaiser linear term is we need to make an assumption, of course, on it. And we assume that alpha, remember, is the degree of spatial regularity where the neutral condition lives. I take a slightly lower value. Lower value for compactness reasons, and I assume that it has this Lipschitz property. So, as an operator from V1 to V0, V1 is the domain of the operator. Remember, I have an operator norm, which is Lipschitz in its argument. So we call the operator norm is this. And for each one in some open set, I assume that I have a generator of I have a generator of a parabolic evolution family. What about this? Parabolic evolution family is a generalization of a semi-group where you have two parameters. So instead of writing T minus S, you write T comma S. This just means that the evolution depends on the particular base point in time. Same thing as. thing as a semi-group really. So it's multiplicative. So you have this equal property here. You have some regularity axioms that I won't detail here. It takes value in a space of differential operator, of a bounded operator and it's the identity on the eigenview of these objects is that they have some smoothing effect. So if you start with some So, if you start with some initial condition and make the heat equation, so they give the solution of the heat equation. And if you evaluate the norm in a paper space, then it belongs to this space, it's not infinite, and you have this estimate with this blow-up. It's regularizing, and also you have the somehow. Also, you have somehow the convert statement that if you subtract the identity and accept to lose a little bit of regularity here compared to the right-hand side, then you gain some older regularity. So there is really a balance between space and time. So otherwise said, let me introduce notations. So I have these S, this norm of S and norm of S minus identity. S and norm of s minus identity, which are less than k and k tilde, where we introduce these generalized holder norms. And here, what's nice about this notation is that beta and beta prime, they have no order. So you have sometimes you have some blow-up type norm and the other way around. So you have this generalized older norm. And they are very extremely useful in evolution. In evolution, in evolution equations. So, the first thing we want to do with these norms is the following. We would like a perturbation argument because we would like to make a fixed point theorem and at some point in the fixed point argument we'll have some terms that look like this. We'll have some terms that look like this. So, there will be two different generators applied to. Be two different generators applied to control dwarf path, and we want to have bounds for this. And the basic lemma we use is very well known results, and you can find the proof in many textbooks, is that this generalized Holder norm here, you assume you have two generators, two evolution family with generators L1 and L2. L1 and L2 that have constant domain B1, then you have this estimate. So you can estimate the difference of them by some constant, which is Euler beta function. It does not really matter, but I find it appealing somehow. Times these norms here of each of the elements. And more important here, we recover the difference of the generators. And that's the property. Uh, that's the property we're going to use to want to make a fixed point here. L is l1 is substituted by this allographic l evaluated to a point and same thing for the right term. Then I will have, I can use my Lipschitz bound, which is an assumption, it is a structural assumption, and then I can close contraction. Contraction. At least there is hope. It is classical and based on this representation. Now I need to talk about control rough paths. So I've spoken a little bit about this already. But control rough paths is you have a rough path, X, and And you want to compare its increment. Sorry, you want to look at paths that have the same local behavior times a certain modulation, which you call Gubinelli derivative. So you want estimates of this form. So here, what this says here is that if y, let's say, is the solution. If y, let's say, is the solution of the PD, I cannot expect that it's gamma holder like this. In order for that to happen, I have to subtract something. And this something is proportional to the increment of the roughness itself. I guess most of you know probably this very well. But here, the punchline is that you have special component. And it's very important here to not work in the same space. For y, for instance, is the same space for each time is a path with value is in B alpha, and this is the space where the initial condition lives. But if you want now, if you want to get some Holder regularity, you have to subtract some spatial regularity here. You have to look in. Regularity here. You have to look in a weaker state. And the good value for it is gamma, actually. So gamma here appears both as a time irregularity index and as a loss of regularity in space. So this in this in this paper here, so this should be well known actually. So there is a seminar where Seminal work of Komini and Tidon on this, and more recently there was the work of Jazimovich and Ira. And even more recently, there was this paper of mine and my friends. So this was the main idea in the PD part of the paper. So we introduced these nodes where we have this other nonce here for parameter object. Other norms here for parameter object, so you and you balance space and time regularities. So here you see you take two gamma in time and minus two gamma in space. So this is the philosophy of these norms. I will try to accelerate a little bit because I'm already late. Now, in Keselinar's case, it's not working. It's not working. So there are many reasons for that, but you cannot work with this space. So you need to introduce further parameters and a subspace of it. So we introduce this space here. So looks a little bit crazy at first sight. We need those four parameters. We take gamma prime to be the regularity of the Kubernetes derivative in time, which should be different. Time which should be different from the solution, and we take the spatial loss sigma to be a number which is less than gamma instead of taking it equal to gamma as I did earlier. Now, with this framework, it's still not working unless you add some weight at zero. So, there will be a blow-up behavior that you need to control, and you cannot use a trick to remove it. To remove it, so you have to work with these weighted norms here. And the weight here appears as some component, some power of s. And the good value, so it's possible to take any epsilon larger than this, but the good value is gamma minus sigma, also positive number. Sigma is a special loss, gamma is the holder large of the rough. Regularity of the rough. So, Antoine, just let you know you have about three minutes left. Yeah, three minutes is not enough. I'm sorry. So, I will maybe skip this slide. So the solution theory should now be in this class of holder generalized control class is weight at the origin. The key point is the weight. The key point is the weighted sewing lemma and the perturbation argument. We want to do a fixed point. For this, we need some remainder estimates. So, remember, if you know a bit of rough path theory, the way we define the integral is quite tricky. In general, we have this compensated Riemann sum, and we actually define it to be the Taylor expansion plus some remainder. And this remainder is really what we estimate. Remainder is really what we estimate. So, here we have nice remainder estimates in the setting, and there is a balance between the gain of weight at the origin and the gain of regularity here that you can gain for the remainder. So, this is an interesting phenomenon, I think. Now, perturbation result is an essential thing, as I said earlier. We can also We can also estimate these remainders as by fixing the integral and making s vary. And so we end up with this nicely estimate here earlier. And the idea is a generalization of a swing lemma with weight. And so you write this as a sum of what you make called day. And this And this has a particular expression as a compensated remnant sum, and you end up with some nice bounds. I can only recommend you to read my paper if you are interested in this. Right, so this is the main result we obtain. So, for every U0, so under some assumptions, for every U0, there is a unique local solution, blah, blah, blah. Blah blah. And you can apply it. What's also cool with this theorem is you can apply it directly to general, to very general Kesellinar system, so arbitrary order. So you assume you have a differential operator of order 2m. In general, what you encounter in life is that m equals one, but there are some interesting cases to be one. To be one, and you assume a little bit of regularity of the coefficient, and you end up with a solution theory for all these familiar equations. That's my opinion that that's somehow an efficient result because we can deal with a lot of functional space, and we have a quite general during. But I'm not here to judge my own work, so I'll let you do that. Let you do that. Straton of each noise is a particular case of rough integration. Somehow you can enhance your... So let's go back to the stochastic LG equation. We can solve it. It's the case n equals one. Remember, I have this. Excuse me. Sorry, I think just playing it. I think the time is up. So if you could just wrap up pretty soon. It's 10, so it's exactly 25 minutes. Yes. May I have two minutes more? Yes, sure. I'm sorry, but yeah. Right, so it's almost over. Theorem, so that's theorem we obtain, right? So, a nice collary of this: if we can build a random dynamical system in the case of dimension one for LG, it's really needed that we work with Mike solution, and this was an open problem, actually. So there is a theorem by Alexandra, and it says that if you have a Maxolution in some abstract banner space, then you can have you can build a You can have you can build a random dynamical system, right? So, I won't give any detail here, but um, a proof of this requires only to take our solution concept with a manuela here in this in this paper in one dimension and to check that this is indeed a mic solution. So, there is a bit of technical work here, but it's it's done quite easily, and uh, that's it. So, you see, I'm So you see, I'm really sorry for these two minutes. Let's thank the speaker very much. Let's talk. Are there any very quick questions? If not, let's thank the speaker again. But the next speaker, Paul, please share your screen.