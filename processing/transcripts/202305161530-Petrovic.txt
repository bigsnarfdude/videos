Jashkara, Devdi Pati, and the rest of the MRC participants from a few years back. We studied a network model, but this is something that works in general. So I can derive to you something that I'm going to call a goodness of fit p-value in the Bayesian setting, where you have a mixture model. So X is the observation you have, Z is your hidden variable, right? And these models here are all log linear, Tauric models, discrete exponents for families, and then you have some hidden variable. Explanations for families, and then you have some hidden variable in tau. Think of it as just a phylogenic three-type mixture, or think of it as a random graph model with hidden communities or something like this. Okay, in that case, there is a very, what looks naive, but we can prove is what we need is a way to compute the goodness of it p-value. All you're doing is doing averaging by the posterior distribution on the latent variable the usual. Latent variable, the usual MCMC algebraic statistics p-value for log linear models. Okay, so I have about a page of notes that I can write on the board to explain this, but I think I leave this for the end so that I don't have to swap between slides and boards and lights and whatnot. Okay, so I can explain this and it's sort of explained also in this paper, which is on the archive. Oh, okay. And this equality is just proportional to right because on the left, yeah, I. Because on the left, you have to do that. Yeah, I am missing every constant possible, and nothing is right. Also, this is just to sort of explain that you can re-weigh everything correctly. Okay. And so, but there are many steps in the algorithm of doing a goodness of fit test for such a model. You have to know how to deal with the latent Z. I don't know. So, I asked my Bayesian friends for some black box estimator for this. And then from that, I sample, I get several. From that, I sample, I get several different sufficient statistics that I sample from those different fibers and average them out. So there's a lot of averaging happening that I'm not putting on this slide because it's like another talk. Okay. Okay. But I still have to compute the p-value for a log linear model. So that's why I still care about sampling model fibers. What's happening? I cannot click. You can click. First-click on that and then pull it up. Yeah. Okay. I love that. Yeah, okay, I love technology. Sorry, it's fine. Okay, so the main players in this talk, or I decided to, it's fine, to do a subtitle on the slide that everybody knows, but there must be at least one person who doesn't love this notation, so I put it here. A is going to be a large, possibly sparse matrix. I'm going to assume it's full rank. So R rows and n columns. X0 is some observed data. Sorry, contingency table. B is a lattice basis. B is a lattice basis of this lattice kernel of A, and I'm picking a lattice basis, not a marker basis, okay? Because it's the only thing that I can actually compute for my examples, and I'll show you why. And the notation for the fiber is going to be F of the right-hand side B, but I never need B, so it doesn't appear in this talk. It's just A times X0, okay? This is the value of the sufficient statistics in the contingency table. So, for those who are perhaps the newest, new to this, you can think of this as. This, you can think of this as the, you know, um, um, a marginals of your contingency table, which are sufficient to describe the distribution of that table. Okay, and uh, so F is the fiber, and of course, there's something called the fiber graph for any set of moves. So the graph whose vertices are the points in the fiber, so all other tables that have the same sufficient statistic and whose edges are there for every move that can connect two points, okay, and so. And so you can define such a fiber graph for any set of moves. You can say, I'm only going to change this cell and go in this direction, and you have a very sparse, unconnected fibergraph, but you can define it. And Markov basis, the definition of a Markov basis is the minimum set that's necessary for connectivity of this graph for every sufficient statistic, right? And some examples are, this is from Hema-Kevindich paper 2015. This is in the Journal of Algebraic Statistics, the top journal in the field. The top journal in the field. It's true. It's true. Everybody who is a leader in the field has published at least one paper there. So, you know, it is the hot topic in general. But, you know, the black points are points in the fiber. They're lattice points somewhere. They're all non-negatives. This is a positive orthem somewhere. And the fiber graph, I put an edge if there exists a move that connects these two. I literally copylifted the figure from their paper. So this notation is not the same as mine. Is not the same as mine, but here you have a set of moves that connects. This is a reduced Grobner basis, this is a universal Grobner basis, this is a Graver basis. You have more connections. So the bigger your basis, the more connected your graph is, the easier it is to explore the graph by starting at a point and trying to explore other points. Okay, so, but I'm going to define a fibergraph, or I'm going to be working with a fiber graph, which is disconnected, and I'm going to work on trying to connect it. And I'm going to work on trying to connect it. Okay. I went through this very fast, assuming people are comfortable. If not, now is the time to stop me. Or stop me, I guess, later. Okay. So copy paste. So it's a screenshot of, I forgot what page number, remark number four from Barron's 98 paper, which I, you know, this is, please don't blame me for doing this. I'm doing this for a reason. Everything that people have thought about improving micro-based. Have thought about improving micro basis, it's in this paper, okay? So, and I mean, because so here's an example: they said, you know, blah blah blah, this is a notation, fiber, you know, okay. Maybe we should do something like a lattice basis. So take a disconnected set of moves and take a Poisson, many combinations of those moves and hope to connect the fiber. We have tried this idea in half a dozen problems and found it doesn't work well. In other words, does the motivation In other words, there's the motivation for actually understanding the full marker basis. You cannot explore a fiber with a disconnected graph. What's wrong with you? But the idea was you try to combine the moves to hopefully jump over these disconnected pieces. Except sometimes it works. So then this paper from 2011 says, you know, with many examples, we show that the appropriate lattice basis is practical. And I don't read the rest because the rest is exactly the idea from the previous slide. From the previous slide, that's exactly what they do. They take Poisson, many a linear combination of Poisson, many lattice spaces, you put them together, make one large move, and just go. Okay. So does it work or does it not work? Okay. And the issue here is it works for these two models, discrete logistic regression and no three-way interaction. Okay. It requires a careful study of what the fibers look like, as most of the time. Like, as most of the time in applications, you can't run anything out of the box, right? So, you understand the fibers really, really well, and then you tune the proton parameter. And when I asked, I think it was Hara who gave a talk, I said, how did you pick? You know, they took a Poisson combination and the mean of that poisson was 52 or something. How did you pick 52? He said very carefully. So, and I mean, I mean, and you know, in the acknowledged Olson's paper, it says it's a remarkable. The acknowledged Oswald's paper, it says it's a remarkably delicate operation. It becomes clear the moment you try it that nobody, I mean, we don't know how to do this in general, right? So it's actually hopeless. I think that's a dissertation topic. I mean, it's not like we don't, yeah, we don't, I don't know. I actually think it should be like five, but whatever. No, but this is something to explore. Okay. And also, here's the other problem. And also, here's the other problem. Some fibers are simply bad, quote, okay. So, everyone has seen this kind of an example. This is again a quote from a paper. I'm sorry, I have to do this to like illustrate a point. So, everyone's seen this example. Maybe Rudy is the expert on this or something. You have a fiber which has this one Markov move that is necessary to go from the left side to the right. And of course, the fiber doesn't sit like this. Yeah, these two cubes are in two different spaces. So, you actually, if this, if, and you're sitting here trying to explore and you're picking. You're sitting here trying to explore and you're picking moves randomly, you are almost never going to get across to the other side, right? I don't care how fast your algorithm is for the marker basis, you cannot bypass this issue. It's a bottleneck. And actually, Hemeck and Windis have this construction, which they disprove some theorem about mixing times. And the construction is a general family of matrices. You cannot see, but there are lots of little connections between two boxes that generalize those boxes. So it's a dense box, dense box, and then one edge in between. Box, dense box, and then one edge in between them, and they also sit in funny spaces. Okay, and these fibers are simply bad, okay. And they say, well, there is a way also what they do is they study very carefully the structure of these fibers for this family of matrices, right? And they say, here is, we cannot come up with a solution in terms of just Markov basis, it's just you're stuck, even graver, you're stuck. However, you should, you know, take a varying number of linear combinations that's the Number of linear combinations, that's the same idea, but do it in a way that edge expansion of the resulting graph can be controlled. Now, here's my, this is the catch-22, right? I do not understand the fibers that I'm working with. I'll show you what they are. I don't understand the matrices I'm working with. I've never seen historic ideals before. I do not have a theorem, but I want to explore the fiber really badly. So, how can I do this when I don't know the fiber graph? I don't even know the size of the fiber or the estimate. I don't even know the size of the fiber or the estimate. I don't understand the structure of my lattice at all. And I don't know what this means varying number of moves. So the best I can do is try what the previous paper has done is try 50 or 10 or 500. I don't know. Okay. So how do I do this? So this is the conundrum that I'm in. And I think if you asked me last year, I would say, well, there's no point. Like this is just, you cannot solve this problem. But now I want to solve this problem. And this is what I really want. Problem, and this is what I really want. I want a model-agnostic algorithm in the way that the original Metropolis Hastings using marker bases didn't care where you came from and who you were. It was just this is what you do. But I needed to learn the fiber as it goes. Right? So it has to be some smart way of updating what you're doing in sampling so that you're not stuck in these corners. Okay. And if you've been plugged in into this randomized algorithms world, you'll. Algorithms world, you'll realize that a lot of other fields know how to do this really well. In particular, statistics knows how to do Bayesian setup and update as they go, right? You keep updating your input and iteratively you convert to something better. So instead of showing you the algorithm blah, you will see it, it's not green. Instead of showing you the code or something, I'll draw the picture of our algorithm. And I forgot to say this is joint work with my PG student, Miles Bacon, who's his graduating. Student Miles Bacon, who's graduating next year. So I have my integer matrix, I have the fiber AX0, and I have a lattice basis. For the sake of me not putting dot dots, let's pretend there's just three things, although this is D, right? So I have element in the lattice basis, and I have a starting point x0. Okay. So I pick a vector of coefficient means lambda. I have a lambda plus and a lambda minus. Okay, bear with me for just one second. Okay, bear with me for just one second, I'll show you what this is. And then I sample from the scallum distribution, which is the difference of two Poissons. Okay, I sample yi, and these are the coefficients for my basis elements. Okay, so I do not take plus or minus bi for each basis element because I cannot. I need a marker of basis for that. I do not take plus on many combinations, I take a difference of plus on many combinations. Okay, and I do not apply one move, I apply the whole movement. I do not apply one move, I apply the whole thing as a move, right? Because it's doing one will not be sufficient. So, this thing is now my new point, which is obtained like this. Okay, and again, scalum is just a difference of Poisson, so it's a similar thing that was in the original paper. All I have to know is what the heck is this lambda? And this is the parameter I'm going to learn as I go. Okay, I'm going to start with it being one, and I'm going to learn it as I go. One and I'm going to learn it as I go. Okay, so what I do now, I repeat this for n steps, capital N. So X1, X2, da da da da, Xn. I predetermine what N is, let's say 1,000 or 100 or whatever. And when I'm happy, I don't know what that means. When I reach Xn, I stop and reconsider where I have been so far to adjust the sampler. Okay, so I adjust the Lambda according to. According to how according to usefulness in fiber discovery, let me not make a technical definition: the expected number of points that are seeing new divided by the size of blah, blah, blah. How useful were the moves in discovering the fiber? Well, what do I mean by this? I look at the moves that I've seen so far. And for example, if I had seen a plus B1 here and a plus B1 here and a plus B1 here, so a plus B1 is appearing a lot, I'm going to increase lambda one plus. I'm going to increase lambda one plus. I'm going to say, hey, we like applying b1 in the positive directions. It seems to be finding lots of points, not on its own, in a combination with other lattice spaces, right? Because if it's just on its own, you're just going to be stuck. But the point is, it's contributing a lot to large, feasible moves that lead me to new points. Yes? Does it make sense? It's only intuition. Well, it's just vision. Okay. It's just vision, okay? So then, what I do is I sample a new x zero and I repeat my algorithm. And I repeat from a mixture. I have the old x zero, I've explored the blue points, then I find a uniformly at random, pick a new point, and I can decide if I only want to pick the point from only the new things that I've seen or overall the whole fiber that I've discovered. And you can decide that on the fly. I don't know. Depends on the application. So, what's the output of the algorithm? Instead of having a marker chain that goes from x0 to x1 to da-da-da. From X0 to X1 to the, I have this is not exactly a market. Okay, I don't actually know what this is. It's a list of fiber points, but I actually, each time I have this, I do this capital N many samples. So I actually have some kind of filtration on my fiber as I keep going. Okay. So I have F0, which is the neighborhood of X0 that I've discovered. This is the new neighborhood of X1, and so on. And it's not difficult. And here's a statement of my theorem. This equals everything, okay? Equals everything, okay? Never mind the, I cannot, the notation, yeah. So the theorem is: if you run this chain long enough, yes, you will find the whole fiber because you have a positive probability of every possible feasible move in the universe that can be applied. And how fast does it converge to that? It depends on how many of those bad bottlenecks your fiber has. So it's not yes. But from your own words, it From your own words, it looks like it makes sense to also model dependence between these YIs because you you make them independent, but you said that they will typically yeah, next step. So I have no idea, right? So I think this is like the first basic thing, and then we should build on this because I think it can do a lot more than it's doing doing right now. What it's doing right now is it can handle matrices that I cannot handle otherwise. So yeah. I mean, yeah, we're plugged in with the ground zero, which is just the Poisson and then the difference, and then just see what happens. Clearly, this should be upgraded to something else. Yeah, yeah. So, are you seeing like conversions in the parameters for your Stellon distribution? Also, that's a whole side. Uh no, no, no, no. So I do not know, I cannot tell when I have converged. Oh, I can tell, but it's not. I'll show you a picture. I'll show you the plot. Okay, so here's one plot. Okay, so this is the picture of a four by four independence model from the 98th paper. Because if you don't do that, so you don't need a Markov change for this, but we try anyway just to see what happens. It's a fiber that has, Luis will know. Luis will know 17-digit size fiber. It was in his Alexstad package tutorial slides. This specific example is being done so the package can run a Markov chain and do really well. So I do the same and I do five time steps, five iterations, and each is a sample size of 1000. Okay, so what I'm plotting here, I'm sure you cannot see, is one, two, three, four, five iterations. This is the black starting point, the blue starting point, the green starting point. The blue starting point, the green starting point when I restart the sample from that point. And at each point, I sample a thousand potentially fiber points. Of those thousand, I reject some because of those thousand, I may create a negative entry in my vector, which is not allowed. And so that goes away, right? And so the number of points sampled in each iteration ranges from 500 to 800. So that means at the very beginning, when you have the At the very beginning, when you have the dumbest possible input lambda, half of the points take you outside of the observable fiber. They take you to negatives, you throw them away. But as you learn the lambdas, it gets better. You keep discovering more and more. And on the right-hand side is the number of new fiber elements. As you can see, it's about 550 per whatever that number is. So the discovery rate drops after some time because I keep rediscovering the point. Because I keep rediscovering the points that I've already seen, right? But I discover them at a steady pace. So, in, I don't know what this is, 18 seconds, I've seen 11,906 fiber points, basically roughly 2,500 per iteration. So this is the new element sampled at each point. So I'm happy because this is like a nice large fiber. I can probably run this for a long time and discover the whole thing, but that's a boring example, just like a But that's a boring example, just like a proof that it, you know, that I'm that we're not doing anything wrong. This is the actual example that brought this problem to us. So I have a family of really large sparse matrices. There are two parameters, n and n. On this slide, you will see the pictures for n equals m equals 8, which is the smallest interesting example in the application that we're studying. So this is the approximate size of the matrix. size of the matrix. Four times seven times seven plus four rows. And then eight times eight times six times seven times seven plus six columns. This is 200 by 400, whatever. Okay. I cannot even put this anywhere and ask for cis, ask for the lattice basis. I cannot, we crash, or maybe I can, but I don't have a supercomputer. So I cannot compute the lattice basis even, which is frustrating, because then you can surely not compute the micro basis. So Markov basis. So, what we did is we Miles implemented a sparse implementation of how you do the Lattice basis using the matrix structure, which is easy. And this works for all sparse matrices, not just this one. And then he was able to run this. So 10 time steps, 10 iteration, da-da. And we see, you know, in, I think this was three minutes, 41,000 fiber elements. And again, the fiber discovery rate is very nice. Okay. This example makes me feel good, but since you Makes me feel good, but since you don't know where it comes from, let me tell you why. This example is the smallest polytope whose lattice points we need to sample in order to solve a massive optimization problem. And it's a PDE-constrained mixed integer optimization problem. And people at Argonne National Lab want to solve this. And my job is to give them a sampler that can help solve it because nobody can solve the problem. It's just that large. Okay. I can't. So you don't know the way just I don't know what percentage of it is, yeah. But for them, it doesn't really matter. So, what I'm trying to let me back up. So, the question is: do I know the size of the fiber and then how do I know when to stop? It depends on what your goal is, right? In the way I'm presenting, my goal is to discover the fiber, right? Because I'm interested in how well this, it's not a chain, this algorithm is performing, right? In their setup, they actually have a linear optimization function. Actually, they have a linear optimization function. So they're going to bias the lambdas according to the cost. Then they don't care if they discover a fiber, they just want to find the approximate optimum, which I can do very fast, right? If I'm doing statistics, I just have to have a sample large enough and be happy that I've sort of explored around. So you tune the lambda, the input to what you need, but I have no idea how large a fiber is. We have a hard time putting the matrix A into R and asking. Into R and asking anything, which is surprising, okay, or was surprising to me. And so, um, all right, so maybe this works well, but what happens with this? Okay, because this is a bad fiber no matter what you do. And so, when I talk, I told Jesus de la, hey, I have this algorithm that's going to replace your Roomba, he said, make it run on this fiber. Okay, fine. So, we start. Very scared, but this fiber we know has 2048 elements. We know has 2048 elements because they understand it really well, and we actually discover it in, I said, here three minutes. And it took three minutes because my silly sampler is discovering a lot of points until it gets until it exhausts the left side, right? And then it jumps over and finds the right side. Okay, so this is the fiber discovery rate, if you will. Like how many new elements are you seeing? And at some point, you don't see any more. So I don't know, this is convergence. Or you wait to see if there's going to be an. Or you wait to see if there's going to be another jump for another component. And then at some point, I don't know when you stop. Okay. So I have you never know when to stop, I guess. So it's interesting to say, you know, when I first thought we were going to run this, I was sure we were not going to get that move. But what's really happening with these kinds of fibers is this. If you have a mark of basis element, which is like this high conductance end that you really need to go from here to here, the problem with the Markov chain. The problem with the Markov chain is that you have to be at this vertex and then pick that move, right? You cannot be at a neighboring vertex and then pick a right, but we can be at the neighborhood of that vertex because every edge in the way the algorithm is set up, every edge from anywhere here to anywhere here has a positive probability. Of course, most have small probability, but Have small probability, but there is a widening of this bottleneck because if I'm in the neighborhood, I just need a combination of moves that will get me that way, and there's a lot more combinations compared to just doing that one. Okay, so we have never been able to get stuck in one component of the fiber. I think I could probably put you to sleep by giving you all the details of the algorithm and you know. All the details of the algorithm, and you know, a heuristic, how you bias. So, there's a lot of heuristics that go on here that you can put in and you know, hope for better results. I'll save those under the rag until there's a question about them, okay? But it's, I originally said I want something that will learn the new component of the fiber and they will not care that there's this high conductance edge. And to me, this is good enough to sort of run that way. Okay, and we've tried it for these large AKs, I mean, and it's fine. AK is, I mean, and it's fine. Yes, please. Yeah, yeah, very good. Combination. Combination. So let me. So you don't immediately go there, but what happens is when you're sitting in this part, this You're sitting in this part, this is one of the moves, this direction, okay? And it's not equal to that move, and then this is another move which is on the direction, and you end up biasing towards these because they've discovered a lot. And then what happens when you're close to here? You end up taking a combination. And so that combination gets you somewhere. And this is not an unlikely one because I have a, because I've updated my lambda. And then you end up going from here to discovering a new one. And you have no idea what the. Discovering a new one, and you have no idea what the corner is, yeah. And so that's yeah. Can I ask you how do you decide when to apply this option to take the longer sequence? I always take the long sequence. I always take the long sequence. Okay. So I always take the long sequence because if I start from a so when I work on random graphs. When I work on random graphs, I start with a Markov basis and I take a lot of small steps, one at a time, because I know they will suffice. And then once in a while, I jump to make sure I'm not stuck. But here I have only the lattice bases. I got three moves instead of 17, you know? So I never take just one of those three. I always take a combination. Again, yeah. Is it the most naive? Yeah. Naive, yeah. Where did I go? Yeah, so uh increase. Okay, so in the pseudocode, so you start you, so you start with lambda being one, because what I want to do is plus or minus one every lattice basis move, and then of course I combine them. So that's like taking up plus or minus one in the micro basis quote, and then when I have seen that this lattice basis move B1. This lattice basis move B1, I keep track of the number of times I have used that move successfully, and if I have used that move successfully a lot, I don't know what that means. Successfully in the sense that I found your points. I found your points, yeah, because we keep track of have you stepped outside of the fiber? Okay, well, that's too far. Don't go there next time, okay? But you cannot tell the algorithm, don't go there next time. You just say, well, maybe this wasn't our favorite combination of moves. Our favorite combination of moves, but maybe those that end up being inside are our favorite combinations, then we bias towards them. So we increase, this is the mean of the Poisson from which you sample the coefficient. So if you increase this to 1.1 or whatever, 2, okay, let's make it 2. This means that next time you are expected to take twice that move. Doesn't always work, but it's post-on anyway, so you're not always going to take. Work, but it's Poisson anyway, so you're not always going to take twice that move, right? If you do it, that's the thing. If you do it always twice, you'll get stuck, right? But you let yourself out of the corner with this Poisson scheme. Yes. This picture is based on intuition, but we prove that this works and we understand the convergence rate in terms of the structure of the fiber. I put none of that on the slide, but that will be in the paper. So that will be in the paper. The intuition, it's just which formula? This? Yeah. The number of points I discover here and then the new points I discover at the next iteration and so on. If I keep running the algorithm, I will discover the whole fiber. I will never get stuck. I can't get myself to write this in words on the whole slide. It will just. Sorry, I can't. Yeah, it's clear you had this press. Clear you have this pressure, they're a fixed length. I don't know. I don't know. I don't know, but I do know that even if I start from here, forget everything else. I just do a lattice move combination for eternity, I will get the whole fiber because it's. For eternity, I will get the whole fiber because that's the definition of a lana spaces, and I'm combining them. So, the only advantage I'm providing to the original suggestion of just do the Poisson and it doesn't work is learn the Poisson as you go. Let it learn where the fiber is, and it will find the rest of the fiber. X0 is close to the bottom right corner, then you'll jump right across the corner. In your very extreme example, it's very unlikely that you will actually in any of these. Actually, in any of these n paths that you start at X0, that you will cross. So, your Poisson will update you so that you actually, in the next step, except the there's a I think there's a proposition that says that when you have such an edge, because it's going between completely different components in different dimensions, that's actually in the latest places. So, you will be likely to jump. So you will be likely to jump between the two for a bit. The only way I can prove that it's faster than the original MCMC or the Metropolis Hastings is the fact that I've widened the bottleneck and I can prove that I've widened the bottleneck because the mixing time depends on these high conductivity. Depends on these high conductance edges. I cannot because I'm not uniformly at random picking moves. So I do not know the mixing time, but I know it's better than Metropolis Hastings with Markov basis, which is not necessarily the best theorem right now, but it's the first one. And yeah, I don't know. Yes. One lambda and I mean. One lambda and I mean lambda plus and lambda minus for the positive coefficients, the negative coefficients. Globally, one at a time. Globally, one at a time. There's a lambda i because I go by iterations. So I start with the lambda and it's one, one, one, one. And then as I update, I replace that lambda by the new lambda. So you're kind of like taking the visual settings and you're saying. So and then you're a scanning that these kind of linear combinations of the fault. And then you're not going to formally randomly pick them. You're picking them probabilistically depending on the probability distribution that is produced from the fault on it. Correct. Which I don't know what it is. Maybe you do. But it's after those collodions. It's those same randomness terrible fire, right? So like if I mean No, no, no, no. I mean, at a given step, yes, but at the next step, it depends on what happened at the previous step. Yes, it's updated. Yes. There's still one set of correct. So maybe you could even think about it as kind of reduced distribution. Yes, yes, exactly. And I don't know what it is. Yes. Yes. Let me edit my question at the end based on what you just said. Yes. No, no, they're good. It makes sense, but for some reason, we haven't been able to get stuck anywhere. So I don't know. So the disclaimer, this algorithm was finished. This algorithm was finished and running on Friday. So I have no idea what it's converting to, but I know that it works. And I'm like, yeah, so okay. So I'm not, yeah, so I have three questions that I should edit according to what you said. So we should just, yeah. I don't know where I, what, what I said. Oh, yeah. So I showed you this. Right. Oh, yes. So my favorite, my, my, one of One of my really favorite papers is this basic and Clifford paper, where they actually use markov chains, mark of bases, and discuss them. And this is the, I think, the algebraic statistics quote of all time. I don't know why. It says, the MCMC algorithms have been successful. They reject the hypothesis model with annoying regularity. And this is in the context of it never works. The statisticians know it's not going to work. You're never going to get the micro basis. You're never going to break it. And it just works. So I also in the same sense, like this algorithm is really. The same sense, like this algorithm is really annoyingly working, and there are some bits that I understand and some that I do not. So, here are the three questions that I don't know how to solve yet, or we haven't started. The first question is, and this is in line of sort of what you said, but I want to sort of make it in this way. So are we able to build up a Markov basis? So clearly, the answer can be every time you take this combination of moves, you know, from here to here, add that to your bag of. Add that to your bag of moves. This is a terrible idea because you have 3 million moves in no time, and most of them will not give you anything, any advantage, right? You're doing combinations of micro moves, it's completely useless. So there are cheap moves that you can easily obtain again. And then there are these useful or efficient moves, and I don't know how to quantify them mathematically or algorithmically. Okay. Because the reason I can't is the fiber discovery rate seems constant. Is the fiber discovery rate seems constant for us? So I don't know at which point I go, oh my god, that was the best combination. Let's keep it. Like, what, like, when? What? So I need a theorem instead. Can I test if I discovered a circuit? Surely someone in this room knows something about circuits of Tory Green Hills. But the problem is, I don't understand the structure of A. All I have is a lattice basis combination. What's an efficient way of telling? An efficient way of testing whether I discovered a circuit or a graveyard element or a dispentimental element or one of these edges in the corner, whatever it is, okay. And I need this for sparse matrices for which we cannot run the Alexand package and say, given the lattice basis and give me the marker basis, okay. And also, if you have a block structure of A, what is the state of the art? So Jesus, oh, this is a comment for myself. I forgot to comment out. He forwarded me on the recent paper, which is 78 pages, and I sent it to a student to read it. And I sent it to a student to read state of the art on the block structure of A and how this helps you with the micro basis. So, can we use this somehow to like please help? I don't know. Okay. So, I don't know how to test whether the move I have in my hands is good or cheap or expensive. I want to keep the expensive ones. If I can do that, then wouldn't that be cool? It's a different way of building up a toric ideal from the line of spaces. I don't think we'll beat 42, except we will, once we figure out how this actually works mathematically. This actually works mathematically. The second question, this picture doesn't look good at all, is talking about the centroid point to which the algorithm converges. Not quite what you said. Okay. But every x0 at every iteration sample the neighborhood around it. And at the end of the iteration, I have converged to some average point. What is this point? What's the meaning of this point? A centroid. A centroid. Can I use that to jumpstart the new? Can I make anything out of this in statistics? Can I say, well, this is the middle of your fiber, or at least this component of the fiber. Here's something useful. You can say, leave that component alone, say something about stats. I have no clue because I don't know what it's actually doing. And we end up with some kind of a multimodal distribution of these lambdas in several different modes. And how can I use that to actually discover what the fiber looks like? Okay. And the third. And the third question is back to Besaga and Clifford. So, no, this is not Besaga, this is Bessag and Clifford, yeah. We ran a special session or something like this on algebraic statistics at the Joint Statistics Meeting in 2016. Don't ask me why I know the year in Chicago. And Stefan Laritzen was one of the discussants in the, or he was discussing in the session. And we titled the session, Caroline Muller and I, 20 years of algebraic statistics. He said, 20 years, it's been around longer. Years, it's been around longer. And of course, you know, gave us the history. And then he pointed out to something that I was embarrassed not to have known at that time, which is the idea of Julian Besag, which is stop running a long Markov chain to try to get an independent sample from your fiber. Just get, run your chain backwards in time and then run 100 short chains forwards, and that's an exchangeable distribution on the fiber, and you're done from the point of view of statistics. Not optimization, not fiber discovery, but statistics. Then, not cyber discovery, but statistics. I don't really quite have a Markov chain. I have an X0 and a neighborhood and an X1 and a neighborhood. How can I use this or can I use this to get output an exchangeable sample from the fiber? What's exchangeable? It's as close to IID as you can get, right? Given that everything is connected. And so, if anybody has any idea about how to talk about this, I will be like ecstatic, but I'll just stop now. But I'll just stop now instead of, yeah, I'll stop now. Thank you. Thank you very, very much. We have some questions already, but not the time for more. I had a question about you had this example m equals n equals eight. And can you say a bit more what's the application? You said that was the smallest. Application. You said that was the smallest example that made sense for the application. So the application for, oh yeah, I have to use a better. So the application for the M MN example, which was this large family. So it is a I'm recorded, so I better. So this, so there, there's, I don't, I am. This, so there's. I don't. I am. I actually took it for granted for what it was, and I don't quite yet know how it fits in well with the whole structure. So I cannot tell you mathematically, but I can tell you in a nutshell what it is, is a problem in which you're trying to solve an optimization problem that has a PD constraint. And then what they do, they being the collaborators at Argonne, they discretize a problem and turning into a very Problem and turning into a very nicely described discrete problem, but you have to find a solution over the set ax less than or equal to b, where x is a lattice point. And so what we do is we take ax equal b, we add the slack variables. And what this does is then gives you this banded matrix with plus and minus ones across, lots of identity blocks that give you stuff, and it just blows up in size. And these are all the possible feasible solutions to the optimization problem. And so. Problem. And so we're just, then there's a linear cost function, and you cannot do anything else. You cannot do the commercial solver, you cannot compute the paper bases, you cannot input the major matrix anywhere. And so these are supposed to solve a large-scale energy problems. But this was like the first toy example to start with. Yeah, I don't have the for certain M and N. So M8 and N8 is the smallest interesting example. Last interesting example. And think about like when you like pixelate an image, right? And then you keep dividing, there's only certain m's and n' that you would want in that division. So you don't do one, two, three, you do two, four, eight. So this is similar. You're subdividing a problem to find these regions and these trust regions. And I have no idea. Like it's like, it's a long setup that I did not put in here at all. Yeah. Can I add something? Yeah, these things are approached by people first. Yeah, thanks. Yeah, I'm very curious about the idea. So, is this something that you could, in principle, use to explore other things, like other spaces, like that are unknown? Explorate. There is a problem in reinforcement learning called option discovery, and where you have kind of, you know, a Have kind of a huge number of states that you don't know and that they may be loosely connected or disconnected. And an option is really a sequence of steps that you might take in your policy that will allow you to connect that graph of states. So this is the problem that people discuss as exploration versus exploitation. And yeah, it is so, you know, the conceptually it looks so similar. Yes. Yeah. I mean, Yeah, I mean, do you want to try it? What is your answer? I want to try this. Oh, you want to try it? Okay, I don't know. No, it's interesting because people think about some approaches to try to, what do you say? Like, how do you train your sequence, right? Like, you know, are you going to pick the weights that appear regularly? Are you going to try to maximize some entropy? Or are you going to try to define some other objective to plug in there? And it seems that a lot of these technologies. And it seems that a lot of this technology could be useful over there. Yeah, no, I think I want to definitely talk about this more. And so perhaps I should also tell you how what does not work. Okay. So what does not work is not doing any biasing. So if you forget this step, that's really bad. And if you try to tune the Lambda on your own, and we try this for that specific optimization matrix, da-da-da. And the only thing that I The only thing that I told Miles one day is, Can't you just buy us this algorithm? And out came this. And so, once you buy us towards the thing that you're trying to get to, I mean, isn't that what we're supposed to do? Don't we do stats? Like, yeah. And that's it. That's the only, that's the only ingredient which is new is biasing towards what you're trying to get anyway. So I think I should be able to borrow a lot more from the other side and perhaps bias in your scenario. I mean, it's here. I mean, it's yeah. This is not just the lattice basis and just the polytope, but I mean, I have this small basis and I just go. What do you think? You mean in this, like in this big one? It's the full rank. It's full rank. So that 100 and whatever. Oh, excuse me. The difference between the two. 200, okay? So it's a 200 by 400 matrix. So the last dimension is. 400 matrix, so the lattice dimension is 200, or 200 moves in the lattice basis, and I have no idea anything else about it. I don't know the size of the fiber, I don't know, it's at least this many. We did not run it for 30 minutes, only three, right? So, okay. Okay, uh, are you okay? Anybody else? If not, then thank you very much again. Thank you. So, uh So the schedule asks for a working period.