For bringing us here, and I suppose I should also thank you for having a 60th birthday to give us an excuse to be here. So, yeah, so I think in the program my talk is called Rooted Clusters for Graph LP algebras, but I probably should have called it Snake Graphs for Graph-LP algebras because that's more of the content of the talk. And this is joint work with Esther and then two other collaborators, Sunita and Sylvester, who are. Collaborators, Sunita and Sylvester, who aren't here. And so, I'm going to give you sort of the really brief two-minute motivation for why we're studying graph-delti algebras. So, there are a lot of generalizations that arose from the original definition of cluster algebras. One of those is LP algebras or Laurent phenomenon algebras due to Lamb and Plafsky, where you take the ordinary binomial exchange relations and you replace them with irreducible polynomials. With irreducible polynomials. And you could ask, you know, why are these interesting to study? And I've put up here sort of a list of things you might be interested in that are related to LP algebras. But really, I think what I'm going to say something about is this bottom one, which is that we see some of the structural features that we like about cluster algebras there. And they're known to have the Laurent phenomenon. So then the sort of natural next question to ask is: if these algebras have the Laurent phenomenon, do we have positivity there as well? Do we have positivity there as well? And this turns out to be sort of a difficult question to think about. And so, maybe more tractable is to think about a subclass of LP algebras. And so that's what I'm going to talk about today. I'm going to talk about graph LP algebras, which are the subclass that have a very nice, concrete, combinatorial definition in terms of graphs. So they're a lot easier to sort of get our hands on and work with. And so if the eventual goal may be. And so, if the eventual goal maybe is to work up to trying to say things about positivity for LP algebras, this seems like a more tractable place to start. So, that's the philosophy. And to define a graph LP algebra, what I'm going to give you are some nice concrete combinatorial descriptions of the cluster variables, the clusters, and the exchange relations. So, we're going to start with some simple graph with simple graph with whose vertices are labeled by the integers one through n. And then the cluster variables are going to be determined, are going to be defined in terms of nested collections of vertex subsets. And to just to give you a definition of what I mean when I say a nested collection of vertex subsets, I'm actually going to give you some non-examples and then some examples. So one thing that I'm not allowing is something like this where I have Is something like this where I have a maybe a pair of vertex subsets that contain adjacent vertices, but they're not, oops, sorry, but one is not a subset of the other. So I have this sort of kissing or neighboring of the vertex subsets. That's not allowed. Another thing that's not allowed is I can't have pairs of vertex subsets where they have maybe, I could say, a non-trivial symmetric difference or they have a non-trivial. Or they have a non-trivial intersection, but one is not a subset of the other. And then the third thing that I don't allow is I don't allow disconnected vertex subsets. And so if these are sort of the three things that I'm not allowing, then if I ask what is allowed, I get maybe collections that look like this. And you can sort of see where the name comes from, right? In order to satisfy those conditions, the subsets have to be nested inside of each other. Okay, so if we're happy with that definition of nested collections of vertex subsets. It's ah, so each individual subset is a connected subset. The thing that this would not be is this would not be a maximal nested collection. I would have to include, oh, sorry for the unintentional rotation. I would have to include the entire graph. The entire graph as another subset to give it maximally nested i'm allowed to have disjoint subsets in my collection. The connected condition is about a single subset. Do you have a question? We have a question by Jacob asking, does the empty set count? No, no, the empty set does not count. The last one is: I guess you could, I guess it doesn't look nested because it's not a maximal collection. So perhaps it was a bad example to draw. So I think that the way you would see it. So if you, what we're going to see eventually is that we're allowed to take out some vertices and then look at maximal nested collections on the remaining subgraph. So if you took out vertex two, then you would have three nested collections. Two, then you would have three nested collections that are sort of boring on the 3-1 vertex subgraphs. And so, I, yeah, I think at this stage, maybe it's not obvious why that's a nested collection, but that's why. Good questions? Are we good to proceed or are there more? Okay. Oh, sorry, I accidentally jumped far ahead in the slides. Okay. So then, given some graph whose vertices are labeled this way, each connected vertex subset is going to correspond to a cluster variable that we're going to label y sub i, where i is the set of vertices. And then for each vertex, we get an additional cluster variable, which we're going to call x sub little i, where i is the label of that particular vertex. Vertex. So, just to show you an example, if I have this toy example that we're going to use as our running example, this has the following cluster variables. So, there's one X cluster variable for each of the four vertices. I get one cluster variable for each connected subset of size one, right? So, here, here, here, or here. I get one y cluster variable for every connected subset of size two, and so on. And so on. And then we're going to want to gather these into clusters. But before, I want to make a note that here I said that we would require that these vertex subsets be connected. But there is a sort of sensible way to define y sub i if i is a disconnected vertex subset as a product of the y variables coming from the connected components. The connected components. And although I'm not going to talk about it, there's a determinantal formula for these y variables that agrees with that definition. So we can write that and have it be meaningful, but it's not an honest to God cluster variable. Okay. And so then we want to know how these gather into clusters. So a graph with n vertices is going to have clusters of size n of the following form. So I get to Of the following form. So I get to pick some subset of the vertices to take x variables for. And then I sort of think about throwing away those vertices from the graph and asking for a maximal nested collection of subsets on the remaining portion. So I'll show you some examples and non-examples. So this first one, this drawing would not correspond to a cluster. It doesn't have enough subsets. It doesn't have enough subsets in it, right? Because, so sure, I threw away vertex four, that's maybe x4. But if I look at the remaining part, this isn't a maximal nested collection. I could put in either y1 or I could put in y2, three. But then this middle one, this is maybe an example that is a good illustration of the fact that I'm just asking that the collection of subsets be maximally nested on maybe a subgraph. So there I Uh, maybe a subgraph. So, there I took x1 and then I looked for a maximal nested collection on the subgraph 2, 3, 4. And then this last one would be, ah, yeah. I'm sorry, I changed the numbering at one point and apparently didn't update it everywhere. Thank you. All right, and then this last one would be a cluster that has all the y-type variables. Okay, and then. Okay, and then there's a particular type of cluster that we defined that has some properties that make it a little nicer to work with, which we call the rooted cluster. And the idea is that if we have a tree graph, you could think about choosing a root for the tree, and then you could draw it as a poset with V as the maximal element and the cover relations in the poset given by adjacency in the tree. So, for the example that we've been drawing, I could draw it. Been drawing, I could draw it in these different ways depending on which vertex I choose to be the root. Okay, and then that gives us a way to define a cluster on it. So if we, for some notation, if we let i subscript less than or equal to x be the collection of elements that are less than or equal to x in the coset with root v. Then you can construct a cluster. Then you can construct a cluster by just taking i sub less than or equal to x for each vertex in the graph, and then get an all y cluster. And just because it's a little bit annoying as notation, we'll just abbreviate this and say ix. And so if I drew some in here, I would get clusters that look sort of like this. Okay, and then another thing that will be a useful definition for us to have later is a rooted. Definition for us to have later is a rooted set. And so this is a property of a set of vertices, not a property of a cluster, even though the names are very similar. So I say that a set is rooted with respect to some maximal nested collection of vertex subsets. If I can pick some vertex in that set to sort of act as a root, so that then if I look at any other Then, if I look at any other two vertices in the set, i sub little i is a subset of i sub little j, if and only if the path between them has to pass, or sorry, the path between i and the vertex acting as the root has to pass through j. So just to make that definition a little more parsable, we'll look at some examples. So, for example, in a rooted cluster, then every set that I take is going to be Every set that I take is going to be a rooted set because I can just take V to be the element that I had chosen to be the root. But if I look at maybe a different cluster, so I needed to make a slightly larger example here, then I might have some sets that are going to be rooted with respect to it and some that are not. So here's an example of a rooted set. So if I take one, two, three, then I could take V as my root and I can. Um, I can check that this condition is satisfied. Uh, so here I1 and I3 are not subsets of each other because I can go directly from one to two and directly from three to two without having to pass through each other. But both I1 and I3 are subsets of I2 because I have to go trivially sort of through two to reach two. sort of through 2 to reach 2. And then a set that would not be rooted with respect to this cluster is the set 245. And you could test different vertices to see if they work. So for example, if I tried to use, let's say, 5 as my root, then if I wanted to go from 2 to 5, sorry. Sorry. Yeah, so if I wanted to go from two to five, I will have to pass through four, but I2 is not a subset of I4. Okay, so we've done a lot with cluster variables and these various types of clusters and sets, and now we need some sort of exchange relation if we're going to have an algebra here. So I'm going to give you sort of a loose definition of the exchange relations because there's actually a bit of notation you need to write them down precisely. Down precisely. And it's just, we're not going to play enough with them for it to be worth the time. But so there are two different types of exchange relations. So the first thing you can do is you can exchange an X variable for a Y variable. And if we think about how the X and Y variables are defined, remember the X variable is, if I take an X variable, like here, if I take X four, that means that I was then only taking a collection of vertex subsets on the remaining subgraph, right? Subsets on the remaining subgraph, right? So there's sort of an intuitive, unique way to switch x4 for a y variable. The only other vertex subset I could add would be one, two, three, four, right, filling in the entire thing. Or on the other hand, if I take out a vertex subset, then there's one unique way to choose a vertex to get rid of so that I still have a maximal nested collection of subsets. Collection of subsets. So that's one thing we can do. And then the other type of exchange we can do is we can exchange a y variable for another y variable uniquely. So one way to say this without any notation is just if you thought about getting rid of one of these vertex subsets, let's say I wanted to get rid of one, three, and I asked myself, what's the only other vertex subset I can put in that will still form a maximal nested? Nested collection of vertex subsets. Well, the only other thing I can do is I can take the vertex subset two, right? And so that's the nice sort of concrete way to think about these exchange relations. Okay, and then if you want to see them written down, just to satisfy those that are interested, this is how you would write them. Here, the thing you would have to define. Here, the thing you would have to define is you would have to define what these p variables are, and they're defined in terms of certain paths on the graph. And then I haven't talked about it, but these a's, we're just working in a ground ring z adjoin a1 through an. So they're just some coefficients. Okay, so here's sort of the story so far: is that we have these two types of cluster variables, they come from either one from each. They come from either one from each vertex of the graph, and then the y sub s come from connected subsets on the graph. And we get clusters from these nested collections of vertex subsets, and then we get exchange relations from those two sort of unique ways to exchange variables. Okay, and in the paper where they defined linear LP algebras and graph LP algebras, Lemon Twelvey made this connection. Lamentlovsky made this conjecture, which was that positivity would hold for graph LP algebras. And so about, I think, two, two and a half years ago now, Pasha posed this question to us in a workshop and we started thinking about it. And then so the natural sort of first question to ask is, well, what tools do I have if I want to start thinking about how I could attack positivity here? And one sort of very immediate idea. Sort of very immediate idea is in that same paper, they observed that if you take the graph LP algebra defined by a path graph, that that is an ordinary cluster algebra of type an, an minus one, if you want to be precise about indices. Sorry, P n is just a path graph on n vertices. Yeah, yeah. Yeah, yeah. Yeah. Is the same true for other simulated state diagrams? No. Yeah. Cycle kind of gives BM. Kind of, yeah. Yeah, but I don't know anything interesting to say about like VN or CN or yeah. And so let me show you maybe how this corresponds. So, let me show you maybe how this correspondence goes. So, let's say that I start with some path graph and some nested collection of vertex subsets on it. What I do is the first thing I do is I extend it. So I add a primed vertex adjacent to each of the leaves that's only adjacent to that leaf, right? So, here I had leaves one and six. So, I add a one prime and six prime to make this a little bit of a longer path. And then And then, so two things I should say. One is I'm thinking that there's another vertex subset here that's capturing all the vertices. I'm just not drawing it because it's sort of annoying to draw. But so then I could think about each vertex subset and instead draw it as a line connecting the neighbors of that subset. So it's obvious how to do that for something like three, where its neighbors would be two and four. For a larger subset, For a larger subset, I'm going to think about its neighbors being. So, for example, here, 1, 2, 3, one of its neighbors is 4, and then I had to add a 1 prime to get a neighbor on the other side. So, if I do that, then I label each of those edges with the vertex subset they came from, right? So, this subset one becomes this edge labeled y1 between 1 prime and 2. This larger 1, 2. This larger 1, 2, 3 becomes an edge labeled Y123 between 1 prime and 4, and so on. And so once I do that, if you sort of squint at this, you can see that this is going to be a triangulated polygon, or you can redraw it a little bit more nicely. And so then you see why these are describing the same thing. An important observation to make is that we know that mutation on Mutation on a surface. So, like another cluster variable that's not in the cluster corresponding to that triangulation shows up as an arc that crosses arcs in the triangulation, right? And if you walk back through this correspondence, that will show up as an incompatible vertex subset. So, you really are capturing the same sort of exchanges. Okay. And so, if you have And so, if you have a cluster algebra of type AN, these are very well studied, right? And we have a lot of different combinatorial gadgets that we could use to talk about positivity for these algebras. And so I'm just going to mention two, which are, I think, the two of my favorites or ones that I've spent more time playing with. So, one thing we could do is we could think about T pads, which I think were defined first for Type A and by Ralph, and then there are some more. And then there are some more general definitions. And this is actually something that we did explore. And we have a paper up on the archive talking about hyper T-pads. And so I'm not really going to talk about that today. I'm just going to advertise that that exists. The other gadget that I'd really like to spend the rest of my time talking about are snake graphs. And so these showed up for the surface model in the work of Musicer. In the work of Musiker, Schiffler, and Williams. And so that's what we have been working on at a time since thinking about hyper-T-pads. And that's the content of what I'm going to talk about today. But just as an aside for those who like T-pads and know something about T-pads or are curious, I will say two things. So one is that we proved that if you define hyper TPADs in a certain way, then whenever you have a tree graph and a Whenever you have a tree graph and a rooted cluster, you can write down an expansion formula for all of the y variables in terms of that rooted cluster using hypert pads. And if you do so, then you get positivity as a consequence because now the coefficients are just counting the number of hyper T pads with the same weight. And if you would like to know more, you can ask Esther or I. Know more, you can ask Esther or I, or we have a paper where we say too many words about how you do this. Okay, but let's go back to snake graphs and spend some time playing with them. So I think I can go pretty quickly through this because Esther gave us a nice description of how snake graphs work this morning. But just to quickly remind you, in case you forgot over lunch, so the idea is that if I want to find an expansion. So, the idea is that if I want to find an expansion for this incompatible arc, gamma, in terms of the arcs of the triangulation, then I can encode each crossing in a square tile. And Esther already pointed this out for me. I was going to highlight that these tiles have some sort of orientation, right, that you could reverse. And if you do so, you can glue together alternating tiles and get a complete snake graph. And stop me if I'm going too quickly. And stop me if I'm going too quickly. I just figure that we've seen this very, very recently. And so, then in the work of Music, Schiffler, and Williams, they give an expansion formula in terms of perfect matchings of these state graphs. And so, for the one that I just drew, you would have three perfect matchings and you could write down an expansion. And so, what we'd like to do is we'd like to draw on this. And so, for the rest of the talk, I'm only going to talk about trees. I'm not going to think about any. About trees. I'm not going to think about any other type of graph. And so, the thing that changes when I move from a path graph to any tree graph is that now, if I think about the neighbors of vertex subsets, in the path graph, I could only have two neighbors. And now I can have multiple neighbors. So if I thought about drawing edges connecting the neighbors, now I might be drawing edges that are connecting more than two vertices. So I have some sort of hyper edge. And so if I So, if I maybe go back to this example we've been looking at, so I've drawn the extended graph here, right? So, we have the one, two, three, four sort of y graph, and then I have my primed vertices added, and I've just drawn the cluster onto the extended graph. So if I thought about representing this in a similar way to that construction for the path graph, I could think about, so here, maybe the vertex subset one, that's going to show up as an That's going to show up as an honest edge just connecting one prime and two. But if I look at maybe this vertex subset one, two, now in this direction, it only has the neighbor one prime, but the vertex two that's at its other end has neighbors four and three. So now I have to draw this sort of hyper edge that connects simultaneously one prime, three, and four. And so I end up with this sort of more complicated looking. End up with this sort of more complicated looking construction. Okay. And so at this point, you might be wondering, well, why trees? What's supposed to be tractable and better about these than other graphs, right? Because I could have drawn this sort of creature for another graph. And so maybe in some sense, I drew the wrong picture here. Another way that I could have drawn this is instead of drawing those edges as hyper edges, I could have drawn them as these color. As these collections of edges of the same color joining the vertices that are their neighbors, right? So, this maybe this hyper edge in orange now became this collection that I'm still thinking of as a single edge. I've just drawn it in a different way. And now maybe you look at it and you start to see where knowing something about the path graph could be useful. So, let's walk through constructing a state graph for this. Snake graph for this. And I'm going to think about constructing a snake graph for the vertex subset 4. So for that variable y sub 4. And so what I'm going to do is I'm going to choose some incompatible neighboring set. So here I decided to choose one, two, because I couldn't have. So I couldn't simultaneously have this. This and this vertex subset in my cluster, right? And so I just made some choice of incompatible neighbor, and then I chose a vertex in that subset that was adjacent to four. So here, two is my only choice. And that's going to allow me to define two sets of vertices. So one of them is going to be the set of leaves. So that if I go from the leaf. Go from the leaf to the vertex four. So to the vertex whose snake graph I'm trying to construct, I have to travel through two. So that's one prime. I have to go down through two and three prime. And then the other set are all the other leads where I can go directly to four without passing through that incompatible neighbor. Okay, and I'm going to use them to construct a To use them to construct a collection of triangulated polygons. So you'll see the connection with the story about the path graph in a second. So if I just maybe looked at part of this tree, so a subgraph that's a path, maybe I choose this one from 4 prime to 1 prime. Then I could draw a corresponding triangulated polygon. So that's this one over here. Or if I instead if I instead sorry I don't want to do that yet if I instead looked at this one from one prime to three prime or sorry three prime to four prime I could draw this one and so what I'm doing is I'm looking at all of the triangulated polygons who have one end in the set of vertices in B and the other end in the set of vertices in E. And then I could think about drawing edges in these polygons coming from just connecting Coming from just connecting neighbors of that vertex subset in the original graph. And so something sort of funny can happen here, though. So if I look at this one on the right, now I don't have an honest-to-god triangulation, right? I've got this problem where y12 and y2123 kind of look the same, right? And so the solution that we came up with for this is, well, maybe I'll just duplicate that vertex one prime. That vertex one prime. And I'll insert this sort of virtual extra edge between them. And we have a scheme for cooking up the labels on these edges that's just a condition based on the labels on the arcs that we pulled apart to separate. And I'm not going to state the exact condition, but you can sort of write down a rule for how you label these edges. And so once I've done that, now I really have two triangulated polygons. Have two triangulated polygons, which are things that I feel much more comfortable working with. And so the game now is: well, now that I have triangulated polygons, I know how to draw snake graphs. So maybe I'll just start by drawing a snake graph for both and see where that takes me. Okay. And so if I constructed a snake graph for both, I would draw, so for this one, I would get this snake graph. This snake graph, and for this one, I would get this. And we are calling these component snake graphs because each of them contains some of the information about the variable whose snake graph we're trying to construct, but not all of it, right? So we kind of need both to have all of the information. And something that you can notice is if I wanted to sort of combine these and glue them together somehow, a natural way to do it would be to say, well, I have these tiles that have the same diagonal. Have the same diagonal. And a lot of these vertices are really the same. So maybe I should identify them. The thing that's different are these two labels in the center, right? So one sort of natural guess for how you might do this is to draw something like this, where I've identified these vertices that are the same. And then here where I had two different vertices, I've drawn these parallel sort of edges. And now you really see the hyper edges showing up. And now you really see the hyper edges showing up, right? So these hyper edges like Y1234 that we sort of projected to ordinary edges, now we can draw as honest hyper edges connecting their neighbors. And so we have this sort of interesting snake graph that contains hyper edges. And I guess one thing I should call out is I decorated this too, I put a little plus on. This too, I put a little plus on it. And you might be wondering, you know, why is that there? And it's because sometimes when we identify vertices, we have to change the valency conditions. So now instead of looking for perfect matchings on these graphs, we have some more complicated valency conditions for the matchings that we're hunting for. So here's the rule for the pluses. So if I identify two vertices with the same label that have different edges in the same Different edges in the same direction, then that vertex is going to pick up a plus for every edge more than one that it has in that direction. And then a vertex with k pluses could have anywhere between one and k minus one incident things in the matching. And so It's allowed but not required. So, for here, if I looked at the matchings that I'm allowing, I get these two matchings where everything has valency one, and then I get this sort of funny matching. I think I maybe have written down the indices a little strangely here. So what I really mean is that for this two, I want to allow it to have an extra edge in the matching incident to it. Yeah, I think that I've written the indexing a little funny here. The indexing is a little funny here. But that's what I mean to say: that for every plus, it's optional to match it an extra time, but I don't have to. And one could check that if you have this set of rules in this graph, if you actually went through and did the exchange relations, that we produce an expansion that's actually the expansion for y4. And so then there's another sort of funny thing that can happen with the valencies, but I actually need to do a different example to Actually, need to do a different example to have that show up. So, we're going to think about the same graph but with a different cluster. So, I've just drawn the maybe extended graph with the edges and hyper edges. And so, here the cluster I'm thinking about instead is I take the single vertex subsets for 3, 4, and 1, and then the entire thing. And if I think about constructing the SNATE graph for Y2, Y2, I could go through the same sort of steps. I choose an incompatible neighbor. I get these two sets of vertices, and then I draw polygons for each of the paths between vertices in B and vertices in E. And so I get again two triangulated polygons. And then, if I draw the component snake graphs, the thing that's sort of different and interesting here is that before they had the same diagonal labels, right? So it was obvious. Diagonal labels, right? So it was obvious that we should just identify those tiles. Here we have the same diagonal label for the first tile and different ones in the second tile. So there's something interesting happening in the gluing here. So when I glue them, really I want to have now two diagonals incident to this upper vertex too, so that I'm not losing some of this incompatibility information. And I end up with, it's maybe a little hard to see in my drawing. It's maybe a little hard to see in my drawing since I'm not an amazing artist, but you have sort of these two parallel branching joined tiles on top. And then I want to bump up the requirement for how many edges are incident to this vertex too in a slightly different way. So when I identify these vertices that have the same label but are incident to different diagonals, now I want to require that they be matched to more things in my matchings. In my matchings. So here, this 2 is supposed to be requiring that I have two incident edges in the matching. And the number that you put there comes from looking at the number of neighbors in the underlying graph. Okay, and then if you have these two constructions, we have this lemma that if you have any. That if you have any maximal nested collection of vertex subsets, that if you construct the snake graph for a single vertex subset in this way, that you get a nice expansion formula in terms of these allowed matchings. And so the next natural question is, all right, well, you've done it for vertex subsets of size one, but that's pretty boring. What about larger vertex subsets? And so one strategy for constructing these snake graphs might be. For constructing these snake graphs, might be to construct the snake graphs for each vertex in that subset and then paste or glue them together in some way. So one sort of helpful fact in this is if you have two vertices that are neighbors in the graph, then when you build the snake graph for one of them, you'll have a unique ij edge in it, which suggests that if I want to glue together the snake graph for i and the snake graph for j, that there's sort of a natural place to That there's sort of a natural place to put them together. And so let's do an example. So we'll go back to our first example where we had already constructed G4. And I've helpfully constructed G2 for us. So maybe now we want to put these together to get G2, 4. And so the thing that we do is we look for this 2,4 edge and we put them together there. And we put them together there. And so here that happens sort of happily, there's no complications. If we wanted to maybe do something similar with our second example, let's say I wanted to construct G12. We already constructed G2. But now if I wanted to think about constructing a snake graph for Y1, that doesn't really make a lot of sense to say because 1 was already a vertex subset in our cluster. Vertex subset in our cluster. And so the question is: you know, what do I do now? And so instead, we're going to remove some things from this graph. So if we look at the diagonal for the vertex subset that we would like to add that's already in our cluster, we're going to think about removing that diagonal edge and everything. So you'll notice that there's another copy of Y1 here. Another copy of y1 here, which you'll always have. And depending on whether y1 is up here or down here, you'll remove everything on the other side of the diagonal. And then the other thing we'll do is this vertex 2 down here, we're going to reduce its valence by 1. So if I do that here, I get rid of everything down here. And now this 2 has this sort of funny valence where it's not required to be matched to anything, but it could be matched to something. But it could be matched to something if it wanted because it has one plus. And so you can get these sort of funny-looking matchings. And these turn out to be exactly the right set of matchings to give you the extension for G12. Okay, and so then in sort of a limited case, if you've got some maximal nested collection and a rooted set, then if you look at the expansion. Look at the expansion that you get from a snake graph constructed in this way, you'll actually get the right expansion for that cluster variable. And as a corollary, you get positivity for those cluster variables. And so then maybe I'll just summarize what we do know. So we know how to glue GI and GJ when J is the only vertex. J is the only vertex covering i in that poset, and that's why things work nicely in for like rooted sets or in rooted clusters. And we also know what to do if we want to glue on a snake graph that corresponds to a set that's already in our cluster. We know how to delete things. What's sort of still in progress is if you wanted to push this further and get a snake graph construction. Get a snake graph construction for more things and positivity for more things. You might think about wanting to be able to do gluing in sets that aren't rooted. So the next sort of best thing would be what we started calling weekly rooted, where you require that I and J either meet the condition for being in a rooted set together, or they're both in some vertex subset that's already in your nested collection of vertex subsets. Collection of vertex subsets. And then these seem like they would be the next most tractable sort of sets. And then the hope would be to push beyond that and be able to write this down for an arbitrary set. And then, although I didn't talk about it, we actually know have another method for constructing these stake graphs, which we sort of have been calling growing stakes, and which can construct some of the same things, some additional things. Some of the same things, some additional things, but has its own set of limitations. And so, another sort of avenue of future work is figuring out: can we use this to get some of the things that seem to be difficult via our piecing construction? Or maybe they'll end up giving us sort of the same collection of constructible snake grass. The difficulty a lot of the time is that when you do this gluing, you will end up with some additional matchings that you don't want, and then coming up with a consistent rule for getting rid of them. Rule for getting rid of them becomes difficult. So you'll come up with one rule and it will work. And then as soon as you try to do something a little bit more general, you need another rule. So that's why it seems to get a little bit messy. Okay. And then I guess I spoke a little bit more quickly than I planned. So that's what I plan to tell you today. So I'll just thank you again and maybe again wish you a happy belated 60th birthday. So, are there questions? Maybe I don't hear you during the just speak louder and other other questions from the online participants. I have questions. Yes, yes. How is it related with graphs? Because we can do this for more general, like building systems. And so what is essential in your approach? So you are just restricted yourself by specific building systems, which consist of connected sets of graphs. Yes, I'm sorry, I muted. Yes, I'm sorry, I'm muted. Yeah, and I'm sorry, I may not have heard your entire question. Could you so you can see the specific uh for then you can see that this is a connected set of graphs, so you can see the specific form of what you call building systems and you can see the nested collection in building systems, so you consider some specific case. And so, my question is: what is essential? So, why you not consider more general, but only Consider more general, but only there's a specific case which is called graphical building systems. Oh, I see. So, why do we have this requirement that we have these nested collections of vertex subsets and not just any collection of vertex subsets? So, you have buildings, so you know buildings, just this collection that just if intersection is non-empty, then the union belongs to the collection. And so, this is just And so, this is just more general construction for which you can decide maximal nested set, nested set. But you consider some specific keys. So, what is just features which you just have from this graphical, but not for general construction? Yeah, so I guess I don't have a good answer to this. I didn't think about whether we could say something about a more general definition. I just sort of took and ran with this definition that was already in the literature. Already in the literature. So, if you consider paradigmal cons, which are generated by vectors of a nested collection, so then you get a fun of, and so have we think of this generators like G-vectors, or what kind of, so you consider cluster variables which are associated just to generators. So, if you just have this is indeed. So, if you just have this indicator function of your collections of your sets, then you just consider just a vector. And then, if you have just for all element in the nested set, just the column, then for all nested set in building set, you get just a fan. And so, therefore, how we can think about this fan, so it is fan of G vectors or what C vectors are the Yeah, no, so I think it's a good question. It's not something that I've thought about, so I don't have an answer for you. Does the stock you talked about work for all LP graph algebras coming from trees? Ah, so the question was: does what I talked about work for all graph LP algebra coming from trees? Yes. Yeah, so we understand, I think, some things about how things work in trees, but once you get beyond trees, we understand much, much less. Are there other questions from online participants? So, if not, are there questions in the room? So that everybody can hear your question. Yes, thanks. So you have these graphs and you look at kind of perfect matchings of them or some variation of it. Is there an algorithm which constructs all the perfect matchings? Like for the snake graphs, you can twist the tiles. Is there something like that? Have to so I think sometimes it's it's clear how you might twist somewhere, and sometimes it's really not. Maybe Esther has her own answer for this, so I think it's not always clear to me how you would reach all of the matchings by twisting. I think it's all about single sand is very nice. All these things that I can make graphs colliding in one place. The structure is very nice there. Right. Yeah. It could also spear a drawing over. Right. So I think when you have like singletons and you have things that are well behaved, you can draw post sets that make sense. And then it's at least not clear to me in some of the messier examples how I would draw a post set with a. Examples, how I would draw a poset with a rank function that makes sense. So I hope that there's something there, and I just haven't figured it out yet. Thank you. So it's just a question about the LPA algebras. So am I correct that you are given, when you give the algebra, you know from the outset what is the complete list of cluster What is the complete list of cluster variables and clusters? Are there only this X and Y that you described, or are there more than that? So you're asking about graph L P algebras or about L P algebras in general? Yeah, so for a graph L P algebra, once I know the graph, I know what all of the cluster variables are. You don't create more by dating? No, I mean you could think of it by starting with a cluster. I mean, you could think of it by starting with a cluster and then creating all the rest according to the exchange relation rules, but you can also just look at the graph and know what all of the cluster variables are going to be. More generally in an LP algebra, you would have to start from a cluster and generate things. Yeah. Yeah. And it's also sort of deceptive because I guess you could think about a graph LP algebra if you had some sense of talking about like an infinite graph, then you might have infinite. Graph, then you might have infinitely many, right? Thank you. It's question inspired by Bernard's question. So you're saying that graph LP algebras are finite type LP algebras, but for usual finite type cluster algebras, there are all this various. Various geometric ways to represent, to present them, or to realize them. Is it other nice examples of geometric realizations? If you take some particular graph, which is not Dinking graph, and I guess I don't know of any others than what we saw with type AN and the path graph. And then, like Esther mentioned, with a cycle graph, you get. Like Esther mentioned, with a cycle graph, you get something sort of type D-ish. I think it's actually type D. Okay. But other than that, I don't know of examples. If you pick a type D digit diagram, that is actually really hard for us to change. Yes. So you could see the example that I was playing with was this small type D example. Small type D example, and that's where you start seeing some interesting things happen. Thank you very much.