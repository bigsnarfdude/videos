For the opportunity to be here. So, it's a fantastic workshop, and I feel honored that I can present as well. So, I'm working at Janssen. I'm heading their statistical methodology group, which is based in Europe, part of a global organization, and today I would like to walk you through some of the challenges that we face to identify surrogate markers in vaccine trials. Surrogate markers in vaccine trials from the industry perspective. So, there will be some focus also on how we use it in practice. And, of course, I'm an employee of Janssen, so I would like to make that clear. So, the background here is to set the scene is that we look to identify and utilize surrogate markers to infer vaccine efficacy. In the presentation earlier today by Peter Gilbert, he already explained that a little bit in the context. Explain that a little bit in the context of the COVID, the Moderna COVID vaccine phase three trial. And it could be to use or to ease future clinical development by bridging to other populations and different age groups, like pediatric or frail populations, which were not included in the phase three study, but also for manufacturing processes or upscaling or transferring to a new building or to develop new vaccines in situations where. Vaccines in situations where it's not feasible to assess or capture efficacy data anymore. So, I would like to use two case studies from recent pandemic outbreaks actually to illustrate to some of these points. So, we'll focus scope a little bit on prophylactic vaccine studies in participants who have not been previously exposed to the pathogen, because that implies that the biomarker is only measured in vaccinated individuals. So, in those So, in those two case studies, it will actually be the Ebola vaccine and the COVID-19 vaccine. In one example, we really use turrogate markers to based on that developed a strategy for regulatory approval. And so we'll illustrate how we tackled that, both the identification, but then also how to infer vaccine efficacy and what were the statistical or the challenges as a whole. And then on COVID-19, I would like to build. And then on COVID-19, I would like to build a bit further on what Peter presented this morning because it's a collaboration there, but illustrating the complexity that can be imposed on the evaluation of surrogate markers through the study design for the primary objective and the data characteristics of the real setting, actually. So, in vaccines and the surrogate market terminology, just for those who are not familiar with it, and I think through the presentation. It and I think through the presentations it has become clear, so maybe I should not spend too much time on that. But very briefly, we're looking for an immunological measurement, right, which is the biomarker, and that correlates with the clinical endpoint of interest that we use with vaccine to evaluate vaccine efficacy. And that can be a reduction in disease or a reduction in infection risk. So, in the correlative risk situation, it focuses just on one group, the surrogate marker. The surrogate marker equivalent, I would say, statistically speaking, then is usually referred to as a correlate of protection, where we look at whether that immunological measurement actually correlates with protection. So can it reliably predict the vaccine level of protective efficacy? And depending on the situation, there are sometimes only single trial data available, which limits the ability to predict, of course, to different settings. And therefore, you would need multiple units. You would need multiple units, and I'm using that terminology. I did not invent that myself, actually, it was written down in two very nice publications, and it's an associated variable, not necessarily a mechanistic. That's something to keep in mind when we look for that. So, when I look at the methodology, and it actually has been nicely presented here today and yesterday, actually, by Peter and then Yiki. By Peter, and then he smaller marriage yesterday, Marik Peris. I think many of the methods look for or can be divided into two categories. If I tend to, if I have to explain it to my biomarker colleagues, for example, on one hand, methods that will be focusing on modeling the relationship. So that will allow us to actually evaluate or infer potential efficacy evaluation from a biomarker and from a clinical perspective. And from a clinical perspective, they are ideally interested in identifying a threshold through that relationship. But on the other hand, it's important to find out how well is a biomarker or a surrogate marker able to predict a vaccine efficacy in this case. And so how valid is it to actually use that to potentially replace as an endpoint in the trials? So what is the strength of the association to look at methods like that? At methods like that. Now, in the case studies, you'll see that we have looked at several of these. So, maybe going to the first case study, the Janssen Ebola vaccine, and that was from an outbreak in 2014-15. Many companies accelerated the development, including the Jansen vaccine, but the Janssen vaccine was not able to infer or evaluate or gather efficacy endpoints only in the human setting at least. Only in the human setting, at least, safety and immunogenicity data was collected. So that reflected in the first row of the data in the table, where we have that immunological data available through the phase one and two studies, and also the first stages of phase three studies. However, no clinical endpoint data was gathered, but in animal experiments in non-human primates, actually, immunological data was captured as well as endpoint data. As endpoints data, the animals were challenged after vaccination with a stringent animal model, meaning that in the absence of vaccination, every animal is 100% lethal. So all animals would die from the challenge. But in that setting, an endpoint could be measured. So that would allow at least to make an association between the immunological data and the clinical endpoint data. And so the question was raised now that we have a lot of immunological. Now that we have a lot of immunological data in the humans, can we actually learn to identify which is the relevant market and then infer or assess the potential for clinical benefit in the humans and takes uncertainty into account, both from a biological point of view, as well as from a statistical point of view, because the endpoint in this case is not the same. I mean, it's the same virus, but the challenge model is stringent and is 100% lethal. Then it's 100% lethal, but in humans, the endpoint is not 100% lethal. So the steps to take in this strategy that we came up with at that time is first identify the surrogate marker, right? Can we establish that immunological marker that is associated with protection in that animal model? And assuming that levels can be compared between the two species, and that's an assumption which is not all. And that's an assumption which is not always possible to make. And here, the stringency plays a role in a conservative manner to mitigate for those assumptions to be made. Then once the relevant marker is identified, the question is: can we infer potential for efficacy? So a model needs to be built to build a relationship and have that model with sufficient. And have that model with sufficient precision, and then based on that, it would allow us to infer the potential for clinical benefit. But here, too, we need to incorporate statistical uncertainty when comparing that with protective immune responses in the animals. So, that's high-level step-wise strategy. So, how did we do that in practice? What you see here on the slide is actually the outcome of five. Is actually the outcome of five non-human primate challenge studies in which 100% protection was seen at the selected dose in the clinic. However, the studies incorporated lower dose levels as well, because that would allow to see where at what level of immunogenicity response or what level of that biomarker do we start to lose the protection. And that is what you see reflected also on the y-axis. The y-axis, and these were identical protocols. The sample size is small per arm here. We have two to six monkeys per arm, and actually, the protocols were reasonably identical, so all data were pulled. But you see three similar plots, which look like an S shape, which have on the y-axis the survival probability reflected by the curve. And I'll explain in a minute what that is, but on the dots reflect the animals that did not survive the challenge. survive the challenge and on the top you see the dots with the animals that did survive the challenge so that were protected and the curve is actually a logistic regression curve and these were all vaccinated individuals because in the control group actually there was all animals died it was 100 lethal so if you think about the methods to evaluate this setting actually simplifies because of that Simplifies because of that. If you think about the methods that Peter presented earlier today, it actually simplifies a lot because in the control group, the probability of infection or in that case death is one in fact. And also every monkey here is exposed because every monkey was challenged, right? So from that angle, there is also no distinction between those who have not been exposed and not infected. Which you have in the real setting. So every monkey has been exposed to the challenge, and it's 100% lethal on control. So the methodology to derive that curve was actually relatively simple through logistic regression. Now, the challenge here or the choice to make is which is the relevant marker. And there were three immunological parameters considered here. ELISA, neutralizing antibodies, which you see on the top, left and right, and then ELISA. Left and right, and then LISPOT, which is a cellular measurement on the bottom left. Now, there is a whole variety of methods that we could use here, and I think this was very nicely presented and illustrated in the presentation of Girt Mollenberg yesterday. We did not use all the layers of the apartment that he explained. We used some which were maybe at the bottom yet, so we could have used more recent ones. But we looked at the bottom right at one. Right, at one of the plots that we looked to differentiate is how well it predicts mortality based on the model. And then we looked at sensitivity and specificity, plotted that against each other. So you have an ROC curve and evaluated the area under the curve for that. And then you see that the up top two curves are actually the ELISA and the neutralizing antibodies, have the better discriminatory. Have the better discriminatory capacity. Now, this was done based on pooling of the data, and we wanted to use this into a decision-making process that could help to infer for efficacy. So, it's important to validate and confirm the relationship that we see here. So, two new studies were set up in the animal experiment to confirm that relationship. And you see that visualized here on this slide, and all of that is actually. This slide, and all of that is actually published if you want to read it in more detail. But you see on this slide here in green, in red, the curve that was presented on the previous slide. Then in blue, it's the same curve, same five studies, plus the two new studies to confirm the relationship, which was the case here, and actually improved the discriminatory capacity. And as mentioned, the studies have different dose levels to also see the Those levels to also see the breakdown point, but if you restrict it to the human level, the ROC curve is actually more towards the top left, even further distinguishing between that. Here it's ELISA that has been shown and for a variety of reasons. ELISA and VNA were similar, but for a variety of reasons, that essay was chosen and used to measure and compare concentrations between the species through the bridging. Through the bridging, and the way that that was then done is using that green curve that you saw on the left, we have to think about how to identify a potential significant threshold. And as the endpoint is different between the species, right, in the sense that there is 100% lethality in the animal model and not necessarily 100% case fatality rates in the humans. So, the way that this was done was using a similar approach as was published for NTACS, actually. Actually, taking the regression curve from the animal model, then performing the assay for each participant in the human, using that level and the curve to then estimate what is the predicted or the estimated survival probability for each of the subjects and average this out over all participants. That gives an estimated mean, but you still need to take into account uncertainty, and that was done through double bootstrap meaning. Done through double bootstrap, meaning bootstrapping both the NHP data as well as the clinical data, and then doing the same procedure over and over again to ultimately derive a confidence interval. And the Brootstep procedure is visualized on the right with the gray band, right? And that's where the two additional studies also contribute to increase the precision on that curve, in fact, which is important for the last step in the process because it's a regulatory. Process because it's a regulatory pathway that we would like to pursue, right? So it's not just identifying the surrogate, but also inferring whether there is potential for protection and humans to be able to submit it to authorities for that potential use. And their threshold was set that in doing the above procedure, deriving the confidence interval, it had to exceed a pre-specified success criterion in line with what is typically done in a pivotal phase three. Done in pivotal phase three trials in humans. So exceeding that 20% and applying that actually on the phase two three data generated the results as specified here, which are also publicly available and it formed the basis for approval of the regimen in Europe. So this illustrates the setting how identifying a surrogate marker was relevant. A surrogate marker was relatively simple in the sense that there were limited markers available, which correlated well with the outcome of interest. And that part was simplified because of the more stringent animal model. The challenge here is how to infer it to humans. And that took several steps in the discussion because of the statistical challenges to do so, but also the biological assumptions that need to be. The biological assumptions that need to be made and need to be discussed within the team, and which are also key here. Now, moving to a different setting, I want to briefly touch a little bit on the complexity on the identification here of the data. So, in this setting, there is a lot of efficacy data available, in fact, and maybe one of well, the COVID vaccine trials are data. The COVID vaccine trials are trials which have more data, one of the richer data sets that there will ever be, maybe in the context of vaccines. However, the complexity in the data that was generated actually complicates also the evaluation of correlates here. And so, speaking to the ensemble study, which was a study that evaluated the Austin COVID-19 vaccine, I would like to acknowledge that there was I'd like to acknowledge that there was a sub the primary objective of the trial was actually to evaluate the efficacy of the single-dose Yanten vaccine. So, maybe first going through the design of the trial here to already lay out some of these additional complexities. Subjects were randomized initially one on one about two years ago, that's when it started, between the Janssen vaccine as well as ora placebo injection. The placebo injection at which they were followed in double-blind fashion until the time point for the primary analysis was reached. For a variety of reasons, including ethical reasons, at that time, once that was established, the vaccine was offered to those subjects who were randomized to placebo, and everybody was unblinded. Some subjects took the vaccine, those on placebo, I mean, but some of the placebo subjects also went for an Also, went for another vaccine that was available at the time because they had access to it after unblinding. But the short, the key to keep in mind in that evaluation is that follow-up ended and that implementation of that crossover actually varies over different countries and sites in the trial. So the timing of the crossover is also dependent on the implementation of the amendments. The amendments. And then, as you all know, a booster has been administered in practice, and so, of course, also in the different protocols. So, the actual regimen and the evaluation changes over time for the different participants in the different study. Now, this study is a collaboration between several parties, including the US government partners, and actually they are leading a sub-study in that trial to evaluate or identify and evaluate. Or identify and evaluate the possible correlative protection. So, several blood draws have been taken to evaluate and use that data for that assessment. And I have to acknowledge there that from the that that is the work being done, or at least the biostatistics team lead by Peter Gilbert, UI Fong, are heavily involved there. And it builds further on what Peter has presented earlier today. What I would like to speak to is not the methods, because that's what he did. Is not the methods because that's what he did, but more the complexity that have to be fed into that method and that we revealed from a company point of view when analyzing the data, but also how what we then need in order to be able to use that in practice, because I think the questions have been framed there already. So maybe looking at the trial data here, at the focusing on the placebo-controlled document. Focusing on the placebo-controlled double-blind period first, when it comes to garlic of protection, that's what will help to define vaccine efficacy versus placebo. What you see here is the graph visualizing all SARS-CoV-2 infections that were observed through PCR over Kalender time in the trial. And there are several things to notice here. If on the y-axis, you see the different countries, as soon. See the different countries. So, first of all, and the dots represented different cases, and we did sequencing to identify what is the underlying variant in each of these cases that caused the infection from occurring. So, first of all, you see a lot of colors and not necessarily the same colour in the same country at the same moment in time. So, there is a large number of cases in every region available. Every region available, but the incidence rates or when the infections came vary by country and time. Recruitment was in a similar period, more or less, of four weeks, so a little bit longer, but there was a lot of overlap in recruitment. So calendar time is not exactly identical to study time, but it's closely related, of course. But you see, incidence rates vary by country and time. And time. And there is a lot of variance with limited overlap if you look at the larger regions: North America, South Africa, and then Latin America. And the placebo control data for recent variants was limited for Delta, only the yellow dots towards the end in South Africa. And absent, there was no placebo control data for the on-ground period. And that was due to reasons that were explained previously. That were explained previously due to the crossover and the booster implementation that happened. And the cases are decreasing because also follow-up ended. It did not necessarily mean that the pandemic ended at that moment in time. But the question is, what can we infer or even identify an immunological measurement that's associated with protection so that we can actually. Protection so that we can actually use it in further practice. But ideally, if we want to be able to use it, it needs to be universal for all of these variants. And that's where the complexity comes in. So there is a large number of cases. And if we look at exploring it by study region or variant, it's also important to take a look at what was the vaccine efficacy for different regions and different variants. And what you see here is the vaccine efficacy by The vaccine efficacy by the variant. So remembering again from the previous graph, the reference strain was actually the one that predominated in the US, so the original Wuhan strain, while other variants were more frequently found in Latin America or South Africa than the reference strain. And if you look at the three lines, it's quite small, but NISARS-COVID means that all infections for the primary end. Infections for the primary endpoint, counting all lineages and also those that did not have a strain identified, resulted in a 53% vaccine efficacy. But the one for the two strains actually were, although with overlap of the confidence intervals, but very precise for the other lineages, was different for the two. The reference train had a higher vaccine efficacy compared to the other lineages. So a differential So, a differential based on a complete set of analyses, actually, and more exploration cells happened, you could think this is something to be taking into account. And then the other aspect is that there is potential confounding due to the fact that what was already illustrated, different risk of acquisition of infection over time by country, but also for different risk factors, right, and also for acquisition of disease. So, I do not want to go. Disease. So, I do not want to go into the methods. I think Peter nicely presented that earlier today. But the point to make is that the additional complexity of variance actually complicates the evaluation of correlates. And that you see also illustrated here in the analysis, which was done by Yu Yi Feng and the team from Peter Gilbert and is published here. But when they came up with results, so what you see here is application of that methodology that was presented of the Methodology that was presented of the controlled vaccine efficacy curve against neutralizing antibody dietics. And the possible explanations that we then had to think through from the efficacy point of view, with the most likely factors that we think is that differential BE by variant. So more work is needed, of course, to deal with that complexity and in the search of correlates and for us as a company to be able to use that immunological measurement for future development. Measurement for future development steps. And maybe, and there are several initiatives that are ongoing. One will be that analyzing it with more data, more variant data. But the US government is also leading analysis to look at multiple trials because, of course, this is a single trial, but there are also other trials that are being done. And ultimately, more thought needs to be given and discussions need to be taken. And discussions need to be taken to think further on what immunological measurement is a universal predictor of vaccine efficacy in the context of these viral variants in order to be able to use that. So closing this presentation, what I wanted to show you today, and I hope I was successful at that, is two case studies were illustrating the complexity that can arise in a different setting. That can arise in a different setting, but how we can use surrogate markers in vaccine development and vaccine decision making. In the Ebola vaccine, that helped actually to form the basis for approval. And that we have to look at both how well can we predict vaccine efficacy in this case, and at the strength of the association, how valid is it actually to use it. Is it actually to use it? But also, can we characterize the relationship sufficiently precise so that it allows us to infer vaccine efficacy in other situations with all the assumptions that we possibly have to make? And also there, methodologically, there have been very nice presentations speaking to that to actually do that, how we can consider that in future projects and the feasibility of the And the feasibility of the evaluation and the simplicity of or the complexity of analysis really may depend also in like in COVID situations, really on the design and the outcome of the primary objective in the trial, because often the evaluation of surrogate is conditional on what is the outcome of the efficacy evaluation. So with that, I would like to acknowledge all the partners in the different Partners in the different projects, of course, which was a large group for the Ebola vaccine and also for the Janssen COVID vaccine, which has been a very nice collaboration. And where I would like to emphasize that the methodological work and the whole Correlate Initiative is really led by the US Government Institute with a big thank you to the COVID and biostatistics team, of which some are also present here online. Present here online. So, with that, thank you all for your attention and open to any questions. Thanks, An. Yes, so we have 30 minutes for questions for either of the speakers. Does anybody here in the room have any questions? Thought you might. Yeah, thanks, Anne, for a really interesting talk. I learned a lot. And I just had, like, I guess, two comments about the Ebola vaccine development. One was that, as you well know, there's a RBSV vaccine, which is highly protective. And as part of your submission package, have you formally, have you thought about looking at the titers from the RBS-V vaccine, the antibody level, and showing that you have? Antibody level and showing that you have similar kinds of levels to sort of support the main argument that you're making in the non-human primates. Yes, that has been discussed as well, but there are several arguments why that was not done or not pursued. One of them was that it's a different vaccine, it may have a different mechanism, and the analyses are looking for associations, not necessarily mechanistic explanations. And also, And also, from an assay point of view, the assays were not necessarily bridgeable between each other. And that's another reason for not necessarily considering or not pursuing on that comparison. I mean, you could use the same assays, obviously, if you wanted to pursue that. But oh, and the other point was that there was a similar kind of argument made for an anthrax vaccine, I think, in terms of like your non-human primate kind of thing. Like your non-human primate, kind of thing, and I think that was successful. So that might be augur well for your submission. Yeah, indeed. And actually, yeah, that's it. Well, I think I put it on the slide and it's certainly also in the publication. I hope I acknowledged it. But yes, the Andrex approach was actually the basis to, I think it was used in their submission strategy, and there are also publications on that as well. And that actually helped the thought process. And that actually helped the thought process in this discussion because I think it came available slightly earlier, and that actually helped a lot in the discussion.