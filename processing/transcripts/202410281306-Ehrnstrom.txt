And he'll give a masterclass in on a functional order equations in moderate. And we'll find out what the master class is as well. Thanks for the nice invitation to come here to Ban, to also give this masterclass. DeMark asked me if I could give a masterclass on non-local and fractional order equations related to mod water waves. I was happy to do I am happy to do that. It's still not clear to me what a master class is. Clear to me what a master class is. I wrote down an abstract which I will more or less follow. So, whenever I get asked, it doesn't happen so often, but when it happens, when I get asked like a colloquium or overview talk or something like introductory talk, I always have a lot of ideas initially. I think, I want to talk about this and this and this and that, but in the end, you don't have the time to prepare and you don't have the time to present this stuff. So, what I will do is I will give some. So, what I will do is, I will give some background, like not only five years ago, but really, where do these operators come from? It's non-local operators. So, I go way back in time and do that soft hopefully. And then I come to some instances of non-local equations. I will definitely not cover all non-local or full dispersion models in waterways, right? So, this is one thing I will definitely not cover for the results. I will mostly focus on. I would mostly focus on the stuff I know, and I will also try to present some of the techniques, some of the proofs, and to show there how the fractional order and how other aspects of the full dispersion operates, how they enter. And in the end, I will try to give a take away. Some of you have seen parts of this talk before, not everything, but some parts, but there will be something new first. Okay, the history of fractional order operators actually go back already to Leibniz, so when they introduced differential calculus. At the same time, they started to think about fractional order differential calculus. The first record of this is Mopital, who at the time spelled his name in a different way, but this is the way it's spelled today. He asked Leibniz in a letter, okay, but what is n in your d dx to the power? In your d dx to the power n, not is an integer, that's one half. So if you, if you draw, for instance, and Biden is actually replied without any proof, but he replied what it is. So he said, okay, so this is his notation. It's a bit unusual to ask, but essentially he said one half derivative of x is the square root of x. So like x divided by the square root of x. And he said that we cannot handle yet We cannot handle yet infinite series with fractional orders, but we will be able to do this, and I will show this. And this is an apparent paradox from which one day useful consequences will be drawn. Now, Euler discussed the subject, as did Lagrange and many others, all the major ones essentially, but it took quite a time until the beginning of the eighteen hundreds, actually, until you had different definitions. Because this was noted that this was just like Because this was just Leibniz, Leibniz sort of guess. And Lacroix, he looked at, okay, what if you have a monomial and you take just the standard derivative of that one, then you can use the factorials to express a formula. Now, Euler had deduced the generalized factorial with the Riemann zeta, which what is now called the zeta function and so forth, and the left left founder symbol. LaFrander's symbol. So then Lacroix's idea was: okay, just replace here in this general expression the integer value of n with a fractional power. And then he could calculate one half, for example, derivative of x. And it was almost the same as what Leibniz said up to some costumes. Okay, then Laplace discussed this Fourier, but the Discussed this four-year, but the real change actually came with Arto. And I'm very happy because I work in Norway, right? So he's our main hero. I mean, actually, every Norwegian mathematician thinks about Arbor almost everything. So they are really happy about it. Only the Scandinavians can read this, but this is something Arbor wrote when he was around 20. It's not in his first collection of works, which is more complete later. And he says that this is. And it says that this is the solution of a couple of problems with the help of finite integrals, ethanol integrals. Okay, so he has a problem in mechanics, and essentially it is, okay, he has an equation t is equal to the integral of ds over square root of a minus x, where s depends on x. Now, Now, as a mathematician, he says, okay, I don't want to solve this one. Okay, I want to solve that as well, but let's make it more general. So let's make the left-hand side a general function of a. A is the end of the interval where you're integrating integrated from 0 to a. Subsize function of a, and then instead of square root, let's take this to be a general fraction. And now overrise a fraction with n, which is the fifth ambition. So n is between 0 and 1. So n is between 0 and 1. And he is able to solve this. His conclusion comes here. If you have the first relation, sub psi of A, is this TS over A minus X to the power n, where n is between 0 and 1, then you can solve for S in terms of psi. And then he just writes the consequence. He just writes the consequence of this in the case where the n is one-half. So, what did he do? He has invented fractional order differentiation for general functions and their inverse. So, what happens if you integrate like a constant or general function? You're gaining one order derivative, essentially. If you integrate If you integrate anything, but then divide with square root of x, so you think you integrate x, but you divide with square root of x, it's actually a convolution, right? But then essentially, you're gaining one order and losing one half. Now he has an extra derivative on s. This is ds, so ds, dx, dx. So he's taking one derivative, integrating, getting one. One and then also gaining yet another one from this, gaining one half from the one over square root. So he expressed this, and this is the inverse of, and he expressed this himself, that psi of x, and this is his notation, so he doesn't use the parentheses in the a, he uses x here. Psi of x is the right-hand side here, which is 1. The right-hand side here, which is one-half the root of s. And this is, so you essentially put everything on foot, both the differentials, fractional, and their inverses. But note that, of course, when you integrate, there is something that he has made a choice, because there is a constant of integration, right? And this was a debate for like 100 years. So, Leoville, Kellan, Riemann, they all came up with. Riemann, they all came up with different, more or less different definitions of fractional cattle. And the problem, a major problem for them, the one that they discussed, was that if you take half a derivative or any derivative of one, then most people think it should be zero, but in these theories, many of them, it would be one over square root of x. This was solved later. This was solved later. I mean the you come to some essentially using complex the complex plane. They could much, much later come to a definition. But I would like to note that this controversy of freedom in definitions of non-local operators still exists. So there are two cases I would like to mention. So one is when you have homogeneous operators. So sometimes we see in talks, okay, we have zero mean, for example, but if you take the For example, but if you take the homogeneous non-local operators where the order is really low, then they are not uniquely defined, so you need to make different choices. Another example of this is when you do elliptic problems, non-local, on a boundary domain in RM, so typically not waterways. There they cannot use directly the Fourier representation, so they need to decide what happens outside of this domain. What happens outside of this domain? And there are spectral definitions of the fraction of La Pasha, and there are definitions that are based on extending the domain and so forth. So this is just to say that somehow it lives up. Now, the first one who actually used fractional order operators, I think, in real problems was Heaviside. This was in the 1890s, working on a Working on electrical circuits, and he was differentiating and integrating with one-half order a lot to make his calculations. I don't know if you all know this, but Hebeside was a very sort of controversial man in math. He was autodidact, did not have a position in math, and his opinion was that math is an experimental science. He essentially tried things first, and then later he said that. And then later he said that correct definitions would come. But he was the first to use it. But then it took actually until the 1970s and 80s until the topic was fully brought into the attention of the PDE community. So the first conference and the first paper entirely devoted to fractional order operators was in 1974. The Calder√≥n problem is famous. It involves something that we'll come back to soon, and that was. Soon, and that was published in 1980 exactly. But in between, so the 1980s and earlier, there have been many things developing in math that would combine these fractional order operators with things that we are interested in as respects. And one such thing, maybe a D such thing, is the linear dispersion relation for Dispersion relation for water waves. And in particular, I will take the gravity case first. That was first deduced by Laplace in 1776. Now, there was a mistake in Laplace's deduction. Airy corrected this around 70 years ago, 70 years later. Kelland made a different mistake, though. But anyhow, so this concerns nice, very smooth waves, weight packages. Wave packages, wave trains of this form. So if you take your, most of you, maybe 95, maybe 100% of you know this. So if you take this unsatz cosine kx minus omega t in the linearized Euler equation, you get out omega squared is a function of k through j k times kh, where h is the depth. With a phase velocity with just this symbol which will appear at the velocity. So, this means, if you think about it now in terms of operators instead, this means that if you think for small sinusoidal water waves, the speed in the transport equation, where L is an operator, is governed by a linear operator depending on the wave number through CK. We would think today of that as a non-local operator, but it seems that they did not do that at the time at all. At all. In between 1905, Hilbert introduces the Hilbert transform. And he does this through this on the line, through this principal value integral. And note that this is Abo's definition if you let the n that he had here, which was between 0 and 1, 10 to 1. Now, Abo said you cannot do this. Here it's done. You cannot do this, here it's done through principle. So essentially, it's letting the order of this, this is like no derivative, right? You integrate in once, but you're dividing with, well, you're convolving with one of it, or one of the time. And just as all those fractional derivative, today it can be expressed conveniently with k to the power s modulus when s is not too big, negative. Too big negative, then we need some discussion about what this means. Well, the Hilbert transform is just i psi k, so that d modulus is h dx. At the time when Hilbert introduced this, it was not known that this was a zeroth order operator. I mean, of course, they had some intuition. I mean, this was Hilbert. But the proof of this is 1928 by Marcel Ries. So it proves that the Hilbert transform is a bounded operator from L P to L P. From LP to LP. This brings us soon to connect back to the Hilbert transform to what was mentioned earlier today, Poincar√© and State Plot. This is also around the early 1900s. It was mentioned in Texas, I believe. And this is more general than the Dirspin Orman map. So Frank Reynolds Nickel considered general operators that map one type of boundary. Boundary data to another type of boundary data in elliptic toggles. And one such is the Dirichet to Norland map. And now, since you have seen this like three times today, I will not say too much. So think about them in a strip or a square, periodic boundary data, for example, in the x-direction. You know something, you know, capital, you know, little f on the upper boundary, and you map this data. And you map this data on the upper boundary, here's the data to its normal data. Okay, and this appears naturally in the Euler equations, as you know, in the right coordinates. Usually, this is actually not achieved through the exact Dirsky-Neumann operator that I have there, but you introduce this square root of one plus eta prime square root. Then you get back what Laplace deduced. Deduced long time before. Now, one of the first to use this, I'm sorry I ended up after the talks this morning, but one of the first to use this was Sakharov in his 68 paper on stability. And this was more rigorously developed by Craig and Suleim and Suleim, actually, in one of the papers. There are two Suleims. And I never recall whether this is the brother. Recall whether this is the brother known as the Sakara-Craig-Sulan formulation. And here you have the Dirichlet-Norman operator. Note that in the first paper, they don't call this the Dirichlet-Norman operator. They call this the Hilbert transform associated to the Flour domain. And the reason for that is that the Hilbert transform can also be expressed as you have an analytic function in the upper half-plane and is mapped. Off-plane, and this maps the real values to the imaginary values at the boundary. And this is essentially the Jirskin Numan. So they called it the Hilbert transform. So this is the first time, I mean, 68 and then 92, almost the first time that this enters into that you combine the dispersion relation actually with on local On local operators and the Hilbert transform. But Nalimov had been thinking about similar things before. So in his 72 paper, he has a Hilbert-type transform to express what we are calling. Also before 92, Bavenko, I think 87, introduced the Bavenko equation. So there uses the classical Hilbert transform, so not exactly the Yeah, it depends on which. Okay, so it depends on which case. So there are used the classical Hilbert transform to express the steady waterway problem through this scalar equation involving quadratic one involving this operator script C, which is just D, so using of course via the Hilbert transport on Infinite, or the same first order Diersley-Neumann expansion that we have seen on finding. And expansion that we have seen on finite data. Now, what's the difference between this and what Laplace did in 76? Okay, note by the way, of course, that one of the symbols terms formal state and the other as age state statement. Now, the lines converge, so now we have everything appearing in the same time. So, we have the fractional derivatives, Laplace linear dispersion relation, this Hilbert transform. Relation, this Hilbert transform, the Poincar√©-Teklov operators, all coming together in this symbol. The difference is that now we're expressing the full nonlinear problem with a linearized dispersion equation. So, this is really what has happened. Now, after this, during the 20 last years, there's been a lot of interest, maybe 30 years, it's been a lot of interest in full dispersion and fractional order. Full dispersion and fractional order equations. So the symbol and its different variance has been used to improve the dispersion relation in model equations, analyze the oil equations in scalar formulations, and investigate the transition between different dispersive or sheep. So what happens if you don't, like in the generalized KDV, you don't change the nonlinearity, but you change the dispersion. So I'll start with an example, which many of you have seen. An example which many of you have seen, and then go on to some more examples from that one. Okay, so one such example is the Wittam equation, which is a unidirectional scalar shallow water gravity equation. That was deduced by Wittam in 67. It has the the Berber's term, the break the quadratic breaking term, it has the Aries kind of dispersion, which is the Kind of dispersion, which is, I mean, airy kind of term. This is Wittam, by the way. I don't know if this is 67 or later. This is inherently non-local. There are no explicit solutions known. It's not integrable. It has the full dispersion symbol, so it's extremely simple. It's like KDB, but you replace the KDB with this half of the Euler linear dispersion. I will not dwell too much on this. I will not dwell too much on this half, but you can ask Bernard if he's here about this half, because it has implications, for example, for stability and instability. Now, this symbol is for large psi, so as an operator, it's like one of Arbo's fractional derivatives. It's minus one-half order derivative, but locally for small frequencies, it's like kd. Sequences, it's like Kdv. So this is the Kdv1 plus Dx. Now, in general, full dispersion equations retain some or all of the non-local properties of Euler dispersion. So we'll see which parts of these symbols are important for different kinds of properties if we want to prove things. For steady waves, there is almost a one-to-one correspondence between the result for full Euler and this simple model collection. So, in particular, if you do bifurcation, this is the critical weight speed one less to one. Okay, so first of all, you have, as always, in all these equations, you have small periodic solutions. Periodic solutions bifurcating, you have small solitary solutions bifurcating, they're all symmetric and exponentially decaying, the solitary ones. You can continue the periodic ones to larger ones and they end with the highest weight. This highest weight is because of this square root, not Lipschitz, but C1. You can also take the period to infinity. Take the period to infinity, and then you need to make some spot transformation here, actually, to get solitary waves of all heights. But in addition to that, you can construct large solitary waves by continuation. There will be some references later for some of these ones. There are many other results for the steady ones. There are turning points near the highest waves, just as for the Full Euler. There are rigorous numeric proofs. There are stability results. Proofs, there are stability results, there are much more that I will not touch upon. But the point is that this simple change of the equation makes it very similar not only for small weights, but also for now. Okay, if you can do this, what other things can you do? Well, you can do many different symbols and many different equations, but let me give you a few. So, one is if you go to deep water, then you not anymore have the tons deep. Anymore have the tons d, but one over d. So this homogeneous. So this is like obvious case. But of course, you see here, okay, if it's one half, then it's fine. But if we're now having a larger power here, so the order would be a very, very large negative, then you need to think about what this definition is. The bidirectional equations, now the order would be a minus one. You have the capillary. You have the capillary case with either strong or weak surface tension, I'll go into that soon. And, for example, the full dispersion Kp equation with a more complicated symbol depending on growth the frequency in the main direction and the weakie transversal uh direction. Thi these are plots p of the symbols uh by the way. And here, for example, there is some singularity in the symbols, but there isn't too much out of it. Symbols, but I'm using too much after this. So, what matters here when you do the different analysis, the growth of the symbols, that's the order of them, the singularities of them, and monotonicity. But what I will come to at the end, hopefully, is that sometimes everything matters in the zone. So, that's very different. I mean, when I started working with them, I was thinking, okay, this is like KDB. It's like K dB when you're close to zero, and then it's like one over square root of psi when you're far away, and that's everything that matters. But that is not entirely true. Let's have a look at FTKT. So what is the full dispersion Kp equation? The full dispersion Kp equation is exactly to the Kp equation what Wittam is to the K d V. This is how it looks. So, this is how it looks. It has this sort of horrifying symbol. And now, if you would take that symbol, expand it in D1 and D2, close to the origin, and take the leading order terms, you would retain the K-P equation. The K-P equation has the KDD parts in one direction and then is weakly transversal in the. Weakly transversal in the transversal direction. So there is weak motion in the opposite, in the orthogonal direction to the right. This is two surface dimensions, not one. And this can have strong surface tension when beta is bigger than one-third or weak. Now, before coming back to the full dispersion KP, let me say some things about how Let me say some things about how you can see which I'm in a bigger context with the dispersion. You can plug it into a family of fractional equations. And now I'm looking only at the order of this operator, right? I'm losing the other properties, but I'm looking at the order. So this is like a fractional order K dB equation, where K dB is when alpha is 2, Benjamin Ona when alpha is 0, Burgess is not in this case. Burgess is not in this scale, so take it out, it's vice versa. Burgess Hilbert is when alpha is minus one. Reduce the Strovsky when alpha is minus two, and then I don't know more names like this. What is known here? Okay, alpha is minus one half, that's width and it corresponds to the gravity of what we direction, right? Calculary gravity widtham is plus one half. Whereas we know that the waterway problem, for example, is globally well posed in several settings, which has been proved today. Here, global well-posedness has only been proved down to six over seven, alpha plus, positive. This is by Peloton, Moulinet and Manto, if I recall correctly. But everyone believes that the right thing is one half. Is one half. So one half, which is exactly the surface tension case, that should be the expected threshold for global closeness of these equations. One-third is, so one of these is energy critical without a mass critical. One-third is another important threshold because solitary waves in this equation ends here. Here when alpha is one-third. After that, you don't have alpha. But if you would change this to an inhomogeneous, like a Bessel type symbol, for example, then you have solitary waves all the way down here. So that's one. Now, even though when you're past the global wealth post threshold, you can still continue. You're going to have an enhanced. Then you can have an enhanced existence time. So, this is a result by Mi1, but it's based on essentially a method that Kyla and Daniel have worked on and elaborated in a number of works, including on the waterway problem. And I think in some cases, you can go past this. Here, I recently spoke to Alberto Maspero, who actually thinks that he can come up with data so that he's. You can come up with data so that this would be sharpened in this case. Now, if you're to the left of zero, to your negative order dispersion, and you're considering steady waves, then there would be highest waves for all negative order dispersion. You never have it for positive order dispersion, but you have it for all negative. If you're between 0 and minus 1, or if you're exactly Or, if you're exactly at minus one, exactly at minus two, then you have wave break. This goes back to Seliger, then Konstantin and Escher. Vera has made the main effort here. The proof of minus two is different. That would be Pedinovsky and others using more like Panasaholm type arguments. So here you have way break. I don't think it's I mean, in between here it's open, I think. Here it's open, I think. However, so two of my students, Mel and Juan, so I was very, I wanted them to do this here. But what they could do is that when you're between minus one and minus two, actually it's more general, but essentially that. You have L2 existence. So you go past wave breaking. You don't see wave breaking here. You have wave breaking, but you stop L2 and infinity data, and you're globally Globally, you could exist for all the times in L2 and you have bounds on L2. But that would be very nice to be able to do it. But we haven't been able so far. Now, you can also do the following. You can make this to a KP type of equation. The sigma here corresponds to plus minus 1, depending on whether the surface tension is strong or weak. So, this is the K-P term. This is called the fractional K-P equation. Now, it becomes difficult for me to tell about all the different results, right? Because now you have alpha here, and then you have strong and weak surface tension and so forth. So I will not say much more than that this exists. And that, so on the time-dependent problem, most of the work is by Klein-Pedol and Saul, and on the study by Robert Brut and Nielsen. Sorry, Donnie. Sorry, don't worry. Okay. So let's look at the surface tension relation. And what I want to come to now is that the surface tension full dispersion symbol will introduce phenomena in the Wittem equation that you don't have in the local counterparts. So if you have strong surface tension, then there's a local minimum. Tension, then there's a local minimum, and what you get is bell-shaped KDV type waves. If surface tension is weak, then you know that there is this kind of local minimum with a unique frequency. So you can get modulated NLS type of solitary waves there. But you can also get this kind of interaction that we saw also earlier today. So you have local extrema with a So you have local extrema with a local extrema to the left with a coexisting frequency. So this can both lead to generalized solitary waves, but also to bimodal waves. So this is what I'm going to now. This is numerical with some proofs when the waves are small. By the cation portrait of the capillary gravity Wittam equation. And what I want to focus on is: okay, you have these classical Beischer equations. You have these classical Beijlat waves, but you also have bimodal waves. This is something that you cannot have. I mean, you don't get it. I actually don't know any other scalar model equation to that order where you get it. So this is really based on using the full dispersion relation. And most interesting, I think, here is: okay, you can combine these different things, and you can have winter ripples and so forth. But what you also can do is this thing, which might not be visible to you. So you can take one of them, cosine k2, and you can translate it. And this means that you can construct asymmetric steady travel waves. So essentially, what you're doing is you're having two modes, cosine k1x and cosine k2x. You're translating one of them, and then you also. And then you already had a family, like a disk of binot solution, and for each of these points in the disk, you can make a torus where you're translating, and you can get asymmetrical base. And this is based on everything in the dispersion relation. So it's not just order, it's not the local behavior near zero, it's everything. And this is for the Witten case work by Olamerda and Douglas. And Doglas there, who will speak about this, I think. And it's also ongoing work in the other equation with Doglas and me and Boris before. Where we probably need to get in someone else for a last step. I don't know if you would talk about this. Another example of how full dispersion models capture more phenomena than their local counterparts comes from the full dispersion cape. Person cable. Okay, and here I should actually see how am I doing with time, and it's so and so. Okay, this is the Kb equation again. It has the Kdb terms, it has the weakly transversal. This is known since a long time ago to have no solitary waves when surface tension is weak. Okay, there's non-existent proof. When surface tension is strong, you have solitary waves of the Summer waves updated fully localized type. When Su and Lan in 2013 proposed a fully dispersed KP equation, so with a full symbol, they more or less... Okay, I don't know. I don't recall exactly. I think the extent the same thing would be valid. So the aspect, the question, would this admit solitary weights in any case? In any case. Okay, and there will be references on the next slide, I think, or a slide, something later. It has K-P solitar waves when the surface tension is strong, but when the surface tension is weak, it's not a non-existence result. Then it has basically skew of some type solitary waves instead. What that means is that you take the K tier. Is that you take the KT equation, you take the full dispersion version of it. The full dispersion version has enough of original Euler in it to detect also DS. And this is like a general phenomena for many of these, that when you change this, you change sometimes more than can be seen originally. So this is a few relations between some model equations and between the solutions of these model equations. So from the Euler equations, So from the other equations you can deduce rigorously how good widtha models and it models slightly better than KDV in terms of these small parameters. The KdV of course can be found within WITHA if you have small waves. So for example the solitary waves I've been mentioning in the Wittam equation and similar equations comes from a paper by me together with Mark and Erich, which goes back now more than one or ten years. More than one or ten years. And essentially, it says that since the symbol close to zero is similar to KdV, you can find Kd solutions. But you can also take the other equations and do 2D modeling, you come to the full dispersion Kp. There is not a proof for that, because the Kp symbol is very strange, but you can do that. So and Mann has worked on that. You can go then where you have strong surface tension, the full dispersion capability. Extension, the full dispersion KP in one dimension becomes it. But you can also go directly from the full dispersion KP to KP. Now, the picture I showed you in the last slide with the fully localized wave is from a paper together with Mark, where we show that the full dispersion Kp equation has small lump-type solutions when the surface tension is strong. But as I said also, when surface tension is strong, When surface tension is weak, then together with DOG as well, we proved that you can get the Davis-Tuwatson type solutions out of the full dispersion. What no one has showed, but it's probably true, is that you can take the full dispersion Davis-Tuhlson equation, go by that one, and then get these Davis-Tubertson solutions. But this has not worked. Okay, most of these results for solitary waves, they are for small waves. So when you really need that, when you have larger waves or larger solutions, then variational techniques become harder. And sometimes these similarities between the solutions of the equations are not true anymore. I want to mention a result, a recent one in solitary waves, but we. Recent one in solitary waves that we came up with. So, this is an extremely short story of solitary waves, but what I want to say mostly is that in the variational techniques for dispersive equations, what has essentially been done in almost all the results I've seen is that you have L2 type constraint minimization. So a quadratic part is held fixed, for example the L2 norm or something similar to it, while you're minimizing the rest of the function. Minimizing the response function and then using something similar to concentration contacts. This goes back to Einstein. Now, in the Wittam equation, there are small solitary waves, as I mentioned before. There are also large ones constructed, for example, by Tron, Valley, and Wheeler. And there are later computer idea proofs to do the same, recent ones. But I want to mention two recent. Recent different constructions where we actually do medium-size and large waves. So one is variational, the other is not. But the thing there is that we can construct large solitary waves more or less directly. One is we use the periodic theory. So for every period, we have the whole set from the zero wave up to the highest wave. We use estimates that we have for the highest waves that are valid for all waves. Bias waves that are valid for all waves that show, that help us take convergence in the periods. The period sets to infinity, and we converge to solitar waves. So that is a simple short note in proceedings of the AMS, which shows that we can get large solitary waves. The other one is a bit more interesting, maybe. So what we do there is that we use the functional functional of the energy and usually you minimize the green part holding the alternate fixed. What we do is something different. We'll maximize the dispersive part. This is the full dispersion part when trying to hold the rest fixed. The problem is that the rest doesn't define the rest. So you need to do something with it. And there And there we can construct large solutions via minimization. That was just published in ARMA recently, and I will give one slide on that. Just how we do. Okay, so you use Planchirel on the energy functional and then you isolate this part, which is similar to the one with the Tirchphere. With the Dierschvier Neumann operator that used, and this is the full dispersion of course. Now, what is this? In the Witten case, this is an operator of order minus one half. So this is the H minus one quarter norm. What's to the right? Well, to the right is something which is not a norm, because it's cubic and quadratic, and mu is unknown. Mu is the result. What we still do is we introduce a function norm, which is the left-hand side, and now we try to make the right-hand side a normal. What we do is we take essentially the right-hand side when solutions are not too big. When they are too big, we extend continuously with something so that this becomes a convex function. Alpha is related to the wave speed, it's not the wave speed, it's related to this becomes. This becomes a convex function, and that means that this is essentially, the right-hand side can be made into an order space, which is essentially an LP type of space, just like f to the power p is a convex function. This weight here is like that. So you use this to define, and then it's a long paper, but essentially then we can maximize the dispersive part, the fully dispersive part, under this construct. The dispersive part under this constraint and get not only small solutions. The parameter alpha is also related to highest weights when f attains this value, f is a. And outside of that, you're not solving which are. And now I need to make some choice about what we talk about. Yes, okay. So this leads us to highest waves and reason. Waves and reasons for regularity and connections back to the fractional derivatives that I started with. If you take this inhomogeneous symbol, the square root of times psi divided by psi, then it has the leading order part, which is a fractional negative order, half negative order operator, plus something which is in L1, so it's essentially a smooth part of the integral curve. The smooth part of the integral kernel connected to the symbol. Note that one over square root of psi is an eigenfunction of the Fourier transform, meaning that this is exactly the kernel of this. In short, this is to say, for this kind of dispersion, the highest wave will just be determined by the order of the object. But that is not so for all dispersions. But that is not so for all dispersions. Okay, so I will come to that. So, and then not dwelling too much on this. What happens essentially is that if you're away, you write the equation two times with an x and a y. What happens here is that you have a product, so if phi is equal to mu half, then the equation is of one type, if it's not, it's of a different type. It's a different type. And what essentially happens if you reach this highest point, you can more or less bootstrap to some regularity, but then you have to work harder to show that this regularity is attained. And what you do to show that that is attained is that you essentially use the same things that Arbon used. Then the problem is though that this is a little bit more complicated because this is a second order difference. This is a second-order difference. The idea is sort of you want to take one of these out, so you sort of want this out so that you can say that mu half minus phi of x is determined by this thing, and that this thing is like square root of x. The problem is that this has an indefinite sign, and another problem is that you really don't, it's not easy to take this thing out of sign. But if you pretend That phi is of the right form, and you see that you can get an estimate, which is essentially the correct thing. So you can bootstrap to prove that the regularity at the highest point is square root, is C one half. Now, the one difficulty here is that this changes sign, but it's also helpful. Design, but it also helps, as we will see soon. Another problem is that this has a singularity, but that also helps. So I will try in the last minute to show you the general situation for highest waves, why this helps, and then a few take-ups. Now, when you're between zero and one, 0 and 1, minus 1, you will have one type of high square, and then to the other side of minus 1, another. So when you're between, strictly between 0 and minus 1 in the order of dispersion, then the regularity of the high square is directly connected to the order of the operator. So this is like the object. However, when you're on the other side of the operator, When you're on the other side of minus one, all highest waves are ellipses. It's not that you get better and better, right? They are lip shits, each of them, and you cannot do better. And this is not only the symbol, right? Because the operator is gaining more and more. So this is related also to the structure of the equation. Now at minus one, many of you already know this, but maybe not everyone, you would expect maybe that you get You would expect maybe that you get Lipschitz because this corresponds to the bidirectional witten, which is the gravity water waves. And we know that that has a 120-degree angle. We know that. And that's Bark, that's known, going back to Toland on Plottico. So that was what we expected a long time ago, but actually, that's not true. It's log lips. There is a logarithm appearing here, so it's not like sigma 1 or something like this. There is a logarithm. I'll come back to the Babenko equation in a short. Now, what's with the green area? The problem in the green area, if you want to do more than just to say that it's ellipsis, is that everything counts. Every single part of the dispersion relation, not only the order, everything counts. Laser, not only order, everything counts. So, this is like what I would call fuller full dispersion. So, it's not only the full dispersion, but it's everything, and I hope to be able to show why. And the reason is that the singular behavior of the kernel ends at alpha is minus one. So, the kernel is the Fourier transform of the symbol. The symbol. And here the kernel is like 1 over x to 1 minus, yeah, okay. Essentially, it's like this opposite, it's 1 over x to some power that's smaller than 1 between 0 and 1. Here you get the logarithm, but after this, the kernel is nicer. And here you can see two and so forth. So there is no part of the kernel which captures more of the way when you do the The way when you do the convolution. Numerical proof says that the angle here will converge as the dispersion grows stronger and stronger, but we don't have a proof of that because, as I said, everything counts. The latest result here is with Olamello and Christopher Valeron, and that's the precise cusp. So the angular behavior, not only that, okay, so we already know, for example, width m by square root of x, but we determine this. By the square root of x, but we determine this coefficient for it. Now, if you take Pabenko's equation and you do the same kind of theory, the angle does not come from this coefficient. The angle comes from this power. Because Tabenko is expressed in the inclination, so the two-thirds comes here. comes here. So the Benkus equation is actually like this case which we already mastered. This is one finer constant in the expression near the high school. This constant has also been found in the computer edited preprint by NC Subomo Sarana and Viker. Now what I'm Now what I will do to keep my time is I will just say that the argument to get the new caspo in the case between 0 and minus 1 is essentially this, that you get out everything and this is like pi half and this determines the constant and this is the second order difference and you see it changes sign. You see, it changes sign and it has a singularity. What you can do is, okay, you do a lot of things. You use that there is a positive part, a negative part. You do scaling, you construct special sequences, you get to inequalities, you use a geometric argument for these inequalities. Geometric argument for these inequalities. They can only be true at the same time, at one point. This is actually not the ones we're using, it's a simplified version. And this gives the angle. So that's the good case for the logarithm. Okay, and then we get the theorem. For the logarithm, which was much harder to determine the log, it's actually easier to determine the cusp. It's easier to determine the caspoid. Why? Because the logarithm is not homogeneous, right? We cannot scale out of it. So that means that there is one part of the integral, namely this one, which is centered around the singularity, which is stronger than all the rest, and which gives you the exact behavior. You don't need a geometric case uh argument in that case. And currently we can do this between minus one-third and one minus one. There is also a computer-assisted proof by your daughter. And the reason we cannot do it on the other side of minus one is that there is no singularity in the kernel. So there is nothing to pick up. So we need to solve like Gap so we need to solve like everything. So the last slide is, and there is probably every single line of this slide can be objected to, but it also has a truth in it, everything. So so far what I've discovered is that okay, which items are capital to that asymptotic behavior at infinity? To that asymptotic behavior at infinity. So the order. So this is the basic order of the equation and it governs basic existence to you. So essentially when you're changing the order, you're also saying which part of the equation is the leading one. So if the order is too much negative, actually a quadratic term will be the leading derivative. So this determines whether you're semi, quasi, or fully non-linear in the problem. And as this version term becomes weaker, you're progressing to You're progressing from k V towards the R check orders, it also determines the presence of highest waves, includable closeness, wave breaking, and so forth. What about the behavior of the symbol near zero or near local minimum? This is coupled to which local model equations are most similar for force, at least for small waves. At least for small waves, long waves, so like Kdb width, Kp, full dispersion Kp, DS, full dispersion Kp. It also has to do with decay of solitary waves through regularity of the symbol. It has to do with resonances and wave interactions. So when I didn't have time to go into resonances, but this will determine like existence time, also multimodal waves. Time, also multimodal waves that we were into. And there will be restrictions when the symbol is homogeneous. Like if you have one over xi to large power, this is okay. What items are potentially coupled to everything? The presence of asymmetric waves seems to be very sensitive to that. As I mentioned, some properties for negative dispersion where the symbol is not, when the current When the kernel of the symbol is not anymore singular. But essentially, what I think is that probably any finer property of solution will be coupled to the full dispersion. Like all parts of it. At least anything that is non-asymptotic. So for example, determining the speed where the highest wave is approached, I would guess is really connected to all parts of it. That is what I want. That is what I want to say, that full dispersion is really full dispersion. It's not only the order for the local behavior, but full. Thanks for your attention. Sort of a question, too. Should I stop or should I go with you can stop the recording if you have? Yes. I don't know what the question is.