What we all know as good-winning calculus. Thank you. So, this is, I mean, it's, I love that this workshop has people from such different backgrounds in it. I'm learning a lot, and I hope other people are too. The thing that I'm going to talk about is so it, you know. So, it, you know, like tangent categories, it's a kind of abstract differential calculus. But it really belongs to homotopy theory. It was invented to describe some objects in homotopy theory. Sorry, Thomas, I forgot about this story of recording the video. Very sorry about that. Sorry about that. It's already taken care of. You don't need to worry about it. Oh, great, great. Sorry. I thought I made a mistake. You can start again. Okay, so my first vague mutterings got recorded. Good. So this is really a topic in homotopy theory that has a lot of categories and functors in it. And over the years, people have applied more sophisticated ideas from category theory to it. To it. And in particular, these days, it's being combined with the abstract notion of tangent categories or tangent structure on a category. So by Bauer, Burke, and Ching in particular. Of course, when you're doing category theory and homotopy theory and you're doing it seriously, then they're not just category. It seriously, then they're not just categories, they're infinity categories. So let's turn the page if I can. There it goes. Here's the basic analogy. So inside the world of homotopy theory, there is the smaller and nicer world of stable homotopy theory. I'll try to give a sense of what that means for those who don't know. And I really like to look at this as being analogous to the fact that in the world of smooth The fact that in the world of smooth functions, there is the much smaller and nicer world of linear functions. Because what this functor calculus is really all about is systematic tools for getting information from stable homotopy theory and using it in unstable homotopy theory in a way that is remarkably analogous. Remarkably analogous to how differential calculus uses linear methods to study nonlinear things. And more specifically, let's think about the category of topological spaces. Well, really, not just the category. I mean, you could say the infinity category, but more naively, let's just say it's a category with extra structure, which allows you to do homotopy theory. So, for example, you know what you mean by a So for example, you know what you mean by a weak homotopy equivalence. And think of the category top, topological spaces with whatever kind of structure you need in order to do homotopy theory there. And think of that category as being sort of like a manifold. And on the other hand, the thing which plays the central role in stable homotopy theory, the way TOP does in homotopy theory, is the category of spectra. Theory is the category of spectra. And I'll try to give a sense of what that means for those who may not have run into it before. And I like to think of the category of topological spaces or any other category that has the right sort of structure to do homotopy theory as being sort of like a manifold or a variety of some kind, where the ones that are like spectra, the stable ones, are the ones that are more like vector spaces. Where did my... Sorry, I ha I have to wake up my iPad from time to time in order to turn the page. There. So yeah. So I hope I can make some, hope what I say makes sense and sparks some thoughts. So in differential calculus, what's that all about? It's about starting with a function that isn't necessarily linear. That isn't necessarily linear and approximating it by one that is. That's a pretty simple idea. And as we know, it's a very deep idea, deeper than it looks. So if all you knew about differential calculus was that that's what it is, you wouldn't understand what's so great about it. Somehow, by learning to systematically approximate functions by their derivatives, Um, you acquire, you know, amazing tools for proving things about functions, like two functions that have the same derivative differ by a constant, or at least locally. The same sort of thing happens here. So I have to tell you what I mean by functors that are sort of, I'll be approximating functors by functors that are the good kind, sort of analogous to linear functors or degree one polynomial functors. I'll talk about this. I'll explain this in some detail, but basically, these are the functors that take push-out squares to pullback squares. And this turns out, this idea, first of all, you can, there is a systematic way of approximating functors of the kind that I'm studying by functors that take push out squares to pull back squares, which I'll call excisive functors. And somehow this is just, this is a very powerful thing to do. This is a very powerful thing to do. Lots of features from HOMA, from differential calculus, have analogs here, including not just linear approximations, but nth degree approximations, something like Taylor polynomials. Also, including the principle that two functions which differ by a constant must be almost the same. Sorry, the two functions with the same derivative should differ by a constant. Should differ by a constant if you know enough else about them. Something like that is even true here: that if you have two functors that are that are susceptible to these methods and you have a map between them, if that map induces an equivalence, a homotopy equivalence after you differentiate them, then in some sense they differ by a constant, at least locally. So I'm just saying this to sort of Now, push outs and pullbacks. Let's just make sure we know what we're talking about. So, if you have a square diagram in some category, you know what it means to be a push-out or a pullback, a co-limit or limit diagram. In homotopy theory, I In homotopy theory, I always, you know, if I say push out, I really mean homotopy push-out. You know, that means like if I have a space X mapped to two other spaces, X1 and X2, I could just glue them together. But what I really have in mind is glue them together in a homotopically meaningful way. So for example, if you have a square diagram of spaces, and if X1, 2 is simply the union of two. X12 is simply the union of two open subsets X1 and X2 along their intersection X well that counts as a homotopy pushout. Or if X12 is a cell complex of some kind and it's the union of two subcomplexes along their intersection, that counts as a homotopy pushout. But if you just took X and mapped it into X1 and mapped it into X2, I'm not so interested in the categorical limit of that in top. Categorical limit of that in top. I'm interested in first making these two maps into co-fibrations in some sense and then gluing things together, right? So the old-fashioned way to do that is using mapping cylinders. You cross X with I and sort of stick one end of it onto X1 and stick the other end onto X2 or something. The point is that this is, as I say, homotopically meaningful. So I don't know. I don't know. We're studying spaces up to homotopy equivalence. That is, we pay special attention to which maps are homotopy equivalences or maybe weak homotopy equivalences. And whenever we make categorical constructions, we try to do them in such a way that weak equivalences are preserved. So look, homotopy push out, think of the examples like here. This asterisk just means a This asterisk just means a one-point space. What if you have two spaces, X and Y, each with a chosen point? You stick them together, you get what topologists write as X wedge Y. It's the co-product in the category of based spaces. It's a pushout in the category of spaces. And, well, if it isn't, you know, if there's something pathological about X and Y and their base point, then you might want. Their base point, then you might want to stick them together along a little arc instead of a point. But we'll ignore stuff like that from here on in. So an example of a push-out square is, of course, that sort of co-product square in base spaces. And up to the right, an example of a pullback square. But now let's think about more important examples. I mean, more other examples. What if you took X and mapped it to a point? What if you took x and mapped it to a point in two ways? I mean, you map it to a point, you map it to another point, you stick those together. Of course, don't just stick them together. Replace the points by something equivalent to a point, like a cone on x, x cross an interval with one end of the cylinder identified to a point. Stick the two cones together to get the suspension. So the suspension is the homotopy pushout of two points along X. And the opposite or dual. And the opposite or dual to that is when you have two points mapping into X, or you have X with a base point, and then you don't form the fiber product until you replace that point by something contractible. Now in this opposite situation, you use path spaces instead of products with I. And a little more generally, these things come up all the time in homotopy theory, just push outs where one of the two corner things is a point, right? The two corner things is a point, right? So A is, say, a nice subspace of X, and X divided by A is the cofiber, the quotient space. Or oppositely, if you have a vibration sequence, you have a space B and a chosen point in it, and you have some other space mapped to it. If that map is nice enough, if it's a fibration, then the fiber deserves to go in the upper left corner. And if it isn't nice enough, And if it isn't nice enough, you make it nice enough, and then you have a homotopy pullback. And in algebraic topology, these cofibration sequences like this sequence here play a special role, partly because when you look at the homology groups of the spaces A and X and the cofiber, you get a long exact sequence. And likewise, the fibration sequences play the special role that if you take homotopy groups now, you get a long exact sequence. You get a long exact sequence. And maybe I'll just tie up this topic by saying this: that this cofiber that I'm writing as x over y, if you have a pushout square and you compare the cofiber of the upper arrow and the cofiber of the lower arrow, they'll come out the same. The induced map from one cofiber to the other will be a weak equivalence if it was a homotopy push-out square. Whereas if it was a homotopy pullback square, then the induced map of fibers will be an equivalence. Than the induced map of fibers will be an equivalence. All right, so I hope you're with me on this. Of course, in top, the push-out squares are not the same as the pull-back squares. You don't get homotopy group exact sequences in a cofibration sequence or homology group exact sequences in a fibration sequence. I just wanted to, for a moment, comment. I just wanted to, for a moment, contemplate this map. So co-products are not the same as products in based spaces, not even up to homotopy, right? And topologists sometimes like to take the co-fiber of this. So this is sort of geometrically like inside x cross y, you have the union of x cross point and point cross. union of x cross point and point cross y. That's this x wedge y or x plus y. And if you squash that to a point, the quotient of x cross y that you get is the thing called the smash product, written with an upside down wedge. It's hard using tech as a topologist, as a homotopy theorist, because the tech command for what we pronounce wedge is actually a V and the one for what we call Actually, a V, and one for what we call smash is a wedge. Anyway, and I thought I would just mention in passing another, if you were trying to do homotopy theory for rings of some kind, like differential graded rings or ring spectra, if you know what that means, it's worth just taking a glance at what the difference between products and co-products there. So, you know, suppose that A is some ring of some sort, an augmented K algebra. K algebra for some commutative ring object of some kind, and maybe just let the augmentation ideal be I. And if B is another such thing, well, then when you tense the co-product, if I'm talking about commutative algebras, then the coproduct of A and B is simply the tensor product, whereas the Cartesian product of A and B, the product, categorical product, is the fiber product over. Is the fiber product over K. So you get that the, well, like the fiber or kernel of this comes out to be I tensor J. If you just imagine tensoring A with B, there's the K tensor K term and the K tensor J term and so on. But there's this extra term I tensor J, which is sort of the difference between the coproduct and the product. product of the product. Now, here's the linear approximation part. The functors that are going to play the role of linear functors are the ones I call excisive. I use that word just because the excision property of homology theory sort of says that homology behaves nicely on pushout squares. And that can be interpreted as saying that some functor from spaces to space That some functor from spaces to spaces associated with homology takes push-out squares to pull back squares. Anyway, I'm going to just use the word excisive or one excisive for functors that from say top to top, but you can be much more abstract, that take push-out squares to pullback squares always. So that's an important part of the story. That's sort of the center of the story here. But also, it's useful to consider categories. Consider categories in which pushouts and pullbacks are the same. And we call those stable categories. And an example of that is chain complexes of any flavor you might think of, like just chain complexes of R modules for some R, unbounded. But also the thing called spectra, which as I say is the sort, that's sort of the central example of a stable category. Now, Now, here's the idea of how you go about making a functor excisive, analogous to making a function linear. Suppose you have f from, oh, just to be definite, from spaces to spaces. And let's assume that f of one point space is up to homotopy a one point space. So sometimes we call it reduced in that case. Then look, you can map f to this new functor, the loops. map F to this new functor, the loop space of F of the suspension. Remember, loop and suspension, I described them. The loop is a certain pullback, the pullback of point and point over something. And suspension is the pushout of point and point along something. So, I mean, if f is reduced, then you can, for any x, you can go like this. x maps to a point, maps to a point. Resolving the points by cones, you get the suspension. That's a pushout square. A pushout square. Now, I wish that f of this pushout square was a pullback square, but nobody said it was. But let's write it down. Well, at least there's a map from f of x to the limit of this. And I've assumed that f of a point is equivalent to a point. So I can write the limit of that as the loop space of f of the suspension at x. Of the suspension at x. So you get a map from f to loop f suspension just by f being a reduced functor. And as soon as you get a map from f to loop f suspension, you're going to do it again to do the same thing to, well, to loop F suspension, map that to loop loop F double suspension, and so on. And then the idea of doing this is that if F had been If F had been excisive, then these maps would all be equivalences. And if it's not, then, well, maybe by the time you go all the way to the end of this direct limit system, you've got a functor that is excisive. And that turns out to be true and quite generally under certain minimal assumptions about About what categories you're working in. I mean, as I say, they should be homotopical categories in some decent sense. So, for example, they could be, you know, quillin, you know, model categories in the sense of quillin such that sequential co-limits commute up to homotopy with, I mean, sequential homotopy co-limits commute with finite limits. Let's commute with finite limits. That's the basic assumption. All right, so there's a way of making a new functor, which I'll call p1f out of f, which is designed to be the universal example of an excisive functor that f maps to. And this is how it looks if f was reduced. And just a slight modification achieves the same thing if it wasn't reduced. I just mentioned in classic. In classical stable homotopy theory, I mean, that's largely about looking at a space stably. So, well, I mean, if f is the identity, you've just got x goes to loop, suspension, x goes to loop suspension, suspension x, and so on. And if you now take homotopy groups of everybody, you have pi n of x mapping to, well, pi n of the loop space of something is pi n plus 1 of the thing. Plus one of the things. So you get group homomorphisms like this for any space just by doing what I wrote above to the identity functor. And in fact, for any given space, this sequence eventually turns into isomorphisms. And what it converges to is what's called the nth stable homotopic group of x. And this functor of x. And this functor of x, the nth stable homotopy group as opposed to the nth homotopy group, this is an example of what's called a generalized homology theory. Homology theories, not just homology, but generalized homology theories, behave well on push-out squares and cofibration sequences. And this is stable homotopy, is sort of the homology theory that you get by modifying ordinary homotopy groups just enough to make a homology theory. And that's enough to make a homology theory. And that's sort of almost the same fact as saying that the direct limit of this is the excisive approximation of the identity functor. All right. Now, as I said, if f was already excisive, then this wouldn't change it. Oh, and I point out that the suspension of an n-dimensional sphere is an Suspension of an n-dimensional sphere is an n plus one-dimensional sphere. So if f is excisive, then this is true. And now I have to say a little bit about spectra. I mean, I don't know. It's, you know, I suspect that computer scientists probably don't have much to do with spectra, you know, and some of you are computer scientists, right? Category theory. Category theorists don't necessarily have much to do with spectra. Over my long life, I have often found myself trying to tell some graduate student what spectra are all about. And it takes many conversations to sort of get my point across. So what am I supposed to say now? Let's just say this. When you have a when you do a When you do what I was doing with a functor, you get maps from, by in particular, applying it on a sphere, you get maps from f of the n sphere to the loop space of f of the n plus one sphere. You get such a thing for every n. And the most old-fashioned idea of spectra in homotopy theory is that a spectrum is a sequence of based spaces, in this case the spaces F of Sn. In this case, the space is f of sn equipped with maps. Well, let's just so by a spectrum, we can say what we mean is a sequence of spaces, one for each non-negative integer, together with for each n, a map from one space to the loop space of the next. So and And in some ways, the nicest spectra are the ones where this map from En to loop space to the next is a homotopy equivalence. Those are called the omega spectra. And there's a basic procedure for replacing a spectrum by an omega spectrum. If you're looking at a sequence of ENs like this, related like this, but the maps are just maps. Well, you can cook up an option. Well, you can cook up an omega spectrum, which you then declare to be equivalent to this one as a spectrum. And you do it by a direct limit process, much like what I just described. You sort of replace E0 by the direct limit of loop NEM, and that's your new E0, and so on. That process is sort of, you know, it's built into what I'm talking about here when I convert a functor to a To a a um an excisive functor. Now, I don't want to say a lot about spectra, except to say there is the just philosophically, the category of spectra is it's sort of what you get from the category of spaces by by it's the. If you were wishing that in the category of spaces, a push-out square was the same as a pullback square, that's sort of meaning you were wishing you're wishing you were in the category of spectra instead. If you modify the category of spaces just enough to make your dream come true, you've invented the category of spectra. And there's an adjunction between these. So here, base spaces, here spectra. A spectrum determines a base space by Determines a base space by converting it to an omega spectrum and then just looking at space number zero in that new list. And the left adjoint to that is the suspension spectrum functor, which is the functor that, well, you start with a space, a base space, x, and it just says, well, there's x, that's my e zero, and then the. X, that's my E0, and then the suspension of X, and then the suspension of that, and so on. Those things form a spectrum. And if you were to convert that to an omega spectrum, you'd be looking at sort of, well, that's a spectrum, but probably not an omega spectrum. And that functor from spaces to spectra is left adjoint to the loop infinity. So there's this basic adjunction in homotopy theory between the Theory between the base spaces and spectra. Now, this is the left adjoint functor, of course, preserves co-limits, and in particular, takes push-out squares to push-out squares. The right adjoint functor, well, of course, preserves limits, so it takes pullback squares to pullback squares. And over in the land of spectra, pullback squares are the same as push-out squares. So when you go from spaces to spectra and back again, spectra and back again you end up taking push out squares to pull back squares and this is sort of the fundamental example of a this functor that the identity functor made excisive is precisely the the composition of these two adjoint functors loop infinity sigma infinity and that's kind of the the most important uh example of a um the sort of prototypical example of a Of prototypical example of an excisive functor from spaces to spaces. Right, I must keep moving along here. Now, for years, I have thought of the category of spectra informally as being a sort of tangent space or tangent category of the category of spaces at the one-point space. And sort of because that's where you go to because of what To uh because of what I just said about the adjunction, in a way, I mean, because it's the it's the it's the it's the nearby linear place where, you know, that you should go to to do linear things with spaces. But that was very vague. But look, here's one good way of thinking about tangent vectors of manifolds. And we've heard been, you know, this has come up already more than once this week. Than once this week. Suppose M is a manifold and P is a point in it. Well, you could think of curves, parameterized curves, smooth maps from the real line to M, taking the origin to P, or it could just be from some neighborhood of the origin. It could be some little interval around zero being mapped to M. Such a thing is supposed to determine a tangent vector. Two such things determine the same tangent vector if they agree to first order, and that's a Agree to first order, and that's a concept you can sort of discuss without even having defined tangent spaces yet. Given two maps from R to M that both take the origin to the same point, you can choose local coordinates, ask whether they have the same constant and linear terms in their Taylor series, and then observe that it doesn't matter which coordinates you choose to answer that question. So these one jets of maps from the line to M serve as tangent vectors. You could take that as the starting point for explaining what you mean by tangent. For explaining what you mean by tangent vectors. And in the same way, now suppose that C is some category in which I can do this functor calculus stuff. It might be top, it might be something else. C is a category, little c is an object. Well, playing the role of curves, let's say we look at functors from base spaces to c taking the trivial base space to little c. To little C. And I haven't said this, but let's make a footnote here of finiteness issues. For most purposes, when I'm talking about this calculus stuff, I'm only going to use functors which, in addition to preserving weak equivalences, my functors that I'm studying and differentiating and working with should also have this property that let's say they Let's say they commute with filtered homotopy collimits. So, a functor from top to top, I'm only going to consider the ones which are determined by what they do on finite cell complexes, because every space is weakly equivalent to an infinite cell complex, and every infinite cell complex is a filtered co-limit of finite cell complexes. So, I mean, I could just be thinking about functors from finite objects to whatever, but I routinely. But I routinely extend them to all objects by taking filtered homotopy collimates. Anyway, maybe I should write sort of some decoration here for finite spaces. But this is an analogy that I like. And just like parameterized curves in a manifold, we have functors from finite spaces to one of these categories. But really, just one jets of functors. So call two such functors here equivalent for this purpose if they agree to first order. What I really mean by that is this is not a property. I shouldn't say classes. I should say consider the category of all functors, suitable functors from here to there. There. Suppose they have a map between two of them. I'll call it an equivalence for jet purposes. If, when you perform this P1 process, making things excisive, if this map between my two curves becomes an equivalence when I replace each of them by P1 of itself, so it's a sort of localization process. It's a sort of localization process. There's the category of all based functors from spaces to here, and then there's a localization of that category where what I'm inverting is the maps which become equivalences when you force the functors to be excisive. Of course, another way of doing that would be to just say I'm only using the excisive functors. So a tangent, I want to say a good picture for what it's meant by a tangent vector of. tangent vector of top or some other such category is it's a one excisive functor from set based finite spaces to this category with respect to a some based object some base point object or in other words i mean maybe you replace c by the slice category of objects over little c, and you look at just functors from here to that that preserve terminal object. Observed terminal object. Anyway, that's a point of view. And so, yeah, so I'm but it is just another way of looking at spectra because if you have such a functor, yeah, I want to say if you have such a functor. And then you evaluate it on spheres, you will find that you have made a sort of spectrum. Let's see, I just have to pick a level of generality here. Let's look at this case where the thing you're mapping into is spaces, and the special object little c is the one-point space. The one-point space. Then I want to say: given a functor from base spaces to base spaces that preserves the trivial space, you can just evaluate it on spheres and get a spectrum. And that way of just saying this is sort of how you go from this parametrized curve model for what you might call a tangent candidate. What you might call a tangent category to the spectrum model. And I just say, because you will be hearing from Bauer and Ching later today, that this is the point of view that they take when they connect this functor calculus stuff with tangent categories. This is what they mean by the tangent category, this sort of excisive, the parametrized curve point of view. And I just mention it. I'll just mention in passing: if instead of top, you just had some other homotopical category C with a chosen object little c, and what I mean by this is just objects over and under little c, so the pointed version of the slice category. If you take just the pointed version of some slice category and use that to build abstract spectra, you're building your spectra not out of spaces now, but out of. Of spaces now, but out of little sea objects. That's another view of what you might mean by tangent category. And it's really the same thing as this parametrized curve business. I think for lack of time, I won't return to the idea of tangent of rings and tangent category of a category of rings. Category of rings. I will say that in manifold theory, just as you can make tangent vectors out of maps from the line to M, of course you can make cotangent vectors out of maps from M to the line. And you could do the same sort of thing here, looking at functors to spaces instead of from spaces. And then I just wanted to put in a plug for this idea that when I'm applying. That when I'm applying these methods to some category, like top or some category of ring spectra or whatever, I think a nice point of view is that when I'm trying to learn to think of some category of this type as a geometric object, maybe a good name for that object would be a sort of a variety over the category of spectra. That is, just as in algebraic geometry, Just as in algebraic geometry, you're dealing with geometric objects where the geometry is all about the functions on those objects. And the functions in that case are polynomial functions. But in some other kind of geometry, they're maybe holomorphic functions. And in C infinity geometry, they're C infinity functions. Well, I just want to think of functors to the category of spectra as being the most important kind of functions on these objects. And the analogy works particularly. And the analogy works particularly well when you're studying those things. So now I wanted to say briefly what's meant by nth order excision. I'll do it very briefly. Suppose instead of making a pushout, I have three maps with a common domain, and then I make pushouts all around to get a very special kind of three-dimensional cubicle diagram. Of three-dimensional cubicle diagram. And then I hit that with a functor f. So now f of x is mapping into f of all the other seven things. And I can ask whether that map is a weak equivalence, whether f takes this sort of pushout cube, takes every such push-out cube to a limit diagram. And if it does, then you say that f satisfies second-order excision. And if you want to say what nth order excision means, you have to make push-outs. You have to make pushouts out of n arrows with the same codomain to make an n-dimensional cube. And it turns out that just as loop infinity sigma infinity x is excisive, a thing like this is too excisive and so on for higher powers. But if you put in smash products or some other related thing like this, you'll always be getting functors satisfying second-order excision. Functors satisfying second-order excision, and similarly for higher order. And there are, as I say, not just sort of linear approximations, but there's a whole Taylor series, or rather a whole Taylor tower. I'm just using tower to mean like an inverse limit diagram. If you have a functor f, let's say that you want to apply it to some object over some object, but f of some object, but f of x. f of x maps to f of y. Let's fix y now and work in the slice category of objects over y. So down at the bottom is the constant functor of objects over y, which is f of y. Here is just some functor f that I started with. Here is that p1 of really of the restriction of f to the slice category. I'm just saying I'm just saying this P1 is the beginning of a whole long story. It turns out for every n, you can cook up a functor called PNF, which is the universal example of an n excisive functor with a map from F. And I mean, you can, you know, if you know how to do that, well, and you do that in a slice category. Well, and you do that in a slice category so that what's at the bottom of the tower is f of y, and you're dealing with objects over y in the domain category. So this is the sort of analog of a Taylor series in this game. I invented this stuff to study certain functors that come out of algebraic k-theory or that come out of the theory of manifolds in a certain way. But of course, some The identity is a natural thing to apply them to as well. For the identity functor from spaces to spaces, P1 is this thing that I keep mentioning. P2, well, has this quadratic, the quadratic correction that gets you from P1 to P2 looks like this. This is X smashed with itself and then divided homotopically by. and then divided homotopically by the sigma 2 action on x smash x. So there's the linear part of the identity, so to speak, and then there's the purely quadratic part of the identity, and there's a map between them and the fiber, the homotopy fiber of that is the sort of second order approximation to the identity. And it's interesting that this map from this to this, although these objects are infinite loop spaces. Are infinite loop spaces, spaces determined by spectra. The map between them is not determined by a map of spectra. So P2F doesn't live in a linear place the way P1F does and the way the purely quadratic part does. And I should say the form of this is something that one sees over and over. It turns out that the purely quadratic part always looks something like that. And I wanted to say. And I wanted to say that so the nth layer from this general theory, one knew that for the nth, for the purely nth degree part, the fiber of the map from pn of the identity to pn minus one of the identity, one knew that it had to have this form. This functor of x is given by taking the nth smash power. Given by taking the nth smash power of x, smashing that with a certain spectrum that comes to you with a sigma n action, the nth symmetric group, and then dividing by that action in a homotopical sense. And then converting that spectrum back to a space. Every homogeneous functor, everything that can occur as just the purely nth degree part of something, the fiber of the map from Pn to Pn minus one, has to have that form. And this thing. And this thing, this nth coefficient of the Taylor series of the identity, so to speak, is something which was first described in detail in Randa Johnson's thesis. And the power series that corresponds to the identity is sort of reminiscent of the logarithm series. I don't have time to say more. In fact, I don't have any time at all. There's one more minute if you want. So let me just say. Just say, I sort of advertised the idea that tangent vectors are a kind of one jet. You can talk about n-jets. What I mean is two functors have the same n-jet if pn of this is the same as pn of that. So you could localize with respect to that. And I'm going to skip what I wanted to say about homogeneous functors, but I wanted to make a point about manifolds. That when you let's let this stand, if n and n are manifolds and you're looking at maps from n to n that take a point p to a point q, you could call two such maps equivalent or agreeing to nth order if, you know, if they're, if when you choose coordinates all around and look at the tail, look at start differentiating, they agree up to nth nth derivatives. The set of all such things is called a space of n-jets. Space of n jets. And I just wanted to make this point that in the world of smooth manifolds, although one jets live in a vector space, n jets don't. An n-jet has an underlying n minus one jet. And if you fix an n minus one jet, then what lies above it up here is a vector space. But, you know, the space of two jets is sort of, it's like a vector. Sort of, it's like a vector bundle over a vector bundle. That's something you always have to reckon with when you think about jets. And that's something that comes up here because the purely, yeah, I mean all right. I just wanted to uh I have I have some scattered things here which I might or might not have time to mention. I just want to say there's a chain rule. If you have categories such as I'm talking about and functors going from, say, C to D and D to E to compose, well, when you make tangent categories for C and D and E, you do get linear maps, one excisive maps between these stable categories satisfying the expected chain rule. Rule. And I wanted to say that if your categories are stable, then you can do straightforward things like write down the second derivative of a composition in terms of first and second derivatives of the f and the g. But that if you want to do that in a nonlinear setting, like for functors from top to top, it gets much more intricate. And Michael Ching's thesis introduced the idea that there's an operad which governs the ways you have to combine all the sort of first, second, and so on derivatives of two functors in order to arrive at the derivatives of the composed functor. And that this was worked out in Ben. And that this was worked out, and then this program was completed by Greg Arone and Michael Ching. All right, I'll just finish by saying this is one of those tangent situations where you cannot subtract vectors, and also that I really like thinking about tangent fields, cotangent fields, and trying to think about connections. All right, I will stop talking now. All right, let's all unmute and thank Thomas Goodwilly. Thank Thomas Goodwilly. So before opening the floor to questions, I'll just give a note on what happened in the chat. So Kiao Peng shared a set of notes on spectra in the point of view of a stable infinity category that are quite nice to read. Nice to read, and Anderskock is asking the following question: The fiber from n jets to n minus one jets is it only an affine space? Oh, I don't know. Yes, I suppose it is. I've been thinking a lot about affine spaces lately, by the way. The affine analog of a stable category. There's a sort of trivial thing you can do where you're sort of like a spectrum without a base point. You can introduce a slice category. If you take some stable category, such as spectra, and you fix an object and then look at the slice category of either objects over it or objects under it, I've been trying to learn how to think of that as being sort of like an affine space where a Affine space, where a stable category is like a vector space. And I find that this is really useful when I'm trying to think about things like vector fields on categories and integral curves of vector fields on categories. But I'm still a little mixed up about many aspects of this little project. So I've got three more hands raised, so quite a lot of questions. In order, I think. So, quite a lot of questions. In order, I think Joff and then Kiao and then Ben. So, Joff, would you like to unmute and ask your question? Thank you. I really enjoyed the talk, by the way. It was a lot of fun. But I was just wondering if you've thought of, especially this JET perspective towards stuff like vit vectors and things like that, where you have, like, of course, vit vectors aren't vector spaces, as cruel as that might be, but you do have that same sort of. But you do have that same sort of vector bundle type trick. I'm sorry, what does this have to do with vid vectors? Oh, oh, the jet perspective you were talking at the end. Yeah. How you get your tower of, say, n jets, n minus one jets, and that looks like n truncated vit vectors, n minus one truncated vit vectors, and that sort of thing together. And by sort of stacking them all up in the tower, comparing how the fibers look over top of each other. Look over top of each other, that might give you that sort of perspective. I was just wondering if you thought of this sort of thing or if you know anything interesting in that regard. I would love, for me, basically the situation is that I refer to, I know what I mean by categories of end jets in this context. And I wish I knew how to work with them better. But I never thought of them in. But I never thought of them in relation to bit vectors. I will say that the fact that one of the surprises in developing this stuff was that much of what is sort of easy to do down on the first order level has surprising payoffs when you get to the nth order level. to the nth order level um i mean like just the fact that that the that the um the fact that the functors that can appear like the the nth the n excisive functors with trivial n minus one excisive part which i call homogeneous they're like homogeneous polynomials the fact that these live in a stable place the fact that that that when you have a functor from spaces to spaces and you analyze it as a tower like this Analyze it as a tower like this, the sort of nth layer, the nth little step in the filtration, actually takes values in infinite loop spaces, is one of the central, is one of the high points of the you can come in if you want what I'm mute and the camera's off. Yeah, it's just question period. Anyway, I was going to say there is I should save this remark for some later discussion, probably. We should turn to other people who have their hands up. Yeah, there's two more people. Of course, you'll have time to chat about it in Gather Town later. Kiao, do you want to ask? Maybe I'd ask, since you see the excessive functor, it's kind of like Functor is kind of like linear polynomial. So what about mean for high order polynomials? So what's kind of mean the function in the property? Yeah, I mean for the general polynomial, I mean what kind of functor should we define? So it makes a big difference whether you're talking about functors from top to top or from the answer gets simpler if these are if the functor if either the domain or the codomain is something stable. So is this can define by some higher Defined by some higher algebra. Some higher what? Higher algebra by Louis Rees kind of his work. I feel, I mean, there are some related I mean, I'm not sure what you're asking exactly, but the functors that The functors that can occur as a, so a linear functor, well, a one excisive functor from spaces to spaces. I mean, if it's reduced, so like no constant term, it's given always by a spectrum, right? The only way to have such a functor from base spaces to base spaces is you take some spectrum of C and you say, okay, I take my space, I smash it with C, and then I loop space. That you get from that spectrum. There's a similar description of what the most general.