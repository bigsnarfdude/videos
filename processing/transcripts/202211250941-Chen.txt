So is it full screen model right now? It it is. Yes, we can see it. Okay. Yes, we should start now. So do you agree to be recorded, Lee? What? Yes, yes, it's okay. Will the recording start? Yep, it started. Okay, thank you so much. Okay, it's a pleasure. This is the last talk of the conference. Talk of the conference is from Li Chen, and the title is Portland or Idol Lichens. Okay, thank you, Ruca, and thank you for coming to the last talk of the conference. It's a pity that I couldn't participate in person. So today I will discuss the Pangara inequalities and the related topics on the VCXAT. So at this point, we have already seen many. We have already seen many different fractals like Sapinski gasket, Spinski cabbage, and other metric space. In my talk, I will discuss a simple version of fractals, the V-sex site, which has both the fractal structure and the tree-like structure. So, well, I start with the With the Pangai inequality. So, while the Pangai inequality has many applications in analysis, probability, and also contain much information about the geometry. So, here's the typical Pangari inequality for which the gradient can be different. Different types of gradient, like upgradient in the sense of Tiger, and so on. So, on Euclidean space, people are remaining manifold with land activated curvature. We have this L2 panga inequality, which is equivalent together with volume doubling property, it's equivalent to heat colour, Gaussian up and low. Low Gaussian up and low bound. So now let's move to the setting of VSIC set, which is an illustrative example. So the picture of the VCAC set is in this. It's the ULIC empathy compact set such that it can be written as the Be written as the union of the five contractions of itself, and we consider the normalized Hausdorff measure such that the measure of the VCX is one. And we are also considering the maybe I should say geodesic distance, which is equivalent to the Euclidean distance. So, also, well, we can Well, we can think of the VCX set as the union of N simplex, and well, the N plus one level simplex refines the N simplex or the cells. So, okay, so that's about the VCX set. Well, we can also consider the VCX set as the limit of The limit of a sequence of the Visac graphs. Well, here it's the in this picture, it's a skeleton of the Visiac graphs, and we can also consider the reference measure on the skeleton, which is a Lobeck measure. It's sigma phallate, but Valid, but infinite singular with respect to the host of measure. So, okay, so that's another viewpoint to look at the VCX. So, okay, so then we'll ask Supenski gasket and other factors. Other factors, so we can think about the Dirac form with as the limit of for the quadratic form of the V-Sheck graphs. Of course, you can also consider an infinite version of non-compact version of the V-Ssek set. So there has been many. So there have been many references, at least some here, for example, in the work of Jungikami, Bala Perkins, Fitzman Hapley, Kumagai, Sukas, and so on. There are many names I didn't list here. So there is a corresponding energy measure, which is not absolutely continuous with respect. Continuous with respect to mu. So hence, we don't have a proper notion of gradient. And last I want to introduce particularly the host of dimension and the so-called worker dimension. So the VSX is dH regular. So there is a host of dimensions. So there is a host of dimension log 5 over log 3, and also it satisfies the sub-Gaussian heat colour estimate and this dw, which is exactly dh plus 1. So this is a very special case. It's a borderline case for which usually dw is between 2 and dh plus 1. But in this case, dh is exactly But in this case, dh is exactly, dw is exactly dh plus one. And so there has been, so there are two Panga inequality which is learned. For example, in the works of Balo, Bas Kumagai, Abish, Salo Kost, Gregorian text, and so on. So, here the difference is that Difference is that in this Panga inequality, the power, the parameter of R is dw instead of 2. So the doubling volume property plus the Pangai inequality is weaker than the up and the lower sub-Gaussian head colour estimate. Estimate. And my talk will discuss the LP version of this Pangari inequality on tree-like factors, such as VCX, actually, or like metric trees. Anyway, we focus on the VCX side as a special example. As I explained before, there is Explained before there is low gradient, so that's the main obstacle. So, we need to find a proper analog for the LP allergy. Actually, so this has been discussed also in the talk of Shimi Zui yesterday. So, okay. So, it's so there are quite some. So, there are quite some positive evidence for which tells us that indeed we can have the Pangara inequality. Here are some evidence. So, for instance, if we consider the Vishek graph, for which I mean the graph with the edges of lines one. Lens one. So then we have this Pangai inequality with a power in this way. And also there are some development in this joint works with many co-authors, Patricia. Patricia, Fabrice, Luke, Lagas, and Sasha, and so on. Anyway, so in this case, we have this weaker battery Emory type estimate and on the Vichy case. So it's like a deep seats estimate. So now let me introduce Um, introduce different PLDs which will work for us. So, one is from purely the metric viewpoint, which is the Caravacian sober leaf space defined as the LP function such that this name soup is finite and And we deliver by Fw1P this semi-room. And here, this alpha P is the same as the Pangai inequality and graphs I mentioned before. Of course, one can also consider this instead of the limit inf, which is better. In that case, we In that case, we write as the variation, and yeah, so this definition is on the whole space, but we can consider the same definition on the bore set. And another version is from the disk creator PLGs we have seen yesterday for the Sepinsky gabbit. And in this case, the sigma p mentioned by mentioned yesterday in the setting of spins capital is 3 to the power p minus 1. Okay, and okay, this p allergy on the graph, so it's incorrecting. Increasing so that we can define this space as the supreme of EM or the limit of EM. That's the same. And because of this special tree structure, so we can also consider a PLD pharmaday weak derivative pharmace skeleton. From the skeleton in this way. Okay. So here there's something special about W11. It's lottery from the metric version definition. In that case, it's a space of BV functions. And so this definition is motivated from the end. On the end point of the real interpolation. Okay, so the Pangai inequality is pretty simple, actually. So here it's aversion from the in terms of the discrete PLG, the limit of The limit of this quick allergy. And of course, when p equals one, so this power here is dh, and there is a type of when p equals two, this power is dw. Actually, we obtain a stronger version of this more retype in quality. Okay, here there are some references of this. Of this P-Logy. I will give you a very brief introduction about the proof, which is motivated by the work of Kushukastuk or the work of Coulon Salov Kost in the 1918s or 1919s. 18th or 1919. Essentially, if we consider the xy as vertices in the m the dynam, this can be obtained by hurdle inequality and this gamma m xy, the absolute value, it means the number of edges which Which collect X and Y. Okay. And okay, if we consider the V-Sheck set, so then there is an approximation procedure. And with the Mori type estimate, so then we can show that. Show that the different characterizations of sorbolif space are equivalent. So the statement of this theorem here is on the space on the Hovich set, but we can refine us to subset. So I think I still have four minutes. Have four minutes, so then I will give a very brief introduction about some of the ideas behind it for the equivalent characterization. So, first of all, let's look at two and three. So, from the definition of FP, so okay. So, uh, one direction. Uh okay, sorry, yes, so um three implies two is more ledger. So for two implies three, two is the PLG from discrete approximation. We use this so-called NP So-called and piecewise affine functions for which, for example, the two-piecework of fine function, so it's like maybe let's say the one-piece was affine function, so which it's linear between the vertices in the second picture here. But But for the upper level for the vertices, so the values are constant, which it's the same as the closest value in the one level, the second level. Okay, so this function has many good Function has many good properties that help us to do analysis. So also we can approximate a continuous function by the so-called piecewise of fine functions. So in that case, we can first work on the piecewise of fine functions and then to work on the Functions and then to work on the zero functions. Okay. And okay, so it's more complicated to compare the metric version PLG and the discrete PLG. So well, if we want to control the discrete PLG, so then we use a fractal version of telescopic IV. Telescopic argument, it may not be very accurate to speak in this way, but anyway, we try if we consider a vertices in Vm. So then we try to find a sequence of simplexes which shrinks to X, then together with some basic convexity inequality, we can do the estimate. We can do the estimate. And for the other part of the inequality, so then we use the Mori type estimate. So that actually we use the fact that this structure, okay, is very regular in the sense that two disjoint seam level seals, they are not too close. Close. So that's the basic ideas behind, and with different calculations, we can use one which is good for us in different problems. And the last slides are some possible applications. And I think I stop here. Thank you. Thank you. Let's take YouTube again. Thank you. Why don't we take your game message for the podcast? Please do ask for the podcast. You're all for coming. As you know, it's the leader participants who make a successful conference. President's still a little bit worked behind the scenes to get you here, but nothing happens without you. And you've got some great things. So, thank you. And thank you very much. It was great. Much exposed, I might still get through a couple of messages. 