So, today, it's a pleasure to be here today to talk about additive and curated relaxed clock models. I'm sure some of those words would be familiar to many of you. I'm sure you're all fairly familiar with clock models and quite probably familiar with uncorrelative relaxed clock models. Maybe you're a bit intrigued by what I mean about additive relaxed clock models, because that's kind of. About additive flux talk model because that's kind of what's a bit different in this talk, and so of course, I will be explaining that. But so, just to sort of get us started slowly, I'm sure you're all familiar with that. I mean, in genomic epidemiology, one thing that is very, very useful in a lot of scenarios is to build a dated phylogeny. I'm sure we've all done that twice. So, just to sort of be clear what I mean by that, you know, in standard phylogenies, there's lots of methods for standard phylogenetics, and all of them reconstruct trees that are branchless. They reconstruct trees that have branch lengths measured in units of evolution, for example, substitutions per site. But dated phylogenies are different because they have their branch lengths measured in unit of time, for example, years, like this phylogeny shown here. That means the genomes are aligned on the x-axis with their known dates of isolation. The branch lengths are measured in units of time, and the internal nodes of the tree are aligned with the estimated date of existence of the different ancestors. Different ancestors. So, in order to build such a dated tethroll, we need to have a molecular clock model which represents how the mutations accumulate all the dated branches of this tree. You can see that this is, we have information about the mutation between the different genomes, and what we want to know is recover something about the dating. So, clearly, we need to have this molecular clock model. I'm sure many of you are familiar with that. Okay, so what molecular clock model can we use? Well, one of the sort of simple Can we use? Well, one of the sort of simplest possible choices, of course, is the strict clock model. So, what the strict clock model is, is it's a model where we're going to say if we have a branch of lens li, this model has a single parameter mu, and we're going to say that the number of mutations that we observe on this branch of length li is going to be Poisson distributed with rate li times u. So, it's a really sort of perfectly natural thing to assume. And in terms of what that looks like for And in terms of what that looks like for branches of different lengths here, shown on the x-axis, this represents the number of mutations that you get in this model for branches of different lengths. Okay, so that's a very simple model to use, and it makes perfect sense if you're a bit familiar with Poisson processes. The difficulty, of course, is that I'm sure again many of you have come across this, that this model is often not fully satisfactory. And that's because we have some variations in the clock rate. In the clock rate in different parts of the tree, very often. So, one of the sort of pioneering pieces of work on this topic was this very famous paper by Alex Heidelmond in 2006, where they realized there was this difficulty and they developed this new model, uncorrelated relaxed clock models. And there are alternatives to that, but I'm going to focus just on this for the purpose of this talk because it is by far the most widely used type of clock models. Type of clock models for relaxed dating in genomic epidemiology. So, the idea in this model is that each branch is going to have its own mutation rate, let's call it Mi, and those MI, they are all independent and identically distributed from a certain distribution with mean mu and variance sigma square. Okay, so a simple example: if mi for each branch is gamma k theta, then when you combine this with the fact that And when you combine this with the fact that the number of mutations is Poisson with parameter mi times the length of the branch, we can infer the distribution for the number of mutation on that branch, and it turns out to be a negative binomial distribution. And what that looks like compared to our previous street clock model shown here, it looks something like this, shown for different sort of levels of relaxation. You can see that the distribution for the number of mutations that we get on branches of different lengths becomes more and more. On branches of different lengths becomes more and more sort of diffuse as you increase the sigma square, the variance of the variance of the relaxed clock. Okay, so this is really, again, I would expect many of you to be familiar with this, but what sort of surprised me when I was thinking about this a couple of years ago now is this. I mean, if you consider two branches of lens L1 and L2, and let's call X1 and X2, the number of mutations that you would get. The number of mutations that you would get on those two branches, you would kind of expect that x1 plus x2 should be distributed in the same way as the number of mutations x on a branch of lengths L1 plus L2, right? And I'm going to call this property, the additivity property of a clock model. Okay, so you would expect that because after all, whether a branch is split in two or not depends completely on which sample you include in your tree. If you add more samples in your tree, then you will sort of be breaking down some of the branches. Trees, and you will sort of be breaking down some of the branches, and you would expect this not to change the distribution for the number of mutations on different sort of parts of the tree. Okay, so this additivity property, it's easy to show that it holds for the street clock model. If you consider two branches of lengths L1 and L2, the number of mutations are X1 and X2 distributed like this. And the number, the sum of X1 and X2 is easy to show. It's also a Poisson distribution with rate. distribution with rate L1 plus L2 times u. So that's the same thing as a branch of lens L1 plus L2. So that makes sort of sense. The strict clock model has this additivity property. But if you think about the relaxed clock model as I've just defined it before, it doesn't have the additivity property, which was a bit of a surprise to me. One simple way to see it is to just consider the expectation and the variance for the number of mutations xi on a branch of length i. On a branch of length i. So the expectation of xi is going to be equal to mu li, the same as in the street clock model. And the variance, if you use the law of total variance, you can show it's equal to mu li plus sigma squared times li square. And because we have this term li square, you can see this is not linear with the branch length li. So that means if we consider now two branches of lengths L1 and L2, we get that the variance for X. For X is not going to be the same as the variance of a branch of length L1 plus L2. So specifically, the variance for a branch of length L1 plus L2, length L, is going to be greater than if you add two branches, the number of mutations happening on two branches of lengths L1, L2. So as we break down the branches, we remove some of that variance. Okay, so this relaxed clock is not additive, and that's we can discuss, of course, if we should worry about that or how important it is. But what's striking is that it's actually very simple to build a relaxed clock model that is additive. And the way to do it, which is this model that I'm proposing today, is the additive relaxed clock model, as I call it. It's a model with two parameters, like the relaxed clock model, mu and omega, let's call them. And this time, the very specific mutation rate, this MR, The very specific mutation rate, this Mi that I had before, has the expectation μ as before, but the variance is going to be proportional to this relaxation parameter omega, but also inversely proportional with the branch length li. Okay, and we will see that when you do that, we get the additive property. So, for example, if we use a gamma model with parameters such that we have those two expectations. Those two expectations is variant. We can show that in this case, using the sort of conjugacy of the gamma with the Poisson, we get that the negative binomial, we get a similar negative binomial distribution for the number of mutations on the branch, xi, which is this model. So that's one type of additive relaxed clock model. Okay, so now let's sort of check: is this actually additive, this model? So, one simple check we can do first is to check that the expectation and the variance are additive. The variance are additive. So, the expectation of Xi, we can show as before that it's still equal to μ Li, so there's no problem there. It's the same as in the strict clock model and the previous flat clock model. And the variance of Xi, again, using the law of total variance, we can show it's equal to mu Li times 1 plus omega. And this time it is linear with the branch length Li. So that means if we consider two branches and we add up the mutations happening on those two branches, it is going to be the variance is going to be the same as if we had a single branch. Same as if we had a single branch of lengths L1 plus L2. Okay, so the expectation add up, the variance add up, but we need more than that. Of course, we want the whole distribution to add up. And if you use the model that I had on the previous slide, this negative binomial, with the second parameter equal to the same thing in the two sort of branches of lengths L1 and L2. We know that the distribution for x1 plus x2 in this case is also going to be negative. In this case, it is also going to be negatively binomial with those parameters, which is the same as the number of mutations on a branch of length L1 plus L2 by definition. So we have proved here that the additive property holds for this simple additive relaxed clock model that I proposed. Okay, and if we look at what those distributions actually look like, so I'll sort of summarize them all here. We have the strict clock model here at the top, we have the relaxed clock, the old. We have the relaxed clock, the all relaxed clock, if you want, with different levels of relaxation shown here, here and here. And this is the additive relaxed clock model with different levels of relaxation again here, here and here. And you can see, of course, that those descriptions are different from the relaxed clock. They behave differently. I mean, they also consider to correspond to a relaxation, a progressive relaxation compared to the strict clock. Of course, we get more and more relaxation as omega increases. But we have differences in the properties. Differences in the properties. I mean, if you look at the long branches, for example, very quickly in the relaxed clock model, for a long branch, a branch of a long duration, we get that the mode is very small, that we expect a few mutations. And that doesn't happen in the additive relaxed clock model. The mode still goes up even for long branches. And conversely, if you look at the sort of really short branches here, we find that the short branches. Here we find that the short branches, there's not that much difference in the distribution of the number of mutations for very short branches, even when you increase the sigma square here, here, and here. And for the ERC, there is more of a difference. You can see that this distribution is sort of being more shifted higher up. Okay, so clearly there are differences between those models. And so the question becomes, well, does it matter? I mean, is this ARC model really superior in any way to the relaxed clock model? Is it important? Is it important what I'm presenting here? So, one way to test this, of course, was to implement these different models. First, we implemented them in my own software for building dated phylogenies called backed dating. Eric Vols also implemented it in his own software called GLater. And finally, we created an implementation as a module in BIST2. Okay, and so to show you some results on simulated data sets. You have some results on simulated data sets comparing the relaxed clock, the old relaxed clock on the left, and the new ARC model on the right here. So, what we did is that we simulated some dated phylogenies under the qualities, and then we simulated some mutation on this. And let's assume for now that we know exactly which mutations happen. That means we observe exactly the exact phylogeny, the exact undated phylogeny. So, this is what works well when you're using backdating or tree data because they take as important. Backdating motor data because they take as input not the sequences but an undated phylogeny in order to build a dated phylogeny. Okay, and so what we see that in the relax clock model, the TMRCAs, especially when the real relaxation was high, we get really, really wide estimates for the CMRC, where the correct value here was zero. And for the ARC, we get something much more much more stable. I mean, yes, we get an increase, of course. More stable. I mean, yes, we get an increase, of course, because as there's more and more relaxation, we have more and more uncertainty, but the uncertainty is really exaggerated in the relaxed plot model. If we do the same thing using BIST2 this time, so using not just undated hylogenies, but using sequences and inputting that into BIST2 under both a relaxed clock model and the new ARC model, we get again that the TMRCAs are, there's more uncertainty. There's more uncertainty in the TMRCA using the relaxed clock compared to the ARC model. And we also get that the clock rate is being estimated not very well, again, especially when we have high values of the relaxation parameter in the ARC. So we get mutation rates. Here's a remutation rate was five, and you get really broad intervals of confidence or credibility for new when you use a relaxed clock model, whereas for the ARC, it's Use a relaxed clock model, whereas for the ARC, it stays much more stable. So, on those simulations, there's no question really that the ARC behaves better. And in fact, one more sort of test we can do is to compute the deviation information criterion to sort of compare the two models. And when we had a high relaxation, high enough to be detected, then we find that the ARC is always preferred compared to the O-relax cluster model in the simulations. Okay, so that's just results on simulation data set. Results and simulation data sets. What about real data? Is all of this relevant when we analyze real data? So we looked at achieved data sets, of course. I mean, time will tell when we apply this to more and more data sets at what extent it's important. But just to show you quickly a couple of results. So this old data set from a paper by Cat Holt in 2013, made of 155 genomes of Shigelasoni iwi, was previously estimated. The TMRC was estimated in this paper by Beast and found. This paper by Beest and found to be 1982 with an interval of 78 to 86. When we apply backdating with the all-relax clock model, we get a very, very similar estimate, which makes sense because it's the same relaxed clock model from Drummond detail that was used in the original BIST analysis. But now, if we do the same analysis using the ARC, we get pretty much the same mean estimate, but we get a tighter interval for the dating of the route. Dating of the route between 1980 and 1986. So we have gained a little bit of precision in terms of the estimate of the dating of the common center of this whole data set. And furthermore, if you do simply, if you compute, if you compare those two models using the DIC once again, you find that the ARC has a smaller DIC, which means that there is conclusive evidence in this case that the data is better explained by the ARC. So this suggests that the ARC is a ARC is a better model and is the one that really applies to these data sets more than the old relaxed clock model. Just one more example on the redataset. We also applied this method to a data set by Wong et al. in 2015, where they were looking at similar typhi. And in that paper, they focused completely on the single clade of typhi, H58, and they estimated a clock rate using Beast for this. Clock rate using beast for this clade. And they decided not to try to date the whole of Simon at Typhi because they said, and indeed you can see it here, that the temporal signal in the whole of Typhi, which is what we show here, if we exclude 58, the temporal signal is very weak, even non-existent, you could say. And so they decided not to even attempt any dating. But of course, we know that this type of root-to-tip linear regression technique is not really powerful in terms of detecting the temperature. In terms of detecting the temporal signal. So, we still attempted to date Typhi using the ARC models that I've described. And we found that you can actually do that. So, based on a thousand genomes of Typhi, we tried it both using the all-relax clock model and the new ARC. And we found again that the ARC explained the data a lot better with a much smaller DIC. And what's nice is that the clock estimate we get is not very different. It's a little bit less, but not very different from the one that they estimated in the H. Very different from the one that they estimated in H58. So it seems to make sense that you would expect to have roughly the same mean estimate in Tai Chi and in that clay that they have worked on before. And so we were able to produce an estimate for the dating of the whole of Typhi around 1166 with a fairly tight confidence of interval. We also double-check the significance of this temporal signal using randomization of the sampling date. Using randomization of the sampling dates, which is a more powerful method than the one shown in the previous slide with a linear regression, and we found that this is significant. Okay, so just to conclude, so what I've shown today that strict clock models are additive, but the all-relax clock model that are being used by everyone are not. And so we defined a new ARC model that has this additivity property. We implemented it in Backdating, Tridata and BIS2, so it's available for everyone to use, freely available. Everyone to use, freely available. We found that ARC gives better results on simulated data sets and also on those few real data sets that we tried to apply it with. We found that it gives better estimates of both the clock rate and the dating and that it is supported by model comparison. And so if you want to know more about this, the paper describing this study has just been published in Molecular Biology and Evolution, and you have the reference here. And that's all I have to say. Thank you for your attention. Okay, thank you, Xavier. We probably have a time for a couple of minutes of questions, so I'll guess I'll read from the chat. So Toby asks, is the ARC equivalent to a model where each short fixed length segment of a branch has an IID mutation rate? Yes, it is. Yes, it is. Absolutely. It's exactly that. Yes, yes, yes. That's right. If you consider an infinitely divisible model, that's exactly what you get. You get an ARC. That's exactly what you get. You get an ARC, yes. And that's something we described in the paper. So, yeah. And Alexandria asks: From Kolmogorov's consistency, the additive property would imply that the existence of a statistic process such that the parametric negative binomial shown was the marginal. Is the underlying process of that a known one? It would probably help if I could read the question rather than. Okay, if I stop sharing, I think I can read it. Okay, okay, I've got it. Stop sharing. I think I can read it. Okay, okay. I've got it. I've got it now. We imply existence of a stochastic process such that the parametric negative binomials shown are the marginal. Is this underlying process a known one? Okay, so that's something that probably we should say for the discussion after, if you don't mind, because I would have to think a little bit about that. And I know we're look, we don't want to delay the next talks. Let's come back to this question in the discussion at the end of the session.