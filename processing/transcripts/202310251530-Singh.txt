So, today I'm going to talk about some recent work done together with my PhD advisor, Dr. Vansa Kodali, and Dr. Martha Delati, who was at the University of Portsmouth in the UK. So you listened to Vansa's talk earlier today. So this will have more or less the same greed entities for the finite dimensional part. And I'll be specifically focusing on the case of the Rashi-Kota model and describe the construction for the Lagrangian multi-farm. The construction for the Lakrangian multiform for this particular model. So, here's a brief outline for the talk. So, I'll start by describing what both our models are and what makes them interesting. Most of you would have listened to Dr. Benwa Visitu's talk yesterday, so you might have some familiarity with what they are. So, I'll describe in some detail the specific model that we'll be looking at, which is one of the simplest cases of the Rashikuda model. And then Model and then proceed on to the construction of the Lagrangian multiform for it, and that would require us to talk about the algebraic background. So, Vanso already described the algebraic ingredients, which come from leader algebras. So, I'll try to push it slightly forward and describe a bit of the recipe as well. Then I'll describe the construction of Lagrangian multiforms for a large class of finite dimensional integrable systems. Dimensional integrable systems, and then describe in particular the construction for the rational Goda model. And towards the end, very briefly, mention some connections and possible generalizations. All right, so Goda models are what we are going to talk about. So they are a general class of integrable systems associated with quadratic Lie algebras. So these are Lie algebras that are equipped with a non-degenerate invariant bilinear form. And they were introduced by Michel Goda in 1976. By Michel Goda in 1976 to describe quantum spin chains. So they are really nice because they are integrable. But what makes them even nicer is that they admit a number of generalizations. So of course the original one was a finite dimensional model with a skew symmetric R matrix, but you can generalize it to include cases where the R matrix is non-skew symmetric. And then you can generalize it to include a fine codon to a fine. To include affine codom to affine cases as well, which are based on infinite-dimensional algebras. So, another recent and very interesting discovery made by Benver was the realization that a large class of non-ultralocal integrable field theories can be reinterpreted as a certain class of affine Goda models. So, that opens up another set of possibilities of understanding non-ultralocal field theories better. Local field theories better, and then possibly even attempt to tackle the question of their quantization. So, our objective here is much more modest. We want to just look at the simplest case of the rational Goda model. So, it is the finite Goda model with a rational R matrix. So, the data that it's based on includes and includes a finite dimensional Lie algebra and a set of points on the Riemann surface. So the last matrix in this case is given like this. And the well-known quadratic Gotha Hamiltonians are essentially, they describe long-range spin-spin interaction, where the strength of the interaction is basically their relative distance on the Riemann sphere. Right? So, this is the case of the Rational-Goda model, and like all integrable models, and even these larger generalizations that I mentioned. That I mentioned. They have predominantly been studied in the Hamiltonian formalism, as is the case with most integral models. And of course, the Hamiltonian formalism has led to some profound, interesting discoveries about these models. But at the same time, knowing the fact that Lagrangians are pretty crucial to understanding physics from a different perspective, it would be nice to have a variational description of these models. So that is the question that we are trying to answer here. That is the question that we are trying to answer here for the case of the Rationale Roda model. So, that, as Vansa mentioned, requires us to use this notion of Plei Di algebras, which is due to Seminov Dejan Shansansky, which he gave in early 80s. So it goes like this. So again, this would be describing in some detail that Vansa has already talked about. You have a Lie algebra and you have a Lie bracket for the Lie algebra. To itself. Now, say that the linear map that you have is a solution of the modified classical Jan-Baxter equation. Then you can define a skew-symmetric bracket like this. And it turns out that the skew-symmetric bracket satisfies the Jacobi identity. So one way to look at the modified classle-Yang-Baxter equation is that if you were to define a bracket like this, then the condition for this bracket to be satisfying the Jacobi identity is essentially. The Jacobi identity is essentially the modified classical Young-Baxter equation. Right, so now what this linear map has done, which is the solution, the solution of the modified classical Young-Baxter equation, that it has allowed you to describe a new Lie bracket on that same vector space, on that same Lie algebra, right? So now you have a second Lie algebra structure on that same underlying vector space. So we'll denote it by G sub R and this particular pair of the vector space with The vector space with this newly bracket that we have defined, we'll call this parallel eta algebra. All right, now the way you have, we have a set of adjoint and co-adjoint actions corresponding to the original Lie structure. We have a set of adjoint and co-adjoint actions corresponding to this new Lie algebra structure that we have. Fine, then what we can do further is that do further is that for every object that lives in for every object that lives in the Lie algebra do something very smart we can take this linear map and define two photo maps using it like this and it satisfies a very useful relation which is that the difference between these two maps will give you the identity map which means that for every object from the Lie algebra you can decompose it uniquely like this right It uniquely like this, right? So, this is something that will come in handy when we are describing construction. Now, something about the group aspects. So, of course, the originally algebra has a Lie group structure corresponding to it. Now, corresponding to this new Lie algebra, we have a new Lie group, right? And the homomorphisms that we just defined over here give Rise to the homomorphisms at the level of the Lie algebra. So these give rise to some homomorphisms at the level of the Lie group, which further allow you to define a multiplication in this particular Lie group. So it's something I would like to highlight over here, like because this multiplication is something that will feature in the Lagrangian multiform we are describing. So I'll mention it again when it comes to that, but it's essential to note that this multiplication. But it's essential to note that this multiplication is not the same as the multiplication in the original League group. So, even though, as such, they would have the same structure, the two League groups, the multiplication in the two League groups differs. Now, again, the way you would have a set of adjoint and co-adjoint actions corresponding to the original Lie group, you have a new set of adjoint and co-adjoint actions of the Lie group on the corresponding algebra. The Lie group on the corresponding algebra and the dual space. Now, further and even more crucially, and something that lies at the heart of this construction, is that the way your Lee bracket, your original Lee bracket, would have allowed you to define a Liboiso structure, a Liboissor bracket on the dual space. Now that second Leap bracket available to you, you can define an additional Leap OSO bracket on the dual space. Leapo-so bracket on the dual space, right? So your original Leepo-So bracket would have looked like this. Now you can define a new Lee Poisson bracket, which would involve, which would be defined in terms of this new Lee bracket that you have. Now the co-joint orbits of this, the action of the orbits of the action of this group on the dual space will have a simple structure, will have a symplectic structure. And this will essentially turn out to play a role in defining the phase space of the model that we would want to construct the multi-form for. Would want to construct the multiform for. Right, so we need one more ingredient before we can start doing meaningful things with it. So that is having a bilinear form, like having a bilinear form with all the nice properties of being non-degenerate, symmetric, and being add invariant. So what we will use this for is allowing us, this will allow us to identify the original algebra with the dual space and the appropriate co-adjoint and adjoint actions. And joint actions. So now comes the theorem by Sebinovty Anchansky, which is that if you have some add invariant functions on the dual space, they will be in involution with respect to this newly Poisson structure in the dual space. So note something important here: that if you were just to take the originally Poisson structure, the originally Poisson bracket, and you Poisso bracket, and you were to think of these functions, then they would simply be Casimis on that on that corresponding to that leapo-so bracket. But now trivial, right? Now, if we were to look at the equations of motion for some object that lives in the dual space and look at the equations of motion induced by these ad invariant functions, so these ad invariant functions H, and look at the equations of motion they generate, they would take these forms, which can They would take these forms which can be written in all these equivalent forms. Now, the nice thing is, and something that will directly establish the connection with integrability in a very explicit way, is that once we use the bilinear form to identify the appropriate spaces and the appropriate co-joint and adjoint actions, then these equations of motion that we described using this newly post-war bracket turns out. Bracket turns out to have this very nice lax form, right? Where this object is some element from the dual space, and this other object from the lattice pair can be described in terms of the gradient of those functions mapped to the correct space. Right, so this essentially goes down to boils down to this fundamental message from this picture that we would want to take is that once you have a solution of the modified classical young. A solution of the modified classical Young-Baxter equation. It allows you to define a newly Poisson structure and newly Poisson structure on the dual space. And then the orbit of the coadjoint action of that of the leak group, of this new leak group on the dual space is essentially your phase space of the model. So the way it would work is that you would pick up some elements from the two. That you would pick up some element from the dual space and you would look at its R-code, not the co-joint action, but rather the R-co-joint action of a genetic element from this new group. And that will define for you the phase space where you will define all the dynamics of the model. So, people who would be familiar with the Adler Costa Sein scheme, which is introduced. Which is intricately linked to many of the well-known models, like Obentur Ching famously, turns out to be a special case of the lead algebra construction. So in fact, the lead algebra is more of a generalization of this particular scheme. So what you do here in the AKS scheme is that instead of looking at in a generic manner, you fix this particular element to be in one of the subspaces. So rather than allowing it to be So, rather than allowing it to be a generic element of the entire subspace, you choose something that is in one of the subspaces, which means that when you're looking at the orbit of the co-adjoint action, only one of the subgroup, the corresponding subgroup to whatever space, dual space, dual subspace you're choosing, will only that will play a role in the co-joint action. So, in this particular case, you will get a co-joint orbit that lies in. Orbit like that lies in this dual subspace that you chose your original element to be in. So this AKS scheme is a special case of the more general lead algebra construction. So something that I missed mentioning earlier is that the lead algebra that we define is not the same as a Leby algebra. So Leba algebras are, of course, way more famous than Leida algebras, and they have an entire classification for them. They have an entire classification for them. But the way these two structures fundamentally differ is that when you're dealing with a Lieb algebra, you say you define, what you do is you define a new Lie structure, a new Lie bracket on the dual space, and like here where you are defining your Lie bracket on that same space. But what the Lieb algebra is restrictive in a sense, what it is restrictive in is that it forces you to work with skew symmetric R matrices. Symmetric R matrices, and nothing in lead algebra says that you only need to be working with few symmetric R matrices. So it gives you that flexibility of incorporating a wider class of models, particularly those associated with non-skew symmetric R matrices as well. Fine, so we have this lead algebra set up, so it's time to put it into use. But everything that we have talked about so far has been about a single time, right? So how do we extend it to a multi-time? Do we extend it to a multi-time picture? So, of course, the answer is already there in the involativity theorem. So, the involativity theorem of Seminovty and Shansky says that if you have any two add invariant functions on the dual space, then with respect to this new Liposa bracket, they will be an involution. So, to define a multi-time version of your equations of motion, all you need to have is a sufficient number of such independent functions. Dependent functions, and then you can define compatible time flows associated with all these evarient functions, and then you can write down a multi-time version of your Lax equation. Fine, so the thing is that we have these integrable hierarchies, but it's still Hamiltonian at this stage. We don't really have any hints of Lagrangian at this level. So, this is the question that we answered in this work. That we answered in this work with Van Dasa and Martha. So, we give a Lagrangian multi-form, a Lagrangian one-form for finite-dimensional system that actually works, that does the job. So, the key ingredient lies in the fact that we want to define things on a co-joint orbit that lies at the intersection of the two different structures: on the original Lie algebra structure and this new Lie algebra structure that. Structure that is induced by the solution of this new solution of the modified Young-Baxter equation, right? So we have a we define a Lagrangian one form with a kinetic part like this. So the good thing is that at the previous level itself, the construction would give out for you a lats matrix, right? So you would pick up some element from the dual space, which would be non-dynamical, some fixed element from the dual space, and it would define for you the phase space, right? So the Lax. Find for you the phase space, right? So the Lax matrix is where the Lax matrix lives in the phase space. So taking the R-co-joint action of this object lambda will fix the phase space for you. And then you will take these field elements from the corresponding group. And these are the objects that will contain the dynamical degrees of freedom. So the dynamics all lies here. And these are the objects that will define the phase space for you. So you write a kinetic term like this. So, you write a kinetic term like this. Again, a point to note that because we are working at the intersection of the two different structures of, so you have two different Lie groups at play, this particular multiplication that we have has a crucial role to play. So, you can't really take the usual multiplication for the first Lie group. This multiplication would correspond to the second Lie group. So, you have a kinetic and you have a potential part to the Lagrangian-Wand form. Now, what do we do about the potential part? Now, what do we do about the potential part? So, of course, they are naturally given by the lead algebra construction. These would be the add-in variant functions on your dual space. Right? So, how do we know this works? We know this works because if we consider the variation of the Lagrangian, it gives you equations of motion which take this very nice lax form. And these would match exactly with the Lax equation that your lead algebra construction. That your lead algebra construction would give. So, this is the result in the paper. And then there are a couple of more results that Vansa has already gone through, so to do with the closure relation and the fact that the closure relation and the possible volatility are related to each other. So, I'll not describe them in detail because he saw them earlier today. So, I will go ahead and focus on the construction of the rational, the construction of the multi-form rational model. Construction of the multi-form Rational Gotha model. So, just a quick recap. So, my Rational-Gotha model is defined by the data of Sam Lee algebra, right? So, this is Sam Lee algebra G and a set of points on the Riemann sphere. So, these are my sites on the Riemann sphere. And we have a particular Lax matrix like this. Now, these Lax matrix for the first time flow, this corresponds to these particular Lax equations. To these particular Lax equations. So, a good check for the Lagrangian multiform that we'd be constructing would be to see if for the first time flow we get the very same Lax equations or not. Right, so now again, this we need to create an appropriate algebraic setup based on the lead algebra framework to incorporate whatever we said in the general construction to incorporate that for the Rational Gotha model. Right, so we need to fix the algebraic data. So, what is it? We need a Lie algebra and the Algebra, and we need a linear map, right? So, the linear map is what would be a solution of the modified Young-Baxter equation and will help you define a new Lie algebra structure, a new Lie algebra structure on the underlying Lie algebra. Right, so let's fix the data first. So, we have a set of points on the Riemann sphere, which are the sites of the model. So, these are the sites which define the spin-spin interaction. So, these live on the Riemann sphere. And then we have the algebra of the G-value. The algebra of the G-valued rational function in the formal variable lambda with poles in this particular set. So, this is the algebra where your Lax matrix will live, and this formal variable lambda is essentially the spectral parameter of your model. Now, around each of these sites, around each of these poles, we'll define these local parameters. So, the pole at infinity has a special play, it's distinct from these, and you'll define. Distinction these and you'll define, we'll define the local parameter in different ways. In fact, we have a double pool over there, but I won't go into the specifics of that. And for the rest of the discussion as well, I will show the construction for the infinite part as well, but I'll mostly be talking about the poles at finite distance to keep things simple and fast. All right, so we have defined this algebra and we have defined a set of points. We have defined a set of points next. So, around each of those points, we define a loop algebra. Around each of these points, we define a loop algebra. So, what is this loop algebra? This loop algebra is the algebra of formula series in the local parameter with coefficients coming from the underlying Lie algebra. And then it has a Lie bracket like this. But of course, we want to define. But of course, we want to define the Goda model on the whole Riemann sphere, which includes all the poles, all the sides of the model. So, what we would do is we would take a direct sum of all these loop algebras that we have defined locally, and this will be the Lie algebra that we will work with. So, the elements here are actually toppled. So, it's a direct, this algebra is a direct sum of this. These loop algebras, so an element here will, elements in this algebra will be tuples where each of the intro. Tuples where each of the entry will come from the corresponding local loop algebra. Right now, to be able to define a linear map, we first need to fix a decomposition of this Lie algebra. So we will define a vector space decomposition. So for a linear map that we'll define using this decomposition, all we need is a vector space decomposition and not really. Uh, decomposition and not really an Lie algebra decomposition. But what, of course, is true is that these two spaces that we have in the vector space decomposition are sub-algebras of this Vicar algebra, right? So this is how we define these two sub-algebras. So we have this algebra in the plus part, which is the algebra of formal theater series. So again, elements here will all be tuples. Here will all be tuples, so where each of the entries will come from the corresponding loop algebra. So this here is in the plus part is the algebra of formal Taylor series in the local parameter. And in the minus part, it will be the algebra of polynomials in the inverse of the local parameter. So I'm skipping the details for the pole at infinity, but because of how we have defined the local parameter, which terms are contained in which part of the sub-algebra will differ? In which part of the sub-algebra will differ slightly. So, for the talk, let me just focus on the finite points. All right, but now one thing we should notice is that the Lax matrix that we have and that we want to construct is actually an element of this algebra FQ that we defined. And it's not really a topple, it's a Lax matrix which is a rational function, right? So, what we need to do is we need to embed this into this loop algebra we have defined. Now, why do we Loop algebra we have defined. Now, why do we do that? We do that because this algebra is somehow not suitable for working with the core joint orbit construction. So, this is the Lie algebra we need to be really working with to doing all the core joint orbit stuff. So, we embed this algebra into this loop algebra, and what we get in return is the vector space decomposition of the same space. The composition of the same space. Right now, the thing to notice here is that this is again a tuple now, so is this. And then we can define the projectors corresponding to this decomposition. And of course, these projectors are no longer same as the projectors for this particular decomposition. So these two decompositions are fundamentally different, even though the two sub-algebras again just contain tuples, but Tuples, but what goes inside the tuple differs in the two cases. Right now, what we do, we have defined the decomposition, we have defined some projectors, and we need an R matrix to describe the, to equip our underlying D algebra with the di algebra structure. So we define the R matrix like this, which is the difference between the two projectors. Now, the thing to notice here is that you will very soon see that. You will very soon see that this again boils down to the simple case, the simpler case of the AKS scheme, where you are going to pick only an element from only one of the subspaces. But the good thing is that it's very easy to show that this particular projector will be a solution of the modified classical Young-Bucksler equation. Right? So, again, if you would remember from If you would remember from the original discussion about the lead algebra, we need a bilinear form with all the nice properties to be able to identify all the algebras with the dual spaces and all the appropriate joint and co-joint actions. So what we finally, so we define a bilingual form like this, which is essentially defining it for each of the loop algebras and taking the appropriate residue and then summing the residues up. All right, now we have a decoding. All right, now we have a decomposition for the dual space, and after appropriate identification, and also noticing the fact that these two sub-algebras here, both of them are maximally isotropic with respect to this bilinear form. So what it finally gives you is that you can identify these two spaces, right? And we know that the embeddings, this is the place where the embedding of the lattice matrix lives. So this is the The lattice matrix lives. So, this is the space we would want to be working with for our construction. Right, so what we are finally going to do is pick an element from here, and we are going to look at the orbit of the co-adjoint action of the corresponding subgroup on the subspace, and that should give me the Lax matrix. So, that is what turns out to be the case. So, after all the appropriate identification of the operators and defining my R code joint action appropriate. My R code joint action appropriately, we have what we need. So we have a way of constructing an embedding of the Lax matrix starting from some element of the underlying dual space. So this is the object that we choose from the dual space. And then we look at its embedding because again, the core joint orbit construction requires us to embed this thing which lives in the algebra of rational functions. In the algebra of rational functions, it needs us to embed this into this particular algebra, and then we look at the co-adjoint orbit of this, and this gives us the embedding of the Lax matrix that we wanted. Right, so this sets up all the ingredients we need. So, we have defined the Lax matrix. We know what our field element should look like. So, our job is done. We can go ahead and write down the Lagrangian multiform. We have the Lax matrix. Of course, we are looking at Of course, we are looking at the embedding of that in this particular picture because, again, we are defining this Lagrangian multiform on the co-adjoint orbit. So this is what goes in place of the Lattx matrix, and these are the objects that go into in place of my field elements and the corresponding time derivative. Right, now it turns out that it turns out Turns out that it simplifies, at least the kinetic part simplifies to this very nice and simple form. And what we have is the Lagrangian multi-form for the rational model. So of course, if you remember, the Lagrangian for the first time flow was something you would have seen in Benoit's talk yesterday. So this generalizes it to having a Lagrangian coefficient for all the higher time flows as well. Higher time flows as well. So, of course, you need to be to write down the multiform explicitly. You need to specify what these functions are. So, for the first and the second time flows, you can in fact do it for all of them, but this is how they look for the first and the second time flows. And then you can go ahead and write down the Lagrangian explicitly and then vary the Lagrangian coefficients and get the equations of motion from them. Them and they will turn out to be the laxic patients that you would have got from your Hamiltonian picture as well. So, which sort of wraps up the job. You can do more things. You can check the closure relation for this, and it will turn out it will satisfy the closure relation, and which essentially puts all this on a firm footing of putting together all the ingredients of the classical Young-Baxter equation, having the lead algebra structure, as well as the ingredients from the Lagrangian multifarm theory side of the closure relation and. Side of the closure relation and the compatible time flows and everything. Right, because I'm out of time, I'll just take one quick minute to mention some future directions. So of course, the whole big thing about talking about lead algebras is that they allow you to work in non-skew symmetric R matrices. But what we did here was only working with skew symmetric R matrix. So that's something that So, that's something that one could easily attempt because your lead algebra picture allows you to do that. So, one good candidate to try would be the cyclotomy-Godor model, which is based on a non-skew symmetric R matrix. Now, the other interesting thing that Van Saul also mentioned in his talk was this possibility of constructing a Lagrangian multiform for a fine-Goda models, which again, going back to Benoit's work on its To Benoit's work on its reinterpretation as non-eltradocal integrable field theories would possibly allow you to write down Lagrangian multiform for non-ultradocal field theories. And then a very hopeful thing would be to imagine that this would somehow allow you to look at a path integral quantization of non-ultralocal theories. Right. And then one quick final point. This is again in reference to Benoit's talk yesterday. So based on all the four teacher assignments and the 3D mixed 4D churn Simons and the 3D mixed BF theory picture. We have seen how integrable models arise out of them after doing introducing some defects and taking into all the gate symmetry considerations. So it would be nice to see where the lead algebra construction fits in that picture, or like whether the two methods are completely different from each other. Probably there is some die algebra ingredient in the background of all the gauge theoretic approaches as well. Gauge theoretic approaches as not. That's all I have to say.