Okay, hello everyone. So I am Olivier from France and the talk is about large-scale parallel geography and applications to COVID-19. So I will first discuss the methods that we implemented in the past ML software and we first published. Software and you first published what one year ago about maximum likelihood-based ancest accounts, ancestral scenarios, and this account for uncertainty in the scenarios. And then I will explain how we will account for sampling bias using the phylogenetic diversity, and we will apply this to coronavirus data. So So, okay, that's it. So, to make it clear, an ancestral scenario is a rooted file syntax T with branch length, and most of the time the branch tree is dated. Tree is dated and the tree is inferred from data from the for the tips and from an upgroup character or morphological character or geographical character etc. And the goal is to predict the state of the character denoted as I for every node of the tree denoted as n and this will be And this will be used to study the emergence of molecular function of phenotypes and, in our case, of biogeography. And the second aim is to summarize the results because if we have very large trees, which we have with coronavirus, we have to make a kind of quick summary. And I explained that with this simple example, assuming that we are using parsimony. We are using parsimony. We know the state of the tips: Brazil, Europe, Europe, Africa, and Africa. And using parsimony, we can infer using the fitch algorithm the state for that node. And here we hit it between Brazil and Europe. Because we have Brazil here, we decide for Brazil. Here we hesitate first we have to here we hesitate between Africa and Brazil and here between Africa and Europe and we do that again. And we do that again. And we conclude that we have Africa on the top of the tree. And now, because we have Africa on the top of the tree, we can go down and we can decide because we have Africa here, that we have immigration here, Brazil here, Brazil here, immigration there. And we have reconstructed everything about the ancestral scenario. But now we can summarize this scenario using this type of representation when we have a cluster. Representation: When we have a cluster at the root of the tree that corresponds to three tips, and from that cluster, we have a second cluster corresponding to Brazil with two tips, and then there is a transmission from Brazil to Europe and from Africa to Europe with a single tip in each of the clusters. And with parsimony, this is not the case in that example, but this can be the case. We may have ambiguities and uncertainties. So in a maximum. So in the maximum record framework, we have a Markov model, denoted as M, and M is normalized, as usual in phylogenetics, and we have what I will call a global rate or scaling factor because we have to, which basically express the average number of migrations per year with data tips. We have to account for the fact that the model is normalized. And then basically, there are two solutions. We can use the joint distribution and select the scenarios that have the highest likelihood or posterior likelihood. And this can be done by dynamic programming efficiently. Or we can compute the marginal posteriors for each of the nodes independently using the pruning and related algorithms. And then we have again to. And then we have again two solutions. We can use a maximum a posteriori prediction called map, which is locally optimal. By locally, I mean that we are looking at a given mode, assuming that M is a true model, and optimal means that it has the lowest probability of error. Or we can decide to have a probabilistic predictor. And then, again, if M is the true model, the posteriors are locally optimal for the given node. Given node, and this optimality can be assessed using different criteria, for example, the surprise R that is used in information theory or the various codes that will be used. Then our goal here was to be in between these two extremes. Because if we have a unique prediction, we do not account for the fact that there are billions of trees with similar lines. Billions of trees with similar likelihood. And when using probabilistic predictors, it's hard to visualize and interpret the results. Then the goal was to account for uncertainty, to have some guarantee in the decision theory framework, to have results that are easy to visualize and interpret, and to be able to manage victories with dozens of thousand tips. And then we use discrete probabilities, for example, if probabilities for example if we decide for a unique prediction the probability 0 0 1 0 with full state or if we decide to predict three states we use a probability of a third for each of the states and zero for the last one and we use the briar score i will explain what this means this was invented in the 50s for weather forecasting because sometimes we do not know it will be rainy or sunny and you say okay the probability will be 0.1 You say, okay, the probability will be 0.5 for that one, 0.3 for this one, and 0.2 for Cloud Lee, or something like that. And the brief score was used, is used to assess accuracy of your predictions. And what we expect is to have a unique prediction in the easy regions of the tree, that is mostly close to the tips, and in difficult regions, most likely close to the root, we expect to have multiple productions. So the prior score has different forms, but one is very simple. This is the square of the Euclidean distance between the truth. The truth is 0, 0, 1, 0. The probability 1 corresponds to what is true and 0 to the other solutions. And we make the square square of the Euclidean distance between the truth and the prediction. And the prediction is a vector of probabilities. And the truth is unknown. And it is known that if you are using the marginal posteriors and if you compute the Euclidean distance between the truth that is unknown and that vector, that prediction vector, this distance is optimal, as low as possible. Then when using discrete When using discrete probabilities, for example, here we decide to predict two states, meaning that we have zero, half, half, and zero. And then the quality of that prediction is assessed by that distance here. And to have this distance as low as possible, we simply minimize the distance between the posteriors and these discrete probabilities. Because of the triangle inequality, Because of the triangle inequality, in some sense, we have some guarantee to be as close as possible to the truth that is unknown. So it works as follows. So first we again we have full states. We compute the marginals using the pruning and similar algorithms. We run these marginals, these posteriors, marginal posteriors, and this one is the highest. is the highest and then based on that we consider different solutions single single prediction corresponding to the first line this is the maximum a posteriori two decisions we have uh half half and zero zero three predictions a third for each of them and quarter we we decide to not predict anything that we do not know what is what is the truth and then we select uh this discrete uh probabilities based on probabilities based on the Euclidean distance between this vector and the vector of posteriors. And in that case, we predict that ABC because that vector is the closest one to this one here. So the time complexity is low. This is n times a square. And I will not show this to you, but with simulated data, the accuracy is very close to the To the accuracy that we get when using the posterior. So we have something which is much simpler because we have one or two or three or four predictions and that the accuracy remains quite high. So now this corresponds to predicting the states and now we have to visualize the results and for that we compress the tree and we have two operations. One is vertical. When we have states, When we have states here, for example here, corresponding to the same predictions, all these states are grouped together and they make this big cluster here with five tips. And for example, that cluster here with two tips corresponds to that node here in the tree. Basically, by compressing vertically, the tree will reveal the clusters. And the second operation corresponds to Corresponds to horizontal compression, we group together the clusters that are similar. By similar, I mean that they have the same ancestry and the same descendants. And for example, here we group the two clusters together and we get this arrow with a value of two, meaning that we have two independent transmissions from color blue to that colour. And here we have an And here we have another horizontal compression. This is a basic principle, this is implemented in the past ML software. Now we will apply this ideas to COVID-19. Here is that what you get from Nexttrain. I downloaded this image a few days ago. It looks very nice, but it's very difficult to draw any definitive conclusion from that. A definitive conclusion from that picture because the red color corresponds to America, North America. There are red colors everywhere. This is the same from Asia, that is blue, etc. So the first idea was to try if we could extract any general conclusion using pastime ancestral scenarios. And then I assume that you remember that paper which was published in Pen Ice by. Which was published in Penhouse by Forster, the Forster family, and they did this nice-looking network explaining the very beginning of the epidemics. This was published a Wednesday, the Thursday, and the Friday. The main press like New York Times, Telegraph, etc., diffused that announcement because of the conclusion of that study and the discussion. And Donald Trump tweeted that the Saturday. Truck tweeted on that Saturday because there was some discussion about the fact that some trains were more adapted to Asia than to America, etc. And the Sunday I was contacted by Marco Salimi with many others and we decided to make a response to that paper which was published in Penhouse by the beginning of May. And the title is there: Sampling Bias and Incorrect Routing Methylogenetic Network. Recruiting made phylogenetic network tracing of SARS-CoV-2 infections unreliable. And then the second goal was to correct for the sampling bias that we have with the data from the GISA. And this bias are huge. For example, you have here, for example, this is the example. In Italy, the number of genomes was 0.54% in the GISATE database. In the G-State database by APRI, and the number of reported cases was about 7.5%. But in the UK, it was just the opposite. We have 30% of the genomes in the glycide were from the UK, and the number of reported cases was 5.5%. Meaning that these biases are really huge, and we definitely have to correct for them. And the basic idea is material. idea is material and simple this is that we take all the data we make a big tree upon the data a fast big tree and then we subsample the each of the country in order to be as close as possible to the prevalence of the number of reported cases through time and to decide which train To decide which strain has to be removed from the tree, we use the phylogenetic diversity, and the phylogenetic diversity is the tree length, that is simply the sum of branch lengths. And this is a measure that is commonly used in species conservation. And for example, here we have Lembios from Madagascar, and you know that cute fellow corresponds to this very long branch with 60 million years of evolution. Years of evolution. And it is endangered. And obviously, this is a priority to preserve that guy. And this is much more important to preserve that guy than that one of these species here. But what we have with this strain is pretty much the same. We would like to select the strain that are exceptional. And another advantage of using the phylogenetic diversity is that the greedy algorithm is. The greedy algorithm is optimal. The greedy algorithm is extremely simple. You select the tip with the shortest branch, and you remove that tip and that branch, and you do it again and again and again until you have the desired number of tips in your tree. So what we did, we downloaded all the strains of the good quality by the end of April. Quality by the end of April. This was about 11,000. We inferred the tree using COVID-19, that is a software that we published recently, using an HMM profile, FastME, and RaxML. And we decided to conserve 2,000 tips. We decided to kept all the first strains in the tree because to have as much information as possible on the Information as possible on the origin of the pandemic. And then the algorithms select the strain with a certain branch. And if it belongs to a country month spare, but strain still have to be removed, it is removed as we take the next one, etc. and etc. And a tree was rebuilt from this S strain and it was dated using least square dating, which is quite fast. And because of this Because this printing process is random, we did that five times to check the robustness of the results. And here is what we obtain. And this basically corresponds to the first wave of COVID-19. So, okay, so we use countries. There was about 70 countries in the study. And because the tree has a number of political And because the tree has a number of polytomies, we resolve these polytomies using ancestral locations. This corresponds to these dashed arrows here. And the scenarios were very stable among the surplus sampled trees, meaning that for different samples, we basically got the same story. And this tree does not represent all the strains because we remove the details, the small cluster. The details, the small clusters, and for example, there are several clusters from the UK which are not shown. Here we have a single cluster from the UK which is here. And we check these results using contact and travel data. There are about 300 patients with such data in the GISAT database. And we checked that we had a good agreement between what we get in the tree and what we know about the patients. And what we know about the patients. And the agreement was 50% for the sub-sampled trees using phylogenetic diversity using the standard genetic diversity. The agreement was 35% and about 15% for the whole tree, meaning that we are in very good agreement with what is known about the patients because we don't expect 100%. Obviously, someone who has been in Italy can have been Italy can have been infected in France by a German guy, or we cannot expect underpurses. And very quickly, we see a Chinese origin by the beginning of January. We have a direct transmission to a number of countries. We have an interesting cloud here, originating from Canada, and this cloud mostly corresponds to... And this cloud mostly corresponds to the Washington state, where the epidemics was there and clear. And the G-CLAD, which has an eye transmital by the middle of January, and then it was transmitted to a number of countries, including France, and then from France to USA. And from USA, it touched again a large number of countries. Again, a large number of countries, and to make a very quick summary, there are three main hubs in this map corresponding to China, Italy, and USA. So, summary, using maximum acclude, it's possible to study very, very large data sets. We use that method for dozens of thousands of strains with HIV. There is a lot of signal, is all that. There is a lot of signal in all data sets we have been looking at because we allow for uncertainties, we allow for ambiguities in the prediction of the ancestral states. But surprisingly, for most of the nodes, we have a unique prediction, for example, about 2% with the studio showed to you. Accounting for something behavior is definitely important, and phylogenetic diversity offers a simple and efficient solution to do it. And we had good results. And we had good results with COVID-19. And for me, the next two directions to work on are being able to build much larger, accurate trees with 100,000 or 1 million sequences. And we are promising results with COVID. Another big problem with COVID is that we have a very low resolution and we have plenty of polytomies. And this is the main difficulty for not only for phylogenography, but for phylodynamics. Geography, but for phylodynamics and etc. So here are the three papers: one was published in Molecular Biogene Evolution. This one about COVID align, which uses a profile SMM to align the genomes, is available online. And the software not only aligns your sequences, but it provides some statistics about all your data set and about every individual sequence. Individual sequence. And we have a note that will be published in the proceedings of the French Academy of Science basically telling the story that I showed to you. So thanks to you, thanks to my collaborators. And your questions are welcome. Thanks, Olivier. So we probably have time to squeeze in one quick question. I'm happy to take them either by raising your hand or you can put them in the chat. Okay, well, let me ask one quick question before we go on, and it's a methodological one. I was wondering in this Breyer criterion that you're using for the distance between the prediction and the truth, is there an interpretation for that like there would be for, say, using KL divergence or some other way to measure the distance? No, the main feature is that there is a family of criteria. The surprisal in information theory is one among these criteria, prior is another one. And the main, all of these criteria are called proper scoring rules in the literature of decision theory in the 50s. And all of this, they have the property that if the model is perfect. That if the model is perfectly known, the marginals, marginal posteriors are optimal. Okay. So, but we use that one because we did not use the surprisal because the surprises are problem with probabilities that are equal to zero. And here we have a lot of probabilities equal to zero. So the brief score was meaningful. Moreover, we have this triangle inequality property. Inequality property which makes which ensure in some sense that we have an optimal prediction. Yeah. Okay. No, there is no, you know, when the criteria was proposed, the formulation was very different and looks very, it was not immediately obvious that this was equal to the square Euclidean distance. I'm pretty sure that the initial proposition had some interpretation, but yeah. So, I'm going to have to cut it off there. I'll just remind you: Olivier is in breakout room one after the meeting, after this session today. So, thanks again, Olivier. Thank you. We're going to move.