Okay, thank you for the kind introduction and the opportunity to be here to present my work. This is a joint work with Giacomo Albi from University of Verona and Giacomo Di Marco from the University of Ferrara. This is still a work in progress, so some things are not totally set still, but we are working on it. Okay, so you're all familiar with the Microsoft. You're all familiar with the microscopic models. They have been widely used for describing also social and economical political phenomena, not only, for example, gas dynamics. And the idea is that collective behaviors, if the number of agents is sufficiently large, can be described using the laws of statistical physics. Also, the process of opinion formation has attracted the interest of many researchers. The interest of many researchers, and there are several models for modeling opinions. Some of them use the cellular automata. So, a cellular automata is a lattice of cells or agents, individuals, in which each cell is linked to a neighborhood of other agents. And initially, each agent has its own opinion. And then this opinion evolves according to using two parameters. Using two parameters, persuasiveness, which is, as the word says, the ability of the agents to persuade other agents to adopt their opinion, and the supportiveness, which is the ability to support the agents who already have the same opinion. Other models instead describe opinion information using mean field model equations and they modelize the evolution of the distribution of opinions. In these models, we have In these models, we have a compromise process, which is based on what should be the human tendency to settle conflicts, at least usually, and a diffusion tend that takes into account some variation of the opinion that are not linked strictly to the single interaction with other agents. And following this path, we have many kinetic models of opinion formations that start from a two-body interactions between two agents. Two agents. As I would say, this interaction takes into account the compromise process between the agents and this diffusion that does not depend on the single interaction between the agents. Then they take the asymptotic limit and these methods derive a Fokke-Planck equation, which is satisfied by the distribution of the opinions among the agents. So we propose a model that fits in this category. And the first thing we do: This category. And the first thing we did is to model the evolution of the social contacts. From now on, I'm going to use social contacts, social media contacts, contacts interchangeably, also number of followers. And so the first thing, we analyze how this evolution of social media contacts goes, and we found an explicit analytical solution expression for the steady state. Then we modeled the binary interactions between The binary interactions between the agents that lead to the formation of opinions. We pass to the asymptotic limits in order to retrive a Fokker-Planck equation, which is satisfied by the density of opinion and context together. And then using Twitter, a data set from Twitter, we estimate the parameters appearing in our model. Until now, we were able to estimate the parameters regarding the geometer contacts, but we did not find still the parameters for the Not find still the parameters for the opinion formation. And in the end, I will show you some numerical simulations. Okay, so as usual, our model for contacts, we assume that we have a set of agents which are indistinguishable between them, and they are only characterized by their number of followers, C. So we are interested in the evolution of H. H is the density of Of the contacts, and this interval given a subset of L plus D is the number of people who have opinion, sorry, of contact C at time t. And from now on, we assume that our daily functions, this is a typo, this is an H, not F, is assumed to be normalized to one. So we are working with the probability distributions. In this case, we have some constraints. Some constraints on the number of contacts because we only can consider interactions that do not cross the boundary C equals zero because we cannot have a negative number of social contacts. And we also assume that there exists some bar C number of social contacts that's considered satisfactory or desirable, at least, by a certain number of the agents. So we describe the evolution of We describe the evolution of social media contacts of a single agent, taking into account the fact that the agents try to reach at least bar C number of followers of contacts. So this is the evolution in time of the social contacts of a single agent, where C is the number of contacts of the agents before the time step, in a sense, and C prime is the number of contacts resulting after the Contacts resulting after the time step. And the function phi, sorry, psi is a value function that we suppose to be bounded and concave, positive if we are above the desired number of social media contacts, negative otherwise. And it's bounded by these two values here. And then we have the random part, which is represented by the term. Represented by the term eta, which is a random variable that's not significant enough to produce a sensible variation in the number of social media contacts, but it must guarantee the positivity of the number of contacts at each time step. So it has to take values inside this set here. And we suppose that it has a mean equal to zero and we define its variance. Okay, in order to study the evolution in time, In order to study the evolution in time of the distribution of social media contacts, we know that the density H solves this Boltzmann-like equation here for all phi smooth functions. And since the evolution of contacts is non-linear due to the presence of the function psi, it is possible to prove that the only conserved quantity in this equation is when is when phi is equal to one. And what we have is that the variation in time of the total of the integral of this density h is zero. So if we start from with a probability density, we still have a probability density for each time t. Instead, if we take phi equal to c, we obtain the evolution of the mean value, which is still bounded, if it's bounded initially, because it is possible. bounded initially because it is possible to prove this upper bound empty for all positive time due to the fact that the function psi is bounded. Okay, so in order to find the Fokke-Planck equation satisfied by the distribution density of contacts, we do the usual scaling. So we suppose that there's a very small change in number of social contacts at each time step. So the function psi is evaluated. So the function psi is evaluated in this epsilon, which is small, and we also scale with epsilon the random part. We also scale the frequency of interactions so that it is possible to observe some evolution of the average, removing the dependence on epsilon. And we will call at h epsilon the scale density. So the evolution of the average satisfies this equation here that remains bounded since the right-hand side is bounded. Right-hand side is bounded as epsilon goes to zero because we have this equation here. This limit here is holds. Okay, now to pass from the kinetic model to the Fokker-Planck equation, the usual strategy, we assume that the random part is bounded, at least their third-order moments are bounded. And we expand the entailor series and we get this reminder here, which is of order epsilon. Is of order epsilon squared, and then we use the scalings I introduced before so that the Boltzmann-like equation becomes like this. So, this is the part, I mean the Fokker-Plant part, and this is the reminder. As epsilon goes to zero, the reminder goes to zero. And we have that the density H solves in the weak form this Fokker solves the weak. Shops, the weak form of this linear Fokker-Planck equation. If we do integration, if we perform integration by parts and we assume that the boundary terms that appear with the integration by parts vanish, goes to zero, so we have that the weak H, sorry, that H solves this Fokke-Planck equation. Okay, now we are interested in the steady state of this distribution of contacts. And the steady state, the stationary distribution. Steady state, the Sasha distribution of contacts solves this first-order ODE, which is possible to solve explicitly with a change of variables. And what we have is that the steady state of the distribution of contacts is given by this function here, which is a log-normal density. So we have that the stationary distribution of contacts is a log-normal density. So, what concerns the opinions? The opinions. We start as usual from the microscopic point of view and from the binary interactions between agents. So, for two arbitrary individuals, we have that V and V star are the opinions before the interactions. And they are between minus one and one, because we assume that the opinion is a continuous variable between minus one and one. V prime and v star prime are the opinions after the interaction. P is the P is the compromise function. And this is the part that takes into account some random variation of opinion due to personal access of information. I mean, this is not strictly related to the interaction with the other agent. And we have like psi here is a random variable with mean zero, and we call its variance sigma squared. We're interested in the evolution of f. f is the density of the agents that at time t f. That at time t opinion b and number of contacts c this is quite standard. The time evolution of f satisfies this Boltzmann-like equation. Still, we are dealing with a problem in which the variable belongs to a bounded domain. In this case, V is between minus one and one. So we can only consider interactions that preserve such bounds. Such bounds, and it is possible to prove that if we take a small enough compromise function p, and accordingly we choose the magnitudes of this random variable psi, then the binary interaction preserves the bounds. So we have that the opinions do not cross the boundary minus one and one. Okay, probably we can skip the proof. Okay, now we want to reply the Fokker-Planck. We want to reply the Fokker-Planck equation for the distribution of opinions given in contacts. So, as before, as it's standard, we assume that all the random variables appearing in our model have bounded moments of at least order three. They are independent and the Ïˆ xi star variables appearing in the binary interactions for the opinion formations are also equidistributed. Also equidistributed. As before, as we did for the contacts, we expand the intelligor series, the smooth function phi. We consider the scalings of the parameters alpha and sigma. And what we get is if we scale also the time variable in order to be able to still see the interaction, we get that as epsilon goes to zero, the reminder that contains the third. The reminder that contains the third-order terms goes to zero, and f satisfies this equation, which is the weak form of a Fokker-Planck equation that can be obtained as before by integration using integration by parts and supposing that the boundary terms appearing with the integration by parts simply vanish. For this equation here, differently from what we did before for the distribution of contacts, it's not easy to find an analytical Easy to find an analytical description of the steady state. I mean, in principle, it's not possible. But lately, during in the numerical simulation parts, I will show you that under very restrictive and simplifying assumptions, it is possible to say something also on the steady state of the distribution of opinions given the context. Okay, so for the numerical simulations, all the numerical simulations. Simulations. All the numerical simulations I'm going to show you today have been performed with Monte Carlo-like simulations. And the first thing we simulated was the evolution of contacts. So we started from the one time step evolution of contact of a single agent. And we set up parameters without taking. Without taking into account the data. So we just a toy example. For our Monte Carlo simulations, we used in this case 1 million agents. And this is what we got. Here on the left, we have in red the analytical steady state, so the log-normal distribution, and in the blue dots represent our simulated distribution. Simulated distribution. While on the right, we have the tail behavior, which is what we were mainly interested in. And as you see, it's quite well approximated. And in this case, we use the scaling parameter epsilon equal to 0.01 for these two pictures and the final time t equal to 40. Okay, so what I want to do is. Okay, so what I was anticipating before, the steady state for the opinion distribution. As I was saying, it is not in principle possible to compute the explicit asymptotic state of this Fokker-Planck, oh, sorry, no, of this Fokker-Planck equation here. But if we assume some quite restrictive assumptions, it is possible to say something on the steady state. For example, To say something on the steady state, for example, what we assumed was that the distribution, the density f could be written as the product of a function that only depends on time and opinion and a function that only depends on contact and opinion. And we also assume that this behavior is true until also for the steady state. Then we took a very easy compromise function and we weighted the diffusion part with this. We weighted the diffusion part with this D here. And the idea is that when the opinion is external, so it's minus one or one, we do not have any kind of random contribution in the interaction. Under such assumptions, it is possible to rewrite the Fokker-Planck equation, dividing, separating the part that depends on the opinion and the part that depends on context. And we can say that. And we can say that it is verified if both the part regarding the opinions and the part regarding the contacts are separately verified. The session resolution of the second one is what we already saw before, is the stationary distribution of the social media context, so it's a log-normal distribution, while the first one has an explicit expression for the stationary solution. For the stationary solution, which is given by this g infinite here, where we have that k is just a constant that assures that the integral of this function is equal to one, while m bar is the mean value for the stationary solution. Okay, so these are two simulations. We have in both pictures in magenta, we have the analytic. Magenta, we have the analytical distribution, and in blue, we have the discrete distribution obtained with the Monte Carlo-like simulations. In the first case, we have that the parameters have been chosen such that sigma squared over alpha is equal to one, while here sigma squared over alpha is equal to 0.2. And these are the numerical and the exact steady-state distributions. Also, in this simulation, for these pictures at least. For these pictures at least, I'm showing you what happened for scaling parameter epsilon equal to 0.01 and 100,000 agents. Okay, now the simulations without an exact solution. In this simulation, we want to model the situation in which the single interaction is more relevant if the first agent enters in contact with a second agent, which is more popular. Agent, which is more popular, so that has a higher number of contacts, while the interaction is less relevant otherwise. And to this purpose, we chose the compromise function p in this way, where we have key is the indicator function, delta is a constant, and this means that the interaction occurs if the opinion of the two agents is close enough. Agents is close enough, and in case this occurs, it is weighted by the popularity of the second agent. We start from initial data. From this initial data, that means that we have that the contacts are already at their study state, while the opinion is uniformly distributed among the agents. And in the simulations, I'm going to show you the parameter, the constant parameter. The parameter, the constant parameter delta is equal to 0.5, and the simulations here are for 10 to the fifth agents. So, yes, this is what happens. At first, we have this uniform distribution of contacts according to the opinion according to the contacts. And then we see that as time passes, there's this formation of two different clusters of opinions between the agents. Between the agents. Why, okay, in this other simulation instead, we consider the interaction are such that two agents interact if their opinion are close enough, but this range of confidence depends on the number of social media contacts of the second agent. So, still, if two agents come in contact, and for example, In contact, and for example, the second one is very popular. There's some kind of compromise, even if the starting opinions are far. Otherwise, there's no interaction between the agents. The starting data, the initial condition for this simulation is an uniform distribution of the opinions. And at first, all the agents have no All the agents have no social media contacts. So we start from people with no contacts, and then we see the evolution of the distribution. So this is what we are looking here. And probably I didn't specify before, but here we have the contacts and here we have the opinions. So at first, they were all uniformly distributed around, almost having no contacts. And as time passes, we see that. Time passes, we see that people with very low amount of social media followers arrive to a sort of consensus, while popular agents, in a sense, separate their opinion from two different classes of opinion. Okay, in this fourth simulation, instead, we start from this initial condition that probably here is clear. So, we start from an initial condition. Clear. So we start from an initial condition in which the agents are the less popular agents have this opinion, while the more popular agents have this other opinion here. And we want to model the situation in which the popular ones, in a sense, hardly change their opinion, while the less popular agents Agents, the opinion of the less popular ones is driven towards the opinion of the agents with more followers. And in order to do this, what we do is we choose this compromise function p, still with the diffusivity with the same function. And this parameter just means that at first the agents are very concentrated around these two opinions, which Around these two opinions, which are numerically speaking, minus three over four and plus three over four. So, this is what happens to the marginal distribution of the contacts. You can see that as time goes on, this goes towards being a log-normal distribution. We just stopped at time t equal to six, but if we went on, this would have become a log-normal distribution. And here, instead, we have the margin. And we have the marginal distribution of the opinion. At first, they are concentrated, this is for the popular ones, and this is for the less popular ones. And as time goes on, the less popular ones, in a sense, adapt their opinion to the more popular ones. And this is what happens with visually. So to this density function, we see that this goes. We see that this group of people more or less remains of the same opinion, while this one that was here before goes to adapts its opinion to the other group of people of agents. Okay, now the process of data extraction from Twitter has also, for example, Jonathan mentioned yesterday, Twitter allows researchers to access Twits data. So it is possible to Data. So it is possible to get an account, an academic researcher access to its data. The main issue for us was to construct this data set because it is not possible to ask Twitter, give me a thousand random thousand number of IDs of people so that I can do some kind of research on them. So what we decided to do, and this is just a choice, it's not probably the best choice, not only the only choice. Probably the best choice, not only the only choice possible. We selected some of the most followed politicians from all around the world on Twitter, and we collected the ideas of a million followers from each of these politicians. Then we merged all the data together. So we had it was like almost 9 million profiles. And then from this large data set. from this large data set of people we randomly extracted 1 million profiles so this is the last our last data set the the problem with using the twitter api is that it has time limitations that cannot be overcomed in any way so each 15 minute intervals it is possible to only retrieve a certain amount of data and this certain amount of data depends on what are you asking for for example it's For example, it's easier in a sense to get the follower IDs of a certain profile, while it's way more heavy, way more slow, the process of extracting how many followers have each ID. Okay. Okay, so as I was saying, we chose a subset of a million users from our Million users from our starting data set. We obtained the information regarding the number of followers of each of these users, and then we simply used MATLAB to fit the data we mined. We did these assumptions that we only considered profiles with at least one follower. Supposing that profiles without any followers were inactive or were inactive or probably were both but this is probably not the best this is not the only way to for example exclude both from this uh from this data set we we use different algorithms but they were embedded in matlab to fit the parameters and we got that the parameters of the of the steady state distribution so of the log normal distribution of of contacts were these two here so So, okay, this is a picture that shows in blue. We have the data. This is the tail behavior of the data. And if you can tell by the picture, but in red, we have the fitting with the non-linear regression and the fitting with the squared algorithm. It's in green instead. Okay, so now last two numerical simulations. These were made using the parameters we obtained. The parameters we obtained from the data, while the other ones were not, of course. So we started from this initial condition here. So we suppose that the contacts were already at their steady state while the opinion was uniformly distributed between minus one and one. And we did two simulations using the data from Twitter. The first one is a very easy one, which is a compromise function p equal to one. And we just simulated the evolution of the density of opinion and contacts in Of opinion and context in this time interval here. Well, the second simulation is a bit more complicated in a sense, which is a compromise function p equal to this here. That means that users are more keen to change their opinion if they enter in contact with a popular one, as usual. And we performed our simulation in time interval 0, 6 with more agents in this simulation here. So this is the first simulation. Simulation here. So, this is the first simulation where the compromise function p is equal to one, and we start from a uniform distribution of opinions. And we get that over time the agents reach some sort of consensus. What I'm showing here is the logarithm of the density F since due to the magnitude of the parameters. To the magnitude of the parameters we got from the data, the function, the log-normal function is very quite on the y-axis. So it wouldn't have been possible to see almost anything without reverting to this kind of option here for the density. And this is what happened in the second simulation. So we still start from the uniform distribution of opinions. Of opinions and the stationary distribution of contacts. And what we have, probably it's not quite easy to see it because the colors are not that defined, but we have that over time, the less popular ones, in a sense, reach some sort of consensus, while the most popular, the more popular here, some kind go to extremal opinions. Over time. Over time. Okay, so what we did so far, we described the distribution of social media contacts, finding the start, we start from the single increment of the number of contacts of a single agent, and then we found the Fokker-Planck equation, and we solved the steady state, we found the steady state distribution of this Fokker-Planck equation. Starting from binary interactions between agents, we derived the Between agents, we derived the Fokker-Planck equation verified by the density of opinion given the contacts. We collected data from Twitter and we estimated the parameter appearing only in the first part, so in the part linked to the social media contacts. What are we planning on doing next? Since this is still, as I was saying, a sort of work in progress. We want to use the access to the API, the Twitter's API, to perform some sort of sentiment analysis. So the idea is to choose a certain topic. Choose a certain topic and perform sentiment analysis on this topic during some time, and then try to estimate the parameters appearing in the binary interaction between agents. So do some sort of inverse solvent, sort of inverse problem to find, for example, the compromise function p and also the value, the magnitude of the random part appearing in this binary interaction. In this binary interaction between agents. So, okay, this is all for me today. Thank you so much for your attention. Questions? Comments? Thank you for your nice talk. Yeah, I just have a couple of questions. Is there any particular reason why you chose this D5? Because I had for example I just identified with the square root of that. Okay, no, in this simulation, yeah, we tried also with the square root of that, but not for the not for the, for example, not for the first simulation in which you can obtain the steady state explicitly. Even though I think it's possible to obtain a steady state also in the case of square root of one minus. Also, in the case of square root of one minus v squared or absolute of v. But yes, we did not actually do any simulation here. We just assumed that the randomness appearing in the interaction is small enough so that, you know, we just wanted to be sure that this was zero at the boundary. So that's why we just use one minus b squared in the simulations we did so far. But I don't exclude that in the future, probably after doing. The future, probably after doing this second part of sentiment analysis, we can actually switch to one of the others weights for the random part of the interaction. Yeah. Thank you. And the other question was, do you think about putting different time scales for the formation of the number of social contacts on Twitter? With respect instead to the formation of the okay, so different time scales for the two. No, we didn't try it, but actually, that's one of the things we want to do because it makes sense to assume that they have different time scales. Yeah, but these are just since the work is quite new in a sense, we still haven't done everything very, very in details. But yes, this is very, a very interesting. Yes, this is a very interesting observation. Yeah, we must do also this. Yeah, in the future, near future, probably. Yeah. Thank you. Thank you. There is one online. Yeah, thank you. Thank you for the interesting talk. This is an interesting model, and I like how you're using the data from Twitter. Have you, do you feel like this? Um, do you feel like there's any way you can use the model in any kind of predictive way? Or do you feel like have you tried looking at fitting the parameters with the subset of the data and seeing if it actually can be used to predict the behavior of the rest of the rest of the data? So you're saying if we know we okay, you were asking if we did some sort of model prediction using the data? Using the data, also. Okay, yeah, that's a good point, exactly. But no, we actually fixed the model before, and then we just use the data to find the parameters, actually. Is there any feeling that you might be able to use the parameters that you've found from this set of data in another context or with another set of data? Do you think that it's very data set dependent, or do you think that if you changed and looked at the different And looked at a different similar set of data, you might actually have to do that. No, I think that it can make sense also if you do not reside on the actual data, I think. Okay, so I think this is true also for other data. I mean, the fact is that we used the data, the distribution of contacts, the choice of the value function. The choice of the value function psi was given by the study of the data, in a sense. Okay, so even though I only talked about the data at the end, at first we saw that the data were following a log-normal distribution, okay, the data from Twitter. And then accordingly, we chose the value function psi in order to match this steady-state distribution. State distribution. So, in fact, we use the data to define the model in a sense. Yeah, that's it. Yeah. But is there any feeling for whether that might, you know, the model that you've designed might be predictive in any way for a different data set? Have you thought about looking at that? Because it would be. No, we can actually. It can be an interesting effect. Yeah, the data set we chose, it's quite restrictive. I know it's. Quite restrictive. I know it's probably using other data sets, it is possible to find other outcomes of the model, honestly. Yeah. Okay. Well, yeah. Thank you for the talk. Thank you. Okay. So, yeah, have you tried to analyze like the, like, for example, restricting to a hashtag and what is happening there? Yeah, that's what we are planning on doing next. Try to find some hashtags. Find some hashtags and use the data to use the API to see what happens linked to this hashtag. But yes, we didn't yet try to do this because we only use the data to find the number of followers, the distribution of followers. But yeah, this should be part of the but just restricting to a topic. Yeah. And just for example, some news, like Just for example, some news like the British prime minister resigned studying the evolution aspect that has like the starting point and exactly exactly. That's what we want to try to do next. It's part of the second part of the work in a sense. Yeah, we want to probably restrict to an hashtag or to a topic and find the tweets that contain that hashtag during time and see how it will. And see how it evolves, how they evolve so that we can try to find the function p, for example, and model it. Probably try also to predict, but I don't know if it's possible, the evolution of opinions on Twitter on such topic. I know that what they were observing is that some sort of they were seeing observing the network. I can send you maybe the reference. Yeah, yeah, I'll be interested in that. Yeah, thank you. Yeah, yeah, I'm interested in that. Yeah, thank you. And they were finding like clustering, like sometimes like there were like sort of communities depending on their political opinions. They clustered, okay, they separated, okay. Okay, that's very interesting. Thank you for pointing it out. If you can link me the results, I would be glad. Thank you. Any other questions? If not, let's take a detail. Thank you.