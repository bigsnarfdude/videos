Maybe we could start. Our next speaker is Professor Bin Zhou from Peking University, and the title is A Revisit to the Fine Bernstein Theorem. So please, Professor Zhou. Yeah. Okay, thank you for the introduction. And thank you for the invitation. Special thanks to Professor Da King Ye for. First, talking here for bringing us together for this conference. Today I'm going to talk about the affine Bernstein theorem. So it's not a new result, but I'm going to give you a review and a new proof in some sense. Okay. So in my talk, I will focus on the graph case. So let u be a uniformly, locally uniformly convex function. This means that the second derivative is The second derivative is non-degenerate and it's at least a C2. So the graph, so the graph of U defines a hypersurface in the M plus one dimensional space. On this graph, you can define an affine metric. So you just use the second derivative of the function with a power of the determinant up to the power minus one over m plus two. So this metric. and plus two. So this metric is a fine invariant. Then you can define the area with respect to this metric. So you can see that in this formula, finally you can get that the final area is the integral on the surface for the for the one over m plus two power of the Gaussian curvature. So you can see from this So, you can see from this formula that is a fine invariant. So, for this problem, you can compare it with the minimum surface in geometric analysis. So, you can study the critical point for the fine area, but it's different to the minimum surface case. So the critical point usually we mean the locally maximum points for the affine area function. So, we call it a fine maximum. So, we call it a fine maximal surface for this reason. And so, for this problem, there is a famous conjecture by SSTEN. So, the conjecture says that an Euclidean complete, a fine maximum locally convex, locally uniformly convex C2 have a surface. I think it should be in R3, must be an elliptical parabola. So this. So, this conjecture has already been proved by Churing Wang in 2000 and is now known as the affine Bernstein theorem. So if you compute the Euler Laplange equation, you get this equation. So in equation one, capital Uij, upper Uij, means the cofactor matrix of the Hessian matrix of the Hessian. Of the ession of U. And W is a power of the determinant. So the index is minus one plus one over m plus one. So actually the left-hand side of the equation is the affine in curvature. So the contributor says that in R2, in dimension two case, so any entire solution to this equation. To this equation must be a quadratic polynomial. Okay, so before I talk about this conjecture, I should mention there's another conjecture by Calabi. But this is already proved by Calabi in 1982. So it's still in dimension two. So he assumed the condition that the affine metric of the graph is complete. Then the Bernstein theory is true. So, here I have some remarks. So, first, the completeness of the affine culture actually is a strong condition because it puts some restrictions on the second derivative of the graph. And there are examples showing that the Euclidean complete is stronger, is weaker than the Is weaker than the affine completeness. So, and there is another paper by Churinga and Wang in 2002. So, they proved that affine completeness implies Euclidean completeness. So, this means that you can give another proof of the affine Bernstein theorem. Since we already have the Calabi conjecture is true in dimension two, and affine completeness implies the Bernstein theorem. implies the Bernstein theorem. And you know that I should appear a different proof to the Bernstein theorem for the Clabi conjecture. And I should mention that both of these conjectures are widely open in higher dimensions. But you can compare it with the minimal surface. You know that for minimal surface, You know that for minimal surface in the dimension higher than seven, there are counterexamples. But here, including the ones paper, sorry, they construct a singular counterexample in dimension 10. So this is the function can be written explicitly as like this. So it is singular because that's So it is singular because that there is a singular point at the origin. But here I didn't explain what is the W21 solution for the maximum, maximum surface. Actually, you can define the weak solution for it. So up to now, there is still no smooth counter examples. And the critical dimension is still unknown. is still unknown of course you can you can study the the the the the analogous problem like the mini minimum minimal con for the minimal surface case here maybe you can study the five maximum cons um okay so so i i would like to include this uh equation to a class of one jump pure type the first order equations so the equation looks like this so we we always consider the uniformly convex Always consider the uniformly convex solutions. So the formula is the same, but here the W, the definition of the W is that you can choose different power of the determinant. So remember that when theta equals to one over m plus two is the affine maximum surface case. And here, capital Uij is always the cofactor matrix of the Hessian. So, for this class of first-order equation, they have variational structures. So, the associated function is, I think we should call it one-jumper-type function. So, here I write the general form with the non-homogeneous term. So, A theta is the determinant part. So, you can see that for different theta, it has different. That for different zeta, it has different formulas. And when zeta equals to one over m plus two, this is the fm area. So for this class of fourth-order equation, so besides the case of f n case, that is theta equals one over m plus two, there is another case that has good geometrical. That has good geometrical background. So, in the case of theta equals to zero, it's also called Ablus equation. So, Abelus equation, the original form, looks like this. So, here the notation, u are small u of ij is the inverse matrix of the Hessian. That means that you take the second derivative again and take the trace of i with respect to i and j. So, actually, you can do some computations. Actually, you can do some computations to get that the left-hand side can be written in this form. But here, W is the inverse of the determinant. So this equation comes from a complex geometry, maybe Keller geometry. So it's related to the study of the scalar curvature problem on topic Kelly manifolds. So actually, Keller manifolds. So actually, it's a reduction from the complex case. So if you consider the Bernstein theorem for this equation, so actually you mean that from the solution U, actually, you can construct an S S1n torus invariant scalar metric. So the first time theorem, we are mean. So if it is scalar flat, then it is flat. Flat, you remain flat. Okay, here I just put all the Burst time-type theorem about this class of first-order equation together. Okay, all these results are in dimension two. So now we know that when theta lies in between zero and one or four, or theta larger than one, then U is a quadratic. U is a quadratic polynomial. So here, here, the case of zeta equals to one over four solves the same conjecture. That is the result of Chulinga and Wang. And for the case from zero to stupidly less than one or four, one or four, it's proved first by Jia Fang and Liamin and myself, with a different proof by myself. And the case of theta strictly. Theta strictly larger than one is proved by tuning a one in another paper. For the case theta equals to one, so here remember that when theta equals to one, there's no definition, but here you just replace this term by a log determinant. In this case, there is a counterexample. Actually, you can take u equals to an exponential function and a polynomial, then you polynomial, then you take the second derivative, then the secondary derivative is a linear function with respect to x1. Then you can take this secondary derivative again. Actually, this is zero, so satisfies the equation. When theta lies between 104 and 1, so we still don't know whether it is true or not true. For all these equations, for For all these equations, for all these equations, the Bernstein theorem is unknown in higher dimension case. Okay, so now let's review the proof for this theorem. But here, in this part, I will assume the interior estimate, and then prove the affine Bernstein theorem. And in the third part, I will give you a new proof on the interior estimates. Estimates. So let's make some observations. The first, so usually we will treat this Monjal Pair-type first order equation as a system of two equations for U and W. So U satisfies a Monjal-Pere-type equation, and the W set satisfies the linearized Monjam-Pierre equation. You can see that this in this system, U and the W. In this system, U and W are still mixed up. A second observation is about the Bernstein-type theorem. So first, for the Monjam-Pere equation, so there is a beautiful theorem by Jorges, Carlabian, and Pavlov. It says that for any uniformly convex solution to the determiner question equals to one in the entire Equals to one in the entire space, the solution should be a quadratic polynomial. So this holds in any dimension. In this talk, I will review a proof for the fine Bernstein theory, but the proof is not the original one by Chuling and Professor Wang. Another result is for the second order. result is for the the second order equation linear linear second order linear equation so as uh the bernstein hopf mika theorem so it says that if you have a solution to the the linear equation here i should emphasize that aij is not uniformly it's just either so if the solution is sublinear at the infinity then it's a constant so if you combine these two results together to Two results together to then you can see that to prove the affine Bernstein theorem, it suffices to show that the determinant is bounded, is globally bounded from above and below. Because if you get this estimate, first you can use the Bernstein-Hoppful Mikkel theorem, then you get that determinant should be a constant. Then you use the Jürgen's cloud. Then you use the Jurgens-Clabi Probulov theorem, and you use a quadratic polynomial. So, as I said, I will first assume the interior estimate to tell you how to prove the fine Bernstein theorem. So, for the interior estimate, I mean, but here, here, we focus on the case that the theta is between 0 and 1 over 4 because this contains the two interesting case theta equals to 0. case zeta equals to zero and then one over four which has a geometric background so interior for the interior estimates it says that if you have a solution and the domain and the solution are normalized then you get all the interior estimate the the constant depends only on theta alpha and the distance to the boundary and here the the the boundary. And here the estimate here I didn't explain the normalized notions of normalization. So I will explain it later. So as I said, I will first assume the interior estimates and prove the fine Bernstein theorem. So first, so for the Mon-Jampier-type equation, usually we do not do the Equation usually we do not do the estimate directly on boards, so we consider the sections. So, for a convex, what is section? So, for a convex function, the section centered at a point x with height h means that it is the sub-level set of the solution of the function. So, here, Lx is a support function of u at x. So, so So the argument will be that we will pull back the section at the infinity and take the height h goes to infinity. So we need to fix a point. So we use a Cavarelli's result that we fix a point x, x0. And so for any edge, there will be x such that x0 will be the center of. That x0 will be the center of the section. So, next, we talk about the normalization, the normalization for domains and the solution. So, a domain is called normalized if it lies between two centered ball at the point x0. So, it means that it almost is nearly a ball. So, a function we call it normalized. It satisfies that you Satisfies that u vanishes on the boundary and the oscillation is one. We will do normalization by directions. So for any convex domain, there is a direction with respect to the center of mass. So that's after the direction, the domain becomes normalized. Okay, now we go to the proof for the Bernstein theorem. So we first we normalize the Um, we first normalize the solution at the origin that it attains the minimum at the other origin. So, as I said, we will pull back the sections at the infinity. So, for any sufficiently large height edge, so we first by Cavalier's result, Cavalier's lemma, and we can choose an x-edge so that with the fixed point. The fixed point zero origin will be the center of mass of the section. Then we normalize the domain by dilation. We get a normalized domain omega h, and we normalize the solution by substituting a supported function and scaling. Then we get a normalized domain, omega h and normalized solution, uh. So here we used the interior estimate. The interior estimate. Actually, we have interior estimates of all orders. Here we just need to use a C3 estimate. Then we get an interior estimate for the normalized solution in a smaller ball. So we need to scaling back to the original solution. So we need to compute that the relation between. Need to compute that the relation between the nominal solution and the original solution. Then you can see that the determinants differ by h up to our power n and the uh and the determinant of the direction. So it's it suffice to estimate this determinant th so um we can get that this this th the determinant should be This th the determinant should be comparable to the h up to the power minus n over two. So, so with this claim, you can see that the determinant will be bounded globally by taking h goes to infinity. So for this, you just need to change back the coordinates, then you get that, then you get the estimate u over h. Uh over h can be compared to this th x up to R2. And you assume that lambda h to be the max and mix minimum eigenvalue of the dilation. Now you distribute this inequality on the unit sphere. You get the estimate on the max and minimum eigenvalue. So this implies the determinant estimate. So So, as I mentioned, once you get the global bound of the denominant, you can prove the fine Bernstein theory. Okay, now we talk about the interior estimate. So, first, I would like to recall the Lagrangi theory for the linearized Mendian-Pierre equation. Because up to now, in almost all In almost all papers related to the first-order equation of Manyamba type, people will use the Cavari-Gutenis result. So this deep result says that if you have a solution to this second-order linear equation, Uij, Wij, then you get the interior regularity. So the point is that you don't have the uniformly ellipticity. You just assume that You just assume that the determinant of the coefficient is bounded from below and from above. Here is strictly larger than what at zero. So for this Cavari-Gutelis theory, there are some extensions to the boundary regularity and the higher regularity by. boundary regularity and the higher regularity by uh namely sabine um and uh like uh win button um but today we will focus on the interior regularity so so um so now it is uh um it is a regular way to to study the regular regularity of this class of uh for so for so the Montgomery-Per table equation by a button-strapping. The equation by a bootstrap argument. So remember that we can decompose the equation as two second-order equations. So the first is a Manjan pair equation, the second is the linear Manjan-Pair equation. So the button-strapping argument is 