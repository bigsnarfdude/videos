Of collection of surfaces by studying the geometry of the base manifold, and this is a collaboration of a group that we have at Duke University. Just a short description of who are in the group. The group started a long time ago before I even write here with the work of Ingrid and Jaron Lippmann, who is in Weizmann University now. And we are studying evolutionary anthropology, it continues with the works of Geneva. Continued with the works of Tinron Gauch and Shan and Robert Trevier that we just heard. We have a new and exciting vein of research now that we focus on the geometry of the base manifold. And we perform this work with Ray Zinn and Alex Swinn. The data is acquired by the Anthropology Department by Doug Boye and his two students, Alicia and Medicine, and that's what we'll be describing today. Rob already described a lot of Lots of interesting parts about this project, but I will try to give a different viewpoint on that. So please excuse me for repeating some of the stuff that he mentioned. So until now, the group was mainly interested in primal molars. We also heard Gary talk about molars today, but I will continue these lines of research. The reason why molars are interesting, because the biologists find out that the diet. Biologists find out that the diet of the lemurs or monkeys are tightly related to the shape, and we can actually say whether they used to eat fruits or leaves, insects or flesh, and deduce some information on the shape and maybe later try to look on ancient molars and try to understand what was their diet. Currently, now, with the PhD of Alicia, that is collected. The PhD of Alicia that is collecting a lot of information about hemata and thalas. The group focus is changing to these interesting bones. And this is a research that has just been started. So the general flow in evolutionary anthropology is once we have some data that is acquired, for example, those molars, we perform registration, define. Form registration defines a metric space, and we are able to compare those TIF and extract some valuable information such as the curvature or other properties of those surfaces. And later on, we would like to perform some kind of cluster analysis and understand something beyond what is known right now. This is, for example, on the right, a tree that was created based on automatic class. Created based on automatic cluster analysis of projecting those molars by a diffusion map into three-dimensional space and analyzing the clusters. And they actually prove the hypothesis made by the biologists that they do correspond to the diet that those species had. But I will not talk about the clustering today. Today I will mainly focus on registration. Focus on registration. We talked about registration a lot today, but I will continue talking about it now. Because this is a problem that is a key problem in this analysis, it's very important to perform the registration as accurate as possible. And I will talk about several stages of registration. So, after acquiring the data, we can perform many Can perform a manual landmark placing on those teeth, and we will shortly describe it. I will also talk about the continuous procrastinist distance and how it is defined, basically how do we roughly align those surfaces. And I will also introduce the fine registration that we introduce using the horizontal diffusion maps, and I'll show exciting results that we just received two weeks ago on the molar teeth. Weeks ago on the molar TIF. So let's start. So once those TIFF are scanned via a CT scanner, we have those point clouds and we perform triangulation and we have a mesh. We clean it a bit because there are different problems with outliers and noise and maybe there are some kind of holes in it and we create a surface. Now we can really start playing with the surface and structure some information. Playing with the surface and structure some information from it. So, the first thing that the biologists perform is place some landmarks in points on the teeth that they think that are important for the comparison, for their manual comparison task. That's how it usually works. And these are placed on the TIFF in three dimension. And they have a collection of TIFF they try to capture. To put the rangmarks on all of them. For example, this is a collection that consists of 50 teeth, and they place not only the point on each and every teeth, but the color coding here represents that those points are sitting in a resembling geometry from their perspective. If we would look closer than those landmarks, we can characterize them as sitting on high curvature areas. Sitting on high curvature areas, and maybe we can use this in order to automate this process. So, the process of manually doing something is always time consuming, but not always, not only because it's also not very accurate. It requires domain knowledge and it also is very subjective. One expert can put the landmarks in certain areas, while other ones would think that other areas are more important for the comparison task. More important for the comparison tasks, so it's something that is subjective. But once those landmarks are placed on those TIFFs, the procrastination is defined. Gary talked about the conformal land beams, but we will talk today about the procrastines. So we have two surfaces, S1 and S2, with their points XJ and YJ. And basically, we are trying to find some rigid transformation between one Between one shape to another, that will register those surfaces in the best, in the optimal manner. And this will define us both the rigid transformation and also the distance between the two surfaces. But we rely on the initial correspondences on those landmarks that were initially marked by the biologists. So the question is: can we avoid this? Avoid this. And to avoid this, this continuous procrastination was defined in this paper of El Hafari, Debushy, and Lippmann in 2013. And what they say basically that we are looking not only for the rigid transformation R, but we are looking for the correspondence map C that will be area preserving the deformorphism, meaning we are trying to find not only the rotation and translation. The rotation and translation, but we are also looking for the best correspondences between the two shapes. And this was built in order to overcome the manual landmark marking. Okay, so now we have this continuous procrastinate distance and we can use it for different purposes. But the question that we ask ourselves is it the best registration that we can attend? Registration that we can achieve. And that's what we'll try to answer today. So, in the continuous procrastinate distance, if you look on it, we are optimizing only the rigid transformation and also the correspondences, but we are not optimizing the points themselves. So, once we are given two sets of points sampled from different surfaces, we are trying to find the best alignment between them. But what we will try to do today is to suggest a method. Just a method how to find those a new set of points from the existing surface that will better represent the alignment. In sort of way, we're trying to find the projection of the landmarks or the points from one surface to other surfaces. So, this is the problem definition. We have a set of surfaces as j and we As J and they are given with some points. We are trying to find we have a reference shape that we selected a priori. Let's say that it's the S1 shape, like here, along with its point, and we are trying to propagate or project its point to each and every shape that we have by minimizing this optimization function. We are not really minimizing, and we will see what we are doing really, but we. will see what we are doing really but we'll see that it's really working so in order to tell you how does it work a short reminder of manifold diffusion fiber bundles and base manifold i'm sure that all of you almost you know how it's what it it is and we also heard about fiber bundles and base manifold from rob but i feel that for the sake of the completion it's something that i must remind Must remind. So we have the scatter data sitting in high-dimensional space. We assume that they're sitting on a manifold. On each point, we are able to look on its surrounding, a small neighborhood, and we can perform random walk in that neighborhood. Since the neighborhoods overlap, we can perform a random walk from far away points, from one point to another, without knowing the global geometry of the manifold. And this is what is used for the diffusion. Is used for the diffusion maps. Once we define the diffusion kernel based on the distances of two points, with some tau that is basically the diffusion time, and it's important to select tau in the best manner. So from the white side, we will not diffuse too much, but from the other side, we will diffuse at least to some points around a certain point. And there was a work by Shanshan and Dibuchi that they introduced a That they introduced a method how to find the best tau using the semi-group property. How do we find it? I will not talk more about it, but we will use this definition of the best tau that we look find. And once we have the diffusion map, we are able to look on the spectral analysis of it and find the again vectors and values and Again, vectors and values, and define the distance between two surfaces in terms of those spectral distances. So if we have a collection of surfaces as here depicted from the molar teeth, we are able to project each teeth to a point here in three-dimensional space. That's what usually happens, why I'm so interested. Why I'm so interested in that because later on we will see that a TIFF is not projected into a single point, but it will be projected to a set of points. And the problem with this current definition of the diffusion matrix is that we lose the geometry of each and every shape and we kind of represent it only using one point in 3D. Maybe to some targets of classification, Targets of classification, it's sufficient, but if you want to analyze and study the change in the geometry of the teeth itself, then it's a problem. To overcome this, we will introduce the horizontal diffusion maps that will perform the diffusion not only on the manifold, but on the fibers themselves. And to that, I need to some several terms from differential geometry. So we have the total manifold E, that is basically the base man. There is basically the base manifold along with this map that maps from the total manifold to the base manifold. And we have the fibers that exist there. And what we are looking now is that we can no longer are able to walk on the manifold itself, but we have also some parallel transport between the fibers. And if you remember, that's exactly what we have on the TIFF. Exactly, what we have on the TIFF. If we have some initial correspondences, we have those mapping between one landmark and another, where they were found manually or using the continuous procrastinist distance. So also in the manifold of the TIFF, we are able to see what we are doing. Now we can define the horizontal diffusion map. So we are adding to the initial term that we had of the distance between Of the distance between two teeth as before, we are adding also the diffusion on the fiber itself, where we are looking on a certain neighborhood of it. Now, the game that we have here is how to define the tau1 and tau2, because we can diffuse on the manifold and also on the fibers themselves. So, before we go to that, I will just describe how the horizontal. Describe how the horizontal diffusion matrix looks like. So it's in the size of the number of points of all the TIFFs in the entire collection, meaning we have a block for TIFF1 that is compared with TIFF2, block for TIFF1 that compared to TIFF2, and so on. And now we can look on the spectral analysis of this horizontal diffusion map. Diffusion map and the eigenvectors will have a geometrical structure that we can use to learn how the geometry of base manifold looks like. And that's what we will be doing later. So once we have the spectrum, we can look on the free dominance spectra of the diffusion map and instead of having one point for each tooth, we can we get that all the m teets are mapped to some uh same surface. Some same surface, same surface that we call the Pringle. It's not very scientific, but each point here, we see that each point from the T is mapped to a point on this Pringle. And each T is represented by a different color. For example, the green point is mapped to the green point here, and this is, if we look on the same locations on this surface, this will correspond to. Surface, this will correspond to a resembling points on the teeth itself. And that's a property that we will use for our refinable registration. So now let's look first on the geometry of those eigenvectors. So each eigenvector, because of the block structure of the horizontal diffusion matrix, we get the first part of each eigenvector corresponds to the first tie. To the first tiff, to the second tiff, and so on and so forth. We can use this information to study how to better calibrate tau1 and tau2. So tau1 we can select simply by using the method proposed by Shanshan and Debuchi of examining the semi-group properties. And count two is a bit trickier, hard to select it because we want to capture the information of the best manifold and also from Base manifold and also from the fiber bundle. And the parameter tau1 and tau2 control the amount of information that is taken into account from the base manifold and from the fibers. If we take tau2 large enough, and that's what we'll see in the toy example that I will show you in a minute, we will observe the diffusion on the fibers only. Okay, so the toy example is the following. And we selected to use this one because looking on the collection of teeth is a bit tricky when we are. Of TIFF is a bit tricky when we are trying to analyze if our metal is working as we expect. So we took the base manifold as this circle, and all the fibers are different variations of it, meaning ellipses with different axes. And we see a tube concatenating all of those ellipses. Each red ellipse is depicted in the same here on this tube. And we have first ellipses that start squished and we elongate them. Squished and we elongate them along the way. Once we calculate the horizontal diffusion map and project the manifold of those ellipses to three-dimensional shape, we get this closed curve. And basically, the color here represents different ellipses that are projected. Again, we see that they are projected to the same surface. And now we can start. And now we can start to analyze and see how the geometry of the eigenvectors are connected and change once we change the tau to parameter. So let's color each ellipse by the eigenvector. So for example, this is the first eigenvector, and we can color the first ellipse, the second ellipse by the second eigenvector, and so on and so forth. Second eigenvector, and so on, and so forth. And so, but we so we see basically the resemblance in the eigenvectors along different fibers. We can perform this for different eigenvectors. And actually, that's what we did. We played with the tau, so we started with tau 2 equals infinity, meaning we have more information that is coming from the fibers, and that's what we see that resemblance along the fibers themselves. While if we decrease tau2 to 2 minus 10, for example, we see that although the first again vectors will still represent the fibers, but we are starting to feel the geometry of the base manifold. And we can tune the tau too so we will win from both worlds. So finally we can tune and get to the fine registration flows. Fine registration flow. So we have the manifold of those shapes, we calculate the horizontal diffusion map, we project all the TIFF to this single three-dimensional domain. Now we are doing the registration. This is an illustration how it is performed. We have this reference shape which is colored here in blue, and we have Colored here in blue, and we have one point that we will be looking now. We have additional shape that we would like to propagate to it the landmarks of the first shape. So we are finding the closest triangle because we are looking on shapes, but here I demonstrated on curves the closest triangle that represents from the second. Represents from the second shape we look on the projection of the original point y 1i to this triangle. We find the barycentric coordinates that actually represent this point in the current triangle based on the points from the second shape of y. Of y lj and y lj plus 1 later on now we have the barycentric coordinates meaning the weights and we can use them to create a new point on the original tooth. So what are we doing? We are generating a new point X L J in that we define it, it's an iterative process, so we define it in the next iteration. So we define it in the next iteration of k plus 1. As here is the simple case of just interpolating the two points that we have here. So each point will basically be a weighted average of the points from the TIF. So now after we defined a new set of points on the TIFF again, we kind of resampled it based on the points that we propagated from the reference TIFF. We performed this. We perform this process all over again until we converge, meaning we calculate the horizontal diffusion map on the new points from this iteration, and so on and so forth. And we saw in the toy example that once we sample the points from the base manifold, the circle, we're able to propagate them to all of the ellipses. And we later performed it on the molar chiff. So I will just show you. And I will just show you briefly the results on the molar teeth. So, we did two experiments. One was on molar teeth that was densely sampled with 5,000 points per teeth, and one was for teeth that were sampled was with 500 points. So, for 5,000 points that were densely sampled, that's the result that we get. We see that we propagate the points from the right to the teeth on the left. TIFF on the left. The initial point on the left is if we look on the zoom area, is the one we started with star, and later we move to the solid one. So because the points are sampled so densely, it's very hard to see that there is some kind of change. But we see that in certain areas, for example, it's logical that on high curvature there will be changes that will occur. We see We see the change. In order to illustrate it better, we sub-sampled the 5,000 points and calculated and sub-sampled only 500 points from them. And again, we propagated the points from the right to the left. We see that the points starting with the star moved quite substantially because it's no longer such densely assembled. And densely sampled teeth. And we see that they are both moving, both the light blue and the dark blue moving in the same direction. And if we compare them to the teeth that we came from, they're moving towards the side of the teeth other than the middle of it, and it kind of makes sense. So this is the current result that we got two weeks ago, and we are very excited that it's finally. We are very excited that it's finally we see the results on Modern Chief and not only the ellipses. And what's next? So, next, we want to evaluate the success of the registration and have some metrics to evaluate how good or not good are we doing. We have this new exciting data sets that are collected by Alicia now of Hammett and TALUS. So, the first challenge is: how do we register? The first challenge is: how do we register bones that were some of them, some of the species have bones that were fused, and some of them have two bones? How do we register them for the comparison task that we'll perform? And we also look for comparing the correlation between the change in the hammer and tau's. So, Rob already mentioned the tools that exist that were developed. That were developed in our group, the Auto3GM and SAMS. But here are the links if you want to look for them one more time. I want to thank the people that support me and my group. And also, last but not least, before I say thank you for listening, I kindly ask the organizers to advertise a session that we are organizing in the next GMM and that will be happening in January 2024 about. About computational techniques to study the geometry of the shape space. And I think this workshop was a big success. And I hope that you will all come and listen and join us in that session. If you want to submit an abstract, so the abstract submission is open in the JMM site until September 12th. And please drop me an email that I will know that. An email that I will know that you are interested in talking. So, thank you very much for your attention. Questions? How much do you trust your faith manifold? How do you have some way of knowing how with your base manifold? Yeah, you say you all cover base manifold. We are not finding a parametrization of the base manifold. We are just assuming that it exists out there. And we hope that the denoising process. We hope that the denoising processes of the TIF and the similarity between them will make the base manifold quite the geometry trust forming. But we didn't measure any measurements about the exactness of the space manifold. So it's a good input. We can think about it. Yeah, I have to listen to you because it's After this, then you have to see much for everything. You have this horizontal diffusion, and then you're putting it into this lower-dimensional space, and then you have the template, and you're doing your final research. So, I'm assuming the top three would say how well you can do your financial. I'm sorry, it's really hard to hear the question. I heard something about the project. I heard something about w the the projection that we are doing to low-dimensional space, but uh w what are you asking? Uh I was just wondering how based on the low dimensional how the properties of that might affect your file registration and you know that you basically you're doing like uh sort of like a matching problem, right? Because you're doing the linear interpolation yeah we are doing the linear interpolation on the local um geometry. Exactly. You have a variable number of points, right? Your base value manifold, the data space that you have, must be sufficiently smooth. I assume, at least not to be convex in order to properly match. Yeah, we assume that the surfaces were quite densely sampled, so we can actually perform this projection in a reliable way. And in a reliable way, that we will be able to find the closest triangle from the mesh that we'll be able to use for our re-registration. I was wondering, if you have a data set that consists of time series of shapes, would you adapt your framework to kind of reflect that? To kind of reflect that, right? So, your place main focus would be maybe the space of shapes at time zero, and then you'd like to have a representation that whether the time could be included in the fiber bundle.