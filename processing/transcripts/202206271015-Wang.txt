Thank you very much to the organizers for inviting me. Today I'm going to give a very brief introduction to causal inference. So I'm told to aim at a very basic level and try to go through some of the fundamental concepts and maybe the fundamental differences between several paradigms to causal inference. So a canonical question in causal inference is we want to estimate the causal effect of a particular treatment on our Of a particular treatment or outcome. So, for example, we might be interested in what's the effect of, say, having air pollution on your temperature. But, of course, what makes this problem not so trivial or even difficult is that we, although we can collect data on air pollution in several locations, and we can also collect data on temperature in many locations, we know that association is not causal. But one explanation for this can One explanation for this can be say due to weather conditions. So, if you have a windy day or even if you have a storm, then probably this is going to blow all the pollutants away. But on the other hand, this is perhaps also going to lower the temperature. So even if the air pollution has no causal effect whatsoever on temperature, you may still observe an association between these two variables in the data set, not because of their causal effect, but because of the so-called confounding effect. Because of this so-called confounding effect due to these weather conditions. And the associations we typically observe in a data set, you can see from this graph, it can be seen as a combination of two mechanisms. So one is the causal effect of air pollution on temperature, which is represented by the red arrow over here. And another one is this confounding factor due to weather conditions. So we want to. So, we want to, our goal in causal inference is try to distinguish these two mechanisms and estimate what's the causal effect of air pollution on temperature. The reason this is important because if there is a causal effect, then it's possible to reduce or even control the temperature by reducing air pollutions. But if there's no causal effect or the association between air pollution and temperature is due to these external confounders, The external confounders, then intervene on the air pollution would not have an effect on temperature. So, to estimate this effect, one canonical approach in statistics is we run regression models. This is all we know in statistics. I mean, I'm just having a very simple and naive linear regression here, but you can think of this as extremal regression or your favorite machine learning models. That doesn't really matter. Just for the sake of simplicity, Just for the sake of simplicity, I'm just putting a linear regression here. So, in slash 101, you will be asked to fit this linear regression, and then somehow you try to say this coefficient for A, which is a treatment, beta 1, will be, you hope that this is close to the causal effect that you want to get. So, the main question or the key question that I want to talk about in this talk is: so, under what conditions can we really What conditions can we really do so? Under what conditions can we interpret this coefficient estimate, either from these linear regressions or from more complex maybe climate models, can we interpret this as causal parameters? So to answer this question, we need to first address what do we mean actually exactly by causal effect and under what conditions can we interpret this beta one as a causal effect? And if this condition fail, what can we do? And if this condition fails, what can we do otherwise? So, these are some of the big questions in causal inference. So, the rest of my talk will be divided into two parts. In the first part, I will try to briefly discuss two paradigms in causal inference. So, one of them I will describe as a mechanistic approach. This is more widely used or more aligned with the traditional spirit. The traditional spirit in physics and applied mathematics. And another approach, which I will call an agnostic approach, and I think this is more aligned with the spirit of statistics and machine learning and data-driven approaches. And you will see that there are some deep connections between these approaches, but there will also be some subtle but important differences. Then I will proceed to go on to briefly discuss some of the classical approaches. Discuss some of the classical approaches in causal inference that will allow you to estimate this causal effect. Okay, so let me first talk about the two frameworks in causal inference. So the first framework I'm going to mention is called the structural equation models. So this is the mechanistic approaches to causal inference. So how this approach proceeds is suppose we have this. Suppose we have this graph on the left-hand side, and this is what we have in mind. Suppose this is just a very simple system. We just have three players here, weather conditions, air pollution, and temperature. And the list arrows on this graph will just represent our knowledge or our physical knowledge about how these different players in the system interact. Okay, so on this system, this is totally based on the Totally based on the prior knowledge from the physics that we know that weather conditions may influence air pollution, and we assume that weather conditions may also influence temperature, and we also suspect air pollution may affect temperature. So, to write down this our assumptions mathematically, we will have a set of equations on the right. So, how do we write down these equations? So, how we write down these equations? So, we first start from the nodes that have no arrows going into it. Okay, so we have three nodes here: X, A, and Y. You can see that X is the only node that has no arrow going into it. So, this is sort of called a root cause. So, we start from this kind of root causes. So, in this graph, this is X, and we say X is some random variable epsilon of X. And the next, we And the next, we are going to model air pollution A. So, on the graph, you can see that there's an arrow going from X to A. So, to write down this mathematically, we're going to say A is a function of X, which is the weather condition here that has an error going to A and also some random error, epsilon A. So, in terms of structural equation models, we write A equals F A of X and epsilon A. And finally, we move on to Y. And finally, we move on to y, which is our temperature. So we can see that there are two nodes have arrows going into y, both a and x. So in terms of structure equation models, we're going to write y equals fy of a x and epsilon y. So over in this sort of structure equation models, an implicit assumption, people may say it or not, is that they assume that all the errors are independent. Okay, so this why this is usually called non-parametric structure equation models. Non-parametric structure equation models with independent errors. Of course, to be able to actually apply this in practice and estimate the parameters, often people are going to make some sort of parametric assumptions. So that it's possible to even estimate these parameters. So one very simple example is linear structure equation models where you assume all the relationships in the systems linear. Of course, maybe more realistic. Of course, maybe more realistic in climate models, you assume these are PDEs, right? So instead of a linear relationships, you assume a sort of a structure equation, partial differential equations. But the idea is that this is some sort of parametric assumptions. It's a system with some parameters that you try to estimate. Okay, so now let me try to explain what's the difference between these structural equation models. Between the structural equation models and the usual statistical models that we are familiar with, or most statisticians are using every day. So, there are actually two set of meanings assigned to these structural equation models. So, when you write down a set of equations and you call the structure equation models, it will specify what actually happens in observational world. Okay, so these three equations will coincide with just the parametric regression. Coincide with just the parametric regression models, you have or you commonly use in statistics, it just describes the word that you observe, but you don't intervene on the system. This is a description of what you observe. But also, quite critically, it's a list set of structure equation models also specify what would happen if you were to intervene on this system. Okay, so there's a different. Okay, so there is a different second, which is not very obvious from the write-up here, is when you write down structure equation models, I also specify if you were to intervene on the system, what would happen to the other variables on the system? Okay, so for example, here, what this linear structure equation model will tell us is: suppose that I'm able to set A to zero. Suppose that I'm If suppose that I'm have some magic to reduce the air pollution level to zero, then this structure equation models also specify what would happen to all the downstream variables. So in this case, it's a temperature. So at least the models also assume what would happen to temperature if I were to set the air pollution level to zero. So this is a very strong assumption. And it's the assumption that's not testable from the data, but this is From the data, right? But this is embedded in this structure equation model framework. So then this is this kind of assumption is what distinguishes these structure equation models with our regular statistical model. So maybe it's helpful to draw an analogy to physics law here, right? So when we write down F equals MA, I mean, at first, this is just a summary of the observation from the real world. But maybe we if you just But maybe we, if you just collect the data from many observations, right, you write, you put acceleration on the x-axis, you put force on the y-axis, you put all the points on the on the as a scatter plot, you will see that they line perfectly on a straight line going through the origin. And the slope will be the mass. So this is the one layer of meaning, which is a summary of the word that we observe. But for this, to go from a summary of the word words, To go from a summary of observations to a physics theory, it actually contains a second layer of meaning, which is if I were to apply a different force to the system, then I would observe a different acceleration. So this sort of counterfactual meaning is what makes an observation a physical theory. Okay, so similarly, come back to our example. So in general, So in general, in physics, maybe listings are very accurate. We don't need to care about list episodes, at least in classical physics. But the Schaucher equation model is very similar to the physics law, except that now we just have this actual term of epsilon. So this will represent some random error that we do not have control over. Okay, so if we are happy to set this. Happy to set this happy to assume this sort of structure equation models, then our causal effect will just be the coefficient that corresponds to the treatment in the structure equation models. So in this case, it's just beta one over here. So definitely, once you can't be to write down a structure equation model, then the things are perfect. You basically know everything that happened in the system. So defining causal effect is easy. You just look at the coefficient and this is your causal effect. And this is your causal effect. And now, again, this is the third assumption in this structure equation models. It's underlying this model is that this kind of structure equation models also make the so-called stability assumption that the parameters of these structure equation models will be the same across different worlds. Remember, it has two kinds of meanings. First, it will categorize what happens. it will categorize what happened in the observational world and the second it will categorize what would happen if you want to intervene on this on this system and the underlying assumption this is one of the key assumptions in the structural equation models is the relationships among these variables including the coefficient of these parameters will remain the same across different worlds across observational world and across Across the observational world and across experimental worlds. And because of this assumption, you can actually use a regression coefficient to represent the causal effect. Because you can use the observational world to estimate these parameters in a system. The analytics assumption lists parameters the same across observational world and experimental world. Then you can use your observational data to estimate these causal parameters. So this is again a subtle. Is again a subtle condition that people overignore, but this is one of the key assumptions that will allow you to estimate these causal parameters with this structural equation model approach. Okay, so just a very quick summary of this parametric structure equation models. I think this is a mechanistic approach to causal inference. And the advantage is obvious, right? Once you know the system, you can estimate the parameters. This will allow you to Uh, you this will allow you to make an inference with uh real-world interpretations and very detailed predictions. Basically, you are now the god, you know exactly what happened in this system. But of course, this comes with very strong assumptions, often parametric assumptions, because it assumes knowledge on the relationships, not only between the variables, the treatment and outcome, but also assumes knowledge on all the players in the system. In the system. In a kind model, this can involve many players that you need to measure, and you assume that you know their relationships through this modeling. And not only that, sometimes you're required to make parametric assumptions so that you can be able to estimate these parameters. And you also make this third assumption, the subility assumption, that these relationships will remain constant. It doesn't matter. Doesn't matter if you were to observe the system or if you were to intervene on the system and set, say, CO2 emission to a different level, and so on. So, these assumptions are all crucial for you to be able to draw causal conclusions from these kind of models. It's great if this assumption holds, but of course, a natural follow-up question is: if any of these assumptions fail, it's not entirely clear. It's not entirely clear how to even define the causal effects. Remember, I say the causal effects beta one in the model, but if the model is not linear, right? So beta one is not well defined. So maybe you can say, okay, maybe it's still approximation to the truth. But ideally, we would like to define our target so that it's independent of the data we observe. So here comes the second. So, here comes the second approach, which I will call an agnostic approach. And this approach is often referred to as a potential outcome or counterfactual approach. So the potential outcome is just one sentence. It just defines the potential outcome Y given treatment little A is defined as the outcome Y that would have been observed if a subject had received treatment little A. Little A. Okay, so first thing, you don't even need to understand the meaning of this sentence. First thing you'll notice is in this definition, there's only A and Y here involved. It's only the treatment and the outcome. You are interested is involved in this definition. All the other players are irrelevant here, right? It's sort of implicit in this definition. But of course, this to define this potential outcome and requires. Find this potential outcome, it requires you to pre-specify what's your treatment and what's your outcome. But you need to decide a priori: I want to look at the effect of the air pollution on temperature. And I'm not interested, perhaps, the effect of human behavior on temperature, etc. But the advantage is doesn't require knowledge of the causal system. This definition only involves A and Y, but not the other players such as X. But not the other players such as X. So let me get a little bit more concrete here using the air pollution example. So, here, let's say, just to make my discussion simpler, I'm going to say air pollution is binary. Okay, so you're either polluted or not polluted. So, Y1 will then be what the temperature in your location would be if there were air pollution in this location. So, this is entirely a counterfactual definition. Is entirely a counterfactual definition, it doesn't matter, it's defined independent of whether or not there's actually air pollution in this location, right? So, this is the hypothetical outcome that so this is why it's called a potential outcome that what a temperature would be if there were air pollution. So, if you would if you are willing to specify, to make more assumptions, to assume that you know all the systems or you know all the players in the system. Or you know, all the players in the system. Then, under the structural equation models that I talked about before, this potential outcome y1 when it now can be just written equivalently as f of y, but you replace the big A here with the one. So this is what would happen if you fix the variable A air pollution to the level one, so that it's polluted, but you keep all the other players in the system at their natural level. At their natural level. So, for example, X here, this is X is what you would naturally observe. But you just fix this temperature at one. So there is a translation between the potential outcomes and the structure equation models. Or in other words, you can think of the potential outcomes as a separation of two randomness or two source of variation into the outcome. One is a treatment. Into the outcome. One is a treatment A, which is explicit in this definition, and you fix this to the level that you want. And only for all other variations, including X and epsilon Y, you just fix them at their natural level. So if you come from a structure equation model background, or if you come from a more applied metric background, this is how you think about potential outcomes. But all the other variables will be fixed at a natural. Variables will be fixed at a natural level. And similarly, y0 here is what the temperature in your location would be if there were no air pollution in this location. And if you think from a structure equation model perspective, y0 will just be the same thing, but you replace A with 0 in this notation. Okay, so we have Y1 and Y0. So these are our true potential outcomes in this framework. Framework. And then with this two, we are going to define our causal effect for each particular location to be a contrast between this y1 and y0. Okay, so here I'm using it's minus, but you can also using a ratio between these two. It doesn't really matter. But if you are willing to assume the non-parametric structure equation models, you can write this as follows. And if you are willing to assume more, if you're willing to assume. To assume more, if you're willing to assume that everything's linear, then you can actually write the causal contrast as beta one. So you can see that these are layers of assumptions that you make by defining your causal contrast. But I think potential outcome is the most abstract or most agnostic definition of this causal effect because it doesn't even require you to know X. And it doesn't require knowledge of the full causal system. And the definition does not depend on any parametric assignment. Definition does not depend on any parametric assumptions about the system. So, now with these potential outcomes, if we were to make inference or try to estimate these potential outcomes, we have to somehow relate these potential outcomes with our observed data. So in the structural equation model approach, this was done by the stability approach, but in the potential outcome framework, this was done by the consistency assumption. So, what this means is, suppose that for each unit, we assume that there are multiple potential outcomes in front of them. Okay, so if the shipment is binary, then this guy has two potential outcomes, y1 and y0. So, there are two fates in front of them, and which one they see will depend on which draw they take, which is the treatment, the actual treatment they take. If this guy were to take treatment A. were to take treatment a equals one then the observed outcome will equals y one if this guy were to take uh treatment zero then the observed outcome will uh equals y zero right so the observed outcome will be one of the two potential outcomes and which one you see will depend on which treatment you take right so if we want to write this abstractly you can write this y equals y parenthesis big a but remember there are two layers of red Two layers of randomness here. First is which may you take represented by big A here, and also the randomness in the potential outcomes you observe. So this is a consistency assumption plays the same role as the stability assumption in the structural equation model approach. So maybe to make this, to connect this with the data a little bit, so suppose that we have these four locations. We have these four locations, and each of the four locations. So, under this framework, we assume that they have two, each of them have two potential outcomes: yi1 and yi0. And for each one, their causal effect will be defined as the difference between these two, and a is which treatment they actually take. So, this is the oracle table, right? But in practice, we don't get to observe this. For example, for the first location, For the first location, uh, is it's uh it's polluted, so its observe outcome will just equals y1. So we get to observe what will happen if it were polluted, but we don't get to observe if it were not polluted. Right, so because we don't observe y0, so we also don't get to observe y1 minus y0. So we don't get to observe the individual causal effect for the first location. Similarly, for the second location, it's not polluted, so we only get to observe y0, but not y1. observe y0 but not y1 and because y1 is not observed we also cannot observe y1 minus y0 and then similarly for the other two locations so the from this perspective fundamentally what this potential outcome framework does it reduce the causal inference problem to a missing data problem this is the is the where we try to make inference about y1 minus y0 of course this is a very difficult missing data problem because the data is missing everywhere The data is missing everywhere. We don't get to observe y1 minus y0 for any of the locations. But if we try to, if we look at the first two columns here, then we still see some hope, right? Because for Y1, we get to observe Y1 for people in the treatment group, so which is for locations with A equals one. So here A will be the sort of missing data indicator if A equals one. indicator if a equals one then we observe y one but if a equals zero we observe y zero and because we because the causal individual causal effect is missing for every location so of course there's no hope that we can estimate the causal effect for each of the individuals so usually in causal inference we aim for some sort of average over the population so one possible choice is the average causal effect you take expectation The average causal effect, you take expectation of this random variable. And if you are willing to assume, again, if you are willing to assume structural equation models, this will be exactly the same as this random variable here. So here I would first just give a quick summary of the comparison between these two frameworks. I think the parametric restructure equation models is great in that if we were able to Great in that, if you were able to get a possible structure equation models, then this gives you everything, right? It allows you to predict everything you would like to see and allow you to predict what will be observed in experimental setting. But to apply the potential outcome frameworks, you need to first specify what's the treatment you're interested in and what's the outcome you're interested in. And from there, you define your You define your potential outcomes just using the treatment and outcome, but not using the other players in the system. And on the flip side, for the structure equation models, your definitions may even also depend on the correct specifications of your models, which will include parametric assumptions, which people often recognize. This is a very strong assumption in statistics, but also your knowledge about the system, like which variable will cause which. System, like which variable will cause which, and this is not often trivial to know. And in the potential outcome framework, these causal effects can be defined non-parametrically. It's independent of your knowledge about the system. You just need to tell me what's your treatment of interest and what's your outcome of interest. And that's sufficient to define the cause and effects. And in the structure equation models approach, this relates the observational world to the experimental world via the stability. To the experimental world via the stability assumption, and in the potential outcome framework, it relates these two words via the consistency assumption. So maybe it's a good time to stop to see if there are any quick questions. Right. If you have a confounder, then you will see an association between. Then you will see an association between A and Y, but you will also see an association between A and Y 1 and Y 0. I'll get to this in a few slides. So don't worry. Yes? It depends on how out y one and Y zero are random variables at the individual level. Individual level, this is a this is a very good question. So, uh, yes, go on, finish your question first. So, are they random variables even at the indoor level? And well, the second one I actually want the statement, and I guess I consider this different random variables. These are different random variables, yeah. Okay, the second question is easier to answer. Yes, they're different. Is easier to answer, yes, they're different for sure. Uh, for the first one, uh, typically in causal inference, people regard this as fixed uh at the individual level. So for let's say they assume, I mean, this is getting philosophical, right? If you take this treatment for you in particular, right, what your outcome would be. But there's a theory that even if you assume this to be random for each individual, all the Random for each individual, all the conclusions will be the same. So all the proofs here don't really go through the same. You just take another level of expectation over the randomness there. So yeah. So philosophically, this is very interesting, but I think mathematically, this is not going to make a change. Yes. Because I don't know whether someone can actually hear the question. So I will change. Then you could use this one and then I'll okay so so my philosophical question is how do we even define treatment How do you even define treatment without having some kind of mechanistical model in the background? So, what does, and because essentially, sort of your, it seems like your treatment A will have an influence on Y, but also some kind of influence on the world in some way or another. So, what is a treatment if you don't have a set of equations somehow linking A to Y, perhaps through some other variables or something like that? Through some other variables or something like that. But is there a definition of treatment without equations? So I think the treatment will be something. So first you pose a question, does A cause B? So the treatment will depend on what you are interested in. So maybe you will ask the question, does human behavior cause air pollution or cause global warming? Right. Yeah, cause, but what do we mean like without a set of equations, what does cause mean? Equations, what does cause mean? How do you think about cause without some kind of mechanistical system in the background? So, if you look at the definition of potential outcomes, right? So this will bypass all the systems, all the mechanistic models. But you just imagine a world where you have human beings and a world without human beings, and then you contrast these two hypothetical worlds. Okay, but then in those, so essentially you have two random variables. You have two random variables, right? A and y, and you have some sort of joint distributions between them. I actually have three random variables: so a, y1, and y0. Okay, why one is what the world would be with your treatment, y0 is what the world would be without the treatment, and you are actually just contrasting those two variables. Okay, so you kind of have two independent models, so there's no dependence between y1 and y0 in a sense. They're kind of from, they can be from whatever different spaces. Statistically, they can be dependent. Statistically, they can be dependent, right? But I guess you mean we define these two random variables, yeah. Yeah, they don't have to be good. Okay, sorry, I know it's a philosophical question, so it's a good philosophical answer. Thank you, Limbo. My question might come from a point of where I didn't understand. So, on your slide 10, you were talking about the sort of a non-parametric The sort of a non-parametric SEM. And you said that you don't need to know X, I think it's slide 10. Second. Is that slide nine? Yeah, so here on the second line, you're subtracting these two functional relationships. And with a non-parametric assumption, I don't see how you would not need to know X to be able to define that. Oh, sorry. I mean, if you use the potential outcome definition, you don't. You use the potential outcome definition, you don't need to know that. If you okay, so it's just for the parametric, but for the non-parametric, you do, yeah. So, if you know the causal system, then you can define in the second line. Okay. If you further know the linearity assumption, you can define using the third line. But for the first definition, y1 minus y0, you don't need to know any of these two. Okay, that is my question. Thank you. Thank you. So, I'll give it back to you. Okay. You? Okay. Okay. Thank you. I think I still have fifty minutes. Okay, so now I'm going to talk about, try to get down to the earth and talk about how we can actually estimate this prime just estimate this causal effects. So one of the most common assumptions people Common assumption people make in the literature is they assume that there's no unmeasured confounding. So, when I say this is one of the most common assumptions, I'm not saying this is one of the most plausible assumptions. Maybe this is one of the most convenient assumptions that people make in causal inference and is to assume there's no unmet confounding. So, what this assumption means, if you were to live in the structure equation model framework, that means that there's no That means that there's no unmeasured variables in the system, right? You know all the important players in the system. You are not omitting, say, any of the important determinants of the climate system. But in the potential outcomes, what this would mean will just be using this conditional independence assumption that A is independent of Y1 and Y0 given X. So I don't have time to go into the details of the comparison between these two assumptions, but I would just want to mention that the But I would just want to mention that the first assumption will imply the second assumption. So the first assumption is a bit stronger. But on the other hand, I think the first assumption is a little bit more intuitive, right? You can think physically to yourself, am I omitting some variables in the system? Whereas the second assumption is just a set of conditional dependence assumptions, right? And it involves potential outcomes, so maybe more difficult to verify. And my interest. And my interest is in the contrast between y1 and y0, but on the population level. So, for example, here I'm just looking at layer difference. You can also look at layer ratio. So, this will be similar to the attributal risk within the first talk. If you take the ratio, this will be P1 minus P0 in the first talk. But the bottom line here is this: after you have this assumption, especially if you have Have this assumption, especially if you have this condition independence assumption, then this problem will now become a purely statistical problem. Because even though you cannot observe y1, under these assumptions, you can prove very easily in two lines that expectation of y little a, so for example, expectation of y1, can now just be written as this particular function on the right. And what's to be to notice here is for the equations on the right, this. For the equations on the right, there's no potential outcomes involved, but everything is defined in terms of observed data. So, this is now just a function of our observed data distribution. So, this question now becomes purely statistical. Okay, so at this point, if you are willing to make a no-unmeasured confounded assumption, then the causal inference problem will be reduced to a statistical problem, which might still be challenging, but I think it's a big step forward. It's a big step forward. Okay, so of course, for this particular statistical functional, there are numerous approaches trying to estimate this functional in an efficient and robust way. So I'm just going to briefly mention three approaches, but keep in mind there are many more approaches in practice. So the first approach is just take a regression adjustment. So if we focus on the function on the right, Focus on the function on the right, we can see that this is you just have this conditional expectation: y given a equals one, x. Right, so you can just use your favorite regression model to estimate this quantity. You can use linear regression, you can use non-parametric regressions, or you can use some fancy machine learning models, doesn't really matter. Well, it does matter for your performance, but in principle, you can use your favorite models to estimate this quantity and then average over all the units in the population. Uh, units in the population, then you will get an estimate of your uh of this uh potential expect mean potential outcomes. So, this is called a regression adjustment. And the second approach that's very popular in practice is called inverse probability weighting. So, remember, I mentioned that under the potential outcome approach, this causal estimation problem will now be reduced to a missing data problem. And the inverse probability weighting is a classical technique in missing data literature. Literature. So, here, in order to ask and the assumption of no unmeasured confounding turns out to be exactly the same as the missing at a random assumption in the missing data literature. So, if you assume missing, no unmeasured confounding, you assume that A is independent of Y1 given X, and this is nothing but just a missing at random. So, you're missing this indicator is A, the outcome you're interested in is Y1, and X will be your covariance. And x will be a covariance. So we can just use standard approaches for missing a random. Here, I say you can use inverse probability weighting. Of course, you can also use imputation. I mean, this is just nothing but a missing data problem. Okay, so one approach is the inverse probability weighting. So you can see that it reweights the observations by this so-called propensity score. So probability of a equals 1 given x. One given x. So, a quick recap of the two approaches I've talked about. So, if you look at the joint density or joint distribution of ya and x, you can see there are three parts, right? The joint distribution of yax can be decomposed as y given a and x and a given x and also the margin of x. So, the regression adjustment, which just, if you still recall, is modeling this part of the likelihood. This part of the likelihood is modeling y given a and x. The inverse probability weighting or the propensity approach is to model the second part in this likelihood, which is a given x. So they are utilizing information in different parts of the observed data likelihood in order to estimate the same estimate. Then, of course, you may ask, maybe we can use both of this information. So this is the so-called Information. So, this is the so-called W bus approach that allows you to model both of these pieces in the observed data likelihood. And the promise of this W bus's major is that this US major will be consistent if you either get your regression model right or if you either get your propensity score model right, but not necessarily both. So, you get two chances to get your model right. If you happen to get your regression model right, then great. model right then great your your estimate is consistent if you happen to get your professional score model right the uh your your estimate will be consistent and the relational behind this uh double robustness is if you just this if you do some math and you will see that the bias of the double robustness measure asymptotically will be can be decomposed as the bias of your regression estimate and the bias of the propensical estimate. So now you can see that if So now you can see that if either one of these converges to zero, then the bias of the W robust one will converge to zero. So this is where the W robustness property comes from. Again, I'm just a very quick introduction to estimators for average causal effect. But as you can easily imagine, there are many, many more approaches for average causal effect. But the bottom line of this, they all assume unmeasured confounding. And this is one of the key assumptions. And this is one of the key assumptions that we have to make or we have to pay attention to if we ever want to go from statistics to causal inference. I think this is one of the holy grail in modern causal inference is how to deal with this unmeasured confounding. And as you can already say, this is a very difficult problem. So there are many approaches that try to get away from this no-unmeasure confounding assumption. Away from this no-unmeasure confirming assumption, so that, but still allow you to estimate the causal effects. So, I'm going to talk about one of these approaches, but first I'm going to say the two things I want to mention. First, this is just one of the many approaches again to allow you to estimate causal effects with unmeasured confounding. And the second, there's no free lunch, right? This alternative framework will also make a different set of assumptions that let's not have. Assumptions that's not testable from data. But hopefully, in some scenarios, this can be more plausible than the no-unmeasured confounding assumption. So you just need to choose which of the assumption you think is more plausible. Okay, so what's the problem of unmeasured confounding? So before in the story, we only have three players, the air pollution, the temperature, and the weather conditions. But maybe there are also some other players that we Some other players that we did not even get to measure, right? For example, industrialization or human behavior may also influence air pollution, obviously, but may also influence temperature. So if there's this kind of external unmeasured variables players in the system, then we run into the problem of unmeasured confounding. And in this case, the There are more details here, but I can tell you that in this case, the assumption for A independent of the Y1 will now break. Okay, because they're connected through this U. So you can see that A and Y are connected not only through the causal effect and observed variable, but also through this unmeasured confounding. So as I said, this is one of the most This is one of the most central problems in causal inference. So there has been some many approaches trying to address this. But the gold standard to deal with this is, of course, if we have a randomized experiment, right? If we can just randomly flip a coin and based on the outcome of this coin, we decide if this location should be polluted and the other location should not be polluted. Then, of course, this is great. We run many such experiments and we compare the temperature. This is done. Right? But obviously, Done right, but obviously, this is not feasible. So, the next best thing we can do is the so-called instrumental variable. But suppose that we have a policy or some instrument that will affect the level of air pollution. And this policy itself needs to be random. Maybe this is due to some elections. So, we can compare the data before and after elections. So, there may be a change in the policy. Change in a policy of air pollution, or maybe this is due to some external factors. But this policy will affect the level of air pollution in a particular location or in some locations. And so we can think about this external factors such as policy. So if the policy is very effective, right? So if the policy is so strict that for locations with this policy, it will always be. It will always be, there will be no air pollution, but for locations without this policy, it will be polluted, then this will be a randomized experiment, right? Because if we assume the policy is randomized. On the other extreme, if the policy is not effective at all, then there will be no link from the policy to the air pollution. So we'll get back to our old problem of unmeasured confounding. And what usually happen in practice is sort of Happen in practice is sort of in between, right? Your policy may have an effect on reducing your air pollution, but it may not completely eliminate your pollution or may not completely decide your air pollution level. So this is sometimes called a quasi experiment, right? This is not quite an experiment, but a quasi experiment. So this is just a very quick look at. Uh look at behind the scene to see how we can estimate the causal effect of A on Y in this case. Remember, we want to know what's the effect of pollution on temperature, but we cannot directly use association between these two estimate lamps because of this unmeasured confounding due to yield. So we introduce this external factor called policy. So if under some assumptions, if the effect of If the effect of Z on Y, the policy on the temperature, can be decomposed as a product of policy on pollution and the pollution on temperature. So if this additional assumption match, then notice that if policy is randomized, we'll be able to know the effect of policy on pollution, which is gamma here. We'll also be able to know what's the effect of policy on temperature, which is gamma temperature. Gamma times delta, then we will be able to know what's delta. No, you can repeat my question. Okay, so the assumption here is that policy is not directly affecting temperature, right? You take a fusion out of it, there's no direct link between policy and temperature. Yes, this is on this slide. Okay, yeah, so what are the conditions here? So, what are the conditions here? So, there are three key conditions for this equation to hold. The first is, as Richard mentioned, the policy cannot have direct effect on the temperature. The policy can only influence air pollution, but cannot affect temperature in any other ways. So, at least the assumption is necessary because we can only estimate the total effect of Z on Y, right? But if Leon. But if there were a direct effect from Z to Y here, an arrow here, then we will not be able to estimate what's the effect that goes through this pathway Z A Y. And at least the effect that goes through this pathway Z A Y, this is what we actually want to get because we want to decompose this effect from ZAY as ZA and AY. Okay, so this is the crucial assumption that policy has no direct effect on the outcome, on the temperature directly. And we also need to assume that this policy. And we also need to assume that this policy is due to some random force. It cannot be, it must be independent of the unmeasured confounding. So that you, and because of this assumption, you can estimate the effect of policy on pollution and the policy on temperature. But if this policy, for example, is introduced because of human behavior, right? Because it's overly polluted, then we introduce this policy. Then this is not a good example. But if this policy is due to But if this policy is due to something that you can see that is close to random, right? For example, maybe one party just wins an election by a very small margin, then you can think of this as sort of random. If they win 51% versus 49%, you don't think there's a real cause of this policy, but it's just due to randomness. And also, this policy. And also, this policy obviously needs to somehow be effective for reducing the pollution, otherwise, it's not doing anything. You cannot just put any random error here as the instrumental variable. So this kind of models is one of the classical ways to deal with unmeasured confounding in causal inference. You can see that it comes with its own set of assumptions, which may or may not be more plausible than the no-unmeasured confounding assumption. Just by the way, so this model was first introduced in economics because the people there, the major company is also a crucial problem. And I think there has up to now it has been maybe three people, no, three Nobel Prize in Economics awarded to related research just in this field. And then the most recent one was last year. Okay, so a very quick summary of what. Okay, so a very quick summary of what I talked about today. I think there are two paradigms to causal inference. The first one, the structural equation models, I think is closer to what climatologists are using now. I think it's a mechanistic approaches that assume, you write down all the equations using all the physical laws, but versus the second paradigm, which is more agnostic, you just look at the treatment and outcome. The treatment and outcome, which is defined based on your question of interest, and then you proceed for your inference. The structural equation model is more intuitive and permits, give you more detailed predictions, but the potential outcomes come from fewer assumptions and is more robust to model mispecification. Then there's a huge area of how to do causal effect estimation. There are two mainstreams. One, you assume there's no unmeasured confounding. Assume there's no unmeasured confounding, and I think the more realistic ways is to stay away from this assumption and try to explore alternative frameworks for making causal inference. So I will stop here and happy to take more questions.