I'm an electrical engineering at mathematician. But since my PhD years, I've been involved in medical image processing and analysis, particularly neuroimages. And lately, most of my research agenda, my research portfolio has been around the development of validated imaging markers to provide objective means of monitoring the efficacy of drug. Efficacy of drug therapy for neurogenitive diseases. So, you'll definitely see the influence of this clinical trial use of some of our research findings in clinical trials in my presentation today. So, these are some of my conflict of interest relevant to today's talk. Since this is, I'm assuming this is order with more technical Although with more technical backgrounds, Kraut, I thought I will start with some definition, some background on neurodegenerative diseases. Neurogenerative diseases are characterized by progressive loss of selectively vulnerable population of neurons, and they can be classified according to primary clinical features like dementia, Parkinsonianisms, or motor neural disease, or anatomical distribution of. Or anatomical distribution of neurodegeneration, for instance, frontotemporal dementia or spinocerebular degeneration where the degeneration is very targeted or based on the principal molecular abnormalities like Alzheimer disease where it is defined by accumulation of amyloid plugs and tile tangles. Among all neurodegenerative diseases, we keep saying this. We keep saying this: the most common cause of dementia in elderly is actually Alzheimer's disease. And Alzheimer disease typically begins with memory impairment. It is diagnosed clinically by deficit of one congregant domain, like memory, plus another after other causes of dementia are ruled out. But the definite diagnosis of actual Alzheimer disease is still required autopsy. Is still required autopsy. And the concept of dementia is actually very old, as it goes back to the 1900s, very, very early, where a lot of Alzheimer's actually described as first patients. But as medical technology improved, both in terms of biochemistry, genetics, as well as neuroimaging, so has the understanding of dimension, its causes. Of dimension its causes, and with the improvement of brain imaging in the late 1990s, particularly, we started to see an influx of neuroimaging studies, which greatly contributed to our biological understanding and biological definition of the pathophysiological processes involved in dementia. And I'm particularly going to talk about Alzheimer's disease today. So, as a result, there are thousands of studies have been published on Studies have been published on different aspects of brain changes and pathology to show some of these pathophysiological features of structural and functional and molecular changes in patient groups. And those are usually compared to health controls where we assume that there's normal aging happening. And that actually led to this very rich neuroimaging portfolio we see in many neuroimaging initiatives nowadays. Test nowadays, but also in clinical trials as well, for various different reasons. And this portfolio includes imaging modalities ranging from structural imaging to molecular post-train emission tomography imaging. For instance, in this slide, you see T1 weighted and T2 weighted images. And those are oftentimes used to understand the structural changes in the prey. The frame, but we also acquire more functionally relevant, like diffusion-weighted images or perfusion-weighted or bold-weighted MR images to understand the state of the function of the brain together with these molecular-specific, for instance, amyloid pet imaging, which is designed molecularly to target amyloid plugs in the brain or the top head imaging. In the brain, or the top head imaging, which is sensitive and targets the taut angles that are accumulating in the brain, and various other ones that has been used in research studies, as well as, as I mentioned, clinical trials. So when we look at these big portfolio of what we call imaging biomarkers to understand the disease, the pathopidiology of the disease. Among all of them, probably vochampal atrophy is the most famous and most replicated biomarker that's been mentioned, that's been associated with Alzheimer's disease. And oftentimes we requantify cochamp atrophy from T1-weighted structural MR images. It has lots of functional properties, but one of the key properties. Properties, but one of the key functional importance of hippocampus is its involvement in episodic memory and retrieval and acquisition of the memory as well. So even though it's not actually very specific to Alzheimer disease, it's sensitive, but it's not specific for Alzheimer disease, meaning there are many other disorders and dementia types where we also see campylatrophy. See for canpal atrophy. The vocabulary atrophy as a biomarker actually allowed us to understand the natural history of the disease. And through that process, it actually allowed us to see that there's a huge need for early diagnosis and there's a huge need for therapeutical interventions earlier in the disease process. And many of those are backed up with a huge literature, particularly. With a huge literature, particularly showing how annual rate of epochable volume is associated with the actual burden of the pathology. In this case, it's the amyloid pathology, and how it varies through different disease stages in normals versus mild cognitive impairment, which is considered as a pre-drama, earlier stage of Alzheimer's disease, and in later stages of the disease, where the individual. Disease where the individuals are diagnosed with mild to moderate Alzheimer's disease. But in addition to that, we also see atrophy, but ample volume changes, tissue changes, even in individuals that have risk factors for Alzheimer's disease. One of these risk factors is this genetic risk factor of ApoE4, and carrier versus non-carriers, even in early disease stages. Even in early disease, pages show hepokal volume differences. So that absolutely added a lot to our knowledge, even though again it's not a specific biomarker for Alzheimer's disease. But I should say the major biomarker finding that had a huge impact on how we define Alzheimer's disease and how currently In how current clinical trials are actually designed, is this observation around amyloid pathology? This is an example from Alzheimer Disease Neuroimaging Initiative. It's a nationwide multi-site neuroimaging study, particularly designed to validate biomarkers for Alzheimer's disease clinical trials. And during the During the early times of amyloid PET imaging, this is an example of large beta-pair PET imaging. Sorry, one of the observations we saw in this observational ANI study was when we look at individuals clinically diagnosed as cognitively normal, about one-third of those individuals actually harbor Individuals actually harbor amyloids, Alzheimer's, amyloid pathology in their brain without showing any clinical symptoms. But at the same time, again, about 20 to 25% of individuals who are diagnosed with clinical Alzheimer disease diagnosis or dementia actually didn't have any amyloid, Alzheimer's amyloid pathology in their brain. So that brought out many questions. Out many questions, but a couple of primary ones were: the ones who didn't have this biomarker, this catology in their brain, but still diagnosed with Alzheimer's disease or dementia, they basically have dementia due to something else other than AD. And if they are enrolled in a clinical trial that targets the AD pathology, they are not going to benefit from those trials. At the same time, the individuals that are The individuals that are performing as cognitively normal, but still carrying all these amyloid pathology in their brain, they could be pre-clinical AD individuals and they might be presenting this very important window for prevention against development of Alzheimer's disease or progression of Alzheimer's disease. So, this amyloid phenotype. This amyloid phenotyping, as I mentioned, was one of the key game changers from biomarkers perspectives and perspective in Alzheimer's domain. And again, there are a huge literature with some of the key observations, again, really changing, shaping how we are designing the clinical trials or how we're defining the Alzheimer's diseases. One is again. One is again this observation where if the individuals are stratified, not based on their cognitive performance or their clinical diagnosis, but based on underlying biological profiles, we can actually detect the decline in their contact performance better. So, this is one example where amyloid imaging, amyloid phenotypes. Amyloid imaging, amyloid phenotyping is applied to, again, clinically normal group and showing clearly that individuals that are amyloid negative based on the phenotyping, they're super stable over six years and beyond. But individuals who were amyloid positive, even at the baseline, they do cross by the by six. Dear, they do cross the threshold for cognitive impairment, so they do decline faster. And this was replicated in various cohorts worldwide, showing the universal impact of this biomarker. It's not a cohort-dependent observation. It does generalize and it generalizes universally, not in United States cohorts. And this idea of And this idea of stratifying basal biomarkers or enriching bason biomarker evidence can be actually extended. And this was another study we looked at where individuals are now certified to groups based on presence of different biomarkers, either amyloid or neurodegeneration biomarkers like amyloid tautothelopy, tau or hippocampal atrophy, but also For cathartrophy, but also based on their risk for Alzheimer's disease, in this case, APOE. And we looked at the presence of one, two, or more of these risk factors or biological changes and how that affects their trajectory, decline trajectory over time. And again, it's the same thing that the more biological evidence, biological changes they present with, the faster they. With the faster they decline. So, this brings us to this new definition. This shift happened a couple years ago in Alzheimer's domain. Basically, rather than defining the disease purely based on clinical symptoms, clinical diagnosis, a new framework, it was research framework, but it's introduced as a bio. As a biological definition of Alzheimer disease, which includes evidence for amyloid pathology, evidence for tau pathology using imaging or fluid biomarkers, and evidence for neurodegeneration, either using structural imaging or metabolic imaging to capture neuronal integrity. And this was the concept behind, maybe you heard about it, behind the ATN analog. The ATN, Amylotau and Neurodegeneration certification of the individuals. And it's a kind of a binary certification, and being positive or being negative in these three categories puts individuals onto different spectrum of Alzheimer's disease or outside the Alzheimer spectrum, meaning they have non-Azheimer pathological changes, but they still show cognitive impairment, which is due to something else. Due to something else other than Alzheimer's pathology. And we've been seeing integration of this biological definition of Alzheimer's disease in clinical trials. Actually, that happened quite fast. And this is a relatively older table, but summarizing some of the most recent trials we've seen for Alzheimer's disease. Seen an Alzheimer's for Alzheimer disease. And many of them not only screen the patients based on their cognitive status, which is, I should say, still the primary screening, but the participants are now going through additional pre-screening based on the presence or absence of some of these biological pathological changes and sometimes also risk factors as well. factors as well so um when we look at again just looking at this biomarker landscape we've been using for alzheimer disease um the definition um the pathophysiological or the biological definition of alzheimer disease requires amyloid plugs um tile tangles um neuronal loss and they they lead to the cognitive decline cognitive impairments and in terms of biomarkers we've been using In terms of biomarkers, we've been using amyloid PET imaging or CSF or nowadays plasma amyloid biomarkers for amyloid classification, tau PET imaging or CSF tau proteins for classification for tau positivity. And then we have various imaging and pollute biomarkers, including structural MRI, FDG PET, or CSF or plasma, neuroflaments. Plasma neuroflameth light biomarkers to quantify neurogenetic positivity in individuals. And one of the questions we ask, though, we have all these biomarkers and we're trying to characterize these individuals. So to what extent AD, our current Alzheimer's disease biomarkers explain the variance we see in clinical outcome measures used in Measures used in clinical trials. And it was a study again we did using Adney Alzheimer Disease Neuroimaging Initiative data sets. Again, it's an observational study. There's no treatment in this study. So we kind of not even looking at placebo, but just kind of looking at the natural history of the counter decline and asking the question to what extent all these biomarkers. All the biomarkers we have, we validated, we can explain the variance in counter decline. And we use our imaging biomarkers for amyloid, we use amyloid PAT. For tau, we use tau-pat imaging. For neurodegeneration, we use structural diatrophy quantification from structural MRI. On top of that, we also accounted for risk. Accounted for risk factors, either from a demographic perspective, like age, gender, sex, female versus male, but also APE as another risk factor and cerebrovascular risk factors. And for cerebrovascular risk factor, we use FLARMR imaging to quantify what matter relations are done. And using a partial least squares, a multimodal partial least squares structural equation model, we try to explain. Cohesion model: We try to explain the variance on key outcome measures used in clinical trials. And those, there are two widely used one. One is ADAS-COC that is primarily used for AD treatment trials for late mild to moderate AD cases. And there's another measure that is pre-clinical amyloid-related. Clinical amyloid-related cognitive decline measure that is optimized and designed for preclinical trials. But either way, when we look at these measures and the change in these measures over two-year period, what we observed was amyloid cell and atrophy, that biomarker, those biomarkers we use to define Alzheimer's disease, only explains part of the variance. Part of the variance we've seen come to decline. It's about 50, maybe 56% in this cohort. And this was actually very consistent with autopsy studies previously published. They don't use biomarkers, but they use pathological indices observed at the autopsy to explain pre-death, pre-post-antimortem decline. Declined. And it was very consistent with those studies. Each biomarker, like amyloid tau atrophy, explains certain aspects, but definitely it's the tau anatrophy that explains the most of the decline, which is again consistent with the biological definition of the disease. It's the neuronal dysfunctional function, neuronal debt that leads to clinical symptoms, not necessarily. Symptoms, not necessarily the amyloid by itself. So, one of the conclusions from this study is: even though we can use these biomarkers to biologically define Alzheimer's disease, the disease is very complicated. It's not just amyloid and ta or neurodegeneration. There are other things happening in just based on our observations, and again, based on data from autopsy, treating or removing ambulance. Treating or removing amyloid, even completely, it's only going to be partially effective in slowing of the cognitive decline. And this is exactly what we've been observing in recent clinical trials as well, like considering Aduhan from Biogen or Lilly's recent trials on amyloid-targeted treatment for Alzheimer's. Of treatment for Alzheimer's. Even though they can show that they can remove amyloid clocks up to 70 or 80 percent, the improvement in the cognitive outcomes have been very limited to 25 to 50 percent. So what is the problem? Like what is that additional percentage we cannot explain? And part of that is, again, coming from our knowledge from autopsy studies is. Autopsy studies is what we call comorbid copathologies. At autopsy, it's so rare to see what's called pure Alzheimer's disease patients, meaning it's very rare to see an individual who died because of Alzheimer disease presenting with only amyloid and tar pathology. They oftentimes present with additional age-related Age-related comorbid pathologies that can vary from one individual to another, but oftentimes they have cerebrovascular pathology, they have UV body disease pathology, and they have TDP4 to 3 or cerebral amyloid and giopoty CAA. And again, from autopsy literature, what we know is each of these, although AD pathology explains most of their counter functions. Most of their cognitive function and cognitive decline. But each of these additional comorbid pathologies actually adds on to their cognitive impairment and adds on to their cognitive decline. And this is just one example from Rush study showing how Lewy body pathologies particularly increase the rate of that affects the trajectory of late life counter decline. But there are all these other studies, very nice. These other studies, very nicely replicating the contribution of these comorbid pathologies on top of the AD pathology. So, from medical trials perspective, I'm just gonna slow down and just go through this kind of a cartoon example. So, we know from imaging studies and neuropathology studies that AD pathologies explain a good Co-pathologies explain a good chunk of the cognitive decline, cognitive impairment, but co-pathologies definitely add noise or contribute to the actual trajectory, the actual rate of the counter decline. So let's assume we're designing an AD clinical trial. And in this trial, what we're targeting is a treatment that's going to slow Is a treatment that's going to slow down the decline by 50%. So, this is assuming the dotted line is what we're expecting from normal aging, the solid black line is the expected rate of content decline on individuals diagnosed with Alzheimer's disease by clinical diagnosis. And the purple lines are targeted. That is the ideal scenario. And if everyone in this clinical trial has pure Alzheimer disease pathology, meaning they don't have any comorbid core pathologies and only amyloid entau is contributing to their cognitive decline. Again, hypothetically, we can kind of assume that this entire decline is primarily driven by tap pathology and a little bit with amyloid pathology. And if the treatment is really effective and working on AD catology, in this case, we're assuming it's tau, then the actual slowing down we will observe will be the black line, which will be very close to our idealized decline or slowing down. We assumed when we designed this trial. But in reality, But in reality, what we're seeing in clinical trials is this mixture of participants with comorbid pathologies. And they will be presenting with amyloid and tau if they're screened properly for AD pathologies. But to varying degrees, they're going to harbor different comorbid pathologies. It could be alpha senior lobby bodies. TDP43 or vascular or CAA. And even if the treatment is really 50% effective on the AD pathology, what we'll actually observe is only this smaller effect on the slowing down of the cognitive decline because that is the 50% of what is attributed. Of what is attributed to the AD-related counter decline. So, in reality, what's happening is while we're expecting a slowing down on the overall counter decline up to 50%, what we will observe is a slowing down of maybe 15 to 20% on overall cognitive decline, depending on to what extent the actual AD pathology is contributing to the cognitive. Contributing to the cognitive rate of the cognitive decline. So, what are the solutions that are proposed is one solution is modifying the recruitment goals. If the goal is to look at effect of a treatment on the AD pathology, maybe one idea is going back earlier or younger. And the logic there is if they are younger, they're not going to have age-related. They're not going to have age-related comorbid pathologies, and it's more likely that they have pure AD pathology driving their cognitive impairment and their cognitive decline. So that's one solution potentially. The second solution is modifying the sample size or the effect size based on some assumptions around the contribution of each co-pathology. And another And another option is relative, it's related to the second option is doing a more precision medicine approach. And this is what I'll come back in in a couple minutes. So before that, all of these ideas are not actually new ideas. They've been practiced in different clinical trials. So rather than doing that traditional diagnostic selection, we've been already doing biomarker analysis and certifying individuals or screening individuals, but we can actually take that one step further potentially in a precision medicine approach if we know the composition of each individual or presentation of each individual. Representation of each individual and assign each individual to the right treatment based on that knowledge. That is the one basic idea behind precision medicine. And it's kind of happening with multi-dimensional or multi-system treatment approaches. So just going back to our problem to solve a cover. To so, how can we adjust for contribution of these comorbid pathologies while individuals are still alive? One big challenge we're having now is biomarkers. Because all of the information, all of the knowledge we have about these comorbid pathologies and their contribution to the disease and cognitive impairments is actually coming from autopsy studies, not inevitable antimony. Not in evil anti-mortem studies. The biomarkers, all established biomarkers we have right now, they are all established for AD pathology, not for non-AD pathologies. But at the same time, from those autopsy studies, we've been building a nice knowledge base about how these comorbid pathologies might have affected the brain, either from structural changes. Either from structural changes perspective or functional changes perspective. And this is kind of a rough summary from the literature where, again, using neuroimaging and autopsy jointly to understand the signatures of these comorbid non-AD pathologies showing how TDP presence of TDP43 affects atrophy in medial temporal log. And it's a dose-dependent effect, meaning the Meaning, the more TDB43 spreads, the more medial temporal love affected in these individuals, or individuals with Lewy body pathology in the middle section, how those actually could have more sparing of some of the middle temporal lobe structures, but also showing greater atrophy in other brain regions, particularly related to sensory motor. Related to sensory motor function. And again, CAA, which is another very common comorbid pathology in Alzheimer's disease, that is the amyloid angiopathy. It's been associated with this signature, atrophy signature, again, using autopsy validated cohorts. So one of the questions we ask is: can we leverage some of these Some of these autopsy knowledge coming from autopsy neuropathology and currently available biomarkers or currently available imaging modalities we have to develop, build what I call a computational biomarker. It's not a molecular biomarker. It's not designed for these pathologies, but it's a way for us to impute the presence of some of these non-AD pathologies. And this imputation I And this invitation idea is actually a very old idea. It's not something new. We've been playing around and many in this domain has been playing around imputing presence of certain pathologies using clinically available metrics or measures. And this was one study where we looked at, for instance, amyloid pathology. We do have clear biomass. Clear biomarkers, molecular biomarkers like amyloid PET imaging or CSF amyloid assessments to truly detect amyloid, but they are either too expensive, not widely available, or invasive. And it really, although they are gold standard, it makes it very difficult to scale these biomarkers and make it widely available, especially when we think from diversity perspectives. When we think from a diversity perspective for clinical trials or for diagnosis or treatment, this has been a big barrier. So we've been looking at plasma or MR imaging from that perspective. Can we use these information from these modalities to impute? It's not the gold standard, but it's a minimally invasive, cost-effective, and scalable approach to screen. Approach to screen individuals for amyloid pathology. There's a huge literature around this imputation idea, how to impute the presence of different pathologies and amyloid has been the focus in this domain. It ranges from using clinical demographic information to incorporating genomics or plasma fluid biomarkers to Fluid biomarkers to different imaging modalities, and some perform really good, very nice, like very high sensitive dense specificity. Some might not be as good, but depending on the setup and depending on the needs, each might have a different use. And we also published on this a while ago. This was one of the early studies we did using MR imaging, structural MR imaging, to Structural MR imaging to impute amyloid positivity in mild cognitive impairment individuals with relatively high sensitivity and specificity and also showing that we can not just impute positive versus negative phenotype, but also impute the burden of amyloids, the global amyloid, using some of these approaches. And we extended that. And we extended that using multi-modal MR imaging, not just looking at structural but also functional, in this case, blood flow changes, and to test if that will allow us to detect amyloid in earlier disease stages. This case, we were looking at early mild cognitive impairment and again, showing very high positive predictive value and negative predictive value and highlighting how. Predictive value and highlighting how functional information actually contributes to this imputation model. But one of the things I want to highlight is this one study we did with Lilly and looking at their real-life clinical trial data using the imputation methods. Because we can impute, but ultimately what we want to show is regardless of the method used for amyloid. Of the method used for amyloid phenotyping, we want to detect the same difference in terms of the clinical impairment and the clinical decline. And this was one study we did with Lilly on their expedition clinical trial and clearly showing that, regardless of using either PET imaging or this computational imputation approach, when we stratify individuals to Is stratifying individuals to their amyloid phenotypes, we can still clearly see how amyloid positive versus amyloid-negative individuals are declining differently throughout the clinical trial. So that is very important to doing that translation of such a biomarker for clinical use or clinical trial use to show its clinical meaning or clinical usefulness. So just going back to one of the challenges is the lack of the biomarkers for non-AD comorbid pathologies and can we impute those from using the data, all the information, all the biomarkers we have for in vivo in anti-mortem. In this case, we have MR imaging, we have amyloid and top heat imaging for the AD pathologies. AD pathologies combined with their demographics and some risk factors and cognition. Can we build a computational model to predict or impute the presence of these non-AD pathologies? In this case, we've been looking at TDP43, LuwaBuddy, NCAA. And this information, that outcome we're trying to impute, it's actually coming from post-smart autopsy pathology reports. Pathology reports. So, what that means is we've been working with, we've been leveraging autopsy studies where there are anti-mortem MR imaging, anti-mortem clinical assessments are done, but they got full neuropathological exam after that. And that required for us to combine multiple studies in this case, it's ANI, OASIS, and NAC, and these are. And these are some of the big imaging initiatives around understanding Alzheimer's disease and the progression of the Alzheimer disease. And it's a relatively small cohort, but from autopsy perspective, it's a decent sized cohort. Just to highlight what we call Alzheimer disease individuals, meaning they have moderate to high Alzheimer's. Have moderate to high Alzheimer disease neuropathological changes. Almost all of them, 98% of those individuals presented with one or more comorbid pathologies in this cohort. And similarly, individuals with non-too-low Alzheimer disease neuropathological changes, you can think those as normal aging individuals. Even those have about 73%, more than 70% of those individuals have. 70% of those individuals have non-AD pathological changes in their brains. So, a couple key things I should mention here is we're trying to leverage autopsy-validated cohorts. Those are very small in terms of sample sizes, very difficult to find. So, studies like these require merging some of multiple of these cohorts to get. Of these cohorts to get to improve our power and to achieve a relatively bigger sample size. But what that means is harmonization of the data. And I will come back to that in a couple minutes towards the end of my presentation. So just a side note, what we use here is from a biomarkers perspective, we use Combat to harmonize our imaging biomarker measures. Imaging biomarker measures to study these three cohorts together. Just jump into the final results from this study. I'll be happy to talk about the details of the methods later, but this was a relatively simple modeling approach. We use multi-label training approaches to impute. These three comorbid pathologies simultaneously. Again, we are limiting our inputs to anti-mortem demographics, cognitive performance, measures of MR volumetrics from anti-mortem imaging, and amyloid and tile positivity from anti-mortem imaging. And what we've been observing is. And what we've been observing is it's not perfect, but to some extent with the full model using all these multidisciplinary inputs, factors, close to 90%. So we can get AUC close to or about 0.9. And that is beyond just using clinical information or demographic information or Or demographic information, or just using AD-related pathology, just to show the added value of MRI imaging using that information from MR imaging and added value of combining multidisciplinary information in this study. But the key thing, I'm just going to skip this one, but the key thing we wanted to show was if we know, if we can impute presence of these comorbid pathologies. Um, comorbid pathologies. Are we going to be able to explain more variance in outcome measures using clinical trials? Just going back to that earlier study I mentioned. And here we repeated a similar analysis to look at to what extent now we can explain the variance in cognitive decline in the same anti-cohort. And what we showed was with AD biomarkers. With AD biomarkers, we can explain up to 43% of the variants, but with the knowledge of non-AD catalogies, TDP43, Libubathy, NCAA, including the contribution of those, we can actually explain another additional 13 to 21% of the variance we see in these outcome measures that are used in clinical trials. A clinical trial. So it definitely has some potential to improve the power we have in these clinical trials. Just wanted to highlight one thing. When we further look which non-AD pathology actually contributes to this variance the most, it was lily body pathology more than TDP43 and CAA, which is very consistent with the autopsy studies. The autopsy studies. This is just one example again, showing how presence of Lewybody is actually impacting the carcto decline more than other co-pathology. So our observation was very consistent with that. Just running further dwelling on how this can be used in clinical trials, we looked at some simulations where Simulations where the sample size is estimated based on the overall decline estimate, but with or without accounting for these non-AD pathological contributions. And what we showed was accounting for this non-AD pathological contributions using this computational imputation approach, we might be able to reduce the samples required sample size by. Samples require sample size by 28 percent. So, slowly wrapping up, what we're seeing is the impact of some of these data analytical tools, both in terms of our understanding of the disease pathophysiology, but also how some of these clinical trials are designed, particularly from Particularly from what we call subtyping of the pathology to better understand the diagnosis and also have a better means of monitoring the disease or prognosis. And that we believe that that's going to be a huge benefit for trial certification and identifying the treatment responders better. And this is one of the challenges I Challenges I included in my presentation. It's a very high-dimensional, what I call a landscape of pathophysiological and biomarker changes that's happening in Alzheimer's disease. And pretty much all of the modeling we've been doing or the stratification approaches we've been practicing are very binary and very one-dimensional. And very one-dimensional. What I mean is we start with, for instance, amyloid phenotyping, which is a binary amyloid positive versus negative. And we define that positive versus negative just purely based on the amyloid pathology without looking at the other pathophysiological changes and how they are related. And from there, we further stratify. So it's always that dissecting in one dimension. Dissecting in one dimension and looking part of that space and keep doing that again and again. But we know that there's a huge nonlinear interaction with these pathologies. This is just one example where it's been illustrated that amyloid and tau is interacting very actively. It's not just being amyloid, positive, or negative states. States, it's regional interactions that are very important for us to understand how pathology and disease is progressing. So, those kind of higher dimensional interactions and higher dimensional definition of these changes are something missing in this, the current framework. We looked at some of these from an interaction perspective. These were relatively older studies, but show Relative to older studies, but showing that how accumulation, greater accumulation of amyloid in certain brain regions, actually accelerates atrophy in totally different brain regions, but connects it either through structure or function. And similarly, how accumulation of amyloid again, very region specific accelerates the accumulation of tau in a different In a different brain region, which defines the Alzheimer disease. So, bringing some of these higher-dimensional nonlinear interactions to the definition of the cohorts or certification of the cohorts is still something we are missing. This is a topic of interest for many groups, and one of them that I'm involved with. That I'm involved with is AI for AD initiative, where we've been extensively looking for artificial intelligence and machine learning approaches for exploration of diagnosis, drug discovery, and for precision medicine. And as you may, you all might know, we've already been seeing impact of AI in imaging and neurotinative diseases. And neurogenital diseases, and it's going from touching to different aspects of imaging and neurogenital diseases. It's not just in the acquisition and reconstruction where we use for phenotyping, but we're also seeing the use of AI in post-processing and interpretation of the results. And what we're now getting into is that contextual interpretation of some of the Interpretation of some of these biomarkers, some of these data using AI approaches. Which brings me to the next challenge, the last challenge I want to mention, which is related to the big data. Many of these requires very big data sets, especially AI using neuroimaging data. And this is where we rely on multi-site data, multi-cohort data sets, and merge those. And merge those data sets. In that case, we're dealing with data collected using different scanners. And if they're coming from different sites, but also sometimes it could be the same site, but again, if you think about Alzheimer disease or any neurodegenerative diseases, these are long progressive diseases. Progressive diseases, and we oftentimes want to look at follow-up data from long periods of times. And technology does change, so there are upgrades happening, and that do affect how these data are collected. And on top of that, we also want to make sure these efforts are generalizable and validated, especially if they will be used in clinical practice or clinical treatment. Using clinical practice or clinical trial, where we're not going to have lots of control on how the data is collected. So, at that point, what is the key is not necessarily controlling, standardizing the approach, but coming up with biomarkers that are robust to these kinds of variations in how data is collected or variations in the technology. Just going back to the annual. Just going back to the ANI data, it's also a very good example of how things can vary and change over the years since AMI has been running for almost 20 years. It's been going through, we're in our phase four now, AMI 4. And we have individuals that's been in the study for 17-15 years and been scanned on different scanners. So, one big question. On different scanners. So, one big question is: how would your brain or their brain look if you've been scanned on a different scanner? Are we going to be able to measure the exact same biomarker? One approach for this, what we call the harmonization problem, is using combat method, and that's one we've been mostly using in our study. Aligning the distribution of the features, but as long as there's this common kind of common characteristic cohort that is included in every sample. It doesn't need to be the same individuals, it's just they show the same cohort characteristics. So we can expect the same feature distributions and use that information. Distributions and use that information to adjust the measurement differences between patches or between scanners or between studies. There are these other approaches, more AI-driven approaches. One is based on adversarial networks, which is basically trained on to learn how to represent the data without the side effects. The side effects. So it's kind of trying to forget, not be able to replicate that side effect on the harmonized outcome. Another one is using adversarial network architecture, decomposing the content from what's called a style latent space. And just using that regressing out that style latent space, producing what is called a harmonized representation of the original image. And this is just one example. What you're seeing is different images are coming up and they just get harmonized based on removal of this style latent space effect. One of the challenges, though. One of the challenges, though, still, even though there are various approaches proposed to do this harmonization, we still don't have that comprehensive understanding of the impact of some of these harmonization approaches, particularly in terms of how much they are modifying some of the biological variants. Biological variants that we might want to preserve when we do the harmonization. So, like taking out some of the unknown biological variants that might be relevant to the clinical question we are asking, but we don't know about it. So, it makes it very challenging to extensively validate some of these harmonization approaches. There are some techniques, some approaches propose, such as partial pooling or hierarchical Bayesian regression. Hierarchical based on regression, but it's still an open challenging problem for neuroimaging and us. I want to end here and thank you for your attention and I'll be happy to stay for questions and participate in the discussions as much as I can virtually. I cannot hear anything. How about now? Perfect. Okay. Level talk. Questions, but I'll start with one. So I've been working. I'll start with one. So, I've been working with these multimodal biomarker projects. And one of the things that people often want to do is what you were doing, sort of figuring out, again, explain the different modalities, sort of what you have Tao adding something to it, what does that buy you? Sort of balancing that versus patient and implications like that. Complications like that because adding you have the through the kitchen sink, you have all this data, but in clinical practice, you might want to have a much more refined biomarkers that doesn't put some burden on the participant and maybe not 100% of what you could have done, but maybe 90, but in half the time or with less invasiveness. And have you guys thought of that? No, no, that is like a perfect question. And it's actually one of the things. It's actually one of the things. I'm sorry, I didn't include any of those data here, but you're absolutely right. It's a balancing act. And I try to highlight it a little bit, but also there are things we need to consider to write, like diversity or accessibility or scalability, because as you said, ANI is ideal setup. It's done in memory aging centers and research. Centers and research centers where they can recruit, they can afford to have these biomarker data collection. But the reality is it's not going to be scaled to any clinical center in the United States or any clinical center worldwide. Those are the questions we need to keep in mind. And that is actually one of the key reasons why there's a huge attention on the plasma biomarkers. On the plasma biomarkers. I didn't talk much about that, but it's not CNS or nervous system biomarker we're looking at. It's very peripheral, but there are lots of evidence that certain bits and pieces are represented in the plasma for amyloid and for PETA. They're not perfect. They're not as perfect as amyloid or topat imaging. Imaging or CSF amyloid and tarbaromarkers. But the idea is, as you mentioned, could we use some of these different biomarkers, more accessible, cheaper, and more patient-friendly biomarkers in a tiered approach, for instance, like to can we come up with Come up with liability or confidence around those. Screen them using first plasma and maybe their clinical assessments. And if they are, this is like triaging, if they are triage negative, you don't need to push them for cat imaging or CSF. And then at that point, decide: do you need pet imaging or maybe you can do MR imaging, you don't need a pet imaging. You don't need PET imaging and have that in the pipeline as the second step, and so on. And this is actually something we've been doing, we've been looking in AMI as a project, looking at the role of fluid and imaging biomarkers in this pipeline, and what would be the optimum pipeline. The answer is probably going to depend on the outcome and then the clinical setting. Setting, like, because there's lots of things contributing to the cost. But it's the cost-benefit judgment you also need to do. I don't think it's going to be one formula or one pipeline that's going to apply for every setting or every question, but it's definitely something we've been thinking about. And I would say it's a very important question. Again, especially from diversity perspective. Especially from a diversity perspective, we need to keep in mind that we need to make sure these are generalizable and accessible by everyone, not just high-end clinical research centers or medical centers. Hi. I can hear you barely. You need the mic. Hello? Yes. Hi, Dugo. Hi, Dugo. This is Armin. Very nice to see you, first of all. Yes, we have a lot of time. Well, very interesting presentation. And it was very comforting to hear some of the things that I found in the work that I've been involved in with AD. I think we analyzed the important point, the ADNI data set, and just look at the much simpler things like just expansion of the volume of the or changing the volume of the hippocampus, for example, right? Things that are very simple. And we notice similar things. We notice that the Similar things. We notice that sometimes the subjects cluster into pieces that don't quite align with the MCIT diagnosis. You already mentioned, right? It seems like the way they were diagnosing this is just wrong, right? It's just not well aligned. Say wrong. Like, I know there's no clinicians in the room, but I shouldn't say wrong. Just to be correct. Yes, it could be better. But another feature that we found is that the trajectories that people follow in terms of volume, in terms of cognitive decline, In terms of volume, in terms of cognitive decline, they're not like the way you drew them on the average, which is like steadily kind of going down. But sometimes they accelerate, sometimes sometimes they stabilize, right? They're highly non-linear. And maybe the speed at which these parameters change, maybe that's an important aspect in all of this. You didn't mention it. So what's your opinion on this? Yeah, so that's another great question. And just starting with the clinical diagnosis, it's. Diagnosis. It's still the practice, right? That that is how we recruit controls or MCIs or dementia in these studies. So I don't think that's going to go anywhere, but I wouldn't say it's wrong, but it only captures just a small window of what's happening with these individuals. So I'm just going to answer a couple of things in what you just said. Couple things in what you just said. The first one is looking at the cognitive decline based on purely clinical diagnosis versus looking at the profiles or patterns of cognitive decline based on data-driven clusters, like biomarker data-driven clusters. They often don't align perfectly. We tend to see, I didn't present any of those, but if Of those, but if you just ignore the diagnosis but look at this higher-dimensional biomarker domain and cluster individuals based on their, you can call it heterogeneous or subtypes, just based on their biological presentation. You will identify quite different clusters and quite different patterns, behaviors of cognitive decline, because the cognitive decline is really driven by those. Driven by those underlying biologies, not based on their clinical diagnosis. Clinical diagnosis is just a snapshot, like a summary of where they are. It's the state versus the stage. So from that perspective, coming to your last point, the state versus the stage, it's so dynamic. Someone can be on a very late stage. Late stage disease, but could be extremely stable, showing not much cognitive decline. But you can also have someone with a very early disease state with this huge dynamic rate of decline. And also, you can have someone with early disease stage with very moderate patterns of decline. Uh, patterns of decline, and those will be diagnosed, will have the similar clinical diagnosis potentially. They will be MCIs, but there's a huge heterogeneity happening there. And that was, I think that's one of the challenges we have. I'm not a really good graphic designer. I wish I could, you know, picture this, like draw this, but I keep calling this a landscape, but what we're looking at is this. Is this higher dimensional of kind of a manifold defined by all these pathological changes, pathophysiological changes defined by either analog cell, neurodegeneration, or do they have vascular risk factors? Do they have a POE? How old are they? Are they female or male? So, all of that basically defines the landscape of that manifold. And on top of And on top of that, different parts of that manifold corresponds to different clinical presentations. And oftentimes, we just do that binary dissecting of that manifold. We just say that like amyloid positives on the right, amyloid negatives on the left. And that is how we're going to look at this manifold. And then we just average out all these nonlinear changes happening in that. Linear changes happening in that biomarker landscape, and I don't know the answer how to deal with it, but ideally, it's we need to look at all of these simultaneously and understand how they simultaneously define the progression of the disease from a cognition perspective. And if the trial is interested in a certain cognitive decline profile, Profile is going to come with a complicated definition or like a certain section in that manifold, but it's not going to be amyloid positive versus amyloid negative, right? It's going to be different combinations, different, you know, landscape piece that represents certain kinds, like different heterogeneous combinations of the biomarkers, but still presenting with the same behavior. I don't think we. Same behavior. I don't think we have a model to describe it, but we're definitely missing that. And it's too complicated for me to model. And I think that that's part of the reason why we've been seeing this very binary definition of the disease, like ATN, amyloid positive, type positive, neurodegenerative positive. But there's so much happening even in positive versus negative sites. The versus negative sides. It's not, the disease is not, it's not binary, it's very continuous happening with lots of interactions. Hope this answers your question, Armin. I'll stop the Q ‚Åá A here. Why don't we take an eight-minute break? I have watched 1022. Let's presume at a house and we'll do a broad discussion of some of the ideas you presented. So let. Presented. So come back at 10:30. You feel free to. And yeah, thank you so much. Thank you.