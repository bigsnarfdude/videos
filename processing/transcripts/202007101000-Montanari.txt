Open online probability school originally designed for the SMS in in-person version. He's been giving lectures on mean field methods as they apply to high-dimensional statistics and to non-convex optimization. Yeah, a last lecture. Yeah, last lecture we connected this to the statistical physics models, and today we're going to see a continuation of this. Today we have one lecture, and this will conclude the program for this week. I would just like to give a quick preview of the schedule for Of the schedule for next week. Next week, we have a series of lectures by Elhan and Mosel on simplicity and complexity in belief propagation. The lectures will take place on Monday, Tuesday, and Wednesday at this same time for one hour. And on Monday and Tuesday, they will be followed by an exercise session. And then we'll also have And then we'll also have a series of lectures by Shirishando Ganguly on large deviations for sparse graphs. And those lectures will take place on Wednesday, Thursday, and Friday. On Wednesday, they will take place in the second part. So what was 1730 UTC. And then on Thursday and Friday, they will take place at this. They will take place at this same time. You can see the full schedule on the OOPS website, as well as posting of the slides and videos and exercise sheets and some references for this week's lectures. So, without further commentary, just to mention again that the videos are being Mention again that the videos are being recorded. In case you do not want to appear in the video, please disable your camera and/or microphone. You will have an opportunity to ask questions over the chat as well as either in the middle of the lecture or at the end of the lectures. You can ask them in person as well. Thank you, Andrea, for joining us again for the fifth in record time. fifth for the fifth in record time so far i think in this in in as a is the longest run sequence of this school so far um and can we can we um spot uh yeah share the screen share the screen okay so thanks to sticking to the end for all of you Sticking to the end for all of you, let's stick to the end, and thanks for the organization again. And yeah, so today we'll go down to the technical, you know, the outline of the construction of the algorithm for the SK model and generalized P-spin model. So the context is that we want to maximize this Hamiltonian over the hypercube. So this can be either a generalized spin model, so a model. So, a model which is a sum of kind of multilinear terms, or the SK model as a special case that is just this quadratic Hamiltonian here. Okay, and the coefficient W given by a GOE matrix. And so, for the argument, I'll stick mostly to the SK model until somehow the end, and then I'll change my formula to generate. I'll change my formula to generalize it just because the SK model is simpler. So, as I anticipated in the last lecture, what we are going to do, we are going to construct an AMP algorithm. And this is going to take this form. So, we have a vector zt in our end, and I'll index time instead that one, two, two, three, four, five, etc. I'll index time by z. I'll index time by zero delta to delta etc. up to one and think of delta as a small constant that then will give me you know will reflect in the approximation ratio one minus epsilon of the optimization problem. And the way the algorithm will work is that, okay, the general IMP algorithm, at each iteration I compute a new z h times t plus plus delta by multiplying the matrix W. By multiplying the matrix W times a function of Z at the previous time, and I subtract this Onsager reaction term. Okay, so what we know in general, so all of our objective is to design the function f and f of t such that this vector z, not really the vector z, really the vector f t of z, will give me. Will give me as good an approximation as possible to the optimum. And the key thing that we will use, and in fact, we'll basically forget about the details of the finite n algorithm for most of the lecture. But the basic lemma that we'll use that we called before a theorem is the state evolution lemma that tells me what it tells me what is the asymptotic. The asymptotics of the joint distribution of the vectors generated by this algorithm. Okay, so here on one side, what I have is a function. So I take any psi, so psi can be, yeah, so here is a locally Lipschitz function with the quadratic growth basically. And I apply apply this function to the coordinate of the vector z, z0 up to z1. So there is a constant number of them, just one over a delta of them. I take expectation, so this expectation with the hat means just the average over the coordinates. So I invented this notation, and then the limiting probability of this is given by the expectation of the same test function. Of the same test function applied to a vector of random variables. And what this lemma tells me is also what is the joint distribution of these random variables. First of all, the first coordinate is independent of the others and in fact is normal zero delta, just you can see immediately by the initialization that is up here. Okay, so here I brought the initialization and this will reflect in. And this will reflect into the fact that Z0 delta is obviously normal, zero delta, but all the others are jointly normal with some covariance q. And okay, how do I construct q? Well, q you construct by recursion. Okay, so the new q is just the covariance of f. The q s plus delta t plus delta is covariance of fs and f. Okay, so this this. Okay, so this lemma really gives me, in a sense, an isometry between my original vectors that are at finite n and these instead these Gaussian random variables. And so I can now analyze the algorithm by working on this probability space here mostly. Okay, so now I told you in the last lecture, I also anticipated that a key ingredient. That a key ingredient here is to impose some orthogonality condition. So, what orthogonality? So, I'll define mt to be ft of iterates. Okay, and then I want to ensure all sorts of orthogonality conditions of the formula. So, I want the increment. So, the scalar products of this increment to go to zero as n goes to infinity. And this I want it for all less than t so increments to be orthogonal with respect to the past. And this again is dictated by somehow the intuition that we have about the structure of low-languies states of this SK model. Of this SK model or these spin glasses. And so, this is something that probably Eli Rand Subag talked about in this school. So, how am I going to do this? Yeah, so let me introduce a piece of notation. Let me call F T. Okay, I will not really use this notation much, but and the sigma algebra generated by Algebra generated by z0 up to zt okay and okay so the way I'll construct I'll impose this orthogonality condition is really something that you know probably you're familiar with if you if you studied you know some probability is I'll construct this by so all these sums of error times run over the grids There are times run over the grids of spacing delta. Where so this is the So, this is the key idea, the key construction, right? So, this defines this function. I'll construct these functions f in this way. The function f gives me mt, so I can define the function f or define the sequence of vector mt. And the way I construct it, I construct it as a sum of terms that are the previous increments. The previous increments each time multiplied by something that is measurable with respect to the past. Okay. And now, you know, of course, now, if you put this through this state evolution theorem at finite n, it's useful to think of the following two contexts. One there is the finite n space. Is the finite end space, therefore, we have three sequences of vectors. We have the Zt that we started with, the US, UT, if you want, and UT is measurable, some function that I didn't yet specify of the ZT, and then this empty. And then corresponding to this, I will have random variables that are Okay, I'll call without a lot of imagination, I'll call it capital Z T delta U delta T and then delta T. Okay, and the relation between these two is that every time I compute empirical averages over these vectors, you know, for large n, they are converged to expectation. Converge to expectation with respect to these random variables. The way I construct the random variables is I apply the same function that I apply to vectors here. I apply them to the random variable. Okay, so I can now rewrite in terms of this random variable my state evolution lemma, the lemma that I wrote before. The lemma that I brought before, I can write it more concisely in the following form. Okay, first of all, let me write the relation between this set of random variable. M delta t will be square root of delta, because this corresponds to m zero, plus the sum s between zero and yes, t minus delta of u. delta of u delta s and then z delta s plus delta minus z s delta okay so this corresponds you know as i said corresponds to this equation the the finite n equation between the vector is this and so the way i constant if you want this is the definition of the random variable capital Of the random variable capital M. And of course, what you have is that you have to impose that the random variable u delta s is measurable on the sigma algebra F S. Okay, so this sigma algebra is whatever is the sigma algebra generated by the random variable. Generated by the random variable z from zero to s. Okay, so this is my definition of m, and now there is the equation that I brought before for the covariance of the z's that I can write, since m t is my function, I can write the equation for the covariance of the z is that like this. Latest kinemic possibility. So, again, how do we read these equations? Given all the z up to some time, you know, t or t minus delta, I can construct, up to some time t, I can construct the m up to some time. I assume that somebody tells me how to compute the u's, right? There is some other measurable functions that tell me how to compute the use. So if To compute the u's. So if somebody gives me all the values of z up to time t, I can compute all the u's up to time t because by definition the u's are measurable. Then I use this recursion to compute all the m up to time t. And then to compute the new, to move one step ahead, I use this recursion. Now I know the covariance of the z up to time t plus delta. Up to time t plus delta, thanks to this recursion. And therefore, I can construct all the z up to time t plus delta. And this way I construct the sequence of random variables z0 to z1. Okay, so perhaps I should pause for a moment, second, and ask whether this makes sense. Or if there is any question. Please, because otherwise the what follows will make no sense whatsoever. Okay, if nobody interrupts me, then now so now I came up with this construction. Was I able to ensure this orthography? Was I able to ensure this orthogonality property that I was talking about? Yeah. Is there a physical meaning to M and U? Oh, yeah. So if M is really meant to be the magnetization. Okay. So again, what is the picture here? The picture that I have in mind. Okay, it would be nice to. Okay, it would be nice to prove more details about the picture, but the picture that I have in mind is that we have this Humming upper cube, and you have this tree of states. It's not a Humming, it's the solid cube. And M, you know, at any given time, you are going down the leaf, and M T is the magnetization up to some. Up to some when you are at radius t. T corresponds to the radius at which you are and yeah, and yeah, so the thing, the m vector is the magnetization that you have at that moment. Now, I must say, this is something that I realized in the inside. Insight. I mean, that is not, you know, okay, if you are, if you know about physics, this can be useful, but you know, it's not really necessarily useful for anything in the proof. Okay, so were we able to generate these martingale properties? And the claim is yes, claim this orthogonality and yes, and claim m delta t for the let's 40, let's say, less than one, and z delta t less than one. So these are discrete time marking. Okay, so how do we prove it? So let's go to the proof of this claim. So, first of all, a couple of remarks. You know, claiming that they are martingale is, first of all, is sufficient. Is first of all is sufficient to prove it for Z simply by the way you know M is construct you see that if Z is a martingale then since U is a measurable M must be a martingale by this by the definition above, by the construction above. By the constructionable. And second, you know, since Z is Gaussian, is sufficient to check that the covariance is the covariance of a martingale, right? So Z delta T Z delta S is equal to some function that I call Q delta. I call q delta of t minimum with s and actually I'll call it minus delta shift some function of t minimum with s but for the following I'll call it q of that function minus delta okay and the the you know obviously the thing goes by induction over uh Uh T assume true up to T and let's try to prove the following and what we want to show is that so we want to show that E z delta T plus Delta, T plus delta, Z delta. S plus delta is some function of Q S delta for every S less or equal than T. This is the Martingale property. Well, you compute it just. So this is, we don't know. I will compute it. So if you substitute the formula for Z. formula for for z, the recursion for z, then this is the same, you get that this must be the same as the covariance of the m by the second formula. So we use first the second formula and then we substitute m from the first formula and so you get delta that is correlation of the first square root of delta and then you get the sum over t prime less or equal than t minus one. minus one and s prime less or equal than s minus one or s minus delta really and then the expectation okay let me forget drop all the superscript delta for the moment u s prime and then z s prime plus delta minus z s prime u t prime prime z t prime plus delta minus z t prime and you see that now uh you know only the diagonal terms survive obviously and so you get delta plus the sum overall let's see s prime less or equal than s minus delta and then you have the second moment u s prime u s prime square and now times the expectation the second moment of the integral of z that by induction hypothesis must be q delta of t prime plus delta minus q delta of t prime. Okay, so now this is a function only on s, so this concludes the proof of the martingale property. Proof of the martingate property and now give me also a recursion for the q's right because this is q delta s right so now how do we choose you well i i want to choose in such a way that is it has That it has a second moment equal to one, so that I simplify this recursion. So I'll choose it. I'll choose it. I can always start from any random variable with a finite second moment and make it in second moment one. So I'll start from any measurable random variable and then normalize it. divided by u bar. Okay, and if you do this, now the recursion for Q rates Q delta S equal delta plus sum over T between actually, okay, I don't know, let's say less or equal than S minus delta and then. minus delta and then q delta t plus delta minus q delta t and this implies that q is actually and this has to be okay if you check the initialization for this recursion the initialization is q delta zero equals zero so together these two imply what imply simply that q delta t is simply equal to t simply equal to t okay so okay so we have now uh the covariance of this process is very simple z is a martingale with with covariance t and how do we construct u now how do you construct this u bar uh we'll we'll take a specific choice i'll construct u bar delta t to be some function To be some function lowercase u of some other process xt and where xt is generated in this way x delta t will be generated in this way. This is at term t plus delta L t. I'll take kit time t and I add the b x delta t t times delta plus the change in z okay so this would be my definition of you now this defines Definition of u. Now, this defines entirely the algorithm, so here so defines the algorithm up to two functions v and u. So these are two functions from reals times the interval 0, 1 to reals. Okay, and okay, they have to satisfy some niceness properties that I will not go into detailing. Okay, so now this up to this function b defines the whole algorithm. This function b defines the whole algorithm. I mean, the algorithm, you know, this defines the function that gives u at the next time. So, this way defines this function f in the AMP algorithm. Perhaps I'll pause another minute to see if this makes sense now. Here, you know, part of, you know, at least part of the guidance is in trying to, you know. I'm trying to get something that has a well-behaved limit as delta goes to zero. So this kind of difference equation, constructing things to this difference equation is very natural given that. Now, I imagine one could go even more general and not make these specific choices, but these choices in the end. These choices in the end, you know, you get broad enough to achieve the result that I wanted to achieve. So, and they can prove easily the existence of the limit delta to zero. So, they are convenient in this sense. I mean, I could choose things much more generally, but perhaps. Okay, so now one nice thing is that now what we have is that you know. What we have is that, you know, remember that this q delta t is the covariance of the process z. So E of Z delta T Z delta S is Q delta T perhaps before I wrote maximum minimum with S. So this is T minimum with S. So what does this mean? It means that just What does this mean? It means that just Z is a Brownian motion sample that the time delta to delta. And then the screen seems to be frozen again a bit after the definition of U and X. Yeah, I see. Okay. Interesting. It's give people pause and time to think so I was saying yeah so what I said is that Z has this covariance that is equal to T minimum with S. So this means what? It means that Z is just a Brownian motion, a sample that A sample that you know those times. Okay, now I have to analyze what, you know, let me rewrite now the two equations that define this process. I have to analyze x delta t plus delta equal x delta t. Oh, okay, let me not rewrite it to analyze this first equation. Where Z now we know that is a Brownian motion, and the other equation that I have to analyze is the equation for M that I remind you is M delta T. Now we can. Delta t. Now I can write it a little bit more explicitly: square root of delta plus. And now there was this variable u that now we wrote it as divided by the second moment. Times now we know that this is Brownian motion. Okay, so the claim is: okay, this is not, so we have to analyze these two. So, it's natural to guess, and it's not too difficult to prove by some kind of stochastic process analysis, is that as delta goes to zero, Xt, all these processes converge to some limit, okay, in the right sense, and this is given by NSD. And this is given by NSD. I mean, a couple of SDs, really. One is, of course, V X T D T plus D B T and the other is empty. Okay, perhaps I'll take a little bit more space because Okay, beautiful. Now, I don't like this having to normalize, so what I can do always is choose, I'll choose the function. I impose the constraint that this is equal to one for all S okay, or equivalently that you know E of m t squared. E of mt square is equal to t. Just by Ito's formula, the two things are the same. Okay, and therefore now m simplifies and it is simply now this gives me a okay, so let's Okay, so let me now write. Actually, I'll change things now, switch gear now, and start writing formula for the general. I did the derivation for the SK model. What happens if you do the general P-spin model? Where, well, it's more challenging, but you get a very similar formula in the end, except that this function xi-second xi appears in particular, psi second of s is here, and then there is u. And then there is U S X S D B S and the X I second also appear in the S D for X B T X T D T So basically the Brownian motion now is Basically, the Brownian motion now becomes always scale. So now you get it. So now this gives me at any given time the distribution of my MT. So if I solve this S D, I get a random variable M that tells me what is the distribution basically of the entries of the vector M T in Rn asymptotically. Now, how do I come up with an approximate optimizer? Well, I take M1. Tick M1, I'll threshold it. These in general can be outside plus one, minus one. So I'll threshold it to get something between minus one, and then I'll do some rounding to get a plus minus one vector. And now basically, M1 is already very close to a plus one minus one vector. This is the estimate of the ground state. And the claim is that. And the claim is that, okay, there is a small lemma that one has to prove that says that 1 over n hn applied to this rounded thing, that is a plus minus 1 vector, is 1 over n h n applied to m at times 1 plus small n of 1 with a probability. Okay, so this is So, this is okay, not hard. And the other lemma is: okay, now I computed what is the distribution of m. I have still to do some work to compute the distribution of h of m or the value of h of m. And okay, this can be done. And the claim is that this one over n h n of m equals 1. Of m equals one is equal to some function of u n v plus molo of one. And this function is very simple. It depends implicitly on u and v, but is the integral between zero and one of size second of t e of u t xt d t. dt okay and now so this is the value if you give me any set two functions u and v I give you a linear time algorithm basically that achieves this value that is obtained by solving the stochastic differential equation and then plug it in plug it it in this functional. So now what I have Functional. So now, what I have to do to design a good algorithm is, of course, there are very bad algorithms here, but what I have to do to construct a good algorithm is to maximize this integral. Okay, so what I want to do is algorithm design is basically the following problem. You want to maximize This functional subject to well subject to the two stochastic differential equations that I brought and then the two constraints that are E of m square t. T equal to T and then M1. So I said that at the end you do the rounding and then you do the rounding and so I should have been more precise. This is bigger or equal and this lemma only holds if M1 is mostly between minus one and one, right? If M1 is very big, of course the vector M1 is too big, is outside the interval minus one, one. Is outside the interval minus one, one, then the thresholding will have a big impact, right? So, you're what you want is that at the end you are in the interval minus one, one, and this has to be almost surely. Okay, so now we have to solve this kind of variational problem. Okay, now there are two approaches to this variational problem. One is that you guess One is that you guess UMD and you compute the value. But what's more interesting is really trying to solve it and to see the connection with Paris's formula. And one way to address it is, okay, we relax it. Okay. Second, we construct an upper bound. Construct an upper bound via duality. We have a question, Andrea. Yeah. Does the expectation of mt squared equal to t only for SK or for general mixed p-spin models? No, this we impose for every model. And you see, this is why this constraint is crucial. Crucial. So if you don't impose that condition, then what happens? The constraint Qt equal T, you know, it's difficult to impose and then it's difficult to get the continuous time limit, right? Yeah. And this is what you should expect because if you cannot impose that constraint, okay, perhaps we can. Perhaps we comment about this at the end. And then, yeah, once you have the upper bound, then we move from the dual. Once you have the solution of the dual problem, it's quite easy to find the solution of the prime and the problem. I'll mainly sketch out what are steps one and two. So I'll sketch out these two steps because they really show the connection with. Really show the connection with. Oh, I'm almost done. Okay, notice also that here the only place in which the fact that M is an easing mode that we are solving an easing model shows up is in this constraint, right? It's on the endpoint constraint. For instance, one easy exercise is to take, so let's perhaps Let's perhaps do the easy one. Okay, one easy exercise is to look at the case in which I look I impose only the constraint E of m1 square equal to one so I don't impose the easing constraint but basically the spherical constraint this infinite m space corresponds to the vector m one having norm square root of n. Square root of n and okay, in that case, this thing can be solved explicitly. For instance, an easy exercise is to look at this. It's even easier because this is a quadratic problem over the sphere, and you can check that in this case, this problem gives a value. The value of this optimization problem is one, which is one half. Is you know one half of the leading eigenvalue of the GOE matrix. Okay, so how do we do the relaxation? So step one, the relaxation. Well, instead, I have a specific way to construct u and v, but now I'll take, I replace u by any measurable function on the single multiple ft, where ft is the single. Where Ft is the sigma algebra of the brain bromium motion. So I optimize over a larger space, and over this space, of course, again, what I have to do is I have to maximize Sorry about that. Okay, so you have basically so the picture is that we have time. Okay, we have m and the time is between zero and one. This has to end up between plus one, minus one at the end. And at each time the constraint is so I kind of can design the diffusion coefficient to be measurable in such a way that at each time M is in the you know m as second moment equal to t and you end up in the interval minus one one and you know all the time I have to maximize this thing, right? Now the real constraint that causes you know of course you know make the problem challenging is you know one constraint that makes the problem challenging is this one because there is of course One because there is, of course, infinitely many of them, really. So, what we do is that we write a Lagrangian. So, okay, one way to write Lagrangian is that I take any function from 0, 1 to reals, negative, and then I define u of t to be the integral between t and 1. Between T and one. And so now I called gamma this in the same way as I called the order parameter in the Parisi formula, not by chance, but because it will end up being the same. And then I define j gamma that is the supremum overall adapted. Adapted processes u of and then I have a little bit Okay. Now I claim, and so okay, sorry, the supreme is subject to the endpoint condition. This endpoint is always almost sure. Okay, so now this is very nice because this, of course, gives me an upper bound on the relaxation, right? And basically, what happens is that, okay, so I added the constraint as a Lagrange term, it's a bit different. Different. So, when the constraints are satisfied, the claim is that this term here vanishes. Okay. So, this term here vanishes when the constraint is satisfied. And yeah, okay, perhaps I'll check that. So, the constant determined there is the expectation of the integral between z. of the integral between 0 and 1 of mu t times xi second of t u squared t minus 1 dt and by the way I wrote things this is the same as the expectation of the integral between 0 and 1 and then there is another integral between 0 and 1 and then of xi Of psi second. Now I'm rewriting, remember that nu is the integral of psi second times gamma. And now there is this piece psi second of t times u t square minus one. And then there is here there is a ds, there is a dt, and here are the integral. And here the integral defining nu, I integrated s between t and one. So I put an integral between an indicator function of s bigger than t. But you see that now if you use Fubinier, you invert this to two integral, I get here exactly I get the integral between zero and one. Between 0 and 1, so I want to do in ds, and then there will be xi second of s grammar of s and then when I do the integral over t, I get the expectation of m of s squared minus s. This is when you integrate over. This is when you integrate over t. Okay, and so this is zero if the constraint is verified. So, because of that, on the constraint, this is zero, so you get a relaxation. Okay, and so now the point is, you know, I want just to compute a j gamma. How do I compute a j gamma? Well, well, you know, you do dynamic programming. So Namely, you write some J gamma of Tz, which is the soup. So this is the optimum when I do the value of this optimization problem when I start with stochastic optical control problem where the particle. problem where the particle, basically the particle mt. So the picture is here, m at time t is a position set. Okay, and then I have to optimize between t and one. So this is the super all controls that are adapted between t and one, and then of the same basically objective. except that I go only between t and one then there is psi prime of s u s plus one half mu s psi second of s u square of s minus one d s and this is always with the constraint now the constraint has to be Now, the constraint has to be, since I start at z, the constraint has to be that z plus the integral between t and 1 of xi second of s us dBs is in minus 1, 1. Okay, so now you have this quantity, and now you've write a dynamic programming equation. That gives you this in terms of some. So now I'll stop writing details, but in terms of j at time, some bigger time theta and some other position. I don't know why. Okay. And the control for some theta bigger than t. And now, once you have a dynamic programming equation, at least formally, you can take the limit theta to t and you get a Hamilton-Jacobi equation. Hamilton-Jacobi-Belgman equation. So a PD for a parabolic PDE for J. Okay, so this parabolic PDE allows me to compute J gamma. And okay, the connection with the original thing is, of course, that J gamma is equal to J gamma of 0, 0, the original upper bound. So you get a PD for this functional. Get a PD for this functional j gamma, and the value of the relaxation is less or equal than j gamma 0, 0. Okay, now how is this related to the Paris CPD? Well, basically, what happens is that up to a change, up to a small constant, basically, if you, instead of working with J gamma, you can work with the Legend differential. Dual of J gamma namely phi gamma t x is okay now I don't remember it, but there is j gamma t. j gamma t z and then there is something like minus z times x and this is probably is mean over z and then there is some constants that some other factor here to to you know eliminate terms that are not interesting that i don't remember uh but basically once you do this transformation then you you you you can check Then you can check that this feat satisfies. Okay, so now this gives you and the corresponding relaxation now you get by doing this transformation, you get that the relaxation is less or equal than P of gamma. Okay, and you can carry out all of this problem. You can carry out all of this program as long as gamma is in this space at least. It was carried out as long as gamma is in this space L gamma, and therefore you can stick here an inf. And at the end of the day, you can verify that if the inf is achieved, you can reverse all the step and come up if inf achieved. At gamma star, we can reverse all the steps of these proofs and come up with the two coefficients that we wanted, b tx and utx, that are actually derivatives of this function phi. Yeah, so this, in a sense, at least to Yeah, so this, in a sense, at least to me, it clarifies a little bit the mystery of this Parisi's formula, in which you start with the maximization problem and the values given in terms of the minimization problem. And at least now in my mind, the way I understand it is that you have a maximization problem, you have an algorithm that solves that maximization problem that is described by a stock. Described by a stochastic process, and you maximize the stochastic problem, you get the value that the algorithm achieves, and really the Parisi formula is the dual of that problem. Okay, in the end, of course, as we talked about in the last lecture, you get the Parisi formula, except that on a different variational space that doesn't have any more than non-decreasing. Doesn't have any more than non-decreasing constraints, so you get different value, and this coincides on the optimum only under the normal well-locked gap condition. Okay, I guess that's all. Thank you. And thanks again to the organizers of this and to everybody that sticked around. Thank you, Andrea. I will unmute all the participants so we can all thank you. All the participants, so we can all thank him together. So there's you could you can feel free to