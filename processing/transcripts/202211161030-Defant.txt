Tell you about pop stack sorting. So the pop stack sorting map is this function pop from the symmetric group SN to itself, and it acts on a permutation by just reversing the descending runs. By descending runs, I just mean the maximal consecutive decreasing subsequences of the permutation. So in this example, the descending runs are 762 and 4 and 91 and 853. And if we reverse them, then 762 becomes 267, 4 stays as 4, 9, 1 becomes 19. 91 becomes 19, and 853 becomes 358. So it's not hard to see that if you start with a permutation and you iterate the POP stack sorting map, so you apply POP to it, you get some new permutation, you apply POP to that, you get some new permutation, you apply POP to that, and so on, eventually you'll get to the identity permutation, but it's not clear how many steps you need to get there. So there's this nice result of under saying that if you're looking at a permutation of size n, the maximum number of iterations you'll need is n minus 1. need is n minus 1. So you can always do it with at most n minus 1 iterations, but and this is also tight because there are some permutations of size n that require n minus 1 iterations. So I think a natural question is what is the average number of iterations that you would need? I don't know the answer, but I have this conjecture that the average number of iterations should be basically the same as the worst case in the sense that it should be asymptotically n times 1 minus little of 1. I don't know how to prove this. I don't know how to prove this, so this is one open problem here. But I can show that it's at least n over 2. This is not that difficult. Actually, there are a few different ways of seeing this, but I don't know how to do any better. So I'd be interested if anyone could find a way to show that the average number of iterations is at least 0.5001 times 10. So let me show a simulation of what this looks like. So here I just took a random permutation of size 100. Random permutation of size 150, uniformly at random, and I plotted it. And now I'm going to show you what happens if I just iterate pop. So it'll just do an animation of this. It looks like this. And usually it looks something like that. I guess I didn't count how many steps that took, but it's maybe a little less than 150. I can show you what it looks like again. Okay, so yeah, that's that's basically what it looks like. So yeah, still I'd be interested if anyone could make progress on this. So let me say a permutation is t pop sortable if it requires t or fewer iterations of pop to get to the identity permutation. This is the same as saying that pop to the t of that permutation is the identity. Of that permutation is the identity. Or pop to the key is like pop composed with itself key times. I have a question or comment. Wouldn't it be really interesting also to explain why the animation looks the way it should be? Yeah, yeah, I think so. Right, yeah, there's a lot that we don't understand. Yeah, looking at what do the permutations actually look like along the way is also very interesting out there. So it's not hard to show that a permutation is one-pop sortable if and only if it is layered. This is the same as. It is layered. This is the same as saying that it avoids the patterns 2, 3, 1, and 3, 1, 2. This is sort of an easy exercise. And then there's this result of Pudwell and Smith showing that when you count the two pop sortable permutations, you get this nice rational generating function here. And then soon after, there was this result of Classen and Goodmanson showing that if you fix any non-negative integer t and you count the t pop sortable permutations, you still get a rational generating function. And they give an algorithm for figuring out what the generating function is. An algorithm for figuring out what the generating function is, but it gets really complicated for larger values of t, so really the main point is that it's something rational. And then also people have looked at what are called pop-stacked permutations. These are just permutations in the image of the pop stack sorting map. And these were studied in a paper by Asanofsky, Banderi, and Hackel, also Asanofsky, Banderi, Billy, Hackel, and Linison. And then there's this paper by Klassen, Goodmanson, and Pantone, where they give a policy. Goodmanson and Pantone, where they give a polynomial time algorithm for counting these pop stack permutations, and they use this to count them up to n equals a thousand. There doesn't seem to be a nice formula, but at least there's this polynomial time algorithm. Okay, so I want to do some poset theoretic stuff. So I'm going to say a meet semi-lattice is a poset L such that for any two elements x and y, they have a greatest lower bound, which is called their meet. Which is called their meat and denoted by this wedge symbol here. So, as an example, this is a meat semi-lattice. If I take any two elements, they have a greatest lower bound, whereas this over here is not a meat semi-lattice, because if I look at the top two elements, I should say a lower bound for them would be something that's below both of them. And a greatest lower bound is a lower bound that's bigger than all of the other lower bounds. But here, these two elements have three lower bounds, but none of them is bigger than all of the other lower bounds. Bigger than all of the other lower bells. So, this is not a meat semi-lattice. I'm going to assume that all of the meat semi-lattices I'm talking about are locally finite. This just means that every interval in the postset is finite. That's just to make sure there aren't weird pathological examples that make the things I'm saying false or nonsensical. And I'll assume that it has a minimal element, which is necessarily unique, and this I'll denote by zero hat. So, because the meet operation is commutative and associative, it makes sense. Commutative and associative, it makes sense to take the meat of any finite set in my meat semi-lattice, and I'll denote that by big wedge x, if x is some set. This is just the greatest lower bound of the whole set x. And then a lattice is a meat semi-lattice whose dual is also a meat-semi-lattice, or another way of saying this is any two elements have a greatest lower bound, which is their meat, but they also have a least upper bound, which is their joint. Okay, so a nice example. Okay, so a nice example of a lattice is given by the weak order on the symmetric group. So if I have two permutations, pi and sigma in Sn, then I'll write this cover relation, pi covered by sigma, if I can get pi from sigma by reversing a single descent. So as an example over here, if I look at this permutation, I have this descent from 6 to 4, and if I reverse it, I get this permutation over here, where 4 is before 6. So this is a cover relation in the weak order on, in this case, S6. This is a picture of the weak order on S4. I don't know how well you can see the permutations, but anyway, it looks something like this. And a nice property here is that it's actually a lattice. Okay, so let me go back to pop stack sorting. If I have a permutation sigma and sn, I can apply pop to it. This just means I reverse the descending runs of sigma. But another way of saying this is what I'm really doing is taking the meat. What I'm really doing is taking the meat in the weak order of the elements covered by sigma in the weak order. So I take sigma, I look at the elements right below it in the weak order, so the things covered by it. I take the greatest lower bound of all of those elements, and that gives me some new thing, which is pop of sigma. And the reason I like to formulate it this way is that this definition generalizes to any meat semi-lattice. So given any meat semi-lattice L, I can define the pop stack sorting operator pop from L to itself by saying, Operator pop from L to itself by saying pop of x should be just the meat of the elements covered by x. And as before, I'll say that an element is t pop sortable if it requires t or fewer iterations of pop to get to the bottom element of my meat semi-lattice. So here's a picture of a lattice with eight elements, and the red arrows are giving the action of pop. So for example, if I apply pop to the top element, there are two things covered by the top element, namely this element. The top element, namely this element and this element. If I take the meat of those two, I get this element down here. So that's why I have this red arrow here. Similarly, this element goes here. This one goes here. This element goes to the bottom. The bottom is always fixed. That's kind of just a convention, so just keep that in mind. The bottom element is always going to be fixed. Okay, so yeah, this is pop stack sorting for meat semi-lattices, and I guess kind of the theme here is: well, as I said before, people have studied this pop stack sorting map for the weak order of the symmetric group. For the weak order of the symmetric group, there are a lot of other interesting meat semi-lattices, and you could try to see if there are interesting things that happen when you look at this POP stack sorting operator on those as well. So one nice family of lattices that I like, which is generalizing the weak order on the symmetric group, is the weak order on a finite Coxeter group. So I won't assume really any Coxeter theory here, this is just for a couple slides. But basically you can think the symmetric group is a nice prototypical example of what's called a finite Coxer group. Of what's called a finite Coxster group. And oftentimes, if you have results about permutations or symmetric groups, you can try to see if they generalize in a nice way to other finite Coxer groups. So here, W is a finite Coxeter group, and it has an associated Coxeter number, which is denoted by H. This is just some special number associated to the group, which you can compute pretty easily. There's like a table of them in Wikipedia. For the symmetric group SN, the Coxeter number is just N. And you can also define the weak. And you can also define the weak order on any finite Coxeter group, and it's still a lattice. And so the result here says that the maximum number of iterations of pup needed to send an element of my finite Coxeter group to the identity is the Coxeter number minus one. And this is exactly the same as Unger's theorem from before in the case of the symmetric group. So remember, he said if you look at a permutation of size n, then the maximum number of iterations you need to send it to the identity is n minus 1. This is the same thing, but for any finite constituency. And there are also results that are kind of analogs of this Klaus and Goodmanson result. Remember, they showed that if you fix any t and you count the t-pop sortable permutations, then you get a rational generating function. The same is true if you replace the symmetric groups by the hyper-octahedral groups. This is just some other nice family of finite poxer groups. And you also get the same kind of result if you replace them by the affine symmetric groups. This is a family of infinite groups. This is a family of infinite Coxster groups, but they still have a weak order, which is still a meat semi-lattice. It's not a lattice because it doesn't have a join operation, but that's okay because we can still do meat semi-lattices. And you still can count the t-pop sorable elements and you still get rational generating functions. You may be getting to this, but are there counterexamples to these theorems if you go up to Coxeter groups? Actually, not that I know. I guess one thing is like you want to have a family. You want to have like. Family, you want to have like you don't want to pick one specific coxider group, you want to just have like a nice family. These are the only ones I've looked at, and I haven't found any kind of counterexample. Yeah. Okay. So this is one family of lattices. Here's another family of lattices. These are called new Tamari lattices. And the elements are lattice paths. Hopefully it's okay that I'm using the word lattice in two different ways, as opposed to and lattice paths. And lattice paths. But for me, a lattice path is just a path where each step is either east or north. And I'm going to fix a lattice path μ. So in this example, μ is going along the bottom here. It's east, east, east, north, east, north, east, north, north, east. And I'm going to look at this region that's weakly to the northwest of mu. And I'm going to look at all of the lattice paths in that region. So, or really what I should say is tam of mu is the set of lattice paths that are weakly above. Is the set of lattice paths that are weakly above mu, and they have the same starting and ending quality. So an example would be this colorful path that I drew here, which is mu, and it's east, east, north, east, north, north, east, north, east, east. So then I can make this tam of mu set into a post set by defining a certain cover relation. And this gets kind of weird. If you haven't seen this before, you might think, why am I defining it this way? It's kind of a very strange definition. There is motivation for. Definition. There is motivation for doing this. This is connected to geometry in certain ways, and there are people who have studied this, and it turns out to have nice properties. So, just, I guess, trust me that this is sort of an interesting definition of the cover relation, although it might seem weird. So, what I'm going to do, oh, well, I should say, in your head, you should just think, okay, there's some nice lattice structure that you can define on these lattice paths, and maybe we don't care what it is. For completeness, I'll tell you what it is. So, for any lattice point in this region, I can define its horizontal distance. I can define its horizontal distance to be the maximum number of east steps that I can take from that point before leaving this region. So, for example, if I look at this point P, its horizontal distance is 1 because I can take one east step, but I cannot take two E steps without leaving this region. And so now, to define a cover relation, I'm going to take some lattice path mu in my set tam of mu. I'm going to pick a lattice point on my path that Point on my path that is right after an E step and right before a north step. So like P here. And then I'm going to travel along the path, starting at P, until I get to the next point that has the same horizontal distance as P. So in this example, P has horizontal distance 1, so I start traveling along until I get to the next point that also has horizontal distance 1, and that's P prime. And now I've colored. And now I've colored in orange the E step that's right before P, and I've colored in purple the stuff between P and P prime. And all I'm going to do is switch the order of those two. So I have my orange step and then three purple steps. Here I have my three purple steps and then the orange step. This gives me some other lattice path that I'm calling mu prime. And this is a cover relation in the post set that I'm defining. Again, this might be really weird, but this turns out to be like a nice But this turns out to be like a nice thing to consider. And there are some nice special cases. So if ν is the lattice path that's north and then m e steps and then north and then m e steps and so on in times, then you get what's called the mtamari lattice. This is denoted by tam sub n of m. And there are some nice enumerative results about these lattices. For example, the number of elements here is the mn Fus-Catalan number. And then And then if you specialize even further to the case of m equals 1, then you get what's just called the nth Tamari lattice. I'll denote this by tams of n. And here, these are just, the elements are just lattice paths that are lying above the diagonal, so they're really just dick paths. So you should think of the nth Tamari lattice as some nice lattice that you can define on dick paths. And so in particular, the number of elements here is the nth Catalan number. Okay. So here's a picture. So here's a picture of the third Tutamari lattice. So there are 12 elements. Each one is a lattice path lying above ν, where ν is north, east, east, north, east, east, north, east, east. And the orange arrows are giving the action of pop. So here's the same picture, but smaller. Let me define m of tam of nu to be the maximum number of iterations of pop needed to send an element of tam of nu to the bottom. Of tam of nu to the bottom. And I'll define n of tam of nu to be the number of elements that actually require that many iterations to get to the bottom. So I can actually compute m of tam of nu for any mu, although it's kind of complicated to state, so I'm not going to do that here. Instead, I'll just tell you what happens when we look at the nth m Tamari lattice. In this case, the maximum number of steps you need to get to the bottom is exactly m plus n minus 2, and the number of elements required. And the number of elements requiring that many steps is given by this formula here. And in the case when m is 1, so we're just looking at the Tamari lattice, then this simplifies and just becomes the n minus second Cadillac element. Okay, so I can also look at TPOP sortable elements of the nth M Tamari lattice. I'll denote the number of these by H sub T of M. number of these by h sub t of m, n. And my conjecture, which is still open in this level of generality, is that for any fixed t and m, if you look at the generating function that's counting t pop sortable permutation elements of the nth m to Mari lattice, then this should be rational. And here, n is varying in the generating function. Okay, so I don't know that this is, I mean, I haven't proven this in full generality, but I know it's true. You know, flow generality, but I know it's true when t is 1 or 2. In this case, I can just compute what the generating function is. It's not that bad, it's actually pretty clean, although there are just some cases, so I didn't state it here. And then we also know that it's true when m is 1. So here we're just looking at the Tamari lattices. And in this case, so Karina Hung showed that the generating function is rational, but it actually is not just rational, it has this really nice form. And here again, the C's are Catalan numbers. These are Catalan numbers. And I'll just mention that. So Karina Hong was a student of mine at an undergraduate research program in the summer of 2021. And she very recently won the Morgan Prize for Outstanding Undergraduate Research. And this was like one of the things that went into her list of accomplishments that got her this award. So I was very proud of her for getting that and proud that this was like one of the things that allowed her to get this award. Okay, so again, this. Okay, so again, this is still open in full generality, but we know some special cases. I have a question when t equals 3, for example. Can you compute all the H T M N's and you just don't know whether that function is rational or you can't enumerate it? So I think in principle, you could do it for t equals 3. It would get more complicated. You could do it for t equals 4. It would get more complicated. And at some point, you just have to stop. And I think I stopped at 2. So, yeah, I think it's that kind of thing. Another question? Yes. I look at this, and at least my feeling is that one should consider bivariate generating functions. Yeah, I think that also looks interesting. I haven't really explored that, but yeah, that could be a good thing to consider. Okay, so I'm gonna sort of have a little side tangent here, which is mainly for motivation. Basically, I wanna motivate. Basically, I want to motivate looking at the image of the pop stack sorting operator. And I told you before that people had done this in the case of the weak order on the symmetric group. This is just the classical case where there are these pop stacked permutations and there are various papers like this polynomial time algorithm for counting them. But you can also do this for other meat semi-lattices. And one of the sort of motivation for, I think, looking at this comes from something called row motion. I'm going to be very vague here just because this is for I'm going to be very vague here just because this is for motivation. But there's this, if you have a distributive lattice, this is a nice family of lattices, there's this special bijective operator on it called row motion. And people have studied this a lot in the field of dynamical algebraic combinatorics, where they'll look at some specific distributive lattices and they'll try to understand the orbit structure of row motion on those lattices. And then Nathan Williams and I introduced a much broader family of lattices that we call semi-distrim lattices. That we call semi-distrim lattices. The name is because there's this family of semi-distributive lattices that generalize the distributive lattices, and there's a family of what are called trim lattices that generalize the semi-distributive lattices. And this is sort of an even broader family that encompasses the semi-distributive and the trim lattices, so we call them semi-distrim. And we show how to define in a sort of natural way this bijective row motion operator on any semi-distrim lattice. And associated to any semi-district lattice is a special graph called the Galois graph. Again, I'm not going to define this, it's just some graph that you can associate to it. And basically, we found that there are a lot of interesting connections between row motion and popstack sorting on a semi-distrim lattice. So I like to think of popstack sorting as like the non-invertible cousin of row motion in some sense. And one of the ways that this connection manifests itself is with this theorem, which Is with this theorem, which says that if you have a semi-distrim lattice L, again, I haven't defined this, but you should just think of this as some broad family of lattices. All the lattices that I've talked about so far are semi-distrim, so this encompasses all of those. So L is some semi-distrim lattice, and L star is its dual, that you could just flip it upside down. Then, okay, there's this row motion operator. It's some interesting bijective operator, and it's bouncing around your lattice. Maybe you have some element here, row motion sends it over here, then row motion goes over here, and it just bounces around. And you can look at how much. Around, and you can look at how many times does row motion go down. So, how many elements x are there such that row motion of x is less than or equal to x in the lattice? It turns out that this is the same as the size of the image of pop on the lattice. And this is also equal to the size of the image of pop on the dual lattice. And this is also equal to the number of what are called independent dominating sets in the Galois graph. So, these are basically like maximal independent sets in the sense that. Sets in the sense that you can't extend them to bigger independent sets. And yeah, so again, this is sort of just extra motivation trying to say, I think it's an interesting thing to consider this as like a nice enumerative question. You've got some interesting lattices. What's the size of the image of pop? And I'll just mention that this equality does not hold for arbitrary lattices. It's some kind of interesting special thing that happens for these semi-discriminate lattices. That's not really relevant here. I just think it's kind of interesting. Okay. So, as I mentioned, there's one place where people had already studied the image of POP. This is with the POP stacked permutations for the weak order of the symmetric group. There's another example that you get by looking at these lattices on DICPAS, which are not the same as the Tamari lattices. So, this is a different family of lattices defined on DICPAS. Here, the order relation is given by saying that if you have two DICPAS, you can kind of If you have two dick pads, you can kind of superimpose them on top of each other. And if one lies weakly above the other, when you superimpose them, then it's bigger in this project. So like this one would lie weakly above this one, this one lies weakly above these two, and these two lie weakly above this one. And there's this theorem of Saponakis, Tassilis, and Sicaris from 2006, where they show that the size of the image of Pop on this lattice is given by this nice formula here. Nice formula here. They were not calling it POP, so they had some different name for it, but this ends up being essentially what they were doing. So this is just another example where people had studied this. And also there's this result by Tarina Hong from the same paper as before, where she shows that the size of the image of pop on the nth Tamari lattice is the n minus first Maudskin number. And the way she does this is to say, well, the nth Tamari lattice is actually isomorphic to Tamari lattice is actually isomorphic to the sub-lattice of the weak order on Sn given by the 3, 1, 2 avoiding permutations. So if you take the weak order on S in, some big lattice, if you pick out the 3, 1, 2 avoiding permutations, that actually forms a sub-lattice, and it's isomorphic to this Tamari lattice. And so she showed that under this way of viewing the Tamari lattice, the image of POP is really the set of 3, 1, 2 avoiding permutations of size n that end with the number n and have no double And have no double descents. And by double descent, I just mean two consecutive descents. So, this equality is really the difficult part of the theorem. It's not hard to enumerate these permutations and show that they're counted by the Motzkin numbers, but really the difficult thing is showing that this is the characterization of the image. And I'll just mention that in the paper about semi-district lattices, Nathan Williams and I pose a bunch of enumerative conjectures. Bunch of enumerative conjectures about the size of the image of pop on various types of lattices. I'm not going to go through what they are, it's just a bunch of different types of lattices. All of these were resolved recently in a preprint by Yoon So Choi and Nathan's son. These were also two of my undergraduate students at the same program, but this past summer, in 2022. Except they did not resolve this last one about what are called bipartite Cambrian lattices, but the others were resolved. And one thing that I think could be an interesting enumerative thing to consider is. Enumerative thing to consider is just the size of the image of POP on the M Tamari lattice. So when M is 1, we get the Motzkin numbers. But for M bigger than 1, I haven't really looked into this. Maybe this could be some interesting thing to look into. I kind of just thought of this when I was making the slides, so I thought, you know, this could be, maybe there's something interesting. And I guess the last thing I'll mention is one other sort of type of problem, which would be to take an infinite meat semi-lattice, L. Meat semi-lattice, L, and count the Tpop sortable elements of that one fixed infinite meet semi-lattice. And you get this generating function. So here a sub t is the number of these tpop sortable elements of L. And you can ask, what is this? And does it have nice properties? And is it rational? Something like that. I think there are some interesting potential candidates for what L could be here. You could look at the weak order on any infinite Coxner group. This is still a meat-semi-lattice. A nice example. Semi-lattice. A nice example is the affine symmetric groups. You can also define some sort of affine analog of the tamari lattices, which are these tamari meat semi-lattices. These are basically, if you're familiar with affine permutations, they're like the 3-1-2 avoiding affine permutations under the weak order. And then there's also something called the weak order of the positive break monoid that I think is also some interesting thing to consider. Yes? Is it obvious that uh Is it obvious that AT is finite? No, I think probably for some examples it will be infinite. Yeah, I mean, I think you could cook up some examples. So yeah, you probably want something where it is finite and you could say something. Okay, so yeah, I think that is all that I have to say. So thank you. Thank you. Thanks for the question. Yeah, so you mentioned earlier. Yeah, so you mentioned earlier in the talk that you can prove in a not very difficult way, or several not very difficult ways, that the average number of steps needed to obstacks for the permutation is at least 10. Yes. So one way that I like is, okay, this is not obvious, but I think it's cool. If, well, let me define, say, f of sigma to be the number of iterations needed to sort sigma. Could you use white? Yes, I could use white. use white yes I can use white so f of sigma it turns out that if you take f of sigma plus f of the reverse of sigma if sigma is not the identity or the reverse of the identity this is at least n. Well I was hoping or something like that. Yeah. So this is actually true but not obvious. Right, it's not obvious. How long does it like two pages? Yeah, so there's this theorem, well there's this paper There's this theorem, well, there's this paper by Unger, and he proves, right? So he proves something, and then using that, you can show it's sort of an easy consequence from this. Yes. Oh, Robin. Okay. Yeah, so after we're finished talking about the symmetric group, then we didn't see any more quantitative conjectures or theorems. So I'm wondering if distributive lattices, if there's some kind of. If there's some kind of something you would guess to be true about the maximum. Oh, right. Well, so I had things for the new Tamari lattices, but I guess I solved those, so they were theorems. I mean, yeah, I don't know if I have any specific conjectures along those lines, but I think for any interesting lattices, you can formulate the same kinds of questions. The same kinds of questions, I guess? Is that what you're asking? Yeah, I guess so. I was just noticing, like, when I was trying to understand your covering relation of the Tauri lattice, I hadn't seen it before, so you're right, it's a little unnatural. And I noticed, well, you could just have the pop a single square, which would be finer, which would therefore presumably give you greater values for the number of pops required. So then, and then and as a distributive lattice, so maybe in the distributive lattice, the So maybe in the distributive lattice realm, that's sort of the worst case. Oh, I see. Yeah, so for a distributive lattice, one way you can think about it is it's the lattice of order ideals of a poset. And what you're really doing to an order ideal is you're just taking away its maximal elements. So actually, in that case, I think it's true that the maximum number of iterations is like the length of a maximal chain in that postet. So there, it's sort of like we kind of understand that as much as we understand the length of a maximal chain in that poset. Yes? I just was looking at this algorithm, you know, since then sorted, and it looked at me, there's a, there's sort of two parts to it. There's one is fast part, when a lot of points move into position. And the slow part is like a single point and some block of points underneath it in increasing water. And that just comes slow. That's sort of on the order of N, because it just has to cover. So, do you have a screw when I can? Do you have us have an idea looked at this? Do you have an idea of like what how how short is this fast part? I don't really know. I mean, I think that would, like, understanding that would help to understand the conjecture or get something better than n over 2. Yeah, so I don't really have anything along those lines. I guess my, another way of sort of thinking of why n over 2 should be, why you can get at least n over 2, is that if you look at like some. if you look at like some uh let me so if you look at some point that's over in the bottom uh right then it should take roughly n steps to get all the way over if you can see that's sort of what's going on here and I can show that like at each step it has to move at most two to the left and that's not hard so from that you get like So from that, you get like, okay, it's going to have to take at least two steps if at each point it's only moving at most two. But it's kind of weird and hard to say that, like, no, it should actually be moving usually at most one step. I don't know if that maybe answers the question. Yeah, I guess the general answer is I'm not, I don't fully understand what's going on. There's bubble sorting and other similar algorithms in Technoscope. Right, and bubble sort, I think, Right, and bubble sort I think uh is much easier to understand. Yeah. Now what about Bruha sortie? Uh what is it? So weak order corresponds to descent. What do you feel considering version which corresponds to? Ah so the the bruha order is not a meat semi-lattice so I don't know how you would do that because you just there's not like a meat operation. A quick question about what we were seeing in the animation. Animation, you saw a lot of patterns drifting to the left, but are these patterns all non-consecutive patterns? Because I don't understand how a consecutive pattern could really drift. I guess I'm not sure exactly what. Yeah, I mean, like, you're sort of seeing chunks of things drift? Yeah, I've seen a bunch of points, you know, like that make a constellation in the sky, and it's drifting to the left or the right. Oh, yeah. Right? But. Left or the right. Oh, yeah. Right? But how can, I don't know, are those points really ones that are not consecutive coordinates? They're separated or I don't understand how they would drift like that. What are they? What are those configurations that remain stable, but move? I think they're just a bunch of points where, like, at each step, maybe they're moving about one step over. So maybe, like, if you have points that are high up, they're If you have points that are high up, there's a good chance that at each step they're going to be the top of a descending run. And maybe if that descending run only has size two, usually it'll have only size two, and so it'll just move over one spot. But if you have a lot of these things and each one is moving one spot, then it kind of looks like they're drifting. But I guess like you could have weird, it doesn't have to do that. They could switch around a little. Like a good portion of the points after a short time seem to be in these. After a short time, seem to be in these blocks that are drifting home. Yeah. Yeah, I don't understand it. Okay. Yeah. All right. I'm sorry. I think we're going to take further questions to after the talk, so we'll say Colin again. Yes, stop on the beginning as soon as we can make a button. And as soon as we do the wing, but select four