Thank you very much. And thank all the organizers for putting this workshop together. I think this is really neat. I've already learned a lot and made a long list of papers that I want to read. This is some joint work that's been funded by the National Science Foundation. It's a collaborative project, and so all of the Project and so all of the participants have been supported under the NSF. Okay, so to how do I get the slide to advance? Oops. Okay, so I thought it might be worthwhile to start with just a quick outline of the way the talk is going to evolve. I just want to set some notation. We're all here talking about. Set some notation. We're all here talking about inverse problems, but I will write down the particular notation that I'm using and try to give some motivation for why we're pursuing this line of image modeling. Part of the motivation came from work we did some years ago now on parametric level sets or PALs for binary images. But now we've developed this. But now we've developed this brand new method, and I am not going to take credit for the acronym here. My co-author, Eric Miller, really, really, really wanted to use Palantir because it comes from some, I don't know, book or movie series or something that he's interested in. So that's where that came from. What's nice about our new model is that it allows us to address To address this issue of multiple contrasts that we couldn't do with our original model, I'll show you lots of numerical experiments where that shows how really exciting this is and talk about future work at the end. So here what I'm using is sort of a generic formulation for our forward model. So this script M will just always refer to the forward model. It doesn't have to be The forward model. It doesn't have to be linear. R is the spatial variable here, and I'm first going to describe it in terms of a continuous function f that I would like to recover. D, the bold-faced D is the discrete data that's collected at the detectors. And for the time being, the W will represent unknown additive Gaussian noise. Additive Gaussian noise. And so our basic assumptions are that we are looking to recover an image that is piecewise constant with a modest number of unknown contrast values and shapes. So again, the forward model, it could be linear, and I'll give examples of this for deep blurring and X-ray CT, or it could X-ray CT, or it could be non-linear. And I'll give an example in diffuse optical tomography later on for that. And this is meant to work in the case when we have extremely limited data, meaning that the discrete problem could be very underdetermined. And I want to recover a discrete image, but what I want to do is respect the fact that in many of these But in many of these applications, a pixel-based or a voxel-based in 3D reconstruction is either not necessary, knowing what we know about the image, or it's undesirable because we would simply have to enforce so much regularization in the regime that it's just not worth it. So, So, as a starting point, I'll use this generic shape-based model. So, if we assume that the object that we want to recover is binary, then you could do this with using characteristic functions, chi D. Basically, we want our unknown property to be some value, some fixed value. Value, some fixed value, F0, inside this region D or and F B in the region outside B. And that's it. And so this becomes a problem of shape-based recovery in that what we want to find is basically the boundary of D and possibly these two numbers if we don't know what those numbers are. And so way back. And so, way back some time ago now, traditional level set approaches could provide a way for finding the boundary of such regions. And the idea is that you're looking for the zero level set of some function phi. So here's a nice picture, one of the uses of Wikipedia. And what you see here is that in these three different images, let's These three different images. It's the same level set cut, but the height of the fee is different. And so you can pick up multiple objects, for example, by using zero level sets to represent these shapes, and the components don't have to be connected. And so if H is a heavy side function, then basically mathematically, And basically, mathematically, the way you could represent that is with this expression here. And this can be made to work in the inverse problems context. It works really well in, say, segmentation, but it's really non-trivial to get this to work well in an inverse problem setting when we have noise and all kinds of ill-posed. And all kinds of ill-posedness. So, part of the problem with why it doesn't work is that there's just too much variability. So, what we decided some years ago is that we really wanted to restrict the class of functions phi to those that we could define parametrically. And then the idea is instead of optimizing for phi itself, Of optimizing for phi itself, we're optimizing for the parameters that define those level sets. And of course, to make this work in a practical setting, we have to replace the heavy side function with a differentiable approximation. Okay, so the original paper that we wrote about this appeared in Sims back in 2011, and the idea was simply to let The idea was simply to let be replaced by something that looks like this. It's a weighted sum of basis functions, and the size of j's are defined in a parametric way. And so we have to recover the expansion coefficients, the alpha j's, and any parameters that define these phi sub j's. Phi sub j's in the j'th basis function. And so in that original paper, and I won't go into why we did this in particular, but instead of the zero level set, we needed to use a c level set. But it's essentially the same concept. If you have a binary image, here's the representation, except that now what we need to recover are the parameters that describe the object of interest and h sub e. And H sub E subscript epsilon is an approximation to the heavy side function. And there is a relationship between this epsilon value and C that again, I don't want to go into right now. So that was a paper that appeared, as I said, in 2011. And since then, it's been picked up and used in a number of different inverse problem settings. One of the things that you One of the things that you have to decide right away is what should those size of j's be? And in practice, one very good choice of basis functions are radial basis functions. So even within the set class of radial basis functions, there are different types. What we used in the original formulation. What we used in the original formulation was compactly supported radio basis functions. These are smooth, but the compact support did some nice things for us in terms of the optimization and so forth. But in other inverse problems, for example, in EIT, folks have used Gaussian radial basis functions. There is a short little procedure. There's a short little proceedings paper here where the authors actually compare various different types of radial basis functions in the context of doing this for EIT problems. And there's been some work where the standard radio basis functions, which you can think of these things as bump functions. So if you take a level set of a Take a level set of a bump, you're going to get a circle. So instead of that, what has been proposed is using ellipsoidal, making these things ellipsoidal so that they can better capture the elongations. And there's some really nice work in a recent paper where you can see this in action in 3D, in a particular inverse problem. But part of the problem that we've stumbled upon was that, okay, if we're using this compactly supported radial basis function, when we define the fees of J's again in this original work, we were defining them so this argument is not a norm, it requires a pseudonym. A pseudonorm. And probably many of you have had experience, you know, where you're trying to do some kind of regularization, then it's not, you know, differentiable where you need it to be. So you stick in the fudge factor, and then there's the question of what should the fudge factor be. So that's mildly annoying. But also, in order to get this flexibility in two and three dimensions, where you're in three dimensions in particular, where you want to You want to add elongation information and rotational information, that can be very tricky. And one of the things we want for this image parameterization to do is to do the regularization for us. We don't want to have to add additional shape-based regularization and complicate the optimization problem. So for those, some of those. For those, some of those reasons, I'm going to be talking today about using Gaussian radial basis functions. Simple to explain, it just means that the size of x would be this exponential function. So the basis functions that I'm looking at, the size of J of R, are psi applied to the two norms squared of this difference. So here again, R is Here again, R is just, you know, it's the variable in two or three dimensions. The chi-sub j then is a vector that has a grid point location in it. And under these restrictions, then the function of which we would like to take a level set just looks like this kind of. Set just looks like this kind of representation. So if I collect over all the basis functions and all these weighting parameters together into one long vector p, so all the alphas, all the betas, all the center locations, that's my vector of unknowns that I need to completely describe the image. So moving from From the continuous setting to the discrete setting. Well, first of all, this is what the whole, this is what it looks like for the zero level set. This is our binary image model now using Gaussian radial basis functions and a phi, which is parameterized in the way that I just described. If I If I imagine now that there are spatial grid points where I would like to reconstruct the object of interest, I will get a vector that I'm just calling F of P at, say, you know, a total of n sub PTS grid points. And this is the This is the representation for those, for the values in each one of the grid points. So these centers for where the basis functions live do not and will not be necessarily sitting at the same grid points as where I'm representing the image. So, what I want to call your attention to here is Call your attention to here is that the vector of unknowns that I'm going to have to solve for in order to be able to represent my image now is this vector p. And the total length of that vector p in 2D is 4 times n, capital N, where n is the number of basis vectors, or 5n in 3d. And that corresponds to And that corresponds to alphas, betas, and chi all lumped together. And that should be a relatively small number compared to the total number of grid points where I'm trying to reconstruct my image. Okay. So the discrete forward model, then with some slight abusive notation, I'm using M again. Using m again looks like this. And the inverse problem looks very simple, right? It is just to minimize this 2-norm for this parameter vector p. And you see that I have no additional regularization, no additional regularization parameter. This is a non-linear least squares problem, and we know how to solve these. To solve these. Okay, so again, this worked very well for us in several cases, but not all interesting images are binary images. I may want to recover images that have multiple contrasts and multiple different shapes. You could take this basic model and, you know, fix. And fix it, I guess, so that you had different PALS representations, say one for each different contrast. And something like this is done in this paper. But it's expensive on the one hand because now you're adding total number of, you're increasing the total number of unknowns and you risk that the problem. Risk that the problem becomes less regularized because you're introducing more parameters that you have to solve for. So, those are issues. But one of the other issues that we discovered when we were trying to do uncertainty quantification is that we were having some concerns with the fact that you can get very different, you can take very different parameterizations, but get a similar representation. Get a similar representation for the image because, at the end of the day, if you have a lumpy-looking surface and you take a level set, several different lumpy kind of surfaces will have the same, you know, the picture will look the same at that zero level set. The alpha j's, these expansion coefficients are unbounded in the original model. Original model. And so we were seeing that you could get very, either very, very peaked alpha j's, or you could vary the beta parameter, that dilation parameter. And we were floating the centers of these basis vectors. So those were unknowns to us, those chi-sub j's. And that means that. And that means that you can't really think of each basis as being labeled, right? It didn't matter if the thing that was originally here moved down or the thing that was over here moved down. You get the same picture. So these kinds of things had a big impact on us trying to do uncertainty quantification. And so, moreover, because Because of some of these issues and the fact that some basis vectors were contributing to the images and some of the other bases were not. We had ill-conditioned Jacobians. So we got around this by doing a trust region regularized Gauss-Newton method, and that works really well to kind of. And that works really well to kind of fix up the problem, but you know, it, I don't know, begs the question of could we have gotten avoided some of this issue with ill conditioning altogether? And if you use just standard radial basis functions, you know, and you have something that looks more ellipsoidal, you'd need a lot of those basis elements to try and capture those kinds of shapes. So these were all things. So, these were all things, these limitations that kind of motivated us to look at different ways that we could improve our method. So, this new Palantir model has several nice features. First of all, we just said what the heck happens if we just fix the centers on a grid. And it works surprisingly well, as I'll show you. Works surprisingly well, as I'll show you. That removes the total number of unknowns. And we add a special transformation that will capture elongation, but has some nice features, as I'll show you. We have a nice way of bounding the expansion coefficients so they can't go all wonky. They can't go all wonky. And we have a way of adding a spatial dependence in the background and object contrast that gives us an ability to actually find multiple contrasts with a single set of basis functions. So we can retain this nice feature of a very few unknowns that we have to solve for with a Gauss-Newton time. With a Gauss-Newton type approach, and we can reconstruct multiple objects. So, just to compare and contrast how this is going to look. So, I'm going to do this just in the 2D case for now. And towards the end of the talk, I'll show you how we can do it for three dimensions as well. So, the old approach. The old approach, these were the basis functions that we used. In this new approach, instead of just having a single beta j, we add this shear type transformation matrix, Rj. And on the diagonal, you can see that these are e to the beta j and e to the minus beta j. j and e to the minus beta j. So probably beta j is not going to go very, very large or very, very small. It's not going to be too extreme. And a gamma j up here. Mu is just a fixed constant. It depends on some properties of how the grid is set up. And instead of thinking of these chi sub j's, these center locations, Center locations as being unknowns. Now they're fixed. They're fixed on a grid. And everything I'm showing you in all the numerical results, they're fixed on a regular grid. All right, so in the old approach, we had just this, the expansion coefficients alpha j that weighted the phi sub j's. And now what Of j's, and now what we have is the alpha j's feed into this function here, which ensures that every weight on these coefficients are bounded between minus one and one. So that helps us with some of the effects we were seeing before, very, very large alpha j's. Excuse me. So at this point, this is what we have. We have, again, this value that's the value of the object, the contrast inside the object, the background value, a phi that depends on these set of parameters, a heavy side. There's a heavyside approximation, and we had to think a little bit about what this approximation should be. It turned out that in the 2011 paper, again, where we're using compactly supported radial basis functions, there was very good reason to use one choice of approximate heavy side function. But in this setting, But in this setting, something else works a little bit better. So I want to explain that. So I want to first just let's drop the assumption that about the background. We're just going to assume it's zero. It makes things a little bit, it simplifies things. And let's assume that I know a number. I've called it C high. So it's a constant. It's fixed a priori. Fixed a priori. I'm assuming I have an image, it has multiple contrasts in it, but C high is at the largest such value. Okay. And then here is the function phi sub r, I've forgotten the p here, oops, the parameterized function that belongs in here. And our heavyside approximation is this one, and the epsilon. And the epsilon is very important here because it actually controls the sharpness of the transition. Now, you might think, oh, heavy-side function should, epsilon should be, you know, such that this thing is a very sharp transition because I'm looking for an image that is piecewise constant. But it turns out that keeping that as a more modest transition. As a more modest transition actually has an advantage, and that's what I'm going to try and convince you of in the next few slides. So, here's a test reconstruction here. All I've done is basically like a denoising problem. So this is M is like the identity operator here. We made this true image with four different contrasts on top of the zero background. And so four, three. So, four, three, two, and one. And we just run our algorithm to find the PALS parameters. I have set up this, you know, there's a total of nine rows and columns of basis elements, right? Not necessarily, in fact, not sitting on the same grid points as the grid points where I've discriminated. The grid points where I've discretized the image. Okay. And I recover the vector P and reconstruct the image here. And what you see is that the highest contrast element is nice and clean and sharp. But I get the other four squares back. There's just a little bit of variability in those squares. So if I look at, this is the function. This is the function that depends on the parameters. That I need to take the level set. I'm looking at the approximate zero level set. And this is the heavyside approximation here. So the way to look at this is if this thing is, unfortunately, I forgot P in all of these. If this thing is, you know, up here in this. You know, up here in this region, right? Then, okay, boom, I'm on this part of the curve, I'm close to the H of E returns approximately one. H of E was pre-multiplied by the largest contrast, which was four. So I get image intensity four. That was the crisp clean square. But still, for Still for phi of r close to zero, for example, the h sub epsilon is 0.5. 0.5 gets multiplied by 4, so I get an image intensity 2. That was one of the squares, and so on and so forth. So the fact that I'm not exactly taking a sharp cutoff allows me to actually see these other. Allows me to actually see these other contrast objects. They're just not, they're just not, you know, they look a little blurry, right? Okay. So it's the fact that this heavy side approximation is not such a good approximation, really, that the other contrast regions can be seen. But as I said, the But as I said, the object with the contrast that was closest to this value, this fixed value of C high, looks the most sharp and uniform. If I take that model and adjust for non-zero background, I throw this a C low, you might imagine, now is the lowest threshold in the image. In the image back into the model. This is what now our parameterized image model will look like. But that's still assuming that C high and C low are known and fixed. So the last piece of the puzzle is putting in a spatial variation into the C high. Into the C high and the C low to get to see if we can't recover the contrasts of those other intermediate contrast values a little more cleanly. So, this is again the image model that we're looking for. Let's see if I can convince you first of all, just by picking some C high and C low images by hand and plugging them in and then solving this problem, knowing what these things are, makes a difference. So, here, the first, there are three different examples here. So, the first row. Examples here. So the first row corresponds to this having, this is C low, this is C high, this is what the reconstruction will look like. So this is a slightly more complicated image in that things are tilted and we have multiple contrasts lying on top of each other. Here is a second example: C low, C high. C high, we get now. This is sharp, this is sharp, this is sharp, this is getting cleaner. Here is an example where this is C low, this is C high, and that is our Palantir reconstruction. So you can see if I know the first two columns, right, if I know a C low and a C high, I can improve things by tweaking these. things by tweaking these these so the the question is you know and and these are very coarse scale um looking images right the sea low and the sea high so how do i get those how do i build this into the process and learn what they should be um so i don't know if this is the most clever thing but we're doing something and it and it works um which is all right so start out um with an initial Start out with an initialization of these high and low contrast images to be just constant images with, you know, whatever our estimates for what the largest and smallest contrasts ought to be based on what I know about the application. And then I will use those, solve this problem with the T Regs algorithm. Algorithm that's that trust region regularized Gauss-Newton method. And that will return to me this image that I've called F K minus 1 at P. I look at that image. I decide on a window size. And over each window, I get a new C low. I replace every. I replace every value in each one of those windows basically with, oh, I that should be that should be a min right there with the minimum of the image in that window and the maximum of the image in that window. And then I just repeat. So, you know, how many times do I have to repeat this? So what do I mean by converged? We just did this until the relative. We just did this until the relative changes in the low and the high distribution images were each below 2% relative change. And it is true that these constant images that I start with, they can't be wildly off. They can't be hopelessly over or underestimates. But otherwise, it learns things pretty quickly. Learns things pretty quickly. So if I run this simple algorithm on the same data set, here is the final C low distribution, the final C high distribution, and that's our Palantir reconstruction. So you can see this is, it's pretty clean. We get this was a piecewise constant problem and everything looks. And everything looks very, very nice. All right, so now we add something in that's a little more interesting than just the identity matrix. First, we'll do a deblurring application. So this is a linear problem, and this was just a Gaussian blurring application. We handmade an image F, we multiplied it by A, we added We added Gaussian random noise. And what I'm going to show you is a comparison of our Palantir reconstruction to just using a standard pixel-based reconstruction with a total variation regularization using the best parameter. So we took the best TV that we could get, tried a whole bunch of different regularizations. Tried a whole bunch of different regularization parameters, and this is what I'm showing you. So this is total variation, deep learned image, and this is our palantir reconstruction. Everything was supposed to be piecewise constant, and here it looks very much so, except for maybe just around the outside of this wing-looking shape. Whereas the TV was a little bit. Whereas the TV was a little bit more blurry, and there's a little bit of funny speckling going on in here. In all the performance metrics, PSNR, SNR, SSIM, mean square error, our method does better, which you could probably tell from the eyeball norm. And I just wanted to point out that, again, in this total variation reconstruction, Reconstruction. This is a pixel-based reconstruction. So the total number of unknowns was equal to 80 squared. Whereas in the palantir, it's three times the total number of basis functions. And I believe this was, I don't remember if I said, oops, I guess I didn't say, but it's something like seven by seven or eight by eight. So three times, you know, 64, for example. 64, for example. So, in this example, this is X-ray CT. It's a fan beam setup. This is real data that you can get from the web, from the Finnish Inverse Problem Society page. This is what they give as the ground truth reconstruction of a phantom that was carved cheese that says CT in it. In it. And I'm going to show you both limited angle and sparse reconstruction. So, in this, this is the first is limited angle, and you can probably see unsurprisingly kind of what you would have expected for a ticking off reconstruction. This is a total variation again on the same data, and this is our palantir. Data, and this is our palantir reconstruction, right? And this was only a seven by seven or so grid of parameters that we had to solve for. So I don't know. I think the proof is kind of in the images about how spectacular this can work. And I should say also, it's relatively insensitive to the number of radial basis functions that we use. Basis functions that we use. We tried seven by seven or eight by eight. Unless you start increasing too much, in which case you're losing the regularization properties there, you do really well. And this is the sparse angle case. Again, also comparing to ticking off TV to our Palantir-based approach. Again, we don't have to choose a regularization. We don't have to choose a regularization parameter other than deciding how many basis functions to use, but it's not very sensitive to that choice. And in these, what I'm showing you is the reconstructions with the optimal regularization parameter. But I wanted to show you that this also works not just for linear inverse problems, but also for nonlinear inverse problems. Linear inverse problems. So, in diffuse optical tomography, we measure the photon fluence or flux at points. And at the so it's a very data limited problem. You have very few sources in 2 or 3D and a very few detectors. And from that, you want to reconstruct an image of the optical absorption. An image of the optical absorption everywhere in the region of interest. In this setting, I've written this input-output map so that it looks like a transfer function. So basically, B here is the columns of the matrix B are basically columns of an identity, some selected columns of an identity matrix and C is a And C is a C transpose selects things. And so we have to solve this large-scale partial differential equation to try it for a given, you know, if you know what F of P is, try to solve that to find the values of the photon fluence and flux. And then you have to pick out the information on the boundary. Information on the boundary. And that's your measured data. So in vectorized form, this is what it would look like. So this is a 2D example with synthetic data. The sources are on this side. It's a transmission geometry. So the sources are only on this side. The detectors are only on this side. And it's this kind of difficult. It's this kind of difficult shape to reconstruct. This is the image that you would get based on the starting values of my parameters. So I just wanted to show you that I'm not cheating here. This is my initial image, which is just pretty much just one big solid blob. And this is our palantir reconstruction. So two things. So, two things. This was noisy data. And this is only a reconstruction using DC data. Typically in diffuse optical tomography, we need to use frequency modulated data and other frequency modulations to get, you know, just to be able to handle the inverse problem, get enough data to reconstruct something. To reconstruct something, but this was with DC data only. So I think this is really, really promising. The last thing I'll note is that the whole model will still work for the 3D case. Basically, the only thing that I have to do differently is now R is a vector in R3. We have the center locations are in R3. And capital R sub bay. So B is now defined as a product of these three matrices where you see these little shear-like transformation matrices embedded in each one of those products. So I do have more unknowns that I have to recover in three dimensions. But to show you, it works. This is a it's just a single contrast case, but it is a limited angle. It's a 3D. Is a limited angle. It's a 3D parallel beam problem. And EGA removed some of the information to make this a limited angle case. Noise level is 1%, and the PALS basis lives on a 7x7x7 grid. So think 343 unknowns compared to, you know, on the order. You know, on the order of 27 cubed in terms of the total number of voxels. This is slices through the true image. So you can see we have a circle and a plus sign in this that we need to kind of reconstruct. And this is the Palantir reconstruction. Again, there's no additional regularization parameter, no additional regularization. Parameter, no additional regularization, it's built into the parameterization. And Age figured out how to kind of use a different visualization tool so you could see the setup. This is the true binary image, and this is our reconstruction. So I think I'm pretty excited about this. We've developed this flexible parametric level set image model. Level set image model. We need relatively few basis functions on a fixed grid. It's capable of capturing edge information, multiple contrasts. There's no regularization parameter really to choose. Side benefit is that we're, you know, we have improved conditioning of the Jacobian, so better behavior for the convergence of the The nonlinear solver. In future work, we want to try and do some adaptive refinement. You might envision starting with a very few basis vectors and basis elements, sorry, and then add additional ones on top of that. We want to look into additional efficiencies, of course, in the optimization and the adaptive weighting scheme with the C high and the C low to see if we can improve on that. To see if we can improve on that, we have more work to do in 3D. Some things I didn't show you was that we have used this in denoising applications with non-Gaussian noise, and we can get some really great results. But we're interested in finding out if it extends to general inverse problems. And finally, we hope to get back to the question that motivated this in the first place, which was uncertainty quantification. Quantification. With this improvement, all the improvements here, we're hoping that this is more tractable now in this regime. So thank you very much for your attention.