I'm hoping this will show up under the name John Wait on the video I'm thinking. Okay, let me see. Okay, so what I want to talk to you guys today is about using models to infer spatial histories from genetic data and. Um, and we can do this because uh, contemporary spatial genetic patterns, samples we collect today, reflect the spatial history of that sample. Right, so that might be a pattern of isolation by distance that we see humans in Europe, or that might be kind of larger scale population movements that people have inferred in this case for rabbit opsis expanding out of Africa. Africa 100,000 years ago. So there are a bunch of approaches that people have used to infer the spatial history from genetic data. One is to think about non-recombining sequences, right? We can think about a mitochondria, parts of a sex chromosome, some viruses. And in that case, genetic relatedness of the sample is described by a single tree. And that is very useful because we can explicitly. Useful because we can explicitly have an explicit spatial model on that tree. And that's, you know, that's the realm of phylogeography. It's been around for a while. And we can do things like with this grabies virus in the northeastern U.S., we can kind of project that tree into space to locate the genetic ancestors and the rates of movement of those ancestors along the tree. Okay, so estimating dispersal rates and the local. Okay, so estimating dispersal rates of the location of genetic ancestors. But of course, if you have a single tree, you have limited information. There's not a ton of information in a single tree, especially as we move backwards in time. There's a lot of uncertainty there. So the other thing we can do is think about recombining sequences, like a human autosome. There, there's lots of information because recombination has chopped that up into many separate trees that all That up into many separate trees that all have unique spatial histories. There's a lot more information there. But historically, we've had no object to model movement on. We don't have a single tree. We don't have access historically to the many trees that relate that human autosomes of the sample. And so it's been difficult to kind of develop an explicit spatial model in that realm. So we've relied on other things. You know, for instance, it's 23and means ancestry composition. Ancestry composition. It'll take your genome and compare it to a reference panel from a bunch of discretized locations and say, you know, which populations are you most similar to? You can then make a statement saying like 25% of your genome comes from Ireland. And that's kind of something about spatial history of the sample. But it's because there's no explicit model, it's a little vague, right? When was 25% of your genome in Ireland? And And why did we choose political boundaries to discretize the population? Race, the outdated notions of race sometimes inform the way we discretize the world and kind of suggest to many people some kind of genetic homogeneity within the group when you discretize and emphasize differences between. And that's especially dangerous when we have created these groups based on some preconceived notion. So there's a Notion. So there's a bunch of difficulties with this approach. And so what I want to talk to you today about is about a different method that is now possible because we can infer ancestral recombination graphs. These ancestral recombination graphs are like trees, they have coalescent events back in time, but there's also recombination events back in time where this sample three. That time where this sample three at the left half of its genome was inherited from over here, the right half of it was inherited from over here at this recombination node. I'm not going to get too much into the details of these graphs, just that with programs like Argweaver and Relate and CSIFER, we can now infer these graphs for recombining sequences. And the cool thing is that we now have, you know, because we're dealing with recombining chromosomes, genomes, we have many traces. I can speak to all of you. That's the one thing that will work. We have many trees, so we have more speech information. And we also have an object on which to model movement, like you can follow the other trees. No, I think John Weekly has just joined, but Noah's out there. So just don't worry. Just stop with our chips. Okay, so I'll so today I'm going to discuss two approaches where we've used these. Use these args to infer spatial histories. The first approach is a simpler approach. It treats the arg not as a single graph with these loops and recombination nodes, but as a sequence of trees. So we have a tree that relates samples at one portion of the genome, this recombination event, and that changes the relatedness. And so we have this new tree and so on down the chromosome, a tree sequence. And our approach is, as I said, pretty simple. We're going to sparsely sample trees from across the genome so that they're roughly independent from one another. And then we're going to apply the classic kind of phylogeographic model of branching Brownian motion to each one of these sparsely sampled trees. And that means that at each one of these trees, the locations of the samples are multivariate normal with. Multivariate normal with a mean at the root and a covariance that depends on the product of the dispersal rate, sigma squared, and s, this matrix S, which is just capturing the shared times between all of the lineages of the tree. So, you know, this sample and this sample share a lot of time, and so their locations will be more correlated, will have higher covariance. And so, this matrix S is kind of the key for describing the distribution of these sample locations, the likelihood of the sample location. And so there's a bunch of details that I'm not going to get into for the second time, including ignoring the distant past and important sampling over these noisy trees that we're inferring from a pan-magnetic model. But ask me about those later if you'd like. The basic idea is that. The basic idea is that we have a likelihood of the dispersal rate at thousands of sparsely sampled trees across the genome. We can multiply all those likelihoods together to get a composite likelihood, and then we can find the maximum composite likelihood dispersal rate. And this is an overly complicated figure, but just focus on the x-axis where we have the dispersal rate inferred from true trees from a swim simulation. And in blue, this is the true simulated parameter 0.4 roughly. When we estimate the dispersal rate, we get something more like 0.2, 0.25. So we're underestimating the true dispersal rate, true simulated dispersal rate. And that also happens when we increase the simulated dispersal rate to 0.6 and orange, 0.8, and green. We're tracking the truth. We're tracking the truth. If we increase the simulated parameter value, the estimate increases in a nice fashion, but there's a systematic bias underestimating. And that's because our model of Brownian motion has no concept of boundaries. So we expect the sample locations to be really far apart from one another, but the boundaries in the simulation make the samples too close. So it's naturally going to happen, but that's just part of, we want a simple model. Just part of we want a simple model that has a tractable likelihood, so we're gonna still use this as valuable information about the dispersal rate. You inform the inferred trees is less biased? Yeah, so if you exactly, if you estimate from the inferred trees, so we've split out a VCF from the simulation, for the trees with relate, and then estimate the dispersal rate from those trees, it is less biased. Trees. It is less biased, and that's because there's some bias in the inference of the trees, and that canceled out a little bit. But yeah, the thing that I'm happiest to see is a strong, strong correlation between the true trees and the inferred trees. So we're not going for like a quantitative prediction of the stimulated dispersal rate. We're going for just kind of qualitatively in a comparison matter, like roughly what order is the dispersal rate. Is it greater or less than? Rating is it greater or less than another sample. But what I'm most excited about is locating genetic ancestors. And so this follows, because everything is nice and normal, this follows quite simply, we get a full probability distribution for a given ancestor. That's any point on the tree, any internal point on the tree, we have a probability distribution that normally distributes variance. And so, for instance, this screen sample here, 500 generations. Here, 500 generations ago, we guess its confidence, 95% confidence ellipse is shown as a screen ellipse, and the true ancestor location is the suspects. It's the line connecting them. And so we can do that for a bunch of different samples. Blue and orange, they've already coalesced, so their ellipses have coalesced. And so we can try to estimate where ancestors are this way. The difficulty here is that as you move back in time, when you're using only a single tree, Using only a single tree, the uncertainty increases, the noise increases, and the error of your most likely estimate of the ancestry increases. Roughly like the square root of time, because it's grounded motion. And so we don't do very well as we move back in time with either the true trees or the inferred trees. But again, the power of our approach is that we're not dealing with a single tree, dealing with thousands of trees across the genome. And so we can apply this. And so we can apply this to many trees, getting thousands of ancestor locations, and then plot the distribution of those ancestor locations. And that's what I'm doing here for this blue sample with this contour plot. And so we have, this is, in blue is where we infer the ancestors to be about 100 generations ago. And in gray, you can maybe see in the background, it's the true simulated ancestral location. So we're tracking roughly kind of where these, the majority. Where these the majority of the ancestors are. And when we compare the mean of this blue distribution to the mean of that gray distribution, we go back in time, we see that the error increases much more slowly. We can go back further in time, and we do better than the naive estimates that I won't get into. And so we think that we can track kind of the major geographic trends, the major geographic ancestries of an individual, not at any particular locus, but in general. Focus, but in general, you might be able to track what the mean ancestor was, or perhaps for admix individuals, something about the variants we also used. So we went ahead and applied this to Arabidopsis, which has a great geographic sampling, Africa, Eurasia, North America, and a very interesting spatial history, which I alluded to at the beginning, where we have this expansion of Africa into the Middle East. Into the Middle East and then North Africa, Morocco. And then about 50,000 years ago, a big colonization from the Middle East into the Iberian Peninsula, where these two ancestry have met and have battling. And so we thought it would be a really fun system to try out our method on. We first tried using as many samples as we could get from the 1001 Genomes Project and more. Genomes Project and more, but the low coverage data caused us to impute too much, and that caused a bunch of difficulties that I'm happy to talk about. But we couldn't infer the trees very well with that low coverage data. So we opted instead for a very small sample, 66 high-quality long-read genomes, where we could infer the trees much more accurately. And luckily, these small sample was sampled in a very smart way. Was sampled in a very smart way with knowledge of this history. So it's actually still quite a useful sample for us. So this is the data that comes from this paper here. This is where the samples are. They classified them into three different types based on a PCA, genomic PCA. The blue up here are non-relics. They're the expansion from Middle East. The orange are the Iberian relics. Iberian relics, that's the expansion from North Africa, and then there's a few non-Iberian relics which are more distantly related to those other two groups. When we applied our method to estimate dispersal rate from the sample, we got a dispersal rate that we think is quite reasonable. It's a little bit higher than a recent machine learning approach that said a small sample from southern Sweden. It's quite a small geographic area. Small geographic area. But it's also a little bit too low to describe the big population movements from the Middle East to, say, Iberia. So I think we're in the right ballpark. Feel comfortable with that. And I mentioned that we can ignore the distant past. And so if we infer dispersal rate as we ignore more and more of the past, so if we just say, look at the last 10,000 generations, we get a higher dispersal. We get a higher dispersal rate. And that might be reflective of more faster movements in more recent times, especially post-glaciation, rabbls is spreading north to south. Oh, and the final thing I'll say is that we see a higher dispersal rate east-west than we do north-south. And that has been noticed before and might be indicative of a more similar environment like east-west axis than the temperature gradient that you get north-south. There's also some talk about human agriculture. Some talk about human agriculture helping to spread east-west. So, just to get into the ancestor locations, which is the funnest part, I think, is I'm just going to show a few examples. Here's a sample from northern Sweden and a sample from Madeira. And a thousand generations ago, we've got the distribution of ancestors. And we see this northern Swedish sample already had its ancestors already moving back. So, quite quickly. Back south quite quickly, and as we go back 5,000 generations, 10,000 generations, we see a great difference where this northern Swedish sample is moving quite quickly back towards the other mountain relic samples, whereas the veneer is still pretty distant from the mainland. And we think that reflects kind of the post-glacial expansion of this mountain relic group. And previous estimates of the colonization time of the year are about 80,000 years ago. So we think we're doing something. So, we think we're doing something like there as well. There's lots of fun things you can do. Where did the genetic ancestors, for example, come from? Non-relic in Iberia has ancestors from the Northeast reflecting that kind of Middle Eastern expansion. Whereas an Iberian relic sample has ancestry that comes from the south, from the west, and the northeast, probably reflecting an admixed history of these two populations. Mixed history of these two populations meeting. Okay, so this has been pre-printed for a long time, long enough to even accumulate a couple of peer reviews. We're almost done with it. So we do, like I said, spatial inference with an explicit spatial model on thousands of trees. It's ready to apply to large data sets using Relay. Although major revision is imminent. I've been saying that for a while, but I really mean it this time. A while, but I really mean it's fine. And downside is that, so my segue to the next section is just that it's a down. The downside is that we throw away most of the trees. So right now we're using every hundredth of tree. We're throwing away 99% of the trees. So there's a lot of information that's being tossed away to get our independence from tree to tree. So what I'm really excited about is how to use all the data. How do we, instead of Use all the data? How do we, instead of dealing with the trees, how do we deal with the whole graph? How do we model spatial movement on the actual graph object rather than on the trees? And so because we're modeling Brownian motion, we know that this is going to be, the sample location is going to be normally distributed. We just don't know what the covariance of the sample locations will be. And heuristically, from the beginning, Ben and I were speaking about this, and we thought, well, let's just like. Speaking about this, we thought, well, let's just do the same thing as we were doing for the sample lineages, their shared times, but just do that for all unique paths in the art. And so, you know, for instance, one has two paths back to the root over on the left or through four on the right. And so you can think of those as two different paths, and you can calculate the shared times between all of these little paths, blue, orange, and pink, and you can create that in some matrix. Now, that would then means they multiply that by the dispersal rate. You know, multiply that by the dispersal rate that gives you the covariance of the endpoints of each path, and that would work for us. But I wasn't very comfortable with just kind of applying this heuristic, so I thought about how can we kind of principally go about modeling Brownian motion on this graph object. And thought about Brownian bridges. And you can use a Brownian bridge to describe the movement along a loop. You snap open the loop, and it starts and ends at the same point. And it starts and ends at the same point. There's results that tell you about the variance and covariance of points along that bridge. But how do you scale that up to a big nested mess of a full arg from a simulation field paper? Fortunately for me, Paneeth Diraje joined my lab. He's sitting in the back here at the community. And at one of the meetings where he was supposed to be asking me questions, I started asking Finnish questions, which is very helpful for me. Questions, which is very helpful for me. And said, How do we do this? How do we go from these bridges to Brownian motion on a full, complicated car? And I think maybe your first year, your PhD, by the next week you came to the meeting and already had made a lot of progress in the problem. And within a couple of months, not only had figured out in a principled way how to derive the covariance matrix for an arbitrary arc, but also proved that it was a clue. Also, proved that it was equivalent to the heuristic that we had thought of at the beginning, just with the slight tweak, we had the normalization back there wrong. But I was very impressed, very happy that Beneath had developed a method to get the full likelihood on the full arc from which we can estimate dispersal rates and monkey ancestors. I think it's also potentially a mathematical advance that's separate from. It's separate from what the problem that we're trying to do, which is following Brownie and motion on these scraps. So then we teamed up with James Kitchens and Graham Kruper at UC Davis, who are also interested in the same problem, to develop an algorithm that could calculate these covariance matrices from large args, thousands of paths in the arc. Do that in an efficient way that doesn't take hours, but instead fractions of a second. So Penice and James did some clever. And James did some clever work to make the computations fast, and then we could go without applying our method. So the first thing we do is estimate dispersal rate in the simulation. This is the true value. If we do the kind of approach I talked about last time with sparsely sample with independent trees, we get this composite likelihood estimate that asymptotes nicely. It puts a systematic underestimate. Ignore the green. Ignore the green. The black is what we estimate from our full R method. And we see this terrible behavior where the dispersal rate increases as you increase the number of genome that you're using to prefer the dispersal rate, the number of treats there, which we were horrified by. But so this is a very bad behavior. It's not a good estimator of disclosure, but we're happy that we figured out why. It's due to kind of excess constraint imposed. Constraint imposed by our model. So every time you add a tree, you're forcing two Brownian motions to meet at a recombination. Two Brownian motions meeting exactly, especially in two dimensions, is very unlikely to meant. And so this puts a lot of constraint on the internal node locations, which increases the dispersal rate. Okay, so it's a model misclassification problem that causes our dispersal rate to go too high. We have a couple ways to. Goes too high. We have a couple ways to demonstrate how to relax this constraint somewhat by not forcing the lineages to meet exactly the recombination mode, but or by just not dealing with the whole arc, just doing kind of a windowed approach where you take a bunch of trees, 10 trees or 100 trees, and you could do a count so likely to put it over mini arcs. So there's a few different things you could do there, but more excitingly, we could. But more excitingly, we can locate genetic ancestors. And because we're using more information, if we locate the ancestors using the R, this blue line, we see the variance in the ancestor location increases, but it's always less than the variance that we, or less than or equal to the variance that we get from locating ancestors from a single tree. So there's, because we're using more information, there's less uncertainty in our ancestors. There's less uncertainty in our ancestor location estimates. This excess constraint, unfortunately, comes back to haunt us again when we're locating ancestors. If we use the full R to locate ancestors from the simulation, we look at the mean bias. It's actually larger when we use the full R than when we use smaller and smaller windows down to a single tree. And actually, we get the less mean bias when mean error when we use. When mean error, when we use a single tree, than when we use the full arc. So, this is again because recombination events are unlikely. It's forcing all the nodes into the center to make the recombination events possible. And so the ancestor locations are biased inwards towards the mean sample locations. So there's some issues there. But we think that we can kind of solve that a little bit with the windowed approach. So through some balance between using There's some balance between using more information. So we want less uncertainty, we use more trees, but we also get a little bit more bias as we use more trees because of model misspecification. So we think that a windowed approach kind of lies somewhere in between there and how big your window is depends on the problem you're interested in. And so the final thing is just that we can visualize the exciting part of this approach is that we can, by using this windowed approach, we can visualize Approach: We can visualize recombination events in the space. We can locate recombination events and we can visualize admixed samples breaking up back in time. So, this sample here has ancestry from the blue population, the top left, and the orange population in the top right. And you can see the true for these two trees, for these two lineages, they split some point back in time. The blue came from the left, the orange from the right. When we infer, we have our 95% complementation. We have our 95% confidence intervals. That's these shadows, blue, and orange, and our most likely estimates in white that you might not be able to see. But we see this nice divergence, our estimates of where the ancestors were nicely followed these two lineages back, demonstrating split that happened 300 generations ago. If you did the same thing with the independent trees, you have wider confidence intervals, so you see less of the divergence. And you also get the divergence happening. Get the divergence happening immediately because we're treating the trees independently. So, the real power of our approach is that we properly model this entwined history of lineages back to the recombination, allows us to locate recombination events and visualize this split a little bit more accurately. Okay, so we have a pre-print of this just about a month ago, led by Beneath and James. We have a full like we did on the full error. Full likelihood on the full air explicit spatial model. There's excess constraint, but we think we can partially remedy this. The windowed approach, or maybe there's more theoretical advances we could take to reduce model misspecification. And the cool thing is we can visualize these genomes geographically diverging. A couple of downsides, requires a full arg, so can't use relator TS infer, which are very fast. You have to use ERG Reaver, which is a small sample. But this is, this should, I'm expecting this. This, this should. I'm expecting this to be related at some point. But the big thing that's preventing us from applying this to data at the moment is that we're not currently accounting for arg uncertainty. So we're taking the arg as the truth and we're not integrating over args or portal sampling over args, which is a harder thing to do than portal sampling over trees. The likelihoods are more difficult. So, in conclusion, we inferred spatial history from arts two ways, one from sparsely sampled trees. Ways one from sparsely sampled trees, one using the full R. Use lots of data, explicit model, no discretization, which is a bit ironic for those of you population tree. Try to avoid using the word population throughout this talk. And just to try to make a more general point, a bit of a specific topic, I think that arts are very exciting because they're bringing sequence data, strings of letters, our numbers. Of letters or numbers closer to theory, especially closer to coalescent theory, but also they're bringing changing these strings of letters into graphs, graph objects that are much closer to the modeling theory world. And so I think people are already utilizing this, but there's lots of applications within population biology for inferring demography, inferring selection, inferring dispersal, what have you. So I think this is an exciting direction. With that, I'd like to thank Kenneth. With that, I'd like to thank Kenneth James Graham, funding, and computational resources. Maybe another way of thinking about it is not that the recombination events are constraining the migration, but that the recombination events are in the wrong place and that the distance hasn't been incorporated into the R. That are inference. So I'm thinking about this with TSA, for example, when the work that we were doing with COVID and plate then developing the argon, when the arm is developed, it doesn't pay attention when it tries to attach some samples to the tree. They're where the geographical location is of those samples. But you could say, I don't know, there's a, you're more likely to attach it to a sample that is actually physically close. Is actually physically neurotically close or inferred close. So I'm wondering if that's another direction to go is to jointly do the inference of ours. Yeah, yeah. Talk to Jerome about that, but it's a yeah, at the moment for like the sparsely sample tree thing, what is used in for where we know we're inferring the trees under the ROM model, a panmic model of these like geographically spread out individuals. Spread out individuals. And then we try to just correct for that with important samples. How likely are these trees under the spatial model versus under the pandemic? I'll upwit the ones that we think are more likely under a spatial model. But perhaps, I don't know how easy, how difficult that is to do with args, or maybe you need to go to the whole thing, like you're saying. Maybe even simulating it at first to see that this is the true arg, and is the problem in the inference of the arg, where is the problem itself? Where's the problem with that itself? Yeah, we haven't done that. We haven't looked at like comparing spatial args to ARGWeaver's inference of the ARG from a spatial standard. Oh, these are the true ARCs. I'm using all the true ARGs in this curve. No, the problem is really model and specification paper. The two parents of the recombination know, even in the simulation, that would be in reality. Definitely in reality. They don't randomly have to meet exactly one another. There's some directional movement that's non-random that brings those lineages together and recompensation notes that we're going to have to go to the spatial handler or whatever it is to properly model something like that, perhaps. Questions? Yeah, so I'm not sure if I'm understanding this. Sure, if I'm understanding this, so there's a forward time process, which is a common ancestor and branches and combines and stuff. And then there's the backward time process, you're trying to infer that. And it's, I mean, it's kind of rounded motion in the backward sense, but it's conditioned in some way, right? It is. So it's not exactly that thing that's, where I haven't worked it out, but like it might not be exactly the thing with the party equipment. not be exactly the thing of the party brownie motion backwards time yeah so so this is you know this is one of the this is so we're using the brownian like for the trees for instance brownian motion model which is kind of forward in time movement uh and this is you know there's there's problems with that model it's not the right model it's not properly accounted for the non-independence between the branches when you get from local density dependence etc so people have tried to develop like So, people have tried to develop like spatial land of Fleming VoIP model that's like, you have a proper forwards and time process and a backwards and time process that accurately captures this time of dependence. So if you want to have that like forward-backwards model, you need to get a lot more complicated. And we're trying to stay simple with like tractable likelihoods here. But another approach would be to try to get more complex, be more computational. More competition. Yeah, so it's curious. Can you? I mean, thought about adapting this model to look at the racial heterogeneity, either modeling it or looking at where your languages move to shape or something about. Yeah, I think there's some of that can just be done in the interpretation, perhaps, how you see ancestors moving. But you could also try to explicitly make the model more complicated and try to figure out if they're. And try to figure out if there are barriers to dispersal or something. I think the Union Bradburt's group is kind of working on that. And I don't know if their preprint has that in it, but you can kind of try to infer the rates of movement through each grid on a map and based on how the ancestors are flowing. It kind of explicitly say, like, what's the dispersal ability of this grid on a map? So I think you can start going there with like. Can you start going there with more intensive numerical kind of approaches? Your hand is up first. Just if I was thinking about experimental evolution and how to fly to that. So is there a problem with too many dead in branches, or is there it just doesn't make any sense because you're anyways have the full information, but like just as a way of a presentation, I think it would. Of way of representation, I think it would be powerful to actually have something like that. I haven't thought of experimental evolution because I have, I don't know, yeah, a good spatial system, perhaps. But I guess for these kind of bacterial expansion experiments, you know, people have, I mean, there you have a single tree, right? Because of asexuality. So people have applied, like, what do the trees, what do the trees? What do the trees look like for like expanding fronts of these bacteria and stuff? So I think then you get more into the back into the ground tree fronts, which is not where our focus has been, but it is an active area of research. But I don't know about, yeah, maybe recombining facial experiment would be neat to think about. But I don't know of the example I did. Maybe you're in the conference. I was just, you know, we could go in for another minute or two and then what's so bad about discretizing space? Oh, okay. I was just a little bit of trying to motivate my approach, which I'm happy that we don't have to decide who's in which group from the outset. We're modeling things in continuous space. Each individual is in its location. We don't have to make any choices. Have to make any choices about splitting groups up. So I get like why not do like big groups, but like, you know, you did like, I'm doing that as a little lattice, right? With really fine grid points, but I didn't really care about this. Yeah. Yeah, I mean, yeah, that's true. You could go that way. I don't, I think that seems nice still not having to do that. Still not heavy. Did you see? Did you get rainballs pain and force things that are causing problems? Yeah, I'm not. Yeah, I guess I'm not sure. I don't know those lattice models that well and how straightforward it is to calculate it. Then you have no issues forward backward, exact model, no problems. And ancestor locations. Yeah, you just say it's diffusing, it's a discrete diffusion, right, on the lattice. I'd be curious. Yeah, I should look into. I was talking when I was talking about the problems talking about the larger groups, but yeah, the kind of bias style maybe. Great. Let's make that. So I don't really know what's going on with the fresh meeting. We have We have judgments.