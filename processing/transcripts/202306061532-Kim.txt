From Wandu Institute of Science and Technology, and he's going to speak about comments of clinical complexity in theory. Okay, thank you very much for the introduction. I would like to thank organizers for inviting me this wonderful place. I really enjoyed everything in here. Thanks. So the first question I had from you. I had from you was where is Kwangju? So I want to ask that in a very clear way. This is the Korean peninsula and there's a soul here. It's in North Korea and Gwangju is in the southern part of the Korean peninsula. So I'm here and this is the Gwangju Institute of Science and Technology Channels. Parker Market is definitely a safer place than solar. Okay, so my talk is based on this paper with three collaborators: the Hugo from Mexico, Victor from Brazil, and Michiro from Japan. But they are all in Korea. So they are collaborating. And actually, there are a very similar topic, similar work to my work here. One of the authors is Anato. One of the authors is anatomy in the audience. And they are very similar topics. And actually, this idea of the colour of complexity is based on this paper, Universal Operator Growth Hypothesis. And you can see it has around 200 citations already. So that means it's a very popular topic now. And actually, I didn't pay attention too much about the current of complexity. I didn't mention too much about the Krillov complexity before I heard a talk by Anatoly less in Korea. In Korea, there was a workshop about all the holography. And then I heard the talk by Anatoly and I got interested in this topic and started studying. So I'm kind of a beginner of this topic. But anyway, I want to share some of my observations about this Philo complex in quantum field view. So, when I came here, I just found I'm kind of on the right track because when I just look at the list of the speakers and talk, among 28 talks, 13 talks are about complexity and creative complexity. So, it's very happy also in this workshop. So, and we already have three talks by Nick and Kashubo and Javier. Javier. So I'm going to build on my talk based on those talks. So, first about the quantum complexity. It's reviewed by Nick very well. Let me just go over very quickly, just to set up stage of my talk. So it's about the quantum computer. So that's why we call it the computational complexity. For just a theoretical physicist, just an input and just the output, and there's something here. out and there's something here. And so we want to quantify how hard, how difficult of carrying out some task. So it can be represented by some quantum circuit and we have to choose some universal basic block, the gate set. For example, if I choose this one, then suppose this circuit can be realized by these three ways, then we just count the number, then complex. Just a count to the number, then complexity is three because it's the minimum number. But there's ambiguity here, that's about how we choose the universal case. It's okay for the computer scientists because they will build it, but it's not okay for us because we cannot build it. It should be given by nature. And in a more abstract way, complexity is kind of a distance, distance between two states. So there are many concepts of distance. For example, Sets of distance, for example, the inner product can be one of the distance. And in this case, for example, in these two states, if I use the inner product, this is very far each other. It's also one of them. But if I use a different concept, for example, how to make this from this, then I just need to put it just one qubit. It's very easy, very close each other. So this is kind of a new distance related to the complex complexity distance. Complexity distance. And we can think about two kinds of complexity, but essentially they may be the equivalent. But so if I say complexity of quantum state, then we need a reference state and target state. And we want to quantify how hard to transfer from one to the other. And we can think about operator complexity. And we can ask how hard to build up some unitories from some units. Some unitaries from some minimum number of k. And in the context of cry-up complexity, this is called the spread complexity and this is called cry-up complexity. This is just the name. And of course, there are relations between these two. I think they are basically equivalent. And Javier also explained already the relation between these two this model. So about the quantum chaos, so everybody will agree the So, everybody will agree the quantum chaos is not well defined. So, I just asked Churchi Etij. So, what is quantum chaos? And you don't need to pay attention to these sentences because this is just a meaningless sentence for us. But anyway, I want to emphasize: it's very interesting. The 3GPT is saying all important ingredients of the quantum chaos F9. So, for example, So, for example, the these guys chat if it is talking about the OTOC in some sense. So, we know about that. And of course, the level spacing statist is very important. And Chat TPT is also talking about that. And normalization ETH is not written explicitly, but somehow it's hidden in the sentences. So, everything we know, JTPT also knows. But now, Krillov completed is not reflected yet, but probably it's a, I mean. Next year, maybe it may be referred here. Just for fun, one more thing. This is the picture I draw for quantum chaos and complexity. Of course, not myself. I use the AI, which is called the metering. I just gave a keyword, quantum chaos and complexity. And the machine learning gave me this nice abstract feature. Feature. Okay, let's come back to the main topic. So, grid of complexity, before going there, the complexity is basically how many things are complex. And it's not necessarily related to the chaos, but if we talk about the chaos, then there is a relation, intuitively, how fast things get complex. So, that's the diagonals of the chaos. Chaos. And the computational complexity or soft complexity is not well defined because of the ambiguity of the universal chaotic set. But the main strong point, one of the main strong points of the queue of complexity is well defined. Even though the point of chaos is not still well defined, but this guy is well defined. And why field theory? So complexity itself is very important for any. The LFT itself is very important for any quantum system, but it's especially, I think, very interesting in field theory in the context of ADSC electric correspondence, in the Holocaust principle. It has something to do with geometry inside the black hole. So in that context, I think it's very important to understand complexity in theory. And in the context of creative complexity, in this paper that we And this paper dealt with this topic for the first time to my knowledge. Okay, so this is the contents of my talk. Okay, so this gentleman is Krylov, so Russian scientist, and this gentleman is the Lamjos, the Hungarian-American or Hungarian-Irish scientist. And both are the people Are the people in the 20th century? And their work, based on the also Krillov Space or Langev algorithm, is collected in this book. And this book is published also in the 20th century. So it's already published in the 20th century. But now, somehow, we rediscovered the usefulness of this method in 21st century physics. So we are now using that. So basically, the methodology is already. So basically, the methodology is already done. So, I'm going to give a short review on grid of complexity and introduce how it's successful in lattice system. And next, I'm going to talk about the view. So, again, the complexity is explained by Kushubu and Javier very well. And probably it's more focused on the spread complexity, but I'm going to talk about. Complexity, but I'm going to talk about more about the operator complexity. So it has something to do with the operator growth. This is a very well-known Heisenberg equation, and we know the exact solution, and they are all equivalent. And for example, you can think about this thin-chain model and with this Hamiltonian. And we can start with one operator, for example. Start with one operator, for example, z1. And as time goes on, this z1 gets complicated in this way. This is t squared t cubed, right here. So that means the commutator of these nested commutators gets complicated. So this is the concept of operator growth. So we know these phenomena, and we want to quantify how the spread of How the spread of this operator. So, first of all, we can think about the basis set composed of these operators. And these operators define the Couloff space, but as stressed many times already, they are not orthonormal bases. So, by using some orthonormality, Orthonormality concept, we want to construct the Krylox basis. But however, in this case, there is no concept of inner product yet. So we want to introduce the Weitman inner product at the thermal system. So by using this inner product, we can construct a credo basis. It's basically a Grem Schmidt procedure. Then we can reformulate this equation in a slightly different way, but of course equivalent. Different way, but of course, equivalent way. So now we have a kind of basis, the orthonormal basis. So that means we can expand this time-evolved operator in terms of this Krielov basis. And this guy plays a role of the probability amplitude. So this is again a schematic structure. So we have we started with this operator equation and Operator equation, and this is equivalent. And by constructing two local basis, we can have a physical or mathematical interpretation of this phi n. This is probably amplitude. And this can be again re-formulated in this way. This is nothing but a quantum mechanical particle on a one-dimensional chain. And DN has our physical meaning of a hoping amplitude. And so, in a more technical level, In a more technical level, what we are doing is, so we want to compute the Bn, which is called Lambda's coefficient, and phi n's, which is probable at amplitude. And this is the equation I just explained here. And how things are going. So first we know all these, b0, b1, b2, bn, and we know also phi 0. If we know phi 0, then we know phi 1. If we know phi 1, then we know. If we know phi 1, then we know phi 2. In this recursive way, we can construct all phi n's from all b n's. And if we know all phi n, then we can define the quill of complexity in this way. The meaning of this quantity is very clear. So, this is just average position, expectation value over the chain. And in this example, we can see what happens. We can see what happens. So, this is T is now time evolution. And as only time, this is five. Only time, this is the amplitude. Of course, everything is discrete, but just continued for the visual purpose. And as time goes on, it just spreads, spread, spread, spread. And every position will increase as time goes on. In that way, we can quantify. In that way, we can quantify how fast operator spreads. Yes? So, why did you choose a particular inner product in the previous slide? Oh, that's a good question. Yeah. So, actually, there is a hidden ambiguity here. So, actually, there's another way of choosing the inner product. But Javier and his collaborators showed this is actually minimized the complexity. So, this is really nice. So, this is a really nice choice. Okay, so this is very vivid visualizing what happens. The operator is now localized at t equals 0 and here, and as time goes on, it just spreads and spread. And if it spreads fast, there's a chaotic system. It spreads slowly, it's not chaotic system. Okay, so let me go to a little bit formal things. So So, of course, we can compute everything in this way, but there should be some way to write a book for that, because that was just one page. So, in this book, there are many, many examples and theoretical theories showing some equivalent way of computing the Lambda's coefficient and amplitude. That is this. So, if we know the autocorrelation function is nothing but the two-point function, then point function, then the point is we can compute everything from this autocorrelated function. Okay, so with this, this is just a Fourier transformation of the autocorrelated function. That's a power spectrum. And from here we can define moment. And this is the Fourier transformation of a moment. So what I want to say is knowing moment is equivalent to knowing all Langdish coefficients. Knowing all Language coefficients. So that means by this relation. Okay, this is again very complicated, but it's already proven mathematical. So let's just trust the mathematical literature. So if you know all moments, you know all Lambda's collisions. Then in order to know moments, what you need to know is just the autocorrelation function because it's nothing but just uh several integrals. Once you know uh uh the power spectrum, we just integrate several times, you know all moments. Integrate several times, you know all moment. So then this gives a very good feeling because the two-point function is very familiar object to all of us. And if we know that, then we can compute everything. Given a quantum system, is the Krielov Krylov basis unique? Oh, sorry. Given a quantum system, is the Krylov basis unique? I think it depends on the operator, initial operator. Yes, yes. Yes, yes. So once you choose the initial operator, yeah, then everything is fixed. Okay, so let me again show you the schematic structure. So if you know the power spectrum, you just do the integral several times, you know all language scripts, and this guy is the initial starting point of the template. That's what I'm using in the real computation. Okay, so now. Okay, so now, so what's good thing for the lattice system? Actually, there is again mathematical literature proving this relation. So this is the power spectrum, and this is the large omega tail. And there is a relation between large omega tail and the large n scaling of this Lange coefficient. Very nice relation. And then the claim is if delta is 1. If delta is 1, then that corresponds to KO existence. That's the claim claimed by the Parker in this paper. And the example is SYK model. So if this is true, then there's a very nice relation here. Once you know the power spectrum, and if you find it behaves like this, then that's automatically chaotic and automatically the Langevin increase linearly. To increase linearly, and Krielov complexity is exponentially increased. These are mathematical relations. Very simple, but too simple to identify K-Op. But anyway, that's the claim in this paper. Okay, so for the later use, let me say one thing here. So, the power spectrum, of course, is a Fourier transform of the autocorrelation. The autocorrelation. So there is a relation uh of about the analytic structure. And the tail, the property of a tail, is encoded as a hole in its immediate axis. Okay, so they are just equivalent. Okay, so then towards field theory. So we can do the same game. So there's now Lagrange. And if you just open the thermal field theory book, then everything is already computed. We just borrow the formula. Power of the formula, and this is the power spectrum for this guy. So we have this formula. And as a starting point, let's think about the Maslis case. That's easier. There is no step function here. So then this guy becomes this, four-dimensional Massless case. And this is a power spectrum. And the asymptotic behavior of a power spectrum looks like this. This looks very familiar for now. This is a beta of two. Now, Now, we can just automatically do that once we know this. Then, by integrating, we can compute the moment. Then, by computing this, we can compute everything. Then there is a problem here. So, as already known, so this Bn, the Langevin's coefficient will increase linearly in this free theory. Something's wrong. So, the original claim is if Language The original claim is: if Lambda's coefficient is increasing linearly, then it should be a chaotic system. But now we are dealing with just a free massless scalar theory. So that means free theory is chaotic. So of course it's not. And one of the resolution is given by Dimarski and Smolki in this paper. And actually, the analytic structure is related. So in this white-time two-point function, Whiteman two-point function, so we will put x equals zero. That means at t equals i beta over two, then there is a full structure. And that pull structure should be reflected in this way. So this is kind of automated by definition in field theory. So then, in a way, the general quantum field theory always will show this behavior. So that means this claim is not, I mean, Not, I mean, can be supported by field theory. So it seems it's too good to be true. So actually, this looks very nice, but in the field theory, it may not work. And also, there's some counterexample, which is the if there is a saddle point in the in the fader space, then because of the saddle point, this may not hold. I mean, the even integrable system can show this. The even integrable system can show this. So there's a little caveat here, big caveat for the field theory. But in the hidden assumption, here is, I said it's a mathematical relation, but the hidden assumption is that Bn should be smoother function of n. Then everything is equivalent. But if Bn is not a smoother function of n, so we don't know what happens here. So for example, everything Everything is related. So, for example, if there is a okay, so the whole point is very strangely and interestingly, quantum chaotic property is already hidden in this two-point function property. This is a spectrum function. Very simple object. So, when you say about OTOC, we said, okay, OTOC is a four-point function. Because it's a chaotic property, it should be something different. So, reasonable. But somehow, it's a two-point function, it knows everything. Function knows everything. And if this scenario works, that means there is something here, but we need some tools to extract some useful information for chaos from this two-point function. And that's the kind of a quilog basis, and quilog Langevin's algorithm. And if we change the property of this two-point function, that something will change. So first thing we can try. First thing we can try is: let's think about the massive case. If there is a mass, then there is a mass gap. This is the kind of IR cutoff. So if we do the same calculation, then this is the Langevin's coefficient. And now there's something different. So there are two lines. So in a way, so this is, for example, n equals, if n equals odd, then this line, n equals even, then this the blue line. Even then, the blue line is the Language Cooper. That means if you go sequentially, then you go up and down, up and down, up and down. This is called the staggering effect. And this is the effect of the mass to the Langevin's coefficient. So we can consider this behavior, not just one smooth behavior and different two-weights. And this alpha, the slope and intercept gamma, will be a function of n. So, this mass gap structure is reflected on the Langevin's coefficient in this way. And this is a numerical computation: how this slope changes as we change mass, and how this gap between the even and odd language coefficient changes as mass changes. And again, by the same computation, we can compute the QL. Computation, we can compute the Coulop complexity. And now there is an oscillation, and it's due to the original starting point, two-point function has this oscillating behavior. And the important point is now here, by changing mass, now it seems the speed, increasing speed is changing. This is low-variability plot, and this is the original exponential behavior, but it seems it's slower. But it seems it's slower if we increase uh mass n. So we can also change the dimension, but the qualitatively the same property occurs. And this is the summary page of the mass effect for the Langevin's coefficient and Kurilov Kurilov complexity. And basically, again, Complexity basically, again, increases exponentially, but this Lyapunov kind of exponent is not Lyapunov, but this exponent is now a function of mass. If a mass decrease, then this lambda decrease. So then, this is just, I mean, fitting formula for these old curves. And here, there is an information of the Langevin position. So, then, actually, there is some relation between these. There is some relation between this and this. Everything is interrelated, but not in this simple way. Okay, good. Right. So the mass gives a staggering to the lambda description and it also has an impact on the exponent. So that's about the II cutoff. And you can also think about the UV cutoff. You can just, if you introduce some kind of If you introduce some kind of, this is an artificial function to understand the behavior, mathematical behavior. By giving some cutoff, this UV behavior can mimic some known result here. So for example, chaotic behavior, then integrable behavior, and free theory can be simulated by introducing this UV cutout. This UV cutoff. One extreme case is just a hard cutoff. If we just make a hard cut, then what happens is it increases linearly, Langdon's coefficient increases linearly, and becomes flat. And in terms of the Prylop complexity, it increases exponentially and increases linearly here. So that means we are dealing with a free theory. But somehow the property of the free theory can be seen in this area after only after introducing After introducing the hard cutoff. So that means somehow the R free theory is now can be considered as the lattice system with the cutoff, but with a large ending. Good. So before finishing, this is just an experiment. So this is not a physical system, but we just want to understand which part of the F, the power spectrum will impact which part of Will impact which part of the Langdon's coefficient. So, for example, if you have this final function, then you have this cutoff, but everything is smooth. Then everything is smooth, and then Lange coefficient, there is no staggering, and this effect is because of this cutoff. Without this cutoff, it will increase forever. And this is another one. So, this blue one, let's explain the red one first. So, red one. Explain the red one because the red one actually there's a mascape here. So then we will see the staggering, clear stagline. And that means actually the in terms of the autocorrelation function, the area of the autocorrelation function is zero. And then because this blue one, there is a cos here, and this cos effect also gives us the staggering effect. And here, this is another extreme case. We just, you know. Another extreme case, we just, in order to pin down what makes us staggering, we made this function. So everything looks okay, but at omega equals zero, we just put f the power spectrum is zero. And that gives us stagger. And without cutoff, it goes forever. Something like that. So let me summarize. So this is the method methodology of this summary. So if you know the two-point function, you can compute everything. The two-point function, you can compute everything, and this gives you the complexity and lambda's coefficient. And it works very well for the lattice system. It looks very nice, too simple. But in the field theory, there is some problem. So, in order to understand field theory better, we need to understand which part of the power spectrum affects which part of the Lambda coefficient. And so, actually, there are many works we can do. For example, There are many works we can do. For example, we can introduce the compact space or interaction or other spins and open systems. And as I already announced, it's very interesting to ask about the holographic counterpart of this concept and about spread complexity. And we now have many observations and conjectures, but we need to justify those more rigorously. Okay, thank you very much. We have time for a couple of questions. Last one. Is the relation between the V coefficients and the voice spectrum only valid for the field theory? Or is it also valid when it presents the theory? Yeah, it's it's such it's it's uh I mean valid for general general field theory. Yeah. It it just comes from the the auto the form of the autocorrelation function. The form of the autopilot say if I'm dealing with a free theory or interacting theory. M is the renormalized mass. Sorry? M is the renormalized mass? No, here is such a pair mass. Now here is a pair mass in the interacting theory. Yes, yes, then we have to think about the renormalized renormalization. Have to think about the renormalization. So, but you can have doing a scale. Yeah, yeah. Oh, B coefficient? There's another B trees. Yeah, B is the L this is B coefficient for the free theory only. Ah, so you are asking what the B coefficient? Yeah, the B coefficient. Oh. The relation between B coefficient and requirement. So is it it seems to me that's only about the people for this theory? Um This period. He's asking about the relation between the moment, which is the power spectrum and the equal efficiency, you mean here? Yes, I think. Yeah, yeah, for instance, yes. Is that true for interacting queries as well? Yeah, it's just valid for just math. Just valid for just methodology. It does not care about anything, specific theory.