Now I mess it up. Sri Cats and he's talking about his project, PhD project, right? Yep. Awesome. Alright, so first of all, I want to thank the organizers for inviting me and for also giving me the option to speak. So today I'll be talking about some tool we've been developing over the last year or so, which is essentially a combination of two techniques used in open quantum systems. We just put them together in one. Put them together in one, and it gives us what I'm calling this effective Hamiltonian framework. And I'm then going to be using that to study thermalization at strong couple. So, okay. I'll start off by asking a question. So, what happens if you take some macroscopic system, you put it in contact with some larger thermal environment? So, if you remember from undergrad stat mech, what's pretty much going to happen eventually, the system will equivalent to a Gibbs state with respect. To a Gibbs state with respect to the system Hamiltonian. And so, very importantly, this is neglecting the impact of system-environment interaction, anyways. And so, in particular, if you go down to foreign scales, now this becomes important. So, now I'll ask a related question. What happens now if you plug a nanoscale system paint contact to a large film environment? Is the state that you'll get in the long term? Is the state that you'll get in a long time? Is it still the Gibb state? And so, in general, the answer to that question is no. So, now by taking into account the interaction energies, you'll get some deviations from the give state. And so, in this talk, I'm going to introduce a way that you can show that and interpret the results that you get from it. So, here's just this picture I took from one of Marco's papers that's just showing that the That's just showing the, I guess, the progress of this kind of problem. So, on the far left, you have the ultra-weak coupling regime, which is basically just statin act, there's no coupling, and in which case, the state of the system is just the given state with respect to the system homophon. And then, in this reference here, the Cresser and Andrews from a couple years ago, they showed that they were able to calculate up to second order in the coupling parameter lambda corrections to the gig state, and then they also. And then they also showed the opposite limit, the ultra-strong coupling limit, that the system is in a Gibbs state, but now with respect to a slightly different Hamiltonian. So what I'm going to be doing today is try to discuss this intermediate regime. And to do that, I'll be talking about this effective Hamiltonian framework. So, whoops. Okay, so here's the outline for my talk. I'll start off by just trying to motivate why. I'll start off by just trying to motivate why strong coupling needs to be studied in open quantum systems. Then I'll introduce one tool that will be useful for me in this talk, namely quantum mastiff waves. Then I'll introduce the general recipe that we use to generate diseffective Hamiltonians. And then we'll talk about an application of thermalization and maybe if there's enough time to quantum absorption refrigerators in thermal machines. And lastly, concluding, I just want to mention that. And I just want to mention that the archive number for pretty much all of us is here if you're interested. So, beyond, naturally, you want to study strong coupling because it arises naturally in nature. So, you could have, for instance, some two-level atom interacting with the mode of the electromagnetic field, or you could have some molecular junction coupled to like two gold leads. And so, in any of these processes, there's no guarantee that this coupling is going to be weak. So you one develops strong coupling formalisms that are able to tackle that. Formalisms that are able to tackle that. And so beyond that, strong coupling physics is a lot more rich. And so you can have non-linear transport phenomena or correlation that can develop between the bath and the system. And also there's kind of like non-additive properties or cooperative effects between the baths that could pop up. There's also the question of setting strong coupling for use in applications. So whether talking about quantum technologies or quantum thermal machines, there's this question. There's this question called dynamics of whether or not strong coupling could be advantageous or not towards such applications. And then other reasons are just to develop methodologies. So a lot of ways that you can tackle strong coupling are numerical. And so ways that are analytic, there's not a lot that you can use generically that will be analytical. And so that's kind of what I want to do here and introduce a way that's still not completely general, but it does a lot better. General, but it does a lot better, and the range of applicability is definitely a lot more than what is currently available. And so here we're always going to be describing a Hamiltonian in the standard system bath form, system Hamiltonian, the Bath Hamiltonian, and then this kind of bilinear interaction part where lambda characterizes the interaction. And so, making the board mark of approximations, we can describe a master equation of the form below, where you have this. Where you have this first term, which is just unitary dynamics. The term on the left, the second term on the right, is the dissipator. That's where any kind of non-unitary dynamics happens. But crucially, this is only valid to second order in system mass coupling parameter. And so then if you'd want to study any kind of strong coupling physics, you would need to develop new tools or go to higher orders. But in general, these master equations are only valid for weak coupling. weak coupling. But the structure of mass equations are nice, and one reason for that name is that the Gibbs state is like a, it's a equilibrium state of such equations. And also they have very nice form and easy to use and you can get analytical insight readily from them. So what we're doing when we generate this effective Hamiltonian framework is in principle, we're able to maintain the form of a red field equation, Lindblad equation, master equation of any kind. That equation, faster equation of any kind. And the only thing that's changing now is that now our system Hamiltonian will be dressed by the coupling parameter. And that's what allows you to kind of go beyond the second order mass equation that it had in the last slide. And now your dissipator is perturbative, but in some new parameter, so, in which case, now we're actually able to capture strong coupling effects. And so I want to highlight one thing: that in this, we're not. Highlight one thing: that in this, we're not necessarily going after perfect numerical accuracy, numerical exactness. We're more so trying to find analytical tools that allow you to gain insight into what strong coupling can provide and what it does. So, your effective system, Hamiltonian, is still the region, right? Yes. And so, I believe the next slide I'll be introducing what we do for that mapping. So, this is just Mapping. So, this is just in pictures. So, essentially, this is a recipe where you start off with some system Hamiltonian, doesn't matter what it is, coupled perhaps strongly to some bosonic reservoir V. And I mentioned before, it's a combination of two tools. So the first, you do some exact mapping, something called a reaction coordinate mapping, where the gist is to kind of redefine the system-bath boundary to comprise now, the original system of interest, as well as one of the bath modes that we're. As well as one of the bath modes that we're calling the RC to create now an enlarged system. And so now, in turn, you've changed your connectivity, where now the system couples strongly to this reaction coordinate, which in turn couples, assumingly weakly, to now this residual bath B prime. And so then the next step in this recipe is to apply a Polaroid transformation. So Polaroid transformations are used a lot in open class systems as well, but not quite in the way we're doing it here. Quite in the way we're doing it here. So normally it's used just to kind of go to some other frame or other basis. It allows us to do a perturbation theory with some other parameter. But here we're applying the Polaron transformation between the system and the reaction core. And so this makes it a lot more general because in principle, instead of extracting the reaction core, it's not dependent on the kind of models you're studying, whereas you're usually using the reaction as a coronavirus transformation if you study more. If you study more general class of systems, you kind of run into trouble. Whereas this step is quite general. And so now, it's not quite clear april what this is going to do. It mostly just makes a mess of the system. In that, where you originally just had this nice connectedness of the system coupled to the reaction coordinate coupled to the bath, now everything couples to everything. In the sense that you get now your system. You get now your system Hamiltonian, which gets dressed by the coupling parameter. So that's where you can maintain information of the coupling. And now it has some kind of U interaction with the bath, the residual bath now, U prime. And then you're also changing the reaction coordinate, and that is getting shifted. But at the same time, you're also weakening this coupling here as well. So you can't necessarily use this for much. You can't necessarily use this for much, but you can make one approximation, which is where you assume that the frequency of the extracted bath mode is the largest energy scale in the problem. And so by doing this, you can essentially truncate this to its ground state, thereby eliminating any kind of connectivity here. And so you've effectively gone back to the same situation you started with. Some system Hamiltonian, now if I'm calling it an effective system, because now I don't know the pan. Effective system because now it'll depend on the system bath coupling strength. And now it couples weakly to the residual bath. So I'm going to show it next, pretty much the same picture with a bit more math underlining it, just to emphasize the steps that we take in transforming Hamiltonian. So the key parameters I think here would be the system Hamiltonian to look at, how this changes, and to look at S, how you couple the bat. So, first, you're just, this is a reaction coordinate. Again, it's changing the connectivity of the model. Then, you're introducing your Poland transformation, which you can essentially just think of as a displacement operator. So it'll displace these reaction coordinate modes. And then once you reach this Hamiltonian, this is where you do your truncation. So you work in a subspace where the reaction coordinate occupies only the ground state, which brings it down to Hamiltonian. Which brings it down to Hamiltonian D. Where now the system Hamiltonian is transformed as so, where inside here does a coupling string dependency, and then you have to compute this partial metrics on it. And then the other thing to notice is the coupling to the bath, it's the same as we started with. Except now you have this additional dressing of the coupling strength and the frequency of the reaction coordinate weakening. The interaction. So. Sorry, can you repeat once again step B? Yes. So B is a reaction coordinate mapping. So it's one of these collective coordinate kind of mappings where essentially you extract one mode from the reservoir, include it into the system, and now you kind of relabel what you call the system to comprise of the system you're originally trying to study as well as the extracted bath mode. Extracted that mode. So essentially now your enlarged system, your system, I guess, would constitute these two terms. Yeah. Can I also? So going from C to D, that's an approximation? That's an approximation, actually. Yeah, so can you explain? Yeah, it's a good point. I'll clarify for you. From A to B and B to C, that's exact. And C to D is an approximation where you truncate this extractive math mode to only its ground state. To only its ground state. And it relies essentially on the parameter here, omega, the frequency of the reaction coordinate being the largest energy scale in the problem. That's the approximation you have to make. Is that necessary? Can you keep few modes? I mean, in practice, you can keep fewer modes, but then you're not going to get the nice structure of maintaining the form of the Hamiltonian exactly, and it'll just get really messy. It'll just get really messy. It's something we're looking at at the moment. How you can do that? There is a way to do it, but it's not as fun to work with. Can you quantify the error you make? I mean... I guess you could, yeah. Because we're able to kind of go beyond and include what is higher levels of producer. I guess you could then quantify the error the regression somewhere. And so do you think it would be helpful to, let's say, iterate the reaction coordinate more than once, so as we know? More than one, so to speak, not because you can. Yeah, that's a good point. That's something that it's discussed in one of the sections in the paper. You can do it, but in practice, I didn't mention anything about the spectrum-density function, but that it complicates things a bit. But in principle, you can do this again and again. So once you get back to D, you can again extract the mode from B prime polaron transformation again. You could do it iteratively if you chose. Um do you hear do you hear me? Uh oh, okay. Yes. I have a I have a concept that the reaction coordinate is assumed to be in the vacuum state. So get zero is a vacuum state of the coordinate, reaction coordinate, after the Polaroid transformation. Yes. So it's not exciting, it's it works. So it's not excise, it's in working yourself. Yes, exactly. Okay, thank you. So it's a good point. In practice, what we do, we compare it to the reaction coordinate, which we get from here, because this is a robust enough tool. And so I can kind of view this whole procedure as just essentially giving. As just essentially giving more insights to what the numerical results of the reactor quote would give you. So, first of all, you could use a master equation and simulate this Hamiltonian. And so you can then check if what you're doing makes sense by comparing what you get from here to these ones. Like a a lower copy. Sorry? But and that would that comparison would be ton could be done at a lower copy. Sorry, what's the last part? It could be done like a a smaller copy because Oh, you're right. Again, I get your point. Yeah. So essentially, once you do this reaction coordinate, the coupling to the residual bath is assumed weak. So you're able to do the master equation now on this and log system. Right now, the strong coupling for the Rix is kind of embedded here. Yes, good point. Okay, I was trying to say. Okay, I was trying to say now. So essentially, all the strong coupling physics, or yeah, most of it, is embedded now into the effective system Hamiltonian that you can obtain by computing this for any given S and H S you have in your problem. And so I mentioned it before, but I'll say it again, this relies on the frequency of the reaction coordinate being the largest energy scale of the problem, such that you can well approximate it the reaction coordinate as being in its ground state. Coordinate is being in its ground state. And I'm going to mention it just because of the theme of this workshop. The reactor coordinate mapping alone is able to capture non-Markovian effects, but by doing this scheme, you're actually killing all non-Markovian effects that might emerge because you're not considering excited levels of the reaction card yet. So no more non-Markovian, I guess. So now we can actually go back to the original problem I posed. Go back to the original problem I posed, that of quantum thermalization at strong coupling. So, to do that, we're going to be studying the generalized spin boson model, where, for instance, a two-level system coupled to a bath of boson is going to be like a two-level atom coupled to the electromagnetic field, or maybe a spin impurity coupled to the phonon, the rest of the lattice. And we use generalized here because the coupling strength has some additional parameter here, theta, which kind of allows you to tune between Of a tune between a sigma z kind of coupling, which would be like more of a dephasing kind of model, where only dephasing dynamics is possible, or this like sigma X kind of coupling, which is more of a standard spin boson type model to observe and transport. And so training through the equation on this expression, if you just compute this for this model, you end up getting the effective Hamiltonian that's here. And so it's a lot more complicated than when you started with, as you can see. It's a lot more complicated than when you started with, as you can see. And so now there's the role of coupling strength kind of embedded in the system. And so there are two important remarks of what is happening here, due to strong coupling. One is a suppression of a spin, or a spin splitting rather. So you can understand this now as one of the roles of strong coupling in this model is to renormalize the parameters. And the parameters being renormalized is delta, the spitting. Is delta the spin splitting. And there's also something else that spong coupling is doing here, the second term. It's adding kind of like a new process, this new tunneling, this new tunneling term that's caused exclusively by the coupling. And so now, since we're saying that this effective system, it couples weakly to its bath, you can say now that the system should thermalize to a give state, but now not with respect to the system Hamiltonian, but with respect to. Not with respect to the system Hamiltonian, but with respect to this affected system Hamilton. Sorry, what's the category omega there now? In the exponent you have over omega squared, right? Oh yeah, the frequency of the reaction coordinate coming in. I know, but does it have an expression in terms of the parameters of your Hamiltonian and the interaction stuff? So these are the important parameters of study. The important parameters are the coupling strength, lambda, and The coupling strength lambda and over the frequency of the back and coordinate omega. That's usually the good. Yeah, I guess I just don't know how you calculate omega. It's the frequency. Yeah, once you extract the reaction coordinate from the reservoir, that's the frequency that it had. Yeah. So when you call strong coupling, would you have that structure? No, strong coupling would be allowed and much larger than, let's say, like the characteristic, like the eigenvalue. Characteristic, like the eigenvalue to the system Hamiltonian. Yes. So if you send lambda to zero, maybe you don't get back to HS. Sorry? If you send lambda to zero in this expression, you don't get back to HS. It should. Also, we made a mistake. Setting alignment to zero here kills this term. Setting alignment to zero here kills this part. Ah, I saw it. Good. Good. My math is there today, I guess. So what I'm plotting here, this figure, are the elements of the screen-state density matrix. So what is in pink? That's just the Gibbs state, so there's no dependence on the coupling. What is in gray? Gray. That's the ultra-strong, the Gibbs, the equivalent state, any ultra-strong coupling limit. Then the blue, these two blues and the two reds, they're what you get from the reaction coordinate method and from this effective Hamiltonian framework spectrum. So importantly, you get exact agreements in this kind of weak and perturbative limit. You get slight deviations in the intermediate regime, but it's still. But it's still a pretty good approximation in that they're all the same trends being followed. And even more surprisingly, you get an exact agreement again in the ultra-strong coupling limit where this thing is not even expected to hold anymore. Yeah. I was expecting to see that one set of markings represents the thermal state with respect to the effective Hamiltonian E. To the effect of Hamiltonian, even in the in-between coupling regime, I expected to see based on the end of your last slide that the actual state of the system is very close to that, even in red dots is exactly the Gibbs state now with respect to that effective system Hamiltonian, whereas this blue is, again, a similar Gibb state. Again, a similar Gibbs state, but now we have to trace out the reaction code. It's not easy to write it. I thought it written here, but yeah, flat. And so down the other slide, you can see the contribution of that other process that was the term proportion as we match in the last slide, where now you actually have coherences that are present in a steady state due exclusively to coupling. And again, the trends are being followed, but there's a slight offset. Slight offset. Okay, so just to mention now, come back to this picture again. What we essentially did is to kind of bridge this gap approximately by saying that in the intermediate coupling regime, the steady state of the system is going to be roughly the Gibbs state now with respect to this effective system Hamiltonian. And surprisingly, it's even able to do well in the ultra-strong coupling regime. Coupling regime. Yeah. What's the relationship between this effective Hamiltonian and our force? Good question. So the Hamiltonian immune force, it comes about from like if you just write out the full Hamiltonian, okay, if you assume that the full Hamiltonian will thermalize, the kind of like exponential of H, S, H, B, Lambda interaction, whatever, you get that from tracing out over the path of that whole thing. And so, And so you can kind of look at this as being an approximation to the Hamiltonian mean force in a sense. That's how I'd see it. What's the approximation? I'm saying approximate only because you don't get the exact value, like there's a discrepancy between the blue and the red. And also because you're making approximations to get there along the way, namely the frequency of the reaction recorded has to be much larger, for instance. Your strategy has an advantage of simplicity and to get analytical design. There are tools that can do this that you can get exactly the right answer, but a lot of them are like, I don't want to say black box, but just input-output kind of approaches. Whereas this, you can actually see what are the two processes that are that are at play. Uh yeah. So can I think that that wants to sort of back to the comment this morning that the view input Comment this morning that if you input a thermal state and sort of a classical effect, I guess you're putting classicality from the beam or say a thermal state. So if I were to grab a new state for the path, then the procedure would not be as a state. I think to do a lot of this you need to have this kind of thermal state for the reservoir. So I don't know if it would Because that means that all the transformations I'm doing until that last point, there is nothing like all the steps that you do for that component. But to do this kind of transformation, I believe you'd have to have, and use the mass equations as well, I believe you'd have to have a thermal state for the reservoir. But we could chat about that afterwards. So, yeah, so what was the other word I said? Yes, it also works in the alternative. Whereas, yes, it also works in the ultra-strong coupling window as well. Okay, and now is there a bit of time? I have a little bit of time, I can do that. So, now I'll also mention another application that we use. So, we did this to study quantum thermal machines. It's an autonomous engine where the goal is to cool this cold environment by using some energy from a work environment, then dump it into its hotter environment. And so, when it's studying kind of systems, the working fluid is. The working fluid is this three-level system that we have here, where epsilon here are the eigenvalues. And so you can find just from master equations, a recoupling master equation framework, that this is the relationship between the eigenvalues and the temperatures of the bath in order to have cooling, in order for this apparatus to work as a refrigerator, through the cooling function. And so then you can also calculate the current that you get, the cooling current, and it just grows with the coupling strength, but it's a recoupling approach. With a coupling strength, but it's a recoupling approach, so eventually it's no longer good. So, if you apply the same machinery, same framework, what you end up finding is now the eigenvalues of the three of the system now get dressed with the coupling parameter. And now the same bound is, you can still use the same bound, you're still using master equations, but now the different fin diagonal values will now depend on the coupling parameter as well. And so now, if you do the same thing now with a strong coupling tool, The same thing now with the strong coupling tool, the reaction coordinate in this case. You find that it's not necessarily a question of advantages or disadvantages to the strong coupling, but more it's just different. So for example, if you're asking the question, like if you're working in this kind of regime, then it would appear that strong coupling is bad because you're no longer able to cool. But if you're like somewhere here, let's say, now you get this new regime where you're able to cool somewhere where that was not possible before. And that's entirely due to the renormalization of. And that's entirely due to the renormalization of parameter effect that I mentioned before, kind of pushing you back into the bound. And yeah, I think I'll be wrapping up now. So just to mention, that was only two of the problems that we looked at in the paper that I mentioned at the beginning. We also studied non-equilibrium thermal transport. So what are the effects of strong coupling on sites and heat currents? We also looked at like phonog-assisted electron transport. We noticed strong coupling electron-phononog effects here. Electron phonon effects here and see what happens. Also, many body spin chains, how we can use this to kind of map one strong coupling, one model at strong coupling into a more simpler model to analyze what's happening there. And I want to also mention, if this interests you, there's some earlier works I've done relating to the reaction quarter mapping alone, here dealing with steady-state heat transport, here showing that you can use the reaction quarter map method. Use the reaction quarter method to capture and characterize non-recorded dynamics. Here I mentioned it a bit, but looking at quantum location refrigerators. And then this one looking at quantum thermal transport with the reaction coordinate that is even useful in the weak coupling regime where master equations should behave well, that they miss something that the reaction coordinate is able to capture. And lastly, this is five with the one I was just talking about here. And so to conclude, And so, to conclude, we introduced some tool that allows you to generate effective Hamiltonians. We are able to interpret strong coupling effects in open quantum systems. And we then applied it to study thermalization of the spin boson type model to show that new processes emerge. And we also looked at quantum absorption refrigerator to show that there's a reshaping of the cooling condition. And so, I'll just mention there's still some open questions here. Some open questions here. So, what I talked about here applies for the moment for bosonic reservoirs. So, we're now thinking a way of explaining this to work as well for phononic, fermionic cases, alright. And we're also trying to tackle a question now of like thermometry with this kind of approach. So, last but not least, I have to acknowledge Professor Diverse Gal, my PhD advisor, Professor Sadnazir from Manchester, and Felix Evander, a very talented undergrad, I guess, now a master's student. I guess now I'm a master's student at Berkeley. So, thank you. Thanks very much. Questions? At the moment, I don't think so. I think that's another avenue we're trying to look at. Because since we're kind of Because since we're getting rid of any kind of non-Markovian phenomena, once we truncate the reactor coordinate, you'd miss all the non-Markovian effects. So I don't, at the moment, I don't know if you could do it with that. There's another question somewhere. Yeah. May I ask a question? Yeah, you go first. Yes, Anton, go. Oh, wow. Thank you for the very interesting talk. Very interesting talk. I would like to ask: do you have some calculations, some simulation of how close your effective Hamiltonian or Gibbs state with respect to the effective Hamiltonian to the enforced Gibbs state in the intermediate regime? Yeah, so that's kind of what this line, the blue one, will kind of represent because that's what's something we obtained with the reaction coordinate, where I guess it's just. Coordinate, where I guess it's the assumption that the reaction coordinate itself is well approximating the mean force Gibbs state. So if you believe that the reaction coordinate method is good enough to represent the mean force Gibbs state, then this is how far the effective Hamiltonian approach is from the mean force Gibb state. Okay. I need uh let you about uh how close is the reaction coordinates uh to the mean force gib state so the The mean force keeps state. So it's an interesting question itself. It could be interesting also to compare directly to the reinforced each state. Yeah, I agree. There are some numerical methods of calculating different states. Yeah, true. Yeah. Okay, but thank you. Yeah, that was all very nice. So one thing that I want to One approximation that seems to be in this is that so you can project onto this zeroth this ground state of the reaction coordinate. So that seems to also assume that this characteristic frequency is much bigger than KBT. Are there any could you instead thermally average that to get some thermal effects or if that if that approximation isn't valid in your system? Does that mean What do you mean you mean thermally averaging? Could you just clarify what you mean by thermally averaging it? What do you mean by the average? So instead of constructing your effective Hamiltonian as just the projection onto the zeroth state, could you construct it as the thermally averaged sum of the nth exciting? I tried that and it didn't seem to work as nicely. I'm not, I didn't try super deeply because I could look into it again. I guess maybe when you I guess maybe when you get down to low enough frequencies, these thermal effects might become important and the approximation of, say, this trajectory breaks down as well. Yeah, exactly. But I think to answer that, I'm not sure if I mentioned it before, but we're looking at right now how to kind of include more effects from the excited states, for example. So I think it's a bit of line we'll draft. And there was someone else with you. Okay. All right. All right. Cool, thank you. Further questions? Thanks for the very nice talk.