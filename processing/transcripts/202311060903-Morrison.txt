It's nice to see some familiar faces. It's been about 10 years since I've been to Pamp, so it's nice to be back here too. Looks to be a very interesting workshop. Let's see, this is kind of small, and I don't quite know why it's doing that, but I hope you can see this well enough. Because this talk covers a lot of ground. It's something I've been thinking about for over 40 years. Over 40 years. And so, you know, I mostly like Blackboard talks that have a nice clean theorem, poignant theorem that you're going to pop out. Anyway, this is not that talk. It covers a lot of ground and would really be impossible to give, I think, on the blackboard. Listed here are a bunch of collaborators over the years, some of whom you may know. The specific four-bracket stuff is done with an undergraduate student. Stuff was done with an undergraduate student, Michael Updine. And you can find everything I'm going to say pretty much in this archive paper. And so in some sense, this talk is a theory of theories that, what does that mean? I'm interested in categorizing kinds of dynamical systems. And we already know of one very important one, Hamiltonian dynamical systems that many of us know and love. us know and love. But this is broader than that, and it's a way of categorizing and constructing thermodynamically consistent theories. And I'll explain what that means. Okay, so that's the introduction. So what is a theory? What is a model? To me, as a scientist, what you really care about is predicting the future or maybe even explaining the past. Even explaining the past. And how you do this is with a dynamical system. Generally, it's a Cauchy problem of some kind. And so it all comes down to the fact that you have a vector field on a manifold. You have a phase space, your set of dynamical variables, and then the dynamics is defined by a vector field of some kind on a phase space, which is a manifold. So ultimately, it's about dynamical systems and vector fields on manifolds. And vector fields on manifolds, although the actual equations of interest could be maps, could be ODEs, PDs, all sorts of things. Generally, we're in infinite dimensions interested in PDEs. So this talk would be about both. So the big question comes, where do the vector fields come from? Well, in physics, they might come from some very fundamental n-body theory of 10 to the 23rd interacting particles with some interaction potential. Particles with some interaction potential, et cetera, et cetera. Something that you really believe, maybe a quantum version of that, which you can't do anything with. You can't solve, you can't put it on a computer. So we generally look for reductions. Ideal reduction would be one where you do asymptotics, rigorous asymptotics. You whittle your system down to something that you know is true because it's within certain bounds. Maybe even you prove bounds. So that's one way where vector fields come from. So that's one way where vector fields come from. That almost never happens in physics and mathematics. It's very rare. The other way is that you have some, you take all the intuition you know, all the experimental data you know, and you make up something that's consistent with all the constraints that you think a good physical system should have. And that's sort of where this metroflecting stuff comes into play. And then hopefully you get a reduced computable model by doing this. So what we'd like to do is categorize those vector fields. To do is categorize those vector fields that you might guess or you got for one reason or another. So, generally speaking, physicists and other engineers know that if you write down a system, they can point to where the dissipation is. In fluid mechanics, you know, oh, there's the viscosity. Let's throw that out for the moment. Or in magnetohydrodynamics or other magnetofluids, there may be resistivities and things. Collision operators, we know where the collisions are, etc. So, if you throw Are, etc. So if you throw that away, what's left is either a Hamiltonian vector field or it's wrong. So now you know where I'm coming from. So then the question is, what's all the rest? Well, it's everything else, right? Of course, it isn't. In physical systems, we know that the dissipator part should do something. And one of the things it should do is probably have some sort of asymptotic. Probably have some sort of asymptotic stability. Maybe if you're not forcing the system, it should relax to something like thermal equilibrium. In fact, the point to which it relaxes, we'll call thermal equilibrium. But from a dynamical systems point of view, it's just a fixed point that's an attracting fixed point of some kind. So how can we categorize such things? Well, what I described suggests that it should be some sort of a gradient flow of some kind. And so I've written a gradient flow. And so I've written a gradient flow for my vector field as some matrix or operator times the gradient of some function, which I've called Rayleigh. Okay, so here's some history. I'm not the first person to try to put dissipation into a framework. Rayleigh did it in his famous theory of sound using adding a term to the Lagrangia. I think Francois is going to talk about what I would call continuation in some sense of what Rayleigh did. Rayleigh did, and he's going to look at Lagrangian variational formulations for doing some things that are similar that I'm going to do. And, Francois, you're here? Oh, thanks. Glad to see you. And so there have been a lot of gradient and sort of dissipative like things in the wind. Con Hilliard for two-phase flows. Otto Ritchie, we know about Perlman, and so on. So these are all things that I'm not going to talk about. I have a different approach. Not going to talk about it. I have a different approach, and that is to use brackets to do it. And that's what metroplectic dynamics is. So I made up this word in 1986, or published in 86, 85. And what it has to do with the metric is sort of in the gradient flow, the G here is taken to be a symmetric object, like a gradient, but it won't be. Like a gradient, but it won't be like a metric, but it won't be a real metric because it would be positive semi-definite. And then there's a gradient there. So that's where the metric comes from. The plectic, of course, comes from symplectic. So the idea is that this is a way of joining Hamiltonian and dissipative systems, metric plectic. So the formalism naturally splits vector fields into ones that are thermodynamically consistent, by which I mean Consistent, by which I mean energy is conserved, that's the first law of thermodynamics, and entropy is produced. There are other invariants you can build in. Good collision operators conserve maximum minimum energy. Won't talk about that. And in any event, it turns out that there's this thing, a four bracket, that sort of includes everything. And it also has a very interesting connection to curvature, like Riemannian curvature. So I'll tell you about that. And that's sort of the main part is to try. That and that's sort of the main part is to try to convince you why a four bracket should even show up here. Most of the ideas of this were in my papers in the 80s, and I'm sort of embarrassed to point out that I didn't discover, really figure this out for over 40 years. Anyway, you can read those early papers if you want. I think I don't need to, with this audience, explain what a Hamiltonian system is, but Thank you. So I got into this game very early in 1980. Much of the business goes back to the 1890 Sophist Lee. 1980 was a big time, a lot of us. I visited Berkeley. And anyway, Alan Weinstein's famous Poisson Manifold paper came out in 82. And that was part of the level of activity here. But the basic idea is to consider. idea is to consider a manifold with a binary operator on functions which is anti-symmetric, satisfies the Jacobi identity and likelihoods. And the interesting thing is that Sophis Lee pretty much knew about, of course he didn't really know what a differentiable manifold was, but he knew about these structures. And what differs from the usual Hamiltonian mechanics is the fact that the Poisson bracket can have degendracy in it. And this gives rise to Casimir invariance. This gives rise to Casimir invariance, which we knew about and called distinguished functions. And we started calling them Casimirs in the 80s. And I asked Alan and other colleagues from that time, how come they did that? And I actually asked them, did I do that? And I think the answer is it comes from George Sudarshan, who wrote a very famous math physics book on mechanics. And his opinion was we should call them these distinguished functions. These distinguished functions, but such is history. So, geometry, here's just a bit establishes by notation, Poisson bracket, maps C infinity functions, two of them to another. You could say it's a Lie algebra realization that's bilinear anti-spectrum. Satisfies the Jacobi identity, and you want Libran so that it generates a vector field. X is a derivation of generating spectrum. So I use lambda zero for kappa lambda zero for zero forms. zero for zero forms and then you can write the bracket in various ways here. This is the pairing between vector space and its dual. J is the bivector, the cosymplectic form, the Poisson tensor, the Hamiltonian bivector. It goes by many names. And it's the crux of the matter. It's the thing that defines the Poisson bracket. So df and dg are one forms of this j that generates a vector field when you put a function in it for one. A function in for one of them. In coordinates, it would be usual Hamilton's equations with this matrix J. And then Casimir invariants are things that commute with all possible Hamiltonians or all possible brackets that live in the phase space. Okay, so here's a cartoon, really a cartoon of a Poisson manifold. Locally, near a regular point, there's a foliation, and the beauty is that if you start on one of these level sets, One of these level sets of the Casimir invariants you stay on for all time because they commute with any Hamiltonian, so it must be constants of motion. So there's a generalization of the Darboux theorem to believe it says this. Okay, so that hope was not too fast. So now here's what the talk is really about. It's an object like the Poisson bracket that has four slots: one, two, three, four. So F, K, G, and N. Three, four. So f, k, g, and n are functions, zero forms for now. Eventually, I'll lift infinite dimensions, but for now, I think we'll try to explain things in a context where things could actually be proven. Infinite dimensions, it gets very dicey, as I'm sure everybody here knows. So, the first question is: why a four-bracket? So, actually, in my early papers in the 80s, I fooled around with three brackets. And it just seems so ad hoc and unsatisfying. Like, okay, anybody can make this out. So I'm putting this over here because he says I'm destroying my computer. So let's see, why four? Okay, so the first thing is that the theory's got two fundamental functions, an entropy and a Hamiltonian, right? To be thermodynamic, you need at least two. Thermodynamically, you need at least two, and we're going to go with those two. So that takes up two slots. You're going to have observables of some kind. You know, what are your dynamical variables? They're going to go in one spot. So that's three. Why the other one? Well, then you have something that's going to generate the dynamics, maybe a free energy or something. So the H and the S go in because you're designing the system to be thermodynamically consistent. And then the F is going to be the thing that generates it. F is like for free energy. F is like for free energy. So the other thing is, I tried really hard to get three brackets to be multilinear, and it's impossible. You need four to be multilinear. So and I believe that that's a good thing to have in the structure. It's just cleaner and mathematically purer. Okay, so the other thing is that four, we'll see, provides a natural way for the whole thing to collapse down. thing to collapse down to all the known previous brackets for dissipation that existed in the literature. It's apparent to all these daughters. Okay, so what is it? And let's see, I started five minutes late, so I'm about halfway through. So a four bracket again takes four zero forms to zero form functions. So I'll use this. And so we could write it symbolically like this. And so we could write it symbolically like this, where there's some symbol r, and there are your four one forms, which are assumed to be exact. So f, k, g, and n are zero forms. G is the exterior derivative. You'll notice I put a semicolon in there, and there's a reason for that. You'll see it soon. And if I were to write it in a coordinate patch, you'd see it be defined by some sort of quadrant vector, like this, in terms of gradients. So I say that I. So, I say that I had a lot of these ideas a long time ago. And so, of course, many manifolds have Poisson brackets. And so what we would like is to find a compatible quadrant vector of some kind, and an S and an H. So these are the ingredients. You'll need a manifold. It'll have to be the Poisson manifold. It'll also have this additional structure. So these are the properties of. So, these are the properties of this thing. And so, basically, these were discovered by trying to make this theory fit previous theories. So, the first is we want it to be multilinear in all slots. And there's some algebraic identities. This is flip the F and K, you get a minus. Flip the G and N, you get a minus. And flip both of them, you get a plus. I mean, flip these two to here, and so on. And there's another identity, and by now, And there's another identity, and by now, maybe a bell is ringing. This might remind you of something. And in fact, there's a cyclic identity that we'll see actually happens automatically in the construction. That is, the dynamics doesn't see this identity. And there's a whole little theory of equivalence classes that comes from this, but we'll probably skip that. So it's a derivation in every argument. And at this point, if you've studied Riemannian geometry, you might think, well, this reminds me of the Riemann curvature. Think, well, this reminds me of the Riemann curvature tensor. In fact, these are asymmetries of what is called an algebraic curvature tensor. So, in geometry, we often see a one-up, three-down object, and that's because it takes three vectors into a vector. That's usual the definition of curvature, or if it's Riemannian, then you have a metric and you can lower it and get this one, this covariant one where they're all down. You see those in geometry books everywhere. What you don't see is this. What you don't see is this. And believe me, I've really, really looked for it. And if anybody can find it, it's sort of surprising because if you had any of these, you could just raise them all up using the bundle map, essentially. And there you go. And in some sense, this is interesting because if I back up, you see that the way that this is built is that, you know, in general, if you have vector fields on a manifold, bunches of them, you don't know. Bunches of them, you don't know that they all lie or define the surface. You need a Frobenius theorem or something to tell you that. So you don't know that here. But here, because this is actually defined on zero forms, ultimately, these are functions that go in here. I know that these functions will define level sets, and I have them. So I know a priori that I'm going to have, roughly at least, a foliation by Hamiltonian level sets and entropy level sets are in. Entropy-level cells are in it. So it's sort of curious to me that this all-up thing has never, oh, I did find it in some obscure book as a homework problem or something that has nothing to do with this, really. So, okay, so brackets of the 80s, the idea is that you take the Poisson bracket, they're your two vector fields, and then you have something, some kind of a generator, and some possible symmetry properties of this thing. Properties of this thing. If you make it Leibniz and bilinear, you get to here where there's your capital, big G I J, and this thing is a map of functions to functions. So the basic question is what properties are you going to instill in this, and what are you going to use for your generator? And those were the things of the 80s. Oh, I played around with symmetric things using the Hamiltonian as a generator of type. It's probably around 1980, but I think I published something. Publish something. I think this metroplectic 2 bracket, the idea is that you should use this, I called it the free energy, which is H plus S, make the dissipator bracket symmetric, and then build in H as degeneracy in the symmetric bracket. That guarantees energy conservation, because H dot will be H with F. Ah, the important thing is, what do you choose for your entropy? What do you choose for your entropy? And this is a major idea, I think, is that entropies should be Casimirs of the Hamiltonian dynamics. Okay, well, why that? Where does that come from? Well, I've probably written down 100 Poisson brackets for various things, probably more, actually. And in every instance where the physical entropy is something that I could identify, it turned out to be a Casimir invariant. So duh, it. So we'll choose the entropy to come from the set of Casimirs. And then if you do that, then F with H is going to be zero because H with H is zero by anode symmetry. S with H is zero because S is a Casimir. And then we sort of make H a Casimir. It's not a real Casimir, but we build it into the degeneracy of the symmetric bracket. And then the second law of thermodynamics comes. This vanishes. This vanishes, and this gives, if you build this thing properly, a positive semi-definite form that gives you at least a formal H-third or Lyapunov relaxation to equilibrium. So basically the dynamics is doing the variational principle of extremizing energy, maximizing entropy and fixed energy. Okay, so I'm going to have to even speed up. Let me just say that if you take the four bracket, stick it. You take the four bracket, stick an H in the second slot and the four slot, it collapses down to what I had done in the 80s. It becomes the same thing. And it basically is a way of building in a projection automatically by the symmetries to make energy conserved. It's very simple to do this. And so you get energy conservation, entropy production. Okay. So there's. There's lots of geometry here, much more than I can. Various kinds of metrics or connections. You can basically take any Poisson manifold, put a metric or just a connection on it, and this thing emerges naturally. The other thing is I know that the set of these things is not empty, because they're Riemannian manifolds, and for every Riemannian manifold, I can get a quadrive just by raising it. So that's one special case. So that's one special case. Although it doesn't have to be that, if it is that, then one discovers that the entropy production, which is SHSH, is actually equal to the sectional curvature. So this identifies the rate of entropy production with the geometrical object. Okay, so this, I got really excited when I saw this. And you see sigma and n are one forms, but when you do the bracket construction, you're left with this. You're left with this quantity here, which is normally the sectional curvature is something defined on two vectors, but I'm doing everything dual, so it's on one of those. Let me just say that these are a whole bunch of brackets from the 80s. Kaufman and I had an anti-symmetric one in 82. And this form was, oh, this is interesting. There's something called double brackets. Tony Block and others. Tony Block and others worked on. They sort of got this out of control theory, and then there's a fluid mechanics. Turns out you can get double brackets out of this if you know what those are. This was a surprise. And then generic, well, generic is essentially the same thing renamed in 1997. There are different versions of generic around. I pinned down the authors, Ramela and Pavelka, this summer. They showed me their most recent version, and I could show. Recent version, and I could show that what they have is essentially what I did in 1984. Anyway, so this four bracket actually reduces to all of these. For example, the two bracket that I did with Cochlin, you put HS here. So I think I'll go through this quickly because I got five minutes or so. Let's see, I started five after, so I have nine minutes. So let me just skip this, which shows basically. Which shows basically how you get all previous theories out of this. So you just take my word for it at this point. We can get into the details later. So, for any Riemannian manifold, there's a four bracket. So, there are a lot of these around. Then there are other methods of constructing them. I'm going to tell you about two of them. One of them is use this Kokarni-Nomitsu product. And the other is that associated with any Lie algebra, there's a very natural construction for these things. Just like associated. Just like associated with any Lie algebra, there's a Lie-Poisson manifold, there's a Lie-Poisson metroplectic manifold that could be constructed from this. And so, my idea is that what I'd like to do, in physics, people write down Lagrangians for various field theories by building in symmetries and making things up using their intuition. It's that you can make four brackets up using your intuition by using the tools that I'm there. I'll tell you in the next five minutes. Tell you in the next five minutes that I could spend a really long time talking about. So, this is the Km product. It was actually defined on vectors, not one forms originally. But basically, if you have two symmetric ranked two tensor fields operating on one forms, so sigma is a tensor field and it operates on DF, DG, et cetera. And this particular thing automatically builds in the algebra. thing automatically builds in the algebraic curvature identities. And also, if it's quite interesting, if these are positive semi-definite, then you can use the Cauchy-Schwartz inequality to prove that the sectional curvature is positive. It's quite beautiful. It just comes out. You can show that it's even the Cauchy-Schwartz that doesn't require non-degeneracy. There's a version of it with degeneracy that you learned about in grade school or wherever. If only one of If only one of them is positive definite and then the sectional curvature has a kind of definiteness, it means that we'll do the variational principle precisely if we want. That's a longer story. This is how you would construct it in coordinates. The four vector, here are these tensors. So, you know, you can just find these things up. I think I'll skip, leave Poisson. And this is sort of cool. So just to So, just to play around in coordinates for a minute, and suppose we have a Lie algebra and the C's are the structure constants. Then you can build this thing. You see, well, I'll do two of them, they'll put four gradients, and you start asking, how can you contract all this to make it work? Well, I need a metric of some kind in there. At least something with two up indices. So it turns out that this works, but it doesn't have that, it has torsion. It has torsion, but there is a way to make this work by changing this by something that doesn't see the dynamics. In fact, if you use the Cartan-Kelling metric, that is this G, this composed, you have something that's completely Lie algebra-based. Give me a Lie algebra, I construct this thing, I put that in here, and there's your formula. So it's pretty obvious that there's a lot of geometry here. And everything, so it's completely determined by a Lie algebra. The other, and this is. By a Lie algebra. The other, this is really fascinating, is that you can, you know, a covariant connection is something that takes vectors to vectors, but you can construct a contravariant connection on one forms that satisfy the Kozul identities, which are Kozul sort of, to get rid of that ugly Christoffel symbol, made the theory of connections algebraic. And if you know about this, he has a likeness. And if you know about this, he has a liveness thing. And there's a term there that's a vector field. If you replace his vector field by J, the bivector, operating on a single one form, operating on a function, then this thing builds beautiful geometry on Poisson manifolds. And we were, there's a paper of Fernandez in 2007 afterwards that talks about this geometry. And this is basically a whole area of geometry now, I see it, I think. So that's just the way. So that's just to whet your appetite. Examples? So everybody's example is the free rigid body for this game. And there, it's a three-dimensional system. It's a Lie-Poisson system. The algebra is SO3. Energy is this quadratic function. L is the dynamical variable. The angular momentum. I's are the moments of inertia. And the Casimir is L squared. Okay, and this has. So, what I'm going to do is use this Kn construction to build a thermodynamically consistent dissipative free-rigged body. And if you do that, I just choose for the two tensors in the K and things a G, and then it turns out that this thing becomes what's called the Riemannian space form, where this can be shown to have the right symmetries. And then if I further reduce it, replace these g's by delta. Replace these g's by delta functions, chronicer deltas. Thing collapses down to this, and then I plug in the age, and this turns out to be the thing that was in my 1986 paper. I didn't plan that, it just fell out. Wow, I must have done it right back then. In any event, what this dynamics does when you use this four bracket is that it conserves energy, and it either, depending on the sign you choose, makes or take or removes angular momentum. Removes angular momentum until it relaxes to a pure spin around one of the principal axes of the system. And it does it while conserving energy. Okay, so that's pretty cool. You could actually make something that did this, that would be nice. All right, so the point of this is that Kn just easily gave something very physical and very interesting. So let's jump to infinite dimensions. I now have multi-component fields. This could be This could be a magneto-fluid model or fluid theory or something with densities and so on. Z is the. Then I'll construct a bracket like this on variational derivatives. This is a Fresh A derivative. Okay, so if you don't know this already. And this R in general is going to be defined as a distribution or an operator, a pseudo-differential operator. There are various ways to put this in a formal setting. But the basic idea is that this thing operates on these things in very different ways. thing operates on these things in various ways, such as to make sure this has the symmetries that you can want and the definiteness. In fact, you can use the Kn construction to build things. And so a natural thing to try in infinite dimensions would be a one plus. And that's not right because I started it at five hours. Actually, it was six hours. Okay, so I have ten minutes for sure. Okay. Okay, so basically the whole thing comes down to now choosing operators sigma and m instead of the tensors before. And for m, I'll just do the u means variational or functional derivative. I'll just do pointwise multiplication. Oh, I chose the Hilbert transform. I got some model out. But you can, it's interesting to just make up these things and see what systems come out. You can generate all kinds of very interesting one plus one fluid theories with dissipation that conserve what you're doing. With dissipation that can serve what you want them to. This is the one I wanted to spend a little more time on, and I think Francois is probably going to talk about this too. I call it the thermodynamic Navier-Stokes equation. The earliest reference I can find for this is Carl Eckhart in the 1940s. And the basic dynamical variables are, so this is fluid, have your Stokes. Rho is the mass density, sigma is an entropy density, S is the specific entropy entropy. S is the specific entropy, entropy for unit mass, and m is the momentum density. So, okay, so you just, I'll just do point-wise on the entropy. That's the simplest thing you can think of. This one required a little bit of thought, sigma. Well, some dimensional analysis and a little bit. So you put some gradients here. I've already used this. The next simplest thing would be to take gradients of these things. Take gradients of these things. And then this is: if I'm putting gradients in, I know I want to do something with the momentum equation. So I'm going to need the derivatives with the components of the momentum density. This partial sub i, is just d dxi. And then there's a, naturally a foretensor appears. Well, what foretensor? It turns out there's a unique isotropic Cartesian foretensor, so I'll use that one because you want your theory to be rotational and stuff like that. So you stick it all in. So you stick it all in, and lo and behold, out pops Karl Eckhart's theory. So I make the four bracket, the energy is just what you think it should be: rho v squared over 2, the kinetic energy density, and the internal energy, u is the internal energy per u per mass. And rho and s are the thermodynamic variables. Entropy is rho times s, entropy u are volume integrated. You stick it in and out pops this system where there is a viscous stress tensor here. A viscous stress tensor here, T, that would normally dissipate energy, but if you modify the entropy equation by adding thermal conduction, then I think that's why Francois calls this Fourier, but also viscous term. And then it's designed so that this term here will, through this, conserve energy, but then you can show, in fact, Eckhart showed that it produces entropy. But now I know it has to produce this entropy because I get it from a four bracket. It automatically does it all. It automatically does it all. Okay, so there are many examples, kinetic theory collision. So maybe I stop with these final comments is that you can read a lot about this. And I hope that you probably didn't understand everything I said, but it will promote discussion here today. And I thank the organizers for allowing me to give this first talk. Hopefully, you can do that. We've started using this for lots of things. I have a graduate. I have a graduate student intern visiting from Morocco, Azadeen, and we've done this for multi-phase flows, and it's quite interesting to prepare with literature. She's extensive on this. With Naulti Sato, I've done it for various exotic collision operators in homogeneous plasmas. Given double brackets and metric brackets, just like we have Poisson, we have symplectic integrators. So we hope to have Poisson. So we hope to have Poisson integrators, and there are a few around. Foisson integrators preserve the symplectic leaves. These things, metroplectic two brackets of various types, have been used in computation. So I propose, hasn't been done, I think it's an easy actually, that one can discretize these four brackets with the symmetries to make at least semi-discrete that is ODs that do what you want them to do. So that's it. Thank you for listening. Thank you for listening. Thanks a lot for this nice first talk. Other questions or speaker? Yes, Peter. There was this namble bracket sometimes, but they were completely different and probably. Yeah, so I played with those two. Nambu brackets are purely anti-symmetric. Yeah. Okay, and yeah. Yeah, and so you can use those as a way of obtaining the Hamiltonian part. Usually their bamboo brackets have three slots and then they can have end slots and then the talk to John put in an additional identity and so on and so on. But those don't describe dissipation. And incidentally, if you read my paper, you'll find that that was all discussed. That was all discovered by an Italian in the 1800s, and you'll find it in the book of Whitaker. And the reference to that is in my paper. He had written down anti-symmetric brackets on ML objects. So he predated MAPU. Anyway, they're interesting things, and I've written papers on them and whatnot, but they don't describe dissipation. That's the bottom real answer to your question. I have another question. Could you just I am confused, so given uh this tens are uh R, for instance, and remind me, what kind of dynamics, but I mean, what is the explicit equation? So you don't know unless you have your H and your S. You have to put those in. Okay, the H should be the H of your Hamiltonian part, and the S should be the Casimir of that. And you would like it to be that the variational principle of H at constant S gives you what you are. Gives you what you are the variational principle to thermal equilibrium. For instance, when you have H plus, yes, it's stability theorem is exactly energy. So what kind of dynamics does it? I mean, so what it's doing is relaxing to that particular equilibrium that's with the energy chasm. It always kind of tries to relax. Yeah, yeah, so the dynamics does the energy, it does real dynamics to the energy chasm minimization principle. Platform. It's determined by the entropy that you take. Yeah? Let's see. Class. So I was wondering, in the case of Kayler geometry. Kayler, yes. So then you also have the structure and you can think you generalize the Hamiltonian dynamics by taking a Hamiltonian that has both the real and the imaginary part. Yes. And that will somehow give you dissipation. Yes. On the other hand, if you have no. This, on the other hand, you have no Casimirs in that case. Yeah, that's the problem. So there are two problems with Kaler. In fact, Fernando's business actually has a connection to Kahler. But if you assume both metric compatibility and the covariant derivative of the Poisson tensor being zero, I forget what you call that, then it becomes just too trivial. It's just too tight of a structure. And the basic reason is the thing I call big G is it has to be. Thing that I call big G has to be degenerate in order for this to work. And a Kayler manifold, the metric that's naturally on there is non-degenerate. So it's just the wrong structure. I played with those for several years, trying to see if I could make them fit this. And this is the answer, I think. Not that. There's Max and then Peter. Max. So in your decomposition, the J and the G, so the Hamiltonian or the sympathetic tensor and the Riemannian tensor, they do not need to have any relation. They do not need to have any relation up here in time. The only relation is that the G should have gradients of H in its kernel. That's it. And the entropy should be the thing that comes from the Hamiltonian part, the Casimir Hamiltonian part. So that's a tie. That's what we call minimal metroflective. But if you get into some of the geometry where there's just a Lie algebra, then they're Where there's just a Lie algebra, then they're really tied together. And there are lots of ramifications for that. And in fact, to make the double bracket thing really work, we use that that I didn't say very much about. But I was hoping Tudor would be here so I could. And Tony. Anyway, yes. Two more questions, I think we can manage them. So you you you mentioned once that the sectional curvature would be entropy. Would be entropy. It's production, S-dot. So the rate of entropy production is sectional curvature. So I had to imagine a system which would increase entropy. So you have your energy surfaces like this. You have your entropy foliation, say, local at least, like this. And it moves along the energy surface to increasing entropy. And the rate at which it moves along there is determined. At which it moves along, there is determined by the sectional curvature. And I've actually cheated because sectional curvature really has a denominator, it's usually done on vectors, not one forms, and it has a denominator that I've thrown out because I'm insisting on multilinearity. So what is the system on a Lie algebra? On a Lie algebra you have a very natural system? Yeah, so I have some examples and I think I won't tell you about them now. Catch me later. I won't tell you about now. Catch me later. So, you know, you could do like SO.