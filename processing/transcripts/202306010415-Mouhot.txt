So let's listen now to Clement Rau, who will speak about the trajectory approach to the Georgia field. Thank you. Thank you, Lauren. Thank you for the invitation. And it's a great pleasure to be in Granada. I came a couple of years ago for a PhD defense, but the first time I came here was during my PhD. I visited Rose Carrillo. I visited Jose Carrillo, was still here, and I worked with Maria Cacellas. And Jose Carizo was not there, I think, yet, or maybe he was away in a trip. Anyway, so what I'm going to talk about today, I try to give an overview of something I've been interested in. It's largely, well, it contains new results, it's also revisiting some of the recent physics. Revisiting some of the recent results in the DeGeorgi theory for kinetic equations, but there's also a pleasure in finding the structure in itself. So this corresponds to several papers. Mostly, I will start with a paper I did with Jessica Guerrand, who is in Montpellier now, published last year, or maybe this year. It was the approach was extended to the non-local case. Was extended to the non-local case by Amelie Roher in Cambridge recently. And then at the end of the talk, I will talk about what we've been doing more recently with Francesca Ansvetsky, Elga Dietter, Jessica Guerrand, Amélie, Loher again, and Anna Laura Reguchi. So, the key word is trajectory, and I will try to explain the motivation and start with an argument in the ellipse. With an argument in the elliptic case in the end, when I explained the trajectory approach, which I learned in some lecture notes of Alexi Vassar, which is the starting point for all of these attempts. So yeah, first, what is the goal? If you want to have something in mind, consider this equation. So that's without this term in parenthesis, that would be a sort of abstract form of a kinetic Foucault-Pranc equation. Frank equation: the A matrix is rough. You could put these terms, but I will drop them immediately for the whole talk. They are in the paper, but let's keep it simple. So, we won't have first order or source term. And in the end of the talk, I will explain how the simple trajectories we did by sort of control problem allow now to have a general structure with a general number of commutators. I will explain what I mean in the sense of Hermonder, but if you don't have There, but if you don't have this term, it's a general kinetic fork, RAF kinetic focal point or RAF-Kolmogorov equation. Okay, you assume some ellipticity on A, and I won't have time to do it in the talk, but we cover also fractional diffusion cases for the right-hand side. Okay, so it has many names, but let's say a kinetic Poké-Planck or a RAF-Kolmogorov equation. Now, the motivation. Equation. Now, the motivation was, it all comes from the DeGeorgian-Nash model theory. So, initially, for those of you who wouldn't know, I know some of you know very well, the motivation comes from a problem, well, formalized by Hilbert, but it's older than Hilbert, he formalized it mathematically, which was to prove the analytic regularity of minimizers of such problems from physics with reasonable Lagrangians. So, what is the problem about mathematically? The problem about mathematically: if you write down the Eriver-Lagrange equations, you obtain here a non-divergent second-order equation non-linear on U. And you have genuinely something genuinely non-linear, for instance, if you plug a simple Lagrangian for minimal surfaces like that. And you want to know that the solution is infinitely smooth and even analytic. It was already known. It was already known at the time that you could get some bounds pointwise on grad U, but it was quickly identified that it was not enough to bootstrap and go higher and construct the smooth solutions. Then came another piece of the puzzle with the Schaulder estimate, very interesting also in the in kinetic theory recently, but I won't have time to talk about it in this talk, the recent extensions. So, Schaulder theory tells you that roughly a non-divergent elliptic equation with Divergence elliptic equation with Alder coefficients gains two derivatives in the Alder scale. And you can bootstrap it. So if you bootstrap Childer, if your coefficients are Alder, you get C infinity. Then you study carefully the Taylor series, you get an empty. The remaining pieces was the other regularity of these coefficients. And I'm still presenting in the elliptic case because it's simpler. If you look at one derivative of your function u, you can actually You can actually write down on this derivative itself a second-order equation, which now is divergence, is a divergent elliptic equation. You just differentiate once. And that on this equation that finally the problem was solved, was unlocked, first by the Georgian elliptic case, and Nash proved something very similar in the parabolic case. So, with the assumption of measurability and ellipticity on A. Measurability and ellipticity on A, you have that this little F is locally held there. And this little F was your first derivative, so everything is unlocked and you go to analytic. So let me briefly mention, give some words about the proofs, because the approach now is really mixing several elements from the different proofs. The proof of De Georgi combines two parts. The first is an iteration of gain of integrability by subject. Of gain of integrability by sober F embedding. And the second is really a control of the oscillation, sometimes called isoperimetric type argument, sometimes intermediate value lemma. They are conceptually equivalent, more or less equivalent results. The proof of Nash is very different. I won't go into it. If you want, there is a very nice preprint of Camilo de Lelis recently called Great or Master These of Nash or something like that. Great papers of Nashashashashash Of Nash, or something like that, great papers of Nash, where he rewrites the proof of Nash in with a more modern, let's say, writing. So he combines what we call Nash inequality, which interpolates with L2 between L1 and H1 that we heard about earlier this week, a control on the Fisher information, and a Poincaré inequality. Moser came up with a slightly different proof a few years later to achieve the Armack inequality. Let me just say the first part is. Let me just say the first part is very similar to the Georgi, but the second part, which we don't use much more anymore, was what interests me is that it was really using a Poincaré inequality again. The proof of Moser was somehow improved by Khrushchev. And later, I just mentioned there's a non-but divergence version that, to my knowledge, we still don't know how to extend to the kinetic case. Okay, so now a word about hypolytic. Okay, so now a word about hypollipticity because what I'll do in the end of the talk is essentially doing some sort of Hermander commutators on the trajectories. So this, the word is associated with Hermander in the late 60s, but there are earlier works, of course. The starting point is a not of Kolmogorov. So I summarize here the main result. Kolmogorov deals with more general equations than this one. I take the simple one. So you have here, you know, Have here a second order on one variable and an Hamiltonian, a first-order operator on the X variable. And he computes the fundamental solutions to this, which is here, and observes that you have a regularization in all variables. For him, it was really about integrating in time a Brownian motion. You know, if you integrate the Brownian motion on V, you get exactly for the law, you get this system. So that was his motivation. So that was his motivation. And you could think now to link with the equation I opened the talk with, you could think to this slightly more general model. You have three variables, v, x, y, and you can wonder, and it's true, that's the general conditions identified by Ramonder, you could wonder now if the regularization goes all the way from the ellipticity in V to the three variables, and it works as well for that model. Well, for that model. So, the idea behind the Hermann device is to identify the good commutator conditions to spread somehow the diffusion, the noise, if you want, to all the virals. So, in a simple case, with one commutator, you could think about it abstractly in this way, using Herman Doz notations. You have an operator that is squared that gives you the diffusion on some variables. You have the first-order operator. You have the first order operator, and if you commute your A and B, you get actually the vector field in the missing direction. That's the idea. At the level of trajectories, what I'll use is that you have to commute the trajectories along the different vector fields. Okay, so now, well, I don't have to say much about this because it was covered in several talks, including Maria and François' talks. So, the main motivation, why So, the main motivation why a lot of people have started working on that on the extension of the Georgi method in kinetic theory, it's mostly because you naturally get equations with either fractional derivatives on the kinetic variable or a second-order complicated sort of Laplacian on the kinetic variable when you deal with long-range interactions in kinetic field. Okay, so you have the non-cuts of Boltzmann, or you have the non-diagnostic. Non-catch of Boltzmann, or you have the Lambda equation that you heard of in previous talks. And well, lots of problems remain on that equation, including even global smooth solution in the spatially homogeneous case. But that was the motivation. Understanding better the regularity theory for this non-linear equation suggests to study these equations with rough coefficients. Okay, so now. So, now let me give you a brief history. It's probably non-exhaustive, but I try to put a lot of references about the results for this model equation. So, you could sort of put the Lambda-Coulon equation in this form if you want. You will need to tell me what is A, what is B, and of course, for your solution, in order to have the ellipticity on A, you will need to make some sort of assumption. But this abstract form covers. But this abstract form covers essentially interesting cases we are interested in in kinetic theory. So, for that equation, the first result along the DeGiorgi method is due to Pascucci-Polidoro, and they essentially did what we call the first lemma of the Giorgi, the gain of integrability. They did it by the Moser iteration. And there's another idea I'll come back later because you cannot do just I'll come back later because you cannot do just energy estimate and MOSER regression. They used the fundamental solution, which I will write in a second. Later, Wong and Zong obtained the older regularity. So not really by the approach of Des Giordi for the second LEMA. They followed more or less the Mosor Kruskop approach. And quite a few years later, with François here, Cyri Lambert in Paris. Uh, Cyri Lambert in Paris and Alexi Vasser-in-Lostine, we adapted completely the De Georgi approach. One thing was, however, frustrating, that was that the second lemma was non-constructive. It was obtained by a contradiction argument. Then, Jesita and Syr revisited the Wangzong result, the Mozart-Kuskov approach. Gitter and Irsch also have a paper which is in the same spirit. Spirit and then we try to obtain the constructive second lemma of the George. So it will become clear when I give the statement. And that's the starting point of what I'm presenting now. We gave a proof based on trajectory that we really wanted to obtain an argument as simple conceptually as the argument I will present in this note of Alexi Vanza for the LT case. And then there is the adaptation of in the non-local case where I'm Of in the non-local case, where Amelie can recover the results of Amber Silvest or Boltzmann non-cutoff, and the paper I'm talking about now. Okay, so a word, I have to show you that because otherwise I can't introduce my cylinders, but for the equation I'm talking about here, so in the simpler case, you have a transport operator, right? We'll call it T-kele graphic, and I have my second-order operator with RAF coefficients. With rough coefficients. We have two invariances. So the structure is invariant, right? As always, I don't claim the equation is invariant, but the assumptions I put on A are invariant by these transformations. But A will be changed, but into something still measurable with the same ellipticity bounds. So you have the Galilean translations. It's a non-commutative group law. You have to make it Galilean because of the translation. Make it Galilean because of the transport operator. It's not just a pure translation. And you have this scaling law, right? Which respects the different order of the terms in the equation. Based on this Galilean translation and scaling, you can define these cylinders. So that's all the shape is a bit different from usual, but all you need to know is there is a scaling and there's a translation group load. And you have to use them. All my pictures will be, of course, flat and rectangular, but you have to use them. Flat and rectangular, but you have to use them everywhere you translate. So, now the main results which are common to the non-constructive and the constructive papers are the following. So, the representation is where time is vertical, flowing upward, and you consider a solution, sometimes sub or super solution, depending on the statement, in an ambient cube. The theory is local and But the theory is local and it's scaling invariant, right? So I do things that unit size, but you can scale it. And the idea is the following: so, within this ambient cube, typically you want to relate something that happens for a cube in the past with something that happens for a cube in the future. Right? Times again flow upwards. So, more precisely, you have three colors. We prove intermediate value. We prove intermediate value lemma relating this cube and this cube. We prove a weak Arnac inequality for this one and this one, the intermediate one, and the Arnac for the red and the red. The only thing you need to notice in this picture is that to go from intermediate value lemma to weak RNAC, you need to slightly leave a small gap in time in this cube. I'm not sure I'll have time to explain why, but it's Not sure I'll have time to explain why, but it's it's uh it's I think necessary. So the intermediate value lema means the following: if in the past you have some mass where f is negative controlled by some delta proportion constant, if in the cube in the future you have some mass above one minus theta, f is less than one everywhere, then you have some mass between zero and Then you have some mass between zero and one minus theta, and you want to have a control of this new constant in terms of delta one and delta two. The weak Arnach inequality tells you that if you control the if, then you control an integral norm. And the integral, the Arnac inequality tells you that if you control an if, then you control a signal. And you can deduce the other continuity quantitatively, either from RNAC or also directly. Either from RNAC or also directly from the intermediate value lens. Okay, so these are the three main statements. Now, the method is to reduce all of them to the Poincaré inequality. So that's the idea that I try to represent here. The first step is, and you need this first step in absolutely all the methods, is the first limit of the droid is the gain of integrability. We don't do it in a very original way. Don't do it in a very original way, we just do it with a sort of clean and slightly optimized fundamental solution method. But it certainly could be done in other ways. This step is not new, it's just optimized a bit. Then we prove a Poincaré inequality that I'm going to write. Then that step is, we couldn't find anything like that in the literature, but it's a quite simple argument based on the Simple argument based on the energy estimate. I'll show it. Then, if you have the gain of integrability and the intermediate value lemma, you obtain the measure-to-point wise estimate. So that step is exactly the original historical argument of De Giordi because it doesn't depend on the equation. So I'll mention it, but I'll probably skip it because I don't have so much time. The interest is here in the method. And this step is that when you... That when you have the measure-to-pointwise estimate, at every scale you obtain weaker knock. That was known in the elliptic case. So, the conceptually it's not new, but it was very nice to see that we could make it completely work in the hypolytic case. And once you have a weak ARNAC and again an integrability, if you combine both, you get ARNAC. Okay, so step one, like I said. So, step one, like I said, we did it by fundamental solutions as Pascucci Polidoro. Step two is the one I'm going to talk about most, the Poincaré inequality. Step three, I'm going to show you. Step four is this de Georgi argument. And step five is inspired from elliptic equation. So, I did not check the first time it appears, but it might be older than that. I learnt it from a paper of Li and Zhang of 17. I'll show you the. I'll show you the argument in a second. So, the beginning of everything is the L2 energy estimates. So, just observe the following. So, if you're familiar with that, you localize with the localization function and you test your equation against F phi squared, your localization function. It's the standard energy estimate localized for a PDE. And you have two radians, a small r, smaller. Two radius: a small r smaller than a big r, and typically that's your small radius, that's your large radius, and you want to get some control here from the L2 control in the large radius. So, don't forget time flows like that. So, you get the control on the grade. So, you get a control on the gradient in V, and you get control on time slices, which means it's a bit better in terms of time, in terms of integrability. The key point is to notice that, unlike the elliptic and parabolic case, you don't control the regularity in all variables. So it's not enough that estimate to start the Georgi Mosa regression. So, what you can do several things here. What we did What we did first with François Cyril and Alexi, well, at the time I was not really aware of the paper of Paspucci Polidoro, so we followed, I don't know if you were, François, but I mean, at the time, we followed what we knew, which was using averaging lemma, which is one of the ways you can think of that transfer some regularity from V to X by the transport operator, and some comparison principle. And principle. Another way to proceed is just to say that if you define this case for Kolmogorov, this simple Kolmogorov operator, it turns out that you can write down the fundamental solutions. And using the fundamental solutions, you can very easily establish the gain of integrability and even some small gain of regularity, putting here the defect measure for a subsolution. Subsolution with the optimal exponent. Okay, so it's just a matter of rewriting the equation using the fundamental solution. So let me skip that. And the fundamental solution, in fact, does the same job as the averaging lemma because it's built in the fundamental solution. There is a transfer of regularity from V to X. Let me skip that. And now let me talk about, show you the statement of the Poincaré inequality, then I'll show you. Then I'll show you how it implies all the rest, and then I'll spend the last 10-15 minutes on the Poincaré inequality. So, what I call a Poincaré inequality in this context is the following. So, I make a picture because that is important. So, this inequality, interestingly, is a way to make. Is a way to measure the oscillation. I mean, roughly speaking, probably one could say that this way to measure the oscillation goes back to Nash, whereas the DeGeorgi way to measure the oscillation was met for point-wise. It's a sort of integral way to measure the oscillation. So it's about saying that if I have a cube in the past, okay, so time. Okay, so time flows like that, and that's my ambient cube where I look at the solution. What I'm saying here is that I look at the average of my solution on this cube in the past, and then I look on this cube here how much has gone above the average in the past. So there is a positive. So there is a positive value. That's for a substrate. And I want to control that by the velocity gradient. Right? So if it was elliptic, you would recognize much better the Poincaré inequality. But it's just because you have time, you have to compare the average in the past with the value in the future. Future. And also, one way to think of it is if you take the gradient in V to be zero, a subsolution means going down along the trajectory of the transport of your first order operator. And you see that in that case, you clearly cannot go above the average you had before. Yeah. Yeah. The averages in variation are averages in the velocities or also space. Velocities for us in space. Oh, in everything. In everything, yeah. So, Z here is the full measure. So, what Z is the full measure? Yeah, sorry. Oh, I wrote it before, but it went a bit fast. Yeah, sorry, Z is an notation for all the values. Just a short hand to make my slides move. The integral on the gradient is also di. Yes, yes, absolutely. Yes, yes, absolutely. These are integral in all the variables. In the hypolitic world, usually you want to think of all the variables as just one. We don't particularize time that much anymore. Yeah, and so that's an average on this time space velocity Q. So this inequality is reminiscent of something used by Nash on the fundamental solution. Fundamental solution, the Moser approach. Like I said, in the elliptic case, it would be simpler. It's in the elliptic case, it's really controlling the integral of f minus average by integral of a gradient. And it turns out that what I'm talking about works as well in the elliptic case. It was just known that's more or less similar to the notable Alexi Basil I was mentioning. Okay, so now before I explain how to prove this inequality, what can you? Prove this inequality, what can you do if you have this Poincaré inequality? Well, assume now that in my past cube here, I have some negative mass. Assume that in my future cube, I have some mass above one minus theta. What can I do? Well, the left-hand side of the Poincaré inequality will be bounded below. Why? Because the average. Why? Because the average in the path here you see has to be slightly below one. Why? Because the function spends some time below zero. So it has to be below one a little bit. And now you bound from below this integral, but you are where am I? Sorry. Yeah, you bound it from above by where f is greater than one minus theta. is greater than one minus theta and you get uh so you get theta one minus theta plus and you have the measure of that set times delta two right and if you choose theta smaller than delta one you get a lower and bound on that okay so that's for bounding below the left hand side now i'm going to bound from above the right hand side with the point inequality so i'm just splitting the integral into three regions integral into three regions, F below zero, so F plus equals zero, F strictly between my two bounds, the intermediate region, and F above one minus theta. So that one will be zero because the gradient of F vanishes there. Now for this region, I1. Well, for this region, I'm just taking advantage that I've been working in L1 all along. So by Cauchy Spartz, I can simply extract. I can simply extract the size of the domain I'm integrating on. And observe that, yeah, the domain was just the intermediate region I was interested in. Okay, I have a control on the gradient by the energy estimate, so I get that. Now, the second term, I2, here I'm going simply to use that it's an integration only where f is greater than one minus theta. So I can for free replace grad F by replace grad F by grad of F minus 1 minus theta plus. And that is again a subsolution to my equation. So I do the energy estimate on that subsolution, which now is a function between zero and theta. So I just get a control by theta. So taking theta small, this one is an error of size theta. This one controls is bounded from above by. Is bounded from above by the measure of the set I'm interested in. So if you put the band from below of the left-hand side together with the band from above of the right-hand side, you get finally a control from below of the intermediate set. Okay, so that's why the Poincaré inequality implies the intermediate value lemma. And then that is the very standard step from the intermediate value lemma. You obtain the so-called measure to point-wise. You obtain the so-called measure to point wise. So I'll skip that unless there is a question. It's really following, it's a beautiful argument, but it's classical unless there are questions. Let me just say what it means. It means if you know that F has some negative values in this pass cube in a way that with a proportion you control, a delta proportion you control, then You control, then you will deduce that f is less, strictly less than one, call it mu in the future q. Okay, so you transform a measure condition into a pointwise estimate and you deduce it from the intermediate value Lema. So let me skip that. One small remark I like a lot. I like a lot. I mean, when I understood that, because I was very much interested in the bridges and the connections between the three approaches, the Georgi, Nash, and Moser. One thing that I found surprising is that the log is everywhere in the work of Nash and Moser. It's really crucial. In Nash, you have estimates on the integral of F log F. He looks at the feature information. Moser actually writes. Moser actually writes down the equation on the log of the solution and performs an energy estimate on it. Chriskov works entirely on the log of the solution for part of his paper. And it looks like you don't see it in the De Giorgi approach. Well, it seems to me that it's hidden in the following aspect. So if you've been, and that would that discussion, that remark would apply as well to give decase. If you follow the De Georgi method and you obtain in the The De Georgi method, and you obtain in the end a measure to pointwise estimates. So you can turn it upside down by writing it on a reformulating it on a super solution, H, and you obtain something like that. You obtain that if you have a control on the measure where the super solution is greater than M, greater than. Than m greater than delta, then you control the if, right? So you relate a measure condition like that to a point-wise condition, but I just reversed it in a way. And if you track down the constant, well, the best I could find is something like that. And if you now revert the delta gives M of delta and you write down things scannily with a pen and using the layer cake representation, you find Representation, you find that actually the measure to point wise, when you try the constant, gives you some integrability on your super solution. So that would be a sort of logarithmic Wickarnac inequality. So it's already included, if you want, in the standard second claim of the Georgi. You have a gain of integravity that is very weak. It's a log integravity. And that's why, for instance, in the Khrushchev paper, there's a lot of work to go from that very weak estimate to what you want is an estimate on the power of H. That's the real Arnach, weak Arnach inequality, a Lebesgue of H. And it is true, but the reason is that when you do this, you've used only the measure to pointwise estimate once in the cube, but if you use it at all. But if you use it at all scales, you can actually improve. You can prove the following induction, right? There's a power here on the M, and here you measure in a geometric way how this decay. And you transform your very bad sort of logarithmic Wicker NAC, you will transform it into a proper Wicker NAC by an induction argument that really uses the measure to pointwise at all scales. twice at all scale so um it's a little bit uh technically ugly but really the idea is that instead of using this so this is my measure to point wise argument uh so this idea was coming from the FTK I'm going to use I'm going to have an iteration on cubes decreasing slightly not to zero but to a final cube and I'm going to cover them with semi-cubes We stand cubes at all scales. They always come by a pair with the past and the future cube. And each time I will apply this estimate at all scale. If you do it well, you have to use the Vitani covering argument, the Lebesgue differentiation theorem. If you do it well, you can deduce that actually you don't get just a log Wikarnac, you really get the Wikarnac. Okay, so now let me spend the last 10 minutes on really. Minutes on really the Poincaré inequality. I think a good start is to show you the argument of Vasser that we started from with Jessica. So, I mean, it's a very simple argument. I don't know if it's, it might be older, might have been older than Alex's notes. So, the argument goes this way: you consider here, yeah, you. Yeah, you consider the elliptic case. And what I want to prove is that if I have a control on the measure of this set, and if I have a control on the measure of this set, then I have a control on the measure of the intermediate set. So I removed a few technical details, but it's more or less the argument. So as you can see, it's really elemental. Just for the sake of simplicity, my F tilde really. My F tilde really shrinks to a point what happens below zero and shrinks to a point what happens above one minus theta. Then I pick up a point in the set where f is negative. I pick up another point where f is greater than one minus theta. And I just write the difference of the two, which of course will be one minus theta. I connect them by adjuster line. So I've really taken it. I've already taken a point X in my sets. Everything is intersected with a cube, but that's the implicit. I don't write the cube all the time. So I take two points, I connect them by a line, I write just the Taylor formula. I bound from above because you can extend by zero. You can extend by zero, or the you know, what happens outside the cube is not too bad, you can always deal with it. So, that's why I just bounded from above by replacing the upper bound by just infinity. And now you integrate on this y that was on this set. You do a spherical change of coordinates to reconstruct the full coordinate z here. You pay a price with this singular denominator. Now, you integrate on the other variable x. Now you integrate on the other variable x that creates the product of the two measure, the measure of the two sets. And I have this integral here that is bounded. And then I obtain here the measure of the set I'm interested in. So why? Because the gradient will be zero when f is not in the intermediate region. In fact, I'm being really not optimistic. I'm really, I'm being really not optimal here. It turns out, if you look at the notes of Alexi, you can be more precise. This term, actually, X, if you track down the fact that X is integrated on that, this term gives you something a bit better, reducing the power here. But anyway, for the purpose of my explanation, it's enough to show that you can control from below the measure of this set by the other one. So the argument has just been here to take two points in the two sets, I mean, just in. Points in the two sets I'm interested in to draw a line in between and to control things in the most obvious way you can. This argument, interestingly, was, as far as I know, not done even in the parabolic case. It was only in the empty case. So now the method we do goes as follows. And then I'll talk about the problem to overcome. But what is the idea? The idea is that we want to control this, that's the We want to control this, that's the left-hand side of my Poincaré inequality. So, the first thing is to replace it by something like that, where I have squeezed here a little smooth function. So, my phi epsilon will be so the phi epsilon will have mass one. will have mass one be positive and smooth so why that because I want to be able you'll see why in a second I want to be able to integrate by part some amount of derivative in the z tilde variable and I can't do that if I'm just taking an average it corresponds to differentiating the indicator function of a box of a cube Function of a box, of a cube. Second thing, I take my two points, so Z is in the future, Z tilde is in the past, and I want to connect them. So that straight line was the one used in the elliptic case. But clearly, I don't want to do this because the difference with the elliptic case, in the elliptic case, you have all the directions in your vector field. So, here, the obvious idea is clear when you. Clear when you look at the paper of Bermonder and all the work on hypolliplicity is to build a path that will use only the allowed vector fields in the equation. So you want to construct a trajectory that uses a transport. So remember, calligraphic T is the transport operator dt plus V dot grad X and grad V. So grad V because you control it by the energy estimate and what energy estimate and why t well because now we consider a sub solution so we expect that we expect that if we do things carefully and we have integral integrals with non-negative integral we will be able to replace the transport operator by the diffusive part okay so that's what we're going to do So that's what we're going to do. For the moment, I don't draw the trajectory. Let's say we have a trajectory that combines the two vector fields. You know, we write down a Taylor formula along these trajectories, which I don't make precise here. And now I'm replacing this term from above by this one, because this is non-negative. So I'm just using the property of being a subsolution. Now, what remains to be done is to integrate by part this blue gradient. Integrate ballipad is blue gradient, and of course, there's a price to pay here. The price to pay is that my trajectory, whatever I do, will have to connect. So I have a point Z here. I have a point Z tilde. And whatever my trajectory is doing, I want to integrate by part using only Z tilde. It can't work all the way. It can't work all the way without having some problems of singularity, right? Because the Z is fixed and it is getting Z tilde, so there will be a part of my trajectory where it will go wrong. So there will be some singularity when I do that. But I don't want to use the Z variable because this is there's a positive part around that. And if I start differentiating the positive part, whatever I do, or even a modified positive part, it completely. It completely destroys the inequality I'm trying to obtain. So, yeah, so how did we solve these two problems? So, having a modification, well, we just in the first paper with Jessica, we just introduced it by brute force and we paid a small error. It turns out that having this small error for epsilon as small as you want in the Poincaré inequality, it adds an It adds annoying terms to everything I told you before, but everything still works. You can deduce the intermediate value lemma, you can deduce measures to point out, everything works. And the trajectories we want to use are the following. So essentially, with Jessica, we were doing something like, well, I will schematically present it this way, we were doing some trajectory in three lines. We were following first, doing a straight line along grade V, then a straight line along transport, then a straight line along grade V. That was, of course, enough to exploit the commutator of our mandatory between the two operators. But there was a problem of singularity in the integration by part, the blue Grand V I was talking about. And to solve it, we noised a bit the trajectory using the pass velocity viol. So that's why it became a bit more complicated. We added this. A bit more complicated. We added this to these clean three trajectories. We added a first one where with a small epsilon, where we added a bit of noise in the position with the pass velocity. And that first trajectory was, in this first paper, we seek a was controlled by this tiny bit of integral regularity. And that was created one additional eruption. So, what we do now is much cleaner the introduction. The introduction of the modification is just done at the intermediate step. So we want now we have three boxes in step two. We want to relate, we want to do a Foincar inequality between this and that, and we just include the modification in the intermediate steps. So it doesn't appear anymore as an error term. And I'm going to finish on that. The trajectories we do. Oh, by the way, I should mention thinking about Thinking about a control problem was very much inspired by analysis and techniques of Nibel and Zahr of 22. Also, we don't have the trajectories, they build for their problem, but clearly they inspired us to write down the control poll. So sorry, the notation has slightly changed because I thought I I could have time to show you the arbitrary number of arm on the commutator, but Arbitrary number of them on the computer. But the first variable with the power zero is the velocity, the second is position. There's a reason to do things this way. You start with a variable that has diffusion and you go down by solving your equations, your differential equations. So we have two, remember this gamma plus here, this gamma minus, we have two trajectories to write down. So the idea is that on the first On the first variable here, I'm going to put two control functions where I adjust the constant here and a function of the parameter s. So the time will move just as a constant times my parameter s. This zero variable, which remember is the velocity, kinetic velocity, I put some control functions on it. So why? I can put everything I want on velocity. Anything I want on velocity. Remember that on velocity I can put any control function I want because I can use the Grad V vector field. It's just one way to say I can build any trajectory I want using these two vector fields is to say, well, I impose anything I want on the velocity and then to compute all the other variables I solve the associated ODs to the transport flow, which here is just the the Newton equation. Here is just the mutiny function. So that's what I'm doing. First variable here, I put in some control functions, but I put two. That's very important. And then I obtain this one as the time integral of the zero, one. And if there was two commutators, x exponent two would be the time integral of x exponent one, and so on and so forth. My two control functions are smooth. Or smooth outside zero with the control of the derivative, well, including. So I don't know why I opened it. And well, sorry, I'll finish on that. You solve the ODEs for your control functions. Here I wrote the Vronskian of my control function. And the nice thing is that when you solve your ODEs, if the Vronskiens is invertible, you get explicitly the map that parameter. That parametrizes, so now my curves are like that. I want to parametrize this point by this one in order to do my integration by power. That's all I really need to know. And you compute it explicitly by solving these solids. It involves the Bronxian. And if you choose the two control functions as carefully chosen powers of S with two different powers, both. With two different powers, both into minus one zero, you obtain that the singularities are integrable. And I stop here, but once you've understood the structure, it's very easy to go to an arbitrary number of computer. Maybe one possible comment. So, would we would this approach adapt? This approach adapts the case where instead of having V delta X, you would have some functional V times delta X because in that case, confusion does not interact well with the V. Yeah, so your question is changing the transport operator to something like that. Yes, this would be useful for using. was the reason for using uh for using the ocean in the first place right because the um if a or b is not good uh the the um elementary solution parametric solution approach does not work yes i agree of course it does yever does work in this case so we we've not done it what what what we did which i did not include in the talk we did uh um we allow for very general linear matrix in the variables here but we did what your question is not But we did what your question is non-linear. We did not do it, but I don't see why not. As long as you have the proper geometric conditions on the A so that you can connect points, you will need certain conditions. Yes, yes. I think is that A is not going to concentrate on hyperplanes. Yeah, I I would I think it's probably something to try. It can be as non-smooth as broad as you want. Non-smooth as well as you want. Actually, your question makes me think to something else. I mean, related to a discussion we had two days ago. Interestingly, the part on the Poincaré inequality, I don't think we need to check, but I think could work possibly. It's not related to ellipticity, even if there was an operator in the kinetic variable that would jump, for instance. But of course, the rest of the Georgia theory uses it, but not that part. I mean, it's a bit connected to. I mean it's connected to going to modernity questions. When you go through the argument of the Georgia, how much that what you're doing differs from the work that Alexis did with Louise on the question of argument or choice? Because there is a sort of transport there, right? And you have to compensate the fact that you have a gradient of the solution with the light at something like this. Is it the same as the was it just last year? I mean, do you take some case from there, or what is different from that? It's just the additional. I don't know if it's the same or not because I don't know enough for this paper. Yeah, if you have a term that is proportional to the gradient of the solution in this, but you don't have the Hamiltonian structure that means it in any theory that makes it not which tell me you have to. Which time you have to know the gradient? So, yeah, is it impossible to scale? Yeah, yeah, yeah. Which time you say gradient term and y, because it is a gradient in Y and then like a diffusion region. But what you don't have is the Hamiltonian dynamics, the fact that you integrate another extra variable. I think so, the difficulty here, the difference here. The difficulty here, the difference here is because the trans or being halutonic. Yes, I mean, in that case, yeah. I don't know if it's difficult or not, but that's what the part we... So if that is the case, what happens if A of B would be the function that corresponds to the gradient of the relativistic correction? Because that would give you even bounded moments. So that's a very good question. It's related to the question of. A very good question. It's related to the question of transfer. We actually looked at it pretty carefully. We have not decided to not include it in the print we are finishing because it's way too long. But I would expect that the relativistic structure would work as well. It might be better, but I would expect this work for it as well. It's just much more complicated because the ODs are not as clean at all. So it's messy. And I see. Okay, so I propose maybe that we postpone other questions to our first session. Thanks a lot.