I want to start off with an observation I think that most of us can agree with that it has been a stressful couple of years over the last little bit. It's been we've dealt with pandemics, war, any number of issues that have undoubtedly impacted us in ways that we still don't fully know yet and on which the science is being done. But in terms of the actual But in terms of the actual stress component, that's what I'm here to talk about today. And in a series of experiments performed by J.D. Baines' group, we've managed to kind of tease out what happens to some of these stress circuits. So I'm going to be talking about the hypothalamic pituitary adrenal axis and specifically, you know, its response to stress, and more specifically, the neural component. So the neural component consists of these CRH-PVN neurons. Of these CRH-PVN neurons. So they're corticotropic releasing hormone neurons within the paraventricular nucleus. These neurons are critical to kicking off the body's stress response. So what happens is they release CRH, and that triggers cells in the pituitary gland to release adrenocorticotropic hormone into essentially the blood circulation. And from there, ACTH activates cells in the adrenal gland. Cells in the adrenal gland, and that kicks off kind of the entire body's stress response. So, you know, the neural component, the final neural controller of this, are these CRH neurons in the paraventricular nucleus. We're going to ask how does the neural components actually adapt to acute and chronic stress? And more specifically, in the experiments that I'll show you, it's really kind of an acute stress that's been induced by the experimenter. So, we're going to ask, So, we're going to ask how does the HPA axis actually evolve, right, for acute stress? And so, again, this work was done experimentally by the lab of J.D. Baines. So it's called the Stress Genomics Lab. Most of the experiments were done. Can everyone see my mouse okay? Yeah, I think we're going. So most of these experiments were performed by Tamash, who's been doing a fantastic set of recordings over the last year. A fantastic set of recordings over the last couple of years. And, you know, while you've seen many of my lab members talk, a lot of this work on stress is primarily my own at the circuit level, whereas Evanson was actually modeling CRH neurons dynamics with particle swarm optimization, if you recall his talk on Thursday. So, all right, let's see what we've done here. And to emulate stress in an animal, we're using a mouse. And for the A mouse. And for these mice, we've got a couple of experiments. We've got a control set of experiments where we take the mouse, and all we do is we take the mouse from its home cage, we put it into a novel environment, and then we just return it to its home cage. So we haven't really done anything to the mouse. We've just moved it into a novel context. And this doesn't emulate stress per se, but it provides us with the control experiments we need to build the context into this. To build context into this. So then we have a series of experiments that we've run where we've taken the mice, we've moved them into this novel environment, and we administer a series of foot shocks and then return the animal back into its home cage. Now, as we'll see, there's going to be activity states that are associated with just moving the mouse into the null environment, which we term the upstate. Okay. And the idea is we're going to. And the idea is: we're going to look at both of these recordings, and we're going to look at the animal's reintroduction into the novel environment on subsequent days after foot shocks have been administered or after this original control experiment. And we're going to determine to what extent these CRH neurons are changing. And the way we're going to do that is with a series of recordings that we conduct while we're doing all of this with mini-scopes. And again, this is Tamash doing this. Is this Tamash doing this? So, if you have any questions in regards to the data collection, you're better off asking Tamash and Jdeep than myself. I am the modeler on this, so I will claim the modeler's ignorance in terms of how any of this stuff is done. From my understanding, they shine a laser onto the cells, the laser fluoresce with a calcium indicator. And so we're really monitoring its calcium levels. And what we've also done is we've created a tracking. Done is we've created a tracking algorithm that can determine which cells we can consistently track longitudinally across four days with these mini-scope recordings. So we can really determine on a cell-to-cell basis how the dynamics of the cell changes. So here are the recordings, and we've pooled this across four animals, where on average we get, you know, about 20 to 30 cells per animal, where we've got the neurons in the home gauge. And this is, these are the kinds of things. Home cage, and this is that these are the controls. Remember, so we're not doing anything in the animal except removing it. We put the animal into the novel environment, and you can see from the calcium indicator, the cells are firing at a higher level. And then when we return the animal to the home cage, we return to this baseline. So, what I've done also is taken something akin to like a photometry signal, or if you want to be very loose, an LFP where I averaged the LFP where I average the calcium across all of these cells, and we can tell: okay, there's a low level of calcium firing in the home cage, taking the animal to the novel environment increases firing, and we get this upstate, which is what we call it. My apologies to anyone working in cortical dynamics. This is not like a cortical upstate. We're probably going to have to change the notation as a result of probably referee criticisms on this point. On this point, but we have unfortunately used the upstate terminology here. So we've got the upstate, and then we return the animal, and everyone just goes back to normal. So there's no placidity here, at least from the looks of it, just by change moving the animal to the novel environment. And in fact, we can reproduce this experiment on multiple days where we don't administer any stressor. And what we see is basically the same levels of activity on day one, day two, day three, day four. And these cells are again tracked. And these cells are again tracked longitudinally, and the correlations are very high from a cell-to-cell basis, not just at the average level. So, from a cell-to-cell basis, I think we've got a correlation coefficient of like 0.7 from day to day for their activity levels. So, there's no real change in the cellular activity. And just moving the animal into a novel environment or a new context is not enough to induce any plasticity. To induce any plasticity, so we've just got this upstate that's fairly stable. Now, what we can do is we can take these animals and do the same experiment, but move them into the novel environment. So take them from the home cage to the novel environment and administer a series of foot shocks. And you can see that the cells themselves respond to the foot shocks by looking at the cell-to-cell recording and looking at the actual. And looking at the actual time average calcium, these little, I don't want to call them spikelets because that's misrepresenting what it is, but these little sharp changes in activity are because we've administered 10 foot shocks with 30 seconds in between foot shocks. So they're fairly regular foot shocks and the neurons themselves actually encode the foot shock somehow as a rapid change in activity. I asked Jadeep and Tomash to confirm this too. It's not And Tomash to confirm this too. It's not something where the current in the foot shock is somehow making its way into the recording. It is actually like the neuron responding to the stressor and that responds, changing the calcium level and causing, you know, just observe it. And when we take the animal then one day after back into that novel environment, a lot of the cells have actually increased their firing activity as indicated. Increase their firing activity as indicated by this calcium, and on the average. And we can do this for day one, day two, day three, where we see consistent changes. So something has consistently changed about the substate. It's increased, at least just at the level of the average calcium. We can see that there's an increase. So we've induced some type of plasticity in this circuit just by exposing it to a stressor. And as a result, everyone increases. And as a result, everyone increases their firing activity more. And because these are CRH neurons, what that means is we typically have a higher CRH response. So more CRH has been released, triggering the release of more ACTH and triggering potentially a stronger hypothalamic pituitary adrenal axis response or a stronger endocrine response, if you will. So, what we did is we took this data now. What we did is we took this data now and we pooled it into just a basic principal component analysis. And as you can see, we have the home state, sorry, the home cage, which we have activity kind of fluctuating around this region. We have this upstate. And then we have a series of foot shocks, which are trajectories that look a lot like homoclinic trajectories actually in the state space, leaving from the upstate and returning back to it. And what we can do then is. What we can do then is look at the subsequent days increase in the upstate. And in principal component space, again, the reason why we can do this is we're tracking all the cells longitudinally. So we have a fairly consistent response from the cells, except for plasticity inductions. And we can pool all of our data and create a pooled data principal component analysis. And if we take a look at the centroid of the home case of the upstate before the foot shocks and the upstate after. Shocks and the upstate after the foot shocks, one day after, we can draw a vector, and that vector is fairly co-linear with the direction of the foot shocks. That in itself is kind of an interesting finding, but it says that, you know, this change in the upstate is maybe somehow guided by the foot shock, where the foot shock is maybe acting as like a pointer or a supervisor in space to move this entire cloud of activity. So we started digging into the data more. Digging into the data more now that we have all of these cells aligned in time and we know that there's some change, and we have the principal component as a kind of course as a large-scale image of everything. So, we started looking into the data more to determine what was actually impacting plasticity. So, it turns out there are two factors that determine the increase in a neuron's response when we re-exposed it to the novel environment. And the first factor is the initial weakness. Is the initial weakness of the response of that CRH neuron's response to the novel environment? So the neuron itself did not participate strongly in the initial upstate before a foot shock. It was recruited very strongly into the subsequent day's foot shock. Sorry, the subsequent day's upstate. And the second component is how strongly the neuron responded to the foot shock. So we've got two factors here that we Two factors here that we observed experimentally, and I'll dig into the data a bit more as to what these two factors mean. Right? So if we take a look at these CRH neurons, most of the neurons actually increase their firing rates, but it turns out the CRH neurons with the weakest response to the novel environment, so the weakest upstate response, tended to increase more. So what does that mean? Well, we can take a look at the calcium signals. The calcium signals for some of the cells. My apologies, by the way, for these FSI plus one day. We were debating as to what to actually name the upstate. And this doesn't actually mean foot shock in the context of this graph. We think of this as just the upstate response. So, in the first thing before the foot shocks, these neurons had weak upstate responses, and we brought Upstate responses, and we brought them back into the cage, into the novel environment after one day, and they had much stronger upstate responses. Whereas the ones that had strong upstate responses before the foot shock, they didn't change much. And we can kind of look at the data in what are called actually turtiles. And this was the first time I've ever seen data divided into thirds. This was Tamash, I think, is doing. I think it is doing, where we looked at it in thirds, and we had basically the weakest third had the biggest increase in their upstate response. Third had a more moderate increase in their upstate response. And the top third had a smaller increase in their upstate response. And all the three thirds went to roughly the same level. And this turns out not to be statistically different between the three. Different between the three, but we had some big increases in the weaker ones. So the weaker a cell responded to the initial upstate, it seems like the stronger it got recruited into the next upstate. So it's almost like there's a ceiling effect happening here amongst all the neurons. So what we did then is we analyzed the data with regards to that previous observation. We knew that there was some Was some ceiling effect happening. So we sorted the neurons according to increased activity in the novel environment. So we had the neurons, you know, previously we had sorted them in. So we just went with a continuum sort where we had them sorted from weakest to strongest. And then we correlated the change in the upstate to the foot shock response. To the foot shock response. And it turns out that the neurons that had the, you know, the neurons that had weaker and weaker responses to the upstate on the initial exposure, they changed a lot, but that change was in proportion to how strongly they responded to the foot shock. So what we're seeing here is a bit of a non-linear interaction. And I'll show how that non-linear interaction translates into a learning rule. Learning rule. So essentially, the neurons that had weak upstates and had a strong response to a foot shock had a strong increase in their upstate response on the second day. And you can see this with a raw correlation coefficient where we sort the neurons according to activity in the novel environment. And also, if we plot out the difference in the neurons response from the novel environment on the subsequent day. Environment on the subsequent day to the original day to the foot shock. So there was a bit of a non-linear response here, and I'll show you how that translates into a learning rule. Because what we did was we took these two observations and we constructed a very simple feed-forward network with some CRH model neurons. And these are just basically leaky integrating fire neurons. And what they have is a series of context inputs modulated by a weight matrix, weight like vector for each neuron and a weight matrix for the entire network. Matrix for the entire network. So, this acts like a simple feed-forward network, and we can induce a foot shock by providing a signal, a foot shock signal, which triggers a diversity of firing responses amongst these cells, depending on what the foot shock weight is. And with these cells, there's kind of a synthetic calcium signal that we have, and we're going to define a calcium threshold to actually induce plasticity. So, you saw in our previous observation, there were In our previous observation, there were two factors that determined how much a cell changed its firing activity on the subsequent day. So we went with actually a two-factor rule in terms of updating the input weights to each neuron. So the first weight term, the first sorry, plasticity term is a recruitment term, where if a neuron has a small weight sum, Weight sum, then there's a kind of a ceiling term here, omega. And the smaller the weight sum is, the larger this recruitment becomes until you kind of eventually saturate at omega. So that mimicked a lot of what we were seeing in terms of the recruitment of weaker neurons more strongly than stronger neurons. So we've got this recruitment term here that dictates the weight change, and then we've got a plasticity gate where if the calcium is over. Where, if the calcium is over a threshold, this plasticity gate comes online to actually trigger plasticity in an amount in proportion to the calcium itself. So these are all terms that a cell, a CRH neuron, actually has access to. It presumably has access to somehow its internal sum of its weights, and it has access to its own calcium. And the threshold is kind of just a globally set threshold. Right? And the idea is a foot shock can induce plasticity with these. Plasticity with these two terms because these two terms were phenomenologically actually describing what we were seeing out of the observations. And so we can simulate this network of CRH neurons, synthetic CRH neurons, and we have the upstate, we can induce the foot shocks, and then we have the upstate on day one. And we can see increases in the activity and increases in the average. But critically, what we also see is the principal components matching exactly what we expect. Matching exactly what we expect from the data. So, this simple rule is actually sufficient to explain the entire network's behavior. So, we've got the home cage, the upstate, the change in the upstate, and then the foot shocks. And the foot shocks end up being roughly co-linear to the direction of the change in the upstate, which is exactly what we expected, which is exactly what we observed in the data. So, from just the simple So from just the simple kind of weight change model that was empirically derived, we basically get the network level behaviors of this entire circuit. Now, what I want to do is think about what the circuit's actually doing. So when we look at this principal component analysis results in our model or in our data, it's clear that there's some kind of supervised learning scheme going on here where the foot shock acts as like maybe some hint as to how. Some hint as to how the network should change its output. But it's also, you know, there are separation boundaries that you can easily draw in the real data or in the model. And those separation boundaries can be thought of as basically defining discrete classes where the network responds in different ways, and you can uniquely decode out either threat or no threat, or novelty, or no novelty. And so we thought about this in terms of how a person. So, we thought about this in terms of how a perceptron might actually work. So, the perceptron learning rule is actually a simple learning rule that's used to classify inputs into a set of discrete states. So, what does that mean? For every input pattern x, there's a desired class D. And that could just be like a discrete integer defining a class or a binary classification. It doesn't really matter. There's a set of weights and a neural response function. And if your weight update If your weight update evolves according to the perceptron learning rule, then the network will start outputting D every time X comes in. So, this is a supervised learning. And so, we started looking at the learning rule we got empirically and the perceptron learning rule. And our two-factor rule here for updating it is somewhat similar to actually the perceptron learning rule if you make a couple of assumptions. The first assumption is that the neural response function is linear. Response function is linear, and the second assumption is that the inputs to the perceptron are binary, and you obtain a kind of rough equivalence between the two. This isn't quite the case because the calcium indicator is postsynaptic. The neuron has calcium. We don't have access necessarily to what the pattern of activity was that induced the foot shock presynaptically. But what we do have is the scalar term that acts a little bit like a ceiling, and then we have some. And then we have some other term across the network that acts as like a pointing vector. So, if we think about this in pattern space, then if this is a classification, we've got the home cage and the novel environment, and maybe there's a decision boundary that determines no threat and potential threat. And when we induce a foot shock, that decision boundary gets changed so that this novel environment is now on the potential threat side rather than the no threat side, and the network response to that is changed. Network response to that has changed. So, what happens in principal component space, which is kind of like the output, we can see basically how the output changes because of the network's new responses to the patterns. And so what we have is we've got the home cage, the novel environment in the home cage. And we can take a look at what happens in principal component space just to kind of show that the patterns are differently responsive. Are differently responsive. We've got like small to no change, or even like an orthogonal change in the home cage response in principal component space, and we've got a big change in the novel environments response indicating threat. So the change on subsequent days because of the home cage is kind of orthogonal, actually, in action of the novel environments. So we've, you know, it's not like every firing pattern has changed. Changed. It's basically kind of classifying the novel environment now as more threatening, whereas the home cage has changed in kind of an orthogonal direction. And in fact, the firing patterns on subsequent days for the home cage don't change so much. So we think that, you know, well, what we've seen empirically is that CRH neurons, they change their activity when you place an animal in an all-bone environment. That was just the basic upstate. That increases plastic, though. And if you And if you stress an animal out after you've moved it to a novel environment, it responds on subsequent exposures to that novel environment with even more firing. That plasticity might be mediated by a perceptron-like two-factor learning rule or possibly another supervised learning rule. But a simple two-factor rule, actually enough to explain what we're seeing in principal component space as well as the neurons empirical changes. The neurons' empirical changes from day to day. So, we want to run some new experiments now that Tamash is actually currently running, and we want to see if these CRH neurons respond in novel environments with stress or without stress in the same mice. So what do I mean? If this is a classification task, if we have, you know, the mice I showed you in the control experiment and in the foot shock experiment were actually different mice. But if we take the same mouse and we do the same experiment, We do the same experiment where we have a mouse and we have novel environment one and novel environment two, and a novel environment one, we give a foot shock. Are the upstates in novel environment one and two both increased, or is it only novel environment one? If it isn't, then if it's sorry, if it's only novel environment one, where we've given the foot shock in the same mouse, then that strongly indicates that first it's it's probably some kind of classification task being done by these cells. Task being by these cells, and second, they can actually discriminate between environments where stressors were exposed in the past or not. There's already some indicator that this is probably going to happen just with the home cage experiments, right? The second experiment we want to run is we want to see if the response to stressors is graded or it's in discrete classes. If this really is a classification task, then we should see kind of discrete classes. One foot shock is going to have. Discrete classes. One foot shock is going to have the same effect as 10 foot shocks or 20 foot shocks. So we're going to do another experiment where we might stagger these foot shocks on like day one and day two, or we just do one foot shock and then another foot shock on a second day. And we'll see if the increase in the upstate is completely discretized. Everyone hits that same ceiling, or if maybe it's not a ceiling, like they don't hit the ceiling immediately, it's a graded response. Immediately. It's a graded response, in which case it might not be class per se, it might be more of a continuum of responses. And with that, I want to thank all of you for attending. My apologies again for not being able to attend in person. Here are all of my lab members. Many of you have met them over the last couple of days. And JDP and specifically Tamash for doing a lot of these cool experiments and all the funders. Thank you. So we have time for a few questions. Maybe I will start. Wilta, can you hear me? Yep. Or Berlin. Okay, yeah, when you were defining the principal component and space for this data set, how much of the data were you using? Was it only like on the complicated part of the data or actually? Complicated part of the data or everything together? Everything together. So we pooled across animals and like neurons because we can track them across days. So the way I created kind of the principal component vector is I so I had day one, day two, day three, day four for cell one, cell two, cell three, cell N, and you just run principal component analysis on the entire thing, and then just plot out the subsets corresponding to different dates. The subsets corresponding to different days to see how the dynamics move. I was wondering if the major components that you found would change in the structure across days rather than just the magnitude itself. What do you mean? That if you were, for example, to define the principal components only with the home case data, and then you checked or tried to define them again for subsequent days, if they wouldn't. One day, do you think it wouldn't be as fun at all? It's possible. We never tried, but as long as we're kind of consistent in how we do it in the modeling and in the experimental data, we can essentially empirically explain our observations with this two-factor rule. That's my hunch anyway. But we haven't defined the principal components in a different way, like defining it just on, like taking one axis to be like the novelty axis, right? Novelty axis, right? Or specifying the axes in different ways. We just went with the simplest analysis where we just created these long vectors and then ran principal component analysis on it. So when you made a case that in the experiment, the response to the foot shocks was indirect to what you measured in the neurons. In your model, how did you set up the foot shocks in your model? Because I guess they're. Foot shocks on your model because I guess there is a direct effect on you. There's a Gaussian phenomenological thing that represents the foot shock. And so it's kind of just a Gaussian current that we feed into the cells that shifts the calcium over thresholds. So the cells increase their firing activity when this thing happens, and that triggers the actual increase in catalog. You know, increase in calcium. We don't like to model how the foot shock does it, it's purely kind of phenomenological that captures a lot of the changes in calcium. All right, thank you. Any other questions online? Now let's thank Wilton again for the talk and thank you for attending online. 