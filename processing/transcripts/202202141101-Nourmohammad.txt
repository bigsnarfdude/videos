Okay, well thanks everyone for being here. And for everyone who is on Zoom, some off time zones, sorry for keeping me up. Yes, I'm going to talk about it. Yeah, you have to unmute it. Do you hear me? Okay, great. Um yeah, so Um yeah, so I'm gonna sort of talk about also very theoretical work and um have as an organizer you have the sort of ability to p organize talks so that your the previous talk is a sort of introduction to your talk. So that's great. Thanks Theory. But so I'm gonna start basically telling you a little bit what what my lab does. Uh we're interested in sort of bridging the statistical physics ideas in evolutionary processes and more recently well And more recently, well, many years, we've gotten interested in adaptive immunity and thinking about that in the context of evolution. So, various sort of facets of this problem, we're interested in the organization on encoding an immune system, sort of to understand the system, immune pathogen co-evolution, predicting the co-evolutionary processes, and now more recently looking at control approaches, how to sort of leverage our knowledge to control pathogen and to curb pathogenic evolution. Evolution. So we do both modeling and data-driven approaches. On the modeling side, they're interested in sulfate decision-making, something more recently we've gotten into that. The image on the video seems to be flip to zoom. I see how many degrees? Like, just mirror. It's correct for yours. No. Something like mine is like 40 shit. Yeah, it's okay online too. Oh, yeah. Okay. That's very interesting. That's even more interesting. Alright. Yeah, stochasticity at play. Alright, so stochastic cell-weight decision-making, that's one of the things of memory and a factor cell decision making and something I sort of touch upon a little bit today. And so on the data-driven side, we're building machine learning and statistical inference. Learning and statistical inference approaches take structure information, sequence repertoire information to characterize something like a later representation for a mere shape space. Gotten into sort of co-evolutionary processes and sort of host pathogen co-evolution and sort of building theoretical ideas of how different strategies come about. So something along the lines that Terry was talking about. And also looking at immune repertoires, both B-cells and T-s. Repertoires, both B cells and T cell repertoires in the context of sort of infections, chronic infections like HIV, and acute infections like influenza and SARS-CoV-2. And the control side, sort of building models of adaptive control for evolutionary processes, so it's our stochastic control approaches. So in this context on top, you have both pink and white cows, and then natural selection, you sort of would select white cows. Would select white cows, but the goal is to sort of implement artificial selection that you would be able to monitor population and add the feedback to drive evolution towards selecting pink cows. Now, substitute your pink and white cows to whatever system you're interested in. And so using these controlled approaches, sort of in the therapy, so building, broadly neutralizing antibody therapy as substitutes for antiretroviral therapy these days to curb HIV. Days to care about HIV escape. But as a math seminar setup, so I'm going to talk about a more theoretical work today, but happy to talk to anyone who's interested in any of the other topics. So I'm going to talk about immune memory or general memory strategies in biological system with some focus on immune system. Before I start, so the work was led by Oscar Struck, who is a PhD. Oscar Strak, who was a PhD student in my group and just graduated recently. And part of the work was in collaboration with Luca Politi. Alright. So memory is ubiquitous in biology. So the most common thing when you talk to someone on the street, they think about cortical memory, so your brain, but we have immune memory, we have memory in biological networks, right? Protein allostery is also some sort of memory in the system that you can remember. System that you can remember basically interactions with ligands. And inspired by biological memory, we are now sort of all of us basically use machine learning and artificial neural networks that use memory to better do computations. On the surface, they all sound like memory, but they use very different strategies to encode it. And so one of the questions we had was that why are these strategies, different strategies used in the immune system? In the immune system. And these are the sort of why questions that in biology may be a bit frowned upon. But so I'm going to sort of give you a bunch of speculations and the ways we've built the models and to think about the system. But well, take it with a grain of salt or take it seriously and I'd be happy to put that. So I'm going to sort of simplify two very complex systems for you. Depending on your screen, on the left or right hand side. On the left or right-hand side, you see olfactory cortex. So that's basically you smell something and you get some signals to your brain. Actually, there's a direct connection between your nose and your olfactory cortex, which is unique in some ways. And so the sort of memory of this smell that is in your brain is sort of distributed, is sort of stored in a distributed fashion, and it's an associative memory, so you can. Memory, so you can smell red wine and remember something about a sunset that you had a red wine in, or something like that, cookies, and your grandmother. So, that's a sort of olfactory cortex in simple form. On the other hand, the sort of memory that we are all maybe more familiar with is the immune memory. And in contrast, so there are many sort of biological differences between the two, but something that is unique and sort of interesting to me is that immune memory is stored. That immune memory is stored more in a compartmentalized or specialized form. So, as opposed to this distributed fashion, if you have a memory against influenza, that memory is completely useless against SARS-CoV-2, most cases. We know this particular example quite well. And so maybe your immune memory receptors are good against some variants of influenza, but they're not going to go out of their way dealing with other pathogens. So, the questions we had. So the questions we had was why do we have these sort of different structures of the memory? And our hypothesis was maybe evolution of pathogens may be the key for different encoding strategies. And I try to convince you about that or sort of give you some evidence for that. That's why it could be true. So what do I mean by evolution? So if you look at antigenic space and older space, so some shape space of the two, over time, long evolution. Over time, long evolutionary time scales, or time scales within a, well, time scales relevant for an organism, what you see is that there is fluctuations in both space, but in the antigenic space, you actually get some directions, and you get the antigenic divergence as opposed to other space. And there is data that supports this. Here, we are looking at evolving pathogens, as Tieri showed, more or less similar plot. H3N2, influenza, antigenic divergence. Influenza antigenic divergence. So, this is a multi-dimensional scaling map, and you see a sort of direction in one of the dimensions and this antigenic space as how the virus evolves. Whereas in the other space, sort of a PCA projection of different odors, you see sort of a breadth of different odors, but there's no directionality in that over time. Okay, so this was our hypothesis as So this was our hypothesis as maybe evolution is playing a role as what strategy we use. We wanted to use a simple model that has nothing to do with biology but is tractable. And well there's a celebrated model of memory storage and it's Hopfield model. It's also one of the models that start as the current neural networks that we're using. So it's inspired by neural network but I'll sort of modify it in a way. But I'll sort of modify it in a way that it could, in some ways, be interpreted as something relevant for immunology as well. And a Hopfield network, basically, what you do is you show the network patterns, and these are binary patterns, plus ones and minus ones. You can show n of these patterns. They can be orthogonal to each other, meaning they're sort of a little overlap with each other. And you sort of show the network, and the network stores a memory of these patterns in the network JIJs. The network JIJs in sort of the connections, and these connections were to resemble synapses in our nervous system. And what happens is that, as you show the network, the memory of these patterns are stored in an energy landscape, and particularly in the minima of these energy landscapes. Now, it is associative memory, and that means that if I so we can think about each of these minima as a tractor for a specific pattern. For a specific pattern. Now, if you show a little bit, so a pattern is a bit different, so maybe some spins flip, some errors, you can still fall by equilibration fall into these minima. And so find the original attractor and retrieve it. So this network is pretty effective in retrieving. So once you're below capacity and you can characterize what the capacity is, you can very well retrieve these patterns. Retrieve these patterns, and these are sort of static patterns, but many different versions of different patterns. Now, we wanted to add evolution to it, and the simplest way of adding evolution was just as you're showing patterns on the background you mutate these spins. So, you sort of flip it, but some mutation rate mu. And so, some calculations later, what we saw was you can optimize the network and your retrieval and learning as much as you can, but Much as you can, but what you end up doing is that there's quite a bit of misclassification in the patterns and retrieve. And we sort of dig into it and we found that this misclassification happens, well, in some ways, memory is lagging behind evolution. That's the smaller part, sort of not the most significant reason that is misclassifying. The reason that it's mainly misclassifying is that as we are trying to learn optimally the evolving pattern. Optimally, the evolving patterns, we need to increase the learning rate to follow evolution. And as we learn learn increase learning rate, we are distorting the energy landscape and building this narrow mountain passes in the energy landscape, which means that I show a pattern here and during equilibration, it can just equilibrate through the energy, through the sort of mountain pass and fall in the different minimum. So that results in significant misclassification. Significant misclassification and distortion of these sort of energy landscapes. So, to remedy the problem, we thought: okay, we can sort of separate the minima from each other and compartmentalize our network. So, this sort of learning and retrieval process would be now two-step. First, you find the compartment you're associated with, and then equilibrate within that compartment. And so, these two sort of formulas I put down. The sort of formulas I put down is these two sort of temperatures that are associated with finding the right compartment and then falling in the right minimum. So beta s is inverse temperature associated with finding compartment. So you can think about it as sort of accuracy of compartment finding, and the other one is accuracy of finding the right minimum. Now you can then try to vary the number of compartments, so the red would be. So, the red would be when your number of compartments equal to the number of patents, and see how your performance changes. And what we see is that for evolving patterns, that's the number on the x-axis, as you increase evolutionary rate, basically only one-to-one networks, so the ones that you have one compartment per pattern class, is the only one that could actually retrieve the memory accurately. And distributed networks fail to do anything useful. Useful. And so you can characterize the phase diagram for this, and what we see is for evolving patterns, you basically have a performance of the network that in the regime that you accurately find the compartment accurately equilibrate in the minimum, you find accurate memory, and that can be only achieved in a strategy that is a one-to-one specialized. And this is actually a pretty sharp transition, meaning that Transition, meaning that there is a separation between distributed network for static. Well, that's the next slide. So, going back to the first story, so thinking about smells, smalls can vary, but other molecules are static, they don't really evolve. And so, if you were to use distributed network, it's pretty efficient to actually retrieve those. Whereas for evolving pathogens, your epitopes are evolving. And we speculate that's why we're using compartmentalizer, very special. Using compartmentalized or very specialized memory setup. So, this was sort of the first big picture story of this talk, but what I'm going to do is now I'm going to go deeper a little bit into immune memory. And this part of the talk is more in the spirit of what Thierry was talking about and trying to think about immune decision-making or memory storage in the immune system in light of a co-evolution with pathogens. So we all So we all know memory, V cells and T cells both are very useful. And one of the two features of memory versus a novel response is that memory is faster and it proliferates much more efficiently and also more rapidly. So if you sort of put numbers together for the novel response to reach a level that is comparable to a corresponding memory response, it takes about two to five days to do so. About two to five days to do so. So, that you can think about as effective time delay between the two. So, that's on the kinetics of memory response. And the energetics of memory response, also as Thierry mentioned, during affinity maturation, we produce these cells with different receptors, and cells receptors become specialized. So, in the antigenic space or in the shape space, they become more and more specialized and less cross-reactive, so to speak, as you go. Cross-reactive, so to speak, as you go down, but somewhere down the line, you sort of produce memory response, memory cells, or select cells for memory. And on average, memory has lower affinity compared to plasma cells. And so there were two hypotheses. The first one was the more running hypothesis up to some point until we had more experiments. And one was basically the first hypothesis is there's strongest selection on what can become plasma. What can become plasma? So you select for higher affinity cells to become plasma, which means on average, but there's not much selection on memory cells. So on average, they have a lower affinity because they can be produced at any time. Second hypothesis, which is more recent, is when there's actually active regulation to make sure that memory cells are of lower affinity. And there are now transcription factors that are identified that are involved to make sure memory is of low affinity. There's something similar in T cells, but not. Similar in T cells, but not quite like that, and that would be effective versus central membrane T cells. But I'll focus on B cells because it's easier to talk about mutations in this context. Okay, so the question that we had was that can we understand these immunostrategies sort of in light of evolution? And this is the picture we have. You get infected with an antigen for the first time. There's no memory in there. You have affinity maturation. You have affinity maturation, maybe one or two weeks of sickness, you produce plasma, and sometime along the line, or you can produce some memory. Now, you can take this memory, so you get reinfected one, two years later, you have a memory, so you have options now. You can choose between using the existing memory that may be a bit off-centered from the new infection, or you can also mount a novel response, one or two weeks of sickness. Response, one or two weeks of sickness, and again you get a very centered memory against the thing you have written down. And so you don't do it for one or two years, but rather you do it for your whole lifetime. And one thing you want to optimize is you want to minimize the harm that incurred on an individual or the organism when facing an evolving pathogen. So this is a very similar optimization criteria that Thierry was talking about, and I'm going to formulate it a little bit differently. Okay. So the trade-off that we are putting in our model, so you need to put a trade-off somewhere, and the trade-off we are putting here is coming from a structural flexibility of receptors. So if you start from a naive receptor, they tend to be structurally flexible. So that means that they can bind to different things. And as they undergo affinity maturation, the mutations tend to make them more rigid and more. Rigid and more specific. So that can be by building salt bridges and in the structure and so on. So first of all, this is sort of not true for all antibodies, but for a lot of them. There is no sort of well-characterized trade-off function between affinity and cross reactivity, and this exact form of this function is not that important for our purposes, but the only thing we care about is that there should be a a trade off between the two. Trade-off between the two. So that's the only assumption basically. And we go back to the shape space. And so the characterization that we have is that we define a specificity factor alpha. So in the shape space, here we look at the affinity of an antibody against a specific antigen, and so you're maybe centered against that antigen with some maximum affinity and some spread, which is the cross-reactivity. Spread, which is the cross-reactivity. And so one over that cross-reactivity, we call it specificity. Now you get reinfected with slight variant of that antigen, an antigenic distance delta. So you can mount a memory response, which would be a slightly lower affinity on this curve. So that would be from the previous infection. Or a novel response that would be centered around a new pathogen and will have a high. And will have a higher affinity once you store the memory. So there's some sub-optimality delta E in the affinity you can achieve. We also can characterize the probability of memory response and to a larger extent depends on the time, this is what we call deliberation time, that two to five days. So if you let immune system, so let's say that time is a tunable quantity. If you let the immune system have infinite time before it mounts a novel response, you always use the A novel response. You always use the memory, right? But if you shorten the time, then you give a memory a lower chance before the novel response kicks in. And so if you have a longer deliberation, higher chance of memory response, but it comes, if memory fails, it comes at the cost that pathogens are growing in the individual and they cause harm. So it comes with a sort of a naive cost of response, which we call it, oh my god. Call it omega. So these are the factors that go in: the deliberation factor or this deliberation time. So we have a finite time to make a decision, and the sub-optimality of response if we were to use that memory. So putting all these things together, we can formulate this as a sort of decision-making process. So decision-making, theory of decision-making goes back to von Neumann when he was doing game theory for gambling. Doing game theory for gambling. But that was in the context of sort of equilibrium decision making. We are talking about non-equilibrium decision making because we have finite time and we have this evolving target that is moving. So we can formulate this and at each step you have a chance basically to update your memory. So that would be exploration by mounting a novel response. Or you have a chance to use existing memory, so exploitation of what you already have. Of what you already have. And that gives you sort of an update rule for your memory, and you can quantify what would be similar to the utility of memory, so the difference in the affinity. And so you want to maximize basically your utility while minimizing the amount of updates you need to do in the memory response. And that update sort of cause, we call it, dissipation. And so that gives you this net utility function. Utility function that is basically similar to statistical physics extracted work in a system in a non-equilibrium system, which you want to maximize. And with that optimization, you get a optimal specificity in a given setup and optimal deliberation time, so waiting time for a naive response to kick in. Okay, so similar to what Tieri discussed, we are going to use this for different We are going to use this for different scenarios of pathogenic evolution. So, if I let antigens evolve at certain rates, higher or lower rate, I'm going to get different answers. And I'm plotting here memory utility, so that net utility function in the background, and what comes out as a specificity function and deliberation. And what we see is that the functions depend on anticipation of pathogenic evolution, and similar as we caught before, we also get three. Similar as before, we also get three phases of memory storage. One being, so if antigens evolve very fast, right, you basically don't use, memory is completely useless, so you only use a naive response or a novel response. If antigens evolve very moderately or very slowly, you can have two different types of memory. One I will call equilibrium memory, which is basically always centered. If antigens don't evolve, you always have a perfect memory, and that's great. Perfect memory, and that's great. But if they, well, you still can use a memory, and that comes basically you're talking about speed affinity trade-off in that case. So if you're in some sort of optimal regime that speed is better than having an optimal affinity, then you use this non-equilibrium or dissipative memory response, which is probably what most of us are using. So, but pathogens, we're dealing with the media. So what pathogens? We're dealing with a whole range of pathogens from chickenpox to influenza with different evolutionary rates. How do we tune beforehand we don't know which type of pathogen we are getting infected with, so how do we sort of tune our system? So the theory, what it predicts is that if I show sort of a uniform distribution of antigenic evolution into our immune system, the optimal solution is this bimodal sort of purple distribution. Purple distribution as a response. So you start from a sort of prior that is flat in a specificity, and you let the system optimize, and you get this bimodal response. So you need to produce highly specific memory and also something with moderate specificity, which is the middle peak. And the highly specific memory is basically the thing that is useful for chickenpox, and the middle one can be useful. And the middle one can be useful for a broad range of evolving pathogens without much fine-tuning. And that's the property of this sort of being in a dissipative regime. And that resembles what type of memory responses we have. So when we store B-cell memory, we have both IgG and IgM response. And IgG responses are more similar to this highly specific memory type, whereas IgM is more flexible and more evolvable. So that's sort of a So that's sort of the two types that we can think about. One of the other predictions of the model that was kind of unexpected for us, but in hindsight, expected, is that lifespan of organism actually impact their memory strategies. And that's a predictioning principle we could test. So if you think in this plot that I sort of change the life expectancy, which means the amount of encounters with Which means the amount of encounters with evolving pathogens that an organism has. So beyond a certain point that you start seeing evolving pathogens, so you go like the antigenic divergence larger than one, scaled quantities, so ignore the dashed line, so to speak, you'll see that shorter-lived organism should have more cross-reactive memory. And that means that, okay, they're not going to see evolving pathogens for a very long time. Pathogens for a very long time. So, whatever memory they store, they're going to use it before they die. And by that time, the pathogens haven't evolved that far. So, they're good. But then, if you live for much longer, you need to mount novel responses because you expect to see more evolving pathogens coming in. And so having cross-reactive memory might become actually quite inefficient. So, fewer pathogenic encounters, you need to have more cross-reactive memory. And that basically says, okay, if I line up. Says, okay, if I line up a bunch of organisms with different lifespans, do I see cross-reactivity to fall off as I increase the lifespan? And so it's hope that we can probably measure this in some ways. And that also relates to, again, original antigenic sin. Now, if you increase the lifespan of an organism immediately, like in the case of humans, we were going from storing cross-reactive memory to the Memory and to the regime that cross-reactivity is not that great, right? So we'll see the cross-reactivity to sort of interfere with novel responses and making a less efficient response in an organism. That's what we see in humans dealing with evolving influenza, for example. Okay, I think my time is over. And with this, I conclude. In the first part, I talked about sort of distributed versus compartmentalized memory or factoring. Memory olfactus immune system, and then I went through more focused sort of topics of immune memory, how to think about it in co-evolution with pathogens, and the fact that memory should be actively regulated. So this thing, this comes out of our model to sort of reduce the affinity of memory to deal with evolving pathogens. Specificity of memory should depend on the lifetime of an organism, and as you increase lifespan, utility of memory. Increased lifespan, utility of memory should go down. Something similar to original antigenics. This, I thank all the people involved, especially Oscar, which has an arrow on his head, and Otto Prank. Thank you.