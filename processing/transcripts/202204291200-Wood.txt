Now it's full screen. That's what we're doing. It is full screen and we're still at the moving pages. All right. We're good. That's right. Thank you. Thank you, Marcus. Thank you, all the organizers. And since this is the last talk of the conference, let me take a moment ahead of time to on behalf. To on behalf of all the speakers and all the participants, to thank the organizers, the organizing committee, and all of the staff down in Oaxaca who are taking care of the in-live participants or in-person participants. And just to express our appreciation, and I'll read a round of applause. And if others want to join, they join me with that. A lot of It's a lot of work, and especially with the hybrid system that we're dealing with, added extra administrative burdens. And I appreciate, and I hope I speak for everyone that appreciates the work that the organizers did. All right, so I want to talk a little bit about some survey and also some newer results on what I call failures of the McWilliams identities. And in the talk, And in the talk, I want to remind people what the classical McWilliams identities are. And I sort of emphasize the word classical here. That one of the things I've learned by participating in this conference is that I'm a bit out of date on some of the network coding, rank metric codes, and other sorts of things that a lot of talks have been about. And I need to do some studying and incorporate them into the way my sort of classical. Away my sort of classical viewpoint on codes and see if I can merge those ideas together. So, I want to remind people what the classical McWilliams identities are, go through an example of what I call these failures, and then provide some summary of when McWilliams identities in this classical sense work and when they don't. So, the classical setting, and this is several other speakers have. Other speakers have talked about things that most people probably know very well is that we have a linear code, which is a linear subspace over a finite field, Fq, of length N, and denote C perp to be its dual code. So with respect to the standard dot product on FQ to the N. I'm going to use small cap H to denote the Hamming weight, and that's a Hamming weight. And that's a Hamming weight on FQ itself, and then that's extended additively to FQ to the end. So you add up the Hamming weights of the entries of any vector. And I think one of the things that distinguishes what I'm talking about here with Hamming weight and some of the other weights is the fact that these weights are extended additively to the vector spaces. And when you do rank weight, that's not the case. So there's already some. Case. So there's already some differences in approaches. And I'll write HWE for the Hanningweight enumerator, which is this polynomial that most people, again, have seen. One way to do it is to use monomials, two monomials, where the hamming weight of a code word appears as the exponent in the y variable, and then the complementary weight appears in the x variable. It appears in the x variable. That way you get a homogeneous polynomial of degree n. And of course, certain, and you sum over the code, different code words may have the same Heming weight. And so when you collect terms, the coefficient, this a sub i of C, just counts the number of code words in C that have Hamming weight equal to I. And I put the H up here to denote that we're using the Hamming weight to make those when you're making those determinations. When you're making those determinations, the original McWilliams identities date from the PhD dissertation of Jesse McWilliams and as well as appears in another paper of hers around 1962, 1963. And I think most people are probably familiar with this formula that you can express the Heming-Weady numerator of the dual code. numerator of the dual code in terms of the Hammingweight numerator of the original code with a linear change of variables and then a scale factor of one over the size of c. One of the things I want to emphasize about the McWilliams identities is that if you want to understand the Hamming-Wetenumerator of the dual code, all you need to know about the code C is its Hamming-Weight enumerator. You don't have to know any You don't have to know anything more about the details of how C is built or how it's constructed or it's sort of what you might say its fine structure. All you need to know is what the Hamming-Wetting numerator is. And then from that, you can determine the Hamming-Wetting numerator of the dual code. I'm not going to do the proof of this. This is a pretty standard proof now that uses the Fourier transform and the Poisson summation formula. I want to run through an example. This example will take a few minutes to do, but it's pretty simple. At least I hope it's pretty simple. So let, whoops, went too far. Let R be Z mod 4. So probably the next best thing to a finite field. A linear code over Z mod 4 will be a submodule. four will be a submodule of R to the n. And there's a standard dot product there as well, which is uses the same formula that we use for every other dot product. So products of individual entries, then add them up and take that with values in the ring. So this would be a computation mod four in this particular example. The dual code is defined in the same way that we define dual codes over finite fields, use as orthogonals. Use as orthogonals using this dot product. So all the vectors y and r to the n, which are orthogonal to all of the code words. So again, these are ideas that most everyone has seen is probably taught courses about. So I want, and I'm going to build two codes for you or have you build your own code. Every one of you can do, you know, follow along. Pick two positive integers, A and B, and all I A and B, and all I assume at the moment is that A is larger than 2B. So two positive integers, A and B, A bigger than 2B. Then define a first linear code. This will get a linear code over F4, which will have dimension one. And its generator matrix is a one by three A minus two B matrix, where you have a bunch of twos and a bunch of ones. And a bunch of ones. And how many of each? So they're 2a of the ones, and the remaining a minus 2b are twos. So this is in this generator matrix. Of course, a minus 2b is a positive integer because of the assumption on a and b. Build a second code. I'm going to use the same a and b, a bigger than 2b, and let c2 be the linear code that's generated by be the linear code that's generated by a 2 by 3a minus 2b matrix. So these two codes have the same length, 3a minus 2b. The first one had just one line in its generator matrix. This one has two lines in its generator matrix. And here they are down below. And so all they have are twos in these. So in the first a minus 2b, remember this is a positive number, there's zeros. The next a block, there's twos, and the next block. There's twos, and the next block after that are zeros. So you just have to imagine a big long generator matrix, but there are only twos here. So this is a, as an abelian group, this is a Z2 plus Z2, whereas the other one, when you generate the code, it'll be a Z4. So here are the four code words for each of these codes. And I'm using the same sort of shorthand notation. There are A minus 2B columns. 2B columns of zeros, and then a columns of zeros, a columns of zeros over here. So here was the generator for the C1 code. When you multiply it by two, of course, two times two is four, mod four. So you just get twos in the last two blocks. And then when you multiply by three, you get that. And then for the other code, the two middle lines were the generator matrix. And the only thing you can do is add them together. And so you get double twos down here. And so you get double twos down here. I want to look at what I call small elements in the dual code. I haven't told you about a weight yet, so I'm just put small in quotes for the moment. But small in the sense of looking at vectors in dual code that have only one non-zero entry. I think most people will go that those are probably fairly small code words. So I'll refer to such a vector as a singleton. Such a vector as a singleton. And if I want to name what the non-zero entry is, if it's R, now I'll call it a singleton R. Now, so there's still some ambiguity. What position is that non-zero entry located? So that's one of the things that we'll play with. So what are the singletons that lie in the dual codes of the examples we just did? And in order to be in the dual code, that a singleton to be in the dual code, that A singleton to be in the dual code, that R has to annihilate the position where it appears in the vector. So it has to annihilate that column in the generator matrix. So let's see how that works for the examples that we have. So I've written these more horizontally now. Okay, so let's look at C2 first. It's got a whole bunch of zero columns. So any non-zero thing will annihilate that, including ones and multiples. Will annihilate that, including ones and minus ones or ones and threes. So in C2 perp, there are A minus 2B columns, and both one and minus one annihilate that. So that counts for the two. Whereas when you look at, if you have a singleton two, well, two is going to annihilate everything in C2, because two times two is four in Z mod four. So there are three minus two A singleton twos. When we go over to C1, When we go over to C1 instead, well, the last two blocks of entries have units in them, and nothing annihilates a unit except for zero. So the only time we were going to get a non-trivial singleton in the dual space is when you annihilate these twos, and so you have a singleton two in the A minus two B columns from the left. No singleton ones or minus ones. All right, so now I'm going to define. All right, so now I'm going to define a weight. Oops, if I click, it advances. Now I'm going to talk about a weight. And this is where the choice of A and B came into play. So remember that at the top of the exercise, we said choose an A and a B with A greater than 2B. So now define a weight on Z mod 4 where A is the weight on 2 and B is the weight on both plus and minus 1. So for example, the For example, the Lie weight would have B equals one and A equals two. So amine weight would have both of them equal to one. Now, none of those meet our inequality, but nonetheless. So here's, we've chosen a weight now. And then we extend the weight from Z mod 4 to vectors over Z mod 4 by adding them up. And this addition now is taking place in the integers. And then to find a weighting. And then define a weight enumerator akin to the way we define a Hamming weight enumerator by simply taking a generating function using the weights as the exponents. I've chosen to write this in sort of affine, an affine version, because I don't really need the homogeneous version so much, but you could use capital X and capital Y in the same fashion that you do with the Hammingwood enumerator. And again, different code words may have the same weight, so you can simplify. So you can simplify terms together, and the capital A sub i is then the number of code words of weight I in C with respect to this W weight. So let's look at the, did I call, let me go back for a second. Yes, I called it WWE, the W weight enumerator. So all right, so the W weight enumerator for these examples, all we have to do is calculate the weights of all of these things. Calculate the weights of all of these things. An element 2 had weight A. So every one of these 2s contributes an A. There are A of them. So the weight of this code word is A squared. Same thing for this one, A squared. And now here we have two in both slots. So this would be 2A squared. So when we look down at the bottom, the W weight enumerator for C2, we see two code words of weight a squared. Of weight a squared and one code word of weight 2a squared. When we do the computation over on for C1, the third line here with the 0, 2, 2, that's the same as the one for the C2 code. That has weight 2a squared. And the other two terms, well, the 2 contributes an A. There are A minus 2B columns of them. So we have there's A minus 2B columns times A. And then Columns times A. And then the ones, or for that matter, the threes down here, each have weight B. So there are two A of those times B. You do the arithmetic and you get A squared. So both of these code words with units in them have weight A squared. And so voila, we see that these two codes have the same W weighting numerator. So now let's think about the dual codes again. And remember that. codes again. And remember that we assumed that A was greater than 2b. So what can be the smallest weight that occurs in actually for any vector? So the smallest weight that can occur is if you have a singleton vector with a plus or minus one as the only non-zero entry, and that will have weight B. If you have a singleton two, that already has weight A, which is more than twice that of B. So this is the smallest. Twice that of B. So this is the smallest weight you possibly can have. If we go back for a second, back for a second, there we are. C1 perp had no singleton plus or minus ones, whereas C2 perp did. So I'm going to go forward again. No singleton ones in the first, in the dual code of the first one, a number of singleton ones in the dual. A number of singleton ones and dual code of the second one. That translates into the number of vectors of weight B in the dual code being zero for the first code, because there are no singleton ones. That's the only way you can get weight B. And in contrast with the second code, its dual code has a number of vectors, a number of dual code words of weight b, namely two times a minus two b. So, and by a To be. So, and by assumption, this is a positive number. So, as a summary of what this little computation does for us, tells us that you can produce two linear codes over Z mod 4. They were not very complicated. They have the same W weight enumerator, but their dual codes do not have the same W weight enumerator. This was under the hypothesis that A is greater than 2B. Greater than 2B. You can do a similar construction. You have to tweak the multiplicities for the columns, but you can do a similar construction when A is less than or equal to 2B. That also leads to failures, except in exactly two cases. One of which, well, cases in a sort of a ratio sense, can always scale. So what really matters is the ratio of A to B. So if the ratio of A to B is one, then you have the Hamming weight, and we know that the The Hamming weight, and we know that the McLuhan's identities hold for the Hamming weight, and it also holds when the ratio is two to one, which is the Lee weight. So that was just, this is sort of the edge case where our inequality failed. But for the Lee weight, the McWilliams identities for the Leeweight enumerator do hold over Z mod 4. I'll get to that in a second. So as a conclusion, only the Hammingweight and the Leeweight Only the Hamming weight and the Lee weight are weights that, with plus or minus symmetry on Z mod 4, that yield McWilliams identities for these W weight enumerators. And again, let me emphasize that the weights are weights on the alphabet, which are then extended additively to the vector space. So for those types of weights, these are the only weights for which you have a McWilliams identity. You can do a very similar sort of construction on any two standards. On any two-step chain ring, my suspicion, I haven't, I'm still sort of working on things greater than that. My suspicion is that there are going to be very few examples for any chain ring construction in this same sort of fashion. So did I show this? Anyway, commutative. Have I showed this commutative diagram already? I say that I did it again, but I've forgotten either that or I. I've forgotten either that or I skipped over something. So I don't remember seeing it. Anyway, so for linear codes over Z mod 4, a way that I like to think about the McWilliams identities is that you think of the collection of all linear codes of a certain length and size. And then think of taking the dual codes. And the length stays the same, but the size will sort of have a common. This will sort of have a complementary size. The product of the size of the code and the dual code should give you the size of the alphabet or sort of the ambient space. So duality takes you from linear codes of one size and dimension to codes of size and complementary dimension. And then the weighting numerators map you down to polynomial rings. And for the Hamming weight, the Hamming weighting numerator. The Hammingweight enumerator gets filled in with a McWilliams transform. Whereas for the Lee weight, or for these A and B weights that we just talked about, there's no way to fill this in. If there was a way to fill this in, then our counterexamples could not exist. You start with two codes that have the same weight enumerator, then if this diagram commutes, their dual codes would also have the same weight enumerator. But we have examples for which that. But we have examples for which that's not the case. So there's no well-defined map across the bottom. All right, so let's, I'm going to return now to the Hamming weight to talk about some generalizations of the Hamming weight. So here they are again. So the monomials that appear have the Hamming weight as the exponent on y, and then the complement to the Hamming weight as the exponent on X, so that you get a homogeneous. homogeneous polynomial. I want to point out that if you evaluate the weight enumerator at x equals 1, y equals 1, what do you get? Well, if you look over on the far right, plug in x equals 1 and y equals 1, you see that you get the sum of these a sub i's. And the a sub i's were counting the number of code words of a particular weight. When you add up over all possible weights, that means add up over all possible weights that means you get the number of code words so when you evaluate the waiting hamming weight enumerator at one comma one you get the size of the code when you do that same exercise on the mcwilliams identities so on the left hand side you'll get the weight you'll get the size of the dual code what do you get on the right hand side well now when x and y are both equal to When x and y are both equal to 1, you get a 0 in this second slot, which means that all these y's are equal to 0. But you got to be careful because when i is equal to 0, the y doesn't actually appear. So what you get is a sub 0, which is 1, times x to the nth power, or whatever's in the x slot. So with x and y equal to 1, this number gives you q, and so you'll get q to the n when you do this. Q to the n when you do this. So on the left-hand side, you have the size of C perp. On the right-hand side, you have Q to the N, that's the size of the ambient space, divided by the size of C. So size of C times size of C perp is equal to Q to the N. That's the size of the ambient space. Okay, so I'm going to refer to that later. So I thought I would explain it now. Thought I would explain it now. So, how can we generalize these Hamming weight enumerators? One generalization was the exercise we did earlier on the W weight enumerators over Z mod 4, and now I just want to be a little bit more systematic about it. So one way of generalizing is just to keep the Hammingweight enumerator, but generalize the codes. So when McWilliams wrote her dissertation, she was using linear codes over FQ. Codes over FQ. And so one way to generalize this is to try to apply this to more codes. So one example is additive codes. So drop the multiplicative nature of codes, but maintain that they're additive subgroups, getting what are called additive codes. You can use a character theoretic annihilator in a very general setting, and there are McWilliams identities there that were exposed. That were exposited by Del Sartre back in 1972. 20 years after Del Sartre, in the early to mid-90s, was the sort of Z4 revolution, the famous Z4 papers. And so you can talk about linear codes over finite rings. And the McLean's identities hold for the Hamming-Waiting numerator over finite Frebenius rings. So that's one of the results from. So that's one of the results from work that I had done back in the 90s. It turns out that when you're dealing with linear codes over finite rings, so it works for Frebanius rings and it fails to work for non-Frevaneous rings. And the reason for that is that you can produce, if you have a non-Frebanius ring, you can produce examples of ideals such that, or codes more generally, so you can produce examples. More generally. So, you can produce examples within your codes which fail this size condition. So, the product of the size of the code times the size of the dual code need not equal the size of the ambient space. So, if that non-equality is present, that means the standard Hamming-Weighty numerator and McLuhan's identities will fail because we saw earlier that. We saw earlier that if x and y are equal to 1 in the McWilliams identities, then you got the size relationship. So we have failure for the Hamming-Wade enumerator in the non-Frevaneous case. But another way to generalize things is to generalize the numerators themselves. Now, some of these examples are very classical, but there's been intervening work, which I think is quite nice. So another way to think about So, another way to think about the Hamming weight enumerator is not sort of thinking of H of C as the Hamming. Well, you still think of it as the Hamming weight, but think of it in a slightly different way. If you partition the alphabet, so if you have a ring, for example, one simple partition that you can do is to partition it into the zero element, and then the other chunk is the non-zero elements. Is the non-zero elements. And in that case, the Hamming weight is counting how many entries belong to the non-zero partition block, whereas the X counts the number of entries that are in the zero partition block. But you can generalize that to any partition of the alphabet into a number of blocks and then count the number of entries in a vector that belong to a particular block in the Particular block in the partition. In this case, you have a variable for every partition block. So it'll be a number of variables. And then the monomial that occurs in the weight enumerator is the product of those variables with multiplicities given by how many entries belong to that block. And then you add up over all the code words. So this is a partition weight enumerator. Enumerator. So that's another way of thinking of generalizing the Hamming weight enumerator. And then another way is the one that we did through our example over Z mod 4 is just to have another weight on the alphabet with positive integer values and use that weight as the exponent on T and the complementary number on X. Now the complementary number has to adjust to what the maximum value could be. Could be. So you use the maximum value of w times n in the other position. That's so that everything becomes homogeneous with degree w max times n. Now, let me go back a second. The partition way of generalizing weight enumerators has had a lot of success. Some very classical examples. Some very classical examples include the complete weight enumerator, in which case you use, in this sense, the complete partition of an alphabet into the singletons. So every partition consists of a single point. And so when you have a code word, you're looking at, well, how many, so if you're doing over Z mod 4, how many ones are there? How many twos are there? How many threes are there? How many zeros are there? How many threes are there? How many zeros are there? And those go into the each one of those values has a variable, and so you get a monomial with four variables in that case. Another, perhaps more useful example are what are called symmetrized weighting numerators, where you use orbits of a group action as the partition blocks. And there's been a lot of work on this. So I put with Work on this. So I put McWilliams and Sloan down here because things like the complete weight enumerator already occur in their famous textbook. But there's been work by Del Sartre, Levenstein, Zinoviev, Ericsson, Onalt, Lonchev, Dougherty, Skirganov, and then some people who are attending our conference and who have spoken or organized, Ymir Byrne and Marcus Refereff, Michael Sullivan, and also another audience member. And also another audience member, Heidi Glisen-Lorenzen. And I'm going to be sort of talking on Heida's treatment of things, giving sort of a quick and just a partial summary of what she's done. She's done a lot more, and I recommend you read her papers. So I'll stick with sort of an additive code version. Look at a finite abelian group A. It has a character group, A hat. That has a character group, a hat, and just define a partition on the alphabet A. That in turn defines a partition on the character group, where two characters will be related, so will be in the same block, if their sums over the blocks of the original partition match up for all J. So you have a partition on A. So, you have a partition on A, and then you get a dual partition on A hat. You could do it again. You'd say, well, what if I take the dual of the dual partition? That will give you a double dual partition on A. It's not necessarily equal to the original partition. It's always a refinement, but it may not be equal. And when equality holds, then that partition is called being reflexive. And as I outlined sort of a little bit earlier. Outlined sort of a little bit earlier for every block, you get a new variable, which I will refer to as z sub j. And then for a vector, you count how many of the entries belong to any of the given blocks. Those give you multiplicities that become the exponents on those variables. You can do a similar thing for any character on the dual, on a hat dual. Such characters can be thought of. Such characters can be thought of as tuples of characters on A. And so, again, you can count how many of them belong to the blocks that occur in the dual partition. And then you can create partition weight enumerators for additive codes. So which partition is being used appears as a superscript. So the number of variables depends on the number of blocks you have in the partition. And you get this. And you get this what is modeled on the complete complete weighting numerator, but now according to counting entries in blocks. The dual code in this context is the character theoretic annihilator of the original code. So this will be an additive code inside the dual abelian group, all the characters that vanish on the original code. And with those notations in And with those notations in mind, you get the following McWilliams identities, where the partition weight enumerator for the original code, the original partition, can be expressed in terms of the partition weight enumerator for the dual code using the dual partition with a change of variables, a linear change of variables, whose coefficients are those sums that came up in the definition of Up in the definition of the dual partition. This sum depends only upon which block pi belongs to, but basically by definition of the blocks in the dual partition. So this is a very nice description. But one word of warning that this is a one-way theorem in the sense that if you start with a partition on A, you get a partition on A hat, and the equation. And the equation needs to be written in this order that the substitution goes into the dual partition case. For the Hammingweight enumerator, the role of C and its dual is symmetric. So you can flip things around and the same McGooley's identities work. That's not true in this case, unless you have a reflexive partition, because of sort of the one-way nature of the door. Of the dualization process. Okay, so now let's talk about the other generalization that I had offered, which is to just take a different weight on the alphabet or on a ring and add up the values in a vector. So let R be a finite Trabaneous ring with one. And suppose you're given a weight. I'm going to assume it has integer values so that when we do integer values so that when we do polynomials we'll have integer exponents on on the so they actually are polynomials assume that the zero element has weight zero and that all the other elements have positive integer weights assume there's a maximum value w max and as we've already seen a couple times already you can extend this additively to a weight on rn simply by adding up the values and so By adding up the values, and so this is now a sum in the integers. And to find the w weight enumerator, as we have seen before in the z4 examples, as well as with the Hamming case, just use the W as the exponent on Y, and then use sort of the complementary weight on the exponent on X so that you have a homogeneous polynomial. I will probably only refer to it in the sort of affine version where you set affine version where you set x equal to one and y equals t just to save some space. Now, examples of this already is you can do this for Lee weights or Euclidean weights. Those are perfectly good examples of this phenomenon. There are some successes. Actually, when I was reviewing my slides last night, I was thinking, should I really use success because it's I'll share. This is sort of off track, but it just popped into my head. I have somewhere in my belongings, I have a trophy from some foot, from some 10K race that I won. It's like, how did I win a 10K? Well, I was the only person in my age group. So sometimes success comes sort of as a default. So successes may not be quite the right word here. But if you forget. Right word here. But if you, for example, if you use the Lie weight or the Euclidean weight on either Z2 or Z3, well, those weights happen to equal the Hamming weight. So of course, the McWilliams identities will hold for the Li and Euclidean weights because we know they hold for the Hamming weight. So just sort of by coincidence, they hold. For the homogeneous weight, well, if you work over a finite field, the homogeneous weight is essentially the Hamming weight. Homogeneous weight is essentially the Hamming way. And so, again, you can piggyback on results for the Hamming way. Now, one case where it really is a success is over Z mod 4 using the Lee way. And that's in the famous five-author paper, the famous Z4 paper, Hammonds, etc., from 1994. It's also true over this small chain ring, F2 plus UF2, also true over 2x2. Also, true over 2 by 2 matrices over F2 for the homogeneous weight. And in all of these cases, Lee weight over Z4, and then these two homogeneous weight cases, there are gray maps to Hamming weights. Hamming weights are Lee weights. So that helps explain why they work. Now, I want to, the title of my talk involved failure. So, how could the McWilliams identities fail? Williams' identities fail. And so I'm going to, again, have this diagram, the commutative diagram that I showed earlier. One way in which, probably the strongest way in which they can fail is that if you can find examples of codes, so find examples of linear codes, same length, same number of elements, with the same W weight enumerator. So it means they have the same image down on the left bottom, such that when you take their dual codes and you take their weighting numerator, And you take their weighting numerators, you get different answers. So, and different weighting numerator would mean that some of those coefficients have to be different. So, there's some weight such that the dual codes have different number of code words of that weight. And that simply means that this is not a well-defined function. So, there's no mapping across that makes the diagram commute. So, that's what we're going to try and do. Now, some of this, there have been some other Now, some of this there have been some other examples of this type of argument before. So, there's a paper by Dougherty and Strykenoff on the Rosenblum-Sfossman weight over matrices that dates from 2002. There are examples, already known examples, for the Lee weight of homogeneous weight over Z mod 8. I learned about them the hard way from a referee, refereeing one of my papers, so helped save me from jumping off of a Helped save me from jumping off of a cliff. And the similar things have occurred in a paper by Shi Shirmoto and Soleil from 2015. There's also some work by Tang Zhu and Kai from 2017 that says if you were to have a McWilliams identities for the Li or Euclidean weights in this W weighting numerator style, then there's a restriction on what it can look like. There's a restriction on what it can look like. So, I want to acknowledge that those works have been done. So, now let's give you an outline of work that I've been involved with in recent years. I should also tell you another story. And I'm trying to think exactly when this happened, because it may have happened twice. I've given lectures at various universities or at various colleges. At various universities or at various conferences over the years. And every once in a while, oftentimes a student will come up and go, Well, you know, does the Hamming weight work for if you use the Lee weight instead or the Euclidean weight instead? And I didn't really know. But a few years ago, actually in 2018, one of the ironies is I was giving lectures at Central China Normal University in Wuhan, the famous city of Wuhan, which now everyone is in the city of the United City of Wuhan, which now everyone knows about. No one knew about it before, but now they do. And I was preparing lectures on McGoing's identities, and I remembered this idea. So I started thinking more seriously about, well, what happens for the lee weight? I knew that it didn't work for Z mod 8, but it's like, what happens more broadly? So here's some results of that. So for the lee weight over Z mod M Z, for M greater than or equal to 5, failure. Failure. We can find two codes with the same W weight enumerator, in this case the Leeweight enumerator, but whose dual codes have different Leeweight enumerators. Why greater than or equal to five? Well, we know it's true for two and three because the Lee weight's the same as the Hemming weight. And we know it's true for four because it's the same as the Lee weight. And we have the five authors paper. For Euclidean weight, I don't know quite as much, but. I don't know quite as much, but I know a lot. That it depends on what I can prove it for any m that's divisible by the following list. If m is divisible by four, by six, by nine, which means any power of that uses only twos and threes, that's bigger than bigger than four, or sorry, bigger than three. Or if it's if m is divisible by a prime. If m is divisible by a prime in this range, which means I've done some computational things for this. My conjecture is that it's true for any m greater or equal to 4. Homogeneous weight over Z mod M. M cannot be prime because when M is prime, then you have a field, and we know homogeneous weight is the same as Heming weight. But as long as you're not prime and greater than or equal to six, then there are examples in the homogeneous weight. Their examples in the homogeneous way. And that's some work that will be appearing soon: proceedings from the Mathematical Congress of the Americas from last year. And then I'm working on homogeneous weight over matrix rings. I already know that it fails for two by two matrices where Q is bigger than two. We know it's true over two, but true with F2, but it's not true for Q bigger than two. 2q is bigger than 2. And it's also not true for 3 by 3s over F2. So my suspicion is that it's not true most generally. There's perhaps one small consolation in this, that when you have a weight, it has often will have a symmetry group. And then you can look at the corresponding McWilliams identities for the symmetrized weighting numerator. So that will give you. That will give you usually a valid, especially in the commutative case, will give you a valid McWilliams identities on a symmetrized weighting numerator. And then you can calculate the W weight enumerators by specializing variables. It's just that you normally cannot fill in the line going across. Okay, so let me give you a quick scan of some of the arguments that go into these results. Go into these results. Give you some examples. So, I first want to talk about lee weight. So, this is some joint work with my former student, Noha Ottogani, and to talk what lee weight is. So, view Z mod MZ symmetrically about zero. So, think of it as being represented by integers in the range from minus m over two to positive m over two. And then the lee weight is the ordinary, the ordinary. The ordinary Archimedean absolute value, which you then extend to vectors by adding up, extend additively. The Leeweight enumerator is just the W weight enumerator using this Lie weight. So the Lie weight occurs as the exponents. There is a symmetry group in this, plus or minus one. We've already said we know the Williams identities hold for m equals two, three, or four. So how do we proceed? If I jump down. Proceed. If I jump down to the bottom line, it says propagate to multiples. So if we have a general way of going, if we know that the McGuilliam's identities fail for M, so we have some examples for Z mod M, then we can basically use the same examples for any multiple of M. So we need to know sort of basic building blocks. So those basic building blocks are the primes, except you have to avoid two, three, and four. So we make some ad hoc. So we make some ad hoc constructions for five, six, eight, and nine. The six, eight, and nine handle m's that are divisible by just two and three that are not in this range. And then five, because five is a pretty small prime and you need to do something different for that. And then we have a uniform construction for all primes greater than or equal to seven, which I will show in a few minutes. So here's an example for Z mod six. mod six pick generator so i'm going to choose the generator matrix um with one row one one one for one of them and one one sorry one one one one for the first one and one one three three for the other one here are the code words laid out for the first code on the left for the second code on the right and here's the lee weight of those code words and you notice that they have the same list of lee weights occurs although not with the same curves, although not with the same vectors. If the same vectors had the same weights, then the codes would be equivalent and they would have, they would, things would work. Different orbits support different ways. So the units support fours, whereas over here the units support threes. It's an exercise to show that the code words of way two in the dual codes differ. way two and the dual codes differ. The number of so there are 12 dual code words of way two on the left, but only 10 on the right. We then can produce a family of examples for primes bigger than or equal to seven. So let t be half of p minus one, and then let g1 have t entries each of two through t. So there are no ones, two through t. G2 has has Has a bunch of ones and then fewer numbers of two through t. So, for example, when p is equal to seven, we have, for example, here three twos and three threes versus four ones, a two, and a three. You can look at the code words of these things and their lee weights. And again, you see that you get the same lead weights in both codes, just in different locations. There's a top-to-bottom symmetry here, which comes A top to bottom symmetry here, which comes about because of the plus one symmetry of the weight. And then, with contrasting the two codes, you notice that the Lee weights, 15, 12, and 9 are in reverse order in the two codes. So that's sort of a general feature of this construction. This is the top-bottom symmetry, and this is the reverse order between the two codes. As a consequence, because these codes run through the same values, they have the same lead-weighting. Same values, they have the same leeway enumerators. The hard work in this result is looking at the dual codes and to show that in this case, it's the weight three code words for which we have different counts. That's a little bit hard. I'm not going to summarize that. You can also do, so I showed you sort of what it looks like for primes greater than or equal to seven, as well as did one for six. As well as did one for six. You can do similar things for five, eight, and nine. You get the same Leeweight enumerators. And then you can show that the examples that you produce have different leeweight enumerators for the dual codes. And then the smallest weight at which they differ is given in this chart. So it's at usually fairly small weights where the Lie weights of the duals differ. But in every case, it's less than m over 2. Over 2. Then the propagation, if you know examples over Z mod M, you essentially take a generator matrix and multiply all the entries by A and view it and then generate a code over Z mod A M. The weights scale by A. So if you have the same weights over M, you'll have the same weights, not identical, but everything will scale. So you have the same number of weights. scale so you have the same number of weights at a given at a given level over z mod m you will again have the same number of weights at the multiplied level over z mod am but for very small weights the lee weights and in the the lee weights in the dual turn out to be the same so um that isn't what i wrote there it's it's here so so for for small values of For small values of weights, you can have the same. I've gotten ahead of myself. Here we are. When you propagate, as long as the weights are pretty small, namely less than the original M, the number of dual code words in the different leeway situations are actually the same. And so when we do the final argument, if you take any When we do the final argument, if you take any integer, at least five, it has to be divisible by code by either a P or the special cases that we already talked about. So we can produce examples in each one of those cases, then scale it up to get to the M that we wanted. We don't change the fact that the Lee weights are the same, the Lee weight enumerators are the same. And we also don't disturb the fact that for small values of J, less than Less than the where we produced the examples, that that in non-equality still persists. So that's sort of an outline of how we do that. I see that my time is getting a little low. So let me, I'm going to speed up a little bit. I think the slides, the talk and the slides will be available so people can look at more details. For the Euclidean weight, the problem lies in the fact that I don't have a uniform construction. That I don't have a uniform construction for all primes. I have an idea for how to produce things, but it doesn't work out. So I can do lots of things numerically, but not sort of abstractly, which is what I would need to be able to do a proof. Nonetheless, here's an example for ZMOD6, where you just use 0, 1, 1, 2, 2, 3, 3, and then 4 ones and 3 2s. Same Euclidean weight enumerator, but. Weighted numerator, but because of the zero different dual codes. For the homogeneous weight, let me just, I want to be cognizant of time. Let me skip, let me skip a bunch of, let me skip a few things. The statement is that for homogeneous weights, m not prime greater than or equal to six. Greater than or equal to six, you can find examples of codes for which the homogeneous weight enumerators are the same, but their dual codes have different homogeneous weight enumerators. So you can do it for that Z mod M situation, as well as for these matrix rings that I talked about before. Oh, here's, let me end with an example for you. With an example for you. I'm sorry that this is got a little pressed for time here. Zmod 15. The homogeneous weight is given in the following list. So every element in Z mod 15, it's either a unit or it's divisible by three or it's divisible by five. And so depending upon which orbit you're in, there's the homogeneous weight. There's the homogeneous way. You can write down some generator matrices, and they'll be two by something. In this case, they're two by 650. This I view as sort of, well, I tell you what the columns are. So here's a column of five and threes, column of one and zero, column of one and three, and so on. A whole bunch of columns. And below here, And below here, I tell you how many times you take those columns. So, what are the multiplicities of the columns? So, you get 50s for one, and then a bunch of different ones for the second one. And if you just calculate, you can calculate the code word, calculate the weights of all the code words that occur in this code. And it's a three-weight code. There are just three values that come up. There are just three values that come up. And the point that I want to make about this, but because of time, I'm not going to be very lucid about, is notice for the first code that anything on the left, all these code words have the same weight. All these have the same weight over here, but a different weight. And we sort of swap locations of where weights can occur. And the miracle about this is that with judicious choices, Judicious choices, you can actually produce a code that achieves those different weights. So I think I will end by saying that that's possible to do. And the difference in multiplicities in the middle is what allows you to make the argument that the dual code words, the number of dual code words, are different. So if people want more details about this, and I apologize for doing it much too briskly, I'll I'll be glad to stick around and talk with you afterwards. Yeah, no worries. No worries, Jay. This was a wonderful and utterly instruction presentation. So I'm quite sure we have a couple of questions. Well, yes, in any case, thank you for your attention. And again, thank the organizers for everything. Please, questions? I have a question. So this may be. This may be a naive question because I've thought a lot more about generalized weight than McWilliams identities and weight enumerators. But I always wondered why people often tend to consider weights such as the Lie weight or the homogeneous weight that assign higher weight to non-invertible ring elements. So, in my intuition, and my intuition partly comes from generalized weights, you would want the generator of You would want the generator of a certain subcode to have the support of the code that it generates, and so you would want the generator to have the largest weight. So, you would want that when you multiply by non-invertible elements, a vector, the weight decreases as opposed to increases. And so, I mean, I realize this is just a very personal, maybe. A very personal, maybe the reason why I would expect this is maybe it's because of where what path I come from, but I always wondered, and I just take the occasion to ask you, I always wondered why, why do people consider this type of weights with this problem? I think I can answer for the homogeneous weight. I think there's sort of electrical engineering reasons for it that go back to Berlikamp's book. And that's about all I can say. And that's about all I can say. Burlikamp, and maybe he'll tell you. For the homogeneous weight, Marcus can correct me on this. I got the idea. Well, I didn't get the idea. Nechayev said that you wanted different, when you're doing codes over rings, if you have a unit in a particular position. A unit in a particular position, it will contribute a lot of information. But if you have a non-unit, because the ideal it generates is not as big, might not contribute as much information to the code. And so he wanted to sort of equalize those so that all choices sort of contribute more effectively. I'm not sure. I'm not sure that that was a very good explanation. I mean, I don't know if there's a good explanation. I just wanted to get the intuition because then again, my intuition also comes maybe a little bit more from network coding. And there, like in physical layer network coding, you look at module generation. And there again, you would expect that something that generates more should have more support or more weight. So I always found this very unintuitive. I always found this very unintuitive. So I mean, I just, you know, it's an answer. And it's the first answer that someone ever gave me. So I think that's good. Thank you. There's one thing that I can say here. The idea behind the homogeneous weight, as Heise and co-authors defined it, was they wanted to mimic certain behavior of the Hemingway. Certain behavior of the Hemingweight. Namely, first of all, that it maps zero to zero, clear. Second of all, that associated elements, meaning unit multiples of each other, should get the same weight. And then the most important for the homogeneous was that the sum over the weights over a principal idea or later also a general idea is always essentially constant. Always essentially constant, meaning constant times the size of the idea. That means the average weight in every ideal should be the same. And actually, where did they take that from? Well, because if you do simple traditional coding theory over GFQ with a Heming metric, then there is this formula for linear code. The average Heming weight is essentially. Heming weight is essentially Q minus one divided by Q. So in a way, Heiser and co-authors looked at what is out there and what makes Hemming so special, and then they tried to form an analogue of the Heming rate for rings. That is part one of the story. Part two is this. I myself, along with Jay and other co-authors, have looked at Have looked at the equivalence theorem, not only here at the enumerator theorems. I think in terms of enumerators, I think Heide and also Jay are the better specialists. But when it comes to the equivalence theorem, you find out that, for example, on Z4, it is not so important that the weight that you assign to the number two is properly large. Number two is properly larger than the weight that you assign to one and three. As a matter of fact, it's only important that the weight that you assign to the element two is non-vanishing to make the extension theorem hold. For that reason, we were already prepared to think in your direction, namely, why not considering also weights that have Weights that have different properties, namely that non-units can get smaller weights. My feeling from my own experiments was that particularly for storage, this might actually be a good idea. So this means the Lee weight on Z4, well, it has its history and it led to other history regarding homogeneous weight, but you have a completely valid point. You have a completely valid point that not all weights need to put higher weights to non-units than to units. That is definitely clear. I hope this was not too confusing, what I said. No, no, thank you both. I mean, it was just a curiosity question. Obviously, it depends also where you come from, what you find intuitive, or what you want to do with it, what you need to suppose to make it work, what you want to work. So, you know, obviously it's just also, it depends. Just also, it depends what is your perspective, but thank you both very much. Yeah, are there any further remarks? I did put the slide up that I had skipped over that talks about the properties of homogeneous weight that Marcus just referred to. Yeah. Yeah, I have one question. So you're looking for examples that the McGilliams identity fails for the homogeneous weight on a single Z mod MZ for values of. Z mod mz for values of m, right? Yes. Yeah. So the fact that the homogeneous weight partition on an individual Z mod MZ is sometimes reflexive, sometimes not, is not of any bearing in this concept of it seems, it seems not to be. Yeah. Yeah. It seems not to be. I mean, at some point, I was, you know, I was looking carefully at your papers and it's like, I'm not sure. It's like, I'm not sure, I'm not sure it applies for this particular purpose, so it's yeah, I also have the feeling, yeah, yeah, yeah, yeah, okay, thank you. Yeah, sure. The let me, there's, there's one, I'm, I'm sorry, I'm turning into a teacher here for a second. The um, this, and I'm really sorry that it's like more time, more time on things. More time on things. Some of the like the talks this morning using projective systems as a way of talking, you know, how do you present a code? Well, one way you can present a code is using these projective systems. And that idea can be done in the ring context as well. Now, depending upon the weight, you have a different symmetry group. Have a different symmetry group. So, when you're using Hamming weight, like was being used in the first lecture this morning, the Hamming weight has a large symmetry group. And so, when you're looking at projective spaces, you're modding out by the full multiplicative group of the field. But if you were using Lee weight on a finite, you lee weight on Z mod P, a finite field, there's a plus or minus symmetry group. So it would make actually make sense to So it would make actually make sense to look at sort of all the non-zero vectors modded out by the action of this symmetry group. And that theory is something that I've pursued quite a bit, and it underlies the computations that occurred over here. These are really sort of, you can, I think it's pretty obvious that I didn't just on an envelope calculate. On an envelope, calculate that these are what the multiplicity should be. I mean, there were some computer computations behind that. And the computer computations made use of this ring theoretic analog and generalization of these projective systems. And so it allows you to do a certain amount of manipulations. And you look for situations where you basically, I was thinking of an analogy, you think of thinking of an analogy you think of if you think of the if you think of the abstract abelian group underlying a linear code think of it think of its points as a checkerboard um and then you if you have a weight you calculate the weight for you know for the um for the encoder that you have and that assigns weights different locations in the in this abstract uh abelian abelian group well what if you wanted to say well i don't i don't like the fact that it's arranged I don't like the fact that it's arranged that way. I'm going to keep the same weights, but I'm going to move them around and put them in different locations. Is there a code that achieves that weight distribution? And that you can calculate if the problem is small enough and you have a big enough computer, you can calculate this stuff. Sometimes the answer is yes. Sometimes the answer is no, but you know. Sometimes the answer is. But but you know. Sometimes the answer is yes, but there are fractions involved. So you have to clear denominators. That explains why in the slide there are 50s here, because there was some fraction that had a 50 in the denominator, and I wanted to get integers. So there you go. So there's a lot of similarity of ideas circulating around here that can come to bear on many different problems. Okay, end of my little pedagogical. Thank you very much. Jay, can I say two words? Because probably we have to leave because there are some people that are already leaving the chat. I would like to thank all of you for coming and joining, at least online, this workshop. I would like to thank the participants, the speakers, the talks were amazing, the organizers as well, I think myself all the time. I think myself all the time. But also, I would like to thank CMO and Beer for giving us the opportunity to have this workshop. Although, in theory, it was supposed to be person. This hybrid version allowed us to actually invite so many more people that could have been interested in the topics and maybe wants to start working on this on coding theory. So, I hope we got in the interest of the international community to work on. International community to work on problems that we suggested. And now we can continue. I don't think this room will be closing. We still have Gather Town if people want to go there. But otherwise, thank you very much.