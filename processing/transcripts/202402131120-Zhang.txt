Okay, so this is an application of AI in the genomic field. So we developed a tool called XA4C. It lets learn the representation from the general using auto-encoder and then use experimental AI to expand to because it's important to because it's important to know the biological reasonings to expand the critical review of critical genes. So I will talk about, have a brief introduction about what is XML AI, but I think many of you already know, and the application of gene expression and the introduce what is X84C and our application in the real data. So as we as we all As we all know that simpler models, they are highly executable, but less accurate. But for highly accurate model, they are more complicated and difficult to intercept. And the example AI can help us to decipher this black box into a white box to understand what's going on inside of the neural network and to understand how do we get. To understand how do we get from the input to get the output. And Xerville helps us to answer why the model makes a prediction and justify whether this prediction makes sense and help us debug and refine our model. If it doesn't make sense, help us refine. And it's also help us confirming the existing knowledge and identify new knowledge, potentially revealed. Knowledge potentially revealed by complex models and help us generate assumptions. So I would like to introduce a little about line. And it was developed by a group of scientists from University of Washington. And the basic idea of LAME we can understand from this mathematical form. So this G, big language G is the family of interpretable models. Integratable models and s is the complex model we get from the AI. And this little g is a simple interpretable model locally. And this pipe x is to neighborhood of the data point. So yesterday you see a plot. This could be a complicated surface, deciding surface, to classify the sample. This is a decision boundary, and this basically answers. And this basically understands if we have a point here, we want to use a local simpler model. For example, we can have a region here. And all the data point, this type identify how close this data point is to the data point we want to predict. So if they are getting closer, then they have more contribution to building this simpler model. And this omega is And this omega is a regularized to regularized term to regularize the complexity to make the model stay syncing. So, this is a basic idea of line. And another method is shape. And the shape is also developed by the University of Washington. And the mathematic specification of shape is we have simplified local input and we this F. And this F is a complicated model, and the G is a simple experimental model. And here we want to use this, it's a dated feature attribute. So we want to have the marginal effect. We start from a non-model and adding the features. And we want to have feature effect attribution. This files. this file is this and x is the correlation vector and we from the from we can sort of go through all the correlations and identify the effect of the features that are of interest so the shared value can be visualized as a force so we will predict starts from the baseline value average all predictors and then each feature value is a fourth And then each feature value is a force that will increase or decrease the prediction. So here's an example. So for individual sample, the actual outcome of the value of each feature will increase or decrease the outcome feature. So now we will apply this into our gene expression data. So this is how the data will apply. We have the hundreds. Of hundreds of thousands of genes and potentially thousands of individuals. And traditionally, people will use differential expression. That's a very simple, very simple one feature at a time, just do a t-test. And people may also do a little fancier to do co-expression network or differential co-expression network to identify the co-expression difference. Expression difference and identify hub genes that are have larger connections. So here, we propose to use autoencoder to learn the representations from the data. The autoencoder have two parts. One is the input encoder part. Another is decode. We learn this representation H in the middle layer and the framework of our work. And the framework of our work is: we use auto-encoder, our input is our expression data, and use auto-encoder to learn these pdl representations, learn the representations of the data. And then we use shared to explain which features are important for the learned representations. And after we get the importance map from this chat, this Check this blue ones. These are the top 1% features. We will select them as a critical gene. And after that, we will put this critical gene into pathway enrichment analysis. So pathways are, in biology, they are a group of genes that work towards the same function. For example, a pathway will be charge of carbohydrate metabolism. them. So then they should have that pathway enriched. We want to see how many of the genes are enriched in this pathway. So as you see here, we select the TCGA data, top six cancers with the largest sample size. And we tried SA4C model to we use auto-encoder to learn the representation and the number of Number of for we tried different structure of the autoencoder, like the layers could be deeper or shallower. And no matter whether it's deeper or shallow, this is a test R square. And the test R square is similar for both shallow network and deep network. They have the similar performance. And then after autoinforter learned the representations, we will do the shifts to get the important part and the genes with the largest 30 critical index summarized among all latent variables and average across samples. And we can see this plot is the distribution of the transcription critical index. So this part is for all genes. This part is for all genes, and this is a distribution for the critical index for the top 1% critical genes. And after that, we did the pathway enrichment analysis. And the top picture A is the top 20 KDG pathways enriched by gene with non-zero critical index. And then after that, we compare. Then, after that, we compare the pathway reach of GIM by XA4C and the differential coexpression and the differential expressions. We see a good overlap between those three methods for the pathway at the pathway level. But when we look at the team level, what's the overlap? We will find a big difference. So the distribution, the plot A is the distribution of artwork. Plot A is a distribution of R12 of pathway using autoencoder in the six tensors. And plot B, we see the overlap between the breaking from E we identified using autoencoder plus shared value. And the overlap between between FA4C and differential expression is pretty low. Also, the overlap between The overlap between the critical value identified by XOC with the departure expression is also very small. So this kind of, but when we look into the D-Genetic is a database that have experimentally validated this variance or this gene is actually contributing to the disease. So this work as our kind of ground truth. And when we look into this, And when we look into this, we see the number of reported genes in the database relevant to the corresponding disease. The number for FS2G is smaller than the number for differential expression. But when we look at the proportion, so we identify 68% of the gene follicles of all the critical gene, I think that they are validated in the district. East neck. So, this reveals that auto-encoder actually incorporates the potential non-linear relation for differential expression is clearly a linear relationship between the phenotype and the features. And for auto-encoder, it's captured the completed potential non-linear relationship between the feature and exist phenotypes. So, this is results shows. Results show even though they have low overlap at the gene level, but XL4C has higher validation rate. So, and here's an example of critical gene in the center of the network. So this is an example pathway, and we have normal and camera tissue. And we will see the difference between, we see the difference between in this pathway. In this pathway, the critical gene connection with the other gene is different, shows different distribution in case and control. So, as a summary, we developed X4C, the XAI tool to reveal critical genes from the perspective of interpretability. And the X4C discovered genes may enjoy greater functional relevance than standard method, such as differential expression, differential coefficients. Such as differential expression, differential co-expression, and they not only allow to integrate gene expression analysis, but to discover the critical gene. And we will characterize the functional relevance from the perspective of evolutionary analysis. So, that's my talk, and thanks for my collaborator. So, Elia Li is the first author for the paper and And these are the three students who did the project, and Dr. O'Reilly is my collaborator, who is consuperized the student project. Thank you.