Happy birthday again. Um so uh this is the joint work with uh Cha Chen from uh um Tennessee and uh Origin De Yan and Gienso. Let's see if this works. All right, so um yeah, there are plenty of slides, but I I I don't think I will shoot them all of them. I'm almost sure I will not shoot them. Um Sure, I will not shoot them. I would like to recall, because I understand that not everyone is an expert in stochastic PDEs here, I would like to recall what's known about solvability of the Barolic heat equation in this linear setting, which is called Bravo-Kenderson model. And then I will move to a description of what is the stochastic weight equation, and then I will discuss. And then I will discuss the scorehog regime. I will give you the main result, probably nothing about the strategy of proof. And then I will discuss some pathwise approaches, because there's been some progress on the stochastic wave equation in the rough setting in the last years. I would like to discuss that and I will give the main result to So, what about the fiberbaric model? So, it's your favorite heat equation. You can consider that an Rd, right? And you write your usual heat equation dt dt equals one half. Well, we use the one half in order to use Feynman Cax representation here, times the Laplace operator applied to U. Applied to U and your noisy part will be linear, right? You have the Cu times W dot. And you would like to consider a general setting, right, where X is in R D again, W dot is a Gaussian noise, you would like it to be either white noise in time or fractional in time, and in space you would like to have a certain spatial covariance. Spatial covariance, generally nothing, but in terms of your stochastic term here, you would like also to be rather general. You would like to consider Strapnovich terms or pathworks or etotype terms or score terms. Alright. One of the motivations to look at this kind of model, there are plenty of them. Of models, there are plenty of them, right? But one of them I've been working on are this intermittency phenomenon. In order to describe that, I will add one parameter to my equation, which is called lambda, and lambda will be kind of the intensity of the work. And what you observe, right, especially when lambda is large or when time is large, is that your solution That your solution will concentrate its energy in a few very high peaks, which will dominate the landscape. This is something you can characterize at the math level, and you would start by analyzing moments, high-order moments. So let's consider k1 larger than k2, and you take your solution. You take your solution ut of x considered as a random variable and you compare the Lk1 norm of this random variable to the LK2 norm. And you look at that when t gets locked. And you get that this is divergent. And this tells you more or less that sometimes this random value will take extremely high values, while most of the time it will be small. Small. Capturing much more by considering large moments. And this is the kind of result which has been obtained by many people through the white noise. I'm giving here a list. And it's still going on. I'm not quoting very new papers. It's still going on. For the fractional noise and time, there are also plenty of studies I'm quoting. Of studies. I'm quoting the first two words. There's a paper by Balan and Kohnux, and by myself, with at that time people from Kansas. So this is something you can study. This is also something you can observe. And I'm also showing you some simulations which have been given to me by Daniel Collus also a long time ago about. About the stochastic heat equation, which is here simulated on well, this is time, this is space, and the spatial variable here is between 0 and 1, and you have those Dirichlet boundary conditions. And you have different values of lambda. So if you take a small lambda, like lambda equals 0.1, what you will see is a kind of stochastic perturbation of your Stochastic perturbation of your uh deterministic heat equation. Right? While if lambda gets bigger, especially here, you will see this concentration of the solution in a very few, very large peaks, right? And here I'm not saying that the solution is zero, but the landscape is too dominated by those few. So that was just the motivation, but let's talk about the first step, right? When can you define this kind of equation? And let's start by a definition of what we could consider a reasonable model for the noise. So again, I'm considering a Gaussian noise. And here I will specialize the setting to uh R, but it could be R D, it's just uh for convenience of uh um what I want to explain. What I want to explain. And so it's a Gaussian noise, it's centered, so it's characterized by its covariance function. And the covariance function here, right, the expected value of wt dot x times w s dot y is given by a product of two functions. You have a covariance in time, right? So it's gamma zero of t minus s and times a gamma one of y minus s. and times a gamma one of y minus x. And those, they will, I mean, one possibility is to take the same type of function for gamma zero and gamma one, and there will be power functions. So here I'm using the fractional Brime emotion type setting, right? So this gamma j for zero and one will be of the form U minus V to a power two H J minus two. hg minus 2. Maybe that's something I should tell you. So this, this function, right, is in fact a distribution. If, I mean, it has to be considered as a distribution if hg is less than one half, which is one of the cases we would like to analyze. Right, and in that case, you would consider the scanner G as the Fourier transform of something which is well defined. All right, so not even the noise is a distribution, sometimes the covariance might be a distribution. Okay, so now in this setting, right, In this setting, right, R plus times R, with this covariance type of covariance function where you really have to understand this kind of thing as the derivative of a fractional Brownian motion in every direction. What kind of existence and uniqueness result do you get? So here I'm drawing H0, right? So this would be the time direct. So, this would be the time direction. Gate 1, you have a few values here. And the first area for which you can solve your equation is this one. So, this is according to 2H0 plus H1, right? And this line here is 2H0 plus H1 equals 2. 1 equals 2. And if you're above this line, you can solve your equation, well, somewhat you could say in a rough path sense, but it's not even that, it's a young equation. So that's the nice reaching. If you're below that and you still want to deal, because the Young equation will be a kind of Stratonovic type equation, right? If you are below this line, you start Below this line, you start renormalizing what we've seen this morning. Before that, we could also discuss the scroll-hot regime, right? When you interpret your differential in the scroll-hot sense, so your usual product is replaced by a weak product, right? You get an equation which is somewhat auto-renormalized. So you get a much better region. You get a much better region where you can solve the equations. So, this has been done like five years ago by Cha-Chen. He has, so those, you might not see that, but those are three lines. So, this slope is one, this slope is two, and this slope is four. Well, negative four. And the Young equation, this regime had been established in the Regime had been established in my people with X Kansas. Alright, and now let's describe a little bit the renormalized region in the Stratnovich sense. So I'm just describing here the first two renormalization regions. So it's again according to the values of 28. According to the values of 2H0 plus H1. And so you get those parallel lines. So this might be 2H0 plus H1 equals 3 half. And this is something you obtain after two steps of renormalization. But in fact, and this hasn't been done. I mean, this red region is something we've also carried out in a paper with another paper with Another paper with Chachen and Deya plus Oyan. But it's pretty clear that you could go on renormalizing forever. You would get thinner and thinner regions. And this hasn't been done by anyone, but I believe if you asked Kaiber, it would tell you that it's completely trivial. For me, it's probably not completely, but we don't have the same sense of trivial. But we don't have the same sense of trivial problem. But the limit of the renormalization procedure would be that that line. So that would be 2H0 plus H1 equals 1. But that would be after an infinite number of steps. Alright, so this was just to mention that for the heat equation, the situation is quite well understood. I don't know which sense. At least as far as solving the equation is concerned. What about the stochastic wave equation? So let me first state what I mean by stochastic heat equation. So I'm still considering, well, the same kind of equation. Well, the same kind of noisy term, which is linear, right? We could also have a non-linearity here, the sigma of ut, but just for sake of simplicity, we'll stick to this linear setting, right? So u times w dot. Here on the left-hand side, you have a second derivative with respect to time, and on the right-hand side, we still have one-half of the plus operator. And right, so this is just the wave equation perturbed by this noise here. And again, we would like to have a general X in R D, a general Gaussian noise with a certain space-time covariance structure, and we would like to consider again the Stratanovich or pathwise differential or the score differential. So, again, a little bit more about the noise. So, here I'm changing a little bit the setting. I'm sorry about that. Again, the covariance function for my noise will be something, well that's as before, right? I'm just writing negative alpha 0 instead of 2h minus 2, right? So it's t minus s to a negative alpha 0. S to a negative alpha zero, and you have a certain covariance in space. And we are just assuming some scaling property for gamma. So it could be a power function as before, but we can do more general. So you could have a gamma CX equals C alpha gamma X. And in fact, we can do even more general than that. In fact, we can do even more general than that. Um we could have a a um condition which is called of a Dallant type, right, involving the spectral measure of gamma or the Fourier transform of gamma. But just for sake of simplicity, I'm sticking to this scaling property. We can, if we have such kind of noise, Such kind of noise, right? With this scaling here, if you fix time, you know more or less what's the regularity of your noise in space. You can place your noise into a besoff space. I'm not writing all the parameters of the besoff space, but the regularity parameter is negative alpha over 2 minus a little something. So if you have such kind. So uh if you have such kind of covariance you you know what kind of very likely right um yeah maybe some simulations uh uh this is basically what uh why I wanted to have my iPad so I have some uh simulations of the uh wave equation just to show you that this uh intermittency phenomenon is also valid for the heat equation so let me compare here two simulations Compared here two simulations. So, one of the wave equation with an additive noise, right? Again, on 0, 1. And with the, here we can afford to have a space-time white noise. We're in dimension 1. Let me try. Let's see if I can do that. Okay, so you can see right uh Okay, so you can see, right? Uh what you see is uh this is the deterministic part, the stochastic part, and you just have a perturbation of your right wave equation. But here you have an additive noise. So your stochastic equation is just a perturbation of deterministic. Let's compare this with Well, the Anderson type noise, right, with the U times W dot, right? Again on 0, 1 with a space-time white noise. That one. It doesn't work too well. Right, so what you will see is more like say tsunami. Like say tsunami time, after a while you will see again some high peaks up in there. You have to wait a little bit you have a kind of exponential growth right to the maximum of your stochastic wave equation. So that's part of the motivation to also study this wave equation to to see This wave equation to see if we can reproduce the intermittency landscape we've seen for the wave function. Alright, so the way we solve the equation is by considering the MIDI formulation. So we're considering what is the fundamental solution of the wave equation. There's a function describing that. I will tell you a bit more. Describing that. I will tell you a bit more about that later. And instead of solving the wave equation, so maybe here I've tried to make something simple, but it's too simple. I think the solution here would be zero. So let me say that here, instead of zero, you could have five. Right? And then here you would add some deterministic. But the stochastic current term, which is the important one, would be integral 0t, integral of Rd of Gt minus SX minus Y, US of Y times W. But you have to give a meaning to this kind of integral, which could be either a score of integral or a rough path type integral. What about the fundamental solution? So the point is that this fundamental solution will become ugly as the dimension gets larger. So if d equals 1, this fundamental solution is just an indicator function. If d equals 2, the fundamental solution will be still an indicator function, but you have this singularity here, right? Here, right, of square root time. If d equals 3, your fundamental solution becomes a measure. Rho t is the uniform measure on the sphere with radius t. And you divide this by t, you get an extra level of singularity. And then for d larger than 3, you get some derivatives, well, some sums of derivatives of this guys. Sums of derivatives of this guy, so it really becomes something off. Everything is nicer looking if you look at the Fourier transforms. The Fourier transform in space, so this is the Fourier transform in space only, not in time, is just sine 2 pi t magnitude of x divided by 2 pi psi. So some of the computations are easier. Easier. Right. So what about the results we get in the score hog regime? So the main result here is this one. So we consider this wave equation in the scorehot sense. So again, the usual product is replaced by a weak product. By a weak product. We have the same noise as before with the covariance function given by a t minus to a negative power times gamma of y minus x with the scaling, right, gamma cx equals c to the negative alpha gamma x, which also gives you a certain singularity of the covariance and of the noise. And well, basically, we're saying if you want to solve the equation, the Solve the equation in the scorehot sense, well, you cannot be too singular. And the exact quantification of that is that alpha 0 plus alpha should be strictly less than 3. So again, we get a very simple condition, and this condition is really necessary and sufficient. So everything is kind of neat in this cohort case. Of neat in the scorehole case, it's pretty common, right? It's much easier to quantify a certain number of things in the scorehot case. Let me tell you a little bit about some results which were obtained before us. So there's the first paper by Dallang himself, where the noise is a white noise in time. Is the white noise in time, eto setting, eto coincides with cohort in that case, and alpha less than, strictly less than two, right? And it's exactly our condition because in that case, for white noise, you can assume that, well, you can consider that alpha zero is one. So let me recall that our condition is just Alpha 0 is 1, you get alpha less than 2. There's a paper by Balan, where she considered something colored in space with alpha less than 2, so the same condition as Dalan's condition. And that's not optimal, because you expect something better if your noise is smoother than the white noise. Than white nose. And there's also a paper by Balan and Tuchin, Chachin and Lechin, where they consider only a noise which is spatial in time and they get this condition alpha less than 3, which also coincides with ours, right? If we have alpha 0 equals 0, we get also alpha less than 3. So we are improving slightly on those Slightly on those three points. All right. I will skip the strategy and tell you about uh pathwise approaches. Uh tell me how much time you give me. Let's say five minutes. Five minutes? You have to Five minutes? You're too late. Right, so yeah, if I have five minutes, I would like to tell you about some previous studies, more in the RAFA or regularity structure community. About what's been studied so far for the wave equation are additive perturbations of the wave equation. So you take again your wave equation here, second. Here, second derivative in time equals one-half plus u. You have here an additive noise, w dot, and you subtract a nasty non-linearity. It's negative ut squared. And the approach which has been mentioned this morning is to, when you have this kind of additive noise, is a This kind of additive noise is to consider that as a perturbation of the stochastic convolution, right? It's sometimes called the Parato and the Bouche trick. So you consider your stochastic convolution, let's call it psi. So it's just this Gaussian process here, right? Integral 0t Rd of Gt minus SX minus Y times your noise. So this is Gaussian, but it could So this is Gaussian, but it could be a distribution, if your noise is nasty. And then you get an equation for the difference, u minus psalm. This equation is a deterministic equation with random coefficients. There's no noise on the right-hand side of the equation here, but you have minus dt plus psi squared. Psi squared. And now the problem is that your might be a distribution and you should be able to define the square of this function. This is something Weijun had also in his phi34 problem or phi23. Again, if W is rough or the dimension is high or both things. Dimension is high, or both things happen. Then, psi is a distribution, you cannot define really psi squared, and you have to renormalize your equation if you want to get a solution. And the way to renormalize that is to consider some smooth approximations of the noise. You solve the equation driven by the smooth approximation un you consider a coefficient which is Which is exponential in m, n, right? So it's 2 to the n gamma, for certain gamma, times t. And, well, you consider this approximation, but the renormalization is here. You subtract this constant, which goes to infinity. You do that, right? There are some papers, like those two papers. Papers, like those two papers, showing that this converged. So, this is what has been done in the Roughpath community in the last past year. Our focus is different, right? Again, we want this noisy part, which would be say non-trivial, right? We want at least u times w that. But again, we could get sigma time times w. Time stop. Right, so this is in the paper by, again, by with the same guys, by Cha-Chen Deya Song. We consider again the might form of the equation, but this time in the pathwise sense. And what we are using, right, and this is something which is new, is the smoothing effect of the wave curve. Of the wave curve. So, this is extremely well documented for the heat equation. For the wave equation, there are some things, but we had really to find a new result in order to go forward. And the integration here, so we're not yet at the rough path level, and I might explain you why if I have time, we're still doing young type integration. Right, and what we obtain is that for the same equation. Obtain is that for the same equation in the Strapnovich sense with the same type of noise, right, with singularities negative alpha zero and time and this negative alpha in space. The condition on alpha zero plus alpha is much worse, but that's also usual for Strapnovich versus versus Skorhol, right? So we want alpha zero plus alpha So we want alpha 0 plus alpha to be less than 1 if t equals 1 and less than 1 half if t equals 2. So we believe that, right? So this is, we believe, optimal, but this is non-optimal. We can improve on that. But what the last thing I want to do is, I think, I think, But uh what the last thing I wanted to uh mention is that the method itself is interesting. It's based on some uh I I won't read the slide, but I just wanted to say that uh this is based on Stray Schartz estimates for the wave equation with waves, right, or for the wave operator if you want, and those are uh also new and uh this is in fact the main part of our job to establish this purely analytic result. Analytic rescuing. So I think I'm done. Thank you. Thank you very much. Are the questions? Smoothing, you mean strike arts estimate? What's this like this interplay between time and space regularity, right? When you said smoothing on the previous slide, do you mean strike arts, or is there another type? No, no, this is the one we. Well, we have a slight. One we well, we have a slightly different estimate, but this is really the one, the main ones, right? You fix time, right? And in fact, this is uniform in time. It's not like for the heat equation where you have a divergence in time. And you take a function which is in a base of space. Again, I'm skipping most of the exponents, right? The regularity is alpha. Then, applying Then, applying your operator, this would be the operator with kernel gt, you're able to get to a better besides space, right, with exponent alpha plus rho d, and this rho d is one, dimension one, and one half as d equals two. This is not optimal, and plus we are not able to treat the d equals three case because we at this point. Case because we at this point in time we still need the kernel to be a function. I have a quick question. At the beginning you said there are different definitions for what intermittency means. Well I mean the the one I've I've given is based on moments. Is the one when you talk by the physicist about intermittency? The one they would write down or not? The one that would write? I don't know. Well, I mean, probably the physicists would go directly to the description of the peaks, but this is also done for a large class of equations, right? You can describe the maximum, you fix time, and you will describe the maximum of the function over a certain region. You can also prove that those are large with respect to all the remaining points. But you would start from, I mean, the building block would be Building block would be this estimate. Alright, if there are no further questions, then let's thank Same once again and all the other speakers if they are fun. So, Kristin and I will go for a short walk. Only we hear five minutes or so.