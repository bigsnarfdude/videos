Jason. All right. Thank you, David. Okay, so I'm Jason Poulis. I'm a postdoc at Harvard Medical School. This is work that I started in my postdoc at Duke and Samsey with Fan Lee and colleagues. And it's very related to what we were just talking about. So this is a panel data setting of N units. Setting of n units with t time periods, we have a binary treatment. We have potential outcomes that are a function of the binary treatment. So potential outcome under control or potential outcome under treatment. And the fundamental problem of causal inference we know is that we can only observe one of these potential outcomes at a time. We also have this initial treatment period. This initial treatment period TO. So, for simplicity, I'm just treating this as a one-initial treatment period. But we can think of more complicated settings where each treated unit enters treatment at different times. I'll talk about that later. So, in the standard setting, so it's we call the forward-looking setting, we have two groups of units. We have never Two groups of units. We have never treated units, which we don't observe. We observe their potential outcome under control both before and after treatment. And then we have a group of what we call in this paper later treated units in which we observe their potential outcomes under control in the pre-period and their potential outcomes under treatment in the post-period. So that's a standard forward-looking setting. And in that setting, Looking at setting, and in that setting, we're typically concerned with imputing the potential outcomes under control for these later treated periods. So what would happen if they were actually untreated? In our retrospective setting, we don't have access to never treated units. And instead, we have always treated units as a comparison group in which we observe their potential outcome under treatment both before. Treatment both before and after the treatment period. And just to further elucidate this, you can think of potential outcomes under control in the scanner setting as a, this is an n by t matrix where the checked values are observed values, the question marks are values we wish to impute. And so again, so we're in the standard setting, the forward-looking setting, we're interested. Forward-looking saying, We're interested in imputing potential outcomes under control for these later treated units after treatment. And so after we impute this quantity, we can essentially plug it in to the causal estimate, which is the average treatment effect on the treated units. And we can also, so that gives us. So, that gives us a per-period treatment effect. So, after treatment, so these were periods after treatments. And we can also take the average of it. So, what's the average treatment effect on the treated units in the entire post-period? So, in our retrospective setting, we essentially just invert the standard forward-looking setting. Standard for looking setting. So here we live in the world of potential outcomes under treatments, where everything is observed except for the later treated observations in the pretreatment period. And this is the quantity we wish to impute. And so after imputing that, the same thing, we just plug it into an ATD estimator and we can get an average three. An average treatment effect of the later treated units in the pretreatment period as though they were actually treated the entire time. And so that's our quantity of interest. So I just want to talk about different treatment assignment mechanisms. So here Here, this is a staggered adoption case where the treated units enter at different times. So, this is from language from Athe et al. I talk about this idea a lot. So, for instance, you can consider the case of adopting a technology. In the first row, we always observe their outcomes. So, this is like a unit. This is like a unit that never adopts the technology. And you can also think of units that adopt the technology in a later time period, units that adopt the technology mid-period, and units that adopted technology like very early. And so you can think of, in this case, the initial treatment time TO as like a vector. As like a vector, n-length vector that contains different times of treatment. But for the purpose of this talk, I'll just talk about the case of simultaneous adoption in which there's just a single initial treatment time. I just wanted to bring that up. And since this is a computational advertising, Computational advertising conference. I want to also talk about the Netflix problem. And so the Netflix problem, we have the N users. So N is the rows. And then T, instead of time periods, we have movies where each entry here is a rating of a movie. And so each user only watches, you know, User only watches, you know, like a few of the available movies. And then, in the Netflix prize challenge, there was like, I don't know, like 100,000 movies and many more users. And so like the entire size of the Matrix were in the millions. The matrix is very sparse. So like, of course, a person doesn't watch every movie. They just watch a few. And the task is to predict the question mark. The question mark. So, we want to know how a user might like a movie based on what they have watched and rated, and also based on what other people have watched and rated. And so, unlike the treatment assignment mechanisms that I'm talking about, this is just kind of Just kind of more of a general missing data pattern. And we can think of in this problem a few unobserved factors, such as movie genre and like the year the movie was released, contributes to ratings. And this is going to be important when we talk about matrix completion methods for imputing these missing values. These missing values. Okay, so this, I'm first starting with interactive fixed effects estimation because this is very much like matrix completion, and it helps kind of elucidate the retrospective analysis. And so, this is from the Ju et al. paper that was mentioned in the chats in the prior. Chats in the prior talk. So we can model potential outcomes under treatment and we can decompose these potential outcomes in terms of factor loadings or unit specific intercepts or unobserved and unobserved factors. So these are the time-varying covariates. And so we can think of potential outcomes under treatment as being the product of the factor loadings and the observed factors. Factors. And our goal here is to estimate this unknown matrix L, which is just the product of these two. And in order to do so, Jew et al. and IPE methods in general rely on fixing the rank R. I should also note that this is similar to previous like econometric Econometric IPE method, such as BY in 2009, in which they propose an IPE method based on fixing R. And so we can partition this unknown matrix, which is the product of the factors and the factor loadings, according to this before and after design. And we can model the observed parts of the potential outcomes under treatment in terms of the observed. So the observed part, so we observe the always treated units in both periods. So we have information on the factor loadings and the factors both before and after treatments. For the later treated units, we only Data treated units, we only observe data in the post-period. So this is their factor loadings and the factors only in the post-period. And we use these two equations to estimate. So the first equation is used to estimate the factor loadings for the always treated group. Group and the factors before and after treatments. And the second equation here is used to estimate the factor loadings for the later treated group. This should be in the post-period. And so ZUI at all, so they actually have a cross-validation method for selecting. For selecting the rank, but this is equivalent to regularizing by norm, by the rank norm. And these predicted estimated quantities we can use to predict the missing potential outcomes. So the missing potential outcome for the later treated group in the pre-treatment period. Again, this is the retrospective. Again, this is the retrospective analysis. So, two estimation issues. This is actually, both of these issues are pointed out by Athe et al., which I'll talk about in a second. So, first of all, the estimation of the factor in the pretreatment period isn't efficient because we don't use all the observed data. We only use the data on the control unit. On the control units. So, in the retrospective case, that's the always-treated units. And it also doesn't work for staggered adoption settings, especially when there are too few controlled units. So this approach by AP et al. we like better because it doesn't require fixing the rank. Instead, we're assuming that the rank is low relative to the dimensions of the Relative to the dimensions of the data. It works with the staggered adoption setting, and it's more efficient because we use all the observed data to estimate factors. So here, matrix completion estimation. So this is the outcome model of the potential outcome under treatment. This is the same as proposed in APL 2017. 2017. There are two key differences. One is in our setting, we're concerned with retrospective analysis. So we're in the world of potential outcome under treatment. We also introduced this covariate X with a time-varying covariate coefficient beta. Like Ethi at all, we include unit and time-specific fixed effects. Specific fixed effects. And these are thought to measure, to capture unmeasured confounding. And like Zhu, the paper of Zhu, we also assume that the errors are conditional zero and conditionally mean independent of the treatment. And so this is akin to like an exogeneity assumption in or an unconfoundedness assumption in the econometrics literature. I think the only difference here is that we're also conditioning on the unknown matrix L. So, to estimate L, we're principally concerned about estimating L, but we also estimate beta and the fixed effects. We're training on the observed values. So these are the values for which treatment is on. So this is all the always treated values, and this is the values of the latest. The values of the later treated unit in the post-treatment period. So, this is all the observed values. And we estimate these quantities through regularized least squares. So the regularization term here is a nuclear norm. And so this is included to yield a low-rank solution for the unknown matrix. We also include, so this is also different from H. So, this is also different from ATHE et al. So, we include a vector L1 norm on the beta coefficients. And so, this is kind of like a lasso regularization to kind of shrink the space of the covariate coefficients. And the regularization hyperparameters are chosen by cross-validation. And this actually can get pretty computationally intensive to. intensive to choose both of these hyperparameters at the same time. Also different from the AP at all is we have here a weighted loss function. So the weighted loss function places more emphasis on the loss for the IT values that are observed that are most similar to the IT values that are in our test set. So the ones that we want to That sort of the ones that we want to compute in terms of an observed covariate. And so, in the paper, we talk about this a lot more. So, the propensity score, so that's the W hat here, you can actually just impute that through the same matrix completion method. So, when calculating the propensity score here, so you're instead of having a Y. Of having a Y outcome, it's your treatment matrix, and then you also include the covariates and the fixed effects. And your L here is used to reconstruct the treatment assignment matrix, and then you use those predicted values to estimate the propensity score. Okay, and so you can think of this as balancing the treaty groups and the control groups in terms of their covariates. And so with the predicted quantities here, we can reconstruct the potential outcomes under treatment for. For the unobserved value. So, this is the later treated units in the pretreatment period. Okay, so we run some simulations just to see how good the matrix completion estimator is. And so, in these simulations, we discard the pre-treatment data because we don't expect there to be any treatment effect. Expect there to be any treatment effect in the post-treatment period. So, we're using a real data set here that I'm going to talk about next. And for each run, we're randomly selecting half of the units as treated, and we're predicting their missing values following a placebo initial treatment period. And we're evaluating the performance of these estimators in terms of RMSC on a test set, comparing the actual. Comparing the actual values versus the imputed values. So we know the ground truth in this simulation. We compare with two different estimators, a difference in differences regression of the outcome on treatment assignment and with unit and time fixed effects. And then this is a generalization of the original synthetic control method for multiple treated units. Multiple treated units. So, we're regressing the pre-treatment outcomes of each treated unit on the control unit pre-treatment outcomes. And we're imposing the same restrictions of the original synthetic control paper, which is a zero intercept and non-negative weights of some to one. And I should also note, so this estimator we're using is without covariates to compare with these two other estimators that don't. These two other estimators that don't use covariance. So, this is essentially outcome regression. We have results in, so the left here is a staggered treatment adoption scenario, and the right plot here is a simultaneous treatment adoption scenario, where the x-axis is the ratio of the placebo initial treatment period to the size. To the size of the placebo data set. So, as X advances, there's more training, there's more data to train on. And the Y axis here is the average RMSC across 100 runs. And again, this is a real empirical data, which we know the ground truth. And in both settings, we find that the difference in differences and matrix complete. Differences and matrix completion. Basically, the performance improves as more data becomes available. And matrix completion in both settings does as well or better than the other comparisons. So I don't know why the synthetic control method, it seems to be overfitting, at least in one scenario. Least in one scenario. Okay, I want to just briefly describe the empirical application that motivates the retrospective analysis. So in this paper with Fan Lee and co-authors, we are looking at the impact of two milestones of European integration on. European integration on cross-border employment in Europe. And so the two milestones are the Schengen Agreement and the Free Movement of Persons or FOM. And so both of these milestones have the intended effect of integrating the European economy by facilitating border crossing and increasing job search across the border. Okay. So the data set is the European Labor Force Survey, and which we aggregate to the region level between 2005 and 2019. The limitation of this data is that most of the available control regions in the survey data set already entered these two milestones in 2005 when we started. In 2005, when we start the analysis. And instead, so this motivates the retrospective analysis. We want to compare the border region that had already entered the study period, the OIST treated units, with those that entered sometime during the study period. So the OIST treated units, that's in the pale blue. So this is countries in Spain and France and Germany. Spain and France and Germany. We have two different types of groups of later treated units. So we have this, what we call the Eastern group. So this is in Poland. Not really good with my European GRV. And then our second group is this cluster of regions that surround Switzerland. And so both of these later treated groups have different initial treatment. Different initial treatment times. So, this is why I'm talking about staggered treatment adoption is because, so the group, the Eastern group entered both treaties by 2011, and the Swiss group entered both treaties by 2009. And so, in this analysis, we're looking And so, in this analysis, we're looking at the combined effect of entering both the Schengen and the FOM. So, in this plot, we have in the top, we have the observed time series of the always treated. So, this is the red dashed line. And this is, we're looking at the percent of individuals working in border regions. So, the share working. So, the share working conditional on those who works. And so, in the OECD units, as expected, there would be no, just looking at the observed data, there's no impact on entering these milestones on their share of cross-border workers because they had already entered years or even decades before. For but for the always for the later treated units, so this is this the solid line here is the eastern later treated units, and the orange here is the Swiss units. So we notice, so for the eastern units, they enter both treaties by 2011, and we can see just descriptively a big increase in the share of cross-border workers. And the same for the And the same for the Swiss units. So they enter both by, I think, 2009. And we also see an increase here. The trials here are the nature's completion predictions. So this would be, for instance, the predicted values of the later treated units in the Swiss group had they always been treated. And you can see it's kind of like a flat. And you can see is kind of like a flat trajectory, like the always treated groups. And similarly, the circles here are the predicted values of the later treated groups in the eastern cluster. So this would be like the values if they had also already been treated. And we just difference the estimated values from the observed values, and then you can get a treatment effect that varies over. Treatment effect that varies over time. So, this is actually kind of very much like the Broderson et al. paper where they look at the evolution of treatment effects over time. So, their treatment effect, they're looking at the effect of advertising campaign on number of clicks. So, this is the effect of entering a European institution. The European institution on share of cross-border workers. And so you can kind of see in both groups, the treatment effect increases over time. These per, we're estimating confidence intervals with bootstrap in the per period time point. However, we want to know more importantly what's the overall treatment effect in the post-treatment period. In the post-remint period. And then to do so, we do a bootstrap. We're removing the time component. So we're bootstrapping over the trajectories. And so we can estimate. So this is the treatment effect of the later treated units in the pretreatment period. And we can get a single estimate of what the overall effect of these policies were. And so an interpretation of this estimate would be had the Schengen and FOM been implemented earlier, there would have been a 0.8% higher share of cross-border workers in Eastern European regions. We don't assume, we don't find the same treatment effect in. Effect in the Swiss regions. Importantly, we also estimate this treatment effect using differences and differences and synthetic control. We find like very similar point estimates, which is encouraging. Okay, just to summarize what the contributions are, we introduce a framework for a retrospective causal inference comparing always treated units with later treated units. Units. We extend the matrix completion estimator proposed by AT et al. using a propensity weighted loss function to correct for covariate imbalances between treated and control groups. We're currently running extensive simulations looking at whether this propensity weighted loss function works. Works the way we want it to, and it comparing it's just the matrix completion approach proposed by Atheol. And it seems as though this weighting the loss function makes a very big difference in lowering the error of these causal imputations. And in the paper, we also talk about a procedure for imputing endogenous covariate. For imputing endogenous covariate covariate values, so when we have covariate in the outcome regression, some of these values are endogenous in that the values occur. We observe values that are endogenous and we have to impute them the same way that we impute the potential outcomes. And so that's also discussed in the paper. Um, so this is the uh the main paper that presents the retrospective analysis, and so this is on archive, and then I have a GitHub here. And so the GitHub also talks about it includes the matrix completion estimator that has the propensity weighting and the covariate. So you can use that. The paper here applies to matrix components. This applies to matrix completion in the standard forward-looking case. And so, again, it's on archive, and there's a GitHub link there. And I thank you for your time, and you can take questions. Thank you, Jason. This is very cool. I have a question, but I asked too many, so let me throw it open to other people first and see if anybody else would like to chime in. Chime in. Well, Jason, one of the things that I liked about what you were doing is that you didn't pay equal attention to predicting all of the unobserved cases. Instead, it seemed that you were able to upweight the effort for some and downweight the emphasis on others based on co-op Emphasis on others based on covariance. And in the context of the Netflix example that you used, I wondered if there might be ways to do that that didn't reflect a covariate, but perhaps some prior belief or some other type of possible information or opinion. Maybe you don't want to estimate romantic comedies very well, but you do want to estimate ratings for horror movies. Ratings for horror movies precisely. Yeah, I think there, I think about this a lot. I think there are two different ways about it. I think you can use the approach that I just talked about, which is basically so here that the missing values are those to be imputed, and so you could. Computed. And so you could create kind of a treatment model. You can basically do the same thing where you create propensity scores based on other covariates you have and then wait a loss function to impute the missing values using those predicted values. So I think you can do the same. Value. So I think you can do the same approach. I think that would be the most straightforward thing. I think there is also a thing, I don't know much about it, but there are recent papers proposing like kind of multi-graph matrix completion where you have the ratings matrix, but you also have a matrix for like other things that you just mentioned. That you just mentioned, like other types of information, and how do you? And so, with these multi-graph estimators, you can kind of leverage knowledge from the other graphs to impute these missing values. That's interesting. Three of the talks in the workshop have to do with tensors. Have you thought about tensor completion? Yes. Yes. Yeah, I think that's very related. Again, like, I don't really know much about it, but that was definitely like an avenue I was thinking about taking this type of research. Because, for instance, like in like in the causal inference context, it's very similar. You might have You might have a matrix for outcomes, but you also have a matrix. You also have different covariate matrices. You might have just more information that you can use to impute these missing values. So yeah, I think the tensor approach would work. And I think there are papers out there that use kind of a tensor model. Thank you. Hi, Jason. Yeah. Thanks for presenting this very cool work. I find it very interesting. Yeah, so from your simulation result, it seems that synthetic control is not a good method, at least in your application. It's like it tends to overfit. It like compared to the difference in difference in your mature completion methods. Yeah, so I don't really, so to be fair, this isn't the synthetic control method proposed by Abby et al. 2010. This is kind of a generalization. These are the synthetic control method proposed, originally proposed, is for a single. Is for a single treated unit. And then in this setup that we're doing, we're interested in imputing potential outcomes for multiple treated units. So what this synthetic control is, is basically running a model, fitting a model for each treated unit. And so I think that's part of the problem. I think when you do that, you lose a lot of information. You're losing information from the other treated units whose values are observed. Whereas in matrix completion, it uses all the observed values. And so I think there's definitely an efficiency argument for using the nature's completion approach rather than this synthetic control approach. So, I think that might be maybe part of the explanation as to why this integrated control approach doesn't do as well. It makes sense. Makes sense. Thank you. And another thing, I see that when you fit in the confidence interval, you are using the bootstrap. Like the industry bootstrap is like a kind of like a voiding topic because it's like a heavy engineering burden. So, is it possible to have Is it possible to have some close the form confidence interval so that it's like computation no easier? Yeah. Yeah. So for computing the per period bootstrap confidence intervals, it is like very computationally intensive because we're shuffling the time periods. shuffling the time periods. And so yes, that it's for doing the for doing the bootstrap for the single trajectory, counterfactual trajectory estimate that I showed at the end of the table, you're removing the time component. So it's actually like not too, it's not, it's very quick to run. So I guess I don't know if you have ideas. So, I guess I don't know if you have ideas about other things to do. Like, this is um, so this is papers under review, and that the um reviewers had like a lot of questions about how we do the bootstrap. And I'm sure there are like better ways to estimate a competence interval. Um, so if you have ideas, I'd like to hear it. Thank you. Yeah, and uh, since I don't have much background on the difference in Have much background on the difference in difference. So, is that like a difference difference method can provide some like close of warm confidence interval? So, the difference in difference estimator we use is also kind of a generalization. So, it's a regression of the outcomes on the treatment matrix with unit in time fixed effects. And so And so there's a paper that's that's that describes this method. So that's the Atheon Imbins 2008 design-based analysis and difference and differences. And so in here they use, they basically adopt diff and diff in the setting. Diff and diff in the setting with the staggered adoption setting.