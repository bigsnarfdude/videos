Very good memory. So it's about mainly TDLC groups, and I want to ask: what does it mean that such a group is computable? It's joint work with Sasha Mernikov, who has devoted a lot of his career to what's called computable mathematics. And well, I hope he's here. Are you there, Sasha? Are you there, Sasha? Yep. Yeah, very good. Excellent. So, first, I give some background on computable structures, given that most of the audience is probably from a different area where it's maybe quite foreign. I'll try to do full screen. So, for countable structures, it's not too hard to imagine what it means that a structure is computable. But if you have forgotten all your computability theory, here's a bit of it. It started in the 1930s and people tried to formally define what it means that a function is computable. And they had various definitions. One was due to Alan Turing, the pretty fashion. To Alan Turing, the pretty famous Turing machines, which are abstract computational devices. And this definition says a function is computable if such a machine only inputs n1 to nk outputs the value. Several other machines have been introduced and even a definition that doesn't use machines at all, but rather builds up the computable functions by some simple operations. Those are called. Those are called recursive functions, then. Though it's really not all about recursion, it's a misnomer, if you want to know. The church-turing thesis then says that this is really a notion that's independent of the particular formal definition, and the notion is the same as intuitively computable by some algorithm. Most people accept this and then actually never bother writing a machine in detail, they just give the algorithm. In detail, they just give the algorithm, all right. So now let's look at structures. A structure in mathematical logic and lots of maths is just a non-empty domain with relations and functions defined on it. And now if the domain is n and these functions and relations are computable, then we say s is a computable structure. Sometimes, maybe the often the elements are not numbers, doesn't matter. Numbers don't matter. More generally, you just say a structure is computable if some copy of it with domain exists and exists, and that copy is computable in a more narrow sense. And if you take it in that wider sense, anything like the integers, rationals, even the SNQ and many other countable groups are just computable. That's great. And for finitely generated groups, being computable is the same as the word problem is decidable. So you have to imagine that, for instance, matrices of determinant one over Q are encoded by natural numbers or by strings if you want. You could also define Turing machines running on strings. Machines running on strings, which is maybe more natural. So it's up to some effective encoding. The structures are computable. Now, a lot of math is about uncountable structures. So what does it mean now that the structure is computable? That's harder because elements of an uncountable domain can't really be inputs to a Turing machine. And what one does, broadly speaking, is use a countable structure of approximations. Structure of approximations to the elements, and that structure is computable in the first sense. For instance, the reals are the completion of the rationals as a ring and with respect to the Euclidean metric. And that metric is computable on the rational numbers, because the distance of two rationals can be computed. So, in that sense, the reals are computable, and that's the beginning of a whole field called computable analysis. Called computable analysis, where then you also study how functions on the reals like e to the x are computable. All talking really about approximations. It's even close to numerical mathematics where people also work with approximations. If we take a different metric, such as the periodic metric, we get a different completion, the periodic numbers, and that's also computable in my sense. For profinite groups, well, we look at the diagram, and that's my computable structure if you want. Though it's not a structure in the sense of domain relations and functions, it's a sort of more general structure. So you bend the notion a bit. But so that diagram is the approximation structure, and that whole diagram in its entirety should be computable. So the final groups, the maps between them are computable by one single machine. All computable by one single machine. So that notion has been studied for 40 years now by Laroche and Smith, ups and downs. One was a student of Nero, I think. So they have early papers in the Journal of Symbolic Logic studying what it means for a profinite group to be computable. I'm looking at TDRC groups later, and our definition will extend that definition, though it looks quite different. Though it looks quite different. And it will also extend the division for discrete groups. All right, so we often will look at closed subgroups of S infinity and outside locally compact, you can also look at computable closed subgroups of S infinity. Let's start with the group itself. So I want to represent it nicely by a tree. Nicely by a tree. I can't just take the functions directly because it's hard to see whether a function is onto. That's not a computable thing. So I have to be a bit more careful. So what I do is look at pairs of functions. One is the function itself and one is the inverse. And I somehow ensure that there are inverses. So some notation, if I have strings, sigma i, I want to denote by sigma zero plus. I want to denote by sigma 0 plus sigma 1 here the alternating string going back and forth between sigma 0 and sigma 1. And now the approximation structure is a computable tree. Denote the tree sim of n, a bit clumsy maybe. So here's the definition of that tree. It's all the pairs sigma plus tau, where both strings are sigma one, are one one. So as maps only natural numbers, and it's consistent with tau being the inverse of sigma. So whenever sigma of tau of k is defined, it should give k. And whenever tau of sigma of i is defined, it should also give i. One feature here. Let's see if this works. Um probably not, but um can you see my white slide? Is this visible? Looks okay. Yes, it's all great because the thing I wanted to use didn't work because of my connection problems, so I have to improvise a bit. So here we have sigma. Well, sigma maps 0 to 1, so try has to map 1 back to 0. Sigma maps 1 somewhere else, so it doesn't matter. Here the length of the strings is just 2. So in the example, sigma is 1, 3, tau is 2, 0, and sigma plus tau is 1, 2, 3, 0, namely alternatingly. Got it? So that way. So that way we can just view the permutations as paths on that tree. Oh, no, not this one. This is summer in Russia, by the way. But I guess we don't want to travel currently. So if I define my tree like this, then the path can be right away viewed. Like this, then the past can be right away viewed as permutations of n paired with the n verses. And that tree is computable. So that tree gives a computable presentations, presentation of simn, because also the operations are computable. Well, in a sense, I haven't quite defined using Oracle Turing machines. So if I have a permutation, I just swap the two components to get its inverse. Components to get its inverse, and I can combine them just concatenation of the functions, and those are all given by elementary operations on the tree. Questions about this? No, what are the edges of the tree? Sorry, so the is what you define the verse. Is what you define the vertices? I'm not quite seeing a relationship in the tree. Oh, it's the tree of strings, tree of strings. So the okay, right, yeah, okay. I have two kinds of tree in this talk. So tree as in computer science means usually a downward closed set of strings. And this tree also has no dead ends. The vertices are the strings, yeah. Okay. But there are no leaves. Yeah. Yeah. Yeah. Yeah. Just like all strings over the natural number, that's and when you extend the string, you get descendants. Descendants are one element longer, yeah. But in this case, I only look at strings of even lengths. Okay, sorry, this is actually needed. So now let's have a quick look at DDLC group. Many people here know more about this than I. The fundamental theorem is Fandansik saying there's a compact open subgroup. Saying there's a compact open subgroup, and therefore the compact open subgroups form a neighborhood basis of one. And using that, you can show that each TDLC group of a separable here is isomorphic to a closed subgroup of the symmetric group. Namely, just the left action on the compact open cosets gives one way to embed it as a closed subgroups of S infinity. S infinity. So examples that I will come back to later: the p-adic numbers and also odd TD, which is the thing I learned about in Newcastle. Td is the tree of very, no, it has degree three, no two. And here now there are undirected trees. So connected graph with no cycle. RTD is the group of automorphisms of the Group of automorphisms of that tree studied first by TITS, and it has some nice properties. Actually, each proper open subgroup is compact, and each compact subgroup contained in a stabilizer of either a vertex or an edge. So we sort of understand the compact open subgroups. And that's useful later. Okay, those two are my running examples and also algebraic. Running examples and also algebraic groups over QP. So, what's the plan? Introduce computability for TDLC groups. Actually, I have two definitions, which sounds bad, but in fact, they are equivalent. They are quite different looking, but in fact, equivalent. That's nice. It adds robustness to the notion. And the difference is what the countable approximation structure is, namely first. First, I view G as a closed subgroup of S infinity, or sim n, I should say, and the tree of finite injections that can be extended to automorphism, meaning a permutation in G. That's the approximation structure. So for RTD, that's probably the natural approach. And the other approach is quite different. You use an order. Is quite different. You use an ordered group weight. I'll tell you what that is of compact open cosets. That's the approximation structure, and that works nicer for QP and SLN of QP. All right, let's carry out the plan, definition one, via closed subgroups. I need a few more definitions here, unfortunately. And stars, the tree in the Stars, the tree in the computer science sense of strings. And if I have a computable sub-tree without dead ends, that's now a nice topological space, totally disconnected space, or rather the set of passes. And it's known, of course, that that set of paths is compact just if each level is finite. And sigma t is the cone or subtree of things extending sigma. Extending sigma. I now want to define CLC trees, computably locally compact trees. And what's it mean? Well, first of all, I can decide whether the subtree above sigma is compact. In general, that's a quite complicated condition that a tree is finitely branching. It's not decidable, but I want that this is deciduable for some reason. And not only that, I also And not only that, I also want a computable function telling me how big the branching can be. So, given sigma and i, if sigma t is compact and rho extends sigma, then rho of i can be at most a function that's computable in sigma and i. So h is a bound of depth. Effectively finally branching. Picture again here. Sigma is here and rows is there. Rho of I is at most H of sigma I. H is a computable function. So, these conditions define the CLC tree. What's everybody doing, by the way? Any questions? Zoom talks tend to be really dry and not to say boring, so I'll try to make this a bit more lively. And yes, Baylor's coming again for some reason. For some reason, it always comes out. All right, so yeah, that's the definition. Now, definition one: recall first the definition of the tree for the symmetric group. And now that's not just called t because the other notation is too long. So, what just how would we define a closed subgroup of sin n is computable? It's called corresponding tree, namely all. Namely, all these things on that tree t that can be extended, that tree is computable. So I can see if there's some extension of eta, which is a permutation in that group G. Okay, that works. But for computably TDLC, I want something else. I want that tree, TG is a very nice tree. It's computably locally compact. All right, that's the definition that works. So we don't just know what's on the tree, we also know which nodes on it are compact and how big the branching can be below. In some sense, it's an effective version of saying GS final subaudits, meaning if you fix, say, one element, then the rest. One element, then the rest can only move around in finite orbits. It's very similar to that, and actually equivalent is the right notation. Okay, so first a bit more about computable subgroups without locally compact. So that's actually interesting by itself. These groups are just the well, close subgroups of SINN are automorphism groups of countable structures with domain n. We know that. Domain n, we know that. So we have a paper with Smelnikov and Greenberg and Toretsky trying to understand how this is related to the computability of the structure, but it's not a direct connection. So what it means to say that G is computable is that we can decide if a finite injection can be extended to an automorphism, assuming M is computable. So for instance, odd Q less than is computable. Q less than is computable because the condition would be the finite injection preserves the ordering. And that can, of course, be decided. By back and forth, it can be extended. Okay, great. So now let's look at RTD, and that one is computably TDLC. Why? Well, again, we can decide whether finite. Can decide whether finite injection on TT can be extended, namely just when it preserves distances on that undirected tree. So that's the first condition. Well, I talk about injections here. These etas aren't quite injections. There are only special cases of injections where you also drag along the inverse, but you can turn it. The inverse, but you can turn it into an injection and you can decide whether it preserves distances. So that's the first condition. But to say that the tree of G equals RTD is CLC, well, actually, whether the extensions are compact is easy. It's just any non-empty string has a compact set of extensions. And to get a computable bound, it's just really. It's just really again by having to fix the distances. If eta max maps x to y, it maps pnx to pny, the balls, and that readily gives the computable bound. The bound just says what's the biggest element that can occur. And of course, I think of the TD here as. The TD here is coded by numbers, so the notes on it are numbered so that I actually have a notion of computability on it. That's very standard to do in computable mathematics. And the picture for the last argument is down here. So eta maps X to Y. maps x to y and therefore the ball b2 of x say to b two of y and that means if anything extends eta it has to keep the distances and therefore i have a bound on the maximum value okay great so it is computerly locally compact Before I go to definition two, here's some things you can do with this. People have looked a lot at functions on TDLC groups, such as the scale, and wondered whether it's computable. Now, if you have a function on an uncountable domain, you first have to say what you mean by saying this function is computable, even if it's very. Is computable, even if its values are just natural numbers. So, in computability, there is a notion of oracle Turing machines dealing with that. It has an extra tape called the Oracle tape where some infinite object can be written, in this case, a path of Tg. And now I just let the machine run with that Oracle tape. It can ask questions as it computes. Is five in X and seven in X or not or so? And it can also have an input, which we just set to the empty string here. Input which we just set to the empty string here, and the machine has to halt with output s of x. That's the definition that's taught in computability classes. The intuition is that the value, of course, only depends on a finite piece of the oracle as the computation holds, but you don't know ahead of time how much. Eventually, you have to come up with a value using that much of the oracle. So now we can study if the scale is computed. So now we can study if the scale is computable on a computable TDLC group. Just the scale for conjugation for anomorphisms in general could be a bit harder to define. So any group you could look at, and if it's actually computable, TDLC can use this definition to see if the scale is computable. For narratives group, I'm not sure what the presentation is and whether it's actually computable, but once that's set. Actually, computable, but once that's settled, perhaps one could study that question. I looked at the previous talk related to that. Okay. Good news is that the scale is, of course, continuous and that's a necessary condition for being computable. George has shown that in 1994. Okay, so that's definition one. Sorry, any questions so far? That's my chat box. Anything there? Any questions? All right, otherwise, oh, here's one in chat. Good. Definition tools via approximation group points. What's the group point? Well, it's basically a group where the operation is part of the binary operation, otherwise same axioms. Or that's too weird a small category. To we add a small category where each morphism has an inverse. Small means the category is a set. So that's the same thing, actually. These occur a lot in various areas. And now if G is TDLC, I can define a groupoid W of G that's also a lower semi-lattice. So it's a lot of structure I get here. Actually, this works for a lot of other groups. I just want to make the group countable in a sense. To make the group countable in a sense by using certain open cosets as approximations. In this case, I use the compact open cosets. That's the domain of my approximation groupoid. I also put in the empty set, just makes it easier to formulate. Letters A, B, C are cosets, and the subgroups are denoted U, V, W. And the cosets are morphisms between. Cosets are morphisms between subgroups. If A is a right coset of U and a left coset of V, that's a morphism. And it's not too far-fetched. I mean, if U and V are stabilizers of sets, then A is in a sense a map between those sets. So the combination of cosets works just like you would expect in a category. And it is a group by because the inverse of the coset goes the other way. But what about the ordering? Well, it's just inclusion and easy exercise, the intersection of two cosets is the coset unless it's empty. So that's my meat operation. I had to add zero to make this a lower semi-lattice. So I have these two structures and they are, of course, related. For instance, the group. The group white operation is monotonic. And in fact, W of G satisfies axioms of something that has been studied by people independently. The whole books about it, inverse semi-groups are equivalent to inductive group heights, and W of G is an example of such an inductive group point. All right, so there. All right, so that's W of G. And where's this come from? Actually, a paper with Catherine Tent and Philipp Schlicht, where we looked at oligomorphic groups mainly. So oligomorphic groups are automorphism groups of random structures, or in the language of permutation groups, each n orbit is finite. Sorry, there are only finitely many n orbits for each n, just the opposite from finite. Opposite from profinite. So, in that paper, which just appeared, we used the term cost group, though it's not a group. And we didn't quite use these group points. We used a ternary relation between cosets, saying A, B is contained in C. Also works, but the new approach is maybe more elegant. So, now what should we say? How should we define computability in terms of these group points? In terms of these screw points? Well, simply we say that countable structure has a computable copy. The whole structure, including the meat. What's computable mean if you have a partial function? Well, first of all, the domain of the function should be computable. The relation of pairs where x, y is defined should be computable, and also the operations then are computable. The operations then are computable. So, definition two, G is TLLC, we call it computably TLLC if the whole approximation group point has a computable copy, but also the index of two subgroups in W of T like U, the index of U intersect V and U. That has to be computable. It's not just that w of t is computable, also that function has to be computable. This condition corresponds somewhat to the condition on the boundlessness in the trees. Give me a moment. Any questions? UP is computable in this sense. How is that? Well, there isn't much in the way of compact open cosets. The subgroups form a chain P to the RzP for some integer R. The quotient is always Cp infinity. So each compact open coset can be described by that R and an element in Cp infinity, because there's a natural transverse. Lateral transversal actually URCR0 CRA is that coset. So we have to index cosets and here we do it by an integer and a number in Cp infinity. And now all the operations are computable, as you can see here. Inclusion is computable because it's just a simple numeric condition. The intersection is empty unless one is contained. Section is empty unless one is contained in the other, and then we know what it is. And also, the index of UR in US, where r is less than r equal to s, is p to the s minus r. Maybe this would be US. No, it's correct. Yeah, it gets smaller. Okay. Good. So that's an example. And it shows you the approximation group. It's a bit like a diagram for a profinite group, but it goes also forward to coarser, less close approximations. And by that reason, any computable profinite group. Any computable profile group is computable in this sense. How about SLN? Well, also not hard. UR is a ring for R less than or equal to zero, and any compact subset of SLNQP is contained in SLNUR for some R because it's compact. So open here. So it means W of S L N Q P is. W of SL and UB is constructed from these compact pieces, W, SL, and UR, or coupons of compact groups. And that makes it easy in the compact setting, which means profinite. You can just look at the finite quotients and figure out all the operations there. That means the pieces are uniformly and are computable and is fixed here. And it's fixed here. So it's not just computable one by one. R is actually an input to the machines, and it's then computable. That's what's meant by uniformity. So that works actually for any algebraic group over QP. Now let me tell you a bit why these two definitions are equivalent. Got 10 more minutes, I guess. So I claim G. So I claim GS property definition one, if and only if it satisfies the condition in definition two. Well, left to right, so now it's a closed subgroup of sim n. And recalling the tree, we note each compact open subset is actually finite in a sense, it's given as a union of finitely many cones. And now we can use that set D here as an input to machines. For instance, we can decide whether the compact open set for D is compact and we can decide inclusion. We can compute, well, there's the computable function m so that this equation holds, so I can do the coupoid operation. Cooperate operation, at least in case it's defined and I can compute it in verse, all working on finite sets of strings. So I can decide whether a compact set is a subgroup, a coset, and even can compute the index u the index of u intersect v and u. The index of U intersect V and U. Just because everything is finite, and I know the branching width of the tree above in compact cones. Yeah, that's perhaps the easier one. And the other one is, well, a bit tedious, but not that much. It's really just the representation by left action on the compact open cosets, checking that's effective and makes. And preserves the computability notions. So, what to get G back from the computable approximation group point, W of G, call it G tilde, the group of permutations preserving the inclusion and the translation on the right by elements of W of D in this sense. So, that's the left automorphisms, if you want. Automorphisms, if you want. And now G tilde is actually isomorphic to G, where G is sent to the left translation line. That's the first to check. And now a bit harder to check that G tilde is computably T D L C in the sense of definition one. So we have to decide whether a finite injection can be extended. Injection can be extended and a few other things. And this is where we need that approximation group is actually lower semi-latters. We need a meat operation now because, well, if I have a pair sigma tau, sigma sends AI to BI and tau sends AI to CI, so tor is the inverse in the sense where these things are all cosets. Alpha can be extended. Alpha is the partial automorphism. Is the partial automorphism here if this intersection is non-zero in W of G because an element in there is basically one sending AI to BI and it's inverse sense AI to CI. That's what this says. And I can compute this intersection and know whether it's empty in that coup point. So that condition tells me I can decide whether alpha can be extended. Alpha can be extended. And the fact that the tree is computerly locally compact because of the index condition in the computable approximation repoid, which I haven't put on that slide. Okay, so two definitions looking quite different, but equivalent, which seems to indicate that this is robust and one application which is. And one application, which is in the paper we've submitted already, is the abelian case. So, in that case, the computability has a few more facets because Frandancy tells you that the abelian TDLC group is actually a nice extension of K, sorry, of L by K. This is the modern usage. This means extension of L by K, not K by L. So L is this. So L is discrete and K is compact. Okay, and now we've used that to give equivalent notions. Computable TDLC in the sense just defined is equivalent to being pro-countable in an effective sense. Each obedian closed subgroup of S infinity is pro-countable. And here I want, well, it's the inverse limit of. Want well, it's the inverse limit of a diagram of discrete abelian groups, everything computable as before, but also the kernels are not just finite. Also, there's a bound on the maximum element in the kernel that can be computed. All this holds for profile groups, but if basically now the last group is just any countable abelian group, but then the extent. and but then the extensions go finite only by adding finite finitely much and last condition perhaps the simplest here the extension is computable so it's there's a computable profinal group and a computable discrete group L, so that G is an extension of L by K where the cocycle C is also computable. Which means here that from a pair of elements of L, I can compute an element of K to as much precision as I want, as K is uncountable. These are all equivalent. It's in the archive version of the paper available. I won't talk about the proof and the last few minutes then are about Pont Jagen van Kampen duality. Do I have time? Do I have time? Oh, not really enough. Remember the dual of an abelian locally compact group is all the characters with the compact open topology. Pontragen, really Pontragen van Kampen's paper is three page long and extends the work Pontragen did on countable and compact groups to locally compact ones. And it says the natural embedding, the same as you know from Bernard spaces, is a topological isomorphism. Is topological isomorphism. Z becomes unit circle, which becomes Z again, and topological properties nicely correspond to properties of discrete groups, such as here. Connected is torsion-free, totally disconnected is torson. So, and the extension diagram just turns around. So, the duals of TDLC groups are actually just the extensions of torsion discrete groups by. Of torsion discrete groups by profinite groups. So L has to be torson. All right, and now we can, of course, ask whether computability is preserved by this process, though it's in general a bit complicated because the dual may not be totally disconnected. However, we have a result in that case. If G is computable, then G hat is always computable in the sense of R we have. In the sense of R, we had before, or QP, meaning there's a metric on a dense computable subgroup, countable. So in that sense, G hat is always computable. For instance, again, if G is Z, then I get a unit circle, which is computable in the sense that the rational unit circle is that subgroup. Just needed. Just needed digging into old Russian literature by Drobitsa and finding a proof that wasn't really there. So it's quite a bit of work to show this one. If G hat is also DDLC, meaning G is an extension of torsion discrete by profinite, then G is computable just if G hat is computable. So then it's an equivalence. Yeah, that's quite satisfying. That's quite satisfying, but it only works for those particular groups. Yeah, that's about it. And there are lots of questions left, such as computing scales for various groups and many others. Just look at the paper for open questions here, some literature hints, the main paper. The main paper about this talk is actually not available yet, but should be soon. Thanks, Andre. Any questions? Any questions? Yeah, I have a few questions. You seem to leave open the question of whether the scale is computable. If I understand correctly, the question is, if you have a computable group, then can you compute the scale? And that you seem to have left open. Is that correct? Yeah, I don't have an example. I don't have an example where it's not computable. I would think such a group can be constructed for profinite and discrete. The scale is always one, so that doesn't, the obvious, these obvious counter examples don't work. But I would think that you can make some artificial group where the scale is not computable, though it's computed, the whole group is computable in our sense. But for things like RTD or so. But for things like RTD, also I would expect it is computable. Okay, so for the automorphism group of the tree, you haven't shown yet whether it's computable. I don't know enough about it, but it would be nice to work with the people who know a lot about it to see if it is. Yeah, I think that sounds like a good project, I think, to try to work that out. I mean, for narratives grouping, as I said, it's not quite clear how to get that computable presentation in the first place because it's a group of almost automorphisms. But I'm sure it can be done in some way, and then perhaps one can also show the scale is computable there. I wonder if it relates to the To the word problem for Hickman-Thompson groups. I don't know. I'm sure someone here knows whether the word problem is solvable for Hickman-Thompson groups. I can't remember offhand. That might relate to whether the Neritans group is computer. Isn't it finitely presented, the Higgman Thompson? Finally presented, yes. Does it make if it's simple, finitely presented? If it's simplified, I represent it, but I don't. Yeah. So, yeah, that should be could be related. And I haven't really taken in your definitions completely, but I have a let me see if I can ask you a question about if I have a non-computable example. Suppose we take the direct product of the cyclic group of order P overall. The cyclic group of order P over all primes is that computable the direct product of the cyclic group of order P? Yes. Over a different prime. Product over the primes of the cyclic group of order P. Yeah, that's pro-finite, and you can make such a diagram that's computable. So it should be computable in the Right, so the kernels of the homomorphisms there in the direct limit will increase in size, they won't be bounded, but that's you know, I was wondering how that related to your one of your conditions there. Well, if the group is compact, I mean, it's it increases, it's not bounded, but there's a computable bound sort of for each length. That's all I want. I didn't want a universal bound. So, yeah, it's any profinite group that you can write down nicely is computable. But Smith and Laroche already came up with examples that are not computable. They're just not useful for the scale. Pro-finite examples? Yeah, they actually have a provider notion that in some sense says the right problem is recursively enumerable. That's the case where. Well, that's the case where the maps in the diagram don't have to be onto. So, and what Smith does is exactly find an example where the diagram is non-onto maps and the group you get is not computable. In the sense, there's no copy actually that's computable at all. That's his main result, I think. And all the papers you mentioned are on the archive, are they? Had any of them appeared yet? Or maybe the first one? Yeah, they are. All on the archive, except the one we are just finishing. So the one only about a billion groups is available on the archive and submitted already. One about targeting duality. Many. Sorry. Is that in the group theory section or somewhere else? Sorry, what? Which? Are these papers in the archive group theory section? Oh, I think it could be logic in the logic section. That's okay. Yeah, I wouldn't have seen this one. This one should be available online in the channel. Okay, maybe we should cross-pose them into the section. Yeah, we probably put at least keywords. Oh, yeah, I see for RSS feeds. Good point. Yeah. I had another question. Sorry, another question. Have you thought about whether this notion of computability is stable under certain group theoretic constructions? Theoretic constructions, say, you know, direct products or, I don't know, open subgroups or things like that. Yes, direct products should be definitely stable. Open subgroups, you need a sub-tree that's computable in the sense that you know what's on the tree. And if so, then yes. And if so, then yes. But more complicated constructions like extensions also, we haven't thought about it. Okay, well, it sounds very interesting and it sounds like there's a lot to do still. You probably think of this paper, building TDLC groups from bioelementary operations. Was it Philip doing this? Yeah, so then you could, of course, think whether any of those you get are computable. Yeah. I wish I knew more about that. He starts with pro-finite groups, and you say there are examples of those which are not computable. Yeah, but probably if you start with only computable groups, then what you get in his sense should also be computable. Maybe, yeah. Yeah, you probably have to restrict a computable extensions, whatever those are. Extensions, whatever those are, right? Yeah, then you have to talk about how the extension is done, co-cycle, and the action. So maybe I had a question that's sort of related. So your analysis of abelian TDLC groups relies on the fact that you have a compact open normal subgroup. So you sort of have a discrete group. So, you sort of have a discrete group appearing as the quotient. But then, there are, of course, many other TDLC groups that have a compact open normal subgroup. And then, if you take sort of increasing unions of such groups, that gives you an even larger class, which includes, for instance, all milpotent TDLC groups. So, I was wondering, like, how far you could, starting from these methods, build up. Starting from these methods, build up to a larger class of groups. Yeah, I think the extension should also work in a more general setting if you have a compact normal open subgroup. Well, you have to require one more thing that the conjugation induced is also computable, not just the two-co-cycle, but then I would expect, so that's probably something we should look at in this. Look at it in this paper still or in a later one. And certainly mentioned that I got interesting questions that shape the final version of the paper when we write it. Well, one question along those lines might be about the TD or C syn groups, so small and varied neighbourhoods or the projective limits of discrete groups. Discrete groups. So, there, I guess, you have a tree describing the projective limit and also your discrete group. And so, they are perhaps two pieces of data that you can decide whether they're decidable and see if that tells you whether the group itself is. Yeah. So, what did you call these groups? See. It's sorry, small invariant neighborhoods. Oh, okay. Fun abbreviation, yeah. Okay, I haven't looked at those, but again, it seems to be a construction from more elementary groups. And yeah, that's worth definitely one should look at that too. Syn groups, okay, good. Great. Yeah, and if you take a directed union of syn groups, that's exactly an elementary group of rank two in Phil's sense. So that's sort of the first non-trivial step on the hierarchy. Okay. Yeah, it's great. I wish I could visit you guys again, but currently we are in lockdown. Currently, we are in lockdown, and probably is Newcastle in lockdown too. Yeah, yes, it is. There you go. Yeah. So it's got to be an.