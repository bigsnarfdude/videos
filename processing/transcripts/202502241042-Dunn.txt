Exciting to conference. So thanks again, Linda, Betty, and Julian for organizing us to come here. And you know, it's such an amazing venue. I'm just like thrilled to be a part of this and such an apt like group of people. So it's a lot of fun. I was told by John that the title of my talk was still available, so I made sure it was different this time around than five years ago. This time around than five years ago. And I'm going to focus more on the digital biomarkers of pre-diabetes and type 2 diabetes work that my group has been doing. As I mentioned, there's another set of digital biomarkers that we're focused on that's more about infectious disease detection, mainly respiratory infection. So prior to COVID, it was flu, RSV, rhinovirus, then of course COVID, and so trying to use smartwatch data. So that's generally sort of the structure of our research. Sort of the structure of our research is leveraging data from smartwatches, ideally consumer smartwatches. So Fitbits, Apple Watch, Garmin, Samsung, like those types that people buy at the store, and trying to get large-scale data that is predictive of health outcomes. The last slide that I'll show in my talk is going to be about this online initiative that we're working on, the DVDP, that's trying to go from the code and data. From the code and data to building sort of like a community resource. So, those are kind of the overarching topics that I'll talk about. But I do want to define when I say digital biomarker what I mean because, you know, the FDA has a definition for what a biomarker is. The definition, the terminology that I'm using is not following the FDA's standard for a biomarker, but this is the terminology that I'm using to describe this kind of setup. This kind of setup where we basically had some target outcomes from this could be clinical data, so it might be information from an electronic health record like somebody's fasting plasma glucose or A1C values. It could be patient-reported data like EPROS or survey data. It could be just discrete illness events, maybe a diagnostic test result. But this is something that we would normally see collected in like an electronic health record, in standard surveys. In standard survey instruments, those sorts of things. And what we're trying to do is create this function, taking measurements in from digital devices, ideally multimodal measurements, so that we could capture more of the variance that's related to these outcomes of interest. And trying to then use whatever the structure of this function ends up being to generate hypotheses about physiology and its relation to these outcomes. And its relation to these outcomes. So, for example, if we see relationships between resting heart rate or heart rate variability in diabetes, does that give then a hypothesis that can be tested about the mechanism of how diabetes damages nerves that then relates to changes in heart rate variability? So, that is the overall structure of the digital biomarker concept that we're working with. So, I'm going to next talk about a pilot study that we did that then motivated a larger scale. But then motivated a larger study that is going on now, and I'll show some data from that larger study. I had a very talented PhD student who was here also five years ago, Brene Bent, who the work that I'm presenting here is really her thesis work. And so she is now Dr. Bent and has completed her thesis. And the data that she used for this was from a prospective study that we were going to do, as well as a retrospective cohort of data that. Cohort of data that I had collected during my postdoc at Stanford with Mike Snyder. And our question was: can we develop these digital biomarkers of clinical variables of interest around diabetes that are using only non-invasive smartwatch data. So we use the Empatica device, which collects heart rate, accelerometry, electrodermal activity, and I'm missing one, temperature. And it's higher resolution. It's now the current version of this is the Ampatica Embrace. What we're trying to do is use the higher resolution data of what we could get from consumer devices like Apple Watch snippets. So we had 16 people. So this is a really small data set. So I want to preface this with every, all the data that I'm going to be showing next is a small data set that then motivated the larger study. So we had 16 people. Did the larger study. So we had 16 people prospectively wearing a CGM, a contiguous glucose monitor, the empatica smartwatch, totally non-invasive. The CGX is minimally invasive, has the filament under the skin inserted with a needle. And then we had A1C tests done in the clinic. From the Stanford data set, 10 people with the empatica and the A1C, but no CGM. I'm going to show you the take-home. If you wanted to read more about how this was done, there's these two papers. But essentially, what we saw was that. But essentially what we saw was that for these biomarkers that were of interest, A1C, glucose variability, and interstitial glucose, we were able to capture the values and again not perfect predictions here, but there was variance in the data and also just kind of the ability to get like a low RFSE, low, I mean, Low MAPE of A1C values using just the smartwatch data alone. One of the other things that's really key to this is that the overall variance of the A1C values was lower in this cohort. So these were people that were mainly pre-diabetic and high normoglycemic. So one of the problems with that study design was that, sure, we could do a pretty good job predicting their A1C values, but it was a limited range. It was a limited range. So that made it easier. Even though these values are pretty good, we're not sure whether the reason for that is just the low variance in valence values. We also looked at metrics of glucose variability and interstitial glucose, and we found that we could, and this is a little bit more promising, because it doesn't much matter that these people are mainly pre-diabetic or high normal. Mainly pre-diabetic or high-normal glycemic because they still eat meals and have variants. So, that we could predict these glucose variability metrics and interstitial glucose pretty well was promising. And so, if we actually compared the performance of the A1C model, the current gold standard of predicting A1C from a measurement that is not a blood sample of A1C is this American diabetes. Is this the American Diabetes Association model that uses CGM data? And they have the EA1C model. So we compared the results of our models. We call them the Watch Random Forest, that's WACTHRF, and then we had a test on the data that we collected, the N equals 16, as well as the external test, which was the N equals 10 from Stanford. And what you can see is that the non-invasive, the watch versions of this model could predict A1C. Model could predict A1C as well as the ones that leveraged the CGM and did even better than the American Diabetes Association model. So that shows there's like room for improvement here. We could do a better job at making these predictions. But what was kind of interesting and surprising about this, we thought that there were going to be some variables from the smartwatch that would stand out against the others, but that's really not what happened. So you can see sort of the feature importances. The feature importances of these different features here, as well as what we were trying to predict here. And it's really kind of all of them were contributing. So that was sort of unexpected and made us question a little bit more like, what's going on here? Why are we seeing relationships between these non-invasive smartwatch measurements and the glucose values? And looking even further, if we broke it down by where. Broke it down by where the data comes from. I think this one brings a lot of insight, which is that if we looked at the addition of the food logs, the food logs predicted like almost half or contributed almost half to the prediction. Whereas if we look at the electrodermal activity, heart rate activity, there's some contribution there, but it's not as strong. I think that's pretty intuitive. But the question that we're trying to get at. Question that we're trying to get at here is like this risk-warm wearable data, what is going on there that is contributing to the ability to predict A1C, glucose, and so on? And so I'm actually, I'm going to skip the next slide because I think it's going to make more sense to explain it in this way. So, what we did was we designed this prospective study, applied to NIH several times, finally got it funded, where we are. Where we are essentially trying to expand those models using a wider range of diabetes status. So, people who are totally normal glycemic, so on the low end of A-glax C values, all the way up to type 2 diabetics who aren't on medications and aren't being treated, which it turns out is very, very hard to find. Ethically, it's really challenging, right? If you find somebody who has type 2 diabetes, the clinicians who are running our study are like, those people should be in treatment. Like those people should be in treatment immediately. So, we're trying to come up with this paradigm where we can actually collect data. And I think that conversation came up last night: you know, how do you collect data on a disease when it's sort of unethical not to treat the disease immediately? As it turns out, because there's a delay in time to get to see an endocrinologist, it actually worked out for us that we get those two weeks of a window before somebody will start treatment. So, we've been working on collecting this data. Working on collecting this data using consumer smartwatches as well as the research grade smartwatches. And so, we're essentially our goal is we're trying to get 34 people in normal glycemic group, 34 people in pre-diabetic, and 34 people in type 2 diabetic ranges. So, everything I'm going to show you next is the data that we've collected so far. One of the things that I really want to note is that we are working very hard to not look at the data before, you know. Before, you know, not start to develop digital biomarkers before actually all the data has come through. So we have some exploratory data analysis that I'll show, and then you know, the interesting questions that we want to ask are still TBD. But here's the data that's in so far. So in the type 2 diabetes group, we have 24 people pre-diabetes. We have 38. It's a lot easier, it turns out, to recruit people with pre-diabetes who maybe used to be in the type 2 range or used to be in the normal range. And then we have 29 normal. And then we have 29 from normal glycemic. The closest that you'll see to a result here is this resting heart rate, where you can see that there's this kind of clear increase for going from the normal glycemic in green, pre-diabetic in yellow, type 2 diabetic in red. And that's one of the sort of many smartwatch variables that we're interested in. And what's nice about using the CGM data is that we really get a nice view of what's going on. Nice view of what's going on. So, you know, there are some surprising things here that we didn't expect. Like looking at the pre-diabetic versus momoglycemic CGM data, that there's really a lot more overlap between them. We thought that there were going to be three distinct peaks, and there's really not. So that starts to sort of open up this question of some phenotyping and whether we can leverage the data to do that. And I'm going to show you on the next slide some more detailed violin plots. Detailed violent plots on the individuals. And then the last thing that has been kind of interesting is we're using this at-home A1C test, which is helping us to not have to bring people to the clinic. So it lowered the cost of the study a lot. It was like hugely beneficial to being able to collect this amount of data, but there's error in that data, more error than if we were to bring people into the clinic. So one of the questions that we have now is: given that we know that there are some Given that we know that there are some issues with the A1T data, and obviously it's giving us something because we're seeing sort of like you know a positive correlation with the CGM data, but it's imperfect. So how do we account for that? And that's maybe one of the questions for the group if anyone has ideas. This is, I know this is kind of like a really busy slide, but one of the reasons that I want to show it is like all of the individual people in our study are on the x-axis here, and what you can The x-axis here. And what you can see is that the people with the A1C and the normal range are in green, pre-diabetic range is in yellow, and type 2 is in red. But one of the things that's so interesting, I think, about the CGM data is that it gives us continuous measurements over two weeks. So we can see that there are some people who just have very different distributions. They're really elongated compared to some others. And also, really interestingly, we have some of these people. So, this is like one off the People, so this is like pawn off the press, we don't know what this means, but that are, you know, they're tit to diabetic, but they look like the normal glycemic people. And so, we've started to look into, you know, are people changing their behaviors? But if so, is it that simple that if somebody just changes their behavior within two weeks, all of a sudden they start to look normal glycemic? Um, and even though their A1C hasn't yet caught up, it's like, you know, if it's that easy, that's kind of amazing. That's kind of amazing. So, lots of questions about this data, but we're just having a lot of fun teasing it apart, and I would love to talk more about it. Yeah, yeah. So, you're plotting the individual normal volume for two weeks? Yeah, right. Um, the Libre, three. Okay. Yeah. Yeah. So, and actually, that's a good point because in the previous So and actually that's a good point because in the previous study, the NF16, we used the DEXCOMG 4 or 6. I would have to double check. That was full, but how to develop it? So it was the 6. Then we used the 6 for the previous study. Yeah. Yeah. And so something also that I would think is really, really exciting is in the time that this study was running, CGMs became available over-the-counter. So we're finding that they're not as good. We're not using those for this study. There's like some weird issues that we didn't expect to see that we're seeing with the over-the-counter versus not. We're seeing with the over-the-counter versus not. That's my key, I guess. So, I'll put in my last plug then, which is for the DVDP initiative. So, essentially, with all of this work, and I imagine that for all of you as well, like we're developing lots of code, we're cleaning data sets. There's just like a lot that people could be leveraging. And so, one of the things that is really important to me personally, but I think also would really help our community, is to be kind of like building on each other. is to be kind of like building on each other's work. And my training was in the bioinformatics and sort of multi-omics community where you know we were building genomics pipelines that people built upon and kept making better and better rather than developing all of these one-off solutions. And it's something that I think our community has really struggled with of like how do we start to build that central infrastructure that we can then kind of build upon. This is like a first attempt at this. Again, this first attempt has been going on. At this. Again, this first attempt has been going on for like eight years. So I am really hoping that at this conference, we might be able to get some more ideas, some more momentum of how we could mirror that sort of huge success in genomics in our community. So that's it. Right, let's get a couple of questions and hit. Okay. I have a question about the contribution of the different data sources. So I wonder is it possible for certain strata of people? I mean, you heard talking about an important score for the core. Is it possible that for some people it's easier to acclaim or what you like? Yeah, that's a really good question. I had one slide that I skipped that. One slide that I skipped that was sort of about this idea of like personalized models, where depending on how much data you have for a person, you could build sort of like a better model than just using the population data. But we have not looked into the feature importances on those individual models. It's a very good question. I think it's definitely worth exploring. Any other questions? Very good job. Very good talk. So I was wondering for the pilot study, what was the criteria that you re-observed on and whether there is availability device to use for this purpose? How did you come for that? Yeah, so it's a two-week period. And, you know, I was having another conversation earlier today about adherence to wear. So one of the good things with CGM is that it's stuck on. So that one doesn't come off. Like when we're collecting data and looking Like when we're collecting data, unless somebody's sleeping on the arm and fessing on it, we've got clean data that's coming through. So that's a good thing. For the smartwatches, we do find that people sometimes take them off. And so one of the things that we've done is we've built an incentive structure into the study to incentivize people to wear it more. And then we have a clinical research coordinator who actually pays attention to the data coming in. And if somebody's not wearing it, she calls the people. Wearing it, she calls the people, so it's really labor-intensive. But you know, one of the benefits of that is that we spend less money collecting data on lots and lots of people because we know that we're getting clean data sets on fewer people. So, it's like a lot of work that goes into each and every person. But yeah, so basically every morning we check on where, make sure that people have devices on. There are a handful of people who we still haven't had quality data on, but it's really, you know, I showed 91 people there, and I think it's like two or three. Showed 91 people there, and I think it's like two or three who haven't been adherent. So, yeah. But in our previous studies, it was a challenge, definitely. Any other questions?