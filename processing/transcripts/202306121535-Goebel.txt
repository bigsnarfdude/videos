More or less Ali to give a talk without a computer. So which means I will not present too many technical details for you. I just hope to sell you on on the idea how some concepts from set analysis, so basic ideas of set convergence and semi-continuity of set value mappings lead to reasonable semi-continuous dependence of solutions to dynamical systems on initial conditions and other perturbations, and that in turn leads to asymptotic stability. And that in turn leads to asymptotic stability theory. That's also reasonable. And finally, given time, I hope to connect this to a result from topological theory of dynamical systems, namely the Cornley decomposition. So, to begin, I have better remind you what is a continuous function. And I really have a point to this because we'll get to sell valued mappings that are not continuous in a moment. Moment. Pictures look like this, and essentially the definition is: if you get a sequence of points converging to x, then the values converge to the value at x. There is a definition of continuity. Once you have a continuous function and you're looking at the initial value problem with a continuous f, so again, I'm assuming here is f is continuous. And by the way, everything is in Rn here. In Rn here, I have an initial condition. For this initial value problem, if it is continuous plus the solutions are unique to the initial value problem, what do you get? You get continuous dependence of solutions on initial conditions. You're assuming you're giving me a subsolution. You're assuming you need a subsolution. Yes. You're assuming that. Yeah. Continuous dependence. Why not just go left shifts? Of solutions on x naught. Well, because I really want to go in the other direction eventually. Right? Ellipsis continuity of f implies uniqueness of conditions, but there are other situations where you have uniqueness of conditions without ellipsis conditions. What is the picture? What is the picture? The picture is there is a new initial condition x0, and there is a solution. If you pick a nearby initial condition on finite time horizons, the solutions stay close to one another. Well, unless something crazy happens, like unless there is some finite time blow-up, then you have to be more careful about this. Okay. Now, what happens? Now, what happens if you kill the uniqueness of solutions? Then, unfortunately, continuous dependence goes out the window as well. A standard example that again I think we show to our students in differential equations courses is when you have a non-literist right-class site, you can have non-unique solutions. So the system can be x dot is root of x, essentially. And then Essentially. And then we know from zero, there's infinitely many solutions. There is one, there is another one, and then you can concatenate them to get many other ones. But when you look at other initial conditions, you actually do get unique solutions from these parts. And already here, based on this picture, you can start seeing what I What I call it outer semi-continuous dependence of solutions on initial conditions is. If you drive this initial condition to zero, the limit of these solutions is this one. So limit of solutions is a solution, but this limit doesn't have anything to do with this one, right? Which is essentially the definition of outer semi-continuous dependence of sets on points or outer semi-continuous. On points or the outer semi-continuity of a set-value map. So let me get to this definition. First, what is a cell-valued mapping? For me, it is a mapping from Rn to Rn. The double arrow notation means cell-valued. There are different ways to think about sub-valued mappings. For me, this means that n of x M of X is a set. A completely different approach is to think about the set value of mapping as a mapping from Rn to the set of subsets. I was trained by my advisor to do it. This way, one reason is you can immediately start using topology in Rn, not on the space of subsets of Rn, to talk about continuity of these things. Okay. And the key definition of continuity. And the key definition of continuity is something I call outer. And sometimes it's called upper. There are sort of some terminology arguments. Again, I'm sticking to what I was told by my advisor. Outer. What is outer semi-continuity? Let me sketch a picture first and then write a definition. So, for each point, the value is a set. This picture might be something like this, like that. There's a picture of a set value mark. This graph is closed, and in fact, closed graph corresponds to outer semi-continuity. How to think of this, for example, why is this mapping outer semi-continuous? This mapping is out there semi-continuous at this particular point? Well, if you look at the values approaching this way, they have a limit. That limit is one of the values at this point. If you approach from here using different values, but you pick a convergent sequence of them, the limit is in here. So the definition is essentially that if you have a sequence of points xi converging to x, and you have values of n and Of n at xi, and these values happen to converge, then the limit of these values is the value of the limit. Just but the area in the crosshatch, you could have infinitely many points that don't converge to anything. Yes. Which means Okay, just they're they're not featured yeah, they're not featured in this definition then. Yeah, you only look at convergent sequences in it. Look at convergent sequences in it. Or alternatively, if you think about the other semi-continuity as a closed graph, right? The assumption that I mean that this set needs to be closed. Okay. There is also a concept of inner semi-continuity. For a variety of control purposes, it doesn't seem to be that relevant, at least not for the ones I want to tell you about. So I'm not going to get there. And of course, if you have a lot of. And of course, if you have a mapping that's inner and outer semi-continuous, you call it continuous. And then there are mappings which are even more regular. You can talk about lipstick continuity of sub-valued mappings. I don't need this. Outer semi-continuity is what I need. Can I? Yeah. Why not use the inverse image of the open set as often as an image? Much more sort of economical approach in this. But that's not like imagine just the the graph consisting of one vertical sigma the pre-image of some open sign could be closed I'm not even sure it's what you said is correct you say continuous function is continuous now the definition is that name the symmetry of the not the set is all yes somehow rely on that so you're saying So you're saying take the graph. Take the graph as a cross, like X line is Y line, right? This is closed, subset, so it's continuous at present. The techniques of any open interval, it won't be there. Right, I think here the image of every open set is open. I think. No, I don't think so. No, I don't think so. So, what's the component? So, here's what you want to say. I mean, that's an equivalent definition. Yes, I don't know if it's upper versus counter something, but isn't there a definition like the upper interconnections of open is open? To do that, you need to power geosynchronous subsets. Well, but I mean that's how you have, right? I'm going from RN to RN, right? So, RN. What is an open source set? An open set of subsets? No, but hang on. This is why I'm really going from Rn to Rn, right? I don't need the topology on the set of subsets in this set. But I think even in your definition, right, there is a way to make sense out of it that wouldn't need to go there. Okay, well. But anyway, to me, closed graph is proposedly the simplest characterization. Okay, so in this, now I want to start. Okay, so in this now I want to start looking at differential inclusions. I will assume something basic assumptions. What is that? Well that means that f of x is not empty, is a convex set, and f itself is outer semi-continuous, so like an outer semi-continuum I will abbreviate as OSC. New individual abbreviated as OSC. And again, in this setting, I'm going to assume boundedness in a moment. It's really very close to being the same as what is often called utter semi-continuous. I'm assuming bounded to have simplify some of the things I say later, locally bounded would have been done. Okay. The important fact is under The basic assumptions. Solutions. So I should have mentioned an initial condition here. Solutions depend out there semi-continuously on initial conditions. So again, similar idea as here. Limit of solutions is a solution, but at the limiting point you can of course have other solutions or other values of the solution map. For other values of the solution map, I mean, this goes back, I don't know, to Philippov times, maybe even earlier. What can come out of it? So let me sketch a picture which perhaps I mean many of us sketch when we teach. Of us sketch when we teach, or you teach, because I don't get to do it that much, non-linear systems from it like Kaliel, for example. I'm sketching a spiral that settles on a circle here. So this is a sketch of a solution. In here, you get something. So let's say this is a solution that we call it phi. What we get here is. What we get here, the circle, is the omega limit. How do we show that the omega limit is an invariant set? Well, you pick any point in here. You pick a sequence of points converging to that point in the omega limit. Then you take solutions from these points. And then you take your limit. And in the limit, you get a solution that verifies the invariance of the omega limit. So again, it's the same principle, right? Limit of the solutions need to be a solution. I did not need continuity or continuous dependence of solutions on initial conditions to do this. It was just the outer semi-continuous property. Of course, when we're dealing with a nice differential equation, it is continuous, but again. Differential equation, it is continuous, but again, it's not really needed. When we can't guarantee uniqueness of solutions, this argument verifies not invariance but weaken variance. In other words, from this point, there exists a solution that stays here. There might be other ones that do some other crazy stuff. Okay, so with this said, what do we get here from this principle? We get that omega limits Are invariant in the right sense. What do I mean in the right sense? So, here I want to throw into one packet omega limits of solutions, which are weakly invariant, omega limits of sets, which are a more general ID concept, and those may end up actually strongly invariant, depending on some other conditions. But again, invariance carries over very nicely. Okay, some other properties. If we have a compact, asymptotically stable set what do we get again, pretty much directly from this property. Directly from this property. The asymptotic stability is uniform automatically. In other words, it admits a failed abound. Basin of attraction is open. So again, the familiar things from Khalil, from differential equations, carry off. Carry over. Well, and there is more, but the really cool properties of asymptotic stability don't follow directly from here, but you actually need to first show that outer semi-continuous dependence carries over to perturbations as well. What does that mean? Well, not only can you vary this, but you can sort of perturb the You vary this, but you can sort of perturb the right-hand side a little. What can you get from this? So, like, what are the benefits of this for asymptotic stability? Asymptotic stability, so this is an extra condition here, asymptotic stability is robust. In other words, you can perturb the right-hand side a little bit and asymptotic stability is preserved. There are different ways of to characterize this. To characterize this. Finally, there exists a smooth Lyapunov function. So robustness is tied to the existence of smooth Lyapunov functions. Do you hear me? Want me to ask you a question? Yes. Quick question. What is there example? Wait, how? Wait, excuse me, you broke up in the most important part of your question. Sorry, I was saying, is there an easy example to see why omega-linit sets may not be strongly invariant? Sure. This here was a solution to a differential inclusion, right? You can have a spiral that leads you to that circle, but in that circle you can have Can have other values of your differential inclusion that will make you go strictly inside. I mean, I can't quickly write a formula, but I think the picture can convince you. Projectors shed off the main side. Right, or. I mean, here is a. Here is another example. Sorry, here is a differential inclusion. If you start a solution at the positive initial condition, the omega limit is zero, and zero is not invariant because from zero you can immediately keep going further to the left. All right, thank you. Okay, so much of this I think actually I mean all of this goes essentially back to previous century Now I hope to bring some of this to what I was involved in over the past 20 years namely extending this to hybrid systems No. I didn't start my stop off. No. So first, what are hybrid systems? In general, hybrid systems are thought to be systems which combine continuous time features and discrete time features from the classical dynamical systems. There are different formulations, different approaches, many of them. Many of them, or at least a good number of them, fall into this category. You have continuous time dynamics, and I'm going to write inclusions, although you can think about differential equations because there's enough interesting stuff in here going on already. And continuous time dynamics apply on some set. And then you have discrete time dynamics. So, this is a representation of a differential difference inclusion or a difference. Inclusion or a difference equation, if you want. And this one applies on some other set. In principle, I'm not telling you anything about what these sets are, how they overlap, or they don't overlap. With this formulation of data, you can still try to define your solutions differently. The early approaches insisted on parameterizing solutions by time only, which sort of kept things closer to continuous time dynamics than discrete time. Closer to continuous time dynamics than discrete time dynamics because then you cannot parametrize difference equations only. If you choose to parametrize things like time, you probably want to use discontinuous solutions, which occasionally sort of jump according to this map. When you use discontinuous solutions, you have to be careful how you measure distances between them because uniform distance becomes a little bit touchy. But and then you probably need to impose some special conditions on these two sets to make things align with your definition of solution We wanted to sort of go away from this we wanted to make sure that we can model differential inclusions and completely separately model difference inclusions in our framework of hybrid systems. So We ended up using a concept that was already floating in the literature, namely solutions are defined on hybrid time domains. What are these things? Well, here is a picture. Hybrid time domains sort of let you know how you can evolve. Sort of let you know how you can evolve continuously and let time flow forward. And you can occasionally jump and count the number of jumps. So, an example of a hybrid time domain is a set that starts at 0, 0, goes forward a little bit, and then maybe your solution experiences a jump, and then another jump, one, that's two, and then the solution goes forward a little bit more, and then there's another jump, and so on. Is another jump, and so on. Special cases of these sets, of course, include just this, which would parametrize a solution to a differential inclusion, or these points, which would parametrize a solution to a difference inclusion. But there are sort of plethora of things in between. Well, there is a complication. These different solutions can have different time domains. Let me sketch you a picture to convince you of. Let me sketch you a picture to convince you of this. There is T, there is J, and there is H. So this will be solutions to the sort of famous or infamous bouncing ball example, which has questionable physics, but pedagogically is actually pretty interesting and satisfying. Take a ball, actually, let me use. Take a ball, you drop it. Take a ball, you drop it from a certain height. As time goes forward, the height decreases. When the ball hits the ground, it experiences a jump, and then the ball goes up again. So, so far, the time domain for this Domain for this evolution of a hybrid bouncing ball is that when you drop a ball from a nearby initial condition, let's say from a point a little bit higher, the solution that you will see is something like that. Something like that, and when you look at the hybrid time domain of it, there is a little bit mismatch. So simple case of two different solutions of a fairly simple hybrid system. These solutions intuitively are close to one another. Their time domains, or their hybrid time domains, aren't the same. And there is sort of a big mismatch between solutions when you. Big mismatch between solutions when you look here and here. Like one solution is still going down while the other one is going up. So when you look at heights, it's not that bad, but if you look at velocities, they're actually quite different. What do you do? Well, we're sort of after outer semi-continuous dependence, so which means you don't want to try to parametr sorry, measure distances between these solutions using uniform distance, because you can't, because the domains don't even match up. Because the domains don't even match up. But you may want to look at graphical distance. And in this sense, if you look at graphs of these solutions, right, these graphs are close to one another as sets. And these graphs are close to one another as well. So. Can I? Yeah, I don't understand why you separate the powers. You could still draw them on the same pile axis. Well, for this system, yes, but in general, we are allowing multiple jumps at the same time. I just don't want to come up with artificial or like logical algorithms where you can switch your algorithm a couple of times instantly, would lead to similar pictures. This is just sort of, I think, an intuitive one to see. But by the way, But by the way, if you sketch velocities for these two and you try to measure uniform distance between them, things go sideways very quickly. They're mismatched. Unless you scale the time and the well Yes, I think one of the confusions coming up is you haven't defined a hybrid time yet in terms of exponentials. Well, I said solutions are defined on sets. Solutions are defined on sets that look like this. Yeah. Right? So thank you for the reminder. What's happening with this solution? This solution starts here. We have zero jumps and time goes forward. At this instant, there is a jump which does lead to parametrization of solutions by both time and the number of jumps. Okay. So now, before you ask me more. So now, before you ask me more questions about this, I better erase it. Sorry. Okay, the punchline for this part is under basic assumptions. What are they? Well, basic assumptions on F you have written there. Same ones. They also apply to G, but you can skip the convexity of the values. In the speed time, there is no averaging, so G doesn't have averaging. No averaging, so g doesn't have to be convex value. These two sets have to be closed. And that's it. They can overlap, they can be the same sets. Under basic assumptions, solutions depend out there semi-continuously on x0. And now that, thanks to Fred, I wrote this. The initial condition attached to here would be. The initial condition attached to here would be x of 0, 0 equals x nothing. And perturbations. So in other words, in this hybrid world, if you change the initial conditions and maybe you perturb your right-hand side a little bit, you can take limits of solutions. But to take limits, you have to think about graphs of solutions, not about solutions. Think about graphs of solutions, not about solutions, values of solutions themselves. And with that, you look at other semi-continuous dependence. In other words, limits of solutions are still solutions. Why is that good? All these things carry over to the hybrid world. You have to think about some of these objects slightly differently. For example, my solution is parametrized by t and j. How do you define omega limits? Well, omega limits are about asymptotic behavior. What does asymptotic behavior mean here? Well, it means that either t goes to infinity or j or maybe both. So the easiest way to say is that t plus j goes to infinity. Different solutions will do different things. How do you measure uniformity of asymptotic convergence? Well, essentially, it's uniformity, you measure the amount of hybrid time that elapses. How do you measure that? Again, you don't count this or that separately, just add them. Well, and asymptotic stability theory, essentially in the form from Khalil, largely carries over. There's of course more to it. There's, of course, more to it. Once you have invariance here, you can talk about invariance principles. Once you get to the existence of smoothly up and off functions, you can do more general things. You can talk about ISS and so on. And I think I'm running out of time. You are a little bit. I was just going to make a small comment. But there are new things that show up as well, like xeno equilibrium. Well, I mean, there are. Well, I mean, there are different characterizations of equilibria you can see, but Xeno equilibria are special ones where I think there is jumps only, but they are subject to the same characterizations, right? You might be able to say a little bit more about them, but I mean, these broad tools work, right? Whether you exclude Xeno or not. Okay, as a pass. Okay, as a punchline, because I don't have time, I can just say I was going to try to sketch pictures and tell you a little bit about something called Conney's decomposition, which fits into Conley's theory, which fits into topological theory of dynamical systems. Conley's decomposition says that you can take an invariant set and break it down into two pieces, the chain-recurrent part and the gradient-like part. Under basic assumptions, it carries over. Thank you. Quick question. So can you say anything about the velocities in in your case? When you said the velocities in in general, like they mismatch, but But can you say something about how they behave? Well, I mean, I can try to quickly sketch it. If it's too complicated, we can talk later. No, no, I mean the picture of the bouncing ball, right, the velocity is essentially the graph. If you just parameterize by time, graphs look like this. If you drop the ball from a different height, velocities will look like that. Like that. At these times, there is mismatch between them. So if you try to use uniform distance, you get intuitively close trajectories with humongous uniform distance between them. I see. And so you have to start improvising. And you have to look at some graphs, but for velocities, then we would have some kind of distance. Well, I mean. Well, I mean, when I talk about graphical distance, I mean, I mean graphical distance if I do the whole solution. I only sketch height. Normally, you look at both height and velocities at the same time. I see what you mean. Okay, I've got to go. All right, so you have further questions for later today or in the afternoon. It's technically 