Okay, thank you. Hello, everyone. Today, my topic is about classification with noise label. And I mainly focus on the bias analysis and correction. And correction. This work is supervised by Dr. Race Yee. Recently, classification has achieved great success, but usually it's very hard to guarantee that the label is 100% accurate. And as reported, the ratio of Loy's label is from 8% to 38.5%. So, currently, it's So currently it's a very hot research topic about noise label in machine learning research communities. And most of the current literature mainly focused on the instance independent label laws. And Fieldwork did the bias analysis. So in our paper, we first theoretically investigate the impact of Lloyd labels and then And then we found that there are two cases where we can safely ignore the machine error. That means ignoring the noise label is totally fine and won't have any bias. This conclusion is a bit counterintuitive. And finally, we propose some new correcting methods. Before that, Before that, we may first look at the classification framework without noise label. So here we have input x, output y, because here we only can see the binary classification, so y only takes negative 1 or positive 1. And we also have the class of classifiers, loaded script F, and we use this sign to predict label of the input x. input X. And the basic goal is to find the optimal classifier. So if we want to choose the optimal classifier, that means we meet some criteria. So generalization error is one of the criteria. Basically, this this error evaluates the difference between the prediction and the true label. Prediction and the true label. And if we look at this formula, we can see there is an indicator function. So minimizing this generalization error usually is complex. So in practice, people often use the convex surrogate loss function phi to replace the indicator function. Then we have varies, and furthermore, if we use the sample mean to approximate the expectation, then we have the value. The expectation, then we have empirical file risk. So basically, the classification is to minimize the empirical file risk. All we need to do is to specify phi function and the script f. But in practice, usually we can't obtain the true label y. We can only access the noise label. access the noise label y star. Here the conditional probability PAX is actually represent the probability y star differs from y. That means in this case the noise label gives us the wrong information. And here this conditional probability depends on the input x. Depends on the input X. So that means the noise generation process may depend on the input X. And if this value is bigger, then that means we have more loads. So we use the expectation of P1x plus P lacty1x to define the misclassification degree to reflect more. To reflect more practical scenarios, we consider two assumptions. The first assumption is we assume the summation of P1x and the P elective yx is independent of x. And while another assumption is we assume both misclassification probabilities is free of x. So that means assumption 2 is stronger than assumption 1. is stronger than assumption one. If assumption two holds, then assumption one obviously holds. Now we consider three kinds of noise label. The first one is instant independent noise label. That means we consider assumption two. In this case, the noise generation process is the same. Process is the same for all X. That means the lowest generation process doesn't depend on the input X. And the second one is semi-instance independent. That means we don't assume the misclassification probability is independent of X, but the summation should be independent of X. And the last one is the most general noise. Is the most general noise label, that means the misclassification probability depends on the input X. In measurement error, one simplest way to deal with the measurement error is to just simply ignore them. That means we just use the noise label to simplify replace the true label. The true label. So then, if we just replace the true label yi by y star in the objective function, then we can obtain the La Yu classifier F half star. So one natural question is what is the bias if we ignore the machine error? So this theorem tells us So this theorem tells us, so here we can see the instance dependent noise label. So this one, we can regard this one as the bias in terms of the fire risk and this is the bias of the naive method in terms of the generalization error. So this theorem tells us the upper bound depends on phi squared f dm. Square F D M. And furthermore, this upper bound is positively related to the misclassification degree. So another natural question is, will using naive method be okay? The answer is yes. So here we found two cases where we can safely ignore the machinery error. Here, rho 1x is the ratio of Is the ratio of the misclassification probabilities in different classes? P1x is a misclassification probability in class 1 and P negative 1x is a misclassification probability in class negative 1, right? And row 2x is the ratio of the class. So basically, row 1 can reflect the imbalance. Can reflect the imbalance of the misclassification probabilities in different classes, and the row two can reflect the imbalance of the classes. So, this theorem tells us when the misclassification probabilities is balanced, that is, Pyx is equal to P lactive yx, then we can safely ignore the measurement error. Error. And the second case is if row 1x is not equal to 1, that means if the misclassification probabilities is not balanced, but this kind of imbalance can be cancelled by the imbalance of the class. That is rho 1x times rho 2x equal to 1, then we can also safely ignore the measurement error. As we mentioned, we identified two cases where using naive method is totally fine. But for the other cases, using naive method may have some problem. So here we propose two corrective methods. The first corrective method is for the assembly instance independent noise label and And we can show that as the sample size n approach to infinity, then this corrective method has the same performance as the case when we have the true label. And the second method is for the instance independent noise label and for any beta, this method can lead to a large class of correct. Lead to a large class of corrective methods. So for early beta belonging to this interval, then we can define phi beta and further we can get the corrected classifier, f-hal beta corrected. And for any beta, this correcting classifier is efficient. And this theorem tells us for any beta belonging to this interval, for This interval for the instance independent noise label, and this corrected classifier has the same asymptotic performance as using the true label. Here we apply our methods to the image data. So, here we use a chest x-ray image data set. This data set has more than sixty Has more than 60,000 images. And the basic goal is to predict the presence of the five diseases from the image. This data set has training set and validation set. In training set, they have for each image, they have the label to indicate the presence of the five diseases. But Diseases, but this label may be mismeasured. And in validation set, we have 200 images. That means we have the labels for 200 images. And this label is from three doctors. So that means this label, we can regard this label as gold standard. And so I'm going to develop the machine learning algorithm to predict the label for the image. So our step is as follows. Firstly, we assume the instance independent noise label, and then we randomly split the validation data set into test set and evaluate evaluation set. Evaluation set and then we implement the correcting method as we ma as I mentioned before and the Laive method. Here the script F is specified the dense net one-to-one network. This is a special architecture of convolutional neural network. And then in test setup, we select the optimal beta and P. Select the optimal beta and the P1 PDP1, and then we compare the naive and correcting methods in the evaluation set. So this table reports accuracy, precision, recall, and F1 score for the line Y method and the corrective method. So we can see for most of the items, the corrective method outperforms the line Y method. So let's summarize this whole. So we firstly theoretically show the bias of using the EV method. That means the bias of ignoring the measurement error. And we identified two cases where ignoring measurement error is totally fine. And finally, we propose two new corrective methods. That's all. Thank you. We have any questions