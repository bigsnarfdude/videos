So our next speaker is going to be Volodymyr Nekrashevich. He's from the Texas AM University and he's going to talk about simple groups of dynamic allowance. Yeah, thank you very much. I was hoping to visit. Thank you very much. I was hoping to visit Oaxaca in person, that I always wanted to visit it, but couldn't work out. And actually, last week I got COVID, so I just got just fine right now, but I guess that was that would make it impossible even more so. So I want to talk about I want to talk about groups acting on Cantor set, which are associated with generalized dynamical systems. So what kind of generalized dynamical systems I'm talking about? I will use the framework of groupoids, et al. groupoids. Sometimes nowadays they're also called ample groupoids. Groupoids. So, in general, a groupoid is a small category of isomorphisms. So, a small means that the set of objects form a set and morphisms form a set. So, we have some objects, points, and arrows between points, which can be multiplied, namely, composed. Composed namely, composed, and we typically identify objects with the identity morphisms at them. So, identity automorphism. So, talk about for us a group ID is a set of morphisms of the category and objects identified with something called units. So, we have a set of morphisms, objects identified with identity as a morphisms, which would be called units. Which would be called units of the group void. And by g raised to zero, we call the we denote the set of units. And because we can compose two arrows only if end of one is beginning of the other, the multiplication is only partially defined. So we get also a set, subset of composable pairs for elements. So we'll use functional notation. So if you have two morphisms, G1 and G2, then the first one, which is in a product, acts after the second one. So G1G, product of these two morphologies is G1G2. Because of that, the source will be G inverse G. Will be is g inverse g so that's the identity in this end and gg inverse is the identity so the unit of the group point on the other end so called range so we have the source map and the range map so this is a map from the groupoid to the set of units both of them so a topological groupoid is a groupoid together with a topology making the structural Making the structural maps continuous. So taking inverse is continuous on the groupoid, and multiplication is continuous as a map from a subset of the square to the groupoid. And another technical condition, typically included, sometimes not, is that source and range maps are open as maps. But we will need the most is a But we will need the most is a is a we will need a stronger condition. So bisection is a subset for which the source and the range maps are homomorphisms onto the domain. So it's you can imagine it as a bunch of collection of arrows, set of arrows. And it's a topological group. So this set has a topology and then there is the set of sources. Is the set of sources, there is the set of ranges, and the set of arrows. So, all three sets are naturally or must be naturally homomorphic. If it is so, then this is called the bisection. And group point is called the tile if there are many of them, namely if the set of open bisections is a basis of topology for the group point. So, example, suppose you have a discrete group acting on a topological space. Then you just take the direct product of the group times the groupoid. Actually, it doesn't have to be discrete. The groupoid will be a tally fit discrete. Generally, this makes sense for topological groups too. Then you take the direct product with the natural multiplication. Natural multiplication, but basically, what happens is that this groupoid is the set of arrows labeled by the group elements. And the arrow goes from x to g of x. And you remember not just the source and range, but also you remember which group element acted. So the set of such arrows would. Of such arrows with the natural composition is a groupoid called the action groupoid. And it is easy to see that it is a type. We are more interested in a different group point, so we can identify two elements of this group. So we identified two arrows labeled with the same. Labeled with the same source and range, labeled by G1 and G2 or G and G2, if and only if when you restrict there is a neighborhood of the source, such that restrictions of both G1 and G2 to this neighborhoods are equal. So now we don't remember exactly what group element acted on X. We remember the local action. So So, of course, if you know the local action of one arrow and you know the local action of the next arrow, you know the local action of the composition and you know the local action of the inverses. So, this identification agrees with the groupoid structure. So, we will get a quotient groupoid and we take it with the quotient topology and And follow directly from the definition that the quotient topology is also, so both topologies are etal. So the original direct product topology on the action group point is atal if G is discrete. If G is not discrete, that's also interesting group point, but it's not at all. And taking this quotient doesn't damage it much, so the quotient topology will be also done for the groupoidal germs. However, and it will be important to us later, as it is typical for taking quotients, you may lose Hausdorffness. So the action group point is Hausdorff provided X is Hausdorff. That X is housed off. The group point of germs is not housed off even if X is housed off. It is locally housed also. Okay, so if you have a bisection, so again, remember this is a bisection is a set of arrows. A set of arrows with which is naturally homomorphic both to the set of sources and ranges. So just following the arrows, you get a homomorphism from the sources to the ranges. So every element G of the bisection defines a map from source of G to range of G. And because all map, both And because all map, both map, source, and range are homomorphisms, this map is a homomorphism. So it is a homomorphism from the set of sources to the set of ranges. So we get a homomorphism between open sets. So if G is a neutal groupoid, the set of such open bisections Of such open bisections itself is a not okay, so there are two things. So, first of all, the set of bisections is a pseudo-group, but the set of homomorphisms that are defined by them is also a pseudo-group of local homomorphisms. The pseudo-group is a collection of homomorphisms between open sets closed under composition, taking inverses, so it's an inverse semi-group, taking restrictions. Taking restrictions, open subsets, and taking unions whenever union is also a homomorphism. In a way, the set of bisections is also a pseudo group, but it's not a pseudo-group of homomorphisms. Conversely, if you have any pseudo-group of local homomorphisms, Morphisms, or actually, any inverse semi-group, we can consider the associated groupoidal drones. So there are more group. For example, a very nice example of such a groupoid of drums is you take some finite alphabet A, take the, say, one-sided shift, so the space of all infinite sequence. Infinite sequences, say to the right. So that's a canter set. Now take the shift. So the shift which erases the first letter. This is not a homomorphism, so you cannot define a group. You cannot generate a group by it, but it's a local homomorphism. So you can restrict it to open sets. So, you can restrict it to open sets such that its restriction is a homomorphism. You will have inverses. And then you can generate a pseudo-group. So, you take all, you can generate an inverse semi-group, for example, by branches of this shift, and you get some semi-group or local homomorphisms. Or you can then take union, so you get pseudo-group. And then you can. And then you can take the group point of germs of this inverse semi-group, this semi-group of local homomorphism. So this inverse semi-group is not, sorry, this group point of germs is not in any obvious way a group point of group action, even though it is action. But it doesn't doesn't, you don't see immediately that it is. So many sources of a type of voids don't really come directly from. Poids don't really come directly from groups, from actions of groups. They come from actions of semi-groups or local action by local homomorphisms. Another example is for example take for instance the circle and take the map x goes to 2x. It's not invertible, but you can consider the group point of germs generated by it. So it will be some. So it will be some groupoid of germs. Okay, groupoids that are groupoids of germs or semi-groups of local homomorphisms are called effective. Okay, so if you have an intal groupoid, you can look at the groupoid of at the semi-group of its homomorphisms defined by bisection. Homomorphisms defined by bisections, and then take group point of germs of that. That will get a quotient of the target called the sector quotient. Okay. Upgrade, what is yeah, another a couple of more technical definitions, and then I'll be ready to go to talk about groups. So, suppose you have a group point and you have an arbitrary subset. Subset. Then by restriction, we mean just the set of all arrows that start and end in this set. So you have a set of units of the groupoid. You take a subset and just take arrows that start and end in this subset. That will be a group, obviously, a groupoid, a subgroupoid. If G is a tile, this is also a tile with respect to the relative topology. Topology, but you can lose effectiveness because if sometimes if this set U is not open, for instance, just knowing its germ at U doesn't determine the germ in the whole space. So sometimes. Not necessarily effective. That's why it's the reason why I talk about groupoids without, I'm not talking about just semi-groups. You'll see that this. Okay, so now we introduce groups. So what is a full group? Or sometimes called ample groups. Maybe ample group will be a more popular terminology eventually. Eventually. In a way, I like it more, but the term full group has stuck. Historically speaking, I think Erberg introduced full groups implicitly and called them ample in his old paper. But then Giordano, Putnam, and Scar reintroduced full groups in a little bit different setting, more general setting. More general setting, and after that, this term stuck. Okay, so suppose you have an entire group weight, then the full group is the set of bisections which are everywhere, like which are kind of global. So it's the set of subsets of the coid. It's unfortunate I use the same word as F here, but let's say subsets. Let's say subsets A such that the set of the sources of A, the ranges of A is the whole space of units, and both maps, and it is bisection, so both maps are homologous. It's not hard to show that if A is a bisection like that and B is a bisection like that, then AB is also bisection like that and A inverse is bisection like that. So, and then you can show that the set of such bisections actually forms a group. Group. If the group point is effective, this full group is precisely the group of all homomorphisms, globally defined homomorphisms of the unit space whose germs belong to the group O. Just all homomorphisms whose germs are in the group OE. So, in a way, it's the biggest subgroup of the group OI. Of the groupoid, not of the groupoid, but of the pseudo-group of the groupoid. Now, it's from now on, I will assume that the unit space is zero-dimensional. The reason for that is that otherwise, this full group will be very small. So, for example, the example that I mentioned, if you take the circle and you take the angle doubling map. And you take the angle doubling map on the circle, you can generate the group point of germs. And then, unfortunately, I don't know if I can hear you. What will be the full group of this? Well, it's not hard to see that the full group will be just the group of rotations of the circle by angles. By angles m divided by 2 to the n. So only these maps. So you don't really see any multiplicity, you won't be able to see any germs that come from multiplication by 2 or division by 2 because they cannot be extended to a homomorphism that is whose germs belong to. Is whose germs belong to this groupoid. So the full group doesn't really remember very well what is the groupoid. But if the group, but that's because the space is connected. If the space is zero-dimensional, there will be many, many elements in the full group. So let's describe how this. Describe how this works, how you construct elements of the two groups. So, suppose you have an entire groupoid. Then, here is a technical definition, what is a degree D multisection. Let me explain to you just by drawing the picture. So, you take a disjoint, a collection of D pairwise disjoint clopen subsets. So, here there are five of them. So here there are five of them. For every pair of them, choose a bisection in the group wage. So it's a collection. For every ordered pair, choose a bisection with that given source and given range. And so if this is I1, I2, we denote this F I2. Know this F I keep on I1. And do it in a way that you get a commutative diagram. So if you have a bisection going from here to here, then the product is exactly the chosen bisection which goes from here to here. And also the inverse is chosen. So you get a commutative diagram of side bisections. So, for example, degree two bisection means that you have two disjoint open sets. Actually, not clopen, but compact open. And you have bisection from here to here and inverse bisection from here to here. So we assume that these bisections and therefore also these sets are compact and open. By the way, that does mean that they're closed because we don't assume that the group point is at once. Okay. Okay, so this is a bisection. And now, if you have a multisection, if you have such a multisection and have any permutation of D elements, you can model that permutation by these bisections. So, for example, if you have a degree. So for example, if you have a degree five bisection and you want to take consider permutation which is cycle of length to the three here and cycle of length to here, you just take the corresponding bisections and take their union and complement that union by the identity, by units. So ident you take ident units everywhere outside. So everywhere here you take identities. So, everywhere here you take identities, and then here you take this bisection, you take this bisection, you take this bisection, you take this bisection, and this bisection. Take union of all of this. That will be a one-big bisection with domain, so with source the whole space, the range the whole space. So, it will be an element of the full group. The full group. So formally, we just take the union of all i of the bisection corresponding to the pair i of i, and then complement it by the units outside. So, for example, if you want to model a transposition, it means that you choose a bisection in one direction, choose the inverse of that. Choose the inverse of that in the other direction, and then complement it by identity outside. That will be an element of the full group. So that will be, in the effective case, you will get this way a homomorphism of the whole space locally belonging to the groupoid. So, germ of this homomorphism at every point belongs to the groupoid. It's this arrow. It's this arrow for these points, arrows in this direction, arrow in this direction for these points. It's unit, so germ of identity for these points. But you see here that you need these sets to be cloppin for this to work. So that's why you need the cantoset, otherwise we can so if you fix a multi-section TQD, you get you represent the symmetric group in the full group. Group in the full group. So denote the range by S of this of the section F and let the symmetric full group, S of G, be the group generated by such copies of the symmetric groups. So this is kind of an obvious way of constructing elements of the full group. Unfortunately, it's not everything. So this is a strict, this is a This is a proper typically, this is a proper subgroup of the full group of the groupoid. And the difference between them is a little bit mysterious. We don't really understand very well what is the difference. There is a map, natural map from the full group to something called first homology. Something called first homology of the groupoid. And in, I think, in all cases that we know, this is the kernel of that homorphism. So, in particular, the quotient is an abelian group. But this is not known in general. And that's something that would be maybe a nice and interesting project, research project, finding a group point where this is not true. For example, finding a group point for which, so this is obviously normal subgroup, so for which the quotient group is not a median. That would be an interesting example. We don't know such an example. But in all examples, But in all examples that we know, the quotient is abelian and it is described by this something called signature map. No, sorry, sorry, index map from the full group to the first homology. I don't have time to explain this. You can read about it in Matsui papers by Hiroki Matsui. Similarly, we define A of G taking alternating groups and taking the group generated by copies of alternating of the alternating groups that you get this way. Get this way. We also don't know. So, alternating group, alternating full group is a subgroup of the commutator subgroup of the full. Again, we don't know if this is equality every time. It is equality in all examples that we know. We have theorems that prove. We have theorems that prove that it is equality for white for many important classes of group white, but it is not known in general. So that's also a mystery. Yeah, okay. So now I will want to talk about normal structure and in particular about simple groups. So if you are interested in simple groups, we need to it's natural to consider only effective groupoids, so groupoids which are groupoids of germs because if we replace groupoid by an effective groupoid by effective quotient, the full group of the quotient will be quotient of Group of the quotient will be quotient of the full group of the original groupoid. Same for semantic and alternating versions. So we need to take effective groupoid jobs. So suppose that G is an effective group point. And suppose you have a closed G-invariant set. G-invariant means that if you take any arrow starting in this set, it necessarily will end in that set. Will end in that set. You cannot have a situation like this for those. Then, okay, and I will be interested mostly in the alternating group for a reason that we will see. So, this alternating full group is maybe it's not the most natural one, but it has best properties and it connects the dynamics of the glupoid with the property of the group in the best. With the property of the group in the best way. So if you restrict your group O to the complement of the invariant subset, so you restrict to an open invariant subset, then the alternating group on full group on that will be a normal subgroup of the alternating. So that's a way to construct normal subgroups. Also, you can take the Also, you can take the pointwise stabilizer of the full group of the set in the full group. That's also a normal subgroup. And in fact, we have this inclusion because, so this is defined as the full group of the group OID restricted to open set. It to open set. So all bisections will live in that open set. And so every multisection will fix pointwise C. So this shows that this is a subgroup of the pointwise stabilizer. So every closed invariant subset defines two normal subgroups. If the action is topologically free, Is topologically free, meaning that if the isotropic groups are trivial, so so in some technical, under some pretenatural technical condition, which is not true in general, but is happens from time to time, they will. From time to time, they will actually coincide these two groups. But in general, they are different. And so, this is an unpublished theorem due to me and Nuclas Matabon that if all orbits of G have at least six elements, then every normal subgroup of this alternating full group is for every normal subgroup, there is exists. For every normal subgroup, there exists necessarily a unique closed subset, closed invariant subset, such that the normal subgroup is between these two canonical ones associated with the closed invariant subset. So normal subgroups of these full alternating groups are very tightly controlled by closed invariant subsets. This is very similar to what people To what people have in C star algebras in the cross product C star algebra. If you have, say, a group action and you consider cross product C star algebra, then one can also show under appropriate conditions that ideals are in a bijection with closed invariant subsets. So that's the same, almost the same situation happens here. Same situation happens here. And a corollary, but it's easier to prove it directly: theorem that if you have minimal and effective groupoid with locally compact space of units, then this alternating group is simple. Minimal means that every orbit is dense, or equivalently, that there are no non-trivial closed invariant substances. Are no non-trivial closed invariant subsets. So, technically, this is consequences of the theorem, unpublished theorem that I mentioned before, but it's also not very hard to prove directly. So, for example, let me recall you that one-sided shift that I mentioned. So, you take some finite alphabet, say. Some finite alphabet, say binary alphabet, 0, 1, and raise it to power n, natural numbers. So you take the one-sided shift, take the one-sided shift, take the groupoid of germs of the one-sided shift. Then, so let G be the groupoid of germs, the full group of the groupoid of germs and in the Terms and in this case is the same as the symmetric group, full group, and in this case is the same as the alternating full group. It's the Higman-Thompson group or the so-called Thomson group within the 2D. So for binary tree so So, what is this group point? So, this is the group point generated by the shift. So, it means that you take the shift, take the inverse of the shift, and take all compositions, and take all germs of that. So, what are compositions of shift and inverse of shift? It means that you're allowed to erase some finite number of initial letters and then And then append some number of initial letters. So it is a prefix exchange transformation, a germ of a prefix exchange transformation. So you take something looking like VW and transform it to UW, where W is infinite and U and V are fixed finite prefixes. And you take a germ of the transformation at that point. So that's what is what basically. So that's what this group word is. It's effective. So the full group is the group of all homomorphisms that locally are these prefix exchanges. And those of you who are familiar with Thomson groups, they immediately recognize that this is exactly the Feedman-Thompson group V. And obviously. And obviously, because we can replace any finite prefix by any finite prefix, the orbits all orbits are dense, so it's a minimal groupoid. And so, this theorem implies a well-known fact that this groupoid V2 is, this group V2 is simple. If you wonder, if you take alphabet of size 3, this theorem will be about the derived subgroup. Not about the Higman-Thompson group. Because then Higman-Thompson group is not simple, is the right subgroup is simple, and this is the alternating group. Is the derived subgroup symmetric for Higman-Thompson group? Let me know if you have any questions. Okay. So this So, this theorem is applicable only in the cases when the unit of space is discrete, homomorphic to the counter set, or to the cantoset minus support. Because only these locally compact totally disconnected spaces support a minimal groupoid action. Minimal group order. Yeah, discrete example would be the Be the defined tree alternating group for which this theorem applies. Okay, so but so far impression, except for this example of the man-thompson group, you may have an impression that these full groups are probably very big. And now I want to give you several results which show you that actually they can be pretty small. Actually, they can be pretty small. So, one condition which I want to introduce is expensivity. We say that an etal group OID is expensive if there is a finite set of compact open bisections such that inverse semi-group generated by them is the basis of topology of G. So, it's important. So, what's going on? We take So, what's going on? We take a finite collection of bisections. So, there are some things like this. And now you are allowed only to take inverses and compositions. But just taking compositions, the inverses, because they are partially defined, when you come. Because they are partially defined, when you compose two, the composition will be defined on a smaller set because the domains and regions do not match perfectly. And so, typically, when you compose, domains shrink. So, this must be complicated enough so that you get a basis of topology. So, you get arbitrarily small the The point is that you must be able to get arbitrarily small bisections. Okay. It is a generalization of a classical notion. So if you have a finite generated group acting on a complex space, Antigenated group acting on a compact space, the groupoid of the action and the groupoid of germs are expensive if and only if the action itself is expensive in the classical sense, meaning that there exists a delta such that if the distance between two images of two points under the group action stays forever less than delta, then Forever less than delta, then the points are equal. So, compact matrizable space, then it doesn't depend on the metric you choose. So, one can show that this is equivalent. So, in this setting, the quantity generated groups and compact space expansivity is equivalent to the classical expansivity. Okay, so the next theorem is that suppose you have an expansive group orbit with compact auto-disconnected space of units, and assume that every orbit has at least five points. Then the alternating full group is finitely generated. So this is applicable, for example, for the Higman-Thompson group. And of course, we know it anyway, but Anyway, but this theorem implies, for instance, that the Higman-Thomps is fine-fit. But not only that. Examples. For example, you can take irrational rotation of the circle and then take an orbit of one point. And then take an orbit of one point and blow it up. So replace every point in the orbit of that one point by two copies. Say every point A is replaced by A plus zero and A minus zero. So you open the circle at that place. If you do it for the whole orbit, you will explode circle into a cantoset while preserving the dynamics. The dynamics, so you'll get a homomorphism of the campus set called sometimes Danjois map. And even though rotation was not expensive because it was isometry, this Danjois map becomes expensive. And then this theorem tells you that if you take the full group of that, then it is fine to generate it, the ultimate one. Okay. Okay, so these two theorems produce a large class of simple and finitely generated infinite groups. Again, you may think that these groups are big in some sense, but in many cases they are small. So, for example, Yushinko and Monor proved that if you start with That if you start with a subshift, so you take finite alphabet and consider its power to z, and take the two-sided shift homomorphism, then take a shift-invariant subset X and assume that the restriction of the shift to this. Assume that the restriction of the shift to this closed invariant subset is minimal. One can construct such examples. For instance, this Danjoi examples are like that. Then the full group of the group weight of germs of the shift is The shift is amenable. So it does not have free subgroups in particular. In a way, it's a small group. But now these two theorems, though it was known before by theorems of Matsui, imply that these groups will be infinitely generated. And that was the first example. And that was the first example of groups of that type. Yeah, in this theorem, we do not assume that the coil is effective. Okay, so now I want to present some particular examples which again show that these groups may be very small in some sense. And that's a And that's an interesting direction of investigation to understand how small they can be. Fragmentations of the Hebrew group action. Suppose A is a homomorphism on the Canter set and has order 2, so it's an evolution. A square is identical. Fragmentation of A is a finite group of homomorphisms such that every element for every element Every element for every element for every point of the cantoset, the action of the element either coincides with the action of this homomorphism A or with the action of the identity. And for every element point of this space, there exists at least one element of the group acting as A. So in other words, So, in other words, we have some order two homomorphisms, some kind of rotation by 100 degrees or something, and we split our space into parts and then take a collection of homomorphism acting on some parts of the space as A, as that rotation, and as identity on the other parts. And you choose, make different. And you choose, make different choices for different parts. So, and you get a whole group of those, and that group is called the fragmentation. So, let's take two homomorphisms of order two, and suppose and let's fragment both of them. Let's fragment both of them. Then the group is generated by these two fragmentations will be called fragmentation of the dihedral group. Theorem. Suppose we have such a fragmentation of the dihedral group, and suppose that all orbits of the original dihedral groups are dense. So the dihedral group acts minimally, and there exists a point. And there exists a point which is fixed under the original involution A, but every element of the fragmentation for every element, the interior of the set of fixed points of H accumulates on X. So then G is an infinite torsion group. So let me draw you like a Draw you like a schematic picture of what's going on and what's typically going on. It's very nice. So imagine that your cantoset looks, well, does it look like a cantoset, but imagine that it does. It looks like this. So it has three petals, which are closed sets, but these three closed sets, the cantoset, they touch in a single point. So these three closed sets have only one common point. Only one common point. But imagine this is a candidate. And then suppose you have some kind of reflection here, so a homomorphism of order two, a reflection here, also a homomorphism of order two, and a reflection here, a homomorphism of order two. So that's our Two. So that's our A, and this common point is X. Then you can have group fragmentation. So in one, you act as A here and A here and identity here. The second element acts identity here, A here, A here. The third element acts The third element acts as a here, a here, add identity here. And then the fourth element is the identity. So you get a Klein group. If you compose this with this, this element with this, you get this, the other way around. So you'll get a group of order four. And every element of this group of order four has a set. A set of fixed points accumulating on this special point x. So this is an example of fragmentation satisfying the condition of the theorem. Now if you throw in into this picture some other homomorphism B such that it will generate a minimal action of the drahedal group. Minimal action of the drahedler group, and then, for example, copy it here. Don't fragment B, just keep it as it is. You'll get a Burnside-type group, so infinite torsion group. Now, it's easy to arrange examples where all conditions of the previous two theorems are satisfied. And in fact, if G satisfies the conditions of this theorem, then the corresponding full group also does. Corresponding full group also does. Well, I mean, it satisfies the conclusion. So you can apply this theorem to the alternating full group, for example. And in this way, you will construct many examples of simple finitely generated infinite torsion groups. So being torsion is So, being torsion is a finiteness condition. So, you get some interesting finis conditions in this case. We don't know what really makes, so there are many more examples of full groups which are torsion, not only covered by this example. And it would be interesting to understand when a full group is torsion. That's something that we don't know at all. And finally, about growth. Finally, about growth. So, suppose you have a fine-tragonator group acting on a set. An orbital graph is a graph gamma with a set of vertices equal to a g-orbit, in which you connect by an arrow pointing to its image, labeled by to its image under a generator, and you label that arrow by the generator. So, for every Y and every generator S, you map, you draw an arrow from S, from Y to S of Y. Okay, I'll skip this. What I want to say is that sorry, that's not that's too specific. So, let me let me define now. Me define now separately. So that so you will get, according to the definition, you will get some graph gamma, which is vertices are orbits, and you have arrows showing how the generators act. And arrows are labeled by the generators. Now we say that this graph is linearly repetitive. Repetitive if there is a constant C such that in this graph, if you take a ball of radius R for every R, for any R, you take a ball of radius R then for every vertex of the graph, for every at x y, vertex, vertex, so you have a ball here with center at x zero, for every vertex x of your graph, there will X of your graph, there will be you will find a vertex Y on distance less than C times R such that ball of radius R around Y is exactly the same as your initial ball. So there is an isomorphism mapping center to center, preserving labels. Center, preserving labels, everything. So, again, for every point on the graph, there is a point nearby, so on distance less than CR, such that the ball of radius r around that point is exactly the given ball. And this is true for every x0, for every r, for every x. So, for every x0, for every r, and for every x, we can find y such that the ball on distance less than cr, such Distance less than CR, such that the ball of radius r is exactly the same as ball around x0. So, if this is true, then we say that the action is linearly repetitive. So, it will mean that these balls repeat everywhere. You can see them everywhere with kind of gaps bounded by a linear function. That's where linear repetitivity comes from. The word linear comes. So, suppose you have a group satisfying the Satisfying the previous conditions of the previous theorem, so that you get a torsion group. If the action is linearly repetitive in the way I described, then the group has intermediate growth, bounded from above by a function of the old C exponent n to alpha, or some alpha between zero and one. So this is my theorem, but this estimate is a big improvement. Is a big improvement which is due to joint work with Kenya Jang and Lauren Bartoldi. In my original paper, the estimate was much, much worse. But this is true for all. So again, this is true if the action is expensive. The same conclusion will be true for the full group, for the authoritating full group. So you Group. So you can get this way simple groups of intermediate growth. And here is an example. This is a group acting on the Fibonacci tree. See that there's one edge is long. You can put in a kind of vertex here, then it will be exactly the Fibonacci tree. So A0 swaps these two global subsets of the Bonacci tree, B0 does this, and then B0 does this, and then there is A1, B1, C1, B1, and so on. They're obtained by taking a copy of A0, A1, A0, B0, C0 down here, and also A2, B2 down there. So this will be a virtually simple group of intermediate growths, and it will be its own full group. So it is also the full group of the corresponding groupoid of growth. Okay, again, we don't know, we don't have. Again, we don't know what alpha here can be. I mean, we have some examples with estimates, but we are looking for examples with small alpha, and we're not satisfied yet with the results. Okay, that's all what I wanted to talk about. So thank you very much for the talk. So, thank you very much for the talk. You missed the applause because I started the microphone too late. Sorry. I heard some. Thank you. Other questions? Hi, Volodia. Thank you for the talk. So I have a maybe silly question. I didn't think that he came to me just now. Does it make sense to take fragmentation of something which is not the dahedral group? That we thought about it at all? Yes, yes. And my graduate student. And my graduate student, Justin Canto, try to do some of them. Yeah, it makes perfect sense. Yeah, so the point here is that why this is works, this condition that the set of fixed points accumulates on X, it kind of slows down orbits in a way, because if you In a way, because if you are accidentally in that region where the point is fixed and you apply a generator, you don't move, and that makes things to start bouncing off and make things torsion and to mid-grove. So, yeah, it makes sense. There are some technical problems with that, though, especially in non-abelian keys. But sorry, we don't have many nice. We don't have many nice examples. We have some, but not where it's not the hidden but something else. Yeah, why the hidden is important? Because it's one dimension, the graph, the Kelly graph. And if you want to do something else, you may look at some trees, but again, with finely many ends, it doesn't look like our technique works for something two-dimensional. That would be nice. Two dimensions that would be nice. I was wondering, like, you know, that if you would take maybe another fragmentation of different groups, if we could still give you, okay, I mean, simple, finitely generated, but maybe some other information about the growth. I don't know what other things. Something about the growth. I mean, I don't know what other open questions are there left on the growth of parallel generated influences. Yeah, like find a group which grows slower than regular sugar groups. We failed that. We feel that, for example, yeah, uh-huh. Yeah, yeah, that's a good question. We don't know. Okay, thank you. Okay, are there more questions, Edward? Do you know if some of your simple groups of intermediate growth can be realized as groups of asynchronous automata? Yes. The the the one I showed is this one is. This one is. In fact, all of them are better than that. So, the examples that we have, the linear repetitive ones, they are kind of asynchronous with bounded delay, so that in order to know the nth letter of the image, you need to know n plus constant. And plus constant letters of the pre-image. So it is a special class of asynchronous. If you wish, if you take like the natural metric, the classical metric on the cantoset, then these maps are lip shapes, not just any homomorphism. Another way of defining it that Of defining it, that you can define them by synchronous automata, but at the non-deterministic. So you are allowed to have several initial states, you allow to have non-deterministic transitions, you are allowed to have not to accept some inputs, but you must be deterministic on infinite words. So that kind of Words. So that kind of automatically. Okay. And in this interpretation, would the homeomorphisms be volume-preserving? Yes, they are. Okay. Well, of course, so in this example with the Fibonacci tree, you have to take the measure corresponding to the golden mean defined correctly, and then it is measure-preserving. You can kind of see it from the picture then. Okay, are there further questions? Maybe from the online audience. Okay, let me maybe ask a last question. So, you have these alternating full groups. So, do you gain more if you? Do you gain more if you replace alternating groups by a family of, say, finite simple permutation groups and you allow only to act on these multi-sections in a specific way? I never thought about it, but there are some problems that alternating are good because if you take this multi-section and then say split. And then, say, split by cut each of these domains in two, you will get a diagonal embedding into a bigger alternating group. So it's nice to have something that respects these diagonal embeddings. I'm afraid that there might be some technical problems trying to do that, but no, I didn't try to. To do that, but no, I didn't try to. Okay, yeah, thanks. Okay, so thank you very much for the talk. Thank you. Yes, another coffee break. Not for you, but yeah, yeah. Okay, have fun.