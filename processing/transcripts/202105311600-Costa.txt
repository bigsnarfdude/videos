Thanks. So welcome everybody to this first afternoon session in Waterloo and morning session in Australia. And our first speaker today is Fabio Costa, and he will talk about background independent quantum causal structures. Independent quantum causal structures. Okay, thank you for the introduction and for putting together this very nice workshop everywhere. I'm happy to open the Australasian time zone. And yeah, good morning, good afternoon, good evening, or good night, depending where you are. So what I'm going to talk about is mostly based on the work done in collaboration with Done in collaboration with Lachman Parker as part of his authorities at the University of Queensland, and there will be a paper uploaded on archive probably very soon. Okay, so today I'm talking about some of the conceptual foundations of the gravity and causal order part of the title of this workshop, which is quantum population, gravity, and causal. Workshop, which is quantum population graphic in cosmic orders, so that meets almost all the criteria. Oops, sorry, that's nothing to do. I don't know why this comes up here. Okay, so the starting point, the motivation is the idea that when we try to combine the conceptual foundation of quantum theory and gravity, in particular of general relativity, there are some radical new features that we expect to emerge. Features that we expect to emerge. One is the idea that causal structure is expected to become dynamical and indefinite. Dynamical because causal structure is dynamical in general relativity and indefinite because in quantum mechanics we don't have definite properties. And one of the challenges of dealing with the dynamical and indefinite causal structures is that it becomes conceptually more difficult to formulate operationally well-defined theory. Operationally well-defined theories. Quantum theory is typically defined relative to a background causal structure that helps you tell where the events and when and how things happen. And so if you take that away from under the feet of theory, it seems that it becomes difficult to even talk about probabilities. The second point is background independence, which is in fact one of the topics that is most One of the topics that is most discussed in the quantum gravity community. So, for example, in the loop, quantum gravity background independence is very prominent, but this is actually all approaches to quantum gravity. And so sometime ago, we came up with this process matrix idea that was not the first example of this formalism, but we tried to pin down in a Try to pin down in a relatively clear way what happens to quantum theory if you remove the assumption of a background causal structure. So what you get is that it is actually possible to formulate quantum theory without a background causal structure. So this in a way addresses the foundational conception issue of formulating quantum mechanics without a direct reference to when and how when things happen and how they are related. And how they are related to each other. So you have formalism where causal relations are defined operationally, and you have an operational sound way to assign probabilities and to recover causal inference without the need to know in advance anything about the space-time in which things happen or the causal relations between how things happen. And the way the framework is formulated is Is formulated is abstractly in terms of laboratory that in the context of gravity and space-time, we can think of an abstract generalization of space-time points or spacetime regions. However, the formalism relies on the labeling of these points. So picturally, we say that we have Alice and Bob, and we don't know in advance if Alice is before Bob or Bob is before Alice, but we assume that we know. But we assume that we know who is Alice and who is Bob, which, in other words, is to say that we know we can assign some coordinates to Alice and some coordinates to Bob. Even though these coordinates may not be better than a classical space-time, we can still assign them. So this means that we are assuming a notion of background reference frame that allows us to point to these parties or to these points. So this is an So, this is an issue because now it becomes unclear if we really want to combine the background independence of general relativity. That seems to conflict with the very foundation of this formalism, which tells us to even talk about what happens to assign probabilities, we need to know in advance coordinates, the locations of what can happen. And so this talk. And so, this talk and this work is about trying to reconcile these two pictures. So, briefly, what is background independence in GR about? So, this is formulated in terms of a space-time manifold, which is you can just think of a collection of points. And a relabeling of points is called a diphthomorphism. So, a diffomorphism is the small. Um, so a diffeomorphism is the smooth relabeling of points, so it's an invertible one-to-one map from the manifold to itself. And the point is that general relativity is invariant under diffeomorphism. There is a bit of debate on the interpretation. The thing we can say for sure is that the Anschlene's equations are invariant about under diffeomorphism. A bit stronger is to say that actually we should assume that observables are invariant under the morphism, or another way to say it is that. Or, another way to say it is that the physical states or the physical properties of general relativity of gravity and any field should be equivalent under diffeomorphism. So, if we have a metric and we have another metric that is related to the first one by diffeomorphism, we should assume that these are two different mathematical presentations of the same thing. So, okay, how do we can we try to combine this with the process matrix? To combine this with the process matrix formalism, so I will present directly a kind of toy model of a space-time that is modeled using the process matrix. So, how does it work? We imagine that our toy universe is composed of a finite set of points, which might well be if you believe that there is some that the space-time is not continuous, or you can just think that it is a toy model. And each point And each point, so these are points that are the abstraction of what we think about as space-time events. Each point is considered as a potential event, as a place something can happen. So mathematically, we represent these as pairs of input and output spaces. And the reason is that an event in quantum mechanics is a quantum measurement. So it's the result of the quantum measurement. Of the quantum measurement, for example, if you measure a particle with the spin one out, and you see spin up, then the seeing spin up is a measurement. And more general here, we have to consider operations. So, not just measurement, but not just what is the outcome of measurement, but also how our operation transforms the system. And the reason we need to consider this is that we want to be general about the causal structure. So, for example, A, B, Structures. So, for example, A and B could be causally related, and therefore, we need to know how an operation of A can influence B or anything else. And mathematically, we describe operations using operators. And if you're familiar with the formalism, you know very well what this describes. If you're not familiar, these details are not too important. What is important to know is that there is a very simple formula to assign probability. Formula to assign probabilities to possible events. So we have a small lowercase AB here represents the outcomes of the events. For example, A can be seen ups and down. And MA, MB, and so on represents the measurements or operators. And there is a simple rule to assign the probabilities, which is really the same form of the Bohr rule. And for the purpose of this talk, you can really think. For the purpose of this talk, you can really think that this object W, which we call proxis matrix, really represents the state that describes the state of space-time and all the fields green. And MA and MB represents observable at the particular points in space-time. And to keep in mind that here, we have a tensor product structure with each of the points. So, regardless whether points are space-like or time-like, we assign subsystems. Subsystems to this point. Okay, and in particular, process matrices can represent usual situations where we know the causal structures. So, in particular, they can represent space-like events or time-like events, or even indefinite causal structures. One example is the quantum switch, but this the formalism is very general. So, they can represent a situation where you cannot say. Say that are incompatible with any space-time on which the various points are located in any classical space-time. But now you see, if you consider, for example, the time-like situation, you see that is intrinsically asymmetric. So, of course, time-like situation means that Alice is before Bob, so Alice can send the signal to Bob, and Bob cannot send the signal to Alice. And this, of course, is not invariant under the relabelling of the parties. Under the relabeling of the parties, if we relabel the parties, then it's a d before a. So, this is one of the instances that makes it clear that these objects in this formalism are not important under labeling, they rely on some background description. And it also highlights the tension that if we want to talk about codal structures and objects, we are precluded from talking about background independence. So, how do we put the things together? Put the things together. So, first of all, what is grounded dependence when we have a finite number of events? In general relativity, we have diffeomorphisms. In this case, we simply have our toy manifold is a finite set of points, and the labels of these points are the equivalent of coordinates. And so, a relabeling is simply a permutation of the points. And so, essentially, permutations are the Permutations are the discrete version of dithomorphism. So, if we want to talk about invariance under labeling or the equivalent of bifeomorphism, we have to talk about invariance under permutations. So, to model this, we have to understand how permutations act on operators. So, remember, we have these different points A, B, C, and each of these points corresponds to a subsystem or to a tensor factor mathematically. Mathematically, and our objects are operators that live on the tensor product of all these spaces. So, for example, we can have an operator A times an operator B. And if we do a swap in this case, the action of the swap, so swap is a simple permutation of two points. It means that now we have the operator sigma at A and the operator rho at B. So, that's the obvious way you can. Hope this way you can think how permutations act on quantum states on or operators. And so, here the notation is telling us that the superscript tells us the tensor factor to which the state belongs. And when we act with the notation, we essentially exchange the tensor factors. Now, something that is worth mentioning. Now, something that is worth mentioning is that this assumes that the dimension of each tensor factor matches. So, this is relatively natural. Like we think about space-time, there will be some local degree of freedom that represents the geometry and whatever fields we have in there. But one might want to care to generalize it a little to different dimensions. If you're interested, you can look at the Lachlan Parkers. Um, at Lachlan Parker's thesis, uh, which you can get if you ask him by email, all right. So, to simplify a little the notation, we get rid of the tensor product. So, now simply a swap is represented by exchanging the labels. So, if we have an operator with label AB, we swap it and write BA, it means we acted with the transition on the operator. So, now if we want. So now, if we want to have a background independence, what we want is that our probabilities are invariant under swapping of the parties. And we can obtain these in two ways, or three, if we put the two ways together. So one way is to impose that processes are invariant. So this means that if we take a process and we act with a permutation, we obtain the same process. And A direct consequence of this is that invariant processes cannot be causally ordered in any non-trivial way. So, the only way a causally ordered process is compatible with the results if there is no causal influence, so if it's a state. But as soon as you have a possibility to influence A to B or B to A, then this cannot be an invariant process. The other way. The other way is to impose permutation invariant on the operations. Or say in a different way, if we assume that observables are invariant on their permutation, then we have to say observing m at A and N at B is the same as observing M at B and N at A, which is the same as observing a probabilistic mixture of all the possible permutations. Of all the possible permutations. The striking consequence of this is that invariant observables, and this is something that is well known in general relativity, well-known issues, that there are no local observables. And that's how it's formalized in this framework, that our observables, our operators, cannot be in the tensor product format. You cannot have M, tensor, B, tensor, C, unless it's some very trivial. Unless it's some very trivial operation that doesn't do anything, if you have anything non-trivial, we are making some measurement. Then the way this is represented is either as an equivalence class of all the different permutations or more conveniently as a mixture of all the possible permutations. Either way, this is not an operator in the product form. So that's what we were saying. This takes away the main structure of the process matrix where we assign Assign an operation to Alice and an operation to Bob and so on. At this point, we have to think about the global observables that are designed across all parties. Okay, so that might be slightly worrying. However, we still have the Bone rule as we defined earlier. And we still talk about observables on background processes. The theory is still operationally well defined, even though. Still operationally well defined, even though the natural operations. And certainly, we can recover the background by introducing a reference frame. This is a concept that is very well known in the foundations of physics, how to, it's called internalized reference frame. The way we do it is that instead, so if you want to talk about something, a process that has a definite kind of structure in this language, the way to do it is to Language, the way to do it is to include a reference frame that you can think about as your rods and clocks. And so now the part that we call Ellis, for example, doesn't have only the system that we were considering at the beginning, but will also have some additional systems. For example, if A was a mass particle, now there will also be an extra degree of freedom that is, for example, a clock that tells you when the operation takes place. The operation takes place and when it can be relative to any, so it doesn't have to be relative to a classical space-time. So technically, that's a way in which you can rewrite any background-dependent process in a background-independent way by internalizing the reference frame. So, the way to do it, if you have a WAB is a background-dependent process. Background-dependent process, you extend it with this reference frame, and you will have a reference frame RA that encodes the state of A. So, A tells you, is essentially a system that if you measure it, it tells you this is Alice's location. And state B is something that tells you, if I measure the system, it tells me this is B's location. And then, after we do this extension, we can take a mixture of raw permutations so that we obtain an. So that we obtain an invariant process. And now we do the same with operations. And then now essentially we can recover all the statistics that we will have in the background dependent process. It's just that it's relative to the outcome of the operation. So when we do an operation, we don't just measure the spin. Essentially, we look at the reference frame. It tells us, oh, this is Alice's location, or this is Bob's location. And given the location, we can decide if to perform. Location: We can decide if to perform axis operations or box operation. There is uncertainty here related to the extension of operations that need some completion for the particular way we introduce this permutation reference frame. And there will be more details about this in the paper. Okay, something very interesting that emerges in this structure in this. In this story, is the structure of invariant processes. So, now thinking again about the general structure of the invariant processes, so now without necessarily thinking that there is this physical reference frame, just any process that is permutation invariant. Now, an invariant process means that is equivalent, it's equal to its own permutations, which means that we can also write. Which means that we can also write it as a mixture of overall permutations. That's in general, is what is called a twirler. And it's also a way to derive an invariant process for accurately non-invariant processes. And there are very well-known results that have to do with the invariant processes and with symmetries in this type. And the point is that. And the point is that if you have a process that is invariant under a symmetry, or in other words, a process that can be written as the mixture of this type, it can always be written as a sum of operators that live on irreducible representations of the group. So here the group is the group of permutations, and you can have a lot of fun starting the representations of the permutation group. The point is that your Hilbert space divides the second. Your Hilbert space divides in sectors or in subspaces, where each subspace is invariant under the action of the group, in this case, under that permutations. And your operators can only be sums of operators on these different spaces. What it means is that you cannot have coherent superpositions of states across the different representations. So, for example, if you have the n equals 2. n equals to the two representations of the rotations are the symmetric and anti-symmetric representation. I think I can to write this. So for example, if we have two qubits then the symmetric space will be the triplets 0, 1 plus 10. This is the symmetric space while the singlet While the singlet is the anti-symmetric space. And you see that individually this subspace is, well, each of these states is invariant on the premotion, except the thing that gets a minus time. So this is anti-symmetric. And the point is that if you have a process that is invariant under permutation, it cannot involve any coherent sum between symmetric and anti-symmetric states. And that's because. And that's because it will have a relative phase, will not be invariant under presentations. So, the typical way this is interpreted is that there is a super selection rule in the sense that our system is associated with a charge, which is some physical property that cannot be in a superposition. So, in this case, one will say, okay, our system, if it's invariant under permutation, it means that it's either symmetric or anti-symmetric. That's something that, in principle, we can measure. We determine if. We determine if the system is symmetric or anti-symmetric, and we can never have a superposition. Now, it's interesting that in the case of processes, that's not so simple. Something I skipped a little over is that the difference between processes and states is that processes are subject to different types of normalization conditions, more strict normalization conditions that simply have to do with the requirement that probabilities are. With the requirement that probabilities are well defined for arbitrary operations. And what happens is that now processes that live in individual representation of a group or a symmetry group are not necessarily varied processes. So even though the total process looks like a mixture of processes that are, say, symmetric or anti-symmetric, the individual The individual components of these mixtures are actually not valid processes, which means you cannot take them on their own, and which means that you cannot interpret this situation anymore as that we have a charge whose value is unknown. So usually when you have a mixture, you can think we have the charge, we don't know which one is its value. In this case, you cannot really interpret in this way. So this is something interesting that we haven't fully interpreted, and possibly. Subject to further start. Okay, so this brings us to the last bit, which you will not find in the paper, which is so far we have talked about relabelings of points or classical, which you can think of as classical coordinate transformations. And now there is a valid question is if that's all to say there is all to say about back gravity dependence for quantum causal structures. For quantum causal structures. Sorry, you're into question time. Oh, sorry, I didn't hear the five-minute warning. Okay, so well, this was just to say that we can consider superpositions of transformations which are not yet fully understood. And I leave there the conclusions and ask for any questions. Okay, let's thank Fabio and we have time for questions. Alex Fabio, thank you for that talk. That was really nice to see all the the parallels you you drew. The parallels you drew, um, sort of with background, other background independence approaches, um, and you know, so you know, have a have a twirl come out and interpret the process matrix. One of your slides, you said something like that the process matrix was equivalent to the state plus the constraints. Yeah. Um, and I was wondering if you know, you've made that more precise in some sense, or like how like I'm trying to sort of make this mapping onto sort of a constraint. Of make this mapping onto sort of a canonical formalism or something like that. So, this is a formal analogy in the sense that we have a Bohn rule that looks exactly the same as the rule that you have for expectation values from observables. So, if you read this formula, you can interpret W as a state and M as observables. So, formally, it looks exactly the same. The only difference is that because now we are considering a Considering a general causal structure, the structure of observables is different. So, technically, observables are now described by quantum instruments. And so, this implies a different set of constraints on W normalization. So, it means it's not just that if it was a state, it will just be positive, semi-definite mass with phase one. But now, for the process, you also need to impose a lot of linear constraints. So, there is a canonical. So there is a canonical metric of this type. I guess what I meant sort of more was like if I had a phase space with some symmetry constraint on it, like the I'm trying to think of like a Hamiltonian constraint or a momentum constraint or something like this. But I guess that's you mean something slightly different here when you say state plus constraints. Because I guess that might be the way we would, in a canonical approach, think of a background independent theory. But yeah, so the point is that here, does not represent. Here, W does not represent just a state in the standard sense of a state of affairs at a given time or well or one of the realization of one of degrees of freedom. So W also represents possible transformations between systems. So I believe there is a direct way to take the phase space and The phase space and translate in process macrosystem. But so, here, when I talk about constraints, I'm talking about the normalization constraints. And then, if you want to impose constraints such as coming from symmetries, that's exactly what I was saying. For example, if you impose the background independence, that's an additional constraints that processes on top of their normalization also need to satisfy environmental permutations. So, these are two separate types of constraints. So, these are two separate types of constraints. Yeah, thank you. More questions?