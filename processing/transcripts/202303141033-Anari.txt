Expansion on Matroids and beyond. I realize this is not the type of talk you're used to in this workshop. I'm very distant from this community. So I hope everything is understandable, but I would rather people understand things and not finish all of what I wanted to say. So please do ask questions if anything is unclear. So the the goal the broad goal of this talk is to give you an alternative perspective You an alternative perspective coming from the theory of high-dimensional expanders on some of the results that are developed through the Hodge theory of multiples. And I'm going to talk about several joint works with Jagannath, Misha, Vishesh, Frederick, Kui Kui, Jan, Shayan, Hui, Heron, Cynthia, and June. Yeah, so I'll mention their names when the results come out. Okay, so where am I coming from? I'm a computer scientist. From. I'm a computer scientist. I work on sampling algorithms. So, the goal of my research is there is some sort of a combinatorial space of objects. I want to sample from these objects efficiently using an efficient algorithm. I think of, I don't know. Given a graph, I want to sample uniformly random spanish. So, one useful type of algorithm to do this is to do a random walk on this space of objects, in particular, local random walk. In particular, local random walks are very useful. Here on the right, I've drawn a picture of the space of spanning trees on some graph for you. And you notice that I've connected two things if they fare on exactly two edges. If I can get from one spanning tree to another by just swapping one edge. So the type of random walk I'm interested in is random walks on these types of halves. Uh it's not directed, yeah, it's symmetric exchange. Yeah. Gonna trade exchange, yeah. Okay, so I'll mention the specifics of these random walks, but just to give you a broad idea up front. Okay, so the most important thing about random walks is how long do you have to do them before you get close enough to the distribution you want to be sampling from, otherwise known as the mixing time. So it's very important to realize: you know, is the number of steps I have to take like 2 to the n, n cubed, or like n log n? Log n until I get, let's say, I don't know, 0.1 close to the distribution I want to be sampling from in some total naive distance. Also, I wanted to mention, this is a slide I borrowed from a talk I gave for practitioners in computer science. So, having theory here is actually quite important. Sampling is not like optimization where you can just do some process and stop when you think. Do some process and stop when you think you're not improving anymore. Sampling is not actually efficiently verifiable in general. So having chart on this is improving. So let me start with some examples. So you notice that the span increase was a special case of matroids. One of the examples I'm going to go over in this talk is general matroids. So what I want to do is sample uniformly random bases from these multiplied. So here on the left, I have So here on the left I have eight bases I get from this arrangement of six vectors. And notice that if I form the same graph as before, connecting two bases if and only if they differ by exactly one element, you get this famous basis exchange graph, which is also the skeleton of some polymer. All right. Cool. So everybody here knows that this is a polytope. So, this is the polytope you get if you look at each basis as an indicator vector, 0, 1 vector, and then form the complex all of them. This is the stop. Okay, so there is an old conjecture of Mihai and Maziani who wanted to sample from these bases uniformly at random. So, they formed this conjecture that if you take some matroid polytope, the comics are the indicators. The comics of the indicators of ACEs. The skeleton has this very nice property that it has expansion at least one. So, what does it mean? It means that however you cut the vertices of the polytope into two sets, the number of edges going between the two sets is at least the minimum size of the two sides. So, this is something that we proved with my co-authors, Collikoi, Cheyenne, and Cynthia. There's Kurikui, Cheyenne, and Cynthia. But maybe some of you have seen this before. I want to talk about some generalizations of this to objects beyond matroids. So in fact, Mihayan Lazirani didn't know what properties of matroids they could use at the time. So instead of trying to use properties of matroids, they generalized their conjecture. They said, take any polytope whose vertices are 0, 1 vectors. Vertices are 0, 1 vectors, its skeleton must have the same property. And this conjecture is still open as of today. We only know it for matrix. All right, so some of you might be wondering why this property is useful for sampling. This is the sort of property that shows up for proving that random walks on a graph mix fast, but it's not. Mix fast, but it's not exactly the type of property you need. So the difference is between these two technical terms: this is expansion, whereas in random walks you really need something called conductance. So let me explain what's the difference by picture. So the expansion property on the previous slide doesn't imply that your random mocks on this graph mix fast. And here is like a sort of silly example. Sort of silly example to see why. So there are 0-1 polytopes which have exponential degree at every vertex. For example, let's say the Perkhoff polytope, the polytope you get by taking the indicators of all permutation matrices, by all the permutation matrices. So every vertex of it has exponential degree. Okay, and now take this Verkov Polytop and make two copies of it in. Make two copies of it by adding one dimension. So now you can see that if I do a random mock on this graph, at every vertex, I'm only like inverse exponentially likely to jump to the other side. So it would take me exponential number of steps to even cross over. So what is happening here is that expansion and really the thing that you need, which is conductance, can differ. Conductance can differ by the maximum degree in this graph. And so the degrees, if they're exponentially large, expansion doesn't mean maximum degrees. All right, so having exponentially large degrees also has other bad consequences. One of them is it's hard to even implement the walk when you're at a vertex. How do you choose between exponentially many neighbors to jump to? It's also, you know, if you take the normal, like, If you take the normal random block, take a uniformly random edge at every vertex and continue doing that, the distribution you converge to is actually not necessarily a uniform distribution. You probably noticed from like basic Markov chain theory that you converge to the distribution proportional to the degrees of your graph. And if these degrees can vary exponentially, then it's actually hard to correct for that. If they only differ within, like, let's say, a polynomial bounded range, you can. Polynomially bounded range, you can actually correct for that and get a uniform debanding sample. In practice, I think like in Google PageRank and other things, there's often a modification where with some small probability you jump to it. Is that of interest in this story or is that tangential to everything? I think it's tangential. Like the distribution of the starting point is something that you can hope to Is something that you can hope to be close to the distribution you get, but for these arbitrary polytopes, it's hard to get a good starting distribution. Even if you allow that something. I mean, if you can get a starting point which is uniformly at random over the vertices of the polytope, then you don't even need to do the random block. But generally, you can't get that without a distribution. Distribution. So, yeah, and also, as I showed, on the Berkroft quality of times 0, 1, even putting aside all of these issues, mixing is not false. So all of these problems go away if you assume the degrees in your graph are bounded by, let's say, a polymerly large amount instead of exponentially large amounts. And one nice property that implies this is shortness of the edges of the polymers. Shortness of the edges of the polytope. So, if you're working with polytopes whose edges have length bonded by a constant, then there can be at most end to that constant many edges going out of every vertex. So all those problems go away. And so if you believe the generalized conjecture of Mihai and Vesuani, you have fast mixing of your random lock, you get fast sampling algorithms and all of that. All right, so probably everybody. Okay, so probably everybody here knows this, but matroids are exactly the zero-bound polytopes whose edges look like this. They are parallel to the difference of two static basis elements, right? And okay, so for these kinds of polytopes, we know the conjecture of Mihai and Vaziran is true. But the next non-trivial thing, if we go to, let's say, even delta matroids, which are polytopes whose edges can be either the difference or the Edges can be either the difference or the sum of two standard basis elements. We still don't know this. We still don't know that these polytopes have expansion one or even inverse polymer. Any questions so far? All right, so even though I can't prove the statement for general even delta matroids, I hope to show you some. I hope to show you some special cases of even delta matroids or some variants of even delta matroids in this talk as evidence that these objects should also have the same properties. The example with the Berger aquapelito, why does that not? Can I realize that? It's not going to have short edges. So think of it as like. So think of it as like. Does Bergoff itself not have short edges? Is that the problem? Okay, but the trick, I could do that at height one or less than one or whatever I want. Oh, you mean do the trick on one of these avatars? No, the Bergoff example. But you're saying the Bergoff itself, within one layer, I already don't have short edges. Yes. You can even need some better components? Well, probably for Berkov Polytope, it's true, but like Berkov polytope, you can think of it as the polytope of perfect matchings on a bipartite graph. If you generalize, on a complete bipartite graph, but if you generalize to arbitrary bipartite graphs, it's not true. Alright, so what are some of these variants and evidence I want to provide for this conjecture? So these are some distributions that have support a delta matroid, but are not uniform on that delta matroid. Okay, so one of them is this thing coming from statistical physics called the monomer-dimer system. So it's a distribution over, you can think of it as matchings over an arbitrary graph. Over an arbitrary graph. So dimers are like the edges in the matching, monomers are the vertices left out by the matching, and this is not a perfect matching necessarily. You have some weights on edges, and you have some weights on the vertices, and you set the probability of sampling matching to be the product of the edges, which are part of the matching, and the vertex weights, which are monomoids, which are not part of the matching. Chink. So if you take this probability distribution, which is over the configurations of edges and vertices, if you project it onto just the monomer set. So take a random sample of a monomer dimer system, and then just look at the monomer set. Forget about what the edges of the matching itself were. Just remember what vertices were present in the matching. So that defines a distribution. So that defines a distribution over subsets of vertices of my graph. And this distribution I can show it has, you know, I have fast mixing walks over it. And this is a distribution whose support is a delta matrix. It's a well-known delta matrix. Even, even delta matrix. It's an even delta matrix, yes. Okay, everybody here knows delta matroids? Or should I? Yeah, I was it. Or should I yeah? Same as an orthogonal matrix. Yeah. Yes. Funny. So, all right, cool. So that's one example. So another example is something analogous to like realizable matroids, but for delta matroids. So take a matrix L if you if you don't want to like worry about the Don't want to worry about the top condition, think of it as skew symmetric. But in general, it works if the sum of L and L transpose is a PST matrix. For skew symmetric matrices, it's just a code. And define a probability. Not everybody knows what it does. Okay, but it's you can take the definition to be just this. Can you stick that in a sentence, please? Yeah, so it's a Yeah, so it's a set system. And so there is a family of subsets of a ground set. And if you look at the indicator vectors of this family, and you take the convex hull, the edges would always be of these two terms. There's there's some sort of inner shape around that, right? Like there's there's some notion of an eye and an eye body on that. I think for even delta matrix, you can just set one of those as like not membership in the set, and one of those as like membership in the set, so then it just becomes like arbitrary sets of varying sizes. For delta mitroids, there are some complications, but for even delta mitroids, I don't think all right. So now take the probability of a The probability of a subset of, let's say, the rows to be proportional to the determinant of the minor principal minor indexed by those rows and the same columns. So this, again, this defines a probability distribution, and this condition is sufficient to ensure that this determinant is positive or non-negative. So it defines a probability distribution over subsets of 1 through n. And again, its support is a delta matrix. Delta matrix. It's somewhat analogous to the realizable matrix case, but for delta matrix. And again, in this case, I can prove that there are fast mixing walks. Character 6-0? This is characteristic 0. You really want the determinant, not the Fafian here? Yes, I want the determinant. Fafian, you have to choose a sign for it. Alright, so another example of a delta matroid is Eulerian tours and a graph. So there are, so think of a graph. It can be directed or undirected. So let me talk about directed first. I'm assuming the number of incoming and outgoing at every vertex are equal. You can even think it's like weakly connected if you want. So such a graph has Eurovarian tools. Euderian tours. Euerian tours is just, you know, you traverse all of the edges and go back to the same place and traverse every edge example once. Okay, so the problem here is, or the distribution you're working with here, is if you're in an Eulerian graph, you want to sample a uniformly random Eulerian tour. There are many possible Eulerian tours. You want to sample one of them uniformly random. So there is some sort of a reduction. I'm not going to go into it if there is time. I'm not going to go into it. If there is time, you can ask me later. There is a reduction to sampling of Aryan tools in general graphs to degree in, to basically graphs where the in-degree and out-degree at every vertex is exactly two. And when the in-degree and out degree at every vertex are exactly two, you're dealing with a delta, in short. So when your vertex has in degree two, out degree two, there is like a binary choice per vertex. There is like a binary choice per vertex that you have to make, either like match the incoming to the out going this way or like this way. And the collection of these choices give you some subset of 0, 1 to the n. It's a delta mitroid. It's an even delta mitroid in this case. So the fact that this is an even delta mitroid, I think, was first studied by Boucher. Is it also expensive or the expansion of size? Yes, yes, I'll get to that. So, yeah. Okay, so even in this case, you get fast mixing. This is again some special case of delta matrix I can prove the conjecture for. But the story changes if you go to undirected graphs. So, undirected graphs, Euderian just means even degree at every vertex. Um again, there is a similar reduction to the case where you have degree oops sorry it should be four. So there is a reduction to Euderian graphs which have degree exactly four at every vertex. Chris just pointed out a picture that has vertex in the middle as to be six. Yes, but this is the graph I start with, not the graph I started with. Can I ask one question about? Can I ask one question about the previous case? This choice between this and this. You chose the ordering of the edges. So it doesn't matter because delta matroids are closed under like these, I think they call it, I don't know, involutions, I don't know. Just call this zero, call this one, or or vice versa. Either way, you get like arbitrary choice per vertex, but uh Arbitrary choice per vertex, but stick with it and you get the usually called twist along. Yeah, twisting, sorry, yes, yes. Okay, so all right, so there is still like a reduction to degree four. Not this picture, but there is a reduction. But you have to make an additional like modification here. Once you're at degree four, at every vertex there are three possible pairings. Just forbid one of them. One of them. And it's up to you which one you forbid. So the general case is reduced to this degree 4 case with forbidden variance. And once you forbid, again, you have a binary choice to make out every vertex. And still, you get a delta matroid in this case. It's not an even delta matroid anymore, but it's a delta matroid. But this case, I can't prove. This case, I can't prove the statement force. So, this is like one concrete delta matrix for which the problem is open. Some people back in 20 years now, some people, Prasad Tatelli and Santosh Venpala, attempted giving an algorithm for sampling this, but turned out their proof out of box. So, this is vital. Okay, all right. So, that was basically the introduction of my talk. Of my talk. So, in the remaining part, I want to make some of these statements precise. So, I'll first give you a more precise definition of the random walks. Turns out walking on the skeleton of the polytope is not that beautiful. I'm going to modify that walk a little bit. And then I'm going to talk about how properties of polynomials, think of like volume polynomials you get out of Hutch theory and things like that. You get out of Hodge theory and things like that help you analyze these sorts of so random marks first. So, to just make sure that we have the right setup, I'm gonna assume that I have a distribution on some n choose k. So, this distribution, I'm gonna denote it by some function which assigns a positive number to every subset of size k out of a ground set of elements. out of a ground set of elements. So matroids are already of this form, right? And my distribution is, some people like to think of this as like a beta hypergraph. The hyper edges have exactly like k vertices. So the matroid case is like easily describable by this operation. So you just let your mu be the function that assigns to every subset of the That assigns to every subset of the ground set, like one or zero, one if it's a basis, zero if it's not a basis. And my goal is to sample now from this distribution. So there is a standard random lock. It's like a modification of the skeleton block I showed you before. It's called the Downoff random walk, and it comes from the theory of high-dimensional expanders. So let me explain what the block is. So each step of the walk, So each step of the block has two sub-steps. The first one is drop an element uniformly a triangle. So let me say, so let's say if you are at this basis at some point in time, you just select three of the elements in the spaces and uniformly at random and drop it. So that takes you to one of the three bottom sets. So let's say, I don't know, you will go to this one. And then you look at anything that could have generated this. Anything that could have generated this. Basically, anything that you can get by adding one element back. And here it's important that you now, so the first substep doesn't depend on your distribution, the unit you want to sample from, but the second substep does. In the second substep, you basically sample from the probability distribution from the prior of the first step. So you think of what sets could have generated this first step. This first step, and you sample proportional to the prior. So this means here you just try adding one element, and then each of the sets you get has some view. You choose proportional to that. Yeah, but there are only like n of them, right? So because it's a single element that you have. But but you count every times as there is an edge? Uh well, there is only one edge between edge two seconds. No, but now three, but then you have you have three, for example you call the median one, now three edges, which coordinates. Uh uh no no no no I don't normalize by that. No, no, no. So you're saying if you started at that second element on the top, you with probably one-third, you go to each of the things on the bottom. Yes. And then once you get there at the bottom, with probably one half, you go to the left or the right. Yes. Exactly. So this would have been. Exactly. So this could have been generated either from this or this. So there is a half chance of going to either one and then you take. The combination of these two gives you like a step of the random walk. So easy is to see that this random lock actually has the uniform distribution on the basis as a stationary distribution. So if the set you started at the top was unit was like from this mu, in one step you would still In one step, you would still be distributed according to. So, basic Markov chain theory says that under basically just mind connectivity assumptions, your distribution converges to this stationary distribution over time. But the real question is, what is the mixing time? And so in the first work with my co-authors, Kuikui, Shian, and Cynthia, we showed that it's enough to take only like polynomial in k number of steps for this work to be sufficiently. For this log to be sufficiently close, so k squared. And later on, this was improved by a lot to basically just a linear number of steps. I'm hiding log factors if you're not familiar with this notation. Log factors for computer scientists is ignored. So k is basically the rank of the metric. Okay. Yeah. So my distribution is unn choose k. And in practice, it is practical. So you can do that. In practice, it is practical, so you can do that. There you are. The log factors depend on that. Good. So there is a. So this result that I wrote is really k log k plus k log log n. So very, very much dependence on n. But there is actually a sub-sequence work of mine which I didn't write because I was just I was just ignoring the yeah. Same same call authorised together with T. That actually reduces it to just K1K. So it doesn't add up. So for the matrix and the dual matrix, you have the same existing? No, for the dual matrix, you would have a different K, right? Yeah, precisely. That's my surprise, because small colouring are normally very small matrix. Yeah, I mean, yeah, so if you think of, let's say, a graphic matroid, Metroid. This walk mixes in time order of the number of vertices, but if you do the dual walk, it mixes in the order of the number of edges. A bound walk. It would be a different walk for the dual. The distribution you want to sample from is the same, but it's a different walk. Cool. So that was the story for matroids. I'll get back to For matroids, I'll get back to where these numbers are coming from. But let me, before doing that, let me show you what's the generalization of Donald blocks to the objects like delta nitroids. So I'm going to do it by example, adjust this Monomer Dynamo distribution. So the way I want to think of my distributions is always as on n true sk. So I want to adjust homogenize, and there is a standard homogenization. I think if you start with like orthogonal nature, Start with like orthogonal matroid definition, it would be just a definition half. So think of a ground set that's like twice as large as the number of vertices. For every vertex, I have like two possibilities, either being a monomer or not being a monomer. And think of subsets of these where I'm selecting one of these elements per vertex. So some subsets here are invalid, but I just assign a rate of zero to them. So still I can be. So, still, I can view my distribution as some function on n choose k. And here, because of parity reasons, you can't do the normal down-up walk anymore. So if you were doing down-up walk, what you would do is you start from some configuration, an assignment of a color per vertex. You would just drop one of these colors from a vertex chosen uniformly at random. And then you try coloring back that vertex with a Coloring back that vertex with probability proportional to mean of the resulting set. But because monomers are, like the parity of monomers is constant, that block stays in place. It can't move between any two sets. There is a simple fix to that, which is just take a generalization of downhill block, where instead of one element, you drop two elements instead. And you add back two elements. So that's what I'm calling two-step downhouse block. In general, we can have L-step downhouse. In general, we can have L step down on block, where you drop L elements uniformly at random, and then from all elements you can add back, you choose proportional to the mean of the results. All right, so in my first result with Ivane, Kiran, and June, we showed that if you do this exact two-step down-up block on this distribution of matroids, you have to only do this for basically like n. Do this for basically like n cubed number of steps. N is a number of vertices in your graph, and you're sufficiently close to basically the distribution you want. But later we actually improved this to n squared, and n squared is actually tight in one space. If there is time, I will show you later why. Mu is an arbitrary function. This walk that I described always has mu as a stationary distribution. Stationary distribution, but these facts are specific to this one, to this distribution. The fact that you have to only run this for this number of steps. What's the distribution you fix? It depends on how many matchings you have. So the distribution here is, yeah, it's like for every subset of vertices, you just assign it the number of perfect matchings on the induced graph on the component. So like, these two renovies, the These two vertexes, the complement graph has like two perfect matchings, so you assign the weight of two. And then when you're going back up, you always choose this set with probability proportional to two. So here is a so we have two examples, so we can in darkness generalize. So there is a conjecture in line with. There is a conjecture in line with the Mihai Vazirani conjecture, but it's like super precise, and I'm going to even make it more precise later. It doesn't formally imply the Mihai-Wazirani conjecture, but it's in the same vein, and it implies that for short-edge polytopes, you have fast out. So, the conjecture here is that if you have any 0-1 polytope, let's say it's already homogenized for you, so the Homogenize for you, so the Haming beta of every vertex is the same, k. So, I'm thinking of like subsets of n choose k as their indicator vectors. So, as long as the L1 length of the edges of this polytope are 2t, so for matroice t would be 1, for even delta matrix t would be 2, but in general, take your arbitrary t. Then the t step down up block, notice that in the second example, I had to take the two step. In the second example, I had to take the two-step presentation was one step. The t-step down our block should mix in time optimal factors, k to the t step. It doesn't apply the Mehai Bazarani because it's a different walk, right? There's was the Yes, although in the case of matroids it does, but in the if you go beyond matroids, it doesn't imply it with constant one, it implies it with some uh inverse form, I think. Uh inverse bomb I but like Mihaimaz Irani's conjecture was also not really about like short-edge polytopes, so it it only implies it for these kinds of polytopes up to one levels, yes. So to go to go up, do I go to choose all the matrix that you see by the theoretical one to the matrix? How do I decide what matrix is out of the background? Yeah, yeah, yeah. So what you do is each step you you basically drop t of the element. drop t of the elements and then try all combinations of t elements you can add and here because I'm looking at the uniform distribution I look at all configurations that fall that become a vertex of the polytope I'm choosing from that there are comparison methods that allow you to transfer like this result and say that the expansion of the polytope itself has to be inverse polynomial as long as T is a constant. Just say again the thing you should have matroids versus delta matroids. Yeah, so for matroids, t here would be one. So I can take the one step down up block, and it makes us in linear prime. For delta matroids, I have to take t equals two. Oh, because you're okay. You're notionally using. Yeah, I'm using the orthogonal. Yeah, I'm using the homogenization. But it's still a 0-1 polytope if you don't, so. But I'm assuming my 0-1 polytope is homogenized. If you don't homogenize. Alright, so that's the random part. So these are the algorithms I want to analyze. And let me tell you why some of the results developed by this community are useful for analyzing this. High-dimensional expansion. So there is a recipe. So I just gave you a family of standard sampling algorithms. You choose your favorite T and you look at the T stepped on a block. Look at the T-step down a block. So, the recipe in general is you first convert your arbitrary distribution. Maybe it's not on a homogeneous family. You homogenize it first so that it's on some entries K. Then you choose your favorite T and you want to analyze this. So, the recipe coming from the high-dimensional expanders literature is to show something called high-dimensional expansion for this hypergraph. And I'll tell you what that means. Sorry? What that means. Sorry? Which high dimension? It's spectral high dimensional expansion. I'll tell you the definitions in a second. And then you want to use the standard Danube random box to approximate the sample. So the high-dimensional expanders theory says basically whatever this notion I'm going to tell you implies these box meets fast. And the original type of this result. The original type of this result is from Kaufman and Oppenheim, and there have been improvements over time. But I'll mention exactly what this means. So before I tell you what high-dimensional expansion is, let me set up some more notation. So far I've been looking at a distribution as like a function on introduced k or like a weighted hypergraph. So to this, you can actually associate a generating polynomial. Basically, like put u as coefficient. Basically, like put mu as coefficients of a multi-affine polynomial. So it has n variables for every subset. I take the monomial corresponding to the product of the variables in that subset. And US would be the coefficient of that monomial with resumed solution. So that's what we call GD. So with this notion, I don't know if people in this community use the word links, but maybe you're. This is basically the same thing as. This is basically the same thing as contraction in matrix theory. Or in polynomial language, you can think of it as like taking derivatives of your polynomial. So you're conditioning your distribution on containing certain elements. That's it. So before telling you exactly what high-dimensional expansion is, let me tell you what it means in polynomial language. So there are results developed in this community. There are results developed in this community that show you that, for example, if this is corresponding to the indicators of basis on an atroc, then log of g mu is concave over the positive orthogonal as a function. And this actually corresponds to a very strong notion of high-dimensional expansion. So high-dimensional expanders are generalizations of like expander graphs. So they have like an expansion parameter, and this is basically the strongest kind of like Kind of like expansion that you can hope for. Okay, all right, so for matroids, how do you prove that this polynomial is not concave? Well, there are now, by now, like a few different methods. I think the original proof was based on this Hodge theory of carrying, June, and Eric. But actually, there are But actually, there are what I would call simpler proofs based on. I think this is maybe a result that a lot of people in this community have missed, but there is a result of this Har Oppenheim on high-dimensional expanders. It's stated more generally, but if you just apply it to matroids, it implies this statement. And at the time when I was doing this work with my co-authors, and I think. Doing this work with Mai Coaters, and I think when June and Peter were doing their work on Lorenzian polynomials, at least we didn't know about the work of Vesar, but it's basically like all of these proofs have the same flavor where you do some sort of induction. So now let me go a little bit more into details and tell you what high-dimensional expansion means. So, in general, I have to tell you a little bit about how we analyze. I have to tell you a little bit about how we analyze Markov chains. So, in general, if you look at a Markov chain, it's evolving like a distribution over time, right? So, at some point in time, you have a distribution over your bases, and then when you take one step of it, you have a new distribution. You're distributed according to something new. So, when you want to analyze Markov chains, you want to basically measure the convergence rate of this distribution evolving over time to your target mu. Over time to your target mu. And basically, there is only like one technique in Markov chain theory, but manifested in multiple different ways, which is to fix some measure of distance to your target distribution mu and show that this measure of distance is contracting every single time by some factor. So there are, in high-dimensional expanders, there are these very useful notions of distance coming from information theory called Coming from information theory called F-divergences. So, what is an F-divergence? So, it's a measure of distance between two distributions. So, mu is a distribution you want to be sampling from, and mu t is, let's say, that your distribution at time t, and you bought t times. So, you want to basically measure how far away is like mu t over mu from being like the constant one function. So, f divergence says take an arbitrary convex functional. Functional and just measure like the difference between the two sides of Jensen's inequality on this ratio. So take the F of the ratio of your F of the ratio of these two distributions, take the expectation of that, and subtract F of the expectation of the ratio. So Jensen's inequality says this is always a positive number. This is always a positive number. And if you have a strongly convex function, this would be zero if and only if that thing inside is just a constant for all sets. And that only happens when you've already converged. So that's why it's a good measure of distance. So there are two different notions in the theory of high-dimensional expanders that pop up, also in other more projects. Pop up, also like in other more partial theory. One choice is when you take f of x to be x squared. So some people call it the chi-squared divergence between these two distributions, some people call it the variance. And there is also another choice popular, which is f of x equals x log x. So in that case, you get the KL divergence between the distributions. Some people call it relative entropy. Doesn't matter. But in either of these two cases, what you want. But in either of these two cases, what you want to show is that in your random log, this measure of distance or this measure of distance is shrinking by a factor every single time. So the reason there are like two choices is because this choice is easier to analyze. It's related to the spectrum of your random block, eigenvalues, and so on. This, not so much. But, anyways, people have. But, anyways, people generally do both kinds of analysis with both x squared and x log x. The first type of analysis is usually called spectral analysis, the second type is called entropic analysis, but the problem is usually spectral analysis doesn't give you the optimal runtime. This is why, like, in the examples I was showing you, I was showing you a first result and then the second result. The first one was spectral, the second one was the spectral. Cool. Cool. So, all right. So let me force through this. So this is the type of thing you want to show. You want to show that if you apply your down-up random block to your distribution, in every single step, it shrinks by a factor of one minus some row. This means that every row of steps, you're shrinking by a constant factor. And so after log of your initial So after log of your initial like F divergence divided by rho, you're pretty close to your distribution. So let's put some numbers behind these. So for variance or like entropy, the initial F divergence that you have, there is at least some point in your distribution whose measure is at least 1 over n2 state. Or, like, if you are dealing with uniform distributions, let's say with matroids, choose an arbitrary basis as your starting point. You'll have measure at least one over n choose k. So, if you take the log of the variance there, you get k log n, but if you take log of the entropy, you get log k plus log log n. And so, as you can see, this is exactly like the, up to the log factors, this k is like the difference that was showing up in all of the previous results. So, either way, in both cases, what you want to show is that there is a large row for variance or entropy, whichever you want. Cool. So, all right, so now I've told you about F divergences. Our goal is to show that in one step of the block, F divergence shrinks by some one minus rho factor. It's up to you. It's up to you. f is either x squared or x log x. Okay, so uh the way okay so the way typically this is done uh is remember a down up was really a down and an up. So the way this is usually done is you show that in the down step you have some contraction and these F divergences have the wonderful property that they can never increase whatever you do. So in the up step you just use that So, in the up step, you just use that, it can't increase. So, the combination of the two gives you some degrees. But still, the question remains: how do you show that the down step is shrinking your F divergence? And this is really where high-dimensional expansion comes in. So, notice I had this down operator. So, let's say here on this example, I have a matrix of rank 3. I had a down operator that would get me to sets of size 2. Would get me to sets of size two. But if I wanted, I could also drop more elements. I could get to sets of size one, sets of size zero, and so on. I could also go from like sets of size two to sets of size one. All of these non-operators are well-defined. They don't depend on my distribution. So the method of analyzing your walk using high-dimensional expanders is instead of analyzing some walk like this, a walk that goes from sets of size k to k minus 1 or k minus 2 or something. To k minus 1 or k minus 2 or something like that. Instead, analyze the rock that drops everything but a single element. So it goes from sets of k, size k to singletons. And so this local to global theorem of high-dimensional expanders that I showed you before says if you can show for your favorite measure of F-divergence, you have some pretty strong contraction for this dump operator, then you can actually. Then you can actually get like a much milder but still good contraction for the down operators than are useful algorithms. So really what you want in your algorithm is k to k minus 1, but for analysis purposes you can work with k to 1. No, that's 1 minus the rho. So like you want So like you want you want your F divergence of this mu d k to 1 to be less than C over K your F divergence between d1. So as you can see this is like pretty like strongly like dependent on C. If C increases just by one like you get like the Polymiel factor worse but still Factor worse, but still, this is all the reason behind all those factors. Cool. So, alright, so if you choose your F divergence to be variance, if you choose your F to be X squared, having contraction of this form C over K, is called spectral independence. And if you choose it to be entropy, then it's called entropic independence. Just some names. But if you show either of these two, then you've shown basically that the same notion of contraction, but with a Milder constant, holds for your algorithmically implementable ones. All right, so now let me show you how this is related to polynomials and things that you know from, let's say, the Hodge theory of electrophilics. So, analyze. So, analyzing the k to 1 operator and how much it shrinks variance or entropy turns out to be a very easily describable property of the generating polynomial of your exchange. So, for variance, this is the property. So you are dealing with homogeneous polynomials, so I can understand their geometry by looking at the level set. So, I can look at the points, the set of points, where my polynomial value is above one, let's say. Let's say. This this has some sort of a uh ju this is like a set. Uh so spectral independence is their property that if you look at if you if you do the change of scaling, if you change the variables to be instead of like z1, z2 up to zm, to be z1 to the c, z2 to the c, and so on, the picture that you get should be locally convex around the all-once point. Strange looking condition. So entropic independence is a slightly stronger condition. It says that if you look at the tangent at the all once point, all of your level set is above it. So it's a stronger condition. And both of these conditions would actually be implied if this whole level set was convex. Yeah, so like uh yeah so like up to like second order derivatives this is convex at the at the almost point. This is just like the global tangent bounds the bounds your function below. And both of these are implied by you know this whole set being convex. And notice that if let's say log of g mu was concave, this set with c equals 1 would be convex. With C equals 1 would be convex. So the level sets of a log-concave formula are convex. So that's how log-concavity is showing up. So more generally, if you have that, so the convexity of that level set is actually equivalent to this, that if you do a change of variable in your polynomial, where you replace your variables by fractional powers of them, so z1 to the 1 over c up to z1 to the 1 over z, the result is log concave over the positive or. Concave over the positive constants. All right, so what I showed you was that Hdx actually implies that if you have this sort of condition, then you get basically the appropriate notion of spectral anotropic independence, and that implies basically that your random box mixing mix very fast, right? So for matros, we already know that this holds with C equals one. We already know that this holds its equals 1. But the conjecture I stated before, you can now strengthen it by saying that homogeneous zero-bound polytopes hx at most 2t have this property with exactly c equals t. So if you form their generating polynomial, you replace every variable by like tth root of them, then you get like a log concave function. This is a monoton properties. That's okay. So we know this for, for example, for matroids, we know that like the generic polymer of a matroid is log concave, but for delta matroids, what you would have to prove is that if you replace the variables by a square root of them, then that thing is log concave, which in general we don't know, but for the special cases I showed you. Is that related to what I was asking about? To what I was asking about replacing the determinant by the Faffian? No, that would be like a change of the coefficients. I'm changing the variables here. You would be like replacing the coefficients by the square root, which is not related to this. So in the interest of time, let me skip this, but I wanted to just say that the inductive proof that we have for matroids does tell you a little bit in this general fractionally log concave case. Like fractionally log concave case, but it has problems. It doesn't work in for, let's say, delta motive. Okay, yeah, so in the interest of time, I was going to tell you a little bit about the flavor of why these conditions I showed you about the level set are equivalent to spectral and entropic independence. But maybe for spectral independence, the point is. The point is, like variance contraction is basically equivalent to bounding the eigenvalues of the single n by a matrix, and that matrix is describable by the Hessian and the gradient of your power model. So that's like a local condition, and that turns out to be a local sort of context. For entropic independence, I'm not going to even bother. All right, so now I want to just state basically. Just state basically where what is the difference between these examples that I showed you I have proofs for versus like the examples I can't prove anything for. And the difference is that in all the examples I showed you, I have a stronger condition, which is some sort of stability condition. So imagine you have the complex plane, you've chosen a sector symmetric around the real axis of some angle, and I'm going to call like And I'm going to call like a polymer sector stable if whenever I choose variables from inside this sector, my polynomial never vanishes. So the thing that I can show for all of the examples I showed you before is that their polynomials, their homogenized polynomials, are stable within a sector of aperture pi over 2. And some of you might be familiar with notions of real Familiar with notions of real stability or half-plane stability and things like that. So that would be like pi over 1. And that 1 or 2 is the same 1 and 2 that's showing up for matroids and delta matrix and so on. So there is a proof that if your polynomial is basically so there is a proof that now we know that That now we know that if your polymer has some sort of sector stability with a sector of angle pi over c, then its generating polynomial is fractionally log concave with the same like c. And that's how I can prove all of these examples. I know nothing beyond this like special case of stability. And let me just conclude by asking you if anybody here knows. You, if anybody here knows any notion of like Hodge theory or tools that come from Hodge theory that could be useful for proving fractional log concavity. So the problem is these are not like polynomials anymore once you take fractional powers. Thanks, Emma. Any questions?