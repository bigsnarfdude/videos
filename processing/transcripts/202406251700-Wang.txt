That is for the invitation. It's my great pleasure to present a recent research work. My co-advisors, Xing Mai and Jinfen Zhang. It's going to be a short and compact talk in about 15 minutes, but the goal is to convey a very simple idea to a probably non-trivial problem, which is a convergence analysis of policy iteration algorithm for entropy-regularized stochastic control problems. A very brief outline, we are not staying for too long on this page, as you can always see on the sidebar. You can always see it on the sidebar. First, what's the underlying protocol control problem? It's very standard transitional control. A few things to mention. First, the control set is just a finite Euclidean space subset. And we first started considering only drift control in the infinite time horizon with the discount factor rho. And all the parameters are known. All the parameters are known. And once we start considering the model uncertainty, in other words, when B sigma are unknown, especially in the case when a deterministic optimum control is unknown or not easy to reach, and we start in practice, draw a random control from a distribution of it rather just a deterministic one. And then that converts the problem into a relaxed control version. Relaxed control version and it comes to the shanlin's entropy term. But before that, I want to talk a little bit about why shannon's entropy and what's the role of it together with the exogenous parameter lambda in front of it. It plays a role of to balance two things, the exploitation and the exploration. And the exploitation is to optimize. Since all the model is unknown, the exploitation is to utilize all the information or Beautifulize all the information or the current level of understanding of the model that we have. And the exploration is the opposite, encouraged to learning the model, to learn the unknown parameters. And if we take a closer log into this term, this pi log pi term is represents for the informational value and it's played against this pi R term in front of it. So that's how it plays the role to value the two side of this relaxed control. The two sides of this relaxed control problem. That's why we need this regularized turned out in this setting. And through a standard control theory, this V satisfy this HJV, and we have the Hamiltonian denoted as H here. And through stochastic calculus variation, we can check this Hamiltonian H has a maximizer in such a Gibbs form very nicely, and naturally follows from. And naturally follows from calculations. This edge has important topologies such as somewhat Lipschitz conditions and linear growth in itself and the derivative part. And keep in mind of those maximizers of those Hamiltonian, it's very natural to propose the policy iteration algorithm. First, you have a random B0 properly, and then at each step, you plug in information from last step into the Information from last step into the Gibbs form and get the maximizer for the step end. And then you reach the Vn for the next step for the next iteration. And this Vn is easy to check that satisfies this recursive linear PDE. And it's very natural to know that Vn is an increasing sequence and has a uniform upper bound. So there is a limit for sure. But the main question that we aim to answer is whether this Vn converts to the true. This V n converges to the true V that's represented from the original HAV, and also if the corresponding policy pi n converges to the corresponding optimal control in the HJV. And if the answer to the two questions are yes, and what's the rate of convergence? That's the main idea here. Now we know what's the problem and what's our goal, let's take a brief literature review to see where we are downstream. Where we are down the screen. The PIA is well known without entropy regularization back to long after 1981 paper. And I have to say, this entropy regulation problem in continuous time settings was introduced firstly by Hao Ren, Toye, and Professor Xing Yu Chen back to 2020. And the people have other studies from other aspects of this problem. For example, as the exhaustion as the lambda goes to zero, what's the behavior of this problem, like Reynolds paper? Problem like Raymond's paper. And also, I would like to mention here all work is to study convergence of PIA, which is the iteration n George infinity was mainly motivated by the paper from Jojo and his fellows. And also a recent paper studied a similar result through a very different argument. And our goal is to provide a very simple proof and obtain exponential convergence in both infinite and finite time horizon. And at the end, we extend. Horizon and at the end, we extend this result into a one-dimensional diffusion control case. Okay, let's look at what's the main result. First of all, we need some mild but standard assumption on the regular on the on the coefficients, those are standard regularities. And with this assumption one, we have our main result in the infinite horizon case first. There are three key points. First, we obtain the exponential convergence of the value function. The value function. And secondly, we construct the convergence relative in C2 norm, which is we also have the exponential convergence on the first order derivatives and second order derivatives. And certainly, to answer the question, yeah, indeed the control pi n converges to the original FAB is optimal solution. And I would like to mention that in our paper, the Our paper, the proof is very simple, it's about the same length. The next three slides are going to be provided a very short proof sketch. And for simplicity, we consider that b equals to one and sigma equals to one here. And the state dynamics becomes just a simple running motion started from s. So first, through standard human cat, we have representations naturally for b and at each step, b end, and those functionals are. And those functionals are written down here. And if we denote the zero norm as of the difference between the first-order derivative of the Vn and the first-order derivative of the V, and through those important properties we mentioned earlier for H, we can easily check that the difference of F bands and F satisfies this bound, which is derivative at step N and step N minus one. And then we need an important And then we need an important representation formula given by early work from Herbert-Jan and Ma. But here in the one-dimensional case, in this representation, the kernel term is very simple, which is nothing but just the brand emotional over T. And when you rate it into higher dimensional general case, it involves a little bit more technical work, but the essence is exactly the same. With this, the help of this. With this, the help of this representation theorem, we reach an upper bound of the difference of first-order derivatives of this term, and which is a sort of recursive type. In the left hand, you have epsilon one, and the right-hand side, you have epsilon one, epsilon n minus one. And worth mentioning here, this constant c here is independent of our discounting factor rule, and we can always set a lower bound. A lower bound, a large discount factor rho zero as nice c squared, which contributes to this derivation one-third here. And then we have this recursive argument, recursive inequalities, and which makes this epsilon one as like a geometric sequence and easily follow to the exponential convergence of this term. And similarly, by plugging back, we have the exponential convergence of Vn. Have the differential convergence of vn, and also we also have a representation for second-order derivatives of z. And through a very similar argument, we reach the recursive inequalities for exit of 2. And together with last step, we obtain the C2 convergence exponentially for Vn. Okay, I went a little bit fast because it's a very simple idea. Very simple idea. Let's do a quick summary of everything. Main purpose is to prove a very simple way from scratch for the convergence of the PIA problem. And those essence relies largely on the Fiji type of the representation formula for the first order essential derivatives. And when the infinite horizon case, when this counting factor is sufficiently large, those row zeros, we obtain the expansion rate of convergence. We obtain the expansion rate of convergence. And this same type of argument can be extended to the finite time horizon, where we do not have the issue with a row. We do not have discussion with a large row small row. And also at the end, we provided a proof, extend the convergence result to the diffusion control case with a fully nonlinear PDE is a one-dimensional case. And at the same time, also prepared a poster in the next room for more detail. Poster in the next room for more detailed proof and the calculations. And also, the paper is available on archive. Thank you very much. Thank you. Plenty of time. Yeah, so can it be cool to assume the boundaries of the control set when you do this or something else? I would. Yeah, so we need a. Yeah, so we need the boundless on the control set to have the upper bound of the initial and also the upper bound of this increasing sequence. Do you mind elaborating your footnote on the in between the on the on my type of the same maybe say better about that? To the same model, yeah. So, uh, so the representation theorem shown here is uh one-dimensional case one, so there is always like a kernel term, and uh, in this 1D case, when your sigma is just constant one, those kernel simplified into this brown emotion over t. But in higher-dimensional case and general sigma, we need some help from the somewhat integration bypass formula for malevolent derivatives, but. Derivatives, but the essence is exactly the same. You need a kernel term, and it has some regularities we can check for. Is it what you call it? Pardon me? Is it the b-smith formula? I think it's more or less a million calculus. The result, yeah. There is a question. Yeah. So this massive work or potentially works for the case when uh the the fusion is controlled. The diffusion is controlled. Yeah, yes, yes, when diffusion is controlled. We currently obtain the result in one-dimensional case when some structures are simplified, and the proof still follows this very similar logic. Yes. Say you know that the value function has derivatives of higher order. Will you get convergence uniform compacts for all derivatives? Okay, that's a very good question. So we assume this twice continuous differential differential. Differentiability in X because our result is obtained under the C2 norm. So if you have higher regularities on the coefficient, we can do something like bootstrap. Yes, yes, exactly. I'm just curious: the main amount you relative you apply to the solution to your X when you use it. Yeah. So, the essence of that is to move the derivatives that apply to those f's into the kernel term, yeah. But it, I mean, you are not the proof doesn't work only for your C, for example, X plus W T, you can see the more linear. It's uh, it's generalized thing. We have the same thing for the generalized project. You just have to assume that the boundary value of the. Yep, that's one case just for presentation purpose. Thank you. Thank you, everyone.