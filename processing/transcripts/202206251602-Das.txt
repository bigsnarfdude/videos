We will be presenting multi-table analysis of this non-stationary and non-linear time series data that we encounter in neural data analysis. And this work I have done while I was a PhD student at University of Maryland. Right now I am at Mass General Hospital doing my postdoc. And Anuttara recently completed her PhD and she will be moving to do her postdoc probably next in next. Doc probably next in the next couple of months. So let's get started with these neural oscillations. So these neural oscillations were first recorded in EG in early 1900s. And since then, it has been established that neural oscillations are the fundamental basis of our consciousness. Even our unconsciousness, like when we are unconscious, this neural oscillation makes us unconscious. makes us unconscious. So neural oscillations are everywhere. They mediate all our aspects of our neural processing, our cognitive abilities, our motor functions, everything, our interaction with the outside environment, all of that. So most important, most interesting thing about these neural oscillations are they are inherently non-stationary. So they need to change from one state to another state. Need to change from one state to another state so that you can adapt to the environmental pressure. Or if you are forced to, like, if you are forced to do something, your brain state has to change in order to perform that task, right? So these neural oscillations are always non-stationary. And just to give you an idea, the time series neural oscillation data, they are, they come in the form of EG recordings. They look like our normal. Like our normal as usual time series data. However, there is another type of neural data recording which are quite recent. So these are individual neuronal recordings. So the neurons, like when they are within that neuronal network, they communicate within themselves using action potential spikings. Spikings. So recently we have been able to record those action potentials and they are recorded at the time points when they were fired. And it has been hypothesized that the time when they are fired carries the information regarding the processing, the neural processing. Neural processing, and as you can see here, they show a certain amount of periodicity. So it seems that they are kind of driven by an underlying oscillation. And here, we will be trying to get the spectrum of that underlying hidden process. All right, so let's start with the continuous time process, which is one of the easy recordings. We will be looking at sleep easy recordings. We will be looking at sleep easy recordings, which has a background of slow ongoing oscillations. And on top of these oscillations, transient OF packets, momentary bus of high frequency components, around 9 Hertz to 13 Hertz, those signals kind of appear and disappears quite randomly. Those are called sleep spindles, and they have been tied to various sleep disorders, they have been tied to various cognitive functions. To various cognitive functions, even they have been tied to neurodegenerative diseases like Alzheimer's. So, characterizing those sleep spindles are very important for medical professionals. And the second-order stationary assumption of the multi-table approach, it's basically gone right out of the bed. So, to capture this non-stationary dynamics, Stationary dynamics, we already have this sliding window approach. And I think the very fast multi-taper people actually use this sliding window approach to deal with the non-stationary signal. However, this approach is kind of suboptimal because they treat each of these separate windows independently. So they undermine. So, they undermine the underlying temporal continuity of the spectrum across time. Right. There is another school of thought which tries to use a totally parametric framework to characterize this non-stationarity. They're called time-frequency autoregressive moving average models. But since they are model-based, there is a chance of model mismatch. And as we have seen again and again today. We have seen again and again today, the model mismatch could actually lead you to wrong inferences. So, for exploratory data analysis, those are not something that you want. So, to deal with this problem, here what we propose is to incorporate the state space modeling with the multi-dependent framework. So, basically, we treat the features that come. The features that come out of multi-table spectra, the eigen coefficients or the eigen spectra, we treat them as the hidden parameters for the state space model. And so basically, we consider those parameters are evolving in time according to this random walk model, and they are generating those tapers data that basically multi-taper gives us. We can also write this same type of Write this same type of state space model with the log spectra based on this chi-square distribution. And now within the state space framework, the hidden parameters, we have the hidden parameters as the eigen coefficient and the eigen spectra. And the temporal continuity is characterized by this alpha hyperparameter or theta hyperparameter. And once the model is given to us, we can use this. Given to us, we can use this expectation maximization algorithm to infer both the hyperparameters and posterior distribution of these parameters, meaning the eigencoefficients are eigenspectra in closed form. Right, so once we have the estimates of the eigen coefficient, eigen coefficients and the eigenspectrum following this M algorithm, we can form the multi-taper as usual. So, just to show you how this thing. So, just to show you how this thing works with data, so this is one of the simulation examples where we have this signal generated as a superimposition of one amplitude-modulated signal and another frequency-modulated signal. And if we apply this different estimation framework, the results look something like this. And as you can see here, the sliding window multi-taper approach. Sliding window multi-taper approach has lots of spectral leakage and the background is quite noisy. So, and those spectral leakage are caused by not taking into account the temporal continuity across different time windows. Since our algorithm, which we call as DBMT and log DBMT, we take into account those temporal continuity, we can actually filter those. Actually, filter those spectral leakages out. And also, that makes the background quite noise-free. So, it's the components of interest are easy to visualize. And the TF armor, as we have already mentioned, the model mismatch is basically the devil and it kind of screws up the whole estimation procedure. And to give you a zoomed-in view, so here is the same estimates for. The same estimates for different methods. As you can see here, the DBMT and log DBMT are easier, like in those estimates, the components of interest are much easier to spot than sliding window multi-taper or time frequency armor. Not but not last but not the least, we can also construct the confidence intervals of these estimates because. These estimates because of our Bayesian nature of the problem formulation. So we have the posterior distribution of this spectrum instead of a point estimate. So we don't even have to do jackknifing or any other bootstrapping method. We can just get the confidence intervals from the posterior distribution of our estimates. Now we go. Now, we go into some theoretical analysis. So, we can show under these assumptions that the EM algorithm actually recovers the exact hyperparameters and the Kalman filters in each step reaches the steady state reaches the steady state. Then, we can show that this DBMT can be decomposed as this. Decomposed as this filter banks. Now, these filter banks could be of infinite length because we are actually combining information from all windows that are there. So, because we have this infinite length filters, our sideband separation is better than the traditional multi-table approach. And another thing. And another thing is, because we are modeling the measurement noise within our state-space framework, this DBMT also offers noise separation. So it basically detects the components where it kind of determines there is a signal component. There it offers similar kind of gain as in multi-table, not like classical multi-table method. Not like classical multi-level method, but when it detects there is no signal, there is only noise, only background, it basically suppresses the whole signal at that frequency. So that is one of the feature that we didn't design for, but the modeling framework basically results into. And using this same filter bank integration, we can also do bias variance. Do bias variance analysis under this quite general assumptions. And here, not going into too much detail, the bias and variance expressions again have the similar expressions as in classical multi-table method, but also has these terms. The sigma squares are the noise covariances. So these terms correspond to those measurements. Corresponds to those measurement noise variances. And the temporal continuity constraints adds in this extra term. And you can see there are these kappa n and mu n parameters that are creeping in, and they are quite hard to compute in closed form. But in some very simple cases, we can actually numerically compute them. Numerically compute them against the temporal continuity hyperparameter alpha. So they basically depend on how related those different spectrum at consecutive windows are. So we can see here the mu, the gain for the noise covariance is always less than one, meaning it is always contributing to Contributing to noise suppression, but kappa n could vary from 0.8 to let's say 1.2. So, based on the temporal continuity across different windows, it offers different kind of bias trade-off. And point to note is when this kappa is one and this mu is one and sigma square equal to zero, meaning we don't consider any noise, any measurement noise at all, this bias variance. This bias variance expression boils down to classical bias variance expressions. So, this is sort of a generalization of the classical bias variance, classical multi tuple method for this kind of time-varying multi-tuple method. Okay, so now let's look at one of the real example, the analysis of the sleep data that we talked before, and we show the sliding. And we show the sliding window multi-taper along with the DBMT and log DBMT estimates. And it's very clear that sliding window multi-taper, we can't see the, like the background is so noisy, we can't see the spindle activities clearly, right? But if you look at the DBMT estimates or log DBMT estimates, they are quite clear. And in log DBMT estimate, they are actually kind of kind of like highlighted by the by the algorithm. So if I zoom in, that becomes even clearer. And again, we can have the same confidence intervals so that we can do statistical testing to determine if there is spindle or not. Right. So now that we dealt with this, let's look into this other type. Let's look into this other type of data, which are the individual neuronal recordings. So this neuronal spiking data is kind of different from the continuous time data, and they are hypothesized to be driven by some continuous oscillations that we are not observing. And we want to find the spectrum of that continuous observation. Observation. So, to do so, what like the existing method actually tries to estimate that underlying continuous oscillation. And it does it by computing this statistics called peristimulus time histogram in literature. It's nothing but an average of all the spiking activities across different trials. So, now this is still not continuous. So now, this is still not continuous, this is still discrete. So, to make it more continuous, like we like not we, people usually use some sort of smoothing, either kernel smoothing or they do some kind of model-based smoothing, let's say states-based smoothing. But this kind of smoothing inherently introduces this frequency domain bias. So, we are already introducing bias even before we are doing the spectral. Even before we are doing the spectral analysis. So, this is already sub-part. And the spectral estimation, the existing works, they just do a conventional Fourier analysis, which, I mean, which is not good. We already know. It's like basic periodogram. And then, even if you do multi-table analysis on this smoothed data, we won't be able to undo the bias that we already introduced. So, our goal will be. So, our goal will be to directly estimate multi-tavel spectra from these neuronal spiking observations. So, to do so, we introduce like this notion of conditional intensity function, which gives us the instantaneous probability of observing a spike. And this is my like, this is uh like. This is like the limiting probability when the interval, time interval, goes to zero. So, once we have this notion of conditional intensity function, we can view this spiking activity as a Bernoulli process after we discretize this conditional intensity function within a finite time intervals. And to do the spectral analysis of this conditional intensity function, Of this conditional intensity function, we assume that there is a second-order stationary process, which is exactly our Bernoulli, which is exactly our CIF, and this process admits this Kramer representation. And further, we simplify using this piecewise continuous assumption where we basically parameterize the spectrum by The spectrum by these quantities am and bm, these different Fourier coefficients. So now, once we have this model, we can write the data log likelihood in terms of these parameters, am bm, which we collected as theta. And then we can do an ML estimate given these spiking activities to get the the to estimate uh this this this theta and then from the spectrum but this is still like doing a fourier transform uh we are not doing any multi-tapering and here we can actually introduce multi-tapering by using a tapered version of the spiking activity but now since uh the spiking activity is not spiking activity is not a continuous signal what Continuous signal, what does tipering mean in this case? Right? So, we came up with something called thinning. So, thinning is a notion of retaining certain spiked on a, like with a probability proportional to some taper value. So, let's say when the taper takes a positive value, Takes a positive value, we retain the spike, we retain the spiking activity with probability proportional to the value of the taper at that time point. But when the taper takes negative value, we actually consider retaining the complement of that Bernoulli process, one minus the spiking activity at that time point. So, if we do that, we can show that this thin process has. We can show that this thin process has CIF, which is basically a tapered version of the second-order stationary process, which is what we want. We can also show that if we do this thinning on different trials and then average across the trials, that average actually converges in probability to the PSTH that we previously discussed. We previously discussed times the tapered version times the this DPSS taper. So, this leads us to follow this scheme. So, we have the PSTH and then we taper the PSTH according to this expression here to get the auxiliary statistics. And then, from this statistics, we do ML estimation to form the eigenspectras and then find. Eigen spectras, and then finally we can average them to get the PMTM estimate. And now, let's see some of the examples of this PMTM. So, here we have we simulated a bunch of spiking, neuronal spiking data based on this continuous time signal. And when we apply the PMTM and the other spectrum. Spectrum estimation methods, we can see the PMTM actually follows the true PhD closer than any other spectrum estimation methods. And the bottom panel actually shows that just like our normal multi-taper method, this PMTM also improves the bias and variance as we increase the number of tapers. We also applied this PMTM on. Applied this PMTM on this general anesthesia data, where aside from this neuronal data, the local field potential or LPF data was also collected. And in medical literature, it has been hypothesized that this LPF data, this LPF, this continuous valid LPF actually drives these neuronal firings. So if we get the spa spectral density, This power spectral density of this LPF and this neuronal data should kind of match, right? So when we apply PMTM on this neuronal data, this PMTM closely resembles to the LPF power spectra, whereas the others don't. Okay, so with that, I will hand over to my colleague. Thanks, Prahloy. So, I'll continue the presentation and explain to you how I used methods similar to what Prahloy just talked about to come up with a unified framework to infer the spectrotemporal connectivity in neuronal populations from spiking data. So, here we consider a problem setting that is very similar to Problem setting that is very similar to what Prahlai said. We have neurons that are oscillating, but what we see are spiking observations that are being driven by these oscillations. And also we consider the fact that these oscillations are varying with time. So there's a frequency time representation. And instead of just single neurons, we have activity recorded from an ensemble of neurons. Recorded from an ensemble of neurons. So, we want to infer the individual spectrotemporal activity as well as the cross-spectral coupling. Basically, we want to infer a time-varying spectral density matrix. And my contribution here is to introduce a direct inference framework to infer the spectrotemporal connectivity from the spiking observations without requiring. The spiking observations without requiring intermediate time domain estimation. So let's see how I did that. Firstly, I modeled the non-linearities between the spiking activity and the time domain oscillations using point process modeling and then used Priestley's formulation of semi-stationary spectra to relate the to model the non-stationarity of the oscillations. And next, following the same formulation that Prola talked about before. That probably talked about before, I derived a closed form expression for the semi-stationary spectral density matrix, which we call the SST matrix. And now we have a forward model that relates our observations to the quantity of interest. And then I further enhance this model using two additional assumptions, similar to what Proloi talked about in the DPMT method. We used a state-space model to model the stochastic continuity across time windows. Across time windows, and then also used a prior distribution to improve the estimates on its past data settings. And once all the elements of the forward model are in place, we solve the inverse problem directly using expectation maximization. And this obviates the necessity of performing intermediate time domain estimation. But so this addresses the issues in two-stage approaches. However, this framework inherently has the conventional Conventional, the bias and variance limitations of conventional Fourier analysis. So, next, we extended this into a multi-tapering framework. But similar to what Prahloy talked about before, the challenge is we do not actually see these oscillations. They are latent. They are the ones that are driving the spiking observations. What we see are the spikes that are being driven by these oscillations. And our approach is based on directly inferring the spectral density matrix without explicitly estimating. Without explicitly estimating these oscillations. So, how did we do that? We noted in our data likelihood the PSTH, which is the ensemble average across the different trials of spiking activity, is a sufficient statistic. So, we introduced the notion which we call a tapered PSTH, which is a perturbed version of the original PSTH with the properties of multi-tapering. So, here the new is the DPSH. The new is the DPSS sequences for each of the data tapers. We modified the PSTH so that it has the properties that would be there if the oscillations were tapered using the DPSS sequences. And then for each of the tapers, we performed this and used the previous expectation maximization framework to derive the estimates. And we call them the eigenSSDs and derived the final estimate, which we call the point process. Estimate which we call the point process multi-taper semi-stationary spectral density estimate or PPMTSST by averaging across the data tables. So let me show you some simulated results. Here we simulated the activity of three neurons that had spectrotemporal coupling. And I'm showing you the ground truth in comparison to the proposed estimates. And the proposed estimates were derived based on the spiking activity, whereas the ground truth was derived based on the spring. Whereas the ground truth was derived based on the actual known oscillations in the simulations, which are not known in real data. And for the ground truth, we consider two cases. The true SSD is what you would get using the autoregressive parameters that we used in simulating these oscillations. And the oracle SSD is what you would get if you computed a direct multi-tave estimate from this continuous X, which is not observable in real data. As you can see, our proposed estimate. As you can see, our proposed estimates closely recover the ground growth. In comparison, if you compare with the existing methods which follow a two-stage approach, they do not recover the ground growth. You can see that they mask the true spectrotemporal connectivity and also they have a lot of error. And this is more visible when looking at a snapshot of the spectrograms, as I have shown here. The black curve is ours, and it closely matches the ground growth given by blue and red. Growth given by blue and red, whereas the existing ones given by green and yellow have a significant offset, a bias which we attribute to the two-stage approach, because multi-stage estimation causes error propagation at each stage, and also biases induces due to time-domain smoothing. Next, I'd like to talk about some theoretical guarantees we had on our estimator. We proved a theorem we showed that the bias and the variance of Showed that the bias and the variance of estimator can be bounded by terms that drop with the number of trials and also the number of tailpares. So, this provides a theoretical quantification about the performance of our estimator under different settings and also shows that our estimator achieves near-oracle performance under asymptotic conditions. And to further validate this, we did extensive simulations. We simulated data under a variety of number of trials and firing rate settings. And firing rate settings, and showed that the performance of our estimator, which is given by the black curves here, closely matches the red curves, the oracle estimator, whereas the other two methods given by green and yellow have a significantly larger amount of error. And we quantify the error using two different metrics, the mean squared error and the spectral leakage. Lastly, I'd like to talk about some real data applications we have on this method. Applications we have on this method. Firstly, we apply this method to identify how the network organizations in rat cortical areas change during sleep. So here we considered basically two populations, pyramidal cells and interneurons. We had spiking activity recorded from these populations during different types of sleep episodes. So, let me show you the results we get from our proposed estimates in comparison to the existing. Post-estimates in comparison to the existing methods. Even at first glance, you can see that the estimates we get from our method are highly denoised and they have better spectrotemporal characterization than two-stage existing method during different types of sleep episodes, wake episodes, then non-rapital sleep episodes, and rapid eye movement sleep episodes. Our proposed method indicated that there's high coupling between these two neurons. High coupling between these two neuronal populations during non-rapetite movement sleep episodes, whereas the coupling was much weaker during the rapid type movement and wake episodes. Next, lastly, I'd like to show an application on another data set. These are data recorded from human subjects undergoing general anesthesia. And here, in addition to the spiking activity from the brain, they also recorded a local field potential. Also, recorded a local field potential LFP signal, which records the global activity of the brain. So, while we originally developed our framework to infer the spectrotemporal connectivity from multivariate spiking observations, a modified version can be used for the joint analysis of spiking activity and continuous activity as the LFP. And that's what we used here. We used our method to jointly analyze the spectrotemporal coupling between spiking observations and the LFP. And the LFP. And the panels I have highlighted here are the estimates from a proposed method. And this indicated to us that there's higher coupling between these two populations after the induction of anesthetic, whereas the coupling was much weaker before the point of induction of anesthetic. So this affirms the previously reported phase locking effects of anesthesia. Of anesthesia, but now at neuron scale. So, this wraps up the presentation. Thank you very much for attending the presentation. We'd be happy to answer any questions you have.