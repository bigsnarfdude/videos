So for this functional, so we have existence and we're discussing uniqueness. So I want to discuss uniqueness. So it's not strictly convex. So what are the for functionals with linear growth, what are the uniqueness results that seem to be available in the literature and are not I'm not telling you that we know all that's been written on uniqueness, far from it. So there are uniqueness results for the least gradient. And so there's work, there was an early work of Sternberg and no, Sternberg in this room. No, Sternberg, this will be much before. Okay, it doesn't matter. There's a more recent piece of work of Bob Gerrard and Mozadi Fran. I'm sorry, I don't remember his name and I didn't think of looking up his name again. Uh so so there are some uniqueness results for the least gradient functional. Least gradient functional, but for this, as far as we can tell, there's nothing the rejection. Why? So there are more general uniqueness results for functions which are one homogeneous. But this is neither strictly convex nor one homogeneous. So all the unique best results that you find in the literature just not apply. So we want So we want to discuss what I planted to try and discuss here. So the key, I mean, there might be different ways of tackling uniqueness for work. So our way of doing it is to realize something. I'm kind of working backwards because actually we started with this and then real and then went the other way around. But it's okay. So our way of so uniqueness, so that's your function, right? It's quadratic and linear. So what you've got to do is you've got to introduce, you've got to write it like this. And it so happens that it's exactly the same. And it so happens that it's exactly the same function. If you minimize this in p, then you get the other function. And so now, when you do that, suddenly you've introduced an additional field P. So you can do that from the get-go or you can do that on the relax functions. Let's say you do it on the relax function, right? It of the relax functional. So the relax functional being this one, the one at the bottom. So this problem reads, it's just translating this by adding one additional field. So it reads as you minimize in terms of three fields, u sigma p P which are kinematically related by the fact that the gradient of u is sigma plus p. q is bv. Sigma is an L2 function. So if you want to think of sigma as well, coming to this part of the functional. And P, because du is sigma plus P P is a bounding measure which will live on the Will live on the set and the Dirichlet boundary part of your set. And on the Dirichlet boundary part of your set, that measure should appear only if you don't satisfy the boundary condition. So ultimate. So it's a vector because u is a scalar. So p should be w minus u nu, where nu is the norm the other normal t to the idea of. To the idea of the quality. And what you're minimizing is exactly here: sigma squared and then mod p. And this is a set of admissible triplets, if you want, in V V L, and bounding measures. And the boundary condition is here. Okay? So if you wanted to, you don't need to. Two, you don't need to use a relaxation. You could say, okay, I look at this problem, and it's pretty obvious because everything is lower semicontinuous, and this guy is subagative, that you have existence. And you also have uniqueness. You have uniqueness of sigma. That's pretty obvious too. Pretty obvious too. But you assume you have two solutions, you take the linear combination weighted by one half of those two solutions. You use the strict convexity of this guy and the sub-anvity of P, and you get that you would be below. So if you have two minimizers, you could build a way. A weighted minimizer which is strictly below your original value, so you have uniqueness of sigma. So in order, so essentially, so the merit of this formulation of in this way, this energy does not depend directly on you. No. Is it clear? I mean, it's clear that maybe I'm missing some case, but it's. Yes, but there is clearly uniqueness in sigma, but why why uniqueness in well that's what we're going to talk about? That's going to be the topic of the talk. So everything, so the question will be, the uniqueness is all about P. Not all about Eve, but all about P. You're too young. So now, this here, written this way, for those of you who, and I know a few of you do, those of you who know Panky Plasticity, which is the static version, if you want. It's kind of a poor man's version of Valnises, Selastoplasticity. This is exactly. This is exactly a static plasticity problem. And this is the way we first came to this problem because we've been interested in plasticity for a long time and we were trying to... So of course it's a very, very elementary plasticity problem because it's, oh, I forgot to say, all I'm going to say today is in 2D. And the scalar. And scalar valued. So u is omega is in R2 and U is scalar valued. So we are very far from class BC. And actually, we are very far from even thinking about a uniqueness resulting class DC. So discussing to get back to this, discussing uniqueness will be discussing uniqueness of P, because we know sigma is unique. We know sigma is unique. And this is a merit of this formulation that he kind of splits the uniqueness. Well, one of the merits is that he kind of splits the uniqueness question into a part, sigma, where you know it's unique just by convexity. If you want, the sigma kind of takes advantage of the quadratic part of the energy at the bottom, and then P, the linear part, which is really in Castro. Inner part which is really incapacitated by my people. Clear so far? So how, you know, one way to... This is a complex problem. So the minimizer satisfies the the Euler-Lagrange equation. You know, we're not in quasi- in the quasi-convex world. We're in a very classical world. Very classical world. So we've got to write the Euler Lagrange equation. So I remind you of the set of kinematically admissible fields. So how do you do that? Well, you first do classical variations with zero boundary conditions, because they have to be admissible. And then you find that being a minimum is equivalent to this, just one relation, right? Just one relation, right? This one. So that's for any variation here where W is zero in the definition of LW. So taking smooth variation, you'll get immediately that the divergence of sigma is zero, which if you know plasticity is not surprising because it says equilibrium, I have no body force. I have no body forces. You saw that if I apply forces, I put surface forces, right? No body forces. And you get another one, which is a little bit less intuitive, but which is very natural, if you know, plasticity, which is that mod sigma should be less than one, almost every. Okay. Now you know, you want You know, you want to come back, so you say maybe that's enough. But you, you know, when you, are you sure you have all the equations? So usually what you do is you take whatever you got, you multiply it by a tense function, you integrate by parts, and you see, and you hope to get back to your original formulation, which is this one. Well, you realize that you have a problem, and the problem you have. And the problem you have is that when you multiply by V and you integrate by part, you have a sigma grad V. But grad V has a part which is L2, so sigma is L infinity, is L infinity because of this, but you have a sigma which is in L infinity multiplied by the gradient of V, which is a which has a part itself, or which has a part itself. Which has a point in SAL, which is a tau, which is L2. That's a mistake. It's V tau V tau Q. So LI and tau are the same thing. So it's a V tau Q, the tau is in L2, so sigma times tau is fine, but the Q is a measure, and you have sigma Q. Sigma is an L infinity function, Q is a measure. An infinity function, q is a measure, that makes no sense. So you have to define sigma q, and so that's work. That's been done a long time ago, so this is not ours, especially, I mean it's partially ours, but so sigma q, you can define sigma q as a measure which is absolutely continuous with respect to mod, to the variation measure of q. measure of q with a balance at nine infinity and very important this measure lives on omega just like q itself or p itself lives on omega union the dirichlet part of the boundary and its restriction to that dirichlet part is this expression. So it's a normal stress times the jump. Now Now because sigma is in L infinity and its divergence is zero, you would expect by just by duality that sigma is in h minus one half. But actually, so that would be meaningless because you have an h minus one half function multiplied by an L1 function because W to Mv. Because W2MV are V functions, so their traces are L1. But really, you can show that you get, because sigma is in L infinity, you can show that sigma nu is in N infinity. So you have L1 by L infinity. So that's good. So that has a meaning. And then if you do And then if you do further variations, knowing that you can define the measure like that, you find that mod P, so the variation measure of P, is sigma P. For those of you who are used to plasticity, if I replace P by its time derivative, this would be what's called Be what's called the flow rule or something like that, or the principle of maximal plastic dissipation. But here there's no time, so mug piece magic. So the conclusion is that being a minimizer is equivalent to three equations, divergence sigma equals zero, mod sigma less than one, and mod p equals sigma p. So now we're going to, we're leaving the So now we're going to we're leaving the variational world and we're going into the the PD world, if you want, where you have this system of equations, of Euler Lagrange equations. And we're going to see what we can say about this. Any questions? Yeah, so maybe can you mention just how you define this sort of pairing? Is it like regularizing and taking? So first you do it as a distrib, you define it as a distribution by doing integration by parts, formally. So you integrate by parts, you multiply by a phi, and you formally integrate by parts so that you get an expression which is a well-defined distribution. And that again is to show that this distribution is a measure. And the absolutely continuous points of the sigma will coincide with what you want. Will coincide with what you want. Well, C ma is L is a nice L infinity function. The absolutely continuous points of Q, you will have the representation. I mean, this requires work. But this has been done first, I think, in a paper by Darmas. So, well. Anthology. Anthology was the first one. And then, so this requires work, you know, and of course. And of course, the more general you are about the boundary condition, the more work it requires. So you have to be very careful, especially if you have a mixed boundary condition, like what happens when you go from directly to normal. It's technical, okay? But it's so So I'm going to give you an example of non-units. So we're in 2D, and I want to spend some time on this. So we have a domain, which is this kind of trapezoid domain. So it's 1, 2. It has a slope 1 or minus 1. And I'm going to give, so I'm going to try and go slope. So on the bottom and So on the bottom and top part, I give myself a Dirichlet boundary condition. This is x, so x over square root of 2, and this is a constant, 2 square root of 2. Well, on the vertical points of the domain, I give myself a Neumann boundary condition, 1 over the square root of 2 minus 1 over the square root of 2. And I want to solve the To solve the Euler-Lagrange equations with them. So there's a very, very simple solution, which is sigma constant, which is 1 over square root of 2, 1, 1, so its divergence is certainly 0. When Cartesian coefficients is 0, it obviously has the right Neumann data, right? And P, I'm going to take P, which is just concentrated here, which jumps in the direction normal to this surface or this line. So clearly, divergence sigma equals zero, clearly mod sigma is less or equal to one. The only thing you have to check. The only thing you have to check a little bit is this one here but that's kind of so inside it's obvious because P is zero. So you have to check it on the boundary, but on the boundary you know what it is. And I constructed sigma so that sigma sigma so that sigma nu is exactly gives you exactly the same so this is a solution is it the only one so we know from street convexity that sigma is unique and a constant so I remind you that you had mod p equals sigma p. Sigma p, but now sigma is a constant, so it's sigma, but it's a vector, and p is a vector measure. So sigma, p is just sigma dot p, where p is the measure. So that means that p must be collinear with sigma. Sigma is a constant, and so the coefficient of coefficient of p must be of the form lambda sigma where lambda is not p. So lambda is a non-negative measure. How can we determine this lambda? So the idea, and that's really the crux here, the idea is to take the curve. Not something very surprising, but okay. So you take the curve. So you take the curl of the total of the gradient, the distributional gradient. Curl is zero. Curl of a gradient is zero. The curl of sigma is zero because sigma is a constant. Don't forget du is sigma plus p. So the curl of p is zero. So you have a, so the curl of p is zero, but p is sigma lambda. Sigma is a constant. When you compute the curl into the When you compute the curve in two dimensions like this, you get d lambda dx minus d lambda dy equals zero. You get a hyperbolic equation. This hyperbolic equation has here as an obvious solution. Anything which is pushed forward of, let's say it's lambda, it's a measure in x plus 1. So now, with this, so you know that p is lambda x. So you know that p is lambda x plus y. So now you know sigma, you know p, so you know du, you can compute u. It involves the antiderivative of small lambda, which is what you call capital lambda, which is, because small lambda is not p is non-negative, so capital lambda will be a monotone function. So you get that u is its plus a monotone function. plus a monotone function. All you need is to see if your boundary conditions will allow you to set. And you satisfy all the equations. So all you need to satisfy are the boundary conditions. So you go and so I remind you of what these things are here. And you cannot have possibly a jump here because you don't satisfy the flow. You don't satisfy the flow rule here. I remind you that the flow rule is this, and you should need, in order to have a jump, that's only possible with sigma dot mu is plus or minus one. That's not the case here, so you have no jump. So because you have no jump, lambda should be zero here, and because lambda should be zero here, and it's a function of x plus y, it should be zero in all this shaded it uh it propagates because it's propagates because it's a face-blow-watch. So you know that Lag dash should be zero on zero one, which means that really your plastic strain should be zero on all this shade region. Now you go up and you realize, so that's what I wrote here, but I wrote it in terms of capital lambda instead of P. Now at x plus y equals 2, it's cooked up, this example. I it's cooked up this example so that you have sigma nu equals one here. So sigma nu is one because sigma is in that directory at 45 degrees. So you can have a possible jump. So that means that the only thing you know about lambda, which is a function of x plus y, is that it's, which is monotone, is that its right limit, if you want to call it lambda, is double. Is double that the value, so u so let me go back. So we have u like this. So here we get square root of 2 plus lambda at 2. So all we know is that lambda plus at 2 should be square root of 2. And now we've satisfied all the equations. Satisfy all the equations. So this solution here with lambda with any monotone function which is 0 till on 0 2 which is 0 till 1 and which has which jumps to square root of 2 is 5. So in particular So in particular, you can take anything you want. You can take things that have jumps, you can take cantor functions, you can take everything you want, you will get a solution. So not only don't you have uniqueness, you have huge amount of non-uniqueness, you have no regularity results. So you cannot hope to get regularity for this kind of problem. You can have canto functions in it. So so so we we so how much I have ten minutes I guess yeah um so we tried to to to to to use this in a more general framework and uh the the way we we did so and we failed and the the the the idea is is the following there is one result that I haven't mentioned so far which is a local regularity result which is extremely Result, which is extremely specific to this problem. You change something in this problem, it's not true, or we don't know if it's true, and that sigma is locally H1. So a priori sigma is an infinity function, but it's actually H1. And that's good because then that means that the duality The duality product, that sigma, if you want, is defined mod p almost everywhere. So because of that, because of what I wrote. So sigma is defined mod p almost everywhere. So sigma p can be defined like this. And because of the Euler Lagrange equation, that means that one is sigma Sigma, the rhythmic cutting derivative of p with respect to its variation in general, almost everywhere. So you get, so now p is sigma p, du is sigma lambda, and lambda is a measure, which is a Lebesgue measure, which comes from sigma, plus the variation measure. That's because sigma is in H1 law, that you can write it like this. Now, when you take the curve, Now, when you take the curl of this, well, in general, whatever sigma is, you get this equation, divergence sigma orthogonal lambda is zero, which is a continuity equation. So it's exactly what we were talking about yesterday, except that you have to be a little bit careful. In all that the Italian school and people have done, they pull out the time. They pull out the time. Here it's a continuity equation, but there's no specific direction time. So it's divergence equals. So you're going to look at the associated characteristic flow, which is like this, and you look at this, and then you go and you look at the work of Ambrosio, Crippa, De Levis, all these people, and you say, okay, can I? And you say, okay, can I apply this kind of Lagrangian flow kind of techniques? And the importance is that the divergence here of sigma orthodox, so because we're in two dimensions, the divergence of sigma-orthodox is a divergence of, is a curl of sigma. Sigma is in H1 log, so it is in L2 log. And then you quickly realize that all these theorems. Realize that all this theory does not apply because all the theory more or less assumes that when you have an equation like this, the divergence of this guy from de Pernagon's pan should be in L infinity log. So it doesn't work. So then you have to say, well, what can I do? What can I do? So the thing we do is we consider the set where mod sigma is one. So here's a set where mod sigma is one. In the previous example, mod sigma was one everywhere. That's not always the case. And we first get local results by assuming that omega is a convex subset of that set. And because it's convex, That set. And because it's convex, and why is convex important? That set has no reason to be convex. But if we take it to be a subset which is convex, which is possible because we are... If this guy is of empty interior, we are such if omega P is convex, if it's not authentic interior, then we can take Interior, then we can take a convex subset and then we have additional regularity. Why? Because we apply Javin auto per term because we are exactly in the situation where divergence sigma is zero and mod sigma is one on a convex. So we get all the technology of Georgia de Pertard, that sigma is locally lips sheet, it's going to become It's going to be constant along characteristic lines in the direction of sigma orthogonal. And with respect to Jabber and upper terms, there's a huge difference. We don't have vortices. Why don't we have vortices? Because we're in H1. And because we're in H1, we cannot have vortices inside, because they wouldn't generate H1. So we have no similarities. So it's a case where Java topan gives us something which is local. That's something which is local. No obstacles. And then from this, we can prove various things. We can prove, and we get, so most notably, we can prove that u is a constant along the characteristic lines, which in this part of the value, in omega p, are straight lines. Now, this seems like a very simple thing, because u, so the characteristic line are x plus s sigma 1. line are x plus s sigma orthogonal. So you want to compute the derivative of this guy, you compute it, but du is lambda is something times sigma, sigma times sigma orthogonal, and this is zero, so you would say this is zero. But of course this is kind of the complete reverse chain rule. It's the B V the the composition of a Limsheet function by a B V function, not of a V V function by a Lipschitz function. I mean I don't know, maybe I'm saying it wrong, but you understand it's not phi of U where phi is Lipschitz and U is V V. It's phi of U where phi is B V and U is Libcheets. So you have to work for this. We get a complete description that I won't get into because it's too complicated and I only have a few minutes. Only have a few minutes. So we get a complete description of the geometry of the characteristics, which is very complicated. You can have fans, but they cannot be interior fans because you wouldn't be in each one. So the fans have to be on the boundary. You can have various regions. You can have places where there are no characteristics that go through those points. And so on. That's that takes. A lot of effort because, although it's not complicated, it's planar geometry. You have to make sure that you get all the cases right and so on. So, this is a bit of a technique. So, now I'm getting to the last slide. So, the case where, now, the whole set where mod C minus one is convex. We don't know. Okay, so we don't know if that's always true. So we don't know if that's always true. But we have examples where omega D is a. We have very few very few explicit examples. There are maybe three or four. So we have an example, the one I showed you before, where you have non-uniqueness. And we have an example where omega p but omega p was all of the domain. Here we have another example which is which is way too complicated to explain, where Complicated to explain where omega p is convex, again, not strictly convex, but convex, and which doesn't fill the whole domain. That's the kind of example, actually, I should say, that if you don't know mechanics very well, you'll never be able to come up with it. So we got this example thanks to Jean-Jacques Margot. It's a crazy example. It's a crazy example. So here we have global results. The reason is that there's another result by Serragin, which says that where, so it's a result in the vector case, replying in the scalar case, which says that a set where the elastic set, a set where mod sigma is to p less than one is open. I highly recommend reading the proof of this. I'm reading the proof of this. And if one of you does that and understands the proof, please send us an email explaining it because it is just already unrelated. So of course, everything that I'm going to say now, which is not much, depends on this. If this is false for some reason, because nobody has a vote. Of that, because nobody has ever read a proof that even our result is easy. So, because of that, we know that on the boundary of this set, which we call P, mod sigma is 1, H1 must have 0. And from this, as of 48 hours ago, we can prove that sigma is continuous everywhere inside the domain. We are absolutely sure. And we are absolutely sure that we can prove that sigma is continuous inside the domain except at maybe two points. But in the last 48 hours, we were able to bothering her for the last year. So we have a very recent... So with that, and after a little bit of effort, we can prove We can prove a result of uniqueness, or at least in the new field that we have created, which is stochastic proof theory. Specialists, some experts here in stochastic stuff, we have a realization of a result of uniqueness. That if omega E, so if the elastic part is convex, u is unique. U is unique for pure Dirichlet conditions. So that's a result of uniqueness just for pure Dirichlet conditions. Omega P, sorry. So what is this stochastic proof? Omega proof is only correct, about 90% probability? Well, I don't know. We were hesitating to name it a stochastic or an oscillating proof. It's been correct before. It's been correct before. It's been known to be correct, it's been known to be false. So the thing is, now we're pretty confident, but confidence is no. We've been confident before, so I would hesitate to say that we have a Thank you very much. At some point, you said that our level of observation can be unique in minimization. Yes. Because it's complex. Because the rule is complex. It's just a matter of uniqueness. Yeah, it's just a matter of uniqueness. Okay, so the solution in the back examples are also minimizing. So all those. So by the way, this shows you that in a very simple problem with linear growth, not only can you needness be default, but regularity. So you have absolutely no regularity for this kind of problem. Whereas for the least gradient problem, there is some regularity. Does that then also give you the uniqueness on the original side? Yes. Okay, so there's some sort of one-to-one. I think I didn't quite. Well, there's uniqueness at least of gradient. Q. Okay, more to do. No, but it's even better. Sorry. It's even better. It's even better because it's not only uniqueness of u, because u is defined as a v v function, but p is defined as a measure of an omega union, the jump. So it tells you how the function, which is unique, jumps at the boundary. Yeah, okay, so it's like unique function. So it's a true uniqueness result for during the community. Because a lot of results for these Because a lot of results for these gradients are uniqueness if you know the trace of you, which is completely different. So a problem which would be infinitely easier would be to say, do you have uniqueness if you know the trace of U? That's different from saying, do you have uniqueness if you apply a boundary condition? Is that clear? Can you just say something about this H1 log? I mean, you said that it's a seamless in H1 log. So this was originally proved by... It's an old result that we just revisited and rewrote because in this case. But this is a tip. It's exactly how you improve additional radiivarian in the nectar. In the leptic seas. You do translation. However, it's, you know, you get a mess. And it works only, so as far as we know it, it works only because the set where sigma is constrained to stay is a ball. E uh you more or less. So you could do, I think, uh so Jean Franco has been working for years on this with Alessandro Giacon. With Alessandro Giaconi and Maria Giovanna more, so maybe he would he should say more about that. So, first of all, the result of Pen Sussan has also in the vectorial gates from the problem of plasticity, for Panvises plasticity, where the context of elasticity is a ball. And we okay, this is still ongoing, but it's almost finished with by Angelana and Alexandro. We generalized it to convex of elasticity, which Of elasticity which have positive curvature, but with no angles. So they don't should be elastic. So for instance, if you think of the analysis, convexity of the analysis of the crest cataly with angles, nobody knows. And there are no proofs of that result and no contradiction proof. Oh, this is computer.