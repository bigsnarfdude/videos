Official complexes, and these are things that are useful in describing the topology of those objects, and we can calculate them with linear algebra. So, topology is, of course, like the study of shape and space and properties of those spaces that are left invariant under certain types of transformations. The classic example, of course, are the donut and the coffee cup. I don't know if there's donuts and coffee live. I don't know if there's donuts and coffee live at Beers right now for you, but I hope there have been. The idea is that these are topologically equivalent because you could, for instance, take this coffee cup and sort of pretend it's made of rubber and you could compress the cup part down into the handle and then thicken up the handle to make a ring that looks like this donut here. So in topology land, we're going to think of things being topologically equivalent when we can Equivalent when we can turn them into each other by sort of stretching and bending and warping and shrinking, but we're not allowed to tear things and we're not allowed to glue things together. Now, there's, you know, describing something topologically is a pretty, is a tall order, but one of the things that we can do to partially classify topological spaces is talk about quantities called Betty numbers. And these are topological and variants. And these are topological invariants, which means that they are left alone under those sorts of transformations that I just mentioned a moment ago. And what Betty numbers count for us is the number of connected components, sorry, the number of holes of different dimensions in our topological space. And then the one tricky part is that it turns out that a zero-dimensional hole is what we think of as a connected component. So let me try to make this. So let me try to make this concrete. Here are some kind of fundamental topological spaces that we think about. Here's a circle. This circle has zeroth Betty number of one because there's one connected component. It's one thing. Then it has first Betty number of one because there's one topological circle. Another way of saying that is there's one hole that has a one-dimensional boundary. The one-dimensional boundary is this curve. Dimensional boundary is this curve. The rest of these Betty numbers are zero because there's no higher dimensional structure. Here's a two torus. So this is a hollow donut. Its zeroth Betty number is one because it's one thing. There's one connected component. Its first Betty number is two because to generate this shape takes two circles or two topological loops. You can imagine one of them as the one that goes around the equator of. Goes around the equator of the donut. And you can imagine the other sort of key circle as the circle that goes through the whole of the donut. So one around the equator and one through the middle of the donut hole. And then the second betting number is one, because there's a void inside this torus. There's a space that we can walk around inside. That's a three-dimensional space, but its boundary is two-dimensional. So the second Betty number is one. Over here, Over here, there's at the two-sphere. The zeroth Betty number is one because it's one thing, there's one connected component. The first Betty number is zero. There's no topological circles in this sphere. You're saying, Chad, there's so many circles on a sphere. Like, why are you saying there are no circles? And the idea is that if you put a rubber band around the equator of this sphere, since we're in topology land, you could contract that rubber band to a point up at the pole here by sliding the rubber band. hole here by sliding the rubber band up and that point has no holes in it. So there's there's no there's Betty one equals zero here, no circles, but Betty two equals one because there's a three-dimensional void with a two-dimensional boundary, the surface of the sphere, inside that ball. We can walk around inside the ball. So this is just to give you a little bit of intuition about how Betty numbers work. And knowing the Betty numbers of something doesn't tell us everything about the thing, but it does tell us some information. It does tell us some information and is a way to at least partially classify things topologically. Now, so far, clarification, Chad. Yeah, please. Could you tell me how these Betty numbers are related to the Euler characteristic? Oh, the Euler characteristic is the alternating sum of the Betty numbers, where alternating means you alternate pluses and minuses. Yes. So the Euler characteristic is another topological invariant, absolute. Invariant. Absolutely. Yeah. And it's one way of defining it is as the alternating sum of the Betty numbers. Alternating sum, meaning I could put a minus one to the n dn and sum it up. All right. Yep. Yep. Very good. So none of this so far has to do with data. I've been showing you idealized shapes, and I want to bring this around to data because that's how we're going to make a connection to collective motion. So the way we're going to bring in data is by thinking about To bring in data is by thinking about simplicial complexes. This just means complexes of simple pieces. And the simple pieces that we're going to have are points, which are called zero simplices, and edges that may connect pairs of those points. And those are called one simplices. And then we can have two simplices, which are triangles bounded by three edges. And we then fill in the triangle. That's a two-simplex. A three-simplex would be a filled-in tetrahedral. Would be a filled-in tetrahedron with four triangular faces and so on up in dimension. Okay, so this is just an example of a simplicial complex I'm showing you here. It's made up of these zero simplices, the one simplices, and this two simplex. And a typical thing that we might like to ask is, you know, what is the first Betty number, for example, of this simplicial complex? Well, our eye can tell us that it looks like there's one hole in this thing, right? This space right here where my cursor is moving. Right here, where my cursor is moving, that's a void. I'm not going to have time to show you the linear algebra behind this, but the power of algebraic topology is that you can encode a simplicial complex using the languages of matrices and vectors, and you can use linear algebra to calculate the Betty numbers. And so when I learned this, because I had never taken topology in my entire life, when I first learned this stuff a few years back, I had to write out a tutorial for myself. To write out a tutorial for myself to actually show how you can encode this all as linear algebra and how you can use linear algebra to automatically calculate those Betty numbers. And that's really critical because I'm making an argument to you about, you know, having tons of data. And if we have tons of data, we can't look at it and count numbers of holes of different dimensions by hand. We need some mathematical machinery to do it. Algebraic topology is that machinery. And if you're interested in seeing this tutorial, And if you're interested in seeing this tutorial that I wrote that shows the linear algebra, it's, I mean, if you have an undergraduate course in linear algebra, it's enough to understand this. And you can find it on my web page, which I'll point you to later on. And so let me now bring this around to topology and data. And the idea is that we're going to take data from collective motion, and we're going to construct a simplicial complex out of it at every scale. And this is going to be a data. Every scale, and this is going to provide us with a way of summarizing our data, a topological way of summarizing the data. So, here's what I'm thinking: so, we're going to start with what's called a point cloud of data. You can pretend that this is, I think it's 18, 18 bugs that we took a movie of from above. Maybe it's some ants walking on a tabletop. And what you're looking at is one frame of the movie, a fixed frame. Okay, so we have the positions of some organisms. And what we're going to do. And what we're going to do is build a simplicial complex out of that data. And the way we're going to do this is using a particular kind of simplicial complex called the Viatoris-Rips complex. And so what this means is that you put a ball of diameter epsilon around each bug. Okay. And so you're seeing those yellow balls here. The balls themselves are not part of the symplocial complex, but they help us visualize what we need in order to build it. And the way we build it is that whenever there are two balls. Is that whenever there are two balls that pairwise intersect, we connect the bugs, which are the points, the zero simplices, we connect them with a one simplex, okay, whenever two balls pairwise intersect. Whenever three balls all pairwise intersect, we don't just draw the three edges, but we shade in the triangle. So that's now having the one simplices and filling in the two simplex. Whenever there's four balls that all pairwise intersect, we don't just Pairwise intersect, we don't just draw all the edges and we don't just draw all the possible triangles. We then shade in the tetrahedron that's bounded by those triangles as faces. And potentially we go so on up in dimension. And so you might notice that we started with data that itself was two-dimensional. We just had points in the plane, and we're building an object out of it that is potentially higher-dimensional than the data that we started with. And so we now have this collection. And so we now have this collection of 0, 1, and 2, and even 1, 3 simplex here. And then what we would want to do is try to characterize this data by counting the Betty numbers. So I'll do it. Again, I'll do it for you by hand. The zeroth Betty number is four because there's four pieces in this simplicial complex. There's this piece, this piece, this piece, and this piece, four separate pieces. The first Betty number is one because there's one thing that has a one-dimensional boundary. That has a one-dimensional boundary and a void in the middle. It's this loop, this topological loop right here that's empty. And then there's no higher-dimensional Betty numbers. And if you're saying, Chad, what about that tetrahedron over here? You have to remember that Betty numbers count voids. This tetrahedron is filled in. So the point is that there's no two-dimensional spaces that are surrounded by a surface that are in this simplicial complex. And again, linear algebra actually will do this for us automatically. Actually, they will do this for us automatically. There are excellent software packages in R and Python and other things as well, where you can just input your data and you can make the simplicial complex out of the data and out will come your betting numbers. So this is a characterization of this data is to count these betting numbers. And then you might say, but Chad, when you drew those yellow balls, the diameter you chose is completely arbitrary. And if you had chosen a different size, a different diameter, epsilon. A different diameter, epsilon, you would have gotten completely different Betty numbers. And yes, that is exactly the point. So, what we're going to do now is repeat the same exercise, but we're going to do it for every different possible diameter epsilon. And I'm going to summarize the results for you in this bottom part of the diagram that's called a topological barcode. And for now, you can focus just on the top part of this barcode, which is going to tell us something about Betty zero, the number of connected components, and then the horizontal. Connected components. And then the horizontal axis here is this diameter, which I'll call the proximity parameter epsilon. So I've chosen a small value of epsilon, and we have these 18 different connected components. None of them are touching. So you count 18 bars in this upper portion of the barcode. We can increase epsilon. Those balls get bigger, but there's still 18 components, so nothing changes. We make epsilon bigger, and oh, look, two of the balls merged. We drew a one. Two of the balls merged, we drew a one simplex that reduces the number of connected components by one because two things merged. And you see that one of these bars dies now. So now there's only 17 bars. We can make epsilon bigger. Some more connections form. That means we have fewer connected components. So more of these bars die off. We can make epsilon even bigger. At some point, some holes form. So you can see a hole here and a hole here. That's why they're And a hole here. That's why there are two bars down in the first Betty number section of this barcode. If we keep making epsilon bigger, those holes close up. But here, another larger hole has opened up. We have even fewer connected components, and we can keep making epsilon larger and larger until eventually all of the holes have closed up, and there's just a single connected component. All of the points are all connected together. And so I think of this barcode, this entire object, as a top. Entire object as a topological summary of that data. It's across every possible scale. Okay, that's for a picture of static data. And so what we would now like to do is let the data evolve dynamically and track changes over time in its topological signature. So let's go back to sort of thinking about a barcode and maybe just focusing on one of the Betty numbers. You could think about Betty zero. And rather than showing And rather than showing the barcode, you could just keep track of the numbers in a table, right? So let's do that now. This is just, you know, made-up data, but let's pretend that when epsilon is zero, there are six connected components. When epsilon is 0.1, there's four connected components, and so on. And the reason I want to arrange them in a sort of vertical table or a vector like this is that I would like to use this horizontal direction to capture what happens at different times. Capture what happens at different times. So I could let my points move around and I could create this vector at every different moment in time. And I would then have a matrix summary of my data. This is just for Betty Zero. And it would show me at different times and different scales, how many connected components do I have? Sometimes we'll think of this entire matrix as representing the topological signature of the data. Sometimes what we might do is connect. What we might do is connect all of the entries that have the same value. So we're sort of drawing contours. And once we have contours, we can get rid of the numbers. And so here we're thinking of Betty zero as a function of two variables, time and persistence parameter. And I'm showing you the contours of that function of two variables. And this is another way that we'll sort of visualize this topological information. This is called a contour realization of computed k-dimensional. Realization of computed k-dimensional whole evolution in the RIPS complex, or for short, we call it a Crocker plot. Now, these Crockers are just one way to summarize topological information. There's a whole menagerie of different summaries out there, and it's growing all the time. So if you're someone who reads the TDA literature, you'll hear about persistence diagrams and barcodes and landscapes and persistence images and vineyards and who even knows what else. But today I'm going to be working with these crocker plots. With these crocker plots. And so now we finally come to trying to apply this to some collective motion systems. I think I won't say too much about the biology of collective motion. Instead, I'm just going to take you to my first case study for what we can do with this tool. And this is just purely to use topology for pure data exploration. Like we have a bunch of data. How can we wrap our heads around it? And so the topology. And so, the target of this case study is this famous model by Vicek. This is a model of self-aligning particles. So, we have n particles moving around in a periodic box, square box. So, by periodic, I mean that if you scroll off the right-hand side, you come back on the left. If you scroll up the top, you come back through the bottom. And each of these particles is characterized by its direction or its heading, which is the direction the arrow is pointing. And what the Vichik model is. Pointing and what the Vichek model provides is a way for each particle to update its heading. And there's two ingredients in that updating. The first ingredient says each particle looks around in a circle of radius r, and it takes the average of the headings of anyone within that range, right? So that says you want to go in the average direction of your neighbors. And then you add a little bit of noise that's uniformly distributed. That noise is intended to capture the fact that organisms can't. That organisms can't sense their neighbors perfectly. Organisms can't execute movement decisions perfectly, perhaps due to influence from the environment or other limitations. So that's really the crux of the model. The rest of this just says that they all move at a constant speed and they update in sort of discrete time in an Eulerian fashion. So that's this kind of famous and highly cited Vicek model. It can do a lot of different things. These are sort of Do a lot of different things. These are sort of my names for, these aren't official names, I should say, for some of the different behavior you can see. But in some parameter regimes, you might see what looks a little bit like clustering behavior. You might see something that looks like loose alignment, where all of the particles are traveling essentially in one direction. In this picture, it's upwards, but they're doing so in a very noisy manner. And then there's something that looks like polarization, where they all move together almost as a rigid body. Almost as a rigid body. And the main parameters that we think of varying might be the number of particles or the density of particles within the box, also the size of the box, the level of noise, sorry, is the other critical parameter. And so I think if you look in the literature, most often, if you ask, what is my group of Fitchak particles doing, 99% of the time, if not more, their behavior is summarized. Their behavior is summarized with this alignment order parameter. So, what this order parameter says is: take the velocity vectors of all of those particles at any moment in time, add them up. Their velocity vectors either reinforce each other or cancel each other out. You get a resultant vector. You take its magnitude, you normalize it to be a number between zero and one, and that's the alignment. And then you plot a time series of that over the course of your simulation. So, you might see a time series. Simulation. So you might see a time series like this, and you might conclude, like, oh, this started out as a group of not very aligned particles, and it ended up pretty aligned. And this is a really useful tool for describing the global behavior of the system, but I do think it's limited. And so just to show you, here's a group of particles that have alignment one. They're all going in the same direction. Here's a group of particles that have alignment zero because all the velocity vectors cancel each other out. However, to me, this group Out. However, to me, this group is actually very aligned, or more precisely, it's two groups, each of which is perfectly aligned within the group, but they happen to be doing opposite things. And yet, also, here's a group that has global alignment of zero because all of the velocity vectors cancel each other out. However, this case of phi equals zero is very different than this case of phi equals zero. And so, our idea was sort of can topology distinguish between things that this sort of popular That this sort of popular order parameter can't. And so I'm going to show you just some sort of proof of concept results from simulations. I think it's helpful to know what is the initial condition for all the simulations. What we do is we take particles and we distribute them randomly in the spatial domain. So in their X and Y coordinates, which are periodic on that periodic box, and we give them random initial headings. So a random coordinate in X and Y. A random coordinate in x and y and theta is actually three random periodic coordinates because of the periodic boundary conditions. And so, topologically, what we have is data that covers a three torus. And the Betty number sequence of a three torus is one, three, three, one, and then all zeros. That's sort of the initial condition of our data. And then we want to see what happens over time. So I'm just, I'm not even showing you the parameter values, but I'm showing you two different parameter regimes, one that Regimes, one that sort of makes clusters like you're seeing here, and one where the particles all polarize and move as a rigid body. And if you were to just look at the order parameter time series, you might conclude that these are pretty similar simulations, right? Like they both start off with low alignment and they both approach very high alignment as time goes on. But let's see what looking at some Crocker plots can tell us about these simulations. So there's a lot going on. Simulations. So there's a lot going on here. So let's focus just on the left-hand simulation first, and let's focus just on the top plot. This is a Crocker plot of Betty zero. So to remind you, this means it's a contour map in scale on the vertical axis and time on the horizontal axis of the number of connected components. And when we see large regions in this contour plot, like regions between contours, it's telling us that the data have a us that the data have a strong topological signature of having a particular number of connected components. So in this region I outlined for you in orange, the function is equal to two here. That tells us that the data feels too clumpy at this moment in time. Some other moment in time later, the data feels more for clumpy. And so if you look at these contours over time, it's sort of indicating like a periodic forming and breaking up of. Forming and breaking up of groups. If you look at the bottom plot, this is showing you Betty 1. You see sort of a mess for a while, but at a certain time in the simulation, what emerges is a very strong topological signature of one loop, one topological loop. And this data exploration here doesn't tell you what that loop is. You have to go look and figure that out. But this shows you very clearly that something is happening. And we went. That something is happening. And we went, we looked at the data, we realized that what that loop is, is the quote unquote loop that connects this data from top to bottom across the periodic domain. So because it's periodic, if I connect all these points, I then wrap around back up to the top here, that forms topologically a loop. And the fact that there's only one loop means that the loop that had gone across the horizontal direction was lost, and the loop that had gone across the theta direction. That had gone across the theta direction, their headings was lost. And so, this tells us that we've lost coverage of the domain in the horizontal direction. It tells us that we've lost coverage in theta, which means that to some extent the particles have polarized. We see a very different picture over here on the right. So we can look at the bottom plot first. So Betty 1, we have a strong signature of two loops. It turns out that those loops are coverage of the domain in the horizontal and vertical direction. The horizontal and vertical directions. What's more curious to me is looking at this top plot for the number of connected components, the strongest signature is just one connected component. That makes sense. Like this data does not look very clumpy, except that there's this small range of epsilon, which for very long amounts of time gives us a signature or a feeling of two clumps in the data. And we stared at this and stared at this, and we couldn't see two clumps. And then finally, Couldn't see two clumps, and then finally realized: if you watch, I'm going to show you the second clump. It's going to appear in green. That's the second clump. It's a single lone agent that's a little bit further from its nearest neighbor than any other individual is. And the way that happened was through noise, right? It happened through sort of some event where this thing got isolated. But the amount of noise is so low in this system that it continues more or less in the same direction as the others, and it might only And it might only rejoin the group after a very sort of long time rare event sort of thing. So I thought this is sort of cool that the topological analysis found this lone agent that by eye I wouldn't have been able to see. So the main point of all of this so far is simply that sometimes just looking at all of the data is too much. Just looking at a sort of global order parameter might be helpful, but it's a very draconian way. Helpful, but it's a very draconian way of going. And that for me, in terms of doing data exploration, I have found that a topological summary sort of strikes a nice balance between these two extremes. I have a couple of other very brief stories I can tell, but I'm conscious that there's six minutes left. Organizers, should I take a brief question or two? Yeah. Feel free. Feel free. Okay, yeah. Great introduction to the topology commercial. I think I finally started to understand it. I've heard it here and there, but I think you talk made it very clear. So I was wondering what's your take on basically like exploration, but what you need to know what you're looking for. So what are the potential uses of that? Like, do you think that can be some sort of measure to? Be some sort of measure to try to like fine-tune model parameters to match the data? Is there some inquiry there? What are the possible applications now that we can compute it? Yeah, I think, okay, so the sound's not great from that corner of the room, but I think God, I got what else can you do besides explore? And if is that right? Kind of like not just that, but like explore for what? I mean, you explore to ask questions, you compute something. To ask questions, you compute something, what do you do? Yeah, okay. So, let me go on and show you a couple more like focused applications, and maybe that will answer your question. Okay, so in this, what I want to do is, oh yeah, please. Can I just interject a quick technical question? So, can you say a little bit about the computational complexity of this? Because it looks a bit like it's a lot of computing for every frame, or is it not so bad? I mean, as with everything, okay. I mean, as with everything, okay, it depends on how much data you have, but it's even more subtle than that. So, when you feed data into one of these software packages, there's really two things that have to be done. The first thing is the algorithm has to take your data and build it into the simplicial complex. That is a classical problem in computational geometry. And I think people know a lot about the complexity of that and how it scales. And I forget exactly what the complexity is, but it's known. But it's known. I'll just say that I'm working on a nice but not amazing iMac desktop machine. And for hundreds or even thousands of points, like my computer does it just fine, like no waiting. However, then comes the algebraic topology part. Once you have the simplicial complex, you then have to calculate the Betty numbers. The challenge there is that the complexity of that operation doesn't depend on the number of points. It depends on the number of simplicies. The number of simplices of different dimensions. And remember that the number of simplices is completely dependent on the actual configuration of your data. So it's very hard to say how long that topological part of the calculation takes. The answer is it depends. Still, that said, I was able to do all the computations I'm going to show you today on my desktop computer without too much problem. And the algorithms, it's very hard to keep up with software development. Very hard to keep up with software development in this area, which is a good thing. The software is getting better and faster all the time. Yeah. And I'll, at the end of this talk, I'll point you to some resources for people who are interested in like getting hooked up with some of the software. Yeah, great. Okay, so here's a quick thing. This is the idea is to try to use topology for parameter recovery. And so let's go back to thinking about this Vichik model. And we wanted to sort of test this question. To sort of test this question: like, if we just observe data in a simulation, can we back out what the model parameters are? So, in particular, the model parameter we're going to experiment with is the noise in the Vichek model. So, we're going to fix the number of particles. We're going to fix the size of the box. We're going to choose five different levels of the noise parameter and run 100 simulations of this stochastic model for each value of the noise parameter for random initial conditions. We're going to let all the simulations go. We're going to let all the simulations go for t-tips. And then we're going to summarize the data in two different ways. One is with that alignment order parameter. Okay, so remember, that's a scalar measure of the data at each frame of the movie. So that's a vector of information, that alignment order parameter. And then what we're going to do is we're also going to summarize it using topology, either a Crocker matrix of the zeroth Betty number, the first Betty number, or both. Betty number or both using 50 different values of the scale parameter epsilon. And so this goes over time and scale. So this is a matrix of data summarizing our simulation. And you might be saying, like, Chad, that's not a fair comparison. Your topology has much more information in it. And so, as a way to try to make the comparison more fair, what we're going to do is just take all of those summaries and do a principal component. And do a principal component analysis reduction down to three dimensions. Okay, so every simulation is now going to be summarized by three numbers, but it could be three numbers that come from computing alignment or three numbers that come from computing topology. And then what we're going to do is just a little bit of kind of basic machine learning stuff. We're going to calculate a Euclidean distance between those three principal component coordinates, and we're going to do it for every possible pair of our simulations. Pair of our simulations. And we're going to have this sort of distance matrix that colors things in dark if they're far away from each other and near if they're close to each other. And then what we're going to do is we're going to take that distance matrix and use it as input into a k-medoids clustering algorithm. And then we can sort of take the medoid of each resulting group and peek at its label, like peek at the value of the noise parameter associated with it. Parameter associated with it, and then see if the other simulations that were grouped with it have the same value of the noise parameter. And if they do, we're going to count it as a success, right? And so when we do this using a distance matrix that's constructed just based on this alignment metric, we only get about 50% accuracy. But when we do it using topological information, right, whether we use the first Betty number, the zeroth Betty number, or both, we get basically perfect accuracy in recovering the correct value of the noise. In recovering the correct value of the noise parameter. And so the moral of the story there is that we used three numbers to do this machine learning task, but whether the three numbers came from the traditional order parameter or the topological summary mattered. And maybe because of the computational overhead that we were willing to invest in calculating the topology, the topology did a really much better and almost perfect job recovering the value. Almost perfect job recovering the value of the noise parameter. That's one example. And I do want to be respectful of time. So I'll just say that the third task I was going to show you has to do with having a set of experimental data and then having two proposed models for that data and using topological summaries as a metric to decide which of those models is a better description of the experimental data. Description of the experimental data. But I think I should stop for now because I want to make sure we stay on schedule. Yeah, but show us the slide where you were going to point us to resources. Oh, thank you. Thank you. Yes. Okay. So let me share again. Thank you for saying that. I have the memory of whatever animal it is we say has no memory. I can never remember what animal that is. Share. And then that was me looking up that you were at Brandeis. And then. Brandeis, and then let's see if I go back to keynote. Okay, so here we go. So this is the experiment. We come to the end of this. Okay, so I get asked very often, like, if I don't have background in topology, and I should tell you all, by the way, I've never taken topology ever. I have no background in topology. I have no background in topology. So, for people like me who want to get started with this, I get asked very often how to get started. So, I put together what I think is a fairly biased, because it's through my limited experience, a fairly biased webpage of resources. So, if you go to my website and then just slash getting started with TDA, that's going to do the trick. And so, I can show you. You can also go to research on my website and just click getting started. My website, and just click getting started with TDA. And then you're going to see a little narrative for me, but there's a bunch of background articles leading into research articles. I'll in particular call your attention to this article. This is a few years old, but still very useful. It's called A Roadmap for the Computation of Persistent Homology, and it's by Nina Otter and Mason Porter and some other folks. And it was like a really great summary of different computational tools. Of different computational tools in 2017. They have updated, but you will still learn a lot from reading that article. There's also links to a couple of like tutorials for learning how to use the TDA packages in R, because that's where I do my work. So yeah, that's the webpage for anyone who's interested. Yeah. Let's join hands to thank Chad for this wonderful talk. Thanks. Thanks. We have Wild Fujita setting up. One more quick question, maybe from Peter or from the room. Sure. But it's been sufficiently articulated. I had a question. So, the last thing you were talking about with deciding on which model to choose based on this tool. So, is the idea Based on this tool. So, is the idea there that you take your data, you look at this analysis of your data, and then you do your model and you look at the results of the model using the same analysis, and then you compare which one's closer. Is that the basically, yes. And these are stochastic models. So, really, you have one instantiation of your experimental data, and then for each of my models, I'm simulating them a bunch of times, and then I'm calculating distances based on topology, and that gives rise to a distribution of distances, and I'm looking at which distribution. Of distances, and I'm looking at which distribution is closer to zero. That's the whole idea. Okay, nice. Okay, thanks. Yeah, yeah, great question. Very cool talk. Thank you. Excellent. Thank you so much. And now we go for something completely different yet again. Units, virtual units, I believe. I was going to hear from Sachital, if they don't just call it. Sorry about that. So, virtual environments, you have a response to the money today, or please go ahead. Okay, thank you. I'm just gonna check how. Okay, good. Thank you. First of all, thank you to the organizers for inviting me. And thank you, Chad, for that really nice talk. I think I'll start with the berry numbers for kids. But so today I'm going to talk about virtual environments for studying human response to collective behavior. Response to collective behavior. Sorry, I'm not finding the window with the slides. Yes, you have to allow us maybe two minutes to try to fix it. Just sorry about that. The Zoom users have to look for your slides and pick it. Oh, okay. But they are not there yet. No. Awesome. So I think the verse falls are funny. So let's give it a okay. Maybe there's a pause. Chat, you want to maybe tell a few words about the evening session? The evening session? Yeah, yeah, absolutely. So evening session is related to diversity, equity, and inclusion. I think the idea we had in mind was that I was going to say a few things about work I do through my nonprofit organization, which is Institute. Nonprofit organization, which is Institute for the Quantitative Study of Inclusion, Diversity, and Equity. So it's using data science tools to help us understand and remedy issues of DEI. So it's going to say a little bit about some of the research we've done, say a little bit about personal experience with DEI issues and maybe some suggest, you know, I don't know, proposed solutions or success stories, and really just try to have a lot of conversation. Leonard, did I summarize that correctly? Summarize that correctly? Very well said. Okay, excellent. Thanks, now we are ready. Thank you. So, as I said, I'm interested in human response to collective behavior. The way I'm approaching this problem is from an applied perspective. I am a robotics engineer, and I'm also interested in collective behavior. My background is in studying fish scrolls and animal-robot interactions. And so, today, what I'm going to be talking about is. What I'm going to be talking about is two problems. Two problems essentially that motivate the experimental setups essentially that I will be describing today. And the relevance to this particular workshop is that we use agent-based models to design these experimental setups. And so the first problem is to study behavioral contagion. is to study behavioral contagion in human groups. And the idea here, the application here is, for example, things like escapeways are a form of contagion and they lead to a lot of disasters. And so the applications are crowd management and emergency response systems. In 2010, there was an incident in Amsterdam where somebody yelled bomb and there was a crowd of 10,000 people that had sort of experienced a mass sort of escape wave. And so that's the motivating. Shape wave. And so that's the motivating example. I've stopped showing that video. It's not very pleasant to see. So I just sort of describe it in words now. The second problem that I'm going to talk about, at least from the experimental perspective, is the idea of human-swarm robot interaction. And here, the problem is that swarm robotics is a pretty well-established field. And the motivation for using swarms of robots is to cover a large area. is to cover a large area. And then there's another field that has come out of that field, subfield is human-swarm interaction, which is that swarm robots by themselves do not really know how, are not intelligent enough to go from place A to place B. And that's where human component comes. So I'm interested in designing new and better control strategies for human-swam interaction. And so the idea here is that all of these setups require, cannot be our Cannot be either unethical to do in a laboratory or impractical to do in a field swarm of robots. We're talking about hundreds of robots. And so in the first study that I'm going to be describing is with my former graduate student, Elham Dr Jafke, and a professor in the psychology department, Brad Sagrin, where we tried to first ask the question, well, where would we be building these virtual environments? And first of all, are there really sort of a viable All, are there really sort of a viable laboratory platform? And so there's this really popular experiment by a psychologist called Stanley Milgram, who did this experiment on a street in New York where he asked actors to look up as passers, as people passing by, and he looked at the gays' behavior. And so we kind of tried to replicate that experiment in virtual reality. And so I'm going to just start and show the, start by just showing. The start by just showing you the experiment itself. So, there's one participant, and the participant is being asked to move between two cylinders just to familiarize them with the setup. And as you see slowly, so this is a replica of our lab in engineering building. And what you see here is people are sort of walking by. And the key things to note here is that there's a crowd of about 60 virtual characters here with whom this participant is interacting through this VR headset. VR headset, and they're not colliding. The movement is pretty smooth, they're sort of moving past each other. And it's natural enough to become immersive after a few seconds. We take surveys after we expose people to these setups to make sure that they find it realistic or not. So somewhere around, as we sort of keep looking at the setup, you should see something interesting happen. Let me see if there's anything else. Let me see if there's anything else that I want to point out before that event happens. Yeah, so we are tracking the head orientation and gaze direction and everything with respect to the crowd as this is taking place. The participant, by the way, this is so right now some of the characters look up and you see that the participant starts looking up. So they've completely forgotten in some sense that they are in a virtual world. And in some sense, that they are in a virtual world and they're responding in pretty much the same way as you would do in a real world setting. You're curious to see what's going on, and so you see that the participants also sort of keeps looking up. So we track these head orientation, and of course, we want to sort of get this data. So, this is an experiment we did with 60s people, and we want to match this data and see how that compares to the real-world experiment. So they keep looking after some time, and after this, the crowd will disperse and then sort of go back to doing what they do. So, because again, most of the sort of mechanics behind this environment is based on agent-based models, I want to make sure that we sort of describe the sort of under the hood what's going on. So, the first model that we started with for using these, for sort of simulating these people in this. Of simulating these people in this room is a social force model. It's a pretty popular model for anybody who's in pedestrian dynamics. And it was proposed by Helving about two decades ago. And the basic model, it's a dynamic model. Some of the models that we've seen today are kinematic models. So this is four-space model. And each agent is sort of directed towards a goal location, is interacting with other agents and also interacting with the environment, with the boundaries. And the problem with this. And the problem with this model is because it's a distance-based model, behaviors like these, where two people are moving together, are not really sort of evident in this model. People start sort of drifting apart when they're too close to each other, which is not realistic. And so when we put this model in our setup, we saw these problems and we also saw force equilibrium set up. So people just got stuck because a certain arrangement was, all forces were sort of matching up. And so then we went to this new model. So then we went to this new model, which is empirically validated, and this came in 2014. And the nice thing about this model is that everything is pretty similar to the social force model, except the interaction force, which is no longer based on distance, it's now based on time to collision. And this is heavily sort of data-driven model. And in our case, it worked really well, gave us smooth trajectories. However, this model is at the model is at the is requires a really small time step and so this slowed down our so there's an sort of engineering problem that we faced that we couldn't really work have it working all the time so we created a mix of model when people were too close to each other we switched to the social force model and and when people were far from each other they we switched to this model and then there were other aspects that i'm not going to sort of go in detail in terms of how they were avoiding collisions with the boundaries but in general we get that video But in general, we get that video that you see in the end. So, these are the results that we sort of, this is one of the results that we got. I'm sort of kind of keeping it short so that we can look at both the studies. On the top with these black circles is our results. So these are the proportion of people looking up, the probability of a person looking up. And you see it has this quorum-like effect, which Milgram actually sort of discovered in his experiment too long time ago. His experiment two long time ago. And here is another experiment that was done in 2012, which was also done in the sort of a real-world setting. There were many people sort of moving in two directions and people were observing the movement of case. And you can see this does not really have a very threshold-like effect. So the question was, what's going on? And so, one of the explanations that we sort of, and by the way, this model of how you sort of describe this threshold effect was also proposed. Effect was also proposed by Gallup. And even based on the parameters of this model, our data matches more closely to Milgram's experiment than to the one that was done more recently. And the reason, first of all, first thing we see is that we hit a threshold much sooner than even the real world data. And the reason for that is this is virtual reality. People are already, most of the participants that we sort of recruited were seeing this for the first time. We're seeing this for the first time. So they were paying a lot of attention, much more than you would do in a real world setting. And second of all, the virtual reality headsets have 110 degrees. So again, all the distractions go away, which are present in a real-world setting. And so that was another reason we think contributed to this really quick rise to the threshold. The reason why we are so different from this other experiment is because in this experiment, there was In this experiment, there was the crowd of actors in some systems who were looking up were distributed amongst a bigger crowd. So it's very easy to miss those cues, even if they were looking up. In our case, and even in Wilgrim's case, these actors were sort of kind of closer together. So that was a cue that was not hard to miss. So we sort of attribute this to distractions and dilution of the stimulus in some sense. Moving on, the Moving on, the psychologist on our team was interested in this other sort of social proof phenomena where there's a big question in psychology of whether these behaviors are automatic. So you look up just because somebody else looked up, or is it thoughtful? Are you really thinking and is it a decision that you actively take? And so when we looked at, so we did a, we had a survey question where we asked, how did you notice and did you decide not to look up? And we saw that at least for a small group of virtual characters looking up. Group of virtual characters looking up, we see that people did make that decision. So, there is some evidence of social proof here, of thoughtful decision-making here. And then there, we see this pitch, yaw, and both trajectories. Right between those two blue lines is where the stimulus begins. And you can see on the left column represents just one character looking up, and the right column represents 10 characters looking up. 10 characters looking up, and we see a delay. So, that delay again is some kind of evidence that there is some thought going on before we take this decision. So, that was sort of interesting from a psychology perspective. So, I hope I'm doing okay on time. But before I begin my next talk, I mean, if there are any questions, or maybe we can take it yet, whatever works. Any questions? Yes. Did you consider looking at some sort of not just delayed data, but I guess you have data showing when did the characters simulation poked up and when actually register the movement upward. But I wonder, But I wonder, does that separate does that really separate conscious thought versus just action? Because that doesn't include information about when they first notice the group. Oh, so that's a very good. So the point is, are they actually looking up or is it just part of their general behavior? And so for that, what we did was we took all this data and we gave it to independent encoders who were actually encoding. So we wanted to sort of do this automatically. So we said, we know there's a pitch mark. Said, we know there's a pitch motion, and I want to sort of put a threshold to that pitch motion. So we get it to give it to sort of lots of, not lots of like six pairs of students who sort of looked at these videos and said when they think somebody looked up. So there is this human perspective of saying, well, that person is actually checking something out. They're looking up. And that became our threshold for the pitch angle. And that became then the point at which we said, okay, now they're definitely. The point at which we said, okay, now they're definitely looking up versus just sort of moving around sort of because that was also there. Okay, so, um, and then I guess the other part of my question had to do with like a delay, like a conscious realization that something's going on and thinking, oh, I should look up, or is it just automatic and the person observes people looking up and just glances up without a conscious thought? A conscious thought. So it seems like this data doesn't really capture that sort of doesn't distinguish between those cases. It just captures the delay, but doesn't really capture the mechanism. Was there like a survey? Yeah, so yeah, that would be... I mean, yeah, so we kind of approached it using the survey question of sort of asking. But yeah, I don't know whether how you would sort of quantify that conscious decision. Of quantify that conscious decision-making process and whether this delay is because of decision-making or they just didn't see, they took their own time to see. So, that's why this was part of our discussion in the end. This is not, we're not saying that, well, this is a thoughtful, this is still an open question. But yeah, so I don't know how to sort of capture that. Because most of the research in psychology is still sort of based on surveys, so we have to. Still, sort of based on surveys. So, we have to sort of work with that. Yeah, I didn't have a good answer, so I was curious if you guys have more thoughts about that. Is there actually something there when they look up? Say that again? Is there actually something there when they look up? Nothing. There's nothing. You might just ask them afterward what was up there. There's nothing. There's actually so that purposely we have nothing, it's just a corner of the roof. Distinguished better, it was just a few thoughts. Female Spirit was conscious under their senses or looking. So, this was the question. We said, Did you see something, but chose not to look up? So, that was like on our on our part, we were trying to sort of extract that decision making. Yes, eye-tracking data captured that you do eye-tracking. Yes, but I'm not so eye-tracking with a virtual reality headset is very hard because you have eye-tracking glasses and then, but yes, that well, that was. But yes, that well, that will tell you where they're looking, which we kind of have, it will tell us what's going on in the and the glasses and the head. That's coming now. So maybe I missed it, but basic setup. So you have actual human subjects that are in those substances, and also you also have in addition in the same virtual environment agents that basically. Environment agents that basically create this, what's their ratio? And how do is it the same interaction between subject-subject and subject-virtual? How is that? So, one human subject and 60 virtual characters. All of those characters are moving according to a mix of these two motion models. And where are the parameters for those coming from? So, these are tuned to make it look immersive. So, when we start sort of, because this is a design, we are not sort of, we're designing the system, so we're trying. We're designing the system, so we're trying to make sure. So, I mean, I have videos showing sort of bloopers where things don't work. So, we see the social force model where people just come and then stand in front of each other and the characters just stay or the character starts doing funny sort of turns. So, we are tuning the parameters of, well, some of these parameters are already there given by the authors of this paper. For example, tau zero is the time to collision in. Is the time to collision in a particular environment. So we pick that. K is also given, a range is given, so we pick that. But then there are other parameters, sort of game parameters that we tune to make it work. But can you get like 20 students and make them interact and see if their interaction will match your agent's interaction? Well, that's where we went to Wilgrim's paper. So we said, well, that's an experiment already done. But yeah, I mean, that could be. But yeah, I mean, that could be redone in this environment, and we could have checked that too. But we kind of, the human subjects are 60 people signing up is going to take a long time. So I think I'm going to go very quickly on the next part because it's a work in progress, but this is work which is currently being done by my student, Arunibhatacharya. And here, again, as I said, the question is that can we design control strategies? Can we design control strategies for human-swam-robot interaction? And I have, I work with Illinois Indiana Sea Grant on their invasive species, afflated invasive species monitoring project. And part of that goal is to sort of put robots into Great Lakes and use them to sort of monitor invasive species. These are mostly fish, but we're also working on microorganisms. But the focus here is: so if we do put a robot in a large lake, In a large lake. And we have a swarm of robots sort of working with this one robot that's being teleoperated by the human. The human knows how to identify the fish, the human knows probably where to go. And the swarm is good in some other things, maybe counting the number of fish, maybe recognizing or getting a lot of other data that might be useful. So how do you design sort of strategies so that the human is not cognitively overloaded? And at the same time, the swarm and the whole The swarm and the whole mission performance is good. So these are the motivating questions. So, how can a robot swarm best help the human in identification and classification tasks? And some of the other related questions come is like, if I have a swarm of robot coming near me, will I feel being helped or will it actually just distract me? And the second part is now if the robot has to, if the swarms has to communicate. Has to, if the swarms have to communicate with the human, what's the best strategy for them? Is there an expression that the swarm can give to the human and make sure that the human understands it? And bear in mind, we want to make sure that these communications are happening non-verbally. And the motivation for that is already if somebody's doing something and you're pigging them with messages, come here, let's see this place, that place, that's going to cause a lot of cognitive overload. So we want to avoid. Overload. So we want to avoid that. We want to sort of be like a natural swarm, a person in the natural swarm. So they communicate non-verbally, and we want to see how that is possible in our system. And so here again, I'm going to start with a video of our virtual environment that Arulim has designed. And this again is based on agent-based models that we adapted from the literature. These fish are sort of moving with the zonal model that was designed. Zonal model that was designed by proposed by Cousin a long time ago. And you can see there are different kinds of fish. We have five different fish species that are moving shoaling and schooling. We found some fish to do kind of a foraging behavior that was not part of the model. So we sort of added that. And then we, of course, because we are interested in this cognitive aspect of this thing, we track. thing we we track we we capture EEG data and and gaze data so the EEG data helps us quantify the cognitive load and the gaze data helps us quantify what they're looking at because if we want to sort of quantify perception then we want to make sure that that we know what the human is perceiving in terms of collective behavior and and so here what we're trying to sort of quantify is the recognizability of a robot these environment this of a robot this environment this environment is purposely made to look green and turbid to match what we see in underwater videos and and and what's what's being what's shown in numbers here is is basically the retinal eccentricity and the angles of tendon by by each robot and we use that to see if based on empirical literature we use that to find out whether you can recognize a robot or not. So I'm going to stop here. I think I'm going Stop here. I think I'm going way ahead of time. So I'm just going to probably. So we're just going to go really fast. We model the fish behavior using these agent-based models and we used real video data to encode these behaviors so that our five fish, two of them are native, sort of look realistic. Again, this is a visual validation. We would like to do some more, and so we are in contact with conservation biologists who work with these fish. Work with these fish to see if we can sort of get their perspective. And then, and this is just a capability of what's possible right now. So, on the top plot, showing the cognitive load, and we just put a proportional control on the swarm to see if we can really make the swarm respond to human cognitive load. And on the right is the swarm distance, the center of the swarm, and on the left. And on the left is the cognitive load. As the cognitive load goes down, the swarm moves away, and then it comes closer when the cognitive load rises. Is this a good strategy? We don't know. That's something you want to sort of do in experiments. And the bottom plot shows that if you use this model of visual acuity, you most often don't see as many robots as you have in the field of view. And so what does that mean in terms of cohesion, coordination, perception of these? Perception of these by a human. So, thank you for your attention. I'm going to stop here right now, and if there are any questions related to that, any questions are very mean questions here. So, you mentioned how could the logistics computed from you? Hopefully the log is computed from EDT. Yes. That seems like a bit of a hopeless fit in a jump. That's a long story. That is a long story. We've been struggling with that. That's a difficult, it's not a straightforward thing to do. And so we're doing a separate study to make sure that our cognitive normal computation is validated based on other established measures. On other established measures. There are some measures out there using EEG data, and it's based on alpha theta waves. I don't know if you so, and so, but there are multiple measures, so it's hard to pick one. So, that's why we're doing a separate study just to make sure we have a good grounding for that. Okay, well, if questions come up, you can. Uh if questions come up later, you can always uh jump to the Slack and uh and drop it there. For now I guess we'll actually have to do that as uh yeah, that's perfect. Welcome to breakfast outside. There's coffee, there is uh work work, there is uh meds and papers together. Thank you. Can you hear a chord and use it? Can you hear all the notes of the time and things go together? Your problem is how do you attempt and like judge all of those things at the same time? Like return control, you know what I mean? Like, if I heard a chord, I can tell that the top and the bottom note are five in the notes of how you just do a quite simple, like that first question. But it's like even like the idea of just counting. So, so there are two parts, right? So the There are two parts, right? So the person who's teleopathy and the robot has to go and monitor. So yeah, the robots can colour. That's a more less sort of smart thing to do, so they can sort of just do triangulation of robots. It's all sort of. So why didn't we have to do position a robots? So the thing about the position of robots to do the test tests. So I'm telling you not the range of robots. I'm moving around. Telling operating room, when I'm moving around, I'm saying, Well, that's the common car. And the question is: Should I sit here and wait for somebody else to come, or should I come? There are about 20 to 50 fish there, and I want to sort of tag or sort of just monitor them. So I want to sort of give some sort of population that would suspend these are. And so this monitoring mission is just making sure. making sure I am identifying the fish, classifying them correctly, and perhaps getting a sense of how many. And is that because humans are better at species ID and the robots are better at species? Yes, yes, yes. So the idea is to kind of give, and also humans are better at also sort of judging the mission level of robots. So for example, right. So I think what did I think that I was going to say about doing the Would then make join the that are we doing the bat model or the functional thing? I was posting it that modeled the answer that I wasn't gonna get fun call. Otherwise, we won't find it any functional control. Okay, um, so the human control. I'm sorry, I think you gotta go. So, the human is basically good in recognizing stuff, but they're also. Recognizing stuff, but they're also very good in understanding the objective of the mission, or you know, high-level objective. So, you know, let's go there because that's probably better place to look at, or let's go in that direction, which an autonomous robot really has a hard time figuring out. They can be good in sort of avoiding, like I recheck targets, they're good in avoiding collisions, but how do you go from place A to place B? All the higher level task allocation. It's task allocation and that kind of pathway, all that stuff is complicated. Okay, all that stuff is complicated, but I'm trying to ask you: does the human just control one or what are the human controls? They can control a higher level. They can control so yeah, there are many ways to do this. So people can control the swarm at the higher level, people can control one robot, multiple people can control multiple robots in the neighborhood. The particular application we are interested in person is controlling one or more robots in a first person. So they are sort of part. So they are sort of part of the smart. But if you do the whole small, the problem is then your job is just this higher level objective. Like I'm going to move it here and then just kind of trust whatever they collect. I wonder if you could control the same time, but not just say, move your center here. Could you control like how you can control the sound? The only problem, so controlling multiple robots to. So, controlling multiple robots together, right? So, if I'm moving and they're all following me, in that sense, or I'm circling and saying, well, tend to go here. People do that already, but it's still like decentralized. If I could like unfocus to a little extent, that can control all of this game, all of them at the same time. It's going to be complementary hards. Yeah, so this there's a plot that people see in HSI literature where the number of Literature where the number of robots and the cognitive order it sort of starts after about 10 or 20. It's sort of explanation because it's really hard to think about sort of controlling 20 kids, tell them all to go. Yes, maybe that's I don't know the exact number, but this is uh let me see if I can pick up. Yeah, there is a limit to where it scales linear reality or Linear reality are maybe not at least a majority of the colours. So, on the X's, there are a good number of robots, the Y, so as this is. As this is how it scales, so the concept of control complexity in the Greek multiple aspects of all the interactions between them, like or in collisions, is factorial. So, like you add one more, even if they can't think about collisions, even if they can sort of, so this is a paper who did it before some kind of role, somebody has a medium role. People sort of it becomes even if you have like two. Even if you have a take this group of people and just sort of move them, then you're basically just grouping a super distribute them, allocate them, it's just like a system. I wonder if there's like a different way of thinking about that that we have thought about. You know, it's something that is like, I don't know, too much about sound, but like the way, like if I can't see a picture all at the same time, but I can't, but I don't. But I can't, but I don't know. I can't. This form of expression you're saying is. Like, how I can hear sounds at the same time, but I can also hear how they fit together. Like, I can hear a chord all at the same time in a way that I can't see multiple pictures at the same time. See multiple pictures. Like the pots you were showing. With that, it's so challenging visually. I wonder if they think about it differently. Like how sound, because we have frequency that stacks these different channels. What we was talking about, bin numbers, is that. She's talking about big numbers, is that sort of kind of topologically making more sense of what's going on around? I guess by going forward in dimension, I don't know about that. Yeah, yeah, yeah, yeah, yeah. I mean, so there has been the problem is, and you did an experiment with Marites, you know, where we said, well, was it fish perceiving a other virtual fish in and then you saw cohesion or coordination matter or something like that? Yeah, we put the fiction. Yeah, yeah. Put the fiction, yeah, yeah, yeah, the screen and the removal of like this little cardboard cutout. Have you seen some of them as well? He said, oh, it's really science fiction, like somebody controlling the fish here, and the role mod here, and the fish isn't controlled here. That's amazing, but he said we also want like a cocaine beef, all these things out there. Alcohol. So basically, I mean, government works. People don't just go anywhere. I was just, what we did yesterday is Bridget and I just sat here and got all the regular Zoom table and a breakdown. Oh, well, easy to get us in the link that catches all of the current seems fine.             Yeah, that's true. I'm gonna see if there's hard. I keep thinking it might be colder out because of the window. Are you chilly? Yeah, a little bit. There's some slides. I'm going to move back in. Oh, yes. Do you mind if I just think we? Oh, not at all. I'm not going to do whatever you like. Um it's basically a very important thing.  Nobody in the fungal cruise, are you? I mean, the bat. I think I put a head up to the bat. Do you have the have the link yeah i have the link i just thought i'll go there because i had committed myself first to that group no people move around there's not going to be a meeting in this neighborhood sorry uh there is not going to be a main meeting in this okay perfect no i'm just looking for the guy that brought his computer because he he removed his little He removed his little USB thing and then he took mine. Yeah, that's clearly the wrong one. He has it and then I don't know why he doesn't need this one for, but clearly you need to swap. Yeah. Because it doesn't seem probably something. Oh, maybe it's the right one, actually. It does kind of fit. Maybe switch it back. I don't know. Yeah, I think one patch represented in for it. Yeah, yeah, that's what it was. I mean, Yeah, that's what we need to do. Sure. It should be fine, I guess. Yes. Perfect. But there's no meeting here. Do you should I shut down the Zoom meeting at all or I'll leave it just in case you need it. Perfect. I'm sorry, all of that.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     