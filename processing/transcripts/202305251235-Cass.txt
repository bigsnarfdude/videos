Welcome back. So it's a pleasure to have Thomas Kass from Imperial College and he will talk about functions topologies and measures on ambient measuring fast spin. Okay, thank you very much for the introduction. Thank you to the organizers for the invitation, this very nice workshop. It's great to be back in Oaxaca. This is the work that I'm going to present. This is what the work that I'm going to present today is joint work mostly with well, it's spread across two papers, but most of it's concentrated from a recent preprint that I have with my graduate student, Will Turner. And I'll also refer in some of the application sections to a recent paper with Terry Lyons and Xing Cheng Shu. And it's going to be important to distinguish between Xing Cheng Shu and Wei Zhun Shu, who's in the audience, because I'm going to refer to both of their works at various points in the talk. At various points in the talk. Right, okay. So, this is part of a project that we've been working on for a while called the Datasig project. And you can see our motto, if you like, here, or our logo. Probably can't see it, actually, certainly at the back. And it's a rough path between mathematics and data science. So, I'm going to concentrate more on the mathematics side of things. But it's important to be aware, and I'll point this out at various stages during the talk, that a lot of the mathematics here has been prioritized. Of the mathematics here has been prioritized by recent advances in the application of the signature method in data science. But this is certainly a mathematics talk, and my objective here is to convince you that there's interesting mathematics to be done by coming out of trying to understand some of these methods. Okay, so I'll give a quick introduction to the signature. I'm very grateful that. To the signature, I'm very grateful that I'm speaking after Xi's talk yesterday because he's done most of the heavy lifting for me already. Whether that was by accident or by design, I don't know, but I'm grateful to it nonetheless. So this will give rise to an understanding or definition of what I mean by the space of unparameterized paths. So I want to sort of establish that in the first 10 minutes or so. And then as I said, And then, as I said, I'll look only probably very briefly at some motivating examples as to why one would be interested in the question of studying the topologies on the space of these unparameterized parts. And then I'll spend the last third of the talk very quickly proposing a suggested list of candidate topologies and then making some attempt to compare their properties. And then this. Then, this is with a view to how we might use this structure at some point for problems in the future. Okay, so let me just for orientation purposes. The purpose of the signature method, as it's been developed recently, has been to give a description, a summary of sequential data, and a mathematical idealization of that is captured in the concept of a path. That is captured in the concept of a path. So we have an ordered sequence of values over a continuum, and as mathematicians, and particularly stochastic analysts, we're well versed in a variety of methods that we have to study such objects. So here I'm going to be dealing with paths which evolve over some fixed interval 0, 1. For convenience, I'm going to assume that they start at the origin. I'm going to assume some regularity here, and I'll assume that they have finite p variation. Assume that they have finite p variation. P will usually be between one and two in this talk. There are extensions to rough paths and geometric rough paths, at least, but I'm not going to address this point. I'm also going to assume for convenience that V has an inner product defined on it. Okay, so I'm going to maybe introduce the signature in a slightly different way to the way in which she introduced it, and that is as a solution or as a response to this differential equation where the solution. Equation where the solution takes values in the extended tensor algebra. And you can see this is a sort of non-commutative exponential or non-commutative exponentiation. The cross here denotes the tensor product and or the tensor product extended to the extended tensor algebra. And you have a way of realizing this as a collection of iterated integrals. Iterated integrals in the case where the path is smooth enough. But the way of thinking about this object is that it's the solution of this differential equation, which in some sense characterizes the response of a large class of non-linear differential equations to this input path gamma. And the way that it does that is through the sort of Taylor type expansion that she presents. The sort of Taylor type expansion that she presented earlier in the week. Okay, so as I said, what comes out of this is a collection of tensors, and this provides a top-down description of the underlying path gamma. And you see that these tensors increase in dimension as k increases. And so the concept The concept here is that you get a progressively better description of the underlying path as you take, as you observe more and more of these higher-order tensors. And I want to make that precise, and this will lead to the definition of the unparameterized path space in a moment. Okay, so okay, the signature has certain properties, and one of the convenient uses of this definition of the signature as a solution. Definition of the signature as a solution to a differential equation is that it makes the process of proving these properties much easier than if you work with iterated integrals. For one thing, it's parametrization invariant. So if you take a curve gamma, no, sorry, that's wrong. That should be a sigma. So if you take a curve sigma and you reparameterize it, then you don't change the signature. So whatever this signature is recording about the path, it's not recording the speed at which you move along it. The speed at which you move along it. So, and this is quite a useful observation in practice because it means that there are lots of situations in which you don't care about the parameterization. And if you're thinking about this, which I'm not at the moment, but if you're thinking about how this could be a data science context, to learn the fact that the object that you're interested in is insensitive to the parameterization has the potential to consume a vast amount of data. To consume a vast amount of data, it's in some cases much more useful to have a representation of the stream which is automatically in sense of the parametrization. There are further properties, it's continuous, and I'll come back to discuss that perhaps a bit later. One of the very useful properties, both from a calculational point of view and from the point of view of identifying interesting underlying mathematical structure, is the way in which In which the signature interacts with natural binary, a natural binary operation on the space of paths. So, if you take two path segments and you concatenate them together, then you get a new path and you can compute the signature of that path. It's just the tensor product of the respective pieces in the order in which the concatenation was taken. So, what this is telling you is that the range of the signature map is closed under is closed under tensor multiplication. Tensor multiplication. Okay, well, that might generate expectations that the range of the signature map is a group. And in order for that to be the case, then you need to also establish the existence of an inverse. And you can do this using time reversal. Okay, so there we are. But one consequence of this last observation is that trivial power. Trivial paths can still have trivial signatures. So, by trivial signature, I mean that the signature of the path is just equal to, is coincides with the signature of the constant path, which will be everywhere zero apart from the zeroth order element, which will be one. And so, I mean, this then means that you would like to somehow identify the class of paths which have the same signature. Which have the same signature, and you can do this, of course, by introducing an equivalence relation, which you def where you whereby you define that equivalence relation in terms of the equality of signatures. Okay, so you can define an equivalence relation on the space of paths in which two paths are equivalent if they have the same signatures. And it turns out this agrees with a notion of equivalence, the notion of tree-like equivalence, which she also addressed, which is purely. Which is purely defined purely in terms of properties of the paths themselves and has nothing a priori to do with signature. And this is the content of this famous results of Hamley and Lyons in the Annals of Maths in 2010. They proved that this notion of tree-like equivalence, which I'm not defining here, first of all, is an equivalence relation. And then when you look at the set of equivalence classes, Set of equivalence classes, this is for the bounded variation case, then you still have these operations, concatenation and time reversal I described earlier. But now because you're looking at equivalence classes, you have a genuine group. And moreover, you can characterize this tree-like equivalence property as coinciding with the equivalence relation which I defined above through equality of signatures. Quality of signatures. Okay. So here that's just a summary of these results. One property that we'll use as well is that there is a unique element of minimal length, or at least unique up to reparameterization, which we usually call the tree-reduced representative of the equivalence class. It's worth mentioning, and it's an important fact to record, that there's an extension to geometric rough paths. Geometric rough paths. And that was proved by Horatio Xi Terry and Dan Yang a few years after the 2016. Okay, so there are further properties of the signature. You have these analytical estimates that allow you to control the higher order terms. There's this, I think, still open conjecture, but she will correct me if I'm wrong, which allows. Which allows you to, or conjectures that you can recover broad features of the path by looking at the asymptotics of the signature. And so, for example, the existence of this limit is known for a broad class of pencil norms. And it's conjectured that it should coincide with the tree-reduced length, for all bounded, at least for the class of bounded variation paths, for which tree-reduced length makes sense. And I think this has been. And I think this has been established for a certain class of paths, but it's still an open question as to whether it's true for the full class of bounded variation curves. Okay, now an important fact for the later discussion is that there is a canonical algebra of functions which can be defined. Which can be defined on path space. If we take a functional on the extended tensor algebra, so we can identify this with an L co-tensor algebra, then we can apply this linear functional to the signature. And because of the way in which these equivalence classes are defined, this is the well-defined function on the space of unparameterized paths. And essentially, because Essentially, because the terms in the signature can be realized as iterated integrals, we see that if we take the product of pointwise product of two such functions can be re-expressed using this so-called Shuffle product on the cotensor algebra as in terms of another one of these functions. So we can identify another linear functional, which we obtain by taking the shuffle product, and then we can look at. Product, and then we can look at the function space of unparameterized path that's associated with it, and this point-wise product is just equal to that function. Okay, so this is a really important observation for the following reason, is because we can show that this class of functions forms an algebra which contains the constant function and which it's easily shown separates points on the space of unparameterized paths. And so one can hope for. So one can hope for a, and indeed it's true, that the Stone-Weierstrass theorem holds in this second. So as soon as you give me a topology, and here's where the topology makes an entrance for the first time, on the space of path, unparameterized path, then, and there's a compact subspace of these set of paths, then you can uniformly approximate any continuous function on this compact subspace by Elements of this algebra. Okay, so here are a couple of questions. This statement of this result first appeared in 2013. I think it was probably known before then, even though it hadn't been formally written down. But in this and also subsequent appearances of this result, there's never really any explicit statement as to what the topology is here that's being used. And this is kind of an important fact because the topology, of course, will influence, in fact, determine what the In fact, determine what the compact subsets are and what the continuous functions are. So it's important to have an understanding of what an appropriate choice of topologies could be for this space of unparameterized paths and then what the consequences of this choice are in terms of the availability of these objects. Okay, so it's particularly important because this result underpins now quite a large body of work. The first The first instance where this was used, I think, in the context of data science was just in the context of simple regression onto signature features. So you have some response variable, and you have an input, which is now a path, which you're representing through the signature. And you maybe take the truncated signature, and you want to try to do something like a linear regression or a ridge regression, and to try to determine what the relationship is as expressed through these signature features between the response. Expressed through these signature features between the response variable and the explanatory signature variables. But there are more sophisticated perhaps, well, maybe I shouldn't use that pejorative term. There are other reasons why or there are other reasons why you might be interested in these sorts of questions. There's been quite a recent body of work on what are called signature kernels and the signature kernel method, and I'll talk about these. And the signature kernel method, and I'll talk about these in a moment. The other point is that there are instances where, and problems, where it would be useful to have a fully described measure theory on the space of unparameterized parts. And I won't say too much about this now, but this goes back to a still unproved, I think, conjecture in a 2009 paper of Lyons and Levin, where they conjectured that you can. Where they conjectured that you can associate, you can construct a measure on the space of unparameterized parts, which is associated to a high-order differential operator, constant coefficient, in the same way that Wiener measure is associated to one-half Laplacians. And there are problems with doing that, but they provide some evidence that this conjecture might be true. But one of the ingredients that it's missing is a properly described measure theory on this basic. Described measured theory on this base of unparameterized parts. Okay, so maybe I'll just say a few words about this recent innovation of the signature kernel. Oh, here I'm giving examples of functions that we'd like to be continuous. Well, we certainly need these linear functionals also to be continuous if we want to apply the result I just quoted. But we would also like for at least a large class of these canonical models for Canonical models for the relationship between an input, which has now changed its name from gamma to x, but x is what was previously gamma. So somehow we'd like these the evaluation of the solution of these control differential equations to be continuous in whatever topology we select. And there are other examples as well. Okay. Okay. So signature kernels, what are these all about? Well, they come about from an attempt, successful attempt, to extend classical kernel methods, and I'll say briefly what these are, to deal with sequential data. So quite an important theme of the work that's been done on the Datasig project is how many of the Project is how many of the tools that are used for vector data can be extended to deal with sequential data through the signature using the proper by exploiting the properties of the signature which I've described. So in this setup, typically one has a reproducing kernel Hilbert space. And in this context, I'm going to mean by that a Hilbert space which consists of functions defined on the set X for which pointwise evaluation makes sense and for which the pointwise evaluations are bounded linear functionals. Of bounded linear functionals. And it's well known that this gives rise to a reproducing kernel, which is characterized through this property here. And also the converse state is true. So if you start off with a reproducing kernel, which is positive and semi-definite and satisfies some conditions, then there is a reproducing kernel Hilbert space associated to it, for which this is the given kernel is the reproducing kernel. kernel is the reproducing kernel. Okay, so you can try to transport these ideas now into the setting where x, the space on which the functions are defined, is the space of unparameterized parts. And that's essentially what this is all about. Maybe I won't go through the construction here. The advantage of doing this, incidentally, in applications can typically be seen in problems where you want to do binary classification. To do binary classification. So typically you have vector-valued data, and the data are of one of two types. And what you want to do is try to separate the data, linearly separate the data. That may not be possible in a low-dimensional space, but if you map the data to a high-dimensional space, then you might have some chance of being able to do it. And this is essentially designed to do the same sort of thing where the data that you're working with are not vectors, but sequences. Not vectors but sequences of paths. So, in this case, we're using the signature as a feature map. And the crucial thing, you might say that that's not a very clever thing to do in one sense, because it means that you have to work in higher dimensions. But it turns out that often for these problems, you don't actually need to record what the image of these vectors are under this feature map. All you need to be able to do is compute some appropriate. Able to do is compute some appropriate inner product. If you can do that, then you can usually solve the problem you're interested in. So the computation of these, so here I'm defining the signature kernel as just being the inner product. So this is going to be the kernel in this setting. The inner product of the signature of a path gamma and a path sigma. Gamma and a path sigma. And as I said before, yeah. For that, yes, I'm implicitly fixing a roughness. I'm implicitly fixing a roughness. But yes, yeah, yeah. Okay, so as I say, maybe I won't spend too long going over this, but these things are computable. And one of the things that we can do is, I And one of the surprising observations is, at least for smooth paths or paths of bounded variation, let's say C1 paths for the moment, there is a, okay, there are a variety of different choices for reproducing kernel-Hilbert space in this case. But in the canonical choice, so where these coefficients just coincide are just equal to one for every k, then there is a PDE associated, a second-order height. Associated, a second-order hyperbolic PDE associated with this signature kernel. And you can use PDE solvers and actually practically implement this and determine values for what these inner products are. Interesting connection, which I probably don't have time to discuss, is the connection between these so-called weighted signature kernels and this idea of hyperbolic development, which also featured integrally in Xi's talk. Into Glee and Xi's talk. This is an example of a function on unparameterized path space. You can express it using the Fawcett-Victois formula for the expected signature of Brownian motion in terms of the hyperbolic development of this path, gamma. So here you have an explicit representation for For the realization of one of these inner products in terms of essentially a solution to an ordinary differential equation or controlled differential equation. And this simplifies further in the case where gamma is a piecewise linear, because this ODE essentially is solvable as a product of matrices. Okay, so let me just say that the topologies also impinge on the discussion here. Pinge on the discussion here because one would like to know, answer questions about these kernels, such as whether the reproducing kernel Hilbert spaces have this universality property, which means that they're dense in the space of continuous functions on compact sets. And also the characteristicness. So whether the, I maybe won't go into this in too much detail, but it was an important source of motivation for the problems that we're studying here. Okay, how much time do I have? Okay, how much time do I have? Seven minutes. Okay, fine. Then I'll be quick. So there's some justification. So here we propose three candidate topologies and we want to analyze their properties. So a very natural approach would simply be to try to topologize the range of the signature map. So you know that the signature So, you know that the signature, the range of the signature map, is this group, which I described earlier. It sits inside the extended tensor algebra. You can certainly put a topology on the extended tensor algebra in lots of different ways, and then you can just say that S, script S, will inherit the subspace topology and then transfer it back by insisting that S is an embedding. We know that this is injective by the way in which the spaces have been defined. Okay, and that's a perfectly sensible thing to do. And so, the topology that we're going to take here is the We're going to take here is the subspace topology of the product topology on an extended tensor algebra. So, this is going to be the weakest topology with respect to which all of the projections are continuous. And this, I think, is what we need at minimum in order to ensure that the linear functionals, these functions in the algebra that I described earlier, are themselves continuous functions. Okay. Well, one might start at the other end and say, well, we already have. We already have a topology on the space of continuous paths of bounded variation that we inherit from the one variation norm. Cancel. And so we can use the quotient topology. So remember that this means that if pi denotes the canonical map, which identifies an element of path space with its equivalence class, then openness of a Then openness of a subset in C in the unparameterized path space is characterized by the pre-image being open, the pre-image of this set under pi being open in classical path space. Okay, so this has certain advantages. It will make it easier to identify continuous functions because, you know, by definition, almost by definition of the quotient topology, any function which is invariant on the equivalence classes and is already continuous with respect to the And it is already continuous with respect to the original topology, will still be continuous in the quotient topology. But it has certain shortcomings. I mean, in particular, quotient topologies can be quite degenerate in their reluctance to respect separation axioms in topology. So in particular, if you start off with a Hausdorff space, it needn't be Hausdorff once you consider the quotient topology. It is in this case, but other properties like that I may or may not discuss depending on how much time. May or may not discuss, depending on how much time I have, fail to hold and implical in the trizability is fails in this case. And really, just for the sake of variety, we also use the introduce this metric topology, so where we define the distance between two equivalence classes by looking at the one variation distance of the tree reduced representatives parameterized at constant speed. Okay, I'm probably not going to go too much into the proof because I don't have any time left at all, but maybe I'll summarize. Left at all, but maybe I'll summarize the results very quickly. So, what we're able to prove is: so, you might ask whether these topologies are all the same, and in fact, they're not, but they're ordered. So, here the chi here denotes the open sets within each of the topologies. The product topology is strictly weaker than the quotient topology, which is strictly weaker than the topology associated with this metric, which I defined. This metric, which I defined. I won't go into the proof. Proof is quite nice, and it does the proof of the strict inclusion relies on this construction of three reduced paths in the paper of Terry and Weijun, which are designed in such a way that all of the terms in the signature up to a certain level is a zero. Well, I don't have time to go into the details of the process. Don't have time to go into the details of the proof. So let me skip to some consequences. So, all three topologies you can show are separable and Hausdorff. That's reassuring to some extent. You can also show that the product topology is a topological group. This is not the case for the metric topology, which we defined. If your interest is to do probability on this space, and I mentioned one problem earlier, which would make Problem earlier, which would make this sort of understanding necessary, then it's definitely of interest to be able to have a Polish space, because Polish space, on Polish spaces, we have exact criterion tightness, which will guarantee that a class of probability measures is pre-compact. Unfortunately, this isn't true for any of the topologies that I defined and won't be true for any sensible topology that you work with on unparameterized path space. With on unparameterized path space. It is nevertheless the case that the product topology is a losing space, and one of the directions of Prohorov's theorem, the sufficiency of tightness for pre-compactness, does still hold in this method. So that's useful. I've listed here, but I don't have time to go into the importance of them at all, two separation axioms from topology, which Topology, which somehow are relevant if you want to properly understand the quotient topology. Okay, so I think I won't get to the end. Let me just summarize this result, which I think is one of the main results of the paper. The product topology we show is not completely metrizable, although it is a losing space. The quotient topology is not even metrizable. And what provoked us to first look at this Provoked us to first look at this problem actually was reading a paper where it was observed that the quotient topology was metrizable. So, this is a surprising conclusion. The metric D is not complete, although of course that doesn't exclude the possibility that there is a metric which induces it on the same space, which induces the same topology, which is complete. I won't go into the proof because I don't have time. But certainly the most difficult aspect of this for us to prove, and there are lots of questions here that we still don't understand or have the answer to, was to prove the non-metrizability of the quotient topology. And the way in which we do this is by showing that it can't simultaneously be first countable and satisfy this regularity property. And there are well-established results in general topology that tell you that any matrizable space has to. Tell you that any metrizable space has to satisfy both of these properties. We show that it can't satisfy both simultaneously, but we don't know whether which of them fails or whether both fail. It would be interesting to know the answer to that question. Okay, so I've run out of time. I'm going to stop there. And these are the references. Thank you for your attention. Thank you very much. Are there any questions? I'm pretty sure you are aware of too good to ask this stuff. So there is another quite magical topology of this many advice. If you pick two paths and you define their distance, so let's say you have two paths X and Y. And you take the inverse and. And you take the inverse and take the product. Yeah. So under this metric, actually your space of unparametrized parts becomes a real issue. So at some time we can. Yeah, we would. I think that's a topology that we would also like to consider, right? Yeah. But we haven't done so yet. Maybe related to that question. There are some works where they have some banner spaces and then they try to create some sort of reproducing kernel to the banached space without having an inner product. So maybe... Yeah, that I think is in general a good idea. You don't actually really need the Hilbert space. You just need a pair of maps, one of which you need a mapping into the Banach space and into its dual space. Into the Banach space and into its dual space, essentially. So that approach might calculate this for this direction. Yeah, I think it would be an interesting question to consider. So in this place, that's a sick. Data sick. SIG is for signature function. It is, yes. Okay, so the question is, in that group, do you come across with the problems that you use these models of non-parametric? These models of non-variant transformations, yeah, absolutely, absolutely. Yeah, so we're working with. I mean, I haven't talked about it here because I just don't focus on the mathematics, but we work with collaborators across a range of domain areas. So one of the most advanced areas is in human-computer interaction. So Chinese handwriting recognition was the first area where signature features were used to, you know, in conjunction with machine learning methods. With machine learning methods, convolutional neural networks, and so on. But that's a very active area where we have some people working on that. One non-parametrized part, well, so in this case, the I mean, it's in the context of a Chinese character on a tablet screen. So if somebody's drawing a path, which is the path in this case, is going to be the evolving character as it's being drawn by the human. By the human. But so that's an example of, but you see, a path is a mathematical idealization, but there are lots of real-world examples. We also have an active collaboration with radio astronomers in Cambridge. So that's another example of a stream, which is very different from the other examples. Thank you. Yeah, thank you very much. Yeah, maybe you could. There is an inner product appearing in Kajan. Is that inner product that appeared in conjunction with the Gilbert space that you were talking about? I want to elaborate a little bit on what that inner product is. Yes. So if you remember that the signature, I'll perhaps go back to the slide because it will make it easier to describe. So Where's the relevant line? So, here, yeah, so here you remember that the signature takes values in this extended tensor algebra. Okay. So, you can define a Hilbert subspace of the extended tensor algebra. And the most obvious way to do that is through this inner product here. So, if you just assume that all of these phi's are equal to one for the moment. Equal to one for the moment. Then this inner product here is the realization of an inner product on the extended tensor algebra applied to two signatures of two paths. Okay, and it's the inner product that you obtain just by taking on Vk, so the k-th order tensor product, the Hilbert-Schmidt inner product, essentially. So the canonical inner product on VK. Product on Vk that you obtain from the inner product on the underlying space V. Okay, and then you can just take the sum of all of these things, and then you can identify a subspace of the extended tensor algebra for which the norm is finite and that gives you a Hilbert space. Okay, but there are lots of different ways in which you can choose that Hilbert space, particularly. Yes, yeah, that makes sense. So then you choose this weighting piece. Then that you choose this weighting somehow? Is that one of the inputs to define it? Different choices of phi will give rise to different inner products. And the point of this example, although I didn't say it in the talk, is to illustrate that in terms of the functions that they contain, the reproducing kernel-Hilbert spaces will change depending on the choice of phi. So this actually, this example of the hyperbolic development is a concrete example of Is a concrete example of a function which belongs to the reproducing kernel-Hilbert space associated to one of these phi inner products, where the choice of phi is k over two factorial, but does not belong to the reproducing kernel-Hilbert space of the what's called the ordinary signature kernel, where all of the phi's are equal to one. Now, I mean, in practice, this doesn't matter very much because all of these reproduced and kernel Hilbert spaces satisfy this universality property. So they're reproducing. Universality property. So they're reproducing kernel Hilbert spaces are still dense in uniform topology on the space of continuous parts. But nonetheless, it's somehow, yeah, they're different. And the choice of phi will influence this. Okay, so now we can thank all the details in the morning and then 