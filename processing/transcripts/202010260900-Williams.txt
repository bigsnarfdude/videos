Your question might get answered right in the chat, or if it's important to forward it to the speaker now, somebody will do so. Our first talk, Jim, don't forget to, oh, you started the recording. Who's starting the recording, the other recording? I did. You did, great. Okay, so our first talk is by Nathan Williams. It will be on independent post-sets. All right. Thank you very much. Thank you for the introduction. All right, thank you very much. Thank you for the introduction, Tom. Right, so this is joint work with Hugh Thomas. He presented a poster on it at both FibSec and last Friday. And the talk is being recorded. And there's the dates. Wonderful. Okay, so in this difficult time to reach our students, we have all sorts of options, all sorts of services that we can use. And so it's helpful sometimes to make like a pro-con table of the different services that you might be able to use. So here they are. So here they are: the services that I'm going to be looking at. I've got Microsoft Teams, I've got Zoom, Google Meet, and then, of course, my favorite way to contact my students, the US Postal Service. And then, of course, you want to keep track of different things. So, for example, maybe there's only a paid version, or maybe there's a free version, or does it offer breakout rooms? Doesn't it offer breakout rooms? What about live captioning? Video? Does it have video support? And of course, import. Support and, of course, importantly, has it been involved in antitrust legislation? Right, so for example, MS Teams has a free version. It does offer breakout rooms. It has live captioning. Okay, so you need to be, yeah, this requires a lot of data to capture. It offers video support, and Microsoft famously has been involved in antitrust legislation, an antitrust suit. Good. Okay, what about Zoom? Zoom also has a free. I think that's what we're using right now. Zoom also has a free thing. That's what we're using right now. It offers breakout rooms. It does not have live captioning. Maybe it hasn't captured enough data yet, but I assume it's recording what we're saying right now in an attempt to figure out how to do that. It does offer video. Hello, I see you. It has not been involved in an antitrust suit. It's a relatively new company. Google Meet, again, free. I believe it does not offer breakout rooms, although it's possible that that's a new feature. It does offer live captioning. Live captioning. It has video, and Google, of course, is involved in an antitrust suit at the moment, I believe. And finally, the US Postal Service, so my personal favorite here, and that is you do have to pay to send the mail, does not have breakout rooms or live captioning, does not offer video support. And perhaps hilariously, it has been involved in an antitrust suit. This happened when they changed. This happened when they changed the standard for mail-sack weave from circular weave to flat weave, or maybe it was the other way around. I can't remember. This was in 2003. Okay, so here we go. We've got this list. And what can we do with it? So let's just keep track. So this is the same list as before. So I've got these objects, I've got these properties, and in general, I can take an object and I could send it to its properties. So for example, the U.S. Postal Service is paid only and has been involved in an antitrust suit. And conversely, I can. And conversely, I can take a property, say video support, and return the objects with that property. So video support would return Microsoft Teams, Zoom, and Google Meets. Okay, so far so good. And let's keep moving. Right. So this brings us to Wheelie's formal concept analysis. And the idea now is that rather than just take a single object to its properties, we'll take a subset of objects to their shared properties. And we'll take subsets of Shared properties. And we'll take subsets of properties to all of the objects that have all of those properties. So let me give you an example here. If we were to look at the objects Microsoft Teams and Google Meet, let me see if I can just mark. So I'm looking at Microsoft Teams here and Google Meet here. Then what they share is live captioning, video, and antitrust, those columns. Everyone following? And conversely, let's see. Well, okay. And conversely, Okay, and conversely, if I were to look at live captioning video and antitrust, then that actually, the objects, the services that have those three things are Microsoft Teams and Google Meet. And that's interesting because I've got this pair where the objects had these shared properties and the properties had those common objects. So there's something interesting that happened. Like, for example, it is true that Google Meet has live captioning, video, and antitrust. Those are the only things it has, but that's not the intersection of all the objects with. But that's not the intersection of all the objects with those properties. That would have to include also the Microsoft Teams. Is everyone following this? Is this making sense? Okay. Cool. And so in particular, this is somehow capturing an idea. It's capturing the idea of like a big corporation video conferencing software, right? So those three things together are somehow capturing that. Actually, there's something a little bit interesting, which is that the live captioning is redundant. I guess the idea is that if you were involved in an antitrust suit and you offer Suit, and you offer the video, then you're already a big corporation. And so you probably have enough data to offer live captioning, right? So if I were to look at the column of live captioning here, if I were to look at this column, then what's happening is it has, so which objects have it? It's Microsoft Teams and Google Meet, but that's actually captured by the objects that have video and antitrust suits. Okay, so it's redundant, actually, the live captioning. And this gives us, so this is, in general, we have a concept. And this gives us, so this is in general, we have a concept, right? The concept then is going to be this pair of objects and properties, where the subset of objects, so it's a collection of objects. And so, what I want, so let's call this subset of objects X and the subset of properties Y, and I want the shared properties of the objects X to be Y, and I want the common objects of the properties Y to be the objects X. Okay, so we can make the graph. So, let me just show you here. So, this is called the poset of concepts. And what I'm gonna do is I'm just gonna order. And what I'm going to do is, I'm just going to order by, say, inclusion of objects, or equivalently, by reverse inclusion of properties. So, one nice way to do this is, so for example, here, if I look at the object A, so you can see that A is connect, A, A has properties two, so I've dropped the story that I was telling before. That's the end of the story. So, A has properties two, three, four, and five. So, I'm just trying to visualize this on a sort of direct This is on a sort of direct on a, well, if you like a bipartite graph. And then B has properties 2 and 4. And C has properties, what is it? 3. Oh, wait, what did I do? Oh, yeah. Sorry, C. Good. C has properties 3, 4, and 5, 3, 4, and 5. And D has properties 1, that's why I put 1 all the way over there, and 5. So this is how I'm encoding the table here that we did originally with this nice little... With this nice little bipartisan graph. And now, what I can do is I can keep track of the concepts that come out of this. Okay, so these are these pairs, x and y, with y being the common properties of x and x being the common objects of y. And so, for example, the example that we just did, this big corporation video conferencing software sits right here in this post set of concepts. Okay, wonderful. And these are all of the concepts. And these are all of the concepts. Okay, good. So I drew them all for you. Okay, and so in particular, what we've done is we've taken this some sort of bipartite graph, and from it, we've constructed a poset. And the first theorem of formal concept analysis is that this is actually a lattice, and every lattice arises as a positive concepts. So I should probably tell you what a lattice is. Tell you what a lattice is. Are there any questions right now? Is this making sense? Okay. So let's talk about lattices. So here we go. I'll start out with this very nice quote by Rhoda. I won't read the whole thing, but just to get to the big vocabulary words. So never in the history of mathematics is a mathematical theory been the object of such vociferous vituperation as lattice theory. So you should go look up what vituperation means. And indeed, it has all of these. It has all of these prominent authors from algebra and so on, including, of course, Garrett Birkhoff and whatever. So, a vision that has been cursed by a conjunction of misunderstandings, resentment, and raw prejudice. So, Rhoda really knew how to write a sentence. It's beautiful. And this is in his many lives of lattice theory. Yeah, so actually, I have it on authority that in the United States, you are only legally allowed to practice lattice theory in the States. Allowed to practice lattice theory in the state of Hawaii for a while. Okay, so here we go. So, a lattice, right, it has a meet and a join, or a join and a meet, so least upper bounds and greatest lower bounds, and you have all the property, you know, all the examples. And let me just say that there were, you know, there were, people thought that this was going places. So, for example, Garrett Verkhoff describes it as the younger sister of group theory. And in fact, originally, I think it was Dedekind. Originally, I think it was Dedekind, he called lattice theory, he called lattices dual groupen, like the dual of groups. This was supposed to be a giant algebraic theory. And then maybe I'll just draw your attention. So Berkhoff is saying that he does think that lattice theory is going to achieve the comparable status to group theory. So this is Garrett Berkhoff in his second edition of Lattice Theory. This paragraph, I did not find it in the third edition. Find it in the third edition, which was published later. Yeah, so, and I should say that lattices have made a pretty huge comeback in combinatorics. I mean, so for example, if you're interested in Garside theory or representation theory, it came up all the time in work of Reading and Hugh Thomas with cluster algebras. And so there's all sorts of stuff. And so it really is making a comeback, I'd say. But you can see from But you can see from Rhoda's original comment that maybe things were a little bit tough for a while. Okay, so I need a couple notions. In fact, this is all I'm really going to use from lattice theory. And that's the notion of join irreducible, which basically means that I can't be written as the join of elements that are not myself, and meet irreducible if I can't be written as the meat of objects that are not myself. And so let me go ahead and label the join and mete irreducibles, and let me do this in some sort of consistent. And let me do this in some sort of consistent way. So, if you recall, so this picture right here, this is our bipartite graph that was encoding our concept lattice, right? And now, if I just start with the lattice, I can start labeling, say, the join irreducibles. So, let me label them like this. So, what does it mean to be join irreducible? Well, in this case, I can just look for things that have a single edge pointing out. At the bottom, so let me label A and then So let me label A, and then maybe I'll do this one B and C, and this one will be D. So you can see there's only a single edge pointing out, so I can't be written as the joint of two things. And then a meat irreducible guy is going to be one where I have a single edge coming out. I can't be written as the meat of two or more people. And so let me label them with the numbers one, well, one through five, but there's a redundancy. So let me do one that has a single edge coming up, and two, and well. And well, so I'll put a pin in right here for a second, and then four and five, okay? And remember that there was that redundancy in our original thing: the idea that if you offered a live transcription service, then it was already included in the fact that you were offering video and you were involved in antitrust suits because you were big enough to have collected enough data to be able to offer these live transcriptions. Transcriptions. And so, but let me put a three here, but this is redundant. It doesn't really hurt me to add it, but I'm not actually getting any new information. So, let me label that by a three, but it's not really a meat irreducible. Okay? Is that all right? Okay. And now what I can do is I can go ahead and fill this in. So let me keep track of the blue numbers that are less than the yellow numbers. So for example, A is less than, well, it looks like 2. Looks like two, three, four, and five, but not one, yes? So A is less than two, three, four, and five. And B is going to be less than two and four. Can you see this? Does this make sense? Yeah? Okay. So B is less than two and four. And what you should be seeing is that I'm reproducing this graph here. And then C is going to be less than, so I'm looking at the picture here. C is less than, the blue C is less than the three, the four, and the five. Blue C is less than the three, the four, and the five, yeah? So the three, the four, and the five, and then D is less than the one and the five. And I've reproduced the picture. So somehow I was able to recover my original bipartite graph from this structure here, as long as up to the labeling of the various join and meter reducibles, and also up to this strange redundancy here, which is fine. Okay, good. So, uh so um and now how do i how do i find my representation what were these um what were these concepts well the idea now is let's look at our original concept of these of this giant corporation video conferencing software what i should do is i should keep track of the meat irreducibles that are bigger than it so that would be the four uh and the five and and three here i guess um i guess uh alex asked if every note is labeled except for the top and bottom no i'm labeling just the join and meet irreducibles and i'm also labeling And meet irreducibles, and I've also labeled a redundant one just for fun because it doesn't hurt me. I'm just encoding more information. Okay, so I'm encoding that extra information of offering a transcript, which you had to do if you were involved in antitrust legislation and offering video services, because you were already a huge company and you've collected that data. Okay, so three, four, and five are above my original element X, and then below it are the joint irreducibles A and C. So D is not below it, and that's how I've written down this and. How I've written down this and this. Okay, good. And of course, I could keep track of it on here. So three, four, and five, and A and C, A and C. Like so. Okay, and so this is now the statement is that for every element in my lattice, I can represent it as this subset of the meter reducibles that are above it and the joint reducibles that are below it. And from the lattice, I can recover my original bipartite graph. Bipartite graph, and so on. Okay, so that's the theorem, and that's how this formal concept analysis sort of thing is working. So, it's a beautiful story, and it really applies. It's some sort of representation theorem for any lattice, okay? And I could add in extra, extra, extra information as long as I keep track of the joining media reducibles, that's good, and then I can have more. Okay, and so a few historical notes. So, this was Rudolph Willey's brilliant restructuring of Brilliant restructuring or rebranding of lattice theory. And so formal concept analysis is like a major thing. His paper has well over 3,000 citations. It's a great idea. And this idea of this bipartite graph encoding the joint meteor reducibles has actually occurred earlier in work of George Markowski, who was a student of Birkhoff. And I think I saw that Curtis Green. I think I saw that Curtis Green is in attendance, has a paper with Curtis Green. So I'm very curious to talk to Curtis about that. And good. And then maybe this idea first appeared in work of Marc Barvu as well, as you can see it there. And I guess the thing to say about Barvu, he and I realized maybe a couple of months ago that he's married to, or was married to the Comte de Poulie Barvoux, who Comte de Purie Barbu, who worked on Lattice theory of, say, like weak order for Coxider groups. So, again, we had previously known of her work, but then we realized that he's worked on this even before. So, that was in 1965. So, these ideas existed before. Hugh also points out that Suchin Brüze, Marcel Poor Such-Bruzet, had similar ideas where he was using this sort of redundancy, right? So, the fact that I had labeled, you know, this is very annoying, but I had. You know, this is very annoying, but I had labeled this three here. That was extra information. If I sort of add in all the extra information of just all the elements that are above and all the elements that are below, then I get a representation also. And that, I think, was MT's idea. Okay, cool. So there we go. Historical notes. Wonderful. And that brings us to Markowski's extremal lattices. So the idea is how compact a representation theorem can we have? And again, so I'm thinking of this. And again, so I'm thinking of this script J, the joint irreducibles that's supposed to be my objects. The script M there is supposed to be the properties of the objects. And so there's that play between them, some sort of Gawa connection. And then, and the claim is that we're going to have really compact representation theorems when the number of joint irreducibles is equal to the number of meet irreducibles, and that's also the length of the longest chain in the lattice. And there's a reason for this, which we'll get to. Okay, so let's take a look. So, in our original example, this is just the same example that we started out with. There were two. out with. There were too many properties. In fact, the three was redundant, but that's not what I'm going to get rid of. What I'm actually going to get rid of here is the fifth property, which I guess was the antitrust legislation. I guess if I'm trying to teach a class, I don't really care if the company was involved. I just want the best service that I can have. So let me get rid of the antitrust column there. And now something interesting has happened. So in terms of the, so I've eliminated that column, and what that does in terms of Column, and what that does in terms of the bipartite graph is I just remove the five from everything. And so that possibly could cause collapses or deletions. In this case, what happens is it just removes a single element. It removes this element right here. So you can keep track of that. But the idea is that how could I have a collapse? Well, you can check. You can check that there are no collapses, I guess is what I want to say about that. Or maybe you want to say something else about that. I don't know. And now it's sort of becoming. I don't know. And now it sort of becomes, so that's what an extremal lattice is. It's, oh, yeah, an extremal lattice is when I have the same number now of joint irreducibles as media reducibles as the length. And so let's study that in a little more detail. So yeah, here. So for example, now it becomes clear why I kept track of that redundant three. Okay, because now three, by eliminating this element here, now it becomes a meat irreducible. So I need that information now. And good. And now I have the same number of join and meet irreducibles. And I need to explain to you why that's important and why that's related to the length of the maximal chain. Why do I have this condition? So let me write down, let me just choose a maximal chain here. So I'm going to choose this maximal chain. Okay. And I'm going to use this maximal chain now to pair up, to find a bijection between my joint. Up to find a bijection between my join and my meet irreducible elements. And the way we do it is as follows. Okay, so if I imagine starting out here, I can start joining, I can find a join irreducible that I have to join with to get to the next element in my chain. And in this case, it's an A. I have to join with A. Yeah? Does that make sense? To move up along that chain. And if I want to move, okay, good. And if I want to move now from this element, from this element here to this element here. From this element here to this element here, now I need to join with B, the joiner reducible B. Everyone following? And in this way, I'm going to get a labeling of every edge in my chain. So to go from here to here, I need to join with the joint irreducible C. And then finally, to get all the way up to the top of my lattice, I need to join with the joint irreducible D. So far, so good? Okay, so that gives me a labeling of the edges of this max. A labeling of the edges of this maximal length path, which is equal to the length of which is equal to the number of joint irreducibles by the joint irreducibles. Okay, now we're going to do the same thing, but we're going to work our way down using meat irreducibles. So now, starting at the top here, let me go ahead and see, well, what meet irreducible do I have to meet with in order to get to the next element in the chain? Okay, so I have to meet with the fourth, the four. Yeah? This making sense? sense? Yes? Okay. And then from the four to get to the to get to get to this element right here, I have to meet with two and then to go from to the next step it looks like I meet with three, the yellow three, and then finally the yellow one takes me all the way down to the bottom of my post-it. So I get this pairing. Does that make sense? Is everyone following that? Does that make sense? Is everyone following that? Okay, so I started out and I just had this, I had this lattice, but now because the length of the longest chain is equal to the number of joint interdiswavents, is equal to the number of meter resolvents, I get to pair them up. Okay, and that's important because it's going to give us a more compact representation theorem. So the idea is, so I can pair up my join and meet irreducibles using this chain. And now let's see what happens to that bipartisan graph that we started with, okay? Graph that we started with. So I'm starting right here. This is the original bipartite graph, and I've drawn some collection, one of these concepts on it. So in particular, the blues have to point, I've directed it so that the blues are pointing to the yellows. Okay, I've just kept track of the direction. And now what I'm going to do is I'm going to use my pairing and I'm going to rearrange things. So for example, A was mapped to one. So this A and this one, let me sort of put some on top of each other, okay? Each other. Okay? And I'm going to do the same thing with B in 3 and C in 2 and D in 4. I'm just going to put them on top of each other and look at how the edges move around. When I do this, I see the following directed edges. So for example, this A slash 1 is connected to this 4 slash D because A pointed to 4 over here, A pointed to 4, but also D pointed to 1. Z pointed to 1. So I get this collection of edges, both of these. Does that make sense? Let me just rearrange this. So far, so good? Okay. And now what I'll do is I'll take the complement of the edges. So any edge that wasn't in this picture, let me do that. So before blues were pointing to yellows. Now I cannot have any blue point to any yellow by taking the edge complements. So for example, let's see. So for example, Let's see. So, for example, there was, you know, this was missing. This direction right here was missing. And so, that's why it shows up here. Okay, so I took the complement of the edges. And finally, having done that, let me just redraw it just using the nice colors. Okay, so what do I sort of keep track here? So when I use this pairing, the pairing between the joint and the mean reducible elements that came from this chain of maximal length, what happens is I get these so-called maximal orthogonal pairs. So-called maximal orthogonal pairs. And so, what's happening is I can't have any blue. No node can be both blue and yellow. There can't be a blue pointing to a yellow because I took the complement of the edges. And then the two sets are maximal. And so this is the translation of the previous notions now into this directed graph that was obtained by merging together my J and M in this very special case. And so here's what the picture looks like in this very special case. So, and this is Markowski's theorem for extremal lattices. And he's saying that, in fact, you take some acyclic directed graph G, you take these maximal orthogonal pairs where blue point to yellow, you have this maximality. And then every finite extremal lattice can be obtained in this way. So it's supposed to remind you of Birkhoff's representation theorem. Representation theorem for distributive lattices. And let me sort of show you how you get that. So the idea here is: imagine now that sending mail is free. Okay, right here. Sending mail is free. So I'll get rid of that edge. So when I draw, so what I've done now is I've gotten rid of this edge from my, from when I, you know, when I took this bipartite graph and I merge things, I've gotten rid of that edge. So when I take the complement, that edge gets added in. Okay? And what does that look like now? Okay, and what does that look like now? That looks like the comparability graph of a poset. And if I take the maximal orthogonal pairs here, you can see that this guy is no longer allowed. The reason being that there's a blue pointing to a yellow. Okay, so that vanishes. And what do you see here? Well, you see exactly the order ideals of a chain of length 2 cross a chain of length 2. This is actually typical behavior. So when you have an extremal lattice, what happens is it's built out of some data. That data is... It's built out of some data. That data is a directed graph, say this directed graph. And if you think about that acyclic directed graph as a poset, that would give you, by Birkhoff, that would give you some sort of distributive lattice. And that's actually sitting inside of the extremal lattice as a spine of the extremal lattice. And around it, there's all sorts of additional information. There's all sorts of other elements. So this is what's happening. This is a fairly large example. So, this is what's happening. This is a fairly large example built out of this directed graph. There are some 66 other objects. Okay. Sam asked: How did I choose yellow versus blue color for vertices? That had to do with join versus meet irreducible elements. Good. And if you like things like Cambrian lattices, then the C-singletons are really the skeleton. That happens to be an extremal lattice. In fact, it happens to be something better than extremal lattice. It happens to be a trim lattice. And this was a notion invented by Hugh Thomas. By Hugh Thomas. It's a special class of extremal lattices with really, really nice properties. And so let me tell you a little bit about this. And Hugh was studying these from the perspective of asking the question, what if a distributive lattice weren't graded? So how could I make sense of what that object would be? And his answer was that you should add in this left modular condition. And let me not tell you what that condition means, but instead give you an equivalent condition. But instead, give you an equivalent condition using our representation theorem. So, what I'm gonna do is I'm gonna say that, so I have some extremal lattice, and I can represent it using Markowski's representation theorem as a pair, these X's and these Y's in terms of the, on this acyclic directed graph. And so we'll call something overlapping if the yellow vertices on the one below intersect the intersect the blue vertices in the one above. Okay, so let me give an example where there's no overlapping. So this red edge right here, you can see that the guys in yellow below, okay, so this one is contained in there because the subset of blue guys are a subset, but the yellow guys from this one below here do not intersect. They do not intersect the blue guys from the one above. So even though there is a cover relation here in this extremal lattice, Extremal lattice, there's no overlap between these two sets. And the theorem is that an extremal lattice is trim if and only if every relation is overlapping. And actually better than that, every cover relation has to overlap in a unique element. So this is an equivalent definition, if you like, of what it means to be a trimmed lattice. The upshot is: so, for an extremal lattice, what we could do is we could Is we could choose this maximal length chain, and what that did, it didn't matter which one you chose, but it let you pair up the join and the meat irreducible elements, okay? And in some sense, what you were doing was you were labeling the vertices of the spine. Well, now what we can do is we can use this overlap, we can use this overlap to actually label all the cover relations of the lattice. So, let's see how that works. So, we get to label all the edges. Okay, so the idea is: so, here's an example that is trim. This is our example. Example that is trim. This is our example from before, and now I get to label all the edges. So, for example, what am I looking for? I'm looking for blue above intersecting yellow below. So, for example, this blue sitting above this guy intersects this yellow, so this gets a label of A, because that's the label of that vertex. Or for example, if I look at this cover relation, what does it get labeled by? Well, it gets labeled by B, because this thing intersects here, right? I'm looking at the yellows intersecting the blue, the yellow from below intersecting the blue from above, and so on. And for example, this edge. On. And for example, this edge, we'll just do one more. The blue above intersects the yellow below, so it gets a label of D. That sort of makes sense? Do you see that? Yeah. Okay, good. And so we get to label the edges. And now what you can do is you get to do some strange things. So for example, you could ask, well, let me just take an element and map it to the labels of the covers below it. Or, so that's this thing right here. That's this thing right here. Or I could map it to the labels of the covers, say, above it. Okay, so I'm thinking of this as these are labeled cover relations. So I'll map it to the set of labels. So this is not crazy if you're coming from a Cox or Catalan combinatorics, where what you want to do is take a sortable and label it by the non-crossing. And the way to do this is to label it by the cover reflections or the covering reflections. Reflections. That goes back to work of reading. And I suspect Emily Barnard will be telling us much more about these sorts of maps next. And yeah, so now what we can do, so we have these bijections, but also what we can do is now, so either one works and we can define this row of motions. The idea is, let me just say I start at zero. So I've labeled now the elements of the post at zero, one, two, three, four, five, and six. These are black labels. They're different from the They're different from the, they're not, they're not the joint irreducibles or the median irreducibles or anything like that. So, if I start with this element right here, this zero, it's got, if I look at the things that are below it here, there's nothing below it. There are no labels below it. So, I map it to the unique element with no labels above it. And that would go to six. And then if I think about six, six has what labels below it. It's got this D and it's got this A, and so it maps back to the zero. Okay. Okay, or I could start say with this element right here, one. Okay, so if I have one and I look at the elements below it, then I see a. So I need to go to the unique element with a above it. That looks like five over here. And then five has a d below it. So I'm looking for the unique element with a D above it, and that's four. And then finally, four has B and C below it, and so it looks like I come back to one. And then you could do two, two has B below it. 2, 2 has b below it, so it goes to 3 and back around. So, okay, you can see this. And this is row motion. So, this would recover your standard definition of row motion if you specialize to distributive lattices and so on. Okay, beautiful. In fact, there's another way to compute it, which is, right, so we have this max length chain. You can do these things in a flipping order. So, if I were to choose A, B, C, and D, one way to compute row motion, let's say I started again at zero, then what I'd do is I'd start walking. So, I say, okay, well, if let me first. Walking, so I say, Okay, well, if let me first flip along the A edge, then the B edge, then the C edge, then the D edge, I get up to six. Okay, so I'm gonna flip in that order. Now to come down, I first flip in the A edge, then B and C don't do anything, and then the D edge, like so, and I come back to zero. I come back around. Or if I started at one, we'll do one more. One, I could flip down the A edge, that would take me here. Then B and C don't do anything, and then D would take me to five, and then if I was at five, And then, if I was at five, I would go to, I'd flip A, B, C, and then D like that, and it would take me to four. And then finally, four would go A, B, C, and there's no D coming out of one, and so I stop there, and so I come back around. And you can see that these are the same orbits as before. This is what we mean by row motion and slow motion, two ways to compute it. Okay, so these edge labels are quite useful, and they let you, one, think of They let you, one, think of objects as independent sets of the underlying graph coming from the Markovsky representation theorem. And on the other hand, you can start defining these dynamics going on. Okay, and just because we're running out of time, the orbits do not change, Toyota. Let's get quickly in the last six minutes, we'll get to independence post-ets. Okay, so yeah, and I've been going extremely quickly, so hopefully it's been somewhat useful. Really quickly. So, hopefully, it's been somewhat useful. And if not, then please go visit the poster. And so now we're going to ask the question: before you're wondering if a distributed lattice weren't graded, let's just now relax it. And what if it weren't a lattice? Okay. And so the setup here is for trim lattices, right? We had these labels on the edges. That's every cover, cover relapse, every cover relation was overlapping. So this is some sort of relation, some sort of labels on the covers. And then also we could think of the elements of that postet as. The elements of that poset as independent sets of an underlying acyclic directed graph. Okay, and so it's natural to ask a question, ask the question: can you sort of characterize what's going on in a trim lattice, say, on just the down and upsets? Okay, so on just the down and upsets, how do they interact with each other? And how can I build the trim lattice using the down and upsets? And yeah, so that's sort of the question. How do they fit together? And how can I model what it means to move? How can I model what it means to move along a cover relation using the down and upsets instead of keeping track of these full maximal orthogonal pairs? These concepts, if you like, from before. Okay, so if you like, we're sort of going to bake up row motion. Okay, so this is a definition, but essentially what it's doing is it's trying to capture. To it's trying to capture what row motion would be on a directed graph. So the idea is down and up, so this D and this U, these are going to be independent sets and they nestle together exactly when the following happens. Okay, so they have to not intersect. There could be no arrow of pointing from blue to yellow as before. And then finally, there has to be this additional thing. So these four additional constraints. What are they? So D can't be increased. So, D can't be increased. So, for example, here, I could move this blue thing back. Okay, if I wanted, I could delete that and then add the blue here. And now it's still orthogonal because blue is not pointing to yellow and everything's okay. So this is that previously was not tight. Or for example, here, if I want to increase an element of u, so I could move it forward along an arrow, and it still doesn't violate anything. Okay, or here, for example, I could add an element to D. An element to D. So, this is not tight because I could add more elements here. And finally, the same thing I could actually have added the U here, it doesn't violate the fact that blue doesn't point to yellow. Okay, so this is what it means to be tight. Somehow they're nestled as close as they can be together. This is somehow trying to capture an idea of row motion, and we could make that more precise if we wanted. And it turns out that any independent set can be uniquely completed in two different ways. So, one is if I think of the independent So, one is if I think of the independent set as blue, then what I do is I work upwards. So, yellow can point to blue. So, I just sort of greedily compute. So, I could not put a yellow here, for example, because then blue would point to yellow. I could not put a yellow here. I could not put a yellow here, but I could put a yellow here. And sort of so on. So, a yellow could go here. It couldn't go here or here. A yellow could go here, and then a yellow could go here, and a yellow could go here. So, I think I complete it in that way. Complete it in that way, if that sort of makes sense. I'm sort of flowing upwards like this, okay? Greedily adding. Somehow, I'm trying to keep track of this is somehow some sort of row motion. And for blue, I do the same thing, but down. And so I'm going to flow from the top and I add in when possible with the idea that blue can't point to yellow. I'm trying to add greedily. So this blue could get added, but now I can't add here. I can't add here because blue would point to blue. It has to be an independent set. I can add here. I can add here. I can't add here. I can't add here. I can't add here, I can't add here, I can't add here, I can add here, I can add here, here, and here, probably. And then yellow can point to blue, but that doesn't work here because there's blues stopping it. And maybe I can get blues here, and okay, and that seems to be the way to complete it. So there, and that was you, then it turns out that that's unique. So satisfying these horrendous conditions here that I'm not going to go into, that's the way to do it. It's just a greedy way to do it. And now we can define flip. And now we can define flips. So, what happens with a flip? So, the idea is: I fix, so I'm flipping at this vertex G. I want to fix stuff that's not above or below G in this directed, acyclic directed graph. And then what I want to do is I want to fix the blue stuff above G and the yellow stuff below G, and then complete uniquely in the same way as I completed the whole thing. So, for example, starting from G, so now. So, for example, starting from G, so now I'm going to try to do this flip. When I do this flip now, so you can see that everything stayed the same here, everything stayed the same here, and now I'm going to flow down to complete right here. So, I would complete the blues this way, okay? And conversely, I would flow up to compute the yellows this way. So, I guess maybe this has to be yellow, that can't be yellow, no, no, and then like this. Okay, so what is the point here? What are all these complicated things doing? If you like, it just comes from. If you like, it's just comes from, I mean, it really did come from a detailed study of how cover relations were working on the edge labels in trim lattices. And in particular, we were looking at a lot of examples for how, you know, what were these things coming from? And then it was really studying these trim lattices and studying this, how these cover relations worked. And so the theorem is that that's actually a poset. The cover relations are given by Relations are given by the flips. So you get this natural structure on independent sets. Well, actually, these pairs, but any pair uniquely determines another. And you get all the standard things. We can define a row motion because we have edge labels by what you flipped. And you can even compute the row motion and slow motion in the same way as before. One thing to observe here, I'm almost finished, that you get the same diagram. So if, you know, now Markowski's theorem was you start with any acyclic directed graph and you build. And you build, and that sort of parametricizes extremal lattices. What we have now is any acyclic directed graph is now also parametricizing an independence postset. And it's a different thing. So this is the same acyclic directed graph as a previous example on page 23 of the slides, but it's a different structure. And yeah, and so finally, if the independence poset was a lattice, then it really recovers. We really did recover the cover relations of a trim lattice. And so, and then furthermore, by Hugh. So, and then furthermore, by Hugh's earlier result, it's therefore also a distributive lattice if it were graded. And so, this is answering the question: what if a distributive lattice weren't a lattice? And you can do all the things that you loved with row motion and so on on these objects. Okay, let's thank Nathan. And are there any questions? I think Theo has one in the chat, which is: do the orbits change if you choose a different maximum length chain? No, no, he answered that already. Oh, he did. Okay. Yeah, it doesn't. I did have another question. It's difficult to phrase. Do any of these techniques allow you to prove that the posit is a lattice? Maybe by going to some version? To some version of a graph and prove it that it's bipartisan. So, I mean, yeah, so these representation theorems, I mean, it's weird because if you start with an independence post-set representation, recovering the extremal lattice representation is maybe not immediately obvious. And this is sort of similar to the bijection between non-crossing partitions. Non-crossing partitions and sortable elements. It's always been a little bit annoying to go back the other way, at least for me. Hugh, do you have something to say? Sure. So, I mean, yes, if you have like a post, if you have a pair of sets, J and M and a relation, then that does define, then the maximal orthogonal. Find then the maximal orthogonal pairs for that are a lattice. So that's that's that's a way to to show that something's a lattice is to that that is a way to show something's a lattice. So that that idea goes back all the way back to Berkhoff. Hughes' favorite way, of course, is to is to say that these are like torsion classes in some sort of uh in some sort of quiver and in some sort of category. And he has beautiful, fancy representation theoretic ways to prove things are lattices. Things or lattices. I have a question, Nathan, actually. Maybe you said this, but it was so fast it was hard to get. Yeah, I went a little quickly, didn't I? No, it's fine. So um do you have like an axiomatic definition of which post sets arise as independence post sets? Rise as independence post-sets? No, no. I think we give a sort of graph theoretic condition on when an independence postet is trim, but no, I don't, no, I don't know. Okay, thanks. Nice to be nice to have an independent condition. I have a question. Yeah, I mean, one advantage is that it's quite quick to generate these things, right? Quite quick to generate these things, right? So if you're trying to generate maximum orthogonal pairs, it can get a little bit tricky. I mean, you have to do these closure conditions. It's a little bit nasty. Here, since things are generated by flips, it's immediate. You just make a tree as you go out. So it's really, really quite quick. You don't have to worry about backtracking or anything like that. So I have a question. Can I be heard? Am I muted? You've got to talk a little louder, Jim. I've got to talk a little louder, Jim. It's hard to hear you. Okay. So, regarding your second bullet point with generalized remotion, have you seen any examples where you have surprising periodicity or homomessy phenomena? Yeah, I mean, so you can define both the piecewise linear and a birational version of the independence posets stuff. This is ongoing work. And there are new examples of periods. Of periodicity. I don't really know if there are better examples than what we already have. There are a few, just looking at some examples, there were some asynchronous directed graphs that gave you periodicity when you did a birational version. Is the birational definition written down somewhere in a preprint? I mean, you can basically lift it from work of Tom. Some work of Tom and I think Mike. I think it's basically coming from there. Since it's independent sets, if you're not actually interested in the POSET structure, then it's just going to be looking at cliques and doing something on cliques, and that's all stuff that they've worked out. Okay. Well, if there are no further questions, let's thank Nathan again.