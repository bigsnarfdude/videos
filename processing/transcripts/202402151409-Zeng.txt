So I think we are most like statisticians, right? So one might talk and try to see some point like statistic modeling can also be useful, especially when you analyze the complete data. So the application I'm going to use actually is the data from electronic health workers. Alright, so I can introduce brief about electronic health workers and the About electronic health workers and the particular application we're going to analyze. And obviously, many of you probably don't know that, but so I can just kind of review what kind of challenge we analyze type of data. And hopefully, you can share the same point as mine saying why we want to use statistical modeling at some point. And why we want to use machine learning or any other kind of technology and the other part. So you can see there are two parts I list here. One is try to learn this latent hydrogen. And try to learn this latent hydrogen actually is related to feature engineering. So you can see statistic model might be useful. And the next one is that once you get this feature, then this optimal treatment is theory. So then you can see we're going to introduce kind of much learning, machine learning approach to do that. So EHR data, we, well, I just jumped to my application here. So the data we collect actually is, oh, by the way, this work was done a few years ago. So for the audience in the publication. So it could be already in the publication so on. So the data we collected actually is from this Ohio State Medical Center. And the data, when we analyze data, I think the data is collected up to 2018. And the data here we use is from 2013 to 2017. So it's about five-year data. And each data, we collect a bunch of biomarkers or clinical measurements from each patient who has a record in this kind of system. And I listed a few important biomarkers. System and I missed a few important biomarker here. Oh, by the way, this is each, we try to study type 2 diabetic patients. So young was already type 2 diabetes. So we collected this kind of measurement. So as you can see, blood pressure, total characteristic level, of course, important one is HBL1C level. And also HDR, body mass, and a lot of medication are prescribed to those patients. And the medication may or may not be medication treated that way. To be authentication 3D diversity, or to be something else. So the data is quite complicated. So you probably can imagine for this kind of data. But of course, we first question YouTube to ask, well, why want to analyze complicated data, right? So I just list a few benefits, which you can easily find in any EHR literature. Basically, they're going to say, oh, why this is this problem? So the first data is very cost-effective. So basically, you don't need to spend money. Don't use basically, you don't need to spend money, it's already in the system. It just goes to this computer and download data and the extra data, and they reflect the real-time and real-world evidence you can see in a hospital. Because that's exactly medical reps you get for each hospital system. And they provide the opportunity, which usually we don't have in specific small studies like clinical trial or cold study, because we can know a lot of patient disease progression, HGLD, and a lot of treatments as we are seeing. And the load achievements, as we are seeing in this type of application. Of course, this is a bigger data framework. People talk about volume, variety, velocity. I think they are 5V is 5B. I forgot the other two V. So our goal is, as I mentioned, I want to do two things. First thing is, I want to look at this data and understand the pattern of patients. So basically, it's kind of feature engineering. We want to extract important features, which we can use for either. Which we can use for either prediction or for treatment decision. And the particular last one, in which my second goal is how to incorporate this feature. When you try to use this data, try to find the best treatment for this type of diabetic patient. So that's kind of goal we can do here. All right, so when you analyze that data, as I said, the data is not designed. It's not like for research purposes. So data just came randomly. So the first thing you analyze. So, the first thing you analyze this data, you need to be very well recognized time window. Because there's no, like, you just start, you have time zero and then you follow patients and so on. So, in this case, time is a carrier time. So, what we do is we divide time window into this few blocks here. So, as you can see, we use the data between 2013-2016. Let's kind of record data. We get those data, and use that try to extract a few. That tried to extract features, you know, basically create like a covariance or feature variable. But the reason we use this kind of pretty wide window, like this through window, because we really want to understand some potential late in the long term underlying feature for these patients. So we use quite a long window. And the patient is like almost more than 8,000 patients for this type of application. And we use like a one-year window, which is 15 to 16. Basically, 15 to 16, basically called this kind of short-term window. Hopefully, we can capture some short-term feature variables, which we can use in the analysis. So, you can see those kind of type of data don't overlap. I mean, the 10 times time, they don't overlap. So, why is it really try to shooting for like a long-term underlying feature or chronicity about patients? The other one is more like shorter one. But then we also try to start define our time zero, right? So, when you give a treatment serial, when you give a treatment to the Decider when you can treat December. So basically, we go to this 2016 and we use the last clinical visit as time zero. Because when patient visits clinic, you're going to get a treatment. So that's our time zero. And the YCG treatment, so of course the next thing is to figure out what's the outcome of this treatment. So then we use 2016-2017 YO window, try to define what's the outcome after the patient gets this condition. So you can see that's a very clear. So, you can see there's a very clear time window we define based on this pre-application. Alright, so again, GHR data is a big note for research, so there are a lot of challenges here. So, first data, I will show you one small snapshot. The data is a longitudinal, and it's very hygieneous. There's a lot of mixed type of organ continuous, binary, or counts. I give an example here. And the bimark is collected in each chemical basis. Collected at each clinical visit, but you can see patients went to see doctor very differently, right? Some patients visit almost monthly, some patients maybe only show up once a year. So it's a lot of like readiness. And the most important time when to see the doctor is informally, right? You feel sick, you've got to see a doctor. So that's kind of, there's a potential informative. You need to take care, you need to take care of analytics, this type of data. And also there's a lot of treatment high. And also, there's a lot of treatment hydrogen as you can see here, which shows up in this plot. What we did in this plot is a snapshot of about 20 patients. I think it's 20 patients. So you can see different color basically means different biomarker measurement for each patient. So as you can see from here, of course, the medication, a lot of pink basis is written medication. So but there are some biomarker measurement like a biomarker like a castle level, HP AP. What is somewhere here? Probably you can tell, but it's not very. And also, you can see between patients, each row is like each particular patient. Between patients, the measurement time planning is very hygienist. Some like very sparse, some is very frequent. So that's kind of thing you need to account for whatever you statistic model or use deeper learning or whatever machine learning. You need to think about this kind of issue. Otherwise, you will get the biased analysis. And this just like a medication. And this just like a medication. So, what I say here is a monotherapy basically means they only get one single genome. But in this data, actually, patients more likely get two or three therapies when they want to see a doctor. And you can see the pattern is very different. Most patients, they got an insulin in this particular patient. Next major is metaphorine. That's kind of standard treatment for the type of diabetic patients. You have questions, I expect that. I have a final question. I have a value question. If you guys have seven issues, I have because of the different medicines, how do you group them together on what science? Well, I will show you later. So this just tries to show you all different medications. Later we can basically group into only four classes. While of course like some medication related to capitalist, right? Some medication nothing to do with that. We can put it on. Do you want to get the chemical information out? What's that? Or chemical? Yeah. I don't have the information. I don't have the information. But all this you can look at the ICD code and you can have all these compounds and information. You could do later. But of course you can do it. Actually, even the full time, I think there are nine classes of medications. But I don't think based on compounds. It's based on the treatment and what kind of symptom or the target to yeah, they're based on that one trying to do classification. There's a medication classification system you can look at. thing you can look at then. Any more questions about this before I go on? Alright, so the first thing is like as you can see the data is so hygienic, so complicated. So the first thing, when you try to do an assignment, when you put all this kind of projection model, you wish your data will be like metrics, right? Everybody had like 1,000 vectors, they can input it all together. But it's different, right? Every patient, number of records, number of measurements, they're very different. Number of measurements, they're very different. So, the first thing you need to do is how make this data become metrics data so you can use, right? And I feel statistical model can play a role here because statistic model, as we all know, statistic model really try to capture mechanism of the process. So, in other words, if you really can capture this mechanism very well, essentially it can be produced all data. So, that's kind of I try to advocate for this kind of feature engineering. It may or may not be okay with you, but I think that's a good thing for this IP. I think that's a good thing for this type of feature. So, so as I said, we use this like four to five year data trying to do this kind of feature engineering for this type of data. So, the first thing, actually, like Jija mentioned in her type of 2 here, is you have this by market at different type, like continuous, approximately continuous, and binary, second data. How to combine them together? So, naturally, we're going to use this kind of generalized exponential primary to try to capture different types of data. Different types of data. So, in this GLS experience family, and we have this, I mean, statistics, we all know this. We have this karmic leak. And this, for each type of, we link to this independent feature variable. But most important thing, we use this latent process. So this spray process basically captures this kind of latent, it could be integrated as disease process or something else, but this process can produce different type of outcomes. This different type of outcome. And also, important thing here is you can make this process to be just multi-value normal distributed and have a collision. So the good thing about this latent process, this modeling, in some sense, is you can project different type of process onto the same scale, basically, right? Because original process is counted data, binary, whatever. But after this kind of projection, you can project on this. Kind of projection, you can project on this latent process, which is a normal distribute, is continuous. So, and the recurring, right? So, once they correlate, so when you say, okay, if I really want to summarize or combine this very different type of biomarker, I can just work on this projection, which is a continuous scale process. Right, go ahead. So, yeah, I just got confused. So, in in general, for the second life, you don't add the error terms. Think about the regression. Think about logistical equations. Right, they don't. So, why do we? This you can think about landing effects. So, if we think about that way, so because this is a multivariate longitudinal, so you can think about it as like running effects. So, they can capture within subject and between biomarker dependence. You can think about that way. I think that's easy to understand. But we just try to make it like a stochastic process. The small key is the number of biomarkers. Oh, where's the small key? I didn't see it, sorry. Oh, yeah, that's right. It's a number, yeah. That's true. Yeah, it's a number, yeah. That's true. Okay, so what we try to make it more flexible because we don't want to ask the t small to be too restricted. So you can see we made a coherent time variant, we even make a covariant this correlation matrix, this omega t, this is the two biomarker correlation to be non-parametric. That's we try to make it more flexible. But one thing we didn't do that, we didn't model this kind of temporal correlation. We could, but we figured out a competition. We could, but we figure out that computation is very challenging. So we try to avoid that. And we won't see that. But they are temporary correlated. We just don't want to model them. Alright, so once you have this, so essentially, I mean, this kind of process, latent process feeling is a status model. Everybody's familiar with the general linear mix effect model. But the good example of this model, like WhatsApp, you can easily combine different types of order by market projector on the same scale, right? Yeah, and then once you understand latent, Yeah, and once you understand the latent process, it doesn't matter this person has two measurements, the other person has 1,000 measurements, because they can all be produced by this latent process. So, this is a good thing. So, yeah, once we have that, we can make a metrics of data as well. So, that's kind of the challenge here. All right, so the next thing I mentioned is informative measurements, right? When they get a measurement, it's informative. And I mean, gotta work on event time data, that's quite a lot. Time data, and that's quite a lot. So, we usually model using this counting process, and we model this kind of intensity. And a lot of this counting process depends on the past history of these patients. So, and the L denote history. And again, for computational purpose, we try not to do two number margins. We make a more permanent in the sense, a semi-permaragent model sense. And once you can get this model, good thing about this model, you can just rescale the county process. Just rescale the counting process by this factor. Sorry, I don't have coin here. So you can rescale by this factor. The reason why you do that after you rescale this counting process, but this is sudden new counting process. It's nothing to do with the patients' history or covariance. Because each patient's measurement time depends on their covariance, depending on their past history. If you're apt for the standardized, so this is like a standardized counting process, you can think about it that way. You can think about it that way. So, work on this kind of process, not every patient under this kind of skill pattern basically becomes homogeneous. There's no heterogeneity going on. So, this is kind of actually exactly related to this inverse probability weighting type thing. And the people call this inverse intensity weight. Basically, you're working on time scale. So alright, so once you have that, of course we try to estimate this beta, this coefficient, and time variant. And the idea is very simple. We just use method moments. We just use method moments. So look at the first moment, look at the second moment, look at dependence. And because we do nano merger, you can see there's a kind of kind of smoothing going on here. But also, one important thing is remember I use this kind of standardized counting process. Because the kind of thing can remove this informative measurements from the counting process. So everything is kind of statistic model. And once you have this model, so um the next thing is how we can extract this equation. thing is how we can extract this equation and we do very simple we could do more complicated but what what we did very simple is once you have this process you know distribution of this process so we can just use data to calculate the posterior mean of this I got skipped this theory we can calculate this posterior mean of this data process only using local data we are not used to flow data one reason is because we never model this temporal correlation if we model all temporal correlation we could use flow data We could display data. But we only wanted this cross-sectional dependence, so we use lock data, try to predict this latent process epsilon. And because we estimate that converge, right, omega t, this number much, and we can sort of define this between subject distance. As you can see, this is a hala novice distance using this covariance matrix capture. Because this kind of distance can remove a redundant information. Can remove the redundant information by different biomarkers, essentially. So, why do we want to come at this distance? So, essentially, we get a distance similarly about these patients by looking at their EHR data in the history. Even though original data is so sparse, so hydrogenous, but by doing it this way, you can look at their distance. Basically, like a kind of profile. Look at each patient profile and you try to decide which patient looks similar or not. And then, once you have distance, like before we talk about it, we can do. Like before, we talked about we can do class analysis. This kind of thing we're doing. So, I just quickly move on. So, this basically describes how statistic model can be useful to handle the computational data, a lot of situations. In this case, missing data, measurement error, multiple type, and the informative measurement time points. I'm sure some deeper learning can do that, but not fully in this case. So, I think that we have. So I think that we have this kind of situation. Sometimes we can go back to statistical thinking about model, how much model can per kill us. So the next one, I said you have this extract, this long-term feature based on profile. The second one, we're going to incorporate this feature, and then when you try to make a precision medicine decision. So the precision medicine basically is that, okay, you have a patient's individual information, gender, age rates, or the extract feature from this previous model. Previous model, but also remember: I have one-year data, I can get a short-term disease by marker. I can just look at the one-year, what's the average blood pressure, what's average HBI, what's the level of BMI in a past year, you know? And this kind of short-term income variable I can incorporate into my decision, right? And then once I have that, then what I'm going to do is, oh yeah, that's what I mentioned, is one-year to care feature. And what I'm going to do is once I have this feature, press this round feature. This feature, practice this long-term feature extracted from the statistic model, then I'm going to try to find the best treatment decision for each new patient. So that's basically my goal. And now related to this medication thing, we have this almost like one, actually data almost like 800 or 200 of these medication compilations. How we do that? Well, we have not tried to use this compound thing. We have not tried to follow this medication classification system to do that. We just do it in my EV because by nuclear diffusion. So we put one group of metaphoria on. So we put one group on metaformia only. You can remember there are 20 or 30 percent of patients that take only use metaformia. A lot of people use the insurance in this particular example. There's other type of 2 diabetes therapy, but other medication nothing to do with the type of diabetes which I put it together. So that's kind of what we're doing. Yes. I tell you why I asked that question because last time I made a sentence thing. I think Medica told me that that basically the home is having holes. That's how I learned. Okay, yeah, maybe, yeah, like I was saying, actually, type of like a medication as a classification system. You can look at different brands like drugs, you can classify into different. There are nine. I remember nine or seven. We had a student do that. And the other one, actually, before we did that, right, we used a data-driven channel. We use a data driven try to classify genetic teams. So, there are kind of approaches to that chemical compound can be used for. But anyway, so we group it into four triangles. That's what we're doing here. And don't even impose four treatments. Do they do multiple together, like the insulation and the other thing together? Not really. We end up with one versus one. We did use multi-category to handle that. Any more questions? Do you want more? So the next thing I want. So the next thing I want to mention here is: remember, once you have this feature engineering, get all this variable, the next thing is we want to come up with best decision, right? Truement decision recommendation on pages. And I mean, statistically, probably if you know this literature, decision is trying to maximize some code and diet function. You provide the best decision, you want to maximize your outcome. And then in this case, because type of 2 diabetic patients, the outcome is try to reduce the glucose. Try to reduce that glucose level, this HVAC level. I mean, you want to control below like 5.6, there will be normal patients. Usually it's up. But the more reduced, the better. That's the kind of output you want to achieve. So from this one, because our goal is trying to maximize the value function. And we feel in this case, we don't need a statistic model because this is basically a machine learning people try to do. Machine learning people, well, the goal is to try to minimize certain loss function, right? Minimize certain loss functions, right? They don't care about how distribution works, like, they don't care about what the underlying model is. The goal is: can you come up with a decision, maximize certain things? And from this point of view, because our goal is to maximize the value function, so we feel like, okay, in this part, we probably don't rely on statistic model because machining is going to be computationally efficient and more fast, in that sense. So, I think that's kind of at the moment, we say, okay, let's say we should do machinery entirely. But, of course, let's come related to. But of course, this can relate to all the research I did before, so we will have doing this kind of outcome within your type thing for this approach as well. So by the way, so but before even going to the half of that, so remember we have this feature variable and we also compare this observation style. So you always need to compare this for principal score because it's going to tell you something about the true material. And we also have this kind of prediction score basically prognostic. Prediction score basically is a program score basically using feature variable, trying to predict outcome. The thing we did, we use this GBM model to try to get this score. So the thing we did here is to use this kind of usual inverse profile rating type of approach. We use what we call the matching kind of approach. The reason of doing this, I think this is a kind of a choice of what kind of machine learning algorithm, something really needs to depend on your application and your data. To depends on your application and your data. And then, in this kind of data, if you try to do immersive weighting, you will see a lot of probability will be closer to zero. You can see already this distribution. Most of the patients take insulin and metaphoria. Automated Haji probably is very small. So when you do IPW, either RPW or augmented IPW, I think the computation will be charged. But in terms, in this case, we check to matching. Matching, we don't do weighting. So matching idea is very simple. So, my idea is very simple. So, you just pick two patients that look very similar in terms of feature variable, and one patient takes treatment insulin, the other one take a metaformia or other medication, and we just look at the outcome to see which one is larger, which one is smaller, right? And based on larger one, that's our recommendation. So, that's kind of idea. And this is a very typical technique you use in the causal universe, right? In addition to IPW, I know all like. Addition to IPW, I know all like the IPW in cosmetic inference, people do match as well. Matching is a very powerful approach in cosmic inference as well. So, um, so that's kind of what we did for this query. But this is just a formulation, how we pick a match set, how we construct this loss function to minimize and the regularization stuff. Yeah, go ahead, please. You mean the matching? Yeah, oh, just this distance. This distance. Yeah, based on distance. I have to. Okay, yeah. Yeah, this data I. Yeah, well, the reason is we put this data. I mean, theory is fixed, or maybe it depends on or something. In practice, we should because something can be dependent on the nearest neighborhood. So if you do, I mean, in practice, people sometimes use one year's neighborhood, but something goes beyond more than one year's way. When you do this nearest neighborhood approach, you matching, you still are going to turn on matching. Okay, cool. So, um, then this is the recognization for match learning. We did um so, okay, now uh how much time do I have? Six minutes, that's great. I can go to my results, that's right. So, again, just a quick review: this is data we have, about 8,000 patients from the beginning. Longitude record is about almost like a half million. And because it's a kind of small And because there's a kind of smoothing, so we have to choose a band of width of 13, and we have this one project to do that. But basically, this just showed, remember, first model statistical model, we try to capture this longitudinal pattern of different biomarkers, and this just showed a coefficient time variant. So I just showed this for here. And this showed like this correlation, I mean, covariance between a different latent process of time, also time changing. So you can see on the map here. But most importantly, remember, once I did this. important remember once I did this model I can define distance similarity between patients right based on their longitudinal profile and I can cluster them and this is kind of hierarchical clustering we did and there are different groups identified here and I just quickly show you this C group looks like so what we did is there are six groups here and basically what we did we reported what's the average value of each biomarker for the six groups to see are they really different right? School to see are they really different, right? And that's a very interesting, right? By the way, like this number is standardized. In other words, it's compared with the mean of population in the data. So yeah, this red, which means the value is very high. So positive is high, negative is low. So you can easily recognize, like I say, for example, group two is high blood pressure, because this variable is Because this value is pretty high compared to other groups. Makes sense? So yeah, group two is like a high blood pressure. Group three is HPN1C level is very high. Group three actually is very healthy because HDL is very high. HDR higher than the HDL group. And group four you can see is the class level is high and the BMI for the last group is more of this variable. So yes. So this is classroom based on the sixth variable? Six variable? Classroom is based on the distance. Distance is based on, I think that not just six, but also medication. You remember, there's a number of medication by market there too. Yeah, but more majority is like the six biomarkers. Yeah. And the other thing that we say, we're going to saw is distinct, so right. And the interesting after this, we have one more data we never use. It's like 2018 data. So basically, we use their data and you do the similar analysis, try to see if the group are matching. Analysis, try to see if the group matches not. Actually, we find those six groups really exactly have a similar pattern in 2018. So, give us a confidence that group structure extracted from this EHR data over five years are really meaningful from this kind of interpretation. But also, it's mostly the kind of systematic pattern because we did see in the new data, which we never used in our data analysis. Okay, once we have six groups here, so what we do is basically to stratify. Do is basically to stratify. We go to each group, try to learn treatment decisions because so different. So that's basically doing. So then we use this kind of match learning, try to do this treatment decisions. I just give all detail. This just shows you the propensity score in each group, the six group. And then that's why I try to mention if you try to do IPW, you can see some probability weights can be very high, some can be very low, will be very unbalanced. So that's why we. Balance. So that's why we argue like a match learning should be a good approach for here. But interestingly, I just want to show this figure here. That's right. So remember there are six groups, right? And we classify into four different medications. One is metaphormine, the other is insulin, and there are other medications as well. So this is observed distribution in each group. So for example, I can inspect group three. You know, in the real data, most people take Most people take insulin, right? Most of the patients receive insulin. But in group 3, it is really high group because level is very high group. So I think I showed number before. Some people take a metiform. And then the second row, this is based on our recommendation. But based on our recommendation, say for patients in group 3, most should recommend this one. I forgot. In metaphor. I forgot. It metaphorically. This is the answer. So, somehow, there's a kind of inconsistency between our actual observed pattern and our prediction or our recommendation. Well, we don't know why, maybe there's some other bad confounder we didn't capture because when doctor make a decision, maybe based on something else, which we didn't capture data, or maybe doctor did the wrong medication, too aggressive for this group. Because they are high glucose level, patients likely to get insane injection. Yes? So, groups four and five seems quite similar, both in the Very similar, both in the original and recommended. Yes, recommended, yeah. So I forgot. Group 4 maybe is the healthy group that high cross HDI is very high growth. But most important is group 3. Actually, I have number if I remember. I know it's well red, so yeah, this shows different groups. This shows like a weekly with the cross-foundation version, right? What's the value we can get here? But yeah, I'll tell you correctly. So anyway, so the presentation I give you. So the presentation I give you, I just want to give you some messaging. I feel like there are still some useful power from statistical models. Even though a lot of cases, once we have this kind of data, people like to feel different or this kind of going into this one. But one thing I feel like the scientist statistics model can easily handle different type of very complicated missing data measurement error, informativeness, right? And also, of course, you have a type of explanation. You can look at this model, you can easily recognize how to interpret it. Recognize how to interpret the LTM. And also, I feel like this also relates to accountability. Something very wrong, we can easily figure out from this kind of model instead of a black box or so. But of course, we also use machine learning because our goal is for decision making. So I think in this case, machine learning has its power too. So I hope this work can give you something to think about. So I won't I can skip the extension. So okay. Okay. Okay. In person? Okay, yeah. Before you ask me questions. So don't expect. No, no, no. Everyone can call. Is that everyone allowed or