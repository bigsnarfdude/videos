Hello. I'd like to share with you my work on spherical multi-taper analysis via spatial spectrally concentrated slapping functions. I'll be reviewing some theory and delving into some applications. In one sentence, mathematical functions cannot be band limited and space. Be band-limited and space-limited at the same time. This is a statement of the Paley-Biener theorem. But what we can do is we can try to find a set of band-limited functions that will be optimally concentrated within some spatial region of interest. And conversely, we can find a set of space-limited functions that will minimize the spectral leakage outside the band limit of interest. Those are the very functions that we call. Those are the very functions that we call sleep-in functions. And we're going to use them both as windows to perform spectral analysis in the multi-taper way, which is the subject of this workshop. And we're also going to use them as spar spaces to represent signals on the surface of a unit sphere, as is especially appropriate in the fields of geophysics, planetary science, or cosmology. Reviewing the Reviewing the one-dimensional Slepian theory is very simple. If we start with a bandlimited function of time, g, whose Fourier transform vanishes outside the bandwidth, plus or minus w, we will be trying via a quadratic concentration measure, lambda, to squeeze as much as possible of any of those functions inside a time interval. Inside a time interval of interest between t negative and t positive. Again, thanks to the Hayley-Wiener theorem, we know that this cannot be achieved exactly, so these equalities here are strict. It turns out that a minor rearrangement yields the well-known Fredholm integral equation that starts Dave Thompson's paper, whereby these unknown functions, the Slepian functions, The Slepian functions are the eigenfunctions of this integral equation with this kernel, the sinc kernel in blue. Two dimensions is just the same thing. A function whose Fourier transform vanishes outside some spectral range, curly kappa, can nevertheless be concentrated inside a finite spatial region R of area A by maximizing that very same type of a concentration. Very same type of a concentration criterion with a ratio lambda, except everything in 2D. Those functions are eigenfunctions also of a Fedholm integral equation, which is given below by equation six here with a kernel that is in blue. Again, the unknown functions, the solutions to this equation, are in magenta, and those are the Slap-In functions of a two-dimensional Cartesian domain. Domain. On a sphere, we're working not in the Fourier basis, but rather in the basis of spherical harmonics, ylm, on the surface of the unit sphere, which we call omega, whose coordinates are r hat. And a band limited function there is a truncated expansion with expansion coefficients glm going up to band limit L. Again, we're going to try to squeeze that function into some sort of a spherical concept. Into some sort of a spherical concentration domain R of region, of area A. Those functions, then, the G, again, are the eigenfunctions of this Fredholm equation with a blue kernel that is made up of a sum, a limited sum, of Legendre functions P of L, of the degree L in the argument that is the cosine of the angle between the two points. Of the angle between the two points R and R prime. Right away, I'll show you some examples. If we concentrate those types of band-limited functions into a spherical cap of a certain opening angle, and we look at the north pole of a sphere, they'll come out like this. With this advanced symmetry, the order structure of the spherical harmonics is preserved. M remains a good quantum number, and we're seeing. Number and we're seeing as a function of diminishing concentration from the top to the bottom functions that show you zero order, order, plus and minus one, and so on. And they tessellate more and more of that region of concentration. I'm only showing a few of them. These are the best concentrated. They get progressively worse. And then there's a whole number of them that have nearly zero concentration capabilities within the Concentration capabilities within the region R, which is denoted by the dashed line here of a spherical cap. But R can be anything. R can be Greenland plus a little coastal buffer, as in this example. Here is a set of spherical slapnin functions to a band limit of L equals 18, listed in decreasing order of concentration with the rank alpha going from 1 to 3 and the lambda from nearly 1 to progressively worse concentration. To progressively worse concentration. We see that they preserve some of the symmetric properties, but of course not all, because the region of concentration, again, is Greenland plus a small coastal buffer. All these three examples that I gave for one-dimensional time series, for two-dimensional Cartesian domains, and for the two-dimensional surface of a sphere are all part of the same class of functions. It turns out that these It turns out that these blue kernels that I showed you are spectrally limited spatial delta functions. I've rewritten the sinc function here in equation 10 in blue, and I note that the trace of that kernel D of the integral equation is a time bandwidth product 2 times Tw in this case divided by pi, which gives you sort of an area of the effective dimension of those functions that are both. Of those functions that are both band limited and concentrated in time. In two dimensions, the kernel dx prime, that blue thing that I've already shown you, again, is a spectrally limited spatial delta function with a trace that is, again, an area bandwidth product. Here, the area of the region is A, and I've chosen a spherical or circular concentration radio. Circular concentration radius of radius k. Finally, in the three-dimensional, fake three-dimensional case of the two-dimensional surface of the unit sphere, I've rewritten the kernel that contained the band-limited sum of Legendre functions as what it really is, a band-limited sum over degrees and orders, L and M, of a product of spherical harmonics, YLM, and YLM. spherical harmonics, Y L M and Y L M R and R prime are two different points on the sphere. And the trace of that thing is again an area bandwidth product. L plus one squared is the total number of spherical harmonics between degree zero and big L. And so once again, this shows you the area of the effective dimension in which these band-limited and regionally spatially concentrated Regionally spatially concentrated functions live. So the SLEP-in functions are bases. They're bases for any band-limited process anywhere on the domain, not just there where they were concentrated, but rather there they will be a sparse basis, as I will show you. There is an important feature of a double orthogonality within the region. They are orthogonal to the concentration ratio lambda. Ratio lambda and on the entire domain, the entire sphere, if you will, in a spherical case, they are remain orthogonal with an inner product of one. After all, they are just linear combinations with a unitary transform between the basis of spherical harmonics and this new basis of slapping functions. And the trace, that time or space bandwidth product, is an area in the sort of a Shannon sense, and I'll be noting that. The Shannon sense, and I'll be noting that and calling that the Shannon number, and I'll give that the symbol n. It's a little bit easier for spherical harmonics to work in a spectral domain, and so by looking for a band limited expansion of spherical harmonics with unknown expansion coefficients that will give me slapping functions, a rewrite of the space Fred Holm integral equation. Integral equation becomes a spectral algebraic eigenvalue product equation where the matrix whose eigenfunctions are the expansion coefficients G L M of the slapping functions is given by the joint product of two different spherical harmonics integrated over the area of the region of interest. Of the region of interest R. So, this operator, that red thing, we call D with elements lm, lm prime, and its trace, of course, is the Shannon number, the area bandwidth product, L plus 1 squared, the dimension of all of the spherical harmonics to degree L, and A over 4 pi, the fractional area of concentration that defines the region of interest. That defines the region of interest. Now, many of the eigenvalues of the operator D are very, very small, and it itself may be hard to calculate. There is some sophistication involved. But most importantly, d is going to be hard to invert because of the presence of all these low eigenvalues. And through all of this, remember that the spatial region R can be completely arbitrary. Greenland, Africa, you name it. Here are some eigenvalues for a spherical cap of a certain opening angle, theta 30 and theta 40. And you're seeing that the eigenvalues have this appealing stair-like stepwise structure, where the very best concentrated functions have concentration ratios that are very nearly one, followed by a transition region, and then a long sequence of functions whose concentration is completely the opposite to being nearly one. Is completely the opposite to being nearly one. In other words, they live completely outside or almost completely outside of the region of interest. Here's the case for an arbitrary region, Greenland, America, Africa, Eurasia, as every panel shows you a handful of examples for different spherical harmonic bandwidths, 6, 12, 18, and so forth. Overall, they all have the same stairway. All they all have the same stairways structure. A slight aside is that when the region of interest is of great symmetry, circular symmetry, spherical symmetry, the symmetry of a polar cap that is flipped through the center to become a double polar cap. Then, despite the elements of D to be sometimes Be sometimes difficult to calculate. The lucky accident or the magical thing that Slepkin and co-workers discovered is that they found an operator that commutes with the original operator whose eigenfunctions are the same, but whose eigenvalue structure is very easy to calculate. In other words, no numerical instabilities. And that commuting operator is a very easily A very easily written down expression, which in the 1D, 2D, 3D spherical case amounts to a tri-diagonal matrix, which forms the essence of this sort of problem in the cases of advanced symmetry on the sphere in the Cartesian domain, as it was all along for the degenerate one-dimensional case. So, in practice, when we're dealing with advanced symmetry, calculating the Slapian functions is a almost Is an almost trivial thing. So, returning back to the sphere here, the crux of the matter is that spherical harmonics form an orthonormal basis on the sphere. Their inner product on the entire unit sphere is a Kronecker delta in the degree and the order. But when two spherical motics interact and are co-integrated against Cointegrated against a portion of the sphere, they are no longer orthogonal. They are indeed that matrix D that we will call the spatial spectral localization matrix of the spectral variety. But the eigenfunctions of that D, those are the Sleptian functions, or rather they are the spherical harmonic expansion coefficients of the Sleptian functions in the spectral case. And so they do form. And so they do form a band-limited localized basis. And as I mentioned before, they are doubly orthogonal. If you co-integrate them on the region R, they evaluate to lambda. And if you integrate them again over the entire sphere omega, they remain an orthonormal basis. The Shannon number, because some of the eigenvalue, I remind you, is n, is a time bandwidth or space bandwidth product, which in the spherical case is the fractional n. Spherical case is the fractional area of the spatial region of concentration multiplied by the entire dimension of the functions in the spectral sense. So because there are unitary transformation from spherical harmonics to Slepin functions, if we just expand a bandlimited function in either basis, there is no difference. But because the Slepin functions are formed for a specific region of interest, Specific region of interest, if we just sum the first n well-concentrated functions, they will form a very good approximation for a signal that is both band-limited and regionally concentrated. What you're missing, the mean squared error, is regulated by the value of the eigenvalue of the neglected functions, which are tiny, and so the approximation is very good. To show this, both the quality of the Both the quality of the approximation and the smallness of the basis that's required to approximate regional signals that are bandlimited in the new custom-made basis of SLAPIN functions. I show you a set of circle harmonics of random degrees and orders. I evaluate them on a square that contains Africa, which itself contains a circle of a portion of it that is of interest. On the left here, I show a geomagnetic model. Left here, I show a geomagnetic model for the lithosphere of the Earth. This is something of geophysical interest, as you may imagine. And on the right, I show the expansion coefficients that are the one-to-one equivalent of that map. You'll notice the wedge that I leave here, that is zero, is the components of the field that are due to the actively generated geodynamo field of the Earth. And so what we're looking at is a remnant geomagnetic. At is a remnant geomagnetic signal that essentially tells us something about the constitution of the rocks that make up the Earth's outer shell. Spherical harmonics are a global basis. They're good for this sort of representation. About 5,000 numbers code for the entire information of this map. But if we want to look at just an area in this circle here, which contains a massive geomagnetic anomaly that is Massive geomagnetic anomaly that is in the Central African Republic. Still, about 5,000 spherical harmonics are needed to represent that anomaly, despite there being almost no information needed or present in the region outside. It's just a consequence of the circle harmonics being a global basis. You still need a whole lot of them, even to produce a regional signal. But so now we'll see what. But so now we'll see what happens when we construct a basis for that circle in terms of Slepian functions. Here are two pictures of the transformation matrix that turn the strict harmonics into Slapian functions. It's the same matrix D. I've reordered it to highlight some aspects of the symmetry, but they're not important right now. But applying that transformation gives us the slapping functions. Again, here I show you that. Again, here I show you that for the region of interest, the circle centered on the Central African Republic. And once again, I enumerate them in decreasing order of concentration. But most of them here still are very, very good. If we use that basis to expand that regional anomaly, then of course, just a handful of functions are important and necessary to reconstruct an anomaly. So to switch through So, the switch through the unitary transformation and the partial expansion from the spherical harmonic coefficients to the new basis of Slepin's functions achieves an excellent approximation error and a very welcome reduction in the number of terms that are needed. And so you have a notion of Sleppman functions in this region being a sparse basis for localized, regionally localized band limited signals. We'll use We'll use them to solve some problems in geophysics. Here are the two GRACE satellites. And in cosmology, here is a W-map satellite, which is mapping the sky temperature. What are the common problems in any and all of this? We collect data that's made up signal and noise, and it's available or it's desired inside a spatial region of interest R. We make some assumptions about the noise as a zero-mean process that's uncorrelated with the signal. That's uncorrelated with the signal and will characterize the noise covariance. In one sentence, we have noisy and incomplete data on the surface of a unit sphere. In equations, D is the data. It's made of S, a signal that we try to reconstruct, and noise, the contamination. Inside the region, we want it, and we try to get to know it. And outside the region, we have no information, or we don't care. Or we don't care. Zero mean noise process, uncorrelated noise with signal, and the notion of having access to a known noise covariance, which we in practice will need to estimate. But here, I'll just take it as a given. If you want to think again about what noisy means, here is what the gray satellite actually returns. This is one month of the geopotential of the Earth expressed. Geopotential of the Earth expressed as a millimeter variations around some other equipotential surface. This is one month. This is another month. Your eyes don't see the difference. I do know there's an earthquake buried inside the thick line here, but that's not the point of this presentation. What your eyes pick up is the strong colored and correlated noise structure that is due to the satellite orbits, the speckle on the continents, and so on. Continents and so on. And so this illustration just serves for me to remind you that our geophysical data, as in this case, is often noisy. To put some pictures to the words incomplete, well, Greenland, of course, or Africa are incomplete regions of the sphere. In the case of cosmology, the notion of incomplete means once you want to try to observe the entire celestial sphere in order to calculate some In order to calculate something about the cosmological parameters of interest in this map of the temperature of the sky, you're seeing the strong contamination due to the universe's galaxy here, which is going to lead to us needing to cut it out somehow. And so the notion of the region of interest in this case is a double polar cap, where the latitudinal band is the region that is not of interest. So the So, the problems we're trying to solve is that there is an unknown signal, a wideband signal that we don't know, and we'd like to get to know it. In the linear case, we're having these types of data, we're having that sort of noise, and our object is to estimate the signal. We can never go to infinity, so we must realize that the estimate, S hat, is always going to be bandlimited to some finite spherical harmonic. To some finite spherical harmonic degree, big L. And the second type of problem is for the same types of data and make an additional assumption of isotropy of the spectrum, such that the spectral density, the covariance of the spherical harmonic coefficients, is only degree dependent. Our objective will be to reconstruct for this type of data and this type of noise this power spectral density, S of L, as the estimate. As the estimate, as Hatzabel, for a finite but limited set of circle harmonic degrees. So data, they're noisy and they're incomplete. Problem one, we'll need to find it, the signal that gives rise to the data. Problem two, we'll need to find the power spectral density of the signal. Finding the signal. If we write down the least If we write down the least squares estimation problem that tries to fit as best we can in the least squares sense the data to the signal that gives rise to it, knowing that the data are limited to the region D, region R. The least squares estimate involves the integration of the data against the spherical harmonic function over the region R, and then mediated by the inverse of that spatial spectral localization matrix. Matrix. And that's precisely why this sort of an estimate is very hard, because, as I told you, d inverse is difficult to calculate. It leads to ill conditioning. It leads to the need of regularization. But in the Slepkin basis, we are not going to regularize by additional terms. We are going to turn it into the Slepkin basis and truncate. So we'll make a truncated Slepkin expansion estimate, the truncation. Estimate. The truncation will be J here, and the unknown coefficients that we're trying to estimate are going to be S hat. And here, the Slepping functions again, G. So the solution of that problem simply depends on the integration of the data against the Slepping function over the region, multiplied by the inverse eigenvalue, and truncation allows us to stop where the eigenvalue becomes very small. The one slide. The one slide application that we have used that is here. It is back to the example of Greenland, where from the time variable gravity data, as given to us by the gray satellite, we have reconstructed the spatial and time history of the mass loss due to the melting of the ice cap, the ice sheet that is covering Antarctica. On the left is a decade of the mass loss in water equivalent of centimeters lost. Of centimeters lost. Red is bad. The ice is gone. And on the right is the sum over this entire region of interest where you're seeing the seasonal ups and downs in the black line, the error bars in the gray whiskers, and the trend, which is inexorably down. Greenland has been losing over 250 gigatons per year and continues to do so. Finally, Finally, multi-taper spectral estimates. If we want to have or if we only have access to data in the region, and we did a boxcar type of periodic RAM, we'd multiply the data by the spherical harmonic basis function only over the region R, square, sum over the orders, and average over the number of the orders. That would be the spherical equivalent of the periodogram as a spectral density. Of the periodogram as a spectral density estimate. That estimate, just like it is in the time series case, is very biased. The coupling due to the box score extends over the entire band. The variance is poorly behaved. The mean squared error depends again on D, and none of this is pretty. However, here is a spherical equivalent to the Thomson multi-taper estimate. Estimate. Slapkin functions g alpha multiply the data against the spherical harmonic basis function, integrated over the entire area of the sphere, but knowing that the g's concentrate in the region of interest, square, some of the orders average, weight by the concentration ratio, and therefore form an eigenvalue weighted multi-taper estimate of the power that will cause. Of the power that we'll call S hat sub L M T. What this procedure achieves is that if you select a small bandwidth over which you try to confidently extract power, then you construct these selecting functions to a smaller L, and you'll have access to about n of them that will be good in the region of interest. That is the only free parameter in this problem that you choose. That you choose. You choose your spectral bandwidth, and then you're stuck with the number of functions with their right eigenvalues, and so on. That is the effective dimension of the problem at hand. So this L dictates the bias. If you make it larger, you will get more tapers. You will get more bias, but you get more tapers. So you have more to average and you have a lower estimation variance. We are showing that. We are showing that the covariance matrix between the tapers up until about the Shannon number is approximately diagonal, approximately uncorrelated outside the band negative L to L. And so the good old procedure of forming a weighted average of estimates made by a single taper with a weight, which here we have taken to be the eigenvalue of those tapers, will give you an intentionally biased spectral estimate, but with Highest spectral estimate, but with a dramatically reduced estimation variance. Here's an example for cosmology. Follow any of the plots. You'll see the black line is a theoretical spectrum. The gray curves are instrumental noise. And if you select a bandwidth, say L equals 30, then you will have exactly uncorrelated spectra every 60. Every 60 apart. And the wider you make it, the lower the estimation variance. But of course, the more bias you deliberately introduce. And so that's the space in which you can navigate the multi-paper estimate on the sphere. We have expressions, exact expressions and approximate expressions and asymptotic expressions for the bias. The important thing here is that it's exactly vanishing outside. Exactly vanishing outside a finite coupling bandwidth by the choice of a band-limited slapping function. These symbols here are Wigner 3J symbols, which are things that we know how to compute. The variance, slightly uglier expression, what we should take away from it is that the multi-taper variance, so the variance of the estimate between two different Between two different degrees, when implemented exactly in the way that I've shown you, is dependent, unlike the bias, which I just showed you. The variance is still dependent on the shape of the region of interest, and that's encoded here by B sub E, which is the power of the equivalent box scar that encodes for the region. And the rest are sums and things that we can calculate following rules, recursion relation. Recursion relation, and so on. It's not pretty, but we can compute it. Here's a set of computations for particular opening angles, theta, theta, theta here, of these double caps. And you see that in the asymptotic regime of large enough Shannon number, which here is k as opposed to the n that I've been using, you're seeing that with every additional paper that you use, you're getting an almost one over the number reduction. Almost one over the number reduction in estimation variance. And so you achieve the square root of n reduction of estimation error. That is the hallmark of multi-taper estimates. Quick example for geomagnetic applications. This is a map, again, of a different rendition of a geomagnetic lithospheric field. Your eyes pick out that the continents have a very different spectral signature than the oceans. Spectral signature than the oceans. And if we want to study those individually, we will have to implement a multi-taper spectral density estimate. Here's a quick result. The whole sphere estimate is on the top. The all continent versus all ocean estimates are in the middle and the bottom panels, respectively. And then those are the things that we study in geophysics. What are the rates? What are the decays? What are the spectral signatures? Are the spectral signatures, and what does that allow us to tell us about the geology of these regions? So, in conclusion, Slepping functions are spectrally and spatially concentrated basis functions. They're a doubly orthogonal basis on the sphere, the entire sphere, and on any portion of it for which they're constructed. They are an ideal basis to separate signal to noise, to do approximation problems, and to do linear inverse problems, some of which I've shown you. Some of which I've shown you, and they're really good data windows for spectral analysis in the traditional multi-taper Thompson-Slepian sense. So the Slepian multi-taper method yields a smooth and intentionally biased estimate of the spectrum. But if we compare to other methods, which I haven't shown here, it requires no iteration, no large-scale matrix inversion, none of that. Once you have the functions, you apply them, you weight them, and you have the spectral density estimate. Have a spectral density estimate that is biased according to your choice. And then, with that choice, comes a reduction of variance, and that leads to a very efficient estimate of the power spectral density. The only parameter that we need to specify and be aware of is that famous Shannon number, the area bandwidth product, which is ultimately given by the bandwidth of the spectrum that we're Bandwidth of the spectrum that we're trying to concentrate in, and the region, the size of the region, and the shape of the region that is forming our area of interest. Thank you very much.