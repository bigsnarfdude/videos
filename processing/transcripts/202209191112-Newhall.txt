I'm very sad to not be there in person. I was supposed to be, and then a week and a half ago, I got COVID. And while I feel a lot better, I'm still not 100%. So, but glad that I can still share this work with you. So, before I start telling you about the story I wanted to tell you today, I just wanted to give some of an overview of the different projects I work on. I just get excited by every new stochastic system that I see, and I Every new stochastic system that I see, and I have to work on all of them. And the theme with my work is trying to take an advantage of an energy landscape. So I also look at a specific active matter swimming droplet system, but one where the droplets leak oil and then respond to the concentration gradient of that oil. And so there's an energy landscape that changes with time. Landscape that changes with time, and the system is always sliding down. There's a spatially extended magnetic system where you have correlated noise between the spins and also this confining geometry because you're talking about vectors that interact with each other instead of particles that interact with each other. And so you're doing that with an energy function and the constraints of physics of trying to make models that take all these things into account. That takes all these things into account. And then Karen already mentioned that we are collaborating on things. So, looking at the interactions of these granular particles and trying to think about how the system moves between states as a transition on an energy landscape for one-day systems and trying to do that. So, those are the things I'm not going to tell you about today. Of things I'm not going to tell you about today. Oh, wait, there's a movie. The little guys swim around, okay? So you can see them modifying. But what I want to talk to you today is a story about the structure of chromosomes inside of yeast nucleus. So on the right, you see some microscope images from Carrie Bloom's lab at UNC. And if you sneak your eyes at it, And if you squint your eyes at it, you can see that there's sort of these brighter patches and duller patches. And they said, oh, there's these clusters that are forming where the chromosomes are sort of clumping up into these blobs to give that structure. So on the left here, instead of having just a bowl of wet noodles of all these chromosomes together, there's some structure on top of that. And so, Carrie Bloom and Greg Forrest and his group have been working on this and developing large-scale models for these chromosomes. So treating the chromosomes like a polymer string, so this floppy wet noodle, and the model for polymers. So the chromosome is being modeled as a polymer, the polymer is being modeled by a bunch of bees held together. Being wobbled by a bunch of beads held together by springs with various forces tuned so that they act like the chromosome and not like polymers in some other swap matter field. So there's springs connecting the beads together. They have this excluded volume force where the beads want to push each other away because they represent. To push each other away because they represent, each bead represents sort of like a tangled mass of yarn. And so then it also has this property that the loose balls of yarn don't want to interact, but if you really push them together and get them on top of each other, they'll intertwine and then they're happy to sit on top of each other. So that's why they excluded volume force goes to zero as the distance goes to zero. Some confinement to keep them inside the nucleus and To keep them inside the nucleus and some thermal noise to keep them all bouncing around. And so, what Greg Forrest and his group found with this large-scale model was that this additional stochastic binding force between beads. So now imagine each bead has one hand sticking out, and if it gets near someone, it can shake hands with another bead and form this pairwise bond, and then at some point break and then go for extra. Point break and then go grab somebody else's hand, that that forcing was able to produce clusters in these simulations. So now you're seeing three plots at three different time scales of this stochastic binding force. So on the far left, you have a very fast binding force. It forms these clusters. It forms these clusters, so each cluster has been given its own color. And so you get these very rigid structures that don't really change over time, but clusters just sort of jiggle around because of the thermal noise. And if you go all the way over to the right, now you've got very slow winding. So you grab somebody's hand and you just hold on for forever. And so what you end up with is basically no structure at all. You just have a bunch of pairs. Structure at all. You just have a bunch of pairs of beads floating around, or a bunch of single beads floating around because they're not bound to anyone. And in the middle here, this is where you have both structure and you have changes between states. And so in this domestic world, we would call that metastability. And I looked at this and said, wow, that's exactly what would happen if you had your hand on the temperature knob. Hand on the temperature knob of an energy landscape. If you were at on the left, low temperature or a high energy barrier, you would be stuck and you wouldn't be able to visit other states of your system. And if you were at a really high temperature or you have a really low barrier, you would just fly all around the system and there'd be no structure at all. You'd just visit everywhere. And it's only in this sort of middle region where you have enough noise that sometimes you can overcome the energy. That sometimes you can overcome the energy barrier between different states, but you don't do it all the time, that you have this metastable configuration. So this is where I jumped into the project and said, great, can we do that? Can we find a way to map this time scale to either a temperature or an affected landscape? How do I take this stochastic force and explain it? Force and explain what's going on. So let me tell you a little bit about the classic picture of this. So the classic picture is you have a system that has an energy, u of x in this case. The system likes to go downhill, so you follow the gradient of u of x, and you add some thermal noise to it. And over time, this system will sample thermal equilibrium. sample thermal equilibrium. So the Gibbs distribution, e to the minus your energy function divided by your temperature. Epsilon in mass speak, KDT in physics speak. And so when that temperature is small relative to the energy barrier, that's when you get these metastable states. And so the bottom picture on the right shows you what I'm thinking of when I say metastable. Thinking of when I say metastable, there's a lot of fluctuations about a small region of your space, so a lot of fluctuations about one, and then there's this fast transition to some entirely different state of your system. And so on the right, I'm just showing you this probability distribution relative to the energy for this system. So this is the framework that I want to try to take the chromosome model. The chromosome model, I want to kind of shove it into this framework, but I've got these two pieces of noise. So there's the thermal noise, but there's also this other non-gradient force that's the stochastic binding that the pairs of beads are changing. Okay, so the first step in doing this is taking a large-scale computational model that had like 398 beads and everything and trying to strip it down to. And trying to strip it down to the most minimal model that still has the clustering behavior that we're trying to analyze. So three beads. So you could have two beads in a cluster, one bead not in a cluster, and one bead can leave that cluster and go join the other bead and switch between clusters. Any fewer beads you wouldn't be able to have switching between clusters. So we have three beads. We took out the springs. We took out the springs between the beads, so it's no longer a polymer, it's just free beads. And in like a confining well instead of a hard walled container, just because that's easier to deal with mathematically, doesn't really change the behavior of the system, and describing these stochastic switching forces by the state of a Markov chain. So the state Chain. So the states of the Markov chain enumerate which bead is bound to which other bead. So for three beads, you have four possibilities, nobody's bound, and then each of the three pairwise bounds. And those form relative to how close the beads are to each other. So if you're close, if the beads are close, they're more likely to bind. If they're far away, they're less likely to bind. And then the bonds all break at the same rate. And so I've highlighted that this switching matrix gets scaled by epsilon, by the temperature, by the same scaling of the thermal noise. And so that'll be comparing why that choice was made in the next slide. But that's preparing to take a limit as that one goes to its growth. So at the bottom, this just demonstrates that this system has That this system has clusters and has clusters that look metastable. So, on the left, you see the bead positions. So, the pink and the blue bead are in a cluster for a while, and then it switches, and the green and the blue bead are in a cluster for a while. And that's what it, the ven stability is easier to see if you plot the pairwise distance, which is the middle plot. And so, the different colors along the bottom, this is which pair is smaller. Which pair is small, so which two beads are close to each other, and then the other two pairwise distances are large. So you can see a switch from the red to the yellow, and so that's from the pink and the blue bead being the close ones to the green and the blue bead being the close ones. So we have metastability. Great. So, you know, trying to shove all of the mathematics of how you analyze. The mathematics of how you analyze this into one slide, I'm trying to force the system into this thermal equilibrium that I had a couple slides ago, this e to the minus energy barrier, or energy function divided by epsilon, the temperature. But now instead of a true energy, it's going to be a quasi-energy, an effective energy, or the quasi-potential W. So on So I want that to be the steady state of this system, so I have to write down an equation for that steady state that combines the Falmer-Planck equation that you would write down if you had just a set of SDEs with thermal noise. But I don't just have a set of SDEs with thermal noise. I also have this stochastically switching force. So I would write down switching matrix times probability vector if I just had a computer. Times probability vector, if I just had a continuous time off chain. And so both of these things together appear in the equations. And so, really, the box equations in the top here are really a set of four coupled equations for the four different states that the Markov chain can be in. So, I'm trying to find a solution to that whole system that looks like this. That looks like this exponential minus one over epsilon w with a pre-factor out front that superimposes these different states so that I have this vector solution to my set of equations. Great, and so here's where that scaling becomes important. So that one over epsilon scaling on the switching matrix, that goes and makes sure that both of these sources of noise, the These sources of noise, the thermal noise and the switching noise, interact in the highest order as epsilon goes to zero. So you end up with a big matrix equation. This matrix M times the vector R is equal to zero. And inside of that is the gradient of this quasi-potential. So that's what you're trying to solve for this quasi-potential. And the pre-factor that super. And the pre-factor that superimposes the different states. So that's fine. I could go and I could just discretize all of space, every single position that the beads could be in, and I could solve for a gradient of W everywhere. But that's a lot of nonlinear solves that I have to do. I don't really need to know W everywhere. I want to know what's that energy barrier between the different states and what's the energy minimizer. And in this case, And in this case, replace energy with quasi-potential. So I really only need to find the gradient of the quasipotential along the path that takes me from one minimum state to the transition or saddle point, if this was an energy function, and then over to a new energy minimizing state. So that's where this thing called the string method can come in to help. So this is a draw. Drawn for a two-dimensional arbitrary system just to illustrate what's happening. And so you're discretizing a path into a bunch of points. That's what all the white dots are. And you're going to iterate and move these points to try to get them to line up with the so that this path is parallel to the gradient of the system. So lots of math that I'm not telling you about. Lots of math that I'm not telling you about, and like why is that the path? Maybe just intuitively, this is like the most efficient way to get up the mountain. It is just always, always climb uphill in the steepest direction. That's going to be the fastest way to get up the mountain. So that's the way that the system is going to escape. So if you know the energy, you can just move the points along the gradient, redistribute the points as you do that, and they end up converting. And they end up converging to this minimum energy path that takes you between minimums. So, what happens here is we don't know the energy because we don't know the quasi-potential. We also don't know the path. So, we have to solve for the path and the quasipotential together, you know, back and forth, back and forth. So, take an initial guess for the path, look for the quasi-potential along the path, update the path based on the quasi-potential, find the quasi-potential along the new path, go back and forth. Potential along the new path, go back and forth. Entire PhD thesis worth of computational challenges in doing that, but at the end of the day you can. So here's a couple of examples. So what you end up finding is exactly what you had hoped for, is that minimizers of the blending potential are a 3B cluster and the 2B clusters. And the two beat clusters, so great. This platinum potential predicts the states that looked like they were metastable in the simulations. I had shown you mainly the 2B cluster states because we tuned all the parameters so that we saw that most of the time. So that's what we're trying to explain, was how I switched between different 2B clusters. And then I can find these transition paths. So the upper left plot. The upper left plot, you start in the triangle configuration and you move until you see the black circle. That's the configuration that's shown in the orange diamond. That's the transition point. And then the bottom plot shows the quasi-potential along that portion of the path. The top plot continues on to show that after you go through the saddle point, you would continue to the 2B cluster. So you can have transition from a triangle. You're going to transition from a triangle, a 3B cluster to a 2B cluster. And then the plot on the right is a 2B cluster to the saddle point. If you were to keep going, then you would end up in the 2B cluster where the pink and the blue bead were near each other. So to validate if we have, like, is this actually the right framework? Like, have we gotten the quasi-material? Framework: Like, have we gotten the quasi-potential that's actually useful to us? Um, is to compare what the quasi-potential is going to predict about the transition times to the numerical simulations of the system. Because I could do other things to average out the stochastic noise of the winding. And so, this is what I'm showing you here in the top plot, that quasi-potential barrier. That quasi-potential barrier from the previous slide, that's the black line at the bottom of the plot with the energy barrier. And the dashed line is a different averaging that I could do. I could say, great, let me take the switching noise to zero first and just replace the switching noise with just one deterministic force, and then only consider the effect of the thermal noise in getting over that effective barrier. And so that gives you a barrier that's much higher. Barrier that's much higher than this quasi-potential approach that is taking into account both sources of noise at the same time. And so it's that quasi-potential barrier height that correctly predicts the scaling of the numerical simulations. So the average time that you're spending in one state is proportional to the plus potential barrier divided by epsilon or the temperature of the system. Of the temperature of the system. So the intuitive picture you can have is that imagine you had an infinitely tall wall that was sometimes there and sometimes not there. And so if you took this sort of average of that switching to zero first, you would take, okay, the fraction of time that's on times the height of the wall, I still have an infinitely high wall. Wall, I still have an infinitely high wall, I'm never going to leave the room. But if you consider the fact that, oh, okay, well, sometimes the wall is there, and sometimes the wall is not there, and while the wall is not there, I'm going to diffuse across the wall and escape. You're using the noise and the switching force sort of together with your thermal noise to get out, and so it's easier to escape than if you just averaged over the switching, this wall between it. Of this wall coming in impact. So that's what I find really interesting when you think about this and the implications it has for biology. That, you know, we've sort of been brought up to think of biology as, at least when I was in high school, taught as like deterministically this is what happens, right? There's like an ion pump, and the ion pump is like a marching thing pushing ions out of the membrane where the little molecular The membrane, where the little molecular motor keeps just like walking down, walking down the tubular. And so you always have this picture of noise is getting in the way, and biology is doing something to suppress that noise and make the system function appropriately. And what the mathematics here is saying is that to get this kind of flexible structure where different parts of the system are Flexible structure where different parts of the genome are going to be accessible at different times because it's always going to be fluctuating around as to which beads are on sort of the outsides of clusters and so which part of the chromosome is going to be accessible, is that it's taking advantage of the noise and using the noise to help the system do things. And to me that's exciting and a different sort of picture of biology and how the systems are. Biology and health and systems are working. So, the last slide, I just want to bring us back to the beginning of the talk, which I said, oh, these pictures from the large scale simulation look like somebody had their hand on a temperature knob and was turning the temperature higher and lower while turning the time scale lower and higher. So, you can go back to the switching matrix and put a parameter out. switching matrix and put a parameter alpha on the switching matrix. So you're taking epsilon to zero simultaneously. You're taking these two noises to zero simultaneously, but you're changing sort of the relative size of them. So this alpha lets you make the switching sort of a little bit faster, a little bit slower, even though in the limit they're both going to zero. And so as you change that alpha, what you see on the plot is that that changes the energy barrier. The energy barrier. So that the slower binding you see a lower energy barrier. And so that means that there's going to be more mixing of the system, which was like the middle picture from way back at the beginning of the talk. And then as you make that binding faster and faster, you approach this, taking the switching to zero fast, you make the energy barrier higher, and so you get more solid plastic. And so, you get more solid clusters. So, this framework is also able to tell you that: that as you change the time scale, you are, in fact, changing this effective energy barrier and explaining the different simulations in the sort of full large-scale model. And so, in that way, telling you maybe an optimal winding speed to make these clusters that are also then able to mix. To mix. Great. So there was some fun with stochastics. Able to predict the three different pictures. When you have clusters, you can explain their lifetime with this quasi-potential framework. And if you make the binding too slow, then Then you don't have a lot of binding happening over the lifetime of a cluster. And so you don't really have clusters anymore. That falls outside of this framework. Great, and I think I didn't take up too much of everyone's lunchtime with all of that. So I'll just thank, I mentioned them while talking, Greg and Carrie Bloom, who sort of started this project and was. This project and was their work that inspired me to join. Ben Walker, who's my graduate student, graduate now, did most of the work, and Anna is thinking about where he left off to think more about these changing time scales and mapping out the sort of, I'll end by saying the word network because that's what we saw at the end of Daphne's talk and what Karen's talk was all about, that there's a network of which minimums are connected to which stats. Which minimums are connected to which saddles, to which other saddles, to which other minimums, and to try to explain more than just this one transition, but the sort of whole set of transitions that you'll see. Thanks. Thank you, Katie. Maybe now we'll start with questions online. I don't think there are any questions online. Okay. Any questions from the audience? Nora? So I really like the idea that noise can be beneficial in biological systems rather than something we have to try to mitigate. So how much do you think our How much do you think our interpretation of a lot of these biological systems, like do you think we've been thinking about it wrong this whole time, you know, when everyone has been posing these ideas of, you know, we have to try to minimize the noise rather than use it? I think, I mean, we can't be completely wrong on everything because, you know, people before us have been able to explain a lot. Before us, have been able to explain a lot by either not considering the ways at all or like the ion pumps, I think people consider them as a Markov chain, and then, great, then we average over the Markov chain, and this explains what's happening. So I think that, like, it's more It's more an avenue forward-looking rather than back-looking. Like the things that we don't understand, maybe it's because we don't understand how the noise is helping the system. Like, if we try to do a deterministic picture, we weren't able to understand why the system was behaving the way it was, and so we moved on to something else to try to understand something else. So, I guess I would see it that way as maybe not that we got things wrong. Maybe not that we got things wrong, but the things that we don't understand, this might be a way to think about them so that we can understand them. One more question? Yes, hi. It was really a neat and wonderful talk. Great to hear you. I was just wondering if this whole idea of using the noise in a positive manner has it something to do with the idea of deriving. Of deriving order from disordered systems or something like that, because I think in the condensed matter physics, that comes as an advantage in this respect. It very well could be. For this particular system, the way I see the switching force working is I like cat. I like cats, so I think of it as herding kittens. So, if you imagine they had a bunch of, if you had like eight kittens around you and you were trying to keep them in your lap, if you picked up one cat and put it in your lap and held it, it would be there, but all the other cats would run away and you'd only be left holding one cat. But if you very quickly were like pulling a cat in and pulling another cat in and pulling another cat in, going back to the first cat and pulling that in, you could keep all the cats in a relatively small area around you. Area around you. So that's how I see the stochastic force working. And so, like, yeah, how do you call that? Is that, oh, I have this stochastic force and there's a deterministic part of it plus some fluctuations, and it's that deterministic part that's like that's an effective, attractive force that's pulling everything in. Or should you look at it as you mentioned, you look at it as you mentioned of um yeah like or order out of disorder so in those other in in in those other systems are it the the disorder that's there or like order despite disorder I don't know that I have a solid answer for you but it but it would be interesting to sort of yeah to zoom out and ask your To zoom out and ask yourself, okay.