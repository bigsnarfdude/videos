So, thank you very much, everyone, for being here for the afternoon session. Today, we're going to have a panel discussion with three experts and users of data analysis and artificial intelligence. And I hope that you'll find this interesting and also to see the state of the art of applications in Mexico. And I would just like to briefly present. And I would just like to briefly present Dr. Ayalbi Itsel Valdeiras. She has worked in laboratories of scientific research in UNAM in Mexico City, and she is a National System of Researchers NI Level 1 researcher, and she's currently working at the Instituto Nacional de Informal Respiratorias. And Eduardo Lises Moya, he is the Director of Artificial Intelligence for the State. Director of Artificial Intelligence for the State of Jalisco. And he has a PhD from Simbestab, and he has done research states in La Rochelle. He has a medical physics degree from UNAM and a physics degree from Universidad de Guadalajara. And he also has experience working with supercomputing laboratories in specifically in the Barcelona Supercomputing Center. And last but not least, we're very happy to have Paola Villarrel here as well. And she Well, and she is, you know, a full stack developer. She has contributed a lot to different aspects of not just data analysis, but how data can affect lives in Mexico. She is a former head of data science and engineering at the CONACIT, which is the National Council for Science and Technology. And she also helped coordinate the COVID-19 data efforts. And she's been recognized as an MIT innovator under 35. Innovators under 35 for Latin America and a BBC 100 Inspiring Women. And she's also been awarded a fellowship at the Berkman Klein Center for Internet and Society at Harvard University. So welcome to the three panelists. Thank you very much for agreeing to come here today and sharing your experiences and your work. And hopefully people are watching either live or they can see the. Either live or they can see this later on. And Yalbi is going to coordinate this. And we want this to be a conversation. So you can also feel free to ask questions along if you want to. Yelby, thank you. All right. Well, maybe I don't know if I can start talking about what I think about intelligent, well, about data science. Well, about data science or AI health in Mexico, but also I would like to ask some questions for the other people that is going to talk today. So, well, like an introduction, I would like to tell you that we are now living this big data revolution. So, well, in my case, I am just working in the government, in a hospital, an institute of the respiratory disease. Of the respiratory diseases. So, we, well, with the pandemic, we have noticed that there is this important and need to, we need to change this digital transformation because, well, not only in Mexico, but in general, in Latin America countries, we don't have all the data as we would like to have. Well, digital to Well, digital to make the proper analysis and help. However, there is a lot of work in all the world. There are a lot of technology that can help us to go into this transition. So, well, for example, in health, we would like to make analysis, for example, descriptive analysis for diagnostic, predictive analysis, prescriptive. So we have a lot of So, we have a lot of data. We can use smartwatches, we can use biometric data, financial data, medical data, also all these scientific data. And well, if we want to prevent diseases, taking out all the information that we already have about physical activity, biopsies, and more recently, this is the omics technology that is going to go to the personalized medicine. Analyze medicine. All that kind of information can help us to build a model and then predict diseases. In other countries, for example, in UK, there are like big biobanks where they have a lot of information about individuals, for example, the genomics information. And other countries like the US, there are a lot of research programs where people are taking all. Is taking all the genomic information of the individuals and they are also collecting, for example, using real-time monitoring to make quick diagnosis or predictive analysis. So this is very important that in our country, for example, well, here in Mexico, that we can make this transition to collect data, to organize. However, what we have seen is uh what we have seen is that we need uh financial uh help from the government or or enterprises because well we need to implement all the infrastructure and well we need also a qualified specialist to analyze the data to collect and also all the the medical people need to be People need to be involved to learn about these new methods for analyze data. So it is important to include some kind of interoperability to share data between the same institution, between other institutions of the same country, also between countries. And that means that we need some new laws. Some new laws. We don't have laws for safety to secure all the data. And in other countries, for example, in Israel, they also have like a software like the diagnostics robotics where they can analyze alone all the clinical experience to diagnose diseases, predict risk, offer solutions and treatments. And here in Mexico, we don't have that kind of technology. Have that kind of technology. We don't have even all the medical coverts that we want for all the people living here. So it is hard to believe, but yeah, we are working in paper. So I would like to start telling you about this and about my work. For example, I am a bioinformatician. So I am including this some. Some classical bioinformatics using statistical methods analyzing omics data. I am working, like, for example, in transcriptomics, that is a very specific field. But right now, in fact, I am also incorporating deep learning methods to predict what a single cell is doing in our body to understand, for example, the lung function, studying some chronic respiratory diseases in idiopathic promotion. Diseases in idiopathic pulmonary fibrosis, that it is a very bad disease, and also in aging. So, also I am working with some collaborators trying to create some models, like three-dimensional models of the organs, like the lungs, and to understand all the functions of the different cells in the lung and under. In the long, and understand what all our genes are doing cell by cell. So, this is a hard work and it is new. And well, I would like to ask all the people here, what do you think about intelligence, artificial intelligence at your work, in your daily life, even? If you also know some stories of success. Also, know some stories of success in your field, or even if you know about some stories here in Mexico, how do you think that this is going to change our world in the future? I can start anyone. No one else wants. Well, thank you for inviting me. For inviting me. My name is Pablo Vidarrella, and as Pablo mentioned, I used to be the coordinator for data science and engineering at Mexico's National Council for Science and Technology. And while working there, I witnessed precisely what Jalbi mentioned, right? Like there's a lot of science going on. But what I also realized was that Realized was that we were lacking a systemic view to better optimize the impact for all the amazing science that happens in Mexico. So, especially in fields like artificial intelligence, where there's a lot of innovation going on, I think that we really need to. I think that we really need to start thinking from the bottom up. I have the sense that right now we are working on solutions because we can, because we have the technical abilities and we have data that we can exploit using algorithms. But we need to connect those technological solutions to problems that are faced in the country, right? So one of the things that we did on CONACID was the COSITA Nacional Informatico, which translates to National Informatics Ecosystem of Health that was That was a hybrid between a repository, yeah, a data repository, but also like an academic repository and also a collaborative group where a lot of analysis and a lot of research projects happen. But they were all focused on what we were. What we were facing at that moment, right? That which was COVID-19. So, what we did was to call for collaborators and projects that could answer a very broad but very concrete question at the same time, which is what can we do to... can we we do to help the government to face the pandemic using data science so we got 75 or so proposals and we filtered those that were not immediately impactful and that that were not trying to answer like an aspect Like on a specific question for this pandemic, right? So we stayed with almost 12 or 15 projects that ranged from predictive analysis, projections, and which they were super impactful in the decision-making process. Definitely the Under Secretary of Health used the projections used by or produced by this team to make logistical decisions. For instance, where to put respirators, where to move hospital beds and doctors and prevent governments or local governments. Local governments on where and when the pandemic was going to hit them the worst. So, in that aspect, that algorithm, or well, that project helped save lives, right? So, those are the projects that we wanted to produce, and that I feel were were needed at the moment. And this also taught me that one of the best ways to produce and to fund science or scientific research and innovation is to connect it to real world problems. And I think some in some cases, especially in technology, like in In technology, like in artificial intelligence, machine learning, deep learning, we have the solution, but we don't have the problem. And that's one thing. And one way, like, I'm critical of those technologies. I do them in my everyday work, but I think that for the most part, there's a gap between There's a gap between the solution and the problem. And one way to solve this is to be more collaborative and to form multidisciplinary, multi-institutional teams that can collaborate with data. So I agree with Yalbi when she mentioned. With Yalbi, when she mentioned interoperability, which I think is key for this. But we also need to include other professionals, not only, for instance, in the case of health, not only medical professionals, but also social workers, anthropologists, lawyers, and all these types of professions that Of professions that perhaps are not like it is not it is not super intuitive to invite them, but in my experience, they provide super good perspectives that can be then implemented in algorithms and systems. So I think that's that's kind of like my message is that we need to be more collaborative and multidisciplinary and in many in many axes and in many. Access and in many ways, so yeah, that's my experience. Thank you. Okay, so if I remember, the question was about our experience in artificial intelligence. Jelvil? So, yes, we work in the Jalisco government with With artificial intelligence and some techniques of data science. We use mostly deep learning for we say to repetitive task for a kind of automatization of some task. Let me put some examples first. Here in Jalisco, there is a Here in Jalisco, there is a park called Aguasul, and there is a big avenue in the middle of the park. And somebody asked if they can close this avenue and join together these both sides of the park. To do that, they need to know how many cars. Any cars pass near to this area, near to this zone. And one way to do that is, for instance, take a lot of, I don't know, yes, people to count visually how many cars pass from this area. In every corner, you have to put one and count. But instead of do that, they use the They use these cameras for security and traffic cameras. And we take these videos and we develop a solution in order to count the cars. Yes. The main problem was related with the park. Yes, this is a big decision. This decision has to is Is more for humans, but the simple task to count these cards, we can make a kind of system to do that. So, this is an example that we use to do that. I want to highlight something because here's a lot of mathematicians and physicists, and some sometimes they ask about, okay, Ask about okay. I work in this, perhaps, how can I apply this? I don't know, I am a physicist, I always think about in this way. And I believe that this kind of workshops or of congress could help us to understand the limits, for instance, of deep learning. Yes. Of deep learning. Yes. As Paola said, deep learning is not perfect. They have some limits. And usually when you train this technique with some kind of data and test with another distribution of data, your model usually fails. So in my experience, So in my experience, some geometry techniques could help to make more robust deep learning. Yes, this is an open research area. We only use the deep learning, but it's important to understand the limits in order to. The limits in order to avoid big mistakes with the technology. And this is my example and one comment I have to do because I feel really great to be here in this conference and I want to link my work with this conference. With this conference but in uh using disconnect. So, this is very interesting. I would like to comment about what Paola said: that we need to collaborate, make teams, make that other professional. Make that other professionals being included in what we are doing. For example, Eduardo, you are telling us that there are some, for example, these people working with math, how a geometry can be applied. So do you really know? I don't know. But for example, yesterday I was looking some of you talking about your projects. You're talking about your projects, and I could see a lot of applications on where you are telling us. Why? Because, well, I am working in other fields, I am a biologist. So, Paola said we need to make these multidisciplinary teams and talk and invite not only this specific group of mathematicians and physics or computational people, but Or computational people, but maybe also invite some kind of people from lawyers. I don't know, try to make maybe a new kind of forum where we can invite other people that maybe we are enough smart to present our results in a not so complicated way, so we can Teach other people that it is from other places what we are doing. Maybe they can see some kind of applications. So, well, what I think is that we need some kind of translators, like people that can speak with experts in some field, and they also can talk with the people that is going to provide us the solutions because we need this. Because we need this kind of medium to ask government or enterprises that, yeah, we need this to some kind of changes in our world. But right now, we don't have this link. So how can we do this is my new question. For example, there are some companies I would like, I don't work for I don't work for IBM, but it's not because my name is like IBM also, but this company, for example, have adopted some kind of projects. For example, in health or other, they have this Watson and the artificial intelligence lab, where they provide some kind of solutions. One is health, but they can do this with other fields. With other fields. And this is very interesting because in the future, we would like to take some kind of decisions using artificial intelligence. And those decisions could be taken in real time. So how can we put all our data ready so all the these systems can just start working the Just start working the algorithms and they can start just giving us solutions quickly. Right? For example, well, right now we had this pandemic. We had to wait two years. We are still doing these conferences using Zoom because all not the people have been vaccinated and although this was pretty fast, it could be faster if we could predict that it was going to be a pandemic since the beginning. Since the beginning. So, what do we need to do to make people talk? What do you think? I don't know if Paula wants to jump here. Sure. Sorry, there's a Um sorry there there's a um band playing like right by me so I apologize for for the music. Um I think one way to to to make people talk um well it it's one of the biggest problems right like uh we as technical people think that we have the solution right and then That we have the solution, right? And by logic, by pure logic, by having a solution, we also think that we understand the problem. But I think that's one of the key errors that we do as technical peoples or technical people. And the reason why is because we are biased, like everyone is biased, right? Like everyone is biased, right? Like, I'm not saying that there are some professions that aren't biased, but I think that everyone is biased and we introduce those biases into what we do. So one way to avoid those biases is by collaborating and having a diverse group of people looking at one problem. People looking at one problem and bringing their own perspectives. So I think that's the main solution. It's hard because, yeah, you need translators, you need people that understand law and code, which is a very rare profile. You need people that understand biology. Biology and medicine, which takes a lot of study. So, yeah, you need to be multi-disciplinary and multi-institutional and you need to really work on laying bridges and to setting common objectives. Sharing common objectives, which I think is the hardest part. And I think these types of efforts should come from governments and bigger institutions like UNAM, but they need to have a systemic perspective. Otherwise, if they only focus on, you know, like the solutionism. Like the solutionism, they are going to spend a lot of money, but all the outcomes are not going to be impactful. So I think, yeah, that's my view on this question. Okay. I could add something. I could add something about that. I could add some experience to that. We make some projects in collaboration with other institutions, for instance, IDB Lab. This is a bank in US for all Latin America. Usually they Borrow money to the governments. And we have a project with Day. This is a big project and we work with a lot of people. And one of the main problems was the communication because when I try to explain something technical, something Something technical, something that I believe that is important. Somebody could don't understand this, and this is very difficult to get a match with the objectives. Perhaps one solution could be work together previously, I mean, have a kind of workshop. Kind of workshop, define the main concept, work in some other cases to see what happened before with some successful example, what happened with not successful example. This is a very important issue and it's very difficult to communicate between To communicate between these different areas. And in my opinion, it could be great if we can start this communication with, for instance, an informal tag, then work together in the basis of the project, and then if we And then, if we have some concept that we understand in almost the same way, we can go to the next level and then work together to get the next object. Yes. In addition, I have I have experience, for instance, with other collaborations. And we had bad experience with some collaborations. I don't want to say the name of the institution, but sometimes they, for instance, when start this topic about the pandemic, they say, okay, we have a team, we can work. Okay, we have a team, we can work together exploring the data, perhaps making a model for COVID-19. And then the next meeting, nobody came. So this is difficult. They need to have some common interest to work together. And this is very important. We need also resources to work together. It's nice to work in a project by law, but some members of the team don't have access, for instance, to computational power, to data. All these things have to be in. In the collaboration. If we want a strong collaboration, we need resources. I need not only money, also infrastructure, as JB said. And why not data and GPUs, a lot of GPUs, these kind of things could be great to make a strong collaboration. Collaboration. Finally, I am working with one mathematician from UNA related with ethical and AI because in the government this is a very important topic. Don't use artificial intelligence to in bad ways, I say, or not ethical applications. And we work very nice because we have Very nice because we have these interests in common, and we are working in a paper, for instance. This is one way that we can work together, learn together, and share experience together. So my abstract on this intervention could be we need common interest to collaborate, resources. Resources and I don't know, um GPUs, I say okay, thank you. Well, I totally agree with you. This is very interesting. This is very interesting because if we don't have resources, we cannot do anything. We not only need data, we need clean data. For example, I had to work at the hospital like three months only cleaning data. And it was like, oh, this is awful. And we need hardware, we need software, infrastructure, people, expert people, money to pay. For people, money to pay those people. But most importantly, what you say, yeah, the common interest because you cannot collaborate with people if you don't have this common interest. So, well, this is very interesting that, well, we know that artificial intelligence accelerates solutions and it can anticipate negative impacts. And well, maybe. And well, maybe we just need to collaborate, develop some kind of policies and all the things that I have already said. But have you seen some problems that we can anticipate that could be related with the use of the artificial intelligence? Well, Eduardo said something about ethics, so this could be another topic that we can talk. Or for example, Or, for example, do we have to work shifting priorities of economic, political, and/or do we have some kind of interest or we must just work like as scientists do, just looking at all the things that we love, and that maybe is going to tell us something in the future. Future. What do you think? Paola, I see you talk, but I'm sorry, I'm sorry. Yeah, I was saying that it's both yes and no, like for some parts of the scientific work. Some parts of the scientific work that are purely scientific. But there comes the time when that work has impact in people's lives, right? Like an algorithm that makes a decision about someone's life about someone's treatment or medical fitness. So when that happens, So when that happens, I think our responsibility as researchers and technicians and technologists is to worry about that and to question that and to work precisely to reduce those biases, reduce the harm our work can influence. Influence to make sure that the application of our work and research is human, right? And we should try to reduce harm. This is also controversial, I know, because a lot of people seem to have the notion that Seem to have the notion that science and technology are unique. But I don't think that's the case. I think that science and technology, as I mentioned before, have the biases from the authors and the scientists and the technologists that produce them. I'm gonna also biases, but also blind spots. Like we cannot, like it is humanly impossible to anticipate all the possible uses our technology could have. So because of that, we need to be humble about it and accept the fact that our technology or our research can have potentially Potentially, or can be potentially harmful, and work to reduce that harm. And one way to do that is, again, collaboration and collaborating diverse groups, because it's not only collaboration between our peers or our cultural identical friends. When I say this, I mean When I say it is, it can mean collaboration between culturally diverse people that can introduce different perspectives and can reduce the blind spots that the application of our technology or science can. So saying that, I think definitely artificial intelligence and machine learning and Agents of machine learning, deep learning can have or can do a lot of hard work. They already don't learn many ways. Like we see examples in the criminal justice system in several different countries, especially in the US, where they use machine learning algorithms to decide people's fate people's fate. So there's an algorithm that decides or measures the risk of someone committing a crime again. And based on that, they decide whether this person should be free or not. So that's a lot of responsibility for an algorithm. And it is very common. It is very common that judges say, Hey, I didn't decide it was the algorithm. So the problem here is that this type of algorithms also reduce accountability of judges and systems. So that's one type of harm. It's already happening. So yeah, I think there's a lot of I think there's a lot of potential plan, but we really, really, really need to be responsible and to think about that as technologists and as scientists. Okay, so let me put Put in this way. Actually, everyone has to be worried about the possible impact of about the research or the things that they do. So this is an ethical aspect for everyone. But in the government, about this panel is more is more important. Is more important to justify why we need to use artificial intelligence. What happens if we substitute some people in the government? Why? Because they have rights. These kind of things is a big issue in the government. So the ethical part is not. the the ethical part is not a simple task is a um it's a task uh that begins in the planning of of the of the project or then continues in the problem understanding in the data cleaning in the data pipeline then in the modeling and the deployment and the verification in every And the verification in every stage of the that call artificial intelligence life cycle, you have to keep in mind this possible risk to this. So, in the government, it's very important to take this. Perhaps you already hear some. already hear some models, some research from Timit, from actually she was in Google and they make a research about the bias in several face recognition models about the color scheme and these kind of things. And this is true because in this case the CNN case the cnn wants all the features they decide which features are more important in the face and if the these models the convolutional neural networks decides that the skin is most important that the nose or the shape of the eyes or something like that of course they they they could have a bias but the problem this is important because uh This is important because in this case, a mathematician could help a lot. It's not only about the data, the data, because you say, okay, you need more people with other kind of skin and the problem is solved. Yes, could be a solution. But there is another way to solve the problem. Looking for other features that don't look for the scale. Look for the skin, the skin color, for instance. Make sure of that. So I saw some research related with that, with these properties looking for make more robust the CNNs. And could be great to have a solution from these teams of research. These teams of research and then apply in the government or in the industry this kind of solution. They also use these kind of techniques of equivariance, invariance, CNNs to certain transformations. And these techniques could help to reduce this risk of This risk to have these kind of biases. So let me put an example of the convolutional neural network. If you use this kind of tool for images, for 2D images, you can almost have an equivariance. Almost have an equivariance property to translation. You have a CNN to classify cats and dogs, and you have a cat and then translate a little bit the cat, the CNN usually don't have a problem with that. But what happened with the rotation? What happened with the skew? What happened with another geometric transformation for the CNN? They don't work well with these kind of transformations. Work well with this kind of transformation, they need to see more examples, or they call this technique data augmentation, or make a different kind of CNN that can handle this transformation more in a best way. I have to say. So, there is, of course, a human part, and because we are in this conference, I have in this conference i have i want to highlight that in in the this these um tools could be improved uh actually by mathematicians like like this group to help us to avoid this bias in the artificial intelligence well this is uh very important Very important. So we need to know that algorithms are not neutral. They can replicate, reinforce bias and misinformation. So they can have some kind of problems. So, well, maybe one question would be if put some kind of the bias, the bias could be the solution. Could be the solution for artificial intelligence. Yeah, there could be some kind of deviasing approaches to avoid discrimination and structural inequalities. So I understand, well, you told, I don't remember if it was Paola or Eduardo, but you said, be worried about your research. Yeah, we should be worried. Because, well, we don't know some systems. Well, we don't know. Some systems just simply could have some kind of these biases and they must not be used because they could violate some human rights. So, well, I would like to end this part of my questions. I don't know if Pablo also have some kind of questions or maybe the audience. But I don't know if you want to discuss some kind of topics. Discuss some kind of topics. But what I, my conclusion would be that people here, mathematicians, you have a lot of power generated of all of these models. Please try to think about these ethics, these things, how if you can produce some kind of solutions, you can benefit the humanity. So, thank you for doing your job. I think. I think this has been very interesting to hear all of your perspectives, and I thank you preemptively. But I would also like to maybe invite anyone else who's in the audience who wants to ask Yalbi, Ulysses, or Paola any questions or between each other, given your different backgrounds. I think that would be pretty interesting. And otherwise, Yarabi, you have the floor. Yeah, maybe do you want to ask something? We can read your questions at the chat. Thank you. So, if no one wants to ask anything, I would maybe just want to ask one quick question to all of the panelists. What would be your, I don't know. I don't know the one thing that you think that would make research better for these areas in our context, in your experience, very succinct, just like just one idea maybe that you think that we can focus on. Just to end. Well, what I would like is that hospital could have this all these digital transformations. All this digital transformation, so I could access the data, just access. Maybe later I could apply some kind of what kind of obstacles do you think if they were removed? And I understand, you know, that we've been trying to collaborate and like even just accessing the data. Of course. Yes, the first step. I think we need to think in systems. So, but not only from the technical perspective, like in a discipline, but decision makers need to think in terms of citizens and we need to create policies and institutions that. Solutions that take systemic problems into consideration and to create, and they create systemic solutions, right? That way we can prevent solutionism that only solves one specific problem in a very expensive way, but then ignores everything else and cannot be replicated. So we need public policies that think. Policies that I think on the development of scientific research and technological advancement or innovation in a systemic way. So, when you think about that, the problems Yalbi is facing can be solved, right? Because you are thinking Thinking in a broader perspective. And I think that's what we need to really, really change things. Otherwise, we're going to buy hardware, buy software, pay people. It's always rains and routine. What we really want is to work. To the work of everyone, resources that we have, and have a feedback or lasting impact. So I think that that's kind of like my final meeting. And thank you, thank you for inviting me. Okay, quick response will be better than. Better data and better models. We need both because there is a lot of noise in the data and we need to handle this with the models. All right, we have one question, two questions. One is from Guido. One is from Guido. Um, he's, I don't know if I am pronouncing well the name. I hope that it is okay to say Guido. Yes, that sounds good. Okay. Well, you said he said we have new checklists for new RIP submissions, particularly in regards to data ethics. Do you think these are enough? So, particularly, you know, from a perspective of industry. A perspective of industry, let's say that in academia, we have been very, very slow to implement any ethics measures, especially at these big conferences. I mean, it only started with all these big scandals only one, like two years ago or three years ago. But, you know, like even reporting the type of data that is being used and disclosing the sources, that is very new. This was not required in the past. And of course, in the industry, And of course, in the industry, things are different because maybe many times the data is expensive and people put a lot of efforts into collecting it. Also, in other communities, don't get me wrong, like in biology, people will do that in medicine. Maybe people are much more sensitive about what they are doing. But here in this AI, it seems that things are only kind of starting to be developed. And so, you know, how would you, you know, maybe think about this from a perspective of? This is from a perspective of a person coming from industry as opposed to academia. Many times we want to think that academia are the good guys, but I would be curious. Well, I can tell you that in medicine, we have a lot of restrictions about safety because we have personal data from people. However, not all the people that collect data are Are doing, they don't have a lot of, they can have some kind of biases. Of course, sometimes they don't think about whether that other people could need data. So they are just making these repositories or the cohorts, like only with their experimental design in mind, but without thinking beyond that. So, well, that could be a problem. Well, that could be a problem. I don't know if Paola and Eduardo could say something, would like to say. Okay. Yes, I feel this checklist and I don't feel comfortable. I feel weird because I don't know what happens if someone lies about this checklist. I think it's not enough, but put the measures in the conference that you have to ask about these ethical concerns in your work. And it's a It's a good beginning to put this topic in an artificial intelligence conference, but of course is not enough. I saw another tool to handle the ethical part of the work. Usually you have to apply before to a committee and they To a committee and they give you some feedback, this kind of thing. This is very common in medicine, and perhaps we in the future will be very common in artificial intelligence also. So that's my comment. Very briefly, I want to say that it doesn't have to be perfect, but perf needs to be new. An advanced progress towards that. Yeah, mistakes are going to be made. That's natural. But we really need to introduce these types of measurements to prevent biases, other problems like technical technologies. I don't know, there is one last question. Jane, I hope it's Jane. I appreciate that you point out that mathematicians can help make some of these projects a reality. I wanted to also ask about the I wanted to also ask about the flip side of that. Do you have any ideas for what mathematicians can, or perhaps, have the responsibility to do to address the ethically problematic applications of machine learning? Well, yeah, I think there have been a lot of consortiums for people, not only mathematicians, but with different perspectives, they are trying to. They are trying to build this kind of, well, like, not like rules, but like, how to say, like the checklist, that how we can do better algorithms for artificial intelligence. So maybe our responsibility will be to know which are all of these concerns. Which are all of these consortiums and try to be part of them. So we can just know what the proposals are and how we can help them to make new decisions. So what do you think? Yeah, something to comment. Yeah, maybe I think that's that's that's I think that's one good way to put it, but at the same time, I think when you were saying that, I was thinking on the difference between pure science and then practitioners, right? So I think when you become a practitioner, you really, really have a responsibility to be proactive. On your responsibility to safeguard the public from your technology or your research. And there's a lot of work, there's a lot of literature that has been written about this. I will recommend some books. Some books, for instance, weapons of mass destruction by Capionier, but also automated inequality and algorithms of oppression. Then what else? I will check the work of the algorithm justice league, which is led by Joey Roemi. From MIT, and she and this organization is really, really leading the way in this type of work. So, yeah, that would be my recommendations. Okay, so this is a not easy question because the mathematician. The mathematician do that they do they do maths and somebody could use these tools for bath. This is simple. There is a history of one guy who developed this new neural network called YOLO. You only look once. And they say, Okay, this. They say, okay, this neural network is great, and then somebody starts to use this for military applications, and they decide to continue this research about this architecture. So maybe it's impossible to do that to. To prevent what will be the use for the mathematician for the tools. Perhaps this responsibility comes later with the application. I don't know, perhaps you can use this special license for peace and these kind of things. I don't remember the name. Remember the name for your work, and you can use it if you don't agree with this. I don't remember the name of these kind of licenses, but I only see these kind of tools to protect your research. So, maybe this is a good point to stop because we've been carrying on. To stop because we've been carrying on, but I'm really happy in a bittersweet way that we ended up with these topics that really tell us that we should curtail our influence and be very wary about how much harm could be caused by algorithms. And hopefully, we can all kind of reflect on that and understand that this is important. And given the perspective of these people that have been, you know, highly successful in their work, but also have first. Work, but also have first-hand experience of how their work can affect other people's lives and how automating decision-making can have an impact in the health or transportation or well-being or even life and death decisions when it comes to distribution of medical devices. So, I think it's been wonderful to be able to listen to you. You know that I'm very thankful for your presence here, and thank you very much for. And thank you very much for participating in the event. And hopefully, you know, we can continue this conversation some other time in some other format. And thank you very much. Thank you for having us. Bye-bye. Thank you. Bye.