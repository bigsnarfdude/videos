And meet the people and get the society off the ground. I think there's some really exciting possibilities going forward. So glad to really be involved. So I'm going to talk a little bit about just like a connection that I thought, sort of that connects sort of two pretty well-known pieces of mathematical modeling. What I do a lot is the evolution of social behavior and then to connect that to sort of ideas about critical transitions, which folks here might be already familiar with, but I present a little background in case you're not. I present a little background in case you're not. So, lots of, you know, you're familiar with from mathematical models and dynamical systems that systems that are close to sort of a tipping point might be less resilient to change, sort of some kind of perturbation. So what do we mean by tipping point? It's not just sort of an unstable equilibrium in some population, but it's some kind of change in external conditions which might actually change the stability of the equilibrium point or change the way that the equilibrium point. Of the equilibrium point, or change by whether the equilibrium point exists or not. So, these are right, we know these are bifurcations of dynamical systems. So, lots of examples about this in natural sciences. So, of course, climate scientists have long talked about tipping points, critical transitions. So, this is this movie, kind of famous example thinking about this circulation in the North Atlantic of cool, salty water, creating one of these sort of long-term thousand-year ocean circulations that help sort of bring warm water. But it helps sort of bring warm water up to Northern Europe. And if that whole circulation became disrupted, it could change the climate in Northern Europe significantly. And the movie dramatizes very, very much what actually happens there. So sometimes these were actually originally, like in the math community, more thought of as these catastrophic bifurcations. So just a subset of these kinds of bifurcations you get that cause the sort of disappearance of an equilibrium point. So the most common one that folks study, if you haven't seen, Common one that folks study, if you haven't seen this before, they're these so-called fold bifurcations. So you might have some system where you have an equilibrium point, you know, just sort of continuous over your set of conditions, whatever sort of other parameter that you might have in the system. And as you change another parameter, the shape of that curve of equilibria changes until at some point you essentially have sort of S shape, right? And each of, as you imagine changing this parameter on the x-axis, Changing this parameter on the x-axis, say from over here, you could be sort of at this equilibrium point. You could say you've got a lot of pretty large population. Population size is shrinking as you maybe change. This could be temperature or some other environmental variable until at some point you reach this full bifurcation, that whole equilibrium point is eliminated, and the population falls off maybe to this much lower population level, which in some cases could be zero, right? You could end up with extinction occurring there. Occurring there. And then, as well, you get sort of this interesting thing where if you go the other direction, maybe changing from the other temperature high or low or something like that, you might have a low population size and you reach another bifurcation here, and then you might have a critical transition in the other direction. So you get kind of a history-dependent process or this existence of hysteresis. Of course, it's a general property of many dynamical systems. There's nothing particularly biological about it. But what's interesting for folks. But what's interesting for folks as well is how to detect whether these are happening, particularly if they're happening in systems that maybe you don't know what the dynamical equations are for these systems. So some of these attempts to sort of detect critical transitions, try to look for signals of them in the time series data. Some of this is looking at things like, you know, the system state might be sort of, you know, again, chugging along just fine, and then at some point it's going to reach, you know, maybe a shift down low. So you could measure something about what. So, you could measure something about the variance in population size or whatever sort of system state variable you're interested in to see if you're getting close to one of these points where there's going to be a big change. So, some of this intuition is that as, say, for example, this landscape where you're at the stable leak blue green point here, as that landscape is getting closer to the transition to the bifurcation, becomes much shallower here, so little perturbations, little movements, there's less resilience to them. So, that's some sort of motive. Resilience to them. So that some sort of motivates this intuition of variance in something like the population size might be increasing as you get towards one of those critical points. So they measure sort of variance, autocorrelation, mixed time series, those are sort of one of the two very common signals that people try to use to measure critical transitions. This has been applied to definitely a lot of more of the kind of ecosystem, ecosystem modeling, ecosystem ecology literature. So this is, let's see, this first example, this is actually again more specific. This is actually again more specific data from this climate example from looking back 34 million years ago. It's sort of these are ice or sediment core data looking at calcium carbonate in the ocean. And so that's a measure or the density of it in the heated water is a measure of sort of temperature or proxy for temperature because the more it comes out of solution as the water gets cooler. So when it sort of goes up in concentration, that suggests sort of a radical change. Suggests sort of a radical change in the climate to be much colder. So this was sort of an ice age period in time. And looking at something like this autocorrelation is a measure of maybe this critical climate transition. This is an example from a freshwater zooplankton experiment with Daphnia, given sort of a constant rate of food or declining food to sort of when they sort of reach a point where their population starts to crash. And again, measuring something like this coefficient of variation, that you see it sort of to spike is that. That you see a sort of spike is that in the population, the case where they're getting declining the population starts to crash. And this third example is sort of a similar microcyanobacteria example from a lake eutrophication experiment, a similar sort of pattern. Once you sort of enriched the population, sort of given it a case where you think there might be one of these critical transitions, that the standard deviation in this in population size and concentration starts to increase pretty rapidly as you reach some critical transition point. Some critical transition point. Okay, so these tipping points, so that's so that although it's been used very commonly in ecology, hasn't been used so much to think about social behavior and how individuals and social groups might interact and sort of maybe more specifically how might we apply some of those ideas to game theoretic models or to evolutionary game theory models. So, some folks have looked at, you know, try sort of thought about, well, are there cases where we sort of lose cooperation, you know, lose sort of sort of some kind of You know, lose sort of some kind of social behavior very quickly in models, but they haven't actually really found examples much of bifurcations, these sort of full bifurcations coming out. And I think that's actually in part because of the focus on two-player games. So two-player games, you only end up having one possible internal equilibrium. So, you know, if you think of like your normal, they have it on freaks, like your normal prisoner's dilemma example here. Here. In the sort of most simplest kind of like replicator dynamic, you only have one internal equilibrium. So either it's stable and you have some kind of snowdrift game or chicken game, or it's unstable and you have a stag coordination game, or it doesn't exist at all and you're in a prisoner's dilemma game or a mutualism game. But with just one equilibrium, that's not enough to get more complex behavior like this, where you have this full bifurcation occurring. So you need one way to sort of get more complex dynamics. To sort of get more complex dynamics is to increase the number of players in the game so you can start looking at n-player games. And there, so compared to, say, like the payoff matrix we had before, where you've got here you have your focal individual, your partner, if your partner cooperates or defects, and then what you get if you cooperate and defect, given what your partner does. So, in my imagination, there's some benefits, what your partner gets, or you give to your partner if you cooperate and your partner gets to you. If you cooperate and your partner gets to you and you receive if they cooperate, you pay some cost if you cooperate. So that's why the sum I see is in that row, and then the benefit B here if you defect and your partner cooperates, and then you get nothing. So just one parameterization of it. So if you extend that to end players, you can imagine there's some, you have your population, and really you're thinking still about what is the payoff that a cooperator gets compared to what the payoff the collector gets. And then really as a function of how many other cooperators there are in the groups. Cooperators there are in the group set of zero all the way up to n minus one cooperators, given that this other remaining one individual is the focal individual and we're looking at their payoff. So then group size, presumably in this case, should be a crucial factor. So it'd be more thinking then about like how does group size affect, because maybe group size one of those parameters is going to change the stability of a cooperation, generate one of these critical transitions. And so there's been some interesting previous work sort of looking at how complex this Work sort of looking at how complex this equilibrium structure is when you start to expand these games to end players. This is some previous work by Bokali and Tralzen. So we want to start, so I want to sort of suggest that we could start working because I don't have any actual full results here, but I'll sort of suggest why it might be possible. Okay, so one thing that we know is that just even just thinking about group size in general is that groups, increasing group size tends to make cooperation Size tends to make cooperation more difficult to evolve. And this is in part because there tend to be diminishing returns if you sort of have to, for example, here have the group size and then the group productivity. And if you just even assumed a linear relationship between group size and group productivity, you still get a marginal, the marginal benefits. The benefit each individual gets as a function of group size is declining as the group size increases. And then even if you make maybe a more stringent assumption that, say, the group productivity is saturated. Group productivity is saturating as a function of group size, it's even worse, and the marginal productivity is declining even faster. So, this sort of sometimes is called the group size or Olson paradox for collective action is one of the reasons that sort of in simple models, collective action cooperation, is more difficult to evolve in larger groups. And certainly, we see lots of examples of that in our very large world today. As things get bigger, cooperation can be harder. So, here's just one example from the So, here's just one example from the literature. This is on vigilance behavior in birds. So, whether they're making a call or doing some other kind of vigilance behavior to suggest the location of a predator or some kind of other competing type. And this is a meta-analysis of a bunch of studies just showing what that affects this correlation between group size and vigilance behavior is. And lots of these studies have found some significant negative correlation between the two. A negative correlation between the two. Okay. So that suggests in some sense that bigger groups are going to be less resilient. So maybe we can increase group size and some of these models and see the sort of emergence of some of these critical transitions. Okay, so there's kind of maybe even a nice, I'll sort of show a nice mathematical framework for maybe for doing this, and this is actually due to Jorge Pena and Georg Valdecki. And they've had a couple papers in JTP on an JTP on end-player cooperation and n-player groups. And what they make use of a nice result that these models often generate something called the Bernstein polynomial, which is something used in approximation theory and the Bezier curves. So if you're Photoshop or something and draw nice curves and stuff, the Bezier curves are often sort of behind the scenes doing the work for you there. And that because there's very nice properties of Brinstein polynomials, that means there's easy. means there's easy there's easier things to prove about these nth grader games okay so the setup is you have again this this payoff matrix basically a payoff table where you've got you know what is the focal cooperator getting what is the focal is eventually getting uh and so they make sort of some relatively modest assumptions that you know you that you sort of prefer an individual whatever individual's payoff is it's going to be better if there's more cooperators in the group so if There's more cooperators in the group. So if they have a cooperator, they get more payoff if we increase the number of cooperators from k to k plus one. And likewise, if they're a defector, they get more payoff if there's more cooperators. So if we let the frequency of cooperators be x, and there's group sizes sort of in some range, n min and n max, then we just calculate the average payoff to a cooperator. And sort of assuming we're sort of randomly sampling individuals, there's no sort of not meeting or matching or anything like that, but it's just sort of this expression. That, but it's just sort of this expression. And we have a sort of similar expression for how much payoff a defector is getting. And then we basically use that to plug that into a replicator equation and get the following replicator equation, where we have sort of x, 1 minus x, the variance here for cooperator frequency, and then this polynomial here, g n of x, which is given by this expression. And sometimes this is called the gain function, this g n here. Function, this gm here. So it turns out, so then of course, you know, to find the equilibria for this particular model, you want to look for where there are zeros, and then in particular, you also want to look for where there are zeros where they're crossing from above. That means that that equilibrium is going to be stable. And it turns out this gain function, this g n of x, this is a Burns gene polynomial. So there's many of these properties about sort of what its zeros are, and then graphical properties so you can figure out when it's crossing from above, when those equilibrium are stable. Here on our stable. Okay, so in so one of the things that we get from this Bernstein polynomials is that like a change in sign, for example, in the polynomial means that there's going to be the selection pressure on cooperation is going to be reversed from maybe selection for cooperation to selection against or vice versa. And it also means that there's a possibility of having an internal equilibrium. So if we count the number of sign changes in that polynomial, then we get sort of an upper bound essentially on the number of possible internal equilibria in the model. Possible internal equilibrium in the model. So, what you can do, sort of one way to plot this, is imagine just sort of looking at this. This D here now is almost called a, what would we call it? This just says the difference basically between the two payoffs, what a cooperator gets or what a defector gets given this number of other cooperators in the group. So you can sort of plot this, you know, for like zero other cooperators, one other cooperator, et cetera. This is for a group size of seven, I guess it must be. And then this is the game. Must be. And then this is the gain function in blue. And these are just sort of boxes here, just for those individual differences between the payoff of a quark and effector are. So anytime this gain function crosses the zero axis, you have internal equilibrium. And again, if it crosses it from above, that's going to be stable. If it crosses it from below, it's going to be unstable. So you really just got a nice map of what the equilibrium structure is for the game. Okay, so one of the what, so there's So one of the, so there's, now that you've sort of allowed these possible, all these possible, this much more general payoff structure here, it's not now sort of the kinds of games really are, you can get very, any kind of complex mixture in some sense that you want of Prisoner's Dilemma with coordination game, with the Snowdrift game. So, one sort of example that they sort of focused on was looking at something called like a threshold public goods game, sometimes called like Public with its games, sometimes called like a sometimes they call it in-person snowdrift. Although, again, I think applying snowdrift or prisoner's dilemma to any in-person games is always a little tricky, but or sometimes called a volunteer dilemma. So, the idea is for some minimum number of cooperators that are necessary to generate this public good, to generate this benefit. So, we set that minimum number to M, and it generates a public good R. And so, that R is something that everyone has access to equally once it's been generated. To equally, once it's been generated. So you can sort of imagine if there's fewer than m cooperators to the group. So there's like the individual is a cooperator and there's k other cooperators. So there's, and that's less than m minus one. Then the cooperator gets, they basically pay this cost of cooperation and it's spread over all the other individuals who are cooperating. So if there's m individuals cooperating, then that's what they get there, then benefit there, or then they. Then the benefit, or then the individuals who are defecting get nothing, so there's no cooperation generated, but they also don't pay any cost. If they're right at that threshold, then this is, they sort of get the benefit here, and then there's the cost. And then if they're above that threshold, then all those defectors are getting the benefit. And then these cooperators get the benefit as well, but pay the cost given by how many cooperatives there are in the group. Okay, so then assuming the payoffs sort of match that assumption. Sort of match that assumption. This is what happens as you go from, say, the threshold being m equals one to seven in total of seven players in this group, is that initially, when the threshold is just one, you have an internal equilibrium point, and it's a relatively low value, so a low frequency of cooperation in the group, but it's internally stable, sort of globally stable. So, in these kinds of volunteer dilemmas, someone wants to sort of is individually. Wants to sort of is individually incentivized in a sense to cooperate. But once that one person is doing it, everyone else is like, I'm good. You know, we've got someone's doing the alarm call, I'm not doing the alarm call, but just someone has to do it. If it takes a much larger fraction, like say the entire population fraction, to get their public good, you end up with an internal equilibrium that's unstable. So once there's enough past that threshold point of enough individuals cooperating that it's stable, you don't want to defect from cooperating because then Cooperating because then there's not enough individuals cooperating, you lose the benefit. But if there's not enough individuals doing it, the cost is essentially the individual cost is too high, and no one ends up doing it. And then in between, you have, you know, you have a now at stable internal equilibrium of cooperation, and there's another unstable equilibrium. So you could either be here at a high-level cooperation or here at a low level. And then potentially, so this is then if you change, this is just a particular cost value of one, if you increase the cost, you can see that it's If you increase the cost, you can see that this gain function has shifted down. So there is, again, the possibility here for a full bifurcation to have occurred by shifting that cooperation down. So, again, just something that, you know, for whatever reason or not, people haven't sort of explored as much on these kinds of cooperation models. Okay, so one kind of nice result that Mildecki and Penya proved as well on this using this Bernstein polynomial approach was that again, if you have this sort of situation, the payoffs don't depend, they sort of, there's no explicit. Don't depend, they sort of, there's no explicit dependence on the group size. Again, the group size is in some range. That if you have an interior equilibrium point and you're increasing the group size, then you have to also decrease the fraction of cooperators at that internal equilibrium point. So that's sort of a very sort of general negative effect for group size on cooperation. Increase groups, you decrease the stable frequency of cooperators. So we can sort of see this. So, we can sort of see this in this plot here. So, this is again, this is like a, and the darker color is a smaller group, the lighter color is a bigger group, and so this whole gain function curve is just shifted over to the left when you increase group size, shifting that internally equilibrium point to a lower value. So, that's the first, that's a negative effect, but there is actually like a corresponding positive effect. And the positive effect is that because you've shifted this internal equilibrium point to the left, Internal equilibrium point to the left, you've made its basin of attraction larger. So you can think of that as a positive effect because now it's a little bit easier in some sense to arrive at this stable equilibrium point. So there's these sort of two contrasting effects potentially. Okay, so then, but there really so far has not been explored to just shift that end parameter. Could group size by itself do it? So what you really need is you need this gain function in a sense to sort of fall off this x-axis to get this full bifurcation to occur. So if it Bifurcation of a curve. So if it just sort of at say hello and if it just shifted continuously down and only sort of came off the axis as you went, you know, below at a zero group size, you wouldn't have any sort of catastrophe in this tipping point sense. But if it comes off before at some finite group size, you're going to get that catastrophe occurring. So really, so there's some open questions here, just sort of throwing them out there. What conditions on these payoffs do you need in order for the group size to generate this curve? Group size to generate this critical transition, this tipping point? Are there conditions then, sort of, in terms of the payoffs that would sort of then reflect the structure of the game that would prevent these kinds of catastrophes from happening? And then, really kind of interesting as well, can we predict these from data, sort of connecting back to those methods that ecologists have already used to try to, and sort of physical natural sciences have used to try to predict these transitions? So, I'll start to talk a little bit, kind of some about methods, maybe. Kind of some methods, maybe that again, sort of stuff I haven't worked on yet, but just sort of throwing it out there. So, detecting them, even though those methods are out there, it's tricky because even though you have sort of this way of like, okay, maybe the theory is telling you they're slow to recover from perturbation, that should generate this higher variance. Maybe you're detecting the possibility of another kind of bifurcation happening that's not one of these critical transitions. So, you expect some of this behavior. Transition. So you expect some of this behavior to happen, any kind of bifurcation, much less one, not just the ones that result in a dramatic change in the system's behavior. Additionally, if you add stochasticity to these kinds of models, it breaks some of these signals. These methods become much more difficult to use. And then, just more in general, you may be measuring the wrong variables. You may not, you know, the state variables you're measuring the system may not be the right state variables to tell you to predict how to predict the. Tell you to predict how to predict the critical transition. So, lots of tricks with this. So, maybe what can we actually learn? So, maybe we don't want to just predict the critical transition by just saying something's going to happen. Maybe we can actually predict the model itself from the data. So, this is sort of what can we do, like some equation learning from the data. So, people are actually been doing this. So, as an example, suppose we have like a lockable terra system here. So, we have species one, species two. So we have species one, species two. This is like that, you know, classic Hudson Bay data links in hair from your like intro ecology textbook. And you can imagine there's maybe, possibly, maybe not, but I think possibly it's got some kind of lock of volterra behavior. And supposedly, you know, we know, like, we're pretty sure there's going to be some kind of positive effect of, say, the prey has some exponential growth rate. Browth rate, sort of, as the simplest term, and then the predator, you know, if the prey is not around, the predator has some death rate, something like that. But you don't know, say, how the density dependence of currents works. I mean, we might, in the simple model, just have these product terms, but maybe we think it's more complicated than that. So what you can do in some of these newer methods is you can sort of replace these terms with just a black box. Inside the black box, you just put a neural network. And you fit then this, you solve this differential equation. You solve this differential equation with that neural network and then fit it to the data. So you sort of essentially have to solve many, many iterations of this differential equation with different weights on the edges of this neural network and see which of those fits better. So this is sometimes called like a shipment model or equation discovery. And so what often you're the idea is essentially you just, it doesn't have to be a neural network, it could be any kind of universal or very flexible function approximator. You sort of replace the unknown. You sort of replace the unknown terms, the terms you don't think you know very well in your differential equation, with this approximator. You fit it to data. And that often these days involves, it's made much, much easier by all these revolutions in machine learning. So machine learning does very similar things. Is that fully out of time? Oh, I got one. Okay. Yes. Okay. And so a lot of this stuff is made, you know, you need to find the stuff is made, you know, you need to find the gradient of, basically you need to find the gradient of this whole system. And effectively, because you're solving, this is another actual solution, you're solving this with an ODE solver, you need to find the gradient of an ODE solver. But it turns out this is now a solved problem essentially with automatic differentiation where you use the computer algorithm to actually find the derivative of your whole computer code. And then even once you've got these two sort of black boxes, you can use other tools like symbolic regression or Cindy. or CINDI to figure out what could be sort of a simple, in terms of a set of analytical terms like x, x squared, x, y, cosine of x, subsequential of x, what those terms could be used to represent these now, these black boxes that you fit. So this is just sort of like, it works sort of fairly well. Most of the cases that people have actually tested in ecology and evolution have been on sort of toy model examples, like this lock and voltaire example, to where you sort of, you know, know what the actual truth is. You know, you know what the actual truth is, and then you see if the method can reproduce these identity-dependent terms with the right coefficients on them, and often they can. And folks are starting to do it in the field, but it's still fairly rare, so it's something to sort of keep your eye on, I think. Here's sort of that recent paper by Bonafe and Colson. They actually apply it to this Odom. Which one is this? Odom and Barrett data for, again, links and hair. Fitting, again, some of one of the Fitting again some of one of these neural networks to the data and showing that you get a kind of what looks like a sort of blockable hair type oscillation where there's some negative effect of the links on the hair and a positive effect of the hair on the links. Reproducing at least some, intuitively, some ecological interactions we think should do there. So then ideally, you know, we could use the same kind of thing for social data. So could we then fit some of those payoff values, use some of the same approach to Values use some of the same approach to find out what those payoff values might be in this kind of social dilemma. And so, maybe you know, what kinds of data there's open questions that voter participation data is a function of community size or time ants spent working as a function of their colony size. There's presumably some data sets that we start brainstorming that we might be able to get. We certainly need enough data to fit it, so that's one of the big challenges is getting enough data to fit these kinds of models. But I think it's sort of an interesting way to think about how to generate equipment. Think about how to then generate equation discovery, but then also generate new ideas for how to do further analytical and mathematical modeling. Okay, so thanks to everyone here. They'll have some fun sources, and I'll take questions if anyone's got the last one before lunch. We have certain time for a couple of questions at least. Thanks, Eric. That was really interesting. I've been quite curious about these kinds of techniques and how I went here and Techniques that you've talked about at the end here. In some ways, they have, to me, an uncomfortable blend of mechanistic and phenomenological. So do what's the end game, I guess? So a phenomenological model often works better in certain circumstances, especially as you put the impulse. Right, right. This somehow fits in between. Do you gain something from both or do you lose something from both? I mean, I think the nice thing about sort of this mix is. The nice thing about this mix is that, you know, say we were like, we know we have weak selection results, and we're like, well, we don't know exactly how things work under strong selection. You start playing around with, you know, some parts of the population process, we're pretty sure that should restrict some of the space that the model is fitting. So like you say, it's true, if you just put a big, if you made this whole thing a black box, that would probably fit the data better. But it wouldn't, even though this will fit the data not as well, it may provide you more kind of quality. You more kind of qualitative understanding of what the mechanism could be. You know, if the mechanism is essentially unknown, then maybe you start, that gives you a guess for another kind of model to start analyzing the mechanics. So I think, yeah, see, if you just want to do prediction, you don't really necessarily need the mechanistic part there. And that often, right, needs to poor prediction. But maybe if we want to generate, I don't know what the functional form is, and then maybe I learn from this is a potential functional form, and I extract out of that an ecological process. Extract out of that an ecological process that that could represent, and then I start to try to figure out: does that sound right? Does that, you know, it'd be a way of generating new models for us to work on. Because the thing that I would worry about, I mean, that makes sense. The thing I'd worry about with that is that there are many different mathematical forms that could be called data similar sorts of behavior, right? And so the fact that it spits out a particular expression mathematically may be hard to come up with a nice totally. Totally. Yeah, and it's fairly sensitive to the library, apparently. Some of these, like the library of equation forms that you give it, or like, you know, the pun. So, yeah, there's definite issues for sure. Yeah. Yeah, it's really cool. But the equilibria, like from the first part of your talk, they were all stable equilibria. So I think, you know, adding on to the potential difficulties is that you're. Potential difficulties is that if you're modeling something where you expect it to be a stable equilibrium portion cooperating, that doesn't give you a lot of data in terms of what that full dynamical equation might be. Right, that's right. Yeah, and that I don't know. I don't know how robust these things will be when you're really interested about something when you have a qualitative change within your vibration, right? That may be much more difficult. But it's still also new. But it's still also new in some ways. There's a lot of research now just in these methods. How do we fit these ODE solvers to data in a way that's robust? People are still doing a lot of work on that. In this group and player games, instead of those things if you had sort of sequential games within the group, you had member players, wouldn't so for instance I'll wait to see what the other person does with this. To see what the other person does, yeah, I just would that I feel like that would kind of stabilize, like have fewer critical transitions. I'll just have to think of: are there situations where that kind of thing is? It's possible. So, one way you could sort of put it in here is you could place the chaos. You could sort of assume there's sort of some sort of like sub-game that's played, and that's parameterized by these things, like how many times do I play with this partner, and what's my response rule, or something like that. But you might still end up with a similar setup where you still have payoffs. Setup where you still have payoffs, and then you could still use this framework and then figure out what the equilibrium structure of that game is. And yeah, I don't know, I actually don't know that it would make it much simpler. Because there's fundamental kind of like degeneracy in the whole thing, which is like these folk theorems from game theory, which sort of say that any equilibrium could be stable in the right model, essentially. So I think coming in on that a bit, I think I've done some stuff with general multiplayer games very much at this time, but also those kind of sequential things that we're talking about. And also, those kind of sequential things that you're talking about. If you design your sequential thing in the appropriate way, then it sort of maps onto that. So it's not really doing anything different in terms of what you get, but there are things you can see with the sequential models that it's harder to see. It doesn't change. It's that much. One more thing. The data you mentioned at the end, I'm talking about the time series, but you said you were talking about manipulating the conditions. You mean oh, here? You mean like an open data? Potential data that you at the very last slide. I noticed I thought you understand something about here? Yeah, yeah. Oh, um uh oh well if we had so if we had time series, then that's that helps us sort of fit the model and then then we can does this model how. And then we can invest: does this model have critical transitions? So it was the other, they're sort of not entirely related, but yeah, if we want, we don't, maybe we don't know what the social model is. We don't know what's causing individuals' payoffs to change as group size changes, something like that. So could we infer that from data? And then maybe we could then use the model to predict: is there a critical group size at which things stop working? Okay, great. Thanks, Michael. Thanks, everyone. Okay, great, thanks. Thanks very much, Jack.