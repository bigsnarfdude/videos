So yeah, so I should I wanted to say that I wrote a speaker for times for an hour and I wrote lecture notes, which are about 100 pages. Not all the details that are in here are going to be on the textbook, so this is specific. It's a lot of parts that we work from next and most I have each in the file or the contact and stuff I have is the base. I have a debate for this specific theme. And you can find, I think, if you Google my name and try and find me on my homepage, you go to presentations, you go find me on top if you want to. Anything you want to check or look at or look up our webcam or something. So, yeah, so the talks will be a bit unusual in the sense that usually when the concept will present some results that have been proved, and here's sort of the main. And here, sort of, the main theme is something that hasn't been proved. So, that will be sort of stimulating that you have a bit of, oh, can it actually be done or not? But, of course, then most of the things I've been telling you are proof, which is about the grounding web and net that I've been working on, and lots of other people. And I want to convince you that all these details that are known, they sort of support a certain conjecture hypothesis that I want to make a point for. That I want to make the point for, but that I will not do. And I suggest at the end a way that may or may not work. So it's sort of an idea for a tool. And yeah, I hope that this sort of open ends makes it maybe an interesting sort of experience. We'll see. So the thing I will talk about, it's basically we already heard about the one facilitated Frederickson-Anderson model. I will mostly look at something almost the same. I think physicists. Almost the same. I think physicists may consider it the same. We are precise mathematicians, so we say it's slightly different. It's called the already has a name, it's the bias, annihilating, ranging process. I've got this very long name, I'll abbreviate it. I'll go abbreviate it as pad. So it's a map of process in continuous time and the state states will be zero one to the z. So it's all configuration of x. And these x i's take values in zero and one. So these are configurations on the edge of numbers. There is one parameter, zero, one. We have seen this parameter in the first talk and then I think it was your queue and well, we've seen it many. Sometimes it's P and sometimes it's Q. So, what are the rules of this markup process? A um side I in the letter set is updated after IID standard exponential awaiting times during the update. During the update, you choose a random neighbor. So you choose some say that aside i is updated, then you choose from j with i minus j one. Two choices, you look with equal probabilities, and I would check if the state there at J1 then you give a new value to xt i new value, which is one is probability p and zero. And zero is probably one minus e. So you see, it's very similar to the non-facilitated FedEx and Anderson model, only that here in the Federal-Anderson model, instead of choosing one neighbor, you would look at both of your neighbors and say if at least one of them has a one, but sometimes the ones and zeros are also interchangeable. So for me, the ones are active ones. Then you would say if there's at least one one, I update it. There's at least one one I update. Now you actually choose, you either look left or right, and if there is one. So, in the case both are occupied, the updates happen actually at a twice higher rate here. That's the only difference. And I think a lot of the things I'm going to, I don't want to prove anything for this model, I'm just going to conjecture mostly. And most of the analysis would work also for the other one. But this dot is from an intricate particle system slightly easier because it's really apparent. Easier because it's really a pair of interaction. So, how do you construct an interaction particle system? So, let's say that E vector, these are our orders, neighborhood pairs and then. And then I define two maps. I define a branching map. So I pick, I will always pick I and J such an ordered pair, but you can define theoretically also for the non-pair, non-nearest neighborhoods. So you pick a configuration and you're going to change this configuration. So I have to change, say that after I apply this math, what the state is in each point, side side. State is in each point side at each side k and there are now two possibilities. It's going to be a one if this side that I'm looking at is this j and at i I have a one. So what this says is that if there is a one at site i, then it branches, it produces a new one, which is now put at the site j. Maybe there was already a one and just stays on it for an NTP concept. Jason for the NTF control. And the other thing is then, in all of the cases, I just keep buttons there. Okay, so that's one map I'll need. And the other one I need is a killing map. It is extremely similar. It's zero if if k is j and x i is one and x k otherwise so what this says is if there is a particle at pi and this method is applied to the configuration then at j I will get the zero whatever was that before. So you kill any particle, the particle at pi kills any particle that may be present at j. But maybe it doesn't change. Okay, so now I can use these maps and I can use Poisson processes to construct this mark of process. So let's say that we use a counting measure on this. So it just gives each singleton measure one. And let's call L dot a deck measure. Then I can construct two Poisson point processes. One for the branching, the one I for branching, this is a Poisson point set on E times R with intensity. A half the product measure, and similarly, I make one for the killing again the possible point set. On this, only the intensity is different. It's a half one minus p times l. And the idea is now is to define your process as follows. Xt, it's going to be in each point, it's going to be It's going to be in each point, it's going to be a piecewise constant, rather continuous with so you only have to say what happens and jumps. The evolution works in the following way that you apply this branching map to what was just before, so it's the left limit here, and it happens whenever you have a point in your Poisson set, so these Poisson sets. Poisson set. So it's Poisson. It's a point set on this. So it's a pair consisting of an element of this and this. And these are again pairs. So it looks like this, an element, if there is such a thing in your Omega B. And because the Beggar measure is non-atomic, you will be sure that at any given time, there is at most one such point in your, and they do not coincide with points in the other Poisson settlement. They are independent. They're independent. So this says that there are these points here that tell you at this time you should apply this map from i to j and similarly for the other one. So you have a private killing map for each thing in omega k and you just keep what you have and now you can prove that there is a almost your That there is a almost purely unique solution to this. It's almost surely unique piecewise constants in each component that solves this. And that's fairly standard here. We conducting microscopes in two interacting variable systems, for example. So let's see how let's draw this. This is a great idea. So, the whole process is that we just part plus this branch and giving grammar school, the children were always sent out by a teacher from time to time to get. To visible with these things. So, does that look like it? So, it's here we have jet into space. Here we have time going on. And here we have the lens. Now, I can represent I draw an arrow. draw an arrow so arrows they don't need a branching and i'm gonna use it to squiggly arrow with a killing so this means that at this time there is a point in my poisson point set uh which says that i should apply this killing so let's say that initially here is a particle and all the rest is zero and it stays here until this point and now it produces another particle here Quite here, and then maybe there is this killing map that says, you know, this new particle is actually killed experiment. So now it goes on like this. And here you can have another event. So now there are two, three particles maybe. Now let's say this one kills that one again. So you have two particles. Yeah, the thing goes wrong like this. So these things have intensity. So these things have intensity p and equivalent have intent uh yes so they have intensity a half p in each direction and these have a half one minus p. So that means that if you now look at it so and indeed if you follow this line the time up to the first moment that you meet an arrow in both directions is expressed standard exponentially because it's half often you have equal probabilities you choose from neighbors it's exactly the informal description before you can make this Before you can make precise with the sort of graphical representations, that's step one. And yeah, it's also good to write a generator. For the generator process, I'm going to take this form. This will be a half times p times the sum of. Times the sum over all i and it's very oriented. Sniper edges, and now you have f of branching x, f of x plus of minus v n sum of i and j this um yeah. Um so I write this down because later actually I introduce more interacting particle systems as well or other ones that often write down such a generator and I may vary a bit like that could be a slightly different rate, somewhat different maps. And you're supposed to next time to understand now. Next time, to understand no, you just change this picture. I'm not going to go to this picture all the time, all right? This in all kind of detail. These are the generators, this is the general function. So, here you have a function. I mean, this is a function f from this space the z to the reals. So, this is a compact space with a product topology. So, this is a contiguous function. And you need a bit more. So, say that if it's a function that depends only on finitely many coordinates, and these individual sums are defined. coordinates and these instruments sums are definitely well defined. And then what you can prove is that this generator you can take the closure and that is then it's a closable operator and it's closure generates the feather semi-group and that is the semi-group of the thing. This is again standard theory and you can again look at my lecture notes about tracking variable systems if you want some details. It's really well defined and we don't need the generators so much. We will usually use actually this way that works. Reuser and use actually these better presentations. Okay, so let's see what is known about. So, this gap has been introduced, it's branching annihilating branching, annihilating, you know, the biasing closes. It was introduced by Target Neuehauser and Ivan Sudbury. In 1993, and I don't think they ever heard of kinetically constrained models, they just thought it was a nice model, and they studied it. And there's one more paper that I know of, it's by Sudbury in 1999, and that's Fedrose Code. And I don't know that they wrote any more than it. But they proved some basic stuff. They showed that the product Bernoulli measures with intensity zero. This intensity zero and p are reversible in variance was which shouldn't surprise you. I mean we have seen many constraint models. This is obviously one and so if you update after that you just put this probability B something and obviously not so it's a this invariant and this is true for the point and they actually showed something Something that I never checked to prove actually. All invariant laws are convex combinations of these two. And yeah, now it's a real bit pity that Oriana isn't here to talk about the one facilitated. And I believe that they proved it's probably similar to what is known, yeah, but that is. Is probably similar to what is known there, but I don't know. Does anyone know if it's known for the unfacilitated Anderson model? For another model, there were the results of all the translation environmentals are either completely frozen or tightened. But for the other models, I hope I started correctly that there's no translation and reference assumption. Translation and variance of assumption. I think I was very strong actually. Okay, so this is stronger because all our particles continue one. If you have particle summary, then you have to relax to summary have to relax to product B. But you know, not that you know he's not making an assumption on the value of P. Yeah, it's for all A, it's for all B that can cool. This is the same P as the P of the parameters, right? All the other invariant, I mean, all the parameters definitely are not invariant. And the final thing they proved, I mean, that is the main thing I think. So maybe I'll double-check if there was any. So maybe I'm forgetting about translation variance, but then definitely they had something like that. No, but it was only simply the only paper in which I know that they studied differently. Which I know that they studied the whole class in environmentals is the one for the Northeast, which was with his other option for five minutes. We didn't look at all the environment measurements, but I might let me try this exchange of things. This is the config. This it's changed sometimes. This is the configuration, and there's a one at the origin and zeros everywhere else. That's just what they're wrong. Formula is proved that this, then if you start, sorry, if you start with a single one, you look at the law of the process as time t that actually converges to this non-trivial measure, and now it is really from that connection. If P is at least an octopus. About the Claudian mitochondria, and Sudbury proved. And then, the second paper by Sudbury, he proved it is actually sufficient. If E is bigger or equal, then 0.0335. And this value comes from a computer-assisted proof. And if you work really hard, you can reduce it for sure. But of course, you would have to work. But of course, you would have to work infinitely hard to prove that it is for all strictly possible. They contexted that immediately in their first paper, but this is, as far as I know, it's old. It is a configuration. So this is initial state H, initial state. Its initial state x with a single one at the origin and everywhere else just zero. So you just start with a single one and ask that does that happen for yes. You can see you had some intuition for why small p is different. Yes, I'm going to talk about this right now. But I guess again, I think this is similar to what is conjectured and known about uh prediction symbols. So why is it a small g mark? Sorry, some variants have a low function. This is convergence in law of probability. So I have this space, then I have probability measures on it. So this, and I put on this. So this is product topology, then I put reconvergence. convergence and uh yeah but you can then prove that b convergence of product measured on this space is equivalent to convergence of finite dimensional distributions which sounds much easier it's the same thing so the main thing so what why is this so actually i have some simulations you can let me you have to be a group right i can actually show you something it's a bit too much work to face Bit too much work to do. I actually simulated this thing. So, this is a random role for small values of p, and you see that it's sort of spreading. So, you start with a single one, and after a while, it spreads. And here, also, you start to see this equilibrium. And that's what you would like to show that it happens for any positive beam. And the main thing is, so you, yeah, so that's what you would like to show that it actually spreads. Actually, it sort of spreads. Here you start to have this thing, and we have this thing of particle, and you want to see that it's pretty spread. So you look at, so you say that Rt is going to be the supremum of all i, such that x ti is one. So the first thing to realize, of course, is if you start with a finite initial state, you will always take finite, right? So you can't just out of lossing create. You can't just out of nothing create something because you need one particle to do something to kill or blend, whatever. So, definitely, the only way it can sort of from a single particle is that it's one sort of multiplies in a sense. So, you look at the light of those particles. So, this follows something. Here you want to show that it spreads. So, you ask, is that an edge speed? So, naively as a physicist, you would immediately write down so that it's. It would immediately write down so that it's been identified as the limit of t equals to infinity one over t r t. And of course, as a mathematician, you immediately say, Well, that's a nice definition, but the limit exists at all. So you can say, okay, maybe I don't know, maybe I want a limit infinite or something. But you would like this thing to be positive. You want something to be bad. But why is that hard? Because imagine that you're in the rightmost particle. So when you do break. Particle. So you do branching, you call it TP, right? So that's good, that spreads. But now some other particles may sneak up from behind and kill it. And that will draw the rightmost particle in. So if you want to show that you spread with positive speed, you have to control how many particles here are going to kill you. And it's not that simple that you can say, oh, behind it, it's already this product law. I know exactly. No, no, no. When you look at the rightmost particle, you look at the center from the right particle, you introduce dependencies, and you cannot control that conclusion so easily. So it's not so easy to conclude how many particles are coming here to kill you from behind. And actually, this proof that works in such a way that... So first of all, this proof is sort of a worst-case scenario. I think they look at the right one. Case scenario. I think they look at the rightmost one, they look at this one position here, say what can happen in the worst case, and they do a very simple thing. And here with the computer-assisted thing, what Ivan Simply does, he looks at, say, n particles, looks at all possible configurations of zeros and ones here. And here he feels like he vows for the worst case. And then he says, okay, I'm going to define a function that depends only on this last M, up to the last one, the configuration that I see here. The configuration that I see here. And that function is sort of, if I shift the whole thing one to the right, the function goes. So it's sort of telling me how far am I affected. Because you know, if you are in this situation, you say, okay, my rightmost one is here. But sort of, I know this. Then P, the important thing is this is this one probability one minus P, right? So if P is small, this is only very small spreading, but the splitting can be much, much stronger if there's lots. Can be much much stronger if there's lots of partners. Of course, you don't expect so many because you expect it to be similar to this product message. So listen if you don't have your consultants. And Starbucks, you know, sort of, he says about it. In such a situation, you know, the effective distance, how far am I sort of really, it's not here, it's almost here because I know with high probability this one is going to kill me before I can branch. And you, so this is, you can make this. And you so this is you can make this more complicated and say I can define some clever function here that gives me a sub martingale. That function gives me speed and then if I worst case here then I get a sub martingale and I get so that's that's how it does it but then and then you can hope of course that if you let the computer find the best functions and you look at so many m's that you start to see some structure and you say okay now I can write down general but somehow the functions look pretty complicated and was not able to guess that it's a clever. Able to guess anything clever from it, and it's just a computer system. Yeah, I'd like, do you know how long you need to get in order to get something like one over p or how long you need to get how large m should be to get about i think maybe it m is eight if i remember well for this one yeah for this one uh you know it's true it's it's true to me You know, it's true. It's two to be eight possibilities, but you have to find a function of the number of possibilities here is two to be eight. So for your computer, it starts to be harder and harder to do that. I met it many years ago, it may be completely off. So actually, my conjecture is, this is my robust conjecture of the whole thing, I think this speed is And this speed is approximately one fourth V squared as V approaches to zero. So I believe the speed is actually positive for everyone how to do any p, but I have some ideas how to do very, very small p and this is what most of my talks will be motivated by. So and that is not a nasty thing. I had some Same, right? I have some ideas how to treat very small people, but then this thing is highly non-monotone because of the skilling. This is a non-monotone actually. More ones can be less ones later because they kill each other. So even if you know that for some very small P, you have a positive speed. I don't know how to prove that for larger P, your speed is still positive. Maybe there is a clever trick, but I have never seen, I don't know any of it. So even if all the things I'm going to tell you in these four hours are working. To tell you, these four hours are working, then still it would be only very, very small. But you would have, I think, some hope of showing that the thing for P sufficiently small, I think there's some hope of proving things. And especially of understanding what this looks like. And I think that's the more interesting part. So now our main interest is in small P. So let's try to understand the process. And P is small. So, what's going to happen when B is very small? So, when B is small, the branching happens with P, which is small, but the killing happens with the 1 minus P, which is almost. So, what's going to happen? So, there are now sort of these quickly arrows all over the place. But for the moment, I don't care about them. I hope for some. Don't care about them. I walk for something of order one. Now I see the first branching arrow. Now I have two particles, but now almost immediately, because they're all over the place, these crystal points, almost immediately, something is going to kill. So maybe the parent just kills the child and goes on like this. Maybe now just like this. Maybe the parent kills again the child. But at some point, what you'll see is that the child kills the parent and that effect. And the effect of this is that sort of effectively, with rate of half B, you jump. So, no, with rate one quarter B, you jump to the right time. So this has plus a half B, but half of them are failures because then you kill your child immediately. But in half of the cases, the child kills you, and that means that you effectively make a jump. So this becomes a zero, and this becomes a one. And now, looking at the case where there's a And I'm looking at the case where they start as a single one and everything else is zero. So for a long time, I claim this single one is going to basically put things behind, and in half of the cases, it's going to lead to a jump because then the child goes on like this. So it's within one quarter P, you jump to the right, with rate one quarter P, you effectively jump to the left. That should be more or less what's going to happen. Going to happen, but of course, yeah, that's just a single particle. Eventually, something more complicated will happen if you wait long enough. And at some point, you will actually see that you create one particle and before you can be closed, you create another. So then you can see. Eventually, these sort of things will start to happen. And now again, there are several things that can happen. This one can kill this one, this can kill this one, or the middle one can kill the outer one. The middle one can kill the outer one. So you actually have a 50% chance now that the middle one gets killed by either of these two on the left. Or let's say it happens like this. You now have effectively user branch. And now you get it. Now these things are each of them are going to walk again like until they get too close to each other so that they can kill each other. But once they get within distance one of each other, they will almost immediately kill each other and then there's only one. So you have a random walk. Random walk, you have ranching, and then you have coalescence. Coalescence means how two become one. So the intuition is that it is effectively when we smaller things should be a sort of density coalescence and a more. So now the plan of our lectures are as follows. We are going to study the scaling limit. Of branching and coalescing blocks with small range layers. And yes, so because here you see you have to wait a bit too long before you see it first branching. So you'll think this is sort of a branching or less than a more. Of a branching colassic random logs, but very small branching. And about this, it is really a lot more. If you do it more simply, not so complicated, but if you just make simple nearest neighbor random logs that coalesce and the branch is a small rate, that the branching rate goes to zero, that is known to have a scaling limit. And I'm going to tell you what that is. And in the last end, my last talk, I'm going to go back to this bar and try to argue how maybe you can actually show that this thing. Actually, show that this thing, if you send peak to zero and rescale, has the same limit, which I believe, and I've got it. And this in the end will give me a very precise conjecture. This is why I think it's really, I can say that the speed is for very small, exactly with its constant. But as I said, that's not. And actually, I should say, I've been working on this for about three years with Rong Feng-Sun, and then for five years, we have been completely busy. We had other things. We had other things that we were doing. We want to come back to it. But if someone is interested in joining this project, I think we'll be definitely happy if someone can kick started because I just ideas of in accidents and we can start it up again. I hope so. How much time do I have? Yeah. Five minutes? Five minutes uh twenty minutes oh yeah yeah you're right oh that's better that's fine actually okay so now I'm gonna write down a generator of a new interacting particle system that I want to compare with Maybe I think I can skip this one actually if I'm going too slow. No, I should not. I should not. So now we're going to do a new simple branching collapse in true one. Replace my X by something simple. First part is the same, but instead of killing, I'm going to do something simpler. Okay, so I have to carry on this new coalescing random walk map. This new is going to be Is going to be zero i is going to be one k j and it's the same old thing it was before otherwise so uh in the picture so this was my branching map and as I have a different symbol for this color And as I have a different symbol for this coalescing random walk now, I have this symbol for it. And what's going to happen? So, here if a particle comes in, creates a new one. Here it's similar, creates a new one, except that this sort of little block is a blocking symbol. It says that a thing can't go on. So, yeah, so you create one here. If there was already one, you coalesce with it. But here, you vacate. But here you vacate. Sorry, it's always zero. So you apply this with the half B and E direction, half one minus B and E direction. That's the new infection power process. And this one also has EZ over MTT as reverse or invariant laws, which is maybe not so obvious this time because there's no clear updating, but you can. Are updating, but you can just check ETL balance. So let's say that they have a 01 next to each other. How often does that just two neighboring sides and ignoring the rest of the letters? So now this one in fact is branching this one with a rate of P and this one now there's no kipping but now you can have the effect that this one jumps here so this end becomes empty and it immediately coalesces with that and so you Covales with that, and so you go back. So, this happens with a rate of half one minus p. And this, well, this configuration has, of course, p 1 minus p as probability in this earlier law, and this has p squared. So, now DJ Revolution says that, yeah, this times this should be this times this, and you see it's correct. So, it is again an invariable reversible invariable. I've changed that. Another thing that is maybe nice, it's this. So, one wonderful thing about this map is that it's monotone, which we before didn't have, that's why our comparison arguments failed. Now we have a thing that is monotone. It's even better. It's additive. So, if I have three processes, x0, 0, 1 initially, so at the initial. So, at the initial time, I start my processes and then I sort of take the union of them, so the maximum point-wise maximum. So, whatever is a one in either of them, I get put a one. That's my new process. If that's true at time zero, then it's also true at any later time. If I use the same graphical representation, you can check it quite easily. So, why is that? Because you can view the whole thing as a sort of percolation. Sorry, just talk about the definition. So, with the method that you have, you also have the mean that goes from 1, 0 to 1, right? That's the friendship data. Yeah, so you also have the sort of right, that's true. So, that's That's true. So let's check that as well. So, this is then this, you're right, it should have been checked. And this is also, and they have the same probability and the same rate. So you're right. That should have been checked. Now I remember it. I have to finish in a few seconds. So I can view the whole thing as a sort of percolation. So I can define an open path. I have two times, say S and U, and I define a function from the time till 2z. And the function is going to be, for example, this path here. This is my gamma. And I say that this gamma is open if it's true that, yeah. So basically, it means that if I make a jump, I can only jump if there's an error at that time. And if I don't jump. And if I don't jump, I'm not allowed to pass these blocking symbols. That's the whole thing. And then you can check that you know, if you want to know the configuration x at time t, and you know what is x at zero, then whenever there is a path from a one here, an open path, to something else, you will have a one here. And yeah, that's exactly the description. And advancing all this, so five more minutes. No, 35. Okay, oh, and I should define, let's take six stages. I'm not making it. Okay, so now you know that it is basically a calculation thing. So you can define these open paths. You can go back. You can ask, so is there a one or a zero here? You explore the thing backwards. Maybe you see an arrow like this. So you can follow. An arrow like this, so you can follow it back. Maybe there's a blocking error, a symbol here from something that you can't draw, and you just try to explore backwards if you can find an open path that hits one of the ones here. So I can put ones up here, I call it Y0, I put some ones here, only one here, and I hit zero. And now I'm going to explore all the open paths down first. Down turns. So basically, I turn the whole picture upside down. I reverse the direction of all arrows. I just like this and the branch goes away. And again, I have the same rules as before. And I get something out of here. And then I get here y t now. And I know that this y zero intersects with this. If I take a polyphase minimum, this is t, then it's different from the all zero configuration. the all zero configuration if and only if by t point rise minimum with zero here is different from the all zero configuration these two events are equivalent because they are the same event as the thing that there's a one here that connects to a one here through an open path if i go back or up it's the same so that's duality yeah but i should find out that so if i turn the whole thing upside down and i reverse the arrows Upside down and I reverse the arrows. So reversing of a branching is again a branching. But I guess if I reverse the other thing, then I get something I haven't seen before. I get this plotting here and an arrow that points towards it. So what is this? It means you can go on. If there's a one here, it will stay one here. But now, if there was a one here, it gets blocked. If there is a zero or whatever, the one comes here. So let's look at another case. If there was a zero here, That's not the case, if there was a zero here, then it will look like this because the one here gets blocked. So, if you think a bit about it, you can say that this thing, if you follow the rules, is a voter model map. So, this is the voter map from I to J, which we get j of y in the point k that is going to be. That is going to be y i if k zero. So it just means that whatever was here, the one or the zero, gets here regardless of what it was before, because it's anyway blocked, and the rest all stains, of course. So that's critical or not. That's the voter model. So now you get the voter model dynamics for the dual. This value process is the voter model. For the dual, because Valer costs is the photo model with some additional branch. And this branching, of course, means that once can spread, it doesn't spread the zero. What you actually get is called the biased photon. So it doesn't venture to become coalescent. No. No. So you reverse the error. So it's this becomes this. So yeah, okay. Yeah, okay. So Okay now this biased rotor model here because it's nearest neighbor is very very simple. Let's understand that one a bit better. So I don't want to write that standard performance. Just to replace that random block, call it random block map by the voter model map. You have the generator of the biased model. I just want to say that in this year. I just want to say that in this nearest neighbor case, it's very simple because I can look at the interface model. I have another line. So let's see. So if my photo model looks kind of like this, then I'm going to put here this. I'm going to put here this thing I have at a certain size minus the next one. So here it's here, zero. One minus zero is one. Here it's zero again, zero. Zero minus one is minus one. Here you get the one again. Here you get a minus one, zero. This minus this is one again. Here you get all zeros. So basically, I mean this we should have defined update. They should have defined how they indicate the jumps from one to zero or zero to one. So this is Z, and this is again a Markov process, this interface process. And you can find out quite easily what is happening. So these ones, they are drifted random walks. So this is a random walk that jumps to one step to the right or left with probability with rate of half B in each direction. Plus, due to the branching, Plus, due to the branching, random volcanoes are half one minus p. So this thing jumps to the left with rate half, one minus p, and jumps to the right with exactly rate half, because the brackenessing error also helps. And this is only due to the processing random bulk jumps, and this is due to both types of errors. Now, this is due to the voter model, and this is due to the voter model and the branch. And because it's all near the neighbor, you can see that this interface, so the ones they move like random walls with a drift to the right. So it's kind of fifth one, with a shift to the right. And the other ones, the minus ones, are in the mortgage that are fifth to the left. There are two of them means. When two of them meet, one and the minus one meet, they disappear into a zero, of course, because it means that this piece of zeros has shrunk to length one, and now these modes just meet each other. So there's no interface anymore. And again, this one looks like this. And this one, maybe these two coalesce, and this one goes on. So this whole system, this is a system of annihilating random box of two types, alternating. Types alternating, so we have drift to the left and right alternate. And as I said, I wanted to go to the limit e to zero, claiming that for this dual culture model, I can now very easily describe the scaling limits. So let's recall here we have duality right to the side. probability that xt point wise minimum by zero or empty equal to the probability initial states I need to manage That was a duality, and this is the biased photo, and these are the ranching and coalescing records. And now I say I can tell you what the now I can, for this dual photo model, for the dual various photon model, I can describe the scale. So let's define a y, early y. P, I'm going to scale things to two squares t. So I multiply all my times with a half b squared. So time is going to run a lot. And this is going to be all that. Sorry, three scale. Time is p over two R where R is in Z and y t i into one so this is a uh yeah it's a subset of the real line for each time it contains of many points it's a set of set of ones basically and this is a set value of process and i claim i'm not going to make it very precise we go more topology later More topology later is this thing. If you look at the whole process in an appropriate sense, with an e to zero, it has a scaling limit. Assuming the initial configurations converge, then the robot of course converges as a in the ball. And what is the description of it? Now let me draw time upwards, you know. Draw time upwards, you know. So I'm going to start the thing in finitely many compact intervals. And in compact intervals, I don't have positive lengths. So this is going to be the only initial states that I allow for this process at the moment. Later, after two more lectures, we don't allow more general initial states. For the moment, we allow only these simple initial states. Because now we can decide, we can just at each point. Now we can decide, we can just at each point we start a Brownian motion, and these Brownian motions are going to have lift plus one and minus one. And when they alternate and when they come together, they annihilate each other. And so make it more interesting. Let's just do a simple grow like this. This will be the whole process. So at later time. Be the whole process. So at later time, you would have these intervals, and this time you would see only one interval, and this time you would see only two intervals. So I call this the extending interval process. And I think you all see the idea that you can make it rigorous in some sense. This biased photo model, if you rescale it in this way, then you can. It in this way, then you can check that it converges in an appropriate sense to mark of flows as taking values in the closed subsets. In fact, finite unions, finitely many compact intervals of positive length, that, well, at this point, there is a singleton, but singleton immediately disappears. That, yeah, the test is disappears. Okay, so now we want to go to the more difficult thing, we want to trying to scale. Therefore, they come to find the scaling limit of that one. And I claim, and what is going to be a theorem, that there exists a unique in-law Michael Krols xt zero, that takes values in the closed subset. Closed subsets of the VRI, and now they're going to be much more complicated than just intervals, which has the property that this duality holds in the continuum. Now it's set, so I use intersection. It is not the empty set. It's not in the empty set, the probability is the same as this probability. And what you can check is that if you know this probability for any finite union of compact intervals, then you have uniquely determined the law of this thing. So I know now the law at time t of this. Now, the law at time t of this process starting from any deterministic initial state, so I have uniquely described the transition probabilities, and then I have uniquely described my Markov process. What is not obvious, of course, is the existence of this thing. But yeah, if it exists, then it actually has to be. And then the final claim is that neither do exactly the same the rescaling, rescaling space and time diffusively. And time diffusively constants, that also this disc process converges with the continuum process. So I have really a scaling limit for this branching and coalescing mechanism. The claim is now that if I'm not going to provide the definition, but this is going to be defined completely in the same way. Assuming in this state converge, this is going to converge, which I told, I mean, I said, I've told you uniquely about this, I have to prove that it exists, and this I'm going to call the branching coalescing pointset. And that one has been introduced in a paper by Ram Feng Sun and me called the Brown Linet. And yeah, we will see all kinds of properties. And that's funny properties is if you started in a compact initial state and at each positive time almost surely consists of finitely many points. And so you can sort of think of it a bit as if these points are sort of Brownian motions that are coalescing as soon as they meet. That are coalescing as soon as they meet, and they are at the same time they are branching. But there is something wrong with this idea because if you mean, if you branch, you get two brown emotions on the same position, they should coalesce immediately. So is it well defined at all? And so that you can think of it. If you think of it, actually, the baby scale, you see the branching rate, you remember, was P, right? And so if you put rescale time with P, then you would see approximately Then you would see approximately one branching per unit time interval in the limit. A viewing scale is p squared, which means that you see infinitely many branchings in each time interval. And that's exactly what's going to happen to this thing. This is sort of they're branching infinitely hard, but you know, most of the branching you don't see because it almost immediately corrects. So it's sort of physicists would say, you know, you have to re-normalize that. So now I'm exactly at the end. I'm also at the end of chapter one. So I have five chapters. I should speed up a little.