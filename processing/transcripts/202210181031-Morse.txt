Is the board and uh yeah the keyword mouse that works yeah okay welcome everyone to the first talk we are not gonna have like too many talks because there is gonna be a bunch of time for discussing but we have some selected speakers among the audience so the first speaker is gonna be Jennifer Morris and she has a very tantalizing Totalizing Tanio. Hi, Sirius. How can you help with magic functions? Okay, thanks, everybody, especially the organizers. Everything's going great. So thanks a lot for all the work for that. I really appreciate it and for putting up with me. So from the title, you can see that I'm going to talk about symmetric functions. And in particular, I want to talk about using series to study. Using series to study symmetric functions. But I've written the talk with the audience in mind, and I'm afraid that I may have ended up with the talk that alienates everyone, even though I tried to make it so that people who haven't invested their entire lives in McDonald polynomials could get something out of this. So the first two sections are really for people who haven't studied McDonald polynomials. And I'm going to review sort of where they came from and how they bring together sort of this trilogy of ideas, modules, symmetric functions, and combinatorics. And then after we see sort of how these guys arose, at the end I'll talk about this sort of new approach. It's kind of an idea from the 1800s that I've been working on with my collaborators, Joan of Blasiak, Mark Heyman, Anna Paul. Mark Heyman, Anna Pon, and George Selinger. And I'm going to try to sell you on this perspective that uses series to study symmetric functions. Okay, so, oh wait, we go backwards, yeah, I was told. So to see where the McDonald polynomials come from, we can start way before that with just the set of harmonic polynomials in n variables, and you can. And you can think of them as those killed by this symmetric differential operator, or it turns out you can get the same set by taking the span of all the partial derivatives of just the standard Mondeterminant. So you get these polynomials and n variables, and they form an SN module where the SN acts by permuting the variables. Okay, so since it's an SN module, you can decompose it into irreducibles, which are indexed by partition. Irreducibles, which are indexed by partitions. And Frobinius, so that's sort of the module, Frobinius had this idea that, well, sure functions are symmetric functions indexed by partitions, and we can map the partition indexing one of the irreducibles to the sure function indexed by the same shape. So then this puts the problems into the hand of a symmetric function person by saying, like, okay, well, study. Like, okay, well, study this symmetric function, try to understand the Sure expansion. And if you know that, whatever this symmetric function is, if you know that this Sure function occurs twice, then you know that there were two isomorphic copies of a module indexed by that shape. Now, obviously, this is not at all helpful if you don't know what this symmetric function is, right? Because then, what is the symmetric function? It's the image of this map. Of this map. That's not useful. But as this example will show you, you can get lucky. And in fact, in the example of the harmonics, the resulting symmetric function is just this simple, beautiful polynomial. And if you expanded this out, right, you would just get the sum over all words. So you can see that the combinatorics of words is behind this symmetric function. And in fact, now you can use combinatorics to study this symmetric. Combinatorics to study this symmetric function, which in turn is the image of that module. So, this is kind of the trilogy of ideas that we like to think of together, and which is what happens with the McDonald-Polymer world. Okay, so I'm going to, so that's the basic example, and then in like the 70s and 80s, everybody in any field of math and physics and In any field of math and physics, and maybe other areas, decided, like, oh, lace-bloring, let's put a Q in, let's deform everything, and call it quantum because then the NSF will fund us. And so, like, depending on where you were, you used this quantum parameter in a different way. And naturally, anybody, if you were thinking of this module symmetric functions and combinatorics picture, you could say, like, okay, well, can they get on board this loop? They get on board this lucrative shift involving a Q parameter? And the answer is yes, obviously. And it turns out we can use the exact same example of the same harmonic polynomials and n variables. But now we can use that quantum parameter, the Q parameter, to record more information than what Virbinius had in mind initially. Here, even though these modules are Modules are isomorphic. Obviously, these are polynomials of degree 2, and those are polynomials of degree 1. Frobenius' map would have mapped those two to a sure function, and even though you would see that, oh, there's two sure functions with the same shape, that wouldn't have told you that one was a module with degree two polynomials and one was a module with degree one. But you can simply record this information by attaching. By attaching q to the power, which reflects the degree of the harmonics. And so now you naturally get a sum of sure functions with q's as their coefficients. Notice that by construction, these are always positive sums of sure functions, right? Because we're taking a decomposition in terms of modules and mapping it to this sum of sure functions. So the symmetric function that you get will always be. Symmetric function that you get will always be a positive sum of sure functions. And if it's graded, such as this was, you'll get these cubes. Again, not useful unless you know what this symmetric function is. And it turns out that this symmetric function is well known for people, not just in symmetric functions, because these came up in other areas, but this guy turns out to be just a Hall-Littlewood polynomial, a particular Hall-Littlewood polynomial. Particular Holo Little Wood polynomial. And the combinatorics of that are very fully well developed. It's beautiful. Laskouche and Briget sort of put the nail in the coffin with the combinatorics by introducing like co-charge to get the Sure expansion. But anyway, you don't have to know or hear about that. You really just need to sort of see that you can study a module that's graded instead by a symmetric function, which is a positive sum. Function, which is a positive sum of sure functions involving coefficients with q. And hopefully you can say something about that polynomial, particularly with cominotaurics. Okay, and so that's that example with the q. Okay, so I would say that around the 70s, I mean, then there was some like algebraic, you know, the module was a little bit later, but anyway, that's that's we know a lot about this. We know a lot about this. And so everybody was like sitting pretty until McDonald decided that we weren't challenged enough in the 1980s. And he was like, well, you think a Q is good. Well, I'm going to put in a T also. And so actually, he came upon some symmetric functions that now had coefficients with a Q and a T. And he came upon these from a totally different area. Area. But sort of just like the guy is like a brilliant computer that without the electronic part. And like, so studying this like Zelberg integral, he found these weird polynomials and could say very little about them other than like, I think that this is a basis for symmetric functions. I think it specializes to Hall Littlewoods when you get rid of one of the parameters. And there seems to be some positivity. Okay, and well, in Garcia's mind, he is thinking of this whole like picture that I showed you with Hall Littlewood polynomials, module positive sum of sure functions with a Q, and then combinatorics, right? And so when McDonald's like, oh, there are these QT symmetric functions that specialize the Holly Littlewoods, and there's some positivity. Well, it wasn't exactly sure positivity when McDonald presented it, but Garcia found that, like, with the platistic substitutions, With a platistic substitution, sorry, seeing the P word, but you could rephrase MacDonald's conjecture as: look, there's this basis for symmetric functions with positive Qt sums of coefficients. And Garcia and Heyman were then like, okay, then where's the module? Because there's probably a module. So they were coming at this backwards. They started with the symmetric functions and then said, oh, couldn't there be a module that would give that? Couldn't there be a module that would give that? So, in other words, if you think about what I showed you for the Hall-Littlewood case, that was the harmonics, there was a degree in X because those were polynomials in X, and you got a sum of Q positive sure functions. They were saying, like, okay, is there some other module now with a bigring, maybe polynomials in X's and Y's, such that when you took the degree in X and degree in Y, you recorded those with now a T and a Q. With now a T and a Q, you would get this modified McDonald's. Oh, I just got a good question. Complaints. I crossed out what you saw. This used to say the module of harmonic polynomials. I guess we looked away for a second. Well, not a second. It was like five slides about it. Anyway, it doesn't. Anyway, it doesn't matter. The point is, that's not what we want because that's only a module with one grading, which would only give you one parameter. We need a module with two gradings to get the two parameters. And that's what they worked on. And so they said, like, okay, well, let's start with, now it's back. That's what it said. We know the picture for harmonics gives all little woods. Now we need to put in a second set of variables, right? Variables, right, which you can do easily. It's a very natural generalization. But unfortunately, they didn't get a McDonald polynomial. They got some other weird positive sum of sure functions with q's and t's. So they said, oh yeah, but wait a minute, don't forget, harmonic polynomials can also be thought of as the span of the partial derivatives of the van derma. How about we make some sort of van derman type thing with two sets of variables? They did that, and they found the McDonald polynomials. As we haven't tried. Polynomials. As we imagine. For colorblind people, this slide could be really hard. I don't think the color matters. No, because there's like words that are not written in white. You can't see the words. I mean, I don't really know what I can do about that. I'm so sorry. I'm just like, for the you can cancel me. But I'm just saying, you know, I mean, I'm not queer people. Yeah, thank you. I do think about that, but apparently not a mod. I'm not like yellow for me. This says polynomials in X. I can read it. This says polynomials in X and Y. This says polynomials in X and Y. Yeah. But it doesn't really matter. Actually, the one I really don't see is harmonic. Oh, polynomial. I get it. I get it. Do you want to sit here, by the way? Yeah, it's your expand. Yeah, cool. I'm not joking, actually. Here's a seat. No, it's got your name on it. Jennifer. Your name on it, Jennifer. That's true. Okay. So anyway, if you care about this trilogy of like modules, symmetric functions, combinatorics, obviously the next question would be like, what about the combinatorics here? But of course, there's another question, right? How can you just sit here with a beautiful module that obviously gives you a QT sum of sure functions? QT sum of sure functions without knowing what the heck those are. So they thought about both of those things. And the naught of McDonald polynomial is what we call diagonal harmonics. So if like me, you sat through like 100 talks on diagonal harmonics and didn't really know what it was, all it is is exactly this generalization of the harmonics now with two sets of variables, and it becomes a symmetric function by mapping under Frobenius's map to Math to recording the degree to this function, okay? But again, if we don't know what that function is, it doesn't help us. It doesn't help us to do this. And so the question was, what the heck is that function that's not a McDonald polynomial? So you can go to sage or maple or whatever it is you use, right? And at the top, I've just given you an example that you get by looking at the diagonal harmonics and using the Frobinius image. And using the Frobenius image, what we do is we go onto the computer and we start playing around with these things. You know it's a symmetric function, positive sum of sure functions. It has QT coefficients. You don't know what it is. So you say, well, maybe if I expand it in some other basis, I'll recognize it. But what's the only other basis of polynomials with Q's and T's at this time, and basically both? It was the McDonald polynomials. So naturally, On the polynomials, so naturally it might expand in terms of this other basis, right? And that would not really be very encouraging to accommodatorials. You get some yucky sum of McDonald polynomials. There's negatives is what I mean by yucky. There's rational functions. Okay, so that doesn't look good or helpful. But weirdly, if you McDonald expand the very easiest sure function you can imagine and look at what you get, it's very similar. Not the same. Not the same, but similar. Okay, that's just a sure function indexed by a column. That is the image of the diagonal harmonics module under the Frobenius map. They're so close. Francois was like, oh, well, if they're so close, I know what to do. Why don't we just like define an operator that says, well, I don't want a 1 here, I want a Q there. So let's let this operator send this McDonald to Q times that McDonald. To q times that McDonald. Let's let that same operator send this McDonald polynomial to t times that McDonald polynomial. So you, this is NABLA. NABLA is just an eigenoperator of McDonald functions. It sends a McDonald polynomial to something times a McDonald. What times the McDonald? The thing you need to get the diagonal harmonics. Okay, and so then the conjecture, of course, based on the definition of NABLA, was that Of NABLA was that diagonal harmonics is NABLA applied to a sure function indexed by a column. Okay, so and that was proven, and some of these things were proven, but so we haven't gotten to the third part, which is, of course, part near and dear to my heart, which is like what about the combinatorics? Okay, so at that time, harmonics gave rise to two different modules into ones that gave McDonald's a combination of. Ones that gave McDonald's were called Garcia-Ahman modules. And the ones that gave S1 to NABA on S1 to the other are called Diamond harmonics. So now, what about the combinatorics? And this is maybe why I'm allowed to even be here, because LLT polynomials come up to describe the combinatorics of both of these families. Okay? And so right about this time was when separately, Lascoux, Leclerc, and Thibone. Lascu, Leclerc, and Tibone were studying what you've now heard about, and you should have known already because it was in the title of this very workshop. But just, I don't know, for emphasis, I've kind of given a little example to redefine LLT polynomial, even though we've already seen it. These have one parameter, not a Q and a T. They used a T yesterday. I'm using a Q, whatever. So they're indexed, again, as you know, by They're indexed, again, as you know, by tuples of skew shapes, which you then fill and make tableau. So, this is just like a skew tableau, a skew tableau, okay? And the monomial is the usual, for those of us that work with this stuff, monomial that you take by every letter goes to a variable. So, if you just look at this, that's a sure function. If you just look at that, that's a sure function. LLTs are a q product of sure functions. Of sure functions. Okay? The sure functions indexed by these shapes. What is the Q? By the way, last school, Leclerc T-Bone did not define them this way. They use ribbon tableau, but this is the one that's more convenient for the McDonald's and diagonal harmonics. So, okay, you've already heard the definition, but just as a reminder, cells on the same diagonal are, you count them if the number is big or below, and if they're on. And if they're on all adjacent diagonals, you count them if the number's bigger above. And that's the statistic, which I'm calling DIN, but whoops. I'm calling it DIN for some reason. It does make sense to me, but maybe no one else. All right. So, anyway, whatever. There's some combinatorial LLT polynomial. And then the conjecture, the shuffle conjecture, or we could also look at the McDonald's, because remember, now we want to know how do you combinatorially explain. Combinatorially explain the diagonal harmonics module? Or how do you combinatorially explain the Garcia-Hayman modules? You need a combinatorial definition of that symmetric function. Okay? And so in 2005, the conjecture was that you can get this QT symmetric function by getting the Q from LLTs and attaching a T to another statistic called area. Call area. Okay, so of course, if you're not always doing combinatorics, these things are way too fast to absorb. So I just hope you'll get the flavor of it. But the formula is not actually that bad. You sum over all dick paths. That's the green, this path. I hope you might not be able to see it, but there's a dick path here. And it's attached to an LLT polynomial. LLTs are indexed by tuples of shapes. By tuples of shapes. Which LLT do I get from a dick path? You just look at the vertical runs and you get a skew. This is a tuple of vertical shapes. Okay, so I'm sorry that they're like vertical columns here. Okay, so that we already know. The LLT we know because we defined it. And then the area is very simple. You just count the number of boxes between Boxes between the diagonal and the dip path. Okay, so that was conjectured in 2005. And sorry, I forgot what I was supposed to say next. So the picture at about 2005 was that not only was there a QT example of this beautiful trilogy of ideas, there were two, right? Two of them. One of them. Of them. One of them gave rise to the McDonald basis for symmetric functions. The other gave rise to the single polynomial nabla on S1 to the M. And this was a bonanza, which means that it gave rise to like so many different directions of research. Like every possible thing you can think of, there is some line that came from McDonald's polynomials. Okay, I'm trying. Okay, I'm trying to restrain myself because I hope you can go to lunch today. And so I'm going to pick really focused direction, which I have in mind, this direction, just because I'm trying to think about this theme of the workshop. Okay, and so what is the, yeah, I'm so sorry. So we computer play this, but R is the. Oh, I didn't say it. Thank you. So I showed you exactly what the shuffle theorem or a conjecture is. Theorem, or a conjecture at this time, was which is that this symmetric function is really just you sum over dick paths and you attach in those LLTs and you attach an area. There was another very similar formula. Yep. Just really, just for the like language, is that what people usually call these vertical strips? You call them language. Vertical strips. They call them vertical strip elements. Okay. Yeah. Yes, and you heard Jim talking about them yesterday. Yep. On that topic. Yesterday. Yep. On that topic, just to clarify, vertical strip LLTs don't have to come from big balance, right? Like they could be more general than that. Because actually that's like the unicellular are more general. Yeah, yeah. Are you saying that like the ribical strips don't have to actually form a dig path? No, but wait, you can. The dig path can give you because you just don't go up as far. They're not. This was the confusion yesterday, too, I think. And maybe I'm wrong, but George, tell me. Wrong, but George, tell me. Because, like, all of those things are weakly displayed, and you could have different offsets where they go down the other way. Wait, I'm saying, like, what if you move the vertical strips in a way that you, that's actually, like, sometimes above the diagonal or whatever, right? Well, you could just go low. Yeah, okay, I see. It's definitely bounded within some bandwidth or whatever. Yeah. But if you get too far, then they don't interact at all. So that won't be a So right, but I'm saying I don't know how many don't lie in this, yes? So you're arranging the vertical strips exactly as they are right there. Wait, that was this. Sorry. That was the pink guys. I mean. But if you applied that level several times, you will have to stop like this, and the vertical strip stretches out. But I don't want to talk about that. That. I'm trying to not scare people. But obviously, I'm not succeeding, but like, okay. But yes, I mean, Francophone's point is that we can get everything, but maybe not from a DID craft. If you just want to answer, it's a D plus plus subset of a corner of corners. Yeah, yeah, that's right. But so we But so wait, who asked originally an answer is no, I guess. Yeah, okay. Right. Um, where are we? Are you going backward? Okay. Everybody's like, please don't go backward. Just here. Oh, yeah, yeah. So so what are we so what line are um the question was the R. I think you got oh I'm sorry. Thank you. I was interrupted um probably by myself. Um Probably by myself. Anyway, so the McDonald polynomials had a similar formula, again in terms of LLTs, the Q's here and the T's here, but now instead of vertical strips, these are ribbon shapes. Okay, so you can take LLT's index just by a tuple of ribbons, and there's an area, and it's a really similar function. Yeah? Okay, thanks for asking. All right, so. Equal. Alright, so this is what we want to focus on, as you might have guessed by the title of the talk, is just the symmetric functions for a minute. Just the idea that there's this very beautiful and rich and well-developed theory of symmetric functions going back to the 1850s. Common autorics is like words, tableau. You know, we hear about Robinson Shenstead, Knuth, Lasku, Choosing Briget, big names. Choosing Roger, big names in that development. But now we're seeing actually there's this basis involving Q's and T's, namely the McDonald polynomial basis, that is apparently positive in terms of sure functions, which is shocking for a family of polynomials. That doesn't happen all the time. And then there was also this other one, which is not a basis, but again, is symmetric functions involving q's and Is symmetric functions involving q's and t's. So the idea is like it sounds like we really need to have a symmetric function theory with the combinatorics developed to the level that we can make headway in the way that we've done for classical ideas. What does that mean? What questions would we need? Well, figuring out how to get the coefficients in terms of sure functions is a huge open problem. But at that point, even proving the shuffle conjecture, this was like before. This was like before Carlson and Mellett like decided to come to the dark side and prove this 10 years later, right? Like that was very non-trivial. So these were some major open problems and at a fundamental level, you ask, can't we have a symmetric function theory that equips us to deal with Qt combinatoric and symmetric functions? Okay, so, oh yeah, I wanted to mention, even though I wanted to mention, even though this is not a basis, we have a basis of some McDonald polynomials, that's just one guy. At that same time, around 2005, it was also conjectured that actually you could apply that naval not just to the sure function index by a column, but to any sure function. Actually, I did that at the very beginning when I defined that. Okay, so in other words, Bergeron or Warrington? What they did? What they did was to give a combinatorial description of this. Yeah, well, that's the conjecture. This, you mean? But Nabla shows that was at the very beginning. You mean the experimentation? You mean the experimentation that led you to believe that it was a nice thing to look at. Yeah, okay. Right. So then let's go back a slide. Thank you, Francois, for the history. In other words, The history. In other words, applying NABLA to S1 to the n was not where you would stop. It was applied to sure functions and many other things. And in particular, in the experimentations, it came out that that was actually sure positive up to a sign. And the conjecture about it was that it too could be written in terms of LLT combinator X, which I don't want to go into, but it's basically some more area and that. Area and now nested paths. Isn't there a sign? Yeah, no, it's up to a sign. Yeah, I said that, but yes, it's up to us. It's sure positive up to a global sign. I actually like to think of plus or minus nabla on a sure function. Yeah. Okay, so sorry, what are we doing next? Oh yeah. Okay, so that's the history. All right, that's kind of where McDonnell polynomials and the symmetric functions came out. Metric functions came out and how it led to what we're going to talk about now, which is like, as you could see by the 10 years that it took for the shuffle conjecture to be proven, there was a lot that needed to be done for the development of the combinatorics on the symmetric function theory. And by the way, he didn't just look at Nabilon and Schur function. They developed a whole family of eigenoperators for McDonald polynomials that turns out to give you an action of the Turns out to give you an action of the elliptic Hall algebra on symmetric functions. So that was another direction that we're not talking about. Okay, but like incredibly important in what we do. Okay, so this part now is the work that I've been doing with what Franz Wall is calling bumps. Bumps? Yeah. Which is that we really, really believe in this philosophy that series are the way to deal with this QT. Deal with this Qt symmetric function world, and it's definitely not new. And we can actually think of it as going back to sort of the original definition of sure functions in the 1850s. It didn't exactly look like this, but if you know how to cofactor expand, you could get there. And what it is, and Franco talked about how the monomial symmetric functions are, you like take one monomial, z to the mu, and you sammeturize it to get a symmetric function. It to get a symmetric function. That's how sure functions are defined a long, long time ago. Take a monomial, which isn't symmetric on its own, and apply a symmetrization. The symmetrization to get a sure function looks like this, which you might know as the Weyl symmetrization, but I feel like this is really before Weyl because it's basically Jacobi. But anyway, I don't want to be controversial. So that's such a lie. Anyway. Anyway, so if you read about symmetric functions from McDonald's book, you'll see he starts with formulas like this and develops the whole theory. But I have to tell you something funny. Somehow I was like searching on something when I was writing this talk and I came upon like an overleaf or what's the overflow where someone was like, does anybody have a reference for something other than McDonald's book to learn about symmetric functions? About symmetric functions. This was before Francois's book. Okay. And I read, someone responded and said, I don't know, but like, I gave up and switched to Schubert calculus because of that book. I thought that was so funny because I'm like, you'll see later, in my mind, they're the same, but I know most people don't think they are, but like, it was very funny to me. Like, oh, let me do something easy, Schubert calculates. But anyway. But anyway, regardless, McDonald's book. For symmetric function, there's proof. Yeah, of course. Yes, absolutely. In fact, that's a very nice, beautiful one. But that wasn't what I wanted to give. No one gave a good answer, except this I'll switch to shooter. Never mind, just give up. But with the Q's and T's, right, then, Bruce, I don't think you have the whole development with Q's and T's. The whole development with Q's and T's. So I think that was really more. But they probably don't want the Q's and T's at the time. Well, I think they did because they were talking about McDonald. For McDonald polynomials, you do. I mean, you need that. But in his book, anyway, you start here and you develop from there. And even with the Q parameter, the Hall of Little Woods, he does the same. And it's a surprisingly useful type of formula. We think of them as like raising operator formulas, but I don't want to use that word. But anyway. That word, but anyway, of course, in his book, Once You Get to Q's and T's, like this comes to a screeching halt, and nothing like that has been used to study the Q's and T's. So it was long wondered, like, can't you get these formulas for Q's and T's? Because they helped him develop, I mean, he didn't develop, but in the book, the development really relies on that type of definition. That's the type of definition that, like, I'm going to try to sell you on. So, unfortunately, it's a little bit daunting at first. It's a little bit daunting at first. But I want to start with the one-parameter case, right? Because, well, obviously, a lot more had been worked out. The whole picture for Holly Littlewoods was well developed. And I said, even in McDonald's book, you can find such a formula for Holly Littlewood polynomials, but not through the Q and T. So I want to give you sort of a similar formula, but actually, this one's due to Shimazono and Wayman. This one's due to Shimazono and Wayman to show you how you can introduce a Q into the classical definition of sure functions to get the Hall Littlewood polynomials. Okay, so this is the operator that gives you sure functions. If you have a monomial and you symmetrize it, you get a sure function. But if we want a polynomial with q's in it, you have to do something else. And it turns out what you do is you put these denominator terms in, and they're indexed a z i over z i. They're indexed a zi over zj, which zi and zj, they are the points above a dick path. Again, the colors will be not great for some people, but this is just any dick path. Well, no, sorry, not any dick path. You're indexed by a partition, the particular dip path, where you write down blocks of sizes given by the partition. So it's the dip path formed by these blocks. By these blocks. So here's a tiny example. The partition is 2, 1, you form a block of size 2, a block of size 1. That actually gives you a dig path, and you get two points, two roots here. Those roots tell you which i's and j's. Okay? So in other words, a little wood polynomial is indexed by a partition. There's a particular dick path that you get from that partition, which gives you the pairs you need. You the pairs you need. That's actually not the confusing part in this definition. We need to know, like, what the heck, how to read this. How do you read this? And this is actually the important part. You actually want to think about it as a series. So you series expand those denominator terms. We can do that. So that's this. And then you're applying the sure sametrization. So sometimes something like this, we know when you apply sigma. Something like this, we know when you apply sigma, it is just the sure function. However, some of these guys don't give us sure functions. Well, we think they don't, but they actually do. Some of them are actually with denominators, and they don't look good. There's a law that says that any symmetrization of any monomial is a sure function up to a sine. So you geometrically expand this, and then there's a theorem that says when you apply sigma, That says when you apply sigma, every term is a sure function up to a sign. Unfortunately, of course, we don't particularly like signs, okay, but that's how it goes. Life is not always perfect. So, kids. So, that's what you get. And for me, I'm thinking, I will call a sure function anything indexed by a non-decreasing sequence. So, there can be negatives there. That's where the Paul comes in. This is an infinite series. In. This is an infinite series, like a sum, but not necessarily positive, of sure functions. But then the pulse is just kill the ones that you don't like. I normally index my sure functions by partitions. That's not a partition, so like get rid of it. Okay, so in the end, you get a polynomial, a symmetric function, a sum of sure functions with q's, right, because I have those q's. You might not be convinced at all that this is. Be convinced at all that this is a nice formula, especially for combinatorialists, because it doesn't in any way reveal positivity. Right? And it's kind of like annoying. You have to series expand and then sanitize and then like kill stuff. I got you. I also kind of think it's like not something you'd meet and love. Yep. Sorry, can you explain again what the sigma operator is? That's the biosymmetrization operator. It's the one. I must have missed it. That's how you. That's how you that's the operator that when applied to a monomial is a sure function. Yeah, okay. Yeah, right. So you're applying the sigma to each monomial? Now in the slide you were just on. Oh, it looked like you were applying the sigma to every monomial. Yes, I am. Now I apply sigma to every monomial. And it's always a monomial? It's always a sure function. Oh, yes. Function. Oh, yes, yes, yes. Oh, yeah. Sorry. Oops. No, it's here. Or zero. Sometimes there's zero. Right. Yeah. And then why didn't you keep the sorry? You have adjacent by increasing by one. And it straightens to zero. Yeah. Yeah, one more clarification. So, can you go one slide forward so that it puts the thing on the bottom? Why didn't you keep the q squared s3? Oh, that cancelled. Oh, that cancelled. So that's why. Okay, thank you. Why does the Z1 squared Z3 give 0 and the Z1 squared Z2 give S2? 113? Sorry, it was? What was the question? I was trying to understand the 0 term versus the 1, 2. Ah, because anytime you have an adjacent, if you have an I, I plus 1, it straightens to 0. In the exponent, this is 201. Oh, okay. This is like so much more detail than you're going to get on anything else in this talk. I'm very happy to spend the time, but I just want to warn you that things get worse. Like, much worse. Yeah. Right? If you multiply by the quartx of all C's, you kind of get more and more terms in the series. Yes. That's exactly right. And we do this all the time. Yep. We do this all the time. Yep. That's right. Yes. He's noting that. Well, let me. You're ahead of me. Okay. Okay or no? Still disturbed? John, you look mad. You're having a mask on. How do you know I'm looking? Because you're like... I mean, it just seems strange to me that when you symmetrize two different monomes. Symmetriz two different monomials that seem part of the same M. Yeah, but you don't symmetriz because you have this denominator. I'll hold my hands together. That wasn't really a question. No, I'm just kidding. Okay, no, please ask if you have questions. That's fine. Anybody? Everybody okay? Everybody convinced that this is Convince that this doesn't seem great. Okay, so I am now going to convince you, I hope, that it actually is. It's like, why would anyone want to look at a Hall Little wood with this formula when you could use Lascouche and Roche, charge, sum of sure functions, whatever? Like, who would do that? Well, lots of people, because that formula generalizes very naturally. Generalizes very naturally. You don't have to take just those roots that lie above the block path. Why not take the roots above any path? Okay, and this was in this generality study by Panyashev and separately Heyman, saying, look, there are these functions, these symmetric functions involving a Q parameter that can be defined for any dip path and any monomial. And any monomial at the top. And they appear to be sure positive. And more importantly, or I don't know, more importantly, this includes a special case, which was why Shimazono and Wayman were so interested. A very special case of this, slightly more general than the Hall Littlewoods, had been studied since forever, since 1992, by like so many people, much fancier than I ever interact with, trying to prove the sugar positivity. The positive sure positivity of a very special case of this. And lots of theories came in to this, and partial progress was made. But even in this tiny parabolic case, they couldn't prove sure positivity. So it's like, if you can't prove sure positivity for this parabolic case, do what any good mathematician does, generalize it to something harder, right? And that's what Panny-Schevenhagen did. Of course, it was still not provable, but it was conjectured. Not provable, but it was conjectured to be sure positive. But it turned out to be the right thing to really look at a more general framework. And now's my selling slide. And if you know me, you know that I basically only think about k-sure functions and have since the 90s when I was a graduate student and discovered them with Lascu and La Pointe. And they came out of McDonald polynomials, like which I'm not explaining, but I thought McDonald polynomials. But I thought McDonald polynomials was what combinatorics was, and we studied them and we found these symmetric functions and couldn't prove anything about them. Maria was the other day like, we have this conjecture, but we've had it since April. I'm like, what, April of 1998? Like, I've had conjecture since 1998. Like, that's wrong. Okay, but anyway, so it was a long time of just conjectures about this basis that came up in McDonald polynomials. Namely, sure positivity was one. Namely, sugar positivity was one of the big ones. But it turned out that if you got rid of, if you let Q be 1 in these polynomials, they are connected to Schubert calculus. And so then there was like this geometry. And that's why I sort of feel like the person who switched to Schubert calculus really didn't do anything, because it's really the same. Which is why I love the topic of the workshop, because I always feel like I'm always like, Schubert, Calculus, and McDonald need to be studied together. But no one ever listens to me. Like, listens to me, and I feel like that's sort of what's happening here. Maybe with one parameter. Do you have kids going here? No! Are you kidding? No, I wish. That's why I'm here. But anyway, so this is really a slide for no one to understand, but just to say that there is an equally interesting framework. Interesting framework involving Schubert calculus that is tied to what I've been talking about. Namely, those catalog functions include not only Hall-Littlewoods and parabolic Hall-Littlewoods, but Keisha functions, which I haven't defined so you can't understand this. But my point is, it's this type of definition that was so scary and awful and caused such anger, right, that was how we were able to settle this conjecture from the 90s. Conjecture from the 90s about the Schrohetzen face-sure functions, that definition did it. Okay, and that definition, well, we actually generalized to non-symmetric and could prove that any catalog function was sure positive. And that's using like crystals and different stuff that we use for this, but whatever. Anyway, one more thing. This can be generalized to like a K-theoretic framework. So if you do like K-theory and super calculus, George Sealen. Calculus, George Salinger really made that leap to showing that those type of formula can prove like branching and open problems there also. So the geometry, I mean in some sense you could say it's easier than McDonald's because you let Q be 1. Actually it's harder because without the Q as 1, you don't have the grading to force you along the right path. But the Q I think I should. If you have the Q, If you have the Q, you're restricted. You can do without the Q. Without the Q, you lose information and you're lost. You can't do anything. So we did prove everything with the Q, but of course it has consequences when Q is 1. Anyway, this is not really the point, but it is to show you, I really knew that that definition would be awful for you, and I want to tell you, like, no, look again because you've got to, yeah. I mean, you started out by selling us on the fact that, like, true positivity is going to come. Like, sure positivity is going to come from a module. Yep. Is there a module? Yes, and in fact, Heyman, when he studied Catalan functions in general, I think that was probably his whole point of view. Like that kind of module. Yeah. Yeah, certainly. It's a whole family of modules, but yeah. Okay. Sorry, where are we? Oh, yeah. There's one more. There's one more formula that is of the spirit of the Paul Littlewoods that I'm trying to sell you on that we might hear about in this room. And this was done by Heyman and Gronowski. It shows that LLT polynomials can actually be written also in terms of these series expressions. Now they change the denominator to involve non-symmetric Hollow Woods. Don't worry about it. The idea is that I can change the denominator. Is that I can change the denominator to something else that people in the NUM know about. And you can view an LLT polynomial as a series that's been truncated. Okay, so this was like totally separate and quite early on work done by Mark and Ian. Okay, oh, and that's by the way, how they prove the sure positivity of LLT polynomials that we were talking about yesterday in general. Okay. Okay, um, wrong way. Okay, so we have these formulas with just the one parameter. Hopefully, you are a little bit of a believer, maybe not as much as me, but like you can see why I might do my, spend my time on it. But we started out by saying, like, what about the QT framework? There are these open problems. We really need to try to have something to make progress there. So you go to Sage again or Maple or whatever it is. To sage again or maple or whatever it is you like. And you say, Well, we knew that this was a hall of little wood. Let's just throw in a tea. Like, do the dumbest thing. And you use sage and you get this, which looks like what, France Law, or anybody. You might recognize this. If you tried to do this and you were looking for the McDonald polynomials, which I think probably people did do, you wouldn't have found them right away. That's not what you get. That's not what you get. Instead, you get the diagonal harmonics. Okay, so in this tiny example, you just throw in a T in the obvious way, and you look at what you get. And if you remembered my slide from the beginning, you would say, oh, yeah, that's the Frobinius image of the diagonal on X. So, of course, we played around and worked and stuff. And, yep. Did you try with three parameters? I thought that was what. I thought that was what our group was supposed to be doing. So, in the end, after lots of experimentation, we came upon sort of the correct things that you need to put in the denominator. Yes, all Q is like Hall Littlewood. All T's to get the T in there, but you also needed a numerator of Qt's. Okay? But the same type of formula, series expand, blah, blah, blah. But, and then again, remember. But, and then again, remember, you have to take the polynomial apart, and that's what we saw was NABLA on S1 to the N experimentally. Now, the part of the talk that I didn't choose to do, even though last night I was having second doubts, is like, obviously, you can use the computer and find a formula like this and get very excited. And I am definitely perfectly happy living on conjectures for 20 years, but like. But like at some point you would want to prove that it's actually naval at S1 to be n. And for that, it turns out that this rational function had been studied by Nago in his work with the shuffle algebra and the elliptical algebra. And so the sort of basically a lot of what we needed had been done. There's just like one little tiny insight, which is that rather than thinking of this as a rational function, right, we use it as a Function, right? We use it as a series and then truncate. Okay, so it turns out, anyway, that if you have a rational function in the shuffle algebra, you can connect it to, take its polynomial part and connect it to NABLA on a function. Whatever. We're not talking about that. But what we are talking about is that we found this formula in the spirit of the ones that we liked. We saw that the polynomial part was nabla on s1 to the n, and it was not difficult to prove that given. Difficult to prove that, given the work that had been done by other people with this elliptical algebra and the shuffle algebra, those are the fancy people. The fancy people? Everybody. What? We've talked about some fancy people. Yeah, oh, they're definitely fancy. Absolutely. Absolutely. Yeah. Anyway, so we have this. Now, by now, this is a theorem. This is a theorem. The shuffle, the fact that this equals the sum of LLTs is a theorem. Okay, so, but of course, we really like this formula and we're really excited about it. So, like, we want to see that at least, can it help us at least reprove what they've already proven? And it turns out, yes, and it's very simple. You go back to the fact that we know that you have one of these beautiful series expressions for LLTs. And then, And then you go and do what, like, my 13-year-old would do and say, I can cross out everything that's equal on both sides. That's not necessarily true because, like, polynomial part was like killing a whole bunch of information. But you can certainly hope, right? You can hope that, I mean, we know this is an identity, thanks to Carlton and Mellon. But we want to prove it with our formulas, and we say, like, oh, well, could we cancel out the polynomial curve? Could we cancel out the polynomial curve? Is it true as an infinite series? While we're at it, let's not bother to symmetrize either. And it turns out when you do that, like you really get something that was basically already known for a long time, which is the Cauchy identity for non-symmetric all little woods. Again, if that's not your area, that wouldn't seem familiar to you, but like it was nothing that people in my area didn't know. So that was like amazing. Not only did the shuffle conjecture hold as The Shuffle conjecture holds as an infinite series identity, you could then prove it using something that was basically equivalent, and then you could get the Carlson and Melan theorem by taking the polynomial part of both sides. Symmetrizing. Okay, so. But those guys, those are the Hall Littlewoods, right? The Duel and the E and F. Oh, did I say McDonald? Non-symmetric. Yeah, they're the non-symmetric Hall Littlewoods. That's what I meant to say. That's what I meant to say. I don't think you said anything, actually. Oh, yeah. These, I did in the definition of LLT a million years ago, but whatever. Yeah, this E is the non-symmetric Hollywood and F is it's dual. That's right. Also, if I change the C1 times CN, and then make that like En, do I get the delta times C1? Yeah, so that's exactly right. But you're itch. Yeah, yeah. So that's essentially what you're doing is. So that's essentially what you're doing is what we did. Like, okay, we reproved their theorem. Like, a man cannot live on reproving another person's theorem alone. And, like, this man can, but, like, people I work with might have wanted more. And so, of course, we looked to see exactly like, okay, well, can we get more out of this? And one of the things we got was the Delta book. I didn't choose to talk about that, but yes. What I chose to talk about was the one that I said, the Navla S Land. Said the nabla s lambda, or plus or minus nabla on s lambda, which had also been written as an LLT series. So, what did this tell us to do? Well, remember, we love these formulas, and we know we have one for nabla on s1 to the n. Is it possible to get one for other, for example, nabla on s lambda? And this is what led us to what we call the cattle animals. We knew that this one was very lucrative, okay? And we knew we needed something else. Okay? And we knew we needed something else for Nabla on S Lambda or McDonald for that matter. So we said, much like Panyashev and Haman had said so many years before, why restrict ourselves to this set of roots, which is everything? Why not just pick any root ideal for Q, any root ideal for T, any root ideal for the numerator, any monomial in the numerator? What do you get? Well, most of the time, garbage, right? Garbage, right? Like, you don't even get monomial positivity in this tiny simple case where I have no roots in the denominator and one in the numerator. So, like, in general, cattle animals are not particularly nice. Obviously, you know in that case they are. And so, the question was, it became a study of, like, when do these guys have nice properties? And when can they give us the answers to what we want? So, RQ. Yeah, go ahead. I'm sorry. So, RQ, RT. So RQRT RQT, any relationship between those sets of roots? No. Well, I mean, sometimes, depending on the definition doesn't remove any relation, but you might tell me that there's a relation that needs to happen to be nice. Yes, as you saw for this, we needed them to be the same. That's exactly right. We define cattle animals for any independent. Most of the time, we think of a cattle on path and take the roots above a catalog on path. And take the roots above a Catalan path, you could do anything. I don't care. Like, that's fine for me, but I don't think you'll get anything nice. But yeah. So, you can't. No, that's a good question. We're allowed to take anything. So, another silly, because you just said, like, oh, it doesn't have to be like an upper order ideal at all. Right. It's like an arbitrary subset of roots. That's right. And most of the time, you don't get coverage. Okay. Yep. Yep. So, what we did was investigated mostly with an eye towards the Laura Warrington conjecture. Towards the lower Warrington conjecture because at that time it was still open, and now we're running out of time. But I do want to at least get to the LLT part. So, this is just what we showed, what I showed you for NABLA on S1 to the N. We use sort of like this nice encoding of the roots. I have all the QT roots in the bottom and almost all in the top. We use a pitcher for this. These guys are the Q, the T roots minus the. Q the t roots minus the qt roots. You notice that the only thing you're missing is sort of the ii plus one. So we encode the root ideals, you know, just looking at the catalog paths in this way, whatever. All this means is like the QT roots are this light colored stuff, and the t roots are this plus that. And in this example, the q and t's are the same. Okay, so now. Okay, so now in general the cattle animals have three sets of roots, so you need to identify three different root ideals to give you something nice. Which three root ideals give you something nice? That's a big question. Hard to say. But we did find ones that gave the sure, the NAVLA on a sure function. We call them sure cattle animals. And it's just like too much to go into the combinatorics. But anyway, I hope that you find this picture beautiful. Find this picture beautiful. The point is that it's very easy to combinatorially define the three root ideals that gives you the sure cattle animal. This is the index, nabla on a sure function. And you like read the diagonals to get black cells, and you read off-diagonals to get these dotted cells, okay, and whatever. There's a combinatorial way to read the function that and then. The function that, and then you have to get the weight, but whatever, we're waiting on that. Upshot is there's a nice simple way to tell what root ideals you need to get nabla on a sure function. Now we had to sort of do a little bit of our own work. We couldn't rely on everything that had been done before to show that this guy, when you take the polynomial apart, gives you Navon as sure. But again, over here, we still have the LLT series. Same thing. Have the LLT series. Same thing. I didn't write the infinite series identity, but it's an infinite series identity that proves the formula exactly like the Schuffle conjecture. And then just very briefly, because of the title of the thing, we have these sort of raising operator formulas for NABLA on a sure function, but really what we have is formulas for NABLA on any LLT. On any LLT. Now, this, while they studied NABLA on a lot of things and found sure positivity, would not have been something that you would have pursued because NABLA on analytics is not sure positive. It's yucky. So like, why would you look at it? You'd look at it because if you have one of these nice formulas, you can prove lots of stuff. Okay? And so, very much like what I showed you for the sure cattle animals, we can find root ideas. We can find root ideals to give NABLA on an LLT. And because I know that people have talked about the unicellular case, this is the unicellular case, you only have basically two things to worry about in terms of your root ideals, two things to be concerned with. So it's a special case of general LLTs. It's not hard to work out exactly what they look like. So we have one of these pretty formulas for. Of these pretty formulas for NABLA on an LLT. And then, just as an application, remember, we still didn't have a formula like this for McDonald's, which was sort of a problem people have been thinking about since the beginning. And we could use Hadlin and Heyman and Lohr's formula. Remember, the McDonald polynomials are written in terms of LLTs. But McDonald's polynomials are eigenfunctions of NABLA. So you can apply NABLA to both sides. So, you can apply an applicable side and then use our catalog animal here. And you can get a reason operator formula for McDonald polynomials, which no one can understand. And so, anyway, this is what it looks like. But now, kind of to Eric's question, like, this is kind of an interesting thing. Well, naturally, we haven't gotten to, we've just found this formula. Now, maybe we can do something with it. I don't know. But one thing that does come from this formula, much in the same way that. Much in the same way that Shimazono and Wayman used one of these formulas because they wanted to study parabolic hallwoods. This formula naturally gives rise to a whole family of McDonald polynomials simply by taking powers of the monomial in the formula. So now you have this whole family of kind of mechanical, right? We know nothing. There's like representation theory, combinatorics, like all the questions that. Common attorneys, like all the questions that we've studied for decades about McDonald's animals, you can now ask about these, which of course we conjecture are cute teacher positive. Anyway, I'm sorry to go over and also speaks like the speed of light, but anyway. Thank you. I'm watching Revangelos could have done a better job. So this is a generalization of the modifier microparameter with this parameter S? That's right. When did you come up with this definition? Oh yeah, very shortly after we came up with Navlon and LLT. We haven't published it or written it or even put it on the archive, but yes. And what is the monomial expansion? Is that known? I don't know. Everything is unknown. Everything is unknown, like that's exactly like it's not obvious. Yeah, good question. Yep, so it seems like this is sort of a new way of getting at true positivity for some of these cases. Well, I don't know if I would say that because in the one parameter case, in the work that we did with cashiers, yes. Because we could go to non-symmetrics and there's some sort of crystal representation theory that's known. Crystal representation theory that's known. I'm not going to go so far as to say sure positivity, that we haven't explored that yet. Okay, but say in the cases that it does work for the nature, is like, does it help you get actual like combinatorial formulas for sure expansions? Yeah, well, I mean, so, for example, you can, let's just take, for example, not the k-share, but the, yeah, we have a combinatorial formula for the k-shares in terms of sure's, in fact, in terms of k plus one sure's. K plus one sure. Yes, we have combinatorial formulas because again, in that one-parameter case, you really can get the combinatorial. You can rederive Lascu-Schuzzen-Berger's charge if you happen to want to, and do, yes. There's for that, yes. Well, a lot would die, right? So, like, this was the, I think, your observation that first, no, maybe. Observation: That, or no, maybe Anton. Like, if you increase S, more will survive, right? Because the truncation is getting rid of negative guys. So, I guess if you decrease S, more would be killed. I don't know, though, about the sure positivity with negative S. I mean, so the whole thing, right, is really just a what infinite G L L character series that we're conjectur conjecturing as positive and this Conjecturing is positive, and this S is just like how much of that series are you pulling off? So if you make it negative, you take the polynomial apart, you're just going to get one. No, but not right away, though. Wouldn't you slowly kill things off? Well, let's see, if S or zero, you have a degree parts of the. Oh, that's even like. And then, yeah, like, you're going to just eat away at a mouth until you get a little bit of a. But maybe progressively, that's the thing I'm wondering. Or. I think you're doing Z1 to Zn, and it's the size of U. So once S is minus 1, now you have a degree 0. Yeah, that's true. So going back to my three parameters, there was a talk a while back in Montreal by Vassau, where he was trying to designularize the Hilbert scheme of point in three space. T-space. Fancy guy, by the way. One of the things that was doing was considered to be graphics like this, generalizing this. Ah yeah, I mean another one here, yeah. A trade graph. But for the shuffle algebra. And then there's other terms because in the numerator you put all the products that would correspond to The products that would correspond to this product. You have Qt here, but you have Q1, Q2. And another term is other terms, Q1, Q3, and Qt, Q2, Q3. And in the bottom, you have another term that is a product of 3. The reason for this is very natural. But anyway, so we could experiment on this. It's definitely a direction. I mean, I'm already over my head, but like, yeah. Yeah. It seems natural from the point of view of geometry and also shuffle algebra, and it's worth looking at. I have lots of pieces to say. Can you use this S trick to pull out more of, say, Uniceller Uniceller LLT polynomials and then maybe get some combinatorial interpretation of this rest of the series. Of this rest of the series. So you mean, okay, but you first need an LLT expansion. But you have like a similar formula like that for LLT expansion. Oh, so I thought you were saying that like if I looked at an LLT expansion, then the S would make it longer and longer. Oh no, so you have a formula like a data polynomial or symmetrization or something gives you the LLT point, right? Yeah, the NABL on an LLT. On NABL. Yeah, yeah. On that level. Yeah, yeah. So you know it's like your definition of an LLT without somebody. Oh, Heyman's? Heyman and Bernowski? Oh, yeah, we can use that one. Can we make sense of more of that series? Like colouring for something. Yeah, I know what you mean. I see. So you mean this series? Yeah, yeah. So you would want to, right there, like, you would want to add some sort of monomial in. Add some sort of monomial in the new C2 velva. Yeah, that's exactly what I was talking to George about yesterday. Like, what have they done? I mean, you can do that, but I think there's a formula involving trickles. Well, that's true even without doing that. That's what this formula is. Does anything known about the geometry of the NAVLAB and LLT? Like, I mean, cellular LLT is like the equivariant homology of the Hessenberg. Well, so since I just learned yesterday about how the unit cellular LLTs relate to the Hessenberg varieties, I definitely would not be the person to answer that. But maybe somebody fancier than me. Fancier than me. Or maybe if your group is boring, you're not sure about. No. No. Yeah. Yeah, so that's why, in terms of the module or something, the way that we think of it. I mean, at least in SN. But I might be sure part of it, you know, statistically replaced t by t plus one. Replace T by T plus 1. Maybe. Anton? Maybe. And so there is this technology when you have some symmetrizization, you can compute it using creation operators. Because I remember that if you apply that to Nihil's formula, you get our formulas with Eric and this AQT algorithm. So do you mean like the D plus or whatever? Or whatever? And then what's the question about it? So, if we apply this conversion to creation of regular formula, I remember getting some expression in the algebra that is part of the proof of the shuttle. So, I'm wondering, like, can you tell me about this creation of figures in that? Well, I mean, after you sent that compositional paper link, then we have been trying to figure out how things. Figure out how things line up, but it's not something that we can do immediately. But you don't have good at using creation operation. Well, in one parameters, yes, but no. But that is exactly how we do all the one parameter. It's essentially creation. We're using we don't really use the formulas as they appear.