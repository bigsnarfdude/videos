We will learn at the end. So, thank you very much for the invitation here to all the organizers, particularly Michael, who invited me also to visit next week in Morelia. I'm going to speak about a subject that is connected to my address. I work in the Institute for Research in. In the Institute for Research in Basic in Theoretical Computer Sciences. And this might be somewhat strange. So let me explain what it is. I got, well, in France, much of the logic that is done in France is done in such places. This is the biggest one in the country. Logic is considered theoretical computer sciences. And indeed, it is, I believe, also always believed in this. Believed in this, and the topic is about the connection between infinite structures of countable and uncountable infinite structures and finite structures, and how we can consider infinite structures that are limits of finite structures organized in some nice way. Well, we have already seen these very nice ideas presented in the work of the Oswald. Presented in the work of Oswaldo and who was talking about Jorge, yes, sorry, Jorge and Stevo. And so you see, there has been this idea of these capturing schemes that are very interesting to me. Morasses, we know all these ideas in set theory. So I want to represent to show some ideas in some other parts of mathematics and to connect them with. And to connect them with what we know inside Syrian model theory. Now, the first part of the talk will be about some work that is kind of motivating and published already, and perhaps you have seen that part of the talk already in some of my other talks. And then the second one will be about some newer things that I'm working on right now with colleagues. Okay, so that's the plan. So let's. Oh, here. Okay, now it will be fine. Okay. So this will be how it will go. It will be the introduction. Then how a finite and infinite model theory connect. I think this is a of this subject is very exciting. We know very little about finite model theory in what we do as set theorists and models. What we do as set theorists and model theorists of the set theoretically. And the connections are being made in recent years. I find it exciting. And then I will talk about these new logics. So let me start with one subject that perhaps many of you know. It's the combinatorial limits. I think the basic combinatorial limit is this graph one. Is this graphphone? And it was developed by Lovash and his group around 2006. And the amazing thing about the graphphone is that you take a sequence of finite graphs, and the graphon is a measurable function from the square of the unit integral to the unit integral that represents this sequence of finite graphs. And I will tell you what it means that it represents it. But you see, the point is that you have. But you see, the point is that you have some behavior of like these graphs, you can think of them as representing some real-life behavior, for example, the internet graph that is changing all the time, growing. And rather than looking at this dynamical process, you want to replace that by a continuous object, which in a sense represents the quantitative properties of the sequence of graphs. This was the idea behind the development of GraphCon and the expander polynomials to. And the expander polynomials before them. And so let's see what are these quantitative properties that I have in mind. So these are certain graph invariants. When you study graphs, you have like we have cardinal invariants in set theory, in graph theory, they have graph invariants, various quantitative properties. And in fact, what can be done is to define quantitative. Quantitative properties of this measurable function, so that when you have a certain quantitative property of graphs, here we will be talking about t, then this quantitative property is represented by the corresponding quantitative property of the measurable function. So, let me go slowly through this notation to explain what I mean by that. So, let me first remind you of this graph homomorphism density number. Morphism density number. What it is is you look at a graph G, so you fix a finite graph S, and you want to imagine this sequence of G n's, and you are interested to find homomorphic copies of F inside of the sequence Gn and you're interested to know the asymptotic properties of the sequence. And what are the homomorphic copies? So, these are copies that are in which you are. That are in which you are allowed to have the same number of vertices. Every relation from F is preserved, but you are allowed to add relations in G. And T of G is the number it's given by this equation, which just simply means if I take randomly a subset of G whose size is the size of F, what is the probability that it will be homomorphic? Probability that it will be homomorphic to F. Okay, so homomorphism said edges have to go to edges, but non-edges can also go to edges. That's right, that's right. We can add relations. So now we represent that as a certain integral. So let us now look at the integral of this function here. Well, I could go and explain what this integral is, but rather than But rather than looking at that, let me just say in what sense this function is kind of representing the limit of g n's by drawing on the board. So I can think of these g n's. So let me imagine that I have a graph on some k vertices, and I want to represent it as a measurable function from the square of the unit interval to the unit interval. How would I do that? Well, I have k vertices. I'm going to divide my unit interval into k blocks on both sides. And I'm going to now think of these k blocks as representing the k vertices. So let's say I have here zero, vertices A0, A1, etc. And when I have an edge, I'm going to think of that as an edge between this. Let's say this is the. This, let's say, this is the first block between the first block and the second block. So, this represents zero, this represents one. So, I'm going to look at this grid and I'm going to color this black. And I can, in that way, represent my graph. And so, this actually gives me a measurable function from this square to zero, one. So, I just take. To 0, 1. So I just take 0 where there is no coloring and 1 when there is coloring. So you can see that you can make a limit of this process, and that will give you a certain integral. And that's how these transfer principles are done. So now you see how you represent them. Now you would like to know if this representation has something to do with some convergence-like properties of this sequence. Clearly, this is kind of a convergence definition. Convergence definition. So, when does it work? Is there some requirement on this sequence of GMs which will actually make us be able to say this? Well, yes, in fact, there is a notion of metric convergence for sequences of graphs. It's called the cut metric. So, this cut metric, I won't define it. It has a definition that you have to think a little bit about. But if you know the Semerer regularity lemma, it comes from there. Lemma, it comes from there. Samurai regularity lemma has a lot to do with this. Anyway, so the theorem, the main theorem of the graphons is that if you have a convergent sequence like that in the cut metric, then you get the graphon is this measurable function. And in fact, the Samroed irregularity lemma is then equivalent to saying that the space of these graphons is compact. Compact. So, here you can learn what was known about this subject at the beginning. It has developed a lot since that time. And now, this is not the only notion of combinatorial limit. These limits have been developed in other contexts and many applications have been found. And for me, what I like about it is this nice smooth transition between the discrete world and the continuous. Between the discrete world and the continuous world. Now, in mathematics, we often think that discrete mathematics and continuous mathematics are separate. One represents algebra, the other one represents analysis. And we have this nice smooth transition. So as I already explained to you, one of the main motivations was from studying this evolving internet graph. And you can then imagine. And you can then imagine that the graph theoretic properties of this internet graph correspond to everyday notions about the internet. So, you know, if you have jams, what is the density of the edges? You can have social networks. You can represent lots of things like this. And that's why people in computer sciences also study this. Okay, now let us look at this. Okay, now let us look at this formula again. Notice that this formula is not going to tell us almost anything if our sequence of graphs doesn't have enough edges. So if you have that, you have a sequence of sparse graphs, then you're just going to get a zero for this T number, and the whole thing is going to be sort of information-free. So this works well for sequences of dense graphs, but for a while, it was an open question. For a while, it was an open question to find some notion of this, which would actually work also for sparse graphs. So, sparse is an informal definition, but formally you can define it as a graph that has a very few edges. And so, if it's a sequence, the number of edges goes to zero. So, to capture this notion, a new theory was needed, and it was the Not needed, and it was developed by two different groups. First, by Benjamini and Schram that defined something called graphings, and then further by Nashetril and Osona de Mendes. And this is where it comes to connect with logic, because they introduced, and with said theory, they introduced the unifying theory of these two types of approaches through this notion of first-order convergence developed by. Convergence developed by Neshitrile and Osona de Mendes, and the notion called the limiting notion, which is called modeling. And it's a very nice notion that it can be defined for any sequence of graphs. And if the sequence of graphs is dense, if these are dense graphs, then we reduce to a graphon. And otherwise, we get new things. So let's see the definition. There is the book that covers that. Is the book that covers that? Let me just bring your attention to the title of the book. There are here graphs with bounded tree depth. They will come a bit later in the talk as well. So just remember that name or the definition is not coming, but I just want you to know it's there. So, in fact, this approach brings us to have some connections with model theory, as I mentioned, and it brings Street model theory, as I mentioned, and it brings us to the second part of the talk. So, let me tell you about first-order convergence is. So, rather than counting just the number of edges in a random part of the graph, we're going to count the satisfaction of first-order formulas. So, we are going to be working in the context where we have a finite relational language in the first order, and we have And we have some sequence of structures. So these are not necessarily graphs. Graphs are an example, but this could be more complicated structures. And we take a first-order formula and we define what they call the stone pairings between phi and an, which is an analog of what we had with the homomorphism density. It is just simply the probability. It is just simply the probability that when you take a k-element subset of a n, k is the number of variables in our formula, that this k-element subset actually satisfies phi. So the formula is given this way. You look at the number of things that satisfy phi, you divide by the cardinality. So this is clearly a generalization of the graph density. And we say that the sequence of structures is convergent in the sense of first order. Convergent in the sense of first order if there is this limit. So you have seen this, for example, in the context of zero-varn laws. So this is how zero-varn laws are defined. If you have a sequence of graphs, you look at the first order formula, then the probability that it will hold under certain circumstances will be zero. Okay, so in various, so now we have something that looks like that formula. We have something that looks like that formula for the transfer of the homomorphism in graphs. What is the analog of graph for? So, this is the modeling. And the modeling is a standard Borel space, actually. So, you see, we come to something that we actually know. So, it's still, of course, uncountable. So, it's a structure. There is a structure, a standard Boreal space in which satisfies phi this, the limit of this. This, the limit of these phi and a is exactly phi a. So the probability converge, if the probability converges, I think n should be on a n. I'm very sorry. Here there is a typo, so a n rather than phi. Probably on the left-hand side, yes. This one, phi A. Yes. Yes. So this is kind of, yes, in the measure says the probability that it satisfies. Unfortunately, the Zoom cuts this down a little bit, but I think you all know what is a standard Borel space. Let me just remind you, this is a measurable space on which there can be defined a metric to make it into a polar space, and the Borel algebra and the measure algebra coincide. And the measure algebra coincide. That's what it means. So you see that we are getting to something that we know. So let's see that we actually know more of this than what we suspect, that these graphons remind us of something that we have known all along, the ultra products. So let's try to make a connection between the ultra products and graphons. So we have a sequence of some small structures and we have a lot of graphs. Of some small structures, and we have a limit, which is some large structure. This is an ultra-product. How about this measure? Where does that come from? So there is a construction of Loeb measure in the theory of ultra-product, which does exactly that. So you can think of, for example, on the graphs, you can think of the counting measure. So it's a counting measure. On each one, you just count. On each one, you just count. And then in the limit of this graph one, you have an actual measure. So this is an instance of the load measure, which is, well, so this was actually discovered by Alec and Sagedi in 2010. They were not aware of the work in the non-standard analysis, or at least their paper doesn't show that they were aware. But they developed this totally independently. This notion of the ultimate. This notion of the ultra-product measure. What is happening here? This is the pointer. Okay. So they wanted to have a hypergraph on, and it turns out that it is not easy to just combinatorially lift the notion of a graph onto a hypergraph one. So now you have hypergraphs. And so they wanted to define that limit. So they said, okay, I'm thinking about the hypergraph as having a discrete measure on it. As having a discrete measure on it, counting measure. I take now an ultra filter, an omega, a non-principle to make things less non-trivial. And now I take the ultra product, and I am almost done. I'm not quite done because I want to have a measurable function in the sense of Lebesgue measure, and this is separable, and the ultra-product measure is not going to be separable. So we have to take a certain separable quotient. So that's what they did. And so you see, Leibniz were known in non-starnot analysis since 1975. And the separable quotient would correspond to a countably generated substructure. In fact, there is this paper from Aroskar and Cummings, which I checked, and it is still to appear, although it has been around since 2014, in which they explain the connection between the Explain the connection between the classical law measure construction, the Elek and Sagedi paper, and then they applied to many different structures, not just to hypergraphons. It's a very nice paper, and I don't know why it hasn't appeared yet. But in particular, this is a big generalization of a large generalization of graphons. And then there are some other people who have done extra things on this. And yeah, this would be an oops, sorry about that. Yeah, this would be an oops, sorry about that. This colleague actresses and tackle drop, we are looking at actions and so adding one extra ingredient to this. And so there are many things. So you see that these connections are being developed. Let us go on and see that this reminds us also of something else that comes out of ultra products. out of ultra products. So in model theory we like to study pseudo-finite objects and there is a large community studying pseudo-finite objects. Valtario Garcia is one of them coming from this part of the world but there are others. So what are pseudo-finite objects? Well these are objects that are elementarily equivalent to alter products of finite objects. So we now see that this should be connected with the graphons. Should be connected with the graphons. So, this is a large subject of research in model theory, and one can see the work of Rushovsky and others for this. And the connection of this with combinatorics, I will perhaps mention here Arten Chernikov, because he has done a lot of work, have solved important problems using these methods. And I will just mention a result of ours with Ivan Thomas. Of ours with Ivan Tomase to show you how one can connect these methods with graphons and with combinatorics. So, I already mentioned this fact that the space of graphons is compact in the cut metric. And I told you that this is more or less an equivalent of the Sambred irregular T lemma. Now, you might know that what is Sambredirgular Tilemma, just to remind those who perhaps don't know, it says if you have a large graph, Graph, and you have some estimate of the error you are allowed to make, then you can divide this large graph into a number of small regular pieces. What does a regular mean? It means that the edges in each one is basically the same with respect to this error. And then you have a small number of irregular pairs. Regular pairs. So, this is the sembread irregular regularity lemma. Those of you who have followed the work of Maliaris and Shellach, they have proved a nice theorem connecting this with stability, in which they show that if your graph is stable, then you don't get those irregular pairs. And this is if and only if. So, you see that the notions of novel theory enter in. So, this regularity lemma is Is interesting in many subjects. It appears in many subjects. And one important version of the regular Tilemma, or let us say improvement of the regularity lemma, is this work from Terence Tahl in 2012. It's called the algebraic regularity lemma. I will show you on the next slide what it actually is. But let me say that it is actually a lemma about fields. About fields, about finite fields, and about graphs that are definable in these fields. So here is the lemma. It's a bit of a chunk to read. So you have this finite field, and you want to look at definable graphs in this finite field. So graphs between some definable part of the field and another definable part. Definable part. So you can think of that picture of the graphon, but now you have a field: F here and here, and you have some definable subject subset here, which is called V, and another one which is called W, and you have some subset of the product. So you can think of that as the graph. So you have this graph E. And now you assume that things are reasonably nice, there is some complexity that corresponds to this epsilon. Corresponds to this epsilon, so don't worry about that right now. The original lemma of tau had the requirement that the characteristic of the field has to be large, but it was later removed that requirement. So what is in red doesn't need. And then what you see, the conclusion here says that you can actually partition this graph. You can partition V into some pieces and W into some pieces, and then you look at the graph. Some pieces, and then you look at the graph between these parts, and it has some regularity properties. So, notably, what is important is that the edges in each part are regular. So, this here corresponds to the definition of what's a regular graph. Okay, so the details are less important than this picture that you have there. So, this was a very nice theory. This is a very Was a very nice theorem. This is a very nice theorem, which had a very complicated proof at the beginning using notions from harmonic analysis and whatnot. And then the proof was redone by Starchenko and Pele using methods from pseudo-finite fields. Unfortunately, they didn't publish their paper because, at the same time, Khrushchev had the same idea, he wrote it to Tao. He wrote it to Tao. So Tao was aware of this proof with pseudo-finite fields. He really liked it and gave a talk at the Fields Institute special semester in model theory. He was invited and gave a talk about this proof. And that got him very excited about the methods coming from logic, particularly the outer product. And you can, well, I'm sure that many of us read his blog, you can see this on his blog. Can see this on his blog. And why he was so excited that, in fact, these methods managed to remove the requirement that the characteristic of the field be large. So we talked about this with Ivan Pomasic, and we had the idea that it ought to be also possible to do this proof using the methods of graphons and get something more out of this situation. So we read this. Situation. So we redid the proof using graphons. And in fact, our theorem in the world of graphons can be formulated without mentioning anything numerical, like in that previous slide. And in fact, it is not just about fields, but it's about something called asymptotic classes. I'm going to tell you what asymptotic classes are, but what I would like to say, which is more important than what an To say, which is more important than what an asymptotic class is, is the structure of this theorem. So, the theorem is that in the space of graphons, you look at the realizations of definable bipartite graphs over structures coming from some class of models. So, here, these are definable bipartite class. Graphs coming from fields. We want to extend it to something bigger than just the class of fields. These are called asymptotic. As the class of fields. These are called asymptotic classes. So we just want to look at the graph ones that you obtain by taking limits of these specific graphs, the graphs that come from here. And it turns out that their general structure is nice. So what we proved, that in the space of graphons, when we look at the accumulation points of this family, then we get a finite set of step functions. You see, the accumulation points will be some measurable functions. Will be some measurable functions, but these are very nice, specific measurable functions, and there are very few of them. So you see now the convergence of structures coming somewhere in this result. So the fact that the Tao's algebraic lemma should be possible to express for us about the classes was already in the private correspondence between Frushovsky Tutau. In Frushovsky to Tao. So, in the language of pseudo-finite structures, but well, it was we didn't know about it. And then, once we send our paper to Tao, he sends us that letter of Rushovsky. So, anyway, let's see what's this asymptotic class in case that you are interested. So, it's some sort of a model theoretic generalization of fields. It's a certain hereditary class of finite structure. Hereditary class of finite structures. Hereditary means it's closed under substructures. Well, it has sort of a complicated definition in terms of, but the important thing is it has two parameters, numeric parameters. There is this numeric parameter mu, which is measured in Q. This is kind of a rational measure on this structure. On this structure, and then there is this parameter d, which is measured in n, and this is sort of a dimension, so you have a dimension and measure, and then there is some requirement that these agree nicely. Okay, so this notion is due to McPherson and Steinhorn, who studied it in quite some generality. So, what we want to So, what we want to pick up for this talk from what we have said so far is that we actually made the conclusion that the graphons that are generated by graphs that come from a certain nice hereditary class are simple. That is the conclusion. So, we would like maybe to understand what kind of hereditary classes will lead us to have such a conclusion. So, let's go to the next slide. When you say, When you say a hereditary class of nice structures, you probably think of phrase elements. This is something we all know. And so, the question is: is there a connection between this and the phrase elements? So, let me remind you a little bit about phrase elements and ages. So, the question that I mentioned is now written here: is suppose that you have a hereditary class of. That you have a hereditary class of graphs. Let's go back to graphs because that's simpler. What conditions on this hereditary class will guarantee that the graphones generated by graphs are whatever we might mean by simple? For example, the simplest ones are the ones that only have values 0 and 1. So what can you say about C that will generate, that will assure that 0 and 1, the resulting graph ones are just step functions with two. Are just step functions with two values, functions with two values. So, as I said, an example of a hereditary class is the age of some countable structure. So, all finite age is defined as all finite substructures of a countably infinite first-order structure G. So, the Freesi construction is an example of a countable structure constructed so that. Constructed so that we control its age. We are given some nice plus and we glue it together, and then we obtain a countable structure such that its age is the class that we started from. So, for example, how could we formulate this question in terms that are closer to astrologic? If we know a model-theoretic classification of this, I call G, this countable structure, what can we do? Countable structure, what can we say about the graphons that are generated by the age of G? So that's a question. So let's see what we can say about that. In fact, we were not the first one to ask this question. Already in the book of Lovash, there is an explanation of this very nice theorem of Lovash and Segedi from 2010, which I'm going to translate. Which I'm going to translate into the language of model theory. It's not stated in this way in the book. So, what they did is that if you have G, which doesn't have independence property, that's what NIP stands from, as a graph in model theory, then every graphon that you obtain from the age of this G is zero, one valued almost everywhere. So, this non-independence property that people have studied a lot in model theory enters. lot in model theory enters here. As I say, it is not mentioned in this way in their book. And the reason is that in fact there is a completely model theoretic free reformulation of the NIP, which connects NIP structure with a dimension that people study in combinatorics and other structures. It is Wapnik-Chervonenka's dimension. So this theorem is So, this theorem is stated in terms of this dimension in the book. And so, for example, this covers the fact that if you take stable graphs, then these graphons are going to be the graphons generated from them are going to have these properties because stable graphs in particular do not have independence property. In fact, there is a very nice characterization of stable graphs. Nice characterization of stable graph. It's a graph that doesn't have a certain subgraph called a half graph. And in fact, it's a very deep theorem of Sahron that NIP is exactly the property that every formula in this graph has a VC dimension. So this suggests a certain connection. This suggests a certain connection. It suggests a connection between the class of properties of the class of finite structures and the resulting graph or object that we obtain. And it's kind of like connecting finite and infinite model theory. Now, I wrote here it is fascinating and difficult to connect finite and infinite model theory. Let's think why it could be difficult. Be difficult because an infinite model theory, so the model theory that we learned from Chag and Kissler's book, the basic assumption is that you deal with infinite structures, theories that have infinite models. And then one of the main theorems is the compactness theorem. Now, if you only want to deal with finite structures, you are missing this theorem. And I'm going at the end of the talk to show you one theorem that is kind of trivial. One theorem that is kind of trivial or easy in the context of infinite models and very hard in the context of finite models. So, there has been this finite models studied since, I don't know, 25 years ago, maybe not that long. And the motivation came from computer sciences. And they developed the methods connecting, well, often kind of mimicking the models theory from infrastructure. Theory from infinite structures to the finite structures and connecting the two. And having really nice applications, I would like to mention the work of Michael Benedict, who was one of the pioneers in this way of connecting finite and infinite model theory. Well, now I don't know how familiar you are with the notions, how they are defined, the stability and all these notions from classification theory. All these notions from the classification theory of Shellach, but usually they are, well, usually they are all defined in terms of some properties of a monster model and some infinite thing does not existing in the monster model. So a monster model is simply some large enough saturated model of the theory and you want to exclude certain configurations, infinite configurations from this model. So all the classification theory is done with this idea behind. Behind and it uses a lot of Ramsey theory, compactness theorem is behind everything. So, how in the world can you adapt this to finite models? In fact, you can, and these people working in this area have managed to connect stability and NIP to finite structures and And actually, see that obtain some deep theorems in which we see that the classification theory from Schellach infinite models does not have the same picture in the finite. In fact, there are fewer classes. So, here is, for example, one nice theorem. So, let us look at the following definition. Let us say that the class of finite relational structures. Class of finite relational structures is monotone if it's closed under weak strat structures. So it's the opposite of homomorphic embeddings, right? So it's just you can drop the relation, well, the counter positive of the homomorphic embeddings, you can drop the elements and relations. So imagine you have such a monotone class. There is this theorem, very recent theorem of Brownfeld, that in such classes, the two properties In such classes, the two properties NIP and stable actually coincide. So, this is not true for infinite models, but for finite models, as soon as they have this kind of reasonable requirement, these two are the same. In fact, for graphs, it was already known by the work of Adler and Adler since 2014. So, maybe now you are curious to see the definition. So, maybe now you are curious to see the definitions of NIP and stable for finite structures. Let us do that on the next slide. So I'm afraid that I typed this, copy this from a paper since there was too much to write in the keyboard notes. I hope you can read. So let me just remind you, for example, what is the order property in infinite models? Well, it says that in the monster model, It says that in the monster model, there is no formula that defines an infinite sequence that looks like the natural numbers. So phi Ai Aj holds if and only if I is less or equal than J in the set of natural numbers. So that is the stability. The stability would be you don't have such a property. Everything is in the negation classification theory. Negation and classification theory. So let's see how we would say that for finite models now. So it says the order property on this class of finite models is if for all n there is some mn in c and a sequence which goes up to n many elements from this mn, which imitates the order of the natural numbers up to the number n. Up to the number n. So this is very natural once you have seen the definition. And it is clearly if you have an infinite model and you look at the finite substructures, then the age of that infinite model, you will see that the infinite model has the order property if and only if the edge has this finite order property. And similarly, you can define the independence property. It's the same thing. So, this is kind of a machine to generate classification theory type properties in classes of finite models. And then you do the same as you would do in the classification theory. And as I said, if you apply compactness, you get that the class is stable in this sense, if and only if the. If and only if the completions of the theory of C are stable, blah, blah. Okay, what I have already said. So it is surprising, therefore, that when you go to this finite version, you get that the two properties coincide. So you see, this finite finitization of these properties is like doing how you formulate the finite transit theorem from the infinite transit theorem. If you think how you would do it, this is exactly. Think how you would do it. This is exactly. So, this is the idea behind. Okay, so let me tell you something that we have done, that Dana, Bartoshova, Rehanna, Patel, and Lin Sko, which is to appear in the Annals of Pure and Applied Logic, which now connects these different ideas of finite structures, structures whose ages Structures whose age is controlled by the class of finite structures and the ultra products. These are the kind of three things that we have seen so far. So the theorem is the following. Let us have a finite relational language like before, and we take a non-principal ultra filter over omega. And we have some sequence of finite health structures. We call this detrending, but really this just means it's increasing. But really, this just means it's increasing fast enough in size. Okay. And now we take the ultra product, it's M star. And we would like to get some sort of Ramsey theory for the ultra product. Well, this is kind of hopeless because you have many colorings that are not controlled at all by the finite pieces. But you have some colorings that are kind of the product of the colorings that you had on the finite. These are called internal in general in the non-standard analysis. In general, in the non-standard analysis, these are internal objects. So, what can we say about internal colorings of the ultra-product? Okay, so our theorem is that if we take any structure of cardinality at most LF1, so not just countable, it can have size LF1, which has the property that its age is contained in the union of the ages of these finite things. We can say something about its Ramsey property. About its Ramsey property. So, what do we want to say? We want to say that the property of having small Ramsey degrees will carry to such an object. So, if the sequence of finite objects has smaller Ramsey degrees, then this K will have some transfer of that. So, how would you formulate that? So, fix some A, which is in K. Which is in K. Okay, so some finite thing. And now you want to look at the copies of this A inside of N, inside of M star and inside of N. And you want to study colorings of such copies. And so we suppose that this A has the property that inside of K it has finite small Ramsey degree. This is called. This just means that when you This just means that when you look at the copies of A inside of K, then there is a Ramsey theoretic theorem about it stating that you have not necessarily monochromatic but dechromatic substructures for every cubic. Then, so what we can say, our conclusion is that the following partition relation holds, and what this means that if I have an And what this means is that if I have an internal colouring of M star of copies of A in M star, then there will be a copy of N, which is such that all A's in it are D chromatic, well, such that all copies of A are colored in at most D colors. Okay, so K, that doesn't matter what K is. Okay, so it's complicated enough without. It's complicated enough without K. So, this is the theorem. So, we get the transfer theorem of the Ramsey degrees. So, now you could see here that we have some connection between countable and uncountable limits. So, can somebody tell me how much time I have? It's one hour I took, is it? Okay, so I've 15 if it's one hour. Yeah, 15. Yeah, okay, great. So, I have time. Yeah, okay, great. So I have time. So, this is what we have done so far illustrates that there is some connection between the countable limits and the uncountable ones. For example, the fact that we have obtained this theorem about the age of a structure and graph forms. So, is there more to it? What can we say more? So, let's see what countable and uncountable limits we know. Countable and uncountable limits we know. So, so far, we have seen countable limits which can be obtained as a simple union, just as a limit or Frase limit. And uncountable limits that we have seen so far have been the ultra products, graphons, and modelings. So, what are the connections between such things? So, we would like to say this connection. Would like to say this connection somehow with respect to the finite structures. So, to have kind of a clean representation of this ultra product Ramsey theorem that I have just shown you. Can we say that just using something simpler than the ultra product? Okay, so so far we have played with sizes. Logic, you can play with sizes, you can play with formulas, but there is something else that you can. Formulas, but there is something else that you can favor, and it's the logic. You could actually try to change the logic. Why do you always talk about a first-order logic? Let's see if we can get some mileage out of that idea. So let me first tell you how in abstract model theory, how we study what's a logic, what is a logic, and then we are going to formulate some logics that are going to express these things. So let's see. Let's see, what's the logic? So, probably we are much stuck to the idea of the Tarski definition of what a model is. We have a set and then we have formula and we developed. But if you really want to say this in an abstract way, you can drop much of this intuition, actually. In fact, you can drop the syntax out of this. There are you really don't need to know the syntax. Need to know the syntax. What's a formula? Who cares? You just have a family of formulas. You have a family of formulas and you have a family of models, and you say which model satisfies which formulas. You don't need to know how these formulas were made. So this is the approach that comes from the 70s. People studied this, people like Barweis, for example. There is a book on that. So this is what I mean here: that in abstract. What I mean here is that in abstract model theory, it was actually already started by Tarski and Watt in the 50s. There is more variety as to what a logic might be. And the semantic and syntax are not necessarily connected. Well, you know, the magic of the first-order logic is the completeness theorem. It says that the semantics, syntax, and the notion of proof are all the same. The same. This is wonderful, but it's too much to expect in general. So let's study things that are somewhat weaker. So let me mention a mathematician called Carol Karp, whose name is on the Karp Prize. She was a model theorist, a student of Watt, who studied this subject of abstract model theory and had a school she studied in this period. This period, and she invented a logic called chain logic, which doesn't have anything to do with what I'm going to say. It was invented for singular cardinals. At the time, the question was to study logics of the type L kappa lambda. And to so where you have a right to take less than kappa many conjunctions, less than lambda many quantifiers. And it turns out that for singular cardinals, this is complicated. This is complicated, different than for regular ones, and she invented this chain logic. And actually, I studied chain logic with Joko Vananen because it's a very easy to be defined logic. And it turned out that it solves one of the problems in abstract model theory, which was previously solved by Sellers by a very complex. By a very complex logic. So, this is kind of aside, but it's maybe nice to know. You perhaps know what's Lindstrom's theorem in model theory that characterizes first-order logic as the maximal one that has compactness and downward Loewenheim colon property 12. And the question was: if you can have something like that in this world of abstract model theory, if you have another logic. Theory: If you have another logic with this characterization, and Sherlock found this, you know, he published in 2021, and the question was since open since the 70s. And it's a very interesting paper. And we actually then with Yoko, well, I think our paper is in Israel's Journal of Mathematics 21. Maybe his is a little bit early. But he proved it first, of course. But we just, what we showed is that. course but we just what we showed is that we showed that it actually also is answered by this chain logic and then we actually compared chain logic with this complicated logic of Sahron and this was behind my motivation behind in what I'm going to tell you now these ideas simply that you know I want to talk about finite models but I want to use the methods from very abstract infinite Very abstract, infinitary considerations. So, what's the logic? Okay, now that you know what I want to do, it will not surprise you that the logic is just kind of some abstract thing where we know we have three things. We have L. This L is like sentences, and S is the structure. So, I'm using the notation from Martos and Vanon, and I'm using their letters, which I think I would have chosen. Which I think well, I would have chosen different letters. Anyway, this L stands for like language, the sentences, and S stands for models, structures. And you have some binary variation between L and S, which is intended to tell you which models satisfy which sentences. Yes. And then, okay, if you are really in this generality, then you get nothing because you know you don't. So you would like to have some nice. So, you would like to have some nice properties of this relation. For example, that it behaves nicely with respect to the negation. So, how would you say that? Well, if you have a model that doesn't satisfy a sentence, then it satisfies its negation. Similarly, its disjunction and so forth. So, these are some basic properties that imitate what we know about the usual Tarski satisfaction and we put them on the requirements of. And we put them on the requirements of this logic and call them nice if they have that. So we don't have to read the details, it's not important. So now what I would like to do is to introduce logics that are going to imitate on countable models what we can do with these uncountable limits. So for example, I want to imitate an ultra product, but on a countable object, or a modeling, but on a countable object. But on a countable object. So, this is what we are going to do in the next slide. So, here is the ultra filter logic. It will be a simple example. You take a non-principal ultrafilter and you look at all. Now, you want to define some logic. So, you take all countably infinite structures of some relational language, but you consider them with a But you consider them with accompanied with an increasing decomposition. This is the idea of Karp, this is the main idea of head chain logic. And you now want to define the satisfaction in the countable object as kind of a limit of satisfaction in these finite objects. So here is for the ultrafilter. It could be some other limit. So we say that m satisfies phi in the ultrafilter logic if and only if the sequence here The sequence here satisfies phi asymptotically, which in this case we take the ultrafilter. But it could be something else, some other notion of asymptotics. For example, the m n's are finite? The m's and are finite, yes. So then, because this is an ultra filter, you can prove that this is closed underneath, it behaves well with negations, and it forms a nice logic in the sense of that previous definition. And then, of course, the washes transfer. And then, of course, the Wash's transfer theorem tells us that in this sense, M is going to satisfy some sentence if and only if the ultrafilter is going to satisfy, ultra product is going to satisfy. So we obtain a way to interpret in a countable structure the pseudo-finite structures, the ultrafilter. So we have some nice countable structures. And notice that no particular connection is asked about these finite pieces, only that they are increasing as sets. Is only that they are increasing as sets. So we can play with this definition and have to replace the ultra filter with the modeling. So, what is the limit that we are going, the definition of asymptotics is going to be? We start the same way as before, the same things. But now we've defined the satisfaction in this way. We say that in the modelling sense, M satisfies phi if and only if the limit of these term pairings is one. Of these tone pairings is one. So we imitate the modeling and we also get a nice logic. And we can play with this notion and we can compare these various logic. There is something called two transforms. The two transforms are useful to obtain comparison between logics. They are kind of like Galo-Atuki transforms in. Key transforms in set theory. So you can define in some natural way what it means, but there is the main idea is that there is this pair of functions. You go from this formulas of one logic to the other, and then you have the pair, it is kind of the inverse, of course, it's not an inverse, from the models of the second one to the first one. And you have this nice condition that connects them. And this is really like the Galois-Toukey connection that you know. The Galois-Tuki connection that you know from cardinal invariance. And heuristically speaking, this connection is that if L prime is above L, then if L prime has some nice property, then L is also has this property. So they studied this for compactness. And we can compare these various logics that we introduced. Well, so why would we want to do this? What is the hope of this method? Well, let me just show you. This is the last slide. Show you this is the last slide. So, as I told you, there are some nice theorems that people proved in finite model theory that are kind of easy in the infinite case, but quite complicated in the finite. And I'm thinking here about the transfer theorem. So, here is a transfer theorem that you probably know from the first order logic. So, in infinite structures, it's very easy to prove. It's very easy to prove. A first-order formula is preserved under homomorphisms in the sense of model theory if and only if it is existential positive. So I'm only reading you a part of what is this? This. Okay, so this is a theorem you know for infinite structures, and it has quite an easy proof. Now look at this for the finite structures. In fact, it turns out that it's still true. It is very It is very difficult to prove this. This is a very difficult paper of Rossmann from 2008 uses many notions from combinatorics. It's one of the rare such transfer theorems that is true in the class of finite structures. Others fail in the infinite take used proved using compactness. This is, Rossman is a computer scientist. Why are they interested in this? Because this comes from data structures, the conjunction. This comes from data structures. The conjunctions, well, actually, existential positive formulas are equivalent to a union of disjunction queries in data structures. Okay, so now also this kind of theorem does not simplify as you would think. So if you replace the class of all finite structures by some subclass of all finite structures, the theorem actually gets harder. Theorem actually gets harder. It's not true. It gets harder, and you can think of what if we restrict to some subclass of finite structures. And then it was proved by Davard that it is true for what he called quasi-wise structures. Then Nestotrill and Osona-De Mendes show that it is still true for nowhere dense classes. Sorry, sorry, they prove that these quasi-white structures are exactly the Quasi-white structures are exactly the nowhere dense classes. And then Adler and Adler proved that this is exactly what was known as superflatness by some model theorists. And well, actually all of these notions, and there is also the bounded three-depth, the one that comes from the title of that book, and all of these notions are actually equivalent to stability. All of them. All of them in monotone classes. So, this shows how nicely this connects with infinite model theory. So, I taught a class last year in Paris 7 on this type of things. It was called games, semantics, and logics. And I had three brilliant students who are Ivory Fronto. Ivory Fronteau, but his ceiling, and then it's still mass. And we decided to actually write a book together. So we are working on that. It might come up, you know, in a few years. Okay. Thank you very much. Aha, okay. I have to take that off. I have to take that off. Okay. Okay, any questions? Yeah, this is just a question for a reference, but in the slides you have your definition of logic of a logic abstract logic. Of abstract logic. Is that you got your paper with Yoko or where did you where that so it appears first in the paper that Yoko wrote with uh Marta Matos and that is in the references of our papers but the definition is in our paper. Okay and you know the name of the paper? Our paper on chain logic something and it's Israel General of Market Fetch. Thank you. Thank you. Okay, anybody else? Okay, anybody else? So, again, on the chain logic, so you've got logics for various ultrafilters, and I assume different ultrafilters can give you different logics. Then you've also got the analog for models, which I guess takes some sort of limits. Do you actually show that those are different from any of the ultrafilter ones, or is it possible that the ultrafilters actually give you everything that you get? Filters actually give you everything that you get from the models? So, I would work on that question. It's an interesting question. So far, I know that ultra-filter logic is stronger than the modeling logic, but I do not know the other direction that it is strictly stronger. So, I'm looking for examples. And I think taking a sequence of sparse graphs should do it. What else? Are there any questions on Zoom? No questions? Okay. Okay, if not, let's thank Mirna again. Thank you very much, and thank you.