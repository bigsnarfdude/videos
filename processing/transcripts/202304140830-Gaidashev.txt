Good morning everyone. So all things all good things come to a starting, we are finishing actually on a very strong note. And our first speaker is Denise Taidase from Ostala University. And he will speak on the randomization for real hand-on-like maps. Thank you. Okay, so this is the first talk. This is the first talk of two today, which will be about renormalization. And I know that I'm giving this talk to a very diverse community. So to some of you, two-thirds of this talk will be trivial. To some of you, this stuff might be new. So I'll go slow and introduce renormalization kind of first question, essentially, for two-dimensional maps. So, real and on-life maps. We're back to the real world. And on life maps. We're back to the real world. Okay, so ideologically renormalization is essentially long-term dynamics, so higher-order dynamics looked at at small scales. And we in the renormalization community, we prefer to think about it not as DM, but as a method, a technique to prove something. Results of the kind. Normal forms for the rescale of long-term dynamics or triangulations of wisdom. Carly pieces of wise maps, construction of those polysis maps, and a study of the endurance sets, via attractors or different kinds of endurance sets. So let's say my talk will essentially fit in two parts. In the third one, if I will make it, if we have time, I will mention something about it. I will first introduce a randomization scheme due mostly to Lubich, Martins, and Andre Carvalia for dissipative analysis. For dissipative and online maps, real maps. And then I will kind of comment and see a little bit more about the recent progress as far as large Jacobians, conservative maps, Jacobians agree to one. Finally, take that time and talk a little bit about extensions to rotation domains, be it annula or single disks. Alright, so let's start the unimodal map. So let's start the unimodal map. We'll know, we'll say that it's renormalizable if there is a sub-interval of the domain which is returned to itself by the second iterate. So I will not talk about generalization or combinatorics, but I will just, you know, for illustrative purposes, I will concentrate on the basic period doubling. Whereas the theory has been developed for. Alright, so the Riemannization operator itself is the second iteratory scale by a fine transformation. By the fine transformation, and it direct relates one dynamical system on a unit, another dynamical system on the same unit interval maps rather than one and another. So within the class of smooth unimodal maps, so U stands for a sufficiently smooth unimodal map properly normalized, which I'm brushing onto the rubber. We can look at the subspace of infinitely normalizable maps. So maps for which you can. So maps for which you can repeat this procedure infinitely many times. And then, of course, we have this famous theorem, first conjecture, then theorem that within this glass there is a 5-in-bound fixed pool. All right. So now, so let's put some domains, pick some domains. I will stand for intervals. Will stand for intervals, B will stand for two-dimensional boxes or domains, superscripts. H and B will stand for horizontal, vertical things. And thus, let me introduce a non-like map as a map. It's a map which maps verticals to correspond and horizontals to parallels over the vertical line within its domain of definition, which is B device. The main implementation, which is B evolves my choice. Okay, so now let's concentrate on a very particular class of anonymite maps. That's where the perturbation epsilon is small and analytically small as measured by the uniform metric on a complexified B. B was the domain. Alright, so here's the complexification. Alright, so here's the complexification: two complex neighborhoods of the intervals, omega H and omega B, and a complex neighborhood of the set B of the blocks. So here A subscript on a space will stand for a mixed polymorphic extension to that, and that analogic extension to A. So first we extended the unit model maps from the horizontal. maps from the horizontal to some complex neighborhood. And now I'm extending the space of non-maps to some complex neighborhood of the box d. Alright, so one-dimensional maps can be trivially embedded into the space H or space of such maps or what is the main one that stands for analogy. Now let's talk about Now let's talk about what it means to be renormalizable for non-like maps, first geometric maps. So what you do, you look at the geometry. And the geometry, if you're not too far from the unimodal case, it's guaranteed this form. So you have two fixed points. One is a saddle, another is a full saddle. And the unstable manifold of one of the saddles should intersect the stable one, along with single. Stable one, the one is single for it. Then you have the following picture. So let's look at this block. That's a kind of like a D, right? So this block under the first iterative goes onto this block, then under the second iterative it goes onto itself. So here we have already a geometric parnormalization domain, some subset of V, of the domain of the non-like map, which goes inside of itself into the second. Well, the problem with this simple With this simple construction, the problem: if you just look at the second iterate, rescale it finally, the new dynamical system is not going to be my points, which was this part. So that you would have the appropriate mapping of poly issues. So, one of the key ingredients of the organization scheme for dissipative and online maps is. Dissipative in all like maps is straightening of set and of an normal. So here I'm saying now that the horizontal volumes so the leaves of the horizontal volumations are not really vertical lines. That's for the second free renormalization. That's how we usually call it. Renormalization, that's how we usually call them culture. But the slopes are rather small, very called slopes are rather small, and then they can be bounded in terms of each other perturbation. That is, in terms of the uniform norm of epsilon. Epsilon was our perpetuation of the one-dimensional dynamical system. And here's this wonderful observation by Andre Michel Markov. Andre Michel Marker, that you can actually straighten the second integer back to the non-like class using this horizontal transformation. So the point is to follow. If you look at the pre-organization straightened out by this horizontal hypermorphism, then the resultant map G has to fall before it's very close to the model. If it's dominant part, G of X, that's controlled by that expression. Let's control the light discrimination. It is a non-like and it's to the national park became smaller. So the prefaces in my spaces, they denote the size of the perpetration. So we have epsilon, now we get epsilon squared. That's the whole, that's kind of the key explanation in this whole scheme. Ring or mutations of two-dimensional dispute non-life maps, they converge one D. The converged 1D dynamical systems super exponential. Okay, so now let me introduce the operator itself. So the operator is creator normalization, and then you have a project, then you conjugate it by the horizontal transformation and the winner of scaling as to recover the size of the original control. So here actually for the fixed function itself, which is quite important. Itself, which the Feigenbaum is pointing, is lambda is exactly the Feichenbaum scales. So the natural question is, what about convergence of these renormalizations? Or do they converge? And this convergence can be studied by utilizing these three key estimates. So the first one is the second one. Right, the second one is that renormalizations of a non-like manner, they are super exponential clots to one-dimensional approximation. So you can come up with a sequence of embedded one-dimensional dynamics, which again is a unimodal model. That's one. And second is that these unimodal models are not. And second is that these unit model maps, they actually converge actually to symmetrically two if I give all methods on them. And that essentially allows us to want to prove one is that the one initial looks for market markets and their center of paper. The hyperbolic theorem that the two-dimensional renormalization algorithm for non-like maps is hyperbolic, has a fixed point which is the. It has a fixed point, which is the invading fixed point. It is hyperbolic at that fixed point, and the unstable dimension is of the unstable dimension one. The stable manifold is of coefficient. And it's actually what coincides with the stable manifold of one-dimensional dynamics of the in modern models. So the two-dimensional part in the spectrum is. Alright, so what can one say about existence of invariant sets for maps like that? And the invariant sets are constructed with the help of the so-called renomination microscope. So you will see now in the next slides lots of notations, subscripts, but in the nutshell, Strays. But in the nutshell, this is nothing but constructing a counter set with the help of an iterative function system. So when people say a randomization microscope, it's just a fancy word, a fancy phrase for an IFS. My IFS is generated by two transformations. One is important change, lambda, and the food is output. And the other one is the current change, that's the focus on. Should be quite dynamics. So since I will be doing this construction at different levels, all of This construction at different levels, all of these objects are bladdered by the randomization methods. So one can now start composing them. So here, the letters omega k, they belong to the alpha b0, one. One can start composing these contractions, and they're contractions because lambda is a strong. And obtaining various branches of this fernalization method. So I said that already, this is function. So I said that already, this is Frank conference. So there is some sigma less than 1 such that the norm of the derivative of these vectors vanishes geometrically. And then one can start mapping the original domain of the map, which I will be remembering by these branches into covers of what will be eventually a cattle set. There's a picture. One of the branches of the microscope maps the whole domain into this kind of small set, and then you move that set by dynamics. The composition of that, but that would be the second part of our basic mapping in my microsoft. So we'll see some more pictures a little bit later and this would. So, you would obtain some deep level set or set in a deep level cover inside one of these guys by composing, looking at one compositions of this mass box with various indices to reward. That's how one builds these covers to check notify only the labels, the word which has been used in my or no in my Microsoft version. My microscope. These are images of the original set under microscope branches, and they have very nice properties. So, first of all, the non-like map permutes those pieces as an endometer. So, essentially, a domiter is an operation of any one of this group. And we have this nice property that one of them sets are permitted with the exception of the last one. With exception of the last one, I did except the last one here. Okay, so the last one, the last one of the sets would be mapped inside of the first one, which is quite a dispute now. And if one looks at the intersections of all these covers of all metals, then one obtains a campuset here. A campuset and the dynamics of the non-like. And the dynamics of the non-light map on this canvas side is actually present in the last two systems. Right, so one can ask the following question. So what happens to these sets? So if one has here's my current set, so here's some piece of Is some piece of some level VM, and we got then inside of this piece, I got two pieces of the next level. So one can start asking the following question. How do the diameters and the distance between these two sets compare to it? And we will say that the geometry is of a camera set is bounded if these two things are comparable at each level. And if they are not. And if they're not, then it's not bound to work. Of course, since it's a two-dimensional picture, the situation may make it much more complicated. We might have the set than this set wiggling around with that. And for RB, for large carbons, this happens exactly. Okay, so um so let's um specify Let's specify this a little bit more. Now, suppose you are for an affine transformation of these two pieces, and after an affine transformation, you want to compare these two pieces to the corresponding pieces for the one-dimensional dynamics. So, those two intervals, so for the one-dimensional dynamics, those pieces could be equals for them by one dynamics. So, after amplifying transformation, if you You compare those two pieces, and you see that the Hausdorff distance between the two-dimensional gaps and the one-dimensional nose is small relative to the diameter of the envelope of the one-dimensional. Then we would say that this generation has epsilon precision. So it's a matter of how close the two-dimensional pieces are positioning themselves with respect to the one-dimensional. Respect to the one-dimensional numbers. So here is a result by Ludwig Veroale and Morkins: is that if you look at the measure of epsilon precision generations, then this measure is actually approaching one geometrically if you go deeper in the level of approximation of the economist. So this is something that we call probabilistic universality. Probabilistic universality. And one of their bigger theorems was that canvas sets for highly dissipative two-dimensional and online maps are probabilistically universal and cancels probabilistically bounded, which means that these garrisons are commensurate almost everywhere with exception of some, well, with except outside of some exceptional places within this. So bad things. So bad things can happen, but they happen in the spots of zero-measure. Yeah, so similarly, one can consider the issue of conjugacies between two such maps. So let me kind of sketch this picture here. Alright, so these are, this is the stable manifold from my renovation. Stable manifold for my normalization. This is that stable one. And let's look at two maps on the stable manifold. So both of them are conjugate to the fixed point, and one can ask the following question. So what about the conjugacy between their tractors, which are the kind of sets? Okay, and one again can look at where that country is. Look at where a conjugacy is sufficiently differentiable. So, if a conjugacy is 1 plus 80 differentiable, then we say that the dynamical systems are rigid. And it turns out that these dynamics are probabilistically rigid. That is, again, so the restrictions of these maps on the camper sets, they are one was later. One plus data conjugate by one plus data transformation outside of some bad spots of zero measures. Okay, so this is probably Okay, so here I'll go very quickly about just basically how the results are in this theory. So it has been generalized to unimodal combinatorics, general unimodal combinatorics by Peter Kelser later. Else leader, then another result is that if one takes a family, let's say parametrized by the average expressed by that relation, by that expression, then the set of parameters for which we have actually unbounded, probabilistic unbounded geometry has full measure. So this is ubiquitous, this bad things ubiquitous with values. And no, the restriction of any one of these maps to its attracting canvas set is not partially hyperbolic because the stable and neutral directions along the campus set are not really continuous. And finally, if one looks at the attractor. Attractor here, the attractor is not just the canvas set, the attractor is actually a canvas set union with all unstable networks of the periodic orbits, which surround this attract, which surround the canvas. Then the geometry of the heteroclinic tangle is controlled by this average cubin. So average rubbing seems to be some kind of landmark parameter here. So, some of these results have been extended. Well, I shouldn't be using that word because actually the randomization theory itself has not been extended to mildly discriminated defaults. I'm giving, just to want to remind you of the definition of a mildly disconnected deferred practices. It's a decode whose domain is separated by stable manifolds of points. So, quite recently, So, quite recently, Grovesnik, Jones, and Trassia, they proved that my detail with the vanishing topological entropy is either more scalable or infinite or normalizable. And in fact, more than that, that infinite normalizable maps, they constitute input. So, infinite normalizable maps, they constitute the boundary of the dimension zero. So, later today, we will hear a talk from Later today, we will hear a talk from Jung about progress towards large educators. I'm not going to say much more about that. I've got 45 minutes. All right, so now I'm going to switch to the core of my talk today to what of these properties are inherited and which ones of these properties actually change if we go to Japan equal to one. So, first of all, there are some really difficult issues with defining randomization for conservative maps. The first one is that it's a conservative map, so it has to map the main, any iterative maps. If you want to return a domain onto itself, you cannot guarantee full return. Well rather, you will be hard pressed to construct a domain like that, which would be mapped onto itself exactly by the second iterative. Unto itself exactly by the second intrins. So, second, there are clear analytic difficulties. We're very far from one-dimensional dynamics, and that's why these a priori bounds, which have been borrowed from one-dimensional linear model maps, they cannot be used here. They are absent. To date, there is no construction of a priori bounds. So, a priori bounds, just comment, it's a fancy word to denote the To denote a pre-compact subset in the functional space, which is randomization and mirror. That's the key to construction, most of renormalization constructions, be it a periodic point or hyperbolic feature. So now let me introduce the classical non-like maps for which some things are known and have been done. So I will fix I will fix uh so these are maps which can be fixed. These are maps which kind of be experiment, and I will normalize it to be equal to zero, real, but extendable analytical to some domain of their real domain of the measurement, some neighborhood in the real domain. And I also, for technical purposes, I require that they have a twist condition. So the map moves points horizontally at different ranges. Horizontally at different rates, they should go vertically. They should cross the main bridge. So, so far, the a priori bounds for the equivalent rather have been done in a computer-assisted way in two separate publications. Which I will mention in a second. But now, let me actually, maybe, you know, just a little bit of hand-waving to describe what kind of nav. Handway to describe what kind of maps this computer system approach deals with. They are non-like maps, but they are in non-like maps in a different set of coordinates. So one chooses, for some reasons, two involutions and conjugates in a non-like map to obtain something which I would still call in a non-like map or maybe FM of width work because that that has been done first by graph ladies and others in ages. Operators in A C. So maps of this formula will call the mutated non-lock, non-like or egg non-popular. And then the randomization of crater, here it's defined by brute force in the sense that if you take a second it really, and then you rescale it in properly. And the rescaling is just, you know, some normalizations of the to of where the fixed point goes under under the other. After the pre-organization of the data. So, one thing that I want to underline right away is that these two scaling stay essentially, that's the thing which puts this aside from one-dimensional context. We will scale here much stronger in the vertical direction than in the horizontal. So, here's the theorem, as I said, has been broken into papers, different bits and pieces of it. Different bits and pieces of it. So, first of all, that trigonomization operator which I had on the first page, on the previous page, has a fixed point and it is hyperbolic. In some appropriately defined dynamic sub-manifold of the space of analytic units of this complex extension of the real domain, the operator has one-dimensional local and steeple manifold. Then, the structure of the stable manifold is defined. Of the stimulus manifold is the following. There is a sprung stable inside of this cable, and the contraction from the sprung scable is sufficiently basketball. That's a tile was important in our tools. Then, the rest of the, so the structure of the stable manifold is like that. It's like that. You have a strong stable, and transversely, we have a foliation which is obtained by moving maps on the strong stable with a quarton change. So that's very nice. So anything outside of the strong stable can be obtained by obtaining a quarton change from the strong scale. Finally, some quantifiers. These risk elements, as I said, they are very different. So you have one quarter in the, for example, the match. In the horizontal dimension, and you have one quarter squared essentially in the vertical dimension. It's not exactly one quarter squared, but that work. Alright, so now let me discuss the counter sets, which one our teams here uses exactly the same procedure, the same renormalization microscope. You take the original real domain and you pull it deep by this iterative function system. So here's actually a better main picture of how these covers are taken. All these covers are tinkered. We think this domain, whereas one of the branches of the magnetization microscope, we have seen this smaller piece inside, which would be one of the pieces in the cover of the stable set now. So this stop being an attractor, this is now conservative dynamics. Nothing can be attracted. It's a stable set. And it's a stable set in the following sets. So theorem from Sarah Sander Bolt. The camper sets The campusets of these guys of integrated normalizable conservative normal like maps have one characteristic exponent zero. So there is no distinction in foliation. So it's one characteristic exponent. So I kind of physically think of this as, you know, it's a set of points. If you stay close, if you start close to that set of points, you stay around. Close to that set of points, you stay around that set of points for a long time. So that's why it's stable, so not in the driver. So it's geometry. So first, the natural question, can this counter set be included into some kind of curve? And what about the properties of this curve? So it was shown by a student of mine that this contained in a witch curve but not in a curve. Is contained in a winchard's curve, but not in a smooth, which would be surprising. So it's the same result as in highly disputed non-like maps, actually. So here we have a similarity with disputed maps. So how about unbounded geometry? So this difference in scalance begins to play an essential role in showing that there is a lot of unbounded charm. So you take this to say. So you take these two sets in some cover. Well, there is an exact choice where each set is there. So first one, what one does, one shows that they're vertical positions, one above the other. So there is line which processes both. Now you take the trial branch of the market, which is where scalable already, just for us to learn it. This guy is much larger than this. So you squash in the vertical direction much more. These two resulting pieces, they are relatively blocked and very close to each other, alright? After the first squash. Now you can actually continue applying these trivial batches of the microscope. And this thing of squashing them, getting closer, getting longer. Them getting closer and getting longer will actually become even more discrete. So, if you look at sets, which are labeled by those two words, they're very long and very close to each other. So, here's here. That's how you recover one particular spot where you have a mounted junction. The distance between them is much smaller than the length of the set. So, you have this incompetent distance. So, next thing to do is to spread this around by dynamics. Drowned by dynamics. So maybe I will not talk too much about this. So there is some, for that, you need some control of derivatives, and the control of derivatives here is very nice. So basic equalities, they say actually that derivatives, they do not generate with k. So k is orbits of some length within the orbit of length to them. So, in what sense is the tip a tip? The tip is in the sense that it's the image it's encoded by the word of infinite zeros. By the way. It's encoded. It's a point in the camera set which whose coding is infinite zeros. So now it is just zero. Isn't the like the combinatorial coding? Like the combinatorial coding, kind of arbitrary. I don't see why. Because you could just, yes, right? You could just permute the coding. Okay, you can permute whatever you want, but just think of that as the point in the candle set which corresponds to the infinite composition of trial branches, of lambdas, of rescalings. No dynamics. That's how we're took. Okay. So with that done, with that control of the turn. With that control of the derivative, what we were able to show is that, right, so this property of diameters of this cells, diameters, being much larger than the distance between them, actually can spread around. If you fix the level of the cover, there is a definite measure of instance which satisfy this condition of in an absorbed build. The diameters are much longer than in the DD6 condition. Okay, so done, same picture. Now I'm going to look at two different cells. This one, the square one, and this block. So if you start rescaling these two bases by trivial branches, by rescaling, you know, everything now happens horizontally. The distance between them will scale with one dirt and the diameters will scale with one dimension. So these are two pieces which will Two pieces which will be kind of the germ for spreading around boundary networks. Networks, bounded germ. And again, a theorem of the same kind of labor that the measure of pieces and their specific labels for these pieces in their proper colours, such that the distance between them is commensurable to their sizes, as expressed by the. Sizes as expressed by that. So that measure is something that, and that's actually a counting measure. So you count the number of pieces relative with that particular property relative to 2m. Okay, rigidity. So, what I want to attract your attention to is that branches of the renormalization microscope. Normalization microscope, the external vectors can be actually bounded from above and from below by very different contexts, by very specific content. Again, measured with the help of some computer systems. And another thing that we have observed, which became crucial in our approach, is that the capricorn rate on the strong stable nanophone, which I described, lies inside the stable model, is gap strong, is measured to H21. So what is gap? One of those. So, why is that important? It becomes important if one starts constructing conjugacies between two maps on the stable network. So, here's this example picture. One, an unlike map there, and another one there on the stable network. So, there is some canvases and covers at certain levels. Ignore the score, just think of this as eat once again. This is eaten, some cover of some level of these kind of things. So, how do you want to construct a conjugate signal? That's a very general thinking ornamentation. So, what you do, you look at a very deep color, or at least half a set, as given by Owen did the meaning of very high minimalization by a very long microscope. And now you go through with the inverse microscope, you identify these two. You identify these two dynamics essentially because these two normalizations, the carry blocks, they converge to the fixed point. So these two guys under anonymization, they converge to this fixed point. And then you go forward with the other microscope. Then you take the property at the exposition. That's how you construct the contrast. And what we were able to show is that the conjugacy, the convergence of these conjugacies can be nicely controlled. Be nicely controlled. This number is smaller than one. The derivatives of this branch of this can be nicely controlled only if it is part of goodness. That's where it was important. That's where the convergence from the strong stable became important. And finally, that the derivative can be made better on. Actually on cover two on the canvas. So that allowed us to close the surprising result, which is recovery. Yeah, yeah, all things. So which is a recovery of rigidity. So the loss of rigidity which happened for these non-like maps actually is not happening for conservative maps. So for conservative maps, we have nice rigid transformations of dynamics. Of the names of two infinitely normalizable conservative non-life names. Now, to finish off, let me kind of give a burden's idea of what is gathering here. And I'm just looking at two facets of two questions, rigidity and boundance of charge. For unimodal dynamics, everything is rigidly bounded. We're dissipated in non-light maps. We have non-rigidity, non-bound bounding, but both in the probability sense. That happens only on the sets of. That happens only on the sets of zero-munction independent set. And in the conservative case, very mixed situation happens. You have rigid situation, but the geometry is wide. It's unbounded. You observe both bounded pieces and unbounded pieces. So the thing that I wanted to say about escape completely just. So, last slide, which is thank you all for listening and especially the organizers. 