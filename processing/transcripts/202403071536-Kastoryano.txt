It's a pleasure to introduce Mike Mr. Yano. He's going to talk about what will be something that we need to see. Thanks a lot. Thanks to the organizers. It's always a pleasure to be in Bampshaw. Especially always a pleasure today with all the snow, this time with all the snow. And it's also a pleasure to be presenting this work because it's sort of the end of a cycle which is started a long time ago. It's really true. This is work together. This is work together with Anthony Chen, Vernando Wandau, and Andras Gillian. And the major contributions to this work were done by Anthony and Andras. So I want to talk about quantum Gibbs sampling algorithms, and to get to that, I'm going to start with the classical Markov chain Monte Carlo. It should be a review from hosting. So the idea, classical Markov chain Monte Carlo. Classical Markov chain Monte Carlo is that you have a vector, a positive vector, the probability distribution. And for the sake of concreteness, we imagine it on a binary space, dimension n, so a hypercube of dimension n. And we want to prepare this state or sample efficiently from this state. The basic idea of Markov chain Monte Carlo. The basic idea of Markov chain Monte Carlo is to construct a probability transition matrix which converges to this state upon many, many iterations, upon infinite many iterations, with certainty. And this might seem a bit crazy, right? Because you don't want to write down the initial state in order to the initial vector, apply 2 to the n by 2 to the n matrix onto it. This wouldn't give you anything at. Onto it. This wouldn't give you anything advantageous. But the key insight of Markov J. Monte Carlo is that sometimes you can perform these iterations on sample by sample. And iterating the matrix sample by sample is something which can often be done locally. And so once you update the samples a sufficient number of times, you obtain a faithful sample from this distribution. Problem distribution. And the specific class of problems that we're going to be looking at are ones that satisfy detailed balance. A detailed balance is a very convenient symmetry in the Markov chain, which guarantees that the particular probability distribution, pi, with which the Markov chain satisfies detailed balance, is guaranteed to be the stationary. It's not guaranteed to be the only stationary state, it's guaranteed to be a stationary state. If you have ergodicity, Stationary state. If you have ergodicity on top of that, it's guaranteed to be the only. And then the key algorithmic questions you might have are: given pi that you want to prepare, can q be implemented efficiently, or can individual steps of q be implemented efficiently? And then how long do you have, how many times do you have to iterate this before you're confident that you're very close to the state pi? Okay, this is the mixing time question. Question. And there are a number of famous applications of this. Two that are worth mentioning here are problems in theoretical computer science and especially a large class of problems within statistical mechanics. We'll be focusing on the statistical mechanics. What was that picture there? It's Monte Carlo. Oh, okay. So the most famous among the Margov J. Monte Carlo algorithms for statistical mechanics is the Metropolis-Hastings algorithm. The setting is you're given a graph and you define a Hamiltonian on this graph. For the sake of concreteness, we consider an Ising-type Hamiltonian. And the state we're interested in preparing is the IMP state of the Hamiltonian. So E, the exponential base. E the exponential beta H, some positive temperature beta. And in the Metropolis-Hastings algorithm, what you do is you build an exploratory matrix, T, which is ergodic. But the one you typically choose is you pick a site, you flip the spin at that site, then you pick another site, and you flip the spin at that site. But that matrix T is This obviously doesn't have pi as a stationary state. So, what you do is every time you flip a spin, then you evaluate the energy difference between the new configuration and the old configuration. If the energy decreases, then you keep the new configuration. If it decreases, then you only keep it with a certain probability, which was proportional to the exponential of beta times times the energy. times the time, times the energy difference. And what you can show is that this, so the probability transition matrix corresponding to the metropolis algorithm satisfies detailed balance. It's going to be ergodic by construction because T was ergodic. It satisfies detailed balance also by construction. So you're guaranteed that to converge to the stationary state in the limit of infinite many applications. And in practice, this often converges. And in practice, this often converges rapidly. For the rest of the talk, we're going to be considering a continuous version of the metropolis algorithm. So instead of having a discrete probability transition matrix, we're going to consider a Markov semi-group. So it's the continuous time equivalent of a probability transition matrix. And we're going to be focusing on the generator of the semicolon. Of the seven. Okay, but you can essentially construct it in a similar manner. What's nice is that it has many of the same problems. You can sort of go from the continuous semi-group, so from the semi-group to a discrete iteration of the channel. Quite simply. So the metropolis algorithm is very convenient. In practice, for simulating statistical mechanics models, but it's also very convenient in terms of teaching us a bit about the physics, the underlying physics. So there's a class of equivalences which is really quite remarkable, and which says that if you consider, there's a fundamental relationship between the dynamics of your system, so how rapidly you converge to your Gibbs state, and the static. State and the static correlations in your system. What this equivalence says is that if your semi-group converges rapidly to its stationary state, then the correlations have to be local. So they decay exponentially. And this is a very, very, very strong equivalence. Because you go from a situation, say if you consider a two-dimensional Ising model, at high temperature, you're going to have rapid convergence and exponentially decaying correlation. And exponentially decaying correlation. By rapid convergence, we mean convergence in a time logarithmic in the volume to a situation beyond the phase transition where the convergence time is exponential in the volume, so you have two exponential separations in the mixing time, and where you have long-range correlations. Correlations that are arbitrary long-range. At the intermediate point, you get this one exponential. This one exponential separation where you have polynomial decaying coefficients. That's a question. So, how reverses are the exponential time of? So, they're both lower and upper bounds. They're both lower and upper bounds. And like I wrote in this paper. Um the everything like exponential low bounds on the work time of an architect is quite hard source. Yeah. I think it's quite hard to always yeah, I would I would just see like it's an if and only if statement. If and only if statement is in the circular hundreds of papers on this. I'm not sure the lower bound is in this particular paper, but I can take something out of it. Good. In the applications of And the applications of Metropolis Monte Carlo are many, many, many. Obviously, in physics and chemistry, optimization, simulated idealing, and its variants, we often use versions of either Gibbs sampling or Metropolis Monte Carlo. In data science, it's used extensively for Bayesian inference for graphical models. Theoretical computer science, it's useful for discussing approximate counting and other problems. So, it might not, I don't, for this crowd, I don't need to convince you that it would be useful to have a quantum analog, but more. Analog of the metropolis algorithm. And at the very least, it should be useful for physics and chemistry simulations, potentially also for optimization. And somehow there's also a fundamentally important aspect to this is that most of our physical theories are based on the assumption that nature behaves or follows a Gibson distribution. If we look at ground states, it's because, consider ground states, it's because we believe that they represent the actual system is in the world. The actual system is at a low temperature. This is probably familiar to most people, but there's a very, so there's a correspondence between classical probability distributions and density matrices, particular positive. Similarly with energy functionals, so an energy functional is a classical analog of a Hamiltonian. As a classical analog of a Hamiltonian, a Markov chain, so a matrix whose columns sum to one has a correspondence which is a completely positive trace-preserving map. So Markov, probability transition matrix takes physical states, so probability vectors to probability vectors, a CPTP map takes density matrices to density matrices. Markov generators also have an equivalent, which are these Lindblot-Master equations. Bloodmaster equations. And finally, detailed balance has at least one extension. There are several extensions, but this is going to be the standard one. We can see. Alright, so this framework has already been fairly well developed. And then we can think of how we want to build a quantum metropolis algorithm. And the first thing we want to try is really to copy what we do classically. So we consider similarly a graph, but now we have a quantum Hamiltonian. A graph, but now we have a quantum Hamiltonian on this graph. We consider the quantum Gibbs state. And unlike in the classical situation where the eigenstates of the Hamiltonian are product, are basically basis states. In the quantum setting, of course, eigenstates of the Hamiltonian can be highly entangled and typically are. So we consider the energy eigenstates of the quantum Hamiltonian at eigenvalues. And eigenvalues. And then what we do is we build this exploratory chain, which is instead of just performing one flip, you perform one Pauli operation, so either X, Y, or Z flips. And then we want to give it this Gibbs factor, right? And what we'd like to do is evaluate whether the energy has increased or decreased after our Pauli flip and accept and reject the move. The move according to this probability, in the same way as metropolitan algorithm does. And this is really what this seminal paper by Kristen Teme and people did in 2011. So they constructed a quantum channel that can be implemented efficiently, well, presumably efficiently on a quantum computer, and which satisfies detailed balance. This is sort of the best you could hope for. The best you could hope for. It can be interpreted as a weighted autumn walk on the island states. And it was not an easy task. So somehow they had to overcome at least two seemingly difficult obstacles. The first was the need to compute the eigenvalues precisely, and there it seems obvious to use phase estimation to do this. And the second one was somehow to do the accept-reject steps. To do the accept-reject steps, which is difficult because you can't clone the information. At the time, they thought that the second problem was the bigger obstacle. It turns out that one's relatively easy to overcome. This first problem, on the other hand, has really been thorny. And it's so thorny, in fact, that there was an issue, there was a problem in their proof. And in the subsequent four pages, And in the subsequent four papers on this, there have been many other papers, but in the subsequent relevant papers, there have been either unphysical assumptions or errors in the proof of trying to... So somehow extending the metropolis algorithm to the quantum setting is easy if you allow yourself for infinite precision phase estimation. But obviously you can't implement infinite precision phase estimation on a quantum computer. As soon as you don't have infinite precision phase estimation, As soon as you don't have infinite precision phase estimation, then you lose detail balance. Somehow, you want to reconcile these two things. Essentially, every attempt to do so either failed or introduced some unphysical assumptions into the code. Not to take anything away from the original paper, it was a phenomenal paper, it still is. But what we've done in a sequence of two papers is really a fixed. Is really A, fix all the problems of the original approach, and somehow we came up with a new approach which is much simpler with every single aspect. Which I understood on your previous slide, the update rule is, so it's an update that needs to map an energy agency to another energy ID. Yes. We cannot do that locally. Cannot do that. Gen in general. Non-computing Hamiltonian. Non-computing Hamiltonian is generically going to have exponentially close eigenvectors, and they're generically going to be very, very highly entangled. You have to resolve, you have to build up the entanglement and resolve the spectral gaps. That's why it's a difficult problem. Right, so why do the previous attempts fail? And it's really this fact of not being able to perform phase estimation. Able to perform phase estimation to arbitrary precision while preserving detailed balance. And it really is related to this energy-time uncertainty relationship. So if you go down this path of trying to approximately satisfy this, you're really going to bump into some fundamental obstacles. So now before showing how we fix this, I want to divert and talk about how this. Talk about how this is related to physics. So far, we've given it a more algorithmic perspective, but it turns out that it's closely related to physics. Unsurprisingly, because it's related to the phenomenon of thermalization. So thermalization, as Martin said, is a tricky business in quantum setting. But there is one particular framework where we can talk quite reasonably about thermalization, and it's if we have a system which is weakly coupled to a thermalization. A system which is weakly coupled to a thermal bath. Okay, so in this situation, we consider it a system Hamiltonian, a bath Hamiltonian, which is typically going to be an infinite sum of oscillators, and they interact weakly with this interaction term. We also assume that all degrees of freedom of the system interact with degrees of freedom of the bath, so there aren't any subspaces which remain untouched. If your bath is forgetful, Is forgetful, or if it refreshes very rapidly, which is the Markovian assumption, and if this epsilon is small compared to any spectral gaps in your system Hamiltonian, then there's a standard derivation of a Markov semi-group, the Davies equation, which describes the evolution of the system. So if these assumptions are System. So if these assumptions are satisfied, then the evolution on the system is a Lindblad semi-group. And the Lindblad semi-group has this specific form. So where you have jump operators, which are the Fourier transform of the time evolution of the original jump operators of the exploratory map. Then you have a coefficient in front. Then you have a coefficient in front, which is a function of the momento, so the energy differences. And this corresponds to the bath correlation function in the derivation. If this bath correlation function satisfies this particular relationship, and it will satisfy this particular relationship if it's an ohmic bath, which is what you assume if you have a bath of bosonic modes. And bosonic modes, then you can show that the Davies master equation satisfies detail balance. So that's great. Also, because you built it from this exploratory operation, this exploratory map, you can guarantee that the Gibbs state is the only stationary state. And this gamma, do you construct it or is it given to you by properties of the environment or whatever it is? It's given to you by properties of the environment. If the environment satisfies. The environment. If the environment satisfies certain properties, which are relatively generic, then it's going to satisfy decode patterns. Which is remarkable because it's telling you that nature thermalizes in a way which is very similar to this artificial algorithm, which was developed independently of considerations of thermalization. And it reduces exactly to globodynamics in the case of a classical Hamiltonian. If you start in an eigenstate. Hamiltonian, if you start in an eigenstate of the Hamiltonian. A while back we considered the question of mixing time of quantum dynamical semi-groups. That's where we first introduced these contraction coefficients. We're just trying to solve this, well, introduce the framework of mixing. Introduced the framework of mixing times for quantum Markov chains. And a couple of years later, we tried extending this structure theorem relating dynamics to statics, to the quantum setting. And I'd say we were sort of partially successful, and then a number of people in the audience, many of the organizers, have worked on this problem. I've worked on this problem a lot since. And I'd say that for commuting Hamiltonians, not classical Hamiltonians, but commuting Hamiltonians, this program is relatively under control, it's relatively finished. On top of that, this is the standard model we consider to talk about self-correcting quantum members. Most of the quantum error correction codes we consider are stable. We consider our stabilizer models or commuting models, and if we talk about self-correction, we usually ask whether there's a subspace, well a qubit subspace, which subspace which survives for a long time in this status model. Okay? So there are many things. I think I'll cover it in the next slide. So are you saying specifically about quantum members or? So what was this statement about exemplars? So we're able to show in the commuting case that the mixing time, so that basically a monomarkov semi-group mixes rapidly if and only if. Mixes rapidly if and only if it has exponential decay correlations. It's not quite true. We need a bit of a more fancy notion of decay of correlations because there are still funny things that happen at the boundary. What really matters is how you go from convergence, from rapid convergence on a small system to rapid convergence on a larger system. And classically, what you'll do is you'll be able to patch out the boundary, because the boundary is also going to be essentially. Also, going to be essentially a product state, or can be represented as a product state. Because quantum mechanically, you can have entanglement at the boundary, you can have topological order, so it is more tricky. But many elements of this correspondence have been established. They label, as you can, are not necessarily local, right? If you're a source of some local interaction, you require. No, that's it. If you're dealing with a commuting Hamiltonian, they are local. Hamiltonian, they are local. As soon as the Hamiltonian is not commuting, then the jump operators become completely non-local. So what goes wrong in the non-commuting case? It's almost everything. So first, the derivation of the Davies equation completely breaks down. The second assumption we had, which was that the coupling to the bath had to be The coupling to the bath had to be small compared to any spectral gap. Of course, this becomes completely, this becomes unreasonable in the non-computing case because you're generically going to have exponentially small gaps in the system size in the spectrum, which means that the coupling has to be exponentially weak. And this is not a reasonable assumption in nature. It can be solvaged, and it has been solvaged if you refresh the bath and you really keep track of things, but then you lose control of the game. But then you lose control of the Gibbs state. So you can derive a Lindblad-Master equation without assuming that the coupling to the bath is exponentially weak, but then you don't know if its stationary state is the case. The other thing is that, as you mentioned, the jump operators become completely normal. So it's not obvious how you'd implement the jump operators on a quantum computer. Jump operators on a quantum computer. One thing you might want to do to sort of tame the non-locality of the jump operators is to introduce a damping term. So you introduce a damping term on the jump operators so that beyond some scale sigma, you can truncate. You can truncate the integral. Right? At very little cost. And what does this mean, like physically? Is this like you only turn them on inside with this activation function, or how should I just understand this thing operationally? It's not physical in the sense that we can't derive it from first principles physically. So it's algorithmic. Okay, so or then algorithm, yes. It's a type of UV cutoff. It's a type of UV cutoff. And then the question is: is this legitimate to do? Legitimate means, you know, if you perform, if you impose a damping, do you still have control over the stationary state? And it turns out you do in the special case where this sigma, this damping, is large compared to the mixing time. Now, if your mixing time is very, very short, this is a reasonable assumption. This is a reasonable assumption. It sort of recovers a form of locality, but most of the time in the mixing time, it's occupy short time. So it's of limited use in some sense. In this first paper that we had out, ironed out the technical issues with the previous papers by introducing this damping term. And it's by no means tricky-based. And it's by no means tricky. It's a long paper, it's very, very technical. So, this is a partial solution to the problem. If you really stick to this desire to jump, to really imitate a classical metropolis and jump between Eigenstates, this is sort of the best you could do. So, you're going to need to keep track of you're going to need to run phase estimation for a time which is proportional to the extent time. Time, which is proportional to the mixing time. Well, beta times the mixing time is the one. I thought you were talking about commute, like solving the previous papers. Those deal with the commuting case? Those dealt with the commuting case, and now what we've done is we've established a framework for the non-commuting case. But before you did that, did you solve something for the commuting case as well? Because you said that this thing was provably possible. What did you do for the commuting case? So so the original metropolis algorithm and the other ones I'm considering look for generic Hamiltonians. I'm saying. In the special case of commuting Hamiltonians, then you can use a Davis general. And they already had shown that this could be. And so your main thing is working out what they did generically for the non-commutative case. Oh, sorry, I have a method question. A very ignorant method question. So at some point you said that you had a problem where you can't do phase estimation to infinite. How does this solve the problem? Well, once you impose a truncation, right, then the time evolution, the weight of the time evolution beyond the truncation here, this is an integral from minus infinity to plus infinity. But the weights of the integrand become Of the integrand become more than exponentially suppressed beyond the scale sigma. This corresponds to forming a phase estimation up to a scale sigma, then ignoring the rest, and that's going to be an error. The thing is to show that this error doesn't affect the stationary state all too much. Simulation algorithm is relatively simple. Relatively simple. I don't want to get into too much of the quantum algorithm aspect of the project. So you have to keep track of all the jumps, you have to encode the damping, but it's not that ugly. The way to think about this is implementing the quantum trajectories picture, or simulation of open systems, but where you keep track of each trajectory. You won't be home before and they're stochastic. Stochastic. And the final cost is beta to the mixing time squared. So, sorry, how much? Is it like a cubic cost or time cost? Time cost. T mixes the mixing times. How long does the station does the how long do you have to run the semi-group before it can converge? Like what's the like the Davis like the the like the math of James that the Davis generates is also has a mixing time. But like is it the same mixing time for each Hamiltonian you have a specific mix. But for each Limbladian you have a specific mix and time. Right, but like the it is extracted from Limbladian derived. Scrap mixing thing had a polyn prefactor next to the exponential time. Yeah, linear n. That in here? No, yeah, so there should be log n funds. Log n because of the linear and n thing. So, is the problem solved? And I would argue, really, no, and for two reasons. The first is that algorithmically, it's very unpleasant that if you think back at the classical case or even the commuting case, mixing time might be Mixing time might be very long for your problem, but every individual step, every individual update to the Markov chain is efficient. Whereas in this setting, and in all the previous settings and things where I claimed it didn't work, even if you could get them to work, we'd still have this issue that an individual step of the update of the Markov chain is going to scale with the mixing time, so typically with the entire system. One thing. One thing. The other thing is that your jump operators are still going to be largely modulated. That's mathematically unpleasant. So there's an algorithmically unpleasant aspect, and there's a mathematically unpleasant aspect. What I believe is that it also renders this algorithm very difficult to use heuristically. Because you just don't know what the mixing time is in the vast majority of problems. And so you're going to get an error that you want to interpret. And you don't know if it's coming from the fact that you didn't run the chain long enough or because the individual steps. Long enough, or because the individual steps were precise. But still, relatively unsatisfying. And so the solution we came up with is really a bit of magic. I have to say, we dropped this problem eight years ago of considering non-commuting Gibbs samples because we just didn't think it was possible. And the solution is Is simple. So we stick to this damping term, which is Gaussian. And then we find a fine-tuned coupling, which resembles the metropolis update. There's this gamma term. Another gamma term which works is. Another gamma term which works is a is a Gaussian. I think I should try it out. And there's something special about the Gaussian because in the previous, so in the case of Davies generators, what we usually consider for omega Consider for omega is a, it's called a logistic function. Because the logistics function satisfies this relationship, which is interpreted as detailed balance at the level of the bath. And this is what you get naturally from a methomic bath. But it turns out, But it turns out that the Gaussian also has this property if you choose A and kappa coefficiently. Somehow you can extract this beta omega by completing the squares of a Gaussian. But the point is that a Gaussian is another example of it. And I'm not going to go through the proof, but it's not. But it's not so hard to imagine that when you consider so write the jump operator all in the energy, so somehow we're writing part of the jump operator in the energy basis and part in the momentum basis. We're sort of flipping between Fourier transform representations. If you write it all in the same representation, you can convince yourself that since the Fourier transform of a Gaussian The Fourier transform of a Gaussian is again a Gaussian, right? And somehow you can use the completion of the squares in Gaussians to specifically obtain this type of relation. That's where the magic step comes in. This gamma just comes from taking a linear combination of Gaussians. The difference between this one and the previous Java versus short. So the difference, the So the difference, the only difference is that we change gamma. The only difference. Damping is basically the same way. It's still a Gaussian damage. Damping is still Gaussian. And then we change gamma. But now you have this V di instruct the signal that you had before. F of T. Yeah. That's a choice. That's a more general class. Okay. Now, exploiting these properties of the Gaussian, you can show. These properties of the Gaussian, you can show that the first part satisfies detailed balance. So the first bit of the Lindla-Master equation is a CP map, not a CPT. It's not trace-preserving, but it's a completely positive map. And you can show that because of this property, it satisfies detailed balance. But the rest of the Lindla operator does not satisfy detailed balance. The second trick Trick, which is very surprising, is that you can always find a Hamiltonian term B that corrects detailed balance. This is in fact completely general. Whenever you have a Lindlett operator for which the first portion of the CP map is detailed balanced, you can always find the Hamiltonian which is also detail balanced. I mean it's in it's in limblab form. It's in limblab form. Oh, but it doesn't say it's how is it not TP if it's in limblab? It doesn't need to be TP. Because of some infinities, because things are infinite here? I thought limblat form if and only if CPT with the positive scam. So the exponential of T L for any T is C P T is the generic part. Yeah, you said it was not T P, but the generic. You said it was not T P, but the generator can can gamma be negative in your example? And then it's not necessarily. Okay, then it's fine. So a body can generically be written as fine acting on something plus Plus rho some kappa rho plus rho kappa dagger This bit is that bit up there and kappa is the rest. I'm saying that phi is a CP, but not necessarily CPTP. Yeah, okay. And the observation is that you can, if phi is CPTP, If phi is CPTP, then you can always find a Hamiltonian. Sorry, if Phi is detailed balance, you can always find the Hamiltonian, which makes this big also detailed balance. And what's remarkable in this construction is that for this specific choice of damping and gamma, then the Hamilton then the jump operators are generically local, and they're local on a scale which is independent of the system size of the scale. Independent of the system sizes theta. And the Hamiltonian B that we've introduced is a sum of quasi-will terms. And it's not that crazy. Somehow, it's some hyperbolic tangent of this R term. So the R term is the bit out there. Intuition and function can play some role in detailed buttons because classically we usually think about changing energy, etc., right? And what does that mean? This is a purely quantum effect. That's what's great. That's really quantum. Well, I'll get to the intuition in a second. There's a sum over V in Boar. What is that? What is that? Oh, a a new is just energy differences. Like all the energy differences you need? All of the energy differences. And like, are those not exponentially small? Yes. Way around it. Okay. I'm not going to talk about the way around it, but there's a way around it. Yes. So right now we have um Now we have jump operators. So for every A, this corresponds to the local site and a Pauli operator on a site. This is going to be integral one of the bottom. These are all going to be individual jump operators, and you're right, there are going to be many of them. Turns out that if you take as a different If you take as a different set of jump operators integral over d omega gamma omega to square root a omega. Then this also fixes the Gibbs state, and you can also fix it with the unitary. The unitary is also going to be quasi-local. Quasi-local. This actually is closer to what you would obtain from a weak system path coupling if you only have a Markovian assumption. If you don't do the second assumption. Sort of gives you cross terms when you apply them. These cross terms wash out if you have a strong Hamiltonian evolution. I was asking just a much simpler question. No, I mean, that's what I said. So this B is going to be for all energy differences. In principle, you want to take a sum over all of them. So for each energy difference, you get a jump operator. What you're going to do typically is if you do a trajectory simulation, you're going to pick one out. Trajectory simulation: you're going to pick one at random, apply it, do time evolution, pick another at random, apply it. It should be Hermitian, right? Yeah. Yes. Because the fan is not the same. I'm from the beach. Yeah, I think I think it's because R is not so it's not Heritage. R is a dagger A. Get back to that. Prison I is a trick you're not seeing right now. Maybe that's why quote unquote Hamiltonian is in quote so the punchline is that the Hamiltonian evolution time first step scales with beta so system size independent mixing time independent Size independent, mixing time independent. And the jump operators are quasi-local with range beta independent of the Hamiltonian. Somehow, exactly as in the classical case, you would use all of the complexity. So here's the intuition of what's happening. So, in classical detail balance, you're jumping between eigenstates. And the probability of a jump is proportional to this Gibbs factor. Very unlikely to do very large jumps if they are small. It's very likely to do small jumps. And what detailed balance says is that these jumps are symmetric. It's as likely to exchange a given amount of energy from the system to the environment as from the environment to the system. In the quantum case, you want to perform jumps between different eigenstates. So you're going to have a beta mu1 plus mu2. Does that kick in? And what happens is that when you introduce the damping term, then the jumps are not going to be precise, right? Be precise. You're not quite going to hit, if you start from this point, you're not quite going to hit the center of the right ball. It's going to be distributed. The width of this ball is going to be proportional to beta. But what happens is because of this relation, I erased it, but with the Gaussian, so somehow the action So somehow the the the action of the damping at the level of the gamma operator corresponds to a shift in the Gaussian. So actually what the damping corresponds to is a shift of this bubble out here. So it's somehow very it's controllable. What the Hamiltonian term does is that it rotates this shift around and cancels. Around and cancels it so that it realigns with the original bubble that you were interested in. So our interpretation. Yeah, so we already have a couple of extensions, so this can be extended to discrete channels rather than continuous semi-groups. And the same thing holds. So, if you have a discrete CPTP map which has detailed balance, sorry, if you have a discrete CP map which has detailed balance, you can turn it into a CPTP map, which also has detailed balance, but you have to add a unitary term. This unitary term is going to be quasi-local, so we can extend it to the discrete case. To the discrete case. We have this other construction, which is closer to what happens in a real system bath-wheat coupling interaction in the non-commuting case. Nice, which connects our construction to something that really happens in physics. And we can also purify the dynamics to get the square root of speed up. That's relatively standard at this point. This is getting closer and closer to a complete theory, right? Something which is pretty rare in our field, where there's a physical description of a process, so something which is connected to the physics of the system, an efficient algorithm which really mirrors what nature is actually doing, and then a very clean mathematical structure. Right, and this is sort of too good to be a coincidence. So we consider this really the definitive quantum metropolis algorithm, at least a class of algorithms which is so reliable that it can really be applied. And in terms of outlook, there are plenty. And in terms of outlook, there are plenty, plenty, plenty of open problems. First of all, we think it might be a very good solution to this problem of simulation and quantum computing. So there's been a lot of criticism recently that all of the resource estimations associated to the simulation, to the ground state simulation problem, don't have much value because you're just throwing the real difficulty under the carpet, which is preparing the initial state. Whereas if you start throwing Whereas, if you start from a high temperature state and anneal down, you're doing the same thing. Well, you're mimicking nature. So, you expect to be able to simulate systems that nature will be preparing in a low temperature state. So, it should be an extremely good ground state preparation algorithm. There might be new physics hiding here, so we don't. Here. So we don't expect that many surprises at high temperature, but we really don't know what's happening at low temperature. So when you reduce the temperature to one over the gap of the Hamiltonian, we really don't know what happens. And we have some very preliminary evidence that there's interesting dynamics happening in this regime, which is not reflected by the spectrum of the habitat. It really opens the door to finally extending all of these mathematical results away from commuting Hamiltonians, the general Hamiltonians. There are obvious questions with error correction. This finally gives us a framework to talk about self-correction of non-commuting models, so subsystem codes, or just ground states of physical systems, which has been very difficult so far. And the simplest. And the simplest versions of our algorithm are not that bad, right? So we expect, we haven't done the full resource estimate yet, but we expect that about 100 logical qubits gate count, which shouldn't be too bad because ultimately the bottleneck of the gate count is going to be the Hamiltonian simulation time. Since it only scales with beta, it really shouldn't be that bad. So we expect this algorithm to be a good candidate for early fault tolerance as well. Early fault authors as well. So, with that, I want to complete and advertise some open positions both at the University of Copenhagen and at the AWS Center for Quantum Computing. I have positions in error correction, tensor network applications, and mathematical physics. Pay attention. Um so yeah you better this first point in this slide. This is uh operation. But only to simulate this I mean you don't need a bath, no? So the problem so far is that in the standard approach to Hamiltonian simulation, you assume, so you have a Hamiltonian, you want to prepare its ground state. You want to prepare its ground state. You assume that you have access to a state which has relatively high overlap to the ground state. You perform phase estimation repeatedly until you project it onto the ground state. This obviously depends upon your ability to prepare an initial state efficient. And with his paper with Garnett, at least in the case of chemistry, there's pretty decent evidence to suggest that it's not generically easy to find. It's not generically easy to find this initial state. You might want to put adiabatically, but adiabatically, it's very difficult to control. Adiabatic evolution, and it's very problem-specific. Whereas if you start at a high temperature, then you adiabatically reduce the temperature at a low temperature. This is basically what nature does to prepare state. Now, of course, you could cross a phase transition, right? In which case, once you cross this phase transition, you're not going. Once you cross this phase transition, you're not going necessarily going to go to the ground state, you'll go to one of many ground states or to some metastable states. But in that case, that's probably also what nature does. Understand your algorithm as and we know how fast we can reduce it. Yeah, because the scaling of the algorithm is linear better, or no, I mean, we basically know we can go, it's going to depend on. We can go, it's going to depend upon an energy barrier. Go fast as long as there's no energy barrier. If there's an energy barrier, you have to go slow. Or you can go fast and end up in a metastable state. Trying to understand where the complexity is. So, for a simple classical setting, say with Ising Hell or Tori and some MaxCAD instance here. Instance here. But also, run your quantum algorithm on that. What parts of the quantum algorithm would then be still? Fixing time. Fix in time. Seems like it's a fallpark. It has explicitly exponential runtime. Exponential rubber. Yeah. But he was saying that it works for other stuff. It's like it works well heuristically. I don't know. But you're saying yours is like... Maybe. But it might work, but... I think you can prove that one requires exponential time to prepare like zero. So like for for any state you want to prepare, it takes like exponential time. I think you have hope. I mean I think you have hope. I mean, you can prove that for certain classes you version with just local updates, or is that ruled out? Yeah, just local updates. Yeah, well, that's going to be the community case. But communicate, non-communicates. Do you think there's any hope for that? It depends what you mean by exactly local. I mean, this is exactly local, but on a scale data. Okay. But on a scale, beta. Okay. Right, so if you're a very high temperature, the beta is very small, so it's going to be. But I mean, it depends on beta, but like beta is bad on local updates. There's going to be tails, unless you have. This is within your framework, but if you have a potentially different framework where you can have strictly local updates and still have some kind of convergence, do you think that's possible at all? Or is that do you think that's ruled out? I wouldn't say anything's ruled out, but I'd be very surprised. I I'd be very surprised though. As a as if maybe if you like truncated like if you have these quas uh quasi local operators, if you truncated them uh besides a certain region, you get some guarantees of the error or yeah yeah that's the whole point. Is that when you truncate them you get guarantees of the error. But like without like yeah you have like the Gaussian truncation. But like you like which is like in the yeah like the in the time dimension and that gives you like And that gives you like things that operate on the side style far apart, but like with strength that is decreasing. Don't have like the operating point like do you have any hopes of getting the ball up like this and I guess you just have to it depends, I mean there's the there's the mathematical formulation of the semi-group. Of the semi-group, in which case you would want to do analysis on it, and there you would want to truncate the jobs. You know, the truncation, the level at which you truncate is going to determine the error. But it scales very well, right? It's more than expected. When you implement the algorithm on a quantum computer, what you do is you run phase estimation for a specific amount of time. But then phase estimation is not going to give you exactly the The transition you want. What you implement is something which has very specific, but you have guarantees. Try to understood how you want to apply this to self-correcting codes. One of the aspects I think is like the self-correcting code, you not only want to go back to the round space, but You want to go back to the ground space, but also you want to make sure you don't make logical error. So it's how DC get the kitchen here. This gives you a framework to analyze, self-correcting. So the first proof that the Torque code in 2D was not self-correcting was by analyzing the Davis generator. The proof that the 4D Torque code is self-correcting was also by analyzing 4D, the Davis generator for the 4D. That Davies generated for the 4G torque. So it doesn't necessarily give you new avenues to find self-correcting quantum memories, but it gives you a framework to analyze them. For cooling type algorithms, I expect them to be a little bit stable against noise. This is a cooling type type algorithm. Yeah, exactly. So I would expect it to be stable against noise to some extent. Right, I mean that that's the whole point of self correction. That's the whole point of self-correction. So, in a self-correcting quantum memory, the thing that introduces noise, which is thermal dynamics, is also the thing which I have noisy gates. It will work without having like perfect logical qubits. Evolution when you run the classroom algorithm? Yeah, you see this, you explained it, you simulate this using a unitary. I mean, I don't know, there might be some additional robustness, but I would expect to be able to run it on disk devices. But that's very quickly dropping. Quickly, probably you will lose detail balance, maybe. I think you lose detail balance very much. No, it does not reduce the daily use of the items commuting. And do you know how the efficiency of the algorithm compares in the case of I I think they'd probably be similar. Is there? Do we know how the gap of the original is related to the gap of the new? That's like the answer question. But you mean the gap of the baby's generator? The original Davis generator and how that will basically get off the new chunk of the implementing. I don't think there's any simple relationship. I wouldn't expect it to work. Back to my first question, I was trying to understand what the classical algorithm of this algorithm is. Also give you the generalization of Or is it the generalization of the modified markup chain model colour updates that? But you also get a like modified classical markup chain model colour update all steps all of that. Not sure I understand the question. I mean, I think it's quite quantity. Uh Um, I'm not sure if I can do it. Well, there are a lot of things to simplify in the LDA.  No, I'll leave you on it. I think I can do the graphics because I think you want to ask the What I've been trying is. Yeah, the Omega. Yeah, you travel. Yeah, but I'm not sure. Oh, yeah, of course. Well, so that's what's probably working. So your approach seems to be quite That's exactly the basic map. I'm sure people down at least. Yeah, that was a big restaurant. I don't know. So that should be done. I guess it's like that one run. Yeah. And we don't know what these are. Well, that one set me up to get a bigger one. Oh, I think I'll do it again after that. I'm asking now this if anything. But yeah, I have a problem with that. It's very similar. Yeah. We also discussed about it. Yeah, I guess that also coincides with the imagery of conditional. This is a little bit larger than my own regular. Regular average case expansions. I think this should be complex. Really nice that we're here to information. But you have it sugar. So the result automation is better and better is the same. 