Very much. So I'll try to recap here what we have to remember yesterday. So you have to remember the definition of delta incidence. So there's a set of points, a set of lines, so we are counting pairs where the point lies in the delta negative of the line. It's important to remember. Then I will be talking quite a bit about these first converged sets today. So I also recover that dimension. So we said that the planar set this column is the first convergence set, with parameters S and P. If there is some three-dimensional family of lines, three-dimensional family of lines with at least s-dimensional intersection, so that every line has at least s dimensional intersection with the set F. And then, as I mentioned yesterday, the sharp lower bound for the Hausdorff dimension of ST firstenberg sets was obtained last year by Kevin Rem and Hong Kong. And the numbers are down here. So every S t first and Berg set has dimension at least a minimum of S plus T V S plus T over 2 and S plus 5. Plus D over 2 and S plus 1. And maybe it's nice to see a simple example of this S T Furstenberg set to begin with, which actually shows that this S plus 1 cannot be on the kit. So consider this example of an S T Furstenberg set. We have an S dimensional counter set on the line, and then we take the product. We say that F is equal to C cross R. Well, I guess most. Well, I guess most people can compute the dimension of this product set. It's the Hausdorff dimension equals S plus 1. And it is actually an S2 Fuschenberg set. So what does it mean? What does it mean that this is an S2 Forschenberg set? So I'm claiming that there's a two-dimensional family of lines that give the line intersects the set in dimension S. And here are the lines. So I can take any line. So I can take any line which goes here, like this. All of these lines clearly have an S-dimensional intersection there. And the dimensionality of these lines is two, because there's even like a positive measure set of these lines. So that's why this is an S, the first converged set, it has dimension s plus one, and that's what the what the theorem would predict in this case. So the study of first converged sets is more or less like the study of these these subservience. Study of these sub-subsets. Okay, so any questions so far about the way we met yesterday? No, example. So I would say today's main topic is to discuss how to even, how to discretize correctly, how to discretize correctly and how to discretize in practice incidence problems involving house-door dimension. That's the That's the point. And so we have already seen that yesterday, just delta separation or square root of delta separation, this is not really quite true. So we need another definition, and this is the definition of delta assets. So this definition was proposed by Ned Scotts and Harry Howell in 2000. S sets? Let me say the other S C sets. Often people just talk about delta S, because the C is not so important. Okay, so I said that a set, let's say a delta separated set to begin with, delta separated set P in any metric space entity is called this un delta S C Delta is Czech if when we look at the intersections of P with metric balls, and they are not too many points. So the number of points in a metric ball is allowed to be at home to this constant C times R divided by delta to the power s. And we are requiring this for every point in the metric space. Point in the metric space, but only for radii which are bigger than delta. So that's the definition of delta, delta C set. And as I already mentioned, often if the constant is not very important, then we just talk about delta sets for maybe so let's uh and or if you're wondering about metric space here, uh I only need this interplane. Uh, I only need this in the plane and in the space of lines. These are the redoharmatic spaces for us. Okay, so just to get a little bit of intuition about this delta S sets, maybe the very first coarse intuition should be that they are a bit like delta neighborhoods of sets of Hausdorff dimension S. That's what you can keep in mind, although it's not true, but it's a good starting point. To make a few true statements, first is Statements. First is that if you look at just the definition of delta S, then you can notice that it gets weaker when S increases. That's important to keep in mind. So the definition, so let's put it this way. Delta S set is the delta T set if S is less than T. Typically, because these quantities here are, they always bigger than one, this R divided by delta, when R is bigger than delta. And in particular, if you're looking at delta S sets in R D, but if you're looking at delta D sets, delta D sets in R D, then it's nothing, it means absolutely nothing. It simply means that you have a delta separated set. Because every delta separated set in R D would satisfy this inequality with S equal to G. Okay, actually this was only remarkable then I'll show two examples. So I want to show you now two delta one sets in R2. And I'm going to claim that these are the only delta one sets in R2 you ever have to know. At least I never need any other delta one sets in R2. So the first one is Let P subset, let's say the unit ball be the maximal square root of delta separate second. Actually, I don't even need maximum. Well, that that's a good thing to keep in mind for this example. You just can take any delta practice. Delta burst. Then P as a delta one set. So we talked yesterday about the square root of delta separated sets, so it's nice to know what they're delta one sets. Why is that the case? Well, let's check it. Well, let's fix, we have to fix. We have to check this inequality for all values of r bigger than delta. So let's fix r first in the interval between squared of delta. Well then, because I'm assuming that my set is squared of delta separated, in any such ball there can be only one point. less than one, which is less than r divided by delta to the power one. So that was quite easy in that range. Well what about the other values of r when r is bigger than square of delta up to one? Well then I can use this sort of an estimate, which says that This sort of estimate, which says that because of the square root of delta separation, let me write it first at the half C at the one. So, because of my square root of delta separation, if you have a radius which is bigger than square root of delta, then in any R ball, there are not that many points. That is R divided by square root of delta squared. And now there's two. And now this 2 cancels out the square. So actually this is also less than r divided by r. Also recall that r is less than 1, so I can just forget about the second power. So square root of delta separated sets are in particular delta 1 sets. Okay, but then there is a very different example. I would say that really the opposite kind of example. I would say that really what was it by the example? Example two. And I think this is quite often called the so-called train tracks, train tracks example. And it looks like this. You take, I will draw a few balls here first. Maybe I drew too many balls. Okay, so these are supposed to be delta balls. Okay, so these are supposed to be delta balls. That's always a delta. And then how many of them I have? In one of these columns, I have square root of delta universe. Square root of delta universe of the balls in each column. And then also the number of columns is also square root of delta universe. So altogether, I have that many columns, I have that many balls per column, I have that the cardinality of p is equal to delta, roughly like delta. Is equal to delta roughly like delta in each point. Well, what is my p? Well, my p is that I just choose one point, one point in each point. Now it becomes a delta-separated set. It's definitely not square of delta separated, but it's still delta separated. And they are not any points. And it's really not hard to check that this is delta one set. It looks like a if you're doing a fractal geometry, it looks like a one-dimensional set, sort of. At the any At that, any wall, there's exactly the correct number of points. So, I would say that if you ever have to deal with an easiness question regarding delta one sets, then try it with these two examples first. And if it works, then you might be in luck. Okay. Questions, comments? Alright, does it matter how far apart the columns are? Thank you. Fantastic. Thank you very much. Yeah, if the columns are all together, it's definitely not the delta one. It's important that there's like a one-dimensional thing here. And then finally, this radius would be exactly the square of the delta button. Square of the other button, and then you can start to see the next column. That's why it's exactly like linear across all time only points. Thank you very much. That's a good question, Tom. So, this example, it seems like the estimate was really sharp, whereas the first example, you sort of threw a lot of things away on both cases. Is that relevant? Not like I throw them away. Well, you you found what you know, the actual estimate was one. The actual estimate was one and you bounded that above by R for delta, which seemed quite lossy. Yes. But still, nonetheless, I don't I don't this is not this is not the delta t set for any t bigger than, sorry, any t less than less than one. So it's still Wondering if that would meant something even when comparing these two examples. Well, yes, definitely this is very, very lossy. Well, it's not lossy when R is cost one. I can't think on the blackboard, so I can't be sure if it would not be a delta S delta S less than one. I'll leave this link to you. Okay, so now I've told you about this delta. Now I've told you about these delta one sets, delta S sets, sorry, what to do with them, why are they useful for discretizing incidence problems involving Hausdorff dimension. So now there are two propositions which allow you to discretize Hausdorff dimension to these delta assets. Super useful propositions. I will now tell you both of them and then I will prove one of them. So the first one. What's this one? Um this would be called the subsets. Subsets formulation. Let k be an arbitrary subset of R D. So no compactness, no Boreal formalities to any subset of R D such that its half-star content for any sum uh x by s. Some x1 is positive. And let's multiply this by saying that it's some number tau, which is positive. Then there exists a delta S C D Z. That's a constant depending only on the ambient dimension. Well, that's Z P subset K. So if I So far, it's trivial because it could be empty, it could be just one point. But then I say that cosa has big coordinality such that the coordinality of t is at least constant times tau times delta minus s. So why is this delta minus s, by the way, natural? If you if you stare at this inequality for a moment, If you stare at this inequality for a moment, and let's say that our cell is contained in the unit ball. So, if our cell is content in the unit ball, and then you apply this inequality to r is equal to 1, what do we get when r is equal to 1? Then you get that the cardinality of p is at most delta minus s. So, any delta s set contained in a unit block, which is a reasonable assumption, usually, has cardinality at most delta minus s. And this proposition is telling you that if you have a positive mobile bond of the Hausdorff content, then you can find a maximal delta present inside it. I won't prove this one because the proof, if you have ever seen the proof of Frostbon's lemma, you just take that proof, you do this. Funny thing is that you don't need this to be any To be any, you don't need any analyticity or total assumptions on that, but it's simply because in the usual proof of Frostman's lemma, there's some weak convergence at the end. Here you don't need to do it, you just start at scale delta, but you build your Frostman measure, your discrete Frostburn measure up from that scale. Okay, so that was the first useful proposition, then there's the second one, and with this. And when this was called the subsets proposition, then this one could be called the cover proposition. This one, I think, originally is due to Katz and Tao, although there have been very many reincarnations of this proposition. Katz and Daw put something slightly, slightly different, but still I would take ideas. Okay, so then. Okay, so then in fact, before I even state the proposition, let me make a little addition to the definition of delta assets. Because here I've talked about delta assets which are delta separated, but quite often it's also use useful to talk about delta assets which are unions of cubes. But I won't use that term in the watch of the proposition. So we also say that the connection of delta diary Q's, so the connection can be config V in delta diary Q's. So that's the diary cues of side delta. It's uh delta Cz. That's Cz if a similar inequality holds, but let me quite again. If the number of Q's in P which are contained in some parent Q, Q, is bounded by C times R divided by delta to the power S for every pair in Q, Q and P R P R, that's another direct number larger than the delta. So R is larger than delta button, and that's it. So, and this means just the cubes in P which are containing cube. Right, so now let me state the colouring proposition. So, here we have again eight. So, here we have again any subset in Rd of Olympia. The proof that I'm going to show to you, it has to be compact. But in Katzental's work, there was no assumption, just gets more technical. Cool. So, let that be compact. And this time, instead of assuming a lower bound for the Hausdorff content, we assume an upper bound. An upper bound. It might look strange at first. So we assume, in fact, that the Hausdorff measure, all the Hausdorff content is equal to zero. Then, as the proposition's name suggests, we are able to cover k with delta sets, although many of them. So there's a sequence, GK, and K runs. And k runs from. So these will be like families of dided cubes. I want them to be small cubes. I also fixed kz. So I just in order to make the dided cubes arbitrarily small for future applications. So I can find a sequence of collections of dided cubes where this pK is in diaded cubes. In dynamic cubes of q to the power minus ke sequence of collections of diet to the power minus k cubes so that each p k is individual delta. A delta S set with a natural delta, so that's having the side net of the cube, and it's a delta S even one set. I can actually make the constant just one. And of course, most importantly, I get the cover. So k is a subset of the union, k ranges over panometers, k equals k0, and the union of this. But let me stop there to digest it. It's really sort of the complete opposite of Frostbon's language. You are able to cover your set efficiently. Well, at least you're able to cover your set with tilted cubes which satisfy this nice non-concentration condition, which is not at all appropriate for the definition Hausdorff me uh Hausdorff measure. Of the House of Love measure. Okay, and the proof is, at least for compact stats, is very strikingly short, so I want to show it. Okay, so consider let's consider the following dynamic variant of Hausdorff content. So you can define this for any satellite in my world, we need it for k. So hs delta dot infinity okay this is equal to in And this is equal to infield over all possible collections of dielectric cubes, so that's collections of dielectric cubes. And then, as usual, in the definition of half star content, I sum over the side lengths or the diameters of the cubes to the power s. And also, I need k to be covered by the cube. Sorry, that's unique. Okay, so so far this would basically be just host of content, nothing else. But there's the delta parameter here. And I require all of these cubes to have side length at least. So this is very unusual. You usually don't want to put lower bars there. But this time I do want to put a lower bar. That's important. Right, okay. So that was the definition of delta assets for diameter cubes. All right, so what are we trying to do? We are trying to find this cover, covered by this delta. Delta, trying to find a covered by this two to the power minus k s. And our assumption is that the s-dimensional house dot. The estimational Hausdorff measure is zero. So also the estimation Hausdorff contact is zero. Because k is compact, here is where I need compactness. You can actually even make this guy small. Think about if this k was the rational numbers, you would not be able to make this small. But because k is compact. We can find a scale delta zero, well, given it's a dynamic scale, such that h is delta infinity of k, that definition, this is less than less than any number I want, so I should start by fixing any number I want, and then I can find this scale depending on that number. Find this scale depending on that number, but actually, I only want to do it for this specific number. That's the only number I care about. What is k0? Well, k0 was the k0 was the starting scale. Okay, I won't tell you exactly why you can do this by compactness, but it's an exercise. Okay, so what does it mean that this guy is less than that? This means that. This means that there is actually a finite family, a finite family of dynamic cubes of all kinds of generations of dynamic cubes. So we just know that the side length of each LQ is actually stealth function such that k is covered by Is covered by this union. And here comes the really, really important thing. The sum of the side x to the power s is precisely this number. There's no weakly seen there, precisely. Why can't I find precisely? Because actually, this infimum here is a minimum. I'm only looking at collections of cubes of sidelines at least delta, and I might say this compact. So there are only so many options you need to consider, and then you just pick the minimum, and then those options. So I can have an exact equation here, which is for what is coming next, this tool shop. We are almost, almost done with the proof, because now I can already tell you, I can tell you exactly what these sets are. Fine. Obvious cubes, q. The nose cube Q in the finite fabric that we just found about, so that the sign Q happened to be to the power minus K. So clearly those sets are, those collections are subsets of dilute tubes of cyber belt. So what remains to be done is to check that these are actually two power bunch k S one sets. one sets. So why are they why are these guys uh two to the power minus k s one sets? So can fix uh k and let's assume to the contrary what if what if there existed a q which violates the condition? So what if there existed some some q q q bar differentiated other cubes in d Vacuum in VR, where R is now larger than this due to our volume, such that our inequality is valuable. What inequality? Well, then delta is inequality. Pk to the cap P bar is pretty larger than R divided by 2 to the power minus K to the power s. Okay, so that's the counter assumption that these. Counter assumption that these would not be typical minus k as. Well, if this is the case, then I take these cubes, I take these cubes here, and I form a new collection. So I form a new collection, cube prime, new collection. Q', which is equal to the original collection Q, where I have added the one single cube, Q bar, and I have removed all the cubes which are colored by the previous cube, by the Q bar. Okay, so now I have a new collection of cubes where I have just removed all the contents of the big cube. It's still a cover. Thank you. It's still a cover. Sorry, of course, that single family is not a cover, but this covers whatever the previous thing covers. So, all together I still have covered. Furthermore, it follows from this inequality with a one-line computation that the sum is smaller. So, let's just say that the sentence is first. Star of course star but if I look at the new sum of this I think I must have made a bit of a notational miss here, because oh, I know, I just got it. I've got a question. So, like, should it be k less than or equal to k0? Like, are you considering big cubes that are bigger than 0 to the minus k? Well, like, it looks like you're. Oh, I'm just confused about these pKs. Why is k bigger than k0? Yeah. Why are we considering small cubes? Yeah. So if you look at this definition, which is that definition is the same as this definition, and we know that this pi is less than 2 r minus k0 s. Then in fact, all the non-empty columns. Then, in fact, all the non-empty collections, PK, have to be small. If there was even a single non-empty PK collection, then a single Q or driver. So, yeah, that's actually something I didn't even mention yet. But what he was saying, it's automatic here that every k is bigger than k0, which was part of the statement of the covering proposition. I told you he just brushes that in the colour. But then you ultimately also have that k is. Uh A is B smaller than like log minus log delta or something. Because like you yeah, you're starting okay. That's yeah, so okay, maybe I see where this question comes from. So there's this initial choice of delta, which is after it has been found its conflict uses. So this is just to show that the existence of delta only guarantees The existence of delta only guarantees, but I only need to consider finitely many options in this collection of cubes. And because I only need to consider finitely many options, I can find a minimizer. Okay. But apart from that, you can just completely forget about the delta. It's not used for anything at all. It has nothing to do with the size of the case. So it doesn't matter that the base are small or shouldn't be a small pace. It's just the only thing I would care about is that. Just the only thing I would care about is that I know that case are reasonably large, as large case are large, case the cubes are small. This is useful for applications. Thanks, sorry. I was just confused because you were saying that the cubes are big and then. Okay. Oh, sorry about that. Okay, I get it. Okay, thanks. Big, big indices, small cubes, yeah. I sure get confused with those. Okay. Alright, so we were just about to wrap up the whole thing. So we have defined a new connection and We have to define the new connection, and I was just saying that it follows from this counter-assumption, strict inequality, that in fact the sum is strictly smaller than the original sum. Strictly smaller than and this is a variation of the minimalic variation also. Okay. Any further questions about that? Yeah, so at the bottom left corner, so this Q prime is formed by removing all of the PKs which intersect QR. Yeah, which intersect chart contain. Some too far, and then this is saying that there are too many elements of key there. Then it's actually better just to remove them, completely unreplaced by the infamy, and then you have a smaller sum. All right. So these are extremely useful propositions. I think they really allow you to delta disk that is basically any house top. Any house dog dimension incidence problem. Even if you don't care about first averages very much, but these are very beautiful. So now that I promised to you that every, or at least many Hausdorff dimension incident problems can be can be discretized using this notion. It becomes reasonable to study incidents. Reasonable to study incidences under this known concentration. So that's what we call the direction. So, what is a reasonable question? So, okay, so let me look at the final incidency for delta essence. I think when you encounter these delta sets and you want to study the incidence question about them, then probably this is the most natural question you can think about. Let's fix two parameters, alpha, beta, less than two. So these are now my dimension parameters. I won't use alpha and beta because otherwise I'll be confused with the ST4 sets. So that's why these would be my dimension parameters as well, in this section. Section. Let T subset B one be a delta alpha set and let L subset A21 be delta beta set. So that impose two variants of the same question. Or let's say, how large can the number of incidences, the delta incidences between these collections be in terms of and now I force these two values, so in terms of alpha beta, or possibly in terms of the Or possibly in terms of the cardinalities of the stress. So in terms of P and L So these are slightly different questions because by the delta alpha, delta beta is a condition. We have upper bounds, we have upper bounds for these now personally at most delta minus alpha, delta minus beta. But of course they could be much smaller. They could potentially be smaller. So I would say that two is a half. Smaller. So I would say that two is a harder question. It's also easy for me to say that two is a harder question because one has been completely solved. And this is what I want to talk about next. So in 2021, this was conflict dissolved by Yuku Fu and Kevin Ren. So this is a theorem. So this is a theorem. So it was archive in 21, but I guess it was published this year. So 2024. Publication year. This gets a bit complicated to state all together, so I will just state it this way. For x is a continuous function. F, which maps from z L of 2 squared to R positive numbers. What F such that the number of incidences, as in the previous question, is bounded by a bulk by this function. By the bulb by this function. Explicit sharp complicated functions. Of course, currently this statement doesn't have very much content, so it's just that they find for every pair of alpha and beta. On beta, the sharp answer question of the law. And it's a continuous function. I think it's a function which has bits quite linear, but it has eight different components. And if I just write it out to you, it will not be very useful. I will just say one important special case. So important where the exponent here is less than Is less than uh less than alpha plus beta plus one over two for when alpha plus beta plus less than two. Okay, uh let me still let me write this out for you, what this probably actually shows. But uh if you look at the incidences P and L P and L. So once again, here P is a delta alpha set, L is a delta beta set, and we assume that the sum is at wash 3. And this is founded by square root of delta minus 1 t times delta. So, what do these bounds have to do with each other? Well, this is sort of answering the second question which I was asking. Second question, which I was asking, but how many instances is can there be in terms of P and L? But I'm not sure if this is sharp for every cognitive E and L. Simply that if you plug in here the upper bounds, so if this is delta minus alpha, this is delta minus beta, then you get back this information. And so the sharpness of this theorem means that the sharpness examples have maximal size. But potentially, they could be, if you don't know, they could be sharp meaning bodies, than these when the sets are really small. Anyway, that's a useful meaning for it. And time permitting, I will show you that maybe next hour. Alright, so that's a that's the incidence inequality. Um so next I want to discuss what this has to do with To discuss what this has to do with the Bergston-Berkshire problem, I have still maybe about five minutes, so maybe seven minutes. You got more than that, haven't you? And at 11-3. Right, but I just wanted to leave some pretty often when I come. So what is maybe interesting here is that this theorem, Furan, it appeared in the archive in 2021. So this was way before the full force direct theorem was, well, the full force direct projection was solved. So this indicates that even a short answer, even a short answer to this question, does Even a sharp answer to this question does not give a sharp answer to the Forced-Bravexet problem. So this is not the right question to ask to solve the Forst and Brexit problem. Nonetheless, it is the right question to ask for some cases of the Forst and Brexit problem. And I want to tell you exactly how this proposes. So it turns out that this proposition, or as already That this proposition, or actually this theorem of weapon, solves exactly the cases where t is larger than two points s of s, the Forston-Brackstein product. And so, in fact, in this range, when t is bigger than 2 minus s, the inequality says that the dimension of f is larger than s plus 1. So, this was the last of the three. The last of the three minimum syntax inequality, that's exactly correct when t is 02 matches. That you can get from the 200 minutes here. But let me tell you somehow in general what information about first worksets you will get when this employees proposition. If, well maybe I should change notation, let's say that g from c n of 2 squared to z n of infinity is any continuous function. So maybe not the full RN function, but just any continuous function such that The incidences between delta alpha sets and delta beta sets, as before, is bounded by delta minus g alpha beta, whenever p is a composite and a and L such A21 is uh delta betas. So in particular now we know by UN speak theorem what is the optimal G. But if you have any such G, then you can get the following information about person bars sets. You can get that that G evaluated at the dimension of S t Forten Berkset to bigger than S plus T. For all the most complex sets so that that is the that is the follow-on connection between That is the that is the formal connection between between these problems stated about delta delta incidences between delta alpha sets and delta beta sets, and what is the best possible information you can get about the dimension of personal estimate person. And I'm running so close to the end of the lecture that I want I I I'm trying to prove this because this is a nice how to show this is a nice illustration how to use the covering method, how to use the covering of covering proposition. There we go. Covered the proposition. Nonetheless, I will only do it. No. It's not so important. I won't spend more of my next time doing it. So I will show you up to the point where you use the colouring members and then you just leave the rest off. So let's uh so it looks quite complicated. It has a G evaluated as team of F G. Not not so nice, but uh we go back there. Um let let's fix a force and exact. So, what do we know when we have a forced intercept? We have a certain associated family of lines, each of which has a large intersection. I achieved just a little bit by adding the following information. Adding the following information: that I have that the three-dimensional content of this five family is at least once, and that most of the intersections have large output content, also intersections or elements. So instead of just assuming some of the things that we have, we have a So instead of just assuming something about the Hausdorff dimension of L and intersections, I shift the parameters a tiny, tiny, tiny bit to get the slower bounds to the Hausdorff one. Okay, so next, I won't use the colouring them at this point, so we are almost done with the group that I'm going to show you. So fix uh any number should be alpha alpha. Would be alpha alpha bigger than the dimension of f. So I have this forst. I fix any number alpha bigger than the dimension of s, dot f. So in particular, now I know the alpha-dimensional Hausdorff measure of f is equal to zero. So now at this point, I have exactly the assumptions of the covering of my disposal. So I can cover F by this. Cover F by this delta to the power minus k sets as I showed you earlier in this way. Okay, so I won't write more about this because it's these are the collections which I define the covering them. And so forth. Then, now here comes the here comes really the crux of the proof. So that should be a good point in the finish. Because we are assuming that all of these intersections of F with L have large house storage content, and I have a cover of F by these families. Therefore, Therefore, just by the regional principle, for every line L in L, there exists some index KL which is bigger than K0, so that the Hausdorff content, the estimation Hausdorff content of the this union intersected with L is at least quite large. So So I have a host of content lower one here. If all of these guys had smaller intersection with L, then it would not be possible just by the subadditivity of Hausdorff content. So after this, there is more pigeonholing, but after pigeonholing, let's say we may assume And we may assume that this KL index is actually independent of L. So, what which means is that you have to pass to a subset of the lines still of substantial host of content in such a way that K L is independent of L. So if sub k, fixed k, you have k0 or all there you go. Uh, there we go. And now at this point, we have managed to delta disk that I saw problem. We set a delta equal to this index that we have found. So I will do no more details, but at this point, we are looking at the incidence problem between the set. At the incidence problem between the set PK, PK, which is now a delta alpha set, and the set of lines. Well, we have to also use the subset, the subset proposition. So we also have to, at that fixed scale, we have to find the the delta T subset L. So at that point you will at that point you will start to see an internet problem between those those families at scale L. Those families that scale ill, and then somehow these fall. I think that's that's much as I want to say about. Any questions for our speaker?