Of the Singapore Plus conference. My name is Joshua Ho, so I'm glad to be starting off this day. I know some colleagues have already left, but that's fine. We have the best for last. So in the very last day, the main topic is about scalability. It's about how do we scale up data analysis to larger number of cells or larger number of samples or having multiple samples per person and multiple people in a large population. Multiple people in a large population. So, when we talk about scaling up, I think we're talking about more than a million cells per analysis or more. I think that's the kind of scale that we're talking about. So, I think this is really forward-looking. I don't think I have a lot of solutions here, and we're going to have a few different people who are speaking today. So, I'll go first. I'll go very, very quick, and I'll try to be on time, very strict to myself as well. So, I'm going to talk about my So, I'm going to talk about my first story. There are a number of stories I'm going to share today that show some of the ways in which I try to resolve this problem of scalability. The first one is the work that I've done using cloud computing. The idea is to do it brute force, basically, by providing more resources, more computational resources that are run in parallel. But instead of moving data to compute, we move compute to data by using AWS Cloud. By using AWS cloud, Amazon Web Services Cloud, because a lot of publicly available data, like SRA data, are actually there. So we've been investigating how do we develop tools to run on that platform. And the problem here is can we go back and mine existing data sets and really go back to look at the sequence, realign them, and see whether there are microbial sequences in human samples. That's really the case. In reality, the framework can be adapted. In reality, the framework can be adapted to look at existing data on anything. Auto is called Voucher, because, like Voucher, we go to look at scavenge animal waste and try to find nutrient inside. That's basically what this team is doing. So, insertion framework is a very basic computational framework. The idea here is that we utilize the batch processing capability of AWS. So, this is not particularly So, this is not particularly new. We're really just using the ability of AWS to allow us to scale up to larger than Q. Scalability comes from auto-scaling. And that allows us to, whenever we have more and more samples, we just have more and more processes to run them in parallel. And that's really how we obtain scalability. But we try to do that in a way that don't let the cost explode. Know, don't let the cost explode basically. So we have tried to do our analysis and try to scale up. Maybe start with here, looking at input file size. Basically, this is the main way we look at scalability. Basically, by giving more and more files, does it scale in terms of time? This is runtime. So, our tools for Vulture scales, I think, relatively well compared to other tools that are not, to be fair, are not. That are not, to be fair, are not designed to do this. They are not designed to scale up, but these are other tools that do microbial weed analysis in human samples. And we can show that the scalability is reasonable and that the cost is actually also reasonable. So all this is now preprint, and we have an example that reprocess and publish COVID-19 patient data. And we're really trying to find out where. Data, and we're really trying to find out where SARS-CoV-2 viruses are, and are there any other viruses that are there as indicating potential co-infection? So, again, for interest in biology, you can look into our paper. Another separate way in which we want to perform scalability is sacrificing some accuracy in terms of the clustering, or maybe I should say the resolution. So, we asked the question: can we do clustering of singles out like million? Of single cells, like million single cells, but do it as quickly as we can. What we realized is that actually, if we do not really enforce, we need to cluster individual cells, but cluster similar cells together, then that would be faster. So essentially, we used a version of db scan, but then using db scan as a spatial clustering methodology, but instead of using a cell as a unit, we first divided a space into grids. So the number of grids is. Grids. So the number of grids is much smaller compared to the number of cells. So that allows us to do much faster clustering in that way. But of course, what we do lose is some resolution. We are not going to have as high a resolution. But again, this at least allows us to run very quickly to get an approximate structure of the clustering space. And again, it is published and the details are in the paper. So hopefully, this gives you a sense of some of the ways we are thinking. Of the ways we are thinking about scalability issues. Another thing that we're trying to develop is visualization. So, some people might remember this from quite a number of years ago, even when I was back in Australia. It took me many, many years to get this published. But eventually, this is the version that we ended up publishing. And the idea is to use immersive visualizations instead of allowing us to just look like a two-dimensional. Look like a two-dimensional scatterplot. We want to be able to immerse ourselves. So, not just 3D visualization, but we have animation as well. So, that means we can actually go into the space. If the animation is set as the trajectory, for example, pseudo-time or other kind of trajectory, we'll actually be able to swim inside the single-celled data through the pseudo-time that you provide as input into the space. In the latest version, we also have a spatial transcript. We also have spatial transcriptomic data that you can map in the same screen, like that one there as well. So, this could be very helpful if you have matched spatial transcriptomic and single-cell RNA-seq data. So, I'm skipping this fairly quickly because there are quite a number of things I do want to show you. This is just to show people that in the University of Hong Kong where I am, we actually have a lot of other colleagues who've developed technology, and this includes some. Technology, and this includes some biophysical properties using optical imaging and using quantity-based imaging technique in order to obtain some biophysical properties. And the other one is another collaboration with a colleague in Senjin, where they developed a trick where they actually physically squeeze the sounds, and by looking at the deformity of the sounds, we can obtain its elasticity. And these are some of the data that we are trying to do. So, hopefully, in a few year or two time, we can show you. In a year or two time, we can show you more data. One of the most interesting things I've been doing the last few years is to try to answer the question about lineage tracing. The main issue is that a lot of our experimental or clinical colleagues have biological samples and they really want to understand lineage. They want to see how they go from one cell type to another. So obviously, we have pseudotype and other kind of inference method to make guesses. But of course, to them, the gold standard is yes. But of course, to them, the gold standard is you actually have a genetic lineage marker. Genetic lineage marker you can see how this marker is located in different cells and that gives them the best evidence for actual Linux tracing. So this is, and in the literature, this is not our brand new idea. So we are inspired by some of the early works, and this is done in the BRO, about the use of somatic mutation mitochondrial. Of somatic mutation in mitochondrial DNA as endogenous somatic genetic markup. So, okay, so these are, so in all our cells, we have somatic mutations that are naturally arising. If we can capture them and if the frequency of the occurrence of this mutation within the time span of your interest of your biological process, then this could be used for Linux tracing. In terms of mitochondria is actually a fantastic place, there are many mitochondria parasites. Place where many mitochondrial pairs are single cells, and the coverage tends to be quite reasonable. So, this was proof of concept back in 2019. And then, and this was earlier last year, where there were experimental protocols that were developed to enrich for mitochondrial reads that can work well with Panex Genomics. And that's how we can open up a lot of possibility. Essentially, this is a PCR-based amplification. Essentially, this is a PCR-based amplification protocol to enrich for mitochondrial reads. This was initially applied to some blood cancers. And we have been basically adapting this type of technology in my own. So there are three type of things that we do. One, we use computational methods to do variant calling. We use self-snips to do the first round of microquantial variant calling, but the number of SNPs would be very large. We did something called nport. So this is a method that allows us to identify. That allows us to identify variable sites. Essentially, those sites, those SNPs are most likely to be clonally informative, clonally discriminative. So we developed a model to do that in collaboration with Yen Ha Huan, whom you have heard earlier this week. And then we did VeroSNP to assign clone. And this is also by Yen Haas now. So we have been able to do that and show that it works well. Well, works well and in fact better than MGATK, which was the tool that was initially proposed for discovering mitochondrial variant corner. So we applied that to different scenarios, including cancer-single cell evolution data sets, where we look at, and this is the giant cell tumor of the bone. So this is a mouthful. And this is an interesting patient. Well, sad for me, because he has a vanilla tumor and then there's a recurrence. A benign tumor, and then there's a recurrence. So, there's a male tumor of the same person at two different time points. So, we were quite interested in studying that. And this is a good example because we want to see whether the same clerk appear in benign and in malignant in the same person. And it turns out we were able to find some using our technique. And the other, sorry, I'm going through quite quickly, is a collaboration of Rio Shugimura from my. Shugimura from my school, who have been interested in using an organoid model. This is campaign sounds organoid model, and perform singles RNA-C and spatial transcriptomy. And we are doing my study on that. So my study is our experimental mitochondria enrichment protocol. In short, with the single-cell RNA-seq, we were able to identify different clones, and this seems to give us consistent relationship with Relationship with how we think embryonic development works. And more interestingly, this also works with our spatial transcriptomics. So this is Tannex Avisium data. So therefore, not only allowing us to assign cell types or deconvoluted cell types into the histology, but also with different clones. And I think that's something that's quite new. We've not seen this type of background before. Seen this number background before. So we're pretty excited about at least the ability for us to do that. So I think I'm still good in time. So I'm more than happy to talk to you about any of these topics. The idea is to go through this quickly so that you can ask me any questions for the rest of today. Anyway, so this is my lab. We are, at least my school, is actively hiring basically anyone at basically any level, looking for students, postdocs. At any level, looking for students, postdoc, where faculty tenure-track faculty positions, also teaching-oriented position for bioinformatics. So, thank you very much. Yes? Thank you for the making talk. I just have one question regarding the spatial data, microcontroller mutation detection. Do you have to decompile the data? I can't, the microcontroller. I can't um the mitochondria is already mixed all together, right? So how do you and there's nothing for you to tell what's the cell type specific. There's no such thing called cell type specific mitochondria. So do you need a deconvolution? Like how does it work? No, there is no deconvolution. So you talk about the spatial transcript permit mass? Yeah, that part we haven't actually quite worked out. We yeah, that actually we do make the assumption. We just look at the spot level. So not the single cell level. But that's something we certainly should and can work on. Should and can work on this thing. Okay, if not, then maybe we should just move on to the next thing. So the next presenter, by setting this up, we're going to use this a little bit. 