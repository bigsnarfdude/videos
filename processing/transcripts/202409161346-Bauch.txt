The organization is for Biden. Biden here. So the title is obviously a reference to Bach's famous comment about models, who in the paper concerned said that since all models are wrong, the scientists must be alert as to what is importantly wrong. It is inappropriate to be concerned about safety for mice when there are tigers abroad. So that, of course, clarifies the issue completely for me. Of course, sometimes you're not sure what's a mouse or a tiger, or sometimes you have a bit of both. So I wanted to, I'm going to. Both. So I wanted to, I'm going to talk about our search today, but I'll kind of organize these around two governing questions. First of all, when are different mathematical models actually the same? And the answer is sometimes. And then the question, when are different social, psychological, or economic theories actually the same? I don't know as much about this, but so I think the answer is never, but dot dot dot. So I'll talk about the first question. And a lot of my work is based on. And a lot of my work is based on social learning. And there's some mathematics, there's a mathematics of social learning, but it's based on Bandura's theory from the 70s. And Bandura thought that what we are because we learn new behavior by imitating or learning from others. And then if we want to put this into a model, we just have to do a couple of things. First of all, we assume two possible opinions or strategies, like pro-vaccine, or anti. We assume that there's a utility associated with authority. We assume that there's a utility associated with each one. By utility being a measure of preference, you clean both tangible stuff like money and intangibles. We assume individuals sample others at some constant rate period of time, so we talk to them. And if the sample person has a higher payoff, then the focal person strategy, that focal person will change strategies. In other words, people imitate successful strategies. If I see If I see Brad Pitt's haircut, I might imitate it in the hopes that I become as successful. So this is instantiated with some equations here, and basically this difference equation just states that the rate of change of, say, a pro-vaccine opinion is just a product of three different things. How often are sampling mothers, K. The relative composition of the population in terms of opinions, because if I'm learning my behavior, Because if I'm learning my behavior from others, there have to be others present for me to learn from. So if everyone 100% is anti-vaccine or 100% pro-vaccine, then nothing's going to change. No one argues about this guy being goof, for example. And finally, the difference in utility. So the bigger the apparent difference in payoff, the stronger the behavioral switch. So these assumptions give rise to this equation, and then you can simulate that. And then you can simulate that. Delta U is the difference in payoffs. So, another way of approaching things is the best response model. This is the idea that people will simply switch to the best strategy immediately without any social input, which is to me as a socially-oriented model, this is a very strong assumption. And it's modeled with this set of equations, so they look a bit different, but the main thing to understand here is that this. Main thing to understand here is that the switching is governed by this S-shaped curve. So if I get a higher utility payoff for Dr. Bradput's haircut, then I'm going to change faster. And if I don't like his haircut, then I don't need it, of course. And if it's a sharp curve, it means I only care about Bad Pet's haircut. And if it's a gradual curve, I'll care more about things like how much does it cost or other factors. Or other factors. But anyway, the main thing I want you to get from this is that these two equations look very different, but there's been some interesting work showing that they often reduce the same thing. In particular, one molecule can be obtained as a lumining case of the other as it concerns the steady-state solutions. So the best response dynamic is actually closely related to the immutation dynamic, and they're identical under certain circumstances. And they're identical under certain circumstances. Contagion is another often used approach. People in so-called sociophysics like the contagion model. The idea is that rumors, ideas, beliefs spread like a disease. And so in that case, for example, if B is the percentage of individuals who believe a rumor, and N is the percentage who are susceptible to it, they don't believe the false rumor yet, then you can see. Then you can model it as an SIS-type model. So the rate of change of believers in the rumor is a product of the percentage who currently believe it, and the percentage you don't. And of course, because n is 1 minus b, this is, you get rb times 1 minus b. And this is actually identical to the imitation model for this special case delta u equals 1. So again, I'm presenting these because sometimes you read papers and You read papers and the author is saying, well, this is a rational assumption, rational, accurate, model, bad. Don't do it. But when we drill down, they're often talking about the same thing in terms of the mathematics they're using. So this is something that I think we should be aware of. So once you've got your imitation model or your best response dynamic, you can couple it to something. For example, the utility view can depend upon the state of some environment, like the amount of disease in the population. Disease in the population. And this is an obvious one to this audience. If prevalence goes up, then more people will get vaccinated. But if there's too many people who get vaccinated, prevalence goes down again. So there's this feedback loop. And then you can couple them together in these equations. So here's again that imitation dynamic coupled to an SI model. So one approach might be to, as Ian referred to, you can kind of endogenously model the behavior instead of tweaking the parameters. Instead of tweaking the parameter beta, you can create a state for that that describes how people change their opinions over time. And this is really part of a broader class of models that we'll also hear about tomorrow in the climate context. So you could apply this to any system where you have a human process and you've got some natural environment. And for example, in a human system, you can model the cultural. Human system, you can model the culture or institutional processes like the process of tree organization. And in the environment, you can throw in all of our lovely detail from our ecological knowledge about what matters. But the tricky part is the coupling. So, for example, the environmental influences the wisdom through many factors like risk perception, economic benefits, conservation value. I'll come back to that in a little bit. And so, whether or Anand and I have looked at various human environment systems over the years, this is just a couple of them, just to show how versatile and how pervasive these systems are. Human-environment interactions come up in forest tasks. For example, transporting firewood is a human decision. Coral reefs, forest grassland mosaics, fisheries, and land use dynamics are all systems. And land use dynamics are all systems where you have this human environment feedback. And we've had a lot of fun over the past 10 years studying these types of systems. But a big question is, what do we do about all the spaghetti, right? We have this nice simple system, but all this other stuff, we know it matters, and we try to ignore it, but it's there in the back of our mind saying, hey, hey, what about this? What about that? What do we do with the spaghetti? So the second way in which I'm interested. Way in which I'm interested in dealing with the spaghetti is through data-driven dynamical systems, which is basically a way of using combining dynamical systems theory and machine learning to get at this question. And in particular, we have something called the center-manifold theorem, which states that if you have some high-dimensional system like the Earth's climate or okay, and that's probably the movie thing. And that's probably the movie thing. The Earth's climate or some complex social system, maybe. The dynamics of many higher-dimensional systems will converge to a lower-dimensional space, especially when you're close to an equilibrium. And in particular, when you get to a tipping point where the nature of the equilibrium changes, dynamics simplify down to a limited number of possible archetypes. This is really crucial. What this means is that. What this means is that whether you're talking about epileptic seizures, phase transitions, or late eutrophication, if you look at certain indicators, they all go through the same patterns as they approach the tipping point. And it's a little bit like a spinning top, right? And if you know what to look for, if you're looking for those indicators, you can hopefully know when a tipping point is near. So it's a bit like a spinning top. So it's a bit like a spinning top. If you spin a top, how do you know it's going to fall? Well, it starts to wobble a bit, right? So it does a little twitch and then it keeps going and then eventually it falls over. In the same way, by looking at these variants, Lagnan-Augocorrelation, et cetera, and as they increase close to a tipping point, we can get some indicator. And they're the same across these different systems because dynamics simplify close to tipping points. But our theory always uses the But our theory always uses the first order term of Taylor Street expansion, right? Because it's easy to, it's aesthetically pleasing. We throw out the higher order terms. I'll just seem to my question period. And so we said, well, what if we just simulate a huge or create a huge library of possible dynamical systems with different tipping points and train an algorithm on it and then apply it to a real data set. If we make our library big enough, If we make our library big enough, that algorithm can predict transitions on data sets it wasn't even trained on. So, this you'll notice is turning deep learning on its head to some extent. And this works as well. So, by using the simplification neurotipping point, we can also use mathematics that actually turn out to be the same in these different systems. So, let's see. So, okay, so I'll just, okay, I will talk briefly about this. So, I'll just, okay, I will talk briefly about this. So, as it concerns the climate, for example, what we're trying to do is develop a different axis for evidence on climate change. The first axis is sophisticated mechanistic models like generalized circulation models. They're mechanistic and predictive, but we don't know if they're including everything that matters. The second axis is ice core data, path shifts. The pro is that it's empirical, it happened. The nature of the forcement is different, however. So, this third axis. However, so this third axis says that there's information present in the noise if we just know how to read it. And so that's our approach. The advantage is that it can predict based on present noise. We don't need a massive training library, but you need to have a big enough library. You have to be assured that your typical code is represented in that library. Okay, so the final question is: you know, when are different social, psychological, and economic theories? And the answer is never, but how do we deal with this? Never, but how do we deal with this as a modeler? So, one way that we try to deal with this in our work is we take some functional form. So, for example, this states that mask use will go up as prevalence goes up. And then we think, well, what different factors are consistent with this qualitative feature of the model? So the health police model is relevant here. Individuals use social and personal variables, a personal variable being perceived risk of infection, so that makes sense. Game three gives you a similar answer. Game 3 gives you a similar answer. Put those under the same function. Accessibility, higher prevalence means more demand for mass, which means more supply. Public health. Public health is most concerned with messaging around prevalent diseases, and therefore they will increase their messaging in response to higher prevalence. So all these are consistent with this functional form. I realize I'm just about out of time, but luckily I only have a couple of slides left. So currently, my student, Steph, I was. Currently my student Sefa is working on this type of approach for COVID-19. We're asking the question, using only information from the first wave of COVID-19 in March 2020, can we predict the second wave, or even remotely? And so we're using a pretty simple model. One interesting thing is that you have exponential decay in time in terms of how many people want to adopt MPIs. So what could possibly cause a decay in time in terms of willingness to A decay in time in terms of willingness to adopt. Well, there's a huge number of things. Emerging treatments make it less dangerous, like proning. We figured that out pretty early in the pandemic, people understoming. Rising case ascertainment, pandemic fatigue, declining fear of the unknown, we're afraid of what we don't know, and we got to know COVID a little bit. Evolution of reduced virulence, a huge number of factors can contribute to this. So we take this model. Here's one example. We fit it to Belgium, the first wave of The first wave of the epidemic in Belgium. We use cases and we use the Oxford stringency index. And then we see if you can predict the second half using approximate lesion computation. And you can see in this case that the orange curve is the behavioral model. The black curve is just the vanilla SIR model. And this is the predicted index. So it does okay predicting the cases and And it does a decent job predicting the index. And here's another example from the Netherlands. So, again, it's not as good in this case, but it's still better than the SAL model. And it even predicts the turnaround in the string index. So it predicts that the government will increase its adherence after the first wave. But I don't want to cherry-pick either. Sometimes it doesn't work. And in this case, in Austria, it gets the predicted stringency wrong. So, yeah, so that's all I want. So, yeah, so that's all I wanted to say. And so I guess I won't show you my last slide, so I'll stop there. Thank you.