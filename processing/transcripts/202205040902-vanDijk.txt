These past two days have been amazing, so I expect we will continue the trend with such an amazing array of speakers. Before we start, I apologize for mispronouncing your names of cities. I am really bad at it, even in my mother language. So we will start online with Dr. Lidritik, who completed his PhD in computer science at the University of Amsterdam. Science at the University of Amsterdam and the Lizmann Institute of Science, where he used machine learning to decipher links between DNA sequence and gene activity. Then he moved on to postdoctoral affiliate positions at Columbia University and Yale University, where he developed manifold learning and massive learning applications for single-cell genomic data. Now he is assistant professor in the departments of computer science in internal medicine at GAA. In internal medicine at GIL. He's specialized in developing machine learning algorithms for high-throughput high-dimensional data. He's recipient of the Dutch Research Council Republican Fellowship and the MIHR55 Maximizing Investigation Research Award. So currently, I am struggling with a vast amount of resources. Running with a vast amount of results derived from investigating single-cell data. So I look forward to the first talk: Discovering Hilon Signatures in Biomedical Data Across Space and Time. That, by the way, is an amazing title. So go on. Thank you so much for that very kind introduction. And yeah, especially thank you for inviting me to give me the opportunity to. Yeah, give me the opportunity to talk about my work. So, yeah, so I thought for today to kind of talk about three or four projects that are kind of ongoing in various stages. And I picked these because they're all to some extent related to sort of interpretability and explainability, which is the theme of the conference. I thought that would be fitting. So since these projects are ongoing and some are quite Are ongoing and some are quite early stages. I would love to get your feedback. So, first of all, our lab works on large biomedical data sets and we work on all kinds of data. So, we've been working a lot with single-cell sequencing, but we're gradually moving into sort of various biomedical imaging, sort of spatial temporal data. And so, while we don't really focus on one specific We don't really focus on one specific specific application, so not one technology or one specific biological system. The core sort of technology, the theme of the lab is that we develop new machine learning methods. And in particular, recently, we have been sort of using ideas from computer vision and natural language processing and bringing them into the biomedical domain and using these ideas to make sense of these large biomedical data sets. Of these large biomedical data sets. And in particular, we've been sort of working with spatial temporal data, and we've developed methods to discover sort of hidden signatures in biomedical data across space and time, and hence the title of my talk. So, and as I mentioned, actually, a lot of our work focuses on explainability. And I think the reason is that, I mean, explainability is important in any sort of application of machine learning, but I would say. Learning, but I would say in the field of biology and medicine, it's especially important because usually we don't have ground truth, we just have a bunch of measurements with no kind of any kind of label. So we really know nothing about it. So if you do your model, your self-supervised model to learn something meaningful, you have to be able to explain it to get some kind of insights because you're really lacking any kind of labels generally. So who here is from So who here is familiar with some technologies, experimental technologies in genomics, including single-cell RNA sequencing? So I'll just briefly explain how it works. So in traditional RNA sequencing, you would take some tissue, you grind it up, and you measure the RNA. And then you want to measure the RNA because RNA is a measurement of the gene expression, right? Gene expression, right? The central dogma in biology of DNA transcribed to RNA, translated to proteins. And both RNAs and proteins do stuff, right? So it turns out if you measure the RNA, you get a pretty good idea what's going on in a tissue. Then in recent years, this technology was sort of adapted to be able to work at the single cell level. Meaning, instead of a whole tissue, you can take an individual cell, measure the transcriptome, and see what's going on. So now you can use this technology to sort of quantify. Technology to sort of quantify heterogeneity in the tissue. So previously, you would have a tumor, you grind it up, you get an average measurement of the expression in the tumor. Now you can get like 10,000 cells and see all the different cell types that are happening in this tumor. Now, you know, machine learning people, computer scientists really are excited about this kind of data because it's big data, both in terms of dimensionality, because we're measuring something like 30,000. Measuring something like 30,000 genes at a time, but also the size, because you're measuring tens of thousands of cells in experiments. So you get a very big data matrix that you want to do stuff with. And the data traditionally is very noisy, very sparse. So you need algorithms to make sense of it. So this experimental technology has driven a whole field. And there's like hundreds of methods now published that make sense in different ways of single-cell data. So it's been really exciting in recent years. Been really exciting in recent years. And including myself, I've been contributing to this field. And so, the first project I want to talk about today uses ideas from causal inference to make sense of sort of experimental perturbations in single-cell data. And so, I think this ties in with the explainability because if you do an experiment, An experiment, um, then and so you know what you're perturbing, um, but then you know, your data changes in some way, and you can measure that. But really, what you want to know is not necessarily what is changing, what you want to know what is changing in a causal manner. What are the causal effects in the data? Because that's really tells you something about the biology. So, just looking at the data without sort of a model in mind would not tell you enough about the biology. So, this is how I think this project. So, this is how I think this project sort of ties in with this theme of interpretability and explainability. So, briefly, why did we develop this method? Well, when you do an experiment, a single-cell experiment, you never do one measurement alone on itself. A proper biological experiment always requires a control. So, you have some cell population, which is your control, and then you have your perturbation. So, for example, you're interested in knocking out a gene, or let's say you're interested. out a gene or let's say you're interested in the effect of some drug on the population, whatever your perturbation is, at the very least you need two conditions. You need control where you have no perturbation and then you have a sample where you have the perturbation and then you want to compare. This is straightforward. The problem is that in sort of traditional methods, you would compare these populations at the distribution level. However, that destroys any sort of single cell effect. So in an ideal world, you would Cell effects. So, in an ideal world, you would compare every individual cell and see what is the causal effect of that perturbation on the cells. However, there's a problem there. Because the measurement is destructive, right? So, in an ideal world, I would have a cell measured in one condition. So, let's say the control, right? You destroy it. Then you take a time machine, you go back to when the cell was still alive, and now you measure it in your other condition, right? Your other condition, right? You need a time machine because when you measure a cell, you destroy it, and you can only measure it in one condition. But to really know what's happening to that single, that specific cell, which is unique, you know, how it reacts differently between the control and the perturbation, you need to measure it in the same cell, but that is not possible. We don't have this time machine. Okay, so this is a fundamental problem to most biological measurements because most interesting measurements, I would say, Know interesting measurements, I would say, destroy the cell. There are some live cell imaging techniques that don't destroy a cell, but you're extremely limited in what you can measure, right? You can maybe measure one or two genes. If you want to do an interesting measurement, like measure all the genes, you have to destroy the cell. So this is a very fundamental problem in biology. So what is the solution? Well, you know what I said, we wanted the time machine. Well, we can't have a time machine. Well, we tried to build a computational time machine, if you will. Time machine, if you will. So, another word for this in sort of the causal inference literature is called counterfactual. So, counterfactual is kind of what would have happened if. So, that example of that cell, what would that cell have looked like if I measured it in the other condition, right? I've measured in condition A, but what would it have, what would it have looked like if I measured in condition B? So this is the counterfactuals like the time machine. So, in this project, we want to use ideas from causal inference. We want to use ideas from causal inference to infer these counterfactual cell pairs. So, have this computational time machine, if you will. And the way we do this is we match cells between two conditions based on their confounder signals. And I'll explain what that is. So when we have a measurement in this experiment that I described with the multiple conditions in the single cells, we can split, we can sort of decompose our signals into two groups. Our signals into two groups. One is called confounders and one are outcome signals. Okay. So the outcome signals are any kind of signal that correlates with a perturbation. So think of it as any gene that changes in response to the perturbation. Let's say the drug that you're perturbing. So let's say we take all those outcome signatures. Everything that sort of changes in response to the treatment. And now we look at what is left. What is left is any kind of signal, any kind of variability in the data. Kind of signal, any kind of variability in the data that is not associated to the outcome, right? To the perturbation. So we can split those two. Now, if we would match cells in the original data without doing this decomposition, we would get an incorrect matching. And the reason is that confounders, so these sources of variability that are not associated with perturbation, for example, changes, differences in cell size or Differences in cell size or cell cycle or what kind of any kind of biological noise, that these differences actually affect the outcome. So different cells can have different outcomes, right? So for example, if you have multiple cell types in your tissue, these different cell types can have different responses to your drug, okay? So as a result, if you would do the matching on the original data, you would get an incorrect matching. The cells change in response to the perturbation. Response to the perturbation. So, the solution is to match the two cells from the two distributions, from the two populations, the two conditions, based on the confounder signals. So, we've removed the outcome signatures. We can match the cells, and then we can bring back the signatures. So, this method is called causal independent effects module attribution plus optimal transport, or cinema OT for short. So, let me explain how the algorithm works. So, we have our experiment, right? So, we have our two cellular populations, our two conditions. Two cellular populations or two conditions, for example, control and drug treatment. And we do our single-cell measurements and we get our gene expression matrix. So we get our cell by gene matrix. Then we use independent component analysis to separate the confounders from the outcome signatures. So as I said before, the outcome signatures is anything that correlates with the perturbation. And anything else is what we call confounder signatures. These are signals. Signals, so these are sources of variability between cells, but they're not associated with the outcome. Now, what we do is we take those confounder signals and we do an optimal transport on that. So, we use optimal transport because optimal transport allows us to match cells between the two conditions in a way that minimizes the total transport cost. And this isn't an assumption that we're making, we're making the assumption that biology. The assumption that biology uses some kind of minimal transport, and I think it's a reasonable assumption, it's probably not a perfect assumption, but we have to make some assumption here in how we're matching the cells. And now we have a matching of cells between the two conditions. So we have our cell pairs that was done on the confounder signals. And now we can bring back our outcome signals. And we can, for every gene pair, we can investigate how the changes. So every gene pair that we get here, sorry, every cell pair that we get here. Every cell pair that we get here is our counterfactual cell. It's our time machine, if you will. It's a cell that's a mapping between two cells that says this is effectively the same cell measured in the control condition and then measured in the treatment condition, right? So, of course, it's not the exact same cell, but it's the best possible matching that we can do. And then for that cell pair, we can compare them. So at the single cell level, we can ask what is the effect, what's the causal effect of our perturbation on that. Of our perturbation on that specific cell. And the effect will be different on different cells. So we compared our method to existing single-cell sort of methods that do something similar, at least in terms of comparing different conditions, because this is, you know, the general problem is not new, where people thought, okay, we have two conditions of an experiment and want to compare them. The difference with our method is that we don't do, we can do That we don't do, we can do actually single cell level analysis. We don't have to compare at the population level, plus, we take causal inference into account. Okay, so we tested our method in different ways. And one way is where we actually generated, because the problem is in biology, you generally don't have ground truth data, right? We don't have ground truth sort of causal matching, right? Because again, because when you measure things, you destroy them. Destroy them. There are ways around it. And one way around that is by generating your own data in silico. So we use this toolbox called Splatter, where you can simulate single-cell data and we can add all kinds of facts in it. And then we can run it through our method and see if we can recover the original causal structure. And we can do that very accurately and better than other methods. We can actually also use real single-cell data and not necessarily predict individual causal pairs of. Individual causal pairs of cells, but we can predict our ability of our model to correctly match cells at least based on some kind of labels that we have, for example, cell types or other kind of metadata. Okay. So just to give you an idea of what kind of analysis is possible with this method. So my collaborator, Ellen Foxman, she runs a lab in which she grows various airway organoids. Organoids. So, organoids are basically cells that you grow in some condition where they, it's not a cell suspension. So the cells are not free-floating, but they are solid, if you will, and they grow in a little organ structure. You generally start with stem cells and they grow into some kind of organ structure that resembles properties of the original organ, obviously much more simplistic, but it's an in vitro system, so you can do all kinds of experiments. So, here's specific. Can do all kinds of experiments. So, here specifically, she grew airway organoids and then she perturbs them in different ways. So, for example, she infects them with different viruses or she exposes them to different environmental conditions. So, in this specific experiment, she did two things, actually three things. She either exposed the cells to a virus where they were infected with a virus, specifically a rhino virus, or she exposed them to cigarette smoke extract. So, we know that smoking. So, we know that smoking has a detrimental effect on your airways, and it also makes you more vulnerable to various airway infections, right, including like viruses. And she did the third condition, namely she combined the infection with the smoke. So, she perturbed, she exposed the cell to both conditions and measured. So, the sort of the biological question that we had in this project was, is the effect of infection. Is the effect of infection different when it's in combination with the smoke extract, right? Is there some kind of sort of interaction between the two conditions? Is there some kind of synergistic effect? Okay. So first what we did is we, so by the way, the mock condition means that there is nothing. There's no virus. No, it's the control condition. So first we combined, we compared the mock condition to the virus condition. So we have our pair of our control and our virus condition. We did our causal matching. Condition. We did our causal matching and analysis. And then we can quantify per cell type. So here it's shown per cell type what the effect was, how much did the cells change in response to this condition per cell type. And you can see that, for example, the ciliated cells and the goblet cells change a lot. Then we can do the exact same analysis, but in the presence of smoke. So we go from we match the smoke condition to the virus with smoke condition. And again, we can measure how things are changing. And what we can see is that things cell are cells are changing. Things, our cells are changing differently, meaning that the presence of the smoke changes how the cells react. So, there's another way of sort of quantifying this effect, and that's in terms of thinking about non-linear effects. So, if you think of there's condition A and there's condition B, if they were completely independent, their effects would be additive, meaning that the A plus B condition would just be a summation of the two, right? So, you can see that here in this current. The two, right? So you can see that here in this cartoon, zero is the mach condition. So if you go from zero to a, that vector, that's one condition, zero to b is another condition. If you would add those two vectors, just completely additive, and that's indeed what you measure, then there's no synergy. There's no nonlinearity going on. The effects are completely additive. If the A plus B condition is different from what you predict, so the measurement is different, that means that there's some kind of interaction going on with A plus B. We can easily quantify. Be. We can easily quantify that. We can literally compute the deviation of the measurement of the combined condition from the separate conditions, and that gives us a measurement of the synergy. And now we can go back to our data with our four conditions, and we can compute the synergy. And the cool thing is that we can compute the synergy at the single cell level. For every individual cell, we get this parallelogram, if you will, and we can quantify to what extent did that cell react to the conditions, to the perturbations, in a linear or non-linear way. In a linear or non-linear way? Was it synergistic or non-synergistic? And we can quantify the score and we can look at that and we can sort of visualize it per cell type. And as a result, we can identify which cells have an especial synergistic response, meaning there is some kind of interaction going on between the virus and the smoke. So we're currently in the process of analyzing this data and figuring out: okay, what are the specific gene and gene programs that are responsible for these synergistic responses? But I just wanted to sort of show you. To sort of show you at a high level what kind of analysis this enables. Okay. Yeah, so this is this project. I want to move on to another project, but maybe there are any questions or suggestions about this project in the meantime. If not, I can just continue to the next. Maybe I have a very quick one. Yeah. Are the symmetry scores comparable across cells? Like, maybe if it's non-linear, maybe even single effects might have, might not be comparable across cells. I don't know. This would be a possibility. So you're saying that if the synergistic effect is not comparable between different cells, you said? Yeah, that's the question. So, well, I guess the Well, I guess the whole point is that it's not constant, right? That different cells have different synergistic effects, right? It might be that there is some cell type that has no synergistic effect, meaning the virus does something to the cells, the smoke does something to the cells, and when you combine them, it's just additive. So yeah, it's combined, but there's no interaction between the two in one cell type. But in another cell type, there might be an interaction between the two processes that creates something different. That creates something different. So, the point here is actually to quantify the synergistic effect at the single cell level and then compare cells and ask: okay, which cells are synergistic and which ones are not? And in the process, learn something about the biology. Does that answer your question? More or less, because, like, in your formula, right, you're comparing the sum with the single effects, basically, right? Yeah, yeah. So, I'm wondering if Yeah. So I'm wondering if like let's say like if you just apply one single effect, like it might be different for each of the cells, right? And then like maybe synergistic cores might not be. I mean is it even necessary that they're comparable across cells? Yes, because we compute the score for every cell. So every cell will have a synergistic score, right? If it's zero, it means Synergistic score, right? If it's zero, it means it's completely additive, right? Yeah, yeah, yeah, no, no, I get that idea. You get the idea. The point is that we are computing it for every individual cell. And the point is that we want to see if there are differences, and there are indeed differences between cells. So. And I have not that part. I was wondering about something, but I can continue. There's just one more question. Yeah. Yeah, I'm wondering how you separate the true metrics. How do you separate the true heterogeneity between the cells? How we separate the what? Sorry, we couldn't hear. How you separate the true heterogeneity from measurement noise because I guess that measurement noise could quite increase differently as well. I see. So how we okay. So the you mean how do we how we separate a biological variability from like a technical variability? Yes. I mean, that's a great question, and that's a general issue in this field of single-cell measurement, single-cell biology. So I would say that, so actually in other projects that I'm not presenting today, we have worked on that. And I would say the short answer is that technical noise has different properties. Properties than biological noise or biological variability. So, for example, one major source of technical noise is that the measurement is sparse, that you have zeros, meaning on average, you're only capturing like 10% of the transcripts in the cell, and the rest is not measured. But that is generally a random process. And with some kind of smoothing methods, imputation methods, you can. Methods, imputation methods, you can fairly easily fix that. Biological variability looks very different. There is, I would say, generally, the biology has sort of low frequency signals and technical noise is high frequency. So it's easily separatable. There's another technical source of major technical noise or artifacts, which is like batch effects, which is a problem on its own. But I would say, so the long answer is it's complicated and it really depends on what kind of noise you're looking at. But in the short answer is. You're looking at, but the short answers: in general, technical noise looks different from biological variability. I hope that answers your question. Questions? Yes? Yeah, if we have time, I have two questions. Yeah. First, I guess on this one, how do you think about saturating effects where there might be an additive effect, independent effects, but then because you get a saturation, it's additive and say a logistic. It's additive in, say, a logistic space rather than a linear space. Yes, but I would say that's still a non-linear effect, right? If just the gene expression function is a sigmoid, right? And your atom and you saturate, it's nonlinear nonetheless, right? Maybe there's a specific cause for that, but that still has effects on the biology, right? Because if it's saturated, then adding the other effect doesn't have an effect, but that has implications for the biology. Has implications for the biology. So I would still say that is non-linear and it's interesting and it has meaning for the biology. And one other thing of time. On their previous project, suppose you also had multi-omics data, you had single-cell multi-omics. How do you think about using that? Would you use that as more features to act on or validation or some other strategy? That's a good question. I mean, so yeah, so you could combine the two data and then you just have more features to match on, right? More rich data and maybe you can do more accurate matching. Maybe another way, and this is really depends on the nature of the multiomics data. Maybe you could use it as a validation, right? So maybe you expect cells that you match causally at the transcriptional level. Causally, at the transcriptional level, that they have similar epigenetic states. So, when you do your singles, like attack sequencing or methylation states or something like that. So, you could use it maybe as a validation where you expect the two cells that you're matching also have matching in this other domain. And then you could use it as validation, perhaps. No. Any more questions? Yeah, let me move on to the next project. So this is not single cell. In fact, this is actually a project, a neuroscience project. So one of my students is actually part of the neuroscience program at Yale. And so we have a collaboration with Jessica Cardin. With Jessica Cardin, who's a neuroscientist, who does calcium imaging. And in this particular project, we're working with what is called mesoscopic, mesoscopic calcium imaging data. So in calcium imaging, you have transgenic mice that basically can emit a photon when their neurons are firing. So it's a little sad, but the mice have essentially a camera that's a hole in their skull, and the camera That's a hole in their skull, and the camera that looks onto their brain, specifically on their cortex from the top. And this allows, I mean, the technology is much more complicated, but to make a long story short, it allows us or my collaborator to measure videos of their cortical brain activity. So it's pretty amazing. So these mice can do things, they can freely behave, or we can do specific experiments where they're shown specific stimulations. We also measure their behavior. We also measure their behavior, but at the same time, we have this video recording of the cortex, as you can see here on the red. Now, it's just the cortex, so it's a two-dimensional projection, but it happens to be that, you know, the higher level processing happens in the cortex, just like with humans. So it happens also to be generally the most interesting part to look at. I mean, there's many limitations with this technology. Every pixel is like millions of neurons, and the time resolution, it's something like 20, 30. Time resolution, it's something like 20-30 hertz, which actually doesn't capture all the frequencies. Nonetheless, it's a pretty amazing technology that this is possible, right? To get a video of brain activity. So you can imagine that this is very rich data and we want to make sense of it. And you need algorithms for that to do that. Moreover, and again, to tie it in with the theme of this conference, this meeting, if you have models that can model this data, can predict it. Model this data, can predict it. That's not really the goal. The goal is to understand what they're learning, right? So, we want if we train a machine learning model on this data, we want to have some kind of interpretability, explainability, because that's what would point us to the biology, right? So, why is this interesting? So, this is actually, I mean, it's a very fundamental question how cognition is encoded. Is encoded in brain activity, right? It's one of the most fundamental questions as humans, I guess. So, this is a spatiotemporal process, right? It's videos. So, you know, can we infer patterns across space and time from this data? And can we then link that to behavior, right? Or can we also define a brain state space, some kind of embedding of some latent space of the brain activities that evolves over time that we can That evolves over time that we can then use to make sense of it. So, this is a very fundamental project and it's very much sort of basic science, but it also has implications for things like disease, right? Because if we want to understand when brain activity goes wrong, quote unquote, let's say in schizophrenia or autism, we need to have a model of how brain activity works in a healthy system, right? So, to understand diseases, we need a model of brain activity. And that's why this is so important, I think, not just. So important, I think, not just for basic fundamental understanding, but also for disease. So, in this project, we were particularly sort of inspired by models in natural language processing models. So, as you probably know, and I saw actually that there were some talks about this earlier and yesterday, I believe, about the amazing sort of progress that has recently been made by natural language processing. In natural language processing, you know, models like GPT-3. So these models can just be learned by on all the text on the internet, right, in a completely self-supervised way. So you just give them lots of text and they learn to do amazing things like answering questions and generating text. They seem really intelligent and creative, actually. So we were wondering, well, can we do the same thing, but instead of text, we have brain activity data. So these models like GPT-3, they're generally based on They're generally based on sort of transformer, what are called transformer models, which are based on this idea of self-attention. So, what is self-attention? So, self-attention is a method to learn contextual information. At least this is how I see it. And in language, contextual information is essentially relationships between words. So, we know that language is highly context-dependent, right? The meaning of a word completely depends. A word completely depends generally, I mean, depending on the word, but on the context. And the meaning of a sentence is, you know, the relationships of the words. Now, self-attention has been incredibly powerful in natural language processing, you know, to do tasks like completing sentences, et cetera. But there's one really cool property that self-attention models have, again, which ties into this meeting, is explainability. Self-attention allows you to. Explainability. Self-attention allows you to get an idea, at least to some extent, what the model has learned. So, not only are they incredibly powerful models in whatever task they have, but they provide insight, which is incredibly important. So in this project, we were wondering, can we use these transformer models to learn to model brain states instead of language? Now, at a high level, language, natural language, and brain dynamics have many. Language and brain dynamics have many things in common. In fact, when you think about it, sort of kind of philosophically, language is a projection of brain states, right? If you think about it, I have some ideas in my head, right? I have my work, my projects, and I want to convey that information to you. In an ideal world, and perhaps in the future, we can do that telepathically. I can send my thoughts to you, and that's it, right? Much more efficiently. And I'm sure at some point we'll get there, but. And I'm sure at some point we'll get there, but right now we have to do it through language, right? So I take my brain states, my thoughts, project it into the language, send the language to you, and you decode it into brain thoughts again, right? So in that sense, language and brain states have very much in common. There are also differences. So for example, language is discrete in time, right? I'm uttering discrete words in time. It's not a continuous thing that I'm Continuous thing that I'm saying. However, brain states, we can think of them as a continuous process, more or less, right? So we have this continuous dynamics in my head, but my language is discontinuous, discrete. So transformer models have been used in the discrete sense. So we had to adapt a model and we created actually what we call the continuous spatial temporal transformer. So we applied the transformer, even though they originally developed. Apply the transformer, even though they were originally developed sort of for discrete data, we apply them to continuous domain. In addition, transformers were either used in time, so for example, to model natural language, right? Or in space, for example, in vision transformers, where they're used to model pixels or patches in an image. And we combine those ideas to model information in space and time because our data is spatial and temporal, right? Our data is sort of videos. Or the videos. So, what does the model look like? So, what we do is we take segments of our video. So, for example, we take 20 frames and we encode each frame using patches. So, every frame is decomposed in different patches. So, each patch has an X and a Y coordinate, a spatial coordinate. But every patch also has a temporal coordinate, right? Because we have, let's say, 20 frames in a segment. So, every patch, every region is encoded with a spatial temporal coordinate. With a spatial temporal coordinate. And then we sparsely sample these patches and then we compute self-attention over those patches. And the goal of the model is actually to predict future brain states. So if you're familiar with the language models, generally the way they are trained, if they're trained self-supervised, is by masking words and predicting those words. So you take a sentence, you mask a word, and then you ask the model, can you predict that word? So you can imagine that if you were able to predict a missing word, You are able to predict a missing word, you have to have a pretty good understanding, a pretty high-level understanding of the sentence and what it means. So, we did a similar thing. What we asked the model to do is say, here's a segment of consecutive frames. And we mask a frame, we ask the model, can you predict that? So, you can imagine that we would never be able to predict that perfectly because the state, the brain state, is not just dependent on other. On other time points like history, but it's also dependent on outside information, right? Which we don't measure. We don't have complete measurement. But to some extent, the brain state should be the result also of previous states. And the reason why we predict brainstorms in the future, and we don't just arbitrarily pick a frame, we always predict future brain states because it allows us to interpret the model in a causal way. You can say, okay, these activities then result in that activity in the future. Then result in that activity in the future, and that gives us better insight into the biology. So we set up the model, we gave it a number of frames, and then we say, okay, encode those frames, compute self-attention, and then predict the future frame. Okay. And this is, again, this is a pretty difficult task because it's hard to predict the future. So the example that I'm showing here on top, we can see the input data. Input data, so in time. So, this is the segment that the model sees and then tries to predict. At the bottom, you can see the train model and its attention weights. So, here we show the attention weights in the original projection on the frames. So, you can see that certain regions are active and others are not active, and that the behavior is also different in time. So, what's important, let me to To um to to to realize is that the attention that the model shows is different from the original activity. It's not just showing regions of high activity or low activity. What it's showing is showing to us where the model pays attention to, where is the information encoded, and not just where, but also when is it encoded, right? Because our attention is across space and time, so we can see. Space and time. So we can see, you know, where in the brain, in one region, is the information encoded, but that might not be the same at different time points. So this gives us some kind of measurement, some kind of, we can call them spatiotemporal motifs that contain the information, at least with respect to the tasks that we're training the model on, which is predicting future brain states. So, where is information, the history encoded? So, yeah, so we can use this model to understand biology. So, for example, what we can see here is that this region is active, which is this somatosensory cortex. So, the somatosensory cortex is usually driven by facial movement and whisking, which are associated with arousal levels. That's something, a concept that they use a lot in neuroscience with mice. That they use a lot in neuroscience with mice, and it's encoded in the somatosensory cortex. And you can see that the model pays attention to there. And in this case, this example, the mouse was presented with a visual stimulus and it was also moving. So we're recording the wheel speed of the mouse. So it was presented with the stimulus, it was moving. So it was in a highly aroused state. And indeed, even though the activity in that region is not that clear, the model pays attention to the somatosensory cortex, which makes complete sense. In fact, this is. Sense. In fact, this is the same even when there is no visual stimulus, but this mouse is still moving. In this case, there is a visual stimulus, there is no movement. When the mouse is not moving, neither is there a stimulus presented. There is no attention of the models to the somatocentric cortex. So this is completely in line with what we would expect. But this is not something you would be able to see from the original data. But our self-attention model. But our self-attention model is pointing us to this pattern, if you will. So, this is just to give you a little taste of what we can then do with this model in terms of the explainability. So, another thing that we can do with this model is we can take these new encodings in terms of self-attention and project them into a lower-dimensional space. So, we can take these high-dimensional attention vectors, dimensionality reduce them. I think here we used probably UMAP to reduce it to two dimensions. UMAP to reduce it to two dimensions. And as you can see here, our learned brain state embedding, so each point refers to as a state in space in time of the brain, is highly correlated with external variables. In this case, it's behavior, whether the mouse was running or resting, as you can see. So this new embedding provides us with a good sort of latent space, low-dimensional state space of the brain. So even though it's very high-dimensional data, it's projecting to low dimensions and we can make sense of it. Dimensions, and we can make sense of it. Okay, let's see. How much? How am I in time? It's like 10 minutes or 10 minutes. Okay. Let me actually skip this project. So, yeah, just very briefly. So, this is very much an ongoing thing, but this also is based on transformers and explainability. Also, it is based on transformers and explainability. So, I think this could be interesting to present. So, we've been, you know, as you can see, very much fascinated by transformers and self-attention. We think it's an incredibly powerful technique that can be used far beyond natural language, as you saw in our use of using it to model brain states. In this project, we actually use self-attention transformative. Actually, use self-attention transformers to encode single-cell data. So, why do we do this? Well, we realize that if you think of a cell, a single cell, and the genes that are active, we can think of the cell as a sentence. Okay, so if you make comparisons analogy to natural language, a cell is a sentence, and the genes that are expressed are the words. So we were wondering: well, if we have many examples of single cells and the genes that are expressed, just like we have many examples of sentences and words, can we use the same techniques, the self-attention transformers, to learn representations of cells and of genes, right? In a completely self-supervised way? There are some differences, though, with natural language. Maybe let me ask you the question. So, what do you think? What is the difference between What is the difference between words and sentences if you compare them to genes and cells? What is one major distinction? Bingo. Very good. Exactly. Natural language has an order, right? And genes don't have a natural order. But there's actually a concept for this in natural language, and it's generally referred to as a bag of words technique. So you can use, yeah, a bag of words means you just have a bag of words, literally, there's no natural order. Words, literally, there's no natural order, and you can still learn meaningful things. So, a cell we can think of it as a bag of genes, right? Um, and then we can still, you know, make sense of it. And the only difference is that for transformer models, you know, in transformer models, the way they work is you have words and words have some word vector associated with them. Either you've pre-trained that with some other model or you learn them into it. But every word has to be associated. But every word has to be associated with a vector. Then, in language models, you add a positional information to it. And there's different ways of doing it, but you're adding information whether the word is the first word or the last word. And this is important information, right, for the meaning of a sentence. And then every word, so every word is encoded by its word vector and its position. And then the transformer model learns or maps, models, attention weights between the different words in the sentence, right, that have their position. Different words in the sentence, right? That have their positional information. In a bag of words approach, you can simply remove the positional information. You say, I don't care about that. Every word is just encoded by its word vector. That's it. And we can still compute attention. The transformer doesn't care about that. You just have one piece of less information. So we can do this in our single cell data. Every gene, so what we're doing is we're learning for every gene a gene vector, if you will, just like word vectors. Vector, if you will, just like word vectors, we have gene vectors. So we have, let's say, 20,000 genes. Every gene, we're learning a vector. You can also initialize the model with pre-learned vectors, and there's different ways, but we're learning these vectors. Now, we don't have positional information, but we have another piece of information. What do you think is that information that we have in single-cell data, in addition to the identity of the genes? Expression. Expression. Yes, exactly. We have expression. So we encode expression, right? So instead of a positional information, we have an expression vector that we can add to the encoding of a gene. So every gene has a gene vector, its identity, plus its expression level, right? And we generally, with different approaches, but we do essentially do a sparse sampling. So let's say you sample 500 or 100 genes in that way. You encode them with their identity and their expression level, and then you compute the 10. Expression level, and then you compute the tension between them. And then you can do with that whatever you want. You can train a supervised model, for example, you can have the model predict labels. Generally, we do a self-supervised model, just like with the language model and our brain model. We train a model to predict masked values. So what we do is we take a gene, we mask it as expression level. So we set the expression level to zero. We compute the attention, and then we try to predict that expression level back. And then we try to predict that expression level back. And of course, a model that's able to predict missing data should learn a meaningful representation of the data. Okay. And we have different ways of training it. Our initial model used a student-teacher setup, which is kind of a contrastive learning approach. Now we're actually using what's called a masked autoencoder. So there's different ways of training the model, but the base model, how we encode the self-attention, is kind of similar. So what can we do with this model? So, what can we do with this model? Well, the first thing what's kind of cool is that just like language models have word vectors, we have gene vectors. Now, this is a necessity. We need to have gene vectors and we're learning gene vectors for the model to work. But it turns out that the learned gene vectors actually provide meaning. So, the way we tested that we are able to learn gene vectors is what we did. We took MNIST data, so image data, and we tabularized it. So, we took every pixel. So, we took every pixel as an independent feature. So, we removed any spatial information. So, we call this pseudo-single-cell data. We pretended that an image is single-cell data where every pixel is a G. Then we trained our, what we call the single-cell transformer, and we learned our feature encodings. And you can see here in B and D are our feature encoded encoder encodings colored by the original pixel coordinates, so X and Y coordinates. Coordinates, so x and y coordinates, as a validation to show that similar pixels are mapped close together. And on the left, you can see the initial in the initialization of the model, which is completely random. So, this is a proof that our model is able to learn meaningful gene vectors, if you will. On the left here is the same thing, but on actual single-cell data. So, every point here is a gene. And as you can see, it learns interesting clusters. And we're actually in the process of validating these clusters right now. Right now, we can also learn cell encodings. So, just like language models can learn sentence encodings, for us, the sentence is a cell, and we can map that cell, that encoding to a latent space, as you can see here on the right, or the fashion MNIST data on the left, where every point here is an input. On the right, every input is a point as a cell. We can map it to a latent space, and here we color it by different perturbation labels to show that it's a meaningful space. So, we can learn both gene encoding. So, we can learn both gene encodings as well as cell encodings. And now, perhaps the most interesting thing, again, tying back to the whole explainability, is self-attention allows us to get an insight into what a model learns. So here you can see an example of a visual transformer model on image data, and you can see that the attention maps point to the foreground or the interesting, the meaningful regions in the image. So, we were wondering: can that provide us insight into biology? And this is something we're working on. Set into biology, and this is something we're working on, but we have sort of three directions that we're going in. One, we can find high-attention genes, and high-attention genes, you know, can think of it as foreground genes, are the important genes in the biology. So basically, it provides us a way, you know, you have 20,000 genes and maybe you can find the 100 most important genes because they have the highest attention. And we can do this in a completely self-supervised way. So it's a way to sort of zoom in onto meaningful biology. Meaningful biology. So, if you're familiar with self-attention, it's actually a feature-by-feature attention matrix that you're learning, right? It's not a vector, it's a matrix. So, we think that this can provide us insight into gene interactions, because if one gene pays attention to another gene, it may be that they're actually interacting in terms of the biology. So, finally, we have ways to validate the high-attention genes. Basically, we use them to do a supervised task where we predict labels. Do a supervised test where we predict labels, and we show that our important genes can predict these labels much better than, for example, random genes or genes identified by other methods. Okay, so that's it for today. Yeah, so just to acknowledge my collaborators, my lab members, and funding. Yeah, so if you're interested in machine learning biomedical data, please reach out to me. I'm looking for postdoc students or any level, really, or interns. At any level, really, or interns. Thank you so much. Yeah, perhaps there are questions about these last projects. Thanks for the amazing talk. Any questions here or with labeling single cell is always complicated. You have a lot of Complicated, you have a lot of noise and it's not always easy to really find the labels of the sets. So when you are encoding the genes, like in this final application or the transformer, like you are doing this on one cell type at a time or like taking all the cells in order to find these encodings for the genes? Right. Right. So we do this approach in an unbiased, as unbiased way as possible. So that's really the point in this project is to what can we learn from single cell data in a completely self-supervised way without knowing nothing about data, no labels, nothing. You just provide the raw data and let the model train and it will find the patterns. So think of it how these language models are trained, right? Like GPT-3, whatever. Trained right like GPT-3, whatever. They get no super, there are no supervision, there's no labels. You just dump a bunch of texts on them, right? Basically, all the texts on the internet, and they just learn, right? They learn by masking words and stuff. So completely self-supervised, and they learn something meaningful. We went into this project with the same philosophy. What can we learn just from lots of data without preventing any supervision, right? Because that would be obviously the most interesting thing, useful thing. You can get meaningful stuff from the data. You can get meaningful stuff from the data without actually providing it with anything except for the raw data. Okay, thank you. Questions? Yes, for the well, thanks for the talk. It was quite interesting. For the brain project, I was wondering, since transformers don't have memory encoded and they cannot process arbitrary sized inputs, how are you deciding which is the scale, temporal scale in which you're fitting the data? Because I'm guessing. Scale in which you're fitting the data because I'm guessing without being without having any idea that it will impact highly the results you get. Yeah, that's a great question. So, actually, we're kind of letting the biology, our results drive that. So, it turns out that, you know, when we give, for example, 20 frames, as, you know, so we're going back 20 frames in history to predict the 21st frame, for example, that's the self-attention goes down exponentially. The self-attention goes down exponentially. Actually, I have a figure of that. I didn't have it in the talk, but the self-attention goes down exponentially with time, right? Which makes sense, right? Because the further you go back in time, the less correlation or information there is in the history, right? And it turns out that actually around like 10, 12 frames, it goes pretty much to zero. So there's no point really in going further. And I'm not saying that there is no information in the brain that goes further back. In the brain that goes further back, just a limitation of the measurement. We have very much incomplete information, right? So maybe if we had some kind of perfect measurement, a very high resolution in space and time, there would be much more information in history. It just turns out with the current technology that we have, it doesn't go that far back in time. So if you think about the measurement being, let's say, 20 hertz, we can think about like half a second, we go back in time, essentially. We go back in time, essentially. No, yes, half a second, 10 frames. So, yeah, just empirically, we have found that there are really no signals further back in time. Does it answer your question? It generates a follow-up, which is, so have you considered, I mean, leaving a bit the unsupervised approach or maybe discretizing time using your expertise so that you can maybe work around this temporal limitation? So, I mean, I said it's we're modeling as a continuous system, but the reality is that the measurement is discrete, right? Because in the end of the day, any measurement is discrete. You have some temporal resolution. In our case, it's like 20 hertz or something, right? So the data is still discrete. So, yes, you could discretize it even more if you wanted, for sure. So, you could say, yeah, you could discretize it. But the thing is, we actually don't want to discretize. We think it's interesting to. Discretize. We think it's interesting to think of the system as a continuous system in time and model it as such. So, for example, some of the things that we're doing with the model is things like interpolation, right? We show that our model, even though it's designed to be discrete, the model originally, transformers, the data is effectively discrete too, that we can still have a continuous measurement or a continuous modeling, and we can prove that by doing interpolation and stuff like that. By doing interpolation and stuff like that. So, actually, I would say, yes, there's ways to discretize, but we don't want to. We want to model this continuous system. That's how we think it's interesting. We think it's novel. Thank you. Questions? Yes? Great. Thank you. I have a question about the single cell transformers because the singles are software from APIs. And without accounting for these, I'm just now using all the Just like now, using all the data. Maybe at the end, what's on mine is just bad things. So I didn't, it's a little bit hard to hear because you kind of seem to get a little bit far away from the microphone. So could you or someone else repeat the question? Or maybe who's like closer to the microphone? Can you hear me now? Yes, yes, thank you. So, in the case of single-sub transformers, as we know, the single cells are. As we know, the single cells suffer a lot from batch effects. I can't create this in the model because if you are just like using all this data, maybe if you what you find is just a batch effect and not a real signal. You're completely right. And this is a major problem in the single cell field, and many people have worked on it, including myself. And I don't think there's ever a perfect solution because, at the end of the day, you know, with batch effects, Of the day, you know, with batch effects, like imagine, I do, I was talking about my experiments, right? About control and perturbation. If I only do one measurement in control and one in perturbation, I never know, I can never know if the difference between the two conditions is a batch effect or if it's a real biological effect, right? In the end of the day, there's no way of knowing. Of the day, there's no way of knowing unless if you make some assumptions where you think, okay, the batch effect has some kind of structure and we can remove that. But if you don't know that, you don't know the difference. So I would say the best solution is to have a proper experimental design where you have multiple controls and multiple perturbations, and they're not done on the same day, right? They're mixed. And then, if there is a batch effect, you can see that batch effect. So I would say my method does not try to. My method does not try to remove batch effects and does not necessarily solve that problem. However, yeah, I think that's the conclusion because if there is a batch effect, then again, that could have been biology, that we can't really distinguish it. So I think it's just not a problem. It's a very real problem. We're not trying to solve that with our method. Not trying to solve that with our method, and I think that's the short answer. And I have to think about it because, actually, now that I'm saying this, I'm wondering if there is a way that we can figure this out, meaning if the batch effect would show up differently in the signals than a biological effect. I have to think about it. Maybe there's a way to do it, but it's something we're not really addressing. It's something that, yeah, other methods try to. Yeah, other methods try to address. I hope that's a satisfactory answer.