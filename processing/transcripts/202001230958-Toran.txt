So, this is the resolution session. It reminds me a sentence of Oliver Kuhlmann. I heard him, one of the co-authors of this paper on Pilagerian Triples, so practitioner and also theoretician. He would say, one of the things that upsets me the most is when people say resolution is well understood. So, this is also resolution. Yeah, so um and especially I will talk about the difference between general and three-like resolution. So in tree-like resolution, as you all know, if a clause is needed more than once in a reputation, you need it to derive every time and so the reputation becomes big. As you can see here. And there's an almost optimal separation between general and tree-like resolution, the length or size of the The length or size of the proof by Benzassoni, Kreitzo and Dickenson. They show that this family of formulas with basically length L in three lag resolution length exponential in L divided by log L. And there's an almost matching upper bound with the same Same, but with a log log L factor in export. It's pretty tight, but it's not completely tight. So what we investigated here is what happens with the space. There's the difference between three-lax space and space in general resolution. And for this, we would work. And for this we will work with configurational style resolution. So we have basically a list of configurations. The configuration is conjunction of clauses and from one step to the next one we can work doing actual download, erasure or inference. And since we are working with three-like resolution, there's a version of this where you allow three-like derivations. Tree-like derivations, and for that difference is that in the inference rule, every time you derive a resolvent of two clauses, the two parent clauses disappear. So this is this characteristic-like inference. And yeah, for complication measures, I would basically talk about closed space, but But other results work also for variable space. Although, first, variable space in the general resolution case, because there is no difference between variable space and tree variable space. This is the same concept. You think a little bit about it. And right, if we have a previous three means like three languages for length or two. And so in warming up for tonight's session on games, we use several games as tools. There will be actually three, so it's important not to mix all of them. So the first one is the well-known prover delayer game introduced by Pablo and Impraiasso in order to prove. In Playasso, in order to prove lower bounds for three-like sites, three-like resolution sets. And here we have two players called delayer and prover and delayer. So prover wants to facify a clause, ask for a variable, and delayer had three possible answers, 0, 1, or stars, if it's one of the two first cases. Prover just plugged. Prover just plugs in the value and reduces the formula. And otherwise, he gets also to choose the value of the variable and plug it in. But for that, for a star, he has to pay one point. And they play until the formula is falsified. And after a clause is falsified, one of the actions is falsified. And the score of the layers, the number of stars, and he wants to keep this number small. So this was introduced in order to prove lower bounds for size, but actually, for an acidifiable formula F, if this is the maximum number. If this is the maximum number of points that the layer can get with an optimal strategy of prover, this exactly characterizes three-like closed fits. Closer here, the people diversion. Okay, the second game you also know is the pebble game. You play this not on a formula but on a graph. And there's the rules: pebble placement. You can put it on an Pebble placement, you can put it on a source, or when all the pebbles are all the places of vertex have a pebble, then you can put a pebble also on that vertex. And you can remove from sources or for any time, from anyone. So you play the game until you have a pebble on the unique sync of the game. Actually, we've Unique sync of the game, actually, we continue playing until there's only one pebble in this unique sync. Okay, and here you come the number of pebbles, the maximum number of pebbles used the name. There is a less known version of the game, which is the reversible pebble game. I think it was introduced by Bennett to charge reversible computation. And here's the same goal: you have a sink, you have to put a pebble in the sink. And the rules are somehow easier. For the placement, because they are symmetric, for the placement, you can always put a pebble in any source or on a vertex when all the predecessors have a vertex, a pebble. Or yeah, and for pebble like this, you put another one here, but for removal, you can only remove. Um you can only remove from the sources um or only if well, if all direct predecessors have a pebble on them. So for in this case this had a predecessor so you could remove the pebble. And you continue so now you could put a pebble here. Actually you could put a pebble in the sink but you have to remove all of them. So like this put in the source, put a pebbling. This pebble in the source, put a pebble here. At this point, we have four. And then you can take this out because the pressure has a pebble. You can take this out. You can take this out. Now you pebble the sink. Now you have to take this guy out. So you start doing the work. This, this. Leave that. Then you can take these two out. Well, you have to take this two out. And for this one, you need the source and sign that's So this is, we will count the number of pebbles and intact. There's also a notion of time, you know, because as you've seen, in some places we have put a pebble several times. So you see, actually for line of n-dots, you need log n vertices, log n doubles. That's the difference with black doubling because you only would need two variables. So let's make sure black, the number of pebbles in the first game, and reversible pebbles in the second game. And the good thing about using pebbling is that there's many connections with resolution. There's an excellent survey by Jakob about this. And in particular, the But the closed space is exactly the number of black pebbles that you need, well, that's not hard to see, played on any refutation graph of the fork. And we will show that curiously there's also a connection with three closed space, but with reversible paper. And also we say, okay, somehow you can say, okay, maybe it's an intuition to this and that reversible. Isn't that reversible? You don't take a pedal out, you have to recalculate it in a three-light resolution, maybe something like that, but it's not that clear. It would become more clear with this other game by the called Ron McKenzie again. This is this paper that has been cited here several times. And as Paul said, when it was published, it was not really It was not really appreciated how much new techniques were in this paper. And in this game, this is closer to resolution, the players play also on a directly acyclit graph. Just to play use Pebbler and color, Pebbler chooses, well, it starts by, he has. By he has always to start by choosing the sink and color colour is red. Red we will identify with zero, with false, and color can either red or blue. Color red or blue. And then he chooses some vertex that's not been colored yet, and color has to color red or blue. And the game ends until either. The game ends until either a red source vertex is colored red, or there is a vertex which is colored red and all the spread sensors are colored blue. So you can see that this is close to resolution because this will be a contradiction. Either the initial clause is falsified or some clauses are satisfied but the resolvent Satisfied, but the resolvent is not satisfied, which could not be. So, go by this notation, run McKinsey is a smaller number of bubbles, number of rounds needed for Pebbler to win and to find a computation. And what is also very important is this connection of Chan is that Connection of Chan is that for every single directed acyclic graph, these two gains coincide. So the number of rounds in the Roundmac gain is exactly the number of pebbles that you need in the reversible game on the graph. Here, you can see that in an example, we've seen that you need log n for this. So, how would you put Log n for this. So, how would you play the Rand McKenzie game here? Well, it starts by choosing the same, it has to be red, move, and then, so what would you do? Well, probably divide the graph in two. So, doubler can choose here. Now, color can decide blue or red, doesn't matter. So, here's red. Red means that now we're playing the game in this section. Blue would be like we're trying to find the contradiction. Like we're trying to find the contradiction in this section. So now we're in this section, and yeah, this binary search kind of strategy will bring us to contradiction in log n moves because now whatever does the graph is divided into. In the situation, now it doesn't matter if it's uh color red or blue. In any case, there will be a contradiction. Either second part of the Either second part. So this is these two games are actually actually coincide. Although it's not that trivial. See why. So with this games tool we can now go for the for these results about about the upper bound in and lower bound in the three closed spaces. And lower bound in the three-closed space. And first, that the tree outclosed space is upper bounded by the minimum of the number of bubbles you need on the reversible bubble game on any refutation of the formula. It doesn't have to be a tree. This G is any refutation, it doesn't have to be a tree. So you have. So you have any refutation and imagine the number of pebbles you need to with a reverse metal escape. So since we know that the triclos space is exactly characterized by this first proverb in the game, we try to give a strategy for proverb in this game. So actually, so very simple. Actually, it's it's all very simple. Um it says simulate this the this the strategy of Pebbler. So in the prover delay game was choosing a variable and then what what it does is that it will be a falsifying assignment of an initial clause would be pretty use. So there's this parallelism between the three the The three, the Ras McKenzie game and the true or delay game. So if Pebbler chooses a clause, proof requires the variables in the clause not assigned by the partial assignment yet one by one until either the clause is satisfied or falsified or a variable is given. Or a variable is given a variable star by. If the clause is satisfied or falsified, the improver moves to the next stage. The game continues. If the variable is given start by the layer, then the prover can extend it and with just one, with this extension, we can make the clause satisfied, so it makes takes. Satisfied, so it makes takes for the star, the value would make the literal true, and that would make choosing a coloring and move to the next one. So there's this parallelism between the games, and the game is played after at most k stages. That means the layer can score at most k points, and the only thing to show is that at the end there's an initial clause. Is that at the end there's an initial clause falsified, and when the run machines gain finishes, it's because either a source vertex has been assigned colour zero by color, the situation, and therefore it's falsified, or we have the situation, but since we are working in resolution, this cannot happen because there will be two part clause with our satisfied and then results. are satisfied and the resolvent is which is kind of so we have this inequality is not an exact characterization like in the case of closed space with the tree because can show that the there's there's formulas that have Have for which the minimum number of pebbles you need in the reversible pebble is like closed space times a log n factor. And there's formulas like this. So how this number is between the number of pebbles in the revel game is between the three closed space and the three closed space times login. There's another interesting upper bound using this notation introduced by Sasha, this kind of amortized closed space, in which you consider the closed space and the minimum of every refutation multiplied by the logarithm of the size of the time needed in the refutation. In the refutation. And actually, this upper bound is the three-closed space. And well, there's several proofs of this fact. Maybe the easiest is that the reversible number of pebbles needed on any graph is bounded by. Bounded by the number of black pebbles, times the logarithm of the time needed for that. And yeah, so basically, if we have a configurational refutation of space S. Space S and time T. What we would do is point to the middle of the refutation. Here we have clauses. I mean, you're thinking about the tablet layer game. Ask for the litters here in a way that you need most one query per clause or one star per close, one point per clause. Clause, one point per clause, because if with one bit you can satisfy the clauses. So in this situation, we have that either one clause here is falsified by the assignment, and then you play on the first half of the configuration, configuration proof, or all of them are satisfied, and then you play in the second half. Therefore, you have here this log of the time. Uh log of the time. So this is this is upper bounds on three closed space, but how, still the question, how large can be the gap between closed space and three closed space? And yeah, for this, so you can see that it's not, cannot be more than the logarithm of the time. And by using pebbling formulas, which we also use. Formulas, which we also know, we can get this proven. Actually, it's not the Pebbling formula it says, but lifting with solidification. And for the special case of Pebbling formulas, you see that it's tight. It's tight, this reversible space. So you have a graph G, you consider how many pebbles you need for reversible pebbling of G, and this is perbounded by a trickler space, and this is at most twice the number of pebbles in this room. So it's it actually very good because now every I mean this is for pebbling formulas The trigger space is basically the reversible number of dots. So, and then you can obtain space separation. So, like you have to find, we know that the closed space is the number of black pebbles, the three-closed space is bounded by the reversible number of pebbles, and we can construct a graph family which is a Which is a gap between black pebbling and reversible pebbling. And this funness exists, like for example the paths. So we have black pebbles with the closed spaces one, or order of one, which is constant. So the version of Public Logan. In the thesis of Mark, there's more examples where the space is not constant. And also from this And also from this result I mentioned before, you can see that, oh well, yeah, the difference between black pebbling and reversible pebbling, the best difference known is a login factor. So this graph like this. And the best possible difference is log not in the number of vertices, but on the time, on the time for the pebbling. So if it's a one-time So if it's a one-time pebbling, one-time black pebbling, then this separation would be optimal. If the black pebbling is not what is called one shot, then you can maybe have an improvement here. I mean, very related to this logarithm of the time. Of the time. It's logarithm of the time in the pebble. But we have produced other graphs which are more complicated, which are not pebbled in one shot, but still we didn't get any better than this log in separation, which we believe, as a matter of fact, we conjecture is optimal. So we have formulas so that the clause space is SN and the triggled space is S of N for some slowing or growing functions S. And it's open whether we can do any better than that. For the case of sighting formulas, we can do I mean we can show that this is optimal. I mean, we can show that this is optimal. So, for any connected graph, the three closed space of the siding formula is at most the closed space time log n. And their families, well, asymptotically, this is something. And how the upper bound goes is also similar. We consider a configuration. Well, a configurational refutation, and we define a partial assignment of some of the variables in the formula to be non-splitting if after applying it to the formula, the resulting graph disconnects in a number of components so that there can be only one large odd component. And then we consider. Then we consider the last step in the proof for which there's a partial assignment satisfying these two properties simultaneously satisfies all the clauses at that step and it's non-split and prove that this has to exist always. And at the next step, the only new clause in the configuration must be an axiom. Must be an axiom of the original Seidman formula. And there is a way, so this is a little bit quick now, but there's a way to query the variables at this stage, paying only k points, k with the space, and splitting the graph so that no component is No component is size bigger than n halves. So it's not like here that we have, okay, and then a prover would jump to the small component, which is odd. So there's always a component that's at most enhanced, and it's odd. So we have divided the proof in two, not like here, not twice the length of the proof, but the graph where the proof is being placed being divided in two. In two, and one of the subgraphs has size and most. So, summarizing, these two measures are different measures, but not too far from each other. The best we got is a login factor separation. And there's some open questions to especially to show that if the login factor is optimal or not, and for the site. optimal or not. And for the side informatics we've shown that. So thank you very much. Questions? Do you think there's a game which characterizes tree calculated exactly? No, I don't think so. Yeah, but an easy example would would be It would be like this formula where you have one big clause and then many again clause. And this can be done by the trick proof of sites, I mean like that, the closed space would be constant. Tree closed space also constant, but the number of black pebbles to refute this graph would be local. So you have a different pillar. It's also strange. Also strange that it's almost optimal. So we have space times log n. The best you can get is space times log of the time of the proof. And well, let's. Well, this is not much. It's interesting that for the size case, it's also in exponential log-log n factor. So I don't know how to deal with it, which would be similar. V as star is just depths, right? V a star is just depths. Is there something else? So the last result it actually shows The last result it actually shows that if you have a tree-like proof which uh writes in the configurational form, then you can balance it. Yeah, okay. Is there a direct uh direct proof of this fact without querying? I haven't thought about it, but probably there should be because uh querying for these two pairs, it's it's a bit indirect. Yeah, yeah. Also also interesting that, okay, the closed space is at most the closed space, right? That was the closed space, right? So this gives a relation between closed space and variable closed space. So that closed space is almost upper bounded by amortized variable closed space. Amortized variable space is just this. Yeah, okay. So um so your result seems to show this property layer game of a product uh by also. So you know that there is this uh variation of this game that I was introducing with Olaf and Massimo, this asymmetric Plu-Delayer game, which the delay is not getting the CO1 point, but it's a function there. So did you try to analyze in general this some log L factor can be handled by this game? Did you try that or not? Well the thing is that your game takes care of this asymmetry for for considering For considering space, you know, so if this is a big part of the tree and a smaller part, yeah, the probable will not give us a delay will not give a star here because maybe it's better to go here, but but then this part is not being counted in the in the in the sense. But here, but for space it's it's an exact characterization of 3 space. Exact characterization of three space. So there's not a point in going to the symmetric situation. 