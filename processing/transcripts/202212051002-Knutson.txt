Okay, so for algebraic things, all uh um all i varieties um are going to be complex. People who recognize why that isn't actually necessary and want to go beyond complex can do that themselves. And particularly, I don't, I'm going to be, I'm not mostly in. I don't I'm going to be I'm not mostly going to be thinking about general schemes that's certainly not in this lecture so I'm either going to be having I'm either going to be thinking about the spec of some ring and it'll be in some variables modules of ideal and and you should just think of this as the vanishing set of an ideal so this is those points P and Cn P in Cn such that F of P is zero for all F in the ideal. And that's what you get that, of course, as written, is inside Cn. And there's plenty of varieties we're interested in that aren't inside Cn. So the other ones that we think about will be proj, and you'll have one extra variable now, modulo some ideal i, and this will be a homogeneous ideal. And this would be a homogeneous ideal. So if you just took the vanishing set, then that would live inside Cn plus 1. So what I want to do is take that, remove the zero vector from it, and divide that by scaling. And so then that's going to live inside CN. Cn plus 1, minus 0 divided by scaling, and that's projective space. So actually, that's not quite fair. That would be if I have all these guys of degree one. But I'm actually also going to be interested in what if I have some coordinates in y that are degree to zero. That are of degree zero, and I've got some coordinates that are of degree one. And then I'm going to get something, I'll do the same, I'll get something that will live inside my, so for my vanishing set, it'll live inside Cn cross Cn plus 1, but then I want to remove the 0 from there and divide only that part. And divide only that part by scaling, and what I'll end up with is Cm cross CPN. So that's if I didn't have any ideal at all, and if I do have some ideal that I want to add to be homogeneous, you know, homogeneous in these variables, and these variables are just degree zero, they're not contributing to the degree, then I'll end up with a sub-variety of this space. Of this space. So I can make, there are plenty of interesting spaces that are neither affine nor projective that one's interested in living in here. One thing that's fun about this definition is that every spec is actually now a proj. You can take your same ring, attach one new variable of re one. Variable of degree one, and where this guy is all living in degree zero. And so now we have just a uniform way to think about the alpha and projective in the same way. They're all branches. Okay, so definition: a toric variety is Is an n-dimensional, let's say, normal. This depends on author, but I'm going to say it. Variety with an effective end torus. N-taurus action. So X. So I've got this map from Tn across X to X. That's my action. And it's your usual notion of group action. I want this to be an algebraic fat, effective, that I don't want to just take this guy out of a trivial action. That's too easy. And this is a little shame, but I don't want it to be influenced. You have a dense, you have a dense orbit or a TM. I see. So, okay, so that's true. For many purposes, I don't care that the Taurus is. Care that the torus is only n-dimensional. It'd be okay if the torus were larger than n-dimensional as long as the effect. So it's got a torus action, but I want an effective n-torus action. So maybe this thing is much larger than n, but it should be um the effect the part of act that acting effectively should be n-dimensional. I guess the the question is, is the torus action part of the data or is it? Actually, part of the data? Or is it? Oh, absolutely. Yes. Yeah. A toriced variety. It's not just a toricable variety. Do you want it to be irreducible? Yeah, the word variety for me means that. Yeah. Yeah. So variety, I'm going to insist this and decide that it's irreducible. Okay. And so with a specified torus action. Okay. And so then, definition version one, a toric degeneration. Degeneration of X is a family. Okay, let me leave a, I'm going to put in a bad word here and come back to it. It's a flat family F to S where Where one fiber is hex and another is a torque variety. Okay, so that's pretty easy to arrange if S is two isolated points. So we want that. So let's at least, for example, ask. Asked that this guy is irreducible, so we're not doing that. The word flat people used kind of blindly, and it's a really terrible definition if you want to think about what, you know, if you want some intuition as to what it's supposed to mean. It's something about some tensor product not having higher tors. What are you supposed to do with that? So, let me give you an example of a flat family that fits the definition. Flat family that fits the definition of flatness. Consider the inclusion of C cross into C. If you follow the definition, that's a flat family. If you think that what flat family is supposed to be, because that's apparently how people use the word, if you think what flat is supposed to be is that the fibers are all kind of the same, well, those fibers aren't kind of the same. So this is, I think it kind of weird that, you know, as a sociological question, that this is the objective. Question: That this is the adjective people are stuck with. I think probably because it's a one-syllable word more than anything else. And so let me upgrade to version two that I did. I'll ask this to be a locally free family. So, what free means here is if you think about the coordinate ring of f, and I mean in this sense, as a In a sense, as a module over the coordinate ring of S. And for me, S, I'm happy to assume that S is affine, so it's got a coordinate ring for sure. I'll think about the coordinate ring of F as a module, the coordinate ring of S. I'd like it to be a free module. And locally, yeah, whatever. Let's just make it a free free module. Okay? So I don't want to assume that S is what That S is one-dimensional. I will be interested in taking multi-parameter families. But let me just say: if S were one-dimensional, like F, like what if S were just a spec of C bracket S, okay, so just polynomials in one variable. If S were one-dimensional, then F were not just a family, but were a projective family, so that F lives as a closed sub-scheme of projective space cross S. Space cross s. Then we could ask about f's coordinate rating one degree at a time, and we'd be getting these finitely generated modules over a VID. So that should sound pretty good. Then flattenness turns into, torsion freeness turns into freeness. So really free, you know, most of the time S will be one-dimensional, and in that most of the time, F will be a projective family, not always, but Family, not always, but I'll certainly violate that in a second. But in those cases, then there's definitely no difference between the adjective people use and the adjective that they actually prove anything with. Seems like they agree in the case of two versions of the phrase. So if F is a projective family over a smooth curve, then they agree. Yeah, so a smooth curve means that it's going to be a spec of a PID and a magnitude. The PID. And then you and the projectiveness is where you're getting the finite generated finally generated knowledgeable thing. Okay, so special case. And I thought for a long time that this was the only case worth considering, and I'm now going to admit bashfully that that's not true. But the special case is. But the special case is that the torus action on the special fiber. So one fiber, this is the general fiber, and another, the special fiber. Special case, the torus action on the special fiber. Torres' action on the special fiber extends to an action on F, okay, on F and on S so that the map F to S is equivariable. Okay, so that's kind of an explanation for me of why the special fiber has this big torus action. That what will happen in this situation is that inside S, so we'll have F, we'll have S, inside S there will be this special point I'll denote Omicron, and over that I'll have If it overdoubles, we'll have a bomb across. Okay. That looks like it can see. It does. Oh, well. But it's only half as tall, though. And anyway, so this is our special fiber. Meanwhile, in here, maybe there's, I don't know, one. And here's our general fiber. Here's our general fiber, which was the guy we're starting with. So the idea would be that under this extension, this guy would be a fixed point. And since this is fixed, therefore, if you have T acting on your F, T will act on this fiber over the fixed point, and that will be Y, it's toric. So in this special case, I'm going. In this special case, I'm going to call this a Grubner. When we have this, so I'll say it's a Grubner family when we have this kind of toric degeneration. And of course, because I think of it as closely related to verbatim bases, I'm not going to project meet two projects. Classic project meets to Gropi. Will I still call it Grogner? I will. So, what did you ask? Classic project. If it's not closer project. Thank you. I think I spelled out what the varieties were here. On the contagion of names attached to mathematical objects. So I think a lot of us in this room have dealt with equivariant Euler classes. Why are they called equivariant Euler classes? Well, because they're like Euler classes of vector bundles. What are those? Well, it's like the Euler class of the tangent bundle. Well, it's that. It's the guy that, when you integrate it, you get the Euler characteristic. Integrate it, you get the Euler characteristic. What's that? Well, it's something that Euler defined for the disk. Okay? Now they call it a grain waiver class. So this one I'm going to call Grubner. Which, in fact, I think is due to Grubner's, I think, the whole concept of Grubner bases and so. I think the whole concept of Grubner Bases and such is actually due to Grobner's student, Book Burger, who was kind enough to name it after his advisor. But I'm not going to call them the Germans. But does it believe that Grobner knew what they were? Sure. Sure. Anyway, I'm not going to call them the Bookberger families. So, and again, because it's too many syllables. So, non-example of this. Let's say we're in three variables, but I'm going to be thinking about proj of that and getting CP2. And I'll think about a family of polynomials where I pick some particular polynomial, maybe pretty generically, and I scale it by epsilon. And I'm going to think about the vanish. I'm going to think about the vanishing set of this, and that's going to live inside CP2 cross C. This is with the epsilon coordinate. And then that's a family over that C. And so for general fibers, for general epsilon, what I'm going to get is an elliptic curve. So I'm going to get, so at epsilon general, At epsilon general, I'm going to get somebody who looks like that. And at epsilon equals zero, I'm going to get this union of these three CP1s glued up in a triangle. And so that isn't a toric degeneration because the special fiber isn't a toric variety. It's only semi-tauric. It's a union of. Semi-tauric. It's a union of three Tauric varieties. Now, I'm going to argue in favor of semi-tauric in a second, anyway, but this is not a case where you can get the two torus that acts on this union to act on the total space of your family. So, if you think about taking the two torus, acting on CP2, and taking one of these curves and thinking about where we move. These curves and thinking about where we move under the CP2, the limits it will go to will be like one of these lines with multiples to be three rather than the union of the three lines. I guess that's also because that monomial is in the interior of the new polyps. That's the same issue as well. That's why it can't be a problem. Right, so if you made a different P where this monomial was on the boundary, then you wouldn't get a smooth curve. So the fact is that people care about the. People care about degenerations of this sort very much in the mirror symmetry crowd, thinking about the Gross Siebert program and Gross Hacking Kiel, Gross Hacking Kiel, Kinsevich, and such. And before then, the physicists talking about palabia hypersurfaces inside storage varieties degenerating to what they gave this terrible name, the large complex structure limit, which is this guy. I don't like the idea that complex structures should have numbers associated to them. Structures should have numbers associated to them, could get large, but that's what they call it. And so they care about degenerations of this sort, which again are only semi-Tauric, not Tauric, but they're not of this Rubnir type. It's also a real fascinating one from algebraic statistics. It has the same non-Eterium model. But it's actually an oddest toward variety. Okay, so. In the non-normal sense. Okay, so even that abnormal sense. Yeah. Yeah. So even it's not just the semi-torque, the failure of this to be irreducible that's the issue, then is what I take from that. That even when it's irreducible, you still want to allow for non-Grubner torque degenerations. Okay, so in the Grubner case, we get degenerations. Degenerations, room for a cemetery there. We get degenerations of sub-varieties. So let's say I've got X degenerating to X naught, which is what I was calling F naught before. And And let's say I've got that. So this is that I have F is mapping to S, and T is acting on the entire thing. T acts on F, T acts on S, and it preserves the point on a cron inside S. Okay, what if I have Y some sub-variety of X? And so I've got some torque degeneration of X, and I've got some sub-variety, then what I can do. Sub-variety, then what I can do is consider the orbit through y, take the closure of that inside f, and I end up with it with a family, a subfamily of f, where in my original fiber it's y, and it's so, I get some subfamily, and because I define it by taking a closure in a lot. By taking a closure, it'll automatically be. Let's in the case where S is one-dimensional, it'll automatically be free. So in the Grubner case, when the dimension is one, I need that in order to get this freeness again. So I have y degenerates to. generates to y0, which is defined as I took the subfamily and I took the zero fiber of that guy. So this is not something that there's yep? Is it obvious that the T does nothing to Y in the original? I guess I'm going to need my T small enough to be. Let's see. What do I need? No, it's not obvious. Maybe whatever T should have left on the generator. Yeah, that's right. So the TX effectively on S0. That's right. So what's okay, that's right. So what will happen is that the T, part of T will act on X, right? So there's going to be this There's going to be this part of t that acts on x. So, this is the, maybe I'll call it the stabilizer of this point 1 inside t will act on x. And I want this to be stabilizer inside t of 1 invariant for that to be true. Anyway, the thing I want to do is. Anyway, the thing I want to emphasize, though, about this construction is that even when x degenerates to a toric variety, it'll frequently happen that sub-varieties inside it will degenerate to things that are only torus invariant, but aren't varieties. And so it's very, yeah, but because they're torus invariant inside a toric variety, they have to be a union of some of the torus orbits. So each of those components individually Of those components individually will be a toric sub-variety. It's just that there will be some reducible union of them. Some picture like this. And so, not from this source, but this sort of picture. And as such, I think it's very interesting to consider not just these toric congenerations, but these semi-toric congenerations, where the limiting object is a union of toric varieties. Object is a union of story varieties instead of a single one. That's also, that's a very reasonable question, right? So certainly, I agree, I would only prefer to consider the case where, once this guy has degenerated and become tors invariant, that, so in particular, that the components didn't. So, in particular, that the components didn't end up with multiplicities. So, that's not enough. Really, I'd like that limit to be reduced. Another reason for like this, one of the first examples was due to Hodge where he came up with the initial standard. I'll be talking about it. I'll be talking about it. Okay, yeah, that's yeah. Or where yeah, the minomal student. Okay, so there's a so this is one way I'd like to change the focus of toric degenerations to say that it's also very interesting to consider semi-tauric ones, where the limit, let's say, still is reduced, but what might be reduced. But might be reducible, might have multiple components, like the sort of picture. The other that I'd like is, and comes up in this sort of situation very frequently, is to not require that my special fiber actually be toric, just to say that it might have more torus action than the general fiber did. Maybe not enough to add. Fiber did. Maybe not enough to actually act with an open orbit, but to get me closer to that eventual goal. So now I'm going to pursue a completely different topic from heretofore and give an example of where you get that sort of degeneration where the torus action gets bigger. So separate topic. Venver degenerations. The Winberg degenerations. So R, remember, sorry, X is Praj of some guy R is some graded ring. And I've got some group action on R. And therefore, I've got a group action on X. And this is acting not And this is acting not just by ring automorphisms, but by agree to ring automorphisms. Then I'm going to define a multi-parameter degeneration of R, and therefore a multi-parameter degeneration of X. Multiparameter degeneration at x, and it's going to be completely built out of this extra structure using the group action. So here, g is going to be a complex connected reductive bleed. And if you're coming from the symplectic camp and From the symplectic camp, and are happy with the other words, or tolerating this word, happy with that one, but are suspicious of this one, then we can just say complexification of a compact group. So, um I will very soon be dealing with complex uh um Complex connected Lie groups that are not of this form, but not to do the Vimberg generations. Okay. Ignore that. All right. So you want to make sure it doesn't disconnect after ten minutes. So let me write R. So R, remember, is a is this complex vector space. Complex vector space. And so it's got this, it's a representation of this group G. So I'm going to write R as a direct sum over dominant weights of G, lambda, of I lambda, the isotopic components. Components. So, one way to think about what I'm doing is I take R and I decompose it into irreducibles, and then I take all the irreducibles of a given type and add them back together. And the thing is that, so why didn't I just decompose it into irreducible? So there's a choice there, whereas this thing doesn't have a choice. So once you combine it all back together, that washes out the choice maybe only. That washes out the choice made a moment ago. I mean, dumbest case, G is the trivial group. So I pick a basis, and then that sounds bad, and I put it all back together into just one big thing, R, I0, and I haven't actually made a choice. All right. So R is a ring, so that means it has. R is a ring, so that means it has this map from R tensor R to R. Living inside there, we have I lambda tensor I mu, and that's going to part of R. And I want to say that actually just because this is a G-equivariant map, because I was acting by Radonomorphisms over here. Radonomorphisms over here, I'm going to have a g equal rate map from the ear up V lambda in here and the ERF V mu in there to various earps in here. But you don't get very many of the earths. The lambda and mu constrained it a lot. So we end up inside not this. That would be the best, right? So that's going to be true. I mean, sorry, this would be the best, right? This would be true. Would be the best, right? This would be true if G were abelian. So if G is abelian, then these lambda and mu, these i lambda, i mu, they're just weight spaces. But for g non-abelian, then they have, then each of these has the weight space lambda and u in them and a bunch of other stuff. And so what we get is things of this form. i plus lambda, lambda must mu minus nu, where nu. Minus nu, where nu is a sum of positive roots from the lead group G. So those are the only things that can occur. And this is a tensor product statement. So when you tensor v lambda with v mu, you only end up in the tensor product with your x like that. Okay? So then I'm going to define our R lambda will be the sum of i and lambda minus nu, nu, a sum of positive roots, in order to say that r lambda times r mu ends up inside r lambda plus mu. Yep? Just try to avoid writing behind that whatever that is. I will try, thanks. Oh, I see. Yeah, you're pretty hooked up, Alan. Well, might ask them if they can move there. Yeah, sure. Even the afternoon, yeah? Yeah, because that's emergency kids. All right. Okay. Um how's this line for the future? All right. So um so you're filtering R by a D compiler? By the, not by the, by the, no, by the things that occur as sums of positive roots. So here's the geometry of this. Let's say this is my root system, and let's say these are my positive, these are my positive. Let's say these are my positive roots, then I'm getting things in here. So it's not the positive mile chamber in any sense. But it's being filtered properly by that. But it's still being filtered by a lattice natural to the threat at some point at that lattice. Well, I mean, many of these islands could be zero. Could be zero. But oh no, no, no, no, that's right. I take it back. Lambda is inside the, I misstated, lambda is indeed inside the dominoes. So, as I land or was. That's right. So, this is for something else. Okay, so when you have a filtration, you automatically get associated to it a degeneration to the associated gradient. So let me first say. So let me first say what the associated, let me first define the associated gradient here. So Ger R lambda is defined as R lambda mod. Could say this a few ways. One is the sum. So the new is that's the for the root or new is as stated. New is sums of positive roots. So alright, so let me let me just see what what the picture looks like here. See what the picture looks like here. So if I have so here's my positive roots. So here is my positive bile chamber, so dominant weights. And so here's where I'm seeing just I lambda, but then all But then all of this stuff is what contributes to r lambda. Thank you. So what I want to mod out is the stuff that's less than r lambda in this sum of positive roots sets. So that's going to be the sum of the r lambda minus alphas, where alpha varies over the simple roots. And so now Ger R is the direct sum of the Ger R lambdas, and everything's been set up such that this is a multigraded ring. Ger R lambda Ger R mu lies inside Ger R lambda plus mu. So this might not sound like such an advance. Sound like such an advance, didn't we already have that down here? But the difference was that this was the filtration of R, those guys overlapped, whereas these guys don't overlap, Ger R is the direct subtle thing. So Ger R is now graded by the lattice of weights, or even better, by the monoid of Domino weights. Okay, so the Okay, so the Ries algebra of a multifiltration is we take the we take the sum over these lambdas we put on a we put on the lambda. We put on this exponential guy just to this is this is just a placeholder on a good write out in less than occasion, but I think I like that. Less notification, but I think I'll like this these are land is and suddenly having a critic of faith about decreasing versus increasing. About decreasing versus increasing filtrations. Rather than leading us five minutes into a rabbit hole and realizing that I got that backwards, let me punch that to my second lecture. Okay, so anyway, what I certainly have here is I have R, and on R there is an action in G. There was an action of G, and I've got this Ger R. And we could say, yeah, there's the action of G on Gur R, and that's because everything we did with in this construction was G equivariant. It was based on these isomput components to find each of these of G, the G invariant subspace, what the R lambdas were, and so G acts on these things. But now we also have another group action. Another group action that's coming from the multi-grading. So the point is that having a Z grading on a vector space is the same thing as having a C cross action on a vector space. So if I have a C cross action on a vector space, then I can go from there to B is the direct sum of the weight spaces. And the other direction. And the other direction, if I have V is a direct sum of di's on the integers, then I can say, let's have z act on a vector from the ith component by the ith power. So it's the same data to specify a circle action as to specify a Z grading. What's a little bit interesting is that we've got not just a Got not just a Z grading, but a naturals grading. But anyway, get to that in a second. So we've got not just a Z grading, but a Z to the rank of G grading, because I mean the weight lattice. So what I'm going to get from that is not just a circle action, but an action of the dual to the weight lattice, which is the torus itself. So I'm going to get another action of T. Of t. Now, you might say that t already acts, but the difference is that this t commutes with g, whereas the t that sits inside there doesn't commute with g. It's not central. It's only, it's abelian, but it's not commuting with the rest of G, and this one is. Okay, so this is a recipe where a ring with group action comes in and a ring with a larger group action comes out. With a larger group of action comes out. And you might worry that this has been too brutal a thing to do to the ring. For example, we might start with a ring defining some smooth variety, and when we're done, we end up with something singular. Yes, that's going to be true. You might worry that you might get something so singular that it's reducible now or it's not reduced. It's not reduced, and those aren't true. In fact, if this is defining something reduced and irreducible, which is to say, if this ring is a domain, then this ring will also be a domain. We'll not have zero divisors. So let's do an example of this and then think about breaking this process into two steps. So, an example I particularly like is An example I particularly like is G is SLTC acting on itself. So R is going to be C bracket A C D. So modulo A D minus B C minus K. So this is the coordinate ring of SL2C, and I'm going to be acting by left multiplication. So, I don't want to do all the details of breaking this coordinate ring up under the action of the SL2C. It wouldn't be too bad if I used both copies of SL2C, the one that X on the left, the one that X on the right. And then you have your bio to tell us how to breach this thing up. I will just tell you what this thing degenerates to. So what, so it's quite, this is supposed to degenerate to something. This is supposed to degenerate to something where I let's get so what did I have? I have these things. I can write this out at least in a couple of degrees. So in degree in our at least for a few filtered pieces. So there's going to be C and there's going to be C times one and ABC of D and then there's going to be C There's going to be C, and it'll have things up to the degree two part of things. And the degree two is getting mixed with the degree zero here. Or maybe I shouldn't say degree. The filtered piece coming from the, or the I0 is getting mixed with the I2, is the best thing to say here. So this guy is coming from I2, and this guy is coming from I0. Coming from I zero. And what we do when we mod out the I0 is throw away that term in favor of just this one. And we end up with this simpler ring, AB by Z. And so what this is generated to is determinant zero matrices. So this was determinant one matrices, now they're determined at zero. Determinate zero. And there's supposed to be not just an active SL2 on this thing, which there is, if you left multiply a determinate zero matrix, you get another determinant zero matrix, but also an extra action, which is the scaling action. So if you scale a determinant one matrix, you get something. But if you scale a determinant zero matrix, you get another determinant zero matrix. That's the extra action. That's the action that comes from the gradient structure? Yeah, so the extra action comes. So, the extra action coming from this guy being having the extra grading. So, now we have a, and you can see the extra gradient on the green level. This is homogeneous ideal now. And yeah, and I guess that's at least two-rated as a property. Well, it's got the obvious, yes. I mean, so it's got another circle inside here, and in fact, there's yet another circle from the other. Circle from the other SL2. So, this is in fact a torque for ID as points. Maybe I'll say some more detail about this example and say how you should think about it from the sympathyometric side and integral system side from that sense. So, SL2C looks like, well, is equal to SU2. Is equal to SU2 times matrices like this, where A is an R plus times matrices like this, where Z is the C. Right? And that's a Gramschmiddle. That everybody in here can be uniquely. Everybody in here can be uniquely written as a product like that. So that means that it looks like SU2 cross R3. But I want to say that it looks like S3, that's this guy, the cotangent bundle, that the cotangent bundle to elite group S3 is trivial. And that's how I want to think of this as being like. As being like this cotangent bundle. So, physically, classical mechanically, we'd say this is the phase base of a particle wandering on S3, positioned in momentum. Okay, so what's going on here? If you want to put an integral system on this, well, we have this SO4 acting on S3. On S3. And inside there, we have SO2 cross SO2. So I was thinking of that as I have this SL2C cross SL2C acting on my determinant one matrices. So these are not the same manifolds, and these are not the same group because each of these guys is a complexification of that. Also, not quite true, there's a two to one. Also, not quite true, there's a two-to-one map here, which is if you multiply the left by the negative of the identity, it's the same as multiplying on the right by negative the identity. So once you take this group and you mod out by that minus one, minus one, that's a diagonal part of the diagonals inside there, then you end up with SO4C. So maybe it's not really not to there because you're thinking about SO4R. Okay, so I've got, and then we were saying, yeah, inside here, you could take diagonal matrices in that or diagonal matrix in that. We have two-dimensional action now on this three-dimensional variety. So, how do you get a third commuting function on here? So, where are my third? function on here so where my first two computing functions are coming from is the milbox map um uh square dual there we go um the my first two functions are coming from these momenta from the so4 but i want i want a third one that's going to commute with these and so i could say let's take the Let's take the norm square momentum. That would be a nice third function on this, excuse me, on the S3. Let's just put the T star in there. There we go. Okay. So I've got my third, I've got my on T star S3. I've got my Got my third function, which is the norm square of the velocity. And that is an SO4 invariant function, and that's why it's going to be going to push on Kenya these things that are coming from SO4. So the thing I don't like about this function in particular, though, is that while it does Poisson commute with these two, it doesn't generate a circle action. So if you think about what So if you think about what happens, if you take a position, a momentum, minus three, and you say, let's follow the Hamiltonian flow of this guy, it'll take your particle and say, follow your geodesic. And of course, every particle is going to go around in a circle. So that sounds like it's generated circle action. But the circles are of different lengths. If you have a particle of very tiny velocity, it'll go around very slowly. Around very slowly, and with a big velocity will grow faster, and so they won't end up all back in the same place at the same time. So, the way you fix that is you take the square root of that thing, just the norm, and you end up with R plus. And now, if somebody has a really tiny velocity, you give them a big kick and tell them to keep up with the other ones. Okay. And that will give you a third continuous function. Continuous function on this that what's on commutes with the two ones you have, and so that'll have give you this three torus acting on this thing. Now, taking a square root of something sounds bad when that thing is zero. So, when it's zero, what are we talking about? We have a particle and it's got a position and its momentum is zero. And we tell it follow your GDZ. And we tell it follow your geodesic. And it says, I don't know what my geodesic is. I haven't actually picked the direction to go. So, this third circle action that I'm suggesting one can have that can use these two, it's not defined on the zero set inside the cotangent bundle. It's not defined on the zero section of the cotangent bundle. Away from there, it's a nice third circle action, and there it does not extend continuously because I Extends continuously because I got everything the derivative of a function that didn't extend differentially. So that's all kind of fake what's going on there. This thing is broken at the actual zero section. So what's the corresponding fakery happening here? So these two are not the same variety. They're not isorphous varieties. This one's smooth, that one's singular for one thing. That was singular for one thing. There also isn't actually a map from this one to that one. I mean, of course, there's maps, you know, constant maps or something. But there's not an interesting map from this one to that one. There is, however, a reasonable topological map, a continuous map, this one to that one, that collapses the zero section to the singular point inside here. So this guy is singular. Remember, it's singular at the zero matrix itself. It's singular at the zero matrix itself. And what's happening is there's a continuous map from this to there that takes the zero section, the place where our Hamiltonian action is briefly down, and collapses it to the singular point there. So I don't want to give a general theorem about how those two are supposed to relate. Those two are supposed to relate because I haven't told you what the analog, I will down in two minutes, what the analog of this stuff is on the symplectic side, but also because Magumi and I haven't written this paper just by having thought about it for 25 years and her, it feels like almost as long now. I'm not going to go line at home. There you go. So this was a let's see. Now I think I'm going to leave the symplectic stuff for the next lecture. I want to say a little bit more about the algebra geometric. So this recipe we had are Of R going to GERD R. I actually, so this was a rings of the G-action thing. So again, can you just tell the story of the degeneration of the total space book collaborator? So here, the total space, here, the total space is two by two matrices, and the map is called determinant, and it goes to one by one. Is called determinant and it goes to one by one matrices. Thank you. Yeah. Thank you. So the general fibers SL2C and the special fibers determinants are matrices. Thank you. All right. So what's very lucky in that case is that the total space is smooth. Even though the special fiber isn't smooth. That's rare, that's weird. Don't calibrate. And in general, when you have the more general recipes, just starting with Starting point reaction on R. Is this always have a corresponding point to generate some sort? I mean, it won't be enough to become foreign. It'll only be enough to pick up this extra action. Let's say family. They'll have a family. There will be a family. Getting from R to per R. He planted it to tomorrow. Right. Oh, that's tomorrow. That was the thing where I'm right. That was the thing where I'm a little bit afraid about increasing versus decreasing filtration. Okay, so I want to give you, I want to factor this as a product of two things. So one of them is going to be the functor on vector spaces that takes a G representation to just the highest weight vectors. So here, N inside, so if we're inside. Inside, so if we're inside the example of GLXC, and is this subgroup, okay, not reductive. So if you have a highest weight vector, that's a vector that's killed by all raising operators, which means that it's invariant under the exponential of raising operators. And then this is the group you get when you multiply together the exponentials of raising operators. Together, the exponentials of raising operators. So there's a subring of R, which is what you get by taking just those invariant vectors. And it's totally not obvious that this suffering is no theory. This is the reason that people learn GIT quotients about GIT quotients by reductive groups is that in general, if you have an N action, an action of this group. Action of this yuck group on subring being very subring lows, we know theory. So, luckily, in this case, it is, and I don't have time to explain why there is doubt, but I'll get back to it. So, then there's a then there's a map the other direction which takes our guy S. So, this is only a ring with a T action. It takes our guy. It takes our guy s, multiplies it, enters it, with the functions on g mod n that we also have to talk about. So this guy has a g action on the left and a t action on the right, because t normalizes n. And this guy only had this t action. So I'm going to take that thing and I'm going to take the Going to take the T diagonal invariance inside there. So diagonal for these two T's that are acting. So when I'm done, this ring will have a G action. And it used to have two T actions, but now this diagonal thing is gone. So we'll have only one T action when we're done. And this recipe you can get by starting with R. You can get by starting with R, taking the invariance, and then inflating it back to be a G action in this way, and you'll go on from having a G action to a G cross T action, since this guy is normal inside that T cross T. So we'll think more about each of these steps individually and the fact that this isn't the identity, it's that. And this process isn't quite the identity also, either. Either, but they're both worth thinking about, and very much it's all going down to thinking about this space. Will you tell us what this is geometrically? I will give these. Let me reinterpret the question as, will I explain analogs of this in the symplectic geometry side for people who like that version of things? Okay, you're right. I've totally said it in ring theoretic terms here. Okay, so that's fair. Okay, so that's fair. So, what people would say in the geometry, people would say, here is x mod n. Okay. I mean, you know, what are you going to do with that? If you, you know, you can't take this and do curve one tenth nest to it, because n isn't a reductive group. Right? So, what would this be about? This would be more reasonable because I'm doing a t quotient here. So, here I'd be saying, So, I'd be taking my guy y and multiplying it, that's the analogy of this, with the g mod mod n, and then quotient of that by diagonal. So that's the, these are the geometric letters one writes down to mean that's right. So x x went to there and y goes to there. So if I start with y, so y. If I start with y, so y is a teat space, and this thing is a g cross teeth space. Maybe we have a couple of quick questions before we go to launch. You have to think you can start with the p-half or the t file, where is it right up here? Yeah, very what if he sorry what if he is a torch any favorite no no so the um uh um uh let's see so that that comes back to my statement before that um well okay so what's what's completely stupid there is that there are no positive roots for Taurus and so my R lambdas will be my I lambdas and so the so the And so the associated gradient I won't divide by anything, and my gr will be r. And so, so what will happen is I will end up with this t is a copy of that t and they act the same way, so it's ineffective.