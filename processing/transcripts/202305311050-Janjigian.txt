Thank you, Benedek. Thank you to all the organizers for the opportunity to speak at this wonderful conference. Like so many people here, Timo has been a very important mentor for me for a long time. And so I'm just happy to be able to join everyone to celebrate his work. So happy birthday, Timo, and happy not being chair anymore day. I will be talking today about a couple of joint works with Timo, with Firas, and with Giddas and with Tom Alberts for one of them. Before I get going, let me get started just by giving an outline of what to expect in the talk. So broadly, it's broken up into three sections. The first section is going to be introductory. I know it's mostly an expert audience, but I just like to make sure that we're all on the same page. So I'll talk a little bit about a little bit of the intuition for the KPZ equation, Hopkole solutions, why we talk about stationary distributions, modular adding constants. Distributions, modular additive constants. So, as the title suggests, this is a talk about the structure of stationary distributions of the APZ equation. I'll talk about a couple of the results from these two projects. So, the first one is joint work with Tom Timohan-Firas on the regularity of the solution semi-group for the KPZ equation. And then in the second one, I'll talk a little bit about ergodicity and the synchronization phenomenon. And then the plan is to close off by just talking about some of the tools that we worked with and what some of the main ideas are. With and what some of the main ideas are. Alright, so that's kind of the outline of what to expect. The KPZ equation, as we know, was introduced in the mid-1980s by Cardo, Parisi, and Zhang as a prototypical model of random planar growth, and they introduced it out of an expectation of universality. So kind of the way to read this equation is that there's three parts to it. You have the time evolution of some height function of an interface. The first term is a Laplacian term, which represents some smoothing. Term, which represents some smoothing. We have this lateral growth term, some slope-dependent growth. And then you have roughening by space-time-white noise. So that space-time-white noise is just a random tempered distribution where the covariance structure is in your doctrine. When I showed Timo the slides, the first thing that you noticed is that all of my pictures are wrong. So I will just comment here that with the sign conventions that we're using, our interfaces should actually be decaying rather than growing, but just to kind of match up. Than growing, but just to kind of match up with this intuition of growth processes, I'm going to keep drawing them this way. So, the way to think about it is you start off with some initial height profile, say a line. The height profile is going to tend to grow as time evolves. The white noise is going to roughen it. And because of the interplay between the white noise and this Laplacian, you see these kind of characteristic exponents here that the roughness in space looks like a Brownian motion. So 1/2 minus, and then time you get 0.4. Half minus, and then time get 0.4th minus. That roughness makes it fairly difficult to define direct solutions to the KPZ equation, and so this was a long-open problem for a long time, how to make sense of this nonlinearity. But the KPZ equation has this interesting property that it was actually known how to solve it before it was known what it means to solve the equation. And the reason is because of this connection that we've seen now a couple of times, a few times, various thoughts, including the last one by Li Chung. The last one by Li Chang. That one can start with this nice, well-posed, linear stochastic partial differential equation, which is the stochastic heat equation with multiplicative white noise forcing. This is also called the parabolic Anderson model. And it goes back even to the original paper by Cardo, Creasey, and Jung that one can observe that if you define the log of the stochastic heat equation and then formally take derivatives pretending that the rules of calculus apply, you arrive at the Cardinal Pre-C. You arrive at the Cardiff-Peric-John equation. And so this is called the Hop-Cole definition of solution. This is the familiar Hop-Cole transformation from PDEs introduced in the 1950s. And it's something of a miracle that it turns out that this is actually the right definition of the solution to the equation, even though we're kind of pretending that we're allowed to use calculus. So just as a reminder here, the KPZ equation was originally introduced out of an expectation of universality. And so one way to see that this is really the right definition. And so, one way to see that this is really the right definition is that it's a scaling limit of a bunch of things. So, this goes back to Bertini and Jacomin in 97, who showed that it was a scaling limit of the asymmetric simple exclusion process and weak disorder scaling. Alberts Hanin and Costell showed intermediate disorder scaling of directed polymers converges to the APZ equation. Herr and Costell showed that a class of normalized equations that look something like this also converge. And now there's a Also converge, and now there's a vast literature. But the salient point here is that this definition, where we start with what's called the mild solution, and I'll return back to what that means later, to the stochastic heat equation and take its law defines the physically relevant solution of KPZ. There's also been a lot of work recently on direct solutions of the KPZ equation that I should mention. So we're going to be interested in couplings of all of the solutions. And these other approaches can give couplings of solutions. Approaches can give couplings of solutions as well. So there are these notions of regularity structures, para-control distributions, energy solutions. And the point is, in the case of energy solutions, up to a non-random multiplicative factor, that all of these machines that have been built agree with the Hopf-Cole solution when we're defining what it means to solve KPC. So this is going to be what we focus on. We're going to be studying this stochastic partial differential equation through the stochastic. Equation through the stochastic heat equation and the Hop-Cohl transformation. As I mentioned at the beginning of the talk, the main interest in this is in the structure of stationary distributions. But if you think about it for a minute, the way that I started this story off tells you that something is going wrong because it models a growing interface. Growing things, in particular transient things, don't have stationary distributions because they're blowing up. So there's a very well-known result by Amir Poron. Very well-known result by Amir Poron and Castel in what's called the narrow-wedge initial conditions. I'll come back to that later. That if we just look at the solution at zero, then it is ballistic. And so since it's ballistic, the process is transient, and we need to do something to have a stationary distribution. Really, the thing that has stationary distributions is the spatial derivative of this process. But if we want to work at the level of PPZ, then instead of thinking about its spatial derivative, we can consider the process modulo and additive constant. Modulo and additive constant. So that's the sense in which we're going to be talking about stationary distributions for the equation. And so, in order to understand what that means, all you do is you start with whatever your favorite initial condition is, and then you just mod out the solutions are going to be continuous by this equivalence relation, saying that two functions are the same if they differ by a constant, and consider the evolution. And it'll turn out that this is still a Markov process, still a nice Markov process, even after modding out by the. Even after modding out by this equivalence relation, an equivalent way to think about this that we'll use is if we're considering the process modulo C, we might as well just fix a point and say that it's equal to zero there. And so it's the same to consider increments. We've seen this in a few of the other talks so far in this conference. So what's expected to hold about the structure of stationary distributions for the KPZ equation and for related stochastic partial differential equations? Stochastic partial differential equations of this type. One of the first results in this area, back in that original paper of Bertini and Jacomin, is that one can show that for each lambda in the reals, a Brownian motion with a linear drift is a stationary distribution, modulo and additive constant for the KPZ equation. Somewhat interestingly, a prediction in a sense that Brownian motion should be invariant for KPZ predates from the introduction of the model. So it goes back to. So it goes back to Forster, Nelson, and Stefan back in the 1970s who were considering the process given by its derivative. And so there are some conjectures about the structure of stationary distributions. So it's believed that each one of these stationary distributions, so Brownian motion with a drift, modulo, and additive constant, is an ergodic distribution for the KPZ equation. And that there's a conjecture that these are the only stationary distributions for the KPZ equation. For the ABC equation. So, one might ask: what is the mechanism that causes these things to be ergotic? What's the mechanism that causes them to be unique in some sense? There's a very nice paper by Yuri Bakhtin and Pasitin Kanyin about a wide class of equations that look like PPZ. So we can observe that this is a stochastic Hamilton-Jacobi equation. And there's a conjecture that for a wide class of stochastic Hamilton-Jacobi equations, possibly with less rough noise here. Possibly with less rough noise here, we have what's called the one-force one-solution principle. So the basic idea here is that one expects that this one-parameter family of stationary distributions is actually attractive for the equation. So what does that mean? One can formulate this either forward or backward in time. So typically we think about this in what's called the pullback attractor point of view here. So let's suppose that I start with an initial condition, which is linear plus a sublinear term. Sublinear term. And then I'm going to, at some distant time in the past, put that initial conditioner. So I might start with 0, or instead of starting with 0, I might start with some rough function which has the same slope at infinity and minus infinity as 0. And then we pull this initial condition back in time into the infinite past. And what one expects to happen is that the solution at later times will stabilize to some coupling of the stationary distribution. Of these stationary distributions. So, this property, when it holds, is kind of an attractiveness property that's sometimes called synchronization, synchronization because from different initial conditions, the later solutions of the equation start to look the same, or a one-force one solution principle. One thing that I'll comment on related to Wolfer's talk earlier is that one should be a little bit careful about the sets of full measure on which this holds. Of full measure on which this holds. So the statement here is that there is a value of lambda. So for each value of lambda, there's a full measure set on which this holds. And then when we consider these kind of processes of these coupled Brownian motions, so the multi-type distributions, which we call Boostman processes, then there can be exceptional directions where this fails. So I'll comment here that there's been a lot of work done on this problem and various models related to KPZ. Models related to KPZ. Probably the most relevant is a paper from about 10 years ago by Eric, Hurie, and Prostia on a model that I think Fredung mentioned, where you have a Poisson forcing for a Berger's equation, and then a couple of later papers by Yuri and Yuri and Li Li in related models with Higg forcing. All right, so let me talk a little bit. Having said what's kind of expected to hold here, we have this one current. Of expected to hold here. We have this one-parameter family of stationary distributions. There's this pullback attractor point of view, which should say that these things are ergodic and that they're attractors for a wide class of initial conditions. And I should also mention one other thing. One expects that the dynamics of KPZ conserve slope at infinity and minus infinity, which is kind of consistent with this picture. So let me talk a little bit about how we formulate our results. So if I'm going to talk about stationary distributions, I need to tell you what space I'm Distributions, I need to tell you what space I'm going to work on. And we actually need a coupling of all of the solutions to KPZ, starting from all initial conditions. And so we had to do a little bit of extra work here. So let me come back and talk about the structure of the mild solutions of the KPZ equation. So if we return back to the stochastic heat equation, this is a nice linear SPDE. I'm going to denote the Gaussian kernel by Gaussian kernel by rho of tx. So this is just our normal with variance t. We can think about this equation as being a multiplicative perturbation of the ordinary heat equation. And so this is kind of the point of view that was taken by Walsh back in the 70s and 80s to define kind of classical tools in stochastic analysis. So there's this space that's going to come up a bunch of times. I'm going to call it MHE. This is the space of possibility. This is the space of positive measures with the property that the integral against Gaussian's is finite. And this is a nice Polish space that serves as kind of the basic space of initial conditions for the K-PZ equation. So the state of the art when we started this project in terms of mild solutions were this pair of papers by Chen and DeLong, who showed in 2014 and 2015 that there's a unique solution to That there's a unique solution to the mild formulation of the stochastic heat equation, which is this Duhamel equation, kind of a fixed-point problem that defines a solution to the stochastic heat equation, which is started from some initial condition mu, which is deterministic in the set. And they were able to show that there's a unique solution for each fixed initial condition and each fixed terminal condition. So this is great, and this one should expect is the maximal space on which one can define the solutions. On which one can define the solutions of the stochastic heat equation, for a reason I'll come back to in just a minute. But for our methods, we really needed a coupling of all of the solutions from all of these different initial conditions. And so the question here is, because these things have sets of, have null sets that we need to keep track of, how does one glue them together? And the basic idea is one that Sean mentioned in her talk as well, that because this equation is linear, it's natural to work with the Green's function. Work with the Green's function of the equation. So the basic idea is going to be to study the structure of this Green's function where I take a delta initial condition of y at some initial time s, and then see if we can't glue these together and then also glue together all of the solutions using my Green's function. I'll mention that there's a bunch of related work on existence and uniqueness for mild solutions, but this is kind of the sharpest result. All right, so before I continue, are there any questions there? Were there any questions there? There's space. So you're requiring pretty strong decay. Well, you can't grow. You can't grow faster than... Sorry, not decay. No, no, no. You can't grow faster than that. Yeah. So this is sharp. So I'll show in the next slide that if you're not in this set, you explode in finite time. And the time actually... I'll say it when I get there. So the Z solves this equation? So this Z solves this equation and also the Yeah, so it it solves the stochastic heat equation. This is the fixed point. This is the Duhamel formulation. So you formulate it as kind of a fixed point problem where you think of this as a perturbation. You apply the solution semi-group of the heat equation to find the fixed point. And then you have to do some kind of retard iteration. No, this is a strong solution to the equation. So you do retard iteration on this, and you actually construct a chaos. In some regimes, you can construct a nice chaos expansion. Regimes we can construct nice chaos expansions of the solution from this equation. So, all you do is you plug the equation into the equation, and then that kind of builds the chaos expansion. And so, when you're working in this level of generality, there's actually a fair amount of work that Chen and DeLong need to do. But if you look at kind of the early papers, it's kind of just, you know, you plug it in and you just check that the series that you get converges in L2. Other questions? Other questions? All right. So this idea, of course, is not new. We've seen it a bunch of times to glue things together by the Green's function. And actually, the Green's function had been constructed previously by Alberts, Hanin, and Costell. So just as an aside here, the real contribution of this work isn't to construct the Green's function, it's to analyze the regularity properties of the solution semi-group that you get through the Green's function. And so kind of the key idea. And so, kind of the key idea in this first paper is the following heuristic. So, Li Cheng mentioned that we have this Feynman-Katz interpretation of the partition function or the solution to the stochastic heat equation. And kind of, in a sense, the natural thing to do is to take the solution and divide it by the heat kernel. The reason is because it's the Green's function. It becomes singular as you go down to zero. And the heuristic here is that that singularity should be completely encapsulated in that heat kernel. So, the reason is the following. So, the reason is the following. Formally, if you take the stochastic heat equation solution and you divide it by the heat kernel, then what you have is a Feynman-Katz solution from the initial point sy to a terminal point Tx of this integral of a white noise along the Brownian motion, and that requires some renormalization. Let's not worry about that heuristically. And so, what one would expect is that if t is close to s, then you're not integrating the white noise over very much, and so the integral should be close to zero. So, this whole thing should be close to one. So, this whole thing should be close to one. And so, that kind of tells you that you should expect that the solution here, all of the singularity, is covered by the heat curve. And this turns out to be true. So, you can check just by doing kind of the usual things with Polmogorov Chentsov and estimating these differences of Brownian bridge transition probabilities in L2, that there's a modification of this field with the property: the fours are artifacts of the proof, but the thing that matters. Artifacts of the proof, but the thing that matters here is that uniformly in time, where you allow s to go all the way down to t, there's a constant that only depends on a compact time interval, so that this renormalized things grows at most polynomially and decays at most polynomially. Something slightly because if s equals t, then it's a delta. If s equals this is not a delta, so this is the renormalized thing. That's the renormalized thing. So I've removed the. So the singularity is entirely in the heat kernel. And so this is really the intuition there. Because now you go back and you redefine the solution as the ratio times the heat kernel. And so what you have is that the solution is actually a tiny multiplicative perturbation of the heat kernel. You can also add in a beta here in front of the white noise. And if you do that, it's also nicely regular in beta. And so you can see that this whole field is kind of locally uniformly in time. Locally uniformly in time, not as you increase time, but on compact sets, a small multiplicative perturbation of the heat kernel. And so it is a rough perturbation. So if you're interested in regularity of solutions, you seek holder continuity and not smoothness. But if what you're interested in, like we are, is the large-scale properties of solutions, multiplying by the heat kernel by a function that grows and decays subpolynomially doesn't change anything at infinity. And so the point is, really. And so the point is really the kind of moral of this first paper is that as a solution semigroup, so now I'm thinking about this as a dynamical system, which you can think of as evolving measures or evolving functions, this is a very regular thing because the heat semi-group is very regular. And so really, just to emphasize here, the contribution is not the construction, it's the regularity and the regularity of the semi-group. So what does this say for the KPZ equation? So this gives a coupling of all solutions. So, this gives a coupling of all solutions to the KPZ equation starting from any Borel initial condition through the superposition principle. And we can give fairly sharp characterizations of what happens to solutions. So what I've written here is just the Hophtkohl definition of a solution to KPZ in terms of the solution to the stochastic heat equation. So you take the log of the convolution of the exponential of your solution, exponential because you want it to take logs to get to Hippy Z, times this green space. Times this Green's function for the QPZ equation. And so we've got this original space that I mentioned here, which is a nice Polish space of measures that you're allowed to integrate against all heat kernels. And then there's this space of continuous functions, which represent measures in this set. And this allows us to give a sharp characterization of what happens to solutions to KPC. So if you take your Borel initial condition, and it happens to be the case that the exponential is in this set, then instantaneously. Set, then instantaneously the solution semi-group is in the space of continuous functions which represent measures in the set. So in particular, the stochastic heat equation dynamics preserve this set. And if you're not in this set, then you explode in finite time. And the time of explosion is actually, the critical explosion time is the exact same as for the heat kernel, for the ordinary heat equation. So we have an if and only if condition here. So we have an if and only if condition here, which was important to us because we're trying to be as general as we can in studying the structure of stationary distributions. So we know that if we can study things on this CKPZ space, we haven't missed anything. So one thing that we need to check, of course, is we redefine solutions to the equation. So this is the Hawk-Bull solution whenever e to the f is in this space of measures. One can actually check that this space is separable. And so there's an argument that you can do that this is the unique way to glue together. The unique way to glue together solutions to the easy equation continuously. And then our methods really want us to think about this as a quenched dynamical system. And so the point is, you freeze the white noise. And now this solution semigroup defined by that convolution formula is continuous as a continuous function value process in the space of continuous functions. And I'll also mention that we have this conservation law. So the slope at infinity is preserved by these dynamics. At infinity is preserved by these dynamics if the slope at infinity exists for the original equation. All right, so with this in mind, this kind of tells us what space you want to work on. This space is sharp in the sense that if you start with any initial condition that's not in MP, where the exponential isn't, then you blow up. And if you are, then the solution ends up in this space of continuous solutions. So what can we say about ergodic stationary distributions? We define the equivalence relation for functions that they're Relation for functions that they're equal if they're equal up to a constant. The equivalence classes will be denoted by brackets, the equivalent, the quotient space denoted with the tilde. The previous result you can check pretty easily implies that as a function-valued process in this quotient space, we have a coupling in which the KPZ solution semigroup is continuous. In particular, this coupling implies that this is a Feller process on that space. So the C total KPZ value Feller process. So, the C total KPZ value feller process. And what we can show is the following. So, we can show that these distributions of Brownian motion with drift are ergodic, they're actually totally ergodic. And then we can give some structural results about any ergodic distribution for this process. So either the, so if you have any ergodic distribution, then either that is the distribution of a Brownian motion with drift lambda for some lambda, or there exists some positive lambda. There exists some positive lambda, so that this measure is supported on equivalence classes, which have slopes at infinity. The slopes are finite. The slope at infinity is some positive number, and the slope at minus infinity is the negative of l. And the way to read this really is that there's a lot of structure in stationary distributions. So some non-obvious things here. We prove that stationary distributions have slopes at infinity. We prove that those slopes are finite, so it keeps these. Those slopes are finite, so PPZ does also preserve having superlinear growth. In principle, there might have been something that grew superlinearly or for which the limits didn't exist, but we figured those out. And then there's just this exceptional case for which there are no known examples. So one open question here is, are there ergodic measures of the second type? We've done a lot of work on it, and we haven't resolved that one just yet. So this is kind of a weird thing to see, right? You have a slope at infinity, a slope at minus infinity, and they have to be the negative. And they have to be the negatives of each other. So, where is that coming from? And where it's coming from is a more general version of this synchronization picture that I talked about earlier. So, what we can show is that there's a random countable set with the property that any fixed point is not in the set with probability one. So, that if you're not in this set, and if you take a sublinear initial condition and you start with something that has slope mu at minus infinity and slope eta at infinity. At minus infinity and slope theta at infinity, plus this sublinear thing, then we can describe what happens. I'll comment that this is a heavily simplified version of the theorem. So we have versions of this with delta initial conditions, these neural edge solutions. These need to be time-dependent when you actually apply them. The statement's kind of complicated there. And then some of these can be infinite as well. So really, you should think about it in terms of lensoup and limits. But here's what happens. So let's suppose But here's what happens. So let's suppose that the slope at minus infinity is positive and the slope at positive infinity is negative. Then what you should do is set lambda equals zero and then there is this one force one solution picture and the limit is a fixed Brownian motion with drift zero. So if there's an ordering that's kind of imposed by the dynamics and if you're out of order then you just go to the zero solution. If things are in the right order where the slope at infinity is negative and the slope The slope at infinity is negative and the slope at positive infinity is positive, then what happens is that whichever one has bigger absolute value wins. And so you get what we're going to call a Boostman function, which is a coupled family of Brownian functions. And so this kind of resolves what happens in terms of the synchronization picture. And you can see where this exceptional case is coming from, because there's only one case where we can't say what happens. And that's when the absolute values are equal for the slopes at infinity. For the slopes at infinity minus. So for ASAP, you know, Liggett 75 considered what happens when you have these sort of balance the shock stays at zero. And I think you showed that you get like one half of each of the two different ones. So is that what you expect? I really don't know. So I've been doing really long simulations of this, trying to figure out what happens. And at least in the simulations, it doesn't look like that happens here. But I have to check the But I have to check the curve. I'm not sure. But most likely the answer is yes, and my coding is bad, not the statement is wrong. So I'll keep playing around with that. Yeah, but yeah, it's a very good question. And we did try to go through these Libya arguments as well. And there's kind of some obstacles with translating the specific things that we did. I think, at least that we ran into. So how do we sorry? Sorry, another question. How do we actually say anything about this process? Where do the proofs come from? It's mainly in terms of this thing called the Busman process. And so what this Boostman process is, is this coupled family of stationary objects that Ofrid talked about previously in other models. And so what this is, is a coupled family of things that are marginally Brownian motion with drift. So what we do is construct this candidate process. What we do is construct this candidate process and then do some coupling arguments in order to show that the solutions actually have the synchronization property. So, the key point here is that this is a coupling of continuous functions. For each fixed time, the increments of this process are going to be Brownian motions with drift. They satisfy this co-cycle condition, which is essentially just coming from the fact that we're getting a four-parameter field here because we're modding out by this equivalence relation. And you might as well just keep track of. You might as well just keep track of every point in the plane where you could set the value equal to zero. And the reason why these things are relevant here is that these are eternal solutions of KPZ. So these you can think of as you have a coupled family of these Brownian initial conditions started at time minus infinity, and then they solve the equation for all time going forward from there. All right, so let me just kind of close off here since I've only got a couple minutes. I've only got a couple minutes left, right? Yeah. Okay. So let me close off here with just one connection, another way of thinking about these that's connected to some of the other talks that we've had, which is the following statement. So Li Cheng mentions kind of hydrodynamic limit, which is what we would call a shape theorem for the KPZ equation. And what this is, is a uniform limit for these fundamental solutions of the KPZ equation at a logarithmic scale. And once you've proven what we would call a And once you've proven what we would call a shape theorem here, as a consequence, you get stochastic homogenization of the KDZ equation. And so, what this is, is we have this random Hamilton-Jacobi equation with a separated Hamiltonian. Hamiltonian is p squared over 2 plus a spacetime white noise. One can do the usual scalings that one would do to homogenize this equation. And then check that if, for example, you had a bounded continuous initial condition, then locally, uniformly, this coupling will continue. Uniformly, this coupling will converge to the viscosity solution of an inviscid Berger's equation, where the effective Hamiltonian is p squared over 2 minus 1 over 24. This 1 over 24 is something that pops up pretty ubiquitously in PPZ. To get it, we rely on the Amir Pormal-Postel result that kind of computed the law of large numbers and then some exponential bounds here. But the thing that I wanted to point out is that another interpretation. point out is that another interpretation of these Boosman functions is that if, so the minus signs here are just because we wanted things to be convex. So if you center the Boosman functions by their mean, then what this is is the stochastic process of stationary correctors for the K-PZ equation. And so the next talk is going to talk a little bit about the structure of this stochastic process and some interesting connections, I think, to the structure of instability in the K-PZ equation. All right, so I'll stop. Capacity of watching it. All right, so I'll stop there. Thank you. Any questions? Technical question. So earlier on how this estimates x plus power, y plus 12? It's an artifact of the proof. Basically, so what you do is you do chat. So you do Kolmogorov-Thensov with the With the Brownian-Bridge transition kernels. And if I remember right, the growth rate is actually k squared for the supremum on a space interval. And then there's a point where things are easier if you just squared that. So we just squared it. You could improve it by going down, by being less wasteful in the estimates. But I'm not sure that it's all that sharp either, just from what you've heard. Either, just from what you said. Does your construction of the boost bone process give you any information about regularity with respect to P? Our construction doesn't, but I would like to advertise the next talk. Okay, perfect. Absolutely. Talk about some regularity. What? So P here is. So, key here is the lambda. So, this is the slope. So, we have a couple family of all the slopes, and then the question is: is it regular with respect to lambda? I don't want to steal Evan's thunder. All right, let's thank Chris again. And we will meet two minutes. 