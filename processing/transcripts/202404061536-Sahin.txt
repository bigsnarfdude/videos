Ejecting myself to all this like lively discussion, but I am going to try to be quick. And as Renee, apologies to a few of you, Vineet, Rod, sorry, you can just look at your phone, no worries. He's here. And Omar, I think a few times they heard this talk. So I'm going to talk about here assortment planning, going back to the theme, I guess, of this conference, market exposure and wealth verification. Market exposure and welfare implications. So, this is joint work with Ventalu and Xiao Wei. And most of the work is done by Venta, our postdoctoral student. He's amazing. He's building a set of papers on the fairness issues around rankings and assortment planning. He's already working on another paper that will be present in the summer conference. Present in the summer conferences. So, okay. Let's try this. Yes, you are right. Okay, so what's the motivation of this work? We are going to look at the fairness issues, but when we talk about fairness, most of the time people assume that it is going to be related to the consumer side. In this talk, we are going to focus on fairness on the provider side in the assortment plan. So most of these providers or third-party sellers, they rely on marketplaces to sell their products or services. And you can think about platforms like Walmart, Amazon, etc. Walmart, Amazon, Etsy, or even Brick and Mortar retailers. If you go to Nordstrom or Kroger grocery stores, they also sell goods from providers, vendors, third-party sellers in their stores. And loser connection is also there for Upwork and LinkedIn. If you think about LinkedIn, a lot of Employees, job seekers, rely on the platform to find a job. And what the LinkedIn does when an employee posts a job posting, basically the LinkedIn recruiter tool create an assortment of resumes and share with the employee to hire. So they rely on the platform to be shown, to be exposed to the employee here. The employee here. So, bottom line is: platforms have the control over assortments, recommendations. I will use them exchangeably to be presented to the customers. And traditional, what platforms does, they choose one assortment that maximize their chosen metric. It can be revenue, profit, or market share in standard assortment optimization. And the providers excluded from Providers excluded from this assortment recommendations get minimal market exposure, and this is unfair to the providers that are small, local, or usually new to the market. So, bottom line is this has long-term economic implications for the platform itself, and there's also regulatory pressure. So, I'm going to show you an article from WAX.com from like two. Article from WACS that come from like two more than two years ago. The European Commission filed a lawsuit against Amazon. And this antitrust case was about Amazon not being fair to the third-party seller in the marketplaces. So, and then they agreed, and Amazon pledged to change some business practices, and Amazon agreed to provide. And Amazon agreed to provide third-party retailers with an equal opportunity for being selected as a default option for the platform's buy box. You may be familiar with Amazon's buy box. There is a buy box and if you got that buy box as the preferred seller, then you get most of the sales. So it is a prime spot on the web page. A similar lawsuit was filed in September 2023 in the US by the Federal Trade Commission. Trade Commission, to Amazon. So, this is becoming a bigger deal for a lot of platforms, Walmart and other ARBMBs. They also have set of assortments to offer to the consumers and they are facing this type of regulatory infringement. So, there is that part, but there is also the other side. So, this is another article from the analytics. From the Analytics magazine, and it emphasizes the importance of the long-term business model for these platforms. So when there is an interest promoting market variety and preventing monopolistic domination, P-fairness, this is producer fairness or provider fairness, may also be a factor. And they emphasize that, for example, ETSI, the system may want to guarantee that new entrants to the market receive fair proportion. To the market, receive a fair proportion of recommendations despite having fewer consumers and established motion. And this is sort of justice not required by the regulator's law, but built into the platform's economic model. So there are reasons to focus on the provider fairness, both for the long-term business health perspective and for the regulatory pressures that a lot of platforms are facing. So there are, and this is an So, there are, and this is not, we are not the first ones to think about fairness. There are common notions of fairness in the literature. Pair-wise fairness is a popular major, especially in computer science literature, which compares all pairs and imposes a fairness constraint for everyone in this room. I compare them and then I impose a fairness notion. Maximum fairness is another fairness notion. We propose a simple fairness. We propose a simple fairness notion or a constraint you might uh think about that, that guarantees minimum market exposure for each provider. It is simpler, it is more interpretable, and you can this minimum market exposure constraint can be merit-based, it can depend on the quality, price, performance of the provider, and it's easy to model, implement, and internal. Easy to model, implement, and interpret. That's why we chose so it is easier to analyze than the other fairness notions. And we, in this paper, we ask the following questions. How do fairness considerations change platform's assortment decisions? What are the characteristics of the assortment? And how do the fairness consider impact consumer welfare, provider gains, and the platform? I think this part is the noble aspect. I think this part is the noble aspect of the paper because the simplicity of our fairness definition allows us to extract insights about the assortment and what the implications are for the consumer welfare. We are not the first ones. Almost everyone in this room did some work on fairness. Will, Jackie, I, Omar, where are you? I, Omar, where are you? Yes, Omar, and co-author Omar Maroom. Everyone works on some aspect. But most of these papers are fairness in resource allocation and the indirect experience. What we are going to talk here are the fairness in assortment planning. And there are two papers that are very close to our paper, Negin's paper with her co-authors and Omar et al. Omar at all, especially this paper in terms of the fairness modeling, it's very similar to our way of modeling. So let me tell you, but we, O Mars group, and we started the projects without knowing each other, and then in an EMSOM conference, I think we realized that, okay, we have a very related paper. So, what OMAR is focusing on is a dynamic exposure. Dynamic exposure constraints. So, in a dynamic assortment planning problem, they are making sure that over time each provider is exposed at least X percent of the time. On the other hand, ours is not dynamic, we are looking more of a static setting and we study the welfare replication status. Well fair implications that is our goal in this paper. So, and Negin's paper, their fairness notion is more like a pairwise fairness notion. Our difference in general compared to this papers, we have a tractable fairness notion, we characterize the food structure, and these two allow us to study the valfarium of kitchens. So, to satisfy the fairness constraints, clearly what we can do, we can just like offer the whole product set. So, it's a simple problem. So, if we want to have a fairness constraint, it's easy, let's offer all product set, but clearly this is not the best solution for the platform or consumers or the providers. So, the idea is that we should offer multiple assortments. How do we offer multiple assortments? How do we offer multiple assortments? And the idea is we can offer random assortments. So you can think about this if these are like three different assortments. 50% of the time I can offer this, 25% of the time I can offer this, and 25%. And the implementation in an online platform would be like a switchback experiment. One RIO for the first assortment, half an RIO for the second, half an RISO. RI score for a second, half an RI third stuff. This frequency needs to be longer because you cannot change the assortment that quickly, but the idea is the same. So, we're not thinking of ranking for now. We are not thinking about ranking. So, this is just we are presenting the assortment. No ranking in this work. Ventao is working on the ranking problem with wareness constraints in a separate paper, but I'm not going to talk about it here. So in a randomized assortment setting we offer multiple assortments and each assortment offered at a set frequency. This allows us to satisfy the fairness constraint. We will get better revenue and welfare performance and this is an easy implement easily implementable in brick and motor online setup. So the remaining questions are how many assortments, different assortments that we are going to be randomizing? What will be the frequency Randomizing over what will be the frequency of these assortments, and what are the Delphi Revenue implications. And this is the standard assortment optimization problem that you saw in the last, I think, six hours. So I'm not going to repeat it. So this is the ML model, same thing. So I is the attraction parameter. So this is without the fair expression. The fair assortment constraint, the optimization, we are going to basically add, this is a bit abuse of notation here, this is the fairness constraint. So I'm going to add the frequencies of assortments offered to the consumers that includes product R, and that should be greater than or equal to gamma R. And I am going to basically maximize this expense. D maximizes expected revenue by choosing these frequencies. So, this is our favourite software optimization problem. One can ask me how do you choose these gamma eyes? In this work, we assume they are exigence, but it can be a function that can depend on price, quality, attractance of product, and can be calculated from data. This is one example. This is one example, and it can be chosen based on the fairness appetite of this platform, or it can be androgenized based on long-term economic implications. So gamma i can be chosen such that it makes seller I or provider I indifferent between entering the platform. So one can think of a seller, I'm not going to sell on this marketplace because there is no way they are going to show me. Going to show me. So it is costly for me to enter. So, what is the right exposure level that I can promise to this guy so that they choose to enter my platform and offer the goods to this? So, that can be chosen in that way. Indeed, in the paper, we have an extension that studies that. Let's solve this easiest problem that we can solve. Gamma here is independent of the product. So, for all the Product. So for all the providers, we have the same minimum exposure constraint. And I define AM as the traditional optimal assortment. So without the fairness constraint here. So the optimal solution is it's optimal to over assortment, the efficient assortment in the sense, which is a traditional optimal assortment with probability 1 minus gamma, and the rest of the whole set of products with probability. Whole set of products with probability gamma. And it is like simple and easy to interpret. It says that you have there's an efficiency and fairness trade-off here. I am going to be efficient one minus gum of the time. And to satisfy my constraint, I'm going to offer the whole set the rest of the time. And this is good. It's very simple. How about if we make this more general? Yes. My instinct was to think of this as my offer AM also. I offer EM all the time, and then I randomly select just one additional product. Your instinct is closed, but you're not doing it randomly. So I'm going to show you the structure. But yes, it is going to include AM all the time, because that is the efficient assortment. So if we have this product dependent gamma i, then we can show that this is, there exists an optimal solution where all offered assortments are. Where all offer the assortments are nested. So remember, I choose the assortments that I'm going to be randomizing around. So there exists a set of assortments, and these assortments are nested assortments. And all of our assortments must contain AM, as we expect them to have. So all of them will have this AM as a subset. The question is: the good thing is the optimal solution can be found in OS for type. OS for type and I only need at most total number of products minus the size of the optimal traditional assortment plus. So you don't need too many assortments to randomize around. If you have 10 products and in the traditional assortment you have five, you only need six different assortments to randomize. So it is pretty good. So far it looks So far, it looks going well, but let's see how the solution looks like. So, the solution, we find the solution using this algorithm. So, we index the products that are not contained in the traditional optimum assortment from 1 to kappa in increasing order of the exposure level. And we define And we define this set S kappa to I as the assortment that contains products, optimal assortment that contains products kappa to I and has the highest exposure level. The key here is putting these minimum exposure constraints in an increasing order on a number line and finding the optimal assortments for each interval. So I will find an optimal interval. So I will find an optimal assortment for this interval and then move on and find the optimal assortment for this interval and then continue the process. So the optimal interval assortment for this interval I know and that is the traditional optimal assortment without the fairness constraint. So this is AM, but these others are assortments that include AM and have additional A and have additional products. But they are not random, they are the optimal ones that we need to include. And some consecutive intervals may have the same set of products. So basically, we can find it in OL square iterations, and it is pretty easy and interpretable solution. So the algorithm offers a simple structure. Offers a simple structure that can be adapted to approximate assortment problems with other fairness solutions. I think that is the beauty of this algorithm. I will show you through the end. We will use this type of solution to create heuristics that solve different fairness notions, like pairwise fairness notion or min max pairness notion. And this result holds, we don't need MRL, it holds as Don't need MRL, it holds as long as the following property holds. So, basically, the key property we need for any assortment A, when product J is not included, but the revenue of J is greater than the revenue of the assortment, when I add product J, the total revenue is greater than or equal to the revenue of A. So, as long as this holds, this algorithm is optimal for any choice model. So, the question is: how about So the question is how about a limited number of assortments? If you tell me that I have a brick and mortar store, I cannot randomize over six different assortments, give me only three, then I can add a constraint on the number of assortments that I can randomize now and solve this problem. In this case, the good thing is I only need to consider the assortments that I found without the limit limit. Without the limit limits, I look at the optimal assortments that I randomize around and basically choose the ones that matches my limit. So here's an example. This is a formal proposition for that. I will always use am, but as some subset of these s stars that I found in the previous case in the limited number case. So this is a tree product example. Three product example, and these are our exposure constraints. But my optimal assortment includes only three without the fairness option. With a fairness assortment optimization, I will be randomizing over these three different assortments. But if you tell me you cannot use three different assortments, you can only use two, then I can just look at these and find the optimal. This is the result. This is the result. So, you only need to just consider and evaluate the combinations to find the optimal. So, this is again easily, efficiently solvable. And we also show that how much you are going to lose if you limit the number of assortments you randomize around. So, if L is the assortments that are being randomized and kappa is the number of products that are outside of Number of products that are outside of the optimal traditional assortment, then our revenue performance will be: this is the revenue with the limit, L, this is the revenue without the limit. So this revenue performance is at least L over cup of plus one at this point, this part. So we can also use this for managerial decisions how much additional money we are going to make. And here comes the cardinality constraint. Here comes the cardinality constraint. As always, this problem: if you tell me you cannot show a random number of products each time, you can only show 10 products, then I need to put a cardinality constraint and find my randomize a certain set. This problem is way harder, and we went to develop two different FPTAs actually for this problem. One based on Antoine's 2020. one based on Antoine's twenty twenty two paper and another one based on another methodology. And now he's trying to figure out which one is working better. We also have a heuristic with a performance part but we are now working on improving the performance of the heuristic that we do not. But the bottom line is we can solve these problems. So more interesting part is the welfare implications. Is the welfare implications. Now we examine the welfare implications of imposing the fairness constraint. I think the interesting result is this. When you impose the fairness constraint into your assortment optimization problem, you always improve the consumer surplus. So this is a really good thing. And I'm sure all of you realize why this is happening. Bill knows it. Why do we have Like, why do we have an increase in the consumer surplus all the time? We show more products, right? So, when you randomize, you show more products. So, this is a nice feature. And if you think, oh, like, okay, but it's literally, is this happening for other cases too? So, if you do the fairwise constraints, it's not always true, though. So, that is, I think, that's a good thing. If you use these fairness constraints as a byproduct, all the As a byproduct, although you didn't care about the consumers explicitly, you have an improvement in the consumer surplus. But if you do the pay-wise fairness constraints, you don't get that nice benefit all the time. So that's a good thing, because this may lead to almost parallel improvement in certain situations for the sellers, platform, and the consumers. So typically, like when people think about these fairness constraints, right? Like let's say if I'm thinking of a recommendation setting, one of the challenges, like if you think of like content platforms, for example, one of the challenges is that I may be providing recommendations that are not as relevant because I'm imposing some sort of a fairness constraint. So from that standpoint, So from that standpoint, there could be a trade-off between the customer cost and fairness training. Correct. Right, so but I guess it's not showing up here because here I guess more choice is always better or people do the V exactly for instance. Exactly. So that's the beauty. So when you do this like the payer wise comparison, this is exactly what's happening. Just to be fair to the provider, you are so focused on the You are so focused on that you are hurting, you may, not always, but you may hurt the consumer because you are providing unrelated product. One can also think about like putting these things in the objective function, right? Like, why don't I maximize the provider's utility, my benefit from it, etc. In that case, also, you always, most of the time, you will end up offering irrelevant products because you think that I. Irrelevant products because you think that I am going to be getting benefits from it, like if you sell ads, sponsored search, those kind of questions. Yeah, this is not true if you have cardinality. Yeah, exactly. Yes, this is only for time conference. Yes. Because you optimal assessments only prove this stuff. This may still be not always true. Sometimes it may be true, but not always. Yeah. So total profit decreases. Total profit is, and it is intuitive, right? So we have a constraint, it goes up. Now, overall welfare with fairness constraint improves sometimes. This is a numerical example that shows that. Not always. So overall welfare includes platform plus seller plus the consumer. So I can improve it, answer certain cases, and under certain cases will go down. Will go down. So if you look at this one, we improved the overall welfare, but these yellow ones we reduced overall welfare. But when we improved overall welfare, this is an R opportunity, right? To create a scale everyone benefits. So we characterize when we improve overall welfare. So when all products share the same markup, total welfare increases. Total welfare increases, welfare response rates are imposed. And from the previous one, you can see that from the previous example, we improve the overall welfare when the price of the products are lower compared to the willingness to pay of the consumers. So we know that consumer surplus always goes up. If the price of the goods, If the price of the goods are lower compared to the willingness to pay, the value that consumers put on the products, and the consumer surplus always, that increase is huge. You are improving the consumer welfare a lot in those cases, while the reduction in the total profit is small because prices are small. I am not making that much money, anyways. So the welfare gain most often comes from the consumers. So for consumers gain a lot, Consumers gain a lot, I lose a little. So, using this intuition, we show the following. When total welfare increases, there exists a sequence of Y such that consumer surplus, seller profit, and the platform profit all increase. So, I am going to create a system to transfer part of the consumer surplus to the other parties in the system. In the system. So, this is an illustration with an example how this is going to be happening. So, without a fairness constraint, I make as a platform owner this much money. And seller one is the only seller that I show in my assortment. Seller two and three, I don't show them, so they make zero. And consumer surplus in this case is this much. So, if I include the fairness, So, if I include the fairness constraints, which are basically have this minimum exposure level, then I am going to be offering one, product one is 70% of the time, Paul said 30% of the time. My own platform revenue goes down, seller one's revenue goes down, seller two and three they gain, and also the consumer surplus almost Consumer surplus almost doubles. So consumers gain a lot, sellers, and I start showing also gain. Now, by charging price premium to the products 2 and 3 prices, and it's like a very little premium will gain a lot for us. So the prices are 9.8 and 9.6. I charge 0.4 additional on top of it. The platform may Top of it. The platform makes more. Still, seller one loses compared to the previous case. Seller two and three still makes more. Consumer surplus still close to double. And then by redistributing this additional 0.1 that I gained back to the seller, everyone and the platform, sellers, and the consumers are better off. So it's 14.8% of 14.8% of consumer surplus basically brings us this. So there is a mechanism to create parental improvements in the system. So I'm going to skip this part and talk about this one. So in practice, you may prefer other fairness measures. So what we study right now, we numerically study how a heuristic using our solution Solution performs for these alternative measures. And we study the output, the structure of the assortment. We also show that instead of the minimum exposure, if you include a minimum market share constraint, we can solve that problem efficiently. We are in the process of understanding whether as simple as this, like Nesta solution also performs well in that case. Also, it performs well in that case. And our approach serves again as for these two cases. So these are the performance of our heuristic for the traditional fairness notions. And here's the conclusion. We propose a fairness notion that is tractable. It has a very insightful source notion. And most importantly, we had the Belfare analysis and showed that. Analysis and show that there can be minimum situations. And my final slide is about what we are doing right now. We are working on extending it to, we are almost done with the market share and the revenue guarantees. So how teams will work under these conditions. Quality of exposure with cardinality constraints, as you alluded. Some of these results will not hold, but Hold, but we are working on it. And we are also working on formal comparison of the fairness notion, meaning the assortment structure under different fairness notions, how they perform in different situations. Have you thought about inventory? So, like, if you have inventory that will change, like, if you stock out of a product, we haven't. We haven't thinked about it. So, what is the question exactly? So, when we stock. What is the question exactly? So when we stock out in one so like if you added an uh like um like if you stock out a pro like um that will affect the so if you had like um a fluid constraint on inventory could you still could you still uh characterize the optimal solution we haven't talked about the inventory part at all but we should yeah yeah yeah thanks 