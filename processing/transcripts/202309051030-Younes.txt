So I'll try to speed as much as I can in the next 30 hours. So just tell me if I'm going too fast. So I want to talk about shape spaces. This is an introduction saying that you want to consider shapes. You want to consider shapes that's relevant in biology. This is part of, I mean, this is important to understand many processes, it's important in medicine. And what I'm going to focus here is not just how to deal with shapes, but it's more like trying to build. Trying to build a comprehensive space that would include shapes or the shapes we would be interested in. So it's a construction of shaped spaces. And there is a large history in this regard, but most shapespaces that are built in practice obey the following steps. Steps. First, you build the space based on a model. And so you have your, I'm calling that M, sometimes called the template. And this is the model shape. And that makes the construction much easier to have a model. And then you are allowed to transform this model into something else, another shape. Something else, another shape, using a space that I'm calling D, which is a space of transformations of M. So it's DM because it may depend on M. And there is, so when you have a transformation that you assume that is acting on M, put it pi, it creates a shape. And the shape space is called S. That's the general framework. I'll give an example later. But then Later, but then the minimum thing that we want to do is to equip the shape space with a metric. And this approach typically starts with a metric on the top space, a space above, that is the M, and project it with some mechanism onto a metric on the shape space. That's a general principle. And then at the end, you have to go. You have to cushion out every invariance that you want to get rid of, and that requires having enough isometries in the space DM so that all this process goes well. Okay, let me just give you an example which is probably the shape space but that is used the most in practice. This is candle shapespace, and so you have to start with a model. Space and so you have to start with a model space, and for panel space, it's very simple. It's just a set of M, capital N, sorry, first integers. And then there are indices, labels. And then the space above, the top space, in that construction is just the space of labeled landmarks, which are, which means one. Landmarks, which means one-to-one mapping from this set of indices to RD. And then there's no difference between this and the shape space Sm, so the pi is just the identity. And we put on dl2 metric. And then there is a half part of the construction which is quotiented out. So everything is prepared so that you can quotient out the Euclidean. out the Euclidean displacement and scaling. This is what kernel the shape space does, and that gives you the space, the shape space of interest, and that is well studied and cases. If you wanted to have unlabeled benchmarks, that's the next level of complexity in the example, instead of having Sn, I mean the pi transformation be the identity, Transformation be the identity, you transform a set. So you transform this labeled landmarks into the set default. So you forget they are labeled. And that gives you unlabeled. Okay, second example is when you want to extend this approach to smooth structures like curves and circles. Structures like curves and surfaces. And in that case, you don't start with one to the set of first n integers, but you start with a model space which is some sub-manifold that you fix. And then you look at, so dimension, say one or two, whether you want to deal with curves and surfaces. And then you look at the space of immersions or embeddings into Rd and the image of your original. Your original manifold with such immersions or embeddings from your shapes. And then you have to define a distance or metric on the M. You usually use a Riemannian metric and you want it to be at least pre-parameterization invariant and preferably have more invariant so that we can also deal with rotational scale. So that's a A second approach for shade spaces. The one I will focus on in this talk is this third approach in which you it's called an extrinsic metric. It's following a terminology introduced, I think, by Michael McFord. I don't know if Martin was part of the authorship of this, the one telling that his name. But now he But now here you take a subset of R D, but you take the generator, the space of transformation, to be the space of diffomorphisms of R D and your shape space is the space of all diffeomorphic transformation of your model space M. And so that that gives you a sudden, I think we can see oh, the one But if you L subm. And now you need a slightly different type of invariance. You have to be invariant to the action, the right action, of the stabilizer of the space x, which is a set of diffomorphisms that leave capital M in bare. That's the minimum requirement that you need on the media. Okay, alternatively, Okay, alternatively, instead of dealing with sets and transforming sets, you can transform embeddings. This is slightly easier to manipulate. And the approach is exactly the same. I won't go through it in detail, but the only difference is that instead of taking the image of set by diffeomorphism, you just compose on the left diffeomorphism. On the left, diffeomorphism with embedded. And you get a new shape space with the same requirements. The stabilizer of an embedding is smaller than the stabilizer of the set it embeds, but that's, you know, and I will go back to this in a second. Okay, so I just want to give credit to a lot of works that have A lot of work that have been working with this approach. The two names I want to emphasize is that all this is a formulation inspired by Greenander's pattern theory. And of course, in biology, this This in biology, this is also a mathematical formulation of dacetamps and models on form and shapes. Okay, let me there are a lot of other methods that use shapes and that represent shapes and that I'm not talking about. If this is your method, your This is your in spirit on this slide. But I'm going to move to the next one. Okay, well, what are maybe the critics and advantages of this method? All this method, the many shapespace actually, that are built, or approaches that are built to study shapes, are purely geometry. I only talk about group action sets, embeddings. There's no biology there, there's no physics. And this is in some sense good because that means that it's non-committal and this is generic. And this is also good because, well, if there's no biology and no physics, we can do whatever we want to define this matrix and make sure that we get all the nice mathematical properties that we would like to have with this matrix. Have with these metrics and work with them. Of course, this is not bad. I mean, if what we compare is our, say, two brains, which is what I'm doing most of the time, from two different pairs of persons, there is no elastic transformation, there is no biological transformation that transforms one brain into another. One brain to another. Now, if you look at evolutions, if you compare the brain of one person to the brain of the same person after a few years, then you want to take into account whatever is going to happen. Probably not elastic transformation, but some biological event that may lead to atrophy if there is some neurological disease, or some other transformation that could be, for example, growth if it's It's about an animal or some going up. And so here, if you deal with this kind of data, then being purely geometric is probably a limitation. So I'll try in the time I have to at least account a little bit, give one example of how you can deal with those issues. But for this, I have to introduce some mathematical notation. Some mathematical notations. I'm going back to the general presentation that I gave about space and deforms, shapes and deforms, and just give you now some notation. So I'm going to describe the model based on embeddings. But actually, well, I'm going to choose this at the same time. So if you have an embedded Model shape, so the model shape, I would consider it as an embedding, then we will consider the diffeomorphic transformation of these embeddings. I'm going to have a notation, I don't know how quite a current use that was. So there's a notation for s set of CP embeddings. Of CP embeddings. Usually the embedding is formed based on a parameterization space that could be very often it's a unit sphere, it could be surfaces that come from anatomy. And of course, the shapes are the embeddings, modular reparametrization of the set I. So modulo the right action of diffeomorphisms of I. And And so I'm going to call the equivalence class by the name of an embedding between brackets. So there is a difference between the little n, which is a generic embedding, and the capital N, which is the template that is fixed. And the diffeomorphism, if for example notation I'm going to call the set of diffomorphism diff with a P if I want. with a p if I want to think about C P diff zero if I want them to go to the identity of infinity. Okay, so now if I have a diffomorphism and a shape, if the shape is, I can define the action of the diffromorphism on that shape, if the shape is an embedding, the action is, as I said before, just given by the composition on Just given by the composition on the left of the sampling and by the diffomorphism, if it's an equivalence class, is just the equivalence class of the transformation. So we have our action, and so this results in two types of shape spaces, one which Types of shape spaces, one which is the shape space formed by the deformorphic transformation of a fixed embedding, capital M, and one is the deformorphic transformation of this embedding up to reparametrization. The one we are interested in is the one which is up to reparametrization, the one which is easier to manipulate is the one without reparametrization. So once you have that, So, once you have that, you build a metric on the set of diffeomorphism, which is dm, which is invariant with respect to the stabilizer of M. And you get a metric by this formula you think about. You just define the metric between Define the metric between two embeddings as the minimum at the transformation that is at minimum distance from the identity and that takes one embedding to the other. And capital M has disappeared from the construction, but it's somewhere including the fact that the shape space is the space of shapes all built from Kenny. From that, from capital. Okay, so let me let me get to the computational formulation. For this, I will need to consider time-dependent diffomorphisms. I will need to consider this Eulerian velocity associated with this time-dependent diffeomorphism, which is defined by this expression, but it's easier to. By this expression, but it's easier to think of it as something that generates diffomorphism using this ODE, this flow, the diffomorphism is a flow associated with the time-dependent velocity. We want to have invariance with respect to the stabilizer of the template. We are, at least in that first example, we will have full invariance. First example, we would have full invariance, full rate invariance by the diffomorphism group, and that means that you want to build a general metric, a Rivarian metric that only depends on the Linarian velocity. So what we will see, I need to define this metric, and so I need to use a Hilbert norm on velocities, and that the Hilbert space I'm going to call it. So because it's on velocity, it's a Hilbert space. Because it's on velocity, it's on Hilton space on vector fields. When I have that, I have all the ingredients to define an action functional on time-dependent velocities, and that's just the integral of the norm squared of the velocity for the Hilbert space that we consider. And implicitly, I have a diffomorphism associated with it, or time diffor. Associated with it, or time-dependent deformism associated with it, obtained by solving the flow equation associated with the velocity. And so we can define, let me go there, we can define the geodesic distance on morphisms by minimizing this action function all, subject to the fact that its flow maps. Its flow maps a diffomorphism, the initial diffomorphism to the final one, the two different that you want to compare. You can then go down to the same type of approach on shape spaces, except that you mean the same expression, but now the evolution equation looks like that. That and this is this is comparing 0 with M1 and you minimize the action functional subject to the constraint that the diffomorphism maps transforms M zero into some shape. Some shape, some embedding that is equivalent to a one. So, this is the problem we have to solve compute distances on shape spaces. We've never solved it exactly. We solve it using something that we call a chordal distance at piece and approximation. I won't have time to discuss this, but what we end up is problem that is an optimal transport, can be think of as an optimal transport problem. Think of it as an optimal transport problem, V being the optimal control problem, V being the control with an end cluster provided by a penalty term, and that gives the NDA algorithm. Okay, so once again, this space is very nice because I Because by designing everything, in particular the norm on the Hilbert space V, we can make sure that all the nice properties we want from geodesics are satisfied. And so this is one good thing that when we want to extend the approach to growth, we want to keep. So, how can we keep that? Let me give you. How can we cook that? Keep that. Let me give you one example, which is trying to incorporate elastic properties. And so just a remark that could actually have the metric depend on the transform shape or transform. Or transform embedding and keep the nice properties it had. And so, what we have is instead of defining the elastic energy or the kinetic energy by the norm V squared, we add one correction term that we can design based on physical or biological properties. And the first term will take care of First term will take care of maintaining all the nice properties that we had before. The second term will make the transformation more realistic. So we can do that, for example, by using we are dealing with the formation of 3D volumes using an elasticity formulation. And if we And if we make a first order expansion of the STCP tensor, we end up, let me go directly to the result, we end up with an elastic metric. So this is the correction term added to the previous metric. An elastic metric that takes this form and every epsilon. form and then epsilon is the usual dv transpose plus dv over two and we define a metric that has to be a quadratic form of this axiom so it depends on the derivative and that corresponds to a linearized elasticity model and oh it's quite different again and and you you be here And and you you B here is just a quadratic form on on um uh semi-definite uh on symmetric matrices. It has twenty-one free parameters and you usually want to make this simpler using some invariants. And one example is this model that can be used in the variant. If you want to have rules in the model, To have growth in the model, if you want to have growth in the model, then you can use the same point of view which was taking elasticity, making a first order expansion, getting some energy, and defining a correction term for a norm for pinetic energy. And You can base the approach based using what is typically introduced in what is called Mark Forelasticity, which is a gross standard that is supposed to exist and that partially explains the transformation, the Jacobian transformation of the shape change, the derivative of the deformation. So you apply your elastic energy or elastic cost only on the part of the transformation that is not the gross tensor and the gross tensor comes from something else. And so you get an elastic energy that instead of looking at the residual of dφ dphi transpose minus d identity, looks at The identity looks at A A transpose minus the identity, or A transpose A minus A identity. Okay, and so if you do once again the first order expansion and apply the same approach as before, we end up with a formulation that is now linearized and we have the linear version of the growth tensor which is called d of g and which now defines Which now define an energy that depends on the velocity of the transformation and the bulk sensor. And that so we extend the previous approach by considering now a transformation that is an evolution that is controlled by two things: the growth tensor and whatever is needed. The gross tensor and whatever is needed to complete it to form the velocity vector. And so we can define, let me just show this thing, we can define, based on this approach, an optimal gross tensor um sorry an an optimal velocity given a gross tensor that defines the norm of the gross tensor and we can define Of the correlation turn, we can define an optimal control problem associated with choosing the corona. And so I just want to mention that you can study this optimal control problem. And because it inherits using this hybrid approach, the nice property that we had from Property that we had from the start on shape spaces. This optimal control problem is well behaved. You can probably skip the partition there here, but you can prove that if you have an optimal control problem that optimizes growth and then get the optimal velocity coming from the morphoelastic term, you get something that is well defined. And I can skip directly to my these are the hypothesis and I These are the hypotheses and I uh I again skip to uh what is my conclusion slide, which is that you can do more, you can try to design the growth standard to make it fit more interpretable transformation like atrophy in disease or rules in brain development. And so you build an evolution equation. An evolution equation for the pro sensor. You have two equations now, the velocity is the pro sensor, you have to deal with it free form. Free boundary PDEs to solve. We can do that of some examples. We tried and got some results. But this would be for another talk. Thank you. We have two minutes. We have two minutes for questions. Well, I mean, Martin comes next. Yeah, yeah, yeah. We have 20 minutes left. Yeah? The elastic 3D model, I wasn't sure to understand what was the shape that you're looking at. So these are like 2D manifolds underneath. So no, in that case, that was, I mean, you you that was just a model for volume. So you have a full volume. You should have a full body. So it was a 3D model. So it was on a vector field? Yeah, so elastic models are on displacement fields, the derivative of displacement fields. When we switch to this Riemannian approach, we take a further expansion of this and we get models on vector fields. So we get something that depends on vector fields, and using the elasticity that depends on this. That we got on this tensor epsilon. This built from dv dv transpose where v is a vector field. Is there any assumption for the number of components that URC has? It's implied by the template and the approach fixes the topology. So it's it's So it's not able, we're working on that, but it's not able for the moment to deal with changes of topology. I suspect that either Martin or Nicola will mention changes of topology because they worked on that, but if they didn't, they just refer to them because they worked on that. One more question. To add to that, is there any way to use it without using a template? It's always there in the construction, at least in these constructions. Other than that, I mean, for example, if you were to use a small transport, you can argue, and I could say there's no template at some point because the template disappears from the formulation, but there's always a fixed topology here. For example, you can use, if you think about optimal transport and the distance associated with the optimal transform. And the distance as a situation is not possible. What you're doing is what you're calling, we're calling, I mean, too bad, I mean, they're going to cut me, but I think we have five minutes. We are calling that a corner of distance, because to use a Timor transport you have to embed your data in a space of probability distributions. And then you define a distinct distance that is nice on the space of probability distributions. Of probability distribution. So you essentially have a bigger space because, of course, not, I mean, your data of interest is not all the probability distribution that you can think of. So you embed your data in a bigger space, and in that space, you take a distance. It's what we call a polar distance. We have different versions of corn distance. But optimal transpose, we have heard about it this morning, is one example. But I can't think about something that is really this change. Is really this shape space construction without embedding the shape space in the bigger space that you in your construction you have the growth tensor, that that means that you mostly represent monotonic shape changes in some sense? And how would you think of doing it if we wanted to represent something that is cyclic? That is cyclic. So I have examples of data where we want to press something that is very eye and comes back. So, how much of the construction depends on the I don't think any of the construction assumes that the growth status is monotonic and we don't think about cyclic things because we think about atrophy or growth as a one-way transformation, but the corsets are. But the cross-stressor could be at this level of generality, of course, the whole complexity is to model the cross-stress that this equation generates, but at this level of generality could be easy. Thank you, Paul. Thank you very much.