To be here. This is my first post-pandemic in-person conference. So, this work will be all of it joint with various people, including Felipe Perez, Jean-Jang, Neil Epstein, and Janet Vasilev. So, the purpose of this talk is to give you a toolbox that's currently pretty useful for studying things in Nix characteristic. Most of the results aren't especially beholden to one. Aren't especially beholden to one characteristic. So the motivation is that a lot of the tools used to study singularities have the same structure. And studying that structure gives us just a lot of options for what to do. So, there's two main types of structure that I'm going to talk about today. So, first is a closure operation. So, a closure operation is a map that takes a pair of R modules to another R module. So we're going to take L is going to be contained in M, and we're going to use the map CL to send it to another R module, L sub M to the C L, such that So first, L should be a very good thing. So first, L should be contained in its closure, which is still contained in our ambient module. And this can very much depend on the ambient module. This is called the extensive property. Second, if we apply it twice, it's the same as applying it once, so the closure is closed. Call this item potence. And third, if we have two submodules of M and L is contained in N, then the closure of L should be contained in the closure of N. So this is called being order preserving on submodules. Being order-preserving on sub-modules. So, where does this come up? Everywhere. Here are some closure operations that come up in studying singularities. So, we've got tight closure. Hoxter-Hunicke 90 is a paper of theirs that talks about tight closure. There are many. Frobenius closure plus closure. You could have a closure coming from a big Cohen-Macaulay module or algebra. I'll talk more about what that looks like in a second. Jeff Beetz talked about these a lot and me. We've got So, same idea, but you could get a closure from a family of big Cohen-Macaulay modules. We talk about this in my paper with Felipe Perez. Two more, so you can. So, you could do something where instead of a big Cohen-Macaulay algebra, you use an almost big Cohen-Macaulay algebra. In particular, Ma and Schweed have talked about this. Or things like EPF closure, full extended plus closure. I've made this incredibly long list to make a point. Incredibly long list to make a point. If you're not familiar with all of them, you will still understand the talk. Okay, so let me talk about module closures, because in some sense, that's the central structure that most closure operations are kind of like module closures. So B can be any R module, not necessarily finitely generated. Module not necessarily finitely generated. The module closure and we'll denote this C L sub B, where B is the module. And this is given by the 2008. So, what happens here is we say an element in the closure of L and M, it's not quite an M, but after we tensor with B, it will end up in the image of L. So, for every little B and B, B tensor X is in the image of this map, tensor products. Of this map, tensor products are happening over the ring. So, this is nice because all of these closures are either module closures or close to being them. So, I'm going to use a star to denote module closures, which are sometimes tight closure for benefits closure. Plus closure is a module closure. You use R plus. These are module closures and And yeah, all of the others are variants on module closures. We're changing this structure slightly to get a different version. So, for example, the way we usually think about tight closure, we have some multipliers. It's not enough to be in the image after tensoring. You have to be multiplied in by certain things. Or if we're working with a family, it's clearly a modification of this. EPF closure, we're adding something to the image. We're adding something to the image, and it's okay not to be in the image of B tensor L, but B tensor L plus a little bit more. So, things that we can prove about module closures, we can often prove about most of these. Solid closure is a module closure. Yeah, I'm not going to talk about it as much today, but well, it's a family. I think it has to be a family. I don't think in most cases you can use a single modular algebra for it. Okay, so the other structure that I want to talk about is test ideals, and I'm going to give a particular version of them. So, I'm going to talk primarily about the sometimes called big test ideal here. There's a finatistic version two. And this is given by we use tau for test ideal, copying tight closure notation. So, this is the intersection over all pairs of our modules L contained in M of everything. Of everything that multiplies the closure of L and M back into L. This is, of course, all inspired by the tight closure test ideal, in this case, the big one. So how does this come up? Well, obviously the tight closure test ideal. If you're curious to know more about that, Schwiden. You're curious to know more about that. Schweed and Tucker have a fantastic survey on this, which is pretty readable. And there's all these versions of tests and multiplier ideals and mixed characteristic. So Mon Schwid have written quite a lot about this. Takumi Murayama has some nice stuff out too. And I'm sure other people. And I'm sure other people. So, these are the two main structures. And the principle of what I'm going to tell you next is: a lot of things that we've proved for a specific closure operation and its test ideal, we didn't really need most of the structure to prove it. They really hold for most closure operations. So, for a starting example, So, this is the motivating example that for tight closure, another way to view it is you take. Another way to view it is you take the injective hull of the residue field in a complete local ring, you look at what annihilates the closure of zero. So, this is the annihilator in R of the tight closure of zero and the injective hull of K. But we don't need most of tight closure structure to get this kind of result. So, we need only the following. So we say that a closure operation is functorial if for any R module map the map is F. The map is F. It goes from M to N, and L is some submodule of M. We have the following. If we take the closure of L and M and then apply our map to it, this is contained in what we get if instead we apply F and then take the closure in N. So compatible with R module maps, mild hypothesis, think all of those satisfy it and many more. And second, And second, we say that a closure operation is residual if for any surjection, say from M to M mod L. There's a bunch of different equivalent ways to phrase this, but let's go with this one. We want the closure of L and M. We want the closure of L and M. So L is what we're modding out by. We want the closure of L and M to be equal to what we get if we take the closure of zero in M mod L and then pull it back up to M. Should I read that bit again? So the idea here is we can work modulo submodules. If your closure is functorial and residual, you can say, kill a minimal prime. Kill a minimal prime, and now you're in a domain. So that's quite nice. Okay, so that result that we said was true for tight closure. That we said was true for tight closure, those hypotheses are all we need to have that be true. So, this you can find this in either my paper with Felipe Perez or various papers with Neil Epstein and Janet Vasilev and myself. Sure, this one. So, do we need complete? We definitely need local. I think we might need complete. So, we have a closure operation that is residual and functorial. So, CL is any residual functorial closure. If Cl is any residual functorial closure operation, then its test ideal is the annihilator in R of the closure of zero in injective hull of the residue field. So there's also a version of this for finatistic test ideals, if that's something you're interested in. So originally, a lot of these proofs came from tight closure and really seem like they might. Really seem like they might rely heavily on specifics of tight closure. And tight closure is great, but it turns out a lot of the proofs really don't rely on that. And picking out which ones do can really help. If we have exactly a module closure, we get a much nicer result. So we're going to need one more definition to state this. So, I'm going to define the trace ideal, which is something that comes up in a much more representation theoretic context. Heidi Lindo's written quite a lot about them. So, this is the trace of B and R is the sum over all maps from B to R. Maps from B to R. We just apply them to B. So if we look at all maps from B to R, just take their images in R is what we're looking at. If our module is finitely generated, you can often compute this in Macaulay too. It's an easier to get a hold of object. So here's a theorem. So if B is an R module And R is a complete local ring. Then the test ideal coming from the B closure is actually the trace ideal. So instead of like mysterious, some infinite intersection. Like mysterious, some infinite intersection, don't know what it is. Actually, quite easy to get a handle on. Even better, if B is solid, basically, if there is a map from B to R that's non-zero, then this directly implies that the test ideal is non-zero. So, where does this apply? Well, one nice case is if we're working over a complete local domain, Big Cohen-Macaulay modules are solid. So, if we're in this setting where we have a So, if we're in this setting where we have a trace ideal, this is actually quite doable to compute in Macaulay too. So, I have actually had a bunch of students doing this for a semester, and they got some fun results. But I want to go into, if we're working from a single module, we have this nice characterization. What if our closure is instead coming from a family of modules or algebras? What can we do there? So, this was if, for example, you're looking at a closure coming from all big Cohen-Macaulay algebras, this would be the kind of tool you would want. So let B be a set, and it does need to be a set. So, sometimes you have to do interesting things with isomorphism classes or restrict the size or something to get one. To get one. So we can define a test ideal for the set. And the test ideal is going to be just intersect the test ideals for every module in the set. Maybe not that surprising. You want it to be a test aid. If something is in here, it's sort of a test element. Is in here, it's sort of a test element for every module closure coming from the family. Okay, so the question is: does this correspond to a closure operation? Is does this correspond to a closure operation? Sometimes. So, for example, the elements of fancy B are actually algebras and they form a directed set then we define Then we defined a closure operation for the family. We can just sort of take the sum as one way to view it, or just if there's some module in the family for which you are in the closure with respect to that module, then you're in the closure with respect to. Then you're in the closure with respect to the family. So we do have examples of closures like this that pop up, like solid closure or look at all of the big Cohen-Macaulay algebras. If you have modules, there's another condition you can use that will get you this as well. And defining this closure is compatible with the test ideal I defined there. So, if we look at the test ideal coming from this closure, that is equal to the family test ideal that I defined over here. So, as a result of this, in combination with the result that I stated up here. So, if R is complete local, then this intersection test ideal. Ideal is actually the intersection over all modules in the family of these trace modules. So if you're working with the family, you can still turn something into trace, which is just much easier to compute. And my students did, and I'm going to show you an example. Yeah, of course. What do we mean by a directed set of all of that? Ah, so if we have any two. Ah, so if we have any two, like we have B and B prime, they map to some third one in this family. In this case, algebra maps. Because we want one to be mapping to one. No, they don't have to be unique. Yeah. There just has to be one. And the reason is just so that we don't want this to sort of get big without control. We want it to be the case. We want it to be the case that we can compare the closures coming from two different modules by mapping to another one and looking at the images there. If your set, you can have a directed finite set. I mean, here. Oh, I see, I see. Okay, so yeah. And then I'll shake it out. Yeah. So we're all. Always some functorial residuals have to have a direct bit. So, if you're looking at modular algebra closures, those are always functorial and residual. And moving to a set of them, even if it's not directed, you're still fine with that. And that's because tensor is right exact, more or less. I don't know if that explanation is, that might be too few words to be helpful, but yes, it's something that can be written down in a few lines. Okay, so here's an example. One thing you might want to look at is if your ring has finitely many finitely generated Cohen-Macaulay modules, maybe you want to look at the intersection over those. And Felipe and I computed this, but my students actually computed it better. They found a much shorter way. So this is Julian Benali, Shernal Potagoni, and myself. So if R is the Whitney umbrella, And I think I need to exclude characteristics two, three, and five, or something like this. But let's just say characteristic K is zero, just for the sake of making sure I'm correct. Let B be the set of finitely generated maximal Cohen-Macaulay. Maximal, Cohen-Macaulay R modules. Sorry, indecomposable up to isomorphism. So then this test ideal is x squared z. So pretty possible to write this down. If you look at the paper. Down. If you look at the paper my students have, it's on the archive and in Involved, they did a bunch of computations for rings with finite Cohen-Macaulay type. Okay. Sorry, they did finite and countable. You're right. But I'm about to state the result about finite Cohen-Macaulay type. So suppose So suppose that R is Kohn-Macaulay local and has finite cohen-Macaulay type. And let B be same thing as up here. So it's the finitely generated maximal Cohn-Macaulay modules that are indecomposable. If R is not regular, Then the radical of the test ideal from this family is the maximal ideal. So I present this here as an example of this kind of result turning things into trace. When we worked with this particular family, that's well understood. You can get both concrete examples computed and some general results about what happens for a class of rings. Results about what happens for class springs. So, Rebecca, this example, this ideal is smaller than the conductor in this case, it looks like. So, that's just the trace ideal from R to the normalization? So, this is they computed the trace ideals for all of the smaller the normalization. But that's cool. Yeah, it apparently is, and I don't know if. Yeah, it apparently is, and I don't know if I can think more about that right the second, but happy to later. This case? Here? Yeah, what is, I mean, it's, I mean, it looks like modulo x squared y to the first c squared. Ah, there's a plus sign in between. x squared y plus z squared. Okay, okay. Oh, x squared times y. x squared times y plus z squared. Yeah, sorry, that's. Y plus z squared. Yeah, sorry, that's a little small. Yeah, um, maybe this is stupid. Why did you explain the characteristics that you said? You didn't write it down, you said it. Because the results that tell us what the finitely generated Cohen-Macaulay modules are, I think restrict away from those characteristics. Okay, so if you look at the, there's a book by Graham Luskie and Roger Wiegend, and it's from there, and they exclude two, three, and five for a lot of their results. Exclude two, three, and five for a lot of their results. Okay, great, thanks. Yeah. Thinking about what you said, Carl, I think it, and if you're finite Cohen-Macaulay type, you will contain the conductor. I think you have to have infinitely many things to cause problems with that. Problems with that. Yeah. So I want to go to a direction of a different type of closure now. So a lot of mixed characteristic closures that have been discussed have a sort of multiplier. So it's not quite a module closure. You have to multiply by elements of small order. So I'm going to give a particular example. I don't know that this particular closure is that useful, but it gives you a sample for the kind of result. But it gives you a sample for the kind of result you can get with things like this. Okay, so for here I'm going to need a lot of setup. So no, but because I didn't tell you the other part of this result, which is if the modules are finitely generated, the ring doesn't have to be complete. Generated, the ring doesn't have to be complete. So, yeah, it doesn't follow from what I wrote on the board, but it does follow. So, if R is a mixed characteristic complete local domain, and then T is a e torsion-free algebra, and pi is an element of t such that t contains Contains a compatible system of pth power roots of pi. All this is set up to get me the multipliers that I want. So now I'm going to define a closure. So, assume that T is an almost big Coin-Macaulay algebra with respect to the system of pth power roots of pi, the definition here is instead of Instead of all system of parameters or regular sequence, you get some weird multipliers related to the pi's. I'm not going to go into it because this isn't the definition isn't quite the point, but define our closure operation by the closure of L and M is the set of X and M such that Such that now we look at pi to the one over p to the n tensor x is in the image of t tensor l to t tensor m for all n greater than zero. So instead of all elements of a module, I just care about these p to the one over, sorry, pi to the one over p to the n's. So in the setting above, we don't get quite that the test ideal is the trace ideal, but we do get something similar. So, this is kind of like the trace ideal. We're looking at all the maps from T to R, but instead of looking at their images, But instead of looking at their images on all of t, we're looking at the image on pi to the one over p to the n times t for all n. So if you've seen a bunch of versions of the tight closure test ideal, this is quite similar to that kind of result. We look at maps from r to the one over p to the e to r, for example, and those images. So the point of this, especially if that was too technical, the point of this is the kind of proof that we used to prove that for module closures, To prove that for module closures, the test ideal as a trace ideal works pretty well here, too. You can apply it to all kinds of things as a technique, even if you change what the closure is like. And we get a cool thing when we apply this to EPF closure. So this is with Zhang Zhang.  So, when we apply this to EPF closure, which is again a variant on a module closure, if we look at the full test ideal, the test ideal is actually zero. The finitistic test ideal is not zero, but the big one is zero. And again, proved by similar method to most of the results here. Yeah, EPF closure comes from Ray Heitman's work. So I believe the definition is we look at the set of X in M such that I want to say one tensor X is in the image of the image of R plus tensor L plus P to the n R plus tensor M to R plus tensor M. Is this right? R plus tensor L plus P to the N R plus tensor the ambient module mapping to R plus tensor M. We need to have a almost different. There's an almost, yeah. Ah, okay. Thank you. And this is. I don't remember off the top of my head, I would have to look that up. Head, I would have to look that up. I have this question parasites results. Yeah, it's irregular. Yeah, so what this is saying in some sense is this closure is a little bit too big, so the test ideal ends up being too small. And it's really just adding this P to the NR plus makes it a little bit too big, but the finatistic one is not zero, so it's not like that much too big in a very vague sense. In a very vague sense. I think one thing that people talk a lot about with test ideals is you want it to be non-zero mostly so that it can distinguish between rings. And this doesn't quite. Yeah, so I don't think I have to find it. Let's find room. So for general closure operation, the finitistic test ideal is the intersection over. Is the intersection over all L contained in M, where M is finitely generated of everything that multiplies the closure of L into L. And I was going to say the financing EPF test ideal is non-zero. Non-zero. And you can see that in Ma, Schwed, Tucker, well, many of the people in this room in this paper, it's a consequence of one of the proofs in there that the finatistic EPF test ideal is non-zero. Okay. So the next thing I want to talk about, I've talked about two different variations on closure operations, but the next thing I want to do is talk about a different kind of test ideal. So if we want to study F-rationality, we don't really study the test ideal of the ring, we study something different. Study something different. So, here's first a definition. So, let Rm be a local ring. R is F rational if for every ideal I generated by a system of parameters. Parameters. I's tight closure is equal to I. So this is sort of the motivating definition for like what a rational thing. This is for characteristic P. But of course, we can define this for any closure moral of my talk. So, but there's one thing that's quite So, but there's one thing that's quite useful about this. And honestly, I'm not sure where this result comes from. I've seen a reference to it in Epstein-Schwed, but I haven't really seen a proof written down. So if RM is cohen-macauli with canonical module module. Omega, then R is F rational if and only if the annihilator in omega of the tight closure of zero in the top local cohomology module of the ring with respect to the maximal ideal is actually all of omega. Oh, great, thank you. Okay. So we can do this for more general closure operations too. So I'm going to define one more thing so that I can talk about this. So an interior operation, this is going to be sort of the dual to a closure operation. Not sort of very much, it is. So this is a map sent. So, this is a map sending an R module M. So, notice I'm not acting on a pair right now. I could be, but I'm not. So we're sending each R module to a different module. And we'll denote that the interior of M or into M such that first, the interior should be contained in M. Second, Second, it should, the interior is already, I guess, open, so applying it twice doesn't change anything. And third, if n is contained in m, then the interior of n is contained in the interior of m. So this is very much, these correspond to the three things we require for a closure operation. Ah, whoops. I didn't write it very well. It should say contained in M. Thank you. So the interior is contained in the original module. So there's a very particular way in which closures and interiors are dual. Let me tell you what that is. And this comes from my paper with Neil. I think published in 2021. Okay, so let Cl be a functorial residual And we want it to be defined specifically on MATLAB dualizable modules over a complete local ring. So, I have to be complete local for this definition, but it turns out to be useful beyond this setting anyway. So, if you take, so this is, if we take hom over R of HOM over R of M into the injective hole of the residue field, and then again it's isomorphic to the original module. Okay, so and I'm going to denote m check is going to be um r of m into erk. So we define a dual operation by so we have a closure operation, and we're going to define CL dual. And we're going to define CL dual. And here's how it's going to act on a module: it's going to be a horrific mess. So we take the dual of M, we mod out by the closure of zero in that dual, and we take the whole thing and take the MATLABs dual again. If this doesn't make sense, you don't need it to understand the rest, but I figured I should put it up. And what's nice about this is, in some sense, this duality is capturing the duality between a closure operator. Capturing the duality between a closure operation and its test ideal. Let me show you what I mean by that. Okay, um Sure, let's cite this as my work with Neil Epstein and Janet Vasilov. So, with R and C L as above, if we take the dual, so this is an interior operation, it's the dual of C L, we apply it to R, and we're going to get We're going to get the annihilator in R of the closure of zero in the injective hull of K. And this should be notable because this is which is the test ideal. So this is a complete local result, but what we're saying is we have in general a dual interior operation to our closure, but specifically the interior of the ring. Basically, the interior of the ring is the test ideal. This generalizes something that Neil Epstein and Carl Schwed wrote about for tight closure. And again, it's not just for tight closure, it works for quite a few closure operations. In fact, I've stated that I require residual, but you don't, there's a more general version in our most recent paper on the archive, which doesn't really need that. So now that we've said, oh, but this. Now that we've said, oh, but this duality isn't just the closure and the test ideal, I can say something about how this relates to f-rationality. And this is with Shang Zhang. We've just started looking at this. So if, in addition, R is Cohen Macaulay with canonical module. Omega, then if we look at the dual operation and instead of applying it to R, we apply it to omega. We get the annihilator in omega of the closure of zero in the top local cohomology module. So, where is it? Compare this to what I just wrote. By compare, I mean they're the same. By compare, I mean they're the same. So f-rationality is still using the dual of the closure. It's just applying the dual to the canonical module instead of to the ring. And I said we have this equivalence for tight closure, that it's the same to have this be all of omega, which is the biggest it can be, as to have ideals be tightly closed if they're generated by a system of parameters. By a system of parameters. And we can say that for any closure operation, really. So or any functorial residual one. So, I've just written down the same thing ahead for take closure. So, if, on top of everything else we've been assuming, CF. Everything else we've been assuming. Cl is functorial and residual. R has a canonical module and is Cohen-Macaulay. Then the interior of omega is equal to omega, where it's the dual interior to the original closure, if and only if for all ideals generated by a system of parameters, i closure is equal to i. So it's the same thing as we had for tight closure, but really this works for just most closure operations that come up in this setting. Yeah, so to summarize what I've been talking about, there's all these closure operations that come up when studying mixed characteristic, but also in commutative algebra in general. A lot of the things that we've proved for like a particular closure operation really hold for most of the ones that we work with. So if you're working with something and you need to modify your closure operation, these results can come in handy because you probably don't have to prove everything from scratch. You can use a lot of these results. Scratch. You can use a lot of these results to say, oh, this is like a module closure in this way. So I already have a whole bunch of properties that are going to be true, even if it's not quite the same closure I was working with before. And there's this duality between a closure operation and its test ideal described this way. But that duality is really more general. It's a general duality between a closure and an interior. And we can apply that to settings where we want to compute, for example, Where we want to compute, for example, the interior of the canonical module instead. So I think probably a good time to stop. Thank you. Questions? Yeah. So this is this is all the rows for say zero for R and Omega. So what happens if you plug in another one? So you don't have like anything. You won't get this. You'll get. You won't get this. You'll get different things. You can still write it as some kind of annihilator, but what it is looks different. I don't know if I've thought about it that much for most things, but for ideals, if you're looking at the interior of an ideal, which omega is often an ideal, we've written down a pretty good characterization of what that looks like. If you look at, there's two of my papers with Neil and with Janet have this. I can point out the specific titles later if you want, but if we're looking at Want. But if we're looking at the interior of ideals, we've written down quite concretely what it is, especially if your ring's approximately Gorenstein, it's really nice. Oh, yeah. The question was, if we're not looking at the interior of R, if we're looking at the interior of something else, is it still like this annihilator or is it something else? And we've written that down for interiors of ideals. But it seems to me that what you get this anipulator of the module, they have zero, and then you get the the math 2 of the module. Yeah, no, that's exactly what's happening here. And you could state this more generally with, you know, R or E or omega and top local cohomology replaced with a modulance matless dual. Yep. Yes. How does this test IPL compare with the one up? Dest take the ultimate pair with the one of mine. This one? Yeah. To be honest, I haven't spent a lot of time studying it. I would be happy to look into that. I think we were using it more as a proof of concept for how these proofs work, so we haven't explored it further yet. Yeah. T is not technology sort of anyway. Yeah. So you replace T with the. So if you replace T with this like big form equality algebra in which every element has a compatible system of T power with that, which I think that would just be one. So the one Lynch one that I wrote down is in a regular ring with respect to an ideal, right? I mean, because we're trying to do something about symbolic powers, which to go to really generalize. But so that's sort of it's a somewhat different set. But so that's sort of it's a somewhat different setup. Yeah, so I think maybe the thing to read from here is less this particular closure as our proof technique works on closures that are kind of like this. Yeah, right. Is there any parallel between interiors and core? Yes, we've got a paper about it up on the archive with me and Neil and Janet. So you core was originally defined for integral closure. So you look at all of the reductions. So, you look at all of the reductions, so things that have the same integral closure as your ideal, but are contained in it. If you flip and do an interior operation, you look at all the things with the same interior that contain your ideal, and you get, we're calling it a hull. But yes, we have a paper on how that duality works. Thank you. So let's take Rebecca one more time.