Welcome back. Hello, everyone. Welcome back. So, our next speaker will be Dr. Matias Anela from the University of Pavia. He's going to talk about uncertainty quantification for kinetic equations of emergent phenomena. Thank you very much. The floor is yours. Thank you. So, So, thank you for the nice invitation. I'm really sorry to not be in presence. I will try to do my best to fill this gap. So, today we speak about some recent results on sort of quantification for kinetic equation. It has been obtained with a series on a series of work with myself and collaborators and friends. So, let's start. So let's start. Oops. I don't like this, but okay. So let's start speaking about what is consulting multiplication for PDEs, and then we go to kinetic equations. So generally, we want to tackle Generally, if we want to tackle, if we want to merge, let's say, PDEs with data, we have some statistics about uncertain inputs, and then we have our PDE model. And then from this PDE model, we obtain an uncertain solution of the PD. And then we have to post-process the solution of this PDE to gain some statistics about uncertain inputs, outputs of interest from which we can make some decision, of course. Some decision, of course. We assisted in recent years to high interest on UQ for PDEs. This is due to some factors like the availability of data, the increased development of high-performance computing, and the possibility to construct new algorithms. Generally, as I said before, we have the possibility through a certain modification. Through a certain quantification, to observe the behavior of some quantities of interest. Then we, in particular, we focus on kinetic equations. Sorry for that. Let's try to do it with Okay. That's the starting point. So let's now investigate the uncertainty quantification for kinetic equation. We start with some starting box. Equation. We start with a starter Boltzmann type equations. So we have some distribution function f that depends on space, velocity, and time. So we have a transport part and then a collision part here. Epsilon is the Knudsen number. And we collect all the source of uncertainty inside a random vector that is here called Z and it can be a general dimension d of Z. The point. Okay, the point is that through this talk, we will assume that the distribution of this random vector is known. And we call it P of Z. This information will give us the opportunity to construct a new algorithm. So in the case of Boltzmann collision operator, the start Boltzmann collision operator reads as follows. So we have the So we have the gain part minus the loss part, and then the collision between particles is weighted by an interaction kernel that is here B. So the pairwise interaction in terms of the velocity, so the post-interaction velocity is raised as follows. And the interaction kernel B has the form that is given here. So it has the form of It has a form of, it depends on the relative velocity between two interacting particles, V and V star, and to the power alpha. So if alpha is equal to zero, we have the classical Maxwellian case, whereas if alpha is equal to one, the R-sphere case, it is equal to two, super R-sphere and so on and so forth. So it is pretty classical. But now we are an additional factor is the uncertainty. So how we tackle the presence of this uncertainty that does not evolve in Uncertainty that does not evolve in time in our setting. So there are several methods. So, for example, stochastic alerting methods, multi-fidelity methods, and then we pass to the SNC stochastic alerting methods. Let's start with classical stochastic alerting. We have some developments on this method in the realm of kinetic equation. I mentioned the works of Shijin and collaborators. So, the point is that with stochastic galaxy, we gain spectral. Stochastic Galerkin, we gain spectral accuracy, but generally it suffers from the course of dimensionality. Furthermore, if we apply directly stochastic galerking to our, to a PD solver, let's say, so the point is that the main physical properties of the solution is lost. Like, for example, the positivity, or if we look to an asymptotic preserving framework, the parabolicity of the limit. Of the limiting equation. So the hydrodynamic system generally is not more hyperbolic in the stochastic gathering framework. The second part is multi-fidelity methods. These methods are based on Monte Carlo sorbers and are pretty efficient, especially in the case of high-dimensional random vectors. Last, Last is the DSMC stochastic directing methods. That I mean, I will focus mainly on these methods. They combine the efficiency of standard DSMC techniques for the Boltzmann equation, like the one of Nambu or Khobovsky, but they couple this DSMC technique with a stochastic alerting in a stochastic alerting sector. So the point is that we gain the So the point is that we gain the spectral accuracy with respect to the uncertainty, but we gain also the conservation of the main physical properties, like for example the positivity and the hyperbolicity of the limiting equations. Okay, let's try to figure out how we construct these methods. So let us consider first. So let us consider first the deterministic case. I just want to recap a bit the SNC methods. The point is that, for example, in the variable sphere case, so B, the deterministic case does not depend on Z, so let's stick to this simplified setting. So we denote by Q of sigma the collision operator with a modified kernel, where we consider B of sigma, that is the minimum between the interaction curve. Minimum between the interaction kernel and a threshold that is geared capital C. So for a fixed sigma, we may consider the homogeneous problem where the main difficulties take part. It is as follows. So we have a new gain operator, it is P, and the loss part is mu multiplied by F. The gain operator P is as the Is as the following form. So it is very classical. It is a Q sigma plus plus mu, a new operator that is given here that takes into account the introduced three shoulder sigma. Now, if we take into account a discretization of the time interval 0, T max, and we said that T equal to T max. equal to T max over NT. So we may apply, for example, a forward Euler scheme, and then we recognize that for each time step, the update in the distribution function is a convex combination between the pre-interaction velocities and the post-interaction ones. And the post-interaction velocities are evaluated through this new gain and gain operator. Okay, so since it is a convex combination, we are the guarantee that. Combination: We are the guarantee that f at time n plus one is again a probability density, provided that mu density is less than one. Okay. Okay, with a classical DSMC scheme, we have to apply some acceptance rejection method, but I want to spend, I don't want to spend too much time on this. It is very classical, and then we the point is that we have to compute some damage or Compute some dummy collision corresponding to the kernel sigma capital sigma. Okay, this is very classic. I point the interested some if you are interested, just look to the to the papers of Nambo and Bobowski, for example. So now the point is that we want to reformulate this DSNC method in the case of the uncertain case. So the interaction kernel. Kernel embed the presence of some uncertainty. So, for example, we don't know whether our interacting gaze, the interacting gas is a Maxwellian type or aerospheric type and so on. So, for example, the interaction kernel depends on Z. Now, we may reformulate the acetyl rejection collision process, taking into account the possibility that the particles interact or not. interact or not. So we introduce an indicator function in the collision process. So two particles interact, i and j interact if this condition is met. And then if they interact, indeed, I mean they modify their velocity according to the classical Newtonian exchange of velocity. Okay so that's just a comment So that's just a compact form to indicate the acceptance rejection process. There is no stochastic adequate method here. Now the idea is to apply generalized polynomial expansion to our velocities. So we approximate each particle, the velocity of each particle in terms of a generalized polynomial calcul expansion so that each velocity is projected in a polynomial. Projected in a polynomial space that depends on the distribution of the uncertainty, so that phi is a set of orthogonal polynomials. And they're also orthonormal with respect to the probability density function p of z, so that if we consider this integral here, it is a Kronecker delta. And the V hat, now it is indeed the projection of the velocity inside the Of the velocity inside the polynomial space. Okay, so V het is the integral of the velocity multiplied by the polynomial of order m. So that may be recast as follows. So it is the expected value of the velocity multiplied by the polynomial that depends on only on Z now. So we have the possibility to reformulate our DSMC method, taking into account the stochastic. Taking into account the stochastic alerting algorithm that we will define as follows. So two particles interact. It means that at the level of their polynomial expansion, we have this set of collisions that takes place in the polynomial space. Now, so the projection of the velocity of the particle i projection of order. Projection of order M is as follows. So we have the projection itself at the pre-collision below at the precollision level. And then we have two additional terms here that are indeed the interaction matrices that has the following form. So capital W is the integral of the indicator function multiplied by multiplied by V i m minus V J m. So we have the polynomial calcul approximation of the velocity i and j. And then v i j m is the matrix that depends on the particle ij and the expansion level of order m, the indicator function multiplied by the distance in terms of the velocity multiplied by Multiplied by m. Okay, so the above quantities can be computed for each condition, for each pair of interacting particles, and sigma. So in all, we have a computational cost that is of the order m squared. If we use, for example, a Gaussian quadratural. So we have a scheme at the level of the particles. So how we go back to the distribution function. So, the distribution function f is given here in the space of space homogeneous setting, and then we will look at the space space inhomogeneous one later on. So, f is approximated given a set of particles of n particles as follows. So it is one over n, the summation of the Dirac deltas centered in Vi. But now we have no more of this quantity here, it's a stochastic formulation. Stochastic Alerking formulation, we have VIM, so it is the stochastic alerting approximation of the velocity of the particle I. So that if we may, for example, compute the evolution of each macroscopic quantities, taking a test function and then multiplying it by f. So with the approximation of the n interacting systems is a phi. interacting systems is a C multiplied by Fn. Okay, so it is simply the test function evaluated at the I n. So the first question is, if we apply this method, are we consistent with respect to the macroscopic quantities of our Polesman equation? So the answer is yes. So if we consider suitable norms, so we take the Suitable norms. So we take the norm with respect to the set of particles. So it is the L2 norm with respect to the set of particles and the random vector. So it is L2 of omega. It is the integration L2 norm in terms of Z. And then we have also to consider L2 norm with respect to all the possible set of particles. We have the following theorem so that at the level of macroscopic quantities, if we evaluate Quantities, if we evaluate the difference between phi F minus V and M, so we have the distribution of n interacting particles truncated at order m in terms of the stochastic direct projection. In normal true, it is less than a Monte Carlo part, it is given by the reconstruction that I described before, plus a stochastic array part here. Part here. So we see that in terms of Z, we gain again spectral accuracy since the error decays as one over m at power r, provided that the velocities are sufficiently smooth. So if they belong to a sub-order space of order r, we may provide again the spectral accuracy with respect to them. With respect to Z. Of course, it is better to consider a Monte Carlo-Monte Carlo approach. If we consider a Monte Carlo in Z and Monte Carlo in the phase space, we would have one over N squared, n power one half here for the reconstruction part, and one over square root of m for the z. Here we are something more. Okay, so we are more accurate than a standard. Than standard Monte Carlo-Monte Carlo solver. So let's give a small example. We consider, for example, a 2D Maxwellian case. So at the level of the interacting kernel, we take alpha equal to zero. So we consider the initial distribution as follows. It's very classical, as in the paper of Bobby of the 75. So we assume. So we assume that the initial temperature is stochastic, so that the temperature behaves like one over A of Z, where A of Z is affected by Z. So for example, A is 2 plus some perturbation of 2 indeed. So it is 2 plus minus K, since Z here it is assumed as a uniformly distributed random vector. So the exact solution is no. So, the exact solution is known for each time step f behaves as follows, where s here is the solution here. So, we have the possibility to compute time by time the evolution of the distribution of function. And here we provide some plots. So, the first row is the expected value at. Expected value at time zero and five for the first two columns, and then the variance at time zero and five for the third and fourth column. On the second row, we may observe the approximation of this quantity obtained through a DSMC stochastic anarchy method. So, in the I-norm, let's say everything works well. Are we sure that actually our method performs well? Actually, our method performs well in terms of the stochastic array of the stochastic arraying error. The answer is yes. If we take, for example, the L2 error, we see that we are spectrally converging toward the analytic solution. So the error is of the order of the machine precision and also at the level of the fourth order moment. It is the first one. It is the one. It is the one that is not conserved, and we have a close expression for the evolution of the fourth-order moment. We see that our method is particularly close to the excess solution. But we have the evidence here looking at the error or the uncertain quantities. Okay, in the variable asphere case, we have no more the time evolution of f so we provide. We provide some consistency computation with respect to the stress tensor, it is here given in terms of the first one, one component of the stress tensor. And we see that some problem arise indeed due to the presence of the indicator function here. I mean, we deviate with respect to the right First component of the stress tensor. In order to do that, actually, we introduce a modification of the indicator function in the form of an hyperbolic tangent. But the problem is that if we plug inside the collision process the hyperbolic tangent, actually you introduce some dissipation. In order to overcome this problem, we coupled our Boltzmann equation with a Our Boltzmann equation with a thermalization process to guarantee that the temperature is conserved. If you do like that, indeed, for each modification that you consider, you preserve the evolution of the first component of the stress tensor as shown above. And then also the L true error with respect to the uncertain quantity is spectrally converged. So, for example, look at the Look at the black curve. So, you essentially reach the machine precision also in this case. So, you can modify the indicator of function so that you guarantee the spectral accuracy. Okay, we tested also the same dynamics in terms of high-dimensional uncertainties. Okay, so in the future. So, in the few minutes that are remaining, so I just want to say that we are working on non-homogeneous problems and we started from plasma dynamics. So, if we consider the evolution of plasma electrons given by the one particle distribution F, then that depends on X V T as before, but we have seen this term that characterizes the Characterize the modification of F with respect to the presence of the self-consistent electric field E, that is solution, where phi is solution to the Poisson equation that is given here. Everything works like before, since Z collects all the sorts of uncertainties, but now we are modifying our equation and we are interested indeed in the non-homogeneous case. So the classical case is where Q. Is where Q is the Landau collision operator, and I mean, I don't want to spend too much time, but it is pretty known by the audience the Larsen this behavior of the Landau collision operator is the local Maxwellian. And in order to tackle this problem, we consider a simplified problem where indeed the collision operator is the BGK type of ability. Operator as before. So if we consider a VGK type operator for epsilon that goes to zero, we recover an error Poisson system that is given here. So if you tackle this problem through a standard stochastic alerting method, actually the error Poisson system is no more hyperbolic. So how to deal with that? The idea is to apply again the stochastic. The stochastic alerting method the particle solver with a stochastic array method. So there are many numerical methods. I mean, for sure, I will not mention everyone. I mean, there are a lot of research advancements in the numerical methods for plasma physics. And I just want to mention the advancement in finite references, volumes, or semi-degram skin or Fourier spectral method. Fourier spectral method, but now we will stick to a particle-based approach. So, also in the particle-based approaches, there are many cases like particle in cell, direct simulation Monte Carlo, like the work of Pobler and Nambo, and deterministic particle method, like the works of Jose and collaborators. Okay, now we apply a stochastic array method at the level of particles. Level of particles. So we approximate the position and velocity with respect to the uncertainty. So we end up with XIM and DIM, so that the macroscopic quantities can be read as follows. So at the cell L, we approximate the mass as follows. So we consider an indicator function. Indicate or function that provides whether xi m is inside the cell il the same for the moment the mean and the temperature so for the collision step we apply a classical BGK collision step so that at the kinetic level each particle at time n plus one is as follows so the the thermalization toward the local Maxwellian Toward the local Maxwellian is given here. For the transport step, we have a poor transport and then we have the modification of the velocity through the interaction with the electric field. So we adopt a three-step method that is given here. It has been taken from the lecture notes of Sony Drucker. Okay, the boundary conditions. Now we consider a periodic type boundary condition. So we have to distinguish these three cases, and then if you want to end up with a compact formulation, you have to take care of the presence of all these indicator functions. Okay, just want to show the performance of the scheme on some reference tests, like the Landau-Dampic case. In the linear case, we see that in We see that in the collisionless for collisionless plasma, we follow the theoretical path. And then, if you add the collision, of course, the dumping is lost. As we see, for example, in this video, so here we provide the evolution of the logarithm of the electric field or the expected value of the electric field. Or the expected value of the electric field together with the confidence bands, and then you see that you follow the theoretical path. In the nonlinear case, similarly, you have in the collisionless plasma two well-defined friends, and so that you have an initial damping and then it disappears following a well-defined frame. So, here you see. Trend. So here you see the evolution of the logarithm of the expected value of the energy, and then you see that we follow the theoretical path. And then I guess after some time, you follow the second trend that is theoretically predicted. And also, you have this poliation effect here. Okay, the spectral convergence is, I mean, the test on the spectral convergence is provided here, and then we essentially see that for a random initial temperature of this form, we have an error that decays in terms of the number m and you reach a massive precision in finite time. So, the last test I want to show you is the last test I want to show you is the two-stream instability test so that here it is so here we show again we have some theoretical results on the logarithm of the expected value of the electric field and you follow this path and then we have also the angle we see this I effect This high effect of the distribution function in the linear two-stream instability so that you reach the well-known patterns of plasma physics. So just to sum up all the contributions, so if you apply standard stochastic array method, you lose somehow the physical properties. Lose somehow the physical properties of your solution. So, in order to overcome this problem, we consider the construction of new schemes that couple the SNC methods with stochastic anarchy methods and they are capable to guarantee positivity and the pervolibility of the limiting equation. There are many other applications of these schemes, for example, to YP demology, traffic flow, fake news spread, and I want to point out that the problem is that the problem is that And I want to point you to the talk of Jonathan Franceschi. The official research directions regard a non-homogeneous Boltzmann. So what I presented today is only for the homogeneous Boltzmann equation for the first part. And we want to extend all the scheme to the non-homogeneous Boltzmann indeed. And then also for the Landau case, we want to couple indeed the standard Glasov equation. The standard Lasov equation with the Landau collision in the Landau collision case. Okay. Thank you very much for the nice talk. I'm sorry that we are slightly running out of time. If there's any very short question, we may be able to address one of those. Or otherwise, we probably would have to move to the second speaker. I'm sorry about that. About that. So hopefully we're going to be able to communicate by email afterwards. And thanks again for the time. No problem. Thank you. Okay, great.