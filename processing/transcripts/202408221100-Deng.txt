Okay, thank you. Yeah, uh, so uh, so, um, in this talk, I'll be discussing these topics from wave turbulence and more precisely, the derivation of wave pian equation from Schrodinger or in general, any seminar dispersed equation. So, this is a recent work, I mean, not recent, very recent, but it's like the work of Recent, very recent, but like the work in the last five years together with Zara Hani. So, some of you might have heard some of my earlier talks, but today I'm going to talk about this from a slightly different perspective, that is focusing more on the, you know, in the context of random data theory, you know, compared to the physical background and intuition. Of course, I will talk about physical motivation. About physical motivations, but okay. So let's start with this basic kind of random data model for dispersed equations and let's say for Schrodinger. And let's take it to be the cubic Schrodinger. So we start with the cubic and it doesn't matter, like in principle, you can consider any dispersion relation. Any dispersion relation, any non-linearity, as long as it's a polynomial. Like there is, if you don't have a polynomial, then things get tricky and you don't, you know, it's not clear what kind of equation you'll get in the end. So, and as long as it's algebraic, like whether it's cubic or quintigo or any power doesn't really matter. Okay. So let's say we have Okay, so here with on with u being a function on t d okay, and then let's choose our random initial data. So as explained in the previous two lectures of Haitian, let's consider u0 okay, so u0x if you want. If you want, so then we put a power, let's say, k to the sigma, and we have a gk ik x. Okay, so here this is the this is what we call the profile, and this is the ID. Run a variable, let's say Gaussian. Okay, so these are the four coefficients. So, here the point is that the four coefficients of the initial data are independent random variables. Okay, so we already know that in this setting, there are two kinds of special cases where sigma is zero or sigma is one. Sigma is one or sigma is zero leads to the leads to the so-called white white noise which is corresponds to the mass conservation of the equation and then you see Of the equation, and then if sigma equals one, and this essentially corresponds to the Gibbs measure. I mean, not exactly because you need to add in potential term, but in some cases, like the Gibbs measure is absolutely continuous with the corresponding Gaussian measure, and in other cases, not absolutely continuous, still they are kind of closely related. So, not again. So, not get into this too much. And this corresponds to the energy conservation. Okay, so what's the setup of today? So, first of all, we're going to move from the two special cases to the more general cases of general sigma. So, today we can see. We consider general sigma, where this means that we are moving from the kind of the equilibrium case where we have invariant measure, or both white noise and geek measures are kind of formally invariant measures. We're moving from the equilibrium case to the off-equilibrium case. So equilibrium. Equilibrium of equilibrium. Okay, and second, instead of this data, so if you look at this initial data kind of carefully, you realize that this contains like inputs from different scales indicated by this. Indicated by this. So k is small. So if you look at this, so k is if k is one, this is low frequency. If k is something very large, which is high frequency. Okay, so this is, of course, one setup. Now, if you consider kind of slightly simpler. Consider kind of a slightly simpler case, or like the we should make call, for example, the like the single scale kind of the case of one single scale, because you can think this data as being composed by different scales, like high frequency, low frequencies. But if you consider the case of single scale, let's say case between like a certain number L and 2L, then we're considering the Then we're considering the single scale data. And the reason for this is that we are going to do rescaling to introduce a case of kind of the equation on the large torus with unit kind of with state of unit frequency. And because of this, we need to assume that this data is a Is supported in the frequency of a fixed scale, let's say L, which we'll see in a minute. The single-scale data at scale L. Okay, so this is the setup we're going to take today, and I will see how this links to this question of wave turbulence. Turbulence. Okay, so that is we take the same equation, and then okay, so if we consider the you know the k being at scale l, then k to the minus sigma is l to the minus sigma, well, l is a fixed number. To have L to the my sigma, and let's say some have g k e to the ik x. Okay, so alternatively, we can write it using a kind of a smooth cutoff function. We write it as okay, and then we have a phi of Yes, okay. So, this is the system that we're going to look at today. So, let's recall that we have the standard curvation equation again on TD that we have our initial data being supported in a kind of a scale. Being supported in the kind of a scale L indicated by this kind of okay. So, how does this link to the topic of wave wave equation? So, we're going to, if we do a rescaling, so if we let V P x equals this. equals this u of t over l square x over l so then this well x belongs to this t l d which is you can write as l times t the d so this is a note t d is a unit torus and then this l time t d is a kind of large torus of A kind of large torus of size L, then you can get, you know, like I dt plus delta of V, we're going to get this, you know, L to the minus two, sorry, times V square V, and then the initial data for V is And then the initial data for v is going to be v 0x is the is the l to the minus sigma sum. And now here, if you consider the frequency is going to go from k to k over l, which we define as a lambda, for example. So lambda. Lambda and then we have we have phi of lambda g lambda e to the i lambda x where lambda is where l to belong to this l minus one times z to d uh okay okay so this is uh this is a setup so This is a setup. So, if we're rescaling, then V becomes this. If you write it in a more standard way, it becomes L to the minus sigma plus V over 2 times L to the sorry, L to the L to the minus D over 2. D over two sum okay, so this is the this is the kind of the normalized random for a series and to get rid of this L to minus two example you can define this w equals W equals sorry, w equals L to the minus one L to the minus one times V then because Okay, so and this uh factor, so let's call this uh uh let's call this alpha. Let's call this alpha. Okay, so this is what we get. This is a system that is posed on L D, which is L times a system pulse on the large torus. And if you look at the Fourier dual of the large torus, this is going to be this. So this is. So, this is L, and then the Fourier is going to be this. So, if you think you have frequency like one, and then this size is one, and then this distance. Okay, so this is the picture, and the physical. Picture and the physical kind of motivation behind this is that you want to study kind of this interaction of a large number of large system of waves. Physically, we're studying a system, large system of interacting waves. Interacting waves. Well, in this case, the waves are represented by the plane waves, the Fourier modes. So here, waves are represented by the Fourier modes. So if you look at this picture with large towers of size L, the kind of number. The kind of number of foreign modes within a unit ball is going to be L to D because it's a D dimension. The mesh kind of size is 1 over L. So the number of waves is equal to L to D. And then if you think of this parameter alpha as controlling basically the The strengths of individual waves, or kind of the strengths, the amplitude of individual waves, because you can think this the right side, this pink box as the standard random first series, and then this factor indicates kind of the amplitude of these waves. Then It's alpha. So, in our setting, we are going to take this number minus sigma plus d over to minus one. This is going to be negative. And so this alpha will be going to zero in the laminate L goes infinity. So we have taking L goes infinity and alpha goes to zero. Okay? Okay, so by the way, in the standard formulation of wave turbulence, it is usually normalized to replace this alpha by one and put this alpha kind of on the right-hand side of the equation, which indicates the strength of the interaction, strength of linearity. Of course, they are equivalent. So then this is. And this is volunteer. So we have these many interacting waves. So each wave is represented by one for a mode. And number of waves is L to D, where L is going to infinity. And then each wave carries its strength, its amplitude, which is alpha. And this alpha goes to zero in a limit. Okay. And then Okay, and then the question is: we want to study the interaction of these waves, and in particular, I want to study the statistical property of the interaction of these waves. Since we're considering random data, we are looking at this problem from this random perspective. Okay, and then we have initial state of wave. Of waves are independent, which corresponds to the fact that we have independent Fourier coefficients. So this G lambda, this IID. Okay, so the initial states of these waves are independent, and then these waves are going to interact with each other via. With each other via the nonlinear Schrodinger equation, via the cubic Schrodinger equation. So each point here, for example, represents a wave and they are going to interact and produce new waves and so on. Okay, so now we have this. We study the the statistics. So this is our goal. So if you go back to the original setup, like we recall when we started with this random data problem for Schrodinger, you see that we have made one kind of That we have made one kind of big simplification. So let's say compare with so the setting of random data. We have made one big syndication by restricting our initial data. Restricting our initial data to be in the single scale, in a single frequency scale. We restrict it single scale L and because of this, we can say much more than what we had previously. Remember that in the case of random data problems. in the in the case of random data problem like if we have gibbs measure then we have global solutions but if we have um you know if we don't have gibbs measure if we don't have invariant measure then we can only get um you know almost sure local solutions under a certain under a certain assumption okay and here not only we get these um these uh these these uh existing solutions but we can get very precise description of these statistical um properties of the system at later times because of this Because of this, we expect to get very precise kind of description of statistics. And this is the main topic we are discussing today. So, how do we get this? I mean, what is a precise description of statistics, and how do we get how to derive? And how do we get, how to derive such statistics information? Okay, so from the physical point of view, the kind of the few key kind of predictions for this system are the follows. So intuition, predictions. First of all, the states of different waves or different frame modes are independent, are still independent in a limit. Inner limits, which, if you look at this system, like this is due to this non-interaction, so you see that even if the initial data has independent Fourier modes, then the solution at later time is not going to have independent Fourier modes. They are going to have kind of be highly correlated because of these non-interactions. Well, I mean, exactly. Interactions. Well, I mean, except in the case where I have the exact, for example, invariant measure, then the behavior is still the same as initial data. But in general, you do not have these invariant measures. Okay, so this is something that we need to deal with, like when the solution, the four coefficients of solution become correlated in later times, like how can you still describe the statistics? So the answer is that this independence is actually kind of restored. Is actually kind of restored in the limit where L goes to infinity. Where L goes to infinity, of course, in the same time, we assume that this alpha goes to zero. Okay, so this is something that goes back even to the classical particle candidate theory of Boltzmann, where he first introduced this idea of so-called propagational chaos. I know, which is something that, if you think of it, it's highly non-trivial. Why would you expect that this independence is preserved or restored kind of even after these highly non-linear interactions, like if you take the limit. So, interpretation is that these kind of these interactions are. These interactions are kind of weak in the limit, in the sense that we're taking alpha goes to zero. So, kind of each individual, like kind of the effect of these interactions on each individual mode or each individual object is going to be negligible where L goes to 18 and alpha goes to zero. And so, somehow you can expect that the somehow you can expect that this independence kind of kind of recovered in a limit. And this is, of course, related to the fact that we're having this limit algorithm zero, which gives, which sometimes gives the name of the weak turbulence. Now, if you have the strong turbulence, then things may then things may just be different. But here, we still have this propagational chaos that we are expecting. Okay, so this is the first thing, the first kind of idea, first intuition. And by the way, all of these have the counterpart in the particle theory, in the kinetic theory, where the In a kinetic theory, where these weak turbulence corresponds to the case of dilute gas, where the number of gas particles is relatively small compared to the size of particles, where you get the Bolsonaro equation and other kind of things. Okay, so first is this. And second, if we expect these different ferromodes are asymptotic independent, then we are considering the behavior of individual fermes, and we can see the second moment. And you can see the second moment expected value of, let's say, you know, square, the second moment of issue for a mode is going to satisfy a particularly effective equation, which we call the wavelength equation. In the limit. Okay, so let me write down what is the waving equation. So you'll see that which rises as following. So it's like Chat, let's do uh display tau and so this is uh Okay, so equals C N N where it's uh let's file okay, so   Okay, so this is a waving equation. So let me explain what the various things in this formula. I mean, first of all, the solution to the waving equation is going to give the asymptotics of this second moment. Going to get the second moment. And by the way, so we also have asymptotics for the high moments, which we will not talk about. Higher moments, which we'll not talk about. And then the second moment is evaluated at the time scale of Tikienetic. And this Tkinat is actually equal to alpha to the minus 4 in our setting, where alpha, remember, is the size of the amplitude of the waves, the size of the initial data. Okay, so this alpha 4, it basically has a meaning that It has a meaning that it equals the kind of the scale of the so-called mean-free path, which is basically interpreted as it's a time scale, a time scale at which the non-linear effect of the non-linear effect on a single kind of frame mode just starts to take effect. So basically, if the time is less anti-kinetic, the time is less anti-kinetic then it's um like and any single uh mole is not going to uh is not going to feel any effect from non-interaction and with when he becomes bigger than t kinetic then these non-effects gets uh gets started getting significant and this corresponds to the excuse me sorry uh can you clarify the notation it the tau t kinetic it what in between it's uh a product or plus it's a product it's a product yeah it's Plus, it's a product, it's a product, yeah. It's product, thank you, yeah. Um, and this corresponds to the like in the in the in the case of dilute gas, it corresponds to the time where a single particle just have exactly all one collisions with other particles. And this, and this, this mean-free path refers to the path that it travels within this time, kind of the length of this path. The length of this path. But since the velocity is size one, then we will not distinguish the time and lengths. So this is basically, you can understand that this antic as the correct time scale where you are going to see this non-evolution of the weighting equation. Okay, so if you rescale the time to this tau, well, tau here we think that is all of one, then this second moment is going to approximate by Moment is going to approximate by the solution to waking equation plus a remainder which is explicitly goes to zero as L goes to infinity. Okay, so the waking equation looks like this. So it's an evolution equation. So here we are considering the so-called inhomogeneous case, sorry, homogeneous case, which corresponds to the fact Which corresponds to the fact that our waves are represented by the Fourier modes or plane waves, which are homogeneous in space. In the case where we have inhomogeneous setting, you are going to replace these Fourier modes by the wave packets, which also depends on X. And in that case, the only difference here is that you are going to have a transport term on the left-hand side. You have, instead of D tau, you're going to have. have instead of d tau, you're going to have d tau plus k dot grad x of n. Yeah, so d tau plus k dot grad x of n, you know, if inhomogeneous. Okay, so otherwise the same. And the right-hand side, you'll see it's pretty much similar to the collision integral in the Boltzmann equation, except that it's Equation except that it is cubic. So you're fixing k, you're inner rating in this manifold, you know, given by the k1 minus k2 plus k3 minus k equals zero. And this corresponds to the momentum conservation. And you have you're integrating also on this manifold where k1 squared minus k2 squared plus k squared k3 squared equals k square, and this corresponds to energy. Corresponds to energy conservation. Okay, and if you recall the Boltzmann equation, you see that you are exactly anywhere in the same manifold, which exactly corresponds to the momentum and energy conservation of the elastic collisions. Okay, and in the parentheses, we have these cubic terms, which you can write it as, for example, as this, nk1. This NK one and K two so NK one n k uh n k is three three times n k plus n k two minus n k n k two times n k one plus n k three okay so you see that if you ignore these factors That if you ignore these factors, then you get Boltzmann equation. You have this integral of delta of the same thing. I mean, at least in three dimensions, you're having this. Okay, so this is uh this shows that there is a uh pretty much um a close relation and similarity between this uh uh this working equation with starting from the Schrodinger model and the you know the for example the half-sphere model that leads to the uh that leads to a Bolsonaro equation. Actually, actually, it turns out that not only they are formally similar, you know, concentrate similar actually, they are pretty similar actually. Similar actually, on they're pretty similar actually on a technical level. Of course, we don't have time to discuss the relation between these two, but just some remark that this thing actually is kind of the exact analog of the Boltzmann equation. And I should mention just one sentence that if you consider the Boltzmann equation, but with quantum particles, With quantum particles, then you do the same thing, then the effect equation you get will be exactly kind of the linear combination of this wavelength equation and the Boltzmann equation, which is called Boltzmann-Notheim equation. So there is version, there's a plus sign for the bosons and minus sign for fermions, but essentially what you get is this. That is the that is the sorry suppose my not mine okay so this is a So, this is a discussion, brief discussion of the waking equation. There is a lot of solution theory, a lot of study on solution theory of the weighting equation, and especially on the so-called Zakhov spectrum. In general, the mathematical study is kind of less complete than that of the Boltzmann equation, but it's kind of much more subtle, its behavior kind of much worse, and you are expecting singularities. And you are expecting singularities. But we're not going to talk about this, and next we'll focus on the rigorous derivation of this question. Okay, so let's review a little bit. You know, we start from the standard Shoning equation. We did rescaling and we reduce ourselves to this model on the large torus. And then we start with. And then we start with again the initial independent initial data initial data with independent fluid coefficients and we're viewing it as a big system of interacting waves and we're studying statistical properties at later times. And then the prediction is that we're going to have propagation chaos, that is the preservation of independence in the limit, and we're going to expect that. Expect that the second moment to satisfy the wave function. Okay, so I'll not talk about too much of the history. So essentially, it starts with, you know, history. So let's say on the physical side, we have works of Perse, 1920s, and maybe the maybe. And maybe the work of Hesselman in the 1960s and work of Zakharov 60s. On the mathematical side, we have work of Spong many 70s and then the work of Erdos some Samhoffer Yao. Yao, in the 2000s, and subsequent works. And this thing is recently kind of much more developed due to this recent work, starting, for example, with Lucrene and Spong. And then the works of Blackmaster Jermaine, Hani, Sheta, 19, which kind of started the study of this topic in recent years. Okay, and so let's now go to our main theorem. This is the So, this is the theorem with honey, which contains in a number of papers, so 2021, 23, essentially this theorem claims a justification of all these facts, including propaganda chaos, including these These asymptotics of second moment given by the weighting equation. Like in a certain setup, where we first derive the equation for sufficiently small scale time tau, and then we extend it to arbitrary large time tau as long as the solution to the weighting equation exists. So let us summarize in one kind of final theorem. So let's develop. That dimension is bigger than three. Okay, so we believe the two dimensions should also be true, but so we are restricting ourselves to three dimensions. And alpha equals L minus gamma, well, gamma is a certain number here. Gamma is gamma between zero and one. How there's a reason. Between zero and one half. So there's a reason why we expect this, but we don't have time to talk about this. And we have this any kind of large time t, t star, be any time. Let's call it tau star. Let's call it tau star. Be any time such that the waving equation has a nice Has a nice solution. So, this is any time such that the working equation has a nice, I mean, in the sense that it belongs to a certain space, you know, up to this time, there is no blow-up. So, let the solution be n tau. And how okay then we have for example we have a programme chaos and let's write it it's right as a as a very very simple in a Simple, in a very simple case, expect the value of, let's say, the cross, you know, the correlation between two particles. So you had how dot  plus O of L to minus theta where I've got infinity okay so this of course just uh just um you know like two the so-called two um you know uh four-point correlations uh and this factorizes into the And this factorizes into the two-point correlation, but you can consider high-order high-order object, which behaves the same. And second, we have the wave equation. We have this derivation working equation, and both of these are true for any fixed constant constant so fixed constant. constant so let's say tau belong to zero tau star okay so this is for the whole um time interval on which the solution to wave king to the wave king equation exists now we are we uh we have these uh these uh predictions being valid um for these um for this whole timing and uh you see by the way that And let me see by the way that if tau s equals infinity, that is to say our solution to wave equation exists globally, then we can choose how belong to something like log log L, which is which is going to infinity, you know, in a in a limit. In the limits of algosomicity. Okay, so this is the kind of the ultimate theorem that we proved in this setup of waking equation. So I think if I have like a few more minutes, so I'll maybe just describe in a few words the idea of proof and then I'll discuss a little bit of the, you know, what's what is expected, what is expected to be done in the. What is expected to be done in the future? You have like five minutes. Five minutes. Okay, good. But may I ask a question here? So, here, for any fixed tau, you have this convergence, but is there any like uniformity over the time interval, the convergence? Okay, so it's uniform as long as you stay away from the maximum. Okay, so let's say Tao Sai, let's say Tao Sai is maximal time, let's say this way. Maximal time, let's say this way. So, tau, sorry, uh, tau si is maximal time, so it's a maximum time you have blow up at taosa, for example. Then, uh, then the estimate is uniform as long as you stay a fixed distance with tau south. So, if you, if you okay, uh, so uh, let's um yeah, and and by the way, so in the in the case Tao side. Way, so in the case tau size infinity, I think this is also uniform as long as tau is less than log log L. Okay, so a little bit discussion on the proof. So the proof for short time. So in the paper, we actually, our first three papers will focus on the short time case. Short time case, what how is Is sufficiently less than one. Okay, and in this case, we're doing expansion, we're doing the Duhamel expansion, where the solution, you know, social expanding in terms of ternary trees, where you think of a ternary tree as one ternary tree as one iteration of cubit. Tree as one iteration of qubit nonlinearity, then you can discern your trees, and then the correlations are turned into pairs of leaves of ternary trees. Okay, so thing you have, if you have, so remember our initial data is Gaussian, so essentially one leaf of the tree represents an initial input factor. Initial input factor in this equation, which is Gaussian. And then, if you take the correlations of Gaussians, you get this so-called weak formula, where you, or this correlation is written by the sum over all the pairings of the Gaussians. And this leads to the idea of the notion of so-called couples. So, for example, this one, these two leaves are paired, and for example, these two leaves are paired, and then, for example, these. And then, for example, these three leads are paired, and these three leads are paired. Okay, so this is a couples. This leads to the notion of troubles. And then the idea is that we're going to do the kind of commentorial analysis of couples. So then we have the commentaries. Commutorics couples, which is kind of the main. Taurus couples, which is kind of the major kind of object, major idea, you know, major ingredient involved in the proof. So, if I if you give me like two more minutes, so I'll just just one minute to say the long time. Long time is essentially we do it by dividing. You know, you know, if you have a tau star, we divide this into small intervals, so each one is like. intervals so each one is like a tau and tau is less than one so divide into kind of um you know short short intervals and then we'll need to propagate kind of um Um kind of providing NSATs that kind of memorizes the interaction history on this interval zOt and this is just just one more word. This is also the reason kind of why why we are getting this time irreversible equation from the Time irreversal equation from the time reversal dynamic, and this is precisely because this interaction history is going to be memorized, and you're going to see this in the effect equation. This interaction history kind of monotonically increases from left to right. In some sense, you can view this as entropy. And this entropy is kind of increasing, which corresponds to the fact that if you go from zero to t and Go from zero to t and from t to higher t, you're going to get more and more kind of more richer and richer kind of interaction history, which corresponds to monotonicity of the entropy and kind of and other kind of things. And this is the same metric for the Bolsonaro equation. Okay, so maybe finally the future directions. I think, well, I mean, the inhomogeneous cases and maybe the longer time scales. Longer time scale means that, you know, tau being log L in the case of Gov existence, or maybe kind of L to the, you know, plus state. L to the you know plus theta theta being zero. I mean, I think this will be needed if you want to actually get actually get to rigorous justify this Zagreb spectrum, but this is very hard at this point. And other kind of models, the Boltzmann, no time, and all other kinds of. And all other kinds of things. So, I think this is a result I think that starts, you know, opens the door to many different problems that should be open for the future investigations. Okay, thank you, Ahsoka.