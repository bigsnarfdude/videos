I am okay to have the talk recorded, yes. Okay, so I'm going to be talking about token sliding reconfiguration of labeled independent sets in forests. So there's, I'll go through some of the previous work related to this as well before I go into the actual thing. This is as well before I go into the actual thing. Most of the work related to token sliding on independent sets are based on the assumption that tokens are not labeled. And I'll be going through the labeled variant mostly. Okay, so an independent set is, as you all know, or I hope most of you know, you have a graph and then you take a subset of tokens, subset of vertices where no two vertices in the subset share an edge. The subset share and edge, but we're going to visualize it as facing tokens and slide them just like with standard token sliding reconfiguration. And because when we're talking about, so the notation I'm going to use here is a squiggly arrow to show that the two independent sets can be reconfigured to each other. When the graphs are undirected, you can always undo a move. And so it goes both ways, which gives us a performance. Both ways, which gives us an area graphs. And then a forest is an unrated graph that contains no cycles. And a tree is a connected component of the forest. And then we also define a sub-tree here, which is if you take an edge UV and you were to delete it, then it produces two components, one of them that has U, another one that has V. So T U V. So, TUV is a component with V, T V U is a component with U. We don't actually delete the edge when we talk about the subtree, we're just referring to the subtree, and you have the parent of the subtree and the child of the, so for UV, if you delete UV, the child of U is ending the subtree would be. A caterpillar is basically it's just like a long path where attached to the path, Where attached to the path, you could have a degree one vertices attached to it. That's caterpillar. And it's especially useful here because it kind of resembles like a one-track road where if you want to pass through a caterpillar, there has to be no one else in your way in the caterpillar at all. Because if anything is on the caterpillar, it's going to block the main path. Okay. Okay, so we have independent sets, and now we're going to look at the case where the tokens in the independent set they're labeled. Okay, so every token has some label. Label could represent a color or some string. It doesn't really matter how you refer to the label. Just the important thing is that every label is unique. So no two tokens are the same. Every token is distinct. And And we also define a permutation function, which we'll be using later, which is just if you have an independent set, you can apply a permutation where the tokens are in the exact same vertices, but then the labels are different. Okay, so we can refer to this mapping using a permutation function. Okay, so those are the basic definitions. And so the main problem that I'm going to address is. So, the main problem that I'm going to address is: given a forest and you have two labeled infinite sets i and j, can we determine whether it's reachable, whether i can reach j or not? And the algorithm is going to be quadratic time currently. Hopefully, there will be room for improvements in the future, but at the moment, it's just a quadratic time algorithm. It's non-constructive, so it does not produce the complete reconfiguration sequence. Complete with that regulation sequence, even if the answer is yes. Okay, so some related work on this. Well, there's a lot of related work on event sets or token sliding and stuff, but the two that stood out the most are these two over here. The first one by Demain and others is about token sliding of independent sets in trees, but In trees, but the tokens are not labeled. And then the second paper here is: it does talk about labeled tokens, and they do slide on trees, but there's no independent set being considered. So you can slide tokens anywhere as long as the vertex is unoccupied. So I will admit that I haven't actually looked at the second paper too deeply because I noticed it really late after I already did most of the work here. So it's very likely that. So, it's very likely that some of the stuff I'm doing could have been adjusted to be much easier using ideas from the second paper. But the first paper, I'm basing most of this work as building off from the first paper. So, in fact, I'll actually go through the very quick summary of what the first paper covers, which is you have a tree and you have an independent. Tree and you have an independent set with no labels, or two independent sets, i and j, and they reach each other or not. So the first step is to identify tokens that are rigid as defined in the paper. So a rigid token is basically a token that can never move at all, no matter what. So like a simple example is if you have a bunch of DB1 vertices connected to something, to some other vertex, and To some other vertex, and all of these degree one vertex have tokens. So nobody can do half because they're all blocking each other. So, this is a very simple example of a rigid token. Of course, the definition is a bit more complicated. And I'm not going to go deep into the characterization of rigid tokens because that's already done in the paper. And they have a linear time algorithm, actually, which goes through the entire tree, removes movable tokens one by one until everything that's left is rigid. Is rigid. And then they gave the reachability algorithm, which is how do you check if two independent sets can be configured, reconfigured to each other or not. So the first step is to find all the rigid tokens in the two sets, in the source independent set and the destination set in I and J. And if the set of tokens are different, then we know it's a no instance because rigid tokens can't move. So there's no way to somehow So, there's no way to somehow produce a rigid token in a place where there wasn't a rigid token or to somehow get rid of a rigid token. So, that's going to be a no. Otherwise, if you do have rigid tokens, then you can't pass through rigid tokens. In fact, no other token can even go near the rigid token. So they kind of block off. They separate different parts of the tree. So you can actually delete the rigid tokens as well as all of their neighbors, which might disconnect the graph. So now you have to look at each of these individuals. You have to look at each of these individual trees one by one, and for each tree, you check how many tokens do you have in the tree, uh, how many tokens you have in the tree for your source independent set, and how many tokens do you have in the destination independent set. Now, if the tokens are different at any time, so we know that's a no instance, if you have a tree with five tokens in one set and three tokens in the other set, there's no way you can slide to each other. But if the tokens match, then the answer is yes. The answer is yes, which is actually really nice because you don't have to worry about anything else. As long as you have the same number of tokens and none of them are rigid, then it's always possible to reconfigure one of them into the other, as long as the number of tokens match and none of them are rigid, which is actually a very beautiful result, which I'll be exploiting a lot later on as well. Later on, as well. So that's the reach building algorithm, which runs in linear time. They also provided a sequence construction algorithm. So given the two infinite sets, which are yes instances, then how do we construct the sequence? So they do provide a sequence which has a quadratic number of steps, which is actually asymptotically optimal as well. As well. Okay, so all of that was what was done before with the unlabeled graph or the unlabeled independent sets. Now we're going to go through the labeled variant. And before I actually go to the algorithm, there's several things that I'll need to go through. So ultimately, we will still take advantage of the unlabeled version of the algorithm. The unlabeled version of the algorithm because it identifies rigid tokens efficiently, which they're still rigid, whether they're labeled or not, they're still rigid. So we can still get rid of rigid tokens. And after that, because we know that they could be configured to each other, if we ignore the labels, they can be configured to each other. So if we do consider the labels, ultimately, all we need to deal with is a permutation of the independent set because the vertices they're occupying are the same. Vertices they're occupying are the same. We know that that's reachable. So it's just a question of can we rearrange the labels in order to solve the reconfiguration. So there's a few other points that I'll need to go through first. So the first thing is about the rigid-free independent sets, the maximum rigid-free independent set. So we say that an independent set is rigid-free if none of its tokens are rigid because we're using. Because we're using the main logarithm to remove rigid tokens, anyways. All of our independent sets that we're dealing with are rigid-free, mostly. But I'm also defining root availability as something where, so if you have an independent set in a tree, so then the maximum, since everything is movable, the maximum independent set is going to be equal to Is going to be equal to the rigid-free capacity. So I define this term rigid-free capacity as the size of the maximum possible rigid-free independent set. But one issue is that if we consider a subtree, if we consider a sub-tree, it's possible that when you're looking only at the subtree, then the tokens are not rigid anymore. So in the overall tree, they're movable, they're not rigid. Movable, they're not rigid, but within a specific subtree, some of the tokens might become rigid. So, in that case, generally, this kind of independent set we say is root available because when everything is movable, there's still space to squeeze a token inside. Once you squeeze in that token into the root, it no longer becomes rigid-free. So, actually, can I draw? Can I draw an example and not show? Like, if you have, for example, this simple example, this is like a tree, and let's say this is the root of a tree, and you have another example of this. So these are basically the same tree, right? They're isomorphic to each other, but the roots are defined differently. So in both cases, the In both cases, the rigid-free capacity is one because you can only have one token that can move around. If you have two tokens, they cannot move around. But the one on the left is not root available because the root is what connects to the rest of the tree. So if you had two tokens, they wouldn't be able to move. Even if you can leave the root, they wouldn't be able to move. So this is not root available. Whereas the one on the right, if you did have a branch connected to the rest of the tree, then you could have. Then you could add two tokens and they will be able to do that. So that's where the root availability comes in. Okay, how do I get up with that? Okay, so there is an algorithm for computing the widget free capacity. I think I, yeah, I can put. Think I yeah, I can quickly go through this. So it's basically a simple recursive algorithm. So we start with the base case where if there's only one vertex, well, in that case, we know there's no token that can move within single vertex. But we do say it's root available because it is possible to add a token to the single vertex. It's just, it just won't be movable anymore. And then in the recursive case, we now consider a node that. A node that has multiple children, a project with multiple children. And then we look at each of those subtrees and we recursively recursively calculate what is their rigid free capacity. And of course, we can fill them up with the rigid-free tokens. So we can add that up and get a total amount. And now the only question is, can we add a new vertex to the root? And that depends on whether any of its children are root available. Of its children are root available because if any of its children are root available, then you can add a token to the root, and then this token can slide to the sub-tree that is root available, and therefore you can add a movable token to the root. But if none of the children are root available, then you cannot add something to the root because there's no place where it can slide to. It's going to be a rooted token. So that's basically how this algorithm works. And this would run in linear time. Linear time given a particular tree, if you would just want to check for a particular vertex, but also you would run in linear time if you want to compute the rigid be capacity of every single sub-tree. You can sort of, by using memoization, you can store down the values that you already know. And every time you need to refer to a sub-tree's capacity, you can just look it up. And if you didn't look it up, if you didn't compute it already, you can just compute it. If you didn't compute it already, you can compute it right away. Okay, so some other properties relating to rigid free capacity is if there are no rigid tokens in a tree, then if you take any subtree, the total number of tokens is equal is at most the capacity plus one plus one, as I mentioned before, because you could have something stuck on the root that needs to get out of the subtree. And also, another important result is if. Another important result is: if the number of tokens is less than or equal to the capacity, so it doesn't have that extra token squeezed on the root, then all tokens in the subtree are movable. Even though you're looking at a sub-tree, it's still movable within the sub-tree. There's an inductive proof to this, which I probably won't be going to because it's rather straightforward. Okay, another important result is on permutation in. Permutation invariant. So, this one actually relates to the fact that the tokens have labels in them. And the main lemma that I'm using here is if you have i going to some j and you know it's possible to permute j through this permutation function. So j can reach some permutation. In that case, i is also able to reach its corresponding permutation. And this arises mainly because you Mainly because you can go backwards. And not only that, but also because, so we go from I to J, and then from J, we can permute J. But once you permute J, you can now go back and retrace the steps you made to go from I to J. So whatever you did to go from I to J, you now undo and go from J to I. Except this time we're using the permitted J. And even though the labels are different, it's not going to affect the validity of any of the steps that we take, right? It's just labels that are different. K, right? It's just labels that are different. The actual vertices that are occupied are still the same. So we can retrace our steps and go back to I, but because we started with the permuted j, the result is going to be the permuted i. So this does assume that if you can go from i to j, you can go backwards. There is a generalized lemma that could be applied for when you don't have, you don't look, it doesn't go in both directions. You don't look, it doesn't go in both directions if you define a step in a way that doesn't go in both directions, so you could still use some kind of permutation invariance. It's a little weaker, of course. But I'm actually not going to use this. I just mentioned that here because it might be related to any interest in directing graphs. So, why is permutation invariance useful? One reason why it's useful is because as long as we can reach the J and do the permutation, As long as we can reach the J and do the permutation, we don't need to find the sequence that goes back to R. And in particular, we can use this to basically make small changes one at a time. So if you have a simple permutation where all it does is just swap two tokens, and now if you, if J, if you reach some J where you can swap the tokens, those two tokens in J, then you know you can swap those two tokens from behind. First place. From the I, first place, the original I that goes to J, and you don't have to go back all the way. And the nice thing here is you can do whatever you want with the other tokens when you go from I to J. You don't have to worry about messing up your messing up the independent set. It doesn't really matter because in the end, all you want to do is reach this J, show that those two can be swapped. Once you show that those two can be swapped, you know it's possible to undo everything and go back to I when those two are swapped and everything that I can reach. And everything that I can reach, you can also reach corresponding set where these two tokens are swapped. So in fact, our general permutation can be decomposed into a sequence of swaps. And if we want to show a yes instance, if you want to show that i can be permuted to i, then you can just try to perform each of these swaps one by one. And if all of them are successful, then that's the yes instance. And for each swap, Instance. And for each swap, you just need to focus on the tier token being swapped. You don't need to worry about anything else. Okay. Now we can also use permutation invariance to prove a no instance. So if you want to show that i cannot go to pi i, usually it's not obvious just from looking at i or pi i. So instead, what we try to do is we try to go from i to some j where you know you cannot go to pi of j. In that case, from the hot positive permutation invariance, it means Positive permutation invariance, it means you cannot actually go from i to pi i either. How do we get to some obvious case where j can't go to pi j? So there, at least for this context of trees, this is the basic structure of a no instance that I'm trying to look for, where you have some caterpillar, and then at the two ends of the caterpillar, you have some vertex u and v. U is connected to a bunch of trees. V is also connected to a bunch of trees. So the set of trees, you can define as a forest FU and forest FV. If there's a token that wants to go inside FB, but right now it's not inside FB, then it's actually impossible for it to go inside FB because all of these are full. So a token can't just enter F. And the only way to clear it out is if something gets out of FB. If something gets out of FB, it has nowhere to go because Gets out of FP, it has nowhere to go because FU is also full. So the tokens are basically stuck. Nothing on the left side can go to the right side, nothing on the right side can go to the left side. So if your pi, if your permutation requires that a token on the left side goes to the right side, then you know it's a no instance. Okay, another point is about sub-tree restricted reconfiguration. It basically just says that if you reconfigure Says that if you reconfigure something within a subtree without worrying about anything else, then that reconfiguration holds even if the stuff outside changes, which is fairly obvious, but it's something that I'll be using in the algorithm. Okay, let's go straight to the algorithm. There's not a lot of time left. So the algorithm has basically three phases. The first Basically, three phases. The first phase is to copy domains algorithm to get rid of the rigid tokens and with some small changes because things are labeled. The phase two is also copying domains algorithm, but this time it's using the sequence construction to actually generate the permutation to reduce the problem into i going to pi of i. And then phase three is to check whether pi i can move. Whether I can move to pi i. So, phase one is based on Debay's algorithm, this is the new time. Phase two is quadratic time based on Domain's algorithm again. Phase three is the new one, which runs in quadratic time as well. So, phase one, there's just some minor differences where we just check the labels. When you check if the related tokens are different, check what the labels are. When you check whether the number of tokens are the same in the two sets on a single tree, you don't just check the number. On a single tree, you don't just check the number, you also check what are the labels on those. And if the labels don't match, you say no. If labels do match, then we need to check whether the permutation is possible. So we now move on to phase two where we use domains construction algorithm, reconfiguration sequence construction algorithm, and find out II. Okay, now phase three is what we do is, so first we need to. What we do is, so first we need to compute all of the widget-free capacities, which, as I mentioned before, and then we decompose into swaps, which I also mentioned before, and we try to check each of them one by one. If any of these swaps fail, and when I say fail, it means it leads to some one of the obvious no instances where you have a caterpillar separating between two forests that are full, then that's going to be a failure. Otherwise, if every swap is Otherwise, if every swap is possible, we will return yes. So, the expensive part here is checking if the swap can be performed because you could have a lot of swaps depending on how many tokens there are. And each swap at the moment, with the current algorithm, it could take linear time across the root. It's a little slow. Okay, so for the details, I think I'm not gonna bore you with all of this text. I think it works best. All of this text. I think it works best if I just go straight to the pictures. So if you have two tokens, S and T, and you want to swap them, first thing you want to do is get S to some tree where it's full and S is the root. And you try to do the same with T. Get it to some tree where it's the root and it's full, which is nice because you don't have to worry about anything behind S or anything behind T. And then after that, we try to see who else is connected to this vertex, U, that's connected to. Vertex U that connected to the tree with S. And for all of these other trees, you also try to fill them up. And we also try to do the same for the T, but even after we try to fill up the neighbors in T, there's still going to be a lot of tokens in between. We try to push them all to T side. So we need S to go to T. It's not actually quite symmetric because even though we want to swap S and T, S is the one that needs to go to its destination. One that needs to go to its destination. S needs to go where T is. T needs to go somewhere else. We don't really care right now, but S needs to go where T is. So we try to push all these tokens towards T side. We'll end up with something like this. Some of these might be partially filled. That's okay. And now we just try to move S ahead. So we find some structure with some empty space in between. We try to move S there. Well, before we move S there, we want to fill it up until there's S there, we want to fill it up until there's only space for one token because we want s to go in very nicely with in a full tree. And once s moves there, our u basically moves to the corresponding vertex that's holding this tree, which means everything wherever s came from becomes a giant sub-tree that was connected to you. And now we try to fill them up again. So we try to fill up all of these sub-trees, and we'll keep trying to. And we'll keep trying to fill them up. Eventually, we might have eventually they might all become empty except the tree that has T in it. If that's the case, we just move the vertex B closer to T so we can still continue filling up all of these. So we keep moving U closer to the token T and we might have to back up V, but eventually what would happen is Happen is we either clear a path to make a swap or we'll get a note instance. So I also went through, I also designed an example, actual example of just swapping two tokens. So you want to swap the blue token with the red token. All of the other tokens are gray because we don't care what their labels are. So we don't care where to go. So the first thing is to find, let's make sure the blue token is at something that's The blue token is at something that's at full capacity, at which it has to be at full capacity, but it still needs to be moving. So, right now, it's on a single vertex. Like if you chop it off from the path to the red token, it's on a vertex by itself, which is not actually rigid-free. So, we need to first move things. And I also computed the rigid free capacities here. So, we need to move things, and we might need to move quite a bit, but it's always going to be. To move quite a bit, but it's always going to be possible to find a particular configuration. And now we also want to do the same for the red one. Now, for the red one, if you try to back it out, it actually can't go backwards because there's a token blocking the way. And unfortunately, I mean, there's a lot of space here. So we can see that there is a lot of space in the right side, but the red token can't go there. So this is one place where we take it. One place where we take advantage of reconfiguring within the subtree because we know that it is possible for these tokens to move on the right side, which means it's possible for the red token to move left somehow. Right now, it can't move left, but we know there is a way to rearrange the stuff on the left. So we save the current state, which I'm calling it as alpha. We mess up the left slide to allow the red token to go. We don't actually need to do this, but what matters is we know that this beta configuration exists. Beta configuration exists. Once we know it exists, we can move the red token away, get that other gray token that's blocking the way somewhere else, move the red token back. We have our beta on the left side again. We can now go back to the alpha. So during the actual algorithm, you don't have to worry about what that beta is. We're not actually moving tokens because we know it's possible to get rid of that token that's blocking the way. And so we will get rid of the token that's blocking the way. Okay, so now we have the red token is also built somewhere. Okay, I'll try to speed this up. So essentially, we have the U and the V. We have everything connected to U is already full. So we find some branch. So we try to move all the gray tokens to the right side. And if they're already full, we move B closer. We move B closer and we keep trying to fill them up and we keep moving B closer. Eventually, we get B to the state where there are no green tokens between U and B. Now we try to find any branch that allows at least one token to enter. So we try to fill up that branch until it has space for only one token left, which is where we move the blue token. That allows us to move the U, and now we can move tokens into the subtree that it came from. That it came from, and we just keep doing that. Sometimes we might have to move B backwards until we're able to do that. And then we move U to the next one. We move the blue token to the next place, and we just keep repeating that. After we move you, we move the token into the tree where you came from. We just keep filling it up. We just keep repeating this process until we get to a state like this. This process until we get to a state like this, where the path between U and B doesn't have a branch that accommodates any tokens, right? So there is one branch sticking out in the middle, but that has a zero in it, which means no token can actually enter it. So we basically have a caterpillar sitting in between. So there's a caterpillar sitting in between. U is connected to a tree that's full, that's at full capacity. And the same goes for the V as well. The V as well. Everything connected to V is full. And you might notice there are tokens that can enter, but that doesn't really matter because even if a token enters, there's no way for the token to get back because it blocks away. The blue token has no way of getting to where the red token is. So this is our no instance. Okay, just some quick notes about the algorithm. There are some, there might be some room for improvement because we don't need to. Because we don't need to use domains algorithm to actually do a complete unlabeled reconfiguration. All we need to do is find out what pi is, and it's possible this can be done faster. I'm still looking into it, but I do think it can be faster than quadratic at least. And then the swaps, because each swap can take linear time in total, which is where our overall answer comes from. But the other paper that I mentioned that slides tokens on trees with labels. On trees with labels, the ideas there might help with improving the raw type of swaps because it basically, well, one thing is it knows it observes that if two tokens can swap, they're basically equivalent. So we can just try to expand our equivalence classes and find out the entire equivalence classes more efficiently without having to check each individual swap one by one. And then we just check if two tokens are in the same equivalence class or not. And we can also extend this problem. Extend this problem in many ways, like trying to construct the sequence, trying to optimize the sequence as well. And we can also extend the idea of labels into scenarios where multiple tokens might share the same label, which complicates things quite a bit. But that's an area that we can look into. All right, that's about it. I'm open for any questions. Thank you. Are there questions? I have a little question. Yeah. Any thoughts about what happens if in each component of the forest you, well, it's not a forest, but the forest you have a site once. To the forest, you have a cycle, one cycle at most. Would it break down completely, or could you handle it in some way? I'm not sure what you mean by only one cycle. No, but one, okay. You don't have a force, but in each component you have at most one cycle. So if you have a cycle, I I'm not entirely sure. So, what I was working on is just trees, so we don't have to worry about cycles. But if there is a cycle, if there is a cycle, but as long as the tree is still full and it's disconnected from the rest of the graph, aside from this one edge, right? So, if this is still a cut edge and that component is. Edge and that component is full. I think that I think the progression should still work because in the it would still be a no instance if you have the scatter pillar separating between these two forests. Of course, that only applies if the edge is a cut edge. If you have multiple edges connecting to the components, none of this applies anymore. Let's thank the speaker again and we're closing this ahead.