Good. So, our final speaker of today, Robert McCann from the University of Toronto, and synthetic null energy conditions. Right, so I probably announced a different title, and it was probably a more appropriate title. But so, the talk really has a couple of different parts, and I'm going to spend a good amount of time surveying some recent approaches to doing general relativity and anonymity. To doing general relativity in a non-smooth setting. And then towards the end, I'll talk about this non-smooth formulation of analogy, which is. Worked a second ago. Okay, great. Right, so the Einstein equation, the Einstein field equations are formulated on smooth Lorentzian manifolds, but in many situations, even generically, Even generically, they are known to predict that the smoothness is going to break down. At least the manifolds are going to be geodesically incomplete. And for example, black hole or Big Bang type singularities. And so this is part of the motivation for trying to have a non-slim theory of gravity. And there we go. And if we switch to positive signature, there's this kind of highly developed theory. Kind of highly developed theory of metric measured geometry, which I guess goes back not quite 100 years to the school of Alexandrov, who realized that if you're in a metric space and you have geodesics connecting pairs of points in the metric space, then you can formulate a notion of sectional curvature bounds based on comparing triangles in the metric space to triangles in Euclidean space or constant curvature model spaces. And on And on more recently, so you can't formulate Ricci curvature bounds based on triangle comparison, but more recently, people have been very interested in studying limits of... So of course, you can have a beautiful sequence of smooth spaces, and the limit is not smooth anymore. So this is another motivation for wanting to develop a non-smooth theory of gravity. So somehow in this world of metric geometry or maybe metric measure geometry, Or maybe metric measure geometry, the smoother Riemannian manifolds are beautiful, they're like the rationals, but you want to complete them in some sense. And when you complete them, you get objects that are no longer Riemannian anymore. And you'd like to be able to deal with, so like the reals, and you'd like to be able to deal with the limiting objects on the same basis that you deal with the sequences that want to make them. And so the notion of convergence that people typically use is for compact spaces is Kronhoff-Hausdorff convergence and for non-compact spaces. Convergence and for non-compact spaces, you have to go to a pointed version of convergence. And this is for metric geometry. And if you have metric measure geometry, so another metric space equipped with that reference volume or reference measure, then you need to modify the definitions a little bit to talk about pointed measured growth. That's part of the reference. And so, of course, there's also this very nice theory of Cheeger-Colding, where they looked at sequences of Riemannian manifolds and possible limits of such. And possible and possible limits of such spaces under lower Ricci and upper dimensional bounds. And a synthetic characterization of these limits was given by Lott, Sturman, and Milani about, oh gosh, almost 15 to 20 years ago. There's also an earlier theory of Bachrian Emery that based on more populistic sort of deer-lay-lone methods, allowing you to characterize what reaching lower bounds might mean in a metric or metric. Reaching lower bounds might need in a metric or metric-metric setting. And there have been a lot of developments in the last 20 years, including many authors, Roswell Julius and Mari among them. And so in some sense, the motivation for the work that I'm going to try to survey is to have an analogous theory, but in luck and search. And a few milestones in this area are five years ago, Michael Kinzinger and Clemens Sand. Ago, Michael Kinzinger and Tim and Seina published a paper which includes sort of a metric setting for triangle comparison bounds in Lorentz and signature. And more recently, a couple of frequencies have appeared thinking about how to formulate notions of convergence. And in terms of synthetic notions of Ricci bounds, there have been a number of people who have worked in this, including myself, but especially I should highlight, I want to highlight. But especially, I should highlight. I want to highlight the work of so I did, I worked in the smooth setting, but showed that one could give an equivalent formulation in the smooth setting to time-like lower reach curvature bounds, equivalent to things that could be made sense of in a non-smooth setting. And then Cavalletti and Modino went ahead and formulated how things ought to be phrased in the non-smooth setting by sort of blending what Kuzier had said and done with what I had done and what Modino and Sir did in the MPM me. And my postpartum, Natias Braun, has been contributing, and many other people have been contributing to development on this theory. So here's the setting. I'm advancing too many slides at once, sorry. Okay. So I'm going to have a set M, and instead of a distance function D that satisfies the triangle inequality, I'm going to have a time separation function L, which satisfies a backwards triangle quality. Which satisfies a backwards triangle inequality. And if you really want the most general case, you have to allow L to take value plus infinity as well as minus infinity. Things are a little simpler. I mean, if you want to allow for like closed time-like curves and so on. But if you want to exclude those things, then you can throw away the value plus infinity and then you have this backwards triangle inequality. And the other thing you want to assume about L is that it's non, that on the diagonal it has a sign. So with this sign on the diagonal, it should be non-negative. This sign on the diagonal, it should be non-negative. I don't really mean hypothesis 2, but on the other hand, hypothesis 2 is more, it doesn't cost much in this setting. So I could substitute non-negativity on the diagonal for hypothesis 2 if I'm not. And so hypothesis 1, together with non-negativity on the diagonal, implies because of the triangle inequality, there are really only three values that L could take on the diagonal. It could be zero some places, it could be plus infinity, it could be minus infinity. Because somehow on the diagonal, L has to be bigger than two values. L has to be bigger than 2L. And as long as L is non-negative on the diagonal, then I only allow 0 and plus infinity as possible values. And if I could exclude plus infinity, like 0. And the typical example, the motivating example is think about Ninkowski space of your favorite dimension and consider the following Lagrangian. Okay, so on Ninkowski space. On a Minkowski space. So, if you're a future-directed vector, you look at its square root of the magnitude of its Minkowski, of its Lorentzian square norm, and otherwise it's minus infinity. And the beautiful thing about this Lagrangian is it's actually concave as an extended real value function. And you can also raise this Lagrangian to your favorite power less than one, and it will remain concave. In fact, the concavity even improves when you, so, of course, it's never going to be. When you, so of course, it's never going to, it's always going to be constant on the light cone, taking the value zero on the light cone. But when you raise this Lagrangian, it's a little bit like a norm. It's one homogeneous in the time light, on the interior of the light cone. And if you raise it to a power less than one, you can make it strictly financed. And so this is Minkowski space, but of course the other motivating example is you're on a Lorentzian manifold and then at each point And then at each point, you have a Lorentzian metric that tells you which vectors have zero inner product with themselves. And since it's, I mean, my signature convention is plus, minus, minus, minus. And so since there's only one positive direction, the future is disconnected from the past, at least locally. But if you have Um, but if you have two points on your Lorentzian manifold, you can ask: is it possible to join them by a curve which is future-directed or not? And if so, you can recover the time separation function you want by is the backwards and triangle imply I'm going to have to try to maximize the integral of this Lagrangian along such curves. And then you could also worry about whether there's a global time orientation for your Lorentzian. Global time orientation of Rigular Lorenzian manifold and so forth, which I'm going to assume. Okay, and please stop me at any point if you have questions. Right. So let me make a further remark about this too. So I said you could also substitute 2 with the hypothesis that L is non-negative on the diagonal, but more or less But more or less, if you just assume one and this, maybe I call this two prime or something, and then you take equivalence classes of points that are in their own futures. So I haven't said what the future is next, but points for whom L is, so if, so for points like this, x, y, where y can be reached by a future-directed curve from x, I'm going to take Lxy to be non-negative. And for other points like y over here, I'm going to take Lxy to be minus 1. Over here, I'm going to take Lxy to be minus infinity. That's my kind of functional anyway, so I'm going to really check it. So if you assume this, 2 prime instead of 2, you get 2 by quotienting it by all points, pairs, x and y, such that both y is in the future of x and x is in the future of y. So 2 comes more or less for free. And then once you have 2, by this quotienting operation, if you have some kind of You know, if you have some kind of causality assumptions like global hyperbolicity, you don't need to quote shortly for free. You get to automatically, but anyways, there you go. Puzzle spaces. As long as you have two, you can look at the set of pairs such that L of XY is non-negative. You can look at the set of pairs such that L of XY is strictly positive. And the first guy becomes a partial order. So they're both translucent relations. Because of two, the first guy becomes a partial ordering. Guy becomes a partial ordering, second guy is a free order, and the triple is a special example of what Kern-Emerit and I call a causal space. So they have this sort of very abstract order of the iterated approach to gravity, which is useful if you want to approximate a space-time by a discrete set. Much in the flavor of, I want to think of a manifold by sampling points from it and keeping the distances between all the sampled points. And now I have a discrete approximation to my manifold, which in the limit is the number of points I sample gets. Which, in the limit, is the number of points that sample gets large enough, hopefully, Gromov converges, with probability one, Gromov House converges to your manifold. Okay, so and I guess what's known more or less is that about smooth Lorentzian geometry is you can sort of decouple the structure. So the light cone keeps track of what conformal class you're in. All the metrics in a given conformal class will have the same light cones. And so the additional information beyond the The additional information beyond the light cone is that you get from a metric is a notion of a volume, basically. And so, in some sense, these causal sets of Cronheimer and Penrose are like the conformal class. They're keeping track of the light cones, so they're keeping track of who's in the future of whom. And if it comes from an L, the L is some additional information, which is like the login. Okay. And anyhow, so if you're in a setting like this, you have Setting like this, you have. I'm going to define the causal and time-like futures of points by using j for the causal future and i for the time-like future, j plus is the future of x, j minus is the past of y. And similarly, if I have sets, I take over sets to define causal future, causal future and past of the set, and the intersection. So, causal diamonds are going to be important. So, whenever Important. So whenever you have an x, you can look at its causal future and you can interact, intersect that with the causal past of y, and the intersection I'm going to call a causal alignment. And some people, I've heard replace the x and y with sense, so I'm going to call this a causal temporal. Anyways. And the difference between the j's and the i's is that you ask for the j's you asked for inequality or non-negativity. That order, non-negativity, and for the i's you have to restrict positivity. And I also have to apologize that because we're trying to develop this kind of axiomatic set theoretic, order theoretic, whatever approach to Lorentzian geometry, I'm going to throw a lot of definitions at you. And that seems to be an unavoidable drawback of the field of the topic. Okay, so a path in such a set of events and A path in such a set of events m is going to be called causal if it's a parameterized curve, parametrized by some contributable along the real line. And if for all parameter values t larger than s, sigma t is in the future of sigma s, then I'm going to call it a causal path. And I'm going to call it a time-like path if sigma t is always in the strict, the time-like future of sigma s. And then you can talk about the Lorentzian length of causal paths. Lorentzian length of causal paths. I'm going to choose a funny sine dimension. So instead of maximizing, I'm going to look at minimizing Lorentzian lengths. And so I'm going to define the negative L length of a causal path by, you know, you look at, so you have a path in your space, which doesn't completely manifold. It starts at, let's say, sigma 0 and ends at sigma 1. And you look at all partitions. Partitions into sub-intervals, and you sum up the time separations between each pair of points in the partition, starting with sigma 0 and sigma 1, and you try to maximize that. And you also maximize it with the points in the partition, and that's how you define the negative L denote of the past sigma. And that's almost bigger than the negative time separation of the endpoints. Time separation of the endpoints of the path because of the backward structure. And so you can then try to minimize this negative Lawrence among causal paths. And it's not so useful to do so if your causal paths don't have some continuity because you could just take the causal path that stays at sigma zero for a while and suddenly it jumps to sigma one. Okay. Okay. And so I'm going to define, say, an L path to be a path parameterized over the unit interval such that each sub-interval of my path, say, you know, like the one-quarter, like say one-quarter, one-half sub-interval, the distance between these two points should be a quarter of the distance between these two points. And similarly, for every positive. And similarly for every possible interior diet. And so this is a property that you think should be characteristic of geodesics. So the fraction, fraction t minus s, of the full, the distance between sigma t is 0 minus is a fraction t minus s, so the distance between signals 1. And this relationship is really only primarily interesting to me when L is positive and not infinite. And I'm going to denote the set of L paths by then. Of L paths by the time-like L paths. And so if you have such a guy, it minimizes the ranks and length probability to a grand point, the rank of inequality. And of course, not all minimizers are going to be LPAS for various reasons. They might be discontinuous. They might not be arc length parametrized if you're proper time parametrized if you're in smooth setting. And also, element minimizers. Also, L minimizers include points that are causally but not time-like related to each other. And so I'm going to call my set of events and my equipped with this time separation function a time-like L hat space if every pair of time-like related events are connected by one of these devices. And the globally hyperbolic Lorentzian length spaces of Kunzinger and Zeiman provide a very rich class of examples of spaces that have this property. Spaces that have this property. But to achieve this, they need a metrizable topology. Okay, so this is actually an interesting point. So to formulate the definition, they need a metrizable topology, but in the end, we're going to see that the, yes, they need a metrizable topology. In fact, they use a metric. So a function D, a positive signature metric, and not just this time separation function L. But in the end, a kind of nice fact is that, at least in this nice globally microbolic or a seamless space setting, All I'm using like space setting, the object that I'm going to come up with is going to turn out only to depend on L and not on D. And I'm going to try to streamline by assuming that by targeting the globally hyperbolic setting, I'm going to try to streamline the presentation a little bit. So I'm going to call a metric space equipped with the time separation function L, a metric space-time. And following Kanzer Seymon, I'm going to upgrade a I'm going to upgrade any path to a curve if it's the ellipsoids. So a causal path becomes a causal curve if the ellipse is a non-constant. And I need to try to say what global hyperbolicity means. So a metric space-time is non-totally imprisoning if whenever you have a compact set, K. So the topology is always going to be the topology metrized by D, unless otherwise save it. Save it. Whenever I have a compact set K, the causal curves in that set are going to have a bound on their D length. And if they have a bound on their D length, of course that will depend on K, then they can always be reparametrized with respect to D arc length. And that's useful for showing convergence, for showing limit curve theorems, for showing compactness of the set of causal curves. On the other hand, it's not so useful for, I mean, if you want to do geodesics and geometry. I mean, if you want to do geodesics and geometry and sectional curvature bounds and reached curvature bounds, you really want proper time parameterizations. So you really want to parameterize with respect to L and not with respect to D. And so there's this tension in the theory between L and D. And the other property that, so basically what this non-tunal imprisonment prevents is it prevents things like curves that go around and meet themselves because they would have arb they would within K. They would have arbitrarily long D length. And so a space-time, a metric space-time is globally hyperbolic if it has this non-total imprisoning property, and also if every causal dime in it is connected. And I also need some notions of causally curve-connected. So I'm going to say it's time-like curve-connected if every time-like related pair of points have a time-like. Related pair of points have a time-like curve joining them, and it becomes a Lorentzian geodesic space if every distinct pair of causally related points are connected by a causal curve. And moreover, this causal curve, which is continuous, attains the minimal possible value of the Lorentzian length. So it's equal to the negative time separation between the 10 points. And okay, so it's hard for me to say what a Lorentzian length space is, but if I'm willing to assume level hyperbolicity, it's not so bad. Not so bad. So, if I have a metric space-time which is globally hyperbolic, then it becomes a Lorentzing length space if and only if it has the following implied properties. It should be time-like curve connected. It should be a Lorenzyn genetic space. And every point X should have some other point in its time-like future, and some point like X plus and its time-like future, and some point X minus and its time-like fast. And it's time-like fast. And finally, the time separation function should be lower semi-continuous, and its positive part should be continuous. So those are kind of nice sort of reasonable properties. And you can see there's some, because of this continuity and also the compactness and so on, there's some relation between the L and the D of the metric space find. And but in these globally hyperbolic Lorentzian length spaces, considering Samuel showed that actually the metric topology of D. The metric topology of D coincides with the topology that's generated by the causal diamonds I xy. And so that actually tells you that if you had two, if you had M D L and M D prime L, and if D and D prime generate the same topology, then it turns out that if one of them is globally hyperbolic, the one's globally. If one of them is globally hyperbolic, the other one's globally hyperbolic. So the notion of global hyperbolicity only depends on L and the topologies generated by the causal diameters, and not on which choice of D you choose to meetrize this topology. This isn't entirely obvious because the notion of causal curves were D Lipschitz, and my non-total imprisonment property depended on D Lipschitz in a heavy way. But the nice fact that Kinziger and Shaman show is that if you're globally highly Is that if you're globally hyperbolic, then the topologies coincide, and that's a purely topological statement. So it doesn't depend on D or D prime at all, it depends on the topology we metrize. And if the topologies coincide, so rather if the diamond generated topology coincides with the metric generated topology, then you get non-imprisonment, non-total imprisonment for free. And there's another characterization which is a non-profit. And there's another characterization which is analogous to what you have in the smooth setting of this global hyperbolicity in this rather non-smooth setting by Henrik Bircher and Reynolds Grassy Left-Belling. So they show that one of these globally Lorentzian length spaces is globally hyperbolic if and only if you could find Cauchy time functions on it and Cauchy surfaces. Okay, so so far so good. So I gave this definition of L path earlier on, which perhaps I should write somewhere. should write somewhere. So I said sigma was an L half if and only if sigma s, the time separation between sigma s and sigma t was a fraction t minus s of the time separation between sigma 0 and sigma 1. And that was supposed to be a positive number for every s less than t between 0 and 1. Unfortunately, even in this nice setting of globally hyperbolic Lorentzian length spaces, we don't know that this property implies continuity of sigma. And so as far as I know, in order to get continuity of sigma, you need to assume something else. And consider the same called this regular localizability. I'm just going to call it regular. What this property is, that I want to know that if sigma, if the Lorentzian length, If sigma, if the Lorentzian length of some sub interval of sigma, which is non-constant, vanishes, then the Lorentzian length of the whole sigma vanishes. So, in other words, if I'm a L minimizer with time-length separated endpoints, then every internal pair of points should be time-length separated as well. I shouldn't have any null segments in the middle of a L minima, Lorentzian length minimizer that has time-length separated endpoints. And so, if you have this, then every L path. Then every L path becomes continuous, and so I wanted to do a proof. So let me try to do a proof on the blackboard. So let sigma be an L path And so I'm supposed to be in a globally hyperbolic regular Lorentzian like space, and so that means that sigma 0, sigma 1, if I look at the causal future of sigma 0 and intersect it with the causal path of sigma 1, the diamond that I get is compact. And because of the L path property, sigma is a causal path, so the entire sigma lies somewhere inside this diamond. Somewhere inside this diamond. And so, what I can worry about is: you know, suppose that, so if, say, sigma sk increases to s, I want to know does sigma s equal to limit of the sigma s k's? And because the diamond is compact, I know that after extracting the sub-sequence, I know that after extracting a subsequence, this limit exists. So after extracting a subsequence, I'll call the limiting point like sigma s minus or something. Subsequentially. And so this would be a picture like sigma s is here, and the sigma s k's are converging to some other point, sigma s minus. And so, but what do I know? I know that. And so, but what do I know? I know that the I know that L of so okay first of all I know that sigma S minus can be connected to sigma s by a Lorentz length minimizer because I've assumed to go back to the previous slide, sorry, here it is. Sorry, I've assumed I've assumed that it's a Lorentzian statistic space. So I've assumed that there's one of these de-lips, it's continuous curves whose Lorentzian length equals the time separation of its endpoints. And so let me denote that by the sigma tilde. And maybe we'll call that like sigma tilde 2. And similarly, I know that there's a D Lipschitz Lorentzian length minimizing. Lorentzian length minimizing a curve called sigma tilde one that joins sigma zero to sigma s minus and I also know that there's one called sigma tilde three that starts here and ends there and so I can concatenate these three things and to get sigma tilde I don't know how to so that's like sigma I don't know how to, so that's like sigma tilde one can add in maybe with sigma tilde two compatibility with sigma tilde three. And then what do I have to check? I have to check that the Lorentzian length of sigma zero sigma one, or sigma s minus, let's say, the time separation between this point and this point agrees with the Lorentzian. point agrees with the Lorentzian length of this curve here. And that was more or less by definition of this curve. And moreover, so this is what Lorentzian length up to a sign of sigma 1 tilde. And moreover, this thing here is a fraction S of the total length of the curve. Total length of the curve. So maybe I'll let T minus L, plus or minus L, sort of potentially signal 0. So this guy is going to be a fraction S of T and this guy's going to be a fraction 0 of T, and this guy's going to be a fraction 1 minus S of T. And so I add them all up, and I find out that this is a Lorentzian length minimizing causal curve joining the initial point to the final point. The initial point to the final point, but it has a null segment in its middle. And that violates regularity. So somehow that's a huge bit of fun. So I piece together this from my L path, which might not be continuous, or Lipschitz or whatever, I can piece together this Lipschitz continuous thing, which has the same largest length to it, it has a LC. Length to when it has a null segment in its midst, but the endpoints of time are separated, and that's this hypothesis. And by the way, this hypothesis is motivated by what happens in a, if you take a manifold, a Lorentzian space-time, a Lorentzian manifold, and you put a metric tensor on it, which is only Lipschitz continuous, then you still have this, you still recover this regular hypothesis. So basically, um, you would end up with this. You end up with this relation between the L paths and the Lorentz length extremizers among curves, which is that they're equivalent up to one being a continuous non-decreasing parametrization of the other. So in other words, you can take a D-Lipschitz proper time, L minimizer, and then you can proper time parametrize it, and you'll get an L path. And Kunzengo and Sam knew this, but conversely, you can take any L path in this. any L path in this regular lobby hyperbolic setting and after it may not be d ellipsitz but there's some reparameterization that makes it ellipsis and so somehow that resolves an awkward annoying gap in the literature okay so henceforth I'm only I'm only going to deal with metric space times or I'm primarily going to deal with metric space times I shouldn't say only which are closed Lorentzian geodesic subsets of these nice globally hyperbolic regular Lorentzian line spaces Line spaces. And okay, now that I have time-like geodesics existing between any pair of points, I can do things like triangle comparison. So I can imitate Alexandrov geometry, and this is what Kinziger and Zaman did. And they looked at these generalized midpoints, but I'm going to, just to simplify the presentation, I'm going to talk about midpoints. So if you have a triangle X, Y, and Z, and Y is Z and y is in the future of X, let's say the time-like future of X, and Z is in the time-like future of Y. Sorry, pen. Then it will follow that Z is in the time-like future of X. And you can take a midpoint of this side, say, and this and look at how with the time separation between. How, what is the time separation between this midpoint and Z is. And you can compare that to what happens in 2D Minkowski space for a triangle whose time separations are the same as this one. And so then you take the midpoint here and you compare the blue time separation here to the green time separation over there. And if this one is always bigger than this one, then you're you have You're you have positive time-like sectional curvature, and if this guy is always smaller than this guy, you have non-positive time-like sectional curvature. And you can do this comparison even if one of them is only positively related. You can still make the comparison here, although maybe you couldn't make it there. If they're both time-like related, you can also compare midpoints here with. Here with that guy there. You don't just need to look at points, you need to look at divisions of the other ratios as well. And of course, what you can't do, there's some points over here that can't be compared to y, but what consider examines do is they say, if you're on this point and you can be compared to y, so if you're in the puzzle future or past of y, then you do the comparison. So by doing this, they're able to come up with some notion of sectional curvature bounds, which turns out to be consistent with what happens in the smooth setting. The smooth setting. And the consistency was proved beforehand, before you had this non-smooth definition by, I guess, Alexander and Bishop about 15 years ago. And that's often the case in this moving to a non-smooth world is that the equivalence of the definitions worked out first in the smooth setting, and then you formulate it using the non-smooth concepts that you prove to be equivalent in the smooth setting in a genuinely non-smooth setting. And of course, another thing that's kind of interesting here. Another thing that's kind of interesting here is: okay, I have a notion. So, Kunzinger and Saman were able to show that these causal sectional curvature bounds have consequences. So, in particular, they prevent the branching of L genuses. So they prevent time-like branchiness. And I'm going to say what is time-like branching. Actually, I guess I formulated it in terms of L paths. So, my space is going to be time-like future non-branching if for every pair of paths, if they coincide on the first path. If they coincide on the first half in their intervals, then they coincide on the whole interval. And similarly, there'd be a time-like pass on branching, which would be if they coincide on the second half interval, and then they coincide on the first half. And if neither of these things happen, then there's time-like branching. And consumers were able to show these kind of curvature bounds prevent this kind of time-like branching. And as I mentioned, Alexander this episode: consistency is definitions in smooth setting with smooth time-like sectional curvature bounds that you. Smooth time-like sectional curvature bounds that you define by taking derivatives and using the Riemann tensor. And rather, recently, Minutianshur showed that these kinds of bounds survive limits in an appropriate sense. So if you have a sequence of spaces that satisfy these bounds, then limit also satisfies the bounds. And of course, I described the comparison for zero, but if you replace the Minkowski Minkowski plane with either the pseudosphere or the constant curvature or answering spaces with positive or negative constant curvature, then With positive or negative curvature, then get versions of time-like sectional curvature bounds for other curvatures as well. Other questions? And so, actually, there are sort of three features that I want to highlight because they're going to recur in our discussion of reach curvature, which is you like the things that you want from a non-smooth definition of curvatures, you want it to coincide with the smooth definition in the case where both apply, and you like non-trivial consequences, and you'd like stability underwears. Stability under that. But if we want to do general relativity, of course, we saw in the previous talk that the Einstein field equations are formulated in terms of the Ricci tensor, and so we'd like to make sense of the Ricci tensor or maybe bounds on the Ricci curvature tensor, at least in time-like directions. And so, in the smooth setting, what you would do is you'd fix a time-like direction, you average the sectional curvature over all triangles that, you know. All triangles that, you know, orthogonal two planes that include that time-like direction. In the non-smooth setting, you don't know how to average. You don't have an algebraic structure, so you can't take a trace. And so what you typically want to do is you want to introduce a reference measure or reference volume, and that's going to contain the information about how to average for you. And so let me sketch first how this works in positive signature before I try to do it. Signature before I try to do it in order to signature. And so the way that I am most familiar with doing this is through optimal transportation. And the idea is, okay, I want to look at the Ricci curvature along some time-like curve. I'm going to need to look at nearby time-like curves and compare how close or far they stay to it. And so I want to fuzz out the curve. And the way I do that is by fuzzing out the initial point and fuzzing out the final point. point and fuzzing out the final point. So I replace the events, the points, by met probability measures, and then I try to construct a geodesic or an L path in the space of probability measures. And so in positive signature, the way this works is you look at the set of rel probability measures on your space. I'm going to focus on those with compact support. If I have two metric spaces and I have a mapping between them, and I have a measure on the first space, I can get a measure on the second space by pushing forward the first measure through the. By pushing forward the first measure through the banding gene. And so, for example, if I have a product space and I look at the canonical projections, then I can look at the joint probability measures. The definition of joint probability measures with marginals mu minus the mu plus is those which push forward through the canonical projections to give me mu minus mu plus. And the way that I lift the geometry from the point M to the probability measures on M is by using this construction from all Using this construction from optimal transportation, which was proposed by Kamborowich in the 1940s, which is I try to look at all joint measures with the two marginals. So these are my two fuzzy events. I look at all pairs of joint fuzzy events. I try to minimize the distance, or the average peak power of the distance. And here, as long as p is bigger than one, and as long as my metric space is polished, so complete this comes this topology between. This topology is completely inseparable, then the p1 will be attained. And moreover, when I take this pth root here, I'm going to get something that satisfies the triangle with poly on the space of measures. And it's actually known what this distance on the space of measures matrizes is weak convergence against functions that grow no faster than weak power distance. So it's a kind of metric for the weak topology. And a nice fact is that if the underlying Fact is that if the underlying set of events or points is a geodesic space, so there are geodesic curves connecting a pair of nuts, then the set of probability measures of compact support is also going to be geodesic for this piece. And so we want to try to do the same thing in Lorentzian signature. Oh yes, let me give you the intuition about why this helps define curvature. So if I'm in a positively originally non-negative space like the sphere, and I take a fuzzy event over here and a fuzzy event over there and I connect them by that. Distance squared minimizing path in the space of probability measures or possibly events, the reaching curve is going to smear out the density of that probability in the middle. So if I look at something like the LQ norm or the L log L norm, if they were the same in the first and last places, it would be smaller in the middle. I mean, I have some convexity of the L log L norm. If I'm in negative Ricci curvature and I have these two events on either side of, say, a saddle, Events on either side of CSAL surface, when I try to interpolate between from this fuzzy event to that fuzzy event, the problem is when you're more concentrated in the middle. And so, something like an L-log-L norm is going to tend to be larger in the middle, so not convex in this case. So, I'm somehow going to use things like convexity of an L-log-L-type norm along these geodesics probability measures to try to define my bounds of my mature. And so, when I, of course, this was done by Lott, Delaney, and Stern. Of course, this was done by Lott, Delaney, and Stern 20 years ago in the positive signature case. When I switched to Lorentzian signature, I want to define something like the Camerovic distance. This time I'm going to use an exponent q, which is less than 1. And as in the positive signature case, I'm going to want to assume that my globally hyperbolic regular Lauren's going on space is published, so that's a completely separate topology. And then, given every pair of measures, I'm going to say that. Measures, I'm going to say that I want to look at the joint measures with these marginals, but I'm particularly interested in whether or not there's a joint measure which vanishes outside the causal future of the pair of points XY or the chronological future of the time-like future. So I'll be interested in these causal measures and time-like measures, and I'll try to maximize the expected qth power of the time separation between my two fuzzy events among all causal measures. And again, if I take the qth power power power, And again, if I take the q's root, then it turns out that this LQ is going to define a time separation on the space of compactly sorted probability measures. And moreover, if the underlying space is a time-like L path space, then the set of probability measures is going to be common time like L like P path space, or P path space. And now the bad news is that not all the LQ paths are going to be continuous. Continuous, continuous with respect to, say, the Kanrovich metrics that we saw in the previous page. And so I should give you an example of the kind of thing that I'm worrying about. So the typical example, go back to Minkowski space, even the Minkowski plane. So R11. And let's define x of t to be something, this will be like the point 9, so it's going to be the point. point 9. So it's going to be the point 9 comma t where t ranges from 0 to 1. And let's define y of t to be the point t where t ranges from 0 to 1. So that's t equals 1 because it's t equals 0. And now let's take a measure like a delta measure concentrated on this curve. Oh yes, and I need to point z of t. So I mean z of t is going to be something that spends part of its time here given z s of t. And Zs at t. And part of it's time here, and it's going to make the jump from there to there at time s. So it's going to be y of zero for all t less than s, and it's going to be y of one for all t bigger than or equals s. That's the name, but less to the one. And so now I take a delta measure on this path plus a delta measure on this path here, and I average them. And I average them. And that guy is going to be an L Q path between its initial and final point for any Q less than 1, but it's not going to be weakly continuous because it makes this jump. And that's an annoyance. We don't want that to happen. And so, in order to cure this problem, I need this definition. I need this definition, which comes from Cavalier and Ludino. And so I'm going to denote the set of maximizers in this problem by gamma q, gamma super q. And I'm going to call the endpoints time-like q dualizable if at least one of these maximizers is concentrated on the time-like set, so as L strictly positive. And some technical condition of all that I don't want to worry about. And I'm going to call them strongly time-like cutilizable if, in addition, Cutilizable if, in addition, brushing the technical details under the rug, all of the maximizers are more targeted. And so the point of this definition is that in the first case, at least one of the maximizers here is going to lead to a D1 continuous LQ path. And once it's D1 continuous, it turns out actually to be D1 that should quite nice. So it's quite nice. And if they're strongly time dualizable, then actually every LQ path becomes D1 for this circle. And, okay. Okay, so I'm gonna let me see what do I need. I'm again focusing on these metric measure space-times, so I'm now going to equip my I'm going to equip my metric space time, Lorentzian-Genesic closed subset of globally heavy Lorentzian length space with a metric measure which is finite and bounded sets and whose fork is the whole thing. And I'm going to assume that the topology is completely separate, probably also that non-sets are compact. And the motivating example for all this is smooth space-times. They're known, it's known that when They're known, it's known that whenever you have a space-time of Lorentzian signature, you can always find an auxiliary to the Riemannian metric, I call it G tilde, which makes the thing into a complete Riemannian manifold. And so when you equip smooth spacetime with the distance associated with G tilde and the time separation associated to G by integrating the square root of G squared along causal curves, what you get is indeed a proper global kind of coincidence in length space. Will be handed all the currents in length space, provided it has provided itself with mutual multiple ways. So, no closed causal curves, and all the causal dimensions should be compact. And so, this will be my basic setting. And you might want to equip it with the volume associated to G, but as we've seen, because this is a contrast on quasi Einstein manifolds, you might also prefer to equip it with some other reference measure, such as the volume times the weight. And I'll take the conformal factor to be formed with e to the minus e, which is the function v. To the minus e, which is smooth function v. And so when my metric measure space time, what we have a lot of regular properties comes from a smooth Lorentzian manifold like this, I'm going to call this metric measure space time. Okay, and now I want to try to move on to in my last 10 minutes, synthetic time-like Reachie bounds, and hopefully, eventually null curvature bounds. So again, we'd like consistency, stability, and consequences. Stability and consequences, and we're going to use an L long L type entropy to try to along geodesics in the space of fuzzy events to try to define a lower bound on RPG curvature. And my entropy goes down when things are spread outwards, like in this central community process going off that will make this curvature. And so this is Cavalier Mundino's definition, essentially. So if I have one of these metric measure space times equipped with a reference measure m, I'm going to say it weakly has time-like curvature dimension parameters k and n. So k is going to be a real parameter and it's going to be positive, possibly infinite. Q is this transport distance exponent. It's going to be between 0 and 1. If and only if, for every either strongly or at least time-like dualizable finite energy pair immediately, Finite energy pair u0, you can find a maximizer and the corresponding LQ path along which the entropy is, so the case to focus on is k equals zero and n is infinity, along which the entropy is convex in that case. And if k is not zero and n is not equal to infinity, you take some modified version of convexity, where finite values of n enhance convexity, positive values of k also enhance convexity, negative values of k were convex. Enhanced convexity, negative values of k relax a little bit, and the k gets weighted by something that's measuring the time separation of the overall geodesic. It's the squared L2 expectation of that time separation with respect to this xy0. But anyhow, when k is zero, you can forget this term in the definition of such activity. And there are two definitions here, actually. If I ask this for every time-like dualizable curve, they call that time-like average dimension. If I ask it for every strongly time-like dualizable curve, I ask if we're strongly timelined on it, we'll curve that due to time range, which dimension with curvature forever k and dimension to every n. And so, what we'd like to know is that this definition gives us the three properties of consistency, stability, and consequences. And so, Catalan and Medino prove a kind of weak stability property. Say if you have a sequence of strongly TCD spaces with certain parameter values, the limit in the sense which they introduced, which I'm going to describe. The sense which they introduced, which I'm going to describe on the next slide, is weakly TCD, the same parameters. And they also show very interesting consequences. So, even in these weak TCD spaces, or even weaker measured, kind of like measured contraction stases with parameters K and N, you're able to show a version of the Hawking single results. So, in other words, if you have an A causal set, future time-like complete, you need to formulate what it means to have a local bound on its mean curvature. On its mean curvature, but if you're in a time-link reaching non-negative space, you have a positive lower bound on its mean curvature, then some future time-length vector is going to be geastically. Some future time-length paths are going to be geodesically. And I should say at the same time that they did this with Eric and Christian who were in the audience, Anna Bitbircher, we were able to show a reminder version of the Haying Singularity Theorem, which probably I don't have time to go into, but basically, it says, I mean, the crudest case. Basically, it says, I mean, the crudest case of it, the simplest case says if you have a subset of Euclidean space and a positive lower bound on its mean curvature, then you can't fit too big a ball into it. So you can't go too far inside. And that's the same kind of thing they're proving. They're saying you can't go too far into the future. There's a bound on how far you can go into the future, and therefore, future decides about being incomplete for some time. And sort of interesting that even in this very non-smooth setting, this prediction of Hawking about the existence of Big Bang tech singularity is robust. Singularity is robust. And here's the notion of convergence they use. So I'm going to fix the point in the support of my measure, my jth measure, and then I say the jth element of a sequence of these space-times converges to a limiting space-time, constant space-time, if and only if I can embed the whole sequence, T continuously and L I symmetrically, into a single big proper, what we have like regular lines. Proper only hyperbolic regular learning length space, such that after the embedding, the distance between the preferred points goes to zero and the measures convert weekly against suitable test functions. So it was compactly 40 tests functions. And this is one of several possible equivalent definitions of convergence in a positive signature case, which seem to be well adapted to Lorentzian signature. And I have to say that in the work of Magutzi and Sur, preprints of Magutzi and Sur, and Sinceur and Balach Müller from last fall, they look at other things that are more closely akin to remote star convergence in these Lorentz cases. So they give some alternatives, but the way they synthesize the jumps is a little bit different than I found today. And so the Cavalier-Mundino stability result was weak was not ideal because it said that a limitedly strong TCD spaces was at least weakly TCD. So Matthias Braun last year showed that if the space Ron last year showed that if the spaces are time-like non-branching, then the weak and strong versions are equivalent. And so the situation has been improved. But on the other hand, what's not clear is that when you have a sequence of time-like non-branching spaces, the limit may not be time-like bond-branching. So we don't have any kind of stability result for either time-like non-branchiness or even the switcher version, which is sort of a measure theoretic almost everywhere kind of time-like bond branching. So that's a nice move to do in positive signature. We know how to resolve. We know how to resolve, but not wanted to be signature. And so here's the consistency statement, which was mostly worked out actually before the work of catalytic and winding up. And so for the consistency statement, I'm going to move into the quasi-Einstein setting. And so if I have a smooth metric measure space-time, I'm going to define this modified version of its Ricci tensor by adding the Hessian of the weight V and subtracting some multiple of grad V tensor grad V, where the Tensor grad V, where the multiple is going to depend on its dimension parameter, capital N, which should be different. In the case where capital N is equal to the topological dimension, then N is equal to concept. And then this result that I published three years ago says that you fix these parameter values in smooth metric measure space-time through weak or strong TCD conditions, those parameters can and are exactly equivalent to either the dimension parameter. The dimension, parameter n being the topological dimension, v being constant, and the reach curvature being non-negative, or greater than k rather in time-like directions, or the dimension parameter, the synthetic dimension being larger than the topological dimension, and its weighted background tensor being larger than k in a time-like field. So, direction we said exclude the q value to be equal to q you could theoret was between zero and one, but you exclude the one value here. Is there any reason? Did you say? Is there any other reason to exclude Q value to quote? No, not really, because the, I mean, so it's a little harder to work with technically with the case q equals one. The thing that was trying to be a norm, which I strictly convexified when q was strictly less than one, becomes non-strictly convex or non-strictly concave when q is equal to one, and it's harder to work with the smooth limit. But you could still do it by approximation. And so Monino and Sur actually had a version of this as well, and they went a little bit further than I did because they were also able to say what it meant to have a reach upper bound. And so in this non-smooth setting, and so, which in the smooth setting gave you a weak solution concept for the Einstein field equations. And I should say another open question is. One question is: Does this thing depend on Q at all? And in the positive signature case, the answer is no. And I have a student that's working hopefully on that negative signature signature case. And here I reproduced a picture from Sadhu Malani's book that shows that a non-negative reaching curve, we should turn it on its side to do relativity, because this should be the time direction. If you have two, a uniform distribution of gas at time zero and gas one, time one, if you're reaching non-negative, the gas can be more spreading. The gas can be more spread out than negative. And you can detect that using this L log L kind of entropy. So it's also, you don't need to use L log L, you can also use these power log kind of entropies. And so you can make other definitions of time-like reach curvature for parameters K and N. And in the Q essentially time-like non-branching case, Matthias has explored this and showed that these other definitions are mostly equivalent to the original one. Are mostly equivalent to the original one, and even there are a few cases that haven't shown the equivalent yet, but I think that's in progress. One of the OVIC problems that Tablight highlighted was can you give some kind of synthetic formulation of the null energy condition? I guess there are good reasons physically, since this guy is satisfied by all known forms of matter, I mean, at least in the classical non-quantum setting. And also, this is sort of the key hypothesis in the pen. Of the key hypothesis in the Penrose singularity, which predicts stellar collapse, unlike the Hawking singularity, which predicts Big Bang. And so, let me sort of, I spent far too long on this problem before realizing that the answer was really in the smooth setting. So, here's a theorem about the smooth setting. I formulated it for the background tensor, but if you don't like the background tensor, you can take B to be zero. So, I want to know, actually, I'm not really going to address the null energy. Not really going to address the null energy condition. I'm going to address the null convergence condition because I'm going to make statement of the Ricci tensor rather than the stress-energy tensor. But if you are willing to assume that we're in general relativity, then it amounts to the same thing because the cosmological constant and scalar picture turns damage in all directions. So my reach to tensor is non-negative in all directions, if and only if, on every compact subdomain of one manifold, my reach to tensor is non-negative in time-like directions, or not non-negative, sorry. Directions, or but not negative, sorry. My region tensor has a lower bound in time-like directions, but the lower bound can get worse and worse as the compact select domain x gets larger and larger. So, this is some equivalence to be proved in the smooth setting, and once you have this equivalent, by the way, this is a very general thing that it doesn't actually care whether I'm dealing with the Ricci tensor or any other symmetric two tensor. But it applies equally well to the background Reachy tensor. And so, this once you have this equivalence between So, once you have this equivalence between null convergence and time-like convergence, since you have a synthetic definition of time-like convergence, you could use it to have a synthetic definition of null. So, the synthetic energy condition that I wanted to propose is that you fix these parameter values. You can only, in the null directions, you can't talk about the size of the reach curve. You can only talk about the sign parameter. So, we don't want to have a curvature parameter, we still have a dimension, a synthetic dimension thing there. And I'm going to say the metric measure space-time. And I'm going to say the metric measure space-time satisfies the weak field convergence condition with mentioned parameter n, given only at each compact subset, and it's a bound such that the causal hull of that compact subset is, let's say, weekly. You can do weekly, strongly, whatever you like, times that curvature dimension parameter with some k and n where the k depends on the subset. And I know I'm running out of time overtime, actually. I know I'm running out of time. I've run overtime, actually. Sorry. So I'm basically at the end of the talk, but what do I want to say? So I want to say that this null energy condition is equivalent to a variable lower bound of the time-like region curvature, and consistency of the null case now follows from the consistency we already had in the time-like case. And the equivalence of these different possible definitions using the power law entropy and the L-law entropy in the null case follows from the equivalence of the timelike case. And all of the nice Case and all the nice consequences of the time-like curvature-dimension conditions get inherited by the null curvature-dimension condition, except for this variable curvature. And here's a nice open problem that I wanted to highlight, although actually we're going to hear from Kristen Kenerer tomorrow that there's, in the smooth setting, there's a little bit of progress on this problem. But it's natural to wonder if the Penrose singularity theorem can hold in the spot-smooth setting as well if we're going to do it very quickly. And on the other hand, And on the other hand, stability looks kind of hopeless because unless you're willing to assume some uniformity along the sequence of the variable lower bound k, it's pretty easy to imagine having a sequence of smooth manifolds which have lower time-like bounds, but the lower time-like bound is getting more and more negative. All of them satisfy the null energy condition, but in the limit. Don't y I don't expect to have a lower time-like bound anymore, and so the null energy condition by the equivalence of the theorem is a quote whole limit. Equivalence of the theorem is a great holding thing. So, thank you very much. Here's a few of the references.