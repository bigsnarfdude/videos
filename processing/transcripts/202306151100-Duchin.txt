Talk about a maybe surprising way that my pure math interests ended up getting used in this modeling work, but the maybe the more surprising to me piece was the other direction, the flow the other way. Like really, I think interesting pure math questions being suggested by the modeling work. Okay, so let me try to get my screen sharing going. Screen sharing going. And okay, do you all see that full screen? Great. Yes. Excellent. So I am delighted to be here for Misha Fest and sorry that I can't be with you in person. And what I want to do is, as I said, talk about this kind of surprising flow two-way. About this kind of surprising flow, two ways from a set of pure math interests that I had the great fortune to talk about with Misha during three years as a postdoc in Davis, and then a way that they ended up getting used for this kind of democracy modeling problem. Okay, so first, just let's start out with the pure math side. So, Misha and I share many interests, and some of them are in the overlap of geometry and dynamics. And so, for instance, And so, for instance, we like to think about Teichmüller space, a kind of moduli space of geometries on a topological surface. So, you can put different kinds of metrics down, maybe hyperbolic ones, maybe flat ones, and you want some organizing space to understand how they relate and how they fit together. So, here's a wonderful animation made by Indira Chatterjee that shows kind of a theme in this area where you can use curves to think. Curves to think about surfaces in creative ways. What she's doing in this picture is cutting open a surface along some curves and then spreading it out flat, sort of indicating, at least in cartoon form, how you can go back and forth between hyperbolic and flat geometries. So I was interested in, so my dissertation problem was about this question. What's the long-term trend when you follow a sequence of random twists? So this is a random walk by the mapping class. Walk on by the mapping class group in Tech Muller space. So maybe you have some hygienist surface and you start doing random Dane twists and you do them for a long time and you try to understand how you move around in Teichmüller space. And the nice answer turns out to be that you follow a Tech Muller geodesic, which is to say it's like an affine deformation in flat coordinates. And that may be surprising, but that turns out to be part of a big theme of different. Part of a big theme of different kinds of dynamical theorems you can prove for these sorts of group actions. Okay, so I wanted to draw a connection from this world of ideas to the other. And one way to see that connection is the use of discrete tools, which happens all the time here in Teichmuller land. But so very frequently, you'll try to come up with an appropriate graph or complex that encodes some structure. That encodes some structure and some elementary moves on the structure. So, the curve graph, the pants graph, the marking graph. Let's think, for instance, about markings. What can you do to markings? So you have maybe a system of curves on the surface, and you can have elementary moves where you twist around a marking or you swap two curves. And then you're sort of navigating around this graph or complex by making these elementary moves for a long time. And if you get lucky, there's a distance formula associated to that. Distance formula associated to that model. So, some way of working with the count of how many elementary moves you have to make is a proxy for some kind of distance you wanted to study in the first place in the continuous setting. Okay, so that's a kind of framing for some ways of thinking that are going to carry over here. Okay, so a new setting for random walks having nothing to do with type molar, as far as I know, is to analyze maps. So, I have been very interested. Um, so I have been very interested for the last few years in graphs coming from geography. So, what do you do? You have some map, and we want to discretize. So, we're going to start with geographical atoms. So, we're going to start with little pieces that tile maybe a state or a city. And we can use ones that come from the Census Bureau, or we can use ones that come from the government, or we can make up our own, but we have some tiling. And then I'm really interested in understanding the graphs dual. Really interested in understanding the graphs dual to those tilings. Okay, so what do I mean by that? I mean we're going to put down a vertex for each tile and an edge for adjacency, so it's the usual thing. This is the kind of map graph that like the four color theorem can be phrased in terms of. Okay, and then why is that interesting for redistricting and kind of elections? Because you can do this to a piece of the country. Country. Here's the whole US, and this is the actual dual graph on what are called census tracts. And then you can assign those to districts. So this is an actual image of the congressional districts that sent members to the House of Representatives circa late fall 2019. And you have to kind of be that specific about the vintage of a map like this because lawsuits means that it changes all the time. This changed the next month. Changes all the time. This changed the next month, if I recall. Okay, so you put those together and you get an assignment of the nodes of a graph to these pieces called districts with some conditions on it, like you want them to have equal population. You want the districts to be connected. So I want them to induce connected subgraphs here. And then I want to understand all the ways to do it or see if I can kind of get a sense of exploring all the ways to do it. Okay. Also, feel free to do that. Okay, also feel free to ask questions, anybody at any point, and I'll try to notice when hands go up or when you interrupt me. Okay, so this is the problem. And how is this electoral? Again, we're going to do the same thing on every state, every city and county, and so on. We do this all the time in the US. We cut things up and vote in the pieces. And in the US, we tend to have the pieces elect a single person. That's what single-member district means. That's what a single-member district means. It means the district elects just one member to a governing body. And we have plurality elections, sometimes called first-past-the-post. So, whoever gets more votes wins. And the problem is you have to wonder whether you can draw the lines adversarially to get lots of disadvantage for the other side, advantage for your side. That's the gerrymandering problem. Okay, so just a cartoon of some gerrymandering. This is the worry that if you. And this is the worry that if you know where people live and how they like to vote, then you can bucket them in different ways to get your favorite outcome. Right. And so people like to say the problem here is the politicians choosing their voters rather than the voters choosing their representatives. Okay. So what I want to do is set up a Markov chain, is set up a notion of an elementary move on districting plans. And then I'm going to run that Markov chain for a long time. And I'm going to hope. Long time, and I'm going to hope that, unlike those random walks in Tychmoar space, I'm going to hope it's not just running off forever along a single highway, but that it's in fact exploring effectively. And I'll try to use this random walk to explore and to get a sense of the possibilities. Okay, so the main mechanism for doing that is spanning trees. And here's why. So spanning trees, so on top Why. So, spanning tree. So, on top you have that geography dual graph, and on the bottom, you have a spanning tree. So, a spanning tree is a tree, a cycle-free subgraph. And what makes it spanning is that it contains all the vertices. And you can think about this as like a skeleton of the network. And what it's good for in this context is that you have control over the number of pieces that you get when you. That you get when you cut a spanning tree. So, just a quick observation: if you look at that tree on the bottom, if you were to delete a vertex, like that one that's roughly in the middle, because the vertex has degree three, you'd split the graph into three components. And so, of course, depending on the degree distribution, vertex deletion isn't a good way to control the number of components that you have. But edge deletion is different. When you delete an edge from a graph, it gives you exactly two connected components. Two connected components. And so that's a kind of recipe here. If I want to cut this entire graph into four pieces, I need to judiciously select three edges to remove, and that's guaranteed to give me the right number of pieces. Okay, so this is going to be my strategy for walking around in the space of graph partitions. All right, so here's how this works out. So on the left is kind of the first thing that might come to mind if you were if someone handed you a distribution. Mind if you were, if someone handed you a districting plan and you wanted to mutate it, make a sequence of moves, you might think of taking each single node and changing its assignment one at a time. So we can call that a flip move. But the problem is it's just very hard to change an assignment with flip moves while maintaining the connectedness of the pieces. So, if you look at these districts, they started out these long vertical stripes, and it's very Stripes. And it's very hard to change those because you can't reassign a vertex in the middle without disconnecting the district. So you have to sort of nibble away at the edges. And even after a long time, it doesn't really forget that it started out long and skinny. But on the right is this recombination chain that I've been working on for a while. Elle Knight is a graduate student who came up with sort of the tree idea in the first place. And Daryl DeFord and Justin Solomon are some of my collaborators on this. And what's the idea? And what's the idea? At every step, you fuse two districts, you draw a spanning tree of the fusion, and then you cut that tree to two new districts. So you're like merging and then splitting a new way, a pair of districts at every move. And I hope you can see in the movie playing on the right, this is very powerful. And so, one way to think about this is that we're building a different complex here to study the state space of partitions, one with lots. Of partitions, one with lots more elementary moves that can connect things that would have taken many, many flips, right? So it's sort of like turbo-charged Markov chain for mutating these graph partitions. Is that good? Anybody have questions about that? Okay, so it works really well. Here it is running on Pennsylvania, which is what I had on the title slide. And it very quickly obliterates the boundary between any two. The boundary between any two districts and gives you something totally new. So it's a pretty good way of sampling districting plans. And I'll just mention while this is running, like this has turned out to be surprisingly impactful. So some of you might have followed this big Supreme Court decision last week in the state of Alabama, where the question was one of racial fairness for Alabama congressional districts. But if you actually go back and read that decision, very much of it is about. Very much of it is about this, which is sort of remarkable and surprising. That the reason this is taken by many of the justices to be relevant to the question of what's fair is that for years, like I guess it's going on 100 years, since the 1930s, the justices have wondered: well, if gerrymandering is where you try to take a lot of extreme advantage, what would it look like if you didn't? If you just followed kind of a neutral process, what would normal Process, what would normal look like? And that's sometimes called the baseline problem. And they've been searching for a way in U.S. law to solve the baseline problem for all this time. And many of the justices, when it suits their political agenda, think this is just a groovy way to study like not gerrymandering. Okay, so I could talk more about that and what they think about Markov chains if you're interested. But let's go back to the math. So, um, Math. So, to make this process work, so here's the promised like turn in this talk where starting with pure math, I got interested in this applied problem, but now I'm going to try to convince you that the applied problem gives back to the pure math brain. Okay, so to make this protocol work, to make this algorithm work, we need a way to generate random trees. Once I've fused two districts, I need a random tree, spanning tree that I'm going to cut. How might I do that? So, here's a very kind of mathematical. A very kind of mathematically, I guess this is natural. First thing you might think: give me a graph, I'll just make all possible spanning trees equally likely. So I have my graph there circled in gray, and here are all of its eight possible spanning trees, and just give them each probability an eighth. And that is a random, that is a probability distribution on spanning trees, and I can sample from it. But of course, this is massively impractical for large graphs. You don't want to generate. We don't want to generate all the trees. There are a lot. Still, this gives us an idea of one possible probability distribution on trees. Just make them all equally like. Okay, here's the second thing that you could do, which comes from the 1990s. It's called Wilson's algorithm, and it's also very nice. You have a graph, randomly, uniformly designate a start vertex and a stop vertex, and do a random walk, simple random walk on the graph from the start vertex. And if you ever From the start vertex, and if you ever make a loop, erase it and then continue and keep going until you hit your target vertex. And when you do that, take that whole path and add it to the tree, and then iterate by starting with some other vertex and random walking erasing loops until you hit the path. Add it and iterate. Make sense? So, by construction, this has to give you a spanning tree. And the surprise is that it's pretty fast. This sounds slow. Is that it's pretty fast? This sounds slow to me, wandering around aimlessly and hoping that you eventually construct a nice tree. Not obvious that this would be doable in reasonable time, but actually you can run this in polynomial time. It's quite nice. What isn't obvious still, I think, is what distribution this induces on spanning trees. Are they all equally likely, like the uniform distribution that we just talked about? Or does this make some trees more likely than others? And what are the properties of which trees are other? The properties of which trees are upweighted. Not obvious, in my opinion. Okay, here's a third thing you can do that I also think is a very beautiful idea. I learned about the mathematics of this from a talk by Cynthia Vinzent, who's a mathematician in Washington. But there's a whole team of, this is a very popular area in computer science to study these. So what we can do is what I'll call the down-up or the up-down tree walk. And here's what I mean. Here's a graph. And here's what I mean. Here's a graph. It's a complete graph on five vertices. And I can start with any spanning tree and then randomly add an edge that wasn't present. This creates a loop. Now I can take that loop and uniformly randomly delete an edge from the loop, giving me a new tree. And so make a cycle, break a cycle, make a cycle, break a cycle. And this constitutes, if I take it at every other time step, a random walk on spanning trees. Okay, so that's what I'm going to. Okay, so that's what I'm going to call up down because we added an edge and then took one away. But I could just the same do down up, start with a tree, delete an edge to make two trees. Now you have a forest with two components, and then add a connecting edge between the two components, and that's the down-up law. So you could do either one of these. The nice thing is, this is very fast process to do, but it's not clear. So this is actually a Markov chain on trees. It's not clear what its steady state is going to. Clear what its steady state is going to, and I think it's not obvious, that it's going to have a nice steady state, that it's going to get there quickly, what that steady state is. So, this is some other way of randomizing trees so far. Okay, and then I'll just mention a fourth, which is actually the most ubiquitous in computer science because it's so, so fast. So, this is Kruskals or similar kind of Kruskal-like algorithms that use weights. So, this is super easy. I just put numerical weights on all. Numerical weights on all the edges drawn from some distribution. Maybe I draw them all IID from like zero to one, or maybe I use some other distribution on the edges. As long as I draw independently, I'm going to think of this as a product measure. I have a measure on every edge, and then I draw independently. As soon as I have weights, I just greedily pick the minimum weight tree. So this is why this is called MST for minimum spanning trees. So in this case, I take the 116 because it's the smallest, then I take 208. It's the smallest, then I take 208. I try to take 343, but it's blocked because it would form a cycle. So I take 532 and I'm done. No, I have a spanning tree. Okay, so this is super fast. All you really need to know here is the order that the edges are in, like the magnitudes don't matter, just the order that these weights fall in is enough. And then you kind of greedily go from bottom to top and try to keep going until you get a tree. Okay, so how do these all compare? So our priority. All compare? So, a priori, these could be drawing from four different distributions on spanning trees. But the cool thing is that actually three of these are the same, not obvious. The uniform tree is what the loop erase random walk is doing, which sort of is what down up is doing, it turns out. And here's what I mean a little bit more precisely: that loop erase random walk, Wilson's algorithm, samples exactly uniformly. This is striking to me. It's not just approximate. Striking to me. It's not just approximate, it's exactly picking every tree with equal probability. And like I said before, it does that in polynomial time. So that's pretty cool. You can do that fast. It's obviously far, far better than trying to generate all the trees in the first place. But even blazingly faster is this down-up or up-down random walk. It turns out to be rapid mixing, which just means the mixing time is polynomial in the size of the problem. And the size of the problem. So it's rapid mixing on spanning trees for any graphs with uniform distribution on trees as its steady state. That's also very cool. And so that's an area, as I said, in theoretical computer science that's really popular right now. People are trying to understand the matroid structure here and mine it for fast chains, fast Markov chains. But MST is different. I don't know. The first time you think about it, this might surprise you. The first time you think about it, this might surprise you because, especially if I'm drawing IID weights for the edges, why should some trees be more likely than others? But they are. And one way that you can see that is that greedy trees, the ones that come from this MST process, are known to be bushier. Let me kind of spell out a little bit what I mean by bushier here. So when I started getting interested in this, because I needed fast tree algorithms to do this registering thing. Register team thing. I looked around and I asked the people I could think of who were experts and they referred me to other experts. And I just asked everyone I could find: what are the known quantitative theorems that distinguish MST from UST, that say something different about the kind of trees you see under MST and UST? And people pointed me to one paper. I only know of one paper on this in the literature. If anyone here at this talk knows more stuff, tell me. I'm very interested in this area now. I'm very interested in this area now. So, here's the one theorem, and it's very cool. It's a classic result of Erdős and collaborators that if you start with a complete graph and you make all spanning trees equally likely, i.e. UST, then the expected diameter of that spanning tree, that is classically known. So let's think about that for a second. The smallest diameter tree possible in a complete graph is a star or one vertex. Is a star where one vertex is connected to all the others, and that's got diameter two. The largest diameter possible is a path that hits all the vertices, so that's got diameter n minus one. So all spanning trees have diameter between two and n minus one. What's the expectation as n gets large? So Erdős and Crew showed that the answer is square root of n. And some of the best theorems I know in that direction, Fan Chung and co-authors from the Circuit Theory. Co-authors from the circa the year 2000 prove really, really sharp versions of that. If you know something about the spectral gap of a graph, then you know a lot about the concentration of spanning trees around diameter square root of n. Okay, but then there's a paper, the only paper that folks pointed me to that shows a way in which minimum spanning trees are different is a paper by Luigi Adario-Berry and co-authors, which shows that for MST, the diameter For MST, the diameter is smaller. In particular, it's not square root of n, it's cube root of n. It's a very cool result, I think, and a little bit surprising. Okay, so what does that mean? Lower diameter means it's more star-like. So you're going to have a different degree distribution. You're going to tend to see higher degree. That's what I mean by bushier. Make sense? Okay. So let me just show you in one little toy example here. Little toy example here, the square or the diagonal, we'll just sort of do a calculation. And by actually writing it all out, what we can see is that MST, or you're choosing IID weights, would give these four spanning trees the collective weight 8 15ths and these four the collective weight 7 15ths. So you can see that it's not uniform. It just misses being uniform. The other thing to notice about this example is that most of these trees are paths, but two of them are stars, and they're in the overweighted Stars, and they're in the overweighted group. So you start to see hints of the fact that minimum spanning trees prefer high-degree bushy things. Okay. So how does this get used in the problem of trying to sample graph partitions? Well, this recombination algorithm I showed you before, where you fuse things, make a spanning tree, split the spanning tree, and iterate. You can use that modularly. You can pick your favorite tree randomization. Pick your favorite tree randomization method. You can choose any way that you want to fuse pairs. You can make various choices, and those all kind of fit into a family of Markov chains. And a good question that you might wonder is just the same way that we looked at for these, like the up-down random walk on spanning trees, a natural question was, what's its long-term behavior? What's its steady state? You can ask the same question here. If you do this recombination procedure a lot, what kinds of graph partitions does What kinds of graph partitions does it tend to favor? And so the answer is that approximately, no matter what you sub in for the, well, no matter what reasonable thing you sub in for the tree algorithm and the pair selection, you'll approximately be drawing from the spanning tree distribution, meaning the probability of seeing any particular partition is proportional to the product over the districts of the number of spanning trees of each district. This is a pretty nice distribution to target. Distribution to target because what it's going to do is it's going to produce districts that have a lot of interior edges, because those are going to be the ones that have a lot of spanning trees. And since there's only a fixed number of edges in the ambient graph, having lots of interior edges means you have relatively few edges between the districts, which is what's going to make them look like they have nice short boundaries. They'll be isoparametrically tame. They won't look crazy and fractal. They'll look nice, which is pretty good for this application of redistricting. Districting. If you know something about network science, this should also sound like what the networks people call small world networks or community detection, where you're looking for stuff that's really well interconnected. And that actually is pretty well applicable to this problem. Okay, and then I'll just sort of close this part by saying that it turns out, so when we started doing this, we were just content to say we approximately draw from this distribution, but now there are a couple different methods that exactly. Uh, there are a couple different methods that exactly target this distribution, so we can make a reversible Markov chain that exactly hits this distribution, which is which is quite nice. Okay, so why would you choose to use MST versus UST? Because I mean, that's supposed to be a theme of this talk is that the application to redistricting made me curious about the mathematics of MST versus UST. So it turns out to be actually quite useful in the problem. Actually, quite useful in the problem. Let me take a second to try to convince you of that. Suppose you're trying to redistrict Missouri. Here it is. It's got 300 some thousand little nodes in its graph. It's quite a, you know, census blocks are small, so it's quite a complicated graph. But not just any partition will do. I actually want one that kind of tends to respect the geographical hierarchy. In particular, it would be nice to keep counties together when possible. Now, if I just run a Markov chain partitioning the block, Just run a Markov chain partitioning the blocks, it doesn't know anything about the counties. So, somehow, I have to come up with an algorithmic way, I have to come up with a kind of idea in the graph algorithm to respect these counties. And so here's a simple idea is I can draw the within county edges from one range of weights, and I can draw the between county edges from a higher interval of weights. If I do this, then MST, minimum spanning treat, is going to prefer the Spanning tree is going to prefer the within county edges. And so it's going to give me trees that are fairly hierarchical. They restrict to the counties as trees. And so when I cut them, they're going to tend to keep counties whole. This just works really well. So let, and it's fast. So let me just show you this working well on Texas. So Texas has a lot of counties. Here they are in this picture. And what I'm showing you now in these colored images is two different heat maps that show. Two different heat maps that show what happens if I take, I think this is a million steps of the Markov chain that randomly fuses, you know, randomizes district assignments. This is a heat map showing you how often each precinct is reassigned. So the yellow things get reassigned a lot. They get flipped from district to district a lot. And a Markov chain, if it's trying to run it to convergence, it shouldn't really matter where you started. You should quickly, again, lose the memory of your starting point. Again, lose the memory of your starting point and converge towards this nice distribution. So, here I'm just showing you that from these two different starting points, I get a very similar-looking heat map of how much things are flipped. Okay, but the heat map doesn't seem to know anything about these county boundaries. And that's because in this case, I'm not doing anything to inform it about county boundaries. I'm just choosing within county and between county weights from the same interval. But in this picture, I'm slightly shifting the interval and you can. Slightly shifting the interval, and you can start to see county boundaries ever so slightly starting to be visible in the second picture. In the third picture, I make the intervals disjoint. So now the greedy protocol is going to always look for within county edges first before it tries between county edges. And now you can see those county outlines are really starting to be visible. And this suggests that the method is doing a good job of keeping counties whole. But also, I still see yellow in lots of different parts of the state. Yellow in lots of different parts of the state. Things are changing everywhere. And then, just to make a kind of polemical point, let me compare this: like, other folks who are doing kind of random districting maybe have other methods that might be problematic sometimes for taking the like English natural language preferences, like try to keep counties whole and like making your algorithm do that. So, for instance, I spent a long time trying to understand what another Long time trying to understand what another author was doing to keep counties whole. And when I did this same forensic on the other guy's stuff, it looked like this. In other words, what you'll notice in the bottom images is the runs with this other method were just too strict in their county preservation. And so most of the state just never changed at all. That's the dark blue is never changing at all. And not only that, but you'll notice for the first time, the two columns are different. So that suggests that if you're not careful. So, that suggests that if you're not careful about promoting county preservation, you can disconnect the whole state space. And then, even if you run a chain for a long time, there's, of course, no guarantee that you'll see the same thing over time. Okay. So just, this is just a little ad that, you know, this idea about the MST distribution actually turned out to be useful. Okay, I see I'm out of time. So let me just end. There's tons of active questions that you can ask here that are good questions. And one is, Good questions. And one is: what is the MST probability of seeing different kinds of trees? And so I've been working with a number of people, including Davis colleague Eric Babson, on trying to think about that. And we've got some interesting, fun results. So how bushy is MST? It actually likes stars best is one thing that we can prove. It's a fun question to try to understand when MST and UST coincide or can be made to coincide. Another nice question is to think about kind of pushing. Question is to think about kind of pushing the idea of intransitive dice a little further. What distributions on permutations can you hit with product measures? And in particular, can you get UST from MST? Can you kind of design your measures on the edges so that you can actually hit the uniform distribution? So I had originally conjectured that you can't, but I had to modify that conjecture to say you can't for K5 and up because one of the And up because one of our collaborators found a cool example on K4. So I'll just show you that in this picture. There's a way to put probability distributions on the edges of a K4 so that drawing weights from those actually makes all trees equally likely. It's a really cool construction, but we're pretty sure you can't do it on a bigger graph than this. Okay, so closing thoughts. These abstract questions, which are just appealing on a pure math level, actually have turned out to have practical impact on the problem. It would be really interesting to find a closing thought. It would be really interesting to find a closed form for the MST recombination chain. We don't even know what graphs have the most trees. I mean, there's just all kinds of basic questions here. I call this the isospanometric problem. Ask me later if you want to know exactly what I mean by that. But there's just tons of basic and open questions here that are very appealing. How likely is a tree to have a balanced cut? Stars don't have balanced cuts. So that's another kind of family of interesting questions. And finally, what kind of frontiers are And finally, what kind of frontiers are formed by this process? Like, can you describe the boundary curves that you get using maybe SLE language? Those are all like intriguing open questions. Okay, so that's the story, pure math to an applied problem and back to pure math. And I thought it was particularly good for a day celebrating Misha, who's within math, really a true polymath, someone who knows a lot about a lot of different kinds of problems and has an extremely creative approach to mixing and matching. Creative approach to mixing and matching. So, thanks, everyone. Great. Thank you. Were there any questions right now? Moon, I have a question. So who was responsible for proving that three models give the same outcome and what tools did they use? Were these geometric tools in any way or just kinetic? Yeah. So Wilson proved that Wilson's algorithm is unique. Wilson proved that Wilson's algorithm is uniform. That was a big deal paper. The shortest and most beautiful explanation I've seen is by Yuval Vigder Sin, and you can find it on his webpage. It's super nice. It would take me about one minute to explain and not more, but I don't think we have a minute now, but ask me later. It's really nice. Vincent and her co-authors proved that the up, down, down, up has UST as a steady state. Is a steady state. And they just because so spanning trees are like the second prototypical example of a matroid, I think. The first example being linearly independent vectors. So they proved some very broad theorems on matroids, which immediately give you consequences for spanning trees or like linearly independent vectors and for everything else that's a matroid. So they have this just hugely powerful framework. Just hugely powerful framework of Markov chain methods for Matroids that just instantly gives you all this powerful stuff on spanning trees. And that's recent. That's the last five years. It's like surprising that such fundamental stuff is so recent, I think. So it's not a geometric argument, but at least not on the face of it. I was wondering if there is a, I mean, in my mind, whenever some In my mind, whenever some coincidences happen, there is negative curvature responsible for these coincidences. So it is just some, you know, random walk trails, geodesic, under some reasonable negative curvature assumptions. Something like this. Yeah, or non-positive, right? That's all you need. For non-positive, that's right. That's right. So you need very mild assumptions. And again, there is a non-positive curvature there somewhere in this problem. So. In this problem. So, one question is: besides the determination that the terminal distributions are the same, maybe the trajectories also, I'm not saying that they fellow travel, but maybe it's like in Khamenovich's theorem, they diverge at most. So, something along those lines. Again, that would be just, I mean, just a completely random suggestion that there might be a really interesting. It's a really interesting question. I have thought about a related question in the same spirit, which is: we're doing this recombination walk on the space of partitions. And so if I knew something about the curvature of the space of partitions, right, then I'd know something about how that walk explores. And so I've done a bunch of curvature calculations on the like parts of that graph that I can build out. And that would be fun to talk about too. So I'd love to follow up with you. Be fun to talk about too, so I'd love to follow up with you. Maybe we can schedule time, yeah. Maybe some out some time. Yeah, that sounds great. Okay, okay. But again, my guess is that there is actually not just grab but complex where you start to see negative curvature, but whatever. So maybe we'll talk some other time. We'll talk, yeah. Cool. Anybody else have a thing? Hi, I was, I was wondering, it seems like the demand that everybody The demand that everyone has is connectedness. Are there other topological demands that everyone wants before they start talking about like compactness, geometric properties? Oh, funny story. Districts don't even have to be simply connected. Texas's legislature put one district completely inside another this time. It's not, it's not just in principle possible, like they voted on that on in that donut district. So, yeah, no, um, and even. Know. And even by the way, connectedness is a little subtler than it sounds because while the Census Bureau releases the graph of what the tiling is, they don't tell you what's next to what. And this is a little subtler than it sounds like it should be. So, actually, one of my like persuasion campaigns, and I have a few right now, is to try to convince the Census Bureau to release the dual graphs, like canonical dual graphs. Graphs like canonical dual graphs, it would actually really help in this space. Do they do they necessarily okay? That's a that's a geometry question, right? Like, where exactly is the boundary? That's a topology question. What's the connection topology, right? Yeah, we can parse out the words how we want, but yeah, um, sure. Um, in terms of what's called compactness, so they use the word compactness in redistricting and they Compactness and redistricting. And they don't even have, like, you know, subcovers in mind somehow when they say compactness. No, what they mean by compactness is like nice shapes. And usually what they mean by nice shapes is isoparametrically nice. Well, actually, what they mean is doesn't make your eyes bleed, but right when they are forced to put a score to it, they mean you compare the length of the boundary to the area. And this is a terrible thing to do on real maps because of coastline problems and what have you. So we So, we've been trying to get some discrete shape scores into the literature. So, that's geometry. And I think we're making some headway on that. Actually, I mean, the Supreme Court decision last week was just a huge surprise. I fell out of my chair three times. And then I read the decision and saw that all the lovely things Clarence Thomas has to say about my work, really funny. But the surprise is that the Supreme Court has really endorsed my approach to compassion. Has really endorsed like my approach to compactness. So, hey, you know, there you go. So, apparently, you know, this idea that scissors complexity is a good way that gets you out of kind of coastline problems. It seems to be catching on, which is one small piece of progress, I think, in this domain. But yeah, yeah, no, both the geometry and topology are surprisingly fuzzy. But what isn't the case, what a lot of mathematicians and OR people who start working on this. And OR people who start working on this think is the case is that if you can just find an optimization that produces the nicest shaped districts, you win. And this just turns out not to be true. Cool. All right. Well, it's nice to see so many familiar faces, at least your static photos on your little Zoom boxes. So I'm glad to be able to join you. Glad to be able to join you and celebrate Misha. Yeah. Thank you, Moon. Okay, so in about 21 minutes on the hour, we oh, let's thank Moon again. Yes. In what? Yes, 21 minutes.