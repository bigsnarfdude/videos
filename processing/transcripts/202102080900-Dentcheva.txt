The topic that I would wish to present. This is a new approach to stochastic optimization problems, especially to multi-stage stochastic optimization in a more general setting. It is a joint work with Andre Rushinsky. And I will introduce a couple of I will introduce a couple of notions that will help me to formulate the optimality conditions for multistage stochastic optimization problems in the two formulations that are known. One in which the non-anticipativity is built in, and one in which we have explicit constraint on it. So we can consider this problem setting, which is quite general. And we have set the problem so that the multi-stage stochastic optimization problems fit in this formulation, but it is more general than this one. Uh, than this one. It probably can be used also for other settings. Um, so the main issue is that we have decisions in the space of random variables with a finite p-moment. So, if you think about multistage problems, if you consider the decision throughout the entire I would the entire time horizon as a policy. It is indeed fits this setting. The objective function is a general function that we consider continuous in the space, in the LP space. Evan Lipschitz continuous. It is designed in mind to accommodate for risk management. Accommodate for risk measures. So the constraints are given by a non-linear operator from the decision space X. So do you see my cursor if I show this way? Is it visible? I'm sorry, no, we can't see the cursor. Cursive. Oh, you cannot see. Okay, so. Um, there's the time. Um, okay, so this is unfortunate, but I don't know how to correct that. Uh, so maybe if I switch to another browser, maybe it will be better. Uh, it shows the community. It shows the cursor shows, but it's very small. Uh-huh. Yeah, we can see it. It's only X. Yeah. Ah, okay. Okay. Okay, still better. Okay, so the idea of this non-linear operator is to encompass the dynamic. And actually, we want to allow for non-linear dynamics. So if you are familiar with multistage problems, so far, all the theory actually is focused. The theory actually is focused on linear dynamics, and we would like to have a more general possibility. So we formulate the dynamic constraints as the values of this non-linear operator to be contained in a random set Y. So we adopt the possibility. So we adopted the point of view that the random sets are actually the slight difference between saying random set and multifunction from the probability space to Rm which is visible or manifests itself in the difference of measurability but I'll use the no I'll I'll use the term random set because it's a little Use the term random set because it's a little bit more intuitive. So, one can think of this as for this operator maps our decisions from the LP space to a random set. Okay, so which is has such a realization scenario. And additionally, we have other constraints which are. Other constraints, which are also sure constraints on the decision X. Of course, we can incorporate these two in one and just extend operator F to incorporate also this identity with X and have these two sets. But we would like to distinguish between them because we want to consider special non-linear operators that Non-linear operators that are just describing the dynamics. And the final constraint is that X belongs to a subspace. This is to accommodate the requirement of non-anticipativity. So we shall have a subspace which will be the space of non-anticipative decisions. So, as I mentioned, we would like to have the operator F describing the dynamics and that is why we shall have it in such a way that for every x, okay, for omega is the specific realization, it will be defined through another function, little f, that takes this realization. It can be random by itself. Okay, so it's a random function that it This random function that depends on x through the realization of x for the same simple event. So a couple of notions that we need, okay. So we show to formulate optimality conditions, obviously we need to deal with the tangent cone and with the normal cone of a visible set at the given point. So for a tangent cone, we show So for a tangent cone we shall use the contingent cone for the closed set. I have repeated here the definition just for a refresher. This is the Limps soup of the set A minus the point X and divided by T. So differential quotient when T goes to zero in a set-valued sense that this would be the Limps so called the other way written through the distance is this. and through the distances this formulation. And we shall deal only with sets that are derivable, which means that actually we have a limit, so not only linear, we don't consider the limiting of the distance, but we have a limit of the distance when for this differential function. Okay, so when Okay, so when the when you consider Lim soup in terms of set convergence, then the Lim soup will be equal to the Limin of the respective differential portion A minus X divided by tau. So another stick Another stipulation that we shall have is that the sets that we shall consider, like the sets X on the previous slide, what dimensions, okay, so this will be such a multi-function so this set X and Y are decomposable sets. So this means that they are representable. They are representable as such all measurable selections from such a measurable multifunction with the capital K. So, for example, if you have a constraint X belongs to the non-negative Belongs to the non-negative order. Okay, this is a simple one. It means as x omega is in the non-negative order and almost surely this would be at the composable set. And for the composable set that are derivable and each realization of the set is the closed for almost all omega. We know that their tangent cone is also the composable set. So it also can be represented in such a way that for every tangent direction V, for example, here, okay, for every tangent direction, if you consider a particular If you consider a particular omega, a particular realization, so the realization of this direction is in the tension cone to the realization of the set X, A, at the point X. And these are all the realizations for the same moment. So it is the composite of pretty nice. Observation, not always an easy one, but it is very useful because then you can deal with the finite dimensional sets and finite dimensional cones. And similarly, if you look at the so we need the normal cone, right to the set in order to formulate optimality conditions. So if we look at polar cones, they Then, if we have the composable cone which is convex, then the polar cone is also convex, the composable cone. So each realization is a polar to the corresponding. Corresponding realization of the concern. So, this is also not too difficult to observe. Now, one of the main notions that we shall deal is that there is a sub-regular multifunction. So, we shall consider just a specific setting in which we take a multifunction between Take a multi-function between two so x is the L P space and y can be a general Banach space, but in our case, this would be always the L P space also. And we consider the inclusion zero belongs to particular image of this mode function. Then we go this. We call these multifunctions the regular at the particular point, okay, x hat, which satisfies the inclusion. If you can identify a neighborhood around this X hat and a constant C, positive obviously, so that they That one can correct for every point which is near x hat for every x, we can find the close by a point that satisfies the inclusion. And it is and there is such an error bound. So the distance between the point x, which we pick, and this nice point can be measured by Can be measured by the violation of the inclusion at the point x, which would be right. So the distance from zero to this n of x. So if we have a particular, so since we are interested in such inclusions, f of x belongs to Belongs to y. So we can consider the multifunction to be the difference between x and y. And we deal with y as the LP space. If the operator is Lipschitz continuous and y is close convex set, then sub-regularities can be written. Can be written in this way, which is familiar, and is equivalent to the notion of calmness, which also was defined much earlier as upper lip sheet property. So this is, it is known that subregularities used in optimization is a little bit different here than what we usually. Usually, it has a subregularity, and it is known that one can use this notion to derive the existence of Lord Range multipliers. So, it was very fruitful also for us. So, now let's investigate a little bit the operator that describes the dynamic. So, we call it the Causal operator. Council operator following the notion in this in deterministic systems. So, what does it mean? So, in multi-stage problems, we have a filtration. So, at the beginning, we just know everything. So, the trivial filtration, and then you have the finest at the end. The finest at the end sigma algebra. And okay, so this is a usual notation. We consider the spaces of random variables that are with finite p-moments that are measurable at the time t. And same is with y. And so the space x in our X in our original formulation is the product of all this Xt. So from the beginning to the end of the temporizing capital T. And the space Y is also the same way. And in the intermediate times, we consider the spaces which are product until little t. So X from 1 to little t is the product of all X's with X's with indices y to little t 1 2 2 and 2 little t. The same, this is if you are familiar with multi-stage problems, this is a usual notation. So for decisions until time t, so you have a sub vector here, x1 to x little t. Uh, x little t. So, this is the notation. So, we now we show code operator Causal if we have a measurable function ft for every t for every t we have such a function that it is the value of the operator Depends on the decisions until time t. And of course, this can be random. So you take omega and this f as usually can be a random function. So this just is to express the fact that the information that we have. The information that we have until time key is sufficient to determine or describe the future behavior of the system given the controls that we know, which are the X's from one to T. So, this is the only well, you can say this way that it is also non-anticipatic, this operator. So we shall make some assumptions on the further structure of this operator. So the usual The usual assumptions. So maybe I say here, we say that this f is superpositionally measurable. So actually we can think of karateodori functions. So it is measurable with respect to the second argument and discontinuous with respect to the first argument. So these are superpositionally measurable. And we actually, in our assumptions, Our assumptions, the basic assumptions under which we should obtain our results, basically we assume stronger conditions than that for the function little f. So f t's are not only measurable with respect to the second argument, but they are an element of yt. And yt, if you remember, is an LT space. Remember is an LP space. Okay, so that with respect to the second argument that they are elements of YT, of course, we need that because we have the inclusion that the operator ft has to belong to, has to give you an argument, has to give you a value that belongs to a close convex set in Y. So, of course. So of course we need that a little FT provides an element of YT, of calligraphic will displace YT. Then additionally, we assume that with respect to the first argument, Ft is not only continuous, but is continuously differentiable. And also, we assume that the Jacobian has a As a mapping, okay, is bounded with the constant that depends on F, so only so under these assumptions, we can show that the Causal operator, so the The Causal operator. So, if the Causal operator satisfies these assumptions, then it is cato-differentiable, and we can obtain the derivative of this operator by looking at the derivatives of the function ft. So, f is gather. So, I think I didn't have it defined here, but Here, but okay, so f is the gathers all f for all t's, and the little f also is such a vector function that comprises the little f's for every t. So t from one to capital T so but the message is basically the causal operator is get out the branch. The causal operator is gaitot differentiable. And we can handle the derivative by looking at the Jacobian of F, okay, the derivatives of little f and their realizations for every omega. So another advantage that we have by looking at Have by looking at such operators is that we can show that if you compose a convex subdifferentiable function with such a Causal operator, then we can calculate the Clark sub-differential of the composition. The composition. So the clerk's of differential of the composition obeys the usual rule. So you have the adjoint operator of the Qato derivative, which exists by the lemma, and the subdifferential of the function rho. So in particular, if we subdifferentiate the distal function. Subdifferentiate the distance function. So, if this convex function is the distance function of f, the Causal operator, to the set Y to which it belongs, is supposed to belong in the optimization problem. Then we can describe the exact sub-differential. We can obtain explicit formula for this sub-differential by using the fact what is the that the distance, we can show the distance function is. we can show the distance function is well follows from the more general result but we can show that the distance function is class subdifferentiable and that we can obtain the description of the subdifferential which then helps us by using this penalty approach to formulate the To formulate the optimality conditions for our problems. So let's look at the multi-stage problems with the built-in non-anticipativity. So this means we, how does it fit in our general formulation? So we have objective function depends on depends on all decisions from one to capital T. This can be a non-linear function and not necessarily additive, but we assume that this is Lipschitz continuous with respect to the decisions. So then we have a causal operator belonging to the sets. To the sets yt. The causal operator, here I have repeated. Okay, so it depends on the decisions until time t and the y t is a random set at time t. So that this is the description of the dynamic. And these are local constraints. So x t belongs to It belongs to some also random sets measurable. So here we suggest another notion that will help us derive the optimality conditions. So we call we say that the system Admits as a regular recourse. So we consider this now omega by omega realization. So at this moment, for every particular omega here, we have a finite dimensional system. So for every particular omega, Particular omega. So we say that the system admits completes a regular record if basically if these little systems are sub-regular. So this means for almost surely, okay, for almost all this means again, so So if you have so here the past is separated from the current point okay because we need this depends from depends on the decisions FT depends on the decisions from one to little t to the current moment, but the current we have additional constraints for the current decision. No constraints for the current decision. This Xt is in the set capital Xt. So, therefore, in four, we have these two separated so that we can have a more specific formulation. And so then we require that for every past decisions and for every now imagine Imagine this xi is replaced by some eta, then you can find another solution that is the distance between eta and xi is bounded from above by the distance of what this eta will give you for little f, how far it is actually. How far is it actually from the set yt where it has to be and the distance between eta, the one that we substituted here psi with, how far it is from the set capital X T where Xi is supposed to be. So this distance, again, this distance is a finite dimension. Finite dimensional. So everything is here is finite dimensional in this condition. So basically, this is a sub-regular recourse means that if you look at every particular scenario at every particular time, the constraint system satisfies the subregularity condition in finite dimension. In finite dimension. Okay, so now if this is the case, so if the infinite dimensional system, so sorry, if we have a complete subregular course, then the infinite dimensional system is subregular at every feasible point. point and we can derive we can write optimality conditions necessary optimality conditions for the problem that we formulated so this is for for this problem so we talk about infinite dimensional system is given by the constraints two in three and the finite dimensionals are in four and five okay just to it's very just to it's very hard when i don't see anybody i don't i have no feedback uh what what is actually uh here understood so um the optimality conditions look similar as one would expect them so we find the subgradient in this sub the clax of differential so we would The Clarkson differential. So we work with Clark's differential. That here, this is why because we cannot derive further sufficient notion that allows us to work with the gatto differentiability only rather than first share, which is not a, we cannot handle non- That we cannot handle non-linear operators. So we find a subgradient and so normal elements now. Normal elements to the set yt at the value of the operator and normal elements to the set xt. And we also have the, so now the adjoint operator in this case, so what is the derivative of ft in the operator that gives us the dynamic? What is the derivative in this case? Okay, there's some linear operator for every key. Is this composed of Elements that correspond to x1, x2 to xt. So this is this a with double index t and 1 to capital T. And these little a's are the respective derivatives of f t for the with respect to x. Now this the could Good part is that these operators, due to our previous results about how the ghetto derivatives of the causal operator looks like. These operators can be represented by looking pointwise at the derivatives of the little function f. Of the little function f, which describes the dynamic. So we have a good control on this form of these derivatives. So in this case, this is this act A with index T L is finite dimensional. So the Finite dimension, so that a joint is just a transpose. So we just write here the transpose A. And of course, here we have to have this all brought to the to be measurable at time t with respect to the corresponding signal to brain duct filtration. This is what With filtration, this is what expectation conditional expectation with sub-index T means. Okay, so this is the projection of these operators at the time t. So, this is for the case of built-in non-anticipativity. So, now So now, if we have explicit non-anticipativity constraints, so you know that we could make all decisions anticipative. So we can make all decisions to be measurable with the finest sigma algebra by just coupling them all. Okay, so we allow. Them all. Okay, so we allow anticipative decisions formally in such a large space. So the space X now becomes a larger space because it takes always this LPs are larger spaces with the sigma algebra. There are more elements here. And We formulate the problem with respect to such decisions, but we write an explicit measurability requirement. Okay, so this non-acceptivity requirement is that Xt the conditional expectation with respect to the sigma algebra F t. So this is So, this is a familiar way of formulating optimized conditions. And this is actually the subspace that we have in the very general formulation of the problem. So This condition defines a closed subspace in the enlarged space, which then is reflected in the last, no, in the first constraint, so here actually in constraint nine in this formulation. So the objective function The objective function should also depend on and should be defined on this enlarged space. And there are various ways to define such an extension of the objective function on the enlarged space that is also Lipschitz continuous because we want to use our general results. Our general results. This is not very difficult to think about. Okay, so how to define such a Lewis continuous extension. Then the causal operator is defined also on the enlarged space by in the same formula, using the same formula as here. As here, okay, by such formula, but this will be the just the large x from one to theta, but just the different objects, okay? Formally, it looks the same, but just the objects are from a different space. So, yt and xt will be from a different space, from a larger space. Larger space, but the formulation is the same. So, sorry. So, then one can formulate the problem in this explicit non-anticipativity constraint included in a similar way. So, the council operator. has to bring values in the sets YT. The YTs are now also enlarged in this extended spaces that allow for all kinds of for which just measurable with respect to the largest, the finest sigma. The largest, the finest sigma algebra, and we have another inclusion here for x and xp. So again, if we assume that for every omega, the little system admits a complete sub-regular recourse, then the system in this enlarged space now space now included the non-recipitivity constraints, the whole system from 9 to 11. So this system in the infinite dimensional space is regular for any feasible point. And now we can formulate the optimality conditions. We can obtain Subgradians and Lagrange multipliers and normal elements so that again we have the usual optimality conditions that we would expect. So you have a subgradient, again, a clark subgradient from the objective function and you uh and we have this uh no uh these multipliers are to belong to the um so they are associated with the non-anticipativity constraint with constraint nine then we have this term is associated with the causal operator as before and these normal terms are And these normal terms are associated with the last constraint for that Xt is in the set Xt. For the non-ancipitity constraint, we have additional this constraint that the conditional expectation of this lambda t is this dual object that this conditional expectation is zero. This is no no. This is known also from the linear systems when we have the corresponding formulation for the linear systems. This condition is satisfied, but here is satisfied as well. And also, we can derive a connection between the two between the two formulas. Between the two formulations. So now, if you look at the conditional expectations of these subgradients and the conditional expectation of these elements and of the normal elements also associated with XP, then we should obtain objects. Okay, which actually satisfies. So, for instance, if you look at the G, this is the conditional expectation at empty of this G. If we take these conditional expectations, then we shall obtain these objects, okay, the one that satisfies this optimality conditions for built in. Multi-conditions for building non-anticipativity. So we have a relation between the two formulations, which is expected. So the main contributions here is introducing the concept of regulatory costs, which I mentioned already several times, that it is much easier. Is much easier to verify the regularity when we look at the just particular scenario with a particular time period. This is a finite dimensional system and we can establish subregularity for this much easier. And then we can infer the subregularity of the infinite-dimensional system. So this allows us really to verify this. To verify these abstract conditions. Also, we were able to work with the Clark subdifferential and to obtain exact formulation of the subdifferential of the form of the subdifferential when we compose that distance function with the Gausso operator and we use the And we use this as a penalty function. So, such a variational principle way of deriving optimality conditions. This was very productive. And so we think that this approach has a potential for further addressing non-linear dynamic systems, with non-linear dynamic, more general than what is currently. Than what is currently known. We are working on specific formulations for dynamic measures of risk to obtain specific optimized conditions in that case. And naturally, question is: can we use not the Clark, but say different calculus, say Kruger-Mortukovich Kalpi? Sake Kruger-Montukovic calculus, so that we have a more accurate description of the subdifferentials, because we know the Clark subdifferential is rather large, although it has advantage for numerical methods, but can be used at different differentials to allows us also to consider non-convex sets. X sets. This is a challenge because we have to describe the form of the coverifer, but if of the operator. And so far, this is only done as far as I know. Maybe my knowledge is not the best. Under frechet assumptions of fresh differentiability. And this, they don't work in LP spaces, this differentiability. Of course, optimality conditions are first step and we hope to have numerical methods for Numerical methods for problems with non-linear dynamics. So, I hope that many colleagues will find it interesting and who will try to make use of these results. Thank you for your attention and we'll be happy to take any questions. Thank you so much for the interesting talk. For the interesting talk. Are there any questions? So, there are no questions at the moment in the chat, so you can just unmute yourself, I think, or ask your question in the chat. Let's just wait for a few seconds. Sorry, I had a baby on my lap. Sorry. I had a question. Uh I had I had a question. Um so do you know if uh the assumptions that you made on um the the the operator capital F and capital Y might make the composition of the distance of f of x to y as a function from x into a Clark regular function? Yes, yes, you can. Oh, it does, okay. Yeah, it does, yeah. Okay, because That's it. Okay. Because then, I mean, at least in that case, in some instances, if that functional is clock regular, then you might not really gain much by using Mordekovich. Because then sort of like everything nice coincides. Right. This is true for convex sets, but maybe you can handle non-convex sets. Ah, okay. Yeah, I see. But this is the issue. But this is the issue is yeah. So they this is what the main the main for us the main issue is we tried for a long time to obtain precise differentiability so that we can apply other until we I mean I knew that this does not work very well in not work very well in LP, but I didn't not realize how not well it works. Because I have here even example, I had it prepared in case someone asks. So I can show it maybe. Let me share this again. I'm still sharing, I suppose. Yeah, they just have to make the screen bigger. Yeah, just have a presentation. Just have a presentation. Okay, so this is this example. Okay, so we have a function that is essentially x squared. Okay, so you have an x squared between minus one, one and then a linear function that is continuous and differentiable further outside of one one. So and this function is not even a random function, it's just plug in a random value. In a random value, is it x squared? You just plug in the random variable and it is not differentiable at zero. So, I mean, there's no hope that you get something non-linear addressed by the share. I mean, but do you need X and Y to be the same L P space? Yes, yes. You need it to be as well. That's another issue. You cannot escape from this. Escape from this. So, because if you had a norm gap, then you could get you could get differentiability of some nonlinear maps between LP spaces. But if you need the same space, then I see the problem. Yeah, that's that's no, you cannot obtain it because if you have the bigger space, then you cannot show that the other one space is bigger than the other. You also don't have precise difference of it. I don't think so. But from L P to L Q with P bigger than Q under certain assumptions on the generating. Assumptions on the generating function f, you will have fresh differentibility. You need some assumptions, but yeah, but there are other issues then. Actually, it does not work at all because then you plug it in, you have to plug it in further. Okay, yeah, yeah, I can see. But like I said, I mean, if you have a norm gap, if you can, if you can, if you're allowed to go from LP to LQ, it's big. You're allowed to go from LP to LQ with big P bigger than Q, and you have enough assumptions, then you can get fresh differentiability. They use it all the time and control of semi-linear elliptic PDEs and semi-linear parabolic PDEs. It's essential. Yeah, we can talk in one of those specials. I'll show you where the problem lies. Okay, yeah. So actually, we had at the beginning a queue, and then we wanted to see what's going on with this queue. But even This queue, but even then is a problem with the superiority. Okay, we can take it offline. Sure, yeah, there's room somewhere. Yeah, okay. Thank you for your attention. I stop sharing. Okay, so thank you very much. So see you again in about 10 minutes. So we start again at 10 and we can explore Soco in between. So Daringa, did you set up the SoCoco app on your