I just don't want to block that. I don't want to yell at it. It's a block. Very good. Okay. Cool. So next talk will be by Alex Primental. So he will be discussing sensitivity with respect to initial conditions for models of mechanics. Great. Thank you, Alexi, and thanks again to the organizers, including the one in the room with me. I'm very happy to be speaking here. I'm very happy to be speaking here. It's been a long pandemic. This is only my second conference since it began, but it's been very informative. For example, learning how to pronounce my name from Russians and Ukrainians. So today I'm going to be giving a kind of follow-up to the talk given by Jacob in the morning session on this set of results. This set of results about positively outkinov exponents for stochastically stoked Galerkinovierstokes. So the trajectory for us is that somehow I want to talk a little bit more about the general theory of these objects called Lyapunov exponents, giving asymptotic information about separation or convergence of nearby initial conditions. I am going to at least I am going to at least confer a vague impression upon you all that it is an intractable, intractably difficult problem for now to estimate Lyapunov exponents for what I will call systems of practical interest. And hopefully I'll convince you that this is a very relevant challenge for understanding the chaotic properties of deterministically forced fluid dynamics. For random systems, however, the situation is substantially more tractable. Is substantially more tractable, and I hope to convince you of that as well. In the presence of noise, somehow the statistics of tangent directions become regularized, and this opens things up considerably. The ideas that I'll talk about today, we've used in a couple of contexts in the collaboration with Sam and Jacob in a series of works starting in 2018. We applied some of these ideas. We applied some of these ideas to establishing positive Lyapunov exponents for the motion of passive tracers, or if you like, the Lagrangian flow. Sensitivity with respect to initial conditions for this flow means that if you initiate two passive tracers very close to each other and invect them by the fluid flow, then they separate exponentially fast. In 2020 and in the follow-up paper by Sam and Jacob in 2021, we established using We establish, using morally these ideas I'll talk about today, a positive Lyapunov exponent for Galerkin Navier-Stokes. That is, not Lagrangian chaos, but Eulerian chaos, at least in the case of Galerkin truncations of Navier-Stokes. The core toolkit, the bare essential mathematical idea behind these results is Furstenberg's criterion, a remarkable result initiating from Furstenberg's seminal 1968 paper. Firstenberg Seminole 1968 paper, Non-Commuting Random Products, and then kind of attaining a life of its own over the subsequent decades. That essentially the meta-theorem is something like this: that for volume-preserving systems subjected to noise, zero-Lyapunov exponents is this like horrifically degenerate situation that can be ruled out in many cases of interest. This is a kind of meta-theorem. You won't see this written down quite like this, but there are many results. This, but there are many results to this effect, and so many names that probably the talk would be over if I listed them all. But this is roughly where we're. So I'll go until two past or three past the hour. Yes? Yes? Okay, so here we are, right? Second time the CatMap, or third or fourth time the CatMap is making an appearance at this conference. I like the Cat Map because it's an I like the cat map because it's an excellent example of a hyperbolic separation of initial conditions. What's happening here is that I am applying the matrix 2111 to a vector in the unit square, and I will do this over and over and over again. And what will happen is that for two nearby initial conditions in general position, they will separate at a positive exponential rate from each other. You can kind of see this just by looking at a pair of points in the left ear of In the left ear of the cat, get separated like this, separated even further like this, and the poor cat gets completely shredded. What I would like to point out, maybe this definition isn't so important, but this EU, the eigenspace corresponding to the larger eigenvalue of 2111, and this ES corresponding to the eigenspace of smaller eigenvalue, they play the role of stable and unstable subspaces. You can think of these. You can think of these as analogs of the eigenspaces of an equilibrium of an ODE or a PDE, but in the moving frame along the dynamical system. And these conditions, this kind of contraction along stable directions and backwards contraction, this, by the way, is synonymous with expansion in the unstable directions. One can axiomatize these things. One can axiomatize these things and talk about the class of uniformly hyperbolic systems. That is, those systems for which uniform expansion and contraction are realized uniformly across space. A lot of blood has been spelt on such systems, but I will mention that in 1971, Ruelland Hawkins proposed this kind of uniform hyperbolicity as a way of explaining the transition to chaos in Couetlo. Chaos in Puetflow. What you have there is a quasi-periodic motion with two incommensurate periods that devolves into a seemingly chaotic soup. Ruel and Hawkins showed that you can take small perturbations of that quasi-periodic motion and acquire these uniformly hyperbolic systems. And so they asserted, well, you know, maybe we should be looking at these chaotic systems instead of the theory at the time, the Landau theory, that infinitely many incommensurate, quasi-periodium. Infinitely many incommensurate quasi-periodic motions were responsible. This seemed to be a lot more plausible and initiated a lot of interest. Unfortunately, uniform hyperbolicity, as it turned out, is somewhat too restrictive for a lot of purposes. And so this smooth ergodic theory, the ergodic theory of smooth systems, was built up around this idea of studying instead these quantities that we can kind of get a grip on. We can kind of get a grip on these Lyapionov exponents. The Lyapionov exponent itself in this definition is the asymptotic growth rate in Jacobian matrices after iterates are taken. The positive Lyapionov exponent indicates the presence of some kind of hyperbolic expansion or contraction. This core results in smooth ergodic theory is the multiplicative ergodic theorem, which kind of diagnoses the moving frame behavior of these. Behavior of these Jacobians and splits a tangent space into an unstable, stable, and center directions. In this telling, the unstable is the set of vectors that grow at an exponentially fast rates. That in the limit, as n goes to infinity, these blow up. The stable directions are the set where the 1 over n log sorry, my handwriting is no better than Jacob's. Where these vectors limits negative and central directions are defined to be the set where the eigenoff exponents are zero. I would note that if f preserves volume, then lambda 1 is greater than 1. Then lambda 1 is greater than or equal to 0. This is kind of an obvious fact. But otherwise, there really aren't very many restrictions on what the Lyapunov exponents can be for general systems. The trouble is, though, that in spite of this impressive abstract theory for Lyapunov exponents, stable and stable subspaces, this smoother gotic theory built up around them, it is damnably difficult to apply any of these ideas to general system, systems out there in a lot of the General systems, systems out there in the wild. And the Cherikov standard map has kind of come to exemplify these challenges. I've depicted here this a kind of phase portrait of the standard map. The coordinates aren't quite right, but if you bear with me, each individual color is a trajectory. So you have this vast green region where trajectories seem to equidistribute over a positive. Distribute over a positive area set. This is consummately chaotic, and you simulate this and you see positively optional exponents there in that green region. But then this kind of coexists with these invariant circles where trajectories are kind of locked into a rotational motion and vectors grow at most linearly. There's some shear between these, but the Lyapunov exponents are zero. These are two kind of diametrically opposing behaviors, and they coexist. Opposing behaviors and they coexist in the same phase space. And kind of these two results I'll mention sort of highlight the difficulties involved. For large values of L, you'd expect this thing to be extremely hyperbolic, right? Because that L in front of the L sine 2x is strongly increasing, roughly horizontal to the x direction, is strongly expanding in that direction. Expanding in that direction. Nevertheless, for L very, very large, you can find lots of elliptic periodic orbits. Elliptic periodic orbits can be found in every ball of size L to the minus 1 over 3. Around the elliptic periodic orbits are elliptic islands. They're encased, by KAM theory, they're encased in invariant circles that again have no chaos, zero-eptone exploits. Exponent. Meanwhile, the set where the Lyapunov exponent is positive, the so-called hyperbolic set, was proved by Gorodetsky to be of Hausdorff dimension 2 and also L to the minus 1 over 3 dense. That is, in every ball of radius L to the minus 1 over 3, there's some hyperbolic point. A big complicated set of Hausdorff dimension 2. It remains an open question to verify that that green region here, this obviously big set, is even positive volume, wide open question. Even positive volume, wide open push. I also want to highlight this very, I think, a very important work of May, of Robert May and collaborators in 1981, who maybe objection is a strong word, but pointed out that if you start with a quasi-periodic motion and deform it, you should expect the resulting deformed dynamical landscape to resemble the standard map and not this sort of uniformly hyperbolic picture. Uniformly hyperbolic picture. This is the typical picture you should expect from a deformation of a quasi-periodic motion. And so the qualitative behavior of, say, Couette flow in the transition to chaos is most likely characterized by such a picture. Well, so much for deterministic dynamics. I want to now pivot to talking about the tractability of this problem of estimating the Yapinov exponents in the presence of noise. Exponents in the presence of noise. Okay, and so for a toy model of this, well, I'd like to start off and just warm up on the idea of taking iterated compositions of IID sampled matrices of determinant one, keeping in the back of our mind that we're modeling compositions of the Jacobian of some volume preserving map. Okay. Well, they're just IID determinant one matrices. The norm is greater than or equal to one for all n. Than or equal to one for all n. And the following listed here, this Furstenberg-Kesten result is a kind of ergodic theorem, or if you like, even a strong law of large numbers almost, saying that this asymptotic exponential growth rate of norms of these matrices converges to a number. Because the matrices are of determinate one, the number is greater than or equal to zero. And of course, the key question here, right, and the question we can't answer for the standard math, when Answer for the standard math. When can eta equal zero? Is eta equals zero possible? Well, as Jacob observed, there are plenty of situations where that zero, the outcome of exponents, is realized. Random rigid rotations realize no vector growth. Random shears realize a linear rate of growth. This last one is a little bit finicky, but it realizes a stretched exponential rate of growth, something like e to the e to the root n, something like this. But at any rate, a zero-ly opinion of exponent situation. The remarkable result in this direction in 1968 by Furstenberg was that up to a kind of coordinate change, these are essentially the only possibilities. I will not state Furstenberg's full theorem, but instead I want to give you a kind of a pretty Of a projective perspective on it. So, what do I mean here? Well, what Furstenberg proved in 1968 is that if the Lyapunov exponent is equal to zero, then there is a deterministic probability measure on the space of tangent directions. Okay, so we think of these matrices as acting on S1, or Sd, sorry. This ought to be S T minus one. We think of Minus one. We think of these matrices as acting on the space of vectors, of projective directions. And what Furstenberg said is that if eta equals zero, then there's some deterministic probability measure on this space of tangent directions preserved by the action of these matrices. Okay? Now, a little bit funny thinking about this kind of thing, but what I want you to think is that I'm advecting. Want you to think right is that I'm advecting this probability measure by the matrix. So if A1 were, say, a hyperbolic matrix, like 2, 0, 0, 1, 12, I'm squeezing mass towards the horizontal axis, and I'm stretching mass away from the vertical axis. It's a little confusing, but stretching in the vector is compression in projective space, and vice versa. It's kind of a thing. Okay, it's kind of a finicky point. At any rate, I can very quickly enumerate what the invariant structure is for each of these cases. Random rigid rotations preserve Lebesgue measure. Of course, I'm just rotating the circle. It preserves Lebesgue measure. Shears preserve the horizontal axis. It preserves delta masses supported on the horizontal axis. This additional degenerate case preserves the union of the x and y axes. Axes. Again, the x and y axes are just delta masses on the circle in projective directions. So this is the basic picture, right? We've somehow associated zero-Lyapianov exponents with these invariant structures, with these invariant measures somehow. Now, I want to pursue this in a slightly more general framework, one closer to the setting of either, if you like, Lagrangian flow or Lagrangian flow or theory and chaos, but in a slightly simplified setting, just to kind of ground the ideas. What I'm going to consider now is a stochastic differential equation on, let's say, Tn for now. Let's say Tn for now. You can think of this as like a Lagrangian flow if you like. And what I'm going to do is take some sort of incompressible motion being Motion being affected by, and I will assume that this is an additive noise, so these vector fields are constants in space. As long as certain very mild regularity conditions are meet, for almost every Brownian path, I can associate to each Brownian typical Brownian paths, I can associate a stochastic flow of diffeomorphisms. That is, for each fixed sample, I map from the initial condition to the time t state. condition to the time t state of this SD, of this Markov process. If the X nod is divergence free, then the resulting stochastic flow preserves volume. So if you think of this like a Lagrangian flow, this is just an incompressibility condition for Lagrangian flow. It's not so unnatural to assume that the process is ergodic. Jacob already talked a little bit about these Hormander conditions and things. I'll completely ignore them, but except to say that when the Smarkov process is ergodic, these lens When the Smarkov process is ergodic, these limits exist. The lambda one exists and is constant with probability one. So the option of exponents makes sense. Under these kind of optimistic horror bracket spanning conditions that, again, I'm really just going to completely ignore for this talk, but I want to kind of hint at, or at least very, very generic in this setting, and you really should. Generic in this setting, and you really should expect in this setting. Under these relatively mild conditions, Bax and Nale in 1989 proved a really interesting extension of Furstomerck's criteria into this setting, that if lambda 1 is equal to 0 for a volume-preserving stochastic differential equation, then the stochastic flow is an isometry with probability 1. Okay, so you think of this as analogous to the case in Furstenberg's theorem of a rigid... Case in Furstenberg's theorem of rigid rotations. But now it's a manifold, it's an entire manifold, and the invariant structure preserved by the flow is a smooth Riemannian metric. As you can imagine, this is an extremely rigid condition, and it's not hard to rule this out via checkable conditions. This is something you can get your hands on. Unlike anything to do with deterministic chaos, this is something you can really rule out. Troublingly, though, this Troublingly, though, this theorem and other theorems of the Firstenberg claver are not quantitative. Although I can say, if I can rule out isometry, then I have a positive exponent, yada, yada, right, I can't tell you how big it is. And this is a little bit frustrating. This is especially relevant, for instance, when we talk about, say, Eulerian chaos, a very crucial aspect of the mode. Of the evolution equation of a velocity field is dissipation. Dissipation is a kind of mildly volume compressive effect, if you like, on the Galerkin-Nuffier-Stokes equations. And so it has a tendency to drag down Lyapunov exponents. It's associated with kind of shrinking them. If these kinds of theorems are not quantitative, we can't really say much about Lyapunov exponents in the presence of a little bit of dissipation. Of dissipation. This is kind of a bad situation. And so, what I'll talk about for the remainder is attempts that Sam, Jacob, and I have made to kind of extract quantitative information out of this. And sort of toward that goal, and Jacob already hinted at this in his talk, is to consider this Markov chain on tangent directions given by assembly Simply pushing forward a tangent vector, pushing forward an initial perturbation, and then tracking the direction on the unit circle where it ends up. Very natural to assume, again, under these hormones or bracket spanning conditions in various guises, that this process admits some unique absolutely continuous stationary measure. And what I'd like to show you now is again a, well, okay, if you read Furstenberg carefully, If you read Furstenberg carefully, this result appears there too. I'm just giving back to Del Credit because I'm a fan. That in fact, we can quantify the Lyapunov exponent lambda one in terms of the way that the gradients deform this stationary measure, nu x. So, what the heck's going on here? So, what the heck's going on here? Well, okay, forget this formula for a second. All right. If the determinant of B is equal to 1, as is the case for these gradients, if the determinant of B is equal to 1, then B is an isometry with respect to the standard inner product on Rn, if B sends Lebesgue to Lebesgue. B is an isometry if and only if it sends the Lebesgue measure on the unit circle to the Lebesgue measure on the unit circle. It must be some rigid rotation, it rotates rigidly. Rotation, it rotates rigidly, and this characterizes this characterizes isometry. And so, what I would like to suggest here is that this formula is describing the distance from isometry in this system. Here, these new x's, these new x's are measures on n minus 1. And what I'm doing is mapping forward. And what I'm doing is mapping forward these measures, d phi x, I'm mapping forward these measures and comparing them to the measure at time t. Now, this quantity here, this h, is the relative entropy, or if you like, the Kohlbeck-Lieber divergence. And it is a quantity with the property that h eta1 lambda is equal to the length of the length eta when lambda is equal to zero if and only if the measures eta and lambda coincide. So you can imagine it as a kind of asymmetric semi-norm on the space of measures. If this h quantity is equal to zero, then the measure is mapped forward perfectly. And if the measure is mapped forward perfectly, then this gradient was an isometry from the tangent space at x to the tangent space at phi tx. Okay? At phi tx. Whereas here, if this lambda 1 is positive, this could only be the result of some kind of accumulated deformations of these new x's. So in this formula, buried in this formula is a quantification of the rate at which my phi t is deviating from isometry. If phi t is an isometry, the Lyapunov exponent has to be zero. And all of these are sort of... Of exponent has to be zero, and all of these are sort of perfectly compatible. I apologize, this too was meant to be an ed. Okay. And so what we do, our sort of idea in this game was to take advantage of the continuous time framework in a slightly different way from Baxendale, and in this, sorry for the flipping, and in this formula to take a derivative with respect to time. To take a derivative with respect to time on the left and the right-hand sides. When one does that, on the right-hand side, we recover n times the Lyapunov exponent. On the left-hand side, after some kind of ugly Edo calculus, and when the dust settles, we recover this Fischer information type identity. Okay? And so because this is a time derivative of the deformation from Of the deformation from isometry, one can think of this left-hand side as the rates at which the deformation is occurring, the time infinitesimal rate at which this deformation is occurring on average, just to kind of compare, right? At positive time, this is some finite amount of deformation between the tangent space at x and the tangent space of phi tx. Whereas here, this one is kind of time instantaneous, really taking advantage of the fact. Really taking advantage of the fact that we are working with a continuous time stochastic system. Incidentally, it appears that Baxendale may have known this formula, but didn't think it was useful, and so never wrote it down. We've recently made contact with him. What's really remarkable about this formula, well, just to kind of dwell on this for a moment, what's really remarkable about this formula is a kind of connection. Is a kind of connection between two things that, in my mind at least, are a priori kind of quite different. On the one hand, I have Lyapunov exponents, which should be, morally speaking, related to deviation from isometry. Surely, positive Lyapunov exponents are incompatible with isometry. And this entropy formula was a very nice way of characterizing that. The Fisher information formula, on the other hand, relates the Lyapunov exponent to a partial Sobolov regularity along the Of regularity along the forced directions, okay, of the stationary statistics of tangent directions. And this I find to be somewhat mysterious. I still don't fully appreciate this. Even in toy models, I'm not quite sure. And I hope that we can extract more information from it in the future. Well, I think I'll take four more minutes. Is uh okay? Yeah, sure. Sure. Okay. Okay. Okay. So, in the context of a little bit closer to this setting of stochastically driven Navier-Stokes, we have an analogous formula of the Fisher information identity in that setting. Of course, it's no longer a direct relation to the Lyapunov exponent. Oh, oh, oh, sorry. It's no longer a direct relation to the Lyapunov exponent. Of the Lyapunov exponent, because, well, if you think before we had a factor of epsilon in front of the xk's that comes down, but we also have dissipation. And dissipation, as I mentioned earlier, drags down the Avonaut exponents. In this case, the matrix A is meant to be a Colercin truncation of the Laplacian, or negative A is a Calercon truncation of the Laplacian, and so the trace of A. Caution. And so the trace of A is some positive number. And it's kind of taking away from the lambda one in some sense. Now, in view of this kind of Hohrmander type, this kind of L1, these L1 Hohrmander estimates for the Fisher information, we were able to bound the Fisher. Bound the Fisher information from below by some weak solo of regularity. This implies that if the lambda 1 divided by epsilon is finite and the limit as epsilon goes to 0, then there is some pre-compact sequence of these densities on projective directions. Okay? And so we obtain the following dichotomy. In our setting, either epsilon inverse lambda 1 goes to infinity, Lambda 1 goes to infinity, or there exists an invariant density for the epsilon equals zero dynamics of xt vt, that is combining the position in state space with the tangent direction. And I want to dwell on the second alternative. As I said earlier, for random systems, preservation of some density in projective directions is kind of a rare thing. Well, something similar is true for deterministic systems. Remember that. Remember that a matrix, a determinant one matrix preserves Lebesgue measure, preserves a density if and only if it's an isometry. This has a similar flavor. If the zero noise dynamics admits an invariant density, if the zero noise projective dynamics admits an invariant density, then there is some measurably varying metric on Rn so that the zero noise is not density. So, that the zero noise flow is an isometry. In this case, Galerkin Euler. In this case, Galerkin Euler is an isometry with respect to some potentially low regularity metric on Rn. It's a little bit hard to imagine what a low regularity metric on Rn means, and I actually don't know how to improve this regularity. It seems to be open for the Navier-Stokes equations, or in the context of the paper that Jay. Of the paper that Jacob presented this morning. This kind of isometry is ruled out by the shearing between energy hypersurfaces. Galerken Euler preserves the L2 balls. These are energy balls. Preserves these energy spheres. Between two energy spheres of slightly different energies, the dynamics on the higher energy surface is a little bit faster than the lower energy surface. The lower energy surface. Okay, and so this creates a kind of tilting, a kind of tilting in the or shearing effect along the surface of the along these hypersurfaces along these hypersurfaces. And this is incompatible with the isometry. And so the alternative one has to hold. So what I would like to emphasize on the last slide is that shearing between energy surfaces is probably not. Energy surfaces is probably not the dominant mechanism of chaos in the Navier-Stokes equations. I would be shocked if it were. But on the other hand, it's extremely difficult to get a handle on any other mechanisms. These would be mechanisms happening inside the energy surfaces. These are very complicated dynamics, which, as we saw from Robert May's objection, could well be tied to very complicated coexistence problems for the Apkinov exponents. And really, we don't have any good tools. Any good tools at the moment for dealing with that? A very natural question is to attempt to improve our scaling of the Lyapunov exponent. Really, there's some expectation that perhaps this top Lyapunov exponent is like order one as epsilon goes to zero, but we're a bit far from saying anything about that. It's of course also of natural interest to go from the Galurkin truncations to the full Maudier-Stokes equations, but again, this is kind of a long-term. This is kind of a long journal. So, thank you very much, and I'll stop here. Thank you very much.